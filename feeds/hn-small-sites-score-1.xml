<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 27 Nov 2020 08:29:26 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 27 Nov 2020 08:29:25 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[I wrote a script in 4 hours that will save my hospital $40k every year]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25207590">thread link</a>) | @joshcase
<br/>
November 25, 2020 | https://joshcase.dev/articles/i-wrote-a-script-in-4-hours-that-will-save-my-hospital-40k-every-year | <a href="https://web.archive.org/web/*/https://joshcase.dev/articles/i-wrote-a-script-in-4-hours-that-will-save-my-hospital-40k-every-year">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

            <div>
                    <div>
        
        <h2>An example of JavaScript automation at work in medicine</h2>

        
            <p><img src="https://joshcase.dev/img/articles/script-in-4-hours/notepad-pathology-js.png"></p><p>
    	I'm not sure if you've ever tried to write an app in Notepad - but I <b>really</b> don't recommend it. Although, when inspiration strikes, you've got to make do with the tools you've got in front of you.
    </p>

    <p>
    	You can view the the <b>pathology.js</b> script repository in its entirety on <a href="https://github.com/joshcase/pathology.js/blob/master/pathology.js">GitHub</a>.
    </p>

    <p>
    	If you're often frustrated with the volume of <i>"copy and paste"</i> or simple data entry required to complete a task at your workplace or elsewhere, you're probably looking at a problem that could be solved with <b>automation</b>.
    </p>

    <p>
    	<b>Automation</b> refers to using computer programs to handle tedious or repetitive tasks, freeing up humans for more meaningful work.
    </p>

    <p>
    	I recently found myself in such a situation when I joined a general surgery unit at a hospital in Australia. The unit employs 4-6 junior doctors to start work up to 60 minutes before everyone else does, purely to manually update a list of patients under their care, along with their current management plans and pathology results.
    </p>

    <p>
    	 The idea is that all the clinical information is collated into a portable, easy-to-read format for the senior decision makers to digest. This document is affectionately known as <b>The Listâ„¢</b>. Here's a de-identified example of what I mean:
    </p>

    <p><img src="https://joshcase.dev/img/articles/script-in-4-hours/list.png"></p><p>
    	Once the information is organised in this way, it provides a convenient overview of the unit and the patients under our care. The problem is that creating <b>The Listâ„¢</b> is a tedious and time-consuming task that virtually all of the junior doctors I know dread. On a weekend, there might be <b>40 patients</b> on <b>The Listâ„¢</b>, all of whom need their blood tests from the last 24 hours manually entered into the correct table - all before you start work! Ouch.
    </p>

    <p>
    	Above all, it makes the job less enjoyable, and is probably a contributor to clinician burnout, as most of the clinicians I know signed up to see and treat patients rather than to fill out spreadsheets.
    </p>

    <p>
    	Unfortunately, most hospitals in Australia and indeed the world hold their information in independent silos that aren't integrated. As a result there's a huge administrative overhead associated with checking multiple sources of information and centralising it.
    </p>

    <p>
    	In this case specifically, there are typically 5 junior doctors each weekday spending anywhere from 15 minutes to 1 hour preparing <b>The Listâ„¢</b>. Opening our patient information system, copying patient details, cross-checking that with our pathology system, copying across the new information - <i>ad nauseam</i>.
    </p>

    <p>
    	For simplicity's sake, let's say there's 5 doctors spending 30 minutes every week day doing this, as well as 1 doctor spending 1.5 hours each day of the weekend.
    </p>

    <p>
    	Assuming we're paying the doctors at overtime rates ($50 per hour), we can cost the labour used for this task annually as follows:
    </p>

    <p>
        Annual Cost ($AUD) = 50 * (5 * 5 * 0.5 + 2 * 1.5) * 52
    </p>

    <p>
    	Which gives us a grand total of <b>$40,300</b> annually. That's a truckload of public cash!
    </p>

    <p>
    	But given this task is highly repetitive and data-entry focused, could we try and automate it?
    </p>

    <p>
    	<i>Yes. Yes we can.</i>
    </p>

    <p>
    	Being the lazy, bratty and entitled millenial I am, after working this job for less than one week, I knew there had to be a better way.
    </p>

    <p>
    	I initially hoped to open a dialogue with the hospital IT department to allow me to deploy a Python application to handle this task for us, but I quickly realised that this route would likely take 6 months of emailing alone before they'd even consider letting me start experimenting with the problem at hand.
    </p>

    <p>
    	Furthermore, maintaining a Python environment on any of the computers where I wanted the script to run would be an absolute headache. So Python seems to be a no-go.
    </p>

    <p>
    	It wasn't until I realised (mid shift, I might add) that I didn't need executable rights to solve this problem at all.
    </p>

    <p>
    	I immediately took my lunch break and fired up <b>*Notepad*</b> of all apps to start throwing together the solution. Desperate times call for desperate measures.
    </p>

    <p>
    	The hospital I'm referring to uses a program called the <b>The Viewer</b> in an attempt to centralise all the information from the different silos I mentioned above. The Viewer is a browser-based web application that asynchronously loads information about a given patient and their admission through hospital.
    </p>

    <p>
    	<i>Because I take patient privacy really seriously and because I'm quite paranoid about accidentally leaking patient data, I've decided not to include a screenshot of The Viewer.</i>
    </p>

    <p>
    	When you open a patient on The Viewer, it first opens a blank web page, and then subsequently sends additional web requests to each of the information silos to get information about the patient - what their recent blood tests have been, what their recent scans have shown, when their outpatient appointments are <i>et cetera</i>. It then populates this initially blank web page with the information it received from the web requests to each of the respective silos.
    </p>

    <p>
    	Any time you open a webpage, depending on which browser you're running, you can right click on the page, click <b>Inspect</b> to open a special menu, and then look for some variation of the <b>Network</b> tab. This essentially allows you to view all the web traffic that is coming to and from the page you've got open.
    </p>

    <p>
    	Here's an example of the Network tab for <i>joshcase.dev</i>:
    </p>

    <p><img src="https://joshcase.dev/img/articles/script-in-4-hours/network-tab.png"></p><p>
    	It's fairly messy to the untrained eye, but you can certainly see a few familiar things: requests to load images like <i>josh-case.png</i> (the portrait for the website footer), to load <i>main.css</i> (the file that has all the webpage structure/decoration information in it) as well as files like <i>list.png</i> that constitute the other pictures in the article.
    </p>

    <p>
    	By refreshing the web page a few times and by poking around, I eventually realised The Viewer was leveraging a script called <b>GetCompletedContent</b> to load the information from each of the information silos.
    </p>

    <p>
    	What's more, when you click on a specific web request in the Network tab, you can see which parameters were sent with the request, essentially allowing you to understand what sort of structure the server is expecting:
    </p>

    <p><img src="https://joshcase.dev/img/articles/script-in-4-hours/network-parameters.png"></p><p>
    	Again, this image isn't from The Viewer, it's also from a <i>joshcase.dev</i> request relating to MailChimp, but you can still see the Query String Parameters that represent the type of data the corresponding server is expecting.
    </p>

    <p>
    	Working this out enabled me to reverse-engineer The Viewer pathology API to poll the hospital servers for specific patient information using JavaScript. I could leverage the knowledge of the <b>GetCompletedContent</b> request and the structure it uses to request pathology information, to automatically pull the information for a given patient.
    </p>

    <p>
    	All I had to do was send a similar request to <b>The Viewer</b> servers in the way <b>GetCompletedContent</b> did:
    </p>

    <p><img src="https://joshcase.dev/img/articles/script-in-4-hours/pathology-request.png"></p><p>
    	And the beauty of using JavaScript to attack this problem is that it will run on any hospital machine at any time - as every modern browser will interpret and run JavaScript.
    </p>

    <p>
    	If you're new around here and don't believe me, right click on this webpage (anywhere) and click <b>Inspect</b>. Look for and click on the <b>Console</b> tab. Copy the following code, and paste it into the console text box:
    </p>

    <p>
        alert("JavaScript will run anywhere.");
    </p>

    <p>
    	And then hit enter. Awesome, right?!
    </p>

    <p>
    	Once I'd written the script to emulate the <b>GetCompletedContent</b> request for the blood test silo, there were a few other implementation details to iron out, (such as parsing the response information and compiling it nicely into a readable table) but the lion's share of the detective work had been done.
    </p>

    <p>
    	A job that once took 5 people 45 minutes to complete now takes 1 person 10 minutes.
    </p>

    <p>
    	That's poised to save the hospital $400,000 over the next 10 years!
    </p>

    <p>
    	 Isn't technology awesome?
    </p>

    <p>
    	If you like stories about technology and medicine, be sure to follow me on <a href="https://twitter.com/_JoshCase">Twitter</a>.
    </p>


        <p>________________</p>        
        

    </div>
            </div>

        </div></div>]]>
            </description>
            <link>https://joshcase.dev/articles/i-wrote-a-script-in-4-hours-that-will-save-my-hospital-40k-every-year</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207590</guid>
            <pubDate>Wed, 25 Nov 2020 10:01:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asking a Tech Recruiter]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25207447">thread link</a>) | @lawik
<br/>
November 25, 2020 | https://underjord.io/asking-a-tech-recruiter.html | <a href="https://web.archive.org/web/*/https://underjord.io/asking-a-tech-recruiter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2020-11-25</small>
        <p>Since I left my comfy job as the tech lead for a SaaS product and went into running my own business I took a closer look at my relationship with recruiters. While working I mostly found the attention of recruiters slightly reassuring but often annoying. I think that annoyance is fairly common, usually built up from countless LinkedIn drive-by attempts from unreading keyword-hunting recruiters. I thought that now, out on my own, maybe this legion of recruiters can be my sales department. And they have been, to an extent.</p>
<p>During my first few days as a free agent I did reach out to one recruiter in particular. This was the one that had been closest to dislodging me from my previous position and I had a feeling he was a sharp one. I had also thrown my cousin at him and he had helped him land his first real ops gig. When I got in touch this recruiter quite swiftly landed me my first client. In parallel I started to accept more recruiter connections and had a lot more conversations with assorted recruitment agencies. It has netted a fair bit of work. But I dare say the hit-rate is mostly low.</p>
<p>The recruiters that I’ve found to give the best results also give recurring results. They are the people that follow up, consider your needs, balance them with client needs and make things happen. It is my feeling that there remains a large cultural gap between the majority of recruiters and developers. I’ve been thinking about how to usefully bridge that. I don’t particularly need it right now but I want to help junior developers find their way into work and more experienced developers find their way to what they actually want. I think recruiters could help there. But I think we’re still quite far off from that.</p>
<p>I reached out  about this to my network on LinkedIn (where the recruiters live). I got a response from Emy Wennerberg Kristoffersson who was willing to take a chance and reach some new developers. Emy works mostly in Sweden around Gothenburg and Helsingborg, so while she might not work in your particular area I think the information and exchange is widely applicable. We figured a good first step is to tackle some of the common skepticisms that developers tend to have around recruiters and recruitment. I hope this will be helpful. The post is not sponsored, I asked her to answer a bunch of uncomfortable and nuanced questions which I think she does gracefully. Let’s get into it.</p>
<p><strong>For some background, can you introduce yourself and tell us a little bit about your professional experience?</strong></p>
<p>Emy: My name is Emy Wennerberg Kristoffersson. I was born and raised in Helsingborg (south of Sweden), but moved to Gothenburg back in 2016. I am passionate about tech, human beings and business development. I settled on tech-recruitment because it gives me the opportunity to combine all of these areas. For the last three years, I have been working in the recruitment industry. I work for Bonsai Consulting, a Gothenburg-based company that specializes in tech recruitment.</p>
<p>I have always had a huge tech-interest. Though, this wasn’t something that I seized back in my younger years, at least not to a greater extent (apart from when loved ones encountered technical problems and I wanted to impress – hah!). My father has always been in the IT sector so I’m quite sure that his tech skills have influenced me. I am a people-person at heart, so I eventually decided to study Human Resources in Gothenburg. In time, I got in touch with Bonsai Consulting whereupon I started to work as a researcher, and my main task was to build a network of candidates who were open to new opportunities. After a couple of months, I leveled up to a position as a recruiter and got a bigger responsibility within the company. Back then we worked broadly in recruitment and recruited to many different industries, but due to my tech-interest, the positions that related to IT and tech always ended up on my desk. One and a half years ago, we decided to work exclusively with tech recruitment due to the enormous demand within the industry.</p>
<p>One of the most interesting things in my profession is the potential for improvement in the recruitment industry. Today, I am aware that there is a lot of frustration against the recruitment profession and I do think that this is a misconception. Many jobseekers consider recruiters as an annoying part of the job search. Generally speaking, we have a pretty bad reputation (let’s talk more about this later). But the thing is, in fact, that we are an asset in a candidate’s job search and in a company’s recruiting process. My vision is to get fewer people out there to see us as an annoying piece of the puzzle, and instead see the value of taking our help as a job coach.</p>
<p><strong>Finding and hiring experienced developers has been a challenging proposition for a while due simply to enormous demand, how does this affect your job?</strong></p>
<p>Emy: The first thing that comes to my mind, is the challenge of getting the companies to understand the market and the developers’ situation. It is a bitter pill to swallow for many recruiters and companies, but today many developers have at least 4-5 opportunities available for him or her. Unfortunately, not all companies understand how coveted many developers are, and therefore they don’t understand the necessity of offering a great deal to potential employees. Not just the salary has been rising during the last years, other requirements have changed considerably as well. Today, many developers expect to be able to work remotely, having flexibility in their working day, good opportunities to develop within the company and to be able to develop their own skills (and so on…). Outstanding developers know their value on the market, and if a company’s position doesn’t sound interesting or profitable, they will go on to their next available opportunity. Many companies lack the understanding of how many offers a developer can have on their table and are therefore unable (or even unwilling) to match their needs. This is a tough nut to crack.</p>
<p>Another thing that comes top of mind is the art of standing out as a recruiter. Due to the enormous demand, many developers are likely to get contacted by a countless number of recruiters every day. The old-fashioned way of sending an email to a developer saying “Hi, here’s a job I’d like you to consider” doesn’t work today. Why? Because that developer has probably received multiple requests from other recruiters already, and my message is likely to disappear somewhere in all that noise. Over the years that I have worked as a recruiter, I have come to understand the importance of understanding the developers needs and desires before sending them multiple job descriptions, preferably even before I contact him or her. It is my duty, as a recruiter, to do my research before I expect a developer to take his or her time to talk with me. For example, If I check their Github I may find out that this developer prefers back-end development in C#/.Net, then I know that it won’t be necessary for me to contact him or her in order to talk about a front-end position where your main focus is in React and Typescript. If I don’t do my research, I’m likely to waste the person’s time. If I don’t find anything on Github or similar, then I think it is pure decency of me to first of all ask if they are interested in having a conversation with me and if they are, I can’t just throw a job description in their face without first understanding what this person is interested in.</p>
<p><strong>Has everything changed with the pandemic? Is development work hard to find now?</strong></p>
<p>Emy: A lot has changed with the pandemic. From my experience, I think that the biggest challenge for recruiters right now is that developers in general are unwilling to take on a new job, even though they might know that their current position isn’t exactly what they want. I think it’s a result of the uncertainty with the pandemic, that no one knows how it will develop and what will happen next. Since the pandemic seriously shook the market during spring and summer, many developers are worried that it will put them in a situation where they’ve left a permanent employment and the safety that it entails, to be the “last man/woman in, first out”.</p>
<p>In the beginning of the pandemic the market was disastrous, from March until September it was clear that even the IT-industry (despite the great demand) suffered from the pandemic. Many start-ups had to end their businesses and bigger companies were prohibited from hiring, many were even forced to dismiss employees in order to survive. Since August until today it has eased, and more companies dare to hire today. With that said though, companies take precautions when hiring and the processes might include more steps than normally in order to be really sure that it’s a good fit for the position.</p>
<p>I’d say that there are many opportunities on the market by now, but of course we are far from “normal”. Unfortunately, many companies demand more senior developers today, in order to fill the positions that they dismissed during spring. So, for junior developers it may still be a challenge to find their first or next position. Many companies can hire junior developers as a short-term consultant-assignment, so it is advantageous to be open to these opportunities as a junior developer.</p>
<p><strong>Is the poor reputation of the recruitment profession in tech among developers deserved or overstated?</strong></p>
<p>Emy: Sadly, I do think that it is deserved. I think that many recruiters have the wrong approach when recruiting for developer-positions. I have talked to many, many, many developers about this, and my understanding of the situation is that developers experience that recruiters don’t understand them nor their industry. And above all, many developers think that recruiters are a bit ignorant and uninterested in understanding it.</p>
<p>Recruiters and developers communicate differently, which is natural due to very different professions. …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://underjord.io/asking-a-tech-recruiter.html">https://underjord.io/asking-a-tech-recruiter.html</a></em></p>]]>
            </description>
            <link>https://underjord.io/asking-a-tech-recruiter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207447</guid>
            <pubDate>Wed, 25 Nov 2020 09:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Prime Number Shitting Bear]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25207219">thread link</a>) | @velmu
<br/>
November 25, 2020 | https://alpha61.com/primenumbershittingbear/ | <a href="https://web.archive.org/web/*/https://alpha61.com/primenumbershittingbear/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
  <p>"I'm only human, Harry."<br>
	<i>- Jim Carrey as "Lloyd Christmas" in Dumb and Dumber</i></p>

  </div></div>]]>
            </description>
            <link>https://alpha61.com/primenumbershittingbear/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207219</guid>
            <pubDate>Wed, 25 Nov 2020 08:54:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An opinionated list of best practices for textual websites]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25207055">thread link</a>) | @dijit
<br/>
November 25, 2020 | https://seirdy.one/2020/11/23/website-best-practices.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2020/11/23/website-best-practices.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<p><em>The following applies to minimal websites that focus primarily on text. It does not
apply to websites that have a lot of non-textual content. It also does not apply to
websites that focus more on generating revenue or pleasing investors than being good
websites.</em></p>
<p>This is a “living document” that I add to as I receive feedback. See the
<a href="https://git.sr.ht/~seirdy/seirdy.one/log/master/content/posts/website-best-practices.md">changelog</a>.</p>
<p>I realize not everybody’s going to ditch the Web and switch to Gemini or Gopher today
(that’ll take, like, a month at the longest). Until that happens, here’s a
non-exhaustive, highly-opinionated list of best practices for websites that focus
primarily on text:</p>
<ul>
<li>Final page weight under 50kb without images, and under 200kb with images.</li>
<li>Works in Lynx, w3m, links (both graphics and text mode), Netsurf, and Dillo</li>
<li>Works with popular article-extractors (e.g.&nbsp;Readability) and HTML-to-Markdown
converters. This is a good way to verify that your site uses simple HTML and works
with most non-browser article readers (e.g.&nbsp;ebook converters, PDF exports).</li>
<li>No scripts or interactivity (preferably enforced at the CSP level)</li>
<li>No cookies</li>
<li>No animations</li>
<li>No fonts–local or remote–besides <code>sans-serif</code> and <code>monospace</code>. More on this
below.</li>
<li>No referrers</li>
<li>No requests after the page finishes loading</li>
<li>No 3rd-party resources (preferably enforced at the CSP level)</li>
<li>No lazy loading (more on this below)</li>
<li>No custom colors OR explicitly set the both foreground and background colors. More
on this below.</li>
<li>A maximum line length for readability</li>
<li>Server configured to support compression (gzip, optionally zstd as well). It’s a
free speed boost.</li>
<li>Supports dark mode via a CSS media feature and/or works with most “dark mode”
browser addons. More on this below.</li>
<li>A good score on Mozilla’s <a href="https://observatory.mozilla.org/">HTTP Observatory</a></li>
<li>Optimized images.</li>
<li>Maybe HTTP/2. There are some cases in which HTTP/2 can make things slower. Run some
tests to find out.</li>
</ul>
<p>I’d like to re-iterate yet another time that this only applies to websites that
primarily focus on text. If graphics, interactivity, etc. are an important part of
your website, less (possibly none) of this article applies.</p>
<p>Earlier revisions of this post generated some responses I thought I should address
below. Special thanks to the IRC and <a href="https://lobste.rs/s/akcw1m">Lobsters</a> users who
gave good feedback!</p>
<h2 id="about-fonts">About fonts</h2>
<p>If you <em>really</em> want, you could use <code>serif</code> instead of <code>sans-serif</code>, but serif fonts
tend to look worse on low-res monitors. Not every screen’s DPI has three digits.</p>
<p>To ship custom fonts is to assert that branding is more important than user choice.
That might very well be a reasonable thing to do; branding isn’t evil! It isn’t
<em>usually</em> the case for textual websites, though. Beyond basic layout and optionally
supporting dark mode, authors generally shouldn’t dictate the presentation of their
websites; that is the job of the user agent. Most websites are not important enough
to look completely different from the rest of the user’s system.</p>
<p>A personal example: I set my preferred fonts in my computer’s fontconfig settings.
Now every website that uses <code>sans-serif</code> will have my preferred font. Sites with
<code>sans-serif</code> blend into the users' systems instead of sticking out.</p>
<h3 id="but-most-users-dont-change-their-fonts">But most users don’t change their fonts…</h3>
<p>The “users don’t know better and need us to make decisions for them” mindset isn’t
without merits; however, in my opinion, it’s overused. Using system fonts doesn’t
make your website harder to use, but it does make it smaller and stick out less to
the subset of users who care enough about fonts to change them. This argument isn’t
about making software easier for non-technical users; it’s about branding by
asserting a personal preference.</p>
<h3 id="cant-users-globally-override-stylesheets-instead">Can’t users globally override stylesheets instead?</h3>
<p>It’s not a good idea to require users to automatically override website stylesheets.
Doing so would break websites that use fonts such as Font Awesome to display vector
icons. We shouldn’t have these users constantly battle with websites the same way
that many adblocking/script-blocking users (myself included) already do when there’s
a better option.</p>
<p>That being said, many users <em>do</em> actually override stylesheets. We shouldn’t
<em>require</em> them to do so, but we should keep our pages from breaking in case they do.
Pages following this article’s advice will probably work perfectly well in these
cases without any extra effort.</p>
<h3 id="but-wouldnt-that-allow-a-website-to-fingerprint-with-fonts">But wouldn’t that allow a website to fingerprint with fonts?</h3>
<p>I don’t know much about fingerprinting, except that you can’t do font enumeration
without JavaScript. Since text-based websites that follow these best-practices don’t
send requests after the page loads and have no scripts, fingerprinting via font
enumeration is a non-issue on those sites.</p>
<p>Other websites can still fingerprint via font enumeration using JavaScript. They
don’t need to stop at seeing what sans-serif maps to; they can see all the available
fonts on a user’s system, the user’s canvas fingerprint, window dimensions, etc. Some
of these can be mitigated with Firefox’s <code>privacy.resistFingerprinting</code> setting, but
that setting also understandably overrides user font preferences.</p>
<p>Ultimately, surveillance self-defense on the web is an arms race full of trade-offs.
If you want both privacy and customizability, the web is not the place to look; try
Gemini or Gopher instead.</p>
<h2 id="about-lazy-loading">About lazy loading</h2>
<p>For users on slow connections, lazy loading is often frustrating. I think I can speak
for some of these users: mobile data near my home has a number of “dead zones” with
abysmal download speeds, and my home’s Wi-Fi repeater setup occasionally results in
packet loss rates above 60% (!!).</p>
<p>Users on poor connections have better things to do than idly wait for pages to load.
They might open multiple links in background tabs to wait for them all to load at
once, or switch to another window/app and come back when loading finishes. They might
also open links while on a good connection before switching to a poor connection; I
know that I often open 10-20 links on Wi-Fi before going out for a walk in a
mobile-data dead-zone.</p>
<p>Unfortunately, pages with lazy loading don’t finish loading off-screen images in the
background. To load this content ahead of time, users need to switch to the loading
page and slowly scroll to the bottom to ensure that all the important content appears
on-screen and starts loading. Website owners shouldn’t expect users to have to jump
through these ridiculous hoops.</p>
<h3 id="wouldnt-this-be-solved-by-combining-lazy-loading-with-pre-loadingpre-fetching">Wouldn’t this be solved by combining lazy loading with pre-loading/pre-fetching?</h3>
<p>A large number of users with poor connections also have capped data, and would prefer
that pages don’t decide to predictively load content ahead-of-time for them. Some go
so far as to disable this behavior to avoid data overages. Savvy privacy-conscious
users also generally disable pre-loading because they don’t have reason to trust that
linked content doesn’t practice dark patterns like tracking without consent.</p>
<p>Users who click a link <em>choose</em> to load a full page. Loading pages that a user hasn’t
clicked on is making a choice for that user.</p>
<h3 id="cant-users-on-poor-connections-disable-images">Can’t users on poor connections disable images?</h3>
<p>I have two responses:</p>
<ol>
<li>If an image isn’t essential, you shouldn’t include it inline.</li>
<li>Yes, users could disable images. That’s <em>their</em> choice. If your page uses lazy
loading, you’ve effectively (and probably unintentionally) made that choice for a
large number of users.</li>
</ol>
<h2 id="about-custom-colors">About custom colors</h2>
<p>Some users' browsers set default page colors that aren’t black-on-white. For
instance, Linux users who enable GTK style overrides might default to having white
text on a dark background. Websites that explicitly set foreground colors but leave
the default background color (or vice-versa) end up being difficult to read. Here’s
an example:</p>
<picture>
<source srcset="https://seirdy.one/misc/website_colors.webp" type="image/webp">
<img src="https://seirdy.one/misc/website_colors.png" alt="This page with a grey background, a header with unreadable black/grey text, and unreadable white-on-white code snippets">
</picture>
<p>If you do explicitly set colors, please also include a dark theme using a media
query: <code>@media (prefers-color-scheme: dark)</code>. For more info, read the relevant docs
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme">on
MDN</a></p>
<h2 id="image-optimization">Image optimization</h2>
<p>Some image optimization tools I use:</p>
<ul>
<li><a href="http://pngquant.org/">pngquant</a> (lossy)</li>
<li><a href="https://github.com/shssoichiro/oxipng">Oxipng</a> (lossless)</li>
<li><a href="https://github.com/tjko/jpegoptim">jpegoptim</a> (lossless or lossy)</li>
<li><a href="https://developers.google.com/speed/webp/docs/cwebp">cwebp</a> (lossless or lossy)</li>
</ul>
<p>I put together a <a href="https://git.sr.ht/~seirdy/dotfiles/tree/3b722a843f3945a1bdf98672e09786f0213ec6f6/Executables/shell-scripts/bin/optimize-image">quick
script</a>
to losslessly optimize images using these programs in my dotfile repo.</p>
<p>You also might want to use the HTML <code>&lt;picture&gt;</code> element, using JPEG/PNG as a fallback
for more efficient formats such as WebP or AVIF. More info in the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture">MDN
docs</a></p>
<p>Most of my images will probably be screenshots that start as PNGs. My typical flow:</p>
<ol>
<li>Lossy compression with <code>pngquant</code></li>
<li>Losslessly optimize the result with <code>oxipng</code> and its Zopfli backend (slow)</li>
<li>Also create a lossless WebP from the lossy PNG, using <code>cwebp</code></li>
<li>Include the resulting WebP in the page, with a fallback to the PNG using a <code>&lt;picture&gt;</code> element.</li>
</ol>
<p>It might seem odd to create a lossless WebP from a lossy PNG, but I’ve found that it’s the best way to get the smallest possible image at the minimum acceptable quality for screenshots with solid backgrounds.</p>
<h2 id="other-places-to-check-out">Other places to check out</h2>
<p>The <a href="https://250kb.club/">250kb club</a> gathers websites at or under 250kb, and also
rewards websites that have a high ratio of content size to total size.</p>
<p>Also see <a href="https://motherfuckingwebsite.com/">Motherfucking Website</a>. Motherfucking
Website inspired several unofficial sequels that tried to gently improve upon it. My
favorite is <a href="https://bestmotherfucking.website/">Best Motherfucking Website</a>.</p>
</article></div>]]>
            </description>
            <link>https://seirdy.one/2020/11/23/website-best-practices.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207055</guid>
            <pubDate>Wed, 25 Nov 2020 08:24:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tihs sbmcraeld txet is rdalebae. Did Cagmdirbe rrhaerceses rlleay dscivoer it?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206928">thread link</a>) | @sebmellen
<br/>
November 25, 2020 | https://www.douglastwitchell.com/scrambled_words.php | <a href="https://web.archive.org/web/*/https://www.douglastwitchell.com/scrambled_words.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.douglastwitchell.com/scrambled_words.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206928</guid>
            <pubDate>Wed, 25 Nov 2020 08:03:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Soy Rule – A Productivity Strategy That Takes Care of Your Time]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206785">thread link</a>) | @iuliangulea
<br/>
November 24, 2020 | https://iuliangulea.com/the-soy-rule/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/the-soy-rule/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://iuliangulea.com/images/soy-rule-cover.png" alt="The SOY Rule cover"></p><p>How many times have you found yourself overwhelmed by the number of commitments you said “yes” to previously? Maybe you even wished you didn’t take some opportunities in the first place. Not because it is not worth doing or is not attractive, but because you don’t have enough time to dedicate to it and thus you have to allocate time from other activities, and that hurts those commitments?</p><h2 id="the-problem">The Problem</h2><p>There is an ever-increasing amount of possibilities and opportunities, but you have to put in time and effort to benefit from them.</p><p>That is not really a problem in itself—the problem comes when you analyze and decide whether to take on the next opportunity that came your way or not.</p><p>The thing is—we are terrible at estimating work as we often underestimate the time needed to perform a task or work on a project. This behavior even has its own name and is called the <a href="https://en.wikipedia.org/wiki/Planning_fallacy">Planning Fallacy</a>:</p><blockquote><p>The <strong>planning fallacy</strong> is a phenomenon in which predictions about how much time will be needed to complete a future task display an optimism bias and underestimate the time needed. This phenomenon sometimes occurs regardless of the individual’s knowledge that past tasks of a similar nature have taken longer to complete than generally planned.</p></blockquote><p>But this is only part of the problem. Another aspect is that whenever we are presented with an opportunity that we like, our enthusiasm and the rewards we anticipate to obtain (both material and psychological) can play against us.</p><p>It is very easy to imagine you at the end of that journey, but you have very little information to be able to imagine yourself along its entire way. That’s why you have to gather as much information as possible and consider the effort you will have to put into it carefully.</p><h2 id="the-solution">The Solution</h2><p>The best way to resolve a problem is to anticipate it. Thus, to avoid such situations in which you find yourself overwhelmed, it makes sense to limit the number of projects you can involve in at any given time.</p><p>Now, I totally understand that any opportunity has its benefits, and I am not advocating here to turn all of them down. But you must have enough time and energy for the currently ongoing things in your life as well as some personal time in which you can do whatever it takes to recharge your batteries and take care of your body and mind.</p><p>Therefore, I came up with a rule that helps me tame my sometimes excessive proactivity and readiness to take on more projects (this is one of my <a href="https://iuliangulea.com/productivity/">favorite productivity strategies</a>. I call it <strong>The SOY (Stop Overwhelming Yourself) Rule</strong> and it is extremely simple, yet it proved itself many times over the years:</p><blockquote><p>You can have at most three projects you can work on at the same time.</p></blockquote><p>And here, a “project” is any commitment that requires your involvement of at least 2 hours a day for at least one week.</p><p>Thus, whenever someone comes up to you with the next great idea and asks whether you are willing to join and contribute, think of what you have currently going on in your life. For instance, if you have a job, write a blog, and try to work on a project of your own, you will probably not have enough time and energy for the new project, regardless of how much you like it.</p><p>In such cases, you must have a clear understanding of what is expected from you and what the project requirements are. Then, it helps to take some time to process and weigh in all the Pros and Cons. And then, you have to either say “no” to the opportunity or put some of your current projects on hold.</p><p>One essential thing to mention is that the SOY Rule is a long term strategy. Yes, you can take on more than three projects once in a while if you know you’ll be done with one of them in less than a month. But in the long term, if you keep it over a period longer than several weeks, your performance will suffer.</p><p>If you liked this article, consider subscribing below and following me on twitter (<a href="https://twitter.com/iuliangulea">@iuliangulea</a>).</p><hr></div></div>]]>
            </description>
            <link>https://iuliangulea.com/the-soy-rule/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206785</guid>
            <pubDate>Wed, 25 Nov 2020 07:34:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to get lots of ideas for side projects and writing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25206661">thread link</a>) | @thesephist
<br/>
November 24, 2020 | https://linus.coffee/note/having-ideas/ | <a href="https://web.archive.org/web/*/https://linus.coffee/note/having-ideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>People ask me how I get so many <a href="https://thesephist.com/projects/">ideas for interesting side projects</a> and <a href="https://thesephist/posts/">blog posts</a>.</p>
<p>I think the best way to describe my growth as a writer/maker over time is that I’ve become more efficient at discovering and refining my own ideas.</p>
<p>There are always ideas floating around in your brain. Sometimes, it comes to you out of the blue in the shower. Sometimes, you’re reading the news over dinner and a particular combination of words sets off a lightbulb. Sometimes, you’re reading and a metaphor resonates with you, so you contemplate on it in the hopes that it leads to an interesting perspective on something else. The key is to <strong>pay attention to your own wandering mind</strong>, notice when good ideas pass by in your mind for a split second, and grab a hold of it and pin it down on your mental desk and don’t let go, until you can expand that idea into something more interesting or valuable.</p>
<hr>
<p>There are fundamentally two knobs you can turn in the imaginary faucet of ideas.</p>
<p>The first is your <strong>creative input</strong>. This is a measure of the diversity and volume of interesting stories, knowledge, music, ideas, and advice you hear regularly. More and more, interesting ideas come to me as a combination of something I read or learned before, and an interesting metaphor or perspective I hear in the moment. The more quality, creative content you consume, the more source material you have from which your brain can synthesize new creative ideas. The diversity of content matters here. You’re going to have much better luck producing creative ideas when you combine knowledge or stories about completely different, unrelated topics, than by combining related existing ideas with each other.</p>
<p>The second knob is your <strong>creative efficiency</strong>, which I define as the fraction of interesting ideas that may occur to you, that you capitalize on. The human mind has tens of thousands of thoughts a day. Because of that staggering volume, most of the time, we’re trained to tune things out and dismiss internal mental side-conversations. But I think prolific creatives are able to counteract that urge to stay focused and hook onto an interesting ideas whenever it passes them by, and then learn to develop it into an insight or a piece of work. Lots of writers I talk to who are starting out tell me that they have ideas that are “mildly interesting” – not completely obvious, but not insightful. The best writers and artists and storytellers have a <em>skill</em> of developing these mildly-interesting ideas and stories into something more profound or valuable, and I think this is a skill that comes only with practice.</p>

        <hr>
        <p>
            
            ←
            <a href="https://linus.coffee/note/writing-growth/"><em>Growth as a writer</em></a>
            
        </p>
        
    </article></div>]]>
            </description>
            <link>https://linus.coffee/note/having-ideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206661</guid>
            <pubDate>Wed, 25 Nov 2020 07:08:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Banned for Security Research]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206462">thread link</a>) | @arkadiyt
<br/>
November 24, 2020 | https://nedwill.github.io/blog/jekyll/update/2020/11/25/banned-for-research.html | <a href="https://web.archive.org/web/*/https://nedwill.github.io/blog/jekyll/update/2020/11/25/banned-for-research.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Note that this post does not reflect the opinions of my employer nor my colleagues, and I conducted this research on my own time.</em></p>

<p>About a week ago, Activision banned me from Call of Duty: Modern Warfare/Warzone (2019) for attempting to study the security of its networking code.</p>

<p>As a user, I think I ought to be able to research vulnerabilities when I may be at risk. Multiplayer games do a great deal of networked communication, both between the user and the vendor (e.g., for fetching stats or user configuration) and between users (when hosting a private game or communicating over the microphone). A user should be able to trust that playing the game in a typical manner should not lead to a compromise. Some initial background research revealed that other security researchers, like me, have reverse engineered previous iterations of the game to discover and report vulnerabilities. There is already a precedent for both the validity of the security risk and Activision’s demonstrated openness to vulnerability reports [<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-20817">1</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-10718">2</a>, <a href="https://github.com/momo5502/cod-exploits/tree/master/huffman">3</a>, <a href="https://github.com/momo5502/cod-exploits/tree/master/steam-auth">4</a>].</p>

<p>To do this research, I needed to reverse engineer the networking code in the game’s executable, as this would allow me to review the code for memory corruption vulnerabilities. Unfortunately, the executable was heavily obfuscated, and IDA was unable to analyze it. Therefore, I had to dump the unobfuscated code from the memory of a running game process. I believe it was at this point where the developers flagged me as a suspected cheater. I did two things to try to read memory from the process while I was in the main menu to avoid affecting any players. First, I attached WinDbg, and the game exited (probably the flagging event). Next, I tried pausing the process before dumping memory from it. I simply dumped an image of the game from memory in the main menu and then exited normally.</p>

<p>After spending a few days reviewing the binary, I decided that the binary was so large and unwieldy to deal with that I would table the project for a later date. But unfortunately, I was banned about a month later, losing over a year of progress on my account. The ban saddens me on a personal level as I’ve reconnected with family and friends from throughout my life playing this game during the pandemic. But more importantly, this sends a clear signal: this research is not welcome. I believe I had a reasonable expectation that it would be. I had done similar work during a CTF, where I reverse engineered and fuzzed CS:GO without ever risking a ban. Valve regularly accepts bug reports, and in one case, they paid a researcher $18000 for <a href="https://hackerone.com/reports/470520">reporting a vulnerability</a>.</p>

<p>Cheating is one of the biggest threats to the experience of gamers online. I understand that the developers shoulder an impressive burden in preventing cheat development and use. They need to leverage a variety of signals to detect cheat development and use. I’m guessing that because they may not have seen security researchers reviewing their platform before, they interpret any attempt to reverse engineer as a sign of malicious behavior. No typical player would attach a debugger to the game, and therefore they probably assume they don’t need much more evidence beyond this to issue a ban. Let me be clear: at no point did I intend to develop or use a cheat, and at no point did I manipulate any aspect of the game for another player or even myself. To this day, I don’t know what exactly caused the ban, and there’s no process to appeal it. What if using a reversing tool as part of my job gets me flagged? This fear is in the back of my mind for all games with anti-cheat, not just Warzone.</p>

<p>Where do we go from here? Obviously, I’d appreciate it if Activision unbanned my account. More importantly, I think they should provide a way for security researchers to have a place in the ecosystem by carving out exemptions for security research and establishing a point of contact (even a bug bounty) for vulnerability reports. The task of managing cheaters on the PC platform is growing both in difficulty and <a href="https://www.pcgamer.com/the-controversy-over-riots-vanguard-anti-cheat-software-explained/">controversy</a> - and I believe that Activision should join Valve and other publishers in fostering a symbiotic relationship with security researchers rather than an adversarial one. Together we can make games safer from cheaters and malicious users alike.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://nedwill.github.io/blog/jekyll/update/2020/11/25/banned-for-research.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206462</guid>
            <pubDate>Wed, 25 Nov 2020 06:23:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overengineering. Predicting the future does not work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206269">thread link</a>) | @DevTalker
<br/>
November 24, 2020 | https://ddimitrov.dev/2020/11/24/overengineering-predicting-the-future-does-not-work/ | <a href="https://web.archive.org/web/*/https://ddimitrov.dev/2020/11/24/overengineering-predicting-the-future-does-not-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


			
<p>This one will be short.</p>



<p>Yesterday, while I was browsing a programming forum, I came across a statement like this:</p>



<p>â€œâ€¦ and currently, I am creating some neat abstractions if I need something more in the futureâ€¦â€�.</p>



<p>This is so wrong! And let me tell you why.</p>



<h2>Overengineering</h2>



<p>Overengineering in software development means creating something that is not needed. Something that brings overhead to the development process and inefficiency to the end product.</p>



<p>An elementary example of overengineering is if all your applications data can be saved in a 10 line XML file, but you use a SQL database.</p>



<h2>Predicting the future</h2>



<p>One of the reasons overengineering happens is because of a lack of information.</p>



<p>Often developers want to predict the future, so they are ready when new requirements come, or requirements change.</p>



<p>The practice and statistics show that they are tragically bad at that.</p>



<p>In fact, even business people donâ€™t know how requirements will change.</p>



<p>Thatâ€™s why <a href="https://en.wikipedia.org/wiki/Agile_software_development">agile methodologies</a> were born.</p>



<p>In the modern world of software development, it often happens during one sprint to create functionality, and in the next one, to change it so drastically that it is better to start all over again.</p>



<p>Do you believe that you will have the right estimate and create the right thing from the first time with all this uncertainty and change? I believe not.</p>



<p>Predicting the future is a waste of <a href="https://ddimitrov.dev/2020/06/29/software-development-is-about-being-effective-and-efficient/">resources</a>, so donâ€™t do it.</p>



<h2>Inexperienced developers</h2>



<p>Inexperienced developers tend to create overengineered things by default ðŸ˜Š. And thatâ€™s is normal for their level.</p>



<p>They do it mainly because of two reasons.<br>1) They want to create something complicated and â€œcoolâ€�, trying new practices, patterns, and technologies.</p>



<p>2) They donâ€™t see a simple way of doing it.</p>



<p>Only gaining experience can solve the second one, but inexperienced developers should intentionally avoid the first one.</p>



<p>Donâ€™t get me wrong. <a href="https://ddimitrov.dev/2020/10/18/how-to-learn-to-become-a-good-software-developer/">New things should be tested</a>, but not directly on paying customerâ€™s projects.</p>
				
		</div></div>]]>
            </description>
            <link>https://ddimitrov.dev/2020/11/24/overengineering-predicting-the-future-does-not-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206269</guid>
            <pubDate>Wed, 25 Nov 2020 05:29:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Graphical Output from Our Custom RISC-V Operating System in Rust]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206221">thread link</a>) | @azhenley
<br/>
November 24, 2020 | https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>An operating system is used to make our job easier when using graphics. In our instance, in addition to everything else. In this post, we will be writing a GPU (graphics processing unit) driver using the VirtIO specification. In here, we will allow user applications to have a portion of the screen as RAM–with what is commonly known as a <em>framebuffer</em>.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#overview">Overview</a></li><li><a href="#pixels">Pixels and Resolution</a></li><li><a href="#virtio">The GPU VirtIO Device</a></li><li><a href="#init">Initialization</a></li><li><a href="#invalid">Invalidation and Transfer</a></li><li><a href="#response">Device Responses</a></li><li><a href="#user">User Space</a></li><li><a href="#api">Simple Graphics API</a></li><li><a href="#conclusion">Conclusions and Further Reading</a></li></ol>



<hr>



<h2 id="overview">Overview</h2>



<p>We command the virtual GPU (virtio-gpu) by sending certain commands to the host (the device). The guest (the OS driver) has an allocation of RAM that becomes the framebuffer. The driver then tells the device, “hey, here’s the RAM that we’re going to use to store pixel information.”</p>



<p>The RAM is contiguous in our OS, but according to the specification, this isn’t strictly required. We will give the driver a rectangle. Everything that falls within that rectangle will be copied to the host. We don’t want to keep copying the entire buffer over and over again.</p>



<p>We will be using the virtio protocol that we used for the block driver here, so I won’t rehash the general virtio protocol. However, the device-specific structures are a bit different, so we’ll cover that part more in depth.</p>



<hr>



<h2 id="pixels">Pixels and Resolution</h2>



<p>A framebuffer must be large enough to store \(\text{width}\times\text{height}\times\text{pixel size}\) number of bytes. There are \(\text{width}\times\text{height}\) number of pixels. Each pixel has a 1-byte red, green, blue, and alpha channels. So, each pixel is exactly 4 bytes with the configuration we’re going to specify.</p>



<p>The framebuffer for our junior GPU driver is going to support a fixed resolution of \(640\times 480\). If you’re a child of the 90s, you saw this resolution a lot. In fact, my first computer, a Laser Pal 386, had a 16-color monitor with a resolution of 640 pixels wide with 480 pixels tall.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png" alt="" width="458" height="281" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png 611w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13-300x184.png 300w" sizes="(max-width: 458px) 100vw, 458px"></a></figure></div>



<p>There are red, green, and blue pixels so close together that by varying the intensity of these three channels, we can change the color. The closer we get to our monitors, the easier a pixel is to see.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png" alt="" width="285" height="288" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png 380w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14-297x300.png 297w" sizes="(max-width: 285px) 100vw, 285px"></a><figcaption>Pixels on a Viewsonic VX2770SMH-LED monitor.</figcaption></figure></div>



<p>You can see these little squares. If you squint enough, you can see that they aren’t pure white. Instead, you can see bits of red, blue, and green. That’s because each one of these little squares is subdivided into three colors: yep, red, green, and blue! To make white, these pixels are turned up to 11 (get the joke?). To make black, we turn off all three channels of that pixel.</p>



<p>The resolution refers to how many of these squares are on our monitor. This is a 1920×1080 monitor. That means that there are 1920 of these squares going left to right, and there are 1080 of these squares from top to bottom. All in all, we have \(1920\times 1080=2,073,600\) number of pixels. Each one of these pixels is expressed using 4 bytes in the framebuffer, meaning we need \(2,073,600\times 4=8,294,400\) bytes in RAM to store the pixel information.</p>



<p>You can see why I limited our resolution to 640×480, which only requires \(640\times 480\times 4=1,228,800\) bytes–a bit over a megabyte.</p>



<hr>



<h2 id="virtio">The GPU VirtIO Device</h2>



<p>The GPU device requires us to read a more up-to-date VirtIO specification. I’ll be reading from version 1.1, which you can get a copy here: <a href="https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html">https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html</a>. Specifically, chapter 5.7 “GPU Device”. This is an <em>unaccelerated</em> 2D device, meaning that we must use the CPU to actually form the framebuffer, then we transfer our CPU formulated memory location to the host GPU, which is then responsible for drawing it to the screen.</p>



<p>The device uses a request/response system, where we the driver make a command to request something from the host (the GPU).  We add a bit of extra memory into our request so that the host can formulate its response. When the GPU interrupts us, we can take a look at this response memory location to see what the GPU told us. This is much like the <em>status</em> field on the block driver, where the block device tells us the status of our last request.</p>



<p>Each request starts with a <em>Command Header</em>, which in Rust looks as follows:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
struct CtrlHeader {
	ctrl_type: CtrlType,
	flags: u32,
	fence_id: u64,
	ctx_id: u32,
	padding: u32
}</pre>



<p>The header is common for all requests and all responses. We can differentiate by the CtrlType enumeration, which is:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum CtrlType {
	/* 2d commands */
	CmdGetDisplayInfo = 0x0100,
	CmdResourceCreate2d,
	CmdResourceUref,
	CmdSetScanout,
	CmdResourceFlush,
	CmdTransferToHost2d,
	CmdResourceAttachBacking,
	CmdResourceDetachBacking,
	CmdGetCapsetInfo,
	CmdGetCapset,
	CmdGetEdid,
	/* cursor commands */
	CmdUpdateCursor = 0x0300,
	CmdMoveCursor,
	/* success responses */
	RespOkNoData = 0x1100,
	RespOkDisplayInfo,
	RespOkCapsetInfo,
	RespOkCapset,
	RespOkEdid,
	/* error responses */
	RespErrUnspec = 0x1200,
	RespErrOutOfMemory,
	RespErrInvalidScanoutId,
	RespErrInvalidResourceId,
	RespErrInvalidContextId,
	RespErrInvalidParameter,
}</pre>



<p>I took this directly from the specification, but Rust-ified the names to avoid getting yelled at by the linter.</p>



<h3>Pixel Formats</h3>



<p>Recall that the framebuffer is just a bunch of bytes in memory. We need to put a structure behind the framebuffer so the host (the GPU) knows how to interpret your sequence of bytes. There are several formats, but all-in-all, they just re-arrange the red, green, blue, and alpha channels. All are exactly 4 bytes, which makes the <em>stride</em> the same. The stride is the spacing from one pixel to another–4 bytes.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum Formats {
	B8G8R8A8Unorm = 1,
	B8G8R8X8Unorm = 2,
	A8R8G8B8Unorm = 3,
	X8R8G8B8Unorm = 4,
	R8G8B8A8Unorm = 67,
	X8B8G8R8Unorm = 68,
	A8B8G8R8Unorm = 121,
	R8G8B8X8Unorm = 134,
}</pre>



<p>The type, <em>unorm</em>, is an 8-bit (1-byte) unsigned value from 0 through 255, where 0 represents no intensity and 255 represents full intensity, and a number in between is a linear-interpolation between no and full intensity. Since there are three color (and one alpha), that gives us \(256\times 256\times 256=16,776,216\) different colors or levels of colors.</p>



<p>For this tutorial, I selected <code>R8G8B8A8Unorm = 67</code>, which has red first, green second, blue third, and alpha fourth. This is a common ordering, so I’ll select it to make it easy to follow along.</p>



<p>Our selected format makes the pixel structure look as follows:</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png" alt="" width="512" height="307" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-300x180.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-768x461.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1536x921.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-2048x1228.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></a></figure></div>



<p>Recall that each individual component R, G, B, and A are each one byte a piece, so each Pixel referred to by (x, y) is 4 bytes. This is why our memory pointer is a Pixel structure instead of a byte.</p>



<hr>



<h2 id="init">Initialization</h2>



<p>Just like all other virtio devices, we set up the virtqueues first and then we work on device-specific initialization. In my code, I just directly copied-and-pasted from the block driver into the gpu driver. The only thing I added to the Device structure was the framebuffer and dimensions of the framebuffer.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">pub struct Device {
	queue:        *mut Queue,
	dev:          *mut u32,
	idx:          u16,
	ack_used_idx: u16,
	framebuffer:  *mut Pixel,
	width:        u32,
	height:       u32,
}</pre>



<p>The specification tells us to do the following in order to initialize the device and get things ready to draw. I Rust-ified some of the content to match our enumerations.</p>



<h4>Create a framebuffer and configure scanout</h4>



<ol><li>Create a host resource using <code>CmdResourceCreate2d</code>.</li><li>Allocate a framebuffer from guest ram, and attach it as backing storage to the resource just created, using <code>CmdResourceAttachBacking</code>.</li><li>Use <code>CmdSetScanout</code> to link the framebuffer to a display scanout.</li></ol>



<h3>A Request Structure</h3>



<p>Recall that our request and response come packaged together. We will put them in separate descriptors, but whenever we get a response back from the device, it is going to be easier if we free just once to free both the request and response. So, in Rust, I created the Request structure to support doing this.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">struct Request&lt;RqT, RpT&gt; {
	request: RqT,
	response: RpT,
}
impl&lt;RqT, RpT&gt; Request&lt;RqT, RpT&gt; {
	pub fn new(request: RqT) -&gt; *mut Self {
		let sz = size_of::&lt;RqT&gt;() + size_of::&lt;RpT&gt;();
		let ptr = kmalloc(sz) as *mut Self;
		unsafe {
			(*ptr).request = request;
		}
		ptr
	}
}</pre>



<h4>Step 1: Create host resource</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request::new(ResourceCreate2d {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceCreate2d,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	format: Formats::R8G8B8A8Unorm,
	width: dev.width,
	height: dev.height,
});
let desc_c2d = Descriptor {
	addr: unsafe { &amp;(*rq).request as *const ResourceCreate2d as u64 },
	len: size_of::&lt;ResourceCreate2d&gt;() as u32,
	flags: VIRTIO_DESC_F_NEXT,
	next: (dev.idx + 1) % VIRTIO_RING_SIZE as u16,
};
let desc_c2d_resp = Descriptor {
	addr: unsafe { &amp;(*rq).response as *const CtrlHeader as u64 },
	len: size_of::&lt;CtrlHeader&gt;() as u32,
	flags: VIRTIO_DESC_F_WRITE,
	next: 0,
};
unsafe {
	let head = dev.idx;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d_resp;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).avail.ring[(*dev.queue).avail.idx as usize % VIRTIO_RING_SIZE] = head;
	(*dev.queue).avail.idx = (*dev.queue).avail.idx.wrapping_add(1);
}</pre>



<p>All we’re really telling the GPU here is our resolution and the format of the framebuffer. When we create this, the host gets to configure itself, such as allocating an identical buffer to make transfers from our OS.</p>



<h4>Step 2: Attach framebuffer backing.</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request3::new(AttachBacking {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceAttachBacking,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	nr_entries: 1,
},
MemEntry {
	addr: dev.framebuffer as u64,
	length: dev.width * dev.height * size_of::&lt;Pixel&gt;() as u32,
	…</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206221</guid>
            <pubDate>Wed, 25 Nov 2020 05:14:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic Content Recognition (ACR) – How Does It Work?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206054">thread link</a>) | @ponderingfish
<br/>
November 24, 2020 | https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/ | <a href="https://web.archive.org/web/*/https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong>Automatic Content Recognition (ACR) refers to technology embedded into OTT applications or SmartTVs that recognizes the content that you are watching by sampling small portions of the video/audio and comparing it with a large database. </strong></p>



<p>ACR is prevalent in SmartTVs and hand-held devices and plays a major role in the audience measurement and ad-tracking industry. </p>



<p>In this article, let’s take a look at how Automatic Content Recognition or ACR works and some use-cases for this technology. </p>



<hr>



<h2>Firstly, how is Data Gathered from OTT Applications?</h2>



<p>Before we look at ACR, let’s first take a quick look into the field of analytics and data gathering in OTT. </p>



<p>Typically, an SDK or library is integrated into an OTT application (HTML5, Android, iOS, SmartTV app, etc.) and then released to the public. Once it’s installed on a phone, or TV, the application can track the user’s actions, the content being watched, etc. at a very granular level. </p>



<p>Each time the user presses play/pause/stop/etc., the SDK records the action and reports it back to a server. Similarly, data points from millions of users are gathered, cleaned, and then presented in a useable format in dashboards back to the OTT content provider. </p>



<p>In most cases, it’s usually the publisher (aka content provider) who is the consumer of this information and the publisher uses it to improve their QoE, content offering, advertising strategies, etc. </p>



<p>You may think that this level of data-gathering is intrusive, but, the fact of the matter is that you agreed to this by pressing “Yes” on the consent form when you installed the app which in all likelihood, you didn’t read! </p>



<p>With that introduction to data-gathering (which is rather common in today’s world), let’s switch over to another form of intelligence-gathering – Automatic Content Recognition (ACR).</p>



<hr>



<h2>What is Automatic Content Recognition?</h2>



<p>Automatic Content Recognition refers to technology that samples the audio or video that a user is consuming, creates a fingerprint from that sample, and compares this against an extensive database of fingerprints to automatically recognize what was being watched or listened to. In some instances of ACR, the recorded sample might be directly transmitted to a server for processing and further information extraction.</p>



<hr>



<h2>How Does Automatic Content Recognition Work?</h2>



<p>As we’ve already seen, ACR works by sampling the video and/or audio and using that information to determine the content being consumed. This leads us to <strong>Acoustic (or Audio) Fingerprinting</strong> and <strong>Video Fingerprinting.</strong></p>



<p>Here’s a visual explanation of ACR works. Simply put, </p>



<ul><li>fingerprints are generated for the media that needs to be recognized (using either audio or video fingerprinting techniques). These fingerprints are stored in a database. </li><li>ACR-enabled SmartTVs, phones, or other devices generate similar fingerprints and transmit them to a server that compares these device-generated fingerprints with the main database to find a match. </li><li>Based on database-match, metrics or data are generated that provide insights into media consumption. </li></ul>







<div><figure><img loading="lazy" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=622%2C370&amp;ssl=1" alt="ACR Automatic Content Recognition
" width="622" height="370" srcset="https://889329.smushcdn.com/2063466/wp-content/uploads/2020/11/image-3.png?size=240x143&amp;lossy=1&amp;strip=1&amp;webp=1 240w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=300%2C178&amp;ssl=1 300w, https://889329.smushcdn.com/2063466/wp-content/uploads/2020/11/image-3.png?size=480x286&amp;lossy=1&amp;strip=1&amp;webp=1 480w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=768%2C457&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=1024%2C609&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=1200%2C713&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?w=1396&amp;ssl=1 1396w" sizes="(max-width: 622px) 100vw, 622px" data-recalc-dims="1" data-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=622%2C370&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div>







<p>That’s fundamentally how fingerprinting and ACR works. Now, let’s take a look at the different techniques used in ACR.</p>



<h3>Acoustic Fingerprinting</h3>



<p>Quoting from Wikipedia, <strong><em>an acoustic fingerprint is a condensed digital summary, a fingerprint, deterministically generated from an audio signal, that can be used to identify an audio sample or quickly locate similar items in an audio database.</em></strong></p>



<p>Certain metrics such as frequency, amplitude, tempo, spectrum (i.e., characteristics in the frequency domain), etc. are used in building a fingerprint or signature of the audio signal. </p>



<p>Another reason why this is important is that audio is generally compressed before transmission. And compression algorithms generally remove characteristics of an audio signal that are not perceptible to humans. Hence, the acoustic fingerprinting algorithm that are you building should also take these sources of distortion and noise into account. </p>



<h3>Video Fingerprinting</h3>



<p>Similar to Audio Fingerprinting, in Video Fingerprinting, small video clips are made from the original video, and certain characteristics are extracted from it. These techniques take care to ensure that image manipulation technologies like compression, or resizing do not affect these fingerprints and the content can be recognized nonetheless. </p>



<h3>Digital Watermarking</h3>



<p>Watermarking is the process of embedding data into video/audio <strong>covertly </strong>such that the embedded information is not ordinarily or easily detected. The watermark can be detected only by specialized and authorized <strong>watermark&nbsp;detecting software</strong>. Watermarking allows publishers to track piracy and establish authenticity.  In the case of Automatic Content Recognition, one can use Watermarking as a method of detecting if someone has engaged with or watched a content. </p>



<hr>



<h2>Uses of ACR</h2>



<p>There are several uses of ACR technology. Some of the more prominent ones are – </p>



<ol><li><strong>Detection of copyright infringement: </strong>Copyrighted material such as video and audio are often used indiscriminately without attributing or paying royalties to the original content creators. If a database of copyrighted content exists, then large UGC platforms such as YouTube, TikTok, Vimeo, etc. could check to see if user-uploaded content contains copyrighted material or not. </li><li><strong>Ad-tracking</strong>: ACR has found a lot of use in the advertising industry and for good reason. Here’s why –<ol><li>Unless you have the <strong>ability to determine if an ad was played and watched by the end-user </strong>(instead of being buried at the end of a long landing page), then your metrics don’t make a lot of sense and it could lead to inflated data with respect to ad impressions, plays, and completion rates. This requires SDKs and changes to the players that can consume a lot of effort and development cycles. </li><li>However, ACR has the ability to recognize the content that is being played by sampling certain pixels of video, or by recognizing the audio. This enables ACR to provide a better picture to the advertisers and publishers on the ad delivery and engagement. </li></ol></li><li><strong>Collating information from different sources</strong>: This is a very interesting use-case of ACR. In most homes, there is one big TV in the living room where people gather to watch movies. However, the content streaming to the TV could come from an STB, Chromecast, Roku, FireStick, or an Xbox. Instead of embedding code inside all these devices, SmartTVs with ACR can recognize the content being played (from the “glass”) and report on it. This allows for content attribution and normalization across a variety of sources. </li><li><strong>Understanding Audiences and their preferences</strong>: Similar to other methods of gathering usage analytics, ACR allows broadcasters and content providers to know how their audience is responding to their content, marketing, strategies, etc. By having fine-grained information about their audience and their usage patterns, broadcasters can better invest their dollars and get a much higher ROI. </li><li><strong>Ad Retargeting by OEMs</strong>: Samsung includes ACR technology in their SmartTVs and sells ad inventory and provides<a href="https://www.samsung.com/us/business/samsungads/resources/tv-ad-retargeting/" target="_blank" rel="noopener"> ad-retargeting services</a>. According to their website, “<em>Samsung Ads offers TV Ad Retargeting that empowers brands to identify audiences who saw or missed their TV spots and reconnect with them via mobile, tablet, desktop or OTT</em>.” And, <em>“Samsung Smart TVs have built-in Automated Content Recognition (ACR) technology that can understand viewing behavior and usage including programs, movies, ads, gaming content and OTT apps in real-time”</em>. You can read more about Samsung’s Privacy Policy <a href="https://www.samsung.com/sg/info/privacy/" target="_blank" rel="noopener">here</a> where they are pretty open about recording your video and audio to understand “you” better! </li></ol>











<hr>



<h2>Controversies Surrounding ACR</h2>



<p>The bone of contention around ACR is due to the fact that audio and/or video are recorded, fingerprinted, and often stored for future use. Some devices might be able to generate the fingerprints on-device, but some might send the audio recordings to the cloud for further processing. </p>



<p>So what happens if your private conversations are in those recordings? Who is listening on the other end?</p>



<p>Samsung got into one of these sticky situations and had to clarify in a <a href="https://news.samsung.com/global/samsung-smart-tvs-do-not-monitor-living-room-conversations" target="_blank" rel="noopener">press release</a>. Their initial privacy policy stated –</p>



<p><em>“Please be aware that if your spoken words include personal or other sensitive information, that information will be among the data captured and transmitted to a third party through your use of Voice Recognition.”</em></p>



<p>This spooked a lot of people and Samsung had to backtrack and <a href="https://news.samsung.com/global/samsung-smart-tvs-do-not-monitor-living-room-conversations" target="_blank" rel="noopener">release a clarifying note</a> that said – </p>



<p><em>If you enable Voice Recognition, you can interact with your Smart TV using your voice. To provide you the Voice Recognition feature,&nbsp;some interactive voice commands may be transmitted (along with information about your device, including device identifiers) to a third-party service provider (currently, Nuance Communications, Inc.) that converts your interactive voice commands to text and to the extent necessary to provide the Voice Recognition features to you. In addition, Samsung may collect and your device may capture voice commands and associated texts so that we can provide you with Voice Recognition features and evaluate and improve the features. Samsung will collect your interactive voice commands only when you make a specific search request to the Smart TV by clicking the activation button either on the remote control or on your screen and speaking into the microphone on the remote control.</em></p>



<p>And, please don’t think that I am picking on Samsung. Another TV manufacturer, Vizio was fined by the FTC for not being forthright with its data-tracking policies. (<a href="https://www.ftc.gov/news-events/press-releases/2017/02/vizio-pay-22-million-ftc-state-new-jersey-settle-charges-it" target="_blank" rel="noopener">link to the notice on the FTC website</a>). </p>



<p>And, here’s an interesting <a href="https://www.consumerreports.org/privacy/how-to-turn-off-smart-tv-snooping-features/" target="_blank" rel="noopener">article from consumerreports.org</a> on how to turn off “snooping” features on Android TVs,&nbsp;Amazon Fire TV Edition,&nbsp;LG,&nbsp;Roku,&nbsp;Samsung,&nbsp;Sony, and&nbsp;Vizio.</p>



<p>All of this constitutes a weird situation, I …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/">https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/</a></em></p>]]>
            </description>
            <link>https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206054</guid>
            <pubDate>Wed, 25 Nov 2020 04:30:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Great software engineers are never actively looking for a job on job boards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205830">thread link</a>) | @karlhughes
<br/>
November 24, 2020 | https://www.karllhughes.com/posts/hiring-process | <a href="https://web.archive.org/web/*/https://www.karllhughes.com/posts/hiring-process">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article>
<div>
<p><img src="https://www.karllhughes.com/assets/img/hiring.png" alt="Recruiting and Hiring Software Engineers">
</p> 

<p>
2020, Nov 13&nbsp;&nbsp;&nbsp;—&nbsp;
13 minute read
</p>
<section id="mc_embed_signup">

</section>
<p>When I took my first real management role as <a href="https://www.karllhughes.com/posts/packback-engineering">Packback’s Head of Engineering back in 2015</a>, I inherited a great team of engineers who were hired before my promotion. Later that year, when the time came for me to do some of my own hiring, I had to quickly adopt a process for finding and onboarding new software engineers.</p>
<p>I started with the framework my predecessor used and brought in some heavy influences from <em><a href="https://www.karllhughes.com/posts/peopleware">Peopleware</a></em> and Josh Tyler’s <em><a href="https://amzn.to/1XQAfT7">Building Great Software Engineering Teams</a></em>. Over the years, I’ve refined my hiring process - mostly through trial and error - to come up with the iteration described here.</p>
<p>My approach is a little unconventional, but I hope it inspires you to think outside the box. This is going to be a long read, so I’ve broken it down into five sections:</p>
<ol>
<li><a href="#the-problem-with-hiring-software-engineers">The Problem with Hiring</a></li>
<li><a href="#skills-i-look-for-in-software-engineers">Skills I Look For</a></li>
<li><a href="#how-i-find-software-engineers">How I Find Candidates</a></li>
<li><a href="#how-i-hire-software-engineers">How I Hire Engineers</a></li>
<li><a href="#mistakes-ive-made-when-hiring-software-engineers">The Mistakes I’ve Made</a></li>
</ol>
<p><em>Note: If you’re looking for some books to help you on your journey as a software engineering manager, <a href="https://www.karllhughes.com/posts/reading-for-engineering-managers">here are some of my favorites</a>.</em></p>
<h2 id="the-problem-with-hiring-software-engineers">The Problem with Hiring Software Engineers</h2>
<p>Any <a href="https://www.karllhughes.com/posts/engineering-manager">engineering manager</a> who’s hired people in the past will tell you that it’s hard.</p>
<p>There are lots of constraints, no way to fairly compare two candidates, and suitable candidates for one team may be horrible for another. Because it’s so hard, the process has evolved to favor people who think like the interviewers, who know someone at the company, or who perform well in high-pressure interviews. It leaves people with non-traditional backgrounds struggling, often works against diverse candidates, and is nothing like the day-to-day work that most engineers do.</p>
<p>For example, a typical interview may require a phone screen with a recruiter who tests for “soft skills.” Next, an engineering manager may screen for baseline technical skills, and then the candidate may be asked to complete an independent project or come into the office for a whiteboarding session. In either case, <strong>the interview is nothing like a typical day working as an engineer</strong> (although the “take-home” project may be the closest in some environments).</p>
<p>Soft skills are important, but “tell me about a time when…” questions favor people who are quick to make things up, and they <a href="https://www.forbes.com/sites/lizryan/2014/03/04/why-i-hate-behavioral-interviewing/#7229c954693c">don’t demonstrate real judgment or problem-solving skills</a>. It’s impossible to assess someone’s character in a 30-minute phone screen, so at best, you can weed people out who are completely unreliable or have poor verbal communication skills.</p>
<p>Similarly, it’s very hard to judge a person’s technical ability in all things during a 1-hour tech screening. The field of web development (and software engineering in general) is so vast that nobody is going to match your requirements perfectly. You can ask them what technologies they’re familiar with and see if they can have a coherent conversation about technical topics, but you probably can’t bump up against the edges of all of their knowledge, especially if it doesn’t overlap with your own.</p>
<p>Finally, I’ve never done whiteboarding or live coding sessions with candidates, but <a href="https://theoutline.com/post/1166/programmers-are-confessing-their-coding-sins-to-protest-a-broken-job-interview-process">a lot of people really hate them</a>, and I think there’s a good reason for that. In the real world, programmers pushed in front of an audience to solve a problem with an obscure algorithm, no time for independent research, and no access to resources. I would never do this job if that were my day-to-day.</p>
<p>Testing programmers at something they don’t need to be good at and expecting to learn something about how they would work at your company is delusional. These kinds of interviews only serve to make the hiring team feel superior and ensure better outcomes for engineers with traditional CS backgrounds.</p>
<h2 id="skills-i-look-for-in-software-engineers">Skills I Look for in Software Engineers</h2>
<p><img src="https://i.imgur.com/FfOzjCZ.jpg" alt="Software Engineering Skills"></p>
<p>In an effort to redesign our hiring process around the skills that actually matter in software engineering, I took the problem down to <a href="https://fpt.guide/">first principles</a>. What skills do I need in a team of software engineers?</p>
<h3 id="initiative">Initiative</h3>
<p>I have never liked micromanaging people. I remember being a team lead at a restaurant in college and getting irrationally annoyed with people who would stand around while customers were lining up at the register. “Go, take an order or something!”</p>
<p>I digress.</p>
<p>Most software engineers who are looking for a job have a certain level of initiative, but great software engineering candidates go the extra mile all the time. For example, I worked with a guy at Packback who had built a website and extremely popular Twitter account to follow the chatter on police scanners. He did all this to learn new things for fun.</p>
<p>Software engineers who take initiative don’t wait for the hiring manager to email them back, they ask about next steps, and they read about the company before they show up for an interview. It’s not really that hard, but it does take time, and very few candidates do it.</p>
<h3 id="reliability">Reliability</h3>
<p>Initiative is a start, but <a href="https://www.karllhughes.com/posts/hero-myth">I don’t want a hero</a>. I want to build a team of consistently reliable engineers who improve over time.</p>
<p>Candidates with a history of staying in jobs for a long time, strong references, and commitment to projects usually make it to the top of my list when hiring.</p>
<h3 id="competency">Competency</h3>
<p>When I was a new engineering manager, I over-indexed on technical skills. It’s easy to fall into the trap of grading engineers based purely on their technical knowledge (whole companies like <a href="https://www.toptal.com/">Toptal</a> and <a href="https://triplebyte.com/">Triplebyte</a> are built on this fallacy), but arcane trivia does not make a sound engineer.</p>
<p>I’ll talk more about how I gauge a candidate’s competency later in this post, but the key question I ask is, <strong>do I think this engineer can learn to solve the problems we are facing?</strong></p>
<p>It’s not about whether they know all the answers on day one, but instead, I look for curious people who are lifelong learners with a drive to improve themselves. If they have that, I’ll find a way to get them the information they need to succeed in this role.</p>
<h3 id="interest-in-the-mission">Interest in the Mission</h3>
<p>I used to call this “passion,” but after a <a href="https://www.listennotes.com/podcasts/exceptions-welcome/building-a-resilient-career-dea4tx69g32/">lively conversation on the Exceptions Welcome podcast</a> I decided to rebrand this skill.</p>
<p>Ultimately, I only want to hire software engineers who care about our industry, the problems we’re solving, and the method we’re using to get there. If we aren’t pointing in the same direction before they join, I don’t want to spend the first six weeks convincing them.</p>
<p>While I don’t want unquestioning loyalty or people who live at the office, I do think it’s important that software engineers are actually interested in the work they will be doing. It’ll make them happier, and that positivity rubs off on everyone.</p>
<h2 id="how-i-find-software-engineers">How I Find Software Engineers</h2>
<p><img src="https://i.imgur.com/bTlxNvy.jpg" alt="Finding Software Engineers"></p>
<p>I’ve used several methods for finding and recruiting software engineers over the years. While I don’t have a ton of data to back up these methods, here’s what I’ve found works for me.</p>
<h3 id="job-listings">Job Listings</h3>
<p>Job listings are the <em><a href="https://unbounce.com/landing-page-articles/what-is-a-landing-page/">landing page</a></em> for job hunters.</p>
<p>A compelling job listing should outline the tools and languages the candidate should know, the projects the candidate will work on, and as much information about day-to-day expectations as is reasonable. I try to make job listings interesting and creative, so I typically use a GitHub repository with lots of information about our team, our company, and the job interview process (<a href="https://github.com/thegraidenetwork/job-openings">here’s an example of the repo I set up for The Graide Network</a>).</p>
<p>Remember that you won’t just share this listing with candidates. You’ll also be emailing it out to everyone in your network, sharing it on social media, and linking to it from your website. It’s a public-facing document that should be good looking and functional.</p>
<h3 id="networking">Networking</h3>
<p>I’ve never paid money to promote a job listing, but I doubt it’s worth it, and here’s why:</p>
<p><strong>The best software engineers are never <em>actively</em> looking for a job on job boards.</strong></p>
<p>They’re locked away behind gatekeepers called “their network,” which includes former managers and coworkers, friends, and people who know them from professional organizations. They jump ship when someone they trust tells them about a great opportunity or when they decide to ask around. Senior software engineers often laugh about how many Linkedin messages we get from naive recruiters.</p>
<p>So, what’s the trick to building a network full of software engineers?</p>
<p>Time.</p>
<p>People are surprised when I tell them that <a href="https://www.karllhughes.com/posts/the-key-to-networking-keeping-in-touch">I spend 4-8 hours per week building and maintaining my network</a>, but the dividends on that investment have been enormous. Whenever I have a new job opening, I write up a job listing and start passing it around. I keep a huge list of people I’d like to work with someday, so I go through it and find an excuse to get lunch.</p>
<p>If you’re not actively building your network right now, start <a href="https://ctocraft.com/blog/how-to-use-writing-to-build-a-solid-talent-pipeline/">writing</a>, <a href="https://www.karllhughes.com/posts/speaking-guide">speaking</a>, and taking meetings with interesting people. It’s the best investment you can make in your career.</p>
<h3 id="cold-outreach">Cold Outreach</h3>
<p>Another unpopular recruiting tool for finding software engineers is cold outreach. I’ve found that it can work, but you have to be careful. It’s easy to come off as spammy or annoying.</p>
<p>Treat cold outreach as an excuse to grow your network rather than jumping straight to “the ask.” Reach out to people, ask them genuine questions; do some research on their background; get to know them. You’re just having a conversation, and eventually, you might slide in a mention that you’re keeping an eye out for software engineers.</p>
<p>End each call by asking if you can follow up in a few months and (shocker!) actually do it. I’ve met some outstanding people this way, even if we never ended up working together.</p>
<h3 id="recruiters">Recruiters</h3>
<p>Recruiters get a bad name in the software engineering world because they can be pretty annoying. I’ve had junior recruiters cold call me at work or send job requests to my company email. Not a good look.</p>
<p>On the flip side, there are a few well-networked and honest tech recruiters out there. Just be ready to pay big bucks as the best likely work on a <a href="https://theundercoverrecruiter.com/contingency-vs-retained-recruiters-what-difference/">retainer rather than contingency</a>.</p>
<p>Even if you do get a recruiter, you need to keep recruiting too. If your recruiter doesn’t have any luck, you don’t want all your leads to dry up with them.</p>
<h2 id="how-i-hire-software-engineers">H…</h2></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.karllhughes.com/posts/hiring-process">https://www.karllhughes.com/posts/hiring-process</a></em></p>]]>
            </description>
            <link>https://www.karllhughes.com/posts/hiring-process</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205830</guid>
            <pubDate>Wed, 25 Nov 2020 03:42:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a scalable 'shot-based' serverless AV1 video encoder in Azure]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205775">thread link</a>) | @mrfusion
<br/>
November 24, 2020 | https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/ | <a href="https://web.archive.org/web/*/https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>This is a 3-part blog covering how to build a scalable shot-based serverless video encoder in Azure. In Part 1, I explain what AV1 is and where we are in the video encoding space. In part 2, we create a logic app to upload and index the video. In part 3, we’ll need to split the video into its scenes and encode individual scenes. For reference, here are the links to all the parts:</p>
<ol>
<li><a href="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-1/">https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-1/</a></li>
<li><a href="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/">https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/</a></li>
<li><a href="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-3/">https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-3/</a></li>
</ol>
<h2 id="the-solution">The solution</h2>
<p>To implement this solution, we need an algorithm that splits the input video into shots. Fortunately for us, <a href="https://vi.microsoft.com/en-us/">Microsoft Video Indexer</a> supports this scenario. Before getting started we’ll setup Video Indexer in our subscription. For the rest of the steps, here’s a quick overview of what’s going to happen:</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/architecture.png" alt="“shot-based” serverless distributed AV1 video encoder in Azure"></p>
<ol>
<li>User uploads an MP4 video file to Azure Blob Storage</li>
<li>Because of the Azure Event Grid integration with Azure Blob Storage, a file upload event triggers a notification</li>
<li>The event notification is consumed by the first Logic App. The first step in the Logic App is to upload the video to Microsoft Video Indexer service</li>
<li>Once the video is indexed, we retrieve the video insights and store it in the “insights” Azure File share</li>
<li>While the video indexing is happening, we also copy the video file from Azure Blob Storage to the “source” Azure File share where it can be accessed by container instances later</li>
<li>When the indexing is complete, an “Indexing complete” notification is sent to trigger the second Logic App</li>
<li>In the second Logic App, the first step is to retrieve the video insights saved earlier</li>
<li>Next, we use an Azure Function to parse the shots data and create our container instance definitions as well as shots encoding commands for each container instance</li>
<li>Now we can use the Logic App-Container Instance connector to create container instances based on container instance definitions defined in the last step</li>
<li>As the container instances finish their respective encoding jobs, they save the output video in the “shots” Azure File share</li>
<li>Next, we trigger another Azure Function to iterate over the output files and create a <a href="https://trac.ffmpeg.org/wiki/Concatenate#demuxer">ffmpeg concat file</a></li>
<li>Once we have a concat file, we create another container instance with ffmpeg installed to execute the concat file</li>
<li>The output of the preview container instance i.e. all the encoded shots files that are combined to one file is saved in the “output” Azure File share</li>
<li>The user can then download the encoded file from the “output” Azure File share</li>
</ol>
<h6 id="user-experience">User Experience</h6>
<p>While building this solution, I wanted to keep the user experience simple. Hence a user needs to take only these steps:</p>
<ol>
<li>Upload an MP4 video file to a specified Azure Blob Storage Account</li>
<li>Download the encoded file from the “output” Azure File share</li>
</ol>
<h2 id="implementation-details">Implementation Details</h2>
<h6 id="setup-microsoft-video-indexer">Setup Microsoft Video Indexer</h6>
<ol>
<li>
<p>Start by going to <a href="https://vi.microsoft.com/en-us/">https://vi.microsoft.com/en-us/</a> and logging in with your Azure account</p>
</li>
<li>
<p>Once logged in, click “Create new account”</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/0-vi-account.png" alt="Azure Video indexer create account"></p>
</li>
<li>
<p>Once you’ve logged into your Azure subscription, fill in the details for the Video Indexer instance you’d like to create.</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/0-vi-connect-azure.png" alt="Connect Azure Video Indexer to Azure subscription"></p>
</li>
<li>
<p>It can take a few minutes for the Video Indexer to connect to your subscription. Once that is done, copy the account id of your new account</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/0-vi-account-id.png" alt="Azure Video Indexer account id"></p>
</li>
<li>
<p>Now login with your Azure subscription at <a href="https://api-portal.videoindexer.ai/developer">https://api-portal.videoindexer.ai/developer</a> and copy the Primary or Secondary key</p>
</li>
</ol>

<ol start="6">
<li>That’s it! Now Video Indexer instance is all setup in your subscription</li>
</ol>
<h6 id="blob-upload-events">Blob upload events</h6>
<ol>
<li>
<p>Create a storage account. I named mine <strong>“serverlessn codermedia”</strong></p>
</li>
<li>
<p>In the storage account, create a container called <strong>“media”</strong> in the <strong>“Blobs”</strong> section. This is where the user will upload an .MP4 video file.</p>
</li>
<li>
<p>In the <strong>“Files”</strong> section, add 4 new file shares</p>
<p><strong>a.</strong> <strong>insights</strong> – we’ll store the insights about indexed video here<br>
<strong>b.</strong> <strong>output</strong> – we’ll store the full encoded video here that the user can download<br>
<strong>c.</strong> <strong>shots</strong> – we’ll store the individual encoded shots video files here<br>
<strong>d.</strong> <strong>source</strong> – we’ll store the user uploaded video file here for access by the container instances<br></p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/storage-account-event-grid-subscription-1.8.png" alt="A screenshot of a cell phone Description automatically generated"></p>
</li>
<li>
<div><p>Once the storage account is created, click the <strong>“Events”</strong> section of the storage account. In the <strong>“Events”</strong> section, use the <strong>“When a new blob is uploaded”</strong> quick start logic app to get started.</p><p>
<img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/storage-account-event-grid-subscription.png" alt="A screenshot of a cell phone Description automatically generated"></p></div>
</li>
<li>
<p>Next screen shows the Azure Blob Storage and Azure Event Grid connections <br>
<img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/storage-account-event-grid-subscription-1.5.png" alt="A screenshot of a cell phone Description automatically generated"></p>
</li>
<li>
<p>First create the connection for the storage account you just created
<img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/storage-account-event-grid-subscription-1.6.png" alt="A screenshot of a cell phone Description automatically generated"></p>
</li>
<li>
<p>Next, sign into Azure Event Grid with your current Azure subscription. Once you’ve done these steps, you should see the following screen showing green status!</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/storage-account-event-grid-subscription-1.7.png" alt="A screenshot of a cell phone Description automatically generated"></p>
</li>
<li>
<p>Hit continue and you should now land on the Logic Apps designer</p>
</li>
<li>
<p>In the <strong>“When a resource event occurs”</strong><br>
<strong>a.</strong> select <strong>Event Type</strong> Item of <code>Microsoft.Storage.BlobCreated</code><br>
<strong>b.</strong> Add two new parameters – <strong>“Suffix Filter”</strong> with value <strong>".mp4"</strong> and <strong>“Subscription Name”</strong> with value anything you want<br></p>
</li>
<li>
<p>In the <strong>“If true”</strong> section
g. Delete all steps except <strong>“Compose”</strong></p>
</li>
</ol>

<ol start="11">
<li>
<p>Your Logic App at this point should look like below</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/storage-account-event-grid-subscription-2.png" alt="A screenshot of a social media post Description automatically generated"></p>
</li>
<li>
<p>Save the logic app with whatever name you choose. In this solution, I named it as <strong>“video-indexer-logic-app”</strong></p>
</li>
</ol>
<h6 id="upload-video-to-microsoft-video-indexer">Upload video to Microsoft Video Indexer</h6>
<ol>
<li>
<p>After the <strong>“Compose”</strong> action, add a <strong>“Create SAS URI by path”</strong> action</p>
<p><strong>a.</strong> For the <strong>“Blob path”</strong>, choose the <strong>“Outputs”</strong> from the previous Compose action. You will have to click <strong>“See more”</strong> to see the output from the Compose action.<br>
<strong>b.</strong> Make sure you’re connected to the same Azure Blob Storage connection we defined earlier <em>(storage-la-conn in this case)</em></p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/2-create-sas-uri.png" alt="A screenshot of a social media post Description automatically generated"></p>
</li>
<li>
<p>Now add a <strong>“Get Account Access Token”</strong> action for Video Indexer (V2) connector.</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/3-vi-get-account-access-token.png" alt="A screenshot of a cell phone Description automatically generated"></p>
<p><strong>a.</strong> The first time you do this, you will need to enter the <strong>Video Indexer API Key</strong> we copied earlier and enter a name for this Logic App-Video Indexer connection<br>
<img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/4-vi-create-connection.png" alt="A screenshot of a cell phone Description automatically generated"><br>
<strong>b.</strong> Once the connection is created, select the <strong>location</strong> you deployed your Video Indexer instance to earlier.<br>
<strong>c.</strong> Select the <strong>account Id</strong> we saved earlier<br>
<strong>d.</strong> Select <strong>“Yes”</strong> for <strong>“Allow Edit”</strong><br></p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/5-vi-get-account-access-token-details.png" alt="A screenshot of a cell phone Description automatically generated"></p>
</li>
<li>
<p>Now add a <strong>“Upload video and index”</strong> step and fill in the following details as shows in the image.
<img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/6-vi-upload-video-index.png" alt="A screenshot of a social media post Description automatically generated"></p>
</li>
</ol>
<p>For the Video Name field you can choose any name or make it dynamic using the expression tab to enter split(triggerBody()?[‘subject’], ‘/')?[6]. This splits the input video Uri to just the file name that was uploaded
<img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/6.1-vi-upload-video-index.png" alt="A screenshot of a social media post Description automatically generated"></p>

<ol>
<li>
<p>Now we need to copy the source video file to the <strong>“source”</strong> Azure File share so that our encoding containers instances can access it. For that, add a <strong>“Create container group”</strong> action and configure it like shown below.</p>
<p>We’re using a small wget container that will download the video from the SAS Uri we generated earlier and then copy it to <strong>“source”</strong> Azure File Share. Note that we’re using a minimal docker image, therefore we’ll need to use “–no-check-certificate” with wget to download from HTTPS SAS Uri of Azure Blob Storage.</p>
<p>Note that I’m creating this container in a new resource group <strong>“encoding-containers-rg”</strong> to keep a dedicated resource group for creating container instances.</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/7-create-container-group.png" alt="A screenshot of a cell phone Description automatically generated"></p>
<p>For the containers field, you can use the following JSON to configure easily</p>
<div><pre><code data-lang="json"><span>[</span>
    <span>{</span>
        <span>"name"</span><span>:</span> <span>&lt;select</span> <span>output</span> <span>Video</span> <span>Id</span> <span>of</span> <span>“Upload</span> <span>and</span> <span>index”</span> <span>step</span><span>,</span>
        <span>"properties"</span><span>:</span> <span>{</span>
            <span>"image"</span><span>:</span> <span>"inutano/wget"</span><span>,</span>
            <span>"resources"</span><span>:</span> <span>{</span>
                <span>"requests"</span><span>:</span> <span>{</span>
                    <span>"cpu"</span><span>:</span> <span>1</span><span>,</span>
                    <span>"memoryInGB"</span><span>:</span> <span>0.5</span>
                <span>}</span>
            <span>},</span>
            <span>"command"</span><span>:</span> <span>[</span>
                <span>"wget"</span><span>,</span>
                <span>"--no-check-certificate"</span><span>,</span>
                <span>"-O"</span><span>,</span>
                <span>"/aci/source/&lt; enter into expression tab split(triggerBody()?['subject'], '/')?[6] &gt;"</span><span>,</span>
                    <span>&lt;Insert</span> <span>Web</span> <span>Url</span> <span>i.e.</span> <span>SAS</span> <span>Uri</span> <span>we</span> <span>generated</span> <span>earlier&gt;</span>
            <span>],</span>
            <span>"volumeMounts"</span><span>:</span> <span>[</span>
                <span>{</span>
                    <span>"mountPath"</span><span>:</span> <span>"/aci/source/"</span><span>,</span>
                    <span>"name"</span><span>:</span> <span>"source"</span><span>,</span>
                    <span>"readOnly"</span><span>:</span> <span>false</span>
                <span>}</span>
            <span>]</span>
        <span>}</span>
    <span>}</span>
<span>]</span>
</code></pre></div>
</li>
<li>
<p>Next, add an <strong>“Until”</strong> action to check for the completion of the previous container instance. Before filling in the details of the <strong>“Until”</strong> action, add a <strong>“Delay”</strong> and <strong>“Get properties of a container group”</strong> action like below.</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/8.1-until.png" alt="A screenshot of a computer Description automatically generated"></p>
<p>Once this is done, now you can fill in the details of the <strong>“Until”</strong> action like below. NOTE: there are a few different state variables that show up. Choose the one I highlighted in the image below. Also in the advanced mode make sure the value is following to make sure you’ve selected the correct variable</p>
<p><code>@equals(body('Get_properties_of_a_container_group')?['properties']?['instanceView']?['state'], 'Succeeded')</code></p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/8.2-until.png" alt="A screenshot of a computer Description automatically generated"></p>
<br>
</li>
<li>
<p>Now for some cleanup! Let’s add a <strong>“Delete container group”</strong> action</p>
<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/9-delete-container.png" alt="A screenshot of a cell phone Description automatically generated"></p>
</li>
</ol>
<h2 id="first-logic-app-created">First logic app created!</h2>
<p>At the end of above steps, your first logic app <strong>“video-indexer-logic-app”</strong> should look like below. I chose to leave the <strong>“If false”</strong> condition empty. You can setup an email notification for example if you choose to do so.</p>

<p><img src="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/media/10-logic-app-1-complete.png" alt="A screenshot of a cell phone Description automatically generated"></p>
<h2 id="end-of-part-2">End of Part 2</h2>
<p>This is the end of Part 2. In Part 3, we’ll actually encode the shots and combine the shots into 1 video file.</p>
<ul>
<li><a href="https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-3/">https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-3/</a></li>
</ul>
<h2 id="av1-resources">AV1 resources</h2>
<ul>
<li><a href="https://www.singhkays.com/blog/av1-wiki-resources-tools/">AV1 Resource Central: Videos, Tools, Presentations, Comparisons, Research Papers, Encoders, Decoders</a></li>
<li><a href="https://www.singhkays.com/blog/its-time-replace-gifs-with-av1-video/">It’s time to replace GIFs with AV1 video!</a></li>
</ul>

<p>Reach out if you have any questions! Feel free to follow me on</p>
<ul>
<li>Twitter - <a href="https://twitter.com/singhkays">@singhkays</a></li>
<li>LinkedIn - <a href="https://www.linkedin.com/in/singhkays/">https://www.linkedin.com/in/singhkays/</a></li>
</ul>
</div></div>]]>
            </description>
            <link>https://www.singhkays.com/blog/azure-serverless-distributed-video-encoder-av1-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205775</guid>
            <pubDate>Wed, 25 Nov 2020 03:33:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4 V's of Good Data Engineering]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205610">thread link</a>) | @apex-consulting
<br/>
November 24, 2020 | https://theapex.io/4-vs-big-data | <a href="https://web.archive.org/web/*/https://theapex.io/4-vs-big-data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <p>When talking about scalable data engineering there are four broad categories of questions that we like to start with. I like to call these the four V’s of Good Data Engineering: Volume, Velocity, Variety and Veracity.</p>

<h3 id="overview">Overview</h3>
<ol>
  <li><a href="#volume">Volume</a>
    <ul>
      <li><a href="#current">Current</a></li>
      <li><a href="#desired">Desired</a></li>
      <li><a href="#anticipated">Anticipated</a></li>
    </ul>
  </li>
  <li><a href="#velocity">Velocity</a>
    <ul>
      <li><a href="#input">Input Velocity</a></li>
      <li><a href="#output">Output Velocity</a></li>
      <li><a href="#intra">Intra Velocity</a></li>
      <li><a href="#pressure">Pressure</a></li>
    </ul>
  </li>
  <li><a href="#variety">Variety</a>
    <ul>
      <li><a href="#flexibility">Flexibility</a></li>
      <li><a href="#discoverability">Discoverability</a></li>
      <li><a href="#useability">Useability</a></li>
    </ul>
  </li>
  <li><a href="#veracity">Veracity</a>
    <ul>
      <li><a href="#traceability">Traceability</a></li>
      <li><a href="#expl">Explainability</a></li>
      <li><a href="#expl">Auditability</a></li>
      <li><a href="#security">Security</a></li>
    </ul>
  </li>
</ol>


<p><img src="https://theapex.io/assets/images/volume.png" width="600"></p>
<p>Volume is simply a measure of how much data you wish to process. This is usually a discussion of gross numbers and timelines associated with them, and gives a rough idea of some architecture constraints and guidelines. For volume the discussion is a straightforward one about business goals and aspirations. Usually the discussion breaks down as follows:</p>
<h3 id="-current-volume"><a name="current"></a> Current Volume:</h3>
<p>What is the current volume of data that a particular data pipeline or system is processing. You can also discuss the current architecture and any bottlenecks it may be facing. When looking at current volume of data some considerations that may matter are:</p>
<ol>
  <li><strong><em>Volumes per access level</em></strong>: What volumes of data currently in terms of access patterns. In other words, there may be 10 PB worth of data, but 9 PB of that may be “cold data” or archive data and only 1 PB is regularly accessed or used for any analytics. Further than that it could be that only 1 TB is “hot data” or data that is frequently accessed. This will also impact how data estimates could be affected, for example archive data may be compressed or stored in columnar or analytical formats which would not give an accurate comparison to row based serial data.</li>
  <li><strong><em>Data Retention</em></strong> Companies may not be keeping all the data they wish to currently keep and have imposed retention policies which they may choose to remove if they have a more scalable data strategy in place. Data Retention can also be used to estimate the amount of data flowing through a system regardless of persistence for data processing purposes.</li>
  <li><strong><em>Record/Message size</em></strong> For each current dataset, how big is a record, and at a static point in time how many records of that size are there? In a streaming context this can impose hard limitations on what technologies can be used (Kafka vs. Kinesis for example), in a static data warehousing context it may give ideas about current suboptimal data model design or heavy denormalization patterns along low latency paths in the data pipeline.</li>
  <li><strong><em>Data Footprint</em></strong>  The amount of data a company stores may not be reflective of the total data footprint the company has especially when taking into consideration data retention policies, data that is ephemeral or not stored anywhere, or query patterns which adopt patterns of heavy denormalization. In well-designed systems some denormalization will lend itself towards better separation between write and read latencies, but will result in a lot of duplicate data. Another example of necessary duplicate data is in RAID configurations or replication such as with HDFS, and backups. In other cases there may be unnecessary duplicate data. Its important to suss out instances of heavy data duplication, necessary or not, in order to get a sense for the total data footprint and distinguish between “raw” system data and derived data that the company has synthesized for various reasons.</li>
  <li><strong><em>Key Datasets</em></strong>  It may also be helpful to get a sense for what are the largest datasets a company deals with and the most frequently changing. Sometimes you can infer key elements about how that dataset may change over time, and thus the right strategy for designing around that dataset. For example if they say their largest dataset is “users” and they are a B2C retail company then you can infer that table is most likely to see heavy growth as the business grows, and will have higher demands for read and write latency.</li>
</ol>

<h3 id="desired-volume"><a name="desired"></a>Desired Volume:</h3>
<p>What is the volume of data the company “wishes” to be able to process in the system. “As much as possible” is not an option, it must be finite and realistic. Over provisioning data processing capacity can get expensive really quickly, especially on the higher ends. More open-ended needs and requirements around scaling can be approached using autoscaling or adaptive scheduling. If the answer is “we dont know” an effort should at least be made to help the company try to estimate.</p>
<h3 id="-anticipated-volume"><a name="anticipated"></a> Anticipated Volume:</h3>
<p>This is meant to bookend the previous point. Whereas as the desired volume is where the company wants to be in X years, the anticipated volume is where the company is most likely going to be within that time. This serves as a lower bound where the desired volume forms a rough upper bound. A less jarring way to discuss desired and anticipated volume (because after all what business is going to admit they aren’t going to grow as fast as they want, even though for most businesses the amount of data being handled is a bad vanity metric) is to simply discuss upper and lower bounds of needed capacity.</p>


<p><img src="https://theapex.io/assets/images/velocity.png" width="800"></p>
<p>Velocity is a measure of how quickly the data is moving over time regardless of the volume of data. Normally it’s hard to talk about data velocity without talking about its desired latencies or limits of time that you have in order to process the data which is usually imposed by external technical or business requirements. You can talk about roughly 3 types of velocity:</p>
<h3 id="input-velocity"><a name="input"></a>Input Velocity:</h3>
<p>How quickly is data coming into the system and how does the system need to accommodate that. This can be as simple as knowing that you only have batch access to the data (daily data dumps) vs stream access to a particular subset of the data, thus can only in best case scenario provide batch analytics on it. Or it can be as complex as planning very tailored distributed stream systems to get a specific input consumption rate.</p>
<h3 id="output-velocity"><a name="output"></a>Output Velocity:</h3>
<p>How quickly does the data need to be accessed or read. Typically this is tied to the front end of the process and the business use cases of how the data is being used. Limits on the associated output latency may vary for different subsets of the data, and may also make exchanges between consistency and availability (in the spirit of the <a href="https://en.wikipedia.org/wiki/CAP_theorem">CAP theorem</a>).  In plain terms, you may be willing to sacrifice accuracy of the data for getting it quicker, or you may opt to scale out further in order to get tighter control over both speed and accuracy.</p>
<h3 id="intra-velocity"><a name="intra"></a>Intra Velocity</h3>
<p>Intra latency is the amount of latency that is permissible between input and output velocity, or you can think of it between the various components of a data pipeline. Intra velocity in a data pipeline is a little harder to tack down. Usually this is either an operational metric, or something that is observed and optimized post-hoc. However, this doesn’t mean it isn’t important as it can have cascading effects on other parts of a data pipeline, sometimes in unexpected ways. In streaming systems back pressure engineering is one way to observe and respond dynamically to changes and levels of intra velocity.</p>

<p><img src="https://theapex.io/assets/images/cascading.gif" width="400"></p>
<p>Cascading failures are familiar to those that have designed tightly coupled stream systems</p>
<h4 id="end-to-end-latency">End to End Latency</h4>
<p>Putting together the three latencies associated with each of these and you arrive at what people typically refer to as “end to end” latency requirements, ie once a piece of data hits your system, how much time do you have before your analytics or end users will see the impact of that data. Keep in mind that varying business use cases may have varying requirements around end to end latency. It is not a universal metric. However, multiple data pipelines may end up affecting one particular end to end latency and may require you to more carefully engineer a particular pipeline to “keep pace” with other parts of the pipeline.</p>



<p>Before going onto Variety, I want to make a quick note about the relationship between Volume and Velocity as they don’t exist in isolation but in terms of planning are heavily dependent on one another. In order to do so I want to introduce the idea of “data pressure”.</p>

<p>You can think of Data Pressure as follows:</p>

<div><div><pre><code>Data Pressure = Data Volume x Data Velocity 
</code></pre></div></div>

<p><img src="https://theapex.io/assets/images/pressure.png" width="300"></p>

<p>In other words a relatively low desired data velocity might be offset by higher data volume and vice versa. This basically expresses the data volume in terms of total amount of data needed to be processed per unit time. It is interesting to look at the limits of data pressure. For example, a really low data volume but high input velocity may lend itself towards stream processing. However, if the needed output velocity on the opposite end of the process velocity is very low, say daily, then it may lend itself towards buffering and then batch processing. In short, the pressure expresses how much strain is put on particular parts of a system and what extra parts of the system may need to be designed intermediately in order to marry front and backend pressure demands gracefully. Those parts that feel more pressure than may need to be given special attention, for example, horizontal scaling, or other strategies such as breaking up the data pipeline stages differently.</p>

<p><img src="https://theapex.io/assets/images/dataflow.png" width="800"></p>
<p>Thinking in terms of total data volume per unit time</p>

<p>In some instances certain processes may not decrease the total data pressure but simply exchange one type of pressure for another. For example, batch processing may be slower, but will allow for processing much higher volumes efficiently, whereas you can avoid processing larger volumes by simply micro batch or stream processing at lower frequencies. One is not better than the other, one may simply be more strategically convenient than the other when you take the whole picture into account.</p>

<p><img src="https://theapex.io/assets/images/pressure2.png" width="800"></p>
<p>You can think of a query over larger dataset but same latency similarly to higher pressure demand on a physical system</p>

<p>The other useful aspect of thinking in terms of pressure is that you can also think in terms of pressure differentials, for example, suppose that you have a very large dataset which you need to query with low latency. In …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://theapex.io/4-vs-big-data">https://theapex.io/4-vs-big-data</a></em></p>]]>
            </description>
            <link>https://theapex.io/4-vs-big-data</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205610</guid>
            <pubDate>Wed, 25 Nov 2020 03:09:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Letters from Alaska]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205393">thread link</a>) | @DoreenMichele
<br/>
November 24, 2020 | https://www.gabrielzzarate.com/blog/alaska | <a href="https://web.archive.org/web/*/https://www.gabrielzzarate.com/blog/alaska">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><section><article><p><em>The following are selections from letters I wrote to my fiancé in the summer of 2014 while working for a commercial salmon fishing company in Kodiak, Alaska.</em></p><h3 id="14-May-2014---Kodiak-Harbor"><a href="#14-May-2014---Kodiak-Harbor" aria-label="14 May 2014   Kodiak Harbor permalink"></a>14 May 2014 - Kodiak Harbor</h3><p>Here in the harbor, there are probably about a hundred large commercial fishing boats docked. Just about every evening, we have seen sea lions come swim amongst the boats! They will surface from time to time. They're huge and entertaining to watch.</p><p>I was a little frustrated while we were working today. James and I have been helping another guy named Jeff. I'm frustrated because both of them have more experience with construction work. Sometimes I'll show my inexperience, and become the joke on the job site. It doesn't bother me too much, but being on the bottom of the totem pole isn't where I like to be. It just gives me the incentive to learn the fishing knots quickly.</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/f3a60/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.webp 375w,https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/08b4d/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.webp 750w,https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/2b317/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.webp 1074w" sizes="(max-width: 1074px) 100vw, 1074px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/bf173/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.jpg 375w,https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/acb04/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.jpg 750w,https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/edd00/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.jpg 1074w" sizes="(max-width: 1074px) 100vw, 1074px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/edd00/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.jpg" alt="Kodiak Harbor" title="Kodiak Harbor" loading="lazy">
      </picture>
    </span>
  <figcaption>Kodiak Harbor, Kodiak AK</figcaption></figure><h3 id="26-May-2014---Arriving-on-the-Island"><a href="#26-May-2014---Arriving-on-the-Island" aria-label="26 May 2014   Arriving on the Island permalink"></a>26 May 2014 - Arriving on the Island</h3><p>We arrived on Bear Island today. We took a flight from Kodiak to Larsen Bay, then hopped in the skiff to Bear. The scenery is beautiful, but our Island itself isn't much to look at. We got here and immediately started mending nets. A guy named Peter showed me how to tie the knots to mend the nets, and I'm getting the hang of it. Also, it turns out that our cook is great <!-- -->—<!-- --> what fantastic news! James and I were able to get a room together, just the two of us, which is nice.</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/f3a60/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.webp 375w,https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/08b4d/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.webp 750w,https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/a9a89/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.webp 1024w" sizes="(max-width: 1024px) 100vw, 1024px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/bf173/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.jpg 375w,https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/acb04/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.jpg 750w,https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/72e01/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.jpg 1024w" sizes="(max-width: 1024px) 100vw, 1024px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/72e01/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.jpg" alt="Bear Island" title="Bear Island" loading="lazy">
      </picture>
    </span>
  <figcaption>Bear Island</figcaption></figure><h3 id="28-May-2014---Hiking"><a href="#28-May-2014---Hiking" aria-label="28 May 2014   Hiking permalink"></a>28 May 2014 - Hiking</h3><p>Because the season doesn't begin till the 9th, we can't send out mail every day like we will be able to. Today was my second full day on the Island. I mend nets most of the day. The nice thing is I get a break after lunch, and I have been reading and napping. Maybe this summer I can learn to sleep so I can enjoy many long naps next to you. </p><p>I think a big part of passing the time and not going crazy will be the friendships. Tonight after dinner James, Luke, Micah, and I hiked up to the highest point on the Island. It's not that far, but there is a good view up there. Luke challenged us to sprint to the top, but we only got 3/4 of the way before we almost passed out breathless.</p><h3 id="31-May-2014---The-Bana"><a href="#31-May-2014---The-Bana" aria-label="31 May 2014   The Bana permalink"></a>31 May 2014 - The Bana</h3><p>The last two days have been challenging as far as work goes. The weather has been pretty bad, a gale came in yesterday (when the wind blows hard), and it was cold and rainy. But even though it hasn't been the best working conditions, we've kept our spirits up.</p><p>Last night was my first shower here. But they don't just shower; they use what they call a Bana. It's a giant sauna. We sit in there and sweat out all the nasty stuff, then rinse off. It is super relaxing, and I haven't felt so clean in my entire time here.</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/f3a60/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 375w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/08b4d/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 750w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/293e0/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 1500w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/9a8a1/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 2250w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/e72c3/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 3000w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/c67aa/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/bf173/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 375w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/acb04/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 750w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/c58a3/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 1500w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/bd53b/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 2250w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/12609/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 3000w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/93719/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/c58a3/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg" alt="Mike Falcochio" title="Mike Falcochio" loading="lazy">
      </picture>
    </span>
  <figcaption>Mike Falcochio</figcaption></figure><h3 id="6-June-2014---The-Season-Begins"><a href="#6-June-2014---The-Season-Begins" aria-label="6 June 2014   The Season Begins permalink"></a>6 June 2014 - The Season Begins</h3><p>Today is the second day of the season. Yesterday we got the nets out, and our first pick was pretty big. We only picked the nets once and brought in around 8,000 lbs, equal to like $16,000. Not bad for the first day. </p><p>When we put the nets out, I didn't take any medicine for sea-sickness, and we were out there in 36 mph winds with some pretty rocky seas. I threw up on three different occasions several times and now have those lovely broken blood vessel spots on my face. Now I've been taking Dramamine, and I've been fine. Unfortunately, a few guys are still getting sick even though they are taking medicine, including James.</p><p>This morning I was picking with Calvin, a 6' 5" guy with long curly blond hair that goes past his shoulders. He's super chill, goofy, and a prankster. Anyway, we had a great time. We were picking in one of the roughest nets, and I was in the front reaching to grab a rope over the side. A big wave came, pulling the rope away from me, and I didn't let go. I fell right over the side into the ocean. In a flash, Calvin ran to the front of the skiff to pull me back in. Haha, what a fun, cold dip in the ocean.</p><p>Being out amongst the weather and rough seas has reminded me of a fair bit of the boating accident, but not necessarily in a negative way. I think about it and thank God for using that experience to make me stronger and for allowing me to be back out there without fear. On the back of my orange rain jacket I wrote in Sharpie: "Joy follows suffering and life follows death" with Dad's and Earl's initials underneath. It's a proclamation to the ocean and the waves that even though that day on the Gulf was hard, God has made me stronger and brought me joy. The joy that comes from being in a love relationship with the King of the Universe, who calmed the seas and gives me hope that I will see both my Dads again.</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/f3a60/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 375w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/08b4d/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 750w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/293e0/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 1500w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/9a8a1/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 2250w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/e72c3/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 3000w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/c67aa/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/bf173/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 375w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/acb04/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 750w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/c58a3/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 1500w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/bd53b/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 2250w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/12609/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 3000w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/93719/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/c58a3/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg" alt="Calvin" title="Calvin" loading="lazy">
      </picture>
    </span>
  <figcaption>Calvin Bulthuis</figcaption></figure><h3 id="10-June-2014"><a href="#10-June-2014" aria-label="10 June 2014 permalink"></a>10 June 2014</h3><p>We had an extended break today because of the weather, so I've been getting extra rest. My back and hands are very sore, so much so that I have to take breaks as I write this letter. They say that the soreness goes away after a few more weeks.</p><h3 id="11-June-2014---Heads-or-Tails"><a href="#11-June-2014---Heads-or-Tails" aria-label="11 June 2014   Heads or Tails permalink"></a>11 June 2014 - Heads or Tails</h3><p>Yesterday I was picking with Luke when we caught a herring in the net (a herring is a small salmon, a little longer than my hand). He picked it up and said, "Heads or tails, Gabe?" I didn't understand what he meant but replied, "tails." He bit off the head, spit it out, and handed me the rest! So I bit off the tail. Nasty stuff! Guys on the crew said the tail is worse because it's where...well, I'll let you imagine what comes out near the tail.</p><h3 id="12-June-2014"><a href="#12-June-2014" aria-label="12 June 2014 permalink"></a>12 June 2014</h3><p>How long is it taking my letters to arive in Greenville? If the weather is good, your letters have been getting here in five to six days, which is quicker than I expected.</p><figure>
  <img src="https://www.gabrielzzarate.com/4e23b322945544755406648171c24d28/low_quality_day_on_the_job-3.gif" alt="A Nice Day on the Job">
  <figcaption>A day on the job. Heavy on the sunshine, light on the fish.</figcaption></figure><h3 id="14-June-2014"><a href="#14-June-2014" aria-label="14 June 2014 permalink"></a>14 June 2014</h3><p>There's not much new to tell here. We've done well as far as the amount of fish we've caught. I think we are close to me the 100,000 lbs mark.</p><p>Can you send me an update on the World Cup? You can probably print out what the scores have been and who scored during the games. That would be awesome.</p><h3 id="17-June-2014"><a href="#17-June-2014" aria-label="17 June 2014 permalink"></a>17 June 2014</h3><p>It's been storming here for the past few days, so we haven't been able to pick the nets three times a day. It seems like we've been fishing for a long time, but we are just getting started in reality. It can be too overwhelming to dwell on how much time I still have to be on this Island. I prefer to take the days one at a time.</p><p>You asked about who I am close to up here. I get along decently well with everyone. Luke is from Charleston. He's a loner and a wild one; he's hiked the Appalachian Trail by himself. In the off-season, he lives in Hawaii and surfs every day. Calvin is also another guy I like. I can't say I am close to anyone yet, though.</p><p>I was so glad to receive your letters today. I love you, Caitlyn. There's a guy named Mike who has a pretty pessimistic view of marriage. He has made a few jokes about getting married to the first girl I started dating, saying that I don't know if there is something else out there better. My response is that I know plenty of girls, and they all represent confirmation after confirmation that what I have is far better. xo :)</p><h3 id="21-June-2014---Summer-Solistice"><a href="#21-June-2014---Summer-Solistice" aria-label="21 June 2014   Summer Solistice permalink"></a>21 June 2014 - Summer Solistice</h3><p>Today is the summer solstice, and they say that the sun won't set until 1 am. The closure was two days long and was a nice break from fishing. The sun has been out for the last two days as well. We haven't seen the sunshine very much.</p><p>I want to hear from you. How did the wedding dress shopping go?</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/f3a60/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.webp 375w,https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/08b4d/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.webp 750w,https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/8b983/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.webp 768w" sizes="(max-width: 768px) 100vw, 768px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/bf173/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.jpg 375w,https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/acb04/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.jpg 750w,https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/212bf/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.jpg 768w" sizes="(max-width: 768px) 100vw, 768px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/212bf/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.jpg" alt="The Crew" title="The Crew" loading="lazy">
      </picture>
    </span>
  <figcaption>The Crew (left to right): Luke Yarborough, Josh Krohn, Evan Dundas, Adam Wilson, Calvin Bulthus, James Peery, Micah Glassman, Gabriel Zarate, Casey Furnish, Mike Falcochio, Moreno, Mark Barnes</figcaption></figure><h3 id="24-June-2014---The-Crew"><a href="#24-June-2014---The-Crew" aria-label="24 June 2014   The Crew permalink"></a>24 June 2014 - The Crew</h3><p>There are 12 crewmen in total. Mike is from Louisiana and has been coming up to work for the Fields for the last seven years! He is given a lot of responsibility for the crew and is a nice guy. Adam, Casey, and Mark are all from Florida. Adam is a big guy with lots of tattoos and is a big, fat southern teddy bear. Casey annoys me the most probably. He likes to talk a lot and try to tell me what to do when he doesn't know what he's doing himself. Mark is interesting. He has done some pretty hard drugs and tells some wild stories. Micah and Evan are the young guys from Idaho. They are both eighteen and are farm boys. Peter is from California but lives in Tennessee. He's a climber, and we have some great conversations. He wants to go to seminary and seems to love people. Luke is a surfer from Charleston and is a relaxed but funny guy. Then there's Calvin, who is the long, curly-haired giant who has the most infectious smile. What a goofball. Josh is also from California and is not my favorite.</p><p>Kelsey is the cook. She makes delicious food and has a no-nonsense attitude that is good for a girl in her position. Overall it is a great group. We laugh a lot.</p><p>So you found the dress! I could feel your excitement even through the letter, so I know it must be the right one. I'm so curious about it now!</p><p>The sun has been shining here for the past few days. It's been so great to have better weather. I got stung by some jellyfish this afternoon. It's no big deal, just an irritating stinging sensation. </p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/f3a60/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 375w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/08b4d/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 750w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/293e0/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 1500w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/9a8a1/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 2250w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/e72c3/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 3000w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/c67aa/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/bf173/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 375w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/acb04/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 750w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/c58a3/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 1500w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/bd53b/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 2250w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/12609/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 3000w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/93719/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/c58a3/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg" alt="Bear Island at Sunset" title="Bear Island at Sunset" loading="lazy">
      </picture>
    </span>
  <figcaption>Backside of Bear at Sunset</figcaption></figure><h3 id="26-June-2014"><a href="#26-June-2014" aria-label="26 June 2014 permalink"></a>26 June 2014</h3><p>I keep coming back to the concept of contentment. Sometimes I try to count the days, and I can get discouraged. Not just a little down, like really discouraged. I can't wait to return.</p><h3 id="27-June-2014"><a href="#27-June-2014" aria-label="27 June 2014 permalink"></a>27 June 2014</h3><p>I think the most significant prayer request would be endurance to keep going. It's long hours and long days here, and there's a long way to go. Some mornings it's tough to get up and get going. Once I get up and eat breakfast, things get better.</p><h3 id="3-July-2014"><a href="#3-July-2014" aria-label="3 July 2014 permalink"></a>3 July 2014</h3><p>After every morning pick, there is usually a couple of hours for shore work before lunch (depending on how long the pick takes). For the last two days, I've been working in the …</p></article></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.gabrielzzarate.com/blog/alaska">https://www.gabrielzzarate.com/blog/alaska</a></em></p>]]>
            </description>
            <link>https://www.gabrielzzarate.com/blog/alaska</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205393</guid>
            <pubDate>Wed, 25 Nov 2020 02:33:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Origin of the Name Posix]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205384">thread link</a>) | @wooby
<br/>
November 24, 2020 | https://stallman.org/articles/posix.html | <a href="https://web.archive.org/web/*/https://stallman.org/articles/posix.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h2><a href="https://stallman.org/">https://stallman.org</a></h2>
<p>
For current political commentary, see
the <a href="https://stallman.org/archives/polnotes.html">daily
political notes</a>.
</p>
<p>
<a href="https://stallman.org/biographies.html#serious">RMS's Bio</a> |
<a href="http://gnu.org/">The GNU Project</a>
</p>

<hr>



<h2>2011-05-11</h2>

<p>
In the 1980s I was in the IEEE committee that wrote the standard that
ultimately became known as POSIX.  The committee set itself the task
of standardizing interface specs for a Unix-like system, but had no
short name for its work.  When the first part of the specification was
ready, someone gave it the name "IEEEIX", with a subtitle that
included "Portable Operating System" — perhaps "Specifications
for a Portable Operating System".
</p>
<p>
It seemed to me that nobody would ever say "IEEEIX", since the
pronunciation would sound like a shriek of terror; rather, everyone
would call it "Unix".  That would have boosted AT&amp;T, the GNU
Project's rival, an outcome I did not want.  So I looked for another
name, but nothing natural suggested itself to me.
</p>
So I put the initials of "Portable Operating System" together with the
same suffix "ix", and came up with "POSIX".  It sounded good and I saw
no reason not to use it, so I suggested it.  Although it was just
barely in time, the committee adopted it.

<p>
I think the administrators of the committee were as relieved as I was
to give the standard a pronounceable name.
</p>
<p>
Copyright (c) 2011 Richard Stallman
Verbatim copying and redistribution of this entire page are
permitted provided this notice is preserved.
</p>


</div>]]>
            </description>
            <link>https://stallman.org/articles/posix.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205384</guid>
            <pubDate>Wed, 25 Nov 2020 02:33:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C is not a subset of C++: A simple program to show differences in the standards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205170">thread link</a>) | @abqexpert
<br/>
November 24, 2020 | https://abqexpert.com/2020/11/24/c-is-not-a-subset-of-c-a-simple-program-to-show-differences-in-the-c-and-c-standards/ | <a href="https://web.archive.org/web/*/https://abqexpert.com/2020/11/24/c-is-not-a-subset-of-c-a-simple-program-to-show-differences-in-the-c-and-c-standards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-883">

    

	<div>

		
<p>The following is a bit of a write up of a program I wrote for a presentation to a bunch of Java programmers(really this was part of a workshop on Qt for Android Programmers) to illustrate that C and C++ are very different languages, and the differences between standards can be large even if the program compiles.  So I tried making this as straightforward as possible.  A ton of people have written up similar things. Hopefully the value here is in the simplicity of the presentation(I tried making it accessible to people with only Java programming experience). I was heavily inspired by <a href="http://ioccc.org/2015/yang/prog.c">Don Yang’s 2015 IOCC entry</a>(Some commentary <a href="http://ioccc.org/2015/yang/hint.html">here</a>, and a fun video of him making it <a href="http://ioccc.org/2015/yang/spoiler.html">here</a>).</p>



<p>Imagine we would like to create a single program which when compiled would tell us how which standard of C or C++ it was compiled with.  Obviously we cannot use any features not common to both C and C++, so no template magic, and so we won’t be able to distinguish between C++98 and C++03 or between C++11,C++14, C++17, or C++20. Obviously we won’t try to tell the difference between C89 and C90 as well. And we will only consider C after C89 since it was not always implemented consistently prior, and K &amp; R function signatures are ugly.   We will try to not use the C preprocessor as much as possible, but in order to tell post-C11 from pre-C11 we need to introduce some macros.</p>



<p>One of the first and simplest differences is between C and C++. In C a character literal like ‘a’ is the same size as an int.  In C++ it is the same size as a char.  Now if you are on a platform where an int and char are the same size, then you will need a different test(In this day and age Fall 2020, even most embedded chips are moving to 32bit ARM/RISC-V/whatever else(I believe most 16bit chips in common use have an int with distinct size from char), where we wouldn’t expect this to be the case). So our first function is:</p>


<pre title="">static int is_C(void){
    int a=0; char b='\0';
    assert(sizeof(a)!=sizeof(b)); /*bail out early on unusual archs.*/
    return (sizeof ('\0') == sizeof(a));
}
</pre>


<p>The next major difference is between C before C99 and C after C99.  The big change was that C++ style inline comments were allowed.  So instead of just ‘/* whatever */’ you could use ‘// whatever’. This leads us to:</p>


<pre title="">static int is_post_ANSI_C(void){
    return 1//**/2
            ;
}
</pre>


<p>So if we have C++ style inline comments we return 1 since the rest of the line is a comment.  If we don’t then we have a ‘/’ followed by a comment followed by 2, so after comment and whitespace removal we get ‘return 1/2;’ which we know by the rules of integer division is 0.</p>



<p>Next in-order to differentiate versions of C and C++ after 2011, and ones before we will need to use a C Preprocessor macro.  After the C11 and C++11 revisions the language changed somewhat dramatically by adding some new prefixes for string literals to allow for the use of Unicode in strings(see <a href="https://en.cppreference.com/w/cpp/language/string_literal">this page</a> for a good reference to what the various prefixes mean, in general cppreference.com is a good source of information on either C or C++).  Here is our macro and function:</p>


<pre title="">#define test(U) U"1"
static int is_post_11(void){
    return (sizeof(test()[0]) &gt;1);
}
</pre>


<p>This uses a trick from Don Yang’s entry, in that in prior versions of the standard the preprocessor would view the ‘U’ in the definition as the value of the argument given to the ‘test’ function-type macro.  In the return statement we pass in no argument so the ‘U’ is replaced by nothing, and we just get ‘sizeof(“1″[0]) &gt;1’ which is just ‘sizeof(char) &gt;1’ which is always false.  In later editions of the standards the ‘U’ is parsed as a prefix to a string literal, in this case a 32bit wide unicode string, so each element in the string that follows the ‘U’ character must be at least 32 bits wide.  As long as we aren’t on an architecture with &gt;=32 bit chars this will lead to ‘sizeof(something at least 32bit) &gt;1’ which will be true for this case.</p>



<p>If proposal N2231 for the C2x standard goes through then both C++20 and C2x will have a char8_t datatype which will be the type of ‘u8’ prefixed string literal which would be another test we could do.</p>







<p>The final program is here:</p>


<pre title="">#include &lt;stdio.h&gt;
#include &lt;assert.h&gt;
 
static int is_post_ANSI_C(void){
    return 1//**/2
            ;
}
 
static int is_C(void){
    int a=0; char b='\0';
    assert(sizeof(a)!=sizeof(b)); 
    return (sizeof ('\0') == sizeof(a));
}
 
#define test(U) U"1"
static int is_post_11(void){
    return (sizeof(test()[0]) &gt;1);
}
 
int main(int argc, char *argv[])
{
    int C = is_C();
    int post_11 = is_post_11();
    int post_ANSI_C = is_post_ANSI_C();
 
    if(C &amp;&amp; post_ANSI_C &amp;&amp; post_11){
        printf("This is C11 or later!\n");
    }
    if(C &amp;&amp; post_ANSI_C &amp;&amp; !post_11){
        printf("This is C99!\n");
    }
    if(C &amp;&amp; !post_ANSI_C &amp;&amp; !post_11){
        printf("This is C89 or C90\n");
    }
    if(!C &amp;&amp; post_11){
        printf("This is C++11 or later\n");
    }
    if(!C &amp;&amp; !post_11){
        printf("This is C++98 or C++03\n");
    }
 
    return 0;
}
</pre>


<p>Which can be compiled with:</p>


<pre title="">gcc -std=c89 main.c
</pre>


<p>Or</p>


<pre title="">g++ -std=c++98 main.c
</pre>


<p>Then it can be run as:</p>


<pre title="">./a.out
</pre>


<p>valid values of the ‘std’ option to try are ‘c90’, ‘c99’, ‘c11’, ‘c++03’, ‘c++11’, etc. More given <a href="https://gcc.gnu.org/onlinedocs/gcc/C-Dialect-Options.html#C-Dialect-Options">here</a>.</p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://abqexpert.com/2020/11/24/c-is-not-a-subset-of-c-a-simple-program-to-show-differences-in-the-c-and-c-standards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205170</guid>
            <pubDate>Wed, 25 Nov 2020 01:56:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remember when you could reboot your computer without rebooting your phone first?]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25205031">thread link</a>) | @mdoms
<br/>
November 24, 2020 | https://annoying.technology/posts/7b574a72da90e5cd/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/7b574a72da90e5cd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/31a8603310fa498ae382fe6140ad8db20c277711/6bc2e/media/neustartdoeswell.png"></p><p>Remember when you could reboot your computer without rebooting your phone first?</p><p>I’m not even kidding: I needed to reboot my Mac because I was unable to navigate character by character using the arrow keys when composing new iMessages in Big Sur, but Finder refused to quit during the reboot with the above error message. It was still syncing my iPhone. (Remember when we thought the iTunes rewrite would be a good thing? <a href="https://twitter.com/manu_faktur/status/1260099839511212032">Good Times</a>!) I tried quite a few things on both devices, but was unable to cancel said sync in any other way than to reboot the phone.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/7b574a72da90e5cd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205031</guid>
            <pubDate>Wed, 25 Nov 2020 01:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Blade Runner tells us about Modern AI]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25204662">thread link</a>) | @laurex
<br/>
November 24, 2020 | https://www.psychoftech.org/blog/2020/11/13/what-blade-runner-tells-us-about-modern-ai | <a href="https://web.archive.org/web/*/https://www.psychoftech.org/blog/2020/11/13/what-blade-runner-tells-us-about-modern-ai">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-62701a95677011374ee2"><div><p>Pope Francis <a href="https://www.vaticannews.va/en/pope/news/2020-11/pope-francis-november-prayer-intention-robotics-ai-human.html">recently devoted</a> his monthly prayer intention to the safe and beneficial development of artificial intelligence. Though the prayer was expressed primarily in terms of reducing inequality, a theme this Pope has touched on often, its final plea had an uncanny resonance: <em>“Let us pray that the progress of robotics and artificial intelligence may always serve humankind… we could say, may it ‘be human.’”</em></p><p>The question of what it is to “be human,” as distinct from the rest of Creation, has concerned the Church for centuries. It was a driving force behind the philosophy of Descartes, whose strong mind-body dualism was in part an attempt to reconcile Church doctrine with the dawning rationalist tradition. Though Descartes was primarily concerned to distinguish us from animals, which he considered mere automata, the specter of a fully mechanical account of humanity looms over his work. Even in the last century, as AI has become less of a fantasy and more of a research program, this fundamental ambivalence remains. We strive to build machines in our own image, and to conceive of ourselves in mechanistic terms, and yet each step we make in this direction unnerves us. The prospect of closing the gap entirely, though it is the stated aim of both AI and cognitive science, strikes most people as horrifying.</p><p>Nowhere is this ambivalence better expressed than in <em>Blade Runner</em>, Ridley Scott’s 1982 sci-fi masterpiece. The film takes place in an imagined 2019, and though it may have overshot the mark in some of its technological details (no flying cars), it could not be sharper with respect to the anxieties that define our age. Scott imagined a world controlled by a few large corporations that have become enormously profitable through the development of intelligent machines. These humanoid robots, known as “replicants,” are primarily consigned to narrow, routine jobs, but there is a pervasive fear that they will infiltrate other areas of human life. The film tells the story of Deckard (a deliberate homonym of Descartes), a so-called “blade runner” charged with hunting down a group of replicants that have escaped from an off-world colony. Deckard disdains replicants, but in his pursuit, he unwittingly falls in love with one, and confronts the possibility that he might be a replicant himself.&nbsp;</p><p>This fear of mistaken identity is distilled, in the popular consciousness, in the image of the Turing Test. Originally proposed by Alan Turing as a test of whether machines could think, the connotations of the test have shifted in response to technological development. At its core, the meaning of the test is existential. As Brian Christian <a href="https://www.amazon.com/Most-Human-Artificial-Intelligence-Teaches/dp/0307476707">writes</a>:&nbsp;</p><blockquote><p>“The Turing test attempts to discern whether computers are, to put it most simply, ‘like us’ or ‘unlike us’: humans have always been preoccupied with their place among the rest of creation. The development of the computer in the twentieth century may represent the first time that this place has changed. The story of the Turing test, of the speculation and enthusiasm and unease over artificial intelligence in general, is, then, the story of our speculation and enthusiasm and unease over ourselves. What are our abilities? What are we good at? What makes us special?”</p></blockquote><p><em>Blade Runner</em> features a Turing Test analog known as the Voigt-Kampff Test, the purpose of which is to weed out replicants posing as human beings. The theoretical basis for the test is never quite made explicit; we know only that it has something to do with conversation and various physiological responses. But in the failed responses of one escaped replicant, Leon, we recognize shortcomings that still plague AI systems today.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1605292311943_32260"><div><p>Modern machine learning systems face a tradeoff: learn too little from the training data and performance will be too random, but hue too closely to the training data and performance will not generalize to new examples. In the jargon of the discipline, the former kind of error is called “underfitting”; the latter “overfitting.” Usually, engineers seek out a sweet spot between these two with respect to a particular narrow problem. By comparison with the goal of a truly flexible intelligence, though, all modern AI systems are drastically overfitted. They are highly specialized to a particular task and brittle in their application. Leon, too, was designed for a particular task: we’re told he can “lift atomic loads all day and night.” When Holden, the test administrator, begins to take him beyond the scope of that task into a hypothetical, he overfits, seeking too much specificity.</p><blockquote><p><em>“You’re in a desert walking along the sand…”</em></p><p><em>“What one?”</em></p><p><em>“What?”</em></p><p><em>“What desert?”</em></p><p><em>“It doesn’t make any difference what desert. It’s completely hypothetical.”</em></p><p><em>“But how come I’d be there?”</em></p></blockquote><p>Modern AI systems can often perform exceedingly well within their domain, giving an illusion of generality. A system from DeepMind, for example, learned to play various Atari games at a superhuman level. But <a href="https://www.technologyreview.com/2020/03/27/950247/ai-debate-gary-marcus-danny-lange/">a demonstration from the robotics startup Vicarious</a> showed that the system lost all abilities when the pixels on the screen were slightly moved. This sensitivity to slight adjustments makes deep learning systems too vulnerable for many real-world applications. Leon, too, is highly sensitive to slight novelty.</p><blockquote><p><em>“You look down and you see a tortoise, Leon. It’s crawling towards you.”</em></p><p><em>“Tortoise? What’s that?</em></p><p><em>“You know what a turtle is?”</em></p><p><em>“Of course.”</em></p><p><em>“Same thing.”</em></p></blockquote><p>The ability to flexibly adapt to novel circumstances remains, for the time being, uniquely human. We reflect, in our cognitive capacities, the bottomless complexity of the physical and social world to which we are adapted. And indeed <a href="https://www.pnas.org/content/108/4/1234">there is evidence</a> that even roboticists pursuing purely <em>pragmatic</em> objectives of behavior in a real-world environment can best achieve these goals through the <em>biological</em> strategies of evolution and development. To give machines our abilities, it seems, we have to give them our histories.</p><p>It is no surprise, then, that the question that drives Leon over the edge and leads him to shoot Holden is one about his past.</p><blockquote><p><em>“Describe in single words only the good things that come into your mind about your mother.”</em></p></blockquote><p>Unlike the more recent model replicants in the film, Leon has not been given memories, and so has no personal history to speak of. The philosopher John Locke believed that the continuity of our memories was the seat of our selfhood, because it is only by virtue of this continuity that we know ourselves to be the same person from one moment to the next. And indeed, part of what makes interacting with even a cutting-edge AI system like GPT-3 so uncanny is the lack of a unitary identity. Paradoxically, this multifarious identity is part of what helps such systems behave intelligently. As Brian Christian <a href="https://www.amazon.com/Most-Human-Artificial-Intelligence-Teaches/dp/0307476707">writes</a>, “[t]o be human is to be <em>a</em> human, a specific person with a life history and idiosyncrasy and point of view; artificial intelligence suggests that the line between intelligent machines and people blurs most when a purée is made of that identity.” Here, the division between intelligence and <em>humanity</em>, whatever that term may turn out to mean, becomes especially stark. A deep neural network trained on hundreds of thousands of conversations may be intelligent, but it cannot give us the comforting cues that tell us we are interacting with a particular person.</p><p>As <em>Blade Runner</em> makes clear, though, the various cues to our humanity are just that: cues. A replicant with memories is a person in every sense that counts. And as long as we don’t believe in a mystical ghost in the machine, we are forced to concede that there are no guarantees about which capacities and traits will remain uniquely human. Consciousness may persist as an unsolvable mystery, but when robots begin to imitate all the outward signs we use to attribute consciousness to our fellow humans, this mystery will lose its salience. As Sam Harris and Paul Bloom point out in <a href="https://www.nytimes.com/2018/04/23/opinion/westworld-conscious-robots-morality.html?mc_cid=7003ba28a2&amp;mc_eid=%5BUNIQID%5D&amp;utm_campaign=7003ba28a2-EMAIL_CAMPAIGN_2018_04_23&amp;utm_medium=email&amp;utm_source=Sam%20Harris%20Newsletter&amp;utm_term=0_f1c2a2c9db-7003ba28a2-">a 2018 op-ed</a>, “Anything that looks and acts like the hosts on ‘Westworld’ [or, indeed, the replicants in <em>Blade Runner</em>] will appear conscious to us, whether or not we understand how consciousness emerges in physical systems.” This future may be far off, but the questions it poses are already with us. With each new development, we’ll have to ask ourselves: how human is human enough?</p></div></div></div>]]>
            </description>
            <link>https://www.psychoftech.org/blog/2020/11/13/what-blade-runner-tells-us-about-modern-ai</link>
            <guid isPermaLink="false">hacker-news-small-sites-25204662</guid>
            <pubDate>Wed, 25 Nov 2020 00:31:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Canvas Made of Pixels]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25204468">thread link</a>) | @sabon
<br/>
November 24, 2020 | https://www.claybavor.com/blog/a-canvas-made-of-pixels | <a href="https://web.archive.org/web/*/https://www.claybavor.com/blog/a-canvas-made-of-pixels">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-e4d84132f42c63276145"><div><p>A year ago over the holiday break, I created a large-scale digital “canvas” that can reproduce works of fine art – paintings, photographs, lithographs, etc. – in a way that is nearly indistinguishable from the real thing.</p><p>For the full effect, you really need to see it in person. But so you can get the idea, here’s a photograph of the frame displaying a Van Gogh:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1493995847697_203326"><div><h3>The Problem with Digital Picture Frames</h3><p>I’ve been interested in digital picture frames since 2003, when I made my first custom frame out of a cannibalized Apple iBook. The promise of digital picture frames, of course, is that they can display new stuff whenever you want – photos, paintings, whatever. But there’s a real problem with digital picture frames: they just aren’t very good.</p><p>What do I mean? To start, in commercially available digital picture frames, you’ve generally got a big black plastic bezel surrounding the display, so the picture frame looks more like a small television than a picture frame. The display itself is all wrong, too. You can see individual pixels, the viewing angle is limited, the contrast is low, and the standard aspect ratio (16×9) of modern displays is too wide for photos and fine art. And until recently, no one has made a <em>big</em>&nbsp;digital picture frame, so the largest thing you could display was a 5×7 or 8×10 photograph. Finally,&nbsp;because screens emit rather than reflect light, they usually appear either too light (glowing) or too dark (washed out), so they <em>look</em>&nbsp;like screens.</p><p>With this project, I set out to tackle all of these problems, and to create something so good at reproducing artwork that a viewer forgets (or never even realizes) that he or she isn’t just looking at the real thing.</p><h3>Lots and Lots of Pixels</h3><p>The first task was to find a large display with very high resolution, accurate color reproduction, a good contrast ratio, and a wide viewing angle.</p><p>The resolution requirement for the display was informed by how people generally look at art: you start at a bit of a distance to take in the piece, then may walk up to it and lean in to inspect details, getting as close as maybe a foot away. If you do the math, at that viewing distance, you need a pixel density of about ~285 pixels per inch to keep individual pixels below the resolving capability of the human eye at the fovea, which is about 60 pixels per degree. (I’ll skip the math and detail about angular resolution and the human eye. If you’re interested, you can read more <a href="https://en.wikipedia.org/wiki/Angular_resolution">here</a>&nbsp;and <a href="https://en.wikipedia.org/wiki/Naked_eye">here</a>.)</p><p>Today, there’s really only one large display that approaches this kind of resolution: the 5K display on the 27” iMac, which has a pixel density of about 220 ppi and an overall resolution of 5120 by 2800 pixels. (If you’re wondering, 4K “Ultra HD” TVs aren’t even close to having enough resolution for this application. A 40-inch 4K TV is only ~110 ppi.)</p><p>Unsurprisingly, Apple also did a great job with the color reproduction and viewing angle on the iMac display. So I had my display.</p><h3>Aspect Ratios and Gilded Wood</h3><p>The next thing I looked at was the frame itself: the material, the dimensions, the mat, and how to make it so the whole thing could be mounted flush against a wall, just as real paintings or photographs are.</p><p>The first thing I wanted to get right was the aspect ratio of the frame, since it would determine what works of art I’d be able to display, as well as the dimensions of the frame itself. As it turns out, an aspect ratio of 16×9 (or 1.77:1) – which is the aspect ratio of the iMac display and basically every other display on the market today – is really bad for displaying fine art, which tends to be much “squarer”. For instance, the average aspect ratio of the works below is ~1.3:1. The Mona Lisa, the “least square” of the bunch, has an aspect ratio of 1.45:1, still significantly squarer than 16:9.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_14_1494706960442_8923"><div><p>Of course, I wasn’t about to saw off the sides of the 5K display. Instead, I designed the frame and mat to overcrop the display, resulting in an aspect ratio of around 1.4:1 – still a bit wide, but a good tradeoff between using most of the display and accommodating most works of art without having to chop their sides off.</p><p>Next I turned to the frame material. I wanted something that looked totally unlike anything you’ve seen around a computer monitor or television – a sort of “anti black plastic”. And that led me to a handmade, gilded wood frame, with a classic profile and a good amount of patina.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_14_1494706960442_11714"><div><p>With the dimensions and frame material set, my last task was to figure out how to mount the whole unit so that it would sit exactly flush with the wall. After cutting a hole in the wall, I had to figure out mechanisms for making millimeter-scale adjustments (solution: screws and wood shims) and properly ventilating the computer while sealed away in the frame (solution: discrete ventilation slats on the bottom of the frame).</p><h3>Photons that Fit In</h3><p>The most interesting problem to tackle was “the blue glowing screen problem”.</p><p>One of the many ways that screens give themselves away as screens is by emitting light that is “out of character” with the surrounding environment. They can be too bright or too dark relative to the things around them, and indoors, displays often seem too blue.</p><p>I solved these problems with what I call “luminance matching”. The basic idea is to sample the light falling on the frame several times a second, and then adjust the display and image parameters so that what’s displayed is “correct” given the surrounding environment.</p><p>To solve the brightness problem, I embedded a photodiode – basically a brightness sensor – into the side of the frame, directed at the wall the frame is hanging on. The frame takes luminance readings off of the photodiode via a <a href="http://www.phidgets.com/">Phidgets</a>&nbsp;USB sensor interface, then automatically adjust the brightness of the display. Getting the mapping from sensor readings to display brightness was a bit tricky, and I ended up using two photodiodes –&nbsp;one for the wall, one for the display –&nbsp;to perform a calibration step, so that the luminance of the actual white wall matched the luminance of the display while displaying a photograph of the white wall.</p><p>For the color matching / white balance problem, I began with the somewhat complicated approach of using an attached USB camera, turning off its automatic white balance, and sampling frames every few seconds to estimate the color of the incoming light. This approach turned out to be overkill, since the color temperature of the light in the hallway where the frame is hanging is very predictable over the course of a day. So instead, I ended up using the awesome little tool <a href="https://justgetflux.com/">Flux</a>, which can adjust the white balance of a display according to the time of day.</p><p>All of this comes together to enable the frame to respond to changing lighting conditions in the same way that a real photograph or painting would.</p><p>You can see it in action here, where I cycle through several different lighting conditions, from dim daylight, to overhead halogens, to simulated direct sunlight. While filming, the exposure settings on the camera were locked, so you can get a sense for changes in lighting across the whole scene, including on an identical (real) photograph hanging opposite the digital frame.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_14_1494706960442_15377"><div><p>The effect in person is really quite startling: guests in our house almost never register that the photograph or painting is being displayed is anything other than a photograph or painting.</p><h3>Shy Mode</h3><p>The final feature I added was what I call “shy mode”. When shy mode is enabled, the picture frame uses a discrete camera and a simple face detection system to determine whether anyone is currently looking at it. If someone is, then the frame won’t change what it’s displaying, since that would be a total giveaway.</p><p>A fun (but impractical and frustrating) variant of this feature is to have the image change <em>as soon as</em>&nbsp;the viewer looks away. So you’re looking at a painting, glance away to another room, and look back to find a new painting hanging on the wall.</p><h3>For Version 2.0</h3><p>Building version 1.0 exposed all sorts of things that could be better.</p><p>Of course, using a whole iMac just for its display is totally impractical. A custom display with a lightweight, Android-runnning system on a chip to drive it would be much better. The ideal display would be something like a 5:7 aspect ratio 55” 8K OLED panel. (OLED would enable a much higher contrast ratio and better viewing angles.) Wireless power or trickle charging of an onboard battery would avoid unsightly power cords or wall surgery. And a richer set of sensors for doing luminance matching and presence sensing would be nice, too.</p><p>In the meantime, I’m pretty excited about what companies like <a href="https://depict.com/">Depict</a>&nbsp;and <a href="https://www.electricobjects.com/">Electric Objects</a>&nbsp;are doing. Their products could be better – the 16:9 aspect ratio is really off in my opinion, OLED will be important, and 4K resolution isn’t enough – but they’re off to a good start. I’m really excited to see what they and others come up with in this space.</p><p>Thanks to Mahmut at Sumner Frames in Palo Alto for helping me with the framing, to Andrew Luo for his help writing various pieces of software, and to Kelly for being okay with me cutting a big hole in our wall.</p></div></div></div>]]>
            </description>
            <link>https://www.claybavor.com/blog/a-canvas-made-of-pixels</link>
            <guid isPermaLink="false">hacker-news-small-sites-25204468</guid>
            <pubDate>Wed, 25 Nov 2020 00:01:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Openstreetmap Foundation: past year changes, their meaning in coming years (2/2)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203902">thread link</a>) | @liotier
<br/>
November 24, 2020 | http://blog.imagico.de/the-osmf-changes-during-the-past-year-and-what-they-mean-for-the-coming-years-part-2/ | <a href="https://web.archive.org/web/*/http://blog.imagico.de/the-osmf-changes-during-the-past-year-and-what-they-mean-for-the-coming-years-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>In <a href="http://blog.imagico.de/the-osmf-changes-during-the-past-year-and-what-they-mean-for-the-coming-years-part-1/">the first part of this blog post</a> i summarized the most important developments in the <a href="https://wiki.osmfoundation.org/wiki/Main_Page">OpenStreetMap Foundation (OSMF)</a> during the past year from my perspective.  In this second part i will – based on the observations from the past year and recent trends being visible – give a lookout on how the OSMF could develop in the coming years.</p>
<p>After <a href="http://blog.imagico.de/osmf-general-meeting-and-board-elections/">my previous piece on the OSMF</a> and the perspective for the upcoming general meeting, <a href="https://www.openstreetmap.org/user/SeverinGeo/diary/394528">Severin Menard has published an interesting and likewise critical take on the current situation of the OSMF</a>.  I agree with most of what he wrote and his culturally somewhat different perspective on things is very valuable.  Definitely recommended for everyone to read.</p>
<p><img src="http://blog.imagico.de/wp-content/uploads/2020/11/osmf-gm2020f.png" alt="" width="512" height="278" srcset="http://blog.imagico.de/wp-content/uploads/2020/11/osmf-gm2020f.png 512w, http://blog.imagico.de/wp-content/uploads/2020/11/osmf-gm2020f-320x174.png 320w" sizes="(max-width: 512px) 100vw, 512px"></p>
<h3>Corporate takeover – it has already happened</h3>
<p>There is one thing however i disagree on with him – the assessment of a corporate takeover as a risk of the future. During the past weeks there have also been <a href="https://lists.openstreetmap.org/pipermail/osmf-talk/2020-October/thread.html#7300">some</a> half baked <a href="https://lists.openstreetmap.org/pipermail/osmf-talk/2020-October/thread.html#7302">initiatives</a> started (last minute before the general meeting as usual) from within the OSMF board towards resolutions meant to protect the OSMF against external takeover.  My view is that these measures and the focus on a defensive strategy against an external attack aimed at controlling the OSMF are meanwhile setting the wrong priorities because the corporate takeover has essentially already happened behind the scenes without that being clearly visible to the outside.</p>
<p>Large corporate OSM data users are not really that interested in staging a coup in the OSMF and run the OSMF themselves at this time.  That would be expensive to do and bear a large spectrum of fairly big risks and also it would – if successfully executed – immediately lead to a struggle for control between the major corporate players.  The main goal of corporate actors with the OSMF is and has been for some time to prevent meaningful regulation of corporate activity in OSM and of OSM data use based on the OdbL.  If that goal is secured, a secondary goal would be for the OSMF to serve as a shared neutral intermediary platform between the different corporations to steer independent volunteer activity in the OSM community in the corporate data users’ collective interests.</p>
<p>The parts of the OSMF board not affiliated with corporate or organized interests seem to have, during the past years, developed the idea that these corporate interests can be negotiated with and that the future of OpenStreetMap lies in compromising between the organized and corporate interests and the core ideas and values of the project.  This quite clearly is an illusion – expecting a big corporation like Facebook to make compromises with an insignificant player like the OSMF is at best naive.</p>
<p>If the goal to prevent meaningful regulation of corporate activity through the OSMF has been accomplished permanently, corporations have no reason to oppose effective takeover prevention of the OSMF – because that would help protecting their position in the OSMF against third parties gaining influence.  And effective prevention of meaningful regulation does not even depend on there being a pro-corporate majority among the OSMF members because the corporations have other significant channels of influence in the OSMF now (through their financial constributions, through their participation in the working groups and through lobbying of the board on non-public channels).</p>
<p>We will in the near future have a fairly good test case for how robust the ability of corporate interests in the OSMF is in preventing meaningful regulation in form of the attribution guideline that has been worked on during the past years.  There are essentially three scenarios of what could happen:</p>
<ul>
<li>The OSMF board decides to adopt a guideline roughly based on <a href="https://wiki.openstreetmap.org/wiki/Draft_Attribution_Guideline">the corporate wishlist from the LWG</a> with some <a href="https://wiki.openstreetmap.org/wiki/Draft_Attribution_Guideline/2020v2">minor adjustments for the optics</a>, to maintain the impression that it is not directly what corporate lobbyists have written.  That seems the most likely scenario at the moment but it bears the strong risk that the craft mapper community will openly oppose this interpretation of the ODbL which would fundamentally endanger the OSMF’s position in the OSM community.</li>
<li>The OSMF board adopts a guideline reflecting the community consensus reading of the ODbL (likely similar to <a href="https://wiki.openstreetmap.org/wiki/Community_attribution_advice">what i drafted</a>) that unconditionally requires attribution that practically makes the user aware of the origin of the data.  That would be strongly against the corporate interests and corporations would certainly do everything within their power to prevent that (including withdrawing funds which would leave the OSMF in financial peril because the strongly increased costs make it depend on regular corporate contributions).</li>
<li>A decision on the matter is avoided by dragging out the process indefinitely.  Although not ideal, because it would be a kind of unstable situation, this would be acceptable for the corporations because it would maintain the status quo of the OSMF not becoming active against data users with insufficient attribution.  It would also avoid an open break with the OSM community, although there would be likely increasing pressure from the OSM community on the OSMF to get active in cases of insufficient attribution by the OSMF’s corporate financial contributors.</li>
</ul>
<p>Some will likely reject my idea that the corporate takeover of the OSMF has already happened.  They will argue that if that was true, corporations would push much more aggressively for their interests.  I don’t think that is the case though.  As explained, the primary interest large corporations have in the OSMF is not positively accomplishing something, it is preventing things negative for their interests from happening.  Accomplishing that is much more valuable for them than anything they could proactively try to push for in the OSMF.</p>
<p>What we will certainly see in the coming years is corporations trying to consolidate their influence on the OSMF, in particular by more and more corporate employees being encouraged to volunteer and being paid for work on the OSMF in the working groups, on the board, in committees and other ways.  This will happen rather quickly in most of the working groups probably, supported by the move of the OSMF to position itself more like a corporate actor which, as i have explained before, is likely going to have a negative effect on motivating volunteers without career interests in OSM for the OSMF.  My estimation is that in 1-2 years a solid majority of the people engaged actively in the OSMF in one way or the other is either employed in some form in an OSM related job or otherwise has a carreer interest at least partly motivating their involvement in the OSMF.  Most of them will be employed by corporate OSM data users or organizations around OSM like HOT.  Currently in the OSMF board for example we have already at least three members to whom this applies, two corporate employees (Mikel and Paul), one small business employee (Rory).</p>
<p><img src="http://blog.imagico.de/wp-content/uploads/2020/11/osmf-gm2020g.png" alt="" width="512" height="278" srcset="http://blog.imagico.de/wp-content/uploads/2020/11/osmf-gm2020g.png 512w, http://blog.imagico.de/wp-content/uploads/2020/11/osmf-gm2020g-320x174.png 320w" sizes="(max-width: 512px) 100vw, 512px"></p>
<h3>Centralization of the OSMF</h3>
<p>The other big upcoming trend in the OSMF i can observe is an increased centralization of power towards the board.  The OSM community overall is highly decentralized and the OSMF has always been kind of an abnormality within that with its hierarchical structure.  But traditionally in the OSMF most of the work has been done in the working groups – including development of policies – and the working groups had a high degree of independence, starting from being created by grassroot initiative from within the community, to allowing also non-OSMF members to participate and to by convention allowing board members to contribute, but not allowing them to have a lead role.  We more recently, however, see a trend towards more and more policy being either actively influenced by the board or being developed by the board itself from the start.  Early manifestations of this trend were the already mentioned Crimea decision (where the board overruled standing policy developed by the working groups) and the organized editing policy (where the board flat out rejected the first draft of the DWG and demanded a more lenient policy).  This year we saw a large number of cases where the board created internal policy, often presenting the results as a done deal without having an open discussion – like in case of the diversity statement – further emphasizing this trend.</p>
<p>In addition, as i have discussed in the first part, we saw during the past year the establishment of several committees (a concept that previously did not exist in the OSMF) – put together by and under direct control of the board.  And for this year’s general meeting <a href="https://wiki.osmfoundation.org/wiki/Board/Minutes/2020-11#2020.2FRes61_That_the_Board_recommends_the_members_vote_Yes_to_change_the_AoA_to_allow_non-board_members_on_committees">we have an AoA change proposed</a> that allows the establishment of committees consisting of board members and OSMF members and to delegate any powers of the OSMF board to these.  In other words:  It would allow the OSMF board to recruit volunteers or paid staff (paid by either the OSMF or by third parties) and delegate any kind of function of the board to them.  Obviously, such committees would be under immediate and absolute control of the board, people could become members of such committees only by appointment by the board and the board could dissolve or remove powers from such a committee at any time.  But, in contrast to the working groups – which don’t have any formal powers and depend for any meaningful decisions on approval by the board – the commitees could be equipped with any of the formal powers and rights the board has within the OSMF.</p>
<p>The effect the establishment of such committees would have is a massive shift in power within the OSMF from the working groups towards the board.  Currently the board is essentially limited in what they can do by their numbers.  Board members are not able to delegate their formal powers to others.  Work requiring more hands can only be done by the working groups, which have a high degree of independence.  If the mentioned resolution passes, the board would essentially no more depend in any way on the working groups of the OSMF – they could assign any tasks so …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.imagico.de/the-osmf-changes-during-the-past-year-and-what-they-mean-for-the-coming-years-part-2/">http://blog.imagico.de/the-osmf-changes-during-the-past-year-and-what-they-mean-for-the-coming-years-part-2/</a></em></p>]]>
            </description>
            <link>http://blog.imagico.de/the-osmf-changes-during-the-past-year-and-what-they-mean-for-the-coming-years-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203902</guid>
            <pubDate>Tue, 24 Nov 2020 22:46:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I made a Loom competitor available directly from a webpage (nothing to install)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203842">thread link</a>) | @Maxmanseau
<br/>
November 24, 2020 | https://hellozest.io/f#/fire | <a href="https://web.archive.org/web/*/https://hellozest.io/f#/fire">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://hellozest.io/f#/fire</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203842</guid>
            <pubDate>Tue, 24 Nov 2020 22:39:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BIT joins OpenNebula's Managed Service Provider (MSP) Program]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203765">thread link</a>) | @amarti
<br/>
November 24, 2020 | https://opennebula.io/bit-joins-opennebula-msp-program/ | <a href="https://web.archive.org/web/*/https://opennebula.io/bit-joins-opennebula-msp-program/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-28713">

    <!-- .entry-header -->

    <div>

		
<p>Managed Service Providers are out to meet the needs of many organizations, and Managed Private Clouds offer a suitable alternative for those looking to reap the benefits of a private cloud environment without the hassle of managing and administering it on their own. And <a href="https://opennebula.io/opennebula-managed-service-provider-partnership/">OpenNebula announced</a> that it is opening the doors to its Solution Provider Partner Program, making way for qualified MSP’s. Our <a href="https://support.opennebula.pro/hc/en-us/articles/115005959343-Solution-Provider-Partner-Program-Guide">Partner Program</a> makes it easy for MSP’s not only to offer private clouds to their customers that are backed by official OpenNebula Systems support, but also having the security and comfort to deploy these clouds with the OpenNebula Enterprise Edition.&nbsp;</p>



<p><a href="https://www.bit.nl/opennebula" target="_blank" rel="noreferrer noopener">BIT</a> has been a long time user of OpenNebula, as well as an avid contributor to its development and evolution over the years. Now, they have joined our Partner Program as an official OpenNebula MSP, offering a comprehensive private cloud service to their customers that reaps the benefits of an OpenNebula subscription and the official backing and support of the OpenNebula Systems team.</p>







<blockquote><p>“<em><em>With OpenNebula’s feature-rich and stable software, along with its extensibility, flexibility, and integration of third-party tools, we have a platform and a partner which allows us to create a dependable platform for BIT and our customers.</em></em>”&nbsp;</p><cite>– Stefan Kooman, System Administrator, BIT</cite></blockquote>







<p>If you are an MSP using OpenNebula, and you would like to ensure that you are equipped to offer the best managed private cloud and support to your customers, reach out to our <a href="mailto:partners@opennebula.io">Partners Manager</a>, and inquire about how you can partner with us as an OpenNebula MSP Solution Provider Partner.&nbsp;&nbsp;</p>
		
		


        <div>
            <p><img alt="" src="https://secure.gravatar.com/avatar/a1737e9efc6920480d8a1abc8d21fd64?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/a1737e9efc6920480d8a1abc8d21fd64?s=192&amp;d=mm&amp;r=g 2x" height="96" width="96">            </p>
            <div>
                <p><span id="autorblog">Michael Abdou</span></p><p>Customer Success Manager at OpenNebula</p>
            </div>
        </div>
	</div><!-- .entry-content -->

</article><!-- #post-## -->

					
<!-- #comments -->

				
			</div></div>]]>
            </description>
            <link>https://opennebula.io/bit-joins-opennebula-msp-program/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203765</guid>
            <pubDate>Tue, 24 Nov 2020 22:30:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Identity and Access Management with Google Cloud]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203692">thread link</a>) | @adrianancona
<br/>
November 24, 2020 | https://ncona.com/2020/11/identity-and-access-management-with-google-cloud/ | <a href="https://web.archive.org/web/*/https://ncona.com/2020/11/identity-and-access-management-with-google-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In this post we’re going to learn how to use Google Cloud IAM (Identity and Access Management) to limit who can manage resources in a Google Cloud account.</p>

<p>If you are interested in AWS IAM, you can check my <a href="https://ncona.com/2020/04/identity-and-access-management-with-aws-iam/">Identity and Access Management with AWS</a> article.</p>

<h2 id="concepts">Concepts</h2>

<ul>
  <li><strong>Member</strong> - An entity that needs to perform an action on a resource. An end user or a service are examples of members</li>
  <li><strong>Identity</strong> - Another name for <strong>Member</strong></li>
  <li><strong>Resource</strong> - A resource is pretty much anything that can be managed in GCP. A compute engine instance or a cloud storage bucket are examples of resources</li>
  <li><strong>Permission</strong> - Allows or denys access to resources. For example: create a storage bucket</li>
  <li><strong>Role</strong> - A collection of permissions. Roles can be granted to <strong>members</strong></li>
  <li><strong>Policy</strong> - Defines who (<strong>member</strong>) can perform which actions (<strong>permissions</strong>) on which <strong>resources</strong></li>
</ul>

<!--more-->

<h2 id="owner">Owner</h2>

<p>When we create a new project, there will be a single <code>Member</code> with the <code>Owner</code> role assigned to it:</p>

<p><a href="https://ncona.com/images/posts/gcp-iam-owner.png"><img src="https://ncona.com/images/posts/gcp-iam-owner.png" alt="GCP IAM owner"></a></p>

<p>This is the person that created the Google Cloud account and has complete domain over it. A project must have at least one owner.</p>

<h2 id="service-accounts">Service accounts</h2>

<p>Service accounts are a way to allow software to do things in Google Cloud. Some examples of software that wants to do something in Google Cloud are:</p>

<ul>
  <li><a href="https://ncona.com/2020/09/introduction-to-google-cloud-cli/">Google Cloud CLI</a></li>
  <li>A build system that publishes docker images to container registry</li>
  <li>A program that stores photos in storage buckets</li>
</ul>

<p>Depending on what the software needs to do, we should assign a role with only the necessary permissions to do what it needs.</p>

<p>Service accounts are created from the <a href="https://console.cloud.google.com/identity/serviceaccounts">Identity -&gt; Service Accounts section</a> on the cloud console.</p>

<p>Since we’re going to be using <code>gcloud</code> for the rest of the article, take a look at my <a href="https://ncona.com/2020/09/introduction-to-google-cloud-cli/">introduction to Google Cloud CLI</a> for how to configure it. Notice that this role is all powerful, so it should be only used by the owner of the account.</p>

<p>Once we have <code>gcloud</code> configured, we can see all the service accounts:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>gcloud iam service-accounts list
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To create a new service account:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>gcloud iam service-accounts create &lt;NAME&gt; <span>\</span>
    <span>--description</span><span>=</span><span>"&lt;DESCRIPTION&gt;"</span> <span>\</span>
    <span>--display-name</span><span>=</span><span>"&lt;NAME&gt;"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To delete a service account:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>gcloud iam service-accounts delete &lt;SERVICE ACCOUNT&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="members">Members</h2>

<p>Gcloud’s interface is not the prettiest, so if we want to get information about the members we have to use this command:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>gcloud projects get-iam-policy &lt;PROJECT&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The output will show all members (including service accounts) and all the roles associated with them.</p>

<p>In the previous section we saw how to add service accounts. Other types of members are:</p>

<ul>
  <li>Google account</li>
  <li>Google group</li>
  <li>Google Workspace</li>
  <li>Cloud Identity</li>
</ul>

<p>I’m not going to explain these in detail.</p>

<p>A Google account is any account that was opened on Google (e.g. myname@gmail.com). We can add a google account as a member of our project using this command:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>gcloud projects add-iam-policy-binding &lt;PROJECT&gt; <span>\</span>
    <span>--member</span><span>=</span>user:&lt;USER EMAIL&gt; <span>\</span>
    <span>--role</span><span>=</span>&lt;ROLE&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>I’ll talk more about the possible values for <code>ROLE</code> later in this article</p>

<h2 id="roles">Roles</h2>

<p>Roles are a way to group permissions so they can easily be assigned to members. There are a lot of roles provided by default by Google (e.g. Editor), but it’s better to create our own roles so we grant the least amount of permissions to each member.</p>

<p>We can see all the roles in our project with:</p>



<p>This command shows the roles’ names and descriptions, but it doesn’t show which permissions are assigned to the role. To see the permissions assigned to a role, we can use:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>gcloud iam roles describe &lt;ROLE&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>For example:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td><pre><span>$ </span>gcloud iam roles describe roles/workflows.viewer
description: Read-only access to workflows and related resources.
etag: <span>AA</span><span>==</span>
includedPermissions:
- resourcemanager.projects.get
- resourcemanager.projects.list
- workflows.executions.get
- workflows.executions.list
- workflows.locations.get
- workflows.locations.list
- workflows.operations.get
- workflows.operations.list
- workflows.workflows.get
- workflows.workflows.getIamPolicy
- workflows.workflows.list
name: roles/workflows.viewer
stage: BETA
title: Workflows Viewer
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Getting the list of all the permissions that exist (and can be assigned to a role) is not easy. The best way I know to find which permissions I need to assign to a role is by asking google. There is a <a href="https://cloud.google.com/iam/docs/permissions-reference">permissions reference</a>, but it’s pretty hard to navigate.</p>

<p>We can create our own role with this command:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>gcloud iam roles create &lt;ROLE ID&gt; <span>\</span>
    <span>--project</span><span>=</span><span>"&lt;PROJECT&gt;"</span> <span>\</span>
    <span>--description</span><span>=</span><span>"&lt;DESCRIPTION&gt;"</span> <span>\</span>
    <span>--permissions</span><span>=</span><span>"&lt;PERMISSIONS&gt;"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>For example:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>gcloud iam roles create MyTestRole <span>\</span>
    <span>--project</span><span>=</span>golden-frame-295509 <span>\</span>
    <span>--description</span><span>=</span><span>"Created this role because I wanted to"</span> <span>\</span>
    <span>--permissions</span><span>=</span><span>"workflows.operations.list,workflows.operations.get"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We can modify a role we created. To remove permissions:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>gcloud iam roles create &lt;ROLE ID&gt; <span>\</span>
    <span>--project</span><span>=</span><span>"&lt;PROJECT&gt;"</span> <span>\</span>
    <span>--description</span><span>=</span><span>"&lt;DESCRIPTION&gt;"</span> <span>\</span>
    <span>--remove-permissions</span><span>=</span><span>"&lt;PERMISSIONS&gt;"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To add permisions:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>gcloud iam roles create &lt;ROLE ID&gt; <span>\</span>
    <span>--project</span><span>=</span><span>"&lt;PROJECT&gt;"</span> <span>\</span>
    <span>--description</span><span>=</span><span>"&lt;DESCRIPTION&gt;"</span> <span>\</span>
    <span>--add-permissions</span><span>=</span><span>"&lt;PERMISSIONS&gt;"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Now that we know how to create <code>members</code> and <code>roles</code>, we can learn how to manage them.</p>

<p>We add a <code>role</code> to a service account by attaching a policy binding:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>gcloud projects add-iam-policy-binding &lt;PROJECT&gt; <span>\</span>
    <span>--member</span> serviceAccount:&lt;SERVICE ACCOUNT&gt; <span>\</span>
    <span>--role</span> &lt;ROLE&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To remove a role:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>gcloud projects remove-iam-policy-binding &lt;PROJECT&gt; <span>\</span>
    <span>--member</span> serviceAccount:&lt;SERVICE ACCOUNT&gt; <span>\</span>
    <span>--role</span> &lt;ROLE&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To see all the roles assigned to a member:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>gcloud projects get-iam-policy &lt;PROJECT&gt;  <span>\</span>
    <span>--flatten</span><span>=</span><span>"bindings[].members"</span> <span>\</span>
    <span>--format</span><span>=</span><span>'table(bindings.role)'</span> <span>\</span>
    <span>--filter</span><span>=</span><span>"bindings.members:&lt;SERVICE ACCOUNT&gt;"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Now we have all we need to create members and attach the correct roles to those members.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I’m not and expert in Identity and Access Management, but I was surprised by how hard it was to get the commands right with gcloud. The way <code>gcloud</code> commands are organized makes it really difficult to use the help to discover how to achieve something. I had to do multiple Google searches to find how to do some things.</p>

<p>The concepts of organization and project can also be tricky. In all the examples above, we created resources at the project level, but it’s also possible to create resources at the organization level, which might make navigation confusing.</p>

  </div></div>]]>
            </description>
            <link>https://ncona.com/2020/11/identity-and-access-management-with-google-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203692</guid>
            <pubDate>Tue, 24 Nov 2020 22:23:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vim Sessions]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203660">thread link</a>) | @RMPR
<br/>
November 24, 2020 | https://rmpr.xyz/Vim-Session/ | <a href="https://web.archive.org/web/*/https://rmpr.xyz/Vim-Session/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Even though I prefer to use one buffer at a time to be more focused. I sometimes needed to have multiple buffers 
open in splits (Terminal, Netrw, …). And when for whatever reason, I needed to close them or shutdown my computer. I didn’t like loosing my context. Enter Vim sessions.</p>

<p>They are quite simple, if you want to save your layout as it is, just type <code>:mksession</code>  or for short <code>:mks</code> 
(yay! 6 strokes saved) and a file named Session.vim will be created. All you have to do the next time you open 
your project folder is <code>vim -S</code>.</p>

<p>P.S.</p>
<ul>
  <li>If there’s already a session file you will need to append ! at the end of the command to overwrite</li>
  <li>You can eventually specify the session filename, for more info <code>:help :mks</code></li>
</ul>

<p>In almost one year of Vim usage, I always wanted to do this, but somehow tutorials address mostly plugins installation and usage. No, I want the real, rough Vim, please.</p>

<p><a href="https://www.youtube.com/watch?v=jPPozzOCyIw"><img src="https://rmpr.xyz/images/sessions.gif" alt="Vim sessions"></a></p>


  </div></div>]]>
            </description>
            <link>https://rmpr.xyz/Vim-Session/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203660</guid>
            <pubDate>Tue, 24 Nov 2020 22:19:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build a Production Grade Workflow with SQL Modelling]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203365">thread link</a>) | @oedmarap
<br/>
November 24, 2020 | https://shopify.engineering/build-production-grade-workflow-sql-modelling | <a href="https://web.archive.org/web/*/https://shopify.engineering/build-production-grade-workflow-sql-modelling">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p><strong>By Michelle Ark and Chris Wu</strong></p>
<p>In January of 2014, Shopify built a data pipeline platform for the data science team called Starscream. Back then, we were a smaller team and needed a tool that could deal with everything from ad hoc explorations to machine learning models. We chose to build with PySpark to get the power of a generalized distributed computer platform, the backing of the industry standard, and the ability to tap into the Python talent market.&nbsp;</p>
<p>Fast forward six years and our data needs have changed. Starscream now runs 76,000 jobs and writes 300 terabytes a day! As we grew, some types of work went away, but others (like simple reports) became so commonplace we do them every day. While our Python tool based on PySpark was computationally powerful, it wasn’t optimized for these commonplace tasks. If a product manager needed a simple rollup for a new feature by country, pulling it, and modeling it wasn’t a fast task.</p>
<p>We’ll show you how we moved to a SQL modelling workflow by leveraging <a href="https://www.getdbt.com/" target="_blank" title="Analytics engineering is the data transformation work that happens between loading data into your warehouse and analyzing it. dbt allows anyone comfortable with SQL to own that workflow." rel="nofollow noopener noreferrer">dbt</a> (data build tool) and created tooling for testing and documentation on top of it. All together, these features provide Shopify’s data scientists with a robust, production-ready workflow to quickly build straightforward pipelines.</p>

<p>When we interviewed our users to understand their workflow on Starscream, there were two issues we discovered: <em>development time</em> and <em>thinking</em>.</p>
<p><em>Development time</em> encompasses the time data scientists use to prototype the data model they’d like to build, run it, see the outcome,and iterate. The PySpark platform isn’t ideal for running straightforward reporting tasks, often forcing data scientists to write boilerplate and it yields long runtimes. This led to long iteration cycles when trying to build models on unfamiliar data.</p>
<p>The second issue, <em>thinking</em>, is more subtle and deals with the way the programming language forces you to look at the data. Many of our data scientists prefer SQL to python because its structure forces consistency in business metrics. When interviewing users, we found a majority would write out a query in SQL then translate it to Python when prototyping. Unfortunately, query translation is time consuming and doesn’t add value to the pipeline.</p>
<p>To understand how widespread these problems were, we audited the jobs run and surveyed our data science team for the use cases. We found that 70% or so of the PySpark jobs on Starscream were full batch queries that didn’t require generalized computing. We viewed this as an opportunity to make a kickass optimization for a painful workflow.&nbsp;</p>

<p>Our goal was to create a SQL pipeline for reporting that enables data scientists to create simple reporting data faster, while still being production ready. After exploring a few alternatives, we felt that the dbt library came closest to our needs. Their tagline “deploy analytics code faster with software engineering practices” was <em>exactly</em> what we were looking for in a workflow. We opted to pair it with Google BigQuery as our data store and dubbed the system and its tools, Seamster.</p>
<p>We knew that any off-the-shelf system wouldn’t be one size fits all. In moving to dbt, we had to implement our own:</p>
<ul>
<li>source and model structure to modularize data model development</li>
<li>unit testing to increase the types of testable errors</li>
<li>continuous integration (CI) pipelines to provide safety and consistency guarantees.</li>
</ul>
<h2>Source Independence and Safety</h2>
<p>With dozens of data scientists making data models in a shared repository, a great user experience would</p>
<ul>
<li>maximize focus on work&nbsp;</li>
<li>minimize the impact of model changes by other data scientists.</li>
</ul>
<p>By default, dbt declares raw sources in a central <code>sources.yml</code>. This quickly became a very large file as it included the schema for each source, in addition to the source name. It creates a huge bottleneck for teams editing the same file across multiple PRs.&nbsp;</p>

<p>To mitigate the bottleneck, we leveraged the flexibility of dbt and created a top-level ‘sources’ directory to represent each raw source with its own source-formatted yaml file. This way, data scientists can parse only the source documentation that’s relevant for them and contribute to the <code>sources.yml</code> file without stepping on each other’s toes.</p>

<p><em>Base models are one-to-one interfaces to raw sources.</em></p>
<p>We also created a Base layer of models using the <a href="https://discourse.getdbt.com/t/how-we-structure-our-dbt-projects/355" target="_blank" rel="nofollow noopener noreferrer">‘</a><a href="https://discourse.getdbt.com/t/how-we-structure-our-dbt-projects/355" target="_blank" title="How we structure our dbt projects" rel="nofollow noopener noreferrer">staging’ concept from dbt</a> to implement their best practice of <a href="https://docs.getdbt.com/docs/guides/best-practices/#limit-references-to-raw-data" target="_blank" title="Limit references to raw data - dbt" rel="nofollow noopener noreferrer">limiting references to raw data</a>. Our Base models serve as a one-to-one interface to raw sources. They don’t change the grain of the raw source, but do apply renaming, recasting, or any other cleaning operation that relates to the source data collection system.&nbsp;</p>
<p>The Base layer serves to protect users from breaking changes in raw sources. Raw external sources are by definition out of the control of Seamster and can introduce breaking changes for any number of reasons at any point in time. If and when this happens, you only need to apply the fix to the Base model representing the raw source, as opposed to every individual downstream model that depends on the raw source.&nbsp;</p>
<h2>Model Ownership for Teams</h2>
<p>We knew that the tooling improvements of Seamster would be only one part of a greater data platform at Shopify. We wanted to make sure we’re providing mechanisms to support good dimensional modelling practices and support data discovery.</p>
<p>In dbt, a model is simply a .sql file. We’ve extended this definition in Seamster to define a model as a directory consisting of four files:&nbsp;</p>
<ul>
<li><code>model_name.sql</code></li>
<li><code>schema.yml</code></li>
<li><code>README.md</code></li>
<li><code>test_model_name.py</code></li>
</ul>
<p>You can further organize models into directories that indicate a data science team at Shopify like ‘finance’ or ‘marketing’.&nbsp;</p>
<p>To support a clean data warehouse we’ve also organized data models into these rough layers that differentiate between:</p>
<ul>
<li>
<strong>base</strong>: data models that are one-to-one with raw data, but cleaned, recast and renamed</li>
<li>
<strong>application-ready</strong>: data that isn’t dimensionally modelled but still transformed and clean for consumption by another tool (for example,&nbsp; training data for a machine learning algorithm)</li>
<li>
<strong>presentation</strong>: shareable and reliable data models that follow dimensional modelling best practices and can be used by data scientists across different domains.</li>
</ul>
<p>With these two changes, a data consumer can quickly understand the data quality they can expect from a model and find the owner in case there is an issue. We also pass this metadata upstream to <a href="https://shopify.engineering/solving-data-discovery-challenges-shopify" target="_blank" title="How We’re Solving Data Discovery Challenges at Shopify" rel="nofollow noopener noreferrer">other tools</a> to help with the data discovery workflow.</p>
<h2>More Tests</h2>
<p>dbt has native support for ‘schema tests’, which are encoded in a model’s schema.yml file. These tests run against production data to validate data invariants, such as the presence of null values or the uniqueness of a particular key. This feature in dbt serves its purpose well, but we also want to enable data scientists to write unit tests for models that run against fixed input data (as opposed to production data).</p>
<p>Testing on fixed inputs allows the user to test edge cases that may not be in production yet. In larger organizations, there can and will be frequent updates and many collaborators for a single model. Unit tests give users confidence that the changes they’re making won’t break existing behaviour or introduce regressions.&nbsp;</p>
<p>Seamster provides a Python-based unit testing framework. Data scientists write their unit tests in the <code>test_model_name.py</code> file in the model directory. The framework enables constructing ‘mock’ input models from fixed data. The central object in this framework is a ‘mock’ data model, which has an underlying representation of a Pandas dataframe. You can pass fixed data to the mock constructor as either a csv-style string, Pandas dataframe, or a list of dictionaries to specify input data.&nbsp;</p>
<p><img alt="Input and expected MockModels are built from static data. The actual MockModel is built from input MockModels by BigQuery. Actual and expected MockModels can assert equality or any Great Expectations expectation" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/input-expected-mock-models.jpg?v=1605811967" src="https://cdn.shopify.com/s/files/1/0779/4361/files/input-expected-mock-models.jpg?v=1605811967"><br><em>Input and expected MockModels are built from static data. The actual MockModel is built from input MockModels by BigQuery. Actual and expected MockModels can assert equality or any Great Expectations expectation.</em></p>
<p>A constructor creates a test query where a common table expression (CTE) represents each input mock data model, and any references to production models (identified using dbt’s ‘ref’ macro) are replaced by references to the corresponding CTE. Once you execute a query, you can compare the output to an expected result. In addition to an equality assertion, we extended our framework to support all expectations from the open-source <a href="https://github.com/great-expectations/great_expectations" target="_blank" title="Great Expectations - Always know what to expect from your data." rel="nofollow noopener noreferrer">Great Expectations</a> library to provide more granular assertions and error messaging.&nbsp;</p>
<p>The main downside to this framework is that it requires a roundtrip to the query engine to construct the test data model given a set of inputs. Even though the query itself is lightweight and processes only a handful of rows, these roundtrips to the engine add up. It becomes costly to run an entire test suite on each local or CI run. To solve this, we introduced tooling both in development and CI to run the minimal set of tests that could potentially break given the change. This was straightforward to implement with accuracy because of dbt’s lineage tracking support; we simply had to find all downstream models (direct and indirect) for each changed model and run their tests.&nbsp;</p>
<h2>Schema and Directed Acyclic Graph Validation on the Cheap</h2>
<p>Our objective in Seamster’s CI is to give data scientists peace of mind that their changes won’t introduce production errors the next time the warehouse is built. They shouldn’t have to wonder whether removing a column will cause downstream dependencies to break, or whether they made a small typo in their SQL model definition.</p>
<p>To achieve this accurately, we would need to build and tear down the entire warehouse on every commit. This isn’t feasible from both a time and cost perspective. Instead, on every commit we materialize every model as a view in a temporary BigQuery dataset which is created at the start of the validation process and removed as soon as the validation finishes. If we can’t build a view because its upstream model doesn’t provide a certain column, or if the SQL is invalid for any reason, BigQuery fails to build the view and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/build-production-grade-workflow-sql-modelling">https://shopify.engineering/build-production-grade-workflow-sql-modelling</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/build-production-grade-workflow-sql-modelling</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203365</guid>
            <pubDate>Tue, 24 Nov 2020 21:52:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Conducto – Use Python to write, run, view and debug DevOps pipelines]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25203326">thread link</a>) | @jonsolo
<br/>
November 24, 2020 | https://www.conducto.com/app/sandbox/github/conducto/examples?dir=cicd%2Fflask_microservice&preview_file=pipeline.py | <a href="https://web.archive.org/web/*/https://www.conducto.com/app/sandbox/github/conducto/examples?dir=cicd%2Fflask_microservice&preview_file=pipeline.py">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.conducto.com/app/sandbox/github/conducto/examples?dir=cicd%2Fflask_microservice&amp;preview_file=pipeline.py</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203326</guid>
            <pubDate>Tue, 24 Nov 2020 21:48:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pam Bypass: when null(is not)ok]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203265">thread link</a>) | @Foxboron
<br/>
November 24, 2020 | https://linderud.dev/blog/pam-bypass-when-nullis-notok/ | <a href="https://web.archive.org/web/*/https://linderud.dev/blog/pam-bypass-when-nullis-notok/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <h2 id="the-problem">The Problem</h2>
<p>Someone enters an IRC support channel and proclaims their dovecot server has
been hacked and a non existing user sends spam email from their server. The
initial reaction might be something along the lines of</p>
<p><strong>Wat ಠ_ಠ</strong></p>
<p>With the following assumption that the user <em>clearly</em> did something wrong.
Hosting email is difficult after all. I don’t quite recall how rest of the
support went, but it was solved and the root cause was not found. However, we
keep on rolling! Then someone posts about a similar incident on <a href="https://www.reddit.com/r/archlinux/comments/jvh38a/postfix_dovecot_got_hacked/">r/archlinux</a>.</p>
<p>Now, if this happens twice something is amiss! Arch has had a few issues with
PAM lately, thus it could be that there is a configuration issue.  Johannes and
I try to reproduce, but I don’t get far and Johannes keeps on working on the
issue.</p>
<h2 id="the-setup">The Setup</h2>
<p>The first thing you notice looking into the <a href="https://github.com/archlinux/svntogit-packages/blob/packages/pambase/trunk/system-auth"><code>/etc/pamd.d/system-auth</code></a>
of Arch Linux is the following lines:</p>
<pre><code data-lang="pam">auth  [success=2 default=ignore]  pam_unix.so   try_first_pass nullok
							       ^^^^^^</code></pre>
<p>This allows a user with a blank password to go forward with the PAM
authentication. As the <a href="https://linux.die.net/man/8/pam_unix">manpage</a> explains;</p>
<blockquote>
<p>The default action of this module is to not permit the user access to a service if their official password is blank. The <strong>nullok</strong> argument overrides this default.</p>
</blockquote>
<p>The second relevant line is the inclusion of <a href="https://linux.die.net/man/8/pam_permit">pam_permit.so</a> which indiscriminately
allows anyone reaching this far access to the system. Clearly a must have for
any well functioning system regardless of being “very dangerous” and “used with
extreme caution” 🙄.</p>
<p>Now, keep all of this in mind as we continue.</p>
<p>The first hint towards the culprit of the issue is when the author of the reddit
posts submits an email to <a href="mailto:security@archlinux.org">security@archlinux.org</a>:</p>
<blockquote>
<p>Back in May 2020 there was a change to root account in shadow file such that root with no password was no longer supported.</p>
<p>During patching this created a file /etc/shadow.pacnew</p>
<p>If that pacnew was not merged to the shadow file this will result in pam allowing any invalid account to successfully auth with no password.</p>
<p>The problem is that if the * is missing from the root line in the shadow file then the most recent pam system-auth config will allow auth bypass.</p>
<p>This impacted me when my mail server (dovecot/postfix) got breached via a “no password” and sent significant spam.</p>
</blockquote>
<p>The change which is mentioned is the following change to the <code>filesystem</code>
package in the file <a href="https://github.com/archlinux/svntogit-packages/commit/0320c909f3867d47576083e853543bab1705185b#diff-3e341d2d9c67be01819b25b25d5e53ea3cdf3a38d28846cda85a195eb9b7203a"><code>/etc/shadow</code></a></p>
<div><pre><code data-lang="diff"><span>-root::14871::::::
</span><span></span><span>+root:*:14871::::::
</span></code></pre></div>
<p>This is something most shadow configurations in Linux distributions carry these
days. Through a bit of oversight the root account of any Arch installation has
no root password set, thus you need to set one yourself or else you can swap tty
and log into the root user. Now this hole was fixed.</p>
<p>Since this file was changed <code>pacman</code> is going to see that the local file has
modification (you probably have more users on your system!) and stuff this
change into <code>/etc/shadow.pacnew</code> as noted in the <a href="https://www.archlinux.org/pacman/pacman.8.html#_handling_config_files_a_id_hcf_a">manpage</a>.  This is also part of the <code>pacman</code> output, but I guess you can see how it’s easy
to miss when you run a server with a few hundred packages to update.</p>
<div><pre><code data-lang="text">[root@archlinux ~]# pacman -S filesystem
resolving dependencies...
looking for conflicting packages...

Packages (1) filesystem-2020.09.03-1

Total Installed Size:   0.03 MiB
Net Upgrade Size:      -0.01 MiB

:: Proceed with installation? [Y/n] 
(1/1) checking keys in keyring                         [###############] 100%
(1/1) checking package integrity                       [###############] 100%
(1/1) loading package files                            [###############] 100%
(1/1) checking for file conflicts                      [###############] 100%
(1/1) checking available disk space                    [###############] 100%
:: Processing package changes.
(1/1) upgrading filesystem                             [###############] 100%
warning: /etc/shadow installed as /etc/shadow.pacnew
:: Running post-transaction hooks...
(1/4) Creating system user accounts...
(2/4) Applying kernel sysctl settings...
(3/4) Creating temporary files...
(4/4) Arming ConditionNeedsUpdate...</code></pre></div>
<p>Usually people install <code>pacdiff</code> from <code>pacman-contrib</code> to deal with these
issues, as they are made a bit more explicit.</p>
<div><pre><code data-lang="text">[root@archlinux ~]# pacdiff 
==&gt; pacnew file found for /etc/shadow
:: (V)iew, (S)kip, (R)emove pacnew, (O)verwrite with pacnew, (Q)uit:</code></pre></div>
<p>This is the setup of the issue. The shadow file was updated, and the users did
not merge the change. The root account is without any password!</p>
<p>But how does this lead to an authentication bypass in PAM for <em>invalid</em> users?
This only applies for root after all.</p>
<h2 id="the-vulnerability">The Vulnerability</h2>
<p>Levente Polyak theorized that these invalid users clearly was returning
something valid for <code>pam_unix.so</code>. How else would they continue to authenticate?
Johannes spelunks through code, looking for the code path that would allow
invalid users to authenticate.</p>
<pre><code data-lang="pam">  demize  : I think it might be because of some changes they did to try to 
	    make the password checking for existing and non-existing users 
	    take the same amount of time.
  demize  : On the first iteration it'll try to get the password hash for the 
	    user. It doesn't exist, so it tries against against root, and 
	    since root did have a null password...
anthraxx  : yeah that would explain why it passes with nullok for non existing 
	    users
anthraxx  : that patch itself makes perfect sense to mitigate side channels</code></pre>
<p>The patch in question is the commit <a href="https://github.com/linux-pam/linux-pam/commit/af0faf666c5008e54dfe43684f210e3581ff1bca"><code>pam_unix: avoid determining if user exists</code></a>.</p>
<p>The commit attempts to avoid a timing attack against PAM. Some attacker can know
valid user names by timing how quickly PAM returns an error, so the fix is to
use an existing user in the system we always validate against to ensure a
consistent timing. But which user is always present on a Linux system? root!</p>
<p>The code does <em>not</em> check if root has any valid passwords set. An invalid user
would fail, loop over to root and try validate. root has no password. It’s
blank. We have <code>nullok</code> set. And we have <code>pam_permit.so</code>. The invalid user is
authenticated. We have enough information to do a quick POC.</p>
<h2 id="the-poc">The POC</h2>
<div><pre><code data-lang="text">[root@archlinux ~]# pacman -Q pam dovecot
pam 1.5.0-1
dovecot 2.3.11.3-2

[root@archlinux ~]# cat /etc/shadow
root:*:14871::::::

[root@archlinux ~]# doveadm auth test something
Password: 
passdb: something auth failed
extra fields:
  user=something
  
[root@archlinux ~]# sed -i 's/root:\*/root:/' /etc/shadow

[root@archlinux ~]# cat /etc/shadow
root::14871::::::

[root@archlinux ~]# doveadm auth test something
Password: 
passdb: something auth succeeded
extra fields:
  user=something
  
[root@archlinux ~]# doveadm auth test this-user-is-invalid
Password: 
passdb: this-user-is-invalid auth succeeded
extra fields:
  user=this-user-is-invalid</code></pre></div>
<p>This is clearly unfortunate for people that rely on PAM authentication for
their systems, and a good lecture as to why you probably shouldn’t use PAM for
this. Also some material for people that strongly believe Arch is not suitable
for servers. Win-win!</p>
<p>As of taping, the PAM package has been patched in Arch and currently going
through some testing. Luckily it’s a compound issue that needs a few things to
go wrong over quite a few months before it amounts to an exploit.</p>
<p><!-- raw HTML omitted -->The vulnerability has been assigned
CVE-2020-27780, and the fixed commit checks if root has a valid password
set.<!-- raw HTML omitted --></p>
<p><a href="https://github.com/linux-pam/linux-pam/commit/30fdfb90d9864bcc254a62760aaa149d373fd4eb"><code>Second blank check with root for non-existent users must never return 1</code></a></p>
<p>Thanks to Johannes Löthberg, Santiago Torres and Levente Polyak for reading over
the draft!</p>

                
                <p><a href="https://linderud.dev/blog/">Back to posts</a></p>
            </div></div>]]>
            </description>
            <link>https://linderud.dev/blog/pam-bypass-when-nullis-notok/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203265</guid>
            <pubDate>Tue, 24 Nov 2020 21:39:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US internet speeds 91% faster in 2020 according to user speed tests]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 203 (<a href="https://news.ycombinator.com/item?id=25203256">thread link</a>) | @mootothemax
<br/>
November 24, 2020 | https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis | <a href="https://web.archive.org/web/*/https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><ul><li>US broadband speeds <strong>increased 91%</strong> from 2019-2020, <strong>nearly doubling</strong> YoY, as measured by annual speed test medians</li><li>US average broadband speeds overtook western EU countries like the UK, France, and Germany for the first time in 5 years</li><li>Broadband speeds in the EU overall rose 57% from 2019–2020, 34% lower than the 91% performance increase in the US</li></ul><p>American internet users have had a very good 2020: according to research performed by FairInternetReport, median US internet speeds in 2020 doubled to 33.16mbps, up from 17.34mbps in 2019. Covering the five years of 2016, 2017, 2018, 2019, and 2020, this is the largest speed increase seen in the US, with speeds staying essentially the same in 2016 and 2017 (8.91mbps and 9.08mbps respectively), and 2018 recording a median speed of 12.83mbps.</p><p>The US stills lags behind many European and developed nations worldwide, and its major cities also often lag behind their European equivalents. That said, there is cause for celebration in Dallas, Seattle and Austin, after our analysis has shown that these cities are performing extremely well relative to most European capital cities.</p></div></div></div>]]>
            </description>
            <link>https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203256</guid>
            <pubDate>Tue, 24 Nov 2020 21:38:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Man linked to missing Bitfinex/Tether funds hoodwinks defense team]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203155">thread link</a>) | @amycastor
<br/>
November 24, 2020 | https://amycastor.com/2020/11/24/reggie-fowler-hoodwinks-his-own-defense-team/ | <a href="https://web.archive.org/web/*/https://amycastor.com/2020/11/24/reggie-fowler-hoodwinks-his-own-defense-team/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4829">
			<!-- .entry-header -->
		<div>
		
<div><figure><a href="https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg"><img loading="lazy" data-attachment-id="4835" data-permalink="https://amycastor.com/con-man/" data-orig-file="https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg" data-orig-size="700,700" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="con-man" data-image-description="" data-medium-file="https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg?w=300" data-large-file="https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg?w=700" src="https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg?w=700" alt="" width="275" height="275" srcset="https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg?w=275 275w, https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg?w=550 550w, https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg?w=150 150w, https://amyhcastor.files.wordpress.com/2020/11/con-man.jpg?w=300 300w" sizes="(max-width: 275px) 100vw, 275px"></a></figure></div>



<p>Reginald Fowler, the Arizona businessman tied to hundreds of millions of dollars of Tether and Bitfinex’s missing money, appears to have conned his own defense team.&nbsp;</p>



<p>As I explained in a <a href="https://amycastor.com/2020/11/13/confirmed-reginald-fowler-cant-pay-his-lawyers/">previous post</a>, Fowler’s lawyers are seeking to withdraw from his case due to nonpayment. (The US government is accusing Fowler of operating a shadow banking operation for cryptocurrency exchanges.) But the details are privileged and confidential, so the judge overseeing the case agreed to allow them to file an ex parte sealed letter.</p>



<p>Judge Andrew Carter has now received the letter—from Hogan Lovells on behalf of itself and Rosenblum Schwartz—reviewed it, and filed a response.&nbsp;As I had suspected, Fowler appears to have hoodwinked his own defense team. Here is the eight-page <a href="https://amyhcastor.files.wordpress.com/2020/11/opinion-and-order.pdf">opinion and order</a>. </p>



<p>“Money isn’t everything,” the SDNY district judge writes. “But in this case, <em>it is the only thing.”&nbsp;</em>[Emphasis mine.]</p>



<p>According to Carter, Fowler’s jilted defense team recounted several conversations with their client in which Fowler promises to pay, but does not, effectively stringing them along. </p>



<p>“Mr. Fowler assured his attorneys he could pay, referring to planned business transactions, real property and bank accounts,” the judge said. </p>



<p>The defense counsel apparently understood that many of Fowler’s assets were frozen, but the hope was that Fowler could unfreeze certain assets by demonstrating that the assets had no connection to case. </p>



<p>However, during the time Fowler’s lawyers had been pressing him for payment and Fowler telling them he did not have the available funds, the lawyers learned that Fowler had plenty to pay his other lawyers—a large international law firm (name withheld) and an unnamed lawyer.</p>



<p>I’m not sure what exactly this means (a tip-off that Fowler had funds hidden away somewhere?) but Carter said: “The anonymous lawyer gave defense lawyer advice regarding Fowler’s ability to pay legal fees from funds that might not be related to criminal activity.”  </p>



<p>So why did Fowler’s lawyers wait this long before asking the court if they could dump their client when the troubles with getting paid started back in February? </p>



<p>According to Carter’s retelling, they thought the case would have been resolved with a guilty plea in January. However, the plea bargain blew up when Fowler learned it would require him to forfeit $371 million. </p>



<p>Recall that after that, federal prosecutors responded with a superseding indictment that added a fifth charge, which would have required a lot of additional (unpaid) work from the defense team. </p>



<p>Fowler’s defense team “decided they would continue representing him even though they had been owed a great deal of money for several months,” Carter said. “But largess shrinks when confronted by the prospect of additional, unpaid hours dedicated to trial preparation.” </p>



<h2>What next?</h2>



<p>There is still the issue of whether Fowler’s defense team should be allowed to withdraw from the case. But federal prosecutors needs to know more about their reasons for seeking withdrawal, so they can respond. </p>



<p>Some information in Hogan Lovells’ sealed ex parte needs to be made public and some needs to remain sealed, Carter said. Certain information about Fowler’s assets should remain sealed. Any information about plea negotiations needs to remain sealed as well. </p>



<p>However, details about the amount and timing of Fowler’s payments to the defense counsel is “highly relevant and should be made public.”</p>



<p>The name of the large international law firm should also be made public, Carter said, stating that “the size and nature of the firm is relevant to the fact that Mr. Fowler paid something to that firm—but did not fully pay Hogan and Rosenblum—and whether Hogan’s and Rosenblum’s acceptance of relatively low retainers was reasonable.”</p>



<p>Low retainers? This may be a sticky point, and something federal prosecutors make a big issue with in their next response. </p>



<p>The judge ordered Fowler’s defense team to file three versions of their letter—a public version redacting what should not be revealed to the government or the public; a sealed version, redacting what must not be disclosed to the government; and a third ex parte sealed version with no redactions. </p>



<p>All filings need to be completed by Dec. 1; the government has until Dec. 8 to respond. Replies are due by Dec. 11.</p>



<p><em>Nov. 24: Updated to clarify a few details, like what Fowler is being accused of and to emphasize that the retainer issue will likely come up again in the government’s response.</em></p>



<p><em>If you like my writing, please consider supporting my work by subscribing to my <a href="https://www.patreon.com/amycastor">Patreon account</a> for as little as $5 a month.</em></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://amycastor.com/2020/11/24/reggie-fowler-hoodwinks-his-own-defense-team/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203155</guid>
            <pubDate>Tue, 24 Nov 2020 21:24:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A 10x better way to manage your job search]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203150">thread link</a>) | @jacobdpeters
<br/>
November 24, 2020 | https://www.tealhq.com/job-tracker | <a href="https://web.archive.org/web/*/https://www.tealhq.com/job-tracker">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="w-node-c72cce9215f1-2656f85e"><div><h2>Save any job listing <br>on the internet.</h2><p>Teal's Chrome Extension will scrape job descriptions from all the most popular listing sites — from LinkedIn to Glassdoor. If it doesn’t recognize a site, you can also add the job posting manually.<br></p></div></div></div>]]>
            </description>
            <link>https://www.tealhq.com/job-tracker</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203150</guid>
            <pubDate>Tue, 24 Nov 2020 21:24:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to easily set up Docker-compose for wordpress/PHP/MySQL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203009">thread link</a>) | @webdevetc
<br/>
November 24, 2020 | https://webdevetc.com/programming-tricks/wordpress/tips/wordpress-docker-docker-composeyml-guided-tutorial/ | <a href="https://web.archive.org/web/*/https://webdevetc.com/programming-tricks/wordpress/tips/wordpress-docker-docker-composeyml-guided-tutorial/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page"><section id="main-content" tabindex="-1"><div><div id="primary"><div id="content" role="main"><div><p>November 15, 2020</p><!----><!----><div id="article-area"><p>If you need to use Wordpress locally, but do not want to go to the effort of setting up a web server and MySQL then you can easily set it all up using <strong>Docker</strong> (with <strong>docker-compose</strong>).</p>
<p>If you have your WordPress files in <code>/yoursite/</code> (so you have <code>/yoursite/wp-content/themes/your-theme/</code> and <code>/yoursite/wp-content/plugins/some-plugins</code>) you can use the following <code>docker-compose.yml</code>.</p>
<p>(You do not need any WordPress files outside of <code>/wp-content</code> for this to work)</p>
<pre><code><span>version</span><span>:</span><span> </span><span>'</span><span>3.1</span><span>'</span>
<span># Source: https://webdevetc.com/programming-tricks/wordpress/tips/wordpress-docker-docker-composeyml-guided-tutorial/</span>

<span>services</span><span>:</span>
<span>  </span><span>db</span><span>:</span><span> </span><span># mysql</span>
<span>    </span><span>image</span><span>:</span><span> </span><span>mysql:5.7</span>
<span>    </span><span>restart</span><span>:</span><span> </span><span>always</span>
<span>    </span><span>environment</span><span>:</span>
<span>      </span><span>MYSQL_DATABASE</span><span>:</span><span> </span><span>exampledb</span>
<span>      </span><span>MYSQL_USER</span><span>:</span><span> </span><span>exampleuser</span>
<span>      </span><span>MYSQL_PASSWORD</span><span>:</span><span> </span><span>examplepass</span>
<span>      </span><span>MYSQL_RANDOM_ROOT_PASSWORD</span><span>:</span><span> </span><span>'</span><span>1</span><span>'</span>
<span>    </span><span>volumes</span><span>:</span>
<span>      </span><span>- </span><span>db:/var/lib/mysql</span><span> </span><span># use the 'db' volume for `/var/lib/mysql`</span>

<span>  </span><span>wordpress</span><span>:</span><span> </span><span># wordpress / php / apache docker config</span>
<span>    </span><span>image</span><span>:</span><span> </span><span>wordpress:5.5.3-php7.4-apache</span>
<span>    </span><span>depends_on</span><span>:</span><span> </span><span>db</span>
<span>    </span><span>restart</span><span>:</span><span> </span><span>always</span>
<span>    </span><span>ports</span><span>:</span>
<span>      </span><span>- </span><span>8080:80</span><span> </span><span># access it on localhost:80</span>
<span>    </span><span>environment</span><span>:</span><span> </span><span># database credentials:</span>
<span>      </span><span>WORDPRESS_DB_HOST</span><span>:</span><span> </span><span>db</span><span> </span><span># points to the 'db' service (below)</span>
<span>      </span><span>WORDPRESS_DB_USER</span><span>:</span><span> </span><span>exampleuser</span>
<span>      </span><span>WORDPRESS_DB_PASSWORD</span><span>:</span><span> </span><span>examplepass</span>
<span>      </span><span>WORDPRESS_DB_NAME</span><span>:</span><span> </span><span>exampledb</span>
<span>    </span><span>volumes</span><span>:</span>
<span>      </span><span>- </span><span>./wp-content:/var/www/html/wp-content</span><span> </span><span># &lt;&lt; maps your local ./wp-content to the wp-content directory on the server</span>

<span>volumes</span><span>:</span>
<span>  </span><span>db</span><span>:</span><span>  </span><span># for mysql</span></code></pre>
<p>Once you have the above config saved as <code>docker-compose.yml</code> and you have Docker installed, just run <code>docker-compose up</code> to start everything.</p>
<p>Then visit <code>http://localhost:8080</code> and you should see the WordPress installation.</p>
<p>Once done you can run <code>docker-compose down</code>.</p>
<p>Note: This <strong>docker config</strong> is ideal if you need to make changes to a theme or plugin. It is not ideal if you need to import a database dump. If you need to edit files outside of <code>/wp-content</code> then you can add more <code>volumes</code> configuration to the <code>wordpress</code> service.</p>
</div><!----><!----></div></div></div></div></section></div></div>]]>
            </description>
            <link>https://webdevetc.com/programming-tricks/wordpress/tips/wordpress-docker-docker-composeyml-guided-tutorial/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203009</guid>
            <pubDate>Tue, 24 Nov 2020 21:08:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs Speed Up 1000%]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202942">thread link</a>) | @tartoran
<br/>
November 24, 2020 | https://blog.binchen.org/posts/emacs-speed-up-1000.html | <a href="https://web.archive.org/web/*/https://blog.binchen.org/posts/emacs-speed-up-1000.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
<p>
I'm still <b>NOT</b> satisfied with my Emacs performance after applying below tricks:
</p>

<ul>
<li>autoload packages</li>
<li>idle-load packages</li>
<li>compiling *.el to  *.elc</li>
</ul>
<p>
After some research, I found I could make my Emacs 1000% fast <b>in 1 minute</b>.
</p>

<p>
Please note I'm talking about the <b>general performance</b> not just startup time.
</p>

<p>
The solution is really simple.
</p>

<p>
Since I'm a Linux guy and my computer got enough (24G) memory. I can place my setup into <a href="http://en.wikipedia.org/wiki/Tmpfs">memory</a>.
</p>

<p>
<b>Step 1</b>, insert below line into /etc/fstab and restart computer:
</p>

<div>

<pre><code>tmpfs       /tmp        tmpfs       nodev,nosuid,size=8G    0   0
</code></pre>

</div>

<p>
<b>Step 2</b>, run the script "emacs2ram":
</p>

<div>

<pre><code>#!/bin/sh

if [ -z "$1" ];then
    echo "Usage:"
    echo "  emacs2ram start"
    echo "  emacs2ram restore"
    exit 1
fi

if [ "$1" == "start" ];then
    backup=emacs.d-backup
    link=.emacs.d
    volatile=/tmp/.emacs.d-$USER

    IFS=
    set -efu

    cd ~/

    if [ ! -r $volatile ]; then
        mkdir -m0700 $volatile
    fi

    # link -&gt; volatie does not exist
    if [ "$(readlink $link)" != "$volatile" ]; then
        # backup project at first
        mv $link $backup
        # create the link
        ln -s $volatile $link
    fi

    if [ -e $link/.unpacked ]; then
        echo "Sync .emacs.d from memory to backup ..."
        rsync -avq --delete --exclude .unpacked ./$link/ ./$backup/
        echo "DONE!"
    else
        echo "Sync .emacs.d from disk to memory ..."
        rsync -avq ./$backup/ ./$link/
        touch $link/.unpacked
        echo "DONE!"
    fi
else
    echo "Moving .emacs.d back to disk ..."
    backup=$2-backup
    link=$2
    volatile=/tmp/$2-$USER
    cd ~/projs
    rm $link &amp;&amp; mv $backup $link &amp;&amp; rm -rf $volatile
    echo "DONE!"
fi
</code></pre>

</div>

<p>
That's all! Please enjoy Emacs as usual.
</p>

<p>
The original script is from ArchLinux Wiki. I learned this technique eight years ago. I'm just wondering why I need eight years to apply it?
</p>

<p>
BTW, I've also moved <b>all my projects into memory</b>, using similar scripts.
</p>

<p>
<b>UPDATE 1:</b>
I also publicize my project-managing script at <a href="https://gist.github.com/redguardtoo/596b1a9fd3eac1cedd13#file-proj2ram">gist</a>. It's almost same as emacs2ram. 
</p>

<p>
<b>UPDATE 2:</b>
Now I use <a href="https://hoytech.com/vmtouch/">vmtouch</a> which is easier to use and more light weight. Run <code>vmtouch -vt ~/.emacs.d</code> to place the directory into memory.
</p>

<p>
Unfortunately, <code>vmtouch</code> doesn't support Windows. You can convert my bash script to DOS batch script. Basically the script copies the directory into ram disk and create a link to the directory in memory. You can use <a href="https://sourceforge.net/projects/imdisk-toolkit/">ImDisk Toolkit</a> to create ram disk.</p>
</div>
        </div></div>]]>
            </description>
            <link>https://blog.binchen.org/posts/emacs-speed-up-1000.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202942</guid>
            <pubDate>Tue, 24 Nov 2020 20:58:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If other engineers in your team are more productive]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202907">thread link</a>) | @_elergy_
<br/>
November 24, 2020 | https://evgenii.info/faster-pacers/ | <a href="https://web.archive.org/web/*/https://evgenii.info/faster-pacers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://evgenii.info/content/images/size/w300/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg 300w,
                            https://evgenii.info/content/images/size/w600/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg 600w,
                            https://evgenii.info/content/images/size/w1000/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg 1000w,
                            https://evgenii.info/content/images/size/w2000/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://evgenii.info/content/images/size/w2000/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg" alt="Not as Productive as Others?">
            </figure>

            <section>
                <div>
                    <blockquote>This is another article about pacers – people whom we use as an example to adjust our behaviour, mostly unconsciously.</blockquote><h2 id="surrounded-by-faster-pacers">Surrounded by faster pacers</h2><p>In this part, we will talk about problems that may occur when <em>you feel </em>that a lot of people in your team are much more productive than you. <br>In many cases, it doesn't lead to any problems – people happily work together and achieve great results. But sometimes their mutual influence can be destructive, and people would feel demotivated and discouraged.</p><p>Several symptoms are indicating that you're affected by faster pacers:</p><ul><li>You feel guilty seeing that colleagues have achieved more than you</li><li>You are afraid of taking challenging tasks which can make you stuck for a while</li><li>You feel like you have to work longer hours to keep up with others</li></ul><p>Daily standups or any other form of sync with colleagues is the perfect time to diagnose this problem:</p><ul><li>Are you nervous about sharing your progress?</li><li>Do those meetings make you feel like you have not done enough? </li><li>Do you find it challenging to describe your results and plans?</li></ul><p>If any of these describes you, a closer look is needed.</p><h2 id="five-actions-to-solve-the-problem">Five actions to solve the problem</h2><p>The most popular advice I heard in this situation is to take it easy. It is normal to have somebody more productive than you, left alone the fact that nobody can be a top performer in all situations.</p><p>Even though I fully understand the reasoning behind this suggestion, I do not think it is helpful. If somebody is nervous about attending standups, you cannot fix it by suggesting not to worry.</p><p>Instead, you can face this problem, find out the reasons and prepare an improvement plan, even if the problem exists only in your imagination. Then, it's going to be up to you whether to follow this plan or not, but at least you will take matters into your own hands – that alone can be sufficient to address most of the symptoms.</p><p>Let's talk about the five things which you can do to get out of this unpleasant situation. </p><h3 id="action-one-demystify-top-performers">Action one: demystify top performers<br></h3><blockquote>no two writers are the same, like snowflakes and fingerprints. No one will ever write in just the way that you do, or in just the way that anyone else does. Because of this fact, there is no real competition between writers. &lt;...&gt; Writing is a matter strictly of developing oneself. You compete only with yourself. You develop yourself by writing.<p>– John McPhee</p></blockquote><p>In time, everyone develops their areas of expertise. No matter how broad or narrow they are, one is the same — people are much more productive when their job overlaps with those areas.</p><p>Before bringing up your own expertise, I would recommend you you to think about your more productive colleagues. <strong>Every time they do something great, ask yourself what helped them to achieve those results.</strong></p><p>Something that could sound self-deprecating at first:</p><blockquote>Mark finished this giant feature for a week. That one would take more than a month for me!</blockquote><p>Can be rephrased and cleansed of magic:</p><blockquote>Mark finished this giant feature in a week because he's been building similar ones for the past three years.<br>He did more than ten last year – now he's extremely good at it.</blockquote><p>Now you can see that Mark's fast pace didn't appear overnight – it required years of deliberate practice. Moreover, you know that doing more things in this area can help you to close this gap.</p><p>That is not the only way of reframing achievements. It could be something like this:</p><blockquote>Mark finished it in a week because he wrote the whole system since the beginning and he knows every line of code by heart.</blockquote><p>or even this:</p><blockquote>... because he did not have the internet at home and spent all his free time working in the office.</blockquote><p>No matter the situation, your goal should be to stop seeing people as <em>just productive</em> and start noticed the reasons behind their results. Most of the time, those reasons are ordinary and achievable by anybody.</p><h3 id="action-two-find-your-comfort-zone">Action two: find your comfort zone</h3><p>Simply put, there are three types of activities:</p><ul><li>Something you enjoy the most</li><li>Something you are good at</li><li>Most important things for the company at the moment</li></ul><figure><img src="https://evgenii.info/content/images/2020/11/Three-types-niche.png" alt=""><figcaption>Three types of activities at work</figcaption></figure><p>The intersection of all three circles is your <em>niche </em>in the team, but finding and expanding your niche deserves a separate article. For this topic, I will focus only on the comfort zone (highlighted in green).</p><p>Everybody has ups and downs, and you will have many periods of not being at your best.<br>One of the smartest things you can do is to prepare something that can give you a little boost when needed — a type of work you like to be doing or an area where you can be very productive.</p><p>If you do not have a comfort zone right now — build one:</p><ul><li>Familiarize yourself with plans of your team.</li><li>Pick an area which will require work in the future.</li><li>Start building expertise there to capitalize on it when the time comes.</li></ul><h3 id="action-three-define-expectations-and-track-achievements">Action three: define expectations and track achievements</h3><p>The easiest way to not meet expectations is is to have no expectations at all. No matter what you achieve, you can always find a room for improvement.</p><p>The simplest way of coping with that is to formulate your goals before you start working towards them. I find daily plans most precise and helpful for this purpose; here is one of my recent ones:</p><figure><img src="https://evgenii.info/content/images/2020/11/image.png" alt=""></figure><p>The expectations were clear and realistic, but I ended up not finishing half of what I planned to do.</p><p>Was it a problem? No, because I knew that I had done more important things instead, and there was absolutely no reason to feel sad about my initial plan.</p><h3 id="action-four-keep-expectations-reasonable">Action four: keep expectations reasonable</h3><p>Sometimes results are noticeably small in comparison to goals:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-1.png" alt=""><figcaption>planned: 7; finished: 1</figcaption></figure><p>While this is a call to think about what can be improved, I would recommend checking your expectations for feasibility first.</p><p>There is a simple exercise to figure out if you are unrealistic in your estimations:</p><ul><li>Take some tasks your team plans to work on and imagine how much time each of them would take for you. Can you complete a particular task one day? In a week? Or maybe you can do five of those in an hour?</li><li>Write it somewhere.</li><li>When <em>other people</em> complete those tasks, check how their results match your estimations. <br>Were they working within their niches or tried something new? How did it impact them?</li></ul><p>This exercise is also helpful when your plans are unambitious and require correction:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-2.png" alt=""><figcaption>100% done!</figcaption></figure><h3 id="action-five-analyse-and-improve">Action five: analyse and improve</h3><p>Detailed plans can be beneficial even when everything looks good:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-3.png" alt=""><figcaption>Perfect plan and execution</figcaption></figure><p>Even though the result matched your expectation, a picky perfectionist can find some food for reflection:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-4.png" alt=""><figcaption>Digging deeper</figcaption></figure><p>I rarely use this method – maybe once every two or three months, but it always helps to take control and find something I can change.</p><h2 id="prove-it-works">Prove it works</h2><p>At the beginning of this article, I mentioned that the best way of noticing this problem is to pay attention to your behaviour when you need to share your progress and describe the plans.</p><p>Feeling that you have not done enough can contribute to the demotivation, which will prevent you from working at your best, which will cause dissatisfaction of not achieving enough, which will incur even more demotivation, which will further decrease your productivity, which will make it even harder to get out of this loop.</p><p>The good news is that the actions above can help you to</p><ul><li>Understand if your expectations are realistic and how to adjust them if they are not</li><li>Find the quick way to get back on track after a period of dissatisfaction</li><li>Figure out what is the exact reason for dissatisfaction and how to improve it</li></ul><p>If anything, it doesn't leave too many reasons to worry.</p><hr><p>As always, you can <a href="https://evgenii.info/faster-pacers#subscribe">subscribe to Resilient Systems</a> and receive new articles by email if you haven't done it yet. <br>You also can <a href="https://twitter.com/_elergy_">find me on Twitter</a> or somewhere else – I am always happy to chat :-) &nbsp;</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Resilient Systems</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://evgenii.info/faster-pacers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202907</guid>
            <pubDate>Tue, 24 Nov 2020 20:54:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Implemented in a Tweet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202779">thread link</a>) | @asyncanup
<br/>
November 24, 2020 | https://anupbishnoi.com/2019/react-in-a-tweet/ | <a href="https://web.archive.org/web/*/https://anupbishnoi.com/2019/react-in-a-tweet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>24 Jul 2019</span></p><p>Let’s implement the basic <a href="https://reactjs.org/">React</a> API in a tweet, with React DOM &amp; State management as a separate plugin in another tweet.</p>

<h2 id="what-we-want-and-shall-get">What we want, and shall get</h2>

<ul>
  <li>Top-down, one-way, state-driven rendering.</li>
  <li>Compose HTML primitives into higher-level components.</li>
  <li>Ability to write JSX to define components.</li>
  <li>Custom props for higher-order components.</li>
  <li>Event handlers that can change application state and trigger re-renders.</li>
</ul>

<h2 id="what-we-wont-get">What we won’t get</h2>

<ul>
  <li>No virtual DOM diffing between old and new renders for efficient DOM updates,
so re-renders will replace HTML content.</li>
  <li><code>setState</code> won’t be asynchronous, but synchronous.</li>
  <li>DOM event handlers won’t have React-ified names (like <code>onClick</code>), but default
DOM names (like <code>onclick</code>).</li>
  <li>Only necessary API surface area implemented, so <em>yes</em> <code>React.createElement</code>,
and <em>no</em> <code>React.cloneElement</code>.</li>
  <li>No <a href="https://reactjs.org/docs/hooks-intro.html">React Hooks</a> API.</li>
</ul>

<h2 id="code">Code</h2>

<p>Here’s React defined as a global</p>

<div><div><pre><code><span>React</span><span>=</span><span>{</span><span>Component</span><span>:</span><span>function</span><span>(</span><span>e</span><span>){</span><span>this</span><span>.</span><span>props</span><span>=</span><span>e</span><span>},[</span><span>C</span><span>=</span><span>"</span><span>createElement</span><span>"</span><span>]:(</span><span>t</span><span>,</span><span>s</span><span>,...</span><span>a</span><span>)</span><span>=&gt;</span><span>t</span><span>.</span><span>bind</span><span>?</span><span>new</span> <span>t</span><span>(</span><span>s</span><span>):(</span><span>e</span><span>=</span><span>document</span><span>[</span><span>C</span><span>](</span><span>t</span><span>),(()</span><span>=&gt;</span><span>{</span><span>for</span><span>(</span><span>n</span> <span>in</span> <span>s</span><span>)</span><span>e</span><span>[</span><span>n</span><span>]</span><span>=</span><span>s</span><span>[</span><span>n</span><span>]})(),</span><span>g</span><span>(</span><span>a</span><span>).</span><span>map</span><span>(</span><span>t</span><span>=&gt;</span><span>e</span><span>[</span><span>A</span><span>](</span><span>t</span><span>.</span><span>props</span><span>?</span><span>t</span><span>.</span><span>render</span><span>():</span><span>t</span><span>.</span><span>part</span><span>?</span><span>t</span><span>:</span><span>new</span> <span>Text</span><span>(</span><span>t</span><span>))),</span><span>e</span><span>)},</span><span>A</span><span>=</span><span>"</span><span>appendChild</span><span>"</span><span>,</span><span>g</span><span>=</span><span>(</span><span>e</span><span>=&gt;</span><span>(</span><span>e</span><span>=</span><span>e</span><span>||</span><span>[],</span><span>e</span><span>.</span><span>map</span><span>?</span><span>e</span><span>.</span><span>flatMap</span><span>(</span><span>g</span><span>):[</span><span>e</span><span>]))</span>
</code></pre></div></div>

<p>What does the above do?</p>

<ul>
  <li>Defines a global <a href="https://reactjs.org/docs/react-api.html"><code>React</code></a>.</li>
  <li>Defines <a href="https://reactjs.org/docs/react-component.html"><code>React.Component</code></a>,
the component base class.</li>
  <li>Defines
<a href="https://reactjs.org/docs/react-api.html#createelement"><code>React.createElement</code></a>
which can create both HTML primitives and custom components.</li>
  <li><code>React.createElement</code> also accepts <code>props</code>, and <code>children</code> which get appended
to the created DOM element.</li>
  <li>JSX essentially transpiles to <code>React.createElement</code> calls, with contents
passed in as <code>children</code> argument. These <code>children</code> can be custom components,
primitive HTML elements, or plain text. Code handles them all correctly.</li>
</ul>

<h2 id="what-how">WHAT! HOW?</h2>

<p>Read the annotated, prettified code below for line-by-line explanation.</p>

<p>For now, moving on to more features!</p>

<h2 id="react-dom--state-management">React DOM + State management</h2>

<p>You can bring in React DOM and React’s State management API come as a separate
plugin, implemented in another tweet!</p>

<div><div><pre><code><span>ReactDOM</span><span>=</span><span>{</span><span>render</span><span>:(</span><span>e</span><span>,</span><span>t</span><span>)</span><span>=&gt;</span><span>(</span><span>e</span><span>.</span><span>h</span><span>=</span><span>t</span><span>,</span><span>t</span><span>[</span><span>A</span><span>](</span><span>e</span><span>.</span><span>render</span><span>()))},</span><span>React</span><span>.</span><span>Component</span><span>.</span><span>prototype</span><span>.</span><span>setState</span><span>=</span><span>function</span><span>(</span><span>e</span><span>){</span><span>this</span><span>.</span><span>state</span><span>=</span><span>{...</span><span>this</span><span>.</span><span>state</span><span>,...</span><span>e</span><span>},</span><span>this</span><span>.</span><span>h</span><span>.</span><span>innerHTML</span><span>=</span><span>""</span><span>,</span><span>ReactDOM</span><span>.</span><span>render</span><span>(</span><span>this</span><span>,</span><span>this</span><span>.</span><span>h</span><span>)};</span>
</code></pre></div></div>

<p>What does the above define?</p>

<ul>
  <li>A global <code>ReactDOM</code>.</li>
  <li><a href="https://reactjs.org/docs/react-dom.html#render"><code>ReactDOM.render</code></a> function
to trigger re-renders.</li>
  <li><a href="https://reactjs.org/docs/react-component.html#setstate"><code>React.Component#setState</code></a>
to set component-level state that triggers a re-render of that component.</li>
</ul>

<h2 id="demo">Demo</h2>

<p>Let’s build React’s own <a href="https://reactjs.org/tutorial/tutorial.html">Tic-tac-toe
tutorial</a> with React-in-a-tweet™.</p>

<p>You can fiddle with the following over at
<a href="https://jsfiddle.net/asyncanup/0bzfy1sq/">JSFiddle</a>, or try it out right here!</p>

<center>
  
</center>

<p>Video of working example:</p>

<video autoplay="" loop="" controls="" width="500">
  <source src="https://anupbishnoi.com/public/img/react-tic-tac-toe-demo.mp4" type="video/mp4">
  Watch a video <a href="https://anupbishnoi.com/public/img/react-tic-tac-toe-demo.mp4">here</a>
</video>

<h2 id="usage-code">Usage code</h2>

<p>Here’s how that sweet sweet demo is implemented.</p>

<p>Throw in a root HTML element:</p>



<p>Sprinkle some CSS to make things look right (from <a href="https://reactjs.org/tutorial/tutorial.html">React tutorial</a>):</p>

<div><div><pre><code><span>body</span> <span>{</span> <span>font</span><span>:</span> <span>14px</span> <span>"Century Gothic"</span><span>,</span> <span>Futura</span><span>,</span> <span>sans-serif</span><span>;</span> <span>margin</span><span>:</span> <span>20px</span><span>;</span> <span>}</span>
<span>ol</span><span>,</span> <span>ul</span> <span>{</span> <span>padding-left</span><span>:</span> <span>30px</span><span>;</span> <span>}</span>
<span>.board-row</span><span>:after</span> <span>{</span> <span>clear</span><span>:</span> <span>both</span><span>;</span> <span>content</span><span>:</span> <span>""</span><span>;</span> <span>display</span><span>:</span> <span>table</span><span>;</span> <span>}</span>
<span>.status</span> <span>{</span> <span>margin-bottom</span><span>:</span> <span>10px</span><span>;</span> <span>}</span> 
<span>.square</span> <span>{</span>
  <span>background</span><span>:</span> <span>#fff</span><span>;</span> <span>border</span><span>:</span> <span>1px</span> <span>solid</span> <span>#999</span><span>;</span> <span>float</span><span>:</span> <span>left</span><span>;</span>
  <span>font-size</span><span>:</span> <span>24px</span><span>;</span> <span>font-weight</span><span>:</span> <span>bold</span><span>;</span> <span>line-height</span><span>:</span> <span>34px</span><span>;</span>
  <span>height</span><span>:</span> <span>34px</span><span>;</span> <span>margin-right</span><span>:</span> <span>-1px</span><span>;</span> <span>margin-top</span><span>:</span> <span>-1px</span><span>;</span>
  <span>padding</span><span>:</span> <span>0</span><span>;</span> <span>text-align</span><span>:</span> <span>center</span><span>;</span> <span>width</span><span>:</span> <span>34px</span><span>;</span>
<span>}</span>
<span>.square</span><span>:focus</span> <span>{</span> <span>outline</span><span>:</span> <span>none</span><span>;</span> <span>}</span>
<span>.kbd-navigation</span> <span>.square</span><span>:focus</span> <span>{</span> <span>background</span><span>:</span> <span>#ddd</span><span>;</span> <span>}</span>
<span>.game</span> <span>{</span> <span>display</span><span>:</span> <span>flex</span><span>;</span> <span>flex-direction</span><span>:</span> <span>row</span><span>;</span> <span>}</span>
<span>.game-info</span> <span>{</span> <span>margin-left</span><span>:</span> <span>20px</span><span>;</span> <span>}</span>
</code></pre></div></div>

<hr>

<p>And now the work horse, the JSX-enabled usage of React-in-a-tweet™ (also lifted
from <a href="https://reactjs.org/tutorial/tutorial.html">React tutorial</a>):</p>

<div><div><pre><code><span>function</span> <span>Square</span><span>(</span><span>props</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span>&lt;</span><span>button</span> <span>className</span><span>=</span><span>"square"</span> <span>onclick</span><span>=</span><span>{</span><span>props</span><span>.</span><span>onClick</span><span>}</span><span>&gt;</span>
      <span>{</span><span>props</span><span>.</span><span>value</span><span>}</span>
    <span>&lt;/</span><span>button</span><span>&gt;</span>
  <span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Returning JSX!</p>

<p>The way that works is: Babel transpiles this JSX to <code>React.createElement</code> calls,
which are handled by React-in-a-tweet just fine.</p>

<p>Remember, JSX transpiles to <code>React.createElement()</code> calls, and passes in the
component type as the first argument, props defined in JSX as the second
argument, and any children provided as the third argument.</p>

<p>For example:</p>

<div><div><pre><code><span>&lt;</span><span>button</span> <span>className</span><span>=</span><span>"square"</span> <span>onclick</span><span>=</span><span>{</span><span>props</span><span>.</span><span>onClick</span><span>}</span><span>&gt;</span>
  Square value: <span>{</span><span>props</span><span>.</span><span>value</span><span>}</span>
  <span>&lt;</span><span>div</span><span>&gt;</span>nested<span>&lt;/</span><span>div</span><span>&gt;</span>
<span>&lt;/</span><span>button</span><span>&gt;</span>
</code></pre></div></div>

<p>transpiles to:</p>

<div><div><pre><code><span>React</span><span>.</span><span>createElement</span><span>(</span><span>"</span><span>button</span><span>"</span><span>,</span> <span>{</span>
  <span>className</span><span>:</span> <span>"</span><span>square</span><span>"</span><span>,</span>
  <span>onclick</span><span>:</span> <span>props</span><span>.</span><span>onClick</span>
<span>},</span>
  <span>"</span><span>Square value: </span><span>"</span><span>,</span> <span>props</span><span>.</span><span>value</span><span>,</span>
  <span>React</span><span>.</span><span>createElement</span><span>(</span><span>"</span><span>div</span><span>"</span><span>,</span> <span>null</span><span>,</span> <span>"</span><span>nested</span><span>"</span><span>)</span>
<span>);</span>
</code></pre></div></div>

<p>So, transpiled code includes <code>React.createElement()</code> calls that contain 3 or
more arguments: <code>type</code>, <code>props</code>, and <code>...children</code>.</p>

<p>Also notice that the click handler on <code>button</code> above has the DOM-defined name
<code>onclick</code>, instead of the name that React gives it - <code>onClick</code>.</p>

<p>This is because React-in-a-tweet does not implement React’s
<a href="https://reactjs.org/docs/handling-events.html#gatsby-focus-wrapper">synthetic events</a>.
But, just like React, you can still assign functions to <code>onclick</code>.</p>

<p>Wait, what about <code>props.onClick</code> though? Why isn’t it it <code>props.onclick</code>?
Well, that’s just a prop name, which can be anything you like :)</p>

<hr>

<p>Moving on to more definitions:</p>

<div><div><pre><code><span>class</span> <span>Board</span> <span>extends</span> <span>React</span><span>.</span><span>Component</span> <span>{</span>
  <span>renderSquare</span><span>(</span><span>i</span><span>)</span> <span>{</span>
    <span>return</span> <span>(</span>
      <span>&lt;</span><span>Square</span>
        <span>value</span><span>=</span><span>{</span><span>this</span><span>.</span><span>props</span><span>.</span><span>squares</span><span>[</span><span>i</span><span>]</span><span>}</span>
        <span>onClick</span><span>=</span><span>{</span><span>()</span> <span>=&gt;</span> <span>this</span><span>.</span><span>props</span><span>.</span><span>onClick</span><span>(</span><span>i</span><span>)</span><span>}</span>
      <span>/&gt;</span>
    <span>);</span>
  <span>}</span>

  <span>render</span><span>()</span> <span>{</span>
    <span>return</span> <span>(</span>
      <span>&lt;</span><span>div</span><span>&gt;</span>
        <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"board-row"</span><span>&gt;</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>0</span><span>)</span><span>}</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>1</span><span>)</span><span>}</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>2</span><span>)</span><span>}</span>
        <span>&lt;/</span><span>div</span><span>&gt;</span>
        <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"board-row"</span><span>&gt;</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>3</span><span>)</span><span>}</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>4</span><span>)</span><span>}</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>5</span><span>)</span><span>}</span>
        <span>&lt;/</span><span>div</span><span>&gt;</span>
        <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"board-row"</span><span>&gt;</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>6</span><span>)</span><span>}</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>7</span><span>)</span><span>}</span>
          <span>{</span><span>this</span><span>.</span><span>renderSquare</span><span>(</span><span>8</span><span>)</span><span>}</span>
        <span>&lt;/</span><span>div</span><span>&gt;</span>
      <span>&lt;/</span><span>div</span><span>&gt;</span>
    <span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Notice how <code>Board</code>’s <code>render</code> function can call <code>this.renderSquare()</code> to fill in
parts of the rendered output. Works just fine.</p>

<p><code>renderSquare()</code> returns a <em>custom component</em>, <code>Square</code>, not an HTML primitive.
Works fine.</p>

<p>Also notice how the <code>onClick</code> handler defined in <code>renderSquare()</code> is just an
arrow function. Works great.</p>

<p>But wait, what’s <code>className</code> doing there? Isn’t that a React-ified HTML attribute
name?
Well, no siree.
<a href="https://developer.mozilla.org/en-US/docs/Web/API/Element/className"><code>className</code></a>
is pure DOM API. Works as is.</p>

<hr>

<p>Now let’s define the root game component itself:</p>

<div><div><pre><code><span>class</span> <span>Game</span> <span>extends</span> <span>React</span><span>.</span><span>Component</span> <span>{</span>
  <span>constructor</span><span>(</span><span>props</span><span>)</span> <span>{</span>
    <span>super</span><span>(</span><span>props</span><span>);</span>
    <span>this</span><span>.</span><span>state</span> <span>=</span> <span>{</span>
      <span>history</span><span>:</span> <span>[</span>
        <span>{</span>
          <span>squares</span><span>:</span> <span>Array</span><span>(</span><span>9</span><span>).</span><span>fill</span><span>(</span><span>null</span><span>)</span>
        <span>}</span>
      <span>],</span>
      <span>stepNumber</span><span>:</span> <span>0</span><span>,</span>
      <span>xIsNext</span><span>:</span> <span>true</span>
    <span>};</span>
  <span>}</span>

  <span>handleClick</span><span>(</span><span>i</span><span>)</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>handleClick</span><span>'</span><span>,</span> <span>i</span><span>);</span>
    <span>const</span> <span>history</span> <span>=</span> <span>this</span><span>.</span><span>state</span><span>.</span><span>history</span><span>.</span><span>slice</span><span>(</span><span>0</span><span>,</span> <span>this</span><span>.</span><span>state</span><span>.</span><span>stepNumber</span> <span>+</span> <span>1</span><span>);</span>
    <span>const</span> <span>current</span> <span>=</span> <span>history</span><span>[</span><span>history</span><span>.</span><span>length</span> <span>-</span> <span>1</span><span>];</span>
    <span>const</span> <span>squares</span> <span>=</span> <span>current</span><span>.</span><span>squares</span><span>.</span><span>slice</span><span>();</span>
    <span>if</span> <span>(</span><span>calculateWinner</span><span>(</span><span>squares</span><span>)</span> <span>||</span> <span>squares</span><span>[</span><span>i</span><span>])</span> <span>{</span>
      <span>return</span><span>;</span>
    <span>}</span>
    <span>squares</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>this</span><span>.</span><span>state</span><span>.</span><span>xIsNext</span> <span>?</span> <span>"</span><span>X</span><span>"</span> <span>:</span> <span>"</span><span>O</span><span>"</span><span>;</span>
    <span>this</span><span>.</span><span>setState</span><span>({</span>
      <span>history</span><span>:</span> <span>history</span><span>.</span><span>concat</span><span>([</span>
        <span>{</span>
          <span>squares</span><span>:</span> <span>squares</span>
        <span>}</span>
      <span>]),</span>
      <span>stepNumber</span><span>:</span> <span>history</span><span>.</span><span>length</span><span>,</span>
      <span>xIsNext</span><span>:</span> <span>!</span><span>this</span><span>.</span><span>state</span><span>.</span><span>xIsNext</span>
    <span>});</span>
  <span>}</span>

  <span>jumpTo</span><span>(</span><span>step</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>setState</span><span>({</span>
      <span>stepNumber</span><span>:</span> <span>step</span><span>,</span>
      <span>xIsNext</span><span>:</span> <span>(</span><span>step</span> <span>%</span> <span>2</span><span>)</span> <span>===</span> <span>0</span>
    <span>});</span>
  <span>}</span>

  <span>render</span><span>()</span> <span>{</span>
    <span>const</span> <span>history</span> <span>=</span> <span>this</span><span>.</span><span>state</span><span>.</span><span>history</span><span>;</span>
    <span>const</span> <span>current</span> <span>=</span> <span>history</span><span>[</span><span>this</span><span>.</span><span>state</span><span>.</span><span>stepNumber</span><span>];</span>
    <span>const</span> <span>winner</span> <span>=</span> <span>calculateWinner</span><span>(</span><span>current</span><span>.</span><span>squares</span><span>);</span>

    <span>const</span> <span>moves</span> <span>=</span> <span>history</span><span>.</span><span>map</span><span>((</span><span>step</span><span>,</span> <span>move</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>const</span> <span>desc</span> <span>=</span> <span>move</span> <span>?</span>
        <span>'</span><span>Go to move #</span><span>'</span> <span>+</span> <span>move</span> <span>:</span>
        <span>'</span><span>Go to game start</span><span>'</span><span>;</span>
      <span>return</span> <span>(</span>
        <span>&lt;</span><span>li</span> <span>key</span><span>=</span><span>{</span><span>move</span><span>}</span><span>&gt;</span>
          <span>&lt;</span><span>button</span> <span>onclick</span><span>=</span><span>{</span><span>()</span> <span>=&gt;</span> <span>this</span><span>.</span><span>jumpTo</span><span>(</span><span>move</span><span>)</span><span>}</span><span>&gt;</span><span>{</span><span>desc</span><span>}</span><span>&lt;/</span><span>button</span><span>&gt;</span>
        <span>&lt;/</span><span>li</span><span>&gt;</span>
      <span>);</span>
    <span>});</span>

    <span>let</span> <span>status</span><span>;</span>
    <span>if</span> <span>(</span><span>winner</span><span>)</span> <span>{</span>
      <span>status</span> <span>=</span> <span>"</span><span>Winner: </span><span>"</span> <span>+</span> <span>winner</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>status</span> <span>=</span> <span>"</span><span>Next player: </span><span>"</span> <span>+</span> <span>(</span><span>this</span><span>.</span><span>state</span><span>.</span><span>xIsNext</span> <span>?</span> <span>"</span><span>X</span><span>"</span> <span>:</span> <span>"</span><span>O</span><span>"</span><span>);</span>
    <span>}</span>

    <span>return</span> <span>(</span>
      <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"game"</span><span>&gt;</span>
        <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"game-board"</span><span>&gt;</span>
          <span>&lt;</span><span>Board</span>
            <span>squares</span><span>=</span><span>{</span><span>current</span><span>.</span><span>squares</span><span>}</span>
            <span>onClick</span><span>=</span><span>{</span><span>i</span> <span>=&gt;</span> <span>this</span><span>.</span><span>handleClick</span><span>(</span><span>i</span><span>)</span><span>}</span>
          <span>/&gt;</span>
        <span>&lt;/</span><span>div</span><span>&gt;</span>
        <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"game-info"</span><span>&gt;</span>
          <span>&lt;</span><span>div</span><span>&gt;</span><span>{</span><span>status</span><span>}</span><span>&lt;/</span><span>div</span><span>&gt;</span>
          <span>&lt;</span><span>ol</span><span>&gt;</span><span>{</span><span>moves</span><span>}</span><span>&lt;/</span><span>ol</span><span>&gt;</span>
        <span>&lt;/</span><span>div</span><span>&gt;</span>
      <span>&lt;/</span><span>div</span><span>&gt;</span>
    <span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>So much code! Well, as far as React API is concerned, there are only a few
interesting things going on in there.</p>

<ul>
  <li><code>Game</code>’s <code>constructor</code> sets initial state (<code>this.state</code>), storing <code>history</code>
and other Tic-tac-toe-specific data.</li>
  <li><code>handleClick</code> click handler uses <code>this.setState()</code> and passes in new state.</li>
  <li><code>render</code> does conditional rendering based on whether the game has been won
yet, and returns JSX for the entire game board.</li>
  <li>Since game state is defined entirely as <code>Game</code>’s React state, the entire game
board will re-render on every game state change in this example. Regardless of
this example, React-in-a-tweet does allow re-rendering specific parts of a UI
as long as those specific UI sections hold their own state, instead of
depending on a single global state.</li>
</ul>

<div><div><pre><code><span>ReactDOM</span><span>.</span><span>render</span><span>(&lt;</span><span>Game</span> <span>/&gt;,</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"</span><span>root</span><span>"</span><span>));</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>✓</span><span>'</span><span>)</span>
</code></pre></div></div>

<p>React DOM API that triggers the first-render, y’all. Passing in JSX for <code>&lt;Game
/&gt;</code> works. It’s just the React you know and love!</p>

<hr>

<p>Finally, a helper function that calculates winner after every move:</p>

<div><div><pre><code><span>function</span> <span>calculateWinner</span><span>(</span><span>squares</span><span>)</span> <span>{</span>
  <span>const</span> <span>lines</span> <span>=</span> <span>[[</span><span>0</span><span>,</span><span>1</span><span>,</span><span>2</span><span>],</span> <span>[</span><span>3</span><span>,</span><span>4</span><span>,</span><span>5</span><span>],</span> <span>[</span><span>6</span><span>,</span><span>7</span><span>,</span><span>8</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>3</span><span>,</span><span>6</span><span>],</span> <span>[</span><span>1</span><span>,</span><span>4</span><span>,</span><span>7</span><span>],</span> <span>[</span><span>2</span><span>,</span><span>5</span><span>,</span><span>8</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>4</span><span>,</span><span>8</span><span>],</span> <span>[</span><span>2</span><span>,</span><span>4</span><span>,</span><span>6</span><span>]];</span>
  <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>lines</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>const</span> <span>[</span><span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>]</span> <span>=</span> <span>lines</span><span>[</span><span>i</span><span>];</span>
    <span>if</span> <span>(</span><span>squares</span><span>[</span><span>a</span><span>]</span> <span>&amp;&amp;</span> <span>squares</span><span>[</span><span>a</span><span>]</span> <span>===</span> <span>squares</span><span>[</span><span>b</span><span>]</span> <span>&amp;&amp;</span> <span>squares</span><span>[</span><span>a</span><span>]</span> <span>===</span> <span>squares</span><span>[</span><span>c</span><span>])</span> <span>return</span> <span>squares</span><span>[</span><span>a</span><span>];</span>
  <span>}</span>
  <span>return</span> <span>null</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<h2 id="wait-how-does-react-in-a-tweet-itself-work">Wait, how does React-in-a-tweet itself work?</h2>

<p>Glad you asked!</p>

<p>Here’s a line-by-line explanation of the tweet-sized source code
of React-in-a-tweet:</p>

<p>Define <code>React</code> global:</p>



<p>Define and implement the following API:</p>

<ul>
  <li><code>React.Component</code>, just a simple base class which stores the <code>props</code> passed
to it.</li>
</ul>

<div><div><pre><code>    <span>Component</span><span>:</span> <span>function</span><span>(</span><span>p</span><span>)</span> <span>{</span>
      <span>this</span><span>.</span><span>props</span> <span>=</span> <span>p</span>
    <span>},</span>
</code></pre></div></div>

<ul>
  <li><code>React.createElement</code>, the work horse of rendering, which accepts:
    <ul>
      <li><code>t</code>, HTML type name or React component class,</li>
      <li><code>p</code>, props</li>
      <li><code>...c</code>, children to be appended to the dom element created.</li>
    </ul>
  </li>
</ul>

<div><div><pre><code>    <span>[</span><span>C</span> <span>=</span> <span>'</span><span>createElement</span><span>'</span><span>]:</span> <span>(</span><span>t</span><span>,</span> <span>p</span><span>,</span> <span>...</span><span>c</span><span>)</span> <span>=&gt;</span> <span>(</span>
</code></pre></div></div>

<p>In the case of <code>t</code> being a React-in-a-tweet component class, ie, a constructor
function derived from <code>React.Component</code>, we can just instantiate that function
with passed props and return the resulting React component instance.</p>



<p>Otherwise, <code>t</code> is an HTML primitive element name, like <code>button</code>, or <code>span</code>. In
this case, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anupbishnoi.com/2019/react-in-a-tweet/">https://anupbishnoi.com/2019/react-in-a-tweet/</a></em></p>]]>
            </description>
            <link>https://anupbishnoi.com/2019/react-in-a-tweet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202779</guid>
            <pubDate>Tue, 24 Nov 2020 20:40:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The war we forgot in our embrace of streaming]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202726">thread link</a>) | @mattbierner
<br/>
November 24, 2020 | https://blog.mattbierner.com/the-war-we-forgot/ | <a href="https://web.archive.org/web/*/https://blog.mattbierner.com/the-war-we-forgot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
    

    <p>I listened to Spotify for somewhere around 650 hours in 2019. That works out to a little over 27 solid days. That’s a lot of music!</p>

<p>I’m from the iPod generation, so the novelty of millions of songs in my pocket for $10 a month hasn’t entirely worn off. Spotify has changed my life. That’s only a minor exaggeration. In the old world of record stores and $0.99 iTunes singles, I never would have discovered artists like <a href="https://jeremiahkane.bandcamp.com/">Jeremiah Kane</a> or subgenres like <a href="https://giallodiscorecords.bandcamp.com/album/apocalypse-domani">Italian Horror Disco</a> which have had big impacts on both my day-to-day life and my creative work. The other great thing about streaming services like Spotify is that they let me focus on what I actually care about: the music! No more hours spent ripping CDs or scouring Limewire, no more nights wasted managing a media library and transferring songs between devices. It’s been so freeing.</p>

<p>Those 650 hours were on just one streaming service too. For a few bucks more a month, I can also stream tens of thousands of movies and shows through services such as Amazon or Netflix. And that’s all without even touching on services such as YouTube! If anything, the biggest problem facing consumers today is that there’s far too much content to choose from.</p>

<p>I’ve been happy gorging myself at this media buffet for years, until a recent project got me thinking about what shifting to a streaming only world means. Because while services such as Spotify or Netflix are in many ways better than what came before, it’s still worth trying to understand what we risk losing in this transition.</p>

<p>I have rarely seen this topic discussed in terms that I connect with. In this post, I want to go beyond typical concerns such as losing access to your library when your subscription lapses, to instead focus on how streaming can effect culture, and specifically remix culture. For, despite the flashy apps and all the billions and billions of dollars spent on new content, I’ve come to believe that streaming services take user control away and are actually quite regressive in many respects.</p>

<p>Ultimately, I feel that the biggest threat of streaming is its view that media is meant only for consumption. This view would be dangerous enough if it were restricted to the domain of streaming, but with streaming currently busy eating the world, I fear it will also come to dominate how we think about our media more broadly. This won’t happen overnight. In fact, we may not even realize that it is happening. The convenience and selection that streaming media promises has blinded us and made us forget a war that we (or at least the most nerdy ones among us) used to care deeply about: the war on DRM. By abandoning this war, we risk losing not only practical control over our media, but also our ability to imagine what our media could be and imagine how we could relate to it differently.</p>



<p>Before we continue though, a word about me: I’m not a musician, I’m not a video producer, and I’m certainly not a copyright lawyer. I’m just a nerd who likes music.</p>

<p>So what inspired this post? Well, to be perfectly honest, it was born from self interest. Streaming and DRM weren’t subjects I had ever given much thought to, let alone wanted to spend a weekend writing about. I was pretty happy with the status quo. That starting changing when I ran into a problem a few months back while building a new app.</p>

<p>You see, for the longest time I’ve wanted to use technology to somehow make the world dance along to my music. This year I finally figured out how to pull this off well. So for the past few months, I’ve been working off and on to create an augmented reality music visualizer iOS app. The app uses music to distort your walls/floors, creating wave patterns and other fun visualizations that look like they are distorting the real world’s geometry. It’s pretty neat!</p>

<p>During prototyping, I used a hardcoded audio file which let me focus on building the basic AR effects. To actually ship the app though, I wanted to let users select their own music. It sounded simple. However, I quickly hit a number of roadblocks.</p>

<p>Here’s an abridged version of my quest to add a music selector to my iOS app. Again my goal was simple: let users play their music with my app’s visualizer. On the technical side, the only important note is that the visualizer is driven by raw audio data.</p>

<ol>
  <li>
    <p>Try adding a media selector to the app using Apple’s built-in media picker UI: <a href="https://developer.apple.com/documentation/mediaplayer/mpmediapickercontroller"><code>MPMediaPickerController</code></a>.</p>

    <p>Discover that <code>MPMediaPickerController</code> shows nothing because I don’t actually have any songs in my phone’s music library.</p>
  </li>
  <li>
    <p>Remember that all of “my music” is actually in Spotify. Remember that Spotify has <a href="https://developer.spotify.com/documentation/">an API</a>!</p>

    <p>Discover that Spotify’s API is really more for remote control style apps. There is no way to access the raw audio data I needed for the visualizer.</p>
  </li>
  <li>
    <p>Check if Apple Music has an API I can use.</p>

    <p><a href="https://developer.apple.com/musickit/">Same issue</a>.</p>
  </li>
  <li>
    <p>Try downloading a song that I purchased on iTunes 10+ years ago.</p>

    <p>Discover that while the song now shows up in <code>MPMediaPickerController</code>, my app can’t access the raw audio data because the old song still has DRM.</p>
  </li>
  <li>
    <p>Go to Bandcamp, download a DRM free song, copy it over to my phone.</p>

    <p>Finally <code>MPMediaPickerController</code> works! Except I don’t own many of the songs I’d like to try in the app. Plus, now I have to manually copy music around like it’s 2003?</p>
  </li>
  <li>
    <p>Suspect that many users will be in the same boat, so see if my app can use a low level audio API to access the currently playing audio on the device.</p>

    <p>Discover that this also does not seem possible, likely for content protection reasons. (Although I won’t go so far as to say it is completely impossible. It may be possible if the music app your app tries to listen to consents or if you are some sort of iOS audio wizard.)</p>
  </li>
</ol>

<p>The only way I’ve found to let users easily visualize their music is by recording from the microphone while music plays over the speaker. Existing music visualizer apps that I’ve found on the App Store seem to have similar limitations. This just seems crazy to me!</p>

<p>So that’s where this post came from: I wanted to build a silly app about making walls dance, and streaming/DRM got in my way. The motivation is not exactly noble sounding when I put it in those terms.</p>

<p>But the app development problems I ran into aren’t nearly as interesting as the thinking they inspired. These problems got me thinking about big concepts like ownership and remixing. And this helped me realize that streaming takes away user control. Understanding all this got me wondering not only about the consequences of this loss of control, but why we mostly all have been just fine with this.</p>



<p>To watch Netflix, you have to use the Netflix app. To watch HBO, you have to use the HBO Max app. To watch Disney, you have to use the Disney Plus app.</p>

<p>Seems obvious enough. But why?</p>

<p>Why do I need apps from these providers at all? It’s not like using the Netflix app is some magical experience. 95% of the time, it’s just a fullscreen video. Any html <code>&lt;video&gt;</code> tag can do that!</p>

<p>So as long as my Netflix subscription is valid, shouldn’t I be able to load up Netflix content in any number of third party apps? Who knows, some of these third party apps might work on older or more niche devices that the official app doesn’t support. They may even have some neat UI ideas or unique features. After all, if anyone could develop a Netflix viewing app, then developers would have to work to make their app stand out from the pack. Having a vibrant app ecosystem seems like it would be a plus for these streaming providers, right?</p>

<p>But this gets to one of the fundamental misunderstandings that I had about streaming services. This misunderstanding explains why I just kind of assumed that it would be simple to hook my AR music visualizer up to a service like Spotify or Apple music.</p>

<p>Let’s take Netflix for example. When I first subscribed, I imagined that my $12 a month was buying me unlimited access to a huge library of Netflix content. However that’s not strictly accurate. Instead, my subscription lets me use sanctioned Netflix apps to view Netflix content. And while this distinction may seem like splitting hairs—especially when Netflix sanctioned apps exist for just about every modern device—I believe understanding it is a key first step in seeing the limitations of our current crop of streaming services.</p>

<p>Stepping back, I can sort of understand why streaming providers do this. If I were feeling particularly generous—or, if I were in marketing—I could probably even BS together justifications about how this setup actually benefits consumers too. Something about how the Disney app is specially designed and optimized for Disney content, and how all this vertical integration provides customers with the best end-to-end user experience. After all, we’re not just talking about apps here, but entertainment experiences! On the technical side, I also know that if you control both the frontend and backend, development and maintenance are simpler.</p>

<p>But seeing as my generosity reserves are now thoroughly depleted, I must also bring up three little letters: DRM. For controlling the entire pipeline also lets streaming providers control how their content can be shared and interacted with. That sounds a whole lot like DRM to me, even if it’s not explicitly called such. The fact that the streamed media itself is also encrypted is more of an implementation detail.</p>

<hr>

<p>So what’s the impact of linking content to an app? Well, simply put, it limits user control. Any control users have must be granted by streaming providers, who currently have little incentive to grant users anything meaningful.</p>

<p>The best analogy I can think of for this setup is that of a jukebox. A jukebox lets you play a large library of songs on demand, however browsing and selecting a song is basically all the control a jukebox grants to you. You certainly aren’t allowed to take some of the records out of the machine and play them on your own record player. Nor …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.mattbierner.com/the-war-we-forgot/">https://blog.mattbierner.com/the-war-we-forgot/</a></em></p>]]>
            </description>
            <link>https://blog.mattbierner.com/the-war-we-forgot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202726</guid>
            <pubDate>Tue, 24 Nov 2020 20:34:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Holiday Torture – VCard/vcf to CSV Converter for Address Labels]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25202644">thread link</a>) | @semireg
<br/>
November 24, 2020 | https://label.live/post/print-address-labels-using-vcard-vcf | <a href="https://web.archive.org/web/*/https://label.live/post/print-address-labels-using-vcard-vcf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://label.live/post/print-address-labels-using-vcard-vcf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202644</guid>
            <pubDate>Tue, 24 Nov 2020 20:27:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being-in-the-Room Privilege: Elite Capture and Epistemic Deference]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202553">thread link</a>) | @Reedx
<br/>
November 24, 2020 | https://www.thephilosopher1923.org/essay-taiwo | <a href="https://web.archive.org/web/*/https://www.thephilosopher1923.org/essay-taiwo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="PAGES_CONTAINER"><div id="SITE_PAGES"><div id="r36i2"><div><div id="Containerr36i2"><div data-mesh-id="Containerr36i2inlineContent" data-testid="inline-content"><div data-mesh-id="Containerr36i2inlineContent-gridContainer" data-testid="mesh-container-content"><section id="comp-khunkqfk"><div data-testid="columns"><div id="comp-khunkqgo1"><div data-mesh-id="comp-khunkqgo1inlineContent" data-testid="inline-content"><div data-mesh-id="comp-khunkqgo1inlineContent-gridContainer" data-testid="mesh-container-content"><div id="comp-khunkqgq2" data-testid="richTextElement"><p><span><span>Original Article:</span></span></p>

<p><span><span><span><span><span>Being-in-the-Room Privilege:</span></span></span></span></span></p>

<p><span><span><span><span><span>Elite Capture and Epistemic Deference </span></span></span></span></span></p>

<p><br>
<span><span><span>Olúfémi O. Táíwò </span></span></span></p></div></div></div></div></div></section><p><span><span><span><span><span>© Melody Overstreet</span></span></span></span></span></p><div id="comp-khunkqh71" data-testid="richTextElement"><div><p>“I abandoned the pitch because I don’t think I’m the right person to write this story – I have no idea what it’s like to be Black... I can send you the Google doc with my notes, too?”</p><p>

I flinched inwardly. It was an innocent and properly motivated offer: Helen, a freelance journalist, was offering to give up something for me, stemming from her concern to live out an ethos of racial justice. But I worried that it was also a trap.</p></div>



<p>Even setting aside the mistake about the power dynamics of the conversation (I am Black, but also a tenure-track professor), there was a problem here that I had seen many times before. Behind the assumption that I had experiential insight she lacked was the recognizable cultural imprint of a much discussed, polarizing perspective on knowledge and politics: standpoint epistemology.</p>



<p>If you consider a textbook definition of standpoint epistemology, it may be hard to see the controversy around this idea. The <span>International Encyclopedia of Philosophy</span> boils it down to three innocuous-sounding contentions:</p>



<p>1)&nbsp;&nbsp;&nbsp;&nbsp; Knowledge is socially situated</p>

<p>2)&nbsp;&nbsp;&nbsp;&nbsp; Marginalized people have some positional advantages in gaining some forms of knowledge</p>

<p>3)&nbsp;&nbsp;&nbsp;&nbsp; Research programs ought to reflect these facts.</p>



<p>Liam Kofi Bright argues persuasively that these contentions are derivable from a combination of 1) basic empiricist commitments, and 2) a minimally plausible account of how the social world affects what knowledge groups of people are likely to seek and find.</p>



<p>So, if the problem isn’t the basic idea, what is it?</p>



<p>I think it’s less about the core ideas and more about the prevailing norms that convert them into practice. The call to “listen to the most affected” or “centre the most marginalized” is ubiquitous in many academic and activist circles. But it’s never sat well with me. In my experience, when people say they need to “listen to the most affected”, it isn’t because they intend to set up Skype calls to refugee camps or to collaborate with houseless people. Instead, it has more often meant handing conversational authority and attentional goods to those who most snugly fit into the social categories associated with these ills – regardless of what they actually do or do not know, or what they have or have not personally experienced. In the case of my conversation with Helen, my racial category tied me more “authentically” to an experience that neither of us had had. She was called to defer to me by the rules of the game as we understood it. Even where stakes are high – where potential researchers are discussing how to understand a social phenomenon, where activists are deciding what to target – these rules often prevail.</p></div><section id="comp-khunkqh91"><div data-testid="columns"><div id="comp-khunkqhc1"><div data-mesh-id="comp-khunkqhc1inlineContent" data-testid="inline-content"><div data-mesh-id="comp-khunkqhc1inlineContent-gridContainer" data-testid="mesh-container-content"><p id="comp-khunkqhe2" data-testid="richTextElement"><h2><span>THE NORMS OF PUTTING STANDPOINT EPISTEMOLOGY INTO PRACTICE CALL FOR PRACTICES OF DEFERENCE: GIVING OFFERINGS, PASSING THE MIC, BELIEVING</span></h2></p></div></div></div></div></section><div id="comp-khunkqhg" data-testid="richTextElement"><p>The trap wasn’t <span>that</span> standpoint epistemology was affecting the conversation, but <span>how</span>. Broadly, the norms of putting standpoint epistemology into practice call for practices of deference: giving offerings, passing the mic, believing. These are good ideas in many cases, and the norms that ask us to be ready to do them stem from admirable motivations: a desire to increase the social power of marginalized people identified as sources of knowledge and rightful targets of deferential behaviour. But deferring in this way as a rule or default political orientation can actually work counter to marginalized groups’ interests, especially in elite spaces.</p>



<p>Some rooms have outsize power and influence: the Situation Room, the newsroom, the bargaining table, the conference room. Being in these rooms means being in a position to affect institutions and broader social dynamics by way of deciding what one is to say and do. Access to these rooms is itself a kind of social advantage, and one often gained through some prior social advantage. From a societal standpoint, the “most affected” by the social injustices we associate with politically important identities like gender, class, race, and nationality are disproportionately likely to be incarcerated, underemployed, or part of the 44 percent of the world’s population without internet access – and thus both left out of the rooms of power and largely ignored by the people in the rooms of power. Individuals who make it past the various social selection pressures that filter out those social identities associated with these negative outcomes are most likely to be in the room. That is, they are most likely to be in the room precisely because of ways in which they are systematically <span>different from</span> (and thus potentially unrepresentative of) the very people they are then asked to represent in the room.</p>



<p>I suspected that Helen’s offer was a trap. She was not the one who set it, but it threatened to ensnare us both all the same. Broader cultural norms – the sort set in motion by prefacing statements with “As a Black man…” – cued up a set of standpoint-respecting practices that many of us know consciously or unconsciously by rote. However, the forms of deference that often follow are ultimately self-undermining and only reliably serve “elite capture”: the control over political agendas and resources by a group’s most advantaged people. If we want to use standpoint epistemology to challenge unjust power arrangements, it’s hard to imagine how we could do worse.</p>

<p><br>
***</p></div><div id="comp-khunkqhr" data-testid="richTextElement"><p>To say what’s wrong with the popular, deferential applications of standpoint epistemology, we need to understand what makes it popular. A number of cynical answers present themselves: some (especially the more socially advantaged) don’t genuinely want social change – they just want the <span>appearance</span> of it. Alternatively, deference to figures from oppressed communities is a performance that sanitizes, apologizes for, or simply distracts from the fact that the deferrer has enough “in the room” privilege for their “lifting up” of a perspective to be of consequence.</p>



<p>I suspect there is some truth to these views, but I am unsatisfied. Many of the people who support and enact these deferential norms are rather like Helen: motivated by the right reasons, but trusting people they share such rooms with to help them find the proper practical expression of their joint moral commitments. We don’t need to attribute bad faith to all or even most of those who interpret standpoint epistemology deferentially to explain the phenomenon, and it’s not even clear it would help. Bad “roommates” aren’t the problem for the same reason that Helen being a good roommate wasn’t the solution: the problem emerges from how the rooms themselves are constructed and managed.</p>



<p>To return to the initial example with Helen, the issue wasn’t merely that I hadn’t grown up in the kind of low-income, redlined community she was imagining. The epistemic situation was much worse than this. Many of the facts about me that made my life chances different from those of the people she was imagining were the very same facts that made me likely to be offered things on their behalf. If I<span> had</span> grown up in such a community, we probably wouldn’t have been on the phone together.</p>



<p>***</p></div><div id="comp-khunkqhs" data-testid="richTextElement"><p>Many aspects of our social system serve as filtering mechanisms, determining which interactions happen and between whom, and thus which social patterns people are in a position to observe. For the majority of the 20th century, the U.S. quota system of immigration made legal immigration with a path to citizenship almost exclusively available to Europeans (earning Hitler’s regard as the obvious “leader in developing explicitly racist policies of nationality and immigration”). But the 1965 Immigration and Nationality Act opened up immigration possibilities, with a preference for “skilled labour”.</p>



<p>My parents’ qualification as skilled labourers does much to explain their entry into the country and the subsequent class advantages and monetary resources (such as wealth) that I was born into. We are not atypical: the Nigerian-American population is one of the country’s most successful immigrant populations (what no one mentions, of course, is that the 112,000 or so Nigerian-Americans with advanced degrees is utterly dwarfed by the 82 million Nigerians who live on less than a dollar a day, or how the former fact intersects with the latter). The selectivity of immigration law helps explain the rates of educational attainment of the Nigerian diasporic community that raised me, which in turn helps explain my entry into the exclusive Advanced Placement and Honours classes in high school, which in turn helps explain my access to higher education...and so on, and so on.</p>

<p><span>​</span></p>

<p>It is easy, then, to see how this deferential form of standpoint epistemology contributes to elite capture at scale. The rooms of power and influence are at the end of causal chains that have selection effects. As you get higher and higher forms of education, social experiences narrow – some students are pipelined to PhDs and others to prisons. Deferential ways of dealing with identity can inherit the distortions caused by these selection processes.&nbsp;</p>

<p><span>​</span></p>

<p><span>​</span>But it’s equally easy to see locally – in this room, in this academic literature or field, in this conversation – why this deference seems to make sense. It is often an improvement on the epistemic procedure that preceded it: the person deferred to may well be better epistemically positioned than the others in the room. It may well be the best we can do while holding fixed most of the facts about the rooms themselves: what power resides in them, who is admitted.</p></div><div id="comp-khunkqht1" title=""><div data-testid="linkElement"><wix-image id="img_comp-khunkqht1" data-image-info="{&quot;containerId&quot;:&quot;comp-khunkqht1&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;imageData&quot;:{&quot;width&quot;:500,&quot;height&quot;:692,&quot;uri&quot;:&quot;53a28d_d7a507c6115d4060a217e2377ff9c717~mv2.jpg&quot;,&quot;name&quot;:&quot;Vessel I.jpg&quot;,&quot;displayMode&quot;:&quot;fill&quot;}}" data-bg-effect-name="" data-is-svg="false" data-is-svg-mask="false" data-image-zoomed=""><img alt="Vessel I.jpg"></wix-image></div></div><p id="comp-khunkqhu2" data-testid="richTextElement"><h6><span>© Melody Overstreet</span></h6></p><div id="comp-khunkqhw" data-testid="richTextElement"><p>But these are the last facts we should want to hold fixed. Doing better than the epistemic norms we’ve inherited from a history of explicit global apartheid is an awfully low bar to set. The facts that explain who ends up in which room shape our world much more powerfully than the squabbles for comparative prestige …</p></div></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thephilosopher1923.org/essay-taiwo">https://www.thephilosopher1923.org/essay-taiwo</a></em></p>]]>
            </description>
            <link>https://www.thephilosopher1923.org/essay-taiwo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202553</guid>
            <pubDate>Tue, 24 Nov 2020 20:16:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic Prompt Construction for Masked Language Models]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202409">thread link</a>) | @dennisy
<br/>
November 24, 2020 | https://ucinlp.github.io/autoprompt/ | <a href="https://web.archive.org/web/*/https://ucinlp.github.io/autoprompt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <div>
            <div>
                
                <div>
                    
                    
                    
                    
                    
<div>
    <p>Welcome to the webpage for AutoPrompt, an automated prompt discovery algorithm to get langauge models to do what you want..</p>

<p>The remarkable success of pretrained language models has motivated the study of what kinds of knowledge these models learn during pretraining. Reformulating tasks as fill-in-the-blanks problems (e.g., cloze tests) is a natural approach for gauging such knowledge, however, its usage is limited by the manual effort and guesswork required to write suitable prompts. To address this, we develop AutoPrompt, an automated method to create prompts for a diverse set of tasks, based on a gradient-guided search. Using AutoPrompt, we show that masked language models (MLMs) have an inherent capability to perform sentiment analysis and natural language inference without additional parameters or finetuning, sometimes achieving performance on par with recent state-of-the-art supervised models. We also show that our prompts elicit more accurate factual knowledge from MLMs than the manually created prompts on the LAMA benchmark, and that MLMs can be used as relation extractors more effectively than supervised relation extraction models. These results demonstrate that automatically generated prompts are a viable parameter-free alternative to existing probing methods, and as pretrained LMs become more sophisticated and capable, potentially a replacement for finetuning.</p>

<h2 id="paper">Paper</h2>

<p>We published the paper at the <a href="https://2020.emnlp.org/">Empirical Methods in Natural Language Processing (EMNLP)</a>.</p>



<div>
<pre>@inproceedings{autoprompt:emnlp20,
  author = {Taylor Shin and Yasaman Razeghi and Robert L. Logan IV and Eric Wallace and Sameer Singh},
  title = { {AutoPrompt}: Automatic Prompt Construction for Masked Language Models },
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  year = {2020}
}
</pre>
</div>



<div>

<div>
    <div>
        
        <div>
        <figure>
            <img src="http://sameersingh.org/img/face/group/taylor.jpg" alt="Taylor Shin">
        </figure>
        </div>
        <div>
            <p>University of California, Irvine</p>
        </div>
    </div>
</div>

<div>
    <div>
        
        <div>
        <figure>
            <img src="http://sameersingh.org/img/face/group/yrazeghi.jpg" alt="Yasaman Razeghi">
        </figure>
        </div>
        <div>
            <p>University of California, Irvine</p>
        </div>
    </div>
</div>

<div>
    <div>
        
        <div>
        <figure>
            <img src="http://sameersingh.org/img/face/group/rlogan.jpg" alt="Robert L. Logan IV">
        </figure>
        </div>
        <div>
            <p>University of California, Irvine</p>
        </div>
    </div>
</div>

<div>
    <div>
        
        <div>
        <figure>
            <img src="http://sameersingh.org/img/face/group/ewallace.jpg" alt="Eric Wallace">
        </figure>
        </div>
        <div>
            <p>University of California, Berkeley</p>
        </div>
    </div>
</div>

<div>
    <div>
        
        <div>
        <figure>
            <img src="http://sameersingh.org/img/face/sameer-sq.jpg" alt="Sameer Singh">
        </figure>
        </div>
        <div>
            <p>University of California, Irvine</p>
        </div>
    </div>
</div>

</div>

</div>
                </div>
                
            </div>
        </div>
    </section></div>]]>
            </description>
            <link>https://ucinlp.github.io/autoprompt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202409</guid>
            <pubDate>Tue, 24 Nov 2020 20:00:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating a Terraform Provider for Plausible]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202260">thread link</a>) | @kurtmc
<br/>
November 24, 2020 | https://mcalpinefree.co.nz/blog/Technical/terraform-plausible | <a href="https://web.archive.org/web/*/https://mcalpinefree.co.nz/blog/Technical/terraform-plausible">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mcalpinefree.co.nz/blog/Technical/terraform-plausible</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202260</guid>
            <pubDate>Tue, 24 Nov 2020 19:45:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon M1: Black Magic Fuckery]]>
            </title>
            <description>
<![CDATA[
Score 714 | Comments 669 (<a href="https://news.ycombinator.com/item?id=25202147">thread link</a>) | @singhkays
<br/>
November 24, 2020 | https://www.singhkays.com/blog/apple-silicon-m1-black-magic/ | <a href="https://web.archive.org/web/*/https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<blockquote>
<p>Black. Magic. Fuckery.</p>
</blockquote>
<p>These are the words used by the user <a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvn0oy/">holdagold on reddit</a> to describe their experience with the new Apple Silicon M1 Macbook Air. Rarely does a product leave people effusing to the extent Apple Silicon M1 has done this week. At best, you get the people who really care about a system’s internals very excited like we saw with Zen 3’s launch recently. For everyday users who just want to browse the web, stream some Netflix, maybe edit some documents, computers have been “perfectly fine” for the last decade. We’ve seen incremental year over year improvements with slightly more performance, slightly more battery life, marginally faster SSD, somewhat thinner design, etc. But something genuinely new, something revolutionary, something once in a generation has been missing. I believe the Apple M1 represents something we can truly call “revolutionary”.</p>
<p>Before we proceed, it’s essential to set the context that I’ve only used two Apple devices in my entire life - <em>a personal 2013 MacBook Air and a 2019 MacBook Pro that I got through work</em>. Everything else has been either a custom-built PC, Windows laptop, or an Android/Windows Mobile smartphone. Even for a “PC/Android Guy”, I have to admit what I saw this week is something special. I believe it’ll go down as a significant milestone in computing history on par with some industry-defining chips like Intel’s 8086, 386, 486, Pentium, Conroe or AMD’s K8, Zen, etc. I hope for the return of Moore’s law and awakening of the x86 manufacturers from their slumber as this will be the “<em>slowest</em>” CPU Apple will ever make. <em>As Henry Clay once said</em>,</p>
<blockquote>
<p>Of all human powers operating on the affairs of mankind, none is greater than that of competition.</p>
</blockquote>
<p>This blog is then my observation of the excitement around this significant launch and captures some of the user and reviewer commentary.</p>

<p>Apple launched its own M1 SoC that integrates an 8-core CPU, 8-core GPU, 16-core Neural Engine, Media encode and decode engines, RAM - all on a single-chip. By including the RAM on the SoC, Apple is marketing this as a Unified Memory Architecture (UMA), central to the performance improvements M1 brings.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_480x0_resize_q75_box.jpg 480w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_800x0_resize_q75_box.jpg 800w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_1200x0_resize_q75_box.jpg 1200w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_1500x0_resize_q75_box.jpg 1500w,
                " src="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_800x0_resize_q75_box.jpg" alt="Apple Silicon M1 summary capabilities">
</figure>
<p>The first products and price points the M1 will be going into are:</p>
<ol>
<li>Mac Mini - $699</li>
<li>MacBook Air 13" - $999</li>
<li>MacBook Pro 13" - $1299</li>
</ol>
<p>Apple promises its new chip is much more energy-efficient than its Intel counterparts, so the battery life promises have gone up across the board:</p>
<ol>
<li>On the MacBook Air - up to 18 hours of video on a single charge (<em>up from 12 hours on this year’s Intel-powered MacBook Air</em>) and offers up to 15 hours of wireless web browsing per charge (<em>up from 11 hours previously</em>)</li>
<li>On the MacBook Pro - up to 17 hours of wireless web browsing (<em>up from 10 hours with this year’s Intel-powered MacBook Pro</em>), and 20 hours of video playback (<em>up from 10 hours before</em>).</li>
</ol>
<p>To showcase that energy efficiency, Apple is shipping the Macbook Air without any fan! It will be passively cooled like all iPhones and iPads.</p>


<p>Surprisingly no! Apple included Rosetta 2 ahead-of-time binary translation technology that translates code designed to run on Intel/x86 CPUs for the Apple Silicon CPUs. The performance is much better than expected and ranges between 70-80% of native code, which is surprising compared to Microsoft’s struggles in emulating x86 Windows apps on ARM CPUs. Apple’s answer might lie in something called TSO, aka. total store ordering as explained by <a href="https://www.reddit.com/r/hardware/comments/i0mido/apple_silicon_has_a_runtime_toggle_for_tso_to/">u/Veedrac and and u/ShaidarHaran2 on reddit</a>:</p>
<blockquote>
<p>TSO, aka. total store ordering, is a type of memory ordering, and affects how cores see the operations performed in other cores. Total store ordering is a strong guarantee provided by x86, that very roughtly means that all stores from other processors are ordered the same way for every processor, and in a reasonably consistent order, with exceptions for local memory.</p>
<p>In contrast, Arm architectures favour weaker memory models, that allows a lot of reordering of loads and stores. This has the advantage that in general there is less overhead where these guarantees are not needed, but it means that when ordering is required for correctness, you need to explicitly run instructions to ensure it. Emulating x86 would require this on practically every store instruction, which would slow emulation down a lot. That’s what the hardware toggle is for.</p>
<blockquote>
<p>In other words, Apple has, of course, been playing the very long game. TSO is quite a large benefit to emulating x86, hence why Rosetta 2 appears to put out a very decent 70% of native chip performance, that and install time translation for everything but JIT features. That’s on a chip not even meant to be a mac chip, so with further expanded caches, a wider, faster engine, perhaps applying the little cores to emulation which they’re not currently, and so on, x86_64 performance should be very very decent. I’m going to dare upset some folks and say perhaps even be faster in emulation than most contemporary x86 chips of the time, if you only lose 20% of native performance when it’s all said and done, it doesn’t take much working backwards to figure where they’d need to be, and Gurman said they were aiming for over 50% faster than Intel.</p>
</blockquote>
</blockquote>

<p>There have been numerous professional reviews and YouTube videos enumerating how Apple’s new products are better than their previous Intel counterparts. In the end, though, it comes down to how these products fit into the core workflows of the consumer who’s spending their money on them. There have been plenty of real-world experiences that I’ve seen in my filter bubble, mostly Reddit and Twitter. I will share some of these throughout this blog.</p>
<h2 id="the-speed">The Speed</h2>
<blockquote><p lang="en" dir="ltr">I pray that Intel, AMD, and Qualcomm is letting the M1 give them ideas, take them in new directions. Because this level of sorcery is too damn powerful to be held by a single company. Especially a monopolizing conglomerate like Apple. But fucking kudos to those chip wizards 👏</p>— DHH (@dhh) <a href="https://twitter.com/dhh/status/1330903542463422469?ref_src=twsrc%5Etfw">November 23, 2020</a></blockquote>
<blockquote><div lang="en" dir="ltr"><p>Purchased a new MacBook Air w/ Apple's M1 chip. </p><p>Holy crap. </p><p>Everything is WICKED fast.</p><p>Windows and prompts pop up instantly. Slowdown NEVER happens — even w/ numerous apps going. </p><p>Evernote, always a resources hog for me, is now a non-issue.</p><p>Huge props, Apple. 👍</p></div>— JP Mangalindan (@JPManga) <a href="https://twitter.com/JPManga/status/1329265657796390914?ref_src=twsrc%5Etfw">November 19, 2020</a></blockquote>
<blockquote><p lang="en" dir="ltr">Have had my M1 MacBook for about a week now... and have been blown away by the performance. Battery just last and lasts, and either the fan never runs or is inaudible. Everything seems faster, even the stuff not yet compiled for Apple Silicon.</p>— Blake Scholl 🛫 (@bscholl) <a href="https://twitter.com/bscholl/status/1331084298451963904?ref_src=twsrc%5Etfw">November 24, 2020</a></blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/the_macbook_air_is_once_again_the_benchmark_by/gczfgs9">u/MagneticGray on reddit</a>:</p>
<blockquote>
<p>Definitely don’t get near one! I have the 12.9” iPad Pro, new Max iPhone, older 13”MBP, and a beastly gaming PC. Our IT guy got the new MacBook Pro today and after playing with it for 10 minutes I was already rearranging my finances in my head.</p>
<p>People keep saying this but it’s eerily fast and silent, like alien technology. I exported a 5 minute clip in unoptimized Premiere Pro and I swear it did it faster than my PC with a 2070 ever has. The MBP wasn’t even warm to the touch afterwards either.</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gctzgic/">u/leach4_pikes on reddit</a>:</p>
<blockquote>
<p>&gt; It’s honestly the best purchase I’ve made in the last 10 years.</p>
<p>This is exactly how I feel. Feels like I’m holding a magical device that shouldn’t exist. Haven’t felt that in a long long time</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxu58m/apple_m1_arm_performance_with_a_2020_mac_mini/gd082ng/">u/lawrencejuliano and u/havaloc on reddit</a>:</p>
<blockquote>
<p>I have a 2018 15” MacBook Pro which is used almost exclusively in clamshell mode these days and attached to an ultrawide monitor. I use it mainly for photoshop and Lightroom for my photography work, and it’s been painful to say the least. It’s quick for all of two minutes until the fan kicks in with the thermal throttling, at which point the machine chugs to a crawl. I’ve been wanting to get a desktop in replacement, eyeing the previous gen Mac Minis but unable to make the move due to the lack of discrete GPU and an inability to push my monitor’s resolution.</p>
<p>In comes the M1 Mac Mini - I ordered right away and received it Tuesday, and my god has it been a breath of fresh air. First impressions were insanely positive, even hooked to my 5120x1440 display it was lightning fast. But yesterday I put it through the paces with edits from a recent shoot, and it was beyond stellar. More photoshop tabs open than ever before, Lightroom CC and classic open together, nothing could slow it down.</p>
<p>To say I’m impressed with this first gen is a massive understatement, this is shaping up to be one of the most enjoyable devices I’ve ever owned. First computer that hasn’t had some feeling of compromise in a long time.</p>
</blockquote>

<h2 id="buyers-remorse-is-real">Buyers remorse is real</h2>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gcyyfjl">u/afelzz and u/WizardSleeveLoverr on reddit</a>:</p>
<blockquote>
<p>I feel so fucking stupid for ordering a Macbook Air in April this year.</p>
<blockquote>
<p>Same. I’m mad at myself. I ordered a MacBook Pro around the same time and of course this comes out. Trade in value is a joke too.</p>
</blockquote>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gd0n94p">u/2shizhtzu4u on reddit</a>:</p>
<blockquote>
<p>I was stupid to by [sic] the early 2020 model. Sent it back today in exchange for this one. The performance on the M1 is far more than what I expected</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gczjpa8">u/kelev on reddit</a>:</p>
<blockquote>
<p>As someone who got an entry level 2020 MBP in June… fuck.</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/_/gcu471l">u/hijusthappytobehere, u/CanadianMapleBacon and u/takesthebiscuit on reddit</a>:</p>
<blockquote>
<p><em>cries in 2020 MBP</em></p>
<blockquote>
<p>2020 MacBook Air purchased in August :(:(:(</p>
</blockquote>
<blockquote>
<p>Ha my dad is 5 months into his MBP gutted</p>
</blockquote>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvvtju/">u/mraheem on reddit</a>:</p>
<blockquote>
<p>Sucks cause i just bought a MacBook 3 years ago. And that battery is super super appealing.</p>
</blockquote>
<h2 id="battery-life-is-insane">Battery life is insane!</h2>
<blockquote><div lang="en" dir="ltr"><p>I haven’t plugged in this M1 Mac in almost 2 days. It’s only half dead. lol. What is this sorcery? 🔋 </p><p>Apple Silicon Macs are the future, man. Competing laptops are gonna have a hard time catching up. <a href="https://t.co/FmX5uVKkFd">pic.twitter.com/FmX5uVKkFd</a></p></div>— Computer Clan (📌M1) (@thecomputerclan) <a href="https://twitter.com/thecomputerclan/status/1329611818847891460?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote>

<blockquote><div lang="en" dir="ltr"><p>The battery life on the new MacBook Pro with M1 chip is INSANE</p><p>I've been doing work on this for several hours, and it's still at 87% 🤯🤯🤯</p><p>I guess it was a good thing I got my 3 week old laptop stolen? Lol<a href="https://twitter.com/hashtag/AppleM1?src=hash&amp;ref_src=twsrc%5Etfw">#AppleM1</a> <a href="https://t.co/fENYDS235O">pic.twitter.com/fENYDS235O</a></p></div>— William Lex Ham ✊🏽🧢 #TheyCantBurnUsAll (@WillLexHam) <a href="https://twitter.com/WillLexHam/status/1329906722845188097?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">https://www.singhkays.com/blog/apple-silicon-m1-black-magic/</a></em></p>]]>
            </description>
            <link>https://www.singhkays.com/blog/apple-silicon-m1-black-magic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202147</guid>
            <pubDate>Tue, 24 Nov 2020 19:36:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grinch Bots Will Steal the Best Deals This Holiday Season]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25202140">thread link</a>) | @mch82
<br/>
November 24, 2020 | https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals | <a href="https://web.archive.org/web/*/https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Grinch bots, also known as scalper bots, have won deals at super-human speeds that consumers can't match in previous holiday seasons. However, due to the development of bots in the sneaker industry and COVID-19, the 2020 holiday season will see software bots complete a record number of online transactions.</p>
<p>In 2018, members of Congress drafted <a rel="nofollow noopener" target="_blank" title="a bill" href="https://tonko.house.gov/uploadedfiles/grinch_bots_fact_sheet.pdf">a bill</a> to outlaw grinch bots, stating that "Allowing grinch bots to rig prices and squeeze consumers during the holiday season hurts American families, small business owners, product makers and entrepreneurs. We will not allow this market manipulation to go unchecked."</p>
<p>This holiday season, grinch bots will purchase over $100 million of sneakers. In addition, this fast-growing software trend will impact clothing, collectibles, computers, electronics, gaming, and any attractive deal where demand outweighs supply. As a result, consumers will either miss out on the hottest holiday gifts, or be forced to purchase them from reseller platforms like eBay at steep markups.</p>
<p>Below, we outline what grinch bots are, how they work, and share details on the industries that are expected to be hardest hit.</p>
<p><strong>Table of Contents</strong></p>
<ul>
<li><a href="#what-are-grinch-bots">What Are Grinch Bots?</a></li>
<li><a href="#how-do-grinch-bots-work">How Do Grinch Bots Work?</a></li>
<li><a href="#grinch-bots-over-500-million">Grinch Bots Will Purchase Over $100 Million of Sneakers During the 2020 Holidays</a></li>
<li><a href="#grinch-bots-in-other-industries">Grinch Bots Are Increasingly Popular In Other Industries</a></li>
<li><a href="#grinch-bots-cost-10000-dollars">The Leading Grinch Bots Are Now Being Sold for Almost $10,000</a></li>
<li><a href="#what-holiday-deals-will-grinch-bots-target-2020">What Holiday Merchandise Will Grinch Bots Target in 2020?</a></li>
</ul>

<h2>What Are Grinch Bots?</h2>
<p>Grinch bots, otherwise known as scalper bots, are software programs built to rapidly purchase scarce goods from websites before humans have the chance to do so. In other words, they automate the checkout process on eCommerce websites. Some grinch bots are programmed and owned by individual hackers. Others, like those mentioned below, are built and sold to consumers known as 'botters.'</p>
<p>The typical features found in grinch bots are: </p><div>
<div>
<ul>
<li>Retailer website compatibility</li>
<li>Captcha solvers</li>
<li>Automated checkout</li>
<li>Restock checking</li>
<li>Proxy integrations</li>
<li>Mobile applications</li>
<li>Customer support</li>
</ul>
</div>
</div>
<p>Botters use technologies in addition to the bots to scalp merchandise. The two most common are proxies and servers. Proxies, offered by companies like <a rel="nofollow noopener" target="_blank" title="Oculus" href="https://oculusproxies.com/index">Oculus</a> and <a rel="nofollow noopener" target="_blank" title="Surge" href="https://www.surgeproxies.com/">Surge</a>, are entered into the bots so that each checkout can use a unique IP address. Servers, managed by companies like <a rel="nofollow noopener" target="_blank" title="Amazon Web Services" href="https://aws.amazon.com/">Amazon Web Services</a> or <a rel="nofollow noopener" target="_blank" title="10xServers" href="https://10xservers.com/">10xServers</a>, are used to increase bot speed. Botters host virtual servers in the same locations as the websites they are botting to reduce the physical distance that the data needs to travel.</p>
<h2>How Do Grinch Bots Work?</h2>
<p>When botters purchase their bot, they program it with their personal information – shipping &amp; billing addresses, credit card info, usernames &amp; passwords. The botters' proxies are also added to the bot.</p>
<p>In anticipation of a sale, botters enter the specific merchandise they hope to purchase from a given retailer. As you can see below, these are stored as tasks in the software.</p>
<div>
<p><img alt="Cybersole task screenshot" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks 2x">
</p>
</div>
<p>Once the sale goes live on the target retailer website, the bot begins the checkout process. Botters can manually complete any necessary actions that the retailer requires during checkout, such as completing a CAPTCHA.</p>
<h2>Grinch Bots Will Purchase Over $100 Million of Sneakers During the 2020 Holidays</h2>
<p>Grinch bots will purchase over $100 million of sneakers during the 2020 holidays. This is consistent with the current size of the U.S. sneaker resale market, which is <a rel="nofollow noopener" target="_blank" title="estimated at $2 billion" href="https://finance.yahoo.com/news/global-sneaker-resale-market-could-reach-30-billion-by-2030-cowen-191003371.html">estimated at $2 billion</a>.</p>
<p>To calculate this figure, we completed a bottoms-up analysis using publicly available data shared by the bots. Many, but not all of the bots, share their transaction volume for each successful sale on Twitter. Cybersole's <a rel="nofollow noopener" target="_blank" title="Twitter account" href="https://twitter.com/Cybersole">Twitter account</a> is a good example, where you can find several posts a month celebrating the purchase of thousands of pairs of shoes.</p>
<p>The estimated 2020 holiday sales of the seven bots below is $70 million. This does not include sales from several other leading bots that do not publicly share their transaction volumes.</p>
<div>
<div>
<div>
<table><thead><tr><th colspan="" rowspan="">Bot</th><th colspan="" rowspan="">Est. Monthly Transactions</th><th colspan="" rowspan="">Est. Monthly Sales</th><th colspan="" rowspan="">Est. Holiday Sales</th><th colspan="" rowspan="">Annual Run Rate</th></tr></thead><tbody><tr><td colspan="" rowspan="">Kodai</td><td colspan="" rowspan="">50,000</td><td colspan="" rowspan="">$10 million</td><td colspan="" rowspan="">$24 million</td><td colspan="" rowspan="">$120 million</td></tr><tr><td colspan="" rowspan="">Cybersole</td><td colspan="" rowspan="">45,000</td><td colspan="" rowspan="">$9 million</td><td colspan="" rowspan="">$22 million</td><td colspan="" rowspan="">$108 million</td></tr><tr><td colspan="" rowspan="">Prism</td><td colspan="" rowspan="">25,000</td><td colspan="" rowspan="">$5 million</td><td colspan="" rowspan="">$12 million</td><td colspan="" rowspan="">$60 million</td></tr><tr><td colspan="" rowspan="">Project Destroyer</td><td colspan="" rowspan="">15,000</td><td colspan="" rowspan="">$3 million</td><td colspan="" rowspan="">$7.2 million</td><td colspan="" rowspan="">$36 million</td></tr><tr><td colspan="" rowspan="">Polaris</td><td colspan="" rowspan="">5,000</td><td colspan="" rowspan="">$1 million</td><td colspan="" rowspan="">$2.4 million</td><td colspan="" rowspan="">$12 million</td></tr><tr><td colspan="" rowspan="">AIO Bot</td><td colspan="" rowspan="">5,000</td><td colspan="" rowspan="">$1 million</td><td colspan="" rowspan="">$2.4 million</td><td colspan="" rowspan="">$12 million</td></tr><tr><td colspan="" rowspan=""><strong>Total</strong></td><td colspan="" rowspan=""><strong>145,000</strong></td><td colspan="" rowspan=""><strong>$29 million</strong></td><td colspan="" rowspan=""><strong>$70 million</strong></td><td colspan="" rowspan=""><strong>$348 million</strong></td></tr></tbody></table>
</div>
</div>

</div>
<h2>Grinch Bots Are Increasingly Popular In Other Industries</h2>
<p>While bots have the deepest penetration in footwear, they are becoming increasingly popular in several other industries. There are several recent high-profile reports of bots outdueling humans to secure valuable in-demand merchandise, for example: </p><div>
<div>
<ul>
<li>In November, resellers used bots to purchase the majority of PlayStation 5s from top online retailers like GAME, John Lewis and Tesco (<a rel="nofollow noopener" target="_blank" title="source" href="https://metro.co.uk/2020/11/20/ps5-retail-websites-crashed-due-to-scalper-bots-13627423/#:~:text=It's%20believed%20that%20scalpers%20were,each%20other%20for%20late%20deliveries.">source</a>)</li>
<li>In September, resellers used bots to purchase the majority of Nvidia's RTX3080 video card (<a rel="nofollow noopener" target="_blank" title="source" href="https://www.extremetech.com/gaming/315210-resellers-used-bots-to-dominate-the-rtx-3080-launch">source</a>)</li>
<li>In April, resellers used bots to exacerbate shortages of the Nintendo Switch (<a rel="nofollow noopener" target="_blank" title="source" href="https://www.ign.com/articles/nintendo-switch-shortages-exacerbated-by-resellers-using-auto-buying-bots">source</a>)</li>
</ul>
</div>
</div>
<p>One of the largest online forums for botters is Reddit, and more specifically the community <a rel="nofollow noopener" target="_blank" title="r/shoebots" href="https://www.reddit.com/r/shoebots/">r/shoebots</a>. While this community started out focused on shoes, many recent threads are about CPUs, electronics, sports cards, and video games. As you can see below, the community has grown exponentially as botting has grown in popularity. It started 2020 at 9,630 members and has 22,400 members as of November 21, 2020.</p>
<div>
<p><img alt="r/shoebots reddit user growth over time" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth 2x">
</p>
</div>
<p>The sneaker market and COVID-19 are two of the largest catalysts of grinch bot adoption. COVID-19 impacted the market in two ways –&nbsp;it increased unemployment, and shifted retail spend online. These forces led to more individuals looking for a new source of income online.</p>
<p>Bots have also begun advertising their ability to operate on websites outside of the footwear industry. On November 12, Prism <a rel="nofollow noopener" target="_blank" title="announced" href="https://twitter.com/PrismAIO/status/1326920747625885698">announced</a> that its bot works on Walmart.com. In fact, there are several bots that work on both <a rel="nofollow noopener" target="_blank" title="Target and Walmart's websites" href="https://www.reddit.com/r/shoebots/comments/jyrwnb/best_walmart_and_target_bot_for_mac/">Target and Walmart's websites</a>. Cybersole's website advertises the ability to use its bot on over 270 websites.</p>
<h2>The Leading Grinch Bots Are Now Being Sold for Almost $10,000</h2>
<p>The market for grinch bots has become increasingly competitive as more software products have entered the market. However, finding and purchasing a copy of the best bots is difficult –&nbsp;bot creators typically limit the number of instances they sell in an effort to prevent their bots from becoming too popular, and obsolete.</p>
<p>As a result, many of the top bots must be purchased through resale themselves. The bot resale website BotBroker.io has sold over 31,000 bots. The pricing data below was recorded from its website in November 2020.</p>
<div>
<div>
<div>
<table><thead><tr><th colspan="" rowspan="">Bot</th><th colspan="" rowspan="">Last Sale Price</th><th colspan="" rowspan="">Bot Creation Date</th></tr></thead><tbody><tr><td colspan="" rowspan="">Wrath</td><td colspan="" rowspan="">$8,299</td><td colspan="" rowspan="">February, 2018</td></tr><tr><td colspan="" rowspan="">CyberAIO</td><td colspan="" rowspan="">$5,600</td><td colspan="" rowspan="">April, 2016</td></tr><tr><td colspan="" rowspan="">Prism</td><td colspan="" rowspan="">$3,998</td><td colspan="" rowspan="">October, 2018</td></tr><tr><td colspan="" rowspan="">SwftAIO</td><td colspan="" rowspan="">$3,750</td><td colspan="" rowspan="">January, 2019</td></tr><tr><td colspan="" rowspan="">Polaris</td><td colspan="" rowspan="">$3,300</td><td colspan="" rowspan="">November, 2019</td></tr><tr><td colspan="" rowspan="">Balko</td><td colspan="" rowspan="">$2,400</td><td colspan="" rowspan="">August, 2018</td></tr><tr><td colspan="" rowspan="">MekAIO</td><td colspan="" rowspan="">$2,400</td><td colspan="" rowspan="">October, 2020</td></tr><tr><td colspan="" rowspan="">Nebula</td><td colspan="" rowspan="">$2,399</td><td colspan="" rowspan="">March, 2018</td></tr><tr><td colspan="" rowspan="">TohruAIO</td><td colspan="" rowspan="">$2,065</td><td colspan="" rowspan="">October, 2019
</td></tr></tbody></table>
</div>
</div>

</div>
<p>Wrath is currently the most expensive bot on BotBroker.io. As you can see below, its price has been steadily increasing the past year.</p>
<div>
<p><img alt="Wrath bot price over time" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time 2x">
</p>
</div>
<h2>What Holiday Merchandise Will Grinch Bots Target in 2020?</h2>
<p>The development of bots in the sneaker industry and COVID-19 mean that the holiday season of 2020 will see a record level of grinch bot transactions. The merchandise categories that will see the greatest bot transaction volume will be: </p><div>
<div>
<ul>
<li>Clothing</li>
<li>Collectibles</li>
<li>Computers</li>
<li>Electronics</li>
<li>Gaming</li>
<li>Sneakers</li>
<li>Toys</li>
</ul>
</div>
</div>
<p>In addition, resellers will almost certainly target flash sales of any high-demand item. Botters have formed 'cook groups' on Discord, where they share the latest information about promising upcoming 'drops' and sales. These groups provide botters an additional advantage over the average consumer.</p>
<p>Unfortunately for these consumers, it's likely that they will be forced to pay a significant premium to purchase the hottest items of the 2020 holiday season. It's hard to compete with the botters and their bots.</p>
</div></div>]]>
            </description>
            <link>https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202140</guid>
            <pubDate>Tue, 24 Nov 2020 19:35:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Thanksgiving Dinner Costs in Every State]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201889">thread link</a>) | @bingdig
<br/>
November 24, 2020 | https://www.viscachadata.com/research/thanksgiving-prices | <a href="https://web.archive.org/web/*/https://www.viscachadata.com/research/thanksgiving-prices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5f288d06b11c6d4682052caa" id="sections">
  
    <section data-section-id="5f288d06b11c6d4682052cae" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
      &quot;imageOverlayOpacity&quot;: 0.15,
      &quot;video&quot;: {
        &quot;playbackSpeed&quot;: 0.5,
        &quot;filter&quot;: 1,
        &quot;filterStrength&quot;: 0,
        &quot;zoom&quot;: 0
      },
      &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
      &quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
      &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
      &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
      &quot;contentWidth&quot;: &quot;content-width--medium&quot;,
      &quot;sectionTheme&quot;: &quot;white&quot;,
      &quot;sectionAnimation&quot;: &quot;none&quot;,
      &quot;backgroundMode&quot;: &quot;image&quot;
    }" data-animation="none">
  
  <div>
    <div>
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5fb44bf0d244e425af400962"><div><div><div data-block-type="2" id="block-e2f45a91e4089e8eb8c0"><div><p>How do the prices of Thanksgiving dinner ingredients vary across the country? Regional differences in cost and competition in addition to price discrimination by retailers can cause the same products to cost very different amounts to consumers depending on where they’re shopping. Viscacha Data’s granular retail data captures store-level prices for over 4,600 Walmart locations nationwide, helping answer this question.</p><p>Using a standard set of Thanksgiving dinner foods, we picked the most common products and calculated average prices by state. The cost of these products, based on the <a href="https://www.fb.org/newsroom/farm-bureau-survey-thanksgiving-dinner-cost-rises-only-a-penny#:~:text=The%20American%20Farm%20Bureau%20Federation's,last%20year's%20average%20of%20%2448.90">American Farm Bureau’s</a> standard 10-person meal estimate, ranges from $47.88 to $50.15 for the 48 contiguous states.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1605651800882_4479"><p>The majority of products’ prices varied little by state, with some like Great Value’s sweet potatoes having no price variation at all. To look at more granular price variance, we focus in on milk, the product in the Thanksgiving dinner list with by far the largest geographic differences:</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1605651800882_5711"><div><p>The price of a gallon of milk ranges from $0.65 to $4.19 across Walmart stores. This likely stems from differing forms of price control across states, where some have state milk commissions that regulate prices and others don’t. Evidently, the differences in milk prices are the largest driver of differences in Thanksgiving dinner prices, particularly explaining the high costs in Pennsylvania and Maine.</p><p>Finally, we looked at geographic price variance of hard apple cider - not part of the standard Thanksgiving dinner basket but a fall-themed accompaniment with interesting price patterns.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1605651800882_9243"><div><p>The price of an Angry Orchard 6-pack of hard cider varies significantly by location, from $7.98 to $11.48. In many cases, prices are similar across locations in a given state but vary sharply from state-to-state, even those that are geographically close together like Indiana and Ohio. In a couple cases, price markups seem to occur in urban areas and their surroundings (e.g. Dallas and St. Louis). Overall, the geographic variation in prices suggests that alcohol purchases may be the largest source of state-by-state variation in average Thanksgiving bills.</p><p><br>To learn more about how Viscacha Data’s novel price and inventory data can monitor and predict consumer and retailer behavior at granular levels, <a href="https://www.viscachadata.com/contact"><strong>contact us</strong></a><strong>.</strong></p><h4>Products Used</h4><p>Thanksgiving dinner:</p><ul data-rte-list="default"><li><p>Butterball All Natural Young Turkey, Frozen, 10-16 lbs &amp; Butterball Farm-to-Family Frozen Young Turkey, No Antibiotics, 10 - 20.9 lb (averaged)</p></li><li><p>Hormel Boneless Half Ham, 3 lbs</p></li><li><p>Great Value Country Gravy Mix, 2.5 oz</p></li><li><p>Great Value Whole Kernel Corn, 12 oz</p></li><li><p>Great Value Fine Green Beans, 12 oz</p></li><li><p>Great Value Sweet Peas, 32 oz</p></li><li><p>Great Value Steamable Sweet Potatoes, 10 oz (2 units)</p></li><li><p>Great Value Mini Marshmallows Value Size, 16 oz</p></li><li><p>Pillsbury Crescent Rolls Original, 16 ct, 16 oz</p></li><li><p>Ocean Spray Jellied Cranberry Sauce, 14 Oz &amp; Ocean Spray Whole Berry Cranberry Sauce, 14 Oz (averaged)</p></li><li><p>Great Value Whole Milk, 1 Gallon, 128 Fl. Oz.</p></li><li><p>Great Value Whipped Heavy Cream, 6.5 oz</p></li><li><p>LIBBY'S® Easy Pumpkin Pie Mix 30 oz.</p></li><li><p>Pillsbury Refrigerated Pie Crusts, 2 Ct, 14.1 oz Box</p></li></ul><p>Hard cider:</p><ul data-rte-list="default"><li><p>Angry Orchard Crisp Apple Hard Cider, 6 pack, 12 fl oz</p></li></ul></div></div></div></div></div></div>

        

        
          
        
        
          
        
      </div>

      
    </div>
  
</article>

</div>
    </div>
  </div>
</section>

  
</article>

          
          
            

          
          
        
      </div></div>]]>
            </description>
            <link>https://www.viscachadata.com/research/thanksgiving-prices</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201889</guid>
            <pubDate>Tue, 24 Nov 2020 19:10:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Love Interfaces]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201818">thread link</a>) | @SmooL
<br/>
November 24, 2020 | https://lucassimpson.com/blog/2020-11-20/why-I-love-interfaces/ | <a href="https://web.archive.org/web/*/https://lucassimpson.com/blog/2020-11-20/why-I-love-interfaces/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog-post"><p>Ahhh, interfaces! Also known as APIs / protocols / behaviours / your-favorite-languages-jargon-term-here. The source of plenty of pain, much rejoicing, and far too much discussion. I plan on contributing, here and now, to that third category. </p> <p>Why do we use interfaces? People will usually give you the standard reasons: it's easier to test, it enforces boundaries and seperation of concers, it decouples components. All of these are great, but none of those are my <em>favorite</em> reason to use interfaces. </p> <p>I love interfaces because they protect me from your shitty code.</p> <p>Did you use 13 spinlocks, all beautifully choreographed to keep 7 seperate maps in sync? Did you start multiple background threads, which all poll some resource far too frequently in a desparate attempt to stay up to date? Is your codes control flow best viewed in the fourth dimension? Maybe you really went out there and started using the <a href="http://antipatterns.com/lavaflow.htm">lava design pattern?</a>. Guess what, I don't care!</p> <p>Let me tell you a story. Junior Dev Dave joins a new software team, learns the basics of the code base, and instead of just fixing &amp;&amp;/|| improving other parts, it's now time for him to create his first component from scratch. Does he immediately dive into it and start experimenting with various implementations? NO! Senior Dev Sarah tells him to first specify the <em>contract</em> that this new component will have with the rest of the codebase. She then spends quality time with him to make sure it's a good one, and then promplty fucks off and repeats this entire allegory with someone else. Senior Dev Sarah does this with confidence, because the only part of her application that really matters, the interface, is done! Junior Dev Dave is free to play in his little sandbox in the corner and do whatever he likes! </p> <p>There's an implicit assumption here that whatever interface Junior Dev Dave comes up with will actually work. I think that's a safe assumption; anyone who's a decent enough programmer knows that making things work is <em>not</em> the hard part. The hard part is ensuring, as the software grows, that with added new features, complexity grows as close as possible to a factor of <code>O(N)</code> instead of <code>O(N^2)</code>. How do you do that? You guessed it, <em>interfaces</em>.</p> <p>A smart person once said "Good abstraction is as little abstraction as possible". Notice they didn't say <em>no</em> abstraction. Interfaces are the dividing walls, the geopolitical barriers, and the defensive design pattern you've been wanting ever since you took a look at your teammates idea of "good" implementation and thought to yourself "wtf". So use them; hell, abuse them. As long as it's all hidden behind a good interface, it's all the same to me. </p> <p><em>"Well then, get your shit together. Get it all together. And put it in a backpack. All your shit. So it’s together. And if you gotta take it somewhere, take it somewhere, you know, take it to the shit store and sell it… Or put it in a shit museum, I don’t care what you do, you just gotta get it together. And then put it behind an interface"</em> -Morty, adapted</p></div></div>]]>
            </description>
            <link>https://lucassimpson.com/blog/2020-11-20/why-I-love-interfaces/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201818</guid>
            <pubDate>Tue, 24 Nov 2020 19:05:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A new superfast exoplanet camera]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201817">thread link</a>) | @finphil
<br/>
November 24, 2020 | https://nuadox.com/post/635693409202536448/novel-exoplanet-camera | <a href="https://web.archive.org/web/*/https://nuadox.com/post/635693409202536448/novel-exoplanet-camera">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="635693409202536448">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/635693409202536448/novel-exoplanet-camera"><h2>A new superfast exoplanet camera</h2></a>
                                <figure data-orig-height="1057" data-orig-width="1920"><img src="https://64.media.tumblr.com/51150d52a0234fec8b7b74eb000dbd40/40229b4b844f5ab1-9d/s1280x1920/801ebf594900e52284fa80ea3c1c36c485264928.jpg" data-orig-height="1057" data-orig-width="1920" width="1280" height="705" alt="image"></figure><p><b>- By <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.news.ucsb.edu%2Fcontact-us&amp;t=YjlhNGVhMzgyYTFhOWY4M2FhNDc4ZDdiM2FkN2YxMWM0M2RmNTBjMyxtbzhUNk9leQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F635693409202536448%2Fnovel-exoplanet-camera&amp;m=0&amp;ts=1606465776">Harrison Tasoff</a> , <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.ucsb.edu%2F&amp;t=M2YxZmRmMDBmNmU1YjMyMTUwMzliNjQ0YzUwOTVmOWZiNjllM2VjNixtbzhUNk9leQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F635693409202536448%2Fnovel-exoplanet-camera&amp;m=0&amp;ts=1606465776">UC Santa Barbara</a> -</b></p><p>In the years since astronomers discovered the first exoplanet — a planet that orbits a star outside the solar system — more than 4,000 have been observed. Usually, their presence is given away by the slight effects they have on their parent stars, which vastly outshine them. For a decade and half, scientists have been trying to image exoplanets directly, but the Earth’s atmosphere presents a major impediment when they attempt to leverage large ground-based telescopes.</p><p>Now, a team of U.S. and Japanese scientists and engineers that includes researchers at UC Santa Barbara have developed a new exoplanet-hunting camera. Deployed at the Subaru Telescope on Maunakea, Hawai’I, the device is the world’s largest superconducting camera by pixel count and will pave the way for direct imaging of extra-solar planets in the near future. An instrument paper appearing in Publications of the Astronomy Society of the Pacific announced the new device to the astronomical community.</p><p>Constructed by researchers in the lab of Professor <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.physics.ucsb.edu%2Fpeople%2Fbenjamin-mazin&amp;t=MmJmZDI2ODhlYmQ0YWZlMjk0NmJhZWFjYmRlZTM4MWIxMjhhNTQ4MSxtbzhUNk9leQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F635693409202536448%2Fnovel-exoplanet-camera&amp;m=0&amp;ts=1606465776">Ben Mazin</a>, the MKID Exoplanet Camera (MEC) uses Microwave Kinetic Inductance Detectors (MKIDs) to enable scientists to directly image exoplanets and disks around bright stars. The detector runs at a brisk 90 millikelvin — just a touch over absolute zero — and is the first permanently deployed superconducting camera that operates in the optical and near infrared spectrum.</p><figure data-orig-height="897" data-orig-width="1000"><img src="https://64.media.tumblr.com/a0d9edf6defa86e4fd44ca29642a9626/40229b4b844f5ab1-b8/s1280x1920/1cb9e615f72e7e1bf5d54e1c4d37129435105c2e.jpg" data-orig-height="897" data-orig-width="1000" width="1000" height="897" alt="image"></figure><p><i>Image: The 20440 pixel MKID device designed for MKID Exoplanet Camera is the highest pixel-count superconducting detector array at any wavelength. Credit: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.news.ucsb.edu%2F2020%2F020103%2Fhere-s-looking-you-mkid&amp;t=MzgyZTExNGM3ZjM5ZDg5OTYwODFkNDY3ODFlMmYyODY5Yjg0NWE4YyxtbzhUNk9leQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F635693409202536448%2Fnovel-exoplanet-camera&amp;m=0&amp;ts=1606465776">Courtesy image</a>.</i><br></p><p>“In exoplanet direct imaging, you are attempting to image planets that are millions of times fainter than their parent stars,” said <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.physics.ucsb.edu%2Fpeople%2Fsarah-steiger&amp;t=Mzc2OGYzNjZiZDVmMzg5ZTgxNDZhYWI2NTIwNzZhZTZhZTYwYzM3OCxtbzhUNk9leQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F635693409202536448%2Fnovel-exoplanet-camera&amp;m=0&amp;ts=1606465776">Sarah Steiger</a>, a doctoral student in the Mazin lab who worked on the MKID pipeline. “It’s the equivalent of trying to see a firefly next to a fully lit football stadium from a plane.</p><p>“What’s more, if you are doing this from the ground, you must look through Earth’s turbulent atmosphere,” she continued. This turbulence is what causes stars to twinkle in the night sky, and is a perennial headache to astronomers, distorting images and casting starlight on dim exoplanets.</p><p>“It’s a constant battle to prevent stray light from the star from completely overwhelming the planet,” said doctoral student <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fweb.physics.ucsb.edu%2F%7Ebmazin%2Fpeople%2Fgrads.html&amp;t=ZDYyNWI3ZjEwODE4MWM0NDU4YjIwYzg5ODE1OWFhNWM5MmE3ZTUwOCxtbzhUNk9leQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F635693409202536448%2Fnovel-exoplanet-camera&amp;m=0&amp;ts=1606465776">Neelay Fruitwala</a>.</p><p>Modern observatories use adaptive optics to correct these distortions. The systems rely on rapid feedback loops and complex algorithms to bend a telescope’s mirror thousands of times per second in ways that counteract the effects of the atmosphere, enabling scientists to recover an image as though the telescope were in space.</p><p>“These very complicated adaptive optics systems let us discover planets like those in HR 8799, which is a system with four planets all above Jupiter’s mass orbiting in it,” said Mazin. But they can also scatter light, which obscures faint exoplanets. “We found that just using adaptive optics by itself was only going to find us a handful of planets — namely those still glowing with the heat of their formation — which are just not that common in our stellar neighborhood.”</p><p>Another advantage of MKIDs lies in their ability to determine the energy of each photon that hits the detector. “This allows us not only to determine a planet’s brightness,” Steiger said, “but also to get a spectrum (the brightness as a function of energy), which can reveal additional information about an exoplanet’s properties, such as its age, mass and potentially atmospheric composition.”</p><p>More advanced detectors employ a coronagraph, which blocks out some of the light from the host star so scientists can better discern the light reflecting off the planet itself. This is important for imaging nearby systems, most of which aren’t particularly young. However, getting the best performance from such a setup requires extremely good adaptive optics.</p><p>“These instruments are sort of hitting a wall right now,” Mazin said. “They can block out the light from the star by about a factor of a million, but the problem is that most planets are more like a billion times fainter than their parent star.”</p><p>One advantage of MKIDs over traditional cameras is that they are very fast. These detectors can read out data thousands of times per second, which are the speeds required to keep up with an adaptive optics system, Steiger explained. This allows an MKID to further clean up an image by communicating with the observatory’s adaptive optics system to remove some of the scattered and diffracted starlight. This pushes the limits of how faint an exoplanet can be imaged.</p><p>The MKID Exoplanet Camera should expand the range of exoplanets that astronomers can directly image to those near Earth. These are the most important because we can characterize them in greater detail, said coauthor Olivier Guyon, the project scientist in charge of the Subaru Coronagraphic Extreme Adaptive Optics (SCExAO) instrument.</p><p>The ultimate goal is to search for evidence of life, and the MEC is an important step in this journey. “We’re not going to be able to do that with Subaru, or with any of the current telescopes, because they’re just a bit too small,” Guyon said. “But we’re preparing for the next big step, which is to deploy exoplanet imaging cameras on larger telescopes such as the Thirty Meter Telescope. When those telescopes come online, the same technologies, the same camera, the same tricks will allow us to actually look for life.”</p><p>That said, there’s still a lot of work left to do, mostly on the MEC’s software and algorithms. The team received a large grant from the Heising-Simons Foundation to tackle this problem and further develop fast optical correction over the next few years. “We’re throwing every trick in the book at this,” Mazin said, “and we’re developing new tricks as well.”</p><p>The authors acknowledge the significant cultural role and reverence that the summit of Maunakea holds within the Hawaiian community and said they feel fortunate to have the opportunity to conduct observations from this mountain. The development of SCExAO was supported by JSPS; the Astrobiology Center of NINS, Japan; and the National Astronomical Observatory of Japan.</p><p>–</p><p><b>Source:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.news.ucsb.edu%2F2020%2F020103%2Fhere-s-looking-you-mkid&amp;t=MzgyZTExNGM3ZjM5ZDg5OTYwODFkNDY3ODFlMmYyODY5Yjg0NWE4YyxtbzhUNk9leQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F635693409202536448%2Fnovel-exoplanet-camera&amp;m=0&amp;ts=1606465776">University of California, Santa Barbara</a></b></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/627551986964889600/50-new-exoplanets-identified-by-ai-from-previous">50 new exoplanets identified by AI from previous NASA data</a></p><p><a href="https://nuadox.com/post/188859348972/nasa-tess-exoplanets">NASA’s TESS spacecraft is finding hundreds of exoplanets – and is poised to find thousands more</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/exoplanet">exoplanet</a>
                                    
                                        <a href="https://nuadox.com/tagged/planet">planet</a>
                                    
                                        <a href="https://nuadox.com/tagged/space">space</a>
                                    
                                        <a href="https://nuadox.com/tagged/camera">camera</a>
                                    
                                        <a href="https://nuadox.com/tagged/optics">optics</a>
                                    
                                        <a href="https://nuadox.com/tagged/astronomy">astronomy</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/635693409202536448/novel-exoplanet-camera</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201817</guid>
            <pubDate>Tue, 24 Nov 2020 19:05:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Email a Dumpster Fire]]>
            </title>
            <description>
<![CDATA[
Score 920 | Comments 249 (<a href="https://news.ycombinator.com/item?id=25201798">thread link</a>) | @bschne
<br/>
November 24, 2020 | https://hey.science/dumpster-fire/ | <a href="https://web.archive.org/web/*/https://hey.science/dumpster-fire/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>What's this experiment all about?</p>
    <p>Well, 2020's been a rough year. An absolute dumpster fire of a year for a lot of people.</p>
    <p>That's when it came to us. Can email be a conduit for catharsis? If you could type out an email, press send, and see it being consumed in an actual dumpster fire, would it help reclaim a little bit of what we've lost?</p>
    <p>Let's find out.</p>
    <p>P.S. We'll only use your email address to notify you about your burn. That's it, the end.</p>
    <p>P.P.S. We're offsetting by 3x every bit of CO2 this creates via <a href="https://www.cooleffect.org/content/project/native-alaskans-saving-lands" target="_blank" rel="noopener nofollow">Cool Effect</a>.</p>
  </div></div>]]>
            </description>
            <link>https://hey.science/dumpster-fire/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201798</guid>
            <pubDate>Tue, 24 Nov 2020 19:04:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hello World Node.js Deployed to AWS Fargate with Auto-Scaling]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201748">thread link</a>) | @yamoriyamori
<br/>
November 24, 2020 | https://matthewkindzerske.com/2020/11/19/node-js-web-app-deployed-to-aws-fargate-w-auto-scaling/ | <a href="https://web.archive.org/web/*/https://matthewkindzerske.com/2020/11/19/node-js-web-app-deployed-to-aws-fargate-w-auto-scaling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-171">
	<!-- .entry-header -->

	
		<div>
			
<p><strong>TL/DR:</strong> I present a detailed how-to for deploying a (hello world) Node.js web application (in container image form) onto <a href="https://aws.amazon.com/about-aws/whats-new/2017/11/introducing-aws-fargate-a-technology-to-run-containers-without-managing-infrastructure/">AWS Fargate</a> with auto-scaling.  This could be useful for the start of your project and then add subsequent layers for your purposes, or bits and pieces of this how-to could help solve a particular problem you’re facing.</p>



<h2>Motivation and Background</h2>



<p>It is not enough to be able to write software.&nbsp; One must also be able to deploy.&nbsp; I’m reminded of the Steve Jobs quote, <a href="https://www.creativethinkinghub.com/steve-jobs-was-right-real-artists-ship/">“real artists ship.”</a>&nbsp; Even if you wrote the next killer social media website, it means nothing unless you can get it out the door, hosted, and in a stable (and scalable!) production environment.&nbsp; This post is an extracted walk-through of how I used the new AWS service Fargate to host a side project.</p>



<p>What is <a href="https://aws.amazon.com/fargate/">Fargate</a>?&nbsp; It’s a generalized container orchestration service.&nbsp; “Generalized” here means that AWS has taken care of the underlying infrastructure usually associated with the creation of a ‘cluster’ (<a href="https://thenewstack.io/aws-fargate-through-the-lens-of-kubernetes/">in the kubernetes sense</a>) of computing resources.&nbsp; Bring your own container (the portable form of your application) and through configuration in the AWS console the application can be deployed into an auto scaling cluster, with integrations for Application Load Balancing, Certificate Management (ACM) for HTTPS, and DNS (Route 53).&nbsp; And what’s really nice is the container can be given an IAM role to call other authorized AWS Services.</p>



<p>Here’s the user story for this article, to help bridge the developer and product owner / business gap:</p>



<blockquote><p><strong>As an</strong> application/DevOps engineer, <strong>I want</strong> to deploy my containerized application to an orchestration service (AWS Fargate), <strong>so that</strong> I can avoid the headaches and complexity of provisioning low level services (networking, virtual machines, kubernetes) and also gain auto scalability for my production/other environment.</p><cite>– an application/DevOps engineer</cite></blockquote>



<h2>The Big Picture</h2>



<p>From the Node.js source all the way to a live app, here’s how the pieces fit together in one picture.  (The draw.io file is included in <a href="https://github.com/yamori/nodejs_hello_world_dockered">my github repo</a>.)</p>



<figure><img data-attachment-id="225" data-permalink="https://matthewkindzerske.com/big-picture-fargate-demo/" data-orig-file="https://matthewkindzerske.files.wordpress.com/2020/11/big-picture-fargate-demo.png" data-orig-size="809,469" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="big-picture-fargate-demo" data-image-description="" data-medium-file="https://matthewkindzerske.files.wordpress.com/2020/11/big-picture-fargate-demo.png?w=300" data-large-file="https://matthewkindzerske.files.wordpress.com/2020/11/big-picture-fargate-demo.png?w=636" src="https://matthewkindzerske.files.wordpress.com/2020/11/big-picture-fargate-demo.png?w=809" alt="" srcset="https://matthewkindzerske.files.wordpress.com/2020/11/big-picture-fargate-demo.png 809w, https://matthewkindzerske.files.wordpress.com/2020/11/big-picture-fargate-demo.png?w=150 150w, https://matthewkindzerske.files.wordpress.com/2020/11/big-picture-fargate-demo.png?w=300 300w, https://matthewkindzerske.files.wordpress.com/2020/11/big-picture-fargate-demo.png?w=768 768w" sizes="(max-width: 809px) 100vw, 809px"><figcaption>Fig. 1: Node.js app, Image Repository, Fargate, &amp; ALB</figcaption></figure>



<h2>Node.JS Web App</h2>



<p>A very basic ‘hello world’ app can be pulled from <a href="https://github.com/yamori/nodejs_hello_world_dockered">my github repo</a>:</p>



<pre><code>git clone \
https://github.com/yamor/nodejs_hello_world_dockered.git &amp;&amp; \
cd nodejs_hello_world_dockered &amp;&amp; \
npm install

# Give it a go and run
npm start
# ... then access at localhost:3000</code></pre>



<figure><img data-attachment-id="229" data-permalink="https://matthewkindzerske.com/screen-shot-2020-11-18-at-3-27-44-pm/" data-orig-file="https://matthewkindzerske.files.wordpress.com/2020/11/screen-shot-2020-11-18-at-3.27.44-pm.png" data-orig-size="619,253" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-11-18-at-3.27.44-pm" data-image-description="" data-medium-file="https://matthewkindzerske.files.wordpress.com/2020/11/screen-shot-2020-11-18-at-3.27.44-pm.png?w=300" data-large-file="https://matthewkindzerske.files.wordpress.com/2020/11/screen-shot-2020-11-18-at-3.27.44-pm.png?w=619" src="https://matthewkindzerske.files.wordpress.com/2020/11/screen-shot-2020-11-18-at-3.27.44-pm.png?w=619" alt="" srcset="https://matthewkindzerske.files.wordpress.com/2020/11/screen-shot-2020-11-18-at-3.27.44-pm.png 619w, https://matthewkindzerske.files.wordpress.com/2020/11/screen-shot-2020-11-18-at-3.27.44-pm.png?w=150 150w, https://matthewkindzerske.files.wordpress.com/2020/11/screen-shot-2020-11-18-at-3.27.44-pm.png?w=300 300w" sizes="(max-width: 619px) 100vw, 619px"><figcaption>Fig. 2: Node.js application up and running</figcaption></figure>



<p>It’s a very basic application:</p>



<ul><li>Built from <code>npx express-generator</code></li><li>Changed the <code>routes/index.js </code>‘title’ variable to ‘nodejs_hello_world_dockered’</li><li>Added a <code>Dockerfile</code>, which we’ll walk through now…</li></ul>



<h2>Dockerfile</h2>



<pre><code>$ cat Dockerfile 
 FROM node:12.18.2-alpine3.9
 WORKDIR /usr/app
 COPY . .
 RUN npm install --quiet
 RUN npm install pm2 -g
 EXPOSE 3000
 CMD ["pm2-runtime", "start", "./bin/www", "--name", "nodejs_hello_world_dockered"]</code></pre>



<p>Some explanation:</p>



<ul><li>The <code>COPY</code> command is copying all the Node.js source into the container</li><li><code><a href="https://pm2.keymetrics.io/">pm2</a></code> is installed for process management, reload capabilities, and it’s nice for production purposes adding a layer on top of the core Node.js code, and not necessary for small development efforts.&nbsp; But importantly, the container is using <code>pm2-runtime</code> which <a href="https://stackoverflow.com/questions/53962776/whats-the-difference-between-pm2-and-pm2-runtime">is needed to keep a container alive</a>.</li></ul>



<h2>Docker Commands</h2>



<p><strong>Assumption</strong>: docker is installed and running.</p>



<pre><code>$ docker -v
Docker version 19.03.6-ce, build 369ce74</code></pre>



<p>Docker build, run then a <code>curl</code> to test.</p>



<pre><code><code># this command builds the image that is ultimately 
# deployed to fargate</code>
docker build -t nodejs_hello_world_dockered . 

docker run -d -p 3000:3000 nodejs_hello_world_dockered

$ curl localhost:3000
&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;nodejs_hello_world_dockered&lt;/title&gt;&lt;link rel="stylesheet" href="/stylesheets/style.css"&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;nodejs_hello_world_dockered&lt;/h1&gt;&lt;p&gt;Welcome to nodejs_hello_world_dockered&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</code></pre>



<p>When done, kill the running container but keep the image.</p>



<pre><code><code># kills all running containers</code>
docker container kill $(docker ps -q)

<code># you should see our nodejs_hello_world_dockered</code>
docker images</code></pre>



<h2>Push the Image to a Container Registry</h2>



<p><strong>Tip</strong>: Use an EC2 or Devops/pipeline within AWS (and not your local machine) for image building and pushing, as uploads from a slow or residential network can take a long time.&nbsp; Take proximity into account for your approach/strategy for large data movements.  This tip should have preceded the Docker section above, but the rationale might not have become apparent until you attempt to push an image to a registry and find that it’s way too slow.</p>



<p><strong>Assumption</strong>: the AWS CLI is installed and has an account with appropriate authorizations.</p>



<pre><code>$ aws --v
 aws-cli/1.16.30 ...</code></pre>



<p><strong>Assumption</strong>: you have an ECR repository <a href="https://docs.aws.amazon.com/AmazonECR/latest/userguide/repository-create.html">created</a>.</p>



<p>Now to push and it’s just two commands (but preceded by an AWS ECR login), to label the image then upload it.&nbsp; Notice the label contains the repositories address.</p>



<pre><code>aws ecr get-login --no-include-email --region us-east-1 \
| /bin/bash

docker tag nodejs_hello_world_dockered:latest \
1234567890.dkr.ecr.us-east-1.amazonaws.com/fargate_demo:latest

docker push \
1234567890.dkr.ecr.us-east-1.amazonaws.com/fargate_demo:latest</code></pre>



<h2>AWS &amp; Fargate</h2>



<p>Congratulations, at this point the application is in a nice and portable (container) format and residing in an AWS ECR repository.&nbsp; The Fargate configuration will consist of the following:</p>



<ul><li><strong>Task</strong>: defines the container configuration</li><li><strong>Cluster</strong>: regional grouping of computing resource</li><li><strong>Service</strong>: a scheduler which maintains the running Task(s) within the Cluster…<ul><li>Auto-scaling will be configured at this level of the stack and will scale up the number of Tasks as configured</li></ul></li></ul>



<p>The remaining AWS service is a Load Balancer which is separate from Fargate.  It will be described later as it exposes the application to the greater web.</p>



<h2>Task Definition</h2>



<p>Access the AWS Console &gt; (ECS) Elastic Container Service &gt; (left side menu) Task Definitions &gt; click ‘Create new Task Definition’.  On the next screen click ‘Fargate’ and then ‘Next Step’.</p>



<figure><img data-attachment-id="192" data-permalink="https://matthewkindzerske.com/004/" data-orig-file="https://matthewkindzerske.files.wordpress.com/2020/11/004.png" data-orig-size="887,499" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="004" data-image-description="" data-medium-file="https://matthewkindzerske.files.wordpress.com/2020/11/004.png?w=300" data-large-file="https://matthewkindzerske.files.wordpress.com/2020/11/004.png?w=636" src="https://matthewkindzerske.files.wordpress.com/2020/11/004.png?w=887" alt="" srcset="https://matthewkindzerske.files.wordpress.com/2020/11/004.png 887w, https://matthewkindzerske.files.wordpress.com/2020/11/004.png?w=150 150w, https://matthewkindzerske.files.wordpress.com/2020/11/004.png?w=300 300w, https://matthewkindzerske.files.wordpress.com/2020/11/004.png?w=768 768w" sizes="(max-width: 887px) 100vw, 887px"><figcaption>Fig. 3: Fargate launch types</figcaption></figure>



<p>On the next screen, fill in the following:</p>



<ul><li><strong>Name</strong>: I have called it ‘fargate-demo-task-definition’</li><li><strong>Task Role</strong>: this can be left as ‘none’, but I can’t stress enough how versatile this is.&nbsp; If your Node.js app needs to make call to DynamoDB, Simple Email Service, or any other Amazon service, you can enable it here.&nbsp; Using the node package <code><a href="https://www.npmjs.com/package/aws-sdk">aws-sdk</a></code> will <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html">automagically</a> query a resource URI at runtime to gain credentials, thus granting authorizations to your app for the role specified.&nbsp; This is very cool.</li><li><strong>Task Execution IAM Role</strong>: leave as the default ‘ecsTaskExecutionRole’, see the image below for the succinct AWS explanation</li><li><strong>Task Size</strong>: this provides a lot of room for tuning, but for this simple Node.js app I’ve plugged in 0.5GB and 0.25CPU respectively for memory and CPU allocation.</li><li>Add Container:<ul><li><strong>Container Name</strong>: I have called it ‘fargate-demo-container-image’</li><li><strong>Image</strong>: Use the image URI from the end of the ‘Upload to Container Registry Section’ which was of the form ‘1234567890.dkr.ecr.us-east-1.amazonaws.com/fargate_demo:latest’</li><li><strong>Memory Limits</strong>: AWS recommends 300MiB to start for web apps.</li><li><strong>Port Mappings</strong>: 3000, for the container port exposing the Node.js application.</li><li>…then click ‘Add’.</li></ul></li><li><strong>Tags</strong>: always try to tag your AWS resources.</li><li>…then click ‘Create’.</li></ul>



<h2>Cluster</h2>



<p>Access AWS ECS and click ‘Create Cluster’.</p>



<figure><img data-attachment-id="195" data-permalink="https://matthewkindzerske.com/001/" data-orig-file="https://matthewkindzerske.files.wordpress.com/2020/11/001.png" data-orig-size="1037,206" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="001" data-image-description="" data-medium-file="https://matthewkindzerske.files.wordpress.com/2020/11/001.png?w=300" data-large-file="https://matthewkindzerske.files.wordpress.com/2020/11/001.png?w=636" src="https://matthewkindzerske.files.wordpress.com/2020/11/001.png?w=1024" alt="" srcset="https://matthewkindzerske.files.wordpress.com/2020/11/001.png?w=1024 1024w, https://matthewkindzerske.files.wordpress.com/2020/11/001.png?w=150 150w, https://matthewkindzerske.files.wordpress.com/2020/11/001.png?w=300 300w, https://matthewkindzerske.files.wordpress.com/2020/11/001.png?w=768 768w, https://matthewkindzerske.files.wordpress.com/2020/11/001.png 1037w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Fig. 4: Cluster creation</figcaption></figure>



<p>There are a lot of different configurations for computing resources, networking, and scaling but we’ll stick with the simple case and select Networking Only.</p>



<figure><img data-attachment-id="197" data-permalink="https://matthewkindzerske.com/002/" data-orig-file="https://matthewkindzerske.files.wordpress.com/2020/11/002.png" data-orig-size="675,630" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="002" data-image-description="" data-medium-file="https://matthewkindzerske.files.wordpress.com/2020/11/002.png?w=300" data-large-file="https://matthewkindzerske.files.wordpress.com/2020/11/002.png?w=636" src="https://matthewkindzerske.files.wordpress.com/2020/11/002.png?w=675" alt="" srcset="https://matthewkindzerske.files.wordpress.com/2020/11/002.png 675w, https://matthewkindzerske.files.wordpress.com/2020/11/002.png?w=150 150w, https://matthewkindzerske.files.wordpress.com/2020/11/002.png?w=300 300w" sizes="(max-width: 675px) 100vw, 675px"><figcaption>Fig. 5: Cluster templates</figcaption></figure>



<p>On the next screen, give it a name such as ‘fargate-demo-cluster’.&nbsp; Leave the ‘Create VPC’ unchecked as we can use the default one but if you’re deploying an intensive app you may want a dedicated VPC.&nbsp; Add any tags.&nbsp; (I highly recommend adding tags so you can quickly search and find associated resources for your projects.)</p>



<h2>ALB – Application Load Balancer</h2>



<p>Access the ALB service and click ‘Create’: EC2 &gt; (left side menu) Load Balancers &gt; ‘Create’ &gt; (Application Load Balancer / HTTP / HTTPS) ‘Create’.</p>



<p>On the next configuration screen, make the following changes:</p>



<ul><li><strong>Name</strong>: I have called it ‘fargate-demo-ALB’</li><li><strong>Listeners</strong>: for now we’ll keep HTTP port 80, though this target group will be deleted eventually.&nbsp; (The ALB creation wizard requires at least one target group.)<ul><li>(Not included in this article, but once the entire system is up it’s easy to add a second listener for HTTPS port 443 while also including a certificate from <a href="https://aws.amazon.com/certificate-manager/">ACM</a>.)</li></ul></li><li><strong>Availability Zones</strong>: choose the intended VPC and select multiple subnets which will eventually become contain the targets for this ALB</li></ul>



<p>Click ‘Next: Configure Security Groups’, though an intermediary page will warn about the absence of a ‘secure listener’.&nbsp; We’ll click through this for now, but as mentioned above a 443 listener can be added in the future (but not part of this article).</p>



<p>On the next page, we’ll ‘Create New Security Group’ and call it ‘fargate-demo-security-group’.&nbsp; Leave the default TCP port of 80, and notice that it’s open to any IP source (0.0.0.0/0, ::/0).&nbsp; Then click ‘Next: Configure Routing’.</p>



<p>On this next page, give the target group a name (fargate-demo-target-group).&nbsp; In the screengrab below, it’s important to understand that the ALB will regularly check for the application providing an <a href="https://en.wikipedia.org/wiki/List_of_HTTP_status_codes#2xx_success">HTTP status code</a> 200 at the specified path.&nbsp; The Node.js app was created to offer a basic response on the root path so the following configuration is fine.</p>



<figure><img data-attachment-id="202" data-permalink="https://matthewkindzerske.com/003/" data-orig-file="https://matthewkindzerske.files.wordpress.com/2020/11/003.png" data-orig-size="575,395" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="003" data-image-description="" data-medium-file="https://matthewkindzerske.files.wordpress.com/2020/11/003.png?w=300" data-large-file="https://matthewkindzerske.files.wordpress.com/2020/11/003.png?w=575" src="https://matthewkindzerske.files.wordpress.com/2020/11/003.png?w=575" alt="" srcset="https://matthewkindzerske.files.wordpress.com/2020/11/003.png 575w, https://matthewkindzerske.files.wordpress.com/2020/11/003.png?w=150 150w, https://matthewkindzerske.files.wordpress.com/2020/11/003.png?w=300 300w" sizes="(max-width: 575px) 100vw, 575px"><figcaption>Fig. 6: ALB health checks</figcaption></figure>



<p>Click ‘Next: Register Targets’, but we’ll skip that page and click ‘Next: Review’ then ‘Create’!</p>



<h2>Service</h2>



<p>The Fargate Service will provide an instance of the Task Definition to be run in the Cluster.&nbsp; Navigate to AWS Console &gt; ECS &gt; (left side menu) Clusters &gt; then click on the Cluster we created “fargate-demo-cluster”.&nbsp; And at the bottom of the screen will be a tag for ‘Services’, click the button ‘Create’.</p>



<figure><img data-attachment-id="204" data-permalink="https://matthewkindzerske.com/007/" data-orig-file="https://matthewkindzerske.files.wordpress.com/2020/11/007.png" data-orig-size="639,258" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="007" data-image-description="" data-medium-file="https://matthewkindzerske.files.wordpress.com/2020/11/007.png?w=300" data-large-file="https://matthewkindzerske.files.wordpress.com/2020/11/007.png?w=636" src="https://matthewkindzerske.files.wordpress.com/2020/11/007.png?w=639" alt="" srcset="https://matthewkindzerske.files.wordpress.com/2020/11/007.png 639w, https://matthewkindzerske.files.wordpress.com/2020/11/007.png?w=150 150w, https://matthewkindzerske.files.wordpress.com/2020/11/007.png?w=300 300w" sizes="(max-width: 639px) 100vw, 639px"><figcaption>Fig…</figcaption></figure></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://matthewkindzerske.com/2020/11/19/node-js-web-app-deployed-to-aws-fargate-w-auto-scaling/">https://matthewkindzerske.com/2020/11/19/node-js-web-app-deployed-to-aws-fargate-w-auto-scaling/</a></em></p>]]>
            </description>
            <link>https://matthewkindzerske.com/2020/11/19/node-js-web-app-deployed-to-aws-fargate-w-auto-scaling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201748</guid>
            <pubDate>Tue, 24 Nov 2020 19:01:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Rainbow Tables Work]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25201513">thread link</a>) | @susam
<br/>
November 24, 2020 | http://kestas.kuliukas.com/RainbowTables/ | <a href="https://web.archive.org/web/*/http://kestas.kuliukas.com/RainbowTables/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><h6><a href="http://kestas.kuliukas.com/">kestas.kuliukas.com</a></h6>
<h3>How Rainbow Tables work</h3>
<p>I found the creator of Rainbow Table's paper, aimed at cryptanalysts,
was pretty inaccessible considering the simplicity and elegance of
Rainbow Tables, so this is an overview of it for a layman.</p>

<hr>

<p>Hash functions map plaintext to hashes so that you can't tell a
plaintext from its hash.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/1.png"></center>

<p>If you want to find a given plaintext for a certain hash there are two
simple methods:<br>
- Hash each plaintext one by one, until you find the hash.<br>
- Hash each plaintext one by one, but store each generated hash in a
sorted table so that you can easily look the hash up later without
generating the hashes again</p>

<p>Going one by one takes a very long time, and storing each hash takes an
amount of memory which simply doesn't exist (for all but the smallest of
plaintext sets). Rainbow tables are a compromise between pre-computation
and low memory usage.</p>

<p>The key to understanding rainbow tables is understanding the
(unhelpfully named) reduction function.<br>
A hash function maps plaintexts to hashes, the reduction function maps
hashes to plaintexts.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/2.png"></center>


<p>It's important to note that it does the reverse of a hash function
(mapping hashes to plaintexts), but it is /not/ an inverse hash
function. The whole purpose of hash functions is that inverse hash
functions can't be made. If you take the hash of a plaintext, and take
the reduction of the hash, it will not give you the original plaintext;
but some other plaintext.</p>

<p>If the set of plaintexts is [0123456789]{6} (we want a rainbow table of
all numeric passwords of length 6), and the hashing function is MD5(), a
hash of a plaintext might be MD5("493823") -&gt;
"222f00dc4b7f9131c89cff641d1a8c50".<br>
In this case the reduction function R() might be as simple as taking the
first six numbers from the hash; R("222f00dc4b7f9131c89cff641d1a8c50")
-&gt; "222004".<br>
We now have generated another plaintext from the hash of the previous
plaintext, this is the purpose of the reduction function.</p>


<p>Hashes are one-way functions, and so are reduction functions. The chains
which make up rainbow tables are chains of one way hash and reduction
functions starting at a certain plaintext, and ending at a certain hash.
A chain in a rainbow table starts with an arbitrary plaintext, hashes
it, reduces the hash to another plaintext, hashes the new plaintext, and
so on. The table only stores the starting plaintext, and the final hash
you choose to end with, and so a chain "containing" millions of hashes
can be represented with only a single starting plaintext, and a single
finishing hash.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/3.png"></center>


<p>After generating many chains the table might look something like:<br>
iaisudhiu -&gt; 4259cc34599c530b1e4a8f225d665802<br>
oxcvioix -&gt; c744b1716cbf8d4dd0ff4ce31a177151<br>
9da8dasf -&gt; 3cd696a8571a843cda453a229d741843<br>
[...]<br>
sodifo8sf -&gt; 7ad7d6fa6bb4fd28ab98b3dd33261e8f</p>

<hr>

<p>The chains are now ready to be used. We have a certain hash with an
unknown plaintext, and we want to check to see whether it is inside any
of the generated chains.</p>

<p>The algorithm is:<br>
</p><ul><li>Look for the hash in the list of final hashes, if it is there break
out of the loop.</li>
<li>If it isn't there reduce the hash into another plaintext, and hash the
new plaintext.</li>
<li>Goto the start.</li>
<li>If the hash matches one of the final hashes, the chain for which the
hash matches the final hash contains the original hash.</li></ul>
You can now get that chain's starting plaintext, and start hashing and
reducing it, until you come to the known hash along with its secret
plaintext.

<p>In this way you check through the hashes in the chains, which aren't
actually stored anywhere on disk, by iterating column by column through
the table of chains, backwards from the last column in the chain, to the
starting plaintext.</p>

<hr>
<p>If you wanted to check whether the hash exists in the last column of any 
of the chains you reduce and hash the given hash once, then check the 
generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a1.png"></center>

<p>You can check the second last column by reducing and hashing twice, 
then check the generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a2.png"></center>

<p>And the third is checked by reducing and hashing three times, 
then check the generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a3.png"></center>

<p>Supposing
a chain ending matches the generated hash the matching chain end might
contain the hash. The starting plaintext which was stored with the ending 
hash can be reduced and hashed until the correct plaintext is found within 
the chain.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a4.png"></center>

<hr>

<p>Collisions are the only problem with Rainbow Tables. Ironically
collisions are seen as a bad thing for hashing algorithms, but in the
case of Rainbow Tables a hashing algorithm which generates collisions
fairly regularly will be more secure.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/5.png"></center><br>
A given hash may be generated by multiple plaintexts (this is called a
collision), which is a big problem for chains because it causes chains
which start different to converge into one. Also you get loops, which
are caused when a hash is reduced to a plaintext that was hashed at a
previous point in the chain.<br>
<center><img src="http://kestas.kuliukas.com/RainbowTables/6.png"></center>


<p>Because of these collision problems there is no guarantee that there
will be a hash of a plaintext that will reduce to some other given
plaintext.<br>
If you have a simple list of hashes and corresponding plaintexts for
every plaintext in a set you will know that if you have not found the
hash in the generated hashes the plaintext that generated the hash is
not in the set.<br>
If you have a table of chains where the reduction function reduces
hashes into the set of plaintexts you could have trillions of chains
generated but you still may not have generated every plaintext in the
set you want to check. You can only say how probable it is that a table
of chains contains a certain plaintext, and this can approach 1 but will
probably never reach 1.<br>
If you have a rainbow table with 10 chains of length 100 you have hashed
1000 plaintexts, but even if there are only 100 plaintexts in the set of
desired plaintexts the 1000 hashes you have in the chains may not
contain all the desired hashes.</p>

<hr>

<p>The way collisions are handled is what sets Rainbow Tables apart from
its predecessor which was developed in 1980.</p>

<p>The predecessor solved the problem of certain plaintexts never being
reduced to by using many small tables. Each small table uses a different
reduction function. This doesn't solve the problem completely, but it
does help.<br>
To solve chain merges and loops each chain ended at a "distinct point";
a hash which was unique in some way, eg hashes where the first 4
characters are 0. The chains keep on going until it reaches a distinct
point. If two chains end up at the same distinct point then there has
been a collision somewhere in the chain, and one of the chains is
discarded. If a chain is generated for an unusually long time without
reaching a distinct point a loop is suspected (where a chain of hashes
ends up reducing and hashing to a previous hash in the chain).
The problem with this is that if there is a collision there is
potentially a whole branch which has to be cut off and won't make it
into the chains, and a loop will cause all the hashes which came before
the loop in the chain to be discarded.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/7.png"></center><br>
Also all the time spend generating that chain will be wasted, and by
ending only at distinct points you have chains of variable length. This
means that you may have to keep checking for a hash within especially
long chains long after the other chains have ended.

<hr>

<p>Rainbow tables differ in that they don't use multiple tables with
different reduction functions, they only use one table. However in
Rainbow Tables a different reduction function is used for each column.
This way different tables with different reduction functions aren't
needed, because different reduction functions are used within the same
table. It is still unlikely that all plaintexts in the desired set will
be hashed, but the chances are higher for a given number of chains.
Chain merges are much, much rarer, because collisions have to occur on
the same column. For a chain of length l the chance of a collision
causing a merge is reduced to 1/l. Loops are also solved, because if a
hash in a chain is the same as a previous hash it won't reduce to the
same plaintext.</p>

<p>The reason they're called Rainbow Tables is because each column uses a
different reduction function. If each reduction function was a different
color, and you have starting plaintexts at the top and final hashes at
the bottom, it would look like a rainbow (a very vertically long and
thin one).<br>
By using Rainbow Tables the only problem that remains is that you can
never be certain that the chains contain all the desired hashes, to get
higher success rates from a given Rainbow Table you have to generate
more and more chains, and get diminishing returns.</p>


<hr>

<p>I hope by explaining the Rainbow Table I haven't made them any less 
wonderful ...</p>

<hr>

<a name="improving"></a>
<h4>An easy way to improve on the "rainbowcrack" Rainbow Tables implementation</h4>
<p>This section probably goes a bit beyond where a layman would be comfortable, 
but if you're interested in the practical applications of the above theory or have some 
interest in cryptography read on..</p>

<p>The rainbowcrack application is how most people come to learn 
about Rainbow Tables, because it is the application which puts the 
theory above into code. It has been very successful, with many websites 
dedicated to generating rainbowcrack hash tables and letting users search them.</p>

<p>However there is a pretty clear way this application could be improved, 
very easily, in the sense that the generated tables would take up a lot less
disk space, but be equally as effective for breaking hashes:</p>

<p>Remember above that when you want to generate a certain chain 
you start from an arbitrary hash. This just means it doesn't matter where 
you choose to start from. The rainbowcrack application starts from a randomly 
generated 64-bit number. This number is then used to generate a chain which 
ultimately ends with a 128-bit hash, which is reduced to another 64-bit number.</p>

<p>Why use a randomly generated number as the starting point? A …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://kestas.kuliukas.com/RainbowTables/">http://kestas.kuliukas.com/RainbowTables/</a></em></p>]]>
            </description>
            <link>http://kestas.kuliukas.com/RainbowTables/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201513</guid>
            <pubDate>Tue, 24 Nov 2020 18:43:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What does it mean to “reconcile to cash”?]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201471">thread link</a>) | @qin
<br/>
November 24, 2020 | https://www.moderntreasury.com/journal/what-is-automatic-reconciliation | <a href="https://web.archive.org/web/*/https://www.moderntreasury.com/journal/what-is-automatic-reconciliation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Businesses that manage payments at scale face the complex challenge of reliably monitoring cash. Most of us have experienced the time delays inherent to ACH, wires, and checks. These delays make it difficult to tie a payment you’ve made or expect to receive to the actual transaction that posts to your bank account. This process is called reconciliation and it is essential for a business to understand how completed and in-progress transactions add up to the cash balance in its bank account.&nbsp;<br></p><p>Most finance teams try to solve the reconciliation problem with spreadsheets, email and manual examination of bank statements — processes that are inefficient and error-prone. At Modern Treasury, we’ve built a better solution that helps finance teams save time and minimize errors. We call it Automatic Reconciliation.&nbsp;<br></p><p>With Automatic Reconciliation, Modern Treasury automatically matches your payments and returns to transactions as they are made available by your bank. Reconciled transactions are reflected in the previous day and intra-day balances available through the API and dashboard, allowing you to reliably monitor cash across all your business bank accounts.&nbsp;</p><p>‍<br></p><h4>How Does Reconciliation Help With Monitoring Cash?<br></h4><p>Let’s say you run a marketplace for artisanal coffee that lets coffee aficionados buy coffee from artisanal coffee roasters anywhere in the country. You collect payments from the buyer, deduct your platform fee and pay the seller. You also need to handle other types of transactions, like refunds and bonus payments to your top performing sellers. Business is going well so you’re processing thousands of orders a week.&nbsp;<br></p><p>To reliably monitor cash, you need to be able to match every single payment you’ve made or received to the corresponding transaction in your bank statement. At scale, this quickly gets very complicated for three reasons.&nbsp;</p><p>‍</p><h4>1. Banks Don’t Move Money as Fast as Your Business <br></h4><p>The time it takes for your transaction to settle depends on which payment method you use. Here’s a list of business payment methods used in the US and their typical settlement times. Because of these settlement timeframes, the rate at which you move money is slower than your business activities.&nbsp;<br></p><figure id="w-node-260693cab140-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc098771bac937c487c98a_AutomaticReconciliationTable.png" loading="lazy" alt=""></p></figure><p><br>Let’s say you pay coffee sellers on a daily basis. If you initiate a number of ACH credits on Monday, they are likely to settle by Tuesday. But by the time they settle, you have already initiated a new batch of payments on Tuesday that will settle on Wednesday.&nbsp;<br></p><p>Without reconciliation, it’s hard to keep track of the cash available in your bank account, what transactions are processing versus complete, and when different sets of transactions are likely to settle.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><h4>2. Banks Process Transactions in Batches</h4><p>Let’s say you need to pay 10 coffee roasters $1000 each at the end of the week. You initiate 10 ACH credit transactions, each for $1000 on Friday before the day’s cut-off. These transactions will likely post to your bank statement Monday evening or Tuesday morning next week.&nbsp;<br></p><p>When you ask your bank to make a payment, it’s placed into a queue that’s sent to the network for processing after a certain cut-off time for the day. Any transactions submitted after the cut-off time are queued up to be processed the next business day. Different banks have different <a href="https://docs.moderntreasury.com/reference#ach-timings" target="_blank">cut-off times</a> for processing transactions.<br></p><p>The next day, instead of seeing 10 separate transactions next week, you’ll see one transaction for $10,000 on your statement. Because ACH transactions take place in batches, your bank directly debits your account for the total amount even though it represents 10 separate payments. Reconciliation helps you tie each payment to the appropriate transaction on your bank statement.&nbsp;</p><h4>3. Monitoring Incoming Payments and Returns is Difficult</h4><p>Let’s say you’re also expecting 100 payments of $20 each from your buyers. You need to know when they hit your bank account to predict cash accurately. You also need to tie each payment to an order. Similar to when you make bulk payments, your bank may record all or some of those payments as a single transaction on your statement.&nbsp;<br></p><p><a href="https://www.moderntreasury.com/journal/what-happens-when-you-ach-a-dead-person" target="_blank">Payment returns</a> also complicate monitoring cash flow. For example, ACH credits will fail due to incorrect account or routing numbers and ACH debits will fail if the counterparty doesn’t have sufficient funds in their account. In both scenarios, your bank will post a return transaction to your bank statement that needs to be reconciled with the original payment.</p><h4>Automatic Reconciliation<br></h4><p>Until now, many companies have relied on manual reconciliation processes that typically involve exporting transactions from the bank portal to a spreadsheet and manually matching them with payments. In addition to being time consuming, the need to email multiple spreadsheets back and forth makes collaboration painful.&nbsp;<br></p><p>With Automatic Reconciliation, Modern Treasury instantly reconciles every single payment with transactions in your bank statement. We <a href="https://www.moderntreasury.com/journal/tentative-reconciliation" target="_blank">tentatively reconcile</a> the transaction when it’s pending and complete the process when it posts. Because ACH processes transactions in batches, a large number of transactions on your bank statement are likely to represent multiple distinct payments. If the transaction aggregates multiple Payment Orders, we automatically create matching <a href="https://docs.moderntreasury.com/reference#transaction-line-item-object" target="_blank">Transaction Line Items</a>.&nbsp;<br></p><p>When you see a Payment Order marked as completed, you can click into it in the web application to see the matching transaction.&nbsp;<br>‍<br></p><figure id="w-node-bb5fd7410dc0-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc08ea82af2f7050239826_Payment%20Orders%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>The Expected Payments feature allows you to monitor your bank account for payments you do not initiate. When the transaction is made available by your bank, it is automatically reconciled with the Expected Payment. You can choose to be notified by <a href="https://docs.moderntreasury.com/reference#expected-payments">webhook</a> or email about its status.&nbsp;&nbsp;&nbsp;<br></p><figure id="w-node-6bf8f8776d0d-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc08fdea9cc07dcb14b23c_Expected%20Payments%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>The Returns feature automatically matches returned payments to transactions and the original Payment Order, making identifying, correcting and redrafting returns a breeze.&nbsp;<br></p><figure id="w-node-2fa9dd183a06-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc0910f4c807451c4b685e_Returns%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>All the data you see in the app is also available through the API, allowing you to further automate and streamline reconciliation by integrating Modern Treasury directly into your business systems or platform.&nbsp;<br></p><p>We also have direct integrations with QuickBooks and NetSuite through our <a href="https://www.moderntreasury.com/journal/introducing-continuous-accounting" target="_blank">Continuous Accounting</a> product. It syncs Modern Treasury directly with your general ledger, allowing you to tag payments with accounting categories. When you’re closing out the books, all you need to do is click a few buttons in the web app to transfer payments that have been Automatically Reconciled to your accounting software.<br></p><p>Finally, because we connect to <a href="https://docs.moderntreasury.com/docs/banks" target="_blank">multiple banks</a>, you can use Modern Treasury to reconcile transactions and monitor cash across all your business bank accounts.&nbsp;</p><h4>Get Started With Automatic Reconciliation</h4><p><a href="https://www.moderntreasury.com/product-demo" target="_blank">Get in touch</a> if you’re interested in exploring Automatic Reconciliation for your business. We’d love to discuss your use case in detail.</p></div></div></div>]]>
            </description>
            <link>https://www.moderntreasury.com/journal/what-is-automatic-reconciliation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201471</guid>
            <pubDate>Tue, 24 Nov 2020 18:39:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to stream your data in Apache Kafka with SQL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201407">thread link</a>) | @Natasha_Fll
<br/>
November 24, 2020 | https://lenses.io/blog/2020/11/apache-kafka-with-streaming-sql-from-real-time-data/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/11/apache-kafka-with-streaming-sql-from-real-time-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img alt="SELECT ApacheKafka WITH StreamingSQL FROM RealTimeData" src="https://images.ctfassets.net/tnuaj0t7r912/14MI0c1G0o6YM0jWb68az7/2623be6f9a8c8b47f72e878b351b604f/Mattero-KOH-Blog-v02.jpg?w=800&amp;q=100"></p><div><p>In another life, I taught the <i>Book of</i> <i>Genesis</i> to high school students, including The Tower of Babel excerpt. It struck me ironic that God’s wrath strikes down the tower, cofounds the universal language and scatters humans around the globe to teach King Nimrod a lesson in hubris; meanwhile, the boys in my class were texting their girlfriends across the country and playing video games with friends in Europe and Asia.&nbsp;</p><p>Technology allows us to form a new Tower; in particular, the ability to stream real-time events. For this technology to be built and managed, a common language is necessary, and more often than not, SQL is the common tongue of developers, architects and analysts. Recently, Matteo De Martino, Senior Scala Engineer at Lenses.io&nbsp; presented on the benefits of streaming SQL to react to real-time data for business critical decisions.&nbsp;</p><p>Anyone competent enough to build a pivot table on Excel understands how to act on data. You take a snapshot or data table and make an active query to parse out distribution and trends. While this is an important retrospective task, it does not allow for you to make business critical decisions in real-time.&nbsp;</p><p>The streaming SQL processors that Matteo explored in his <i>Kafka Office Hours </i>allow for users to process real-time data. As infinite amounts of data stream through an Apache Kafka cluster, users can model the transformations of data and write back to Kafka.</p><p>Lenses SQL Engine takes it a step further with SQL Processors. Not only can you model transformations, you can execute them as well. Users are able to scale, manage and govern their data with <a href="https://lenses.io/dataops/">DataOps</a>. </p><p>This activates data, allowing <a href="https://lenses.io/customers/">Lenses.io customers</a> to process data as it arrives and update the running state automatically.</p><p>Streaming SQL focuses on future data, so businesses can make time critical decisions. Matteo’s presentation outlines the advantages of Lenses Streaming SQL &amp; SQL processors. Watch his video below and then try SQL for yourself using <a href="https://lenses.io/box/">the Lenses Box, a self contained Apache Kafka environment.&nbsp;&nbsp;&nbsp;</a></p><p><iframe src="https://player.vimeo.com/video/483029806" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>


</div></div></div></div>]]>
            </description>
            <link>https://lenses.io/blog/2020/11/apache-kafka-with-streaming-sql-from-real-time-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201407</guid>
            <pubDate>Tue, 24 Nov 2020 18:33:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Expensive Security Fails in Healthcare Apps]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25201335">thread link</a>) | @_Tata_
<br/>
November 24, 2020 | https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019 | <a href="https://web.archive.org/web/*/https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><a href="https://www.ego-cms.com/tags/healthcare"><p>Healthcare</p></a><h2>Most Expensive Healthcare App Security Fails in 2018–2019</h2><p>MyFitnessPal, PumpUp, and Strava all were unable to avoid data breaches. Find out why and what you can learn from these cases to make your app more secure.
</p></div></div><article><div target="_blank"><p>In 2018, the average cost for a corporate data breach reached almost <a href="https://igniteoutsourcing.com/healthcare/healthcare-security-breaches/">$4 million</a>.&nbsp;</p><p>Let’s take a look at a few of these attacks to learn what went wrong and secure your business from such risks.</p><h2>1 MyFitnessPal</h2><p>MyFitnessPal is a typical fitness application. It allows users to log cardio and strength exercises, connects with more than 50 devices and other apps, tracks steps, counts calories, and so on. Released in 2009, MyFitnessPal quickly gained popularity — it was chosen as the number one health and fitness app four years in a row. But everything changed in February 2018.</p><figure id="w-node-9fe8c2a22398-7a0a8b78"><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/KRcvSWvR0kc"></iframe></p></figure><p>The MyFitnessPal data breach was probably one of the most publicized in the healthcare industry. Hackers accessed the personal data of almost <strong>150 million users</strong>, stealing their names, hashed passwords, IP addresses, and email addresses. Fortunately, the criminals couldn’t get to users’ credit card and social security numbers, as this data was collected and stored separately.&nbsp;<br></p><p><a href="https://www.underarmour.com/en-us?&amp;cid=PS%7Cgoogle%7CTrademark%7CUA%7CIP%7CExact%7Cunder%20armour%7CSRnf0L2T&amp;gclid=CjwKCAjw1_PqBRBIEiwA71rmtbPVRSTc31VHHLODl9D2ZnA-9HiTBv4xxSkBkyeWl8Z7kAJldUZ_QhoCaG8QAvD_BwE">Under Armour</a>, the company which acquired MyFitnessPal in 2015, became aware of the data breach at the end of March 2018. Four days later, users started to receive notifications and emails requiring them to change their passwords and offering recommendations on how to safeguard their accounts. In February 2019, the stolen personal details appeared on the dark web.&nbsp;<br></p><p>Other apps owned by Under Armour were not affected, but the company still <strong>lost 4.6% of its market</strong> <strong>value</strong> because of the data breach. However, the company and the app survived. MyFitnessPal still has a lot of users and pretty high ratings in the app stores (4.5 on Google Play).</p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>MyFitnessPal should have been equipped with <strong>two-factor authentication</strong>. For a mobile application, we would recommend using biometric authentication or at least push notifications.&nbsp;</li></ul><ul role="list"><li>Reliable <strong>encryption</strong> is a must for companies that are serious about privacy and security.</li><li>For the majority of passwords, Under Armour used the <a href="https://content.myfitnesspal.com/security-information/FAQ.html">Bcrypt</a> hashing function. This is a reliable mechanism. But for the remaining passwords, the company used the <strong>rather weak </strong><a href="https://content.myfitnesspal.com/security-information/FAQ.html"><strong>SHA-1</strong></a>. Using Bcrypt for all passwords could have reduced the scope of the breach.</li></ul><ul role="list"><li>Collecting and <strong>storing</strong> the most important <strong>data separately</strong> is a great practice — it kept credit card data safe. Otherwise, Under Armour could have faced a much more serious loss in market value.</li></ul><ul role="list"><li>If a breach happens, it’s essential to <strong>notify users as fast as possible</strong> — keeping silent will simply destroy your company’s reputation. Under Armour did well here.</li></ul><h2>2 PumpUp</h2><p><a href="https://www.pumpup.com/#home">PumpUp</a> positions itself as the world’s most positive fitness community. It offers users numerous workouts and programs, an opportunity to learn more about fitness and get support from other members, and other features. After the app was released in 2012, it became rather popular.<br></p><p>The PumpUp data breach took place in May 2018, when personal data of more than <a href="https://www.zdnet.com/article/fitness-app-pumpup-leaked-health-data-private-messages/"><strong>6 million users</strong></a><strong> </strong>stopped being private. Data compromised included information on users’ locations, email addresses, gender, and dates of birth, full-resolution profile photos, workout data, health information (for instance, weight and height), device data, and private messages. In certain cases, even credit card data was exposed.&nbsp;<br></p><p>The incident happened because the core backend server hosted on the Amazon Cloud was left without a password for an indefinite amount of time. Anyone could see the private content of the app’s users.</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7cdf1127270466b858d20_5d78d2e9cd001218b4a025f0_eb187d1d-170d-44e4-8ab7-2aa08946fd06.png" loading="lazy" alt=""></p></figure><p>The exposed server wasn’t even found by the company — it was discovered by security researcher Oliver Hough who then contacted <a href="https://www.zdnet.com/article/fitness-app-pumpup-leaked-health-data-private-messages/">ZDNet</a>, a business technology news website, to investigate the case. ZDNet spent a week trying to get in touch with PumpUp, but there was no reply. However, in the end, the server was secured.<br></p><p>Since there were no comments from PumpUp after the breach, we can’t tell exactly how much money they lost. But their reputation was definitely affected.&nbsp;<br></p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>To avoid this problem, PumpUp had at least to protect their data with a password. Ideally, this would have been combined with <strong>two-factor authentication</strong> to keep users’ data safe.&nbsp;</li></ul><ul role="list"><li>It seems that the company didn’t run any security tests — <strong>regular security scanning</strong> would have helped them notice the problem much earlier. EGO recommends performing such tests on a regular basis.</li><li>Another mistake PumpUp made was ignoring<strong> communications</strong> from ZDNet and ignoring the incident. If a breach happens, a company should stay in touch to show users that it cares.</li></ul><h2>Strava</h2><p><a href="https://www.strava.com/mobile">Strava</a> is a fitness app for tracking running, cycling, swimming, and other activities. It allows users to map and record their routes, analyze their activities, participate in challenges, etc. The app was released in 2009, and since then it has been installed more than 10 million times on Android OS alone (according to <a href="https://play.google.com/store/apps/details?id=com.strava&amp;hl=en">Google Play</a>; no data on iOS downloads is available).<br></p><p>The story of the Strava failure began in November 2017, when the company released a global heat map showing running routes for all users who opted to make their data publicly available. To create the map, Strava used GPS data from smartphones and fitness tracking devices on <strong>1 billion</strong> activities. This data was collected from 2015 to 2017. Over <strong>27 million</strong> users tracked their routes during this time, and due to confusing privacy settings, some of them didn’t even know that they were sharing sensitive data.&nbsp;<br></p><p>This map was the brainchild of Strava. But in January 2018, Nathan Ruser, an Australian student, noticed that by analyzing the map, it was possible to determine the whereabouts of military bases and other sensitive locations.</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7c54a7adc793c1f5f41b3_5d78d3ce1f37d12d04642dcc_Artboard.png" loading="lazy" alt=""></p></figure><p>Strava and its map got a lot of criticism. In response, the company didn’t delete the map, but rather changed it significantly.&nbsp;<br></p><p>First of all, the data isn’t available to everyone anymore — to zoom in and see street-level detail, users now have to log in with their Strava account.&nbsp;<br></p><p>Second, the map is now updated monthly, which means that if a user changes their privacy settings and doesn’t want to provide data for the heat map anymore, their data won’t be included in the next month’s map.&nbsp;<br></p><p>Third, all roads and paths with little activity aren’t shown on the map until they’re used by different users (not only runners, for example) for different activities.<br></p><p>To develop the heat map, Strava had to collect, analyze, and put together loads of data, which took money and a lot of time. Then the company had to update the map significantly, which meant unexpected additional expenses.&nbsp;<br></p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>In the case of Strava, there were no hackers or other criminals — the company gave out important information on its own. There was not even some kind of social engineering, as no fraud was involved. Strava simply didn’t pay enough attention to the potential outcome, and that was their main mistake — they didn’t anticipate the consequences. Explaining the importance of security and privacy to the entire team and <strong>training staff</strong> on a regular basis probably couldn’t have prevented this incident fully. But if the Strava staff would have thought about possible implications, they would have noticed that something was wrong during the map development phase.&nbsp;</li><li><strong>Privacy settings</strong> should not be confusing. Users must be able to set everything up easily and quickly. If privacy settings had been clearer, most users would have been able to prevent their private data from being published.</li></ul><h2>The Bottom Line</h2><p>To protect your healthcare app from security mistakes and failures, you have to pay attention not only to encryption and multi-factor authentication. As you can see from the Strava case, it’s also crucial to plan updates and new releases very carefully.&nbsp;<br></p><p>Follow these simple rules: run security tests and staff trainings on a regular basis, secure your app with multi-factor authentication and encryption, keep privacy settings simple, and analyze all potential outcomes.&nbsp;<br></p><p>And, obviously, if something does go wrong, stay in touch with your users. </p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7c533a29d5b2035e7ec00_5f6cbf011fddb44501d8d28d_5d3042f66324e92dec2018cb_Business%20Insights.png" loading="lazy" alt=""></p></figure><p>‍<br></p></div></article><section><div><div><p>LIKE THIS ARTICLE? Help us SPREAD THE WORD.</p></div></div></section></div>]]>
            </description>
            <link>https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201335</guid>
            <pubDate>Tue, 24 Nov 2020 18:26:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[E2E Encription with Rails and Stimulus.js]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201320">thread link</a>) | @ggsp
<br/>
November 24, 2020 | https://jensravens.com/e2e-encryption-with-rails/ | <a href="https://web.archive.org/web/*/https://jensravens.com/e2e-encryption-with-rails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  
  
  <div>
    <p>July  7, 2020</p>
    

<h2 id="why-you-should-care-about-encryption">Why You Should Care About Encryption</h2>

<p>Nowadays, the news is full of data leaks, breaks, and hacks and one thing is clear - you don’t want to be the one who leaks all your customer data to some hackers on the internet. One of many ways of securing your application and your customer’s data is end-to-end encryption or (e2e encryption for short). This means that data gets encrypted as soon as possible on the user’s device, is sent encrypted over the wire, and only gets decrypted at the receiver’s device. This stands in contrast to the usual encryption at transport and encryption at rest which is used by most applications and is implemented at the protocol level (you just put SSL on your connection and no one can snoop on your data while in transport - isn’t that great?).</p>

<p>So which one to use?</p>

<h3 id="encryption-at-the-protocol-level-eg-ssl-encryption">Encryption at the protocol level (e.g. SSL encryption)</h3>

<ul>
  <li>is easy to implement and completely transparent to the application</li>
  <li>protects from hackers snooping out your data while it’s transported</li>
  <li>is supported pretty much everywhere and is fast</li>
  <li>allows everyone with access to the database (from admins to hackers) to see all the content in the database</li>
</ul>

<h3 id="e2e-encryption">E2E-Encryption</h3>

<ul>
  <li>removes an entire vector of attacks. No one except the designated receiver can see any data - not even the database admin</li>
  <li>adds a higher level of privacy - if the admin cannot accidentally see data that she shouldn’t see, you don’t need to think that much about regulating data access in production systems</li>
  <li>gives the user total control about her data</li>
  <li>is harder to implement as all data processing has to happen on the client (more about this later).</li>
</ul>

<p>So as both methods have their pros and cons, you should carefully consider which option to use. E2E encryption works great for very personal data (e.g. social security numbers, private messages, secure notes) while it becomes a really hard problem if you’re dealing with data you want to filter on the server side (server-side full-text search becomes impossible).</p>

<h2 id="how-does-e2e-encryption-work">How does E2E encryption work?</h2>

<p>This post focusses on asymmetric encryption - which is just for a fancy word for saying that you can encrypt a message with a public key and decrypt it with a corresponding private key. Only the owner of the private key can decrypt a message, but everyone having access to his public keys can send him encrypted messages. A popular implementation is PGP which is mostly used to encrypt emails.</p>

<h2 id="what-we-are-going-to-build">What we are going to build</h2>

<p>To showcase several parts of e2e encrypted systems, we’re going to build a secure messaging app where users can send each other encrypted messages. The encryption is based on our work on <a href="https://covtrace.de/">CovTrace</a>, a digital attendance list for restaurants during Covid19-times. Features include:</p>

<ul>
  <li>users can signup and manage their encryption keys</li>
  <li>users can create a new key pair of private and public key</li>
  <li>users can send messages to other users and encrypt them in the browser</li>
  <li>users can receive messages and decrypt them in the browser</li>
</ul>

<h2 id="the-tech-stack">The Tech-Stack</h2>

<p>Even though a lot of things happen on the client, we are going to use a fully server-side rendered application:</p>

<ul>
  <li>Rails, ActiveRecord and Postgres
    <ul>
      <li>slim as a templating engine (you could of course also use ERB)</li>
      <li>devise for user authentication</li>
    </ul>
  </li>
  <li>Webpacker and Stimulus for the JavaScript part</li>
  <li>openpgp.js as an encryption library</li>
  <li>Turbolinks to turn the application into a single page application (SPA)</li>
</ul>

<p>This blog post will highlight the relevant parts of encryption and key management. You can find a fully working application at GitHub: https://github.com/JensRavens/rails-stimulus-e2e-encryption</p>

<p>This app is a simplified version we are running successfully for CovTrace in production.</p>

<h2 id="the-application-skeleton">The Application Skeleton</h2>

<p>This section deals with the Rails-side of things: models, controllers, keeping data where it should be. If you’re only interested in the encryption part, you can skip to the next section.</p>

<p>Let’s get started with <code>User</code>s. Create a migration with <code>rails g model user keys</code> and modify it as follows:</p>

<div><div><pre><code><span>def</span> <span>change</span>
  <span>create_table</span> <span>:users</span> <span>do</span> <span>|</span><span>t</span><span>|</span>
    <span>t</span><span>.</span><span>text</span> <span>:keys</span><span>,</span> <span>array: </span><span>true</span><span>,</span> <span>null: </span><span>false</span><span>,</span> <span>default: </span><span>[]</span>
    <span>t</span><span>.</span><span>timestamps</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>As you can see the user has an array of (public) keys, so other users can send them encrypted messages. Let’s allow that user to login in: <code>rails g devise:install User</code> and suddenly your user can login and sign up. Let’s give him something to login to. Add some user routes to the <code>routes.rb</code> (more about messages later):</p>

<div><div><pre><code><span>resources</span> <span>:users</span><span>,</span> <span>only: </span><span>[</span><span>:index</span><span>,</span> <span>:show</span><span>,</span> <span>:update</span><span>],</span> <span>shallow: </span><span>true</span> <span>do</span>
  <span>resources</span> <span>:messages</span><span>,</span> <span>only: :create</span>
<span>end</span>
</code></pre></div></div>

<p>and create the users controller:</p>

<div><div><pre><code><span>class</span> <span>UsersController</span> <span>&lt;</span> <span>ApplicationController</span>
  <span>before_action</span> <span>:authenticate_user!</span>

  <span>def</span> <span>index</span>
    <span>@users</span> <span>=</span> <span>User</span><span>.</span><span>where</span><span>.</span><span>not</span><span>(</span><span>keys: </span><span>[]).</span><span>where</span><span>.</span><span>not</span><span>(</span><span>id: </span><span>current_user</span><span>.</span><span>id</span><span>).</span><span>order</span><span>(</span><span>email: :asc</span><span>)</span>
  <span>end</span>

  <span>def</span> <span>update</span>
    <span>@user</span> <span>=</span> <span>current_user</span>
    <span>@user</span><span>.</span><span>add_key</span> <span>params</span><span>.</span><span>require</span><span>(</span><span>:user</span><span>).</span><span>require</span><span>(</span><span>:public_key</span><span>)</span>
    <span>redirect_to</span> <span>root_path</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Thanks to devise we get the <code>current_user</code> method and an <code>authenticate_user!</code> filter for free and we can fully focus on our logic. The index page should have a list of all users that can be contacted (only users that have public keys can receive messages). Also, the <code>update</code> method allows adding additional keys via the <code>User</code> model:</p>

<div><div><pre><code><span>class</span> <span>User</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>def</span> <span>add_key</span><span>(</span><span>key</span><span>)</span>
    <span>keys</span> <span>&lt;&lt;</span> <span>key</span>
    <span>save!</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Let’s build some basic UI for it in <code>users/index.html.slim</code>:</p>

<div><div><pre><code><span>h1</span><span> </span>Conversations
<span>p</span><span> </span>Hello<span> </span><span>#{</span><span>current_user</span><span>.</span><span>email</span><span>}</span>!
<span>-</span> <span>if</span> <span>current_user</span><span>.</span><span>keys</span><span>.</span><span>any?</span> <span># only allow sending messages once some keys have been added</span>
  <span>ul</span>
    <span>-</span> <span>@users</span><span>.</span><span>each</span> <span>do</span> <span>|</span><span>user</span><span>|</span>
      <span>li</span><span> </span><span>=</span> <span>link_to</span> <span>user</span><span>.</span><span>email</span><span>,</span> <span>user</span>
<span>h2</span><span> </span>Key<span> </span>Management
<span>-</span> <span>if</span> <span>current_user</span><span>.</span><span>keys</span><span>.</span><span>any?</span>
  <span>h3</span><span> </span>Your<span> </span>Keys<span> </span>#<span> </span>list<span> </span>all<span> </span>known<span> </span>public<span> </span>keys<span> </span>of<span> </span>the<span> </span>logged<span> </span>in<span> </span>user
  <span>-</span> <span>current_user</span><span>.</span><span>keys</span><span>.</span><span>each</span> <span>do</span> <span>|</span><span>key</span><span>|</span>
    <span>pre</span><span> </span><span>=</span> <span>key</span>
<span>h3</span><span> </span>Add<span> </span><span>Keys</span><span>
</span><span>=</span><span> </span><span>form_with</span><span> </span>model:<span> </span>current_user<span> </span>do<span> </span>|f|
  <span>=</span> <span>f</span><span>.</span><span>label</span> <span>:public_key</span>
  <span>br</span>
  <span>=</span> <span>f</span><span>.</span><span>text_area</span> <span>:public_key</span><span>,</span> <span>required: </span><span>true</span>
  <span>br</span>
  <span>=</span> <span>f</span><span>.</span><span>submit</span> <span>"Add Key"</span>
</code></pre></div></div>

<p>And with that we have a more or less functional UI (more on generating keys later):</p>

<p><img src="https://jensravens.com/img/posts/pgp/key-management.png" alt="PGP Key Management"></p>

<p>Great, let’s add some messages with <code>rails g model message</code> and modifying the migration as follows:</p>

<div><div><pre><code><span>def</span> <span>change</span>
  <span>create_table</span> <span>:messages</span> <span>do</span> <span>|</span><span>t</span><span>|</span>
    <span>t</span><span>.</span><span>text</span> <span>:content</span><span>,</span> <span>null: </span><span>false</span>
    <span>t</span><span>.</span><span>references</span> <span>:sender</span><span>,</span> <span>null: </span><span>false</span><span>,</span> <span>foreign_key: </span><span>{</span> <span>to_table: :users</span> <span>}</span>
    <span>t</span><span>.</span><span>references</span> <span>:receiver</span><span>,</span> <span>null: </span><span>false</span><span>,</span> <span>foreign_key: </span><span>{</span> <span>to_table: :users</span> <span>}</span>
    <span>t</span><span>.</span><span>timestamps</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Messages have a sender and receiver and a text field to store the encrypted message and also a scope to retrieve the conversations a user is involved with:</p>

<div><div><pre><code><span>class</span> <span>Message</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>belongs_to</span> <span>:sender</span><span>,</span> <span>class_name: </span><span>"User"</span>
  <span>belongs_to</span> <span>:receiver</span><span>,</span> <span>class_name: </span><span>"User"</span>
  <span>scope</span> <span>:with_user</span><span>,</span> <span>-&gt;</span> <span>(</span><span>user_id</span><span>)</span> <span>{</span> <span>where</span><span>(</span><span>sender_id: </span><span>user_id</span><span>).</span><span>or</span><span>(</span><span>where</span><span>(</span><span>receiver_id: </span><span>user_id</span><span>))</span> <span>}</span>
<span>end</span>
</code></pre></div></div>

<p>Now let’s give the user a way to see messages that were received to so far:</p>

<div><div><pre><code><span># users_controller.rb</span>
<span>def</span> <span>show</span>
  <span>@user</span> <span>=</span> <span>User</span><span>.</span><span>find</span> <span>params</span><span>[</span><span>:id</span><span>]</span>
  <span>@messages</span> <span>=</span> <span>Message</span><span>.</span><span>with_user</span><span>(</span><span>@user</span><span>.</span><span>id</span><span>).</span><span>with_user</span><span>(</span><span>current_user</span><span>.</span><span>id</span><span>).</span><span>order</span><span>(</span><span>created_at: :asc</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<p>This retrieves the user from the URL and all messages that have been exchanged between the current user and the selected user.</p>

<div><div><pre><code><span># users/show.html.slim</span>
<span>h1</span> <span>=</span> <span>@user</span><span>.</span><span>email</span>
<span>-</span> <span>@messages</span><span>.</span><span>each</span> <span>do</span> <span>|</span><span>message</span><span>|</span>
  <span>div</span> <span>style</span><span>=</span><span>(</span><span>"text-align: right"</span> <span>if</span> <span>message</span><span>.</span><span>sender_id</span> <span>==</span> <span>current_user</span><span>.</span><span>id</span><span>)</span>
    <span>div</span>
    <span>small</span> <span>=</span> <span>l</span> <span>message</span><span>.</span><span>created_at</span><span>,</span> <span>format: :short</span>
<span>=</span> <span>form_with</span> <span>model: </span><span>@message</span><span>,</span> <span>url: </span><span>user_messages_path</span><span>(</span><span>@user</span><span>)</span> <span>do</span> <span>|</span><span>f</span><span>|</span>
  <span>=</span> <span>f</span><span>.</span><span>text_area</span> <span>:content</span>
  <span>=</span> <span>f</span><span>.</span><span>submit</span>
</code></pre></div></div>

<p>Again relatively straight forward: Iterate over all messages and display the creation date and add a form with the message content.</p>

<p>Also we need a corresponding controller to persist those messages:</p>

<div><div><pre><code><span>class</span> <span>MessagesController</span> <span>&lt;</span> <span>ApplicationController</span>
  <span>before_action</span> <span>:require_login</span>
  <span>def</span> <span>create</span>
    <span>@message</span> <span>=</span> <span>Message</span><span>.</span><span>create!</span> <span>params</span><span>.</span><span>permit</span><span>(</span><span>:content</span><span>).</span><span>to_h</span><span>.</span><span>merge</span><span>(</span><span>sender_id: </span><span>current_user</span><span>.</span><span>id</span><span>,</span> <span>receiver_id: </span><span>params</span><span>[</span><span>:user_id</span><span>])</span>
    <span>redirect_to</span> <span>@message</span><span>.</span><span>receiver</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>This action will redirect to the receiver - which effectively reloads the page and shows the newly created message, which will look like this once we have some content:</p>

<p><img src="https://jensravens.com/img/posts/pgp/chat.png" alt="PGP based Chat"></p>

<p>With the basic CRUD out of the way, let’s get to the interesting part - the encryption.</p>

<h2 id="key-management">Key Management</h2>

<p>With the existing controller and UI the user could already create a key somewhere else and put it into the field. But to make things easier and more convenient, we’ll allow generating a key pair in the browser. For this, we will use Stimulus.js and https://github.com/openpgpjs/openpgpjs.</p>

<p>OpenPGP.js is quite a heavy dependency (it adds about 350kb to your bundle), so let’s load it asynchronously only if it’s needed. To better structure our frontend code, all encrypt/decrypt related code will go into <code>app/javascript/model/crypto.js</code>.</p>

<p>Copy the openpgp.js code into <code>app/javascript/lib/openpgp.js</code> (as of the time writing, it doesn’t work yet as a yarn dependency with webpack) and implement a loading function:</p>

<div><div><pre><code><span>export</span> <span>async</span> <span>function</span> <span>loadPGP</span><span>()</span> <span>{</span>
  <span>await</span> <span>import</span><span>(</span><span>"</span><span>../lib/openpgp</span><span>"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This code uses an async import (isn’t modern javascript cool?), which will tell Webpacker to split the bundle into multiple chunks. This way the PGP library is only loaded if it is actually needed and will not block loading the page.</p>

<p>Now let’s allow the user to generate a keypair:</p>

<div><div><pre><code><span>// crypto.js</span>

<span>export</span> <span>async</span> <span>function</span> <span>generateKey</span><span>()</span> <span>{</span>
  <span>await</span> <span>loadPGP</span><span>();</span>
  <span>return</span> <span>await</span> <span>openpgp</span><span>.</span><span>generateKey</span><span>({</span>
    <span>curve</span><span>:</span> <span>"</span><span>curve25519</span><span>"</span><span>,</span>
    <span>userIds</span><span>:</span> <span>[{</span> <span>name</span><span>:</span> <span>"</span><span>Anonymous</span><span>"</span><span>,</span> <span>email</span><span>:</span> <span>"</span><span><a href="https://jensravens.com/cdn-cgi/l/email-protection" data-cfemail="432e222a2f03263b222e332f266d202c2e">[email&nbsp;protected]</a></span><span>"</span> <span>}],</span>
  <span>});</span>
<span>}</span>
</code></pre></div></div>

<p>This makes sure the dependency is loaded before calling into PGP to generate a key. This code is using the <code>curve25519</code> encryption curve, which is quite a recent addition that results in secure, but relatively short keys.</p>

<p>Let’s also add a message to persist a private key in the browser for later use:</p>

<div><div><pre><code><span>// crypto.js</span>
<span>// persist an array of all known private keys in local storage so it can be read later</span>
<span>export</span> <span>async</span> <span>function</span> <span>registerKey</span><span>(</span><span>plainKey</span><span>)</span> <span>{</span>
  <span>const</span> <span>keys</span> <span>=</span> <span>JSON</span><span>.</span><span>parse</span><span>(</span><span>localStorage</span><span>.</span><span>getItem</span><span>(</span><span>"</span><span>keys</span><span>"</span><span>)</span> <span>||</span> <span>"</span><span>[]</span><span>"</span><span>);</span>
  <span>keys</span><span>.</span><span>push</span><span>(</span><span>plainKey</span><span>);</span>
  <span>localStorage</span><span>.</span><span>setItem</span><span>(</span><span>"</span><span>keys</span><span>"</span><span>,</span> <span>JS…</span></code></pre></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jensravens.com/e2e-encryption-with-rails/">https://jensravens.com/e2e-encryption-with-rails/</a></em></p>]]>
            </description>
            <link>https://jensravens.com/e2e-encryption-with-rails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201320</guid>
            <pubDate>Tue, 24 Nov 2020 18:24:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Error codes are far slower than exceptions]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25201269">thread link</a>) | @vips7L
<br/>
November 24, 2020 | https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/ | <a href="https://web.archive.org/web/*/https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
TL;DR On modern 64-bit PC architectures, C++ exceptions only add unreachable code with destructor calls into functions and their effect on performance is below 1%, but such low values are difficult to measure. Handling rare errors with return values requires additional branching that slows down the program in realistic scenarios by about 5% and are also less convenient. If an exception is actually thrown, stack unwinding costs about 2 µs per stack frame.
</p>

<p>C is considered to be the fastest programming language. C++ has features that only make C more convenient without an effect on performance and features that do impact performance. They help a lot to improve code quality, so they are often used anyway. Runtime polymorphism is virtually ubiquitous, exceptions less so.</p>



<p>A completely valid reason not to use exceptions is when the executable’s size is or is expected to be tightly constrained by the platform’s limitations. A questionable reason not to use them is performance, as it’s unlikely for completely new functionality to work without compromises. Also, using exceptions in wrong cases can completely ruin performance because handling a thrown exception is known to be very expensive.</p>



<p>But how significant is the performance impact? On most modern 64-bit platforms, exceptions are implemented in a way that minimises their cost as long as they are not thrown. There are no checks for exceptions being thrown in the generated functions, the execution switches to special functions and special data when handling an exception. However, not using exceptions is not free either. Rare errors have to be handled somehow. One possibility is to have the program simply abort, leaving any broken state on the disk, leading to very annoying user experience (done for example in Unreal Engine and Unity Engine, where incorrect API usage in code causes the editor to crash and keep crashing until the incorrect binaries are manually erased). Another alternative are error codes, when functions report they failed and the calling code is supposed to react appropriately, which is less convenient for the programmer and requires the program an additional check after returning from functions, however, it’s often done for performance reasons.</p>



<p>But actually, how do these approaches affect performance? I have tested this on realistic examples that simulate use cases typical for video games.</p>



<h2>Reminder – where not to use exceptions?</h2>



<p>An exception, as its name suggests, is supposed to deal with <em>exceptional</em> cases. An exception is a case when a rule doesn’t apply. In software, that means something isn’t going as intended. Not a part of a use case. A failure. Invalid user input, connection failure, corrupted data, invalid packet, failure to initialise a device, missing file, programmer errors…</p>



<p>In many of these cases, the program shouldn’t just abort. Invalid user input stopping the program is super annoying because it causes all unsaved data to be lost and forcing the user to wait until the program restarts. Connection failure is a very recoverable problem, usually solvable by simply reconnecting. Invalid packet causing a program to crash is an open door to sabotage, as anyone can send invalid packets to cause the program to crash. And that is what can be solved by exceptions. Throwing them is slow, but the code does not need to be optimised to what isn’t its use case.</p>



<p>Examples of incorrect use of exceptions is when they’re thrown when everything works as it should. Breaking from a double loop, handling the end of a container, checking if a number can be deserialised in order to use a default value otherwise…</p>



<p>Modern 64 bit architectures use a model called <em>zero-cost exceptions</em> that optimises error handling with exceptions strongly in favour of the happy path when no exception is thrown at the cost of very bad performance of exceptions when they are actually thrown.</p>



<p>In other words, it should be possible to run the program in a debugger with the stop on exception function enabled.</p>



<p>Although not all error handling can be efficiently handled with exceptions, error codes can handle all of it. The question is, should they?</p>



<h2>Test 1 – XML parsing</h2>



<p>For the purpose of this test, I have written an XML parser. I chose to write a parser because it can fail at many locations and does not depend on I/O. It’s definitely not standard-compliant or guaranteed to fail on every possible invalid input, but it can parse a usual XML configuration file and should end with an error in most cases where the file is syntactically incorrect. The code is quite low level and should be relatively fast (about 150 MiB/s), but I did not optimise it and used STL containers to make it convenient to use (as opposed to in-situ parsing). I wrote it with a lot of <code>#ifdef</code> checks to switch between exceptions, error codes and abort on error just with compiler arguments and thus ensure that the only differences between the variants would be what is necessary for different error handling.</p>



<p>I benchmarked it with <a href="https://gist.github.com/Dugy/5fee1b49777054d01f12e22ce9f986e5">an XML file that imitates the configuration of a video game</a>. Its size is 32 kiB and is loaded into memory before the benchmarks start. The parsing was repeated 10000 times and the duration was averaged, then repeated 10 times to test that its imprecision was below 1%.</p>



<p>The code was compiled with GCC 9, on Ubuntu 20.04, with an Intel i7-9750H processor with maximum single threaded frequency 4.5 GHz. I ran all experiments that I wanted to compare at a similar time, without doing anything in between, in order to equalise the influence of other programs occupying cache. Anyway, there were still outliers that took noticeably more than average. I removed these.</p>



<p>The version that aborted on error was as fast as the version with exceptions. The version with error codes was 5% slower.</p>



<p>For some reasons, if failures were handled by a special function that printed the error and exited the program, it was for some reasons slightly (about 1%) slower than the version with exceptions. I had to use a macro to make it comparable to the speed of code using exceptions. This behaviour was repeated in the other tests.</p>



<h2>Test 2 – filling classes with the parsed XML</h2>



<p>For this test, I’ve written several classes meant to represent the structures in the XML file and code for filling the data with the parsed XML structure. This part was about 10 times faster, probably because there was much less dynamic allocation.</p>



<p>The error margins of the code with exceptions and the code with no proper error handling overlapped, but the times were 0.6% higher for exceptions. In the case of error codes, the program was 4% slower. I achieved a similar slowdown by forgetting to use move semantics.</p>



<h2>Test 3 – Updating with data from a binary stream</h2>



<p>This test imitates the usage of an asynchronous API for reading data from a TCP socket (such as Boost Asio or Unix Sockets). These APIs are used in a way that always a certain number of bytes is read from the stream, have to be processed and then more data is read. For faster processing and reduced bandwidth, the data are in binary form. Because network data in video games are streamed continuously, waiting for the end is not feasible.</p>



<p>The communication is represented by three message types that identify different possible updates. Because the messages have different lengths, it’s not possible to exactly determine whether all of the message’s length is available, so the function that identifies the message and calls appropriate parsing code will fail often even if everything is running correctly – so exceptions cannot be used to handle this type of failure. Other failures, like unidentifiable message types, wrong identification of objects or large sudden changes of values (either cheating or data corruption) are still handled by exceptions (in the case where they are used).</p>



<p>The data were read from memory in order to prevent networking from influencing the tests. The data were generated by <a href="https://gist.github.com/Dugy/d3d851ab4826cc3121fc00b79cb5124d">this script</a>.</p>



<p>The result of the test was similar to previous tests – the code using exceptions for error handling was 0.8% slower than the code that aborted on error, which was within the margin of error, while the code using error codes to handle errors was 6% slower.</p>



<h2>The results</h2>



<p>The times taken by the benchmarks are summarised in the following table, scaled so that the time needed by the version that aborts when an error happens is 100%.</p>



<figure><table><thead><tr><th>Test</th><th>Abort</th><th>Exception</th><th>Error code</th></tr></thead><tbody><tr><td>Parsing</td><td>100%</td><td>100%</td><td>106.2%</td></tr><tr><td>Filling</td><td>100%</td><td>100.6%</td><td>104.2%</td></tr><tr><td>Updating</td><td>100%</td><td>100.8%</td><td>106.2%</td></tr></tbody></table></figure>



<p>The imprecision was around 1%, so the version using exceptions might not really be slightly slower and the difference might be the result of chance or some invisible compiler decisions, like inlining. The time needed by the version using error codes was consistently higher.</p>



<p>The entire source code is <a href="https://gist.github.com/Dugy/2532c810bb232b8ff1603cfa679bdf28">here</a>.</p>



<h2>Error handling and clean code</h2>



<p>When an exception is not handled in a block, the execution exits the block automatically until it finds a piece of code that can catch it. Any other type of handling does not support this and requires writing additional logic to handle the failure, although in almost all cases the appropriate reaction is to abort the operation the program is performing (the test with reading from a stream is an example where this does not apply). This can significantly lengthen the code even if the reaction to any failure in a function being called is to return the error code to the caller’s caller.</p>



<p>This is a line from the initialisation sector of a constructor in test 2:</p>



<pre data-enlighter-language="cpp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">	animation(*source.getChild("animation")),</pre>



<p>It forwards the child XML tag called <code>animation</code> of its argument to the constructor of a member class called&nbsp;<code>animation</code>. The constructor may fail due to incorrect content of the XML tag, or <code>getChild</code> function can fail because the entire tag is missing. This aborts the creation of the structure, or some other process in the program that’s in the <code>catch</code> block.</p>



<p>If the errors …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/">https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/</a></em></p>]]>
            </description>
            <link>https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201269</guid>
            <pubDate>Tue, 24 Nov 2020 18:20:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Cargo bikes? An empirical analysis of the Pedal Me fleet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201188">thread link</a>) | @ingve
<br/>
November 24, 2020 | https://pedalme.co.uk/why-cargo-bikes/ | <a href="https://web.archive.org/web/*/https://pedalme.co.uk/why-cargo-bikes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><h2>A short introduction to the future of urban mobility.</h2><p>Cargo bikes are often faced with misconceptions about their potential and use for large scale logistics. In this post, we present the case of Pedal Me in London to demonstrate their efficiency in dense urban areas and emphasise their competitive advantage over cars and smaller vans.</p><p>To do so, we analyse data from our fleet in September 2020 and summarise the direct logistical advantages of e-cargo bikes. We report on the average speeds of our bikes, and compare the distances travelled by bikes and cars for similar journeys. We then investigate the case of larger logistics jobs to evaluate how e-cargo bikes fare against motorised vehicles with much larger capacity.</p><p>For e-cargo bikes to be able to replace a significant proportion of van and car journeys, we explain the importance of using them at their maximum potential and give a brief overview of the training program at Pedal Me. In the end, we look at the huge impact e-cargo bikes can have beyond more efficient logistics for making kinder and healthier cities.</p><h2>1. Logistical advantages of e-cargo bikes</h2><h3>a. Faster speeds in dense urban areas 🐇</h3><p>To compare e-cargo bikes and motorised vehicles, we start by looking at their speeds in central and inner London to those of cars and vans. <a href="https://www.london.gov.uk/questions/2019/19767">Transport for London reports that in 2018</a>, the general traffic speeds in London, as measured for central, inner and outer London using GPS-based data for key roads on weekdays (07:00 to 19:00), were:</p><ul><li>11.4 km/h in central London (in green on map below)</li><li>18.7 km/h in inner London (orange on map)</li></ul><p>These numbers should be taken as an upper bound though, given that the congestion levels in inner London this year were <a href="https://envirotecmagazine.com/2020/09/16/study-says-traffic-congestion-increasing-in-london-above-2019-levels-outside-city-centre/">reported to be significantly worse than last year</a> (<a href="https://www.theguardian.com/environment/2020/sep/15/road-congestion-levels-in-outer-london-higher-than-before-lockdown">up to 153%</a>).</p><p>To measure the speed of the Pedal Me fleet, we collected GPS data from 37 bikes in September 2020 between 07:00 and 19:00. This corresponds to approximately 19,000 km ridden. In central London, the average speed of the bikes was of 15km/h. In inner London, it was of 16.4 km/h. What this shows, is that within a 3-5 miles radius of the centre, bikes are likely to move significantly faster than vans or cars. With congestion levels going up due to more cars on the road on one hand, and with more restricted lanes and continued investment in cycling infrastructure on the other, this advantage will only be heightened.</p><p>Indeed, the competitive speeds can be largely explained by the fact that cargo bikes can move past stationary traffic, are allowed to use bus lanes and benefit from separated cycling infrastructure.</p><div id="attachment_8465"><p><img src="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=592%2C592&amp;ssl=1" alt="" width="592" height="592" srcset="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=768%2C768&amp;ssl=1 768w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=650%2C650&amp;ssl=1 650w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=1125%2C1125&amp;ssl=1 1125w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?w=2120&amp;ssl=1 2120w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?w=3180&amp;ssl=1 3180w" sizes="(max-width: 592px) 100vw, 592px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=768%2C768&amp;ssl=1 768w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=650%2C650&amp;ssl=1 650w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=1125%2C1125&amp;ssl=1 1125w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?w=2120&amp;ssl=1 2120w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?w=3180&amp;ssl=1 3180w" data-lazy-src="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/sept_all_bikes_gps_with_zones.jpg?resize=592%2C592&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>Orange: Inner London. Green: Central London. Pink lines show the bike movements analysed.</p></div><p>Beyond competitive moving speeds, and perhaps more importantly for dense urban areas, e-cargo bikes do not need to waste time on finding parking space. Parking is a considerable burden for delivery vans (<a href="https://link.springer.com/article/10.1186/s12544-019-0349-5" target="_blank" rel="noopener noreferrer" data-token-index="1" data-reactroot="">studies show this takes between 9-15 minutes</a>). They usually imply some additional walking to the final delivery point, as well as frequent parking fines (in the first quarter of 2013, FedEx and UPS owed NYC $2.8 million combined in parking fines). The cost of finding parking means that <a href="https://dl.acm.org/doi/abs/10.1145/3173574.3174100" target="_blank" rel="noopener noreferrer" data-token-index="5" data-reactroot="">many delivery drivers opt for longer walking distances between drops to avoid having to waste time on parking</a>.</p><p><img src="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?resize=609%2C490&amp;ssl=1" alt="" width="609" height="490" srcset="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?resize=1024%2C824&amp;ssl=1 1024w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?resize=300%2C241&amp;ssl=1 300w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?resize=768%2C618&amp;ssl=1 768w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?w=1196&amp;ssl=1 1196w" sizes="(max-width: 609px) 100vw, 609px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?resize=1024%2C824&amp;ssl=1 1024w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?resize=300%2C241&amp;ssl=1 300w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?resize=768%2C618&amp;ssl=1 768w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?w=1196&amp;ssl=1 1196w" data-lazy-src="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/Screenshot_2020-10-19_at_11.43.53.png?resize=609%2C490&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><h3>b. Shorter trip lengths 🗺</h3><p>Beside the speed of movement, e-cargo bikes also benefit from shorter routes. To analyse the significance of this, we look at the estimated differences in trip distances for cars and bikes of Pedal Me jobs in September. In total we compare the distances for more than 2000 jobs using Open Street Maps (using the <a href="https://geoffboeing.com/2016/11/osmnx-python-street-networks/">OSMnx library</a>) to measure the shortest journeys when cycling and driving.</p><p>On average, bike trips were 6% shorter than car trips. Of the 11,800 km studied this corresponded to 620km saved. When looking at trips that were shorter than 5km, the journeys were on average 8% shorter, with 25% of trips being at least 10% shorter in terms of distance. This effect has been seen in other cities as well. <a href="https://www.rippl.bike/en/rippl-23-consolidation-down-under-sydneys-cbd-cycle-logistics-hub/">A study in Sydney</a>, for example, showed that bikes travelled a third less than vans in the city.</p><h3>c. Efficiency of smaller capacity vehicles in last mile delivery 📦</h3><p>The limited capacity of e-cargo bikes can be a deceiving aspect of their efficiency for large scale last mile delivery operations.</p><p>During the first lockdown in the Spring of 2020, Pedal Me displayed the potential of e-cargo bikes by <a href="https://pedalme.co.uk/2020/09/08/pedal-me-x-lambeth-council/">delivering over 10,000 packages in collaboration with Lambeth Council</a> to the individuals and families most in need.</p><p>In this section, we compare the delivery distances for three client jobs, where the loads surpass the capacity of cargo bikes to explain how cargo bikes can outcompete vans despite their smaller capacity.</p><p>For each client job, we compare the total distances travelled across all vehicles for vans and cargo bikes. A visual analogy would be to compare the lengths of thread required to draw the routes satisfying all deliveries. For an apples to apples comparison, we ignore the advantage of shorter routes available to cargo bikes that we saw in the previous section and assume vans and bikes follow the same directions.</p><p>We compare total distances for a large number of drops under the assumption that 50km driven by a van are equivalent to 50km ridden by bike in terms of (wo)man-hours, even when those kms are done by multiple vehicles (e.g. 50km x 1 = 10km x 5).</p><p>To find the optimal routing of vehicles, we used the Google OR optimisation engine and the driving distances from Open Street Maps (OSMnx).</p><p>The first job consists of 9 drops spread widely across the city, which are deliveries for the Water House Project restaurant in East London. A cargo bike is only able to carry 6 of these boxes, as they are quite voluminous.</p><div id="attachment_8467"><p><img src="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-drops.png?resize=370%2C424&amp;ssl=1" alt="" width="370" height="424" srcset="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-drops.png?w=754&amp;ssl=1 754w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-drops.png?resize=262%2C300&amp;ssl=1 262w" sizes="(max-width: 370px) 100vw, 370px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-drops.png?w=754&amp;ssl=1 754w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-drops.png?resize=262%2C300&amp;ssl=1 262w" data-lazy-src="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-drops.png?resize=370%2C424&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>The red icon represents the pickups and blue represent the drops</p></div><p>For a single van, the total distance travelled to deliver all 9 packages is of 54km. For three cargo bikes, the total distance travelled was of 48km, brushing off 6km (i.e. more than 10% of the distance).</p><div><div id="attachment_8468"><p><img src="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-van-route.png?resize=417%2C269&amp;ssl=1" alt="" width="417" height="269" srcset="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-van-route.png?w=658&amp;ssl=1 658w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-van-route.png?resize=300%2C193&amp;ssl=1 300w" sizes="(max-width: 417px) 100vw, 417px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-van-route.png?w=658&amp;ssl=1 658w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-van-route.png?resize=300%2C193&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-van-route.png?resize=417%2C269&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>as the crow flies route for a single van for all 9 drops (total distance 54km)</p></div></div><br><div><div id="attachment_8469"><p><img src="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-bike-routes.png?resize=400%2C260&amp;ssl=1" alt="" width="400" height="260" srcset="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-bike-routes.png?w=656&amp;ssl=1 656w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-bike-routes.png?resize=300%2C195&amp;ssl=1 300w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-bike-routes.png?w=656&amp;ssl=1 656w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-bike-routes.png?resize=300%2C195&amp;ssl=1 300w" data-lazy-src="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/WHP-bike-routes.png?resize=400%2C260&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>as the crow flies routes for three cargo bikes (total distance 48km)</p></div></div><p>The second job consists of 114 drops across the city, for Grubby, a plant based recipe kit company. Here, the Pedal Me cargo bikes are able to carry 30 parcels.</p><div id="attachment_8470"><p><img src="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?resize=419%2C461&amp;ssl=1" alt="" width="419" height="461" srcset="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?resize=930%2C1024&amp;ssl=1 930w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?resize=272%2C300&amp;ssl=1 272w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?resize=768%2C846&amp;ssl=1 768w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?w=990&amp;ssl=1 990w" sizes="(max-width: 419px) 100vw, 419px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?resize=930%2C1024&amp;ssl=1 930w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?resize=272%2C300&amp;ssl=1 272w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?resize=768%2C846&amp;ssl=1 768w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?w=990&amp;ssl=1 990w" data-lazy-src="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubby-drops.png?resize=419%2C461&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>The red icon represents the pickups and blue represent the drops</p></div><p>While a van may carry all packages, we compare the total distances for three vans, assuming that 50 deliveries require approximately 8 hours of work. We find that the total distance for three vans is 65km. For 5 cargo bikes, the total distance was of 62km, again leading to more efficient logistics overall.</p><div><div id="attachment_8471"><p><img src="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-bikes.png?resize=405%2C263&amp;ssl=1" alt="" width="405" height="263" srcset="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-bikes.png?w=660&amp;ssl=1 660w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-bikes.png?resize=300%2C195&amp;ssl=1 300w" sizes="(max-width: 405px) 100vw, 405px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-bikes.png?w=660&amp;ssl=1 660w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-bikes.png?resize=300%2C195&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-bikes.png?resize=405%2C263&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>as the crow flies routes for three vans (max capacity of 50 parcels due to time constraints, total distance 65km)</p></div></div><br><div><div id="attachment_8472"><p><img src="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-vans.png?resize=405%2C262&amp;ssl=1" alt="" width="405" height="262" srcset="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-vans.png?w=662&amp;ssl=1 662w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-vans.png?resize=300%2C194&amp;ssl=1 300w" sizes="(max-width: 405px) 100vw, 405px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-vans.png?w=662&amp;ssl=1 662w, https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-vans.png?resize=300%2C194&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/grubbys-vans.png?resize=405%2C262&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>as the crow flies routes for five cargo bikes (max capacity of 30 parcels parcels due to volume, total distance 62km)</p></div></div><p>For the final job, we look at 188 densely distributed drops for Freddie’s flowers. Because of the condensed nature of the drops we assume a single deliverer can do up to 70 drops in a day. We thus do the comparison with three vans. Here, a Pedal Me cargo bike can carry up to 36 packages (although specifically designed flat bed cargo bikes can carry 55+).</p><div id="attachment_8473"><p><img src="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?resize=511%2C415&amp;ssl=1" alt="" width="511" height="415" srcset="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?resize=1024%2C831&amp;ssl=1 1024w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?resize=300%2C243&amp;ssl=1 300w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?resize=768%2C623&amp;ssl=1 768w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?w=1186&amp;ssl=1 1186w" sizes="(max-width: 511px) 100vw, 511px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?resize=1024%2C831&amp;ssl=1 1024w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?resize=300%2C243&amp;ssl=1 300w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?resize=768%2C623&amp;ssl=1 768w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?w=1186&amp;ssl=1 1186w" data-lazy-src="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-drops.png?resize=511%2C415&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>The red icon represents the pickups and blue represent the drops</p></div><br><div><div id="attachment_8474"><p><img src="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-vans.png?resize=445%2C267&amp;ssl=1" alt="" width="445" height="267" srcset="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-vans.png?w=656&amp;ssl=1 656w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-vans.png?resize=300%2C180&amp;ssl=1 300w" sizes="(max-width: 445px) 100vw, 445px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-vans.png?w=656&amp;ssl=1 656w, https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-vans.png?resize=300%2C180&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-vans.png?resize=445%2C267&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>as the crow flies routes for three vans (max capacity of 80 parcels for time constraints, total distance 44km)</p></div></div><br><div><div id="attachment_8475"><p><img src="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-bikes.png?resize=434%2C254&amp;ssl=1" alt="" width="434" height="254" srcset="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-bikes.png?w=656&amp;ssl=1 656w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-bikes.png?resize=300%2C176&amp;ssl=1 300w" sizes="(max-width: 434px) 100vw, 434px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-bikes.png?w=656&amp;ssl=1 656w, https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-bikes.png?resize=300%2C176&amp;ssl=1 300w" data-lazy-src="https://i2.wp.com/pedalme.co.uk/wp-content/uploads/2020/11/freddies-bikes.png?resize=434%2C254&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>as the crow flies routes for six cargo bikes (max constraint of 36 parcels due to volume, total distance 55km).</p></div></div><p>This time, the total distance for vans was of 44km for vans and 55km for cargo bikes. While the larger capacity leads to more efficient logistics for vans, the difference can be largely explained by the initial distance from the depot (red dot) to the first drop for all riders (approx. 1.5km x 6 riders). This could have perhaps been saved by e.g. organising a mobile sub-hub for the bikes to collect from (e.g. with a trailer). It may also be interesting to note that it is particularly in densely located drops like this that cargo bikes benefit most from time saved from parking when compared to cars and vans.</p><p>Overall, these examples show that cargo bikes are extremely competitive for larger scale logistics. Rather than being hindered by their smaller capacity, cargo bikes can result in globally more efficient routes for deliveries when the load is distributed between more vehicles.</p><p>To summarise, we have seen that e-cargo bikes benefit from several advantages when compared to vans and cars: They move faster, they are able to park closer to drop locations without wasting unnecessary time looking for a space, and have shorter routes across the city. Finally, we saw that their smaller capacity (in terms of weight and volume) can lead to more efficient routes overall because deliveries are distributed amongst more vehicles.</p><p>This competitive advantage with vans can only be true if the available capacity of e-cargo bikes is used to their full potential. In the next section, we explain how at Pedal Me, our riders are trained to do just that.</p><h2>2. Understanding and leveraging the full potential of e-cargo bikes</h2><p>An e-cargo bike can carry up to 150kg, with trailers adding in an additional 150kg. The loads transported by Pedal Me around London are impressive to many, and customers are often surprised by the volume and weight they can hold.</p><p>Since the beginning of the company, Pedal Me has led an important R&amp;D program to train riders into using cargo bikes at their full capacity in a safe and professional way. The curriculum, which involves on-road training, maneuvering of the bike, loading, and navigation, is City and Guilds assured and trains riders to be predictable, professional, and communicative road users.</p><p>While studies point at a <a href="https://www.lowtechmagazine.com/2012/09/jobs-of-the-future-cargo-cyclist.html">wide range</a> of <a href="https://ecf.com/news-and-events/news/cargo-bike-crazy-potential-delivering-goods-bike-0">estimates</a> for <a href="https://www.sciencedirect.com/science/article/pii/S2352146516000478">the proportion</a> of <a href="https://etrr.springeropen.com/articles/10.1007/s12544-017-0246-8">van journeys</a> replaceable by cargo bikes in urban areas (anywhere between 10-90%, although often in the lower ranges), …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pedalme.co.uk/why-cargo-bikes/">https://pedalme.co.uk/why-cargo-bikes/</a></em></p>]]>
            </description>
            <link>https://pedalme.co.uk/why-cargo-bikes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201188</guid>
            <pubDate>Tue, 24 Nov 2020 18:13:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking Back DevOps]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201166">thread link</a>) | @semicolon
<br/>
November 24, 2020 | https://www.opslevel.com/2020/11/18/taking-back-devops/ | <a href="https://web.archive.org/web/*/https://www.opslevel.com/2020/11/18/taking-back-devops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <h2 id="lets-get-devops-to-mean-service-ownership-again">Let’s get DevOps to mean Service Ownership again.</h2>
<h3 id="we-broke-devops-and-its-preventing-us-from-building">We broke DevOps. And it’s preventing us from building.</h3>
<p>When the first cloud providers emerged in the mid-2000s, they unlocked a new superpower: the ability to near-instantly provision hardware. Service-oriented architecture and microservices developed as a new architectural pattern. As a result, DevOps emerged as a practice to organize engineering teams around those new services - combining development and operations responsibilities onto the same team.</p>

<p>In 2006, Werner Vogels, CTO at Amazon, described DevOps as: “You build it, you run it.” Fast forward to today and DevOps is a far cry from these origins. Code is no longer deployed efficiently, and the practice of DevOps has weakened. Here’s how this happened:</p>

<h4 id="1-we-rendered-the-term-devops-meaningless">1. We rendered the term DevOps meaningless.</h4>

<p>Over the last several years, DevOps has become simultaneously a practice, a culture, a team, a job title, and a vendor product. You can hire some DevOps, buy some DevOps, adopt DevOps, and sprinkle a little bit of DevOps on top for good measure.</p>
<ul>
  <li><strong>‘DevOps’ is a team</strong>, responsible for horizontal engineering concerns like standardized CI/CD and observability.</li>
  <li><strong>‘DevOps’ is a trendy job title</strong>, merely renamed from “Operations”.</li>
  <li><strong>‘DevOps’ is a vendor product</strong>, like “Azure DevOps”, “ServiceNow Enterprise DevOps”, and “IBM DevOps”.</li>
</ul>

<h4 id="2-we-spent-way-too-much-time-debating-microservices-vs-monolith">2. We spent way too much time debating microservices vs monolith.</h4>

<p>This is the wrong debate. And it’s distracted teams from focusing on how to own and operate code efficiently. For some companies, a monolith works just fine. For others, microservices is the way to go. For many, it’s a hybrid of fat services or serverless or applications or some other mix. The more important question is: <em>How do you get your team to a place where engineers own the code they write so everyone can ship faster and safer?</em></p>

<h4 id="3-we-built-some-devops-tools-but-for-crucial-needs-were-stuck-in-spreadsheets">3. We built some DevOps tools, but for crucial needs we’re stuck in spreadsheets.</h4>

<p>DevOps tools are siloed around monitoring, logging, tracing, incident management, CI/CD, etc. But there is nothing that unifies the information from those tools to answer broad questions about production architecture. Companies with the best DevOps cultures use this set of siloed tools, but they have also spent millions of dollars to <em>build their own</em> tools and systems–everything from lists of owners to full-fledged internal tools. We’ve seen teams with:</p>
<ul>
  <li><strong>Giant wikis of services</strong> that answer basic questions about architecture, including simply who owns what.</li>
  <li><strong>Spreadsheets of services</strong> that are painstakingly created (and later tossed away) during engineering initiatives like upgrades or security improvements across a large and complex architecture.</li>
  <li>Eventually spreadsheets and wikis are thrown away and <strong>complex internal tools</strong> are created that require a lot of engineering resources to build and maintain.</li>
</ul>

<p>Building these stop-gap solutions are a huge barrier to entry; there needs to be a way for <em>all</em> teams to adopt DevOps culture.</p>

<h3 id="lets-take-back-devops">Let’s take back DevOps.</h3>
<p><strong>If we want to get back to shipping code even faster, more securely, and with less risk, we need to reset DevOps so that it’s synonymous with <em>Service Ownership</em>.</strong></p>

<p>When DevOps = Service ownership, teams get:</p>
<ul>
  <li><strong>Autonomy:</strong> Teams fully control how their systems are built and run in production. Architecture becomes less prescriptive.</li>
  <li><strong>Speed:</strong> As long as your team’s SLOs are being met, there should be nothing stopping you from shipping quickly.</li>
  <li><strong>Resiliency:</strong> Shifting reliability and security concerns to dev teams naturally increases risk, but ownership involves educating/measuring teams against critical practices so that they can still deploy with low risk.</li>
  <li><strong>Accountability:</strong> People are no longer paged because a service goes haywire - or, worse yet, has a security breach - and learn that nobody owns the service, wants to touch it, or even knows anything about it.</li>
</ul>

<p>We’ve underinvested in tools to make DevOps actually work. There’s a lot we still need to build to help engineering teams adopt service ownership and unlock the full power of DevOps.</p>

<hr>

<h3 id="opslevel-enables-service-ownership-its-the-future-of-devops">OpsLevel enables Service Ownership. It’s the future of DevOps.</h3>

<p>OpsLevel helps DevOps teams own, operate, and understand their entire production infrastructure. You can easily catalog all your services, tools, ownership, and changes, while you continuously measure and improve how you build and operate your software. Teams ship faster, with confidence.</p>

<p>Forward-thinking engineering teams at Segment, Zapier, Auth0, Convoy, Under Armour, Chegg, and more use OpsLevel to drive service ownership. <strong>We’re proud to announce we’ve raised $5M in funding led by Vertex Ventures, with participation from S28 Capital, Webb Investment Network, Union Capital, and a number of angels</strong> including:</p>
<ul>
  <li>Alex Solomon, Andrew Miklas, and Baskar Puvanathasan (founders of PagerDuty)</li>
  <li>Anne Raimondi (CCO of Guru, Board member Asana, Gusto, Patreon)</li>
  <li>Frederic Kerrest (Executive Vice Chairman, COO, and co-founder of Okta)</li>
  <li>Jean-Michel Lemieux (CTO of Shopify)</li>
  <li>Maynard Webb (ex-COO of eBay)</li>
  <li>Yuri Sagalov (co-founder of AeroFS)</li>
  <li>Evan Weaver (CTO and co-founder of Fauna)</li>
  <li>Paul Judge (co-founder of Pindrop Security)</li>
  <li>Bill Clerico (co-founder of WePay)</li>
</ul>

<p>If you’re interested in joining our mission to take back DevOps and empower cultures of service ownership, <a href="https://www.opslevel.com/careers/">check out our open roles</a>.</p>

<p><em><a href="https://www.linkedin.com/in/john-laban/">John Laban</a> and <a href="https://www.linkedin.com/in/klprose/">Ken Rose</a> are co-founders of OpsLevel. John was previously PagerDuty’s first engineer and the pair of them bring senior technical expertise from Shopify, Amazon, and more.  They’ve spent the last decade scaling engineering teams and helping them transition to DevOps and service ownership.</em></p>

                </div></div>]]>
            </description>
            <link>https://www.opslevel.com/2020/11/18/taking-back-devops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201166</guid>
            <pubDate>Tue, 24 Nov 2020 18:11:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[P² quantile estimator – estimating the median without storing values]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25201093">thread link</a>) | @ciprian_craciun
<br/>
November 24, 2020 | https://aakinshin.net/posts/p2-quantile-estimator/ | <a href="https://web.archive.org/web/*/https://aakinshin.net/posts/p2-quantile-estimator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span><time datetime="2020-11-24">November 24, 2020</time>
&nbsp;&nbsp;
<i></i>&nbsp;
<a href="https://aakinshin.net/tags/statistics/">Statistics</a>
<a href="https://aakinshin.net/tags/quantiles/">Quantiles</a>
<a href="https://aakinshin.net/tags/performance-telemetry/">Performance Telemetry</a></span></p><p>Imagine that you are implementing performance telemetry in your application.
There is an operation that is executed millions of times, and you want to get its “average” duration.
It’s not a good idea to use the arithmetic mean because the obtained value can be easily spoiled by outliers.
It’s much better to use the median which is one of the most robust ways to describe the average.</p><p>The straightforward median estimation approach requires storing all the values.
In our case, it’s a bad idea to keep all the values because it will significantly increase the memory footprint.
Such telemetry is harmful because it may become a new bottleneck instead of monitoring the actual performance.</p><p>Another way to get the median value is to use a sequential quantile estimator
(also known as an online quantile estimator or a streaming quantile estimator).
This is an algorithm that allows calculating the median value (or any other quantile value)
using a fixed amount of memory.
Of course, it provides only an approximation of the real median value,
but it’s usually enough for typical telemetry use cases.</p><p>In this post, I will show one of the simplest sequential quantile estimators that is called the P² quantile estimator
(or the Piecewise-Parabolic quantile estimator).</p><h3 id="the-p-quantile-estimator">The P² quantile estimator</h3><p>This algorithm was initially suggested in <a href="#Jain1985">[Jain1985]</a>.
Below you can find a short overview of this approach,
notes about typos in the original paper,
numerical simulation,
and a C# implementation.</p><h4 id="the-main-idea">The main idea</h4><p>Let’s say we have a stream of observations <span>\(\{ x_0, x_1, x_2, x_3, x_4, \ldots \}\)</span>
and we want to estimate p-quantile.
The suggested approach introduces five markers that correspond to the estimations of</p><ul><li><span>\(q_0\)</span>: The minimum</li><li><span>\(q_1\)</span>: The (p/2)-quantile</li><li><span>\(q_2\)</span>: The p-quantile</li><li><span>\(q_3\)</span>: The ((1+p)/2)-quantile</li><li><span>\(q_4\)</span>: The maximum</li></ul><p>The <span>\(q_i\)</span> values are known as the marker heights.</p><p>Also, we have to maintain the marker positions <span>\(\{ n_0, n_1, n_2, n_3, n_4 \}\)</span>.
These integer values describe actual marker indexes across obtained observations at the moment.</p><p>Next, we have to define the marker desired positions <span>\(\{ n'_0, n'_1, n'_2, n'_3, n'_4 \}\)</span>.
For the first <span>\(n\)</span> observations, these real values are defined as follows:</p><ul><li><span>\(n'_0 = 0\)</span></li><li><span>\(n'_1 = (n - 1) p / 2\)</span></li><li><span>\(n'_2 = (n - 1) p\)</span></li><li><span>\(n'_3 = (n - 1) (1 + p) / 2\)</span></li><li><span>\(n'_4 = (n - 1)\)</span></li></ul><p>In order to speed up the algorithm, we can precalculate increments of the desired positions which
should be added to the current values after each new observation:</p><ul><li><span>\(dn'_0 = 0\)</span></li><li><span>\(dn'_1 = p / 2\)</span></li><li><span>\(dn'_2 = (n - 1) p\)</span></li><li><span>\(dn'_3 = (n - 1) (1 + p) / 2\)</span></li><li><span>\(dn'_4 = (n - 1)\)</span></li></ul><p>Note that in the original paper, the authors use one-based indexing.
I decided to adapt it to the zero-based indexing which is more convenient from the implementation point of view.</p><h4 id="initialization">Initialization</h4><p>Once we collected the first five elements, we should perform initialization logic:</p><p><span>\[\left\{
\begin{array}{llll}
q_0 = x_{(0)}, &amp; n_0 = 0, &amp; n'_0 = 0,      &amp; dn'_0 = 0,\\
q_1 = x_{(1)}, &amp; n_1 = 1, &amp; n'_1 = 2p,     &amp; dn'_1 = p/2,\\
q_2 = x_{(2)}, &amp; n_2 = 2, &amp; n'_2 = 4p,     &amp; dn'_2 = p,\\
q_3 = x_{(3)}, &amp; n_3 = 3, &amp; n'_3 = 2 + 2p, &amp; dn'_3 = (1+p)/2,\\
q_4 = x_{(4)}, &amp; n_4 = 4, &amp; n'_4 = 4,      &amp; dn'_4 = 1.
\end{array}
\right.
\]</span></p><h4 id="marker-invalidation">Marker invalidation</h4><p>For each <span>\(x_j\)</span> for <span>\(j \geq 5\)</span>, we should invalidate our markers.</p><p>Firstly, we should adjust extreme marker heights
(if <span>\(x_j &lt; q_0\)</span>, we should update <span>\(q_0\)</span>; if <span>\(x_j &gt; q_4\)</span>, we should update <span>\(q_4\)</span>) and
find <span>\(k\)</span> such that <span>\(q_k \leq x_j &lt; q_{k+1}\)</span>
(or <span>\(q_k \leq x_j \leq q_{k+1}\)</span> for <span>\(k=3\)</span>):</p><table><thead><tr><th>Condition</th><th><span>\(q_i\)</span> update</th><th>k</th></tr></thead><tbody><tr><td><span>\(\phantom{q_0 \leq~} x_j &lt; q_0\)</span></td><td><span>\(q_0 = x_j\)</span></td><td>0</td></tr><tr><td><span>\(q_0 \leq x_j &lt; q_1\)</span></td><td></td><td>0</td></tr><tr><td><span>\(q_1 \leq x_j &lt; q_2\)</span></td><td></td><td>1</td></tr><tr><td><span>\(q_2 \leq x_j &lt; q_3\)</span></td><td></td><td>2</td></tr><tr><td><span>\(q_3 \leq x_j &lt; q_4\)</span></td><td></td><td>3</td></tr><tr><td><span>\(q_4 \leq x_j\)</span></td><td><span>\(q_4 = x_j\)</span></td><td>3</td></tr></tbody></table><p>Secondly, we should update the marker positions and the marker desired positions:</p><p><span>\[\begin{array}{lcl}
n_i = n_i + 1 &amp; \textrm{for} &amp; i = k + 1, \ldots, 4; \\
n'_i = n'_i + dn'_i &amp; \textrm{for} &amp; i = 0, \ldots, 4. \\
\end{array}
\]</span></p><p>Finally, we should adjust non-extreme marker heights (<span>\(q_i\)</span>) and positions (<span>\(n_i\)</span>) for <span>\(i \in \{ 1, 2, 3\} \)</span>
in the following way:</p><div><pre><code data-lang="cs"><span>for</span> <span>(</span><span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>3</span><span>;</span> <span>i</span><span>++)</span>
<span>{</span>
    <span>d</span> <span>=</span> <span>nꞌ</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span>
    <span>if</span> <span>(</span><span>d</span> <span>&gt;=</span>  <span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span>  <span>1</span> <span>||</span>
        <span>d</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&lt;</span> <span>-</span><span>1</span><span>)</span>
    <span>{</span>
        <span>d</span> <span>=</span> <span>sign</span><span>(</span><span>d</span><span>)</span>
        <span>qꞌ</span> <span>=</span> <span>Parabolic</span><span>(</span><span>i</span><span>,</span> <span>d</span><span>)</span>
        <span>if</span> <span>(!(</span><span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>&lt;</span> <span>qꞌ</span> <span>&amp;&amp;</span> <span>qꞌ</span> <span>&lt;</span> <span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]))</span>
            <span>qꞌ</span> <span>=</span> <span>Linear</span><span>(</span><span>i</span><span>,</span> <span>d</span><span>)</span>
        <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>qꞌ</span>
        <span>n</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>d</span>
    <span>}</span>
<span>}</span>
</code></pre></div><p>The core equation of the algorithm is a piecewise-parabolic prediction (P²) formula
that adjusts marker heights for each observation:</p><p><span>\[q'_i = q_i + \dfrac{d}{n_{i+1}-n_{i-1}} \cdot
\Bigg(
(n_i-n_{i-1}+d)\dfrac{q_{i+1}-q_i}{n_{i+1}-n_i} +
(n_{i+1}-n_i-d)\dfrac{q_i-q_{i-1}}{n_i-n_{i-1}}
\Bigg).
\]</span></p><p>Once we calculated <span>\(q'_i\)</span>, we should check that <span>\(q_{i-1} &lt; q'_i &lt; q_{i+1}\)</span>.
If this condition is false, we should ignore the parabolic prediction and use the linear prediction instead:</p><p><span>\[q'_i = q_i + d \dfrac{q_{i+d}-q_i}{n_{i+d}-n_{i}}.
\]</span></p><h4 id="the-result">The result</h4><p>Once you need the requested quantile estimation value, we should just take the value of <span>\(q_2\)</span>.</p><h4 id="typos-in-the-original-paper">Typos in the original paper</h4><p>A find a few typos in the original paper which may confuse readers who want to implement the algorithm from scratch:</p><ul><li>Page 1079, Box 1, B2:
<code>$i = k, \ldots, 5$</code>
should be replaced by
<code>$i = k + 1, \ldots, 5$</code></li><li>Page 1079, Box 1, B3:
<code>$\textbf{THEN}\; q_i \leftarrow q_i$</code>
should be replaced by
<code>$\textbf{THEN}\; q_i \leftarrow q'_i$</code></li></ul><h3 id="numerical-simulation">Numerical simulation</h3><p>It’s time to check how it works.
I decided to visualize sequential values of the following quantiles estimator:</p><ul><li><strong>The P² quantile estimator</strong><br>A sequential estimator that is described above.</li><li><strong>The Type 7 quantile estimator</strong><br>It’s the most popular quantile estimator which is used by default in
R, Julia, NumPy, Excel (<code>PERCENTILE</code>, <code>PERCENTILE.INC</code>), Python (<code>inclusive</code> method).
We call it “Type 7” according to notation from <a href="#Hyndman1996">[Hyndman1996]</a>,
where Rob J. Hyndman and Yanan Fan described nine quantile algorithms which are used in statistical computer packages.</li><li><strong>The Harrell-Davis quantile estimator</strong><br>It’s my favorite option in real life for non-sequential cases because
it’s more robust than classic quantile estimators based on linear interpolation,
and it provides more reliable estimations on small samples.
This quantile estimator is described in <a href="#Harrell1982">[Harrell1982]</a>.</li><li><strong>Actual</strong><br>The true median value which is taken from the underlying distribution.</li></ul><p>Below, you can find several plots for the following distributions:</p><ul><li><strong>Normal distribution</strong> <span>\(\mathcal{N}(0, 1)\)</span></li><li><strong>Gumbel distribution</strong> for <span>\(\mu = 0, \beta = 1\)</span></li><li><strong>Beta distribution</strong> <span>\(\textrm{Beta}(10, 2)\)</span></li><li><strong>Uniform distribution</strong> <span>\(\mathcal{U}(0, 1)\)</span></li><li><strong>Bimodal distribution</strong> (mixture of <span>\(\mathcal{N}(10, 1)\)</span> and <span>\(\mathcal{N}(20, 1)\)</span>)</li></ul><p>Here are the results:</p><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg" target="_blank" alt="normal"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg" target="_blank" alt="gumbel"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg" target="_blank" alt="beta"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg" target="_blank" alt="uniform"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg" target="_blank" alt="bimodal"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg"></picture></a></div></div><p>As you can see, The P² quantile estimator produces reasonable median estimates.
I also checked how it works on a considerable number of real data sets and
I’m pretty satisfied with the results.
You can also find a discussion about accuracy and the equation for the mean squared error in the original paper.</p><h3 id="reference-implementation">Reference implementation</h3><p>Below you can find a C# implementation of the discussed algorithm.
Also, you can use it via
the latest nightly version (0.3.0-nightly.64+) of <a href="https://github.com/AndreyAkinshin/perfolizer">perfolizer</a>.</p><div><pre><code data-lang="cs"><span>public</span> <span>class</span> <span>P2QuantileEstimator</span>
<span>{</span>
    <span>private</span> <span>readonly</span> <span>double</span> <span>p</span><span>;</span>
    <span>private</span> <span>readonly</span> <span>int</span><span>[]</span> <span>n</span> <span>=</span> <span>new</span> <span>int</span><span>[</span><span>5</span><span>];</span> <span>// marker positions
</span><span></span>    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>ns</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span> <span>// desired marker positions
</span><span></span>    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>dns</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span>
    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>q</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span> <span>// marker heights
</span><span></span>    <span>private</span> <span>int</span> <span>count</span><span>;</span>

    <span>public</span> <span>P2QuantileEstimator</span><span>(</span><span>double</span> <span>p</span><span>)</span>
    <span>{</span>
        <span>p</span> <span>=</span> <span>probability</span><span>;</span>
    <span>}</span>

    <span>public</span> <span>void</span> <span>AddValue</span><span>(</span><span>double</span> <span>x</span><span>)</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>count</span> <span>&lt;</span> <span>5</span><span>)</span>
        <span>{</span>
            <span>q</span><span>[</span><span>count</span><span>++]</span> <span>=</span> <span>x</span><span>;</span>
            <span>if</span> <span>(</span><span>count</span> <span>==</span> <span>5</span><span>)</span>
            <span>{</span>
                <span>Array</span><span>.</span><span>Sort</span><span>(</span><span>q</span><span>);</span>

                <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
                    <span>n</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>i</span><span>;</span>

                <span>ns</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
                <span>ns</span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>2</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>4</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>2</span> <span>+</span> <span>2</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>4</span><span>;</span>

                <span>dns</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
                <span>dns</span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>p</span> <span>/</span> <span>2</span><span>;</span>
                <span>dns</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>p</span><span>;</span>
                <span>dns</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>(</span><span>1</span> <span>+</span> <span>p</span><span>)</span> <span>/</span> <span>2</span><span>;</span>
                <span>dns</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>1</span><span>;</span>
            <span>}</span>

            <span>return</span><span>;</span>
        <span>}</span>

        <span>int</span> <span>k</span><span>;</span>
        <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>0</span><span>])</span>
        <span>{</span>
            <span>q</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
            <span>k</span> <span>=</span> <span>0</span><span>;</span>
        <span>}</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>1</span><span>])</span>
            <span>k</span> <span>=</span> <span>0</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>2</span><span>])</span>
            <span>k</span> <span>=</span> <span>1</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>3</span><span>])</span>
            <span>k</span> <span>=</span> <span>2</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>4</span><span>])</span>
            <span>k</span> <span>=</span> <span>3</span><span>;</span>
        <span>else</span>
        <span>{</span>
            <span>q</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
            <span>k</span> <span>=</span> <span>3</span><span>;</span>
        <span>}</span>

        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>k</span> <span>+</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
            <span>n</span><span>[</span><span>i</span><span>]++;</span>
        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
            <span>ns</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>dns</span><span>[</span><span>i</span><span>];</span>

        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>3</span><span>;</span> <span>i</span><span>++)</span>
        <span>{</span>
            <span>double</span> <span>d</span> <span>=</span> <span>ns</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>];</span>
            <span>if</span> <span>(</span><span>d</span> <span>&gt;=</span> <span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span> <span>1</span> <span>||</span> <span>d</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&lt;</span> <span>-</span><span>1</span><span>)</span>
            <span>{</span>
                <span>int</span> <span>dInt</span> <span>=</span> <span>Math</span><span>.</span><span>Sign</span><span>(</span><span>d</span><span>);</span>
                <span>double</span> <span>qs</span> <span>=</span> <span>Parabolic</span><span>(</span><span>i</span><span>,</span> <span>dInt</span><span>);</span>
                <span>if</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>&lt;</span> <span>qs</span> <span>&amp;&amp;</span> <span>qs</span> <span>&lt;</span> <span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>])</span>
                    <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>qs</span><span>;</span>
                <span>else</span>
                    <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>Linear</span><span>(</span><span>i</span><span>,</span> <span>dInt</span><span>);</span>
                <span>n</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>dInt</span><span>;</span>
            <span>}</span>
        <span>}</span>

        <span>count</span><span>++;</span>
    <span>}</span>
    
    <span>private</span> <span>double</span> <span>Parabolic</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>double</span> <span>d</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>q</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>d</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span> <span>*</span> <span>(</span>
            <span>(</span><span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>+</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>])</span> <span>+</span>
            <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span>
        <span>);</span>
    <span>}</span>

    <span>private</span> <span>double</span> <span>Linear</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>int</span> <span>d</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>q</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>d</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>+</span> <span>d</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>d</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]);</span>
    <span>}</span>

    <span>public</span> <span>double</span> <span>GetQuantile</span><span>()</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>count</span> <span>&lt;=</span> <span>5</span><span>)</span>
        <span>{</span>
            <span>Array</span><span>.</span><span>Sort</span><span>(</span><span>q</span><span>,</span> <span>0</span><span>,</span> <span>count</span><span>);</span>
            <span>int</span> <span>index</span> <span>=</span> <span>(</span><span>int</span><span>)</span> <span>Math</span><span>.</span><span>Round</span><span>((</span><span>count</span> <span>-</span> <span>1</span><span>)</span> <span>*</span> <span>p</span><span>);</span>
            <span>return</span> <span>q</span><span>[</span><span>index</span><span>];</span>
        <span>}</span>

        <span>return</span> <span>q</span><span>[</span><span>2</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div><h3 id="conclusion">Conclusion</h3><p>The P² quantile estimator allows estimating quantile values on a stream of numbers without storing individual …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aakinshin.net/posts/p2-quantile-estimator/">https://aakinshin.net/posts/p2-quantile-estimator/</a></em></p>]]>
            </description>
            <link>https://aakinshin.net/posts/p2-quantile-estimator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201093</guid>
            <pubDate>Tue, 24 Nov 2020 18:06:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to layer sales onto a bottom-up self-serve product]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200913">thread link</a>) | @jcs87
<br/>
November 24, 2020 | https://www.lennyrachitsky.com/p/sales-bottom-up | <a href="https://web.archive.org/web/*/https://www.lennyrachitsky.com/p/sales-bottom-up">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>👋 Hello, I’m&nbsp;<a href="https://twitter.com/lennysan">Lenny</a>&nbsp;and welcome to a ✨&nbsp;<strong>once-a-month-free-edition&nbsp;</strong>✨ of my newsletter. Each week I humbly tackle reader questions about product, growth, working with humans, and anything else that’s stressing them out at the office.</em></p><p><em>If you’re not a paid subscriber, here’s what you missed this month:</em></p><ol><li><p><a href="https://www.lennyrachitsky.com/p/magical-growth-loops">Magical growth loops</a></p></li><li><p><a href="https://www.lennyrachitsky.com/p/managing-up">How to manage up</a></p></li><li><p><a href="https://www.lennyrachitsky.com/p/product-management-startup-big-company">Startup PM vs. big company PM</a></p></li></ol><blockquote><h2>Q: I have a self-serve bottom-up SaaS product, and I'm trying to decide if, when, and how I should hire my first full-time salesperson.</h2></blockquote><p>One of the most surprising takeaways from <a href="https://www.lennyrachitsky.com/p/how-todays-fastest-growing-b2b-businesses-b11">my research into early B2B growth</a> was that <strong>100% of the bottom-up B2B companies ended up layering on a sales team</strong>. It’s rarely a question of if — it’s a question of when, and how.</p><p>Since I don’t have a lot of depth in sales myself, I went straight to my go-to person for all things sales: <a href="https://twitter.com/Kazanjy">Pete Kazanjy</a>. If you don’t know of Pete, he wrote <a href="https://www.foundingsales.com/">THE book on startup sales</a>, which he recently released as a physical book. This tweet was not an exaggeration:</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7c5ce225-1f4f-47eb-afe6-1da59ed276f5_1190x756.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7c5ce225-1f4f-47eb-afe6-1da59ed276f5_1190x756.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/7c5ce225-1f4f-47eb-afe6-1da59ed276f5_1190x756.png&quot;,&quot;height&quot;:756,&quot;width&quot;:1190,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1236090,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Pete generously agreed to write a guest post, and unsurprisingly, <strong>below you’ll find the most in-depth and tactical guide for adding sales into your org. </strong>Including<strong>:</strong></p><ol><li><p>Should I start with a self-serve product?</p></li><li><p>Should I ever involve salespeople?</p></li><li><p>When should I add a salesperson to the mix?</p></li><li><p>How do I set myself up for success during The Transition?</p></li><li><p>Common pitfalls to avoid</p></li></ol><p>Let’s dive in!</p><p><em>A bit more about Pete: In addition to authoring <a href="https://www.foundingsales.com/">Founding Sales</a>, Pete Kazanjy is also the founder of <a href="https://www.atriumhq.com/">Atrium</a>, makers of <a href="https://www.atriumhq.com/">data-driven management software for sales teams</a>, and founder of <a href="https://modernsaleshq.com/">Modern Sales</a> (the world’s largest peer-education community for sales operations and leadership professionals). He previously started and sold TalentBin (a recruiting software startup) to Monster Worldwide. You can find him on <a href="https://twitter.com/Kazanjy">Twitter</a> and <a href="https://www.linkedin.com/in/kazanjy/">LinkedIn</a>.</em></p><h2><strong>The Transition: </strong>Layering Sales onto a Bottom-Up Self-Serve Product</h2><p><em>By Pete Kazanjy</em></p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F91b85976-c55f-4f8a-9d16-2b3807f40e6a_2150x1171.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F91b85976-c55f-4f8a-9d16-2b3807f40e6a_2150x1171.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/91b85976-c55f-4f8a-9d16-2b3807f40e6a_2150x1171.png&quot;,&quot;height&quot;:793,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:180377,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>“Bottom-up” (or “product-led”) B2B growth is a hot topic in early-stage circles these days, and it makes sense why. A self-serve (“easy-in”) entry motion, that’s later combined with a strong direct sales motion, can make for explosive revenue growth as shown by IPO’d exemplars Zoom, Slack, Datadog, and private market dynamos like Airtable, Figma, and others. The combination of bottom-up self-serve plus direct sales can simultaneously lower CACs and power larger contract values (with expansion into enterprise contracts). This would never be possible in a pure self-serve model.</p><p><strong>The crux of this article is that waiting too long to add sales-involvement often leads to a large opportunity cost.</strong> Many successful self-serve applications saw their market position usurped by competitors who adopted a sales-assisted motion and effectively firewalled the self-serve-only products out of lucrative enterprise segments (e.g. Dropbox).</p><p>Below, I’ll help you understand if layering in sales is right for your business, when to take the leap, and how to navigate this critical transition successfully:</p><h2>First of all, should I even start with a self-serve product?</h2><p>Self-serve has a lot going for it, but it’s not necessarily a slam dunk decision for every product. Below are four questions to take into consideration before building a self-serve product (many of which can be answered before you launch):</p><h4><strong>1. Is the product simple enough for self-serve?&nbsp;</strong></h4><p>Successful self-service is about allowing a user to get to success and have that “aha” activation moment on their own. So the question that follows from this is how easy is it for users to get to that <em>aha</em> moment? Zoom is not complicated. Send someone a link or join someone’s link, and boom, you’re talking to them. Dropbox is pretty straight forward – download this client, and tell it what folders to sync. Airtable is a bit more advanced, but you can start simple, and they’ve invested heavily in a content catalog of templates and recipes to allow for self-served advancement.</p><p>Note, “complexity” is audience contingent. Tableau is not an easy product to use by any stretch of the imagination, but it’s self-serviceable by the technical data analysts for whom it was designed, and as such started self-serve with a desktop client download. Similarly, Stripe, Datadog, Twilio, New Relic, and other developer tools have all started self-serve, in that their technical audience has the capacity to self-serve even these more involved products. Some offerings are really just too complex to start self-serve, such as enterprise-grade marketing automation platforms like <a href="https://www.marketo.com/">Marketo</a>,&nbsp; and software targeting massive financial enterprises like <a href="https://blend.com/">Blend</a>.</p><h4><strong>2. Is this truly new and differentiated?&nbsp;</strong></h4><p>If your offering is truly new and differentiated, self-serve can be fantastic. When <a href="https://www.yesware.com/">Yesware</a> and <a href="https://www.mixmax.com/">Mixmax</a> first launched, most organizations didn’t have any sort of sales engagement email offerings for their salespeople. The notion of sending someone a link to a public calendar with which to book time was crazy talk when <a href="https://calendly.com/">Calendly</a> first launched. Software that proactively monitors your revenue stack’s automations and linkages for errors has never existed, which is why <a href="https://seesonar.com/">Sonar</a> can be self-serviced by sales and marketing operations staff. Personal business cloud app search has never existed before, and thus there’s no reason for a given user in an organization to not download and give <a href="https://getcommande.com/">Command E</a> a try.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8bdaeb77-d849-4833-aeb9-3add8098b57c_1017x574.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8bdaeb77-d849-4833-aeb9-3add8098b57c_1017x574.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8bdaeb77-d849-4833-aeb9-3add8098b57c_1017x574.png&quot;,&quot;height&quot;:574,&quot;width&quot;:1017,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><h4><strong>3. Can this co-exist with a (less good) incumbent in a given company’s stack?</strong></h4><p>Conversely, if your offering can coexist alongside inferior incumbents, self-serve can also work. Most organizations where Slack was adopted early-on already had Gmail and thus GChat. Organizations that start using <a href="https://www.getguru.com/">Guru</a> may have antiquated knowledge bases in Sharepoint or in Confluence wikis. This is where my company, <a href="https://www.atriumhq.com/">Atrium</a> lives. Customers will frequently have legacy analytics infrastructure, like Tableau or Looker, in place, but its complexity underserves the needs of the sales organization, leaving open an opportunity for Atrium to enable data-driven management for sales managers and sales operations staff in a way they’re currently not doing. Tableau and Looker still end up existing in the organization, but for more advanced analytics run by a data or analytics team.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4948801-3ec0-4078-9e3e-ef583adfe8d8_1017x575.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4948801-3ec0-4078-9e3e-ef583adfe8d8_1017x575.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a4948801-3ec0-4078-9e3e-ef583adfe8d8_1017x575.png&quot;,&quot;height&quot;:575,&quot;width&quot;:1017,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>By contrast, an “end to end” offering like a Human Resource Information System (e.g. Workday) or email sending platforms (e.g. Iterable) are not something you have “two of” in an organization. As such, even though <a href="https://www.saplinghr.com/">Sapling</a> makes delightful modern HRIS software, they don’t have a self-serve offering. <a href="https://iterable.com/">Iterable</a> makes great, modern customer engagement software, but it’s highly unlikely an organization would run a legacy system like <a href="https://www.oracle.com/cx/marketing/campaign-management/">Responsys</a> and Iterable side by side. Self-serve would likely not work for them.&nbsp;</p><h4><strong>4. Will you focus on small organizations?</strong></h4><p>If none of the above apply, you can still target smaller orgs that have not yet adopted a legacy provider with a self-service offering. <a href="https://stripe.com/">Stripe</a> is a great example here. Payments providers already existed when Stripe first came on the scene, so it was less likely for a mature e-commerce provider with an existing payments provider to switch to a new upstart. But because legacy providers were clunky with poorly documented APIs, Stripe was the obvious choice for new internet businesses who didn’t yet have a payments provider.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F57067d98-1583-4066-9827-5d27fffba73e_1012x569.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F57067d98-1583-4066-9827-5d27fffba73e_1012x569.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/57067d98-1583-4066-9827-5d27fffba73e_1012x569.png&quot;,&quot;height&quot;:569,&quot;width&quot;:1012,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p><a href="https://www.revops.io/">RevOps</a> makes fantastic quoting software for sales organizations that can be self-setup, but there’s no way anyone who already has Salesforce CPQ or Apttus is going to switch over to them. But for a 10 person sales organization that wants to systemize the creation of quotes and sending proposals, the idea of solving that problem in less than 5 minutes (rather than 3 months, like a standard Salesforce CPQ deployment) is really attractive. Which is why self-serve works for RevOps, specifically targeting this down-market segment.</p><h2><strong>Should I</strong> ever involve salespeople?&nbsp;</h2><p>Once you’ve determined whether self-serve is right for you, growth is going well, and you’re on your merry way (i.e. people are self-serving, getting to “aha”, transacting, and retaining), the next question would be “OK, well, should we get some salespeople involved here?” Well, that depends.</p><p>There are two primary reasons to add salespeople to a self-serve commercial motion:</p><ol><li><p>To facilitate the <strong>penetration or expansion</strong> of your solution into an organization where it has an initial foothold, and/or&nbsp;</p></li><li><p>To help <strong>raise conversion</strong> rates of your self-serve offer&nbsp;</p></li></ol><p>It turns out, humans are <em>really<strong> </strong></em>helpful when it comes to smoothing over weird edge cases, communicating complicated concepts, and persuading other people to surmount their inertia and try a new thing. They’re good at, you know, selling! But there’s a downside. Humans are expensive, and can only do so many tasks in a given amount of time - as compared to software which, once written, is really cheap to run, and can be scaled up to do as many tasks as you like. </p><p>So the question of “should I add sales to the mix?” is one of “will it help?” and “will the juice be worth the squeeze?”</p><h4><strong>1. Facilitating the penetration or expansion into an organization</strong></h4><p>This is the approach Slack and Zoom’s early sales motions helped with. It <em>wasn’t</em> about a salesperson showing up to an organization and saying “Hi, you need intra-organizational communication assistance, you should check out Slack.” Rather, teams within organizations might start using Slack to communicate amongst themselves, and the addition of an “Account Manager” (psssst...it’s a salesperson) helped unify those various pods into a single contract, while potentially adding more pods, was powerful. Similarly, in a more “single-player” offering, like <a href="https://getcommande.com/">Command E</a>, a handful of sales people in a 200 person sales organization might start using it to search their Salesforce opportunities, their Google Docs, and their Gmail, but a “Customer Success Specialist” (psssst...it’s a salesperson) offering to “give a personalized tour to the rest of the sales organization” could also be quite powerful (for expansion).</p><h4><strong>2. Helping with conversion</strong></h4><p>Sometimes even supposedly simplistic offerings …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lennyrachitsky.com/p/sales-bottom-up">https://www.lennyrachitsky.com/p/sales-bottom-up</a></em></p>]]>
            </description>
            <link>https://www.lennyrachitsky.com/p/sales-bottom-up</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200913</guid>
            <pubDate>Tue, 24 Nov 2020 17:50:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Convync is offering a free Zoom alternative to virtual Thanksgiving gatherings]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200912">thread link</a>) | @xzhao254
<br/>
November 24, 2020 | https://www.convync.com/thanksgiving/ | <a href="https://web.archive.org/web/*/https://www.convync.com/thanksgiving/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="detail-content">
        <h2>Invite your friends and family to the ultimate virtual Thanksgiving</h2>
        <p>Sign up below to generate a shareable link to your free,
            personal virtual dining room for up to 8 family and friends,
            no download necessary.
        </p>
        
    </div><div id="faq">
        <div>
            <div>
                <h3>What is this virtual dining room?</h3>
                <p>
                    It’s essentially a group video chat platform that takes place around
                    a virtual dining table. It’s like Zoom, but without the fatigue,
                    and with a delicious virtually baked turkey in the middle.
                </p>
            </div>
            <div>
                <h3>What is Convync?</h3>
                <p>
                    Convync is a collaboration platform where remote
                    teams can convene and sync in “virtual offices”.
                    It is a delightful alternative to existing communication
                    platforms and emphasizes real-time video and voice
                    communication for a better, more inclusive remote work
                    experience. Watch the demo video below or check out our
                    <a href="https://www.convync.com/">homepage</a>
                    for more information.
                </p>
                <iframe src="https://www.youtube.com/embed/tjcdGU_KgsA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
                </iframe>
            </div>
            <div>
                <h3>Who are we?</h3>
                <p>
                    We are a group of friends who met in college who are now trying
                    to build a company. Check us out on LinkedIn!
                </p>
                <p><a href="https://www.linkedin.com/in/xzhao16/">
                        <img id="profile__image" src="https://www.convync.com/static/images/thanksgiving/kevin.png" alt="Kevin">
                    </a>
                    <a href="https://www.linkedin.com/in/vivekgaddam/">
                        <img id="profile__image" src="https://www.convync.com/static/images/thanksgiving/vivek.png" alt="Vivek">
                    </a>
                    <a href="https://www.linkedin.com/in/desmond-caulley-bb64646b/">
                        <img id="profile__image" src="https://www.convync.com/static/images/thanksgiving/desmond.png" alt="Desmond">
                    </a>
                    <a href="https://www.linkedin.com/in/huynie/">
                        <img id="profile__image" src="https://www.convync.com/static/images/thanksgiving/huy.png" alt="Huy">
                    </a>
                </p>
            </div>
            <div>
                <h3>Is it secure?</h3>
                <p>
                    We built security into Convync ever since its inception.
                    All voice, video, and data communications
                    are peer-to-peer and fully encrypted. We use WebRTC,
                    a modern protocol for real-time communications used
                    by companies worldwide.
                </p>
            </div>
            <div>
                <h3>What devices are supported?</h3>
                <p>
                    Convync is currently supported on both MacOS and Windows using
                    your favorite browser. Mobile support is coming in the future.
                </p>
            </div>
            <div>
                <h3>
                    I would like to try out Convync at work, how can I sign up to beta test?
                </h3>
                <p>
                    You can beta test for free and create your own virtual office by following the steps in this
                    <a href="https://www.convync.com/accounts/getstarted/">link</a>. Feel free to also get in touch
                    with us at <a href="mailto:xz@convync.com">xz@convync.com</a>.
                </p>
            </div>
            <div>
                <h3>I have some ideas and suggestions for you, how can I get in touch?</h3>
                <p>
                    We would love to hear from you.
                    Hit us up at <a href="mailto:xz@convync.com">xz@convync.com</a> or contact us through <a href="https://www.linkedin.com/company/convync-inc">LinkedIn</a> &amp;
                    <a href="https://twitter.com/convync">Twitter</a>
                </p>
            </div>
        </div>
    </div></div>]]>
            </description>
            <link>https://www.convync.com/thanksgiving/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200912</guid>
            <pubDate>Tue, 24 Nov 2020 17:50:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do people find bugs?]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25200893">thread link</a>) | @bitwizzle
<br/>
November 24, 2020 | https://cryptologie.net/article/511/how-do-people-find-bugs/ | <a href="https://web.archive.org/web/*/https://cryptologie.net/article/511/how-do-people-find-bugs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>You might wonder how people find bugs. Low-hanging fruit bugs can be found via code review, static analysis, dynamic analysis (like fuzzing), and other techniques. But what about deep logic bugs. Those you can’t find easily. Perhaps the protocol implemented is quite complicated, or correctness is hard to define, and edge-cases hard to detect. One thing I’ve noticed is that re-visiting protocols are an excellent way to find logic bugs.</p>
<p>Ian Miers once said something like that: "you need time, expertise, and meaningful engagement”. I like that sentence, although one can point out that these traits are closely linked--you can’t have meaningful engagement without time and expertise--it does show that finding bugs take "effort".</p>
<p>OK. Meaningful engagement can lead to meaningful bugs, and meaningful bugs can be found at different levels.
So you're here, seating in your undies in the dark, with a beer on your side and some uber eats lying on the floor.
Your computer is staring back at you, blinking at a frequency you can't notice, and waiting for you to find a bug in this protocol.
What do you do?
Perhaps the protocol doesn't have a proof, and this leads you to wonder if you can write one for it...</p>
<p>It worked for Ariel Gabizon, who in 2018 <a href="https://electriccoin.co/blog/zcash-counterfeiting-vulnerability-successfully-remediated/">found a subtle error</a> in a <a href="https://eprint.iacr.org/2013/879">2013 zk-SNARK paper</a> used by the Zcash cryptocurrency he was working on.
He found it by trying to write a proof for the paper he was reading, realizing that the authors had winged it.
While protocols back in the days could afford to wing it, these days people are more difficult--they demand proofs.
The bug Ariel found could have allowed anyone to forge an unlimited amount of money undetected.
It was silently fixed months later in an upgrade to the network.</p>
<blockquote>
<p>Ariel Gabizon, a cryptographer employed by the Zcash Company at the time of discovery, uncovered a soundness vulnerability. The key generation procedure of [BCTV14], in step 3, produces various elements that are the result of evaluating polynomials related to the statement being proven. Some of these elements are unused by the prover and were included by mistake; but their presence allows a cheating prover to circumvent a consistency check, and thereby transform the proof of one statement into a valid-looking proof of a different statement. This breaks the soundness of the proving system.</p>
</blockquote>
<p>What if the protocol already had a proof though?
Well that doesn't mean much, people enjoy writing unintelligible proofs, and people make errors in proofs all the time.
So the second idea is that reading and trying to understand a proof might lead to a bug in the proof.
Here's some meaningful engagement for you.</p>
<p>In 2001, Shoup revisited some proofs and <a href="https://eprint.iacr.org/2000/060.pdf">found some darning gaps in the proofs for RSA-OAEP</a>, leading to a newer scheme OAEP+ which was never adopted in practice.
Because back then, as I said, we really didn't care about proofs.</p>
<blockquote>
<p>[BR94] contains a valid proof that OAEP satisfies a certain technical property which they call “plaintext awareness.” Let us call this property PA1. However, it is claimed without proof that PA1 implies security against chosen ciphertext attack and non-malleability. Moreover, it is not even clear if the authors mean adaptive chosen ciphertext attack (as in [RS91]) or indifferent (a.k.a. lunchtime) chosen ciphertext attack (as in [NY90]).</p>
</blockquote>
<p>Later in 2018, a series of discoveries on the proofs for the OCB2 block cipher quickly led to <a href="https://eprint.iacr.org/2019/311">practical attacks breaking the cipher</a>.</p>
<blockquote>
<p>We have presented practical forgery and decryption attacks against OCB2, a high-profile ISO-standard authenticated encryption scheme. This was possible due to the discrepancy between the proof of OCB2 and the actual construction, in particular the interpretation of OCB2 as a mode of a TBC which combines XEX and XE.</p>
</blockquote>
<blockquote>
<p>We comment that, due to errors in proofs, ‘provably-secure schemes’ sometimes still can be broken, or schemes remain secure but nevertheless the proofs need to be fixed. Even if we limit our focus to AE, we have many examples for this, such as NSA’s Dual CTR [37,11], EAX-prime [28], GCM [22], and some of the CAESAR submissions [30,10,40]. We believe our work emphasizes the need for quality of security proofs, and their active verification.</p>
</blockquote>
<p>Now, reading and verifying a proof is always a good idea, but it’s slow, it’s not flexible (if you change the protocol, good job changing the proof), and it’s limited (you might want to prove different things re-using parts of the proofs, which is not straight forward).
Today, we are starting to bridge the gap between pen and paper proofs and computer science: it is called formal verification.
And indeed, formal verification is booming, with a number of papers in the recent years finding issues here and there just by describing protocols in a formal language and verifying that they withstand different types of attacks.</p>
<p><a href="https://eprint.iacr.org/2019/526">Prime, Order Please! Revisiting Small Subgroup and Invalid Curve Attacks on Protocols using Diffie-Hellman</a>:</p>
<blockquote>
<p>We implement our improved models in the Tamarin prover. We find a new attack on the Secure Scuttlebutt Gossip protocol, independently discover a recent attack on Tendermint’s secure handshake, and evaluate the effectiveness of the proposed mitigations for recent Bluetooth attacks.</p>
</blockquote>
<p><a href="https://eprint.iacr.org/2019/779">Seems Legit: Automated Analysis of Subtle Attacks on Protocols that Use Signatures</a>:</p>
<blockquote>
<p>We implement our models in the Tamarin Prover, yielding the first way to perform these analyses automatically, and validate them on several case studies. In the process, we find new attacks on DRKey and SOAP’s WS-Security, both protocols which were previously proven secure in traditional symbolic models.</p>
</blockquote>
<p><img alt="tamarin" src="https://cryptologie.net/upload/tamarin-obseq-lemma-attack.jpg"></p>
<p>But even this kind of techniques has limitation! (OMG David when will you stop?)</p>
<p>In 2017 <a href="https://blog.cryptographyengineering.com/2017/10/16/falling-through-the-kracks/">Matthew Green wrote</a>: </p>
<blockquote>
<p>I don’t want to spend much time talking about KRACK itself, because the vulnerability is pretty straightforward. Instead, I want to talk about&nbsp;why&nbsp;this vulnerability continues to exist so many years after WPA was standardized. And separately, to answer a question: how did this attack slip through, despite the fact that the 802.11i handshake was&nbsp;formally proven secure?</p>
</blockquote>
<p>He later writes:</p>
<blockquote>
<p>The critical problem is that while people looked closely at the two components — handshake and encryption protocol —&nbsp;in isolation, apparently nobody looked closely at the two components as they were connected together. I’m pretty sure there’s an entire&nbsp;geek meme&nbsp;about this.</p>
</blockquote>
<p>pointing to the "2 unit tests. 0 integration tests." joke.</p>
<p><img alt="meme" src="https://cryptologie.net/upload/ezgif-3-a0aa048a0c79.gif"></p>
<p>He then recognizes that it’s a hard problem:</p>
<blockquote>
<p>Of course, the reason nobody looked closely at this stuff is that doing so is just&nbsp;plain&nbsp;hard. Protocols have an exponential number of possible cases to analyze, and we’re just about at the limit of the complexity of protocols that human beings can truly reason about, or that peer-reviewers can verify. The more pieces you add to the mix, the worse this problem gets.
In the end we all know that the answer is for humans to stop doing this work. We need machine-assisted verification of protocols, preferably tied to the&nbsp;actual source code that implements them. This would ensure that the protocol actually does what it says, and that implementers don’t further screw it up, thus invalidating the security proof.</p>
</blockquote>
<p>Well, Matthew, we do have formally generated code! <a href="https://hacl-star.github.io/">HACL*</a> and <a href="http://adam.chlipala.net/papers/FiatCryptoSP19/FiatCryptoSP19.pdf">fiat-crypto</a> are two examples.
Anybody has heard of that failing? I’d be interested…</p>
<p>In any case, what’s left for us? A lot! Formally generated code is hard, and generally covers small parts of your protocol (e.g. field arithmetic for elliptic curves).
So what else can we do?
Implementing the protocol, if it hasn’t been implemented before, is a no-brainer.
In 2016, Taylor Hornby an engineer at Zcash <a href="https://electriccoin.co/blog/fixing-zcash-vulns/">wrote about a bug he found</a> while implementing the zerocash paper into the Zcash cryptocurrency:</p>
<blockquote>
<p>In this blog post, we report on the security issues we’ve found in the Zcash protocol while preparing to deploy it as an open, permissionless financial system.
Had we launched Zcash without finding and fixing the InternalH Collision vulnerability, it could have been exploited to counterfeit currency. Someone with enough computing power to find 128-bit hash collisions would have been able to double-spend money to themselves, creating Zcash out of thin air.</p>
</blockquote>
<p>Perhaps re-implementing the protocol in a different language might work as well?</p>
<p><img alt="" src="https://cryptologie.net/upload/Screen_Shot_2020-11-23_at_10.16_.18_PM_.png"></p>
<p>One last thing, most of the code out there is not formally verified.
So of course, reviewing code works, but you need time, expertise, money, etc.
So instead, what about testing?
This is what <a href="https://github.com/google/wycheproof">Wycheproof</a> does by implementing a number of test vectors that are known to cause issues:</p>
<blockquote>
<p>These observations have prompted us to develop Project Wycheproof, a collection of unit tests that detect known weaknesses or check for expected behaviors of some cryptographic algorithm. Project Wycheproof provides tests for most cryptographic algorithms, including RSA, elliptic curve crypto and authenticated encryption. Our cryptographers have systematically surveyed the literature and implemented most known attacks. We have over 80 test cases which have uncovered more than&nbsp;40 bugs. For example, we found that we could recover the private key of widely-used DSA and ECDHC implementations.</p>
</blockquote>
<p>In all of that, I didn't even talk about the benefits of writing a specification... that's for another day.</p>
</article><p>Well done! You've reached the end of my post. Now you can <a href="">leave a comment</a> or read something else.</p></div>]]>
            </description>
            <link>https://cryptologie.net/article/511/how-do-people-find-bugs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200893</guid>
            <pubDate>Tue, 24 Nov 2020 17:49:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A simple tool to create beautiful CSS backgrounds]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200839">thread link</a>) | @parisianka
<br/>
November 24, 2020 | https://www.magicpattern.design/tools/css-backgrounds | <a href="https://web.archive.org/web/*/https://www.magicpattern.design/tools/css-backgrounds">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><nav><div><div><p><a href="https://www.magicpattern.design/features">Features</a></p><p><a href="https://www.magicpattern.design/examples">Examples</a></p><p><a href="https://www.magicpattern.design/tools">Tools</a></p><p><a href="https://www.magicpattern.design/blog">Blog</a></p><p><a href="https://www.magicpattern.design/pricing">Pricing</a></p></div></div><div></div></nav><div><h2>Beautiful pure CSS background patterns that you can actually use in your projects! <br>Created by<!-- --> <b><a target="_blank" rel="noreferrer" href="https://www.twitter.com/d__raptis">@d__raptis</a></b></h2></div><p><a type="button" href="https://www.producthunt.com/posts/css-background-patterns?utm_source=badge-featured&amp;utm_medium=badge&amp;utm_souce=badge-css-background-patterns" target="_blank"><img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=271102&amp;theme=dark&amp;period=daily" alt="CSS Background Patterns - FREE editable patterns that actually look cool | Product Hunt" width="250" height="54"></a></p><div></div><div><div><div><div><div></div><p>Back Color<!-- -->:</p></div><div role="group"></div></div><div><div><div></div><p>Front Color<!-- -->:</p></div><div role="group"></div></div><div><div><div></div><p>Opacity<!-- -->:</p></div><div role="presentation" tabindex="-1"></div></div><div><div><div></div><p>Spacing<!-- -->:</p></div><div role="presentation" tabindex="-1"></div></div></div><div><div><div><p>Wavy</p><div><div></div><div></div></div></div></div><div><div><p>Rhombus</p><div><div></div><div></div></div></div></div><div><div><p>ZigZag</p><div><div></div><div></div></div></div></div><div><div><p>ZigZag 3D</p><div><div></div><div></div></div></div></div><div><div><p>Moon</p><div><div></div><div></div></div></div></div><div><div><p>Circles</p><div><div></div><div></div></div></div></div><div><div><p>Diagonal</p><div><div></div><div></div></div></div></div><div><div><p>Diagonal v2</p><div><div></div><div></div></div></div></div><div><div><p>Paper</p><div><div></div><div></div></div></div></div><div><div><p>Isometric</p><div><div></div><div></div></div></div></div><div><div><p>Polka</p><div><div></div><div></div></div></div></div><div><div><p>Polka v2</p><div><div></div><div></div></div></div></div><div><div><p>Lines</p><div><div></div><div></div></div></div></div><div><div><p>Lines v2</p><div><div></div><div></div></div></div></div><div><div><p>Diagonal v3</p><div><div></div><div></div></div></div></div><div><div><p>Boxes</p><div><div></div><div></div></div></div></div><div><div><p>Lines v3</p><div><div></div><div></div></div></div></div><div><div><p>Lines v4</p><div><div></div><div></div></div></div></div><div><div><p>Triangle</p><div><div></div><div></div></div></div></div><div><div><p>Triangle v2</p><div><div></div><div></div></div></div></div><div><div><p>Rectangles</p><div><div></div><div></div></div></div></div><div><div><p>Cross</p><div><div></div><div></div></div></div></div></div></div><div><p><a type="button" href="mailto:jim@magicpattern.design">Submit your own CSS pattern</a></p></div><div><div><div><div><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 500 500"><path d="M249.893 400C194.606 400 149.787 444.771 149.787 500L350 500C350 444.771 305.181 400 249.893 400Z" fill="#6282E3"></path><path d="M249.893 300C194.606 300 149.787 344.772 149.787 400L350 400C350 344.772 305.181 300 249.893 300Z" fill="#6282E3"></path><circle cx="250" cy="100" r="100" fill="#4252EE"></circle><rect x="50" y="300" width="100" height="400" transform="rotate(-90 50 300)" fill="white"></rect></svg><div><h2>Create unlimited patterns in seconds. <br>Try it now, it's so easy.</h2><p>The easiest way to brand your business uniquely</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.magicpattern.design/tools/css-backgrounds</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200839</guid>
            <pubDate>Tue, 24 Nov 2020 17:45:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The new generation of biotech seed funds]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200836">thread link</a>) | @aaavl2821
<br/>
November 24, 2020 | https://www.baybridgebio.com/blog/top-seed-funds.html | <a href="https://web.archive.org/web/*/https://www.baybridgebio.com/blog/top-seed-funds.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        
	<p>by Jonathan Algoo and Richard Murphey</p>
	
        <p>This post will cover:</p>
          <ul>
            <li>A list of good seed-stage biotech investors</li>
            <li>A list of helpful resources on how to raise seed funding</li>
            <li>A discussion of the different types of investors funding seed-stage biotech companies</li>
            <li>An overview of the fundraising process</li>
            <li>Some alternative ways of funding your company</li>
          </ul>
	<p>Until very recently, biotech venture capital was only available to seasoned big pharma executives with extensive networks.  If you were a young scientific founder, raising your initial capital was very difficult.</p>
	<p>But that has changed.  In the last few years, dozens of new funds have emerged specifically to invest in young scientific founders.  These new investors are embracing founders that have traditionally been overlooked by the biotech VC community.</p>
	<p>If you are a young scientific entrepreneur, there has never been a better time to start a company.  But that doesn't mean it is easy.  This post will provide some resources to help first-time scientific founders understand the fundraising process.</p>
	<br>	
	<h3>The top biotech seed investors</h3>
	
	<p>To create this list, I asked biotech founders in my network which investors they would recommend.  I only asked founders who had raised $1M or more in seed capital in the last two years.  Thus every investor on this list (as of Q4 2020) is 1) actively investing and 2) is founder-friendly.</p>
	<p>The downside of this methodology is that this list is not comprehensive.  Because it is limited to founders I know, this list certainly omits great investors.  If you are a founder and think an investor should be added, <a href="https://goo.gl/forms/kHRFwxfXidRVZsDf1">let me know</a>.</p>
        <p>If you are interested in getting feedback on your pitch or learning more about investors and fundraising, we're experimenting with a few programs to help: 1) office hours and pitch feedback from founders who've recently raised seed capital and 2) "founder support groups" where 4-6 founders get together each month or so to help each other out.  If you're interested in participating, let us know <a href="https://forms.gle/gVawWFEukbDoQTPW9">here</a>.</p>
        <p>On to the investor list (thanks to Jonathan Algoo for pulling some of this info):</p>
	</div>
    </div><section>
    <div>
      <div>
	
	
	<p>There are a number of great guides on seed fundraising on the internet.  These guides are mostly written for software startups, but because many of the new generation of seed investors come from the Silicon Valley startup world, many of the lessons apply to biotech companies raising seed capital.  This post will provide some additional information that is specific to biotech.</p>
        <p>If you are raising seed money for the first time, these are a few of the excellent resources you should read:</p>
	<ul>
	  <li><a href="http://paulgraham.com/fr.html">How to raise money</a> by Paul Graham, cofounder of Y Combinator</li>
	  <li><a href="https://lifescivc.com/2013/09/ten-tips-for-raising-startup-capital-in-biotech/">Ten Tips for Raising Startup Capital in Biotech</a> by Bruce Booth, Partner at Atlas Venture</li>
	  <li><a href="https://youtu.be/LR6YQy-p3hU">How to pitch to biotech VCs: two 'mock pitches' and VC panel discussion</a> (video)</li>
	  <li><a href="http://paulgraham.com/convince.html">How to convince investors</a> by Paul Graham</li>
	  <li><a href="https://www.michaelseibel.com/blog/how-to-pitch-your-company">How to pitch your company</a> by Michael Seibel, President of Y Combinator</li>
	  <li><a href="https://lifescivc.com/2017/03/abundance-scarcity-venture-capital/">Of abundance and scarcity in venture capital</a> by Bruce Booth</li>
	  <li><a href="https://lifescivc.com/2016/05/tale-two-startup-worlds-biotech-tech-vc-ecosystems/">A tale of two startup worlds: biotech and tech VC ecosystems</a> by Bruce Booth</li>
	  <li><a href="https://youtu.be/0pXDNuRJTm4">How 5 young founders started and funded their biotech companies</a> (video)</li>
	  <li><a href="https://www.ycombinator.com/library/4A-a-guide-to-seed-fundraising">A guide to seed fundraising</a> by Geoff Ralston, president of Y Combinator</li>
	  <li><a href="https://www.ycombinator.com/library/3N-process-and-leverage-in-fundraising">Process and leverage in fundraising</a> by Aaron Harris, parter at Y Combinator</li>
	  <li><a href="https://techventures.columbia.edu/news-and-events/videos/venture-capital-perspectives-early-stage-biotech-investing-doug-cole-flagship">Early stage biotech investing</a> with Doug Cole, Flagship Pioneering</li>
	  <li><a href="https://www.ycombinator.com/library/2u-how-to-build-your-seed-round-pitch-deck">How to build your seed round pitch deck</a> by Aaron Harris</li>
	  <li>Venture Deals <a href="https://www.amazon.com/Venture-Deals-Smarter-Lawyer-Capitalist-dp-1119594820/dp/1119594820/ref=dp_ob_title_bk">book</a> and <a href="https://www.techstars.com/newsroom/learn-how-to-do-venture-deals-from-the-experts-free-7-week-class">free class</a> by Brad Feld and Jason Mendelson</li>
	  <li><a href="http://paulgraham.com/fundraising.html">A fundraising survival guide</a> by Paul Graham</li>
	  <li><a href="https://www.baybridgebio.com/blog/vc_basics_2.html">Mechanics of venture capital</a> by me</li>
	  <li><a href="https://a16z.com/2016/09/11/vc-economics/">16 definitions on the economics of VC</a> by Scott Kupor, Andreessen Horowitz</li>
	</ul>
	<p>Many of the above resources are created by people from the tech software world, and some are from traditional biotech investors.  There are many differences between these two broad categories of investors, some of them very deep.  A unique challenge of raising capital in biotech is navigating these differences.</p>
        <br>
        <h3>Differences between "tech-bio" and "biotech" investors</h3>
        
        <p>Many of the biotech investors who come from the software world refer to themselves as "tech-bio" or "bio" investors.  From ~2000 until a few years ago, "biotech" was a dirty word in the Silicon Valley software world – most big tech VCs specifically avoided biotech.  Recently, many of these tech VCs have started active biotech investing practices, and they've created new terminology to describe the space.  I’ll use "tech-bio" or "bio" to refer to investors coming to biotech from the software world, and "biotech" to refer to investors who have always specialized in biotech.  When I say "biotech" to refer to a topic other than investors, I'm just referring to the industry as a whole.</p>
        <p>One of the major differences between these categories of investor is that tech-bio investors are much more active and founder-friendly at the seed stage, so they are your best bet for raising initial capital.  However, tech-bio investors are <a href="https://www.baybridgebio.com/blog/top_vcs_2018.html">not as active</a> at the Series A stage as biotech VCs (with the exception of a few firms like a16z and DCVC).  So you will likely need to raise your Series A from traditional biotech investors, or a mix of biotech and tech-bio investors.</p>
        <p>The transition from tech-bio VC-funded seed stage company to biotech VC-funded Series A stage company can be difficult.  You may get conflicting advice from seed and Series A investors.  Biotech VCs may expect very different things than tech-bio VCs during a fundraising process, including much more scientific diligence and a different kind of pitch.  Biotech VCs may want a much lower valuation than you were expecting.  They may want to replace or supplement the senior management team, or have input into the scientific direction of your company (often focusing more on products than the platform).  They may take a more active role in your future fundraising and BD strategy.</p>
        <p>There are several tech-bio VCs that are active at the seed stage and have great relationships with Series A biotech VCs, or that lead Series A rounds themselves.  Raising from them can ease the seed-to-Series A transition (though there are downsides as well).  Getting feedback from Series A investors during your seed process (even if you don't expect to raise from them) can also help you figure out what kind of company to build that will attract Series A investors.</p>
        <p>While raising a Series A round can be tough now, the capital markets are evolving very quickly, and in a year or two, there may be many more VCs active in the Series A market.  There is a large wave of companies that raised seed rounds in the last few years that are starting their Series A process.  Many of them are high-quality companies with great teams that are finding a shortage of investors who support their vision.  Series A investors who combine the scientific rigor and expertise of biotech VCs with the ambition of tech VCs will find many quality companies eager to partner with them.</p>
	<br>	
	<h3>Types of investors</h3>
	
	<p>From the 2000s until a few years ago, the tech and biotech startup worlds have been largely independent.  Few investors funded both tech and biotech companies.  That has changed significantly in the last few years.  Below are some common types of investment firms that you may come across:</p>
	<p><b>“Traditional” early-stage biotech VCs</b>: These investors are large, established venture funds that primarily invest in Series A or later rounds, and primarily fund therapeutics companies.  They also do seed investing and venture creation as a way to feed their Series A investing practice, but they make their money on Series A and later-stage investments, not seed investments.  For many years, these were the only investors that regularly invested in seed-stage biotech companies, even though seed investing was an ancillary focus for them.</p>
	<p>These funds are highly specialized and experienced.  They have the most domain expertise, best track records and deepest scientific and industry networks of all early-stage biotech investors.  These firms are generally staffed with PhDs or MDs who understand science and have deep experience in the industry.</p>
	<p><i>Examples</i>: 5AM Ventures, Atlas Venture, ARCH Venture Partners, Flagship, The Column Group, Versant, MPM Capital, Third Rock Ventures, Polaris Partners</p>
	<p><b>Tech-bio VCs</b>: These are the software counterparts of the traditional biotech VCs -- the blue-chip venture funds – that have decided to invest in biotech in addition to tech / software.  Like their biotech counterparts, they make their money on Series A investments, but use seed investing to support their Series A and later-stage venture business.  These funds often got into biotech by doing seed investments to test the biotech waters, but many are becoming very active at the Series A stage.  Some of these funds have dedicated investment vehicles for biotech (like a16z and DCVC), some invest in biotech from their main software / tech fund, and some have dedicated funds for seed investing while others invest from the same fund for Series A and seed.  Most of these firms started out as software investors, but others (like Lux and DCVC) have traditionally invested in “hard tech” (robotics, AI, energy, etc – anything that isn't a mobile or web app), of which biotech is a subset.</p>
	<p>These funds have a different approach to investing than biotech VCs.  They tend to do diligence more quickly than biotech funds, offer more founder-friendly terms, and focus more on marketing to attract deal flow, win deals, and raise money from LPs (this is why so many tech VCs blog and tweet, while very few biotech VCs blog).  They also tend to be more open to investing in younger technical founders than biotech VCs.</p>
	<p><i>Examples</i>: a16z, DCVC, Lux Capital, 8VC</p>
	<p><b>“Tech-bio” seed funds</b>:  These funds are typically started and managed by people from the “tech” startup world, but differ from “tech-bio VCs” in that they make their money on seed …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.baybridgebio.com/blog/top-seed-funds.html">https://www.baybridgebio.com/blog/top-seed-funds.html</a></em></p>]]>
            </description>
            <link>https://www.baybridgebio.com/blog/top-seed-funds.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200836</guid>
            <pubDate>Tue, 24 Nov 2020 17:44:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby on Rails: Still the Best Web App Framework for Most Teams]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25200799">thread link</a>) | @sairamkunala
<br/>
November 24, 2020 | https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html | <a href="https://web.archive.org/web/*/https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>Earlier this year, I was in the position to choose the framework for the startup at which I’m now the CTO. I
could’ve chosen anything. I went with Rails.  And you should, too. It still is the best framework for getting up
and running <em>and</em> for continued iteration and development.</p>

<!-- more -->

<p>Writing a web app requires many moving pieces.  If you use something like Spring, Node, Express, or any other basic
library, you have a <em>lot</em> of decisions to make:</p>

<ul>
  <li>How are URLs routed to code?</li>
  <li>How are headers, params, and request bodies parsed?</li>
  <li>Where does the code live to manage this?</li>
  <li>How are responses created?</li>
  <li>How do we generate dynamic HTML?</li>
  <li>How do we mitigate against common security vulnerabilities such as cross-site scripting?</li>
</ul>

<p>Of course, web apps almost always have a database, which leads to more decisions:</p>

<ul>
  <li>How will we access the database?</li>
  <li>How is the database schema managed?</li>
  <li>What conventions will we use for table and column names?</li>
</ul>

<p>Then, there are concerns around the development environment:</p>

<ul>
  <li>How do we write tests?</li>
  <li>How can we execute a test using a web browser?</li>
  <li>How do we manage the data needed for our tests?</li>
  <li>How do we manage data needed to run the app locally?</li>
</ul>

<p>Finally, there are concerns around deployment and production:</p>

<ul>
  <li>How do I get JavaScript packaged for the browser?</li>
  <li>How do I manage CSS?</li>
  <li>How do I create cacheable bundles for CDNs?</li>
</ul>

<h2 id="the-cost-of-making-so-many-decisions">The Cost of Making So Many Decisions</h2>

<p>These decisions are only the beginning.  I’ve worked on web apps that used libraries only—no frameworks—and all of
these decisions plus more had to be made. Many had to be made before the team could start working.  But as time
went by and the team’s composition changed, managing these decisions was a constant tax.</p>

<p>…managing these decisions was a constant tax</p>

<p>Because <em>we</em> made these decisions and <em>we</em> configured our libraries to work in a particular way, it was not
uncommon for developers to want to know why we did it that way, and could we change it?  Many of these decisions
amount to conventions not enforceable with code, so a good chunk of our code reviews required making sure everyone
followed the conventions.</p>

<p>And then we would update our libraries to find out they were suddenly incompatible.  Because we’d hand-selected
libraries to solve each problem, we had no way to guarantee they all worked together other than making sure our app
still worked.  It was hard to see the value in the series of decisions that led to this architecture.</p>

<h2 id="stop-making-so-many-decisions">Stop Making So Many Decisions</h2>

<p>With Rails, you don’t have to make <em>any</em> of the decisions above. None.  Once you type <code>rails new</code> all of those
decisions are made.  True, there are more decisions you will have to make, but Rails will have eliminated a huge number of ultimately pointless decisions.</p>

<p>Rails will have eliminated a huge number of ultimately pointless decisions</p>

<p>It simply doesn’t matter how JavaScript is packaged, what your database naming conventions are, or how HTTP requests are routed to code. You need answers and conventions for all of that, yes, but the actual conventions don’t matter.</p>

<p>What you also need are the conventions to be enforced or managed in code, not documentation. That way, everyone is
incentivized to focus on the problems specific to their domain instead of the plumbing of their app.</p>



<p>This has been the value proposition for Rails since its inception over 15 year ago.  In that time, Rails and its
ecosystem have matured, improved, and continued moving forward.  The value Rails brings is still needed, and it is
<em>still</em> the best framework for most teams.</p>

<p>Engineers without Rails experience may continue to believe the fantasy that Rails does not scale or that it can’t
be used for “serious” problems.  Those of us <em>with</em> Rails experience know this isn’t true.  But what we also worry
about is that Rails apps can become unmaintainable.</p>

<h2 id="rails-helps-maintainability">Rails Helps Maintainability</h2>

<p>Hopefully, it’s obvious that no framework or set of libraries can ensure maintainability.  I would argue that Rails
gives you a better chance.  Rails—and its ecosystem—tend to evolve together, so you can rely on the stability of
your core tools over many years.</p>

<p>Rails basis in conventions also means that there are generally fewer parts of an app to get crufty as time goes by.
But, it’s still up to the team to establish conventions and ways of working to capitalize on that.  As it would be
on any team.</p>

<p>So what happens when the team stops making pointless decisions, worrying about library compatibility, and spending
code-review time on conventions?  They start thinking about the problems they need to solve. That’s why Rails is
the best web framework for most teams.</p>

  </section></div>]]>
            </description>
            <link>https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200799</guid>
            <pubDate>Tue, 24 Nov 2020 17:40:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No surprises here – On the absence of information in today’s media]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25200732">thread link</a>) | @s3v
<br/>
November 24, 2020 | https://www.turningchaos.com/essays/no-surprises-here | <a href="https://web.archive.org/web/*/https://www.turningchaos.com/essays/no-surprises-here">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-4a3121594376e73eb592"><div><h2>The absence of information in today’s press</h2><p>"<em>Nobody goes to a newspaper for news.</em>" —Martin Gurri</p><p>We're told we live in the information age. Statements like this often quote the mind-boggling amount of data produced on the internet using exotic-sounding words like zettabytes per day as proof. To function in this sea of data, we're supposed to find signals in the noise and read from credible sources of news and other information. With news media taking political stances, it's not that easy.</p><p>My assertion, paradoxically, is that polarization has greatly diminished the <em>quantity of information</em> being produced and consumed via today's press despite the sea of content they produce. The result is a loss of the press's effectiveness in their two functions within a healthy democracy, as a check on government and promoter of informed debate.</p><h2>Information</h2><p>It's important to define terms. What is information?</p><p>In the <a href="https://en.wikipedia.org/wiki/Information_theory">information theory</a> definition, the quantity of information in a message is related to the amount of <em>surprise</em> it contains. This idea of surprise is key so I'm going to spend some time on it.</p><p>Let's imagine you're receiving messages about some set of data and you're trying to determine its distribution. Each message contains one data point. Early on, as you receive messages, the information provided by each piece of data is high because you know very little about the data itself. With each new piece of information, you start to construct a representation of the overall data set like the one shown in the image below.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606176449103_6575"><div><p>After some number of points, you realize the data is a normal distribution or bell-curve and you can make some determination about its structure. In this case, the mean or average value as well as its width (or standard deviation). Let's say the average value is 0 and the standard deviation is 1. This means that 68% of the values will be between -1 and 1, 95% will be between -2 and 2, and &gt;99% will be between -3 and 3.</p><p>Great! Let's say the next set of messages that you get are 0, 0.1, and 1. Those numbers are completely within the expected range we calculated earlier. There's nothing particularly surprising about them, and as a result, <strong>there is almost no information</strong> contained within them.</p><p>What if you get a message of 10? Now there's a problem. There's almost no chance that the distribution we described above should include a value of 10. Getting 10 is very surprising. So surprising that it may mean the model we had for this data is entirely wrong. That's a lot of information contained in one message of 10, way more than the other messages we got earlier.</p><p>Why does 10 have so much information? It's because it's surprising. It causes us to challenge the model we had built. It could be that the message was a mistake, a fluke. But it could also be that the conclusions we held were wrong. <strong>The more high-information messages like this we get, the more we should start to challenge the beliefs we previously held.</strong> Now let's get back to media.</p><h2>News media</h2><p>In today's polarized media, each side of the media discourse has established its perspective, and the content they publish conforms to this perspective. When you go to a news outlet with a particular leaning, you may not know exactly what stories they'll be writing about, but you do know what <em>kind</em> of stories will be covered and from what perspective. Your knowledge about that outlet's outlook was built up over time as you encountered what they publish.</p><p>When one outlet consistently publishes pieces that align with their perspective, the information content provided by each article starts to diminish. When the theme of each article aligns within the expected distribution, there's no surprise and thus no information.</p><p>It's important to take a moment to distinguish surprise from shock. As you may be familiar, it's common for media to publish stories that have a shock value as they compete with other organizations for your attention. What I'm discussing in this essay isn't the shock value or the particular event that the news media is writing about, it's the perspective of the news organization and the degree of surprise that they published it. For example, you might be shocked at the behavior of one political party's behavior, but are you surprised by it, and more importantly, are you surprised that a news organization that takes the opposite position is publishing a story about it? Shock and surprise can be related, but there's a distinction here between headlines that are attention-grabbing and whether the content fits the mold of the news organization's narrative.</p><h2>Implications</h2><p>The danger of this is two-fold. First, if you only read from one source or a set of sources with similar outlooks, the media source's perspective can start to become yours. You end up with a world-view that aligns with the publisher's view. Since that source never prints anything which disputes that view, your perspective on the world becomes insulated and unchallenged. It's like the example above where we thought we knew the distribution was a bell-curve until we got a few message outliers. Those outliers demanded we reconsider our earlier conclusions. Except this time, <strong>the outliers exist but we never receive them</strong>. We go about our days oblivious to information that would challenge our world-view because it doesn't get published anywhere we look.</p><p>"<em>A free press is one of the pillars of democracy</em>." - Nelson Mandela</p><p>The second danger involves the media's role as a check on government. The branches of government exist to prevent the abuse of power by one another. <strong>The press exists to prevent the abuse of information by the government.</strong> It should question and investigate claims by the government to inform voters and further civic discourse.</p><p>However, this function requires the press to be viewed as impartial, truth-seeking, and without advancing an opinion except where explicitly noted (i.e. the opinion section). If the average voter comes to distrust the press, this function is lost. Articles that would normally inform the voter, providing surprise and evidence that would counter a particular world-view, instead go unread or dismissed. Voters either write off the press entirely or read solely from outlets with views that align with their own further solidifying their own beliefs. In either case, we end up with tribes of perspectives unwilling to seek a compromise that can allow the country to proceed collectively.</p><p>I'm not claiming that all reporters are like this. There are excellent reporters that seek truth regardless of politics. Unfortunately, this independent perspective is increasingly difficult to find. Well-reasoned, objective reporting doesn't generate the same attention as partisan emotion.</p><p>Instead, our press needs to promote information and surprise without bias. By only publishing from one narrative, they insulate the public (and themselves!) from information that could lead to honest debate and discovery. Likewise, our opinions should be formed from a careful examination of arguments and evidence on each side of the issue, <strong>reading from only one perspective is akin to not reading at all.</strong></p></div></div></div>]]>
            </description>
            <link>https://www.turningchaos.com/essays/no-surprises-here</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200732</guid>
            <pubDate>Tue, 24 Nov 2020 17:35:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launching Autocode 1.0]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200619">thread link</a>) | @tardismechanic
<br/>
November 24, 2020 | https://autocode.com/community/announcements/launching-autocode-1-0/ | <a href="https://web.archive.org/web/*/https://autocode.com/community/announcements/launching-autocode-1-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://autocode.com/community/announcements/launching-autocode-1-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200619</guid>
            <pubDate>Tue, 24 Nov 2020 17:25:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparison of Email Hosting Possibilities]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25200588">thread link</a>) | @Wronnay
<br/>
November 24, 2020 | https://blog.m5e.de/post/comparison-of-email-hosting-possibilities/ | <a href="https://web.archive.org/web/*/https://blog.m5e.de/post/comparison-of-email-hosting-possibilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>I’ve hosted my own Mailserver in various configurations since more than 6 years now. Since then I’ve taken multiple breaks from hosting it myself and explored other solutions for hosting emails with your own domain names.</p>
<p>Because my own Mailserver has lately problems (downtimes) I wanna explore other possibilities of hosting my email addresses.</p>
<p>So let’s take a look…</p>

<p>You simply setup a Mailserver with software like Mailcow, Mailu or Mail-in-a-Box on a virtual Server and manage it yourself.</p>
<p>Pros:</p>
<ul>
<li>You have the control</li>
<li>Unlimited domains</li>
<li>Unlimited mailboxes</li>
<li>Cheaper than most alternatives if you don’t look at the time you need for setup and maintenance</li>
</ul>
<p>Cons:</p>
<ul>
<li>Most cheap VPS don’t offer a lot of space and if you subtract the OS and installed software, then your space for mail is very limited</li>
<li>You need to invest a lot of time</li>
<li>You need a good spec VPS because Mailserver software and SPAM protection are performance intensive</li>
<li>Small VPS are often targeted by criminals and protection isn’t very easy</li>
</ul>
<p>This is what I’ve done the most of the time.</p>
<p>In the past this was very straightforward if you know how to setup and secure a mailserver but I’ve lately problems with things like DDoS and Brute Force Attacks.</p>
<p>A <a href="https://news.ycombinator.com/item?id=24154524">question</a> from me on Hacker News was even so heavily voted that it was for a short time on the front page of HN - so this seems to be a problem for other people too.</p>
<h2 id="pawnmail">Pawnmail<a href="#pawnmail" arialabel="Anchor">⌗</a> </h2>
<p>This service doesn’t exist anymore but I wanna mention it because it was one of the few free providers where you can get mailboxes for your own domains.</p>
<p>AFAIK that service doesn’t exist anymore because it was targeted by spammers and had problems with attacks.</p>
<h2 id="zoho-mail">Zoho Mail<a href="#zoho-mail" arialabel="Anchor">⌗</a> </h2>
<p>The free plan supports one domain with up to five users and has a 5GB/User and 25MB attachment limit.</p>
<p>Unusable for me because IMAP/ POP/ Active Sync are not included in the free plan.</p>
<p>Indian company, the CEO seems to support Hindu nationalism.</p>
<h2 id="yandex-mail">Yandex Mail<a href="#yandex-mail" arialabel="Anchor">⌗</a> </h2>
<p>The biggest player in my comparison. Offers 10 GB of storage, up to 1000 users and support for custom domains for free.</p>
<p>It seems like the only problem is that you have to trust a Russian company.</p>
<h2 id="mxroute">MXroute<a href="#mxroute" arialabel="Anchor">⌗</a> </h2>
<p>Has various plans for custom Domain Email Hosting. All plans include support for unlimited Domains and unlimited Email Accounts.</p>
<p>Especially the Black Friday deals seem to be pretty good every year.</p>
<p>US company, interestingly the Founder has worked for Christian Institutions - so both - the CEOs of Zoho and MXroute seem to be religious persons.</p>
<h2 id="mailcheapco">Mailcheap.co<a href="#mailcheapco" arialabel="Anchor">⌗</a> </h2>
<p>Cheap Hosting Provider for custom Domain Email, comparable to MXroute but it has more bad reviews than MXroute.</p>
<h2 id="migadu">Migadu<a href="#migadu" arialabel="Anchor">⌗</a> </h2>
<p>On the HN Post to this Article <a href="https://news.ycombinator.com/item?id=25201493">someone mentioned</a> Migadu.</p>
<p>Migadu is the only provider on this comparison from Switzerland and the pricing is more expensive compared to the US providers…</p>
<p>So you pay more but your data is probably also more secure.</p>
<h2 id="postaleio">postale.io<a href="#postaleio" arialabel="Anchor">⌗</a> </h2>
<p>French provider, offers a free plan which includes one domain, 2 mailboxes, 3 aliases and 1 GB per mailbox.</p>
<h2 id="conclusion">Conclusion<a href="#conclusion" arialabel="Anchor">⌗</a> </h2>
<p>Unfortunately it seems like the cheapest hosting possibilities are either trusting a Russian company which government maybe spies on you, trusting a US company which is also obliged to let the government spy on you or to go to an Indian company which is run by a Hindu nationalism supporter…</p>
<p>Hosting your own server isn’t the cheapest option but you are more in control.</p>
<p>I know there are privacy focused providers like ProtonMail or Fastmail out there but the cost of those services are way higher than the providers I mentioned at the time of this writing. (Especially if you want more than one mailbox. Most popular services are on a pay per-user basis, but MXroute, Mailcheap, Yandex and your own VPS are more on a pay per-storage / resources plan)</p>
<p>So I think I will split my domains to various services - in that way no government has all of my information and I am more immune to downtimes.</p>

      </div></div></div>]]>
            </description>
            <link>https://blog.m5e.de/post/comparison-of-email-hosting-possibilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200588</guid>
            <pubDate>Tue, 24 Nov 2020 17:22:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Edutainment Is Not Learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200474">thread link</a>) | @giansegato
<br/>
November 24, 2020 | https://giansegato.com/essays/edutainment-is-not-learning/ | <a href="https://web.archive.org/web/*/https://giansegato.com/essays/edutainment-is-not-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Before I got into productivity and performance, I used to spend many hours online ingesting vast troves of digital content. My information diet ranged from inspirational TED talks to specialized podcasts, from blog posts found on Hacker News to ebooks shared on Twitter.</p>
<p>I’m deeply curious, and I gave in to new content as much as I could. What could be the harm?—I thought. I <em>loved</em> spending my time this way. It felt useful, it was fun, and it nurtured my self-image as a “smart guy” — all at the same time. Truly, a learning hack.</p>
<p>Turns out I wasn’t hacking anything: The learning wasn’t real.</p>
<p>A few months ago, doubts began to creep into my mind about the effectiveness of my habits.</p>
<p>While I’d amped up my information consumption, I wasn’t retaining most of it. My memory was behaving like a leaky bucket. Sure, I was spending tens of hours listening to politics on the radio. But when I tried to use any of those points in a conversation, I found that I didn’t actually know enough to make a coherent argument. <strong>I knew the surrounding context, but the moment I needed to get specific my argument would crumble</strong>. Same for many other topics: the more technical they were, the less retention I had.</p>
<p>Where did all that information go?</p>
<p>The problem lied in how I was seeing learning, and therefore how I was approaching it.</p>
<p>Learning is what turns information consumption into long-lasting knowledge. The two things are different: while information is ephemeral, true knowledge is foundational. If knowledge were a person, information would be its picture.</p>
<p>It’s easy to think of learning in <em>accretive</em> terms: if I stack up enough information, it will eventually turn into knowledge. We tend to judge the world in material terms, and if data were tangible, an indefinitely growing memory might be reasonable to assume. The more information I consume, the more information I store, the information data I can later retrieve. The more business newsletters I’ll read, the more I’ll know business.</p>
<p>However, this line of thinking wasn’t really applicable to my case: I was undoubtedly consuming many business newsletters each week, but that wasn’t translating into long-term business knowledge.</p>
<p>I spent the last eight months trying to find an answer to this riddle. It took me deep into the topic of meta-learning: How do humans learn? And how can we learn better in the digital information age?</p>
<h2 id="learning-must-be-effortful">Learning must be effortful</h2>
<p>Unfortunately for us, human memory does not resemble storage, and “passive accumulation” isn’t how learning happens.</p>
<p>The truth is that we retain information only when we put <em>serious effort</em> into the process of learning. The intrinsic effortfulness of learning is not just a byproduct of the core activity, like shortness of breath during running. On the contrary: it’s what <em>actually</em> <em>enables</em> it. The relationship is causal.</p>
<figure>
    <img src="https://giansegato.com/img/essays/edutainment-not-learning/image_1.png"> 
</figure>

<p>I didn’t find a learning hack to avoid effort because there’s no such thing as easy learning: <strong>learning <em>must</em> be effortful in order for it to happen</strong>.</p>
<p>What surprised me the most is that learning is far more grounded in the physical world than I was comfortable admitting.</p>
<p>The most literal meaning of effort is <em>physical</em> effort (think of weight lifting at the gym). The same holds true with information retention: it works best when the process of assimilating it is <em>physically effortful</em>. Our memory shines when our learning is physical, visceral, and obvious, like the aching in your hands after a morning spent hand-writing.</p>
<p>Since they’re passive, easy, and exclusively digital, after this realization all my podcasts, e-books, audiobooks, newsletters, blog posts, videos, live webinars were suddenly deprived of their “<em>learning status</em>”. Instead, they assumed their proper place in my schedule as pure <em>entertainment</em> activities.</p>
<p>The fact of the matter is that digital products make it uniquely easy to trick yourself into thinking that you’re learning when you are actually being entertained.</p>
<p>What I still didn’t know was why our mind works like this. Is this just the current state of digital learning and teaching, or there’s actually a margin for <em>easy</em> learning to be found somewhere?</p>
<h2 id="the-neurology-of-learning">The neurology of learning</h2>
<p>I’m no expert in medicine, let alone neurology, but I did want to roughly understand what happens when we — as humans —&nbsp;create knowledge. Luckily I didn’t need profound medical expertise to get the gist of the matter.</p>
<p>Our brain is made of a web of interconnected neurons. The links between these neurons are called axons: long, slender projections of nerve fibers that transmit electrical impulses.</p>
<p>Around these axons, there’s an insulating membrane called myelin. It covers many neuronal axons and facilitates the propagation of electrical signals along neuronal circuits. The more myelin around an axon, the stronger and more connected the signal transmission will be.</p>
<figure>
    <img src="https://giansegato.com/img/essays/edutainment-not-learning/image_2.png"> 
</figure>

<p>Myelin is to neural transmissions as oxygen is to fire. It allows rapid information transfer over long distances, and it <a href="https://doi.org/10.1126/science.1261127">greatly increases</a> the speed of propagation of electric signals in our brain.</p>
<p>See it as water flowing through a pipe with dynamic, changing capacity. Pipes with greater capacity can move more water, more quickly than a small pipe or a slow drip. The more myelin supporting a neural connection, the easier it is to use that connection — and thus to use the skill or remember the topic associated with that connection</p>
<p>A key aspect of myelin is that it’s highly dynamic. It’s an integral component of our brain plasticity. So the question becomes: how is myelin generated, and why?</p>
<p>When we come across a new topic, new regions of the brain start activating. The more we use those new regions, the more myelin is synthesized, the easier that topic (or activity) gets.</p>
<p>We all know the old saying <em>practice makes perfect</em>. The more we use a certain region of our brain, the more our brain “prioritizes” and “hones” it. That is what leads to myelin: activity induces myelination, which leads to increased strength of connectivity and efficiency along those very neurons. It’s a self-reinforcing process.</p>
<p>In other words, it compounds.</p>
<figure>
    <img src="https://giansegato.com/img/essays/edutainment-not-learning/image_3.png"> 
</figure>

<p>See now why it’s so hard to learn? To learn anything we must make active use of unexplored regions of our brain <em>before</em> they’re ready. It’s, quite literally, getting out of the comfort zone. The more we use them, the more they get better. <strong>Learning is <em>structurally</em> hard.</strong></p>
<p>The truly mesmerizing thing about myelination is that it is correlated with active use of <em><a href="https://doi.org/10.1038/nn.4351">motor neurons</a></em>. It looks like human cognition is fundamentally grounded in sensory-motor processes: we retain information better when we associate some <em>physical activity</em> to it. <strong>The general intuition is that movement provides additional cues we can use to retrieve knowledge.</strong></p>
<p>We can see this effect happening when we take notes. A larger corpus of research is suggesting that taking notes physically — that is, by hand-writing them — is <a href="https://doi.org/10.3389/fpsyg.2020.01810">far more effective</a> than using a laptop. Keyboarding does not provide tactile feedback to the brain that the contact between pencil and paper does: this contact, this raw feedback, is the key to creating the neurocircuitry in the hand-brain complex, that <a href="https://doi.org/10.3389/fpsyg.2020.01810">evidence shows</a> supports memory and retention.</p>
<p>All of this means <strong>we need to radically reassess digital learning</strong>. We haven’t evolved to store information by passively watching Masterclass videos: that’s just not how our minds work.</p>
<p>However, the other side of this coin is that we’re living in times of unprecedented information surplus. This is an opportunity that we should learn to seize.</p>
<h2 id="creative-learning-in-a-digital-world">Creative learning in a digital world</h2>
<p>The best way to describe my information diet before discovering that effort is instrumental to learning would be <em>edutainment</em>.</p>
<p>Edutainment mixes education topics with entertainment methodologies. Even if edutainment optimizes for passive attention instead of effortful engagement (the opposite of learning), it’s not just “mere fun.” Deleting Twitter and unsubscribing from newsletters, as suggested by Deep Work advocates like <a href="https://www.calnewport.com/books/deep-work/">Cal Newport</a>, can actually end up <em>preventing</em> learning.</p>
<p>I see edutainment as <em>preparation for learning</em>: it’s a powerful explorative tool that can provide ideas and motivation to learn. And yet, it’s also not learning itself, in the same way as buying running shoes is not running.</p>
<p>Within this framework, “mindless” browsing online can be transformed into <em>scouting for learning opportunities</em>. It’s yet another searching problem where it’s key to balance the exploration of new opportunities with the commitment to the existing ones — a topic I wrote about at length in <a href="https://giansegato.com/essays/the-ebb-and-the-flow-of-product-development/">another essay</a>. It’s about balancing the time spent “scouting” for interesting topics online with the offline effort needed for long-term retention and integration.</p>
<hr>


<hr>
<p>Pragmatically, I solved this trade-off with a powerful tool: a learning inbox.</p>
<p>A learning inbox is a to-do list for stuff I’d like to actually learn. I picked up the idea from Andy Matuschak — legendary ed-tech expert —, who <a href="https://notes.andymatuschak.org/A_reading_inbox_to_capture_possibly-useful_references">used a similar concept</a> as a tool for capturing possibly-useful references. The learning inbox is a system that forces me to be mindful about what content is <em>learning</em>, and what is at the end of the day just <em>entertainment</em>.</p>
<p>Everything interesting I find on my way is sent to my learning inbox and from there gets triaged, be it a paper, an online essay, a blog post, a YouTube video, or a podcast. When an item ends up in there, there are three things that can happen: I either decide to actively engage with it, to file for future interest, or just trash it. Active engagement is exactly what it sounds like: <strong>I need to take effortful action to consume the content in the list</strong>, otherwise I automatically bucket it as entertainment.</p>
<p>In other words, I need to do something with it. To <em>create</em> something. Write a blog post about it, use it in a new project, test it on the field, teach it at a meetup. That’s why I speak at <a href="https://giansegato.com/about/#talks">many conferences</a>: it’s a learning tool.</p>
<p>In <a href="https://gettingthingsdone.com/">GTD fashion</a>, permanence in this list is temporary. It’s a release valve, not a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://giansegato.com/essays/edutainment-is-not-learning/">https://giansegato.com/essays/edutainment-is-not-learning/</a></em></p>]]>
            </description>
            <link>https://giansegato.com/essays/edutainment-is-not-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200474</guid>
            <pubDate>Tue, 24 Nov 2020 17:13:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jsonb: Few more stories about the performance (2017)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200456">thread link</a>) | @victorbojica
<br/>
November 24, 2020 | https://erthalion.info/2017/12/21/advanced-json-benchmarks/ | <a href="https://web.archive.org/web/*/https://erthalion.info/2017/12/21/advanced-json-benchmarks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span>21 Dec 2017</span></p><blockquote>
<p>As such, there’s really no “standard” benchmark that will inform you about
the best technology to use for your application. Only your requirements, your
data, and your infrastructure can tell you what you need to know.</p>
</blockquote>
<p>For already some time I can’t stop doing interesting/useful/weird (one at the
time) benchmarks to reveal some details on how to apply document-oriented
approach in the world of relational databases. Finally, I decided that I have a
critical mass of those details to share in the form of blog post. So welcome to
The Benchmark Club, where we’re going to discuss what it takes to create a fair
performance comparison of different databases. As you may guess, the first rule
of The Benchmark Club is to never share a reproducible benchmarks. But we
identify ourselves as a badass engineers, so we’re going to break this rule
today.</p>
<p><img src="https://erthalion.info/public/img/fight_club.jpg" width="100%"></p>

<h2 id="targets">Targets</h2>
<p>It’s not possible to compare all the existing solutions to store and process
the data in form of documents (although looks like people usually expect exactly
that), so I’ve limited my scope to PostgreSQL, MySQL and MongoDB:</p>
<ul>
<li>
<p>PostgreSQL - just because it’s an enlightened database, which is a part of my
very existence.</p>
</li>
<li>
<p>MySQL - also has quite decent implementation of binary json, so it’s
interesting to compare PostgreSQL with one of its closest rival.</p>
</li>
<li>
<p>MongoDB - one of the most popular NoSQL databases. Sort of synonym for
“document-oriented” approach as for me.</p>
</li>
</ul>
<h2 id="environment">Environment</h2>
<p>Unfortunately for me, I don’t have any bare metal servers to test the
performance. So all my tests were made using AWS EC2, which has its own pros
and cons:</p>
<ul>
<li>Super easy to reproduce the same results on your own.</li>
<li>Many companies use AWS as a main platform to run their infrastructure, so my
results maybe even more relevant for them.</li>
<li>But there are some implications of using EC2 for performance tests.</li>
</ul>
<p>My typical benchmark environment had two EC2 instances, one for a workload
generator, another for a database. I was using <code>m4.large</code> instance type with a
gp2 ELB volume and the default Ubuntu 16.04 AMI image, so HVM virtualization
was available. Both instances were in the same availability zone, VPC and
placement group, so we eliminated significant networking issues.</p>
<p>But it’s not really enough to be confident in results. There are still some
interesting performance-relevant <a href="https://henrikingo.github.io/presentations/Highload%202017%20-%20Measuring%20performance%20variability%20of%20EC2/index.html#/title">details</a> about using
EC2 (e.g. it’s usually advised to disable hyper-threading to get better
latency), and in general benchmarking is quite dangerous area (only insane
persons join The Benchmark Club, because everyone thinks he is smarter than
you, but no one wants to help). To at least partially mitigate those possible
issues and make sure that my tests are more reproducible I tried to be as
careful as possible - for almost every use case I did at least 4 rounds of the
same benchmark (and usually even more).</p>
<p>As a tool for benchmarks I used YCSB, which is a quite well-known instrument to
test the performance of NoSQL databases. It provides many interesting types of
workload, but unfortunately only documents of quite simple structure are
involved. To be more precise, YCSB uses simple flat documents with some number
of keys and corresponding values, which is not that close to the reality from
my point of view. That’s why I also created a <a href="https://github.com/erthalion/ycsb">fork</a> of this tool,
where I introduced the possibility of creating documents with some complex
structure, and drivers for PostgreSQL (jsonb) and MySQL (binary json) (warning:
I should mention, that it’s not a code I can be proud of, but you know - “it
works for me”).</p>
<p>To create an environment, I have an <a href="https://github.com/erthalion/ansible-ycsb">ansible playbook</a> (for
those of you who had seen my talks about this topic on various conferences,
this playbook always was public, but after some time I stopped to include it
into my slides, since there was no real feedback), that accepts some parameters
like EC2 key, availability zone and other stuff, and creates all the required
instances, configures them, and starts data load stage and actual test. The
only thing you need to do manually is to create subnets with all the security
groups for your databases (I’m just to lazy to automate it). Unfortunately,
Ansible itself became an issue at some point, since it still uses Python2,
which is not available on the latest versions of Ubuntu, so there are few hack
required to be able to use it.</p>
<p>Besides running database itself, every instance also collecting system metrics
using <code>sar</code> tool (plus some database related metrics from <code>pgview</code> or
<code>mongotop</code>), and they’re available after a test.</p>
<p>Few random notes. I’m not sure about current situation, but when I was writing
all those scripts there was no proper service in the latest versions of Ubuntu
for the latest version of MongoDB. Which means I had to include one more
template and create this service myself.</p>
<p>Another nice thing that costs me several sleepless nights is something called
“unattended-upgrades”. This Ubuntu service could wake up sometimes and start to
update the system. Besides the minor fact that I just don’t need to have this
overhead, this caused test failures sometimes because of a lock for package
installation. So I disabled it. Generaly speaking, to prevent flaky tests it
totally makes sense to add Ansible retry to update packages section, something
like:</p>
<pre><code>until: update_result.stderr == ""
retries: 10
delay: 1
ignore_errors: yes
</code></pre>
<p>One more thing that you can do to make your life easier is to add</p>
<div><div><pre><code>host_key_checking = False # we know our hosts
timeout = 60  # or even more
pipelining = True # reduce number of SSH operations
</code></pre></div></div>
<p>into <code>ansible.cfg</code> on your host machine (<code>pipelining</code> theoretically can break
compatibility with sudoers configurations, but I never experienced anything
like that in my tests).</p>
<p>To save some money and time, almost for all tests I actually used already
prepared AMI images with everything I need. But if you preload test data into
this image, you have to understand, that obviously there will be no data in the
cache at the start of a test.</p>

<p>In my tests I used some variety of database versions:</p>
<ul>
<li>
<p>PostgreSQL 9.6.3/10</p>
</li>
<li>
<p>MongoDB 3.2.5/3.4.4</p>
</li>
<li>
<p>MySQL 5.7.19/8.0.3</p>
</li>
</ul>
<p>To make it simple, you can assume that we’re using the latest stable version,
and I’m going to mention a particular version only if it makes some performance
difference.</p>
<p>When dealing with configurations for these databases, I tried to adjust only
those options, that were directly related to either instance parameters or the
nature of a workload. Everything more detailed I left for the next part of my
research. This led me to the following important options:</p>
<ul>
<li>
<p>PostgreSQL</p>
<ul>
<li>
<p>shared_buffers</p>
</li>
<li>
<p>effective_cache_size</p>
</li>
<li>
<p>max_wal_size</p>
</li>
<li>
<p>checkpoint_completion_target</p>
</li>
</ul>
</li>
<li>
<p>MySQL</p>
<ul>
<li>
<p>innodb_buffer_pool_size</p>
</li>
<li>
<p>innodb_log_file_size</p>
</li>
</ul>
</li>
<li>
<p>MongoDB</p>
<ul>
<li>
<p>write concern level</p>
</li>
<li>
<p>checkpoints</p>
</li>
<li>
<p>eviction</p>
</li>
<li>
<p>transaction_sync (just out of curiosity, it’s not really recommended to
use)</p>
</li>
</ul>
</li>
</ul>
<p>Few important notes:</p>
<ul>
<li>
<p>proper data consistency is used for all the tests (which means write concern
journaled for MongoDB)</p>
</li>
<li>
<p>SSL was disabled (it’s like that for PostgreSQL and MongoDB, for MySQL driver
I had to disable it manually)</p>
</li>
<li>
<p>for PostgreSQL and MySQL prepared statements were used</p>
</li>
<li>
<p>all databases were used in a single instance form. For MongoDB it’s actually
quite unnatural, and usually you want to use replication to get the eventual
consistency. But at the same time it allows us to test all involved databases
under the similar conditions when they do more or less the same work. Right
now I’m working on the second part of my test suite to test databases
clusters, so you can think about this one as a first step, that nonetheless
is quite interesting by itself.</p>
</li>
</ul>
<p>And few words about types of documents that were involved. With the default
YCSB I can define:</p>
<ul>
<li>
<p>“simple” or “small” document - 10 keys and values, every value is 100
random characters</p>
</li>
<li>
<p>“large” document - 100 keys and values, every value is 200 random characters</p>
</li>
</ul>
<p>And using my fork I also can define:</p>
<ul>
<li>“complex” document - 100 keys and values that form a tree with 3 nesting
levels, every value is 100 random characters</li>
</ul>

<p>YCSB provides several interesting <a href="https://github.com/brianfrankcooper/YCSB/wiki/Core-Workloads">types of workload</a> to
simulate real world situations. Let’s start with the simples one, <code>WorkloadC</code>,
that consists 100% of read queries. Every read query fetches a single document
by its ID, so we need to discuss how can we index our documents:</p>
<ul>
<li>
<p>PostgreSQL - we can index either a single path/multiple paths (using regular
functional index) or all paths (using GIN index) inside a document.</p>
</li>
<li>
<p>MongoDB - we can index either a signle path or multiple paths inside a
document.</p>
</li>
<li>
<p>MySQL - there is no direct support for indexing binary json, but we can
create a virtual column and index it as usual. So, again, a single or
multiple paths inside a document.</p>
</li>
</ul>
<p>Let’s try to make a simple performance test using “default” indexing approach,
which means we’re going to index an entire document for PostgreSQL, only ID in
MongoDB, and only ID in a separate virtual column in MySQL.</p>
<p><img src="https://erthalion.info/public/img/benchmarks/select_jsonb_path_ops_throughput.png" width="100%"></p>
<p>This graph represents throughput for under a <code>WorkloadC</code> for all the databases.
By Ox we have a number of clients that are querying our databases, so basically
it’s a level of concurrency. By Oy there is a throughput value.</p>
<p><img src="https://erthalion.info/public/img/benchmarks/select_jsonb_path_ops_latency_99.png" width="100%"></p>
<p>On this graph you can see a 99th percentile of latency for the same test.</p>
<p>And I bet you already have a lot of questions about this data. Since we strive
to get a fair comparison, we need to discuss and explain them:</p>
<ul>
<li>
<p>Why there is a spike for all of them at about 20 clients?</p>
</li>
<li>
<p>Why there is a performance degradation for MongoDB when number of clients is
growing?</p>
</li>
<li>
<p>Why there is a performance gap between MySQL and MongoDB?</p>
</li>
<li>
<p>Why there is a performance gap between PostgreSQL and MongoDB?</p>
</li>
</ul>
<h2 id="spike-at-20-clients">Spike at 20 clients</h2>
<p>That one is probably the easiest one and it relates to an instance
configuration. The next graph shows the CPU consumption for PostgreSQL
in a test with exactly 20 clients.</p>
<p><img src="https://erthalion.info/public/img/benchmarks/pg_select_cpu_20.png" width="100%"></p>
<p>As you can see, CPU resources almost completely consumed, and judging from the
same metrics before 20 clients we still have some capacity. So that’s the</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://erthalion.info/2017/12/21/advanced-json-benchmarks/">https://erthalion.info/2017/12/21/advanced-json-benchmarks/</a></em></p>]]>
            </description>
            <link>https://erthalion.info/2017/12/21/advanced-json-benchmarks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200456</guid>
            <pubDate>Tue, 24 Nov 2020 17:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding web animations: a half-baked history]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200336">thread link</a>) | @weareferal
<br/>
November 24, 2020 | https://weareferal.com/blog/a-half-baked-history-of-web-animations/ | <a href="https://web.archive.org/web/*/https://weareferal.com/blog/a-half-baked-history-of-web-animations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p><a href="https://weareferal.com/blog/category/tech-chat/">Tech Chat</a></p><p><time datetime="2019-09-12">September 12, 2019</time><img data-src="https://cdn.weareferal.com/assets/uploads/illustrations/feral-post_07.jpg?mtime=20200930100108&amp;focal=none" alt="Feral post 07" src="https://cdn.weareferal.com/assets/uploads/illustrations/feral-post_07.jpg?mtime=20200930100108&amp;focal=none"></p><p>A long-winded and uninformed walk-through of web animations through the ages.</p><hr></div><section data-component="textBlock"><p>Pic­ture the scene: you like your site, but it’s a&nbsp;bit <em>bland</em>. You want it to <span>POP</span>. You start by adding a&nbsp;few sim­ple <span>CSS</span> ani­ma­tions to your but­tons. They look pret­ty good. Then you decide you want to have nice page tran­si­tions. No prob­lem, there are lots of libraries to help with that — you pop one in. Maybe you should ani­mate your land­ing page? In fact, why not have each ele­ment ani­mate <em>at dif­fer­ent times</em>. Hmmm, might need some JavaScript for that. <span>OK</span>, well that <em>works</em> but let’s try it out on my&nbsp;phone&nbsp;…</p><p>Soon it’s <span>3</span>a.m. and you’re knee-deep in the Chrome Dev-Tools try­ing to make sense of your pathet­ic <span>3</span>fps page-load expe­ri­ence. You haven’t seen your friends or fam­i­ly in&nbsp;days.</p><figure><img src="https://cdn.weareferal.com/assets/uploads/posts/Clockwork-Orange.jpg?mtime=20200930100059&amp;focal=none" data-image="1555"></figure><p>The point is, once you get beyond sim­ple fade-ins, ani­ma­tions on the web are <u>hard</u>.</p><p>The goal of this post is to try give you the con­text as to <em>why</em> they’re hard, as well as a&nbsp;brief his­to­ry and run-down of the avail­able approach­es to tack­ling animation.</p><p>This post won’t give you a&nbsp;detailed expla­na­tion of how each approach works, but it will give you the under­stand­ing you need to be able to han­dle ani­ma­tion on the&nbsp;web.</p><h2>Overview</h2><p>To get a&nbsp;good overview of where we cur­rent­ly stand with brows­er ani­ma­tions, here’s what we’re going to look&nbsp;at:</p><ul><li>Flash 😱</li><li><span>SMIL</span> (<em><span></span>​<span>“</span>smile”)</em></li><li><span>CSS</span> Tran­si­tions and Animations</li><li>JavaScript ani­ma­tions</li><li>Web Ani­ma­tion <span>API</span> (<span>WAAPI</span>)</li><li><span>3</span><sup>rd</sup> par­ty ani­ma­tion frame­works and libraries</li></ul><p>For con­text, let’s begin with the most infa­mous (and now defunct) approach.</p><h2>Flash</h2><figure><img src="https://cdn.weareferal.com/assets/uploads/posts/Feral-90s.png?mtime=20200930100110&amp;focal=none" data-image="4axj6pwr8q78"><figcaption>Fer­al’s first web­site cir­ca&nbsp;<span>1994</span></figcaption></figure><p>Back when browsers were still at war, there weren’t many cross-plat­form stan­dards to point to. The web was young and exper­i­men­ta­tion was rife. Devel­op­ers want­ed to be able to cre­ate inter­ac­tive web­sites and games, what­ev­er the&nbsp;cost.</p><p>Flash was the answer. It was a&nbsp;pro­pri­etary, closed-source appli­ca­tion (even­tu­al­ly owned by Adobe) that allowed devel­op­ers to build these inter­faces and games and then dump them into the brows­er via the <code>&lt;object&gt;</code> tag and a&nbsp;brows­er plug-in. The brows­er <em>could</em> inter­act with them but it was the respon­si­bil­i­ty of the installed Flash plug-in to run every­thing. Essen­tial­ly the brows­er was out­sourc­ing its job to&nbsp;Flash.</p><p>While Flash was a&nbsp;great tech­nol­o­gy, it went against the core prin­ci­ple of the web; to be open and acces­si­ble. As the web matured, a&nbsp;slew of new stan­dards and specs began to take shape intro­duc­ing the abil­i­ty to do many of the things Flash could do, but native­ly via the brows­er. At the same time, smart­phones came along. <a href="https://www.apple.com/hotnews/thoughts-on-flash/">Apple famous­ly did­n’t want to sup­port Flash in their iPhone</a> and the writ­ing was on the&nbsp;wall.</p><p>To cut a&nbsp;long sto­ry short, Flash sup­port has been dep­re­cat­ed on all major browsers and Adobe will be putting it out to pas­ture in <span>2020</span>.&nbsp;<span>RIP</span>.</p><p>So how do we ani­mate on the web with­out&nbsp;Flash?</p><h2>SVGs and&nbsp;<span>SMIL</span></h2><p>Flash pro­vid­ed the ecosys­tem for cre­at­ing ani­ma­tions that could be plugged into the web, but the core com­po­nent at the heart of these ani­ma­tions was <em>vec­tor graph­ics</em>.</p><p>Vec­tor graph­ics are <em>res­o­lu­tion inde­pen­dent</em> image files. <a href="https://www.shutterstock.com/blog/raster-vs-vector-file-formats">In con­trast to <em>raster</em> image for­mats</a> such as <code>pngs</code><code>jpgs</code> and <code>gifs</code>, vec­tor graph­ics are made up of paths and shapes instead of pix­els. These res­o­lu­tion-inde­pen­dent ele­ments are per­fect for icons and illus­tra­tions, par­tic­u­lar­ly on todays high-res­o­lu­tion screens.</p><p>While Flash was devour­ing the web in the <span>2000</span>s, the <span>SVG</span> stan­dard was being built to sup­port <em>open</em> vec­tor graph­ics in the brows­er. Although these weren’t well sup­port­ed until the <span>2010</span>s, they pro­vid­ed the bedrock for high qual­i­ty graph­ics and ani­ma­tions via the <code>.svg</code> file for­mat and <code>&lt;svg&gt;</code><span>HTML</span> element.</p><p>You are prob­a­bly famil­iar with SVGs. They are based on <span>XML</span>, so they look very like our reg­u­lar&nbsp;<span>HTML</span>:</p></section><section><pre><code data-component="syntax-highlighter">&lt;svg&gt;
  &lt;g&gt;
      &lt;rect ...&gt;
      &lt;path .. &gt;
      &lt;line ...&gt;
      &lt;circle ...&gt;
  &lt;/g&gt;
&lt;/svg&gt;
</code></pre></section><section data-component="textBlock"><p>Around the same time SVGs were being stan­dard­ised to han­dle <em>vec­tor graph­ics</em>, we were also look­ing for ways to stan­dard­ise mul­ti­me­dia on the web <em>in gen­er­al</em>. Pro­pri­ety plug-ins were han­dling almost all of the audio (remem­ber RealPlay­er?), video and ani­ma­tion on the web and this was becom­ing a&nbsp;closed-source quagmire.</p><p>To han­dle this, the <span>SMIL</span> (“Syn­chro­nised Mul­ti­me­dia Inte­gra­tion Lan­guage” 🤷🏻‍♂️) stan­dard was devel­oped. Pro­nounced <em>smile</em>, this was an ambi­tious stan­dard aimed at pro­vid­ing the frame­work for deliv­er­ing video, audio and ani­ma­tions in a&nbsp;more open, user-friend­ly and acces­si­ble way. If <span>HTML</span> allowed you to deliv­er a&nbsp;<em>doc­u­ment</em> to the brows­er, <span>SMIL</span> would allow you to deliv­er and coor­di­nate <em>mul­ti­me­dia</em> to the browser.</p><p>Includ­ed in the <span>SMIL</span> stan­dard were the tools need­ed to ani­mate SVGs. To do so it aug­ment­ed SVGs with ani­ma­tion-spe­cif­ic ele­ments to be used along­side the reg­u­lar shapes and&nbsp;paths:</p><ul><li><code>&lt;animate&gt;</code></li><li><code>&lt;animateMotion&gt;</code></li><li><code>&lt;animateTransform&gt;</code></li><li>…</li></ul><p>These allowed you to do com­plex and coor­di­nat­ed ani­ma­tions with­in a&nbsp;sin­gle <span>SVG</span>&nbsp;file.</p><p>In sum­ma­ry, SVGs and <span>SMIL</span> give you the toolset to cre­ate Flash-like ani­ma­tions in the brows­er using an open stan­dard. But what are its short­com­ings with regard to animations?</p><ul><li>First­ly it’s a&nbsp;huge and com­plex spec­i­fi­ca­tion. It’s scope is much larg­er than just ani­ma­tions so get­ting start­ed is&nbsp;hard.</li><li>It’s obvi­ous­ly lim­it­ed to ani­mat­ing <em><span>SVG</span></em> ele­ments. You can’t use it to ani­mate oth­er ele­ments on a&nbsp;page.</li><li>Although <a href="https://caniuse.com/#feat=svg-smil"><span>SMIL</span> still has good sup­port</a>, there are <a href="https://groups.google.com/a/chromium.org/forum/#!msg/blink-dev/5o0yiO440LM/YGEJBsjUAwAJ">rum­blings of it being phased out in most browsers</a>.</li></ul><p>So while it’s still around in <span>2020</span>, it’s prob­a­bly best to look beyond <span>SMIL</span> for ani­mat­ing on the&nbsp;web.</p><p>The good news is that you can still ani­mate SVGs <em>with­out <span>SMIL</span></em> using the oth­er APIs and tech­nolo­gies that we’re going to dis­cuss&nbsp;below.</p><h2><span>CSS</span> Tran­si­tions, Ani­ma­tions <span>&amp;</span>&nbsp;Transforms<br></h2><p>As the web found its feet in the mid-<span>2000</span>s, one of the big leaps for­ward was the intro­duc­tion of both <span>HTML<span>5</span></span> and <span>CSS<span>3</span></span> (~<span>2005</span>). These remain the lat­est releas­es of the <span>HTML</span> and <span>CSS</span> stan­dards and they intro­duced a&nbsp;slew of new fea­tures that helped unite web tech­nolo­gies across browsers.</p><p>One of the most antic­i­pat­ed fea­tures was the joint-intro­duc­tion of <span>CSS</span> ani­ma­tions, tran­si­tions and trans­forms via the fol­low­ing properties:</p><ul><li><code>transform: ...</code></li><li><code>transition: ...</code></li><li><code>animate: ...</code> + <code>@key-frames</code></li></ul><p>These three addi­tions paved the way for native ani­ma­tions in the brows­er and are the go-to for most devel­op­ers these days that want to get start­ed with brows­er animations.</p><p>Because they were intro­duced at the same time, they are often assumed to <em>all</em> be required when ani­mat­ing but this is not the case. It’s vital to under­stand these as <span>3</span>&nbsp;dis­tinct (albeit relat­ed) features.</p><p>Let’s have a&nbsp;look at them in a&nbsp;bit more detail.</p><h3><span>CSS</span> Trans­forms</h3></section><section></section><section data-component="textBlock"><p>The <code>transform</code> prop­er­ty allows you change the appear­ance of an ele­ment. For exam­ple you&nbsp;can:</p><ul><li>Scale</li><li>Skew</li><li>Trans­late</li><li>Rotate</li></ul><p>Just like you would an image in Photoshop.</p><p>Here’s the impor­tant part: on its own, a&nbsp;<code>transform</code> has <u>absolute­ly noth­ing to do with ani­ma­tion</u>. Trans­forms <em>can</em> be ani­mat­ed but they have noth­ing to do with ani­ma­tion themselves.<br></p><h3><span>CSS</span> Tran­si­tions</h3></section><section></section><section data-component="textBlock"><p>The <code>transition</code> prop­er­ty is the baby-sib­ling in the <span>CSS</span> ani­ma­tion fam­i­ly, dis­tinct from its old­er sib­lings <code>animate</code> and <code>@key-frames</code>.</p><p>Let’s drop the metaphor and be clear: tran­si­tions and ani­ma­tions are sep­a­rate fea­tures to be used in dif­fer­ent circumstances.</p><p>Tran­si­tions allow you to define an ani­ma­tion that runs when a&nbsp;par­tic­u­lar prop­er­ty on an ele­ment changes, for example:<br></p></section><section><pre><code data-component="syntax-highlighter">.truck {
	transition: transform 1s ease-in;
}

.truck.drive {
	transform: translate3d(100%, 0, 0);
}
</code></pre></section><section data-component="textBlock"><p>Here, when we add the <code>.drive</code> class to our truck the brows­er applies a&nbsp;<code>transform</code> that moves the truck <span>100</span>% to the&nbsp;right.&nbsp;<br></p><ol><li>How is this tran­si­tion trig­gered? For the tran­si­tion to begin, our ele­ment needs to have the <code>.drive</code> class applied. We could use pseu­do-selec­tor like <code>:hover</code> in our tran­si­tions, but usu­al­ly these trig­gers are applied via JavaScript. Either way, <strong>tran­si­tions require a&nbsp;trig­ger to run</strong>.</li><li>What if we want this to run more than once (i.e. loop)? We can’t do this with tran­si­tions. <strong>Tran­si­tions only run once, in response to their trigger.</strong></li><li><strong></strong>What if we want inter­me­dia <span></span>​<span>“</span>stages” to our opac­i­ty tran­si­tion? For exam­ple, maybe fade-in to <code>.2</code> opac­i­ty, hold there, then fin­ish fad­ing-in to <code>1.0</code> opac­i­ty. We can’t con­trol that with tran­si­tions. <strong>Tran­si­tions only have two <span></span>​<span>“</span>states”.</strong></li></ol><p>The impli­ca­tion of this is that tran­si­tions are use­ful when you want to ani­mate some­thing that has a&nbsp;def­i­nite start and end-state and only needs to run once when triggered.</p><h3><span>CSS</span> Ani­ma­tions</h3></section><section></section><section data-component="textBlock"><p>The <code>animate</code> prop­er­ty and <code>@keyframes</code> at-rule address some of the ques­tions left unan­swered by tran­si­tions, but remem­ber that they are a&nbsp;dis­tinct fea­ture meant for dif­fer­ent things.</p><p>While tran­si­tions are good for one-off ani­ma­tions these are used for cre­at­ing mul­ti-stage ani­ma­tions that run more than&nbsp;once.</p><p>What does an ani­ma­tion look&nbsp;like?</p></section><section><pre><code data-component="syntax-highlighter">.wheels {
	animation-name: spin;
	animation-duration: .3s;
	animation-iteration-count: infinite;
	animation-timing-function: linear;
	animation-direction: normal;
}

@keyframes spin {
	from {
		transform: rotate(0deg);
	}
	to {
		transform: rotate(360deg);
	}
}
</code></pre></section><section data-component="textBlock"><ol><li>In con­trast to a&nbsp;tran­si­tion, this ani­ma­tion begins imme­di­ate­ly when the page loads. We <em>could</em> add the <code>animation</code> prop­er­ty to a&nbsp;trig­gered class or pseu­do-selec­tor, but we don’t have to. In oth­er words, <strong>ani­ma­tions can run with­out a&nbsp;trigger.</strong></li><li>The next thing to note is that our ani­ma­tion here can have &gt;<span>2</span> states. We can add as many states as we want in our <code>@keyframes</code> rule to give us real­ly fine-grained con­trol over how the ani­ma­tion pro­gress­es. <strong>Ani­ma­tions can have mul­ti­ple states</strong></li><li>We can also con­trol how many times this ani­ma­tion is run. In our exam­ple it will spin indef­i­nite­ly as we’ve indi­cat­ed <code>i…</code></li></ol></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://weareferal.com/blog/a-half-baked-history-of-web-animations/">https://weareferal.com/blog/a-half-baked-history-of-web-animations/</a></em></p>]]>
            </description>
            <link>https://weareferal.com/blog/a-half-baked-history-of-web-animations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200336</guid>
            <pubDate>Tue, 24 Nov 2020 17:01:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple’s Missing Profits]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200251">thread link</a>) | @simonpure
<br/>
November 24, 2020 | https://digitstodollars.com/2020/11/20/apples-missing-profits-the-usual-suspects/ | <a href="https://web.archive.org/web/*/https://digitstodollars.com/2020/11/20/apples-missing-profits-the-usual-suspects/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Yesterday <a href="https://digitstodollars.com/2020/11/19/the-mystery-of-apples-missing-profits/">we teased the problem of Apple’s steadily declining hardware gross margins</a>. Today we want to walk through some of the possible reasons for the decline. </p>



<figure><table><tbody><tr><td></td><td><strong>2013</strong></td><td><strong>2014</strong></td><td><strong>2015</strong></td><td><strong>2016</strong></td><td><strong>2017</strong></td><td><strong>2018</strong></td><td><strong>2019</strong></td><td><strong>2020</strong></td></tr><tr><td>GM</td><td>37.6%</td><td>38.6%</td><td>40.1%</td><td>39.1%</td><td>38.5%</td><td>38.3%</td><td>37.8%</td><td>38.2%</td></tr><tr><td>OM</td><td>28.7%</td><td>28.7%</td><td>30.5%</td><td>27.8%</td><td>26.8%</td><td>26.7%</td><td>24.6%</td><td>24.1%</td></tr><tr><td>GM<br>(ex-srvcs)</td><td>﻿</td><td>﻿</td><td>﻿</td><td>﻿</td><td>35.2%</td><td>34.4%</td><td>32.2%</td><td>31.5%</td></tr><tr><td>Srvcs GM</td><td></td><td></td><td></td><td></td><td>60.0%</td><td>60.8%</td><td>63.7%</td><td>66.0%</td></tr></tbody></table></figure>



<p>The first thing to note is that gross margins peaked in 2015 and have been trending down ever since.</p>



<p>A few people asked us if their services business was the culprit. Apple began a serious push into music, video and content around that time. Several people pointed out that Netflix, Spotify, XM and other content companies all had to sustain weak gross margins early in their life. The problem with this theory is that Apple’s services gross margins are both higher than corporate average and have been growing while the hardware margins are declining. </p>



<p>Services include more than the content business. The segment also contains Cloud Services, Apple Care and Advertising. As far as we know Apple’s ad business is too small to move the needle much, but we imagine it is fairly profitable. Apple Care is an extended warranty business, insurance basically, and common wisdom will tell you as a consumer to never buy the extended warranty, because it is always priced for the seller to make (a lot of) money. Cloud Services is largely about selling cloud-based storage for what we, as customers of this particular service, find to be an exorbinant price. Apple storage costs $9.99/month for 2TB of storage. Apple probably made enough on these to cover the initial start-up costs of the content business, and now content is profitable in its own right, as borne out by the numbers.</p>



<p>The next most obvious cause would be an increase in component costs. But this seems unlikely. True, during this period Apple was upgrading the screens and RF components and much of its Mac line. This may have had an impact, but given Apple’s past operations practice it is hard to see this alone being the big driver in costs. If the screen really cost that much more we imagine Apple could have held off upgrading for a period, smoothing out the hit. Similarly, the increase in RF content has been taking place for almost ten years, since Apple started adding 4G. There is nothing that leads us to believe Apple has conceded much on any component pricing. </p>



<p>So the next place we would look is product mix. The chart below shows revenue growth by product category, with 2013 as the base year. During this period, Services and Wearables really took off. However, we already know services was not the culprit. That leaves Wearables, and here we may have found our first clue. </p>



<figure><a href="https://digitstodollars.files.wordpress.com/2020/11/image-1.png"><img data-attachment-id="3860" data-permalink="https://digitstodollars.com/image-1-2/" data-orig-file="https://digitstodollars.files.wordpress.com/2020/11/image-1.png" data-orig-size="686,416" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-medium-file="https://digitstodollars.files.wordpress.com/2020/11/image-1.png?w=300" data-large-file="https://digitstodollars.files.wordpress.com/2020/11/image-1.png?w=470" src="https://digitstodollars.files.wordpress.com/2020/11/image-1.png?w=686" alt="" srcset="https://digitstodollars.files.wordpress.com/2020/11/image-1.png 686w, https://digitstodollars.files.wordpress.com/2020/11/image-1.png?w=150 150w, https://digitstodollars.files.wordpress.com/2020/11/image-1.png?w=300 300w" sizes="(max-width: 686px) 100vw, 686px"></a></figure>



<p>Apple launched Apple Watch in 2015 and Airpods in late 2016 (in Apple’s 2017 Fiscal Year). When Airpods first came out, it was hard to buy them, with multi-month wait times. At the time, many ascribed the delay to the popularity of the devices, and they were very popular. However, a more likely reason for the delay was that Apple was having a hard time manufacturing them. Something about production, maybe the perfectly rounded case or maybe the miniaturization of circuitry in the earbuds, was driving up defect rates. Another way to spell manufacturing problems is increased cost of goods sold. If 10% or 20% of devices are defective, that can often be enough to wreck the profitability of a device, and our guess is that Apple’s initial manufacturing rates were worse than that. Apple Watch seems to have less problems in manufacturing, but we suspect these also had poor gross margins to start out. </p>



<p>We believe these devices are now manufacturing at good yields. But there is the possibility that the margins on these products are poorer than the average iPhone or Mac. And as they have grown strongly, it is possible that they are weighing down margins. And this leads to our next suspect – mix shift.</p>



<p>Mix shift refers to the blended gross margin. If you are selling high margin products and then start selling lower margin devices, the average price of your devices falls . No discounts or price reductions involved, but prices, and thus gross margins, fall when everything is averaged out. As noted above, part of this is the growth of possibly lower-margin Wearables. But there is more to the story.</p>



<p>The graph below shows revenue growth by geography, again the base year is 2013. The standout feature of this chart is China. A combination of Trade War patriotism and resurgent strength among Chinese brands drove a reduction in Apple’s growth in China. This is important as we believe Apple’s iPhone sales in China skew heavily towards higher priced devices. So declines in China also likely brought down blended gross margins. </p>



<figure><a href="https://digitstodollars.files.wordpress.com/2020/11/image-2.png"><img data-attachment-id="3863" data-permalink="https://digitstodollars.com/image-2-2/" data-orig-file="https://digitstodollars.files.wordpress.com/2020/11/image-2.png" data-orig-size="660,408" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-medium-file="https://digitstodollars.files.wordpress.com/2020/11/image-2.png?w=300" data-large-file="https://digitstodollars.files.wordpress.com/2020/11/image-2.png?w=470" src="https://digitstodollars.files.wordpress.com/2020/11/image-2.png?w=660" alt="" srcset="https://digitstodollars.files.wordpress.com/2020/11/image-2.png 660w, https://digitstodollars.files.wordpress.com/2020/11/image-2.png?w=150 150w, https://digitstodollars.files.wordpress.com/2020/11/image-2.png?w=300 300w" sizes="(max-width: 660px) 100vw, 660px"></a></figure>



<p>This is borne out further by Operating Margins, as shown in the graph below. We had to double check the data on this one because it so closely mirrors the graph above. Just as Apple’s China sales slowed, so did their operating margins in the region. Given that there was no obvious change in regional operating expenses during this period, the most likely explanation for a fall of this magnitude is that decline in sales and gross margins.</p>



<figure><a href="https://digitstodollars.files.wordpress.com/2020/11/image-3.png"><img data-attachment-id="3866" data-permalink="https://digitstodollars.com/image-3-2/" data-orig-file="https://digitstodollars.files.wordpress.com/2020/11/image-3.png" data-orig-size="676,416" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-3" data-image-description="" data-medium-file="https://digitstodollars.files.wordpress.com/2020/11/image-3.png?w=300" data-large-file="https://digitstodollars.files.wordpress.com/2020/11/image-3.png?w=470" src="https://digitstodollars.files.wordpress.com/2020/11/image-3.png?w=676" alt="" srcset="https://digitstodollars.files.wordpress.com/2020/11/image-3.png 676w, https://digitstodollars.files.wordpress.com/2020/11/image-3.png?w=150 150w, https://digitstodollars.files.wordpress.com/2020/11/image-3.png?w=300 300w" sizes="(max-width: 676px) 100vw, 676px"></a></figure>



<p>One other important thing happened in 2016 – Apple began selling the iPhone SE in that year. The SE was the company’s first foray into sub $400 devices. Apple does not break out unit sales anymore, let alone sales by model, but the launch of this device seems very likely to have affected the company’s gross margins. However, the situation is not quite as straightforward as that. At the time, Apple noted that the new models actually boosted gross margins. We believe the SE was designed with this in mind. That being said, while the SE alone probably did not cause the decline in margins, but we believe it did signal a new approach from Apple towards pricing and market segmentation. Just as Apple began launching &gt;$1,000 phones, they also opened up the flood gates to lower priced devices, growing their addressable market. </p>



<p>There were suspicions about this at the time, and not long after Apple stopped disclosing unit numbers. When they did that <a href="https://digitstodollars.com/2018/12/18/non-disclosure-apple/">we had the strong suspicion</a> that they were trying to mask something unpleasant. And it now seems likely that Apple was moving towards a lower-weighted price band, and unit numbers would have made that glaring. </p>



<p>So after all that, our best guess is that mix shift is the leading cause of Apple’s gross margin decline, with some element of a shift to more expensive components and casing a contributing factor.</p>



<p>In our next piece we will review what Apple can do to address this. </p>



<p><em>Photo by&nbsp;<a href="https://unsplash.com/@sixstreetunder?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Craig Whitehead</a>&nbsp;on&nbsp;<a href="https://unsplash.com/s/photos/detective?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></em></p>
			</div></div>]]>
            </description>
            <link>https://digitstodollars.com/2020/11/20/apples-missing-profits-the-usual-suspects/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200251</guid>
            <pubDate>Tue, 24 Nov 2020 16:55:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin 2021 Probabilistic Forecast]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200220">thread link</a>) | @refrigerator
<br/>
November 24, 2020 | https://my.causal.app/models/21522 | <a href="https://web.archive.org/web/*/https://my.causal.app/models/21522">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://my.causal.app/models/21522</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200220</guid>
            <pubDate>Tue, 24 Nov 2020 16:52:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is the internet of money America's to lose?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200011">thread link</a>) | @venturegrit
<br/>
November 24, 2020 | https://andyjagoe.com/the-internet-of-money/ | <a href="https://web.archive.org/web/*/https://andyjagoe.com/the-internet-of-money/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>The Berkshires is a popular countryside getaway in western Massachusetts, a few hours drive from New York or Boston. If you visit, you'll notice charming villages, verdant farms, and people using a currency other than US dollars. Berkshire County has its own local currency called the <a href="http://www.berkshares.org/">BerkShare</a>.</p><figure><img src="https://andyjagoe.com/content/images/2020/11/image-3.png" alt="" srcset="https://andyjagoe.com/content/images/size/w600/2020/11/image-3.png 600w, https://andyjagoe.com/content/images/2020/11/image-3.png 750w" sizes="(min-width: 720px) 720px"></figure><p>BerkShares are available at <a href="http://www.berkshares.org/berkshares_banks">local bank branches</a> in exchange for US dollars at a rate of 95 cents per BerkShare. BerkShares can be spent at a rate of $1 to 1 BerkShare, effectively giving you a 5% discount for spending locally.</p><p>History is <a href="https://base.socioeco.org/docs/pictorial_history_of_ccs.pdf">full of local currencies</a> and <a href="https://en.wikipedia.org/wiki/Local_currency#List_of_local_currencies">hundreds are in use</a> around the world. But most don't last for long. One of the most successful local currencies, the <a href="https://en.wikipedia.org/wiki/Bristol_Pound">Bristol Pound</a>, has been suspended and is converting all accounts to pound sterling.</p><p>New currencies are not as unusual as you might think. Currencies come and go all the time. Over the past few years we've seen many new digital currencies emerge. Like Bitcoin.</p><p>What's new is that central banks are entering the fray. The Bank for International Settlements (BIS) estimates that 80% of central banks are now <a href="https://www.bis.org/publ/bppdf/bispap107.pdf">looking into central bank digital currencies</a>. China has an active pilot and claims to have completed <a href="https://www.reuters.com/article/china-currency-digital/spending-with-chinas-digital-yuan-around-300-million-pboc-says-idUSL1N2HO0B1">4 million transactions</a>, with a <a href="https://www.wsj.com/articles/china-to-expand-testing-of-a-digital-currency-11597385324">full roll-out planned</a> for the 2022 Beijing Winter Olympics. <a href="https://www.theblockcrypto.com/post/75022/a-global-look-at-central-bank-digital-currencies-full-research-report">Other countries have also completed pilots</a>.</p><p>Why is this happening? </p><p>Because <a href="https://andyjagoe.com/software-eats-money/">money is becoming software</a>. And the internet of money is emerging. </p><p>What is the internet of money? </p><p>It's the reimagining of money and the global financial system. It's doing for money what the Internet did for information. Like making payments as easy as sending email.</p><p>Central banks realize this, and it's making them nervous. What will the internet of money look like? How will it work? Nobody knows. But it's sure to be one of the most consequential developments of our lifetimes.</p><p>Let's start our exploration of the internet of money in an obvious place: central bank digital currencies. What exactly are they? What problems could they solve? What problems might they create? And should we be worried about China's?</p><p>One of the best and simplest definitions of <a href="https://www.bankofengland.co.uk/-/media/boe/files/paper/2020/central-bank-digital-currency-opportunities-challenges-and-design.pdf">central bank digital currency</a> comes from the Bank of England:</p><!--kg-card-begin: markdown--><blockquote>
<p>A Central Bank Digital Currency (CBDC) would be an electronic form of central bank money that could be used by households and businesses to make payments. The key differentiation between reserves (which have been electronic and central bank issued for decades) is that they are universally accepted to all households. And unlike banknotes, would be fully digital.</p>
</blockquote>
<!--kg-card-end: markdown--><p>Importantly, a central bank digital currency could enable direct peer-to-peer payments outside of today's banking and payment systems, and is money backed by the central bank (like cash) and held outside of commercial banks.</p><p>To help you understand how central bank digital currencies fit into the general monetary landscape, here's a "money flower" diagram based on <a href="https://www.bis.org/publ/qtrpdf/r_qt1709f.htm">the one created by the Bank for International Settlements</a>:</p><figure><img src="https://andyjagoe.com/content/images/2020/11/image-6.png" alt="" srcset="https://andyjagoe.com/content/images/size/w600/2020/11/image-6.png 600w, https://andyjagoe.com/content/images/size/w1000/2020/11/image-6.png 1000w, https://andyjagoe.com/content/images/2020/11/image-6.png 1392w" sizes="(min-width: 720px) 720px"><figcaption>The "Money Flower"</figcaption></figure><!--kg-card-begin: markdown--><p>The "money flower" categorizes money according to four properties:</p>
<ul>
<li>Is the money <em><strong>universally accepted</strong></em> or not? Note the diagram misses that this is a sliding scale and not zero or one. No money is acceptable everywhere.</li>
<li>Does the money exist in <em><strong>electronic</strong></em> form?</li>
<li>Is the money backed by the full faith and credit of the <em><strong>central bank</strong></em>? Cash and central bank digital currencies are, but bank deposits are not. That's why they need deposit insurance.</li>
<li>Does the money exist in bearer form (whether physical or digital) such that it can be exchanged <em><strong>peer-to-peer</strong></em> with no intermediary?</li>
</ul>
<!--kg-card-end: markdown--><p>With this understanding, let's look at the benefits central bank digital currencies might deliver.</p><h2 id="benefits-of-central-bank-digital-currency">Benefits of central bank digital currency</h2><p>An increasing amount of work exploring central bank digital currencies is being done by the <a href="https://blogs.imf.org/2019/12/12/central-bank-digital-currencies-4-questions-and-answers/">International Monetary Fund (IMF)</a>, the <a href="https://www.bis.org/cpmi/publ/d174.pdf">Bank of International Settlements (BIS)</a> and <a href="https://en.wikipedia.org/wiki/Central_bank_digital_currency">many others</a>. Key benefits include:</p><p><strong>Improved financial system stability</strong>: Some central banks are concerned about the concentration of payment systems among a few very large companies (some of which are foreign). Also, allowing settlement directly in central bank digital currency instead of bank deposits reduces the concentration of liquidity and credit risk in payment systems. This reduces the systemic importance of large banks.</p><p><strong>Payments competitiveness</strong>: A central bank digital currency provides competition for large companies involved in payments, reducing the potential rents they can charge. It could also open the payments landscape to smaller players and reduce the need for small banks and non-banks to run their payments through large banks, which charge them high fees.</p><p><strong>New monetary policy tools</strong>: A central bank digital currency enables much better data analytics on payment flows and could enable the central bank to deliver targeted "helicopter money" directly to people who need it as opposed to waiting for it to trickle down via the banking sector. An interest bearing central bank digital currency could also enable the central bank to force negative interest rates. That said, holding money that's explicitly reduced every month might not be that popular, and "helicopter money" could just as easily be delivered via <a href="https://www.coindesk.com/watch-us-lawmakers-will-talk-digital-dollar-fedaccounts-in-thursday-hearing">FedAccounts</a>—no central bank digital currency required.</p><p><strong>Financial inclusion</strong>: Central bank digital currencies would be designed primarily for payments, whereas banks are primarily lenders. This is one reason bank's have such poor deposit and payment products. <a href="https://andyjagoe.com/how-to-beat-the-bank/">There's no incentive to improve them</a>. Many central banks want to ensure a safe public money option is available in a world where use of cash is rapidly declining. However, the issue with the unbanked may be more complicated than it seems at face value. In the US, <a href="http://jpkoning.blogspot.com/2020/11/why-are-so-many-americans-content-to-be.html">most of the 5.4% of people who don't have bank accounts don't want them</a> because they don't trust banks. JP Koning discusses some creative ways this might be addressed via <a href="http://jpkoning.blogspot.com/2020/11/why-are-so-many-americans-content-to-be.html">USPS accounts or even Walmart accounts</a>. Could the same apply in other regions too? Could financial inclusion be addressed without a central bank digital currency?</p><p><strong>Currency competitiveness</strong>: A central bank digital currency could expand global usage of a local currency and reduce the dependency on the dollar by improving payment capabilities. This could also help work toward <a href="https://en.wikipedia.org/wiki/Reserve_currency">reserve</a> status.</p><p><strong>Reduce the cost of cash</strong>: Supporting a national means of payment using cash has become very expensive in some countries, especially when they span large geographic areas or many small islands. A central bank digital currency could be a cheaper alternative.</p><p>Are central bank digital currencies the way the internet of money is likely to be built?</p><h2 id="problems-with-central-bank-digital-currency">Problems with central bank digital currency</h2><p>In theory, there are many good reasons to consider a central bank digital currency. But this is only in theory. In reality, the digital money landscape is moving very fast and the issues and challenges with a central bank digital currency are enormous.</p><p>First, there is the privacy issue. Unlike with cash, every single transaction could be recorded and monitored by the government. You might say people willingly trade away privacy for convenience today to use Facebook and Google. This is true. But the downstream impact of not using Facebook or Google is limited. And you can turn tracking off. But what if you couldn't buy or sell something because the government had decided to censor you or the other party? What if it was a mistake?</p><p>Second, central bank digital currency would be cancellable and could be remotely seized with the push of a button. Where would the checks and balances be on the safety of your money? Commercial banks at least have a financial incentive to protect their client's money and demand a court order to freeze an account. What incentives does the central bank have to protect <em>your</em> money? If there's a mistake, what's your recourse? Standing in line at a government office?</p><p>Third, a strong foreign central bank digital currency might make it harder for some countries to run independent monetary policies and control domestic financial conditions. And foreigners using local central bank digital currencies might similarly increase capital flow volatility and complicate domestic monetary policies.</p><p>Fourth, a central bank digital currency could disintermediate the banking sector and increase the possibility of bank runs. If individuals prefer holding central bank digital currency over bank deposits in any significant volume, banks will be forced to raise expensive wholesale money or increase interest paid on accounts. This will force banks to accept lower margins or charge higher interest rates on loans.</p><p>Finally—and most importantly—central banks are experts in money, not software. To understand how important this is, let's look at what's happening now at the intersection of software, networks and money.</p><h2 id="the-public-blockchain-is-dollarizing">The public blockchain is dollarizing</h2><p>One of the most significant recent developments is that the public blockchains are dollarizing. Cryptocurrencies pegged to the dollar (called <a href="https://academy.binance.com/en/articles/what-are-stablecoins">stablecoins</a>) now account for 40% of the daily public blockchain transaction volume, up from almost zero two years ago.</p><figure><img src="https://andyjagoe.com/content/images/2020/11/image-7.png" alt="" srcset="https://andyjagoe.com/content/images/size/w600/2020/11/image-7.png 600w, https://andyjagoe.com/content/images/size/w1000/2020/11/image-7.png 1000w, https://andyjagoe.com/content/images/size/w1600/2020/11/image-7.png 1600w, https://andyjagoe.com/content/images/2020/11/image-7.png 1808w" sizes="(min-width: 720px) 720px"></figure><p>In addition, the dollar denominated cryptocurrency monetary base is exploding, growing at over 300% this year. While only 7.5% of the monetary base of Bitcoin, crypto dollars are growing 50% faster.</p><figure><img src="https://andyjagoe.com/content/images/2020/11/image-8.png" alt="" srcset="https://andyjagoe.com/content/images/size/w600/2020/11/image-8.png 600w, https://andyjagoe.com/content/images/size/w1000/2020/11/image-8.png 1000w, https://andyjagoe.com/content/images/2020/11/image-8.png 1552w" sizes="(min-width: 720px) 720px"></figure><p>Public blockchains dollarizing may be a pivotal development in how the internet of money will ultimately work. Why is it happening? And why so fast?</p><p>In short, a <a href="https://unexpected-values.com/crypto-dollars/">massive global supply-demand imbalance in the dollar market</a>. </p><p>First, the world's debt today is largely denominated in US dollars, now reaching almost $60 trillion. Debtors require dollars to service this debt, and <a href="https://www.reuters.com/article/us-global-markets-debt/new-high-water-mark-for-global-foreign-currency-debt-idUSKBN1X921E">dollar debt is now 4x euro debt and 20x yen debt</a>.</p><figure><img src="https://andyjagoe.com/content/images/2020/11/image-9.png" alt=""><figcaption>Source: <a href="https://www.bis.org/statistics/gli1907.pdf">https://www.bis.org/statistics/gli1907.pdf</a></figcaption></figure><p>Second, while the fed funds rate is low, most developed country's rates are even lower. This drives demand for US debt, which again increases future demand for dollars to service this …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://andyjagoe.com/the-internet-of-money/">https://andyjagoe.com/the-internet-of-money/</a></em></p>]]>
            </description>
            <link>https://andyjagoe.com/the-internet-of-money/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200011</guid>
            <pubDate>Tue, 24 Nov 2020 16:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In 1994 when Steve Jobs got to use a device like an iPhone (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199999">thread link</a>) | @GoRudy
<br/>
November 24, 2020 | https://www.cake.co/conversations/6bNY8PD/that-time-in-1994-when-steve-jobs-got-to-use-a-device-like-an-iphone/ | <a href="https://web.archive.org/web/*/https://www.cake.co/conversations/6bNY8PD/that-time-in-1994-when-steve-jobs-got-to-use-a-device-like-an-iphone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><div><p>Chris: There were probably some hard feelings a couple of decades ago but none lingering, not even those that may have been there wouldn't have been squarely aimed at you. </p><p>Since you were in charge of dealing with 3'd party developers I think I always realized you had a hand in the onboarding of AOL, though until I read your post I always assumed the idea originated with Sony. In the end it didn't really matter - the presence of AOL on SONY MagicLink's did not generate device sales any more than our name did, and ultimately AT&amp;T PersonaLink was utterly dependent on device sales and unlike AOL, spent a fair amount of money to actually attempt to actually generate device sales. As you'll see in point 2 below we saw an urgent need to diversify into a PC application about a year before the MagicLink launched, but as we both know that idea died a slow, agonizing death.</p><p>There are two somewhat related points that I don't recall if we discussed or not which could have possibly (though not probably) reversed the fortunes of at least our part of the General Magic universe.</p><p>1. AT&amp;T spent all that money developing what we would today call a cloud based platform for "communicating applications using General Magic's Telescript technology." Our deal with General Magic obligated us to be the first to develop any application that had anything to do with Telescript, and that was the GM/PersonaLink messaging application. If all General Magic wanted was a then current state of the art e-mail network, we could have made that available a week after our initial meeting with Marc Porat, Rich Miller and Bill Atkinson when they first visited us at a Bell Labs facility in NJ. No, it had to have Telescript.</p><p>To my recollection no 3'd party apps were ever developed using Telescript, including AOL's. In truth there wasn't much Telescript in the PersonaLink Mail application - I think it was primarily tied to authenticating users and providing a rather clever user directory, but it was a start, and again, a core contractual item we were obligated to meet.</p><p>While AT&amp;T certainly had an issue with AOL, we never quite understood why General Magic didn't have an isssue with it (at least when we thought it was all Sony's doing), as it substantially compromised the value of it's whole Telescript proposition, which, despite various public pronouncements to the contrary, was obviously a distant second in importance internally to MagicCap. Various Magicians have indicated their disdain for John Sculley and Apple for upstaging General Magic's device - can you see the similarity AT&amp;T saw for the introduction of an AOL messaging app on MagicCap devices to Apple's action? We had a similar reaction to Motorola's tie up with an outfit named RadioMail. Perhaps you were involved with that one also.</p><p>2. We campaigned long and hard for a MagicCap for PC's sofware app as it became apparent that Sony's $800+ device wasn't likely to fly off of store shelves and Motorola's $1500+ device might not ever make it to market, along with the phantom devices of other alliance members Panasonic and Philips. Rich a company as we were, AT&amp;T could not afford to dole out Sony MagicLink's for free or very little to tens of thousands of customers, but we easily could have and would have distributed software to millions of customers for free, which we believe would have put tens of thousands of users on the PersonaLink network, generating revenue for both AT&amp;T and General Magic, and perhaps providing a "tandem" device-computer solution that would have benefited device partners - which was ultimately the architecture that won that generation of handheld devices.</p><p>Our requests went nowhere for quite awhile, and were ultimately undertaken by a too little, too late internal effort at General Magic that never produced a viable product. </p></div></div></div>]]>
            </description>
            <link>https://www.cake.co/conversations/6bNY8PD/that-time-in-1994-when-steve-jobs-got-to-use-a-device-like-an-iphone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199999</guid>
            <pubDate>Tue, 24 Nov 2020 16:35:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neural Networks for Option Pricing]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199972">thread link</a>) | @jptitus
<br/>
November 24, 2020 | https://samuellee19.github.io/CSCI145_Option_Pricing/ | <a href="https://web.archive.org/web/*/https://samuellee19.github.io/CSCI145_Option_Pricing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h2 id="project-overview">Project Overview</h2>
<h3 id="background">Background</h3>
<p><strong>The Black Scholes model</strong> is used to price put and call options by estimating the variation over time said financial instruments. The model is based on the assumption that the markets are highly efficient (i.e., Efficient Market Hypothesis), which suggests that stock prices are uncorrelated to one another across time. As a result, Geometric Brownian Motion (GBM) also has been assumed. However, the assumption is often violated in practice, leading to numerous variations of the Black-Scholes model.</p>
<p>The <strong>Black-Scholes formula for European call and put options</strong> are:</p>
<p><span>\[C(S_0,t)=S_0N(d_1)-Ke^{-r(T-t)}N(d_2)\]</span> <span>\[P(S_0,t)=Ke^{-r(T-t)}N(-d_2)-S_0N(-d_1)\]</span> where<br>
- <span>\(S_0\)</span>: Stock Price<br>
- <span>\(C(S_0,t)\)</span>: Price of the Call Option<br>
- <span>\(K\)</span>: Exercise Price<br>
- <span>\((T-t)\)</span>: Time to Maturity, where T is Exercise Date<br>
- <span>\(\sigma\)</span>: Underlying Volatility (a standard deviation of log returns)<br>
- <span>\(r\)</span>: Risk-free Interest Rate (i.e., T-bill Rate)<br>
</p>
<p>The <span>\(d_i\)</span> variables are defined as: <span>\[d_1=\frac{\ln\frac{S_0}{K}+(r+\frac{\sigma^2}{2})(T-t)}{\sigma\sqrt{T-t}}\]</span> <span>\[d_2=d_1-\sigma\sqrt{T-t}=\frac{\ln\frac{S_0}{K}+(r-\frac{\sigma^2}{2})(T-t)}{\sigma\sqrt{T-t}}\]</span></p>
<p>Finally, <span>\(N(x)\)</span> is cumulative distribution function for the standard normal distribution.</p>
<h3 id="project-objectives">Project Objectives</h3>
<p>In this project, we aim to do the following:<br>
1. Recreate Culkin and Das’ work<br>
2. See whether fitted simulated model performs well on actual data<br>
3. Observe if the model can perform better based on different datasets</p>
<h2 id="methodologies">Methodologies</h2>
<h3 id="data">Data</h3>
<p>To recreate Culkin and Das’ work we utilized the same simulated data used in the paper to train and validate the neural network.</p>
<p>Aditionally, we queried UKX options data and the options’ underlying stock infromation from Bloomberg (see Bloomberg Query File). We also created another dataset by <a href="https://github.com/jknaudt21/Option-Scraper-BlackScholes">scraping</a> information for S&amp;P500 companies from Yahoo Finance and AlphaQuery.</p>
<h4 id="culkin-and-das-2017">1. Culkin and Das (2017)</h4>
<p>To train a neural network to learn the call option pricing equation, Culkin and Das (2017) simulated a range of call option prices with ranges of different parameters<span data-cites="Culkin_Das_2017">(Culkin and Das <a href="#ref-Culkin_Das_2017">2017</a>)</span>:</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Range</th>
</tr>
</thead>
<tbody>
<tr>
<td>Stock Price <span>\((S)\)</span></td>
<td>$10 — $50</td>
</tr>
<tr>
<td>Strike Price <span>\((K)\)</span></td>
<td>$7 — $650</td>
</tr>
<tr>
<td>Maturity <span>\((T-t)\)</span></td>
<td>1 day to 3 years</td>
</tr>
<tr>
<td>Dividend Rate <span>\((q)\)</span></td>
<td>0% — 3%</td>
</tr>
<tr>
<td>Risk Free Rate <span>\((r)\)</span></td>
<td>1% — 3%</td>
</tr>
<tr>
<td>Volatility <span>\((\sigma)\)</span></td>
<td>5% — 90%</td>
</tr>
<tr>
<td>Call Price <span>\((C)\)</span></td>
<td>$0 — $328</td>
</tr>
</tbody>
</table>
<p>In total, the dataset contains 300,000 observations.</p>
<h4 id="ukx-bloomberg-data">2. UKX Bloomberg Data</h4>
<p>This data is consisted of call options for stocks in the UKX 100 from Bloomberg Terminal. As Bloomberg Terminal has an upper bound for queries, this data only consists of 1600+ observations.</p>
<h4 id="sp-500-scraped-data">3. S&amp;P 500 Scraped Data</h4>
<p>To address a limited number of observations on the above data, we collected additional data through web scraping. Although web data may be imperfect, it can still hold useful information. For this dataset there are 57,000+ observations and we evaluate it separately from the addendum of UKX data.</p>
<h2 id="code">Code</h2>
<p>We used following dependencies and <code>scikit-learn</code>’s prebuilt models to train and visualize our results:</p>
<div data-layout="l-body">
<pre><code>
import numpy as np
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd
import matplotlib.pyplot as plt
import pickle
from scipy import stats
import matplotlib
matplotlib.rcParams['figure.dpi'] = 300</code></pre>
</div>
<h3 id="importing-and-preparing-training-data">Importing and Preparing Training Data</h3>
<table>
<colgroup>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>Index</th>
<th>Stock Price</th>
<th>Strike Price</th>
<th>Maturity</th>
<th>Dividends</th>
<th>Volatility</th>
<th>Risk-free</th>
<th>Call Price</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>206.484</td>
<td>194.386</td>
<td>1.093</td>
<td>0.006</td>
<td>0.863</td>
<td>0.059</td>
<td>79.434</td>
</tr>
<tr>
<td>1</td>
<td>79.582</td>
<td>73.926</td>
<td>0.844</td>
<td>0.020</td>
<td>0.760</td>
<td>0.081</td>
<td>24.976</td>
</tr>
<tr>
<td>2</td>
<td>130.957</td>
<td>154.101</td>
<td>1.326</td>
<td>0.019</td>
<td>0.606</td>
<td>0.042</td>
<td>28.928</td>
</tr>
<tr>
<td>3</td>
<td>53.021</td>
<td>58.598</td>
<td>0.792</td>
<td>0.028</td>
<td>0.573</td>
<td>0.037</td>
<td>8.574</td>
</tr>
<tr>
<td>4</td>
<td>455.191</td>
<td>529.570</td>
<td>0.501</td>
<td>0.009</td>
<td>0.091</td>
<td>0.044</td>
<td>0.210</td>
</tr>
</tbody>
</table>
<p>The original dataset contains an unnecessary index column, so we dropped it from the data frame.</p>
<h4 id="normalizing-the-data-as-done-in-culkin-and-das">Normalizing the data (as done in Culkin and Das)</h4>
<p>As we know that the Black-Scholes formula is linear homogeneous in <span>\(C(S,K)\)</span>, we can normalize our data as: <span>\(C(S,K)/K=C(S/K,1)\)</span></p>
<p>Hence, the results are shown below:</p>
<table>
<colgroup>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>Index</th>
<th>Stock Price</th>
<th>Strike Price</th>
<th>Maturity</th>
<th>Dividends</th>
<th>Volatility</th>
<th>Risk-free</th>
<th>Call Price</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1.062</td>
<td>1.0</td>
<td>1.093</td>
<td>0.006</td>
<td>0.863</td>
<td>0.059</td>
<td>0.409</td>
</tr>
<tr>
<td>1</td>
<td>1.077</td>
<td>1.0</td>
<td>0.844</td>
<td>0.020</td>
<td>0.760</td>
<td>0.081</td>
<td>0.338</td>
</tr>
<tr>
<td>2</td>
<td>0.850</td>
<td>1.0</td>
<td>1.326</td>
<td>0.019</td>
<td>0.606</td>
<td>0.042</td>
<td>0.188</td>
</tr>
<tr>
<td>3</td>
<td>0.905</td>
<td>1.0</td>
<td>0.792</td>
<td>0.028</td>
<td>0.573</td>
<td>0.037</td>
<td>0.146</td>
</tr>
<tr>
<td>4</td>
<td>0.860</td>
<td>1.0</td>
<td>0.501</td>
<td>0.009</td>
<td>0.091</td>
<td>0.044</td>
<td>0.000</td>
</tr>
</tbody>
</table>
<h3 id="training-the-model">Training the model</h3>
<p>To remain as faithful to Culkin and Das, we trained the neural network with the following parameters:<br>
- 4 hidden fully connected layers, each with 100 neurons<br>
- Batch size of 64<br>
- 10 training epochs<br>
- 80-20 train-validation split<br>
- Mean Squared error as loss function</p>
<p>The main difference between our model and the paper’s model is that our network uses ReLU as the activation function for every layer, instead of using LeakyReLU, ELU, ReLU, and ELU for the four layers respectively. We also did not employ dropout regularization. Lastly, we opted to use “Adam” as our optimizer rather than stochastic gradient descent.</p>
<div data-layout="l-body">
<pre><code>
np.random.seed(32)
X_train, X_test, y_train, y_test = train_test_split(df.drop('Call Price', axis=1), 
                                                    df['Call Price'], test_size=0.2)

mlp = MLPRegressor(hidden_layer_sizes=(100,100,100,100), 
                   solver='adam', shuffle = False, batch_size=64, verbose=True,
                   max_iter= 10
                    ) </code></pre>
</div>
<h2 id="analysis-and-visualization">Analysis and Visualization</h2>
<p>We started by exploring the most basic performance metric for every regression problem: <span>\(R^2\)</span></p>
<div data-layout="l-body">
<pre><code>
print("Training set score: %f" % mlp.score(X_train, y_train))
print("Test set score: %f" % mlp.score(X_test, y_test))</code></pre>
</div>
<p>We received <span>\(R^2\)</span> values (training and test) of 0.999476 and 0.999474.</p>
<p>We can see that the model produced very promising results from the simulated data. While the results show that the algorithm is able to learn option pricing mechanism, we cannot draw any significant conclusion that it can produce meaningful results in real life situation.</p>
<p>We can visualize the succes of the model in the graph below:</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_27_0.png" width="257"></p>
<p>We can also explore the distribution of both the in-sample and out of sample error:</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_29_0.png" width="268"></p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_30_0.png" width="268"></p>
<div data-layout="l-body">
<pre><code>
rmse = mean_squared_error(preds_test, y_test)**0.5; rmse # root mean squared error
print("RMSE: %.4f" % rmse)</code></pre>
</div>
<p>Root Mean Square Error of the prediction is 0.0041. Hence, the pricing error in the training set can be summarized as below:</p>
<table>
<thead>
<tr>
<th>Number of Observations</th>
<th>minmax</th>
<th>mean</th>
<th>variance</th>
<th>skewness</th>
<th>kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>240,000</td>
<td>(-0.045, 0.039)</td>
<td>-0.003</td>
<td>0.000007</td>
<td>-0.400</td>
<td>12.084</td>
</tr>
</tbody>
</table>
<p>The pricing error in the test set can be summarized as below:</p>
<table>
<thead>
<tr>
<th>Number of Observations</th>
<th>minmax</th>
<th>mean</th>
<th>variance</th>
<th>skewness</th>
<th>kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>11,841</td>
<td>(-1.407,204.185)</td>
<td>0.091</td>
<td>10.957</td>
<td>54.036</td>
<td>3,074.578</td>
</tr>
</tbody>
</table>
<h2 id="validating-with-real-data">Validating with real data</h2>
<p>So far, we have observed the behavior of the model using the synthetic data. Though the use of synthetic data has allowed us to learn the Black-Scholes model quite accurately, we have yet to see how the model performs using real data. Plus, we could also gauge whether models trained in real data are able to better price options in the market.</p>
<p>Nonetheless, it is worth noting that a common option trading strategy is to determine whether an option is undervalued or fairly valued with respect to the market’s price and the price outputed by Black-Scholes. With this in mind, if our model misprices an option with a higher price, it could be an indicator that said option is undervalued.</p>
<p><strong>Important</strong>: by the time the data for this article was collected, the current risk-free rate was 0.88%.</p>
<h3 id="ukx-bloomberg-data-1">UKX Bloomberg Data</h3>
<p>To start the validation, we pulled options data using a Bloomberg terminal. To limit the size of query, we extracted the data for around ~1600 calls on stocks in the UKX100.</p>
<table>
<thead>
<tr>
<th></th>
<th>Stock Price</th>
<th>Strike Price</th>
<th>Maturity</th>
<th>Dividends</th>
<th>Volatility</th>
<th>Risk-free</th>
<th>Call Price</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>4,732.0</td>
<td>1.0</td>
<td>0.09</td>
<td>0.000000</td>
<td>0.392</td>
<td>0.0088</td>
<td>4,731.0</td>
</tr>
<tr>
<td>1</td>
<td>4,732.0</td>
<td>1.0</td>
<td>0.34</td>
<td>11.949099</td>
<td>0.392</td>
<td>0.0088</td>
<td>4,731.0</td>
</tr>
<tr>
<td>2</td>
<td>4,732.0</td>
<td>1.0</td>
<td>0.02</td>
<td>0.000000</td>
<td>0.392</td>
<td>0.0088</td>
<td>4,731.0</td>
</tr>
<tr>
<td>3</td>
<td>2,094.0</td>
<td>1.0</td>
<td>0.09</td>
<td>0.000000</td>
<td>0.530</td>
<td>0.0088</td>
<td>2,093.0</td>
</tr>
<tr>
<td>4</td>
<td>2,094.0</td>
<td>1.0</td>
<td>0.34</td>
<td>4.424667</td>
<td>0.530</td>
<td>0.0088</td>
<td>2,093.0</td>
</tr>
</tbody>
</table>
<p>Though it might seem that this data is normalized already, such is not the case. Therfore, we normalize the data by dividing by the strike.</p>
<p>We proceeded with dropping <code>Call Price</code> column on the data and predicted to see how the model performs.</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_40_0.png" width="263"></p>
<p>From a quick glance, there seems to be some minor deviations. In fact, we got <span>\(R^2\)</span> value of 0.8699. We can also see the distribution of the errors. Since the simulated data were not generated under a normal distribution, it would not be surprising to observe a skewed distribution:</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_44_0.png" width="263"></p>
<p>While the model performed worse relative to previous sample, it still achieved a high R-squared value considering that the training data and the test data came from different sources. Hence, the above graph is summarized as below:</p>
<table>
<thead>
<tr>
<th>Number of Observations</th>
<th>minmax</th>
<th>mean</th>
<th>variance</th>
<th>skewness</th>
<th>kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>1,685</td>
<td>(-3,088.616,0.352)</td>
<td>-28.828</td>
<td>44,608.131</td>
<td>-10.457</td>
<td>123.588</td>
</tr>
</tbody>
</table>
<p>It makes sense that a model trained from the simulated data would perform relatively bad. However, a real question is whether neural network can perform well given real data that is not normally distributed.</p>
<p>To mitigate the effect of having less data, we increased the number of epochs:</p>
<div data-layout="l-body">
<pre><code>
np.random.seed(32)
X_train_ukx, X_test_ukx, y_train_ukx, y_test_ukx = train_test_split(ukx.drop('Call Price', axis=1), 
                                                    ukx['Call Price'], test_size=0.2)

mlp_u = MLPRegressor(hidden_layer_sizes=(100,100,100,100), 
                   solver='adam', shuffle = False, batch_size=64, verbose=True,
                   max_iter= 20
                    )

mlp_u.fit(X_train_ukx, y_train_ukx)</code></pre>
</div>
<p>Hence, the model achieved <span>\(R^2\)</span> values of 0.999998 and 0.999998 for training and testing sets.</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_51_0.png" width="259"></p>
<table>
<thead>
<tr>
<th>Number of Observations</th>
<th>minmax</th>
<th>mean</th>
<th>variance</th>
<th>skewness</th>
<th>kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>337</td>
<td>(-0.316,9.836)</td>
<td>0.164</td>
<td>0.804</td>
<td>7.901</td>
<td>69.226</td>
</tr>
</tbody>
</table>
<p>From the above, we can see that the model was able to perform very well, given that there were only 1,685 observations used for training the model. However, one thing to note is that the result exhibits a very <strong>high kurtosis</strong>: while the model is consistent in most cases, it could lead to a severe gain/loss (long tails) from time to time. In real-life application, such model will not be preferred by the practitioners as …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samuellee19.github.io/CSCI145_Option_Pricing/">https://samuellee19.github.io/CSCI145_Option_Pricing/</a></em></p>]]>
            </description>
            <link>https://samuellee19.github.io/CSCI145_Option_Pricing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199972</guid>
            <pubDate>Tue, 24 Nov 2020 16:33:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I've Liked Chess So Much]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199971">thread link</a>) | @naftaliharris
<br/>
November 24, 2020 | https://www.naftaliharris.com/blog/why-ive-liked-chess-so-much/ | <a href="https://web.archive.org/web/*/https://www.naftaliharris.com/blog/why-ive-liked-chess-so-much/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p>November 22, 2020</p>
  
<p>
I've liked chess off and on for twenty years. I don't remember learning to play but I do remember an after school class and losing repeatedly to my dad and cousin when I was little. When I taught myself to program my first real project was making a chess engine, though it could only search to depth two since I didn't know about recursion. In college I played casually and was arguably the third best player in my house. I learned more about programming there and made a <a href="https://www.naftaliharris.com/blog/chess">better engine</a> that was good enough to beat me consistently and even <a href="https://www.naftaliharris.com/blog/chess-puzzle">beat another weak engine</a> once or twice. These days I occasionally <a href="https://lichess.org/">play online</a>, I usually do a few puzzles a day, and I watch <a href="https://www.youtube.com/channel/UCMxK1FKAbmj2N-faTWLwNig">Mato Jelic</a> and <a href="https://www.youtube.com/channel/UC6hOVYvNn79Sl1Fc1vx2mYA">John Bartholomew</a> to relax.
</p>
<p>
Considering how long I've played chess I've never been very good at it. Today I'm arguably the second best in my office. I'm a little above 1500 on lichess 5+3 blitz, which I'm somewhat proud of because that's above the provisional rating you get when you join. I've never played on a team or in a tournament or even played a game under classical time controls. I play the Ruy Lopez and the Najdorf Sicilian but am usually out of book after six moves or so and don't have a response I love to d4. Most games I play have at least one blunder or missed opportunity from me. I'd probably still lose to my cousin but I'm pretty sure I'd beat my dad today. People say "oh I'm sure you're just being modest" when I say I'm not very good but I'm actually not being modest.
</p>
<p>
Chess is one of the few things that's been a part of my life for so long that I'm not good at. Though I've long enjoyed the game I've never devoted the time and focus to really improve. There have even been a few several year periods of my life when I wasn't thinking about chess at all. But sure enough I'd stumble across a board or see a game and get back into it.
</p>
<p>
So why have I liked this game so much? There are so many answers to that for me and in the rest of this post I try to scratch the surface of it. The common thread though is that chess is incredibly beautiful and I see many aspects of life as I've experienced it so far reflected in it. I haven't read "How Life Imitates Chess" yet but I greatly admire Kasparov's play and post-chess life and imagine I'd enjoy it a lot.
</p>

<h2>Knots and Gnarls</h2>
<p>
Chess is full of rules, exceptions, and exceptions to those exceptions. For example, each chess piece is unique and different, with its own very contextful strengths and weaknesses. Some of them move in unusual ways (pawns, knights, castling, or en-passant) and this makes chess somewhat complicated to learn. Kings are vulnerable and weak... until the endgame when they become fearless and aggressive. Queens are the most powerful piece, but run away a lot since they're usually too valuable to risk. Rooks can be a fearsome battering ram or an impenetrable laser, but are also surprisingly awkward to maneuver. Bishops are great in open positions but can only visit half the squares of the board and can be worse than useless if blocked in. Knights are proud (and on the fifth or six rank you could even call them arrogant), but miraculously generally about as valuable as the straight-laced bishop. The humble pawn is the weakest piece but nonetheless the "soul of chess" and very occasionally the star of a rags to riches story.
</p>
<p>
Some criticize chess for these quirks and compare it unfavorably to Go but I believe this makes chess reflect the knottiness and irregularity of human interaction, history, and society. Humans are not spheres, we use base ten rather than two, and the streets and buildings of our cities whisper stories of those who came before us. How fitting it is that chess has these quirks as well.
</p>

<h2>Life's Journey</h2>
<p>
When you make your first few moves in a game, you are embarking on the same highway that the greatest players of the game and millions of your ancestors have also walked. A couple moves later and you're on a quieter and more obscure road, with perhaps a few local experts but a lot less fanfare. And a few moves after that, despite the billions of games that have been played, you or your opponent will be the first person ever to make a particular move, and from that point on you'll be blazing your own path.
</p>
<p>
I think this reflects the same pull of history, culture, and tradition that influences all of us. As we grow up we learn to walk and talk and share many experiences that others have had before us, but we gradually grow into our own unique person and one day start leading our own lives. It's mind boggling, awe-inspiring, and almost sacrilegious that you can recreate this in a five minute blitz game. Some bemoan memorizing opening lines and promote variants like Fischer Random but I enjoy and am proud to learn from the wisdom of our predecessors and to join in the vast distributed discovery of the secrets of our shared game.
</p>
<p>
Above a certain level, you can't win games by playing solidly and simply waiting for your opponent to make a mistake. Rather, you must learn to formulate a plan and execute on it while either frustrating the plan of your opponent or executing yours faster and making them react. Chess, like life, rewards the person who knows what he or she wants and goes out and seizes it with initiative. Before I understood this I didn't mind playing with the black pieces, but now I always feel a small thrill to be assigned white. When you have the initiative you can feel it in your hands and your pulse, and as in life it feels good to be living your plan as opposed to somebody else's.
</p>
<p>
Part of that planning process involves understanding what's important now and what will be important in the future. Strong players fight over progressively more subtle advantages... open files, a well placed piece, better pawn structures, control of a square, many of which don't seem to be immediately relevant. To play at that level involves understanding what the future will hold and preparing for it today.
</p>

<h2>Unknown Objective Reality</h2>
<p>
Every possible chess position is either a win, loss, or a draw under perfect play. But with the very limited exception of certain endgames and "mate in n" positions, for almost any position (including of course the starting one) nobody knows with certainty which it is. This is despite the fact that every player intuitively knows the algorithm to solve chess and every chess engine, left to run infinitely on the opening position, would do so.
</p>
<p>
Similarly, I believe there is a single reality in life. Sometimes we have a pretty good sense of what that is, sometimes not, and sometimes reasonable people disagree on it. Unfortunately, except in certain limited situations (notably mathematics), this reality is usually impossible to know with near certainty.
</p>
<p>
Many people believe that chess is a draw. Although I wouldn't be surprised if it were, I think this reasoning generally extrapolates from the play of our best players or engines and implicitly assumes that perfect play would have similar characteristics, an assumption I don't think is warranted. With today's technology of course we'll never know.
</p>

<h2>The Human Spirit</h2>
<p>
Chess brings out some of the human characteristics I most admire. The best players are creative, confident, tough, clear-eyed, prepared. You can't watch the games of Mikhail Tal or Judit Polgar and not be moved by their will to win, their fearlessness, and their fighting spirit, or see their personalities come through their games. I'm proud to say that no matter who my opponent is I always play to win.
</p>
<p>
The struggle between two players pouring their soul into a game produces a piece of art. One player makes a threat, the other ignores it and makes a greater threat, the first parries it while simultaneously increasing the tension elsewhere. Each player's best ideas wrestle and produce a beautifully violent dance. The thing that pains me the most about not being good at chess isn't losing games (though this does significantly impact my mood) but rather ruining this work of art by hanging a piece or missing a combination. There's a debate about whether chess is a sport but I think a more apt description is a competitive art form.
</p>
<p>
What to make of the fact then that engines easily beat the best human players today? Are they closer to the "human ideal" than we are? I don't think so. When humans play they pour their personality and spirit into the game, regardless of their skill level. While Magnus Carlsen is a far better player than me he isn't any more human than I am. We anthropomorphize engines sometimes but they are not sentient. They cannot invest emotionally into their games and so their wins are without joy and their losses are without sorrow.
</p>
<p>
When Garry Kasparov lost to Deep Blue in the '90s some people thought the game would be over. But a few decades later it's clear that the existence of strong engines hasn't diminished the game, any more than cameras have diminished the art of painting. In fact, engines have made it easier to analyze games and improve your play, at the minor cost of the occasional cheating scandal. Chess is certainly not over for me or the millions of others around the world that love this game.
</p>

<h2>The Next Twenty Years</h2>
<p>
I don't know if I'll get any good at chess in the next twenty years. My only hope I get as much from it in the next two decades as I've gotten from it in the last two. What a beautiful game.
</p>


  

  <h3>You might also enjoy...</h3>
  

</div></div>]]>
            </description>
            <link>https://www.naftaliharris.com/blog/why-ive-liked-chess-so-much/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199971</guid>
            <pubDate>Tue, 24 Nov 2020 16:33:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Quicklang.net – A Simple Programming Language That Runs in the Browser]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199865">thread link</a>) | @chkas
<br/>
November 24, 2020 | https://quicklang.net/ide/ | <a href="https://web.archive.org/web/*/https://quicklang.net/ide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://quicklang.net/ide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199865</guid>
            <pubDate>Tue, 24 Nov 2020 16:24:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My EOY Reflection Checklist]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25199785">thread link</a>) | @opsgal
<br/>
November 24, 2020 | https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong | <a href="https://web.archive.org/web/*/https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>The End-of-Year Checklist</strong><span>&nbsp;</span></em><em><span></span></em></p>
<p><span>I like starting the year with an empty to-do list and a fresh perspective. As an obsessive list maker, this process naturally starts with another list. Some of the questions can be treated as action items, but many require deeper reflection (perfect for the quiet week at the end of the year). I hope that you find it useful as you close out 2020!</span></p>

<h5><strong>As a Company</strong></h5>
<ul>
<li><span>What actions most moved the company forward and how can we double down on them? What should we have spent less time doing?&nbsp;</span></li>
<ul>
<li><span>Using the </span><a href="https://www.forbes.com/sites/kevinkruse/2016/03/07/80-20-rule/?sh=15a5959d3814"><span>Pareto Principle</span></a><span>, the return on certain actions will significantly outweigh others.</span></li>
</ul>
<li><span>Did our actions reflect our values? Did we call out times that employees personified our values? Do we need to add or subtract values?</span></li>
<li><span>Which relationships are most important to our success (e.g. customers, investors, partners) and what can we be doing to provide them with more value?</span></li>
</ul>

<h5><strong>As a Manager</strong><span>&nbsp;</span></h5>
<ul>
<li><span>Do we have the </span><a href="https://www.jimcollins.com/concepts/first-who-then-what.html"><span>right people on the bus</span></a><span>?</span></li>
<li><span>Are the right people owning the right things or are there better ways that we can be distributing the work?</span><br><span></span><span></span></li>
</ul>

<p><span>I keep a Trello board to manage this; <a data-cke-saved-href="https://trello.com/b/v6lu8Xpc" href="https://trello.com/b/v6lu8Xpc" target="_blank" rel="noopener">steal my template here</a>.</span></p>
<p><img src="https://cdn.buttercms.com/j9hSXZluRBG3S2HjajIu" alt="trello chart" width="683" height="158"></p>
<ul>
<li><span>How were my 1:1s? Did my reports walk away feeling that I had removed blockers, clarified vagueness, and given clear instructions?</span></li>
<li><span>Do my reports know their metrics for success?</span></li>
<li><span>How connected is the team overall?</span><strong></strong><span></span></li>
</ul>
<h5><strong>Meetings</strong><span>&nbsp;</span></h5>
<ul>
<li><span>Is every meeting on my calendar still relevant and useful?</span></li>
<li><span>Have I invited the right people to each one?</span></li>
<li><span>Are the major meetings for the upcoming year already scheduled? Mine are:</span>
<ul>
<li><span>Off-sites</span></li>
<li><span>Customers business reviews</span></li>
<li><span>Employee reviews</span></li>
<li><span>Team town halls</span></li>
<li><span>Quarterly kickoffs</span></li>
<li><span>Annual trainings</span></li>
</ul>
</li>
<li><span>Do I like the cadence and timing of my recurring meetings?</span>
<ul>
<li><span>Can I schedule any back-to-back to minimize distractions?</span></li>
<li><span>Are meetings optimized to my energy peaks?</span>
<ul>
<li><span>I’m fresh and driven in the mornings and do my best work then. Mentally challenging meetings are best during this window.</span></li>
<li><span>My mind is more relaxed and able to freely brainstorm in the afternoons; I shift most meetings to this time.</span>&nbsp;</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5><strong>Tools</strong></h5>
<ul>
<li><span><span>Are we using the right tools (software, banking, equipment, etc.) to accomplish our goals? Can we eliminate any?</span></span></li>
</ul>
<figure><img src="https://cdn.buttercms.com/exgcpuvKRdmBDDBzKUvF" alt="saas-list" width="772" height="101">
<figcaption>
<p><span>This number balloons quickly, so I keep a spreadsheet of all our tools to track which are still in use and who has access.</span></p>
</figcaption>
</figure>
<ul>
<li><span>Do the right people have access to each tool? Has admin access been given to the logical person?</span></li>
<li><span>Do we have the right tier of service for our size?</span></li>
<li><span>Are there more effective tools available that could reduce or combine the efforts of others?&nbsp;</span></li>
</ul>
<h5><strong>Finance</strong></h5>
<ul>
<li><span>Are our finances generally in order? This can include:</span></li>
<ul>
<li><span>Outstanding invoices</span></li>
<li><span>Unpaid bills</span></li>
<li><span>Sales commissions</span></li>
<li><span>Expense reconciliation</span></li>
<li><span>Credit card charges</span></li>
</ul>
<li><span>Are there areas that we could cut costs next year?</span></li>
<li><span>Is billing set to preferred person and method? (I like to see every charge come through and to optimize points based on spend.)</span></li>
</ul>

<h5><strong>Operations</strong></h5>
<ul>
<li><span>Where can we automate tasks?</span></li>
<li><span>Are the company files clean and organized? What about mine?</span></li>
<ul>
<li><span>If a company file no longer seems relevant, I dump it into an archive folder rather than delete anything.</span></li>
<li><span>I run an inbox-zero on my file downloads and desktop, forcing myself to put any important files somewhere safe in case something happens to my computer.</span></li>
</ul>
<li><span>Are our templated documents up to date?</span></li>
<ul>
<li><span>Check company address, point of contact, and legalese on contracts, mNDAs, etc.</span></li>
</ul>
<li><span>How are our processes? Which ones are sloppy, overly prescriptive, or begging to be eliminated entirely?</span></li>
</ul>

<h5><strong>Performance</strong></h5>
<ul>
<li><span>How did I perform against my job description?</span></li>
<ul>
<li><span>I keep my job description as a living document to capture what I take on and hand off over time. When I doubt where my time is being spent, I discuss this document with my boss and adjust accordingly.</span></li>
</ul>
<li><span>How were my 1:1s with my boss? Did I come to the meeting with thoughtful questions and specific to-dos?&nbsp;</span></li>
<li><span>Did I listen to and incorporate feedback effectively?</span></li>
<li><span>Did I step up when I needed to? Did I delegate my areas of weakness?</span></li>
</ul>
<h5><strong>Role</strong></h5>
<ul>
<li><span>How do I want my job description to change in the next year based on what the company needs and on my own strengths and weaknesses?</span></li>
<li><span>Which relationships within the company are most important to my efficacy? Can I do anything to improve upon those relationships?</span></li>
<li><span>Which tasks I should be taking on or offloading?</span></li>
</ul>
<h5><strong>Time</strong></h5>
<ul>
<li><span>Am I spending time on </span><a href="https://www.nfx.com/post/time-management-for-founders/"><span>the most valuable things</span></a><span> and letting the unimportant things fall through the cracks?</span></li>
<li><span>What have I been putting off?&nbsp;</span>
<ul>
<li><span>Can I eliminate it or delegate it?</span></li>
<li><span>Can I give it more clarity?</span></li>
</ul>
</li>
<ul>
<li><span>I tend to dread tasks that either feel pointless or excessively vague, so I ask:&nbsp;&nbsp;</span></li>
</ul>
<li><span>What can I stop doing altogether?</span></li>
</ul>
<h5><strong>Personal</strong></h5>
<ul>
<li><span>Do I like my personal systems for keeping track of to-dos?</span></li>
<li><span>Do I know what I bring to the table when I join a meeting?</span></li>
<li><span>Am I maintaining a network of people I can turn to for advice?</span></li>
<li><span>Am I making time outside of work for activities that keep me healthy and happy?</span></li>
</ul>
</div></div>]]>
            </description>
            <link>https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199785</guid>
            <pubDate>Tue, 24 Nov 2020 16:16:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Harmful Biases in Performance Reviews]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199752">thread link</a>) | @ochronus
<br/>
November 24, 2020 | https://ochronus.online/biases-in-performance-reviews/ | <a href="https://web.archive.org/web/*/https://ochronus.online/biases-in-performance-reviews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div itemprop="text">

<p>We are all prone to biases. We cannot help but evaluate and assess people and situations through the lens of our own prejudices. When it comes to performance reviews this can have a huge unwanted impact as it influences compensation, promotion decisions, and even firing.</p>
<p>When you give a performance review for a colleague, you’re very directly impacting their career trajectory. Even so, if you’re their manager. Given the weight of this kind of influence, it’s our responsibility to make sure the reviews are as fair and objective as possible.&nbsp;</p>
<p>Not all is lost, though. Once you’re aware of the existence of these biases and the way they work, you can utilize certain strategies (and a good amount of self-awareness) to minimize their effect.</p>
<p>Below, I break down the most common performance review biases and share advice on how to deal with them both as the giver and the recipient of performance reviews.&nbsp;</p>

<h4 id="0-general-advice-for-managers-"><strong>General advice for managers</strong></h4>
<p>One of the best ways to counter bias in reviews is to come up with a great review format that guides people and doesn’t magnify bias effects. Phrasing matters a lot. Setting the tone, being clear about the purpose and scope of the feedback form is key.</p>
<p>Another very important point is to understand that giving quality feedback takes time, a certain kind of focus, and is a considerable effort. Make sure you proactively prepare your engineers for the feedback season and plan for it – one thing that worked pretty well for me is to represent feedback tasks as cards on the team board and even set them as sprint goals. Nothing makes feedback quality deteriorate more than rushing and feeling that you don’t have enough time for it. You can organize feedback training, too, with our without your HR peers.</p>
<h4 id="1-general-advice-for-everyone-"><strong>General advice for everyone</strong></h4>
<p>On the flip side of the above – expect that giving feedback is not a trivial task. Take your time, make sure you have a quiet corner, don’t do it in one go, take notes, work on your wording, look at email/slack/pull request history too and treat your peers as customers of your feedback.</p>
<p><a href="https://ochronus.online/thoughts-on-feedback/">My article on feedback</a> might help in that.</p>
<hr>
<h2 id="2-recency-bias">Recency bias</h2>
<p>Alice had a very strong year, she had great contributions to the projects her team was working on, achieved most of her goals, mastered a new language, and a framework. In the past month though, due to personal issues, she kept her involvement to the bare minimum. In his feedback to Alice, Bob highlights that he expects more from her and that she feels distant from the team. Bob completely fails to call out the amazing job Alice did earlier and the growth she had had.</p>
<p>Recency bias is when recent events weigh much more heavily in your performance review than older, possibly even more significant events. This is partly due to how our memory works and is a completely natural thing, yet its impact can be really bad and can bias your review in either direction depending on what people remember about you recently.&nbsp;</p>
<h3 id="3-how-to-deal-with-recency-bias">How to deal with recency bias</h3>
<p>The best way is to collect feedback more frequently – for example, do a 360 each quarter even if you only have the performance review once a year. Project-level retrospectives can be helpful as well. Some managers keep ‘files’ on their engineers to counter this bias, but honestly, that can easily backfire – it can feel like a shady practice to their teams. Prefer transparent and open frequent feedback instead.</p>
<p>Some people find it useful to keep a personal achievement log, which helps with their self-assessment or calling out things missing from their feedback. If you feel there are important bits missing from the feedback you’ve been given, call those out. If your manager doesn’t encourage more frequent feedback you can still ask for informal ones from your peers at any time.</p>
<hr>
<h2 id="4-similarity-bias-and-affinity-bias">Similarity bias and Affinity bias</h2>
<p>Alice and Bob graduated from the same university and are both huge Star Trek fans – they talk about it all the time, they get along really well and connect outside work, too. Bob’s feedback to Alice is always overly positive and he’s prone to overlooking seemingly obvious gaps in her performance.&nbsp;</p>
<p>We subconsciously tend to rate people similar to us higher. Similarity can mean many things – personality, looks, way of thinking, etc. Affinity bias occurs when we work with someone we feel we have an affinity with; maybe we attended the same college, we grew up in the same town, or they remind us of someone we know and like.</p>
<h3 id="5-how-to-deal-with-similarity-and-affinity-bias">How to deal with similarity and affinity bias</h3>
<p>A clear, and transparent performance evaluation system helps a lot here. Such a system is clear and well-understood level definitions, which can guide your focus while thinking about others’ performance. That said, levels are usually not public information in companies, so this won’t help too much with peer review.</p>
<p>Getting feedback from multiple peers can help mitigate the effect of this bias.</p>
<hr>
<h2 id="6-halo-effect-and-horn-effect">Halo effect and horn effect</h2>
<p>Alice is really great at debugging and fixing notoriously tricky bugs others usually struggle with. Because of this, she saved the day multiple times. That said, she barely meets her level’s expectations if we look at the wider spectrum. Alice gets really positive feedback from her team highlighting how grateful they are for her being the ‘bug hunter’ and omitting any gaps she might have elsewhere.</p>
<p>Bob meets his level’s expectations in general and is great to work with. That said, he has the tendency to be impatient and cut discussions short because of that, which really hurts his ability to effectively work with others in these situations. Bob gets negative feedback highlighting that he should really work on his temper and communication – not mentioning any of the amazing work he’s done otherwise.</p>
<p>In the halo effect, a single positive event or attribute lifts your review up, and in the horn effect similarly a single negatively perceived action or trait ‘poisons’ your whole review.</p>
<p>This gets even worse if your manager is biased. A classic example of the manager having a halo bias is when they see one of their engineers as the “hero” or the “10x engineer”, being blind about any gaps they might have (btw. check out my older post about <a href="https://ochronus.online/kill-your-heroes/">hero engineers</a>). An example of a manager having the horn bias is when they stigmatize an engineer as e.g. “unreliable” or “not smart enough” based on a one-off event.</p>
<h3 id="7-how-to-counter-the-halo-or-horn-effects">How to counter the halo or horn effects</h3>
<p>You might ask “why would I want to counter the halo effect if it results in positive reviews about me?”. True, it might momentarily be even helpful for you, but not having a clear picture of your gaps ultimately does more damage than good to your career. It hinders your potential to grow and if you change teams, managers, or companies you might be suddenly underperforming and you won’t necessarily understand what happened.</p>
<p>To counter the effect of these biases you first need to understand what the main positive or negative thing is in your feedback and have a heart-to-heart about it with yourself. Again, a proper level definition system helps a lot. If you feel that people are generalizing a one-off negative event, ask them to provide more examples of that behavior. You can actually call out that you feel stigmatized by that single event or trait. If you can, highlight counterexamples.</p>
<p>Sometimes phrasing of rating scale points helps mitigate these biases, e.g. if you call the two extremes of the scales “consistently underperforming” and “top performer”.</p>
<hr>
<h2 id="8-idiosyncratic-rater-bias">Idiosyncratic rater bias</h2>
<p>Bob is an engineering manager leading a mobile developer team. Bob has deep experience in project management but almost none in mobile development. Bob seems to consistently rate the development skills of his engineers much higher than they really are, while he rates the project management performance of the lead developer lower than it is.</p>
<p>Idiosyncratic rater bias happens when people evaluate skills they’re not good at, higher. Sometimes they rate others lower in things they’re great at. This is rooted in lower standards we have for things we don’t have deep knowledge about and higher standards for things we’re experienced at. In other words, our feedback reflects more on our own skills than the person’s we’re reviewing.</p>
<h3 id="9-how-to-counter-the-idiosyncratic-rater-bias">How to counter the idiosyncratic rater bias</h3>
<p>To overcome this bias as a manager, try rephrasing your performance evaluation questions for yourself from a different perspective, e.g.:</p>
<p>If this engineer wanted to resign I would try to retain them.</p>
<p>I would want this engineer on my team at any time.</p>
<p>I would hire this engineer again at any time.&nbsp;</p>
<p>Research shows that people are much more accurate when rating their own intentions compared to rating other people.</p>
<p>Also, having a diverse set of feedback from peers can mitigate this (there’s a low probability for every reviewer to be biased the same way).</p>
<hr>
<h2 id="10-centrality-bias">Centrality bias</h2>
<p>Alice is the manager of a team. She hands in her annual performance evaluations, and you notice that almost everyone on her team scored near the middle of the scale. Now you wonder if that’s actually a realistic image or not.</p>
<p>Many managers don’t like being extreme and tend to be moderate in their reviews. When everyone is receiving a rating of 3 out of 5 across the board, there’s no distinguishing the low-performing and high-performing employees. This will result in unfair reviews and people being pissed by lack of recognition and that nothing happens to low performers.&nbsp;</p>
<h3 id="11-how-to-counter-the-centrality-bias">How to counter the centrality bias</h3>
<p>Well, an easy hack is to remove the middle of the rating scale, the ‘neutral’ option, e.g. have a scale of 4 instead of 5 to force managers to decide. If you received one of the ‘meh’ reviews, have a heart-to-heart with your manager and highlight where you disagree. For example, if you feel you’ve been doing better in a certain area ask for explicit examples of how you could do better and cross-check it with your data points. Rating on multiple skills and axes can help, too, compared to a single, unified rating.&nbsp;</p>
<h2 id="12-contrast-bias">Contrast bias</h2>
<p>Alice is really good at project management. Bob is …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ochronus.online/biases-in-performance-reviews/">https://ochronus.online/biases-in-performance-reviews/</a></em></p>]]>
            </description>
            <link>https://ochronus.online/biases-in-performance-reviews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199752</guid>
            <pubDate>Tue, 24 Nov 2020 16:14:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scalability Patterns of Distributed Systems]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199689">thread link</a>) | @parsecs
<br/>
November 24, 2020 | https://robertovitillo.com/scalability-patterns/ | <a href="https://web.archive.org/web/*/https://robertovitillo.com/scalability-patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>November 24, 2020</p></header><p>I have released a new chapter of <a href="https://distributedsystemsmanual.com/">the Distributed Systems Manual</a>! It explores the different patterns at your disposal when designing horizontally scalable applications. </p><p><span>
      <a href="https://robertovitillo.com/static/36007df3454b93db0383ef2ec08c67fa/0f903/partitions.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Partitions and Replication" title="Partitions and Replication" src="https://robertovitillo.com/static/36007df3454b93db0383ef2ec08c67fa/fcda8/partitions.png" srcset="https://robertovitillo.com/static/36007df3454b93db0383ef2ec08c67fa/12f09/partitions.png 148w,https://robertovitillo.com/static/36007df3454b93db0383ef2ec08c67fa/e4a3f/partitions.png 295w,https://robertovitillo.com/static/36007df3454b93db0383ef2ec08c67fa/fcda8/partitions.png 590w,https://robertovitillo.com/static/36007df3454b93db0383ef2ec08c67fa/efc66/partitions.png 885w,https://robertovitillo.com/static/36007df3454b93db0383ef2ec08c67fa/c83ae/partitions.png 1180w,https://robertovitillo.com/static/36007df3454b93db0383ef2ec08c67fa/0f903/partitions.png 1719w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>The simplest way to scale an application is by running it on more expensive hardware. But, that only brings you so far as the application will eventually reach a performance ceiling. The alternative to scaling up is scaling out by distributing the load over multiple nodes.</p><p>The chapter presents three independent categories of scalability patterns that can be combined within the same application: functional decomposition, partitioning, and duplication.</p><h2 id="functional-decomposition"><a href="#functional-decomposition" aria-label="functional decomposition permalink"></a>Functional Decomposition</h2><p>Functional decomposition is the process of taking an application and breaking it down into individual parts. Think of the last time you wrote some code - you most likely decomposed it into functions, classes, and modules. The same idea can be taken further by decomposing an application into separate services, each with its well-defined responsibility. Decomposing an application into services doesn’t come for free, though, and the chapter talks about the costs of doing so.</p><p>The chapter also dives into patterns that become crucial once your application is split into multiple services, such as using an API gateway to shield external consumers from the internal APIs and leveraging asynchronous messaging to improve the overall system’s availability.</p><h2 id="duplication"><a href="#duplication" aria-label="duplication permalink"></a>Duplication</h2><p>Arguably the easiest way to add more capacity to a service is to create more instances of it and have some way of routing - or balancing - requests to them. The thinking is that if one instance has a certain capacity to handle load, then two instances should have a capacity that is twice that. Creating more service instances can be a fast and cheap way to scale out a stateless service, as long as you have taken into account the impact this can have on the service’s dependencies. </p><p>Scaling out a stateful service is significantly more challenging as coordination comes into play to replicate the state among the instances. The chapter introduces the concept of load balancing by discussing the implementation of L4 and L7 load balancers. Then, various approaches to state replication are explored, like single-leader, multi-leader, and leaderless. Finally, the chapter explores how to implement caching and content distribution at scale.</p><h2 id="partitioning"><a href="#partitioning" aria-label="partitioning permalink"></a>Partitioning</h2><p>When a dataset no longer fits a single node, it needs to be partitioned - or sharded - across multiple nodes. Sharding is a general technique that can be used in a variety of circumstances. The chapter discusses different sharding strategies and their relative trade-offs and explores how to rebalance partitions when new nodes are added to the system.</p><h2 id="ps"><a href="#ps" aria-label="ps permalink"></a>P.S.</h2><p>Thank you for all the feedback you have been sending me over the past months! I have rewritten parts of previously released chapters based on it. I plan to keep updating the book over time, just like software, so that every time you go back to it, you will find an improved version of what you initially read. </p><hr></article></div>]]>
            </description>
            <link>https://robertovitillo.com/scalability-patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199689</guid>
            <pubDate>Tue, 24 Nov 2020 16:09:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ham Radio Needs to Embrace the Hacker Community Now More Than Ever]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25199686">thread link</a>) | @parsecs
<br/>
November 24, 2020 | https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/ | <a href="https://web.archive.org/web/*/https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-pane">
  <div>
    
    <h2 id="an-open-letter-to-all-ham-radio-operators">An Open Letter To All Ham Radio Operators</h2>
<p>“Ham Radio is dying!” A phrase all to often uttered that it’s become cliché, but it’s partly true. You can’t deny a considerable section of the ham radio operators in the world are in the latter part of their lives.They won’t be around forever so naturally new people must assume their place. The good news is amateur radio licenses are on the rise. The bad news is the people induced to ham radio these days aren’t interested in pushing the limits of RF technology. To be blunt I’m talking about preppers and those solely interested in emergency communications. Neither of which have any desire to explore ham radio beyond a disaster fetish in which they use their $25 BaoFeng HT to save the world. So what can ham radio operators do? Easy, reach out to the hacker community! First, allow me define the word hacker since there are nefarious connotations of the word’s meaning. When I use the word hacker, I’m talking about the type of individual who wants to comprehend how a given technology works and who explores all the possibilities that technology has to offer. These are the people who grew up dismantling electronics just to appreciate how they work, the people who stayed up late into the night teaching themselves to code, and these are the people ham radio needs to propel it further into the future. To attract and retain hackers within the ham community there are a few things that we need to do.</p>
<h3 id="1-stop-primarly-promoting-emergency-communications">1. Stop Primarly Promoting Emergency Communications</h3>
<p>Every day I see on the <a href="https://www.reddit.com/r/amateurradio/">r/amateurradio</a> subreddit a number of people who solely promote ham radio’s role in emergency communications. Does it have a place within the hobby and community? Certainly, however, there is little interest from the hacker community in relaying messages about the state of the weather during a thunderstorm. Ham radio offers so much morel. You do it a disservice when you either dismiss the other areas of the hobby as secondary to emergency communications or fail to mention them at all. For crying out loud, we launch our own communications satellites and utilize them every day. Satellite communications, the blending of RF and VoIP to communicate around the world, software defined radio represent the things we need to promote to the hacker community. To effectively communicate, identify your audience.</p>
<h3 id="2-start-promoting-software-defined-radio">2. Start Promoting Software Defined Radio</h3>
<figure>
    <img src="https://www.kj7nzl.net/img/radios/hackrf-one-sdr-001.webp" alt="Will SDRs like the HackRF One be the future of ham radio?"> <figcaption>
            <p>Will SDRs like the HackRF One be the future of ham radio?</p>
        </figcaption>
</figure>

<p>There is a lot of interesting work that’s currently being done within the hacker community with RF. Most of this work is currently centered around WiFi, LoRa, IoT networks. It not difficult to imagine someone who has an interest in these communication technologies wouldn’t be open to software defined radio. They just need to be presented with easy to understand examples and a little encouragement to become licensed. Kelly Albrink’s 2020 DerpCon talk <em>Ham Hacks: Breaking into the World of Software Defined Radio</em> does just that.</p>

<p>
  <iframe src="https://www.youtube.com/embed/LIcE0frWtLo" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>Software Defined Radio is here and we as hams need to explore all the potential the technology has to offer. Currently full SDR transceivers are available from Flex Radio, and the major ham radio manufactures are beginning to produce hybrid SDR transceivers. With SDRs such as the BladeRF 2.0, LimeSDR and the HackRF One the entry point into software defined radio is relatively low. These lowcost SDRs make excellent platforms for experimentation within the VHF/UHF bands. The <a href="https://www.youtube.com/c/TechMindsOfficial">YouTube channel Tech Minds</a> has some excellent videos of what these little radios can do.</p>

<p>
  <iframe src="https://www.youtube.com/embed/qx_orXHiQk8" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h3 id="3-provide-communities-that-foster-technical-discussion-and-exploration">3. Provide Communities That Foster Technical Discussion and Exploration</h3>
<p>It’s been my experience that local radio club are more focused on emergency communications rather than the more technical aspects of ham radio (Seriously, why so much obsession with emergency communications?). Most of the anecdotal evidence I’ve collected has suggested this is a common occurrence around the United States. This type of focus doesn’t foster an environment of learning and exploration. Why would the hacker community want to participate, in discussions about who’s going provide communications “support” on the corner of Elm and Main St. during the annual Forth of July parade? You need to create the type of environment where the discussion is focused on RF technology. If you can’t do that locally in person or over the air, then it’s time to turn to the digital voice modes. That’s right, DStar, DMR, and System Fusion provide an opportunity to essentially create local communities of common interest. Access to these communities are as easy as connecting to one’s hotspot; I guess you could present the argument that some repeaters are connected to these digital networks and blah blah blah. Hotspots! That’s what the cool kids are doing these days. As an aside, <a href="https://www.kj7nzl.net/blog/building-my-own-lonestar-electronics-mmdvm-hotspot/">check out my new hotspot</a>.</p>
<h4 id="introducing-the-radio-hackers-ysf-reflector">Introducing the Radio Hackers YSF Reflector</h4>
<p>In my efforts to better understand the System Fusion and WiresX Network and how they relate to each other, I created a YSF Reflector called Radio Hackers. As you may have guessed this is the beginning stages of the hacker community, I’m fostering among ham radio operators. This is by nowhere complete and I welcome you to assist me in any way that you can. The most significant thing you can do is inform others and join in on the discussion on the reflector.</p>
<ul>
<li>ID: 33360</li>
<li>Name: Radio Hackers</li>
<li>Dashboard: <a href="http://hackers.ysf.kj7nzl.net/">http://hackers.ysf.kj7nzl.net</a></li>
<li>Bridged Networks: TBD</li>
</ul>
<p>If anyone knows more about bridging networks together with XLX please reach out to me. I’d love to speak with you more. My contact information is provided on the <a href="https://www.kj7nzl.net/">home page</a> of this site.</p>

  </div>
</section></div>]]>
            </description>
            <link>https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199686</guid>
            <pubDate>Tue, 24 Nov 2020 16:09:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Relax for the Same Result]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199673">thread link</a>) | @svrma
<br/>
November 24, 2020 | https://sive.rs/relax | <a href="https://web.archive.org/web/*/https://sive.rs/relax">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
<header>
<div><p>from the book “<a href="https://sive.rs/n" rel="tag">Hell Yeah or No</a>”:</p></div>

<small>2015-10-02</small>
<audio src="https://m.sive.rs/sive.rs.relax.mp3" preload="none" controls="controls"></audio></header>

<p>
	A few years ago, I lived in Santa Monica, California, right on the beach.
</p><p>
	There’s a great bike path that goes along the ocean for seven and a half miles.
	So, fifteen miles round trip.
	On weekday afternoons, it’s almost empty.
	It’s perfect for going full speed.
</p><p>
	So a few times a week, I’d get on <a href="https://surlybikes.com/bikes/pacer">my bike</a> and go as fast as I could for the fifteen-mile loop.
	I mean really full-on, 100 percent, head-down, red-faced sprinting.
</p><p>
	I’d finish exhausted and look at the time:
<strong>
	forty-three minutes.
</strong>
	Every time.
	Maybe a minute more on a really windy day, but basically always forty-three minutes.
</p><p>
	After a few months, I noticed I was getting less enthusiastic about this bike ride.
	I think I had mentally linked it with being completely exhausted.
</p><p>
	So one day I decided <strong>I would do the same ride, but just chill</strong>.
	Take it easy, nice and slow.
	OK, not <em>super</em> slow, but dialing it back to about 50 percent of my usual effort.
</p><p>
	And ahhh… what a nice ride.
	I was relaxed and smiling and looking around.
	I was barely giving it any effort.
</p><p>
	I saw two dolphins in the water.
	A pelican flew right over me in Marina del Rey.
	When I looked up to say “wow!” he shit in my mouth.
	I can still remember that taste of digested shellfish.
	I had to laugh at the novelty of it.
</p><p>
	I’m usually so damn driven, always doing everything as intensely as I can.
	It was so nice to take it easy for once.
	I felt I could do this forever, without any exhaustion.
</p><p>
	When I finished, I looked at the time: <strong>forty-five minutes.</strong>
</p><p>
	Wait — what?!?
	How could that be?
	Yep.
	I double-checked: forty-five minutes, as compared to my usual forty-three.
</p><p>
	So apparently all of that exhausting, red-faced, full-on push-push-push I had been doing had given me only a <strong>4 percent</strong> boost.
	I could just take it easy and get <strong>96 percent of the results</strong>.
</p><p>
	And what a difference in experience!
	To go the <em>same</em> distance, in about the <em>same</em> time, but one way leaves me exhausted, and the other way, rejuvenated.
</p><p>
	I think of this often.
	When I notice that I’m all stressed out about something or driving myself to exhaustion, I remember that bike ride and try dialing back my effort by 50 percent.
	It’s been amazing how often everything gets done just as well and just as fast, with what <em>feels</em> like half the effort.
</p><p>
	Which then makes me realize that half of my effort wasn’t effort at all, but just unnecessary stress that made me <em>feel</em> like I was doing my best.
</p>
<img alt="" src="https://sive.rs/images/bikesand.jpg">



</article>



</div></div>]]>
            </description>
            <link>https://sive.rs/relax</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199673</guid>
            <pubDate>Tue, 24 Nov 2020 16:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Continuous Agreement for Future Equity]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199610">thread link</a>) | @simonpure
<br/>
November 24, 2020 | https://fairmint.co/cafe-continuous-agreement-for-future-equity/ | <a href="https://web.archive.org/web/*/https://fairmint.co/cafe-continuous-agreement-for-future-equity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>The CAFE, or Continuous Agreement for Future Equity, is the result of years of experience from investors, lawyers and, of course, founders reflecting on today’s financing methods and looking to create a better way to fundraise that would be beneficial for investors, entrepreneurs and stakeholders at large. The CAFE has been thought with the following objectives in mind: give more control to founders, more liquidity to investors and more access to stakeholders.</p></div><div id="the-cafe"><div id="what-cafe"><p>A CAFE (pronounced /ka.fe/) is a Continuous Agreement for Future Equity. It allows investors to make cash investments in a company at any single time, but get company stock at a later date, in connection with a specific event. A CAFE is not a debt instrument, but is intended to be an alternative to convertible notes and SAFEs that is beneficial for both companies and investors.</p></div><div id="read-cafe"><p>Here is a <a href="https://fairmint-documents.s3.amazonaws.com/CAFE/CAFE+Template.docx" target="_blank">simple template</a> we’ve created as an example form of CAFE. Keep in mind, each Company may want to customize and amend the form of CAFE based on legal feedback, and using this template is not a requirement to conduct a CAFE offering. Also note, these are just templates and are not intended to constitute legal advice. You will still need to work with counsel or choose to forego working with counsel yourself.</p></div><div id="what-problem-cafe-solve"><div><p>The CAFE enables you to financially align your stakeholders to the success of your company. The digital economy has radically changed the nature of the relationship between customers and corporations. Individuals have switched from being passive consumers to being an essential force in creating value, either by their actual work (Airbnb, Uber, Apple's App Store, Amazon Marketplace...) or through their data (Facebook, Google...).</p><p>For that reason, financially aligning stakeholders to the success of the company is now the strongest competitive advantage that a company can build. Yet, there is no easy solution to do that today (see the letters sent by <a href="https://www.axios.com/airbnb-asks-sec-to-let-it-give-hosts-equity-a7d99495-0782-4bce-92bb-4c692ef1b621.html" target="_blank"><span>Airbnb</span></a> and <a href="https://www.axios.com/uber-asks-sec-to-let-it-give-equity-to-drivers-1539296399-4594e4e4-727f-4fae-873e-58df1ebd20d9.html" target="_blank"><span>Uber</span></a> to the SEC asking to let them give equity to their hosts and drivers respectively).</p><p>The CAFE has been created with the objective to turn equity into a company’s most powerful tool to engage with its community. On the one hand, the CAFE allows for <a href="http://www.paulgraham.com/hiresfund.html" target="_blank"><span>high-resolution fundraising</span></a> at scale, enabling anyone in the world who believes in a company (and who are not restricted by applicable laws) to invest in it, at any single time. On the other hand, the CAFE allows companies to better reward key stakeholders (users, customers, partners, drivers, hosts…) and incentivize them to their financial success.</p><p>More specifically, the CAFE addresses the expectations we gathered from hundreds of discussions with founders, investors and stakeholders:</p><ul><li><p>Founders want more long-term <b>control</b> of their company,</p></li><li><p>Stakeholders want <b>access</b> to the financial upside of the companies they love and use,</p></li><li><p>Investors want increased <b>liquidity</b> on their investments.</p></li></ul></div></div><div id="what-key-characteristics-cafe"><div><p>The CAFE has been designed to be an improvement over the SAFE. Like the SAFE, it allows for <a href="http://www.paulgraham.com/hiresfund.html" target="_blank"><span>high-resolution financing</span></a> but it has other key characteristics. Most notably, subject to applicable law (which may require the observation of holding periods or other securities law compliance requirements, depending on jurisdiction), it is designed to achieve three essential features:</p><ul><li><p><b>Accessible to Qualifying Investors and Stakeholders</b>. Anyone in the world who supports the company’s product or mission and qualifies to participate under applicable law is able to buy or earn CAFE, anytime, easily and online.</p></li><li><p><b>Digital</b>. The CAFE makes companies’ equity programmable. Using the CAFE, founders can create automated and scalable stakeholder incentivization plans to let their key stakeholders earn CAFE according to the rules they set. Software is finally eating equity.</p></li><li><p><b>More Liquid.</b> We created the CAFE as a standard digital security. As such, subject to applicable law, it has the potential to leverage decentralized <a href="https://medium.com/dragonfly-research/what-explains-the-rise-of-amms-7d008af1c399" target="_blank"><span>AMMs</span></a> as well as securities exchange platforms to enable easy trading of CAFE.</p></li></ul></div></div><div id="what-benefits-cafe"><p>The CAFE has many benefits over traditional equity offering while remaining compatible with traditional equity financings:</p><div><div><p>Traditional Equity Offering</p><p>CAFE Offering</p></div><div><p>Rights</p><p><span>Incremental dilution.</span> Every new round of financing makes you lose long-term control over the destiny of your company in the form of relinquishing governance and control rights.</p><p><span>Fixed.</span> Your CAFE offering has a fixed dilution, no matter how much capital you end up raising. On top, shares issued on conversion of a CAFE by default do not require relinquishing governance and control rights. You stay in control.</p></div><div><p>Management Focus</p><p><span>On fundraising.</span> Fundraising is a full-time job and distracts you from growing your business.</p><p><span>On the business.</span> Once launched, qualified investors can invest at any single time without you being involved in the granular details of the process.</p></div><div><p>Stakeholders Incentivization</p><p><span>Manual.</span> With traditional equity offerings, you usually create a stock option pool for employees, consultants or advisors but it’s near impossible to scale.</p><p><span>Automated.</span> A CAFE offering gives you the ability to create an automated and scalable stakeholder incentivization plan specific to your business</p></div><div><p>Investors Liquidity</p><p><span>Friction.</span> Unless you are a large company with lawyers, access to secondary markets, and an experienced team, it is challenging to enable liquidity for stakeholders and investors prior to an exit or IPO.</p><p><span>Easier.</span> A CAFE offering makes it easier to orchestrate the liquidity of your stakeholders, investors and yourself as secondary trading can happen compliantly on decentralized AMMs.</p></div><div><p>Typical Participants</p><p><span>Professional investors.</span> VC and business angels.</p><p><span>Professional investors &amp; everybody else.</span> Stakeholders, Seed &amp; Pre-seed VCs, business angels &amp; LPs.</p></div></div></div><div id="what-differences-cafe-safe"><p>As there are different types of SAFE, we’ll use a YC SAFE POST with valuation cap / no discount for the comparison. Regarding the CAFE, we’ll use the default CAFE template that Fairmint has made available.</p><div><div><p>Fundraising</p><p><span>One off.</span> Each SAFE issuance is a one-off financing event with its own negotiation phase, its own terms and a fixed amount of capital committed.</p><p><span>Continuous.</span> A CAFE offering is on a “set it and forget it” model. Once launched, qualified investors can invest on their own at any single time.</p></div><div><p>Price terms</p><p><span>Negotiated.</span> The valuation cap, the discount and pro-rata rights are subject to negotiation with every investor which creates friction in the fundraising process.</p><p><span>Automated and non-negotiable.</span> The price of a CAFE is a function of the number of CAFE purchased (the amount invested) and the number of CAFE already issued to investors (the more CAFEs already issued, the pricier), reducing negotiation friction and freeing founder time to focus on building. See “How is the price of a CAFE determined?”.</p></div><div><p>Amount raised</p><p><span>Fixed.</span> For every new SAFE issued, you raise a fixed amount of capital. To raise more capital, you need to issue more SAFE, which dilutes you more (see Dilution above).</p><p><span>Unlimited.</span> For a fixed dilution (see Dilution above), you can raise an unbounded amount of capital with a CAFE offering. New CAFEs are automatically issued (at a higher price calculated automatically) whenever there is demand from investors.</p></div><div><p>Conversion trigger</p><p><span>Equity financing event.</span> SAFEs typically convert into equity at the next equity financing event (a “priced round”). At that moment, the number of shares per SAFE investor is calculated using each SAFE’s valuation cap or discount based on the round’s terms. Calculating conversion can also be challenging due to different formulas for calculating valuation caps, adding confusion and complexity for founders.</p><p><span>Liquidity event.</span> CAFEs convert into equity when a liquidity event happens (IPO or sale of the company). At that moment, the number of shares per CAFE holder is calculated using the target equity percentage allocation of the CAFE offering and giving every CAFE holder its pro-rata share based on their CAFE holdings. The founders and their advisors do not need to worry about complex calculations, as all logic is executed automatically.</p></div><div><p>Converts to</p><p><span>Preferred stocks.</span> SAFEs convert to preferred stock, which is typically the same series of stock with the same rights as the stock being purchased by new investors in a priced round.</p><p><span>Non-voting preferred stocks</span> By default, CAFEs convert to a separate series of non-voting preferred stocks with 1x non-participating liquidation preference rights.</p></div><div><p>Liquidation preference</p><p><span>Yes.</span> Same terms as the new investor (usually 1x non-participating).</p><p><span>Yes.</span> 1x non-participating with the same seniority level as similar SAFEs in the liquidation waterfall.</p></div><div><p>Dilution for Existing Shareholders</p><p><span>Incremental.</span> Every new SAFE issued dilutes existing stockholders, often significantly, as they are the only being diluted. It’s not uncommon for founders to realize at the time of conversion that they have lost 40 to 50% of their equity after multiple rounds of SAFEs prior to a priced round.</p><p><span>Fixed.</span> Your CAFE offering has a fixed equity percentage allocation so the  dilution for existing shareholders is known and fixed, no matter how much capital you end up raising via your CAFE offering. You stay in control.</p></div><div><p>Dilution for SAFE holders</p><p><span>Pre-equity financing: No dilution.</span> Post-Money SAFE holders (the more common form of SAFEs today) do not get diluted by new SAFE issued by the company, existing shareholders (i.e. the founders) do.</p></div><div><p><span>Post-equity financing: Normal dilution.</span> Once SAFEs convert to equity, SAFE holders get diluted every time a new equity financing event occurs. The only way to not get diluted is to (i) have pro-rata rights (ii) reinvest at every round</p></div><div><p>Dilution for CAFE holders</p><p><span>No dilution from equity financing.</span> A CAFE offering has a fixed target equity percentage allocation, making it naturally anti-dilutive. So, collectively, all CAFE holders will not be diluted even if the company raises more equity financing rounds.</p></div><div><p><span>Predictable dilution from new CAFE investors.</span> A CAFE holder, taken individually, gets diluted each time a new CAFE is issued.</p></div></div></div></div><div id="for-investors"><div id="why-cafe-good-investors"><div><ul><li><p><b>Liquidity.</b> First and foremost, the CAFE gives investors a clearer path to liquidity. Unlike …</p></li></ul></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fairmint.co/cafe-continuous-agreement-for-future-equity/">https://fairmint.co/cafe-continuous-agreement-for-future-equity/</a></em></p>]]>
            </description>
            <link>https://fairmint.co/cafe-continuous-agreement-for-future-equity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199610</guid>
            <pubDate>Tue, 24 Nov 2020 16:02:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aurora 7 Prototype – 7 Screen Laptop]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 171 (<a href="https://news.ycombinator.com/item?id=25199499">thread link</a>) | @882542F3884314B
<br/>
November 24, 2020 | https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/ | <a href="https://web.archive.org/web/*/https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="Actual_Page_Container">

<!-- REVOLUTION SLIDER -->

<!-- /REVOLUTION SLIDER --><!-- -->

<section>
<div>





<h2>Prototype Objective Summary:</h2>

<p>Very simple :) - Design and build a proper mobile Security Operations Center.</p>

<p>I always knew this would be an ambitious undertaking. Power considerations, structural rigidity, actual portability and the ability to be easily and quickly compactible were priorities. For a further break down of the objectives please read on.</p>



<h2>Prototype Objective Breakdown and Achievement percentage:</h2>

<p>This is a breakdown of the objectives. It also shows how much of the objective in percentage was achieved with the Aurora 7 Prototype.</p>

<div>


<div><p><label><span>100%</span> 6 Cores or more at 5GHZ capability </label></p>
</div>

<div><p><label><span>100%</span> Fully integrated Multi Touch Screen in Palm rest </label></p>
</div>

<div><p><label><span>100%</span> 4 x 17.3 UHD/4K Screens </label></p>
</div>

<div><p><label><span>70%</span> Ability to easily replace parts </label></p>
</div>

<div><p><label><span>70%</span> Ability to swap wiring and parts with easily attainable parts </label></p>
</div>

<div><p><label><span>90%</span> Rechargeable battery system fully self contained </label></p>
</div>

<div><p><label><span>70%</span> Easily Replaceable batteries </label></p>
</div>



<div><p><label><span>100%</span> NVIDIA GTX 10 Series Graphics </label></p>
</div>

<div><p><label><span>100%</span> Separate Programmable System Monitor LCD </label></p>
</div>

<div><p><label><span>100%</span> User/Arduino accessible Embedded Microcontroller. </label></p>
</div>





<div><p><label><span>100%</span> Ability to fold down compactly to facilitate travel </label></p>
</div>

<div><p><label><span>100%</span> Full NO-NONSENSE 104 Key tactile backlit Keyboard. </label></p>
</div>

<div><p><label><span>80%</span> Overall Structural Rigidity </label></p>
</div>



<div><p><label><span>100%</span> Everything folds or swivels out of the primary chassis (NO appendages) </label></p>
</div>



<div><p><label><span>100%</span> Out of band always visible battery gauge </label></p>
</div>



<div><p><label><span>100%</span> More than 16TB SSD Storage potential </label></p>
</div>
</div>

</div>
</section>

</div></div>]]>
            </description>
            <link>https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199499</guid>
            <pubDate>Tue, 24 Nov 2020 15:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Unique Messages. Only Unique Messengers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199481">thread link</a>) | @dbustac
<br/>
November 24, 2020 | https://danielbusta.com/message/ | <a href="https://web.archive.org/web/*/https://danielbusta.com/message/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-171">

	
<!-- .entry-header -->

	<div>

		<div>

			
<blockquote><p><em>Everything that needs to be said has already been said. But since no one was listening, everything must be said again.</em></p><cite>André Gide</cite></blockquote>



<p>If people were only allowed to say original things, the world would remain in complete silence 99% of the time.</p>



<p>By “original” I mean “new” or “novel” — things that nobody has ever said before.</p>



<p>As the saying from the Bible (a very successful <em>and</em> repetitive book) goes: “<em>There’s nothing new under the soon”.</em></p>



<p>The world is built on repetition.</p>



<p>History. Seasons. Music. Literature. Time. The internet. You name it. Repetition is everywhere. And without it, life would be unbearably overwhelming.</p>



<p>So what makes you think that your work should be any different?</p>



<p>What makes you think that you should be an exception?</p>



<p>You’re not only allowed to repeat what others have said, but you’re also allowed to repeat yourself.</p>



<p>You just have to find slightly new ways to say the same things. You need to infuse them with your character and personality. You have to find <em>your way</em> to say things.</p>



<p>After all, there are no unique messages. There are only unique messengers.</p>


<p><em>This piece is part of a series of 30 atomic essays where I explore what it means to be a&nbsp;<a href="https://rationalcreatives.substack.com/" target="_blank" rel="noreferrer noopener">rational creative</a>&nbsp;and the different aspects of being a creator online. You can read all the others essays&nbsp;<a href="https://twitter.com/dbustac/status/1328419048070279174?s=20" target="_blank" rel="noreferrer noopener">here</a>.</em></p>
		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://danielbusta.com/message/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199481</guid>
            <pubDate>Tue, 24 Nov 2020 15:48:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Seeing the invisible: radio interference on the 868 / 915 MHz frequency bands]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25199382">thread link</a>) | @adunk
<br/>
November 24, 2020 | https://www.thingsquare.com/blog/articles/sub-1-ghz-channel-noise/ | <a href="https://web.archive.org/web/*/https://www.thingsquare.com/blog/articles/sub-1-ghz-channel-noise/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <section><p>IoT (Internet of Things) devices are almost always&nbsp;wireless.</p>
<p>This means that they depend completely on the quality of the wireless&nbsp;communication.</p>
<p>Poor quality means bad connectivity. High quality means good&nbsp;connectivity.</p>
<p>Poor quality typically means that there is too much interference – <a href="https://en.wikipedia.org/wiki/Channel_noise_level" target="_blank">noise</a> – in the air. In the <a href="https://www.thingsquare.com/iot-platform/" target="_blank">Thingsquare IoT platform</a>, we use <a href="https://www.thingsquare.com/blog/articles/channel-hopping/" target="_blank">channel hopping</a> to avoid channels that have too much&nbsp;interference.</p>
<p>But how does the system know which channels are interfered more than&nbsp;others?</p>
<p>Enter <strong>channel scanning</strong>.</p>
<p>Channel scanning measures how much energy there is on each wireless radio&nbsp;channel.</p>
<p>When there it measures a high energy level on a channel, that means that there is noise on the channel. Noise that will interfere with our&nbsp;communication.</p>
<p>The channel scanner maintains a smoothed average of how noisy each channel is. This is called the <em>noise floor</em>. Devices will try to communicate less on channels where the noise floor is&nbsp;high.</p>
<p>But that’s not&nbsp;all.</p>
<p>The channel scanner can also be run in a mode where it continuously scans the channels and reports its findings back to the user. This makes the invisible radio waves visiable to our eyes. And we don’t even need to be physically&nbsp;present.</p>
<p>To see a device’s noise floor, all we have to do it ask&nbsp;it.</p>
<p>This is a typical nice and even noise&nbsp;floor:</p>
<div>
<div data-layout="grid" data-controls="#filterControls" data-animation="quicksand" data-x-gap="32" data-y-gap="32" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 1},
{&quot;width&quot;: 1100, &quot;cols&quot;: 1},
{&quot;width&quot;: 800, &quot;cols&quot;: 1},
{&quot;width&quot;: 480, &quot;cols&quot;: 1},
{&quot;width&quot;: 300, &quot;cols&quot;: 1}
]">
<div>
<p><small>
A good looking noise floor on the 868 MHz band.
</small>
</p>
</div>
</div>
</div>

<p>This is fairly evenly distributed across the&nbsp;channels.</p>
<p>By contrast, this is what the noise floor looks like if we have a rogue transmitter close to the channel&nbsp;scanner:</p>
<div>
<div data-layout="grid" data-controls="#filterControls" data-animation="quicksand" data-x-gap="32" data-y-gap="32" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 1},
{&quot;width&quot;: 1100, &quot;cols&quot;: 1},
{&quot;width&quot;: 800, &quot;cols&quot;: 1},
{&quot;width&quot;: 480, &quot;cols&quot;: 1},
{&quot;width&quot;: 300, &quot;cols&quot;: 1}
]">
<div>
<p><small>
The noise floor after placing a device that continuously sends a signal around 865 MHz.
</small>
</p>
</div>
</div>
</div>

<p>To make the above graph, we programmed a sub-GHz device to send a continuous signal on the 865 MHz band. This is only allowed to do during development – a deployed device must follow strict regulations about frequency use. More on this&nbsp;below.</p>
<div>
<div>
<div>
<div>
<div>
<div>
<div>
<figure>
<svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 8 8" style="enable-background:new 0 0 8 8;" space="preserve">
<path d="M3,1.3C2,1.7,1.2,2.7,1.2,3.6c0,0.2,0,0.4,0.1,0.5c0.2-0.2,0.5-0.3,0.9-0.3c0.8,0,1.5,0.6,1.5,1.5c0,0.9-0.7,1.5-1.5,1.5
C1.4,6.9,1,6.6,0.7,6.1C0.4,5.6,0.3,4.9,0.3,4.5c0-1.6,0.8-2.9,2.5-3.7L3,1.3z M7.1,1.3c-1,0.4-1.8,1.4-1.8,2.3
c0,0.2,0,0.4,0.1,0.5c0.2-0.2,0.5-0.3,0.9-0.3c0.8,0,1.5,0.6,1.5,1.5c0,0.9-0.7,1.5-1.5,1.5c-0.7,0-1.1-0.3-1.4-0.8
C4.4,5.6,4.4,4.9,4.4,4.5c0-1.6,0.8-2.9,2.5-3.7L7.1,1.3z"></path>
</svg>
</figure>
<blockquote>
Access points make particularly good channel scanners, because they have a quick connection to the backend.
</blockquote>
</div>
</div>
</div>
</div>
</div>
</div>
</div>

<h2 id="how-the-channel-scanner-works">How the Channel Scanner&nbsp;Works</h2>
<p>The channel scanner works by sweeping all the available channels – typically 50 – and measure the current signal strength on that&nbsp;channel.</p>
<p>This data is reported to the backend, which sends it to the user’s frontend. The frontend displays it in a nice-looking graph on the&nbsp;screen.</p>
<p>Although all devices maintain a noise floor and run the channel scanner, access points make particularly good scanners because they have fast connection to the&nbsp;backend.</p>
<p>The channel scanner will scan the frequency band that the access point is configured to operate on. So if it is configured for operating in the <span>US</span>, it will scan the 915 MHz band. In Europe, it scans the 868 MHz&nbsp;band.</p>
<p>This is what the channel scanner looks like in continuous scanning&nbsp;mode:</p>
<div>
<div data-layout="grid" data-controls="#filterControls" data-animation="quicksand" data-x-gap="32" data-y-gap="32" data-media-queries="[
{&quot;width&quot;: 1500, &quot;cols&quot;: 1},
{&quot;width&quot;: 1100, &quot;cols&quot;: 1},
{&quot;width&quot;: 800, &quot;cols&quot;: 1},
{&quot;width&quot;: 480, &quot;cols&quot;: 1},
{&quot;width&quot;: 300, &quot;cols&quot;: 1}
]">
<div>
<p><small>
Continuous noise sampling on the <span>EU</span> frequency band.
</small>
</p>
</div>
</div>
</div>


<h2 id="what-are-some-sources-of-channel-noise-in-the-wild-">What are some Sources of Channel Noise in the&nbsp;Wild?</h2>
<p>The most common source of channel noise is other devices that communicate on the 868 / 915 sub-GHz&nbsp;frequencies.</p>
<p>Every device that sends on the 868 / 915 MHz frequencies must adhere to strict&nbsp;regulations.</p>
<p>These regulations are maintained by <a href="https://www.etsi.org/" target="_blank"><span>ETSI</span></a> in the <span>EU</span> and <a href="https://www.fcc.gov/" target="_blank"><span>FCC</span></a> in the <span>US</span>. Even if the two regulatory bodies have slightly different rules, they both have a large&nbsp;overlap.</p>
<p>Devices&nbsp;must:</p>
<ul>
<li>Listen before they talk. If someone else is transmitting, they must wait until the other transmission is done before sending something&nbsp;themselves.</li>
<li>Switch channels often. No device may use their frequency for more than a couple of milliseconds. After that, they must switch to a different&nbsp;frequency.</li>
<li>Alternatively, communicate very&nbsp;seldomly. </li>
</ul>
<p>Because devices follow these rules, their wireless medium will mostly be&nbsp;available.</p>
<p>When another device transmits, only other devices of the same kind can understand what is being&nbsp;transmitted.</p>
<p>That is, a Thingsquare IoT device does not understand what an off-the-shelf garage door opener is&nbsp;saying.</p>
<p>To the Thingsquare device, the signal from the garage door opener will be just noise. Noise that is being picked up by the channel&nbsp;scanner.</p>
<p>And it isn’t just non-Thingsquare devices that will show up as&nbsp;noise.</p>
<p>If two Thingsquare networks are deployed at the same location, they will use different encryption keys and channel hopping schedules. So if they happen to hear a transmission from another device, the receiver will not be able to decrypt it. And so it will be interpreted as&nbsp;noise.</p>
<h2 id="conclusions">Conclusions</h2>
<p>Every <a href="https://www.thingsquare.com/iot-platform/">Thingsquare IoT device</a> runs a channel scanner that scans its sub-GHz bands to check for radio interference. The devices will then try to avoid channels with too much&nbsp;noise.</p>
<p>And by looking at what our devices’ channel scanners measure, we get a peek into the wireless conditions that we cannot see with our bare&nbsp;eyes.</p>
<p><small>Thingsquare builds IoT solutions with our customers with extremely robust sub-GHz wireless mesh networking – <a href="#" data-modal-target="#start">get in touch with us</a> to see how we can help you!</small></p>
</section>
        </div></div>]]>
            </description>
            <link>https://www.thingsquare.com/blog/articles/sub-1-ghz-channel-noise/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199382</guid>
            <pubDate>Tue, 24 Nov 2020 15:36:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Don't Work With Startups (Or FAANGs)]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25199374">thread link</a>) | @elliotbnvl
<br/>
November 24, 2020 | https://devcareer.elliotbonneville.com/no-startups-or-faangs | <a href="https://web.archive.org/web/*/https://devcareer.elliotbonneville.com/no-startups-or-faangs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-no-startups-or-faangs"><p><span><span>This chapter is not a hard and fast set of rules you should always abide by, but is some reasoning and facts that I’ve found to be true about picking a company to work for, while optimizing for a high rate, freedom, and flexibility.</span></span></p><p><span><span>The tl;dr version is that you shouldn’t work with startups, because they are high pressure and don’t pay well, and you shouldn’t work with household names (Facebook, Amazon, Google, Netflix, and their ilk) because they don’t provide as much flexibility.</span></span></p><p><span><span>Instead, you should target a sweet spot right in the middle, working with companies who have enough money to pay you well, but aren’t large enough and well-run enough that they can afford to be extremely exclusive and demanding of their employees.</span></span></p><p><span><span>As a side effect of their size, these companies often have pressing technical issues that are growing pains which haven’t been resolved yet that you can be of real value in solving. Working with them leads to doing high-value, satisfying work that pays well and affords you freedoms you wouldn’t otherwise find.</span></span></p><p><span><span>We’ll clear up some common misunderstandings and establish our reasoning by tackling this topic from first principles, as per usual.
</span></span></p><p><span><span><em>This post is an early release chapter of </em></span><span><em><a href="https://devcareer.elliotbonneville.com/">a book I'm writing in public</a></em></span><span><em>, working title of </em></span><span>Refactor Your Career</span><span><em>. If you're interested in following along for more prerelease chapters and other info, you can sign up for the newsletter below:</em></span></span></p><h2 id="block-b97dcd7b406e467b87a25fbcb87546ba"><span id="b97dcd7b406e467b87a25fbcb87546ba"></span><span><span>Don’t work with startups</span></span></h2><p><span><span>The definition of a startup is “a company prioritizing fast growth over everything else.”</span></span></p><p><span><span>Given the current economic incentive structure of the venture capital model, startups often take outside investment to grow more quickly.</span></span></p><p><span><span>As a result, startups typically optimize to get as much done with as little money and in as little time as possible, because they are not cash-flow positive and have limited financial runway.</span></span></p><p><span><span>Therefore, they are incentivized to find extremely high return-on-investment employees who will work long hours for little money. To find these employees, they will use a number of strategies:</span></span></p><ul><li id="block-53700a214aaf4831be4625f6876e0ed7"><span><span>Offer equity instead of cash compensation</span></span></li><li id="block-2b21919a7bb64e3e962a21fd7d352e42"><span><span>Offer “fun” benefits (beer, ping pong table, catered lunches, free movie tickets, etc.)</span></span></li><li id="block-bb36db0b8db44966b9505bbb5ec4ea1a"><span><span>Target young, talented, and hardworking engineers who are new to the industry and don’t have connections</span></span></li></ul><p><span><span>An extremely high return-on-investment employee is always getting the short end of the stick. The money has to come from somewhere, and in this case the money is coming from the employees’ pockets.</span></span></p><p><span><span>As an aside, your employer wins when they get the most bang for their buck, but the more bang they get for their buck, the less bang you get in return for the most valuable resource you possess -- your time.</span></span></p><p><span><span>At its core, hourly billing is a profoundly adversarial relationship, and you need to understand the rules by which it operates in order to not be taken advantage of. If you don’t know the rules of the game, you will lose. If you know the rules of the game and don’t play to them, you will lose. If you want to win, you must play intelligently, intentionally, and aggressively.</span></span></p><p><span><span>Hourly billing is just the beginning. As you grow in skill and “career capital” (c.f. </span><span><a href="https://www.amazon.com/Good-They-Cant-Ignore-You-ebook/dp/B0076DDBJ6" target="_blank" rel="noopener noreferrer"><em>So Good They Can’t Ignore You</em></a></span><span>, Cal Newport), you’ll want to explore ways to move away from hourly billing to a better way of billing, i.e. separating time worked from results delivered. Big benefits to you and your clients all the way around. Jonathan Stark writes eloquently on the issues with hourly billing </span><span><a href="https://jonathanstark.com/the-moral-dilemma-of-hourly-billing" target="_blank" rel="noopener noreferrer">here</a></span><span>.</span></span></p><p><span><span>Let’s take a deeper look at the strategies startups use to find employees, and why that means working for one is usually a bad strategy.</span></span></p><h3 id="block-5b675128f52f4bc7ae0ffadf51c842d9"><span id="5b675128f52f4bc7ae0ffadf51c842d9"></span><span><span>Taking equity is becoming a micro venture capitalist</span></span></h3><p><span><span>Venture capitalism is a bet on the future. Even the best venture capitalists lose money on most of their investments. They only turn a profit because they invest at scale and need just a couple of big wins per batch of investments in order to make up for that extremely high percentage of losses. They also study investing all day, every day, and are surrounded by people all doing the exact same thing.</span></span></p><p><span><span>Second, time is fungible. If you want, you can trade time for money directly (that’s what hourly billing is, after all). Therefore, an investment of time is an investment of your personal funds.</span></span></p><p><span><span>As a result, if you take equity compensation instead of cash when working at a startup, you are investing your money directly into that startup.</span></span></p><p><span><span>Given all of the above and bearing in mind that venture capitalism is a high risk bet that only works at scale for people who exclusively study how to invest, the odds that you are going to make a return on your investment with the limited amount of resources that you have to invest is vanishingly low.</span></span></p><p><span><span>Don’t try to play venture capitalist with the most valuable thing you have -- your time.</span></span></p><p><span><span><a href="https://www.jwz.org/about.html" target="_blank" rel="noopener noreferrer">Jamie Zawinski</a></span><span> (OG programmer, one of the founders of Netscape and Mozilla.org, the guy who probably wrote your screensaver, and now a dance club proprietor [yes, really]) has this to say about working for startups:</span></span></p><blockquote id="block-bf5cc1f488d24661902d79343aefc830"><span><span>Follow the... money. When a VC tells you what's good for you, check your wallet, then count your fingers.

He's telling you the story of, "If you bust your ass and don't sleep, you'll get rich" because the only way that people in his line of work get richer is if young, poorly-socialized, naive geniuses believe that story! Without those coat-tails to ride, VCs might have to work for a living. Once that kid burns out, they'll just slot a new one in.</span></span></blockquote><p><span><span>You can read the full post from 2011 </span><span><a href="https://www.jwz.org/blog/2011/11/watch-a-vc-use-my-name-to-sell-a-con/" target="_blank" rel="noopener noreferrer">here</a></span><span> and I highly encourage you to do so. It’s a zinger.</span></span></p><h3 id="block-ffa7baffd6a6461a9f9db8658d9237c6"><span id="ffa7baffd6a6461a9f9db8658d9237c6"></span><span><span>Empirically, equity is not as valuable as it seems</span></span></h3><p><span><span>Backing up the logic above, loose empirical analysis shows that if you look at total startup compensation as income combined with equity </span><span><em>adjusted for likelihood of realizing that equity’s value</em></span><span>, statistically you end up making less money in the end.</span></span></p><p><span><span>Patrick McKenzie, a well-known entrepreneur and prolific writer, and currently working at Stripe to “increase the GDP of the internet,” has this to say on the topic of valuing equity grants:</span></span></p><blockquote id="block-f861c0e363034719a6aa4cf4032f0005"><span><span>Roll d100. (Not the right kind of geek? Sorry. rand(100) then.)

0~70: Your equity grant is worth nothing.

71~94: Your equity grant is worth a lump sum of money which makes you about as much money as you gave up working for the startup, instead of working for a megacorp at a higher salary with better benefits.

95~99: Your equity grant is a lifechanging amount of money. You won’t feel rich — you’re not the richest person you know, because many of the people you spent the last several years with are now richer than you by definition — but your family will never again give you grief for not having gone into $FAVORED_FIELD like a proper $YOUR_INGROUP.

100: You worked at the next Google, and are rich beyond the dreams of avarice. Congratulations.

Perceptive readers will note that 100 does not actually show up on a d100 or rand(100).</span></span></blockquote><p><span><span>Dan Luu, another well-known developer and blogger, has this to say on the subject:</span></span></p><blockquote id="block-841b5199ddf14a02af23c89b2adf0131"><span><span>For a more serious take that gives approximately the same results, 80000 hours finds that the average value of a YC founder after 5-9 years is $18M. That sounds great! But there are a few things to keep in mind here. First, YC companies are unusually successful compared to the average startup. Second, in their analysis, 80000 hours notes that 80% of the money belongs to 0.5% of companies. Another 22% are worth enough that founder equity beats working for a big company, but that leaves 77.5% where that's not true.

If you're an employee and not a founder, the numbers look a lot worse. If you're a very early employee you'd be quite lucky to get 1/10th as much equity as a founder. If we guess that 30% of YC startups fail before hiring their first employee, that puts the mean equity offering at $1.8M / .7 = $2.6M. That's low enough that for 5-9 years of work, you really need to be in the 0.5% for the payoff to be substantially better than working at a big company unless the startup is paying a very generous salary.</span></span></blockquote><p><span><span>You can read the rest of Patrick’s post </span><span><a href="https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/" target="_blank" rel="noopener noreferrer">here</a></span><span>, and the rest of Dan’s post </span><span><a href="https://danluu.com/startup-tradeoffs/" target="_blank" rel="noopener noreferrer">here</a></span><span>. I highly recommend that you do so; they are erudite writers with a lot of insight into the industry.</span></span></p><h3 id="block-886c6f74b682471f90e8c002e01f09c9"><span id="886c6f74b682471f90e8c002e01f09c9"></span><span><span>Startup benefits are the cheese in the mousetrap</span></span></h3><p><span><span>While it might seem rather cynical, the benefits at a startup are just the cheese in the mousetrap. If you calculate the actual cash value of the benefits that many startups offer, you’ll find that they’re laughably low. Free beer, access to the company ping pong table (that never gets used), free movie tickets and a two hundred dollar per month business learning stipend actually work out to a relatively low amount of cold, </span><span><del>hard</del></span><span> mildly wrinkled Franklins.</span></span></p><p><span><span>Even things that are seemingly inherent to the unpurchasable, intangible benefits of startup culture like an open desk plan, brilliant and intense coworkers, and technically cutting-edge work can all be had elsewhere for a fraction of the time-cost of working at a startup if you’re willing to think outside the box.</span></span></p><p><span><span>Given that remaining within this particular box is so expensive, I highly encourage you not to do so without full understanding of what you’re doing.</span></span></p><p><span><span>If you can make $80/hr at a startup and $130/hr at a regular company, you are paying the startup $50/hr for the privilege of working there. For $50/hr, you can figure out a way to get most of the same benefits and come out way, way ahead.</span></span></p><p><span><span>Do what makes you happy, but do it with your eyes open. Also, if you really want to work at a startup, you might be better served by starting one.</span></span></p><h2 id="block-aebdc986fc9a4a39917e802441860771"><span id="aebdc986fc9a4a39917e802441860771"></span><span><span>Don’t work with household names</span></span></h2><p><span><span>There’s a word that gets tossed around a lot in the communities where developers that talk about their careers hang out (Hacker News, Reddit, et. al.) -- FAANG. It’s an acronym that refers to Facebook, Apple, Amazon, Netflix, and Google.</span></span></p><p><span><span>People talk about these companies (which pretty much are all out in Silicon Valley or in Seattle) so much that an acronym evolved as a catchall to refer to them. When I say “household name,” these are the companies …</span></span></p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devcareer.elliotbonneville.com/no-startups-or-faangs">https://devcareer.elliotbonneville.com/no-startups-or-faangs</a></em></p>]]>
            </description>
            <link>https://devcareer.elliotbonneville.com/no-startups-or-faangs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199374</guid>
            <pubDate>Tue, 24 Nov 2020 15:35:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Disc as Dongle]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25199286">thread link</a>) | @mortenjorck
<br/>
November 24, 2020 | https://interuserface.net/2020/11/the-disc-as-dongle/ | <a href="https://web.archive.org/web/*/https://interuserface.net/2020/11/the-disc-as-dongle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
          <!-- <style>
        body.single {
          background-color: #;
        }
      </style> -->
      <h3>November 23, 2020</h3>
      
      <p>One possible future of digital distribution is already here – in the guise of an existing format.</p>
      
<p><span>The industrial design</span> of the just-released Playstation 5 may be <a href="http://interuserface.net/2020/06/the-regressive-design-of-the-playstation-5/" data-type="post" data-id="633">regressive</a>, but it looks to the future in one critical way: Judging by the ungainly grafting-on of its disc drive, its original conception as a digital-only console is unmistakable.</p>



<p>For many, digital-only is a conflicting proposition. It curtails long-established freedoms of lending and resale, yet most would agree that it is also inevitably the future. But it doesn’t have to be the former. There is a solution – and it already exists.</p>



<p>The physical discs included with the retail versions of console games have served an increasingly marginal utility over the past console generation. Ever-larger day-one patches weigh in in the gigabytes. Triple-A games already require tens of gigabytes of data to be copied from the disc to the hard drive in order to manage load times, and the Playstation 5’s reliance on a super-fast SSD architecture only formalizes this. </p>



<hr>



<p><span>This leaves the disc</span> with precious little to actually do – it’s too slow to be played from, its data is often outdated by the time it’s installed, and as broadband speeds continue to inch upward, the read speed of even a modern Blu-ray drive is already slower than some fiber connections. Yet despite all this, the lowly disc still has one ace in the hole.</p>



<p>Even stripped of its value as a storage mechanism for game data, the disc serves a critical purpose: It is the physical manifestation of a license, an unencumbered and freely transferable token with which ownership of a game is immutably entangled. Future games could well ship with an essentially empty disc, relying on the network for everything else, yet the advantage of the disc-anchored license would remain undisputed. The disc allows one to, as memorably demonstrated in Sony’s 2013 response to Microsoft’s aborted digital-only Xbox play, simply <a href="https://www.polygon.com/2013/6/10/4417490/playstations-one-step-tutorial-on-sharing-used-games">hand that license to someone else.</a></p>



<hr>



<p><span>All this then invites the question:</span> Why does it have to be a <em>disc?</em> Why does a console need a noisy, mechanically complex, and expensive optical drive just to read a license? Professional software has long used USB peripherals, or dongles as they are semi-affectionately known, as the physical manifestation of licenses. The disc has become a dongle, so why not just use a dongle?</p>



<p>A few kilobytes and an encryption scheme are all that’s required to tie licenses to a physical device today. A tiny, inexpensive USB device could serve as the retail form factor for future games, ushering in an all-download future that retains nearly all the benefits of physical legacy formats. It could perhaps even, via firmware update, add “physical media” support to both the digital-only Playstation 5 and Xbox Series S.</p>
      <!-- <p class="metadata">
        Clayton Miller&ensp;&bull;&ensp;      </p> -->
      </article></div>]]>
            </description>
            <link>https://interuserface.net/2020/11/the-disc-as-dongle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199286</guid>
            <pubDate>Tue, 24 Nov 2020 15:27:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interim analysis shows 91.4% efficacy for the Russian Sputnik vaccine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199213">thread link</a>) | @yread
<br/>
November 24, 2020 | https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/ | <a href="https://web.archive.org/web/*/https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<ul>
<li>
<p>
<b><i>The efficacy of the Sputnik V vaccine is 91.4%, based on the second interim analysis of data obtained 28 days after administering the first dose</i></b> (7 days after the second dose).
</p>
<ul>
<li>
<p>
<b><i>Calculation was based on the analysis of data on volunteers (n = 18,794) who received both the first and second doses</i></b><i> of the Sputnik V vaccine or placebo at the second control point (39 confirmed cases as of November 23, 2020) in accordance with the clinical trial protocol. </i>
</p>
</li>
</ul>
</li>
<li>
<p>
<b><i>Preliminary data from volunteers obtained 42 days after the first dose</i></b><i> (corresponds with 21 days after the second dose) <b>indicates an efficacy of the vaccine above 95%.</b> </i>
</p>
</li>
<li>
<p>
<i>The <b>interim research data will be published by the Gamaleya Center team in one of the leading international peer-reviewed medical journals.</b> Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report.</i>
</p>
</li>
  
<li>
<p>
<i>Currently, 40,000 volunteers are taking part in the Phase III double-blind, randomized, placebo-controlled clinical post-registration study of the Sputnik V vaccine in Russia, of whom more than <b>22,000 volunteers were vaccinated with the first dose and more than 19,000 volunteers with the first and second doses</b>.</i>
</p>
</li>
<li>
<p>
<i>There were <b>no unexpected adverse events during the trials</b>. Monitoring of the participants is ongoing.</i>
</p>
</li>
<li>
<p>
<b><i>The Sputnik V vaccine is based on a well-studied human adenoviral vector platform that has proven safe and effective with no long-term side effects </i></b><i>in more than 250 clinical trials globally conducted during the past two decades - while the history of the use of human adenoviruses in vaccine development began in 1953. More than 100,000 people have received approved and registered drugs based on human adenoviral vectors.</i>
</p>
</li>
<li>
<p>
<b><i>The uniqueness of the Russian vaccine lies in the use of two different human adenoviral vectors</i></b><i> which allows for a stronger and longer-term immune response as compared to the vaccines using one and the same vector for two doses.</i>
</p>
</li>
</ul>
<p>
<b>Moscow, November 24, 2020 –</b><b> </b>The National Research Center for Epidemiology and Microbiology named after N.F. Gamaleya of the Ministry of Health of the Russian Federation (Gamaleya Center) and the Russian Direct Investment Fund (RDIF, Russia’s sovereign wealth fund), announce positive results obtained during the second interim data analysis of the largest double-blind, randomized, placebo-controlled Phase III clinical trials in Russia’s history involving 40,000 volunteers. Gamaleya Center experts have once again confirmed the high efficacy of the Sputnik V vaccine, the world’s first registered vaccine against coronavirus based on a well-studied platform of human adenoviral vectors. <b>Evaluation of efficacy was carried out among volunteers (n = 18,794) 28 days after receiving the first dose (7 days after the second dose) of the vaccine or placebo upon reaching the second check point of the trial in compliance with the clinical trial protocol. The analysis demonstrated a 91.4% efficacy rate for the Sputnik V vaccine. </b>
</p>
<div>
<center><img width="90%" alt="table_eng_spu.jpg" data-src="/upload/medialibrary/70b/70bc3db939ed55ad755e935e8ae26df3.jpg" data-crc="5b1b93c0b54d98c83dc2e94e48f68aad" height="auto" title="table_eng_spu.jpg" src="https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/table_eng_spu.jpg"></center>
</div>
<p>
According to the protocol of Phase III clinical trials of the Sputnik V vaccine, its interim efficacy is calculated at three statistically significant representative check points - upon reaching 20, 39 and 78 cases of novel coronavirus infection among volunteers both in the placebo group and in the group that received the vaccine. The second interim analysis of the Sputnik V vaccine efficacy was carried out on the basis of 39 confirmed cases identified in the placebo group (31 cases) and in the vaccine group (8 cases). The ratio of the placebo group to the vaccinated group is 1 to 3.
</p>
<p>
The uniqueness of the Russian vaccine lies in the use of two different vectors based on the human adenovirus, which allows for a stronger and longer-term immune response as compared to vaccines using one and same vector for two doses. <b>So, preliminary data on volunteers on the 42nd day after the first dose (equivalent to 21 days after the second dose), when they have already formed a stable immune response, indicates the efficacy rate of the vaccine is above 95%.</b>
</p>
<p>
The next interim data analysis will be conducted upon reaching the third check point of 78 confirmed coronavirus cases among the study participants. Final data analysis will be available by the end of Phase III clinical trials.
</p>
<p>
The interim research data will be published by the Gamaleya Center team in one of the leading international peer-reviewed medical journals. Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report.
</p>
  
<p>
As of November 24 more than 22,000 volunteers were vaccinated with the first dose and more than 19,000 volunteers with the first and the second dose of the vaccine at 29 medical centers in Russia as part of the ongoing clinical trials. Currently Phase III clinical trials are approved and are ongoing in Belarus, the UAE, Venezuela and other countries, as well as Phase II-III in India.
</p>
<p>
As of November 24, no unexpected adverse events were identified as part of the research. Some of those vaccinated had short-term minor adverse events such as pain at the injection point and flu-like symptoms including fever, weakness, fatigue, and headache.
</p>
<p>
During the clinical trials, the safety of the vaccine is constantly being monitored; information is analyzed by the Independent Monitoring Committee comprising leading Russian scientists. Collection, quality control and data processing is conducted in line with ICH GCP standards and involves the active participation of Moscow’s Health Department and Crocus Medical, the contract research organization (CRO).
</p>
<p>
<b>Mikhail Murashko, Minister of Health of the Russian Federation,</b> said:
</p>
<p>
“The data demonstrating high efficacy of the Sputnik V vaccine give us hope that we will soon obtain the most important tool in the fight against the pandemic of the novel coronavirus infection”.
</p>
<p>
<b>Alexander Gintsburg, Gamaleya Center Director,</b> said:
</p>
<p>
“It is very important that the second interim efficacy analysis of Sputnik V has confirmed our findings from the first stage and shown its efficacy at 91-92%. Let me stress that the second analysis was conducted a week after volunteers got the second dose, meaning that their bodies have partially reacted to both doses. We expect the efficacy rate to be even higher based on the data three weeks after the second immunization when the body’s strongest and most stable response is achieved. We plan to conduct the third interim data analysis after 78 confirmed coronavirus cases among volunteers and we have every reason to believe that the results will exceed our initial expectations. The drug’s final efficacy assessment will be made available after Phase III clinical trials are concluded.”
</p>
<p>
<b>Denis Logunov, Gamaleya Center Deputy Director,</b> commented:
</p>
<p>
“Results from the second interim analysis of the Sputnik V vaccine are in line with our expectations and predictions. The vaccine’s high efficacy rate is an important indication that a stable immune response to the coronavirus infection is formed among the study’s participants. We expect that the next interim results will demonstrate Sputnik V’s positive traits, moving us closer to the study’s completion and the beginning of a mass vaccination of our fellow citizens.”
</p>
<p>
<b>Kirill Dmitriev, CEO, Russian Direct Investment Fund,</b> said:
</p>
<p>
“Gamaleya Center has developed one of the most efficient vaccines against coronavirus in the world with an efficacy rate of more than 90% and a price that is two times lower than that of other vaccines with similar efficacy rate. The uniqueness of the Russian vaccine lies in the use of two different human adenoviral vectors which allows for a stronger and longer-term immune response as compared to the vaccines using one and the same vector for two doses.”
</p>
<p>
***
</p>
<p>
The safety of vaccines based on human adenoviruses has been confirmed in more than 75 international publications and more than 250 clinical trials conducted during the past two decades - while the history of use of human adenoviruses in vaccine development started in 1953. Adenovirus vectors are genetically modified viruses of the regular flu that cannot reproduce in a human body. When the Sputnik V vaccine is used, the coronavirus itself does not enter the body as the vaccine only contains genetic information about part of its outer protein coat, the so called "spikes" forming its crown. This completely eliminates the possibility of getting infected as a result of vaccination while also causing the body's stable immune response.
</p>
<p>
On September 4, The Lancet, one of world’s leading medical journals, published a research paper on the results of Phase I and Phase II clinical trials of the vaccine that showed no serious adverse events and an effective immune response of those vaccinated.
</p>
<p>
Requests for more than 1.2 billion doses of Sputnik V vaccine came from more than 50 countries. The vaccine supplies for the global market will be produced by RDIF’s international partners in India, Brazil, China, South Korea and other countries.
</p>
<p>
On August 11, the Sputnik V vaccine developed by the Gamaleya Center was registered by Russia’s Health Ministry and became the world’s first registered vaccine against COVID-19. Detailed information on the Sputnik V vaccine, its human adenoviral vectors technological platform, and other details are available at&nbsp;<a href="https://sputnikvaccine.com/" target="_blank">sputnikvaccine.com</a>
</p>
<p>
<b>Be the first to learn about Sputnik V on social networks:</b>
</p>
<p>
<a href="https://twitter.com/sputnikvaccine" target="_blank">Twitter</a>
</p>
<p>
<a href="https://www.facebook.com/sputnikvaccine" target="_blank">Facebook</a>
</p>
<p>
<a href="https://www.instagram.com/sputnik_vaccine/" target="_blank">Instagram</a>
</p>
<p>
<a href="https://www.youtube.com/channel/UCLvQuKL3Nn7NnT9Jyi_dlgQ" target="_blank">Youtube</a>
</p>
<p>
***
</p>
<p>
<b>Russian Direct Investment Fund (RDIF)</b> is Russia's sovereign wealth fund established in 2011 to make equity co-investments, primarily in Russia, alongside reputable international financial and strategic investors. RDIF acts as a catalyst for direct investment in the Russian economy. RDIF’s management company is based in Moscow. Currently, RDIF has experience of the successful joint implementation of more than 80 projects …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/">https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/</a></em></p>]]>
            </description>
            <link>https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199213</guid>
            <pubDate>Tue, 24 Nov 2020 15:20:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built a community platform from scratch in 7 days]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199149">thread link</a>) | @hrishikesh1990
<br/>
November 24, 2020 | https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days | <a href="https://web.archive.org/web/*/https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <h2>I am the co-founder of Flexiple and Remote Tools. In this post, I describe how I built a community website from scratch (almost) in 7 days.</h2>
  
  <p>TABLE OF CONTENTS</p>
<ol><li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#product-brief">Product Brief</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#basic-setup">Basic setup &amp; Making the website live</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#user-onboarding">User Onboarding</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#user-profiles">User Profiles</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#email-notifications">Email Notifications</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#removing-unnecessary-features">Removing unnecessary features</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#consistent-ui">Consistent UI across all pages</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#iterations-on-homepage-ui">Iterations on homepage UI</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#transfer-early-access-data">Transfer early access data &amp; Initial threads</a></li>
<li><a href="https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days#going-live">Going Live</a></li></ol>
<br>
<br>
<ul><li>Custom built on top of <a href="http://lobste.rs/" target="_blank">lobste.rs</a>, computing-focussed community</li><li id="product-brief">Tech stack: Ruby on Rails, Tailwind, JawsDB, Heroku</li><li>Cost: $17/mo ($7 for Heroku dyno + $10 for JawsDB)</li><li>Time to launch: 7 days</li></ul>

<p>For a quick read, you can check this twitter thread instead:</p>
<blockquote>— Hrishikesh Pardeshi (@hrishiptweets) <a href="https://twitter.com/hrishiptweets/status/1306234294214377473?ref_src=twsrc%5Etfw">September 16, 2020</a></blockquote>  
<h2>Product Brief</h2>
<p>We spent ~2 yrs to build a niche remote working audience at Remote Tools. We have 4000 newsletter subscribers, 20,000 unique users monthly, 42 stories &amp; 2 seasons of podcast.</p>
<p>We are building an exclusive remote work focussed community on top of this. Given we already have a sizeable audience, the community website canâ€™t be a simple MVP.</p>
<p>The broad pointers are â€“</p>
<ul><li id="basic-setup">Content posts &amp; user profiles are the prime focus.</li><li>UI &amp; Micro interactions are going to be a major hook for the website.</li><li>Want to stand out from traditional forum websites like&nbsp;<a href="https://tribe.so/" target="_blank">Tribe</a>.</li><li>Timeline for launch is 1-2 weeks. Build only thatâ€™s most essential.</li></ul>
<br><h2>Basic setup &amp; Making the website live</h2>
<p>I didn't want any setup &amp; maintenance hassle and since I am using Rails, Heroku seemed to be the perfect choice.</p>
<p><a href="http://lobste.rs/" target="_blank">Lobste.rs</a> codebase is tested with MariaDB while Heroku pairs well with Postgres. I didn't want to spend a lot of time on migration, so, I searched for Maria-based on Heroku and found JawsDB.</p>
<p><img src="https://remote-tools-images.s3.amazonaws.com/cb_1-1180x744.png" alt="Basic setup &amp; Making the website live" width="100%" max-width="700px"></p><p id="user-onboarding">I was a little skeptical to use an unknown DB/ plugin. So I dropped an email to their support asking a few basic queries. I received a response in just an hour which instilled confidence in me to go ahead with JawsDB.</p>
<br><h2>User Onboarding</h2>
<p>We want only truly passionate &amp; interested people to join Remote Clan and engage in genuine discussions. We didn't want to restrict access by charging for membership, so instead, we had every member share information about their work, experience &amp; their thoughts around remote working.</p>
<p><img src="https://remote-tools-images.s3.amazonaws.com/user+onboarding.png" alt="user onboarding" width="100%" max-width="700px"></p><p>Naturally, the website must have tiered access basis profile completion. I added user profile fields and proper redirects &amp; prompts for incomplete profiles vs. onboard users.</p>
<br><h2>User Profiles</h2>
<p>We already have detailed information &amp; reviews on 900+ remote working tools posted by makers over 2 years. So we wanted to leverage and seamlessly connect Remote Tools with Remote Clan.</p>
<br>

<p>Added an interactive dropdown as part of the profile to choose from the list of tools on Remote Tools. Data from Remote Tools in stored in Remote Clan DB and is fetched automatically once every week.</p>
<br><h2>Email Notifications</h2>
<p>We know it isn't realistic to expect people to log onto Remote Clan by themselves. So we needed a way to prompt users to take action.</p>
<p><img src="https://remote-tools-images.s3.amazonaws.com/email+notifications.png" alt="email notifications" width="100%" max-width="700px"></p><p>Email notifications are the best in this regard since everyone checks their mail regularly. <a href="http://lobste.rs/">Lobste.rs</a>  already had an email notification module, which I tweaked a little to send out notifications when -</p>
<ol><li id="removing-unnecessary-features">Someone comments on a post made by you</li><li>Someone replies to your comment</li><li>Someone tags you explicitly</li></ol>
<br><h2>Removing unnecessary features</h2>
<p>We want all conversations among members to be public so that everyone can benefit from the discussion. So personal messaging as a feature didn't make sense, at least at the current stage.</p>
<p><img src="https://remote-tools-images.s3.amazonaws.com/removing+unnecessary+features.png" alt="removing unnecessary features" width="100%" max-width="700px"></p><p>Similarly, we didn't want to overload users with tons of settings &amp; features which aren't essential to core interaction on the community.</p>
<p id="consistent-ui">So I stripped off most of the extraneous features including hats, moderation log, browser notifications etc.</p>
<br><h2>Consistent UI across all pages</h2><br>

<p>Tailwind is amazing for many reasons, but these stood out for me -</p>
<ul><li>Creating custom components &amp; UI was super easy &amp; quick</li><li id="iterations-on-homepage-ui">I was able to easily replicate custom components across all pages</li><li>I also liked the components offered out-of-the-box and used it for standard pages like all login/ signup pages.</li></ul>
<br><h2>Iterations on homepage UI</h2>
<p>The landing screen is the most important page on the website. We wanted to put our best effort on this so as to retain all of the traffic we divert to it from Remote Tools &amp; other channels.</p>
<p><img src="https://remote-tools-images.s3.amazonaws.com/interations+on+homepage+ui.png" alt="iterations on homepage ui" width="100%" max-width="700px"></p><p id="transfer-early-access-data">We spent a good amount of time discussing &amp; debating possible options for the posts, colors, buttons, hierarchy etc. and came up with 4 choices. We put up the 4 choices through our Twitter account and also sent it in our newsletter to get people's opinion on what clicks.</p>
<br><h2>Transfer early access data &amp; initial threads</h2>
<p><img src="https://remote-tools-images.s3.amazonaws.com/transfer+early+access+data.png" alt="" width="100%" max-width="700px"></p><p>For ~2 weeks, we had put up a simple early access page explaining the community and having interested people sign up. This was before I wrote even a single line of code.</p>
<br>

<p>We had ~150 people complete our onboarding form on Typeform for early access. All of this data was sitting in AirTable and I wrote a simple script to fetch the data &amp; create these users &amp; their profiles.</p>
<p><img src="https://remote-tools-images.s3.amazonaws.com/initial+threads.png" alt="transfer early access data" width="100%" max-width="700px"></p><p>Finally, we created our initial set of threads on community guidelines, introductions &amp; coffee chat.</p>
<br><h2>Going Live</h2>
<p>That's it! We were live on Day 8 ðŸ˜Ž</p>
<p>I sent out welcome email to all early access users via MailMeteor.</p>
<p><img src="https://remote-tools-images.s3.amazonaws.com/going+live.png" alt="Going live" width="100%" max-width="700px"></p><h3>I document my journey and write regularly about tech &amp; remote work on Twitter, you can <a rel="noreferrer noopener" href="https://twitter.com/intent/user?screen_name=hrishiptweets" target="_blank">follow me there</a>.</h3><br>
</div></div>]]>
            </description>
            <link>https://www.remote.tools/remote-work-community/i-built-a-community-platform-in-7-days</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199149</guid>
            <pubDate>Tue, 24 Nov 2020 15:13:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning Vim in a Week]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199069">thread link</a>) | @notkaiho
<br/>
November 24, 2020 | https://mikecoutermarsh.com/learning-vim-in-a-week/ | <a href="https://web.archive.org/web/*/https://mikecoutermarsh.com/learning-vim-in-a-week/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
<div>
<article itemscope="" itemtype="http://schema.org/BlogPosting">

<div itemprop="articleBody">
<p><strong>Note:</strong> I turned this blog post into a talk for Boston Vim, check it out here: <a href="https://mikecoutermarsh.com/boston-vim-learning-vim-in-a-week/">Learning Vim in a Week - Boston Vim</a>.</p>
<hr>
<p>I’d been using Sublime for a long time and recently switched over to Vim. It look me about a full week to learn enough to use it daily for work. Here is what I did to do it!</p>
<p>###Before you start, you should know…</p>
<ul>
<li>All that stuff Sublime or TextMate can do. So can Vim. Plus more.</li>
<li>You’ll be able to keep your entire workflow in a single terminal window, without taking your hands off the keyboard.</li>
<li>
<strong>.vimrc.</strong> This is the file you modify to customize Vim, you’ll become very familiar with it.</li>
<li>Don’t start learning at work, it’s frustrating at first and you won’t be able to get much done. Weekends are good.
<h3 id="getting-started">Getting started…</h3>
<p>These are roughly the steps I followed to learn Vim.</p>
</li>
<li>Grab a coffee, open a terminal, and run the command <em>vimtutor</em>. Go through it a couple times (I did it sporadically over a couple days).</li>
<li>There’s also a gamified version of vimtutor,&nbsp;<a href="https://vim-adventures.com/" target="_blank" rel="nofollow">Vim Adventures</a>.</li>
<li>Steal someone else’s <em>.vimrc</em> and <em>.vimrc.bundles</em>. These files let you add plugins and customize Vim.&nbsp;<a href="https://github.com/thoughtbot/dotfiles" target="_blank" rel="nofollow">Thoughtbot’s is good</a>. Here’s&nbsp;<a href="https://github.com/mscoutermarsh/dotfiles" target="_blank" rel="nofollow">mine</a>. You’ll eventually have your own, but it helps to start with someone elses.</li>
<li>
<a href="https://stackoverflow.com/questions/127591/using-caps-lock-as-esc-in-mac-os-x" target="_blank" rel="nofollow">Remap your Caps Lock to ESC</a>. You will use ESC in Vim <em>constantly</em>. Having it closer to your home row helps.</li>
<li>Speed up your key repeat rate. This is how quickly a key press repeats when you hold down a key. It helps you scroll through code much faster. On OSX you can do this&nbsp;<a href="https://pqrs.org/macosx/keyremap4macbook/" target="_blank" rel="nofollow">KeyRemap4MacBook</a>.</li>
<li>Watch screencasts. Thoughtbot&nbsp;<a href="https://learn.thoughtbot.com/vim" target="_blank" rel="nofollow">has a ton of great ones if you subscribe to prime</a>. The one I found most helpful was “<a href="https://learn.thoughtbot.com/purchases/8889fb98cf0046fb0ae61a1597584573" target="_blank" rel="nofollow">Vim for Rails Developers</a>.”</li>
</ul>
<h3 id="switching-files-and-searching">Switching Files and Searching:</h3>
<p>The biggest barrier for me using Vim full time was quickly navigating a project. There are bundles you can use to make this really easy.</p>
<h3><a href="https://github.com/kien/ctrlp.vim" target="_blank" rel="nofollow">CTRLP</a></h3>
<p>This does the same thing as Sublime’s Ctrl P. Fuzzy search by file name. Must have.</p>
<p><img src="https://mikecoutermarsh.com/assets/archive/images/2014/Oct/ctrlp.jpg" alt="vim ctrl p"></p>
<h3><a href="https://github.com/scrooloose/nerdtree" target="_blank" rel="nofollow">NERDTree</a></h3>
<p>Gives you a sidebar that you can quickly navigate files with. I’ve mapped NERDTree to &lt;F10&gt; so I can quickly open and close it. I’ve also mapped &lt;F9&gt; to bring me to my currently open file in NERDTree (super useful).</p>
<div><div><pre><code><span>" Toggle nerdtree with F10</span>
map <span>&lt;</span>F10<span>&gt;</span> <span>:</span>NERDTreeToggle<span>&lt;</span>CR<span>&gt;</span>

<span>" Current file in nerdtree</span>
map <span>&lt;</span>F9<span>&gt;</span> <span>:</span>NERDTreeFind<span>&lt;</span>CR<span>&gt;</span>
</code></pre></div></div>
<p><img src="https://mikecoutermarsh.com/assets/archive/images/2014/Oct/nerdtree.jpg" alt="nerdtree"></p>
<h3 id="ag-for-vim-project-wide-search">
<a href="https://github.com/rking/ag.vim" target="_blank" rel="nofollow">Ag for Vim</a> (Project wide search)</h3>
<p>Super fast search. Also speeds up indexing when using CtrlP.</p>
<p><img src="https://mikecoutermarsh.com/assets/archive/images/2014/Oct/ag.jpg" alt="ag"></p>

<h3>Copy &amp; Paste:</h3>
<p>I struggled for a while with copying and pasting code from outside Vim. It’s just a little different than other text editors and this makes the transition a little rough.</p>
<p>I recommend reading this&nbsp;<a href="http://vim.wikia.com/wiki/Cut/copy_and_paste_using_visual_selection" target="_blank" rel="nofollow">article on copy/paste</a>.</p>
<p>Also, if you have Vim’s auto indent and auto commenting turned on (which you probably do and want). When you paste, code may automatically be reformatted or commented out. This is annoying.</p>
<p>Vim has a “paste mode” that you can toggle on and off. I mapped it to &lt;F2&gt; so that when I do need to paste from outside of Vim, I can tap a key to do it.</p>
<div><div><pre><code><span>"key to insert mode with paste using F2 key</span>
map <span>&lt;</span>F2<span>&gt;</span> <span>:</span><span>set</span> paste<span>&lt;</span>CR<span>&gt;</span><span>i</span>
<span>" Leave paste mode on exit</span>
<span>au</span> <span>InsertLeave</span> * <span>set</span> nopaste
</code></pre></div></div>
<h2>Finally, Commit to it</h2>
<p>Once I had the basics down, I hid Sublime from my dock and started using Vim for real work. Anytime I found I was slow with something, I’d look up a fast way to do it, learn it and continue on.</p>
<p>One thing I’ve learned is, there is always a faster way to do something in Vim.</p>
<h3 id="more-reading">More reading</h3>
<ul>
<li><a href="https://learn.thoughtbot.com/vim">Thoughtbot’s material on Vim is really great.</a></li>
<li>Once you learn Vim, checkout Tmux - <a href="https://robots.thoughtbot.com/a-tmux-crash-course">A tmux Crash Course</a>
</li>
</ul>
</div>



</article>
</div>
</div></div>]]>
            </description>
            <link>https://mikecoutermarsh.com/learning-vim-in-a-week/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199069</guid>
            <pubDate>Tue, 24 Nov 2020 15:06:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A lesson in creating and using niche business DSLs at scale]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198991">thread link</a>) | @rhnvrm
<br/>
November 24, 2020 | https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/ | <a href="https://web.archive.org/web/*/https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>At Zerodha, we process millions of trades in real-time, where each trade comes
into the system as concurrent high throughput HTTP requests. Each trade
increases the latency for subsequent orders in the queue that are under
processing at the same time at our OMS (Order Management System). When a single
order comes through to the OMS, it goes through a bunch of computationally
intensive validations and adds to the latency. To reduce the latency of orders,
we decided to offload some of these business validations from the OMS into an
external component called Veto, which pre-validates incoming orders based on
custom dynamic rules set by our Risk Management team. Rejected orders never go
through to the OMS thereby reducing significant load on the OMS. This is the
story of how we incrementally built this engine to keep up with the changing
business and regulatory environment starting with a custom DSL (Domain Specific
Language) and ending up with writing a framework to manage rules written in Go
and embedded inside Go plugins.</p><h2 id="overview">Overview</h2><p>Our goal with Veto was to build a dynamic evaluation engine framework capable of
hot-reloads. This framework would provide a generic environment to manage, track
and audit rules and filters on an easily accessible dashboard. The engine should
have support for custom data-stores related to the orders. Rules in this
framework are business validations on orders placed by our clients. These
validations range from simple checks like validating the limit prices to be
within circuit limits, to complex beasts, which <a href="https://support.zerodha.com/category/trading-and-markets/kite-web-and-mobile/articles/why-did-my-bank-nifty-option-order-get-rejected">validate fresh buy
orders</a>
in Nifty/BankNifty strikes due to exchange OI restrictions.</p><p><img src="https://zerodha.tech/static/images/bnf-veto-rejection.png" alt="banknifty-rejection-example"></p><p>Our first solution utilized our research from the
<a href="https://sentinel.zerodha.com/">Sentinel</a> project. We combined
<a href="https://github.com/Knetic/govaluate">knetic/govaluate</a>, which is an expression
evaluation engine, along with a filter manager and a hot reload mechanism with
an HTTP server which would either respond with an appropriate rejection to
the incoming order or proxy to the upstream OMS, thereby acting as a reverse
proxy with validations. The expression language was similar to Excel formulas,
which was familiar to our RMS Team that managed and operated it through custom
management dashboard built using <a href="https://frappe.io/">Frappe/ERPNext</a>.</p><h2 id="problems-with-dsls">Problems with DSLs</h2><p>After taking it live, we realized a bunch of issues that
cropped up and became pain points for us over time. These were not really technical,
but more or less, human usability issues.</p><ul><li><p>Since the underlying engine was a simple expression evaluator, the operators
would end up spending hours trying to write complex rules, and similarly the
developers, who are supposed to approve the rule to be production ready, spent
time reviewing it.</p><ul><li><p>This was due to how unreadable the expressions would become beyond a certain
complexity. Simple rules were indeed faster to write, but anything beyond
it would be beyond human capability to comprehend, which would cause
unnecessary and difficult debugging sessions in the office.</p></li><li><p>Unlike a regular language with branching, the operator writing the
rule would be stuck on writing logic defined with bracket matching
and <code>AND/OR</code> statements. Also, missing support for variables would not
allow us to reuse values.</p></li><li><p>To write a single complex rule, operators would depend on writing the rules
into manageable chunks. For example, a single spread (shown below) the rule would be broken
into <code>spread_ce_buy</code>, <code>spread_ce_sell</code>, <code>spread_pe_buy</code>, <code>spread_pe_sell</code>
rules.</p><p><img src="https://zerodha.tech/static/images/veto-govaluate-example.png" alt="Veto Govaluate Sample"></p></li></ul></li><li><p>Custom error messages and any non-boolean behaviour were not possible, as the
expression can only evaluate to a boolean. Switching to a proper language, we
could use early returns in the rule and return custom messages alongside the
evaluation result.</p></li><li><p>Implementing new functions and adding new variables was a pain.</p><ul><li>This meant that if you were to add a new function, you would have to bundle
it within the engine, defeating the purpose of the rules being dynamic.</li><li>This also meant the developer had to always be involved in writing the rules, defying the whole purpose of having a DSL for business folks.</li></ul></li></ul><h2 id="new-beginnings">New beginnings</h2><p>Our learnings from these issues made us reflect if it would be worth it for the
operators to keep using a simple expression language. The way we were going, we were
essentially building a DSL (Domain Specific Language) on top of <code>govaluate</code>,
that would keep getting more complex with time.</p><p>We finally decided that a solution to the problem was to use Go-like language as
the DSL instead of <code>govalute</code> and distribute the dynamic rules as Go plugins, as
Veto was written in Go in the first place, just like the rest of the Kite stack.
It is simple, easy to learn, and has good tooling around it.</p><p>We debated heavily on the best approach to solve the problems that we were
facing with veto rules and shortlisted a few candidates. We picked a complex rule in production written using govaluate and wrote that in the following to benchmark the performance of the rules in the alternatives.</p><ul><li><a href="https://github.com/Knetic/govaluate">Govaluate</a> - evaluates arbitrary C-like expressions</li><li><a href="https://github.com/containous/yaegi">Yaegi</a> - embedded go interpreter</li><li><a href="https://www.openpolicyagent.org/docs/latest/policy-language/">Rego</a> - open-policy-agent DSL</li><li><a href="https://github.com/hashicorp/go-plugin">Hashicorp Plugins</a> - plugin system over RPC.</li><li><a href="https://golang.org/pkg/plugin/">go-plugins</a> - native go plugins</li></ul><p>Benchmark Results:</p><div><pre><code data-lang="fallback">govaluate:
1319773 907 ns/op
go-plugins:
2745398 503 ns/op
yaegi:
202173 11091 ns/op
rego:
83476 13796 ns/op
</code></pre></div><p>We considered govaluate to be the baseline for our experiments. In our
benchmarks, native plugins outperformed other solutions and brought the power of
the entire Go runtime into independent plugins. We discarded Hashicorp plugins,
as they were slower. Yaegi was nice, but not as fast as govaluate. Govaluate and
Yaegi provide a simpler way to distribute rules, when compared to native plugins
which need a bit of orchestration.</p><h2 id="veto-v2">Veto v2</h2><p>Considering all the facts, we decided to go ahead with native Go plugins. They
are as fast as native code once loaded, and given enough tooling, act just like
regular Go code, along with all its niceties like type safety and none of the
baggage of other alternatives.</p><p>Veto v2 would be a web server which loads rules from native Go plugins on boot
and behave like a reverse proxy accepting incoming orders as HTTP requests,
either rejecting them in place or proxying them to the upstream OMS.</p><p>Since there are
<a href="#overcoming-go-plugin-caveats">problems</a> associated with building and
distributing plugins due to dependency issues, requiring in-tree building and
compilation, we decided to first work on writing a framework to abstract the
caveats associated with go plugins.</p><h3 id="a-framework-for-writing-rules">A framework for writing rules</h3><p>Rules in Veto v2 are now written in plain Go by the operators. A rule looks similar
to the following sample rule.</p><p>Each rule is expected to provide three functions.</p><p>Rules are contained in the <code>Validate</code> functions that are expected to accept an
interface and return a <code>rule.Result</code>. The contexts contain the controllers and
data needed for validating the rule, and are passed by the host to the rule
manager which iterates over all the rules. The host can then interpret the result
and do what it needs to, in our case render a response to the user with a custom
message, or proxy to the upstream.</p><p>Another added benefit of having written a custom go plugin based framework for
rules, is that we can implement our own testing framework for validation of the
rules. Every rule is expected to return its own testcases as a
<code>map[interface{}]e.Result</code> where the interface is the context. This way if a
rule implements all the testcases, we are sure that any minor refactor will be
also correct in the future. This reduces the need for constant developer
oversight and the testing needed for the rules. Also, the testcases provide
extra documentation for the future.</p><p>The following rule contains a sample circuit limit rule for illustration.</p><div><pre><code data-lang="go"><span>package</span> main

<span>import</span> (
    <span>...</span>
)

<span>// Slug is the identifier for the rule. Used in statistics and logging.
</span><span></span><span>func</span> <span>Slug</span>() <span>string</span> {
    <span>return</span> <span>"a_sample_ckt_limit_rule"</span>
}

<span>// Validate, is where the validation logic resides.
</span><span></span><span>func</span> <span>Validate</span>(data <span>interface</span>{}) (e.Result, <span>error</span>) {
    d, err <span>:=</span> m.<span>SetupOrderData</span>(data)
	<span>if</span> err <span>!=</span> <span>nil</span> {
		<span>return</span> e.Result{}, err
	}

    <span>...</span>

    <span>// Get the market for the incoming order
</span><span></span>    s, err <span>:=</span> d.Ticker.<span>GetSnapForOrder</span>(d.OrderData.Order)
	<span>if</span> err <span>!=</span> <span>nil</span> {
		<span>return</span> e.Result{}, err
	}

    <span>...</span>

	<span>// Check limits
</span><span></span>	<span>if</span> d.Order.Price &gt; s.UpperCircuitLimit {
		<span>return</span> e.Result{
			Result: <span>true</span>,
			Message: fmt.<span>Sprintf</span>(
				<span>"Your order price is higher than the current [upper circuit limit](https://support.zerodha.com/category/trading-and-markets/trading-faqs/articles/what-does-circuit-limits-i-e-price-bands-mean) of %g. You can place an order within the range or [use GTT](https://support.zerodha.com/category/trading-and-markets/gtt/articles/what-is-the-good-till-triggered-gtt-feature) for long-standing orders."</span>,
				s.UpperCircuitLimit),
		}, <span>nil</span>
	}

	<span>if</span> s.LowerCircuitLimit &gt; d.Order.Price {
		<span>return</span> e.Result{
			Result: <span>true</span>,
			Message: fmt.<span>Sprintf</span>(
				<span>"Your order price is lower than the current [lower circuit limit](https://support.zerodha.com/category/trading-and-markets/trading-faqs/articles/what-does-circuit-limits-i-e-price-bands-mean) of %g. You can place an order within the range or [use GTT](https://support.zerodha.com/category/trading-and-markets/gtt/articles/what-is-the-good-till-triggered-gtt-feature) for long-standing orders."</span>,
				s.LowerCircuitLimit),
		}, <span>nil</span>
	}

    <span>return</span> e.Result{}, <span>nil</span>
}

<span>// TestData is expected to be provided by the rule,
</span><span>// so it can be validated before it is allowed to be published.
</span><span></span><span>func</span> <span>TestData</span>() <span>map</span>[<span>interface</span>{}]e.Result {
	tckr <span>:=</span> <span>&amp;</span>ticker.Ticker{
		Data: <span>map</span>[<span>string</span>]<span>interface</span>{}{
			<span>"NSE:INFY"</span>: snaps.Snap{
				LastPrice:         <span>12.34</span>,
				UpperCircuitLimit: <span>15.0</span>,
				LowerCircuitLimit: <span>10.0</span>,
			},
		},
	}

	<span>return</span> <span>map</span>[<span>interface</span>{}]e.Result{
		<span>&amp;</span>m.OrderContext{
			Controllers: m.Controllers{
				Ticker:      tckr,
			},
			OrderData: m.OrderData{
				Order: oms.OrderParams{
					Exchange:      <span>"NSE"</span>,
					Tradingsymbol: <span>"INFY"</span>,
					Price:         <span>20.34</span>,
					OrderType:     <span>"LIMIT"</span>,
				},
			},
		}: e.Result{
			Result:  <span>true</span>,
			Message: <span>"Your order price is higher than the …</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/">https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/</a></em></p>]]>
            </description>
            <link>https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198991</guid>
            <pubDate>Tue, 24 Nov 2020 14:58:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[John Kerry Shifts Position on Nuclear Power to Face the Challenge of Climate]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198858">thread link</a>) | @ericdanielski
<br/>
November 24, 2020 | https://rationalmiddle.com/secretary-john-kerry-shifts-position-on-nuclear-power-to-face-the-challenge-of-climate-change/ | <a href="https://web.archive.org/web/*/https://rationalmiddle.com/secretary-john-kerry-shifts-position-on-nuclear-power-to-face-the-challenge-of-climate-change/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="body">
        <div>
            <div>
  				<div id="content" role="main">
                	<article>	

           
    <div>
        <p>The debate over nuclear power is a hotly contested one. Opponents cite old and still important challenges like safety of citizens from atomic radiation, security of nuclear material, and the remaining waste product produced by nuclear power. Some of these issues had almost been forgotten by the public until the explosion of <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwj-m_7-hLvRAhUC4oMKHcr8DXUQFggcMAA&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FFukushima_Daiichi_Nuclear_Power_Plant&amp;usg=AFQjCNFjDkYep94vHSleUg_0nEpPa9--GA&amp;sig2=ImRId1sZbKSDMYro6Qi9fA">Fukushima Daiichi</a>, a Generation II nuclear plant in Japan, in 2011. Nuclear disaster is a fear deeply embedded in our psyche. It’s the subject of countless movie plots and TV shows.</p>
<p>However, in the last decade a new fervor for nuclear has been building around nuclear both for and against. This interest has inspired the creation <a href="http://pandoraspromise.com/">documentary</a> <a href="http://www.imdb.com/title/tt1194612/combined">films</a> and sparked the formation of <a href="https://en.wikipedia.org/wiki/Transatomic_Power">new companies</a> which aim to tackle the things that make the public uneasy about nuclear. Proponents have been touting new safety systems and a return to research performed in the 60s and 70s on reactors that would produce far less waste than current designs.</p>
<p>Increasingly, both sides have been playing tug of war over this information, but little has been said directly by the Obama administration. Obama did appoint Ernest Moniz, a nuclear physicist, to the post of Energy Secretary in 2013, but both Moniz and the administration have been relatively quiet about nuclear since that time – until this week.</p>
<p>During a <a href="https://www.state.gov/secretary/remarks/2017/01/266741.htm">speech at MIT</a> on January 9, 2017, Secretary of State John Kerry explained that he once did not believe nuclear was a viable solution and supported Bill Clinton in shutting down nuclear research. He went on to say that, given the challenge of climate change and the advances in nuclear proposed in Generation IV, that researchers should “go for it”.</p>
<p>This kind of ability to reassess one’s position with scientific advancements, learning new information, and placing it in the context of the challenge of climate change and the food/water/energy nexus is what the Rational Middle is all about.</p>
<p>Watch the video below.</p>
<p><iframe width="900" height="506" src="https://www.youtube.com/embed/f15rSTy7Spg?feature=oembed" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p>
                
                
        
            </div><!--/item-content-->
    </article>                </div><!--#content-->
                            </div><!--/row-->
        </div><!--/container-->
    </div></div>]]>
            </description>
            <link>https://rationalmiddle.com/secretary-john-kerry-shifts-position-on-nuclear-power-to-face-the-challenge-of-climate-change/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198858</guid>
            <pubDate>Tue, 24 Nov 2020 14:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Homemade recycling rig turns plastic waste into new products]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198780">thread link</a>) | @lysp
<br/>
November 24, 2020 | https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/ | <a href="https://web.archive.org/web/*/https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-26604">
<h3>Homemade recycling rig turns plastic waste into new products</h3>
<p> — <span>November 24th, 2020</span>
</p>
<div>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6.jpg" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6.jpg 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-300x225.jpg 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-385x289.jpg 385w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-768x576.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>While that plastic cup, bag, dish, or other item may have served its purpose, more than likely it could be formed into something new. With this in mind, the SOTOP-Recycling team of Manuel Maeder, Benjamin Krause, and Nadina Maeder developed <a href="https://www.instructables.com/Automated-Injection-Molding-Machine-for-Plastic-Re/">an automated injection molding machine</a> that can be built at home and is small enough to allow you to run your own recycling operation!</p>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder.png" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder.png 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder-300x218.png 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder-768x558.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>The “Smart Injector” receives shredded pieces of plastic in a small hopper, then transports them down an extrusion pipe where heat is applied. This material is clamped together via a pair of stepper motors, with screws and timing belts implemented to apply sufficient pressure. Everything is controlled by an <a href="https://store.arduino.cc/mega-2560-r3">Arduino Mega</a>. </p>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD.jpg" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD.jpg 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD-300x200.jpg 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD-768x512.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>As shown in the video, the plastic waste is converted into phone covers in just minutes, though other things could also be made depending on the form tooling used.</p>
<figure><p>
<iframe title="Injection molding machine for recycling plastic" width="500" height="281" src="https://www.youtube.com/embed/Eq9IbetsLB4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>
<section>


<p>
<small>

You can follow any responses to this entry through the <a href="https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/feed/">RSS 2.0</a> feed.
You can <a href="#respond">leave a response</a>, or <a href="https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/trackback/" rel="trackback">trackback</a> from your own site.
</small>
</p>
</section>
</div>
</div></div>]]>
            </description>
            <link>https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198780</guid>
            <pubDate>Tue, 24 Nov 2020 14:39:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making 8500 plants available to you]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25198771">thread link</a>) | @roboben
<br/>
November 24, 2020 | https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html | <a href="https://web.archive.org/web/*/https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://permapeople.org/blog/assets/making-8500-plants-available-on-permapeople.jpg" alt="8500 plants available on Permapeople"></p>

<p><strong>tl;dr We made ~8500 plants available to you by importing the Plant For a Future dataset. You can use it now to create lists, guilds and help improving that data.</strong></p>

<p>The first thing I did when I started Permapeople was to look at other plant databases and platforms with a similar focus. If you ever were in the situation to try to get some information about specific plants, especially attributes which are important for a Permaculture style of gardening, there is a high chance you found <a href="https://pfaf.org/">Plants for a Future</a> (PFAF). It is a database started by Addy and Ken Fern, later turned into a not for profit organization operated by a handful of trustees. In recent years, they refocused their work on plants’ role in fighting climate change through carbon sequestration. If you don’t know them, you should definitely check them out.</p>

<p>I put a lot of consideration into importing the PFAF database into Permapeople, but decided against it in the beginning. The more I talked to people and our first users, I figured that using existing datasets saves contributors a lot of time and provides an immediate value. Most people I talked to are beginners or people running larger gardening operations, and I wanted to create something that could help them immediately in their projects. I think the PFAF database is one of the best resources available, but I found some problems with it, limiting its usefulness.</p>

<h2 id="data-quality">Data Quality</h2>

<p>While the PFAF dataset is probably the biggest by numbers and completeness, it has a few problems: Many things are outdated, incorrect, ambiguous, or incoherent. Some might think that plant data and its field, <em><a href="https://en.wikipedia.org/wiki/Botany">botany</a></em> is a static field. Actually, it is really the opposite: New discoveries, nomenclature changes, and fresh scientific research comes in weekly. Keeping track of this with a tiny circle of paid workers is a tough job to do. Even if you could contribute a fix, there is no way of doing that. Crowdsourcing this problem by letting anyone change the data could be very helpful. This is one of the main reasons I started Permapeople: I wanted to have one place to find up-to-date, correct, peer-reviewed information on the plants I want to grow. If I miss some info or find something incorrect, I can easily edit it and help everyone who needs this information after me. Think Wikipedia, but specifically for plants.</p>

<h2 id="no-clear-roadmap">No clear roadmap</h2>

<p>What makes working with PFAF data more challenging is that there is no information on if and when data gets corrected, updated, or added to PFAF. We do not know if and when new features will be added and if the organization will shift its focus to other projects in the future.</p>

<h2 id="unstructured-data">Unstructured Data</h2>

<p>While this is related to the data quality, the PFAF data is not structured and rather a full-text description of the plant. This makes it hard to find or sort through specific info because many attributes are not filterable and searchable. For example, while PFAF has great information on <em>companion planting</em>, it’s impossible to search based on these connections. You are left with searching through many plant profiles, reading long paragraphs, and scanning for the required information.</p>

<h2 id="missing-features">Missing features</h2>

<p>Having a database is great, but information seekers and contributors need some functionality to work with it. PFAF doesn’t provide any of that, and this is why we already added some of these missing features to Permapeople.</p>

<h3 id="see-the-editing-history-and-sources">See the editing history and sources</h3>

<p>A huge factor of why Wikipedia is so trustworthy is that every change is public and can be easily reviewed by anyone. This lets a user easily gauge any meta-information about a plant: Is this info credible or just a myth created by the hive-mind of the internet? Do many people agree with that info? Are there sources proving the correctness of the information? If yes, how many? Or how are people working within a similar climate to you faring with that plant?</p>

<h3 id="create-plant-connections-and-guilds">Create plant connections and guilds</h3>

<p>Companion planting and the more advanced <a href="http://www.neverendingfood.org/b-what-is-permaculture/permaculture-guilds/">concept of guilds</a> are a huge part of the success of Permaculture. At Permapeople, you can create explicit plant connections (may they be beneficial or adversary) and organize plants into guilds. This info can be fed back to the database and give users even better information: If two plants are used in many user-generated guilds, there is a high chance that these plants go well together.</p>

<p>Much of this functionality is in a very early stage, and we need your help and feedback to improve these features and the data itself. I hope this post helped you understand why I imported the PFAF dataset into Permapeople and how we plan to improve on the hard work PFAF and its contributors have already accomplished. In the best case, we can contribute our changes back to PFAF.</p>

<p>If you are interested, I suggest you try to <a href="https://permapeople.org/search">search for some plants</a> and <a href="https://permapeople.org/users/sign_up">sign up</a> to create your first list or guild.</p>

<p>Happy growing 🌱✌️,</p>

<p>Ben</p>

<p>PS: If you work for PFAF (or know someone who does), please reach out to us at hello at permapeople org - we’d love to talk about the future!</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198771</guid>
            <pubDate>Tue, 24 Nov 2020 14:38:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A heat map and a new styling for Indoor= (Openstreetmap indoor mapping)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198621">thread link</a>) | @liotier
<br/>
November 24, 2020 | https://2metz.fr/blog/indoorequal-style-heatmap/ | <a href="https://web.archive.org/web/*/https://2metz.fr/blog/indoorequal-style-heatmap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article lang="en">
  
  <p><time datetime="2020-11-24 00:00:00 +0000">24 November 2020</time> - François</p>

  <p><em>For those who are not familiar with <a href="https://indoorequal.org/">indoor=</a>, I recommend consulting the <a href="https://2metz.fr/blog/indoorequal-openstreetmap-indoor-viewer/">introductory post</a>. In short, it’s a map that displays the interior spaces of OpenStreetmap with a level selector.</em></p>

<p>A new version is available with improvements such as the heat map and a new styling.</p>

<h2 id="heat-map">Heat map</h2>

<p>To rapidly visualize locations that are indoor mapped, <a href="https://indoorequal.org/">indoor=</a> can now display a low zoom heat map.</p>

<figure>
<img alt="A heat map to locate indoor mapped locations in OpenStreetMap" src="https://2metz.fr/assets/blog/indoorequal-heatmap-2adfe009e4cc18dda707f9c67f30822aaa9214b5c70c5bfcf4138a891d099a2e.png" integrity="sha256-Kt/gCeTMGN2nB/nGfzCCKqqSFLXHDFv89BOKiR0Jmi4=" crossorigin="anonymous">
<figcaption>A heat map to locate indoor mapped locations in OpenStreetMap</figcaption>
</figure>

<p>It will therefore be much easier to locate indoor mapped locations. Here are a few places that I discovered:</p>

<ul>
  <li><a href="https://indoorequal.org/#map=17.29/41.97637/-87.905125&amp;level=1">Chicago Airport, IL, USA</a></li>
  <li><a href="https://indoorequal.org/#map=17/1.360945/103.990497&amp;level=1">Singapore Airport, Singapor</a></li>
  <li><a href="https://indoorequal.org/#map=17.39/51.499368/-0.12456&amp;level=1">House of Commons, London, UK</a></li>
  <li><a href="https://indoorequal.org/#map=18.77/38.8977124/-77.0365066">The White House, Washington D.C., USA</a></li>
</ul>

<p>This work was carried out by <a href="https://pavie.info/">Adrien Pavie</a>.</p>

<h2 id="new-styling">New styling</h2>

<p>In order to clearly distinguish the different interior spaces, the styling has been largely revised.</p>

<ul>
  <li>Rooms with interest points are in blue</li>
  <li>The other rooms are in yellow</li>
  <li>Traffic areas are in white</li>
  <li>A specific icon set to make the click more explicit has been added</li>
</ul>

<p><img alt="" src="https://2metz.fr/assets/blog/indoorequal-style-15cf917174f4ade9112135a4eba075741fa9f425d2773012ee4f2b99425bbc02.png" integrity="sha256-Fc+RcXT0rekRITWk66B1dB+p9CXSdzAS7k8rmUJbvAI=" crossorigin="anonymous"></p>

<p>In addition to the indispensable vending machines for drinks and other delicacies, you will also be able to see the ping-pong and foosball tables.</p>

<figure>
<img alt="" src="https://2metz.fr/assets/blog/indoorequal-table-tennis-ffbf484050c0f460f56fbc6b970e06ccff738699c48a81a081d003dcc66eee08.png" integrity="sha256-/79IQFDA9GD1b7xrlw4GzP9zhpnEioGggdAD3MZu7gg=" crossorigin="anonymous">
<figcaption><a href="https://indoorequal.org/#map=20.38/48.8520471/2.2868159&amp;level=1&amp;poi=node:2741751144">A ping-pong table at the École Centrale d'Électronique, Paris, France</a></figcaption>
</figure>

<figure>
<img alt="" src="https://2metz.fr/assets/blog/indoorequal-table-soccer-3b34b8ab0cda0ff16fc9d67d2656656f7bc4a8e053bf50a1988002ef4caa6d5e.png" integrity="sha256-OzS4qwzaD/FvydZ9JlZlb3vEqOBTv1ChmIAC70yqbV4=" crossorigin="anonymous">
<figcaption><a href="https://indoorequal.org/#map=20.03/48.9024495/2.4005376&amp;level=0">A foosball table in Arkose, Pantin, France</a></figcaption>
</figure>

<p>This work was carried out by <a href="https://www.jawg.io/">Jawg</a>.</p>

<h2 id="other-improvements">Other improvements</h2>

<ul>
  <li>Multiple interest points have been added</li>
  <li>The display of the interior doors has been corrected</li>
</ul>

<h2 id="integrate-indoor-in-your-map">Integrate indoor= in your map</h2>

<p>Do you want to add interior spaces to your map? Use the <a href="https://github.com/indoorequal/mapbox-gl-indoorequal">mapbox-gl-indoorequal</a> library and create your free API key on <a href="https://indoorequal.com/">indoorequal.com</a>.</p>

<p>If you are not using mapbox-gl, the schema has been updated so you can make your own integration: <a href="https://indoorequal.com/schema">indoorequal.com/schema</a>.</p>

<hr>

<p>Thanks to everyone who contributed to this version.</p>

<p>To have a look at all of this, you can go on <a href="https://indoorequal.org/">indoor=</a>.</p>

<p>And to learn more about mapping indoor spaces, please visit the <a href="https://wiki.openstreetmap.org/wiki/Simple_Indoor_Tagging">wiki page Simple Indoor Tagging</a>.</p>


</article>

    </div></div>]]>
            </description>
            <link>https://2metz.fr/blog/indoorequal-style-heatmap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198621</guid>
            <pubDate>Tue, 24 Nov 2020 14:19:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Always leave the code better than you found it]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25198597">thread link</a>) | @mooreds
<br/>
November 24, 2020 | https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Dear new developer,</p>



<p>I’ve spent a lot of my time maintaining working code. I think that is more typical of software developers than working in greenfield development. Yes, there are definitely jobs where you are writing more new code than maintaining, upgrading, bug fixing and improving old code (startups without product market fit being one, consulting being another) but in general code is expensive and folks want to run it for a long time. </p>



<p>Often you’ll jump into code to fix a bug, investigate an issue or answer a question.</p>



<p>When you do so, improve it. This doesn’t mean you rewrite it, or upgrade all the libraries it depends on, or rename all the variables. </p>



<p>You don’t need to transform it. </p>



<p>But you should make it better. Just clean it up a bit. Doing so makes everyone’s lives just a bit better, helps the codebase in a sustainable way, and assists the business by making its supporting infrastructure more flexible.</p>



<p>What are some ways to improve the code when you are in it?</p>



<p><strong>Document</strong></p>



<p>Whether that is a comment that explains something tricky, a larger piece of documentation external to the code which explains how to interact with it, or fixing a typo, trustworthy documentation is key to interacting with code. This is a good way to start improving a codebase because it has minimal impact on the actual code. Therefore it is low risk. But if you’ve ever had a great comment explain a confusing bit of code, you’ll appreciate the time this effort can save.</p>



<p>You can also help documentation by removing old, crufty docs. If you see a comment that doesn’t apply, remove it. If there’s cut and paste documentation which doesn’t apply, get rid of it. That cleans up the code for the next person to come along (who might be you).</p>



<p><strong>Write a test or improve a test</strong> </p>



<p>Tests help you write maintainable, extensible code that others can change fearlessly. If you run across code that isn’t tested and you have time and the supporting framework to write one, do so. </p>



<p>Even if it tests simple functionality such as “can I instantiate this object” or “how does this function react when I pass it two null values”, an additional test will help the robustness of the code. </p>



<p><strong>Refactor it</strong></p>



<p>This is one of the most flexible improvements. Refactoring code can range from renaming a variable to be more true to its nature to an overhaul of an entire module. Start small and don’t get wrapped up in perfection. Make the code clearer in intent. </p>



<p>It’s easy with refactoring to get wound around an axle and make too many changes and end up with broken things. Timeboxing is one technique I use to avoid, or at least minimize, my tendencies toward this when refactoring. If all I have is 30 minutes, I’ll make my changes smaller in scope.</p>



<p>A warning about refactoring. Don’t refactor what you don’t understand. Don’t drive by refactor. Discuss your plan with someone more familiar with the code; <code>git blame</code> is your friend. Especially if the code is not well tested, you want to make sure you don’t do more harm than good.</p>



<p><strong>Upgrade a dependency</strong></p>



<p>It’s sometimes a winding path, but upgrading your dependencies regularly is a good way to maintain the code. I remember working in a fork of struts. It was an important application for the company, but we didn’t spend the time upgrading the dependencies, because it was too painful. Eventually, parts of the code became harder to update. The entire application couldn’t benefit from newer technologies and paradigms because of the older dependencies holding it back. </p>



<p>It never feels good to spend time updating a dependency; to me this always feels like running in place. But if you don’t do so, eventually dependencies will end of life and you’ll be forced to update. That’ll be even less pleasant. </p>



<p>All of these actions not only help others because they improve the quality of the code, they also provide examples to other developers on how to do so. For example, it is far easier to write the second test in a suite than the first. You can cut and paste a lot of the setup code and tweak only what is different. The first bit of documentation will inspire more.</p>



<p>Code isn’t everything, but it is an important work output. Whenever you touch it, you should strive to leave it in a better place that it was before you did so.</p>



<p>Sincerely,</p>



<p>Dan</p>
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198597</guid>
            <pubDate>Tue, 24 Nov 2020 14:16:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Lisp Iteration]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198573">thread link</a>) | @wooby
<br/>
November 24, 2020 | https://tailrecursion.com/~alan/Lisp/CommonLispIteration.html | <a href="https://web.archive.org/web/*/https://tailrecursion.com/~alan/Lisp/CommonLispIteration.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p>
Created Monday 23 November 2020
</p>

<p>
Each of the following definitions of a <a href="https://en.wikipedia.org/wiki/Factorial" title="factorial">factorial</a> function demonstrate a way to <a href="https://en.wikipedia.org/wiki/Iteration#Computing" title="iterate">iterate</a> in <a href="https://en.wikipedia.org/wiki/Common_Lisp" title="Common Lisp">Common Lisp</a>, with brief notes. I hope that by demonstrating many different ways that the same thing can be written, you can develop a sense for the character of the constructs afforded by the language, and of the variety of possible styles. Common Lisp is famously syntactically extensible via <a href="https://en.wikipedia.org/wiki/Common_Lisp#Macros" title="macros">macros</a>, so keep in mind that my examples are by no means the <i>only</i> ways to iterate.
</p>

<p>
For further reading on the iteration and control structures of Common Lisp, I heartily recommend:
</p>

<ul>
<li><a href="http://www.gigamonkeys.com/book/macros-standard-control-constructs.html" title="Chapter 7">Chapter 7</a> and <a href="http://www.gigamonkeys.com/book/loop-for-black-belts.html" title="Chapter 22">Chapter 22</a> of <a href="https://amzn.to/3nOWKa2" title="Practical Common Lisp">Practical Common Lisp</a> by Peter Siebel.</li>
<li>A reasonably-priced used copy of <a href="https://amzn.to/2UUTfm3" title="ANSI Common Lisp">ANSI Common Lisp</a> by Paul Graham.</li>
</ul>


<p>
<i>Note: several of the examples return nonsensical results for negative inputs. The addition of <tt>(assert (not (minusp n)) </tt>or similar is a good idea, but I have omitted it here for clarity.</i>
</p>

<h2>DOTIMES</h2>

<pre>(defun factorial-dotimes (n &amp;aux (prod 1))
  (dotimes (i n prod)
    (setq prod (* prod (1+ i)))))
</pre>

<ul>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/03_dae.htm" title="&amp;aux lambda list keyword"><tt>&amp;aux</tt> lambda list keyword</a> names a local variable <tt>prod</tt>. <a href="http://www.lispworks.com/documentation/HyperSpec/Body/s_let_l.htm" title="LET"><tt>LET</tt></a> could also be used for this purpose, but at the cost of more indentation.</li>
<li><a href="http://www.lispworks.com/documentation/lw50/CLHS/Body/m_dotime.htm" title="DOTIMES"><tt>DOTIMES</tt></a> binds <tt>i</tt> successively from 0 to 1-n and finally evaluates to <tt>prod</tt>.</li>
</ul>


<h2>DO</h2>

<pre>(defun factorial-do (n)
  (do ((i 1 (1+ i))
       (prod 1 (* prod i)))
      ((&gt; i n) prod)))
</pre>

<ul>
<li><a href="http://www.lispworks.com/documentation/lw50/CLHS/Body/m_do_do.htm" title="DO"><tt>DO</tt></a> binds <tt>i</tt> to 1 and then to (1+ i) in subsequent iterations. <tt>prod</tt> is bound first to 1 and then to <tt>(* prod i)</tt> in subsequent iterations.</li>
<li>When the test clause <tt>(&gt; i n)</tt> becomes true, <tt>prod</tt> is returned. Contrast with the test clause of <tt>for</tt> loops in other languages, which terminate the loop when they become <i>false</i>.</li>
<li>I like the way Paul Graham explains <tt>DO </tt>and<tt> DO*</tt> in <a href="https://amzn.to/2UUTfm3" title="ANSI Common Lisp">ANSI Common Lisp</a>.</li>
</ul>


<h2>LOOP</h2>

<pre>(defun factorial-loop (n)
  (loop
     for i from 1 to n
     for prod = 1 then (* prod i)
     finally (return prod)))
</pre>

<ul>
<li><tt>i</tt> is bound from 1 to <tt>n</tt> inclusive.</li>
<li><tt>prod</tt> is bound to 1 and then <tt>(* prod i)</tt> in subsequent iterations in a manner similar to <tt>DO</tt>.</li>
<li>In the <tt>finally</tt> clause, <tt>prod</tt> is returned by <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/m_return.htm#return" title="RETURN"><tt>RETURN</tt></a> once iteration is complete. The <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/s_block.htm#block" title="BLOCK"><tt>BLOCK</tt></a> named NIL established by <tt>LOOP</tt> is the point of return.</li>
<li><a href="http://www.lispworks.com/documentation/lw50/CLHS/Body/m_loop.htm" title="LOOP"><tt>LOOP</tt></a> supports a comprehensive iteration and accumulation <a href="https://en.wikipedia.org/wiki/Domain-specific_language" title="DSL">DSL</a>. <a href="http://www.gigamonkeys.com/book/loop-for-black-belts.html" title="Chapter 22">Chapter 22</a> of <a href="https://amzn.to/3nOWKa2" title="Practical Common Lisp">Practical Common Lisp</a> offers a great introduction.</li>
</ul>


<h2>Recursion</h2>

<pre>(defun factorial-recursive (n)
  (if (zerop n)
      1
      (* n (factorial-recursive (1- n)))))
</pre>

<ul>
<li><tt>FACTORIAL-RECURSIVE</tt> calls itself, but when <tt>n</tt> exceeds the maximum stack size supported by the implementation, an error is signaled.</li>
</ul>


<pre>(defun factorial-tail-recursive (n)
  (labels ((recur (n prod)
             (if (zerop n)
                 prod
                 (recur (1- n) (* n prod)))))
    (recur n 1)))
</pre>

<ul>
<li><tt>FACTORIAL-TAIL-RECURSIVE </tt>does not call itself directly.</li>
<li>Instead, it defines with <a href="http://www.lispworks.com/documentation/HyperSpec/Body/s_flet_.htm" title="LABELS"><tt>LABELS</tt></a> an internal and recursive helper function, <tt>recur</tt>.</li>
<li>recur <a href="https://en.wikipedia.org/wiki/Tail_call" title="calls itself in tail position">calls itself in tail position</a> and the stack never overflows in implementations that implement tail-call elimination.</li>
</ul>


<h2>TAGBODY</h2>

<pre>(defun factorial-tagbody (n &amp;aux (i 0) (prod 1))
  (tagbody
     begin
     (when (eql i n)
       (return-from factorial-tagbody prod))
     (setq prod (* prod (incf i)))
     (go begin)))
</pre>

<ul>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/s_tagbod.htm" title="TAGBODY"><tt>TAGBODY</tt></a> is the most general but also the lowest-level and most verbose iteration construct.</li>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/03_dae.htm" title="&amp;aux lambda list keyword"><tt>&amp;aux</tt> lambda list keyword</a> names local variables <tt>i</tt> and <tt>prod</tt>, initializing them to 0 and 1, respectively.</li>
<li><tt>begin</tt> names a label within the <tt>TAGBODY</tt> that may be jumped to.</li>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/m_when_.htm" title="WHEN"><tt>WHEN</tt></a> <tt>i</tt> is <a href="http://www.lispworks.com/documentation/HyperSpec/Body/f_eql.htm" title="EQL"><tt>EQL</tt></a> to <tt>n</tt>, <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/s_ret_fr.htm" title="RETURN-FROM"><tt>RETURN-FROM</tt></a> returns <tt>prod</tt> from the <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/s_block.htm#block" title="BLOCK"><tt>BLOCK</tt></a> named after the function by <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/m_defun.htm" title="DEFUN"><tt>DEFUN</tt></a>.</li>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/s_go.htm" title="GO"><tt>GO</tt></a> jumps to <tt>begin</tt>.</li>
</ul>


</div></div>]]>
            </description>
            <link>https://tailrecursion.com/~alan/Lisp/CommonLispIteration.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198573</guid>
            <pubDate>Tue, 24 Nov 2020 14:14:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digitizing Old 8mm Tapes]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25198435">thread link</a>) | @todsacerdoti
<br/>
November 24, 2020 | https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/ | <a href="https://web.archive.org/web/*/https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-660">
	<!-- .entry-header -->

	<div>
		
		<p>It’s astounding to think back and consider how much technological progress has occurred in just the past 15 years. Most folks today carry a smartphone in their pocket everywhere they go, and a great many of those smartphones have powerful cameras built in capable of recording multiple hours in high definition. Pair this ability with low-cost video editing software—<a href="https://www.blackmagicdesign.com/products/davinciresolve/" rel="noopener noreferrer" target="_blank">some of which comes at no cost at all</a>—and far more people today have the tools to practice shooting, editing, compositing, and rendering professional-looking videos on a modest budget.</p>
<p>My personal experience with photography began around age 7 shooting on <a href="https://en.wikipedia.org/wiki/110_film" rel="noopener noreferrer" target="_blank">110 film</a> using a small “spy” camera I got as a gift. My dad’s <a href="https://www.sony.com/electronics/support/product/ccd-v5" rel="noopener noreferrer" target="_blank">Sony CCD-V5</a> was bulky, heavy, and probably expensive when he bought it around 1987, so he was reluctant to let me or my sister operate it under his supervision, let alone borrow it to make our own films by ourselves. As a consequence, my sister and I kept ourselves entertained by making audio recordings on much cheaper audio cassette hardware and tapes—we produced an episodic “radio show” starring our stuffed animals long before the podcast was invented. Though my sister and I took good care of our audio equipment, Dad stuck to his guns when it came to who got to use the camcorder, but he would sometimes indulge us when we had a full production planned, scripted, and rehearsed. <a href="https://en.wikipedia.org/wiki/8_mm_video_format#Video8" rel="noopener noreferrer" target="_blank">Video8</a> tapes were expensive, too, and for the most part Dad reserved their use for important events like concerts, school graduations, birthdays, and family holidays.</p>
<figure id="attachment_706" aria-describedby="caption-attachment-706"><img data-attachment-id="706" data-permalink="https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/ccd-v5/" data-orig-file="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?fit=528%2C390&amp;ssl=1" data-orig-size="528,390" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ccd-v5" data-image-description="" data-medium-file="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?fit=300%2C222&amp;ssl=1" data-large-file="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?fit=528%2C390&amp;ssl=1" loading="lazy" src="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?resize=528%2C390&amp;ssl=1" alt="Sony CCD-V5 camcorder" width="528" height="390" srcset="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?w=528&amp;ssl=1 528w, https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?resize=300%2C222&amp;ssl=1 300w, https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?resize=210%2C155&amp;ssl=1 210w" sizes="(max-width: 528px) 100vw, 528px" data-recalc-dims="1"><figcaption id="caption-attachment-706">I remember it being a lot bigger.</figcaption></figure>
<p>I went off to college and spent a <em>lot</em> of time lurking the <a href="https://originaltrilogy.com/" rel="noopener noreferrer" target="_blank">originaltrilogy.com forums</a>. It was here that not only did I learn a lot about the making and technical background of the Star Wars films (a topic I could blog about ad nauseum), but I also picked up a lot about video editing, codecs, post-production techniques, and preservation. OT.com was and still is home to a community of video hobbyists and professionals, most of whom share a common love for the <a href="https://starwarsviscomp.wordpress.com/" rel="noopener noreferrer" target="_blank">unreleased “original unaltered” versions</a> of the Star Wars trilogy. As such, many tips were/are shared as to how to produce the best “fan preservations” of Star Wars and other classic films given the materials available, sacrificing the least amount of quality.</p>
<p>I bought my dad a <a href="https://www.sony.com/electronics/support/product/hdr-cx100" rel="noopener noreferrer" target="_blank">Sony HDR-CX100</a> camcorder some years ago to supplement his by that time affinity for digital still cameras—he took it to Vienna and Salzburg soon after and has since transitioned to shooting digital video mostly on his iPhone. But the 8mm tapes chronicling my family’s milestones over the first 25 years of my life continued to sit, undisturbed, in my folks’ cool, dry basement. My dad has recordings on them going as far back as 1988 that I’ve found so far. These recordings are over 30 years old, so the tapes must be at least that age. </p>
<p>8mm video tape <a href="https://fstoppers.com/diy/unlocking-memories-8mm-tapes-324466" rel="noopener noreferrer" target="_blank">does not last forever</a>, but making analog copies of video tape incurs generational loss each time a copy is dubbed. On the other hand, a digital file can be copied as many times as one wants without any quality loss. All I need is the right capture hardware, appropriate capture software, enough digital storage, and a way to play back the source tapes, and I can preserve one lossless digital capture of each tape indefinitely. The last 8mm camcorder my dad bought—a <a href="https://www.sony.com/electronics/support/product/ccd-tr917" rel="noopener noreferrer" target="_blank">Sony CCD-TR917</a>—still has clean, working heads and can route playback of our existing library of tapes through its S-video and stereo RCA outputs. This provides me with the best possible quality given how they were originally shot.</p>
<hr>
<p>Generally with modern analog-to-digital preservation, you want to losslessly capture the raw source at a reasonably high sample rate with as little processing done to the source material as possible, from the moment it hits the playback heads to the instant it’s written to disk. Any cleanup can be done in post-production software; in fact, as digital restoration technology improves, it is ideal to have a raw, lossless original available to revisit with improved techniques. For this project, I am using my dad’s aforementioned <a href="https://www.sony.com/electronics/support/product/ccd-tr917" rel="noopener noreferrer" target="_blank">Sony CCD-TR917</a> camcorder attached directly to the S-video and stereo audio inputs of a <a href="https://web.archive.org/web/20150128124027/https://www.blackmagicdesign.com/products/intensity/models" rel="noopener noreferrer" target="_blank">Blackmagic Intensity Pro</a> PCIe card. The capturing PC is running Debian Linux and is plugged into the same circuit as the camcorder to avoid possible ground loop noise.</p>
<p>Since my Debian box is headless, I’m not interested in bringing up a full X installation just to grab some videos. Therefore I use the open source, command-line based <a href="https://github.com/lu-zero/bmdtools" rel="noopener noreferrer" target="_blank">bmdtools</a> suite—specifically bmdcapture—to do the raw captures from my Intensity Pro card. I do have to pull down the <a href="https://www.blackmagicdesign.com/developer/product/capture-and-playback" rel="noopener noreferrer" target="_blank">DeckLink SDK</a> in order to build bmdcapture, which does have some minor X-related dependencies, but I have to pull down the DeckLink software anyway for Linux drivers. I invoke the following from a shell before starting playback on the camcorder:</p>
<p><code>$ ./bmdcapture -C 0 -m 0 -M 4 -A 1 -V 6 -d 0 -n 230000 -f &lt;output&gt;.nut</code></p>
<p>The options passed to bmdcapture configure the capture as follows:</p>
<ul>
<li><code>-C 0</code>: Use the one Intensity Pro card I have installed (ID 0)</li>
<li><code>-m 0</code>: Capture using mode 0; that is, 525i59.94 NTSC, or 720×486 pixels at 29.97 FPS</li>
<li><code>-M 4</code>: Set a queue size of up to 4GB. Without this, bmdcapture can run out of memory before the entire tape is captured to disk.</li>
<li><code>-A 1</code>: Use the “Analog (RCA or XLR)” audio input. In my case, stereo RCA.</li>
<li><code>-V 6</code>: Use the “S-Video” video input. The S-video input on the Intensity Pro is provided as <a href="https://web.archive.org/web/20150122212738im_/https://images.blackmagicdesign.com/media/products/intensity/models/connections-intensitypro.png" rel="noopener noreferrer" target="_blank">an RCA pair</a> for chroma (“B-Y In”) and luma/sync (“Y In”); <a href="https://www.amazon.com/dp/B07K768YD1/" rel="noopener noreferrer" target="_blank">an adapter cable</a> is necessary to convert to the standard miniDIN-4 connector.</li>
<li><code>-d 0</code>: Fill in dropped frames with a black frame. The Sony CCD-TR917 has a built-in <a href="https://en.wikipedia.org/wiki/Time_base_correction" rel="noopener noreferrer" target="_blank">TBC</a> (which I leave enabled since I don’t own a separate TBC), but owing to the age of the tapes, there is an occasional frame drop.</li>
<li><code>-n 230000</code>: Capture 230000 frames. At 29.97 FPS, that’s almost 7675 seconds, which is a little over two hours. Should be enough even for full tapes.</li>
<li><code>-f &lt;output&gt;.nut</code>: Write to <code>&lt;output&gt;.nut</code> in the <a href="https://wiki.multimedia.cx/index.php/NUT" rel="noopener noreferrer" target="_blank">NUT container format</a> by default, substituting the tape’s label for <code>&lt;output&gt;</code>. The <a href="https://github.com/lu-zero/bmdtools/blob/master/README.md" rel="noopener noreferrer" target="_blank">README.md provided with bmdtools</a> suggests sticking with the default, and since FFmpeg has no trouble converting from NUT and I’ve had no trouble capturing to that format, I leave the output file format alone.</li>
</ul>
<p>Once I have my lossless capture, I compress the .nut file using bzip2, getting the file size down to up to a quarter of the original size depending on how much of the tape is filled. I then create parity data on the .bz2 archive <a href="https://en.wikipedia.org/wiki/Parchive" rel="noopener noreferrer" target="_blank">using the par2 utility</a>, and put my compressed capture and parity files somewhere safe for long-term archival storage. 🙂</p>
<p>My Windows-based Intel NUC is where I do most of my video post-production work. It lacks a PCIe slot, so I can’t capture there, but that’s fine because at this point my workflow is purely digital and I only have to worry about moving files around. My tools of choice here are AviSynth 2.6 and VirtualDub 1.10.4, but since AviSynth/VirtualDub are designed to work with AVI containers, I first convert my capture from the NUT container to the AVI container using FFmpeg:</p>
<p><code>$ ffmpeg.exe -i &lt;output&gt;.nut -vcodec copy -acodec copy &lt;output&gt;.avi</code></p>
<p>The options passed to FFmpeg are order-dependent and direct it to do the following:</p>
<ul>
<li><code>-i &lt;output&gt;.nut</code>: Use <code>&lt;output&gt;.nut</code> as the input file. FFmpeg is smart and will auto-detect its file format when opened.</li>
<li><code>-vcodec copy</code>: Copy the video stream from the input file’s container to the output file’s container; do not re-encode.</li>
<li><code>-acodec copy</code>: Likewise for the audio stream, copy from the input file’s container to the output file; do not re-encode.</li>
<li><code>&lt;output&gt;.avi</code>: Write to <code>&lt;output&gt;.avi</code>, again substituting my tape’s label for <code>&lt;output&gt;</code> in both the input and output filenames.</li>
</ul>
<div id=""><div>
<h2>A note about video containers vs. video formats</h2>
<p>Pop quiz! Given a file with the .mov extension, do you know for sure whether it will play in your media player?</p>
<p>Files ending with .mov, .avi, .mkv, and even the .nut format mentioned above are “container” files. When you save a digital video as a QuickTime .mov file, the .mov file is just a wrapper around your media, which must be encoded using one or more “codecs.” Codecs are small programs that can en<strong>co</strong>de and/or <strong>dec</strong>ode audio or video. These codecs must be specified at the same time as when you save your movie. QuickTime files can wrap among a great many codecs: Motion JPEG, MPEG, H.264, and Cinepak just to name a few. They’re a bit like Zip files, except that instead of files inside you have audio and/or video tracks, and there’s no compression other than what’s already done by the tracks’ codecs. Though Apple provides support in QuickTime for a number of modern codecs, older formats have been dropped over time and so any particular .mov file may or may not play… even using Apple’s own QuickTime software! Asking for a “QuickTime movie” is terribly vague—a QuickTime .mov file may not play properly on a given piece of hardware if support for a containing <em>codec</em> is missing.</p>
<p>AVI, MKV, and MP4 are containers, too—MP4 is in fact based on Apple’s own QuickTime format. But these are still just <em>containers</em>, and a movie file is nothing without some media inside that can be decoded. Put another way, when I buy a book I’m often offered the option of PDF, hardcover, or paperback form. But if the words contained therein are in Klingon, I still won’t be able to read it. When asked to provide a movie in QuickTime or AVI “format,” get the specifics—what codecs should be inside?</p></div></div>
<p>Now that I have an AVI source file, I can open it in VirtualDub. Owing to its namesake, VirtualDub’s interface is reminiscent of a dual cassette deck ready to “dub” from one container to another. It isn’t as user-friendly as, say, Premiere or Resolve when it comes to editing and compositing, but what it lacks in usability it gains in flexibility. In particular, VirtualDub is designed to run a designated range of source video through one or more “filters,” encoding to one of several output codecs available at …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/">https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/</a></em></p>]]>
            </description>
            <link>https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198435</guid>
            <pubDate>Tue, 24 Nov 2020 13:59:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gleam and Static Types with Louis Pilfold]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198388">thread link</a>) | @crowdhailer
<br/>
November 24, 2020 | https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/ | <a href="https://web.archive.org/web/*/https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="fl-main-content" itemprop="mainContentOfPage" role="main">

		
<div>
	<div>

		
		<div>
			<article id="fl-post-6124" itemscope="" itemtype="https://schema.org/BlogPosting">

	
	<header role="banner">
		
		<meta itemscope="" itemprop="mainEntityOfPage" itemtype="https://schema.org/WebPage" itemid="https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/" content="#023 Gleam and Static Types with Louis Pilfold"><meta itemprop="datePublished" content="2020-11-24"><meta itemprop="dateModified" content="2020-11-24"><div itemprop="publisher" itemscope="" itemtype="https://schema.org/Organization"><meta itemprop="name" content="Thinking Elixir"></div>	</header><!-- .fl-post-header -->

	
	
	<div itemprop="text">
		<p>
We talk with Louis Pilfold about how he created Gleam, a static typed language that runs on the BEAM. Louis explains some of the challenges with bringing static types to the BEAM and shares ideas on what can possibly be done about it. We learn how Gleam got started, how it works, and how Elixir and Erlang can interop with it. We cover the recently released Gleam OTP work, talk about Type Driven Development and much more!
</p>

<p>
  Show Notes online – <a href="https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold">https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold</a><br>
  
</p>
<p><strong>Elixir Community News</strong></p>

<ul>
<li><a href="http://devonestes.com/announcing_muzak" target="_blank" rel="noopener noreferrer">http://devonestes.com/announcing_muzak</a> – Devon Estes’ Muzak mutation testing library</li>
<li><a href="https://blog.appsignal.com/2020/11/17/announcing-appsignal-for-elixir-integration-2-0.html" target="_blank" rel="noopener noreferrer">https://blog.appsignal.com/2020/11/17/announcing-appsignal-for-elixir-integration-2-0.html</a> – AppSignal released 2.0 of their reporting tool</li>
<li><a href="https://github.com/phoenixframework/phoenix_live_view/pull/1223" target="_blank" rel="noopener noreferrer">https://github.com/phoenixframework/phoenix_live_view/pull/1223</a> – Phoenix LiveView file upload fix for components</li>
<li><a href="https://github.com/rrrene/credo" target="_blank" rel="noopener noreferrer">https://github.com/rrrene/credo</a> – Happy 5th birthday Credo!</li>
<li><a href="https://elixir-lang.org/blog/2020/11/17/real-time-collaboration-with-elixir-at-slab/" target="_blank" rel="noopener noreferrer">https://elixir-lang.org/blog/2020/11/17/real-time-collaboration-with-elixir-at-slab/</a> – New Elixir case-study looks at the collaborative wiki product Slab</li>
<li><a href="https://github.com/teamon/tesla/releases/tag/v1.4.0" target="_blank" rel="noopener noreferrer">https://github.com/teamon/tesla/releases/tag/v1.4.0</a> – Tesla v1.4.0 released – an Elixir HTTP client</li>
<li><a href="https://elixirforum.com/t/introducing-elixirls-the-elixir-language-server/5857/119" target="_blank" rel="noopener noreferrer">https://elixirforum.com/t/introducing-elixirls-the-elixir-language-server/5857/119</a> – ElixirLS version 0.6.2 released.</li>
<li><a href="https://dashbit.co/blog/you-may-not-need-redis-with-elixir" target="_blank" rel="noopener noreferrer">https://dashbit.co/blog/you-may-not-need-redis-with-elixir</a> – Jose Valim wrote a blog post addressing the idea of people saying “you don’t need Redis when you use Elixir”.</li>
<li><a href="https://baremessages.org/" target="_blank" rel="noopener noreferrer">https://baremessages.org/</a> – A new “binary serialization library” called “bare”. Aims to make Erlang data structures serialize easier in <em>other</em> languages</li>
<li><a href="https://sr.ht/~hauleth/BARE-Erlang/" target="_blank" rel="noopener noreferrer">https://sr.ht/~hauleth/BARE-Erlang/</a></li>
</ul>
<p>Do you know some Elixir news we don’t? Tell us at <a href="https://twitter.com/ThinkingElixir">@ThinkingElixir</a></p>
<p><strong>Discussion Resources</strong></p>

<ul>
<li><a href="https://github.com/gleam-lang/gleam" target="_blank" rel="noopener noreferrer">https://github.com/gleam-lang/gleam</a></li>
<li><a href="https://gleam.run/" target="_blank" rel="noopener noreferrer">https://gleam.run/</a></li>
<li><a href="https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/" target="_blank" rel="noopener noreferrer">https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/</a></li>
<li><a href="https://thinkingelixir.com/podcast-episodes/016-gleam-games-and-types-with-quinn-wilton/" target="_blank" rel="noopener noreferrer">https://thinkingelixir.com/podcast-episodes/016-gleam-games-and-types-with-quinn-wilton/</a></li>
<li><a href="https://github.com/gleam-lang/gleam/graphs/contributors" target="_blank" rel="noopener noreferrer">https://github.com/gleam-lang/gleam/graphs/contributors</a></li>
<li><a href="https://www.embark-studios.com/" target="_blank" rel="noopener noreferrer">https://www.embark-studios.com/</a></li>
<li><a href="https://racket-lang.org/" target="_blank" rel="noopener noreferrer">https://racket-lang.org/</a></li>
<li><a href="https://akka.io/" target="_blank" rel="noopener noreferrer">https://akka.io/</a></li>
<li><a href="https://developers.google.com/protocol-buffers/" target="_blank" rel="noopener noreferrer">https://developers.google.com/protocol-buffers/</a></li>
<li><a href="https://github.com/lalrpop/lalrpop" target="_blank" rel="noopener noreferrer">https://github.com/lalrpop/lalrpop</a></li>
<li><a href="http://www.elixir.london/2016/louis-pilfold" target="_blank" rel="noopener noreferrer">http://www.elixir.london/2016/louis-pilfold</a></li>
<li><a href="https://www.youtube.com/watch?v=IONWi9hayEA&amp;index=13&amp;list=PLWbHc_FXPo2ivlIjzcaHS9N_Swe_0hWj0" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=IONWi9hayEA&amp;index=13&amp;list=PLWbHc_FXPo2ivlIjzcaHS9N_Swe_0hWj0</a></li>
<li><a href="https://gleam.run/community/" target="_blank" rel="noopener noreferrer">https://gleam.run/community/</a> – Join the Gleam Discord server</li>
<li><a href="https://twitter.com/louispilfold" target="_blank" rel="noopener noreferrer">https://twitter.com/louispilfold</a> – on Twitter</li>
<li><a href="https://github.com/lpil/" target="_blank" rel="noopener noreferrer">https://github.com/lpil/</a> – on Github</li>
<li><a href="https://lpil.uk/" target="_blank" rel="noopener noreferrer">https://lpil.uk</a> – Blog</li>
</ul>
<p><strong>Find us online</strong></p>
<ul>
<li>Message the show – <a href="https://twitter.com/ThinkingElixir" target="_blank" rel="noopener noreferrer">@ThinkingElixir</a></li>
<li>Mark Ericksen – <a href="https://twitter.com/brainlid" target="_blank" rel="noopener noreferrer">@brainlid</a></li>
<li>David Bernheisel – <a href="https://twitter.com/bernheisel" target="_blank" rel="noopener noreferrer">@bernheisel</a></li>
<li>Cade Ward – <a href="https://github.com/cadebward" target="_blank" rel="noopener noreferrer">Github</a></li>
</ul>
<div itemscope="" itemtype="http://schema.org/AudioObject"><meta itemprop="name" content="#023 Gleam and Static Types with Louis Pilfold"><meta itemprop="uploadDate" content="2020-11-24T04:15:45-07:00"><meta itemprop="encodingFormat" content="audio/mpeg"><meta itemprop="duration" content="PT48M57S"><meta itemprop="description" content="We talk with Louis Pilfold about how he created Gleam, a static typed language that runs on the BEAM. Louis explains some of the challenges with bringing static types to the BEAM and shares ideas on what can possibly be done about it. We learn how Gleam got started, how it works, and how Elixir and Erlang can interop with it. We cover the recently released Gleam OTP work, talk about Type Driven Development and much more!



Show Notes online - https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold"><meta itemprop="contentUrl" content="https://media.blubrry.com/thinkingelixir/s/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3"><meta itemprop="contentSize" content="67.4"><div id="powerpress_player_9920"><!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
<p><audio id="audio-6124-1" preload="none" controls="controls"><source type="audio/mpeg" src="https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3?_=1"><a href="https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3">https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3</a></audio></p></div></div><p>Podcast: <a href="https://media.blubrry.com/thinkingelixir/s/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3" title="Download" rel="nofollow" download="023-gleam-louis-pilfold.mp3">Download</a></p>	</div><!-- .fl-post-content -->

	
	<div></div>		
</article>


<!-- .fl-post -->
		</div>

		
	</div>
</div>


	</div></div>]]>
            </description>
            <link>https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198388</guid>
            <pubDate>Tue, 24 Nov 2020 13:52:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Htmx 1.0.0 Release]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25198287">thread link</a>) | @crbelaus
<br/>
November 24, 2020 | https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/ | <a href="https://web.archive.org/web/*/https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>htmx 1.0.0 Release</h2>
<p>I'm happy to announce the <a href="https://unpkg.com/browse/htmx.org@1.0.0/">1.0.0 release</a> of htmx.</p>
<p>htmx is now mature enough that I can recommend it as a general replacement for intercooler.js
projects.  I <strong>don't</strong> think there is a strong reason to port an existing intercooler project to
htmx.  I have several large intercooler apps and will not be moving them over any time soon. I can, however, recommend using htmx over intercooler for new projects.</p>
<p>htmx is a different sort of javascript library.  It is an HTML &amp; hypertext-oriented reply to the current dominance of javascript-based SPA libraries.  It is a response to Tom MacWright's question:
<a href="https://macwright.com/2020/10/28/if-not-spas.html">"If not SPAs, What?"</a>.</p>
<p>As the <a href="https://htmx.org/">homepage says</a>:</p>
<ul>
<li>Why should only <code>&lt;a&gt;</code> and <code>&lt;form&gt;</code> be able to make HTTP requests?</li>
<li>Why should only <code>click</code> &amp; <code>submit</code> events trigger them?</li>
<li>Why should only GET &amp; POST be available?</li>
<li>Why should you only be able to replace the entire screen?</li>
</ul>
<p>HTML-oriented web development was abandoned not because hypertext was a bad idea, but rather because HTML didn't have sufficient expressive power.  htmx aims to fix that &amp; allows you to implement <a href="https://htmx.org/examples/">many common modern web UI patterns</a> using the original hypertext model of the web.</p>
<h3>History &amp; Thanks</h3>
<p>htmx began life as <a href="https://intercoolerjs.org/">intercooler.js</a> back in <a href="https://github.com/bigskysoftware/intercooler-js/commit/62d3dbdb5c056ee866aba3575e148de649fc3efe">2013</a>.</p>
<p>In <a href="https://github.com/bigskysoftware/htmx/commit/e38dea64dd1065003a0e833d7b469d24e6bc2919">april</a> of this year I began work on a jQuery-indepenent &amp; improved version of intercoolerjs, renamed
to htmx.  I chose to rename the library because, in working on intercooler, I had come to appreciate that intercooler &amp; htmx were completing HTML as a hypertext rather than just some funky, idiosyncratic javascript libraries.</p>
<p>In <a href="https://github.com/bigskysoftware/htmx/releases/tag/v0.0.1">May</a> htmx reached 0.0.1.  Soon thereafter I had the good fortune of being contacted by <a href="https://twitter.com/ben_pylo">Ben Croker</a>
who was interested in htmx as a base for his new reactive library, <a href="https://putyourlightson.com/plugins/sprig">Sprig</a>.  Ben was willing to be an early adopter of htmx and pushed the library along
much faster than it would have gone otherwise.</p>
<p>I have been very lucky to the have help and feedback from many contributors in <a href="https://github.com/bigskysoftware/htmx/graphs/contributors">Github</a> and on <a href="https://htmx.org/discord">Discord</a>.  I'd like to thank, in particular, <a href="https://github.com/benpate">Ben Pate</a>, <a href="https://github.com/rschroll">Robert Schroll</a> &amp; <a href="https://github.com/jreviews">Alejandro Schmeichler</a> for contributing code as well as new ideas and discussions.</p>
<p>I would like to thank <a href="https://devmode.fm/">Devmode.fm</a> for having me on to <a href="https://devmode.fm/episodes/dynamic-html-with-htmx">talk about htmx</a> and for cleaning up all my "uhhs" and "umms".</p>
<p>Finally, I would like to thank <a href="https://github.com/jsampson">Justin Sampson</a>, who took a lot of time to explain REST &amp; HATEOAS to me and how intercooler (and now htmx) fit into that model for web development.</p>
<h3>Changes</h3>
<ul>
<li>I bumped the version number :)</li>
</ul>
<p>Enjoy!</p>

</div></div>]]>
            </description>
            <link>https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198287</guid>
            <pubDate>Tue, 24 Nov 2020 13:38:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use Reddit to get your first users]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 131 (<a href="https://news.ycombinator.com/item?id=25198280">thread link</a>) | @xavier_
<br/>
November 24, 2020 | https://blog.spreadtheworld.net/posts/get-first-users-reddit/ | <a href="https://web.archive.org/web/*/https://blog.spreadtheworld.net/posts/get-first-users-reddit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As an indie hacker, we all struggle to validate our ideas, get our first users, and get some traffic. I played a lot with <a href="https://www.reddit.com/user/xAvi_r">Reddit</a> for the last few months, and I can tell you: it’s a gold mine!</p><p>Reddit is super powerful:&nbsp;there are millions of users on the platform, each subreddit is very segmented by niche, and it’s free to use!</p><p>We sometimes see it as an intimidating platform, but it’s not that hard.</p><p>Here is how I&nbsp;use it:</p><h2 id="validate-your-idea">Validate your idea</h2><p>The first step of your indie hacker journey is to validate your idea. You don’t want to spend weeks building something nobody wants. But it can be hard to find your potential customers to validate your product idea.</p><p>With Reddit, you can do it easily. There are subreddits dedicated to Ideas’ feedback. You can post your idea there and you will get some responses within 24hrs. The feedback can be pretty generic as the people in these subs are mostly entrepreneurs and not your potential customer.</p><p>To validate my product idea I prefer to post directly on the sub I&nbsp;want to target. Let’s say you create a tool for developers then I’d post to /r/webdev. You don’t need to have a working MVP, just make some screenshot (or a video) and ask for feedback. Or, even better show them a landing page with a pre-order button or an email form and wait for their reactions.</p><p><em>(For the idea validation step, don’t be afraid to post on a big subreddit with hundreds of thousands of users, the more people see your idea the stronger your validation will be)</em></p><p>Within 24hrs you’ll know if that idea is worth pushing! If you get positive feedback - or even pre-orders - you can build your MVP. If you’re ignored or trashed, then find another way or get another idea!</p><h2 id="get-your-first-users">Get your first users</h2><p>Once your MVP is ready you need a bunch of beta testers to give you some feedback.
Reddit can also help you with that.</p><p>But this time I’d go with a small subreddit, and a super targeted one. Let’s say you created a no-code tool for startups, I’ll try to get my early adopters from /r/nocode (3.7k members) instead of posting on /r/startups (517k members) for instance. It’s a small subreddit, very niche. Then, once you have the first feedback you can iterate on it and post on some bigger subs.</p><p>The idea of “incremental launches” is to start small, build an audience, get some feedback, and grow step by step. Once the super-targeted subreddit loves your product you can start to post on big subreddit and get some traction.</p><p><em>PS: Small subreddit are super powerful if you choose them wisely. I got more than <a href="https://twitter.com/AngeZanetti/status/1325847913466048516">400 visits</a> in 48hrs from my last post on /r/nocode!</em></p><h2 id="get-some-traffic">Get some traffic</h2><p>Last step of the process: your MVP is ready, you need some traffic. And you want a lot of it!</p><p>The strategy here is to create some content around your product and share it with big subreddits. The secret is to provide as much value as you can. Share your secrets, how you grow your product, share your analytics, how much money you make, what did you learn during your journey, etc… It needs to be valuable and targeted to an audience.</p><p>Post your content to the biggest subreddits like /r/Entrepreneur, /r/Programming, or /r/Marketing and add a link to your product/blog at the end (Check the rules of the sub first, but most of them are ok with it)</p><p>If your content is well-targeted and brings some serious value you can get thousands of visitors in a day! And it’s totally repeatable. As long as you can provide value you’ll get some free traffic!</p><p>Do you want to launch on Reddit? DM me on Twitter, I’ll be happy to help → <a href="https://twitter.com/angezanetti">Twitter</a></p></div></div>]]>
            </description>
            <link>https://blog.spreadtheworld.net/posts/get-first-users-reddit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198280</guid>
            <pubDate>Tue, 24 Nov 2020 13:36:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EC2 Origin]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198157">thread link</a>) | @ashishsheth
<br/>
November 24, 2020 | http://blog.b3k.us/2009/01/25/ec2-origins.html | <a href="https://web.archive.org/web/*/http://blog.b3k.us/2009/01/25/ec2-origins.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>I was trying to avoid writing this post and had succeeded at that goal for almost 2 years. After some recent exchanges, I see the wisest move is the opposite. so, here goes.</p>
<p>In 2003 I was working at Amazon for the best manager I’ve ever had, Chris Pinkham. Chris had hired me the previous year as a network engineer, quickly promoting me to manager for the (ridiculously awesome) team. Chris was always pushing me to change the infrastructure, especially driving better abstraction and uniformity, essential for efficiently scaling. He wanted an all IP network instead of the mess of VLANs Amazon had at the time, so we designed it, built it, and worked with developers so their applications would work with it. He wanted anycast <span>DNS</span>, so we hacked up some routing software and put it out there (great idea at the time, but in hindsight we probably should’ve taken a different approach). Chris asked for something, we figured out how, and did it.</p>
<p>Sorry for the digression, back to what I was saying about 2003: Chris and I wrote a short paper describing a vision for Amazon infrastructure that was completely standardized, completely automated, and relied extensively on web services for things like storage. We drew on the work of a number of other folks internally who had been thinking and writing (and sometimes even coding) in the storage services space, and we combined it with our own thinking and experience in infrastructure. Near the end of it, we mentioned the possibility of selling virtual servers as a service.</p>
<p>We presented the paper to Bezos (he doesn’t do slides), he liked a lot of it, and we went back to work.</p>
<p>A few months later, in early 2004, I was told Jeff was interested in the virtual server as a service idea and asked for a more detailed write up of it. This I did, also incorporating a couple of requests Jeff had, like the idea of a “universe” of virtuals, which I translated into network-speak as a distributed firewall to isolate groups of servers. This first cut at it looked almost nothing like the production EC2 service, and, in my view, every change made by the team who built EC2 was for the better. As just one example, that first paper called for a system manifest from which a server would be built. This is similar to how much systems automation works, but is actually terrible for the sort of dynamism desired for EC2.</p>
<p>After presenting the “executive brief” paper to Jeff, the realities of turning this hare-brained scheme into a real service meant involving the smartest folks around (i.e., not me). In the Amazon style of “starting from the customer and working backwards”, we produced a “press release” and a <span>FAQ</span> to further detail the how and why of what would become EC2. At this point attention turned from these paper pushing exercises to specifics of getting it built. Most importantly, who would lead the effort?</p>
<p>Everyone seemed to leap at once to the same conclusion: Pinkham. And so it was that Pinkham returned to South Africa, taking a stellar lead developer with him, and they built the EC2 team, then built EC2. That last part seems awfully compressed, doesn’t it? Well, that’s because I had almost no interaction with the EC2 team. They went off and kicked a lot of ass and the rest is history.</p>
<p>The end.</p>
<p>Want more data? Here’s Jeff in a 2008 interview with Om Malik…</p>

<time datetime="2009-01-25">
  —Jan 25, 2009
</time>
</article></div>]]>
            </description>
            <link>http://blog.b3k.us/2009/01/25/ec2-origins.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198157</guid>
            <pubDate>Tue, 24 Nov 2020 13:18:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An opinionated list of best practices for textual websites]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197950">thread link</a>) | @kkoncevicius
<br/>
November 24, 2020 | https://seirdy.one/2020/11/23/website-best-practices.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2020/11/23/website-best-practices.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<p><em>The following applies to minimal websites that focus primarily on text. It does not
apply to websites that have a lot of non-textual content. It also does not apply to
websites that focus more on generating revenue or pleasing investors than being good
websites.</em></p>
<p>This is a “living document” that I add to as I receive feedback. See the
<a href="https://git.sr.ht/~seirdy/seirdy.one/log/master/content/posts/website-best-practices.md">changelog</a>.</p>
<p>I realize not everybody’s going to ditch the Web and switch to Gemini or Gopher today
(that’ll take, like, a month at the longest). Until that happens, here’s a
non-exhaustive, highly-opinionated list of best practices for websites that focus
primarily on text:</p>
<ul>
<li>Final page weight under 50kb without images, and under 200kb with images.</li>
<li>Works in Lynx, w3m, links (both graphics and text mode), Netsurf, and Dillo</li>
<li>Works with popular article-extractors (e.g.&nbsp;Readability) and HTML-to-Markdown
converters. This is a good way to verify that your site uses simple HTML and works
with most non-browser article readers (e.g.&nbsp;ebook converters, PDF exports).</li>
<li>No scripts or interactivity (preferably enforced at the CSP level)</li>
<li>No cookies</li>
<li>No animations</li>
<li>No fonts–local or remote–besides <code>sans-serif</code> and <code>monospace</code>. More on this
below.</li>
<li>No referrers</li>
<li>No requests after the page finishes loading</li>
<li>No 3rd-party resources (preferably enforced at the CSP level)</li>
<li>No lazy loading (more on this below)</li>
<li>No custom colors OR explicitly set the both foreground and background colors. More
on this below.</li>
<li>A maximum line length for readability</li>
<li>Server configured to support compression (gzip, optionally zstd as well). It’s a
free speed boost.</li>
<li>Supports dark mode via a CSS media feature and/or works with most “dark mode”
browser addons. More on this below.</li>
<li>A good score on Mozilla’s <a href="https://observatory.mozilla.org/">HTTP Observatory</a></li>
<li>Optimized images.</li>
<li>Maybe HTTP/2. There are some cases in which HTTP/2 can make things slower. Run some
tests to find out.</li>
</ul>
<p>I’d like to re-iterate yet another time that this only applies to websites that
primarily focus on text. If graphics, interactivity, etc. are an important part of
your website, less (possibly none) of this article applies.</p>
<p>Earlier revisions of this post generated some responses I thought I should address
below. Special thanks to the IRC and <a href="https://lobste.rs/s/akcw1m">Lobsters</a> users who
gave good feedback!</p>
<h2 id="about-fonts">About fonts</h2>
<p>If you <em>really</em> want, you could use <code>serif</code> instead of <code>sans-serif</code>, but serif fonts
tend to look worse on low-res monitors. Not every screen’s DPI has three digits.</p>
<p>To ship custom fonts is to assert that branding is more important than user choice.
That might very well be a reasonable thing to do; branding isn’t evil! It isn’t
<em>usually</em> the case for textual websites, though. Beyond basic layout and optionally
supporting dark mode, authors generally shouldn’t dictate the presentation of their
websites; that is the job of the user agent. Most websites are not important enough
to look completely different from the rest of the user’s system.</p>
<p>A personal example: I set my preferred fonts in my computer’s fontconfig settings.
Now every website that uses <code>sans-serif</code> will have my preferred font. Sites with
<code>sans-serif</code> blend into the users' systems instead of sticking out.</p>
<h3 id="but-most-users-dont-change-their-fonts">But most users don’t change their fonts…</h3>
<p>The “users don’t know better and need us to make decisions for them” mindset isn’t
without merits; however, in my opinion, it’s overused. Using system fonts doesn’t
make your website harder to use, but it does make it smaller and stick out less to
the subset of users who care enough about fonts to change them. This argument isn’t
about making software easier for non-technical users; it’s about branding by
asserting a personal preference.</p>
<h3 id="cant-users-globally-override-stylesheets-instead">Can’t users globally override stylesheets instead?</h3>
<p>It’s not a good idea to require users to automatically override website stylesheets.
Doing so would break websites that use fonts such as Font Awesome to display vector
icons. We shouldn’t have these users constantly battle with websites the same way
that many adblocking/script-blocking users (myself included) already do when there’s
a better option.</p>
<p>That being said, many users <em>do</em> actually override stylesheets. We shouldn’t
<em>require</em> them to do so, but we should keep our pages from breaking in case they do.
Pages following this article’s advice will probably work perfectly well in these
cases without any extra effort.</p>
<h3 id="but-wouldnt-that-allow-a-website-to-fingerprint-with-fonts">But wouldn’t that allow a website to fingerprint with fonts?</h3>
<p>I don’t know much about fingerprinting, except that you can’t do font enumeration
without JavaScript. Since text-based websites that follow these best-practices don’t
send requests after the page loads and have no scripts, fingerprinting via font
enumeration is a non-issue on those sites.</p>
<p>Other websites can still fingerprint via font enumeration using JavaScript. They
don’t need to stop at seeing what sans-serif maps to; they can see all the available
fonts on a user’s system, the user’s canvas fingerprint, window dimensions, etc. Some
of these can be mitigated with Firefox’s <code>privacy.resistFingerprinting</code> setting, but
that setting also understandably overrides user font preferences.</p>
<p>Ultimately, surveillance self-defense on the web is an arms race full of trade-offs.
If you want both privacy and customizability, the web is not the place to look; try
Gemini or Gopher instead.</p>
<h2 id="about-lazy-loading">About lazy loading</h2>
<p>For users on slow connections, lazy loading is often frustrating. I think I can speak
for some of these users: mobile data near my home has a number of “dead zones” with
abysmal download speeds, and my home’s Wi-Fi repeater setup occasionally results in
packet loss rates above 60% (!!).</p>
<p>Users on poor connections have better things to do than idly wait for pages to load.
They might open multiple links in background tabs to wait for them all to load at
once, or switch to another window/app and come back when loading finishes. They might
also open links while on a good connection before switching to a poor connection; I
know that I often open 10-20 links on Wi-Fi before going out for a walk in a
mobile-data dead-zone.</p>
<p>Unfortunately, pages with lazy loading don’t finish loading off-screen images in the
background. To load this content ahead of time, users need to switch to the loading
page and slowly scroll to the bottom to ensure that all the important content appears
on-screen and starts loading. Website owners shouldn’t expect users to have to jump
through these ridiculous hoops.</p>
<h3 id="wouldnt-this-be-solved-by-combining-lazy-loading-with-pre-loadingpre-fetching">Wouldn’t this be solved by combining lazy loading with pre-loading/pre-fetching?</h3>
<p>A large number of users with poor connections also have capped data, and would prefer
that pages don’t decide to predictively load content ahead-of-time for them. Some go
so far as to disable this behavior to avoid data overages. Savvy privacy-conscious
users also generally disable pre-loading because they don’t have reason to trust that
linked content doesn’t practice dark patterns like tracking without consent.</p>
<p>Users who click a link <em>choose</em> to load a full page. Loading pages that a user hasn’t
clicked on is making a choice for that user.</p>
<h3 id="cant-users-on-poor-connections-disable-images">Can’t users on poor connections disable images?</h3>
<p>I have two responses:</p>
<ol>
<li>If an image isn’t essential, you shouldn’t include it inline.</li>
<li>Yes, users could disable images. That’s <em>their</em> choice. If your page uses lazy
loading, you’ve effectively (and probably unintentionally) made that choice for a
large number of users.</li>
</ol>
<h2 id="about-custom-colors">About custom colors</h2>
<p>Some users' browsers set default page colors that aren’t black-on-white. For
instance, Linux users who enable GTK style overrides might default to having white
text on a dark background. Websites that explicitly set foreground colors but leave
the default background color (or vice-versa) end up being difficult to read. Here’s
an example:</p>
<picture>
<source srcset="https://seirdy.one/misc/website_colors.webp" type="image/webp">
<img src="https://seirdy.one/misc/website_colors.png" alt="This page with a grey background, a header with unreadable black/grey text, and unreadable white-on-white code snippets">
</picture>
<p>If you do explicitly set colors, please also include a dark theme using a media
query: <code>@media (prefers-color-scheme: dark)</code>. For more info, read the relevant docs
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme">on
MDN</a></p>
<h2 id="image-optimization">Image optimization</h2>
<p>Some image optimization tools I use:</p>
<ul>
<li><a href="http://pngquant.org/">pngquant</a> (lossy)</li>
<li><a href="https://github.com/shssoichiro/oxipng">Oxipng</a> (lossless)</li>
<li><a href="https://github.com/tjko/jpegoptim">jpegoptim</a> (lossless or lossy)</li>
<li><a href="https://developers.google.com/speed/webp/docs/cwebp">cwebp</a> (lossless or lossy)</li>
</ul>
<p>I put together a <a href="https://git.sr.ht/~seirdy/dotfiles/tree/3b722a843f3945a1bdf98672e09786f0213ec6f6/Executables/shell-scripts/bin/optimize-image">quick
script</a>
to losslessly optimize images using these programs in my dotfile repo.</p>
<p>You also might want to use the HTML <code>&lt;picture&gt;</code> element, using JPEG/PNG as a fallback
for more efficient formats such as WebP or AVIF. More info in the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture">MDN
docs</a></p>
<p>Most of my images will probably be screenshots that start as PNGs. My typical flow:</p>
<ol>
<li>Lossy compression with <code>pngquant</code></li>
<li>Losslessly optimize the result with <code>oxipng</code> and its Zopfli backend (slow)</li>
<li>Also create a lossless WebP from the lossy PNG, using <code>cwebp</code></li>
<li>Include the resulting WebP in the page, with a fallback to the PNG using a <code>&lt;picture&gt;</code> element.</li>
</ol>
<p>It might seem odd to create a lossless WebP from a lossy PNG, but I’ve found that it’s the best way to get the smallest possible image at the minimum acceptable quality for screenshots with solid backgrounds.</p>
<h2 id="other-places-to-check-out">Other places to check out</h2>
<p>The <a href="https://250kb.club/">250kb club</a> gathers websites at or under 250kb, and also
rewards websites that have a high ratio of content size to total size.</p>
<p>Also see <a href="https://motherfuckingwebsite.com/">Motherfucking Website</a>. Motherfucking
Website inspired several unofficial sequels that tried to gently improve upon it. My
favorite is <a href="https://bestmotherfucking.website/">Best Motherfucking Website</a>.</p>
</article></div>]]>
            </description>
            <link>https://seirdy.one/2020/11/23/website-best-practices.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197950</guid>
            <pubDate>Tue, 24 Nov 2020 12:46:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The German Elon of the 70s]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197941">thread link</a>) | @revolucien
<br/>
November 24, 2020 | https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s | <a href="https://web.archive.org/web/*/https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5f18775b30d9fd6c1ed21e6a" data-item-id="5f18775b30d9fd6c1ed21e6a">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1595439165510" id="item-5f18775b30d9fd6c1ed21e6a"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1595439201816_6409"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1595439277525-N1KY1FTDNW9EB1P2KT6U/ke17ZwdGBToddI8pDm48kKtijf5x5S0rIV7X_qDH3dB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaZbTVdO5VSPAOxIcVIbmIFLIFeVDbQiz7iBIgNCzklBDD2o6CESiqIlH5ssNFrtmA/Lutz_Kayser.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1595439277525-N1KY1FTDNW9EB1P2KT6U/ke17ZwdGBToddI8pDm48kKtijf5x5S0rIV7X_qDH3dB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaZbTVdO5VSPAOxIcVIbmIFLIFeVDbQiz7iBIgNCzklBDD2o6CESiqIlH5ssNFrtmA/Lutz_Kayser.jpg" data-image-dimensions="2400x1600" data-image-focal-point="0.5,0.5" alt="Meet Lutz Kayser, the pioneering rocket engineer and founder of OTRAG  (Source:    OTRAG   )" data-load="false" data-image-id="5f18789af192c5616c553b96" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1595439277525-N1KY1FTDNW9EB1P2KT6U/ke17ZwdGBToddI8pDm48kKtijf5x5S0rIV7X_qDH3dB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaZbTVdO5VSPAOxIcVIbmIFLIFeVDbQiz7iBIgNCzklBDD2o6CESiqIlH5ssNFrtmA/Lutz_Kayser.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Meet Lutz Kayser, the pioneering rocket engineer and founder of OTRAG<em> (Source: </em><a href="http://otrag.com/" target="_blank"><em>OTRAG</em></a><em>)</em></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-1f175e5db5ee82782e37"><div><p>It’s 1977 and you’re standing on a rocky plateau overlooking the dense jungle of Zaire in what is now modern-day Congo. You and a group of maverick engineers work for OTRAG, a West German rocket startup that is sponsored by Zaire’s dictator, Mobutu Sese Seko. After many months of toil in the African bushland, you’re ready to launch the world’s first privately developed rocket booster––a 9-meter (30 ft) tall juggernaut which, from a distance, looks like a bundle of aluminum pencils with a nose cone. The countdown proceeds smoothly. Then finally, there’s liftoff: The rocket leaves the launch pad with a deafening roar and climbs to an altitude of 12 km (7.5 miles) before plummeting back to Earth. The plateau erupts in jubilation.</p><p>Wait, what? This unlikely scene from the jungle might sound crazy to you. A private rocket company from West Germany that is attempting to make it into space in the late seventies? That’s more than three decades before Elon Musk’s <a href="https://en.wikipedia.org/wiki/SpaceX" target="_blank">SpaceX</a> successfully launched its first rocket, the <a href="https://www.youtube.com/watch?v=dLQ2tZEH6G0" target="_blank">Falcon 1</a>, into orbit. But this incredible and long-forgotten tale is entirely true and forms the plot of the documentary<em> </em><a href="https://vimeo.com/300738920" target="_blank"><em>Fly Rocket Fly</em></a><em>, </em>which premiered at the Munich Film Festival in 2018. The film is now available to stream on <a href="https://www.amazon.com/Fly-Rocket-Lutz-Keyser/dp/B082H4WJJG" target="_blank">Amazon Prime</a> and <a href="https://vimeo.com/ondemand/flyrocketfly" target="_blank">Vimeo</a>.</p><p>The rise and fall of OTRAG is one of the strangest, and most remarkable, startup tales I’ve encountered to date. It’s an almost surreal story of entrepreneurial adventure and ambition that bears an astonishing resemblance to Werner Herzog’s<em> </em><a href="https://en.wikipedia.org/wiki/Fitzcarraldo" target="_blank"><em>Fitzcarraldo</em></a><em>. </em>In Herzog’s 1982 movie, Klaus Kinski plays an obsessive dreamer who manually drags his massive steamship over a steep hill in the Amazon jungle. Unfortunately for Fitzcarraldo, this astonishing engineering feat doesn’t translate into his mission’s overall success (Herzog later went so far as to call it a “<a href="https://www.nytimes.com/2009/08/02/books/review/Harris-t.html" target="_blank">conquest of the useless</a>”). The same could be said about OTRAG. Despite a number of successful test launches, OTRAG was a spectacular failure. The company burned through massive amounts of funding and eventually ran afoul of Cold War politics. Its demise is a case study in what happens to startups when their timing is wrong, their technology speculative, and their market unwilling to embrace disruptive innovation.</p><h3><strong>The Emperor of OTRAG</strong></h3><p>All startups are a reflection of their founders. The man behind the rocket-building adventure in the jungle was Lutz Kayser, a German aerospace engineer who was something of a 20th-century Elon Musk. Kayser began pursuing his dream of a low-cost rocket launcher in the 1960s. As a student of rocket pioneer <a href="https://en.wikipedia.org/wiki/Eugen_S%C3%A4nger" target="_blank">Eugen Sänger</a>, he experimented with new propulsion systems using industrially available components and low-cost fuels. The initial work with Sänger carried over into Kayser’s first startup, Technology Research Ltd., which he founded in 1970. The company received several million Deutschmark in research grants and was hired by the West German government to explore a low-cost alternative to the ailing <a href="https://en.wikipedia.org/wiki/Europa_(rocket)" target="_blank">Europa II</a> rocket program.&nbsp;</p><p>It was during this time that Kayser developed his vision for a low-cost, modular rocket system that could transport satellites into orbit<em>.</em> The idea was as simple as it was revolutionary: it involved the parallel clustering of many standard fuel tank and engine modules <em>(Bündelrakete)</em>. The smallest flight-worthy rocket module consisted of four clustered tank units and four identical engines. Bigger, more powerful boosters could be constructed by bundling together larger quantities of these tank-and-engine modules. The largest configuration on paper had as many as 600 individual engines! And there was another idiosyncrasy to the design: instead of being stacked <em>atop</em> one another, the stages would be nested <em>inside</em> one another and shed like layers of an onion as they burned out. This arrangement didn’t make for a particularly handsome vehicle and the rocket’s design was frequently compared to a<em> </em>bundle of asparagus. But aesthetics weren’t the point; “low cost, not high tech” was the North Star.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606063350099_13600"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064185347-VN7XY7VCBE5NGAOK3N04/ke17ZwdGBToddI8pDm48kJmhqGN-mSClKRKwJ41evzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dt65uYDq5wjmpAbzmJV4EKyPzCeG_9Y6bPguKi4sPluTCjLISwBs8eEdxAxTptZAUg/1.png" data-image="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064185347-VN7XY7VCBE5NGAOK3N04/ke17ZwdGBToddI8pDm48kJmhqGN-mSClKRKwJ41evzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dt65uYDq5wjmpAbzmJV4EKyPzCeG_9Y6bPguKi4sPluTCjLISwBs8eEdxAxTptZAUg/1.png" data-image-dimensions="1988x966" data-image-focal-point="0.5,0.5" alt="Lutz Kayser with a prototype of his “cluster rocket” (left), next to a design sketch by Klaus Bürgle (right).  Source:    OTRAG" data-load="false" data-image-id="5fba982f2b4bfe31fd69b8dc" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064185347-VN7XY7VCBE5NGAOK3N04/ke17ZwdGBToddI8pDm48kJmhqGN-mSClKRKwJ41evzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dt65uYDq5wjmpAbzmJV4EKyPzCeG_9Y6bPguKi4sPluTCjLISwBs8eEdxAxTptZAUg/1.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Lutz Kayser with a prototype of his “cluster rocket” (left), next to a design sketch by Klaus Bürgle (right). <em>Source: </em><a href="http://otrag.com/" target="_blank"><em>OTRAG</em></a></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606063350099_15492"><div><p>The key to holding down the rocket’s cost lay in three simple design principles, some of which have been rediscovered by the current crop of “<a href="https://en.wikipedia.org/wiki/Private_spaceflight#NewSpace_terminology" target="_blank">NewSpace</a>” companies. The first principle was rooted in the modular platform architecture itself. Building a whole family of launch vehicles around the same tank-and-engine modules simplified the vehicle configuration and saved millions in development costs. It also meant lots of tanks and engines in production, generating both economies of scale and lower prices. SpaceX applies the same design philosophy today: its main rocket, the <a href="https://en.wikipedia.org/wiki/Falcon_9" target="_blank">Falcon 9</a>, employs nine identical engines (plus another one to power the second stage), while the <a href="https://en.wikipedia.org/wiki/Falcon_Heavy" target="_blank">Falcon Heavy</a> uses 27 units of the same engine. This creates a virtuous cycle whereby the operating model helps drive the business model: being the cheapest launch provider in the market translates into a greater number of launch contracts, which in turn drives higher volumes and scale efficiencies. Once this flywheel is in motion, it becomes easier to run the business as it continues to operate.</p><p>The second design principle was to use mass produced, commercially available components instead of expensive “space grade” equipment from government contractors. The tank units, for example, were made of long pipeline tubes that were manufactured by the German steelmaker Krupp. Amusingly, a Volkswagen windshield-wiper motor was used to open and close the valves that controlled the propellant flow to the engines. Complex and trouble-prone components, like <a href="https://en.wikipedia.org/wiki/Turbopump" target="_blank">turbopumps</a> or <a href="https://en.wikipedia.org/wiki/Gimbaled_thrust" target="_blank">gimbals</a>, were avoided altogether. Instead, the fuel tanks were partially filled with compressed air that forced the propellant into the engines, and the rocket was steered by throttling back individual engines on the side where less thrust was desired. SpaceX would later use components from existing supply chains as well: The Falcon 1 used readily available car wash valves with modified seals to feed propellant into the engine, while the first <a href="https://en.wikipedia.org/wiki/SpaceX_Dragon" target="_blank">Dragon</a> spacecraft utilized a modified bathroom stall latch for securing the cargo lockers.</p><p>The third design principle was a simplified rocket engine that could run on extremely low-cost fuels. The<em> </em>basic job of rocket fuel is to burn steadily and intensely when combined with an oxidizer. Once the fuel and oxidizer are fed through an injector into the combustion chamber, they produce a hot gas that shoots out of the bell-shaped exhaust nozzle at the bottom. This creates the necessary thrust to launch the rocket upwards. The most common rocket propellant in use today is a mix of ultra-refined kerosene (RP-1) and liquid oxygen (LOX). SpaceX, <a href="https://en.wikipedia.org/wiki/Rocket_Lab" target="_blank">Rocket Lab</a>, and many other launch providers work with this fuel mix. Kayser, in contrast, opted for a much cheaper propellant combination: regular diesel oil as fuel and nitric acid as oxidizer. Though providing less thrust per pound than RP-1/LOX and being extremely toxic, this combination cost only 5% as much and was readily available.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606063350099_27594"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064291685-VEMSFLQL8VPXVMHIP4SE/ke17ZwdGBToddI8pDm48kFhaRfXD0sHRzS4HFtXwQmMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dnuqrDbxeiwpNrWn4d5W-MeZh_NIeMKNsMLkG5wAFm5KCjLISwBs8eEdxAxTptZAUg/2.png" data-image="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064291685-VEMSFLQL8VPXVMHIP4SE/ke17ZwdGBToddI8pDm48kFhaRfXD0sHRzS4HFtXwQmMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dnuqrDbxeiwpNrWn4d5W-MeZh_NIeMKNsMLkG5wAFm5KCjLISwBs8eEdxAxTptZAUg/2.png" data-image-dimensions="1986x962" data-image-focal-point="0.5,0.5" alt="Kayser in the control center at the German Aerospace Center in Lampoldshausen.  Source:    OTRAG" data-load="false" data-image-id="5fba9899317ba5146213cb17" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064291685-VEMSFLQL8VPXVMHIP4SE/ke17ZwdGBToddI8pDm48kFhaRfXD0sHRzS4HFtXwQmMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dnuqrDbxeiwpNrWn4d5W-MeZh_NIeMKNsMLkG5wAFm5KCjLISwBs8eEdxAxTptZAUg/2.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Kayser in the control center at the German Aerospace Center in Lampoldshausen. <em>Source: </em><a href="http://otrag.com/" target="_blank"><em>OTRAG</em></a></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606063350099_29089"><div><p>Much of the early work on this novel rocket concept was done at a test stand rented from the German Aerospace Center in <a href="https://www.dlr.de/content/en/articles/sites/lampholdshausen/about-lampoldhausen.html" target="_blank">Lampoldshausen</a>, north of Stuttgart. Over a period of four years, Kayser’s team went through hundreds of test firings to perfect the diesel oil/nitric acid cocktail. The biggest challenge around getting the engine to work was the “<a href="https://en.wikipedia.org/wiki/Hypergolic_propellant" target="_blank">hypergolic</a>” nature of the fuel mix: diesel oil and nitric acid ignite immediately upon contact and are subject to <a href="https://en.wikipedia.org/wiki/Combustion_instability" target="_blank">unstable burning</a>. Just getting the engine started was difficult: if ignition happened too late, a pool of almost-ready to burn propellant had already accumulated in the combustion chamber, triggering an explosion that would demolish the engine and its immediate surroundings. The group eventually achieved a breakthrough by inventing a radial fuel injection system that provided the right vapor mixture of fuel and oxidizer.</p><p>Then came an unexpected setback. By 1974, the West German government had lost interest in the project and decided to concentrate its rocket research efforts on a new, pan-European launch vehicle, the <a href="https://en.wikipedia.org/wiki/Ariane_1" target="_blank">Ariane 1</a>. Technology Research Ltd.’s fiscal tap<em> </em>was shut off. Kayser was undeterred. He began looking for private funding to bring his rocket to market but it was difficult. Venture capital as we know it today didn’t exist in 1974. Venerable firms like <a href="https://www.kleinerperkins.com/our-history/" target="_blank">Kleiner Perkins</a> and <a href="https://www.sequoiacap.com/article/remembering-don-valentine/" target="_blank">Sequoia</a>, both founded in 1972, were still in their infancy and unavailable to a little-known entrepreneur from West Germany. Kayser’s only option was a highly unorthodox crowdfunding strategy: he decided to raise money from wealthy individuals who wrote off their investment through tax deductions <em>(Abschreibungsgesellschaft). </em>Few investors believed that Kayser’s company would actually succeed, but that …</p></div></div></div></div></div></article></section></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s">https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s</a></em></p>]]>
            </description>
            <link>https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197941</guid>
            <pubDate>Tue, 24 Nov 2020 12:45:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ask Your Coworkers What They Make. You’ll Earn More]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197935">thread link</a>) | @Fiveplus
<br/>
November 24, 2020 | https://civicskunk.works/ask-your-coworkers-what-they-make-youll-earn-more-46efb2daf63e | <a href="https://web.archive.org/web/*/https://civicskunk.works/ask-your-coworkers-what-they-make-youll-earn-more-46efb2daf63e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="1842">Lack of wage transparency is a real factor in suppressing American wages.</h2><div><div><div><p><a href="https://medium.com/@Nick_Cassella?source=post_page-----46efb2daf63e--------------------------------" rel="noopener"><img alt="Nick Cassella" src="https://miro.medium.com/fit/c/96/96/0*1ojfl3YBepASbp5C.jpg" width="48" height="48"></a></p></div></div></div><p id="1bb9">I remember the uneasiness of asking for my first raise—only to have my boss tell me the number I had in mind would make me the “highest paid employee.” It was a startling admission. I was asking for $44,000 a year, which seemed reasonable to me. But I didn’t know how my pay compared to the business’ other five employees. So I didn’t call my boss’ bluff. I settled for $42,000.</p><p id="b7d1">You probably don’t know how much your coworkers make either. I get it. It’s an awkward conversation to have. It’s taboo. Plus, do you really want to discover that Stephen makes $20,000 more than you? No. So you don’t ask. You skirt around the issue, only talking about your pay in the privacy of your own home.</p><p id="4ac1">There is a serious price to pay for keeping your salary secret, though: it benefits your boss. Their asymmetric knowledge of who earns what enables them to pay you “<a href="http://www.hamiltonproject.org/people/benjamin_harris" rel="noopener">less than [your] economic value</a>” demands, as my experience illustrates.</p><p id="208c">Now, standard economic theory suggests that this shouldn’t happen. In a competitive labor market, a worker’s pay is determined by the economic value of their labor. If a business underpays its employees, then they should expect to have their workforce leave for better jobs. But one of the features of a competitive market is “<a href="http://www.economicsdiscussion.net/market/features-of-a-perfectly-competitive-market/7108" rel="noopener">perfect knowledge</a>”; that is, both businesses and employees possess the same information.</p><p id="7b27">However, that’s not the case in America today. While websites like Glassdoor supply people with greater awareness of salaries and benefits, these “<a href="http://www.hamiltonproject.org/papers/information_is_power_fostering_labor_market_competition_through_transparent" rel="noopener">data sources all have considerable weaknesses when it comes to gaining a precise understanding of prevailing wages</a>.” To get a leg up over their employees, more than half of employers <a href="http://www.hamiltonproject.org/papers/information_is_power_fostering_labor_market_competition_through_transparent" rel="noopener">conduct their own salary surveys</a>. These employers generally don’t share their findings with the employees. Instead, they say, “Trust us, we offer competitive compensation.”</p><p id="0e4e">Is it any wonder America suffers from decades of stagnant wages?</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2432/1*uVgy2c4ZV8MuzgXQM1xcoQ.png" width="1216" height="1149" srcset="https://miro.medium.com/max/552/1*uVgy2c4ZV8MuzgXQM1xcoQ.png 276w, https://miro.medium.com/max/1104/1*uVgy2c4ZV8MuzgXQM1xcoQ.png 552w, https://miro.medium.com/max/1280/1*uVgy2c4ZV8MuzgXQM1xcoQ.png 640w, https://miro.medium.com/max/1400/1*uVgy2c4ZV8MuzgXQM1xcoQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*uVgy2c4ZV8MuzgXQM1xcoQ.png?q=20"></p></div></div></div></figure><p id="53b6">This feature of the modern workplace is totally avoidable, too. When <a href="https://www.npr.org/sections/money/2015/02/23/385843576/50-years-of-shrinking-union-membership-in-one-map" rel="noopener">unions represented the majority of American workers</a>, there was greater “<a href="https://www.brookings.edu/research/information-is-power-fostering-labor-market-competition-through-transparent-wages/" rel="noopener">familiarity with the distribution of wages in a given market</a>.” In turn, this put “<a href="https://www.brookings.edu/research/information-is-power-fostering-labor-market-competition-through-transparent-wages/" rel="noopener">workers in a stronger position during negotiations</a>”—which could help explain why wage growth was stronger when more people belonged to a union.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1600/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg" width="800" height="459" srcset="https://miro.medium.com/max/552/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg 276w, https://miro.medium.com/max/1104/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg 552w, https://miro.medium.com/max/1280/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg 640w, https://miro.medium.com/max/1400/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg?q=20"></p></div></div></div></figure><p id="a62f"><a href="https://www.nytimes.com/2018/02/22/us/politics/supreme-court-unions.html" rel="noopener">Unions aren’t coming back</a>, though. So in a post-union economy, how do we empower workers to negotiate for higher wages?</p><p id="939b">Benjamin Harris of Northwestern University has compiled <a href="https://www.brookings.edu/research/information-is-power-fostering-labor-market-competition-through-transparent-wages/" rel="noopener">a report</a> enumerating five remedies to improving wage transparency. Quickly, Harris’ points are:</p><ul><li id="ad8d">Enact state laws to protect workers who discuss pay</li><li id="1dd6">Require large firms to disclose pay trends to the Equal Employment Opportunity Commission</li><li id="ec04">Amend the safe harbor for compensation surveys</li><li id="f822">Change state law to facilitate reciprocal pre-hiring wage disclosure</li><li id="9ce6">Allocate funds for the Department of Labor to study transparency</li></ul><p id="141b">The logic behind these wonky prescriptions is compelling. If businesses are forced to be transparent about wages, they will have a harder time suppressing them. You’d think whether you’re conservative or progressive, that is an outcome worth working towards.</p><p id="05c4">Alas, Republicans have blocked legislation that aims to provide workers with more information on compensation. They have filibustered and condemned the Paycheck Fairness Act—a labor law that, among other provisions, would punish “<a href="http://thehill.com/blogs/floor-action/senate/203064-senate-gop-blocks-paycheck-fairness-bill" rel="noopener">employers for retaliating against workers who share wage information</a>.”</p><p id="7c09">Their arguments against the Act are ridiculous. Ever the critical thinker, Marco Rubio summed up his party’s attitude towards greater wage transparency when he claimed that “<a href="https://thinkprogress.org/marco-rubio-explains-his-opposition-to-equal-pay-law-3c3924506778/" rel="noopener">all [the Paycheck Fairness Act] really did is just help lawyers sue</a>.” Ah, yes. Astute point, Marco.</p><p id="9f61">If history has taught us anything, it is that businesses will not pay people what they are worth until they are forced to. That’s why some employers <a href="https://www.classaction.org/blog/can-i-be-fired-for-discussing-wages-at-work" rel="noopener">retaliate against workers for even <em>discussing</em> wages</a> with each other. So while <a href="https://www.inman.com/2018/03/09/the-week-in-financial-markets-why-arent-wages-growing-faster-in-this-booming-economy/" rel="noopener">everyone</a> <a href="https://www.washingtonpost.com/news/posteverything/wp/2017/10/09/why-arent-wages-growing-more-quickly-a-graphical-analysis/" rel="noopener">keeps</a> <a href="https://www.nationalreview.com/2017/09/growth-stagnant-economists-disagree-reasons-automation-offshoring-demographic-change/" rel="noopener">asking</a> “<a href="http://theweek.com/articles/760002/why-arent-wages-growing-faster" rel="noopener">why aren’t wages growing</a>?,” keep in mind that there is a <em>very simple fix</em> which could improve workers’ bargaining position.</p><p id="1f13">Enforcing greater wage transparency is not a silver bullet. It’s not going to completely erase all wage stagnation. But it is a powerful remedy to a labor market that favors the employer. If Americans want to see bigger paychecks, they should start by figuring out what their coworkers are making.</p><p id="64c2">Think about <em>that</em> the next time you ask for a raise.</p></div></div></div>]]>
            </description>
            <link>https://civicskunk.works/ask-your-coworkers-what-they-make-youll-earn-more-46efb2daf63e</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197935</guid>
            <pubDate>Tue, 24 Nov 2020 12:44:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yet another one-man SaaS technology stack]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197922">thread link</a>) | @agranig
<br/>
November 24, 2020 | https://www.sipfront.com/blog/2020/11/the-technology-stack-behind-sipfront/ | <a href="https://web.archive.org/web/*/https://www.sipfront.com/blog/2020/11/the-technology-stack-behind-sipfront/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <div>
        <div>
          <div>

    
        <div>

          


<article>
  <header>
    
    <p>
    <b>
<time datetime="2020-11-24T12:32:37+01:00">Tue Nov 24, 2020</time> by Andreas Granig
 in 
&nbsp;<a href="https://www.sipfront.com/blog/categories/engineering/" rel="category tag">Engineering</a>


&nbsp;<a href="https://www.sipfront.com/blog/tags/technology-stack/" rel="tag">technology stack</a>, <a href="https://www.sipfront.com/blog/tags/sipp/" rel="tag">sipp</a>, <a href="https://www.sipfront.com/blog/tags/perl/" rel="tag">perl</a>, <a href="https://www.sipfront.com/blog/tags/aws/" rel="tag">aws</a>, <a href="https://www.sipfront.com/blog/tags/behind-the-scenes/" rel="tag">behind the scenes</a>


    </b>
    </p>
  </header>
  

<p>Since several people have asked me about the technology behind Sipfront, I’d
like to shed some light behind the scenes on the tech stack currently used to
drive the service. Sipfront is currently a one man show, therefore it’s
important to keep everything as simple as possible.</p>

<p>I tried to balance the technology stack in a way to finally use new stuff I
wanted to play with since a long time while still being able to move very
quickly.</p>

<h2 id="off-to-the-cloud">Off to the cloud!</h2>

<p>In the past, I used to self-host as many services as possible. RDBMS,
Key/Value Stores, Message Queues, Email delivery, even VM Infrastructure, since
it’s just an <em>apt-get</em> away. With all the flexibility and freedom in adapting
the services to your needs comes the setup time in the short run (which
fortunately is rather small in lots of cases if you’ve worked with those
services in the past), but more importantly maintenance time in the mid- to
long-run. Software updates, backups, tweaking, scaling, you name it.</p>

<p>This time around, I rather forced myself to using hosted services as much as
possible to focus on the actual Sipfront service development instead of herding
the backend infrastructure. You might argue that this comes with a huge cost,
but then again while you don’t have tens of thousands of users, the costs are
quite contained, and the value of my time spent on implementing the service is
by far out-performing the cost of maintaining backend software. Eventually, when
profits are high enough to cover the cost of dedicated DevOps engineers, we
might optimize infrastructure costs by moving it off the cloud. The important
aspect here is to not lock the technology too much into a specific platform,
which actually is quite hard when looking at the compelling tools they provide.
See below.</p>

<h2 id="the-architecture">The architecture</h2>

<p>Based on the chosen cloud approach, I deployed the service on Amazon
AWS. The high level design is shown in the picture below.</p>

<p><img src="https://www.sipfront.com/blog/img/sipfront-hld.png" alt="High Level Design"></p>

<p>The key take-away is that all services are deployed as Docker containers in AWS
Fargate. While Fargate has its annoying restrictions and limitations like for
instance not being able to set ulimits for the number of open files (important
when opening lots of sockets on a container) or setting net_admin privileges
(required if you want to gather per-port traffic statistics using iptables log
rules), it’s simple enough to do its job for now. At a later stage we might
migrate to Kubernetes to get more control over the containers, but taking into
account that I didn’t have too much experience running this kind of
infrastructure, it would have been way of an overkill to start off.</p>

<p>So essentially the workflow of a test session looks like this:</p>

<ol>
<li><p>A user starts a test session on app.sipfront.com using the dashboard.</p></li>

<li><p>The test session is created on the sipfront-app service providing the
dashboard, and its configuration is persisted in the Postgres database
acting as main datasource.</p></li>

<li><p>The session is dispatched to a worker queue and is picked up by a
sipfront-worker instance from there</p></li>

<li><p>The worker instance creates an AWS StepFunction state machine, if
necessary provisions the AWS VPC elements for networking and the Fargate Task
Definition for the containers and triggers the start of the state machine.</p></li>

<li><p>The StepFunction state machine launches the containers which include the
traffic generation tools.</p></li>

<li><p>Once running, the containers fetch their auxiliary files like xml scenarios,
credential files etc. from the sipfront-api instances and publish their
states via MQTT to the AWS MQ.</p></li>

<li><p>The traffic generation tools launch according to the test configuration and
publish their metrics via MQTT.</p></li>

<li><p>The sipfront-persistor instance picks up published metrics from the message
queue and persist them into the main DB.</p></li>

<li><p>On the dashboard, the sipfront-app instance polls for new metrics of the test
session via a websocket connection and paints them on the report page by
updating graphs and tables.</p></li>

<li><p>Once the traffic generation tools end, they wind down the container
instances by notifying their peers via MQTT, and the Fargate cluster is
cleaned up.</p></li>
</ol>

<h2 id="web-technologies">Web technologies</h2>

<p>All components except for the traffic generation tools are written in Perl. This
might sound a bit ancient, but it’s the programming language I know best and
which I’m using most since 20 years, so I get things done very quickly.</p>

<p>Web components like sipfront-app and sipfront-api are created using the
<a href="https://mojolicious.org/">Mojolicious Framework</a>, while the main website is
served as static files stitched together using the <a href="http://www.template-toolkit.org/">Perl Template Toolkit</a> to avoid redundant HTML code for different
pages. This blog section right here is powered by <a href="https://gohugo.io/">Hugo</a> to
generate static pages from Markdown content.</p>

<p>The web containers are then exposed via AWS Load Balancers, which also handle
the TLS certificates.</p>

<h2 id="voip-technologies">VoIP technologies</h2>

<p>The traffic generation tool currently in use is <a href="https://github.com/SIPp/sipp">SIPp</a> with custom patches for MQTT support, while the
service is built in a way that any tool able to run in a Docker container and
publishing its metrics via MQTT can be used.</p>

<p>SIPp is extremely powerful if used properly and can generate a huge amount of
signaling traffic.</p>

<p>The media generation to support audio and video streams and being able to gather
the audio quality is currently in the build stage at the time of writing. The
tools used here will be <a href="https://www.kamailio.org/">Kamailio</a> as a control daemon
for <a href="https://github.com/sipwise/rtpengine">rtpengine</a>, which can be used to
inject media into the calls.</p>

<h2 id="deployment-strategies">Deployment strategies</h2>

<p>Since all components are deployed in AWS and are running in Docker containers,
I’ve built a CI/CD pipeline using AWS CodePipeline.</p>

<p>I’m keeping the git main branch of the various components, which reside in
private Github repositories, clean and production ready, so each push to main on
Github will trigger via a web hook the corresponding AWS CodePipeline code.</p>

<p>The pipeline is then invoking a Source step fetching the source code, a Build
step creating the Docker container and pushing it towards the AWS ECR, and a
Deploy stage to replace the Fargate task with a new one based on the newly
created container.</p>

<h2 id="observability">Observability</h2>

<p>At the moment, I use AWS CloudWatch to collect and present all container logs
and metrics. This is probably the biggest source of improvement to tackle next,
as it’s really clumsy and is not providing all metrics one would expect (load,
anyone?). Therefore I’m leaning to a Prometheus based solution here in the near
term.</p>

<h2 id="infrastructure-as-code">Infrastructure as code</h2>

<p>I’m currently working on packing the whole infrastructure into AWS
CloudFormation definitions, so I can easily spin up completely new instances of
the full stack. This is important for me to have development, staging and
production environments cleanly separated.</p>

<p>This concludes the peek <em>behind the scenes</em> and sheds some lights on how
Sipfront is built. If you have any comments and suggestions, let me know at
<a href="https://twitter.com/andreasgranig">Twitter</a>.</p>

</article> 



        </div>

        


    

	      </div>
	    </div>
	  </div>
	</div></div>]]>
            </description>
            <link>https://www.sipfront.com/blog/2020/11/the-technology-stack-behind-sipfront/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197922</guid>
            <pubDate>Tue, 24 Nov 2020 12:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vmtouch – The Virtual Memory Toucher]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197904">thread link</a>) | @gjvc
<br/>
November 24, 2020 | https://hoytech.com/vmtouch/ | <a href="https://web.archive.org/web/*/https://hoytech.com/vmtouch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        

        

<h2>Portable file system cache diagnostics and control</h2>

<ul>
<li><a href="https://github.com/hoytech/vmtouch">Download from github</a></li>
<li><a href="https://github.com/hoytech/vmtouch/blob/master/vmtouch.pod">Read the online manual</a></li>
</ul>

<p><strong>vmtouch</strong> is a tool for learning about and controlling the file system cache of unix and unix-like systems. It is BSD licensed so you can basically do whatever you want with it.</p>

<h2>Quick install guide:</h2>

<pre><code>$ git clone https://github.com/hoytech/vmtouch.git
$ cd vmtouch
$ make
$ sudo make install
</code></pre>

<h2>What is it good for?</h2>

<ul>
<li>Discovering which files your OS is caching</li>
<li>Telling the OS to cache or evict certain files or regions of files</li>
<li>Locking files into memory so the OS won't evict them</li>
<li>Preserving virtual memory profile when failing over servers</li>
<li>Keeping a "hot-standby" file-server</li>
<li>Plotting filesystem cache usage over time</li>
<li>Maintaining "soft quotas" of cache usage</li>
<li>Speeding up batch/cron jobs</li>
<li>And much more...</li>
</ul>

<h2>Support</h2>

<p>To complement the open source community, Hoytech offers services related to vmtouch:</p>

<ul>
<li>Advanced feature development</li>
<li>Support contracts</li>
<li>Training sessions</li>
</ul>

<p>Please <a href="mailto:doug@hoytech.com?subject=vmtouch%20support">contact Doug Hoyte</a> for more information.</p>

<h2>Examples</h2>

<h3>Example 1</h3>

<p>How much of the /bin/ directory is currently in cache?</p>

<pre><code>$ vmtouch /bin/
           Files: 92
     Directories: 1
  Resident Pages: 348/1307  1M/5M  26.6%
         Elapsed: 0.003426 seconds
</code></pre>

<h3>Example 2</h3>

<p>How much of <em>big-dataset.txt</em> is currently in memory?</p>

<pre><code>$ vmtouch -v big-dataset.txt
big-dataset.txt
[                                                            ] 0/42116

           Files: 1
     Directories: 0
  Resident Pages: 0/42116  0/164M  0%
         Elapsed: 0.005182 seconds
</code></pre>

<p>None of it. Now let's bring part of it into memory with <strong>tail</strong>:</p>

<pre><code>$ tail -n 10000 big-dataset.txt &gt; /dev/null
</code></pre>

<p>Now how much?</p>

<pre><code>$ vmtouch -v big-dataset.txt
big-dataset.txt
[                                                    oOOOOOOO] 4950/42116

           Files: 1
     Directories: 0
  Resident Pages: 4950/42116  19M/164M  11.8%
         Elapsed: 0.006706 seconds
</code></pre>

<p>vmtouch tells us that 4950 pages at the end of the file are now resident in memory.</p>

<h3>Example 3</h3>

<p>Let's <strong>touch</strong> the rest of /big-dataset.txt/ and bring it into memory (pressing enter a few times to illustrate the animated progress bar you will see on your terminal):</p>

<pre><code>$ vmtouch -vt big-dataset.txt
big-dataset.txt
[OOo                                                 oOOOOOOO] 6887/42116
[OOOOOOOOo                                           oOOOOOOO] 10631/42116
[OOOOOOOOOOOOOOo                                     oOOOOOOO] 15351/42116
[OOOOOOOOOOOOOOOOOOOOOo                              oOOOOOOO] 19719/42116
[OOOOOOOOOOOOOOOOOOOOOOOOOOOo                        oOOOOOOO] 24183/42116
[OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOo                  oOOOOOOO] 28615/42116
[OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOo              oOOOOOOO] 31415/42116
[OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOo      oOOOOOOO] 36775/42116
[OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOo  oOOOOOOO] 39431/42116
[OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO] 42116/42116

           Files: 1
     Directories: 0
   Touched Pages: 42116 (164M)
         Elapsed: 12.107 seconds
</code></pre>

<h3>Example 4</h3>

<p>We have 3 big datasets, <em>a.txt</em>, <em>b.txt</em>, and <em>c.txt</em> but only 2 of them will fit in memory at once. If we have <em>a.txt</em> and <em>b.txt</em> in memory but would now like to work with <em>b.txt</em> and <em>c.txt</em>, we could just start loading up <em>c.txt</em> but then our system would evict pages from both <em>a.txt</em> (which we want) and <em>b.txt</em> (which we don't want).</p>

<p>So let's give the system a hint and <strong>evict</strong> <em>a.txt</em> from memory, making room for <em>c.txt</em>:</p>

<pre><code>$ vmtouch -ve a.txt
Evicting a.txt

           Files: 1
     Directories: 0
   Evicted Pages: 42116 (164M)
         Elapsed: 0.076824 seconds
</code></pre>

<h3>Example 5</h3>

<p><strong>Daemonise</strong> and <strong>lock</strong> all files in a directory into physical memory:</p>

<pre><code>vmtouch -dl /var/www/htdocs/critical/
</code></pre>

<h2><a name="saying"></a> What other people are saying</h2>

<p>People have found lots of uses for vmtouch over the years. Here are a few links in no particular order:</p>

<h3>Articles</h3>

<ul>
<li><strong><a href="https://www.hostingadvice.com/blog/vmtouch-delivers-file-system-cache-diagnostics/">FEATURED: Hosting Advice: Interview with Doug about vmtouch</a></strong></li>
<li><a href="http://www.admin-magazine.com/Articles/Tuning-Your-Filesystem-s-Cache">Admin magazine: Performance Tuning Dojo: Tune-Up</a></li>
<li><a href="http://blog.parse.com/learn/engineering/techniques-for-warming-up-mongodb/">Techniques for Warming Up a MongoDB Secondary</a></li>
<li><a href="http://www.inmotionhosting.com/support/website/server-usage/linux-check-memory-usage">Linux Memory Usage</a></li>
<li><a href="http://marek.vavrusa.com/c/memory/2015/02/20/memory/">What a C programmer should know about memory</a></li>
<li><a href="http://www.slideshare.net/JimmyMrdell/playlists-at-spotify-cassandra-summit-london-2013#slide32">Playlists at Spotify - Using Cassandra to store version controlled objects</a> (slide 32)</li>
<li><a href="http://careers.directi.com/display/tu/Understanding+and+optimizing+Memory+utilization">Understanding and optimizing Memory utilization</a></li>
<li><a href="http://www.admon.org/system-tuning/vmtouch-file-system-cache-diagnostics-and-control/">admon.org</a></li>
<li><a href="http://thewebdev.de/vmtouch-virtual-memory-touch/">thewebdev.de</a></li>
<li><a href="http://www.trevoroconnell.com/2012/02/tune-up-paging-with-vmtouch.html">Tune Up Paging with vmtouch</a></li>
<li><a href="http://www.jothirams.com/linux-cached-memory/">Linux Cached Memory</a></li>
<li><a href="http://fulmicoton.com/posts/pagecache/">Of how much of a file is in RAM</a></li>
<li><a href="http://blog.armcd.co.uk/2012/05/manipulating-the-kernels-page-cache-with-vmtouch.html">Manipulating the kernel's page cache with vmtouch</a></li>
<li><a href="http://www.slideshare.net/e1coyot/memory-management-in-linux-kernel">Memory management in Linux kernel</a> (slide 16)</li>
<li><a href="http://radar.oreilly.com/2013/12/supercomputing-on-the-cheap-with-parallella.html">Supercomputing on the cheap with Parallella</a></li>
<li><a href="http://prismoskills.appspot.com/lessons/System_Design_and_Big_Data/Chapter_06_-_System_Design.jsp">System Design and Big Data, chapter 6</a></li>
<li><a href="http://issuu.com/lucidimagination12/docs/gaikaiwari_sudarshan_-_lucene_yelp_lucene_revoluti">Lucene @ Yelp</a> (slide 16)</li>
<li><a href="http://tuxdiary.com/2016/01/26/vmtouch/">tuxdiary: vmtouch: portable file cache analyzer</a></li>
</ul>

<h3>Real-world sightings</h3>

<ul>
<li><a href="http://www.gossamer-threads.com/lists/linux/kernel/1693344">Linux kernel mailing list: zcache: Support zero-filled pages more efficiently</a></li>
<li><a href="http://comments.gmane.org/gmane.comp.db.sqlite.general/79457">comp.db.sqlite.general: Strange eviction from Linux page cache</a></li>
<li><a href="http://blog.binchen.org/posts/emacs-speed-up-1000.html">Emacs speed up 1000%</a></li>
<li><a href="https://lwn.net/Articles/580335/">Jolla Review: Some Rough Edges, But This Linux Smartphone Shows Promise</a> (vmtouch deployed on maemo phones?)</li>
<li><a href="http://lists.ceph.com/pipermail/ceph-users-ceph.com/2014-October/043509.html">ceph-users: Ceph SSD array with Intel DC S3500's</a></li>
<li><a href="http://forum.proxmox.com/archive/index.php/t-16798.html">proxmox forums: CPU Performance Degradtion</a></li>
<li><a href="https://confluence.aps.anl.gov/display/howtos/Evicting+data+from+filesystem+cache">Argonne National Laboratory's Advanced Photon Source</a></li>
<li><a href="https://discuss.elastic.co/t/dealing-with-os-page-cache-evictions/21974/5">Elastic Search: Dealing with OS page cache evictions?</a></li>
<li><a href="http://th30z.blogspot.ca/2012/06/data-center-deploy-using-torrent-and.html">Data-center deploy using torrent and mlock()</a></li>
<li><a href="http://forum.xbian.org/archive/index.php/thread-764.html">Making best use of 512mb Pi with tmpfs</a></li>
<li><a href="https://groups.google.com/d/msg/redis-db/zaLGF1Bit0A/QsVGMJtTpKEJ">redis-db: Issue with Redis replication while transferring rdb file from master to slave</a></li>
<li><a href="http://qnalist.com/questions/5278241/oplog-memory-consumption">mongodb-user: Oplog Memory Consumption</a></li>
<li><a href="https://bugs.centos.org/view.php?id=7091">CentOS bugtracker: oom killer kills process rather than freeing cache</a></li>
<li><a href="http://www.openldap.org/lists/openldap-technical/201511/msg00022.html">LMDB mailing list</a></li>
<li>Used to optimize <a href="https://sportcrypt.com/">ethereum sports betting</a></li>
</ul>

<h3>Instagram</h3>

<p>Discussion about instagram's usage of vmtouch:</p>

<ul>
<li><a href="http://instagram-engineering.tumblr.com/post/13649370142/what-powers-instagram-hundreds-of-instances">What Powers Instagram: Hundreds of Instances, Dozens of Technologies</a></li>
<li><a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html">Instagram Architecture: 14 Million Users, Terabytes Of Photos, 100s Of Instances, Dozens Of Technologies</a></li>
<li><a href="http://highscalability.com/blog/2012/4/9/the-instagram-architecture-facebook-bought-for-a-cool-billio.html">The Instagram Architecture Facebook Bought For A Cool Billion Dollars</a></li>
<li><a href="https://gist.github.com/mikeyk/1424540">parse_vmtouch.py</a> (script used by instagram)</li>
</ul>

<h3>Stack-overflow and friends</h3>

<ul>
<li><a href="http://stackoverflow.com/questions/7118543/does-the-linux-filesystem-cache-files-efficiently">Does the Linux filesystem cache files efficiently?</a></li>
<li><a href="http://stackoverflow.com/questions/23048001/postgresql-doesnt-use-memory-for-caching">Postgresql doesn't use memory for caching</a></li>
<li><a href="http://stackoverflow.com/questions/19995756/mongodb-numa-hardware-page-faults-but-enough-ram-for-working-set-touch-comman">MongoDB, NUMA hardware, page faults</a></li>
<li><a href="http://stackoverflow.com/questions/23662322/know-programs-in-cache">Know programs in cache</a></li>
<li><a href="http://serverfault.com/questions/278454/is-it-possible-to-list-the-files-that-are-cached">Is it possible to list the files that are cached?</a></li>
<li><a href="http://serverfault.com/questions/406308/tell-the-linux-kernel-to-put-a-file-in-the-disk-cache">Tell the linux kernel to put a file in the disk cache?</a></li>
<li><a href="http://serverfault.com/questions/408614/securely-wipe-an-entire-linux-server-with-itself">Securely wipe an entire Linux server with itself</a></li>
<li><a href="http://serverfault.com/questions/43383/caching-preloading-files-on-linux-into-ram">Caching/preloading files on Linux into RAM</a></li>
<li><a href="http://serverfault.com/questions/597115/why-drop-caches-in-linux">Why drop caches in Linux?</a></li>
<li><a href="http://serverfault.com/questions/435635/clear-flush-cached-memory">Clear / Flush cached memory</a></li>
<li><a href="http://serverfault.com/questions/504193/limit-filesystem-cache-size-for-specific-files-under-linux">limit filesystem cache size for specific files under linux</a></li>
<li><a href="http://serverfault.com/questions/592907/memory-mapping-files-for-a-blazing-fast-webserver-on-linux">Memory mapping files for a blazing fast webserver on Linux</a></li>
<li><a href="http://serverfault.com/questions/590124/performance-difference-between-ramfs-and-tmpfs">Performance difference between ramfs and tmpfs</a></li>
<li><a href="http://unix.stackexchange.com/questions/203920/how-do-i-lock-a-growing-directory-in-memory">How do I lock a growing directory in memory?</a></li>
<li><a href="http://unix.stackexchange.com/questions/215202/how-do-i-vmtouch-a-directory-not-the-files-it-contains">How do I vmtouch a directory (not the files it contains)?</a> (good question, I don't know of a userspace way to do this)</li>
<li><a href="http://dba.stackexchange.com/questions/64925/mysql-queries-are-10-to-100-times-slower-after-os-reboot">MySQL queries are 10 to 100 times slower after OS reboot</a></li>
<li><a href="http://www.quora.com/How-can-one-examine-what-files-are-in-Linuxs-page-cache">How can one examine what files are in Linux's page cache?</a></li>
</ul>

<h3>OS packages/ports</h3>

<ul>
<li><a href="https://admin.fedoraproject.org/pkgdb/package/vmtouch/">Fedora Linux</a></li>
<li><a href="https://software.opensuse.org//download.html?project=utilities&amp;package=vmtouch">RHEL/OpenSUSE/SLE</a></li>
<li><a href="http://www.freshports.org/sysutils/vmtouch/">FreeBSD</a></li>
<li><a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=672696">Debian</a> (stalled)</li>
<li><a href="https://aur.archlinux.org/packages/vmtouch/">Arch Linux</a></li>
<li><a href="https://packages.gentoo.org/packages/dev-util/vmtouch">Gentoo Linux</a></li>
<li><a href="https://launchpad.net/~pg-radadia/+archive/ubuntu/vmtouch">Ubuntu PPA</a></li>
</ul>

<h3>Non-english</h3>

<ul>
<li>Spanish: <a href="http://blog.renzocolnago.com/as-tecnologias-que-rodam-o-instagram/">1</a></li>
<li>French: <a href="http://www.gcu-squad.org/2012/04/u-cant-vmtouch-this/">1</a> <a href="https://wiki.koumbit.net/VmTouch">2</a></li>
<li>Chinese: <a href="http://blog.chinaunix.net/uid-20662820-id-3480240.html">1</a> <a href="http://blog.sina.com.cn/s/blog_56c9b55c0101195u.html">2</a> <a href="http://www.damndigital.com/archives/39684">3</a> <a href="http://blog.yufeng.info/archives/1903">4</a> <a href="http://anykoro.sinaapp.com/2012/11/25/ramdisk-vmtouch-and-mlock/">5</a> <a href="http://xiezhenye.com/2013/05/mongodb-%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8.html">6</a></li>
<li>Russian: <a href="http://users.livejournal.com/_winnie/353678.html">1</a> <a href="http://habrahabr.ru/company/yandex/blog/231957/">2</a> <a href="http://bulimov.ru/it/meminfo-visualizer/">3</a></li>
<li>Polish: <a href="https://nfsec.pl/root/4694">1</a></li>
</ul>

<h3>Misc</h3>

<ul>
<li><a href="https://www.openhub.net/p/vmtouch">OpenHub</a></li>
<li><a href="https://github.com/uhub/awesome-c">Awesome C directory</a></li>
<li><a href="http://thefiringline.com/library/compsec.html">Computer Security Resources</a></li>
</ul>

<h3>Other tools</h3>

<ul>
<li><a href="https://code.google.com/p/linux-ftools/">linux-ftools</a></li>
<li><a href="https://github.com/caisonglu/cachemaster">cachemaster</a> (inspired by vmtouch)</li>
<li><a href="https://github.com/tobert/pcstat">pcstat</a></li>
<li><a href="https://github.com/datenwolf/fmlock">fmlock</a></li>
<li><a href="https://github.com/Feh/nocache/">nocache</a></li>
<li><a href="http://manpages.ubuntu.com/manpages/ureadahead.8.html">ureadahead</a></li>
</ul>

<p>There are also lots of mentions on twitter using the <a href="https://twitter.com/hashtag/vmtouch">#vmtouch</a> hash-tag</p>

<p>Have another link? Please <a href="https://hoytech.com/about">let me know</a>!</p>

<h2>Author</h2>

<p>vmtouch is copyright (c) 2009-2017 Doug Hoyte and contributors.</p>

<p>Contributors are listed in <a href="https://github.com/hoytech/vmtouch/blob/master/CHANGES">CHANGES</a>.</p>

      </div></div>]]>
            </description>
            <link>https://hoytech.com/vmtouch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197904</guid>
            <pubDate>Tue, 24 Nov 2020 12:39:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quake III Arena, K3s and a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197850">thread link</a>) | @alexellisuk
<br/>
November 24, 2020 | https://johansiebens.dev/posts/2020/11/quake-iii-arena-k3s-and-a-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://johansiebens.dev/posts/2020/11/quake-iii-arena-k3s-and-a-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<figure>
    <img src="https://johansiebens.dev/uploads/2020-11-22/quake_iii_arena_.png"> 
</figure>


<p>Yesterday I saw this tweet of Chris Campbell passing by in my timeline:</p>



<p>Aah, the memories. Quake III Arena, one of my favourite first-person shooter games.</p>

<p>Years ago, I spent (and lost) so much time playing this fast-paced game with friends and foes, and now it is brought into the world of containers and Kubernetes with <strong><a href="https://github.com/criticalstack/quake-kube" target="_blank">QuakeKube</a></strong> by <a href="https://twitter.com/CapitalOneTech" target="_blank">Capital One Tech</a>.</p>

<blockquote>
<p><em>QuakeKube is a Kubernetes-ified version of</em> <a href="https://github.com/inolen/quakejs" target="_blank"><em>QuakeJS</em></a> <em>that runs a dedicated</em> <a href="https://en.wikipedia.org/wiki/Quake_III_Arena" target="_blank"><em>Quake 3</em></a> <em>server in a Kubernetes Deployment, and then allow clients to connect via QuakeJS in the browser.</em></p>
</blockquote>

<p>Of course, I couldn’t wait to give it a try, especially after reading the documentation, saying:</p>

<blockquote>
<p><em>Container images are being cross-compiled with</em> <a href="https://docs.docker.com/buildx/working-with-buildx/" target="_blank"><em>Docker Buildx</em></a> <em>so it can run on hardware with different architectures and operating systems. Currently, it is building for <code>linux/amd64</code> and <code>linux/arm64</code>.</em></p>
</blockquote>

<p><strong>ARM64 support!</strong> Great, it means I can run it on one of my Raspberry Pis!</p>

<h2 id="let-s-get-fragging">Let’s get fragging!</h2>

<p>Most of the work is already done by others, so with the proper tools and projects, it will take you only a few minutes to get everything up and running.</p>

<h3 id="prerequisites">Prerequisites</h3>

<ul>
<li>a Raspberry Pi with Ubuntu 20.04, which supports arm64<br></li>
<li><code>k3sup</code>, a light-weight utility to get from zero to KUBECONFIG with k3s on any local or remote VM.<br></li>
<li><code>arkade</code>, a simple Golang CLI with strongly-typed flags to install charts and apps to your cluster in one command.<br></li>
<li><code>kubectl</code><br></li>
<li>a DigitalOcean account and an API Token</li>
</ul>

<h3 id="installation">Installation</h3>

<p>First, install <code>k3s</code> on your Raspberry Pi running a arm64 OS like Ubuntu 20.04</p>
<div><pre><code data-lang="bash">$ k3sup install --ip <span>192</span>.168.0.52 --user ubuntu --k3s-extra-args <span>'--no-deploy servicelb --no-deploy traefik'</span></code></pre></div>
<p>After the installation of k3s on the Raspberry Pi, k3sup also downloads the required kubeconfig file in your current working directory.<br>
Make sure to configure <code>kubectl</code> to use this config file:</p>
<div><pre><code data-lang="bash">$ export KUBECONFIG<span>=</span><span>$(</span>pwd<span>)</span>/kubeconfig</code></pre></div>
<p>Next, install the inlets-operator with <code>arkade</code>:</p>
<div><pre><code data-lang="bash">$ arkade install inlets-operator --provider digitalocean --token-file ~/do-api-token</code></pre></div>
<p>The inlets-operator will create an inlets exit-node on DigitalOcean, giving the LoadBalancer services in the private k3s cluster a public IP address.</p>

<p>As clients connect to the server via QuakeJS in the browser with websockets, the OSS version of inlets will do just fine. If you want to have better support for TLS etc, I can highly recommend having a look at inlets PRO version.</p>

<p>Finally, take the example yaml file from the QuakeKube GitHub repository and make the appropriate changes. The service should be updated to a LoadBalancer instead of type NodePort, and of course you can change the configuration to tweak the game preferences to your own needs.</p>

<p>Example of a QuakeKube yaml file:</p>
<div><pre><code data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: quakejs
spec:
  selector:
    matchLabels:
      run: quakejs
  replicas: <span>1</span>
  template:
    metadata:
      labels:
        run: quakejs
      annotations:
        prometheus.io/scrape: <span>'true'</span>
        prometheus.io/port: <span>'8080'</span>
    spec:
      containers:
      - command:
        - q3
        - server
        - --config=/config/config.yaml
        - --content-server=http://localhost:<span>9090</span>
        - --agree-eula
        image: docker.io/criticalstack/quake:v1.<span>0.5</span>
        name: server
        ports:
        - containerPort: <span>8080</span>
        readinessProbe:
          tcpSocket:
            port: <span>8080</span>
          initialDelaySeconds: <span>15</span>
          periodSeconds: <span>5</span>
        volumeMounts:
        - name: quake3-server-config
          mountPath: /config
        - name: quake3-content
          mountPath: /assets
      - command:
        - q3
        - content
        - --seed-content-url=http://content.quakejs.com
        image: docker.io/criticalstack/quake:v1.<span>0.5</span>
        name: content-server
        ports:
        - containerPort: <span>9090</span>
        volumeMounts:
        - name: quake3-content
          mountPath: /assets
      volumes:
        - name: quake3-server-config
          configMap:
            name: quake3-server-config
        - name: quake3-content
          emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: quakejs
spec:
  type: LoadBalancer
  selector:
    run: quakejs
  ports:
    - port: <span>80</span>
      targetPort: <span>8080</span>
      name: http
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: quake3-server-config
data:
  config.yaml: <span>|
</span><span>    fragLimit: 25</span>
    timeLimit: 15m
    bot:
      minPlayers: <span>3</span>
    game:
      motd: <span>"Welcome to Critical Stack"</span>
      type: FreeForAll
      forceRespawn: <span>false</span>
      inactivity: 10m
      quadFactor: <span>3</span>
      weaponRespawn: <span>3</span>
    server:
      hostname: <span>"quakekube"</span>
      maxClients: <span>12</span>
      password: <span>"changeme"</span>
    commands:
      - addbot sarge <span>2</span>
    maps:
    - name: q3dm7
      type: FreeForAll
      timeLimit: 10m
    - name: q3dm17
      type: FreeForAll
    - name: q3wctf1
      type: CaptureTheFlag
      captureLimit: <span>8</span>
    - name: q3tourney2
      type: Tournament
    - name: q3wctf3
      type: CaptureTheFlag
      captureLimit: <span>8</span>
    - name: ztn3tourney1
      type: Tournament</code></pre></div>
<p>Apply the yaml manifest to your k3s cluster:</p>
<div><pre><code data-lang="bash">$ kubectl apply -f example.yaml 
deployment.apps/quakejs created
service/quakejs created
configmap/quake3-server-config created</code></pre></div>
<p>Wait until all pods are running, and until the inlets-operator created the exit-node:</p>
<div><pre><code data-lang="bash">$ kubectl get pods,service
NAME                                         READY   STATUS    RESTARTS   AGE
pod/inlets-operator-76fb794578-s2fg4         <span>1</span>/1     Running   <span>0</span>          147m
pod/quakejs-tunnel-client-6f7c986dfc-mdt5w   <span>1</span>/1     Running   <span>0</span>          50s
pod/quakejs-786cc496b-g7b7n                  <span>2</span>/2     Running   <span>0</span>          80s

NAME                 TYPE           CLUSTER-IP    EXTERNAL-IP                       PORT<span>(</span>S<span>)</span>        AGE
service/kubernetes   ClusterIP      <span>10</span>.43.0.1     &lt;none&gt;                            <span>443</span>/TCP        152m
service/quakejs      LoadBalancer   <span>10</span>.43.46.33   <span>143</span>.110.174.204,143.110.174.204   <span>80</span>:32116/TCP   80s</code></pre></div>
<p>And that’s it! Open up your favourite browser, load the application and start fraggin’!</p>

<figure>
    <img src="https://johansiebens.dev/uploads/2020-11-22/quakejs.png"> 
</figure>




<hr>

<p><strong>References:</strong></p>

<ul>
<li><a href="https://github.com/criticalstack/quake-kube" target="_blank">https://github.com/criticalstack/quake-kube</a><br></li>
<li><a href="https://github.com/inlets/inlets-operator" target="_blank">https://github.com/inlets/inlets-operator</a><br></li>
<li><a href="https://github.com/alexellis/k3sup" target="_blank">https://github.com/alexellis/k3sup</a><br></li>
<li><a href="https://github.com/alexellis/arkade" target="_blank">https://github.com/alexellis/arkade</a><br></li>
</ul>

      </div></div>]]>
            </description>
            <link>https://johansiebens.dev/posts/2020/11/quake-iii-arena-k3s-and-a-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197850</guid>
            <pubDate>Tue, 24 Nov 2020 12:34:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything Curl – Trace Options]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197836">thread link</a>) | @kristianpaul
<br/>
November 24, 2020 | https://ec.haxx.se/usingcurl/usingcurl-verbose/usingcurl-trace | <a href="https://web.archive.org/web/*/https://ec.haxx.se/usingcurl/usingcurl-verbose/usingcurl-trace">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="a6ef002b560e4352b590a3456afb72f4" autocorrect="on" spellcheck="true" data-gramm="false"><p data-key="19ab964dd5104d0e96746d1e9325ab76"><span><span data-key="c47a63eb63b94ec497e15ed367a3313b"><span data-offset-key="c47a63eb63b94ec497e15ed367a3313b:0">There are times when </span><span data-offset-key="c47a63eb63b94ec497e15ed367a3313b:1"><code spellcheck="false" data-slate-leaf="true">-v</code></span><span data-offset-key="c47a63eb63b94ec497e15ed367a3313b:2"> is not enough. In particular, when you want to store the complete stream including the actual transferred data.</span></span></span></p><p data-key="ebacf752bc4a4890967ec23222938013"><span><span data-key="79f7332dd6bf466aacd76677ded40423"><span data-offset-key="79f7332dd6bf466aacd76677ded40423:0">For situations when curl does encrypted file transfers with protocols such as HTTPS, FTPS or SFTP, other network monitoring tools (like Wireshark or tcpdump) will not be able to do this job as easily for you.</span></span></span></p><p data-key="58ba64ab45d8412da695e15d71709c8a"><span><span data-key="388656d103e64ea080c159503ff14673"><span data-offset-key="388656d103e64ea080c159503ff14673:0">For this, curl offers two other options that you use instead of </span><span data-offset-key="388656d103e64ea080c159503ff14673:1"><code spellcheck="false" data-slate-leaf="true">-v</code></span><span data-offset-key="388656d103e64ea080c159503ff14673:2">.</span></span></span></p><p data-key="da7a8717ac1c470eae69cbe4790ce6ce"><span><span data-key="971b082de53d4f43b1fbd479951ad5dd"><span data-offset-key="971b082de53d4f43b1fbd479951ad5dd:0"><code spellcheck="false" data-slate-leaf="true">--trace [filename]</code></span><span data-offset-key="971b082de53d4f43b1fbd479951ad5dd:1"> will save a full trace in the given file name. You can also use '-' (a single minus) instead of a file name to get it passed to stdout. You would use it like this:</span></span></span></p><div><pre data-key="4cbf6e9356b64ff484fb8d13de5929bc" spellcheck="false"><p><span data-key="b9ee5fdba4e84b738b41fa1c7f15fff2"><span data-offset-key="b9ee5fdba4e84b738b41fa1c7f15fff2:0">$ curl --trace dump http://example.com</span></span></p></pre></div><p data-key="405e863d115f431dadbf90deed491cf9"><span><span data-key="005bd2da5cdc4f1485025d85c8f20bf3"><span data-offset-key="005bd2da5cdc4f1485025d85c8f20bf3:0">When completed, there's a 'dump' file that can turn out pretty sizable. In this case, the 15 first lines of the dump file looks like:</span></span></span></p><div><pre data-key="0e0c49cd57b2442fac8b95477d19da3f" spellcheck="false"><p><span data-key="44ae1b41de7f46f991bf292597d73863"><span data-offset-key="44ae1b41de7f46f991bf292597d73863:0">== Info: Rebuilt URL to: http://example.com/</span></span></p><p><span data-key="6fed896d67624b529a0fdd3edf7203d2"><span data-offset-key="6fed896d67624b529a0fdd3edf7203d2:0">== Info:   Trying 93.184.216.34...</span></span></p><p><span data-key="4404aae5e0284eca86045739a019584a"><span data-offset-key="4404aae5e0284eca86045739a019584a:0">== Info: Connected to example.com (93.184.216.34) port 80 (#0)</span></span></p><p><span data-key="a91c13b6fb19420899f0ba554ad791c0"><span data-offset-key="a91c13b6fb19420899f0ba554ad791c0:0">=&gt; Send header, 75 bytes (0x4b)</span></span></p><p><span data-key="c6f46dbe7f4f488f92bb4a297ef5052a"><span data-offset-key="c6f46dbe7f4f488f92bb4a297ef5052a:0">0000: 47 45 54 20 2f 20 48 54 54 50 2f 31 2e 31 0d 0a GET / HTTP/1.1..</span></span></p><p><span data-key="3c91a889a2fe43a0a667319325baa522"><span data-offset-key="3c91a889a2fe43a0a667319325baa522:0">0010: 48 6f 73 74 3a 20 65 78 61 6d 70 6c 65 2e 63 6f Host: example.co</span></span></p><p><span data-key="2e97d4ff01da467d85992911f65474a3"><span data-offset-key="2e97d4ff01da467d85992911f65474a3:0">0020: 6d 0d 0a 55 73 65 72 2d 41 67 65 6e 74 3a 20 63 m..User-Agent: c</span></span></p><p><span data-key="5ef52f20d4114d228d1bf5d3c67708a1"><span data-offset-key="5ef52f20d4114d228d1bf5d3c67708a1:0">0030: 75 72 6c 2f 37 2e 34 35 2e 30 0d 0a 41 63 63 65 url/7.45.0..Acce</span></span></p><p><span data-key="3984e066f33645678f4330fce9d9658b"><span data-offset-key="3984e066f33645678f4330fce9d9658b:0">0040: 70 74 3a 20 2a 2f 2a 0d 0a 0d 0a                pt: */*....</span></span></p><p><span data-key="393ecd26a68e4a88998c7e654e2b8fdb"><span data-offset-key="393ecd26a68e4a88998c7e654e2b8fdb:0">&lt;= Recv header, 17 bytes (0x11)</span></span></p><p><span data-key="8b97f7554ac14ffa92725f4d1ce50791"><span data-offset-key="8b97f7554ac14ffa92725f4d1ce50791:0">0000: 48 54 54 50 2f 31 2e 31 20 32 30 30 20 4f 4b 0d HTTP/1.1 200 OK.</span></span></p><p><span data-key="48514fc4c23648779fcbd53d72ae53df"><span data-offset-key="48514fc4c23648779fcbd53d72ae53df:0">0010: 0a                                              .</span></span></p><p><span data-key="7118cb05b71540edbdd422769bb1d41c"><span data-offset-key="7118cb05b71540edbdd422769bb1d41c:0">&lt;= Recv header, 22 bytes (0x16)</span></span></p><p><span data-key="eedfedbbe314499f904e81cad9e260c6"><span data-offset-key="eedfedbbe314499f904e81cad9e260c6:0">0000: 41 63 63 65 70 74 2d 52 61 6e 67 65 73 3a 20 62 Accept-Ranges: b</span></span></p><p><span data-key="7a13f50dcfd74da5aff6f4598e00f943"><span data-offset-key="7a13f50dcfd74da5aff6f4598e00f943:0">0010: 79 74 65 73 0d 0a                               ytes..</span></span></p></pre></div><p data-key="e1381af0207e449a94931cb2b99773da"><span><span data-key="40a899c38f7b4a98a7387c1526a19730"><span data-offset-key="40a899c38f7b4a98a7387c1526a19730:0">Every single sent and received byte get displayed individually in hexadecimal numbers.</span></span></span></p><p data-key="3be1a1fe222a45b39a27341b6371848c"><span><span data-key="aa4dc13ee63040aab0c0303f6f7e5650"><span data-offset-key="aa4dc13ee63040aab0c0303f6f7e5650:0">If you think the hexadecimals are not helping, you can try </span><span data-offset-key="aa4dc13ee63040aab0c0303f6f7e5650:1"><code spellcheck="false" data-slate-leaf="true">--trace-ascii [filename]</code></span><span data-offset-key="aa4dc13ee63040aab0c0303f6f7e5650:2"> instead, also this accepting '-' for stdout and that makes the 15 first lines of tracing look like:</span></span></span></p><div><pre data-key="22868136a84e4e15810fefe740495ec8" spellcheck="false"><p><span data-key="9e299d2991d6426ba442339ee9e9f139"><span data-offset-key="9e299d2991d6426ba442339ee9e9f139:0">== Info: Rebuilt URL to: http://example.com/</span></span></p><p><span data-key="80b9bc8a91c2435bb40fba6cb5dfa9ff"><span data-offset-key="80b9bc8a91c2435bb40fba6cb5dfa9ff:0">== Info:   Trying 93.184.216.34...</span></span></p><p><span data-key="149c766c24ed40f386d75b401156ae33"><span data-offset-key="149c766c24ed40f386d75b401156ae33:0">== Info: Connected to example.com (93.184.216.34) port 80 (#0)</span></span></p><p><span data-key="2eb4b3433be241cf9d8eb7187f2f7e0b"><span data-offset-key="2eb4b3433be241cf9d8eb7187f2f7e0b:0">=&gt; Send header, 75 bytes (0x4b)</span></span></p><p><span data-key="19e16419fc4a4a18967d864bd04c66c0"><span data-offset-key="19e16419fc4a4a18967d864bd04c66c0:0">0000: GET / HTTP/1.1</span></span></p><p><span data-key="e1bda71508224e9fb07f75c1910e48ab"><span data-offset-key="e1bda71508224e9fb07f75c1910e48ab:0">0010: Host: example.com</span></span></p><p><span data-key="b2b1088640fd4ae5ab0cc1b6ca6483be"><span data-offset-key="b2b1088640fd4ae5ab0cc1b6ca6483be:0">0023: User-Agent: curl/7.45.0</span></span></p><p><span data-key="d6d0ce807724460789e6ebb6f6e892ec"><span data-offset-key="d6d0ce807724460789e6ebb6f6e892ec:0">003c: Accept: */*</span></span></p><p><span data-key="a78aa7be8d554fa6a96f7c9d6ffbfa23"><span data-offset-key="a78aa7be8d554fa6a96f7c9d6ffbfa23:0">0049:</span></span></p><p><span data-key="39c0feb1902f44e1a5510b833f89f811"><span data-offset-key="39c0feb1902f44e1a5510b833f89f811:0">&lt;= Recv header, 17 bytes (0x11)</span></span></p><p><span data-key="872de778b8e54a4ca78408bb59ad8477"><span data-offset-key="872de778b8e54a4ca78408bb59ad8477:0">0000: HTTP/1.1 200 OK</span></span></p><p><span data-key="7219088e0db041a686b8de990b9ce04c"><span data-offset-key="7219088e0db041a686b8de990b9ce04c:0">&lt;= Recv header, 22 bytes (0x16)</span></span></p><p><span data-key="fb7b2cac706844fabd0b49ed2853a9b4"><span data-offset-key="fb7b2cac706844fabd0b49ed2853a9b4:0">0000: Accept-Ranges: bytes</span></span></p><p><span data-key="73d1394550f4418c8c83309c8fe64c6c"><span data-offset-key="73d1394550f4418c8c83309c8fe64c6c:0">&lt;= Recv header, 31 bytes (0x1f)</span></span></p><p><span data-key="f69380f0d894401199a175232fb1082d"><span data-offset-key="f69380f0d894401199a175232fb1082d:0">0000: Cache-Control: max-age=604800</span></span></p></pre></div><p data-key="21a030a4b3934ff086e961b01bacf8c5"><span><span data-key="45a9708d34fa4752b596d88b6c328371"><span data-offset-key="45a9708d34fa4752b596d88b6c328371:0">This options prefixes all verbose/trace outputs with a high resolution timer for when the line is printed. It works with the regular </span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:1"><code spellcheck="false" data-slate-leaf="true">-v / --verbose</code></span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:2"> option as well as with </span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:3"><code spellcheck="false" data-slate-leaf="true">--trace</code></span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:4"> and </span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:5"><code spellcheck="false" data-slate-leaf="true">--trace-ascii</code></span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:6">.</span></span></span></p><p data-key="7dbd3d9e6be64569ae4ebfea8bdc44bf"><span><span data-key="d1a95ff5f69a4df297db6d12ca769d30"><span data-offset-key="d1a95ff5f69a4df297db6d12ca769d30:0">An example could look like this:</span></span></span></p><div><pre data-key="f3da03e1fe2f4e2dac6c9f1e40521e40" spellcheck="false"><p><span data-key="cacf73c781794099a94f5b902e53b860"><span data-offset-key="cacf73c781794099a94f5b902e53b860:0">$ curl -v --trace-time http://example.com</span></span></p><p><span data-key="1276cd54ea564f18b7a06b52900c17c6"><span data-offset-key="1276cd54ea564f18b7a06b52900c17c6:0">23:38:56.837164 * Rebuilt URL to: http://example.com/</span></span></p><p><span data-key="b13c21a8314e458baeee201b73f970e2"><span data-offset-key="b13c21a8314e458baeee201b73f970e2:0">23:38:56.841456 *   Trying 93.184.216.34...</span></span></p><p><span data-key="5ef410ea4c8a4361bf582f6d3a529375"><span data-offset-key="5ef410ea4c8a4361bf582f6d3a529375:0">23:38:56.935155 * Connected to example.com (93.184.216.34) port 80 (#0)</span></span></p><p><span data-key="0217c735977049c1a784a28bf069dfce"><span data-offset-key="0217c735977049c1a784a28bf069dfce:0">23:38:56.935296 &gt; GET / HTTP/1.1</span></span></p><p><span data-key="3e04d627753b4d09a993df6cffa6957f"><span data-offset-key="3e04d627753b4d09a993df6cffa6957f:0">23:38:56.935296 &gt; Host: example.com</span></span></p><p><span data-key="4bcff79e2b814cce8580b3e7b6bdd83b"><span data-offset-key="4bcff79e2b814cce8580b3e7b6bdd83b:0">23:38:56.935296 &gt; User-Agent: curl/7.45.0</span></span></p><p><span data-key="a36dc28f81b44594bb976f8fcccf8f88"><span data-offset-key="a36dc28f81b44594bb976f8fcccf8f88:0">23:38:56.935296 &gt; Accept: */*</span></span></p><p><span data-key="fe46ebea85294730aa0343db560b267e"><span data-offset-key="fe46ebea85294730aa0343db560b267e:0">23:38:56.935296 &gt;</span></span></p><p><span data-key="84569ebfbf29412baf4978628e7be2ce"><span data-offset-key="84569ebfbf29412baf4978628e7be2ce:0">23:38:57.029570 &lt; HTTP/1.1 200 OK</span></span></p><p><span data-key="4fea7818e129445397f0d80923b92786"><span data-offset-key="4fea7818e129445397f0d80923b92786:0">23:38:57.029699 &lt; Accept-Ranges: bytes</span></span></p><p><span data-key="924e7f8c5f434d6288a907642f83342b"><span data-offset-key="924e7f8c5f434d6288a907642f83342b:0">23:38:57.029803 &lt; Cache-Control: max-age=604800</span></span></p><p><span data-key="c05e4aa2dae740dc955924488c78a2f0"><span data-offset-key="c05e4aa2dae740dc955924488c78a2f0:0">23:38:57.029903 &lt; Content-Type: text/html</span></span></p><p><span data-key="479f1288467c414a92097deb991b5fa5"><span data-offset-key="479f1288467c414a92097deb991b5fa5:0">---- snip ----</span></span></p></pre></div><p data-key="6fa17657da7c4b9fb344c095331193e5"><span><span data-key="4c19bbee96c14e618d2e5b80ae437f5b"><span data-offset-key="4c19bbee96c14e618d2e5b80ae437f5b:0">The lines are all the local time as hours:minutes:seconds and then number of microseconds in that second.</span></span></span></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://ec.haxx.se/usingcurl/usingcurl-verbose/usingcurl-trace</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197836</guid>
            <pubDate>Tue, 24 Nov 2020 12:31:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[School Supplies, Loop Pedals, and Tips for Zoom Open-Mic Nights]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197814">thread link</a>) | @whatrocks
<br/>
November 24, 2020 | https://www.charlieharrington.com/school-supplies | <a href="https://web.archive.org/web/*/https://www.charlieharrington.com/school-supplies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h3>2020-11-16</h3><div><p>Somedays I remember that I have a <a href="https://amzn.to/2H8SH8O">loop pedal</a>.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/b6492df4a2d5144202ebc69c5d29b21b/669cd/loop.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="loop pedal" title="loop pedal" src="https://www.charlieharrington.com/static/b6492df4a2d5144202ebc69c5d29b21b/a6d36/loop.png" srcset="https://www.charlieharrington.com/static/b6492df4a2d5144202ebc69c5d29b21b/222b7/loop.png 163w,
https://www.charlieharrington.com/static/b6492df4a2d5144202ebc69c5d29b21b/ff46a/loop.png 325w,
https://www.charlieharrington.com/static/b6492df4a2d5144202ebc69c5d29b21b/a6d36/loop.png 650w,
https://www.charlieharrington.com/static/b6492df4a2d5144202ebc69c5d29b21b/e548f/loop.png 975w,
https://www.charlieharrington.com/static/b6492df4a2d5144202ebc69c5d29b21b/3c492/loop.png 1300w,
https://www.charlieharrington.com/static/b6492df4a2d5144202ebc69c5d29b21b/669cd/loop.png 3024w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p>Those are the best sorts of days.</p>
<p>Somedays that leads to a new song.</p>
<h3>School Supplies</h3>
<p>Hello, world, this is your premiere of SCHOOL SUPPLIES, the third single off my forthcoming EP: "Greetings From Buttzville, NJ":</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/o57rqh88CJY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p>The chords, for those interested (looking at you, The Grones) are:</p>
<div data-language="text"><pre><code>Verse
G Bm Em C

Chorus
D G C

Outro(key change!)
A C#m F#m D</code></pre></div>
<p>That's right! I pulled off my first key change. Thank you, Taylor Swift "Love Song" for the daily inspiration.</p>
<p>I'll leave the lyrics as an exercise for the reader.</p>
<h4>Uncle Mike's Tips for Running a Zoom-Based Open Mic Night</h4>
<p>Big thanks to Uncle Mike for organizing our second Zoom family open mic night. He runs a tight ship, mostly trying to prevent me from launching into a <a href="https://www.charlieharrington.com/bullet-train-to-merlins-grave">Bullet Train to Merlin's Grave medley like at Popestock</a>.</p>
<p>To paraphrase his tips:</p>
<ul>
<li>Each performer gets one song, of "normal song length" (so that means no Tubular Bells)</li>
<li>Announce the order in advance</li>
<li>Tune up your instrument when you're on deck or in the hole</li>
<li>Don't worry about messing up, start over if you need to, this is fun. Music is the best!</li>
<li>Change your zoom settings to "Original Sound"</li>
</ul>
<p>This last one is key. Zoom does some "stuff" to make things sound "good" during boring work meetings that are boring. It's not optimized for fun singalongs that are fun. So, it's pretty much essential to <a href="https://support.zoom.us/hc/en-us/articles/115003279466-Enabling-option-to-preserve-original-sound">follow these steps</a> when you're singing and strumming over Zoom, unless you're trying to incorporate cosmic waves of hollow nothingness into your jam. Maybe you are?</p>
<p>Oh, you should check out Uncle Mike's music podcast, <a href="https://www.tellyouwhatpodcast.com/">Tell You What! The Podcast</a>. He interviews young musicians and bands on the run and it's fun and great and keeps you on your toes with new upcoming artists.</p>
<p>As Uncle Mike says, music is the best!</p></div><div><p>The almost-never newsletter. I won't spam you, and you can unsubscribe anytime.</p></div></div></div></div>]]>
            </description>
            <link>https://www.charlieharrington.com/school-supplies</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197814</guid>
            <pubDate>Tue, 24 Nov 2020 12:28:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Live SaaS growth feedback with Sujan Patel]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197772">thread link</a>) | @tomhuntio
<br/>
November 24, 2020 | https://saasmarketer.io/ep-015-sujan-patel-shares-4-saas-growth-strategies-for-bcast/ | <a href="https://web.archive.org/web/*/https://saasmarketer.io/ep-015-sujan-patel-shares-4-saas-growth-strategies-for-bcast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                  <div>
                  	<div>
		
<article id="post-1946">
	<!-- .entry-header -->

	
	
		<p><img width="1200" height="628" src="https://saasmarketer.io/wp-content/uploads/2020/11/Sujan-Patel-SaaS-Marketer-FB-Thumbnail.jpg" alt="" loading="lazy" srcset="https://saasmarketer.io/wp-content/uploads/2020/11/Sujan-Patel-SaaS-Marketer-FB-Thumbnail.jpg 1200w, https://saasmarketer.io/wp-content/uploads/2020/11/Sujan-Patel-SaaS-Marketer-FB-Thumbnail-300x157.jpg 300w, https://saasmarketer.io/wp-content/uploads/2020/11/Sujan-Patel-SaaS-Marketer-FB-Thumbnail-1024x536.jpg 1024w, https://saasmarketer.io/wp-content/uploads/2020/11/Sujan-Patel-SaaS-Marketer-FB-Thumbnail-768x402.jpg 768w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 60vw, (max-width: 1362px) 62vw, 840px">	</p><!-- .post-thumbnail -->

		<p>
	Content, Partnerships</p>

	<div>
		
<p>Or listen on:</p>
<ul>
<li><a href="https://podcasts.apple.com/us/podcast/confessions-of-a-b2b-marketer/id1504044930" target="_blank" rel="noopener noreferrer">Apple Podcasts</a></li>
<li><a href="https://open.spotify.com/show/7Ko5WPGfuyueiphdlRGAES" target="_blank" rel="noopener noreferrer">Spotify</a></li>
<li><a href="https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy5iY2FzdC5mbS9jb25mZXNzaW9ucy1vZi1hLWIyYi1tYXJrZXRlcg" target="_blank" rel="noopener noreferrer">Google Podcasts</a></li>
</ul>
<hr>
<p>After our <a href="https://saasmarketer.io/ep-014-300k-sessions-per-month-with-sujan-patel-of-mailshake/" target="_blank" rel="noopener noreferrer">previous episode</a>, Sujan causally mentioned that he would love to talk further about growing bCast…</p>
<p>I jumped at the chance and asked Sujan if he would be happy to record them: he was.</p>
<p>We didn’t speak about it again until we jumped on another call to record… I think Sujan did approx. 5 minutes of research before. He then proceeded to brain dump 4 MASSIVE growth strategies for bCast:</p>
<ul>
<li><span> Focus on features that help existing customers GROW</span></li>
<li><span> 10x SEO volume</span></li>
<li><span> Pure backlink hustle</span></li>
<li><span> Get to know the influences</span></li>
</ul>
<p>We could have gone on for another 30 minutes, but we only had 30 minutes to record.</p>
<p>Each of these have been put into practice since we recorded approx. a week ago and I will update you with how we do right here on this blog. We may even bring Sujan back on in 6-12 months to debrief on progress.</p>
<p>Check out:</p>
<ul>
<li><a href="https://sujanpatel.com/" target="_blank" rel="noopener noreferrer">Sujan’s blog</a></li>
<li><a href="https://twitter.com/sujanpatel" target="_blank" rel="noopener noreferrer">Sujan’s Twitter</a></li>
<li><a href="https://mailshake.com/" target="_blank" rel="noopener noreferrer">Mailshake</a></li>
</ul>
<p>Also… thanks for reading/listening and of course… if you jump over to <a href="https://podcasts.apple.com/us/podcast/confessions-of-a-b2b-marketer/id1504044930" target="_blank" rel="noopener noreferrer">Apple</a> and leave a review… always, if you can leave a review I will get you and your business a shout out on the show!</p>
<hr>
<p>This episode is brought to you by <a href="https://ahrefs.com/webmaster-tools?utm_source=email&amp;utm_medium=newsletter&amp;utm_content=saas_marketer" target="_blank" rel="noopener noreferrer">Ahrefs super, freaking, awesome, free Webmaster Tools</a>.</p>
<p>You can:</p>
<ul>
<li>Monitor the health of your site</li>
<li>Check for backlinks</li>
<li>See which keywords are working for you</li>
</ul>
<p>By simply signing up <a href="https://ahrefs.com/webmaster-tools?utm_source=email&amp;utm_medium=newsletter&amp;utm_content=saas_marketer" target="_blank" rel="noopener noreferrer">here</a>.</p>
<p>(+9026 people signed up in the past 7 days!)</p>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img alt="" src="https://secure.gravatar.com/avatar/a4824982d9a3d3b7f192b17948b4a36f?s=100&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/a4824982d9a3d3b7f192b17948b4a36f?s=200&amp;d=mm&amp;r=g 2x" height="100" width="100" itemprop="image" loading="lazy"></p><div><p>Tom Hunt is the founder of SaaS Marketer and bCast (B2B podcast hosting for high growth businesses). He lives and works in Hackney, London with his delightful partner Rebecca and little dog called Bear.</p></div></div>	</div><!-- .entry-content -->

	<!--<footer class="entry-footer">
		<span class="byline"><span class="author vcard"><img alt='' src='https://secure.gravatar.com/avatar/a4824982d9a3d3b7f192b17948b4a36f?s=49&#038;d=mm&#038;r=g' srcset='https://secure.gravatar.com/avatar/a4824982d9a3d3b7f192b17948b4a36f?s=98&#038;d=mm&#038;r=g 2x' class='avatar avatar-49 photo' height='49' width='49' loading='lazy'/><span class="screen-reader-text">Author </span> <a class="url fn n" href="https://saasmarketer.io/administrator/tom-hunt/">Tom Hunt</a></span></span><span class="posted-on"><span class="screen-reader-text">Posted on </span><a href="https://saasmarketer.io/ep-015-sujan-patel-shares-4-saas-growth-strategies-for-bcast/" rel="bookmark"><time class="entry-date published" datetime="2020-11-24T11:46:21+00:00">11/24/2020</time><time class="updated" datetime="2020-11-24T11:57:32+00:00">11/24/2020</time></a></span><span class="cat-links"><span class="screen-reader-text">Categories </span><a href="https://saasmarketer.io/category/content/" rel="category tag">Content</a>, <a href="https://saasmarketer.io/category/partnerships/" rel="category tag">Partnerships</a></span><span class="tags-links"><span class="screen-reader-text">Tags </span><a href="https://saasmarketer.io/tag/listen/" rel="tag">Listen</a></span>			</footer>-->

	<!-- .entry-footer -->
</article><!-- #post-1946 -->


	</div>
    

</div>
</div></div>]]>
            </description>
            <link>https://saasmarketer.io/ep-015-sujan-patel-shares-4-saas-growth-strategies-for-bcast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197772</guid>
            <pubDate>Tue, 24 Nov 2020 12:22:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Configuring Git for Work]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197762">thread link</a>) | @fphilipe
<br/>
November 24, 2020 | https://phili.pe/posts/configuring-git-for-work/ | <a href="https://web.archive.org/web/*/https://phili.pe/posts/configuring-git-for-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><article>
  <header>
    
    <p>
      November 17, 2020
    </p>
  </header><p>You can override your globally configured email inside individual repositories, allowing you to use your work email for work-related repos. Setting this up for each repo—and remembering to do so—is cumbersome. Luckily, there is an easier way to accomplish this for all repos within a certain directory.</p>

<p>One of the first things you did when you set up Git was to configure your name and email:</p>

<pre><code>$ git config --global user.name "Jane Doe"
$ git config --global user.email jane@mail.com
</code></pre>

<p>The above commands added the following lines to your global Git configuration file <code>~/.gitconfig</code>:</p>

<pre><code><span>[user]</span>
	<span>name</span> <span>=</span> <span>Jane Doe</span>
	<span>email</span> <span>=</span> <span>jane@mail.com</span>
</code></pre>

<p>Each repository also has its own Git configuration located at <code>.git/config</code>. Configs in the local file take precedence over the global configs.</p>

<p>You can set configs in <code>.git/config</code> manually or by passing the <code>--local</code> flag to <code>git config</code>. Thus, if I want to use my work email in a specific repo, I need to set it as follows:</p>

<pre><code>$ git config --local user.email doe@acme.org
</code></pre>

<p>If you want to do this for all work repos, it gets a bit cumbersome. Above all, it’s easy to forget to do this for repos that you’ll clone or create in the future.</p>

<p>Fortunately, Git has a more scalable approach to this problem. You can <strong>conditionally</strong> include further Git config files based on the directory of a Git repo.</p>

<p>Let’s assume that all my work-related repos are inside the folder <code>~/Documents/Acme/repos/</code>.</p>

<p>First, I’ll create a separate Git config file <code>~/.gitconfig-work</code> that contains my work-related overrides:</p>

<pre><code><span>[user]</span>
	<span>email</span> <span>=</span> <span>doe@acme.org</span>
</code></pre>

<p>Then, I include this file from my global Git config file in <code>~/.gitconfig</code>:</p>

<pre><code><span>[includeIf "gitdir:~/Documents/Acme/repos"]</span>
	<span>path</span> <span>=</span> <span>.gitconfig-work</span>
</code></pre>

<p>It’s important to place above snippet <strong>at the end</strong> of your <code>~/.gitconfig</code> file because, according to the <a href="https://git-scm.com/docs/git-config">documentation on git-config</a>:</p>

<blockquote>
  <p>The contents of the included file are inserted immediately, as if they had been found at the location of the include directive.</p>
</blockquote>

<p>If we were to restructure our work directory, e.g. by changing <code>Acme</code> to <code>acme</code> or by moving the repositories somewhere else, such as to <code>~/repos/acme/</code>, the include directive would no longer apply. My newly created commits would now use my globally defined private email rather than my work email. Most likely, I wouldn’t even notice.</p>

<p>To prevent this from happening, we can generalize the path used in the include directive above. First, we can use <code>gitdir/i</code> to perform the matching case-insensitively. Further, there are a few assumptions around the path that can help us. From the <a href="https://git-scm.com/docs/git-config">docs</a>:</p>

<blockquote>
  <ul>
    <li>
      <p>If the pattern does not start with either <code>~/</code>, <code>./</code> or <code>/</code>, <code>**/</code> will be automatically prepended. For example, the pattern <code>foo/bar</code> becomes <code>**/foo/bar</code> and would match <code>/any/path/to/foo/bar</code>.</p>
    </li>
    <li>
      <p>If the pattern ends with <code>/</code>, <code>**</code> will be automatically added. For example, the pattern <code>foo/</code> becomes <code>foo/**</code>. In other words, it matches “foo” and everything inside, recursively.</p>
    </li>
  </ul>
</blockquote>

<p>Equipped with this knowledge, we can generalize the include directive so that it applies to any Git repository that is nested within a folder named after my company—case-insensitively, mind you:</p>

<pre><code><span>[includeIf "gitdir/i:acme/"]</span>
	<span>path</span> <span>=</span> <span>.gitconfig-work</span>
</code></pre>

<p>To verify that this is working, I can look up the resolved config value in a specific repo:</p>

<pre><code>$ cd ~/repos/private/my-project
$ git config user.email
jane@mail.com

$ cd ~/Documents/Acme/repos/website
$ git config user.email
doe@acme.org
</code></pre>

<hr>

<p>I encourage you to check out the <a href="https://git-scm.com/docs/git-config">git-config manual</a> (<code>git help config</code>). You’ll find some interesting things in there. For instance, an include directive can be conditional on the branch you’re currently on.</p>


  
</article>
    </div></div>]]>
            </description>
            <link>https://phili.pe/posts/configuring-git-for-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197762</guid>
            <pubDate>Tue, 24 Nov 2020 12:20:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Lucky with Posting on HN]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197696">thread link</a>) | @jhunter1016
<br/>
November 24, 2020 | https://samizdat.dev/getting-lucky-with-posting-on-hacker-news/ | <a href="https://web.archive.org/web/*/https://samizdat.dev/getting-lucky-with-posting-on-hacker-news/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>You know the feeling of watching your post quickly drowning in the Newest section of Hacker News, right?
It seems like pure, chaotic luck. Or is it?</p>
<p>I tried to crack the code of successful submissions.</p>
<p>I built a tool that parses Hacker News every two minutes and logs the state into the
database. The program has been working for <strong>14 days</strong> so far.</p>
<p>For the latest two weeks, there were <strong>13846</strong> stories, and only <strong>1403</strong> of them reached the first
page of Hacker News.</p>
<p>It’s <strong>10.1329</strong> percents. It doesn’t sound too bad, does it? It turns out <strong>every tenth story
hits the first page</strong>.</p>
<p><em>All time values are in UTC.</em></p>
<h2 id="stories-and-chances-to-hit-the-first-page">Stories and chances to hit the first page</h2>

<p>It seems like Saturday and Sunday are the least active days when it comes to new stories.
But it means you have the biggest chance to hit the first page during these days.</p>
<h2 id="total-number-of-stories-and-chances-by-hour">Total number of stories and chances by hour</h2>
<p>Let’s take a look what about best hours to publish then.</p>

<ul>
<li>I wouldn’t post at 15:00 - 16:00 since it’s the lowest chance to hit the first page. Too many
submissions during these hours.</li>
<li>11:00 - 12:00 looks like a good spot, everyone is getting awake and your post is already waiting
them on the first page.</li>
</ul>
<h2 id="votes-and-overall-activity">Votes and overall activity</h2>
<p>The watcher continuously checks Hacker News and logs the current position and the score of every
story into the database.</p>
<p>Let’s see what the most active days and hours were.</p>

<ul>
<li>Saturday and Sunday are the least active days.</li>
<li>Monday is the most active day.</li>
</ul>

<ul>
<li>00:00 - 10:00 are the least active hours</li>
<li>14:00 - 21:00 (UTC) are the most active hours on Hacker News.</li>
<li>15:00 - 19:00 (UTC) are the best hours.</li>
</ul>
<h2 id="finally-fun-facts">Finally, fun facts</h2>
<ul>
<li>48 stories hit the first page with literally 1 score point (you get it by default).</li>
<li>4 stories hit the first page with literally 2 score points.</li>
<li>590 stories needed 3 score points to appear on the first page.</li>
<li>318 stories needed 4 points.</li>
<li>143 stories needed 5 points.</li>
</ul>
<p>The longest living posts on the first page:</p>
<ul>
<li>65h13m56s  <a href="https://news.ycombinator.com/item?id=25154128">Flash Animations Live Forever at the Internet Archive </a></li>
<li>63h34m18s  <a href="https://news.ycombinator.com/item?id=25074959">macOS unable to open any non-Apple application</a></li>
<li>49h17m45s  <a href="https://news.ycombinator.com/item?id=25044254">Zoom lied to users about end-to-end encryption for years, FTC says</a></li>
<li>45h29m29s  <a href="https://news.ycombinator.com/item?id=25031491">Japan’s Onryō Spirits Inhabit a Purgatory of Revenge and Cosmic Rage </a></li>
<li>45h26m48s  <a href="https://news.ycombinator.com/item?id=25042002">Large-scale multilingual audio visual dubbing </a></li>
</ul>
<p>I’m going to analyze the statistics even further, it’s just a matter of time.</p>
<p><strong>Follow me on Twitter to get updates: <a href="https://twitter.com/reconquestio">@reconquestio</a></strong></p>
<p>Have an idea or want to contribute? Tweet/Email me.</p>
<h2 id="missing-charts">Missing charts</h2>
<ul>
<li>
<p>The watcher records the position of stories on the page and this data is not illustrated on the charts.</p>
</li>
<li>
<p>There is enough data to come up with a specific interval of time required to get the first upvotes to
get to the first page.</p>
<p>For instance, 3 upvotes in 12 hours will not get you to the first page, but will 3 upvotes
in 5 minutes get you there?</p>
</li>
<li>
<p>How long do posts live on the first page on average?</p>
</li>
</ul>
<h2 id="other-researches">Other researches</h2>
<ul>
<li><a href="https://antontarasenko.com/2015/04/23/best-time-to-post-its-irrelevant/">2015, Best Time to Post? It’s Irrelevant</a></li>
<li><a href="https://www.reddit.com/r/Entrepreneur/comments/5451l4/findings_on_the_optimal_time_to_post_to_hacker/">2016, /r/Enterpreneur: Findings on the optimal time to post to Hacker News</a></li>
<li><a href="https://medium.com/@mi.schaefer/what-is-the-best-time-to-post-to-hacker-news-829fad3eac71">2017, What is the best time to post to Hacker News?</a></li>
<li><a href="https://chanind.github.io/2019/05/07/best-time-to-submit-to-hacker-news.html">2019, The Best Time to Submit to Hacker News</a></li>
</ul>
<p>Thanks to <a href="https://twitter.com/ivmirx">Ivan Mir</a> for reading drafts of this.</p>


<hr>
    <b>Comments</b>
    
    
</article>

        </div></div>]]>
            </description>
            <link>https://samizdat.dev/getting-lucky-with-posting-on-hacker-news/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197696</guid>
            <pubDate>Tue, 24 Nov 2020 12:11:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Image Classification: Tips and Tricks from 13 Kaggle Competitions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197491">thread link</a>) | @patrycjaneptune
<br/>
November 24, 2020 | https://neptune.ai/blog/image-classification-tips-and-tricks-from-13-kaggle-competitions | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/image-classification-tips-and-tricks-from-13-kaggle-competitions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p>Success in any field can be distilled into a set of small rules and fundamentals that produce great results when coupled together.&nbsp;</p>



<p>Machine learning and image classification is no different, and engineers can showcase best practices by taking part in competitions like Kaggle.&nbsp;</p>



<p>In this article, I’m going to give you a lot of resources to learn from, focusing on the best Kaggle kernels from 13 Kaggle competitions&nbsp; – with the most prominent competitions being:</p>



<ul><li><a href="https://www.kaggle.com/puneet6060/intel-image-classification" target="_blank" rel="noreferrer noopener nofollow">Intel Image Classification</a></li><li><a href="https://www.kaggle.com/c/recursion-cellular-image-classification" target="_blank" rel="noreferrer noopener nofollow">Recursion Cellular Image Classification</a></li><li><a href="https://www.kaggle.com/c/siim-isic-melanoma-classification" target="_blank" rel="noreferrer noopener nofollow">SIIM-ISIC Melanoma Classification</a></li><li><a href="https://www.kaggle.com/c/aptos2019-blindness-detection/notebooks" target="_blank" rel="noreferrer noopener nofollow">APTOS 2019 Blindness Detection</a>&nbsp;</li><li><a href="https://www.kaggle.com/c/diabetic-retinopathy-detection" target="_blank" rel="noreferrer noopener nofollow">Diabetic Retinopathy Detection</a></li><li><a href="https://www.kaggle.com/c/image-classification-fashion-mnist/notebooks" target="_blank" rel="noreferrer noopener nofollow">ML Project — Image Classification</a></li><li><a href="https://www.kaggle.com/c/cdiscount-image-classification-challenge/notebooks" target="_blank" rel="noreferrer noopener nofollow">Cdiscount’s Image Classification Challenge</a></li><li><a href="https://www.kaggle.com/c/plant-seedlings-classification/notebooks" target="_blank" rel="noreferrer noopener nofollow">Plant seedlings classifications</a></li><li><a href="https://www.kaggle.com/c/aesthetic-visual-analysis/notebooks" target="_blank" rel="noreferrer noopener nofollow">Aesthetic Visual Analysis</a></li></ul>



<p>We’ll go through three main areas of tweaking a Deep learning solution:</p>



<ul><li>Data</li><li>Model&nbsp;</li><li>Loss function&nbsp;</li></ul>



<p>…and there will be a lot of example projects (and references) for you to check out along the way.&nbsp;</p>






<h2>Data</h2>



<h3><strong>Image Pre-processing + EDA&nbsp;</strong></h3>



<div><figure><img loading="lazy" width="241" height="209" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Kaggle-data-1.png?resize=241%2C209&amp;ssl=1" alt="Kaggle data" data-recalc-dims="1"></figure></div>






<p>Every Machine Learning/Deep Learning Solution starts with raw data. There are 2 essential steps in the data processing pipeline.</p>



<p>The first step is <strong><a href="https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline" target="_blank" rel="noreferrer noopener nofollow">Exploratory Data Analysis</a></strong> (EDA). It helps us analyse the entire dataset and summarise its main characteristics, like class distribution, size distribution, and so on. Visual methods are often used to display the results of this analysis.&nbsp;</p>



<p>The second step is <a href="https://towardsdatascience.com/image-pre-processing-c1aec0be3edf" target="_blank" rel="noreferrer noopener nofollow"><strong>Image Pre-Processing</strong></a>, where the aim is to take the raw image and improve image data (also known as image features) by suppressing unwanted distortions, resizing and/or enhancing important features, making the data more suited to the model and improving performance.&nbsp;</p>



<p>You can dig into these Kaggle notebooks to check out a few examples of <strong>Image Pre-Processing</strong> and <strong>EDA</strong> techniques:</p>



<ul><li><a href="https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline#Building-a-baseline-model-" target="_blank" rel="noreferrer noopener nofollow">Visualisation</a></li><li><a href="https://www.kaggle.com/rohandeysarkar/ultimate-image-classification-guide-2020" target="_blank" rel="noreferrer noopener nofollow">Dealing with Class imbalance</a></li><li><a href="https://www.kaggle.com/datafan07/analysis-of-melanoma-metadata-and-effnet-ensemble" target="_blank" rel="noreferrer noopener nofollow">Fill missing values (labels, features and, etc.)</a></li><li><a href="https://www.kaggle.com/vincee/intel-image-classification-cnn-keras" target="_blank" rel="noreferrer noopener nofollow">Normalisation </a></li><li><a href="https://www.kaggle.com/ratthachat/aptos-eye-preprocessing-in-diabetic-retinopathy#3.A-Important-Update-on-Color-Version-of-Cropping-&amp;-Ben's-Preprocessing" target="_blank" rel="noreferrer noopener nofollow">Pre-processing</a></li></ul>






<h3><strong>Data Augmentation</strong></h3>



<div><figure><img loading="lazy" width="500" height="281" src="https://i1.wp.com/neptune.ai/wp-content/uploads/Kaggle-data-augmentation.gif?resize=500%2C281&amp;ssl=1" alt="Kaggle data augmentation" data-recalc-dims="1"></figure></div>



<p><a href="https://media1.giphy.com/media/ciwwr8kBcdGSJUkRZ8/giphy.gif" target="_blank" rel="noreferrer noopener nofollow"><em>Credits</em></a></p>



<p><strong>Data augmentation</strong> can expand our dataset by generating more training data from existing training samples. New samples are generated via a number of random transformations that not only yield believable-looking images but also reflect real-life scenarios—more on this later.</p>



<p>This technique is widely used, and not just in cases with too few data samples to train the model. In this case, the model starts to memorize the training set, but it is unable to generalize (performs poorly on never seen data).&nbsp;</p>



<p>Usually, when a model performs great on training data but poorly on validation data, we call this condition <a href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" target="_blank" rel="noreferrer noopener nofollow"><strong><em>overfitting</em></strong></a>. To solve this problem, we usually try to get new data, and if new data isn’t available, data augmentation comes to the rescue.</p>



<p><strong>Note</strong>: A general rule of thumb is to always use data augmentation techniques because it helps expose our model to more variations and generalize better. Even if we have a large dataset, although it comes at the cost of slow training speed because augmentations are done on-the-fly (which means during training).&nbsp;</p>



<p>Plus, for each task or dataset, we have to use augmentation techniques that reflect possible real-life scenarios (i.e. if we have a cat/dog detector we can use horizontal flip, crop, brightness and contrast because these augmentations match differences in how photos are taken).</p>



<p>Here are a few Kaggle competition notebooks for you to check out popular data augmentation techniques in practice:</p>



<ul><li><a href="https://www.kaggle.com/datafan07/analysis-of-melanoma-metadata-and-effnet-ensemble" target="_blank" rel="noreferrer noopener nofollow">Horizontal Flip</a></li><li><a href="https://www.kaggle.com/iafoss/pretrained-resnet34-with-rgby-0-460-public-lb" rel="noreferrer noopener nofollow" target="_blank">Random Rotate and Random Dihedral</a></li><li><a href="https://www.kaggle.com/cdeotte/triple-stratified-kfold-with-tfrecords" target="_blank" rel="noreferrer noopener nofollow">Hue, Saturation, Contrast, Brightness, Crop</a></li><li><a href="https://www.kaggle.com/nroman/melanoma-pytorch-starter-efficientnet" rel="noreferrer noopener nofollow" target="_blank">Colour jitter</a></li></ul>






<h2>Model</h2>



<div><figure><img loading="lazy" width="500" height="343" src="https://i0.wp.com/neptune.ai/wp-content/uploads/kaggle-machine-learning.png?resize=500%2C343&amp;ssl=1" alt="kaggle machine learning " srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/kaggle-machine-learning.png?w=500&amp;ssl=1 500w, https://i0.wp.com/neptune.ai/wp-content/uploads/kaggle-machine-learning.png?resize=300%2C206&amp;ssl=1 300w" sizes="(max-width: 500px) 100vw, 500px" data-recalc-dims="1"></figure></div>



<p><em><a href="https://www.google.com/search?q=i+can+predict+the+future+meme&amp;tbm=isch&amp;ved=2ahUKEwj-kuj346zsAhXLALcAHYUHCBkQ2-cCegQIABAC&amp;oq=i+can+predict+the+future+meme&amp;gs_lcp=ChJtb2JpbGUtZ3dzLXdpei1pbWcQAzICCAA6BggAEAcQHjoECAAQDVD2SFigUmDHU2gAcAB4AIABuQGIAZ8HkgEDMC43mAEAoAEBwAEB&amp;sclient=mobile-gws-wiz-img&amp;ei=wBqDX_6yN8uB3LUPhY-gyAE&amp;bih=695&amp;biw=1080&amp;prmd=isvn&amp;rlz=1C9BKJA_enIN888IN888&amp;safe=strict&amp;hl=en-US#imgrc=zIkrgmXonyocyM&amp;imgdii=745rZYAZFGURlM" target="_blank" rel="noreferrer noopener nofollow">Credits</a></em></p>



<h3><strong>Develop a baseline (<a href="https://www.kaggle.com/uzairrj/beg-tut-intel-image-classification-93-76-accur" target="_blank" rel="noreferrer noopener nofollow">example project</a>)</strong></h3>



<p>Here we create a basic model using a very simple architecture, without any regularization or dropout layers, and see if we can beat the baseline score of 50% accuracy. Although we can’t always get there, if we can’t beat the baseline after trying multiple reasonable architectures, maybe the input data doesn’t hold the information required for our model to make a prediction.&nbsp;</p>



<p>In the wise and paraphrased words of Jeremy Howard:</p>



<p>“You should be able to quickly test if you are going into a promising direction, in 15 minutes using 50% or less of the dataset, if not you have to rethink everything.”</p>






<h3><strong>Develop a model large enough that it overfits (<a href="https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline#Building-a-baseline-model-" target="_blank" rel="noreferrer noopener nofollow">example project</a>)</strong></h3>



<p>Once our baseline model has enough capacity to beat the baseline score, we can increase the baseline model capacity until it overfits the dataset, then we move to applying regularization. We can increase module capacity by:</p>



<ul><li>Adding more layers</li><li>Using a better architecture&nbsp;</li><li>Better training procedures</li></ul>






<h3><strong>Architecture</strong></h3>



<p>According to literature, the architecture refinements below improve model capacity, but barely change the computational complexity. They’re still pretty interesting if you want to dig into the linked examples:</p>



<ul><li><a href="https://arxiv.org/abs/1812.01187" target="_blank" rel="noreferrer noopener nofollow">Residual Networks</a></li><li><a href="https://arxiv.org/abs/1605.07146" target="_blank" rel="noreferrer noopener nofollow">Wide Residual Networks</a></li><li><a href="https://arxiv.org/abs/1812.01187" target="_blank" rel="noreferrer noopener nofollow">Inception</a></li><li><a href="https://www.kaggle.com/hmendonca/fold1h4r3-arcenetb4-2-256px-rcic-lb-0-9759" target="_blank" rel="noreferrer noopener nofollow">EfficientNet</a></li><li><a href="https://www.kaggle.com/hmendonca/fold1h4r3-arcenetb4-2-256px-rcic-lb-0-9759" target="_blank" rel="noreferrer noopener nofollow">Swish activation</a></li><li><a href="https://www.kaggle.com/kmader/inceptionv3-for-retinopathy-gpu-hr" target="_blank" rel="noreferrer noopener nofollow">Residual Attention Network</a></li></ul>



<p>Most of the time, model capacity and accuracy are positively correlated to each other – as the capacity increases, the accuracy increases too, and vice-versa.</p>






<h3><strong>Training procedures</strong></h3>



<p>Here are some training procedures you can use to tweak your model, with example projects to see how they work:</p>



<ul><li><a href="https://arxiv.org/abs/1710.03740" target="_blank" rel="noreferrer noopener nofollow">Mixed-Precision Training</a></li><li><a href="https://arxiv.org/abs/1812.01187" target="_blank" rel="noreferrer noopener nofollow">Large Batch-Size Training</a></li><li><a href="https://www.kaggle.com/datafan07/analysis-of-melanoma-metadata-and-effnet-ensemble" target="_blank" rel="noreferrer noopener nofollow">Cross-Validation Set</a></li><li><a href="https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79" target="_blank" rel="noreferrer noopener nofollow">Weight Initialization</a></li><li><a href="https://arxiv.org/pdf/1911.04252.pdf" target="_blank" rel="noreferrer noopener nofollow">Self-Supervised Training (Knowledge Distillation)</a></li><li><a href="https://arxiv.org/abs/1812.01187" target="_blank" rel="noreferrer noopener nofollow">Learning Rate Scheduler</a></li><li><a href="https://arxiv.org/abs/1812.01187" target="_blank" rel="noreferrer noopener nofollow">Learning Rate Warmup</a></li><li><a href="https://www.kaggle.com/rohandeysarkar/ultimate-image-classification-guide-2020" target="_blank" rel="noreferrer noopener nofollow">Early Stopping</a></li><li><a href="https://www.kaggle.com/dataraj/fastai-tutorial-for-image-classification" target="_blank" rel="noreferrer noopener nofollow">Differential Learning Rates</a></li><li><a href="https://www.kaggle.com/vincee/intel-image-classification-cnn-keras" target="_blank" rel="noreferrer noopener nofollow">Ensemble</a></li><li><a href="https://www.kaggle.com/dataraj/fastai-tutorial-for-image-classification" target="_blank" rel="noreferrer noopener nofollow">Transfer Learning</a></li><li><a href="https://www.kaggle.com/vincee/intel-image-classification-cnn-keras" rel="noreferrer noopener nofollow" target="_blank">Fine-Tuning</a></li></ul>






<h3><strong>Hyperparameter tuning</strong></h3>



<div><figure><img loading="lazy" width="480" height="345" src="https://i2.wp.com/neptune.ai/wp-content/uploads/Kaggle-Hyperparameter-Tuning.gif?resize=480%2C345&amp;ssl=1" alt="Kaggle Hyperparameter Tuning" data-recalc-dims="1"></figure></div>



<p><em><a href="https://images.app.goo.gl/a5g4VdSBKLZfccXW6" target="_blank" rel="noreferrer noopener nofollow">Credits</a></em></p>



<p>Unlike parameters, <a href="https://www.oreilly.com/library/view/evaluating-machine-learning/9781492048756/ch04.html" target="_blank" rel="noreferrer noopener nofollow">hyperparameters</a> are specified by you when you configure the model (i.e. learning rate, number of epochs, number of hidden units, batch size, etc).&nbsp;</p>



<p>Instead of trying different model configurations manually, you can automate this process by using hyperparameter tuning libraries like <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" target="_blank" rel="noreferrer noopener nofollow"><strong>Scikit learn Grid Search</strong></a>, <strong><a href="https://keras-team.github.io/keras-tuner/" target="_blank" rel="noreferrer noopener nofollow">Keras Tuner</a>,</strong> and others that will try all hyperparameter combinations within the range you specify, and it will return the best performing model.</p>



<p>The more hyperparameters you need to tune, the slower the process, so it’s good to select a minimum subset of model hyperparameters to tune.</p>



<p>Not all model hyperparameters are equally important. Some hyperparameters have an outsized effect on the behaviour, and in turn the performance, of a machine learning algorithm. You should carefully pick the ones that impact your model’s performance the most, and tune them for maximum performance.</p>






<h3><strong>Regularization</strong></h3>



<p>This method forces the model to learn a meaningful and generalisable representation of the data by penalising <a href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" target="_blank" rel="noreferrer noopener nofollow"><strong><em>memorization/overfitting</em></strong></a> and <a href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" target="_blank" rel="noreferrer noopener nofollow"><strong><em>underfitting</em></strong></a>, making the model more robust at dealing with data it has never seen before.&nbsp;</p>



<p>One simple method to solve the problems stated above is to get more training data, because a model trained on more data will naturally generalize better.</p>



<p>Here are some techniques you can try to mitigate <a href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" target="_blank" rel="noreferrer noopener nofollow"><strong><em>overfitting</em></strong></a> and <a href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" target="_blank" rel="noreferrer noopener nofollow"><strong><em>underfitting</em></strong></a>, with example project links for you to dig into:</p>



<ul><li><a href="https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline" target="_blank" rel="noreferrer noopener nofollow">Adding Dropout</a></li><li><a href="https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline" target="_blank" rel="noreferrer noopener nofollow">Adding or changing the position of Batch Norm</a></li><li><a href="https://www.kaggle.com/cdeotte/triple-stratified-kfold-with-tfrecords" target="_blank" rel="noreferrer noopener nofollow">Data augmentation</a></li><li><a href="https://arxiv.org/abs/1710.09412" target="_blank" rel="noreferrer noopener nofollow">Mixup</a></li><li><a href="https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline" target="_blank" rel="noreferrer noopener nofollow">Weight regularization</a></li><li><a href="https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline" target="_blank" rel="noreferrer noopener nofollow">Gradient clipping</a></li></ul>






<h2>Loss function</h2>



<div><figure><img loading="lazy" width="400" height="300" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Kaggle-loss-function.png?resize=400%2C300&amp;ssl=1" alt="Kaggle loss function" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/Kaggle-loss-function.png?w=400&amp;ssl=1 400w, https://i0.wp.com/neptune.ai/wp-content/uploads/Kaggle-loss-function.png?resize=300%2C225&amp;ssl=1 300w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1"></figure></div>



<p><em><a href="https://memegenerator.net/img/instances/64802690.jpg" target="_blank" rel="noreferrer noopener nofollow">Credits</a></em></p>



<p>Also known as cost function or objective function, the <a href="https://medium.com/@prince.canuma/how-to-develop-your-ai-intuition-ii-9dedb4a41c1c" target="_blank" rel="noreferrer noopener nofollow"><strong>loss function</strong></a> is used to find the difference between the models output from the target output, and to help the model minimize the distance between them.</p>



<p>Here are some of the most popular loss functions, with project examples where you’ll find tricks to improve your model capacity:</p>



<ul><li><a href="https://arxiv.org/pdf/1906.02629.pdf" target="_blank" rel="noreferrer noopener nofollow">Label smoothing</a>&nbsp;</li><li><a href="https://www.kaggle.com/iafoss/pretrained-resnet34-with-rgby-0-460-public-lb" rel="noreferrer noopener nofollow" target="_blank">Focal loss</a></li><li><a href="https://arxiv.org/pdf/2009.13935.pdf" target="_blank" rel="noreferrer noopener nofollow">SparseMax loss and Weighted cross-entropy</a></li><li><a href="https://gombru.github.io/2018/05/23/cross_entropy_loss/" target="_blank" rel="noreferrer noopener nofollow">BCE loss, BCE with logits loss and Categorical cross-entropy loss</a></li><li><a href="https://arxiv.org/abs/1801.07698" target="_blank" rel="noreferrer noopener nofollow">Additive Angular Margin Loss for Deep Face Recognition</a></li></ul>






<h3><strong>Evaluation + error analysis</strong></h3>



<div><figure><img loading="lazy" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Kaggle-error-analysis.jpg?resize=504%2C343&amp;ssl=1" alt="Kaggle error analysis" width="504" height="343" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/Kaggle-error-analysis.jpg?w=672&amp;ssl=1 672w, https://i0.wp.com/neptune.ai/wp-content/uploads/Kaggle-error-analysis.jpg?resize=300%2C204&amp;ssl=1 300w" sizes="(max-width: 504px) 100vw, 504px" data-recalc-dims="1"></figure></div>



<p><em><a href="https://www.google.com/search?q=error+analysis+mem&amp;tbm=isch&amp;ved=2ahUKEwirzZvK6KzsAhUEkksFHdVoDXwQ2-cCegQIABAC&amp;oq=error+analysis+mem&amp;gs_lcp=ChJtb2JpbGUtZ3dzLXdpei1pbWcQAzICCAA6BAgAEEM6BQgAEM0COgQIABANOgYIABAIEB46BAgAEBhQ_xRYzClgtCtoBHAAeACAAbUBiAHxCJIBAzAuOJgBAKABAcABAQ&amp;sclient=mobile-gws-wiz-img&amp;ei=nx-DX-uBHISkrtoP1dG14Ac&amp;bih=695&amp;biw=1080&amp;prmd=bivn&amp;rlz=1C9BKJA_enIN888IN888&amp;safe=strict&amp;hl=en-US#imgrc=18Fu76HGpiW_zM" target="_blank" rel="noreferrer noopener nofollow">Credits</a></em></p>



<p>Here, we do an ablation study, and analyse our experiment results. We identify our model’s weaknesses and strengths, and identify areas to improve in the future. You can use the below techniques at this stage, and see how they’re implemented in the linked examples:</p>



<ul><li><a href="https://www.kaggle.com/vincee/intel-image-classification-cnn-keras" target="_blank" rel="noreferrer noopener nofollow">Tracking metrics and Confusion matrix</a></li><li><a href="https://arxiv.org/pdf/1610.02391v1.pdf" target="_blank" rel="noreferrer noopener nofollow">Grad CAM</a></li><li><a href="https://www.kaggle.com/iafoss/pretrained-resnet34-with-rgby-0-460-public-lb" target="_blank" rel="noreferrer noopener nofollow">Test Time Augmentation (TTA)</a></li></ul>



<p>There are many experiment tracking and management tools that take the minimal setup to save all the data for you automatically, which makes the ablation study easier – <a href="https://neptune.ai/" target="_blank" rel="noreferrer noopener nofollow">Neptune.ai</a> does a great job here.</p>






<h2>Closing thoughts</h2>



<p>There are many ways to tweak your models, and new ideas come out all the time. Deep Learning is a fast moving field and there are no silver bullet methods. We have to experiment a lot, and enough trial and error causes breakthroughs. This article already contains a lot of links, but for the most knowledge-hungry readers, I also added a long <strong>reference section</strong> below for you to read more and run some notebooks.</p>



<h3><strong>Further research</strong></h3>



<ul><li><a href="https://www.kaggle.com/blazeka/multi-gpu-tensorflow-convnet-0-65" target="_blank" rel="noreferrer noopener nofollow">Distributed Training</a></li><li><a href="https://www.kaggle.com/sentdex/first-pass-through-data-w-3d-convnet" target="_blank" rel="noreferrer noopener nofollow">3D Image classification</a></li><li><a href="https://github.com/fastai/fastbook/blob/master/01_intro.ipynb" target="_blank" rel="noreferrer noopener nofollow">Converting data from other domains into images</a></li><li><a href="https://arxiv.org/abs/2009.11892" target="_blank" rel="noreferrer noopener nofollow">PK-GCN: Prior Knowledge Assisted Image Classification using Graph Convolution Networks</a></li></ul>



<h3><strong>References</strong></h3>



<p>Papers:</p>



<ul><li><a href="https://arxiv.org/abs/1605.07146" target="_blank" rel="noreferrer noopener nofollow">Wide Residual Networks</a></li><li><a href="https://arxiv.org/abs/1710.09412" target="_blank" rel="noreferrer noopener nofollow">mixup: BEYOND EMPIRICAL RISK MINIMIZATION</a></li><li><a href="https://arxiv.org/abs/1801.07698" target="_blank" rel="noreferrer noopener nofollow">ArcFace: Additive Angular Margin Loss for Deep Face Recognition</a>&nbsp;</li><li><a href="https://arxiv.org/abs/1905.11946" target="_blank" rel="noreferrer noopener nofollow">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a></li><li><a href="https://arxiv.org/abs/1710.05941" target="_blank" rel="noreferrer noopener nofollow">Searching for Activation Functions</a></li><li><a href="https://arxiv.org/abs/1704.06904" target="_blank" rel="noreferrer noopener nofollow">Residual Attention Network for Image Classification</a></li><li><a href="https://arxiv.org/abs/1710.03740" target="_blank" rel="noreferrer noopener nofollow">Mixed Precision Training</a></li><li><a href="https://arxiv.org/pdf/1911.04252.pdf" target="_blank" rel="noreferrer noopener nofollow">Self-training with Noisy Student improves ImageNet classification</a></li><li><a href="https://arxiv.org/abs/1906.02629" target="_blank" rel="noreferrer noopener nofollow">When Does Label Smoothing Help?</a></li><li><a href="https://arxiv.org/abs/1801.07698" target="_blank" rel="noreferrer noopener nofollow">Additive Angular Margin Loss for Deep Face Recognition</a></li><li><a href="https://arxiv.org/pdf/1610.02391v1.pdf" target="_blank" rel="noreferrer noopener nofollow">Grad-CAM: Why did you say that? Visual Explanations from Deep Networks…</a></li><li><a href="https://arxiv.org/abs/2009.13935" target="_blank" rel="noreferrer noopener nofollow">A Comparative Study of Deep Learning Loss Functions for Multi-Label Remote Sensing Image Classification</a></li></ul>



<p>Blogs:</p>



<ul><li><a href="https://medium.com/@prince.canuma/wide-residual-nets-why-deeper-isnt-always-better-f2a02947dca3" target="_blank" rel="noreferrer noopener nofollow">Wide Residual Nets: “Why deeper isn’t always better…”</a></li><li><a href="https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/" target="_blank" rel="noreferrer noopener nofollow">Tune Hyperparameters for Classification Machine Learning Algorithms</a></li><li><a href="https://towardsdatascience.com/image-pre-processing-c1aec0be3edf" target="_blank" rel="noreferrer noopener nofollow">Image Pre-Processing</a></li><li><a href="https://gombru.github.io/2018/05/23/cross_entropy_loss/" target="_blank" rel="noreferrer noopener nofollow">Understanding Categorical Cross-Entropy Loss, Binary Cross-Entropy Loss…</a></li><li><a href="https://paperswithcode.com/method/noisy-student" target="_blank" rel="noreferrer noopener nofollow">Noisy student</a></li><li><a href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" target="_blank" rel="noreferrer noopener nofollow">Overfitting and Underfitting With Machine Learning Algorithms</a></li><li><a href="https://medium.com/datadriveninvestor/developing-ai-projects-under-pressure-202cbab7428f" target="_blank" rel="noreferrer noopener nofollow">Developing AI projects under pressure</a>&nbsp;</li><li><a href="https://towardsdatascience.com/understanding-neural-networks-19020b758230" target="_blank" rel="noreferrer noopener nofollow">Understanding …</a></li></ul></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neptune.ai/blog/image-classification-tips-and-tricks-from-13-kaggle-competitions">https://neptune.ai/blog/image-classification-tips-and-tricks-from-13-kaggle-competitions</a></em></p>]]>
            </description>
            <link>https://neptune.ai/blog/image-classification-tips-and-tricks-from-13-kaggle-competitions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197491</guid>
            <pubDate>Tue, 24 Nov 2020 11:27:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TensorBoard vs. Neptune: How Are They Different]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197478">thread link</a>) | @patrycjaneptune
<br/>
November 24, 2020 | https://neptune.ai/blog/tensorboard-vs-neptune-how-are-they-actually-different | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/tensorboard-vs-neptune-how-are-they-actually-different">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p><a href="https://medium.com/louis-dorard/an-overview-of-ml-development-platforms-df953060b9a9" target="_blank" rel="noreferrer noopener nofollow">ML model development</a> typically involves a tedious workflow of managing data, feature engineering, model training and evaluation.&nbsp;</p>



<p>A data scientist could easily run in the order of hundreds of combinations of these things before converging onto a final model which solves the business problem. Managing those experiments, tracking progress and comparing them is an uphill battle which most data scientists fight everyday.&nbsp;</p>



<p>There are multiple tools available to make this process easier and today we will take a look at two of them. This writeup will take you through a <strong>deep comparison of TensorBoard with Neptune</strong>, one of the modern experiment management tools. We will take you through a model development cycle and compare the utility of TensorBoard and Neptune at various steps of the process. For the purpose of this comparison, we will be using the digit recognition problem with the MNIST dataset.</p>



<hr>



<p><strong><span><sup>SEE ALSO</sup></span></strong>&nbsp;<br>– <a href="https://neptune.ai/blog/tensorboard-tutorial" target="_blank" rel="noreferrer noopener nofollow">Deep Dive into TensorBoard: Tutorial With Examples</a><br>– <a href="https://neptune.ai/blog/the-best-tensorboard-alternatives" target="_blank" rel="noreferrer noopener nofollow">The Best TensorBoard Alternatives</a></p>



<hr>



<p><strong>Areas of comparison</strong></p>



<p>We will compare TensorBoard and Neptune by dividing the ML model development process into the following parts:</p>



<ul><li><strong>Exploratory Data Analysis</strong>: perform ad-hoc analysis on data to help in deciding training parameters, feature engineering, etc.</li><li>Experiment Setup: provide means to store multiple experiments together as an entity to allow easy comparison in the future.</li><li>Model Training &amp; Evaluation: train a model and look at the evaluation metrics to debug and compare performance.</li><li>Model Debugging: dig deeper into the training process and figure out what went wrong.</li><li>Hyperparameter Tuning: the ability to train multiple models, compare them easily, and <strong>pick a winner</strong></li><li><strong>Versioning</strong>: ability to add data/code/feature/model metadata for comparison.</li><li><strong><a href="https://neptune.ai/blog/best-software-for-collaborating-on-machine-learning-projects" target="_blank" rel="noreferrer noopener nofollow">Collaboration</a></strong>: allow multiple users to work together and manage access.</li></ul>






<h2>Exploratory Data Analysis (EDA)</h2>



<p>EDA is typically the first step in the process of developing an ML model. This is usually very custom to the problem at hand and requires high flexibility. Both TensorBoard and Neptune have light support for this.</p>



<p>Even though Neptune does not have tools to help you in EDA per-say, it allows us to visualize the ad-hoc analysis done using jupyter notebooks on the Neptune UI. This can be done using 2 ways:</p>



<ul><li>You can save notebook checkpoints directly into Neptune projects. <a href="https://ui.neptune.ai/neptune-ai/credit-default-prediction/n/1-0-eda-application-table-ac75c237-1630-4109-b532-dd125badec0e/ca1df3be-b2e4-4b26-99d6-b7e98a3d4273" target="_blank" rel="noreferrer noopener nofollow">Here</a> is an example of a public notebook containing EDA. If you want to check out how this works here are the docs.</li><li>You can attach custom charts or visualizations to the Neptune experiment. We will go through an example of this later.</li></ul>






<h2>Experiment Setup</h2>



<p>Before you start using any experiment management tool you need to set up an experiment so that it can be easily identified and referred to in the future. Here we will compare TensorBoard and Neptune on these aspects.&nbsp;</p>



<p>First, let’s define a project and experiment name which we will use for tracking.</p>



<pre>PROJECT = <span>'blog-neptune-vs-tensorboard'</span>
EXPERIMENT = <span>'model-1'</span>
</pre>



<p>Download the dataset:</p>



<pre>mnist = tf.keras.datasets.mnist
(X_train, y_train), (X_test, y_test) = mnist.load_data()
X_train, X_test = X_train / <span>255.0</span>, X_test / <span>255.0</span>
</pre>






<h3><strong>Tensorboard</strong></h3>



<p>Tensorboard has no direct support for setting up an experiment. We need to create a directory structure ourselves and store logs in there. The good thing is that it works with Google Cloud Storage and AWS S3 paths so that all data can be stored and read from the cloud directly.</p>



<p>Here, we will create a local directory for a project and then another for an experiment.</p>



<pre>
DATA_BASE = Path(<span>'../neptune.ai'</span>)</pre>



<pre>
project_dir = DATA_BASE / <span>'blog-tensorboard-vs-neptune'</span>
exp_dir = project_dir / <span>'first-model'</span>
<span>if</span> <span>not</span> project_dir.exists():
    project_dir.mkdir()
<span>if</span> <span>not</span> exp_dir.exists():
    exp_dir.mkdir()
</pre>






<h3><strong>Neptune</strong></h3>



<p>Experiment creation and management are first-class citizens in Neptune. It allows us to create a project within which multiple experiments can be added and compared. All this is managed seamlessly on the Neptune server.</p>



<p>First, we created a project called “blog-tensorboard-vs-neptune” on the Neptune UI (<a href="https://docs.neptune.ai/workspace-project-and-user-management/projects/create-project.html" target="_blank" rel="noreferrer noopener nofollow">docs on how to do it</a>). Now we can initialize the neptune client pointing to that project and create experiments in it.</p>



<pre><span>import</span> neptune
neptune_project = neptune.init(f<span>'aarshay/{PROJECT}'</span>)
neptune_experiment = neptune_project.create_experiment(name=EXPERIMENT)</pre>



<p>As we can see, Neptune gave us an automated ID called `BLOG-1` for the experiment. We can see this on Neptune UI as:</p>



<figure><img loading="lazy" width="1024" height="243" src="https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard.png?resize=1024%2C243&amp;ssl=1" alt="neptune vs tensorboard" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard.png?resize=1024%2C243&amp;ssl=1 1024w, https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard.png?resize=300%2C71&amp;ssl=1 300w, https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard.png?resize=768%2C182&amp;ssl=1 768w, https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard.png?resize=1536%2C365&amp;ssl=1 1536w, https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>






<h2>Model Training &amp; Evaluation</h2>



<p>Model training is typically carried out using off-the-shelf tools like Keras which we’ll be using here. Model evaluation involves looking at the loss function and other metrics of concern. Both TensorBoard and Neptune provide fairly good support for model evaluation.</p>



<p>Let’s train a simple model using Keras.</p>



<pre>model = tf.keras.models.Sequential([
   tf.keras.layers.Flatten(input_shape=(<span>28</span>, <span>28</span>)),
   tf.keras.layers.Dense(<span>64</span>, activation=<span>'relu'</span>),
   tf.keras.layers.Dense(<span>64</span>, activation=<span>'relu'</span>),
   tf.keras.layers.Dense(<span>10</span>, activation=<span>'softmax'</span>)])

model.compile(optimizer=<span>'sgd'</span>, 
   loss=<span>'sparse_categorical_crossentropy'</span>,
   metrics=[<span>'accuracy'</span>])
</pre>



<p>Both neptune and tf logging can be achieved using callbacks:</p>



<pre><span>from</span> tensorflow.keras.callbacks <span>import</span> TensorBoard, Callback
</pre>






<h3><strong>Tensorboard</strong></h3>



<p>There is a predefined callback method that allows you to log model metrics onto a specific location. Note that this is the same location which we defined in step 1. You can read more about the parameters in the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard" target="_blank" rel="noreferrer noopener nofollow">official doc</a>.</p>



<pre>tb_callback = TensorBoard(
    log_dir=exp_dir,
    histogram_freq=<span>1</span>,
    write_graph=<span>True</span>,
    write_images=<span>True</span>,
    update_freq=<span>'epoch'</span>,
    profile_batch=<span>2</span>,
    embeddings_freq=<span>1</span>)
</pre>






<h3><strong>Neptune</strong></h3>



<p>For Neptune, a custom callback can be defined which will log model metrics to Neptune at the end of every epoch (you can also use the <a href="https://docs.neptune.ai/integrations/keras.html" target="_blank" rel="noreferrer noopener nofollow">predefined Neptune callback for Keras</a>).&nbsp;&nbsp;</p>



<pre><span><span>class</span> <span>NeptuneLoggingCallback</span><span>(Callback)</span>:</span>
     <span><span>def</span> <span>on_epoch_end</span><span>(self, epoch, logs=None)</span>:</span>
        <span>for</span> metric_name, metric_value <span>in</span> logs.items():
            neptune.log_metric(metric_name, metric_value)

neptune_callback = NeptuneLoggingCallback()
</pre>



<p>Now we will pass both of these callbacks to the model fit method and train the model:</p>



<pre>callbacks = [tb_callback, neptune_callback]
model.fit(X_train, y_train,
          epochs=<span>10</span>,
          validation_split=<span>0.2</span>,
          callbacks=callbacks)
</pre>



<p><strong>Test set performance</strong></p>



<pre>test_loss, test_accuracy = model.evaluate(X_test, y_test)
</pre>



<pre>neptune.log_metric(<span>'test-loss'</span>, test_loss)
neptune.log_metric(<span>'test-accuracy'</span>, test_accuracy)
</pre>



<p>Both TensorBoard and Neptune show the loss and accuracy metrics for training and evaluation runs.</p>



<p>The TensorBoard UI looks as:</p>



<div><figure><img loading="lazy" width="1024" height="552" src="https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-UI.png?resize=1024%2C552&amp;ssl=1" alt="tensorboard UI" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-UI.png?resize=1024%2C552&amp;ssl=1 1024w, https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-UI.png?resize=300%2C162&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-UI.png?resize=768%2C414&amp;ssl=1 768w, https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-UI.png?resize=1536%2C828&amp;ssl=1 1536w, https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-UI.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure></div>



<p>Here each plot contains a line for train and validation runs.</p>



<p>In Neptune, the project page has additional metrics added:</p>



<figure><img loading="lazy" width="1024" height="236" src="https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard-metrics.png?resize=1024%2C236&amp;ssl=1" alt="neptune vs tensorboard metrics" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard-metrics.png?resize=1024%2C236&amp;ssl=1 1024w, https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard-metrics.png?resize=300%2C69&amp;ssl=1 300w, https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard-metrics.png?resize=768%2C177&amp;ssl=1 768w, https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard-metrics.png?resize=1536%2C354&amp;ssl=1 1536w, https://i2.wp.com/neptune.ai/wp-content/uploads/neptune-vs-tensorboard-metrics.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>



<p>Also, inside the experiment, we see these metrics as both charts and logs:</p>



<figure><img loading="lazy" width="1024" height="563" src="https://i1.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics.png?resize=1024%2C563&amp;ssl=1" alt="Neptune metrics" srcset="https://i1.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics.png?resize=1024%2C563&amp;ssl=1 1024w, https://i1.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics.png?resize=300%2C165&amp;ssl=1 300w, https://i1.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics.png?resize=768%2C422&amp;ssl=1 768w, https://i1.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics.png?resize=1536%2C844&amp;ssl=1 1536w, https://i1.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>






<hr>



<figure><img loading="lazy" width="1024" height="368" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics-2.png?resize=1024%2C368&amp;ssl=1" alt="Neptune metrics" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics-2.png?resize=1024%2C368&amp;ssl=1 1024w, https://i0.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics-2.png?resize=300%2C108&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics-2.png?resize=768%2C276&amp;ssl=1 768w, https://i0.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics-2.png?resize=1536%2C552&amp;ssl=1 1536w, https://i0.wp.com/neptune.ai/wp-content/uploads/Neptune-metrics-2.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>






<h2>Model Train Debugging</h2>



<p>Simply knowing the eval metrics is not always enough. If the model does not perform as expected, we enter into the hell of neural network debugging (if you do get there check out this <a href="http://josh-tobin.com/troubleshooting-deep-neural-networks.html" target="_blank" rel="noreferrer noopener nofollow">resource on DL troubleshooting</a>). This typically involves evaluating the model on more metrics and understanding if something went wrong during the training itself.</p>



<p>TensorBoard provides a lot of model training characteristics right off-the-bat.&nbsp;</p>



<ul><li>We can visualize network architecture and distributions of weights and gradients over time. This allows us to get an intuition to tune the model’s training parameters like learning rate and weight initialization.&nbsp;</li><li>It provides a projector for visualizing vector embeddings.</li><li>There is a profiler which can be used to debug model training times. This is particularly useful when we’re using a GPU and trying to minimize model training time by parallelizing reads with GPU processing.</li><li>TensorBoard also has the flexibility to add custom images which can be used to understand training data, confusion matrices or any ad-hoc information.</li></ul>



<p>You could refer to our <a href="https://neptune.ai/blog/tensorboard-tutorial" target="_blank" rel="noreferrer noopener nofollow">dedicated blog</a> on TensorBoard for detailed examples on these. For illustration, the network graphs and histograms are shown below:</p>



<div><figure><img loading="lazy" src="https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-graphs.png?resize=768%2C538&amp;ssl=1" alt="tensorboard graphs" width="768" height="538" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-graphs.png?resize=1024%2C717&amp;ssl=1 1024w, https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-graphs.png?resize=300%2C210&amp;ssl=1 300w, https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-graphs.png?resize=768%2C538&amp;ssl=1 768w, https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-graphs.png?resize=1536%2C1076&amp;ssl=1 1536w, https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-graphs.png?w=1576&amp;ssl=1 1576w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1"></figure></div>






<hr>



<div><figure><img loading="lazy" src="https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-histograms.png?resize=768%2C536&amp;ssl=1" alt="tensorboard histograms" width="768" height="536" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-histograms.png?resize=1024%2C714&amp;ssl=1 1024w, https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-histograms.png?resize=300%2C209&amp;ssl=1 300w, https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-histograms.png?resize=768%2C536&amp;ssl=1 768w, https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-histograms.png?resize=1536%2C1071&amp;ssl=1 1536w, https://i2.wp.com/neptune.ai/wp-content/uploads/tensorboard-histograms.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1"></figure></div>



<p>Neptune does not provide any metrics off-the-bat, but it makes it really easy to add custom images and dynamic charts through its integrations with third-party libraries like <a href="http://matplotlib.org/" target="_blank" rel="noreferrer noopener nofollow">Matplotlib</a>, <a href="https://optuna.org/" target="_blank" rel="noreferrer noopener nofollow">Optuna</a>, <a href="https://github.com/ModelOriented/DALEX" target="_blank" rel="noreferrer noopener nofollow">Dalex</a>, <a href="https://altair-viz.github.io/" target="_blank" rel="noreferrer noopener nofollow">Altair</a>, etc.</p>






<h3><strong>Image Logging with Matplotlib</strong></h3>



<p>Let us compare the process of logging a custom image on TensorBoard and Neptune. We need an image first, let’s use the scikit-plots library to create ROC curves for all the labels and push that as an image.</p>



<pre><span>import</span> numpy <span>as</span> np
<span>from</span> scikitplot.metrics <span>import</span> plot_roc

predicted_probs = model.predict(X_test)
predicted_labels = np.argmax(predicted_probs, axis=<span>1</span>)
figure, ax = plt.subplots(<span>1</span>,<span>1</span>,figsize=(<span>8</span>,<span>8</span>))
plot_roc(y_test, predicted_probs, ax=ax)</pre>



<p>Pushing this in TensorBoard requires the following code:</p>



<pre><span>import</span> io

<span><span>def</span> <span>figure_to_tf_image</span><span>(figure)</span>:</span>    
    buffer = io.BytesIO()
    figure.savefig(buffer, format=<span>'png'</span>)
    buffer.seek(<span>0</span>)

    tf_image = tf.image.decode_png(buffer.getvalue(), channels=<span>4</span>)
    tf_image = tf.expand_dims(tf_image, <span>0</span>)

    <span>return</span> tf_image

file_writer = tf.summary.create_file_writer(str(exp_dir))
<span>with</span> file_writer.as_default():
    tf.summary.image(<span>"ROC Curves"</span>, figure_to_tf_image(figure), step=<span>0</span>)
</pre>



<p>This would show up in the tensorboard UI as:</p>



<div><figure><img loading="lazy" width="512" height="372" src="https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-image-logging.png?resize=512%2C372&amp;ssl=1" alt="tensorboard image logging" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-image-logging.png?w=512&amp;ssl=1 512w, https://i0.wp.com/neptune.ai/wp-content/uploads/tensorboard-image-logging.png?resize=300%2C218&amp;ssl=1 300w" sizes="(max-width: 512px) 100vw, 512px" data-recalc-dims="1"></figure></div>



<p>However, pushing this to Neptune requires just 2 lines:</p>



<pre><span>from</span> neptunecontrib.api <span>import</span> log_chart
log_chart(name=<span>'ROC Curves'</span>, chart=figure, experiment=neptune_experiment)
</pre>



<p>This would appear as below. Note that the chart below is actually an interactive plot, Neptune handles that under the hood.</p>



<figure><img loading="lazy" src="https://i0.wp.com/neptune.ai/wp-content/uploads/neptune-image-logging.png?resize=768%2C605&amp;ssl=1" alt="neptune image logging" width="768" height="605" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/neptune-image-logging.png?resize=1024%2C807&amp;ssl=1 1024w, https://i0.wp.com/neptune.ai/wp-content/uploads/neptune-image-logging.png?resize=300%2C236&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/neptune-image-logging.png?resize=768%2C605&amp;ssl=1 768w, https://i0.wp.com/neptune.ai/wp-content/uploads/neptune-image-logging.png?resize=1536%2C1211&amp;ssl=1 1536w, https://i0.wp.com/neptune.ai/wp-content/uploads/neptune-image-logging.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1"></figure>



<p>You can find this chart on Neptune <a href="https://ui.neptune.ai/aarshay/blog-neptune-vs-tensorboard/e/BLOG-1/artifacts?path=charts%2F&amp;file=altair_confusion_matrix.html">here</a>.</p>



<p>Along with logging images, Neptune enables us to log almost anything to the experiments API for …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neptune.ai/blog/tensorboard-vs-neptune-how-are-they-actually-different">https://neptune.ai/blog/tensorboard-vs-neptune-how-are-they-actually-different</a></em></p>]]>
            </description>
            <link>https://neptune.ai/blog/tensorboard-vs-neptune-how-are-they-actually-different</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197478</guid>
            <pubDate>Tue, 24 Nov 2020 11:25:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Serverless Cloud Platform for Building Chat Apps with Node.js]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197365">thread link</a>) | @aaronnwabuoku
<br/>
November 24, 2020 | https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/ | <a href="https://web.archive.org/web/*/https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>In <a href="https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/">this tutorial series</a>
, I'll be showing you how to build a functional and secure chat app using 
the latest React Native libraries, the Expo framework, and Firebase, powered by the ChatKitty platform.</p><div>
          <p>This is the first article of this series. After reading this article, you will be able to:</p>
<ol>
<li><p>Create an Expo React Native application</p>
</li>
<li><p>Create a Firebase project for user authentication</p>
</li>
<li><p>Create a ChatKitty project and connect to ChatKitty to provide real-time chat functionality</p>
</li>
<li><p>Use Firebase Authentication and ChatKitty Chat Functions to securely implement user login</p>
</li>
</ol>
<h2 id="what-is-react-native">What is React Native?</h2>
<p><a href="https://reactnative.dev/">React Native</a> is a great way to develop both web and mobile applications very 
quickly, while sharing a lot of code when targeting multiple platforms. With a mature ecosystem of libraries 
and tooling, using React Native is not only fast but also reliable. Trusted by organizations like Facebook, 
Shopify, and Tesla - React Native is a stable framework for building both iOS and Android apps.</p>
<h2 id="what-is-expo">What is Expo?</h2>
<p>The <a href="https://expo.io/">Expo</a> framework builds on top of React Native to allow developers to build universal 
React applications in minutes. With Expo, you can develop, build, deploy and quickly iterate on iOS, Android and web 
apps from the same JavaScript code. Expo has made creating both web and mobile applications very accessible, 
handling would-be complex workflows like multi-platform deployment and advanced features like push notifications.</p>
<h2 id="what-is-firebase">What is Firebase?</h2>
<p><a href="https://firebase.google.com/">Firebase</a> is a <a href="https://www.cloudflare.com/learning/serverless/glossary/backend-as-a-service-baas/">Backend-as-a-Service</a> 
offering by Google. It provides developers a wide array of tools and services to develop quality apps 
without having to manage servers. Firebase provides key features like authentication, a real-time database, and hosting.</p>
<h2 id="what-are-chatkitty-chat-functions">What are ChatKitty Chat Functions?</h2>
<p>ChatKitty provides <strong>Chat Functions</strong>, <a href="https://www.cloudflare.com/learning/serverless/what-is-serverless/">serverless</a> 
cloud functions that allow you to define custom logic for complex tasks like user authentication, and respond 
to chat events that happen within your application. With ChatKitty Chat Functions, there's no need for you 
to build a backend to develop chat apps. ChatKitty Chat Functions auto-scale for you, and only cost you when they run.
Chat Functions lower the total cost of maintaining your chat app, enabling you to build more logic, faster.</p>
<h2 id="prerequisites">Prerequisites</h2>
<p>To develop apps with Expo and React Native, you should be able to write and understand JavaScript or 
TypeScript code. To define ChatKitty Chat Functions, you'll need to be familiar with basic JavaScript.</p>
<p>You'll need a version of <a href="https://nodejs.org/en/download/">Node.js</a> above <code>10.x.x</code> installed on your local machine 
to build this React Native app.</p>
<p>You'll need to install the <a href="https://docs.expo.io/workflow/expo-cli/">Expo CLI tool</a> through npm or npx.</p>
<p>For a complete walk-through on how to set up a development environment for Expo, you can go through 
<a href="https://docs.expo.io/get-started/installation/">the official documentation here</a>.</p>
<p>You can checkout our Expo React Native sample code any time <a href="https://github.com/ChatKitty/chatkitty-example-react-native/">on GitHub</a>.</p>
<h2 id="creating-project-and-installing-libraries">Creating project and installing libraries</h2>
<p>First, initialize a new Expo project with the <strong>blank managed</strong> workflow. To do so, you're going to 
need to open a terminal window and execute:</p>
<pre><code>expo init chatkitty-example-react-native</code></pre>


<p>After creating the initial application. You can enter the app root directory and run the app:</p>
<pre><code># navigate inside the project directory
cd chatkitty-example-react-native

# for android
expo start --android

# for ios
expo start --ios

# for web 
expo start --web</code></pre>


<p>If you run your newly created React Native application using Expo, you should see:</p>
<p><img src="https://www.chatkitty.com/images/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/screenshot-created-project.png" alt="Screenshot: Created Project">  </p>
<p>Now we have our blank project, we can install the React Native libraries we'll need:</p>
<pre><code># install following libraries for React Native and Firebase
yarn add @react-navigation/native @react-navigation/stack react-native-reanimated react-native-gesture-handler react-native-screens react-native-safe-area-context @react-native-community/masked-view react-native-paper react-native-vector-icons firebase</code></pre>
<h2 id="creating-reusable-form-elements">Creating reusable form elements</h2>
<p>We'll be creating Login and Signup screens soon which share similar logic. To prevent us from violating 
the <a href="https://thevaluable.dev/dry-principle-cost-benefit-example/">DRY principle</a>, let's create some 
reusable form components that we can share across these two screens. We'll also create a loading spinner 
component to provide a good user experience whenever a user waits for a long screen transition.</p>
<p>We'll create reusable <code>FormInput</code>, <code>FormButton</code>, and <code>Loading</code> UI components. At the root of this Expo
React Native app, create a <code>src/</code> directory and inside it create another new <code>components/</code> directory.</p>
<p>Inside the <code>src/components/</code> directory, create a new JavaScript file <code>FormInput.js</code>. In this file, we'll 
define a <a href="https://reactjs.org/docs/react-component.html">React component</a> to provide a text input field 
for our Login and Signup screens to use for the user to enter their credentials.</p>
<p>The <code>FormInput.js</code> file should contain the following code snippet:</p>
<pre><code>import React from 'react';
import { StyleSheet, Dimensions } from 'react-native';
import { TextInput } from 'react-native-paper';

const { width, height } = Dimensions.get('screen');

export default function FormInput({ labelName, ...rest }) {
  return (
    &lt;TextInput
      label={labelName}
      style={styles.input}
      numberOfLines={1}
      {...rest}
    /&gt;
  );
}

const styles = StyleSheet.create({
  input: {
    marginTop: 10,
    marginBottom: 10,
    width: width / 1.5,
    height: height / 15,
  },
});</code></pre>


<p>Our next reusable component is going to be in another file <code>FormButton.js</code>. We use it to display a button 
for a user to confirm their credentials.</p>
<p>The <code>FormButton.js</code> file should contain:</p>
<pre><code>import React from 'react';
import { StyleSheet, Dimensions } from 'react-native';
import { Button } from 'react-native-paper';

const { width, height } = Dimensions.get('screen');

export default function FormButton({ title, modeValue, ...rest }) {
  return (
    &lt;Button
      mode={modeValue}
      {...rest}
      style={styles.button}
      contentStyle={styles.buttonContainer}
    &gt;
      {title}
    &lt;/Button&gt;
  );
}

const styles = StyleSheet.create({
  button: {
    marginTop: 10,
  },
  buttonContainer: {
    width: width / 2,
    height: height / 15,
  },
});</code></pre>


<p>Finally, create a <code>Loading.js</code> file. We'll use it to display a loading spinner when a user waits for a 
screen transition.</p>
<p>The <code>Loading.js</code> file should contain:</p>
<pre><code>import React from 'react';
import { View, ActivityIndicator, StyleSheet } from 'react-native';

export default function Loading() {
  return (
    &lt;View style={styles.loadingContainer}&gt;
      &lt;ActivityIndicator size="large" color="#5b3a70" /&gt;
    &lt;/View&gt;
  );
}

const styles = StyleSheet.create({
  loadingContainer: {
    flex: 1,
    alignItems: 'center',
    justifyContent: 'center',
  },
});</code></pre>


<p>Now we have our reusable form components, we can create a Login screen for users to enter our chat app.</p>
<h2 id="creating-a-login-screen">Creating a login screen</h2>
<div><p>The first screen we'll be creating is the login screen. We'll ask an existing user for their email and 
password to authenticate and provide a link to a future sign up form for new users to register with our app.
</p><p>
The login screen should look like this after you're done:</p></div>
<p><img src="https://www.chatkitty.com/images/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/screenshot-login-screen.png" alt="Screenshot: Login screen">  </p>
<p>Inside the <code>src/</code>, create a <code>screens/</code> directory, inside this directory create a <code>LoginScreen.js</code> file.</p>
<p>The <code>LoginScreen.js</code> file should contain:</p>
<pre><code>import React, { useState } from 'react';
import { View, StyleSheet } from 'react-native';
import { Title } from 'react-native-paper';
import FormInput from '../components/FormInput';
import FormButton from '../components/FormButton';

export default function LoginScreen({ navigation }) {
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');

  return (
    &lt;View style={styles.container}&gt;
      &lt;Title style={styles.titleText}&gt;Welcome!&lt;/Title&gt;
      &lt;FormInput
        labelName="Email"
        value={email}
        autoCapitalize="none"
        onChangeText={(userEmail) =&gt; setEmail(userEmail)}
      /&gt;
      &lt;FormInput
        labelName="Password"
        value={password}
        secureTextEntry={true}
        onChangeText={(userPassword) =&gt; setPassword(userPassword)}
      /&gt;
      &lt;FormButton
        title="Login"
        modeValue="contained"
        labelStyle={styles.loginButtonLabel}
        onPress={() =&gt; {
          // TODO
        }}
      /&gt;
      &lt;FormButton
        title="Sign up here"
        modeValue="text"
        uppercase={false}
        labelStyle={styles.navButtonText}
        onPress={() =&gt; navigation.navigate('Signup')}
      /&gt;
    &lt;/View&gt;
  );
}

const styles = StyleSheet.create({
  container: {
    backgroundColor: '#f5f5f5',
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
  },
  titleText: {
    fontSize: 24,
    marginBottom: 10,
  },
  loginButtonLabel: {
    fontSize: 22,
  },
  navButtonText: {
    fontSize: 16,
  },
});</code></pre>


<p>Later, you'll hook up this login screen to ChatKitty to log in users into your app. We've also configured 
the <code>navigation</code> prop to navigate the user to the Signup screen you'll soon be creating. For now, 
let's add a stack navigator to direct users to the initial login route.</p>
<p>Create a new directory <code>src/navigation/</code>. This will contain all the routes and components needed to build 
the app's navigation. Inside this directory, create a <code>AuthStack.js</code> file.</p>
<p>The <code>AuthStack.js</code> file should contain:</p>
<pre><code>import React from 'react';
import { createStackNavigator } from '@react-navigation/stack';
import LoginScreen from '../screens/LoginScreen';

const Stack = createStackNavigator();

export default function AuthStack() {
  return (
    &lt;Stack.Navigator initialRouteName="Login" headerMode="none"&gt;
      &lt;Stack.Screen name="Login" component={LoginScreen} /&gt;
    &lt;/Stack.Navigator&gt;
  );
}</code></pre>


<p>Later, you'll be adding another route for the Signup screen to our navigator.</p>
<p>Next, you'll need a navigation container to hold the app's stacks, starting with the auth stack. 
Create a <code>Routes.js</code> file inside the <code>src/navigation/</code> directory.</p>
<p>The <code>Routes.js</code> file should contain:</p>
<pre><code>import React from 'react';
import { NavigationContainer } from '@react-navigation/native';
import AuthStack from './AuthStack';

export default function Routes() {
  return (
    &lt;NavigationContainer&gt;
      &lt;AuthStack /&gt;
    &lt;/NavigationConta…</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/">https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/</a></em></p>]]>
            </description>
            <link>https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197365</guid>
            <pubDate>Tue, 24 Nov 2020 11:05:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Virtual Experiences for Teams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197289">thread link</a>) | @joalavedra
<br/>
November 24, 2020 | https://onsite.fun/activities | <a href="https://web.archive.org/web/*/https://onsite.fun/activities">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div mb="2"><div><div><p>Connecting teams through personalized and curated virtual activities.</p></div></div><div><div><ul><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f96c0c35e980c07219862d7"><div><div><div><div width="0"><p><img alt="4" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczA1LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczAxLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczAyLnBuZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczAzLkpQRyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczA0LnBuZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="4" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczA1LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczAxLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div></div></div></div><div><p><h6>Archaeology of Leaves</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>Serbian</span></p><p><span> English</span></p><p><span> Spanish</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f96e639d43a3b033484d677"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMy5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMC5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMS5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMi5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMy5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMC5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div></div></div></div><div><p><h6>The Lisbon Street Art Adventure</h6></p><div><p>From 75€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Portuguese</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f96eab3d43a3b033484d678"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwNC5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwMS5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwMi5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwMy5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwNC5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwMS5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Discover Visual Thinking</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>Greek</span></p><p><span>English</span></p><p><span>Spanish</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f96f32bd43a3b033484d679"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDMuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDQuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDIuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDMuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div></div></div></div><div><p><h6>Magic Show with a Professional Magician</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>French</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f970a2ed43a3b033484d67a"><div><div><div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczA0LmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczAxLmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczAyLmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczA0LmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczAxLmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div></div></div></div><div><p><h6>Cocktail Workshop and Masterclass</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Portuguese</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f970dc8d43a3b033484d67b"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDQuSlBHIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDIuSlBHIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDMuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDQuSlBHIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>The Secrets and Scandal of art at the Borghese</h6></p><div><p>From 75€</p><p> / 5 people</p></div><div><div><p><span>English</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f989d667c1a08065afb4615"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDIuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDMuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Create Your Own Espadrilles Workshop</h6></p><div><p>From 350€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Spanish</span></p><p><span>French</span></p></div></div></div><div><div><div><div><p><span>Material included</span></p></div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f9e8c9d758ef0033ec1c532"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTA0LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTAxLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTAyLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTAzLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTA0LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTAxLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div></div></div></div><div><p><h6>Online Live Escape Room</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fa47a42ccb5fb037cbcc1e6"><div><div><div><div width="0"><p><img alt="4" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczA1LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczAxLlBORyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczAyLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczAzLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczA0LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="4" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczA1LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczAxLlBORyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div></div></div></div><div><p><h6>Unlock your body with some dance moves</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Russian</span></p><p><span>Spanish</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fa482163f481803d20dd8f7"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDIuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDMuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Have a Gnocchi Party with your team</h6></p><div><p>From 125€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Italian</span></p><p><span>Portuguese</span></p><p><span>Spanish</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fad1a07687d9703518bcd6c"><div><div><div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMy5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMS5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMi5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMy5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMS5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div></div></div></div><div><p><h6>Unwind your body with yoga flow </h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>Spanish</span></p><p><span>English</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fb548072af9a4030c9e0969"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDIuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDMuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Drawing Memories With Blue Ink</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>Spanish</span></p><p><span>English</span></p><p><span>Greek</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fbae89ecd4d220339f54148"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDIuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDMuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Sweet French Pastry</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Spanish</span></p></div></div></div><div><p><span>NEW</span></p></div><div><div><div></div></div></div><span></span></a></div></div></div></li></ul></div></div></div></div></div>]]>
            </description>
            <link>https://onsite.fun/activities</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197289</guid>
            <pubDate>Tue, 24 Nov 2020 10:54:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Useful Browser Extensions for Developers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197283">thread link</a>) | @avadhoot
<br/>
November 24, 2020 | https://blog.indorse.io/20-useful-browser-extensions-for-devs-2d023da2a3d0 | <a href="https://web.archive.org/web/*/https://blog.indorse.io/20-useful-browser-extensions-for-devs-2d023da2a3d0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@constantin_?source=post_page-----2d023da2a3d0--------------------------------" rel="noopener"><img alt="Constantin" src="https://miro.medium.com/fit/c/96/96/1*TR5J9Q-6q6t6yzz2QMtJpA.png" width="48" height="48"></a></p></div></div></div></div><p id="96fe">On Chrome, <a href="https://medium.com/u/7f273c236233?source=post_page-----2d023da2a3d0--------------------------------" target="_blank" rel="noopener">Firefox</a>, Opera and/or Brave</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3200/1*KuwK-Op861rVKuoVrtuX-g.png" width="1600" height="900" srcset="https://miro.medium.com/max/552/1*KuwK-Op861rVKuoVrtuX-g.png 276w, https://miro.medium.com/max/1104/1*KuwK-Op861rVKuoVrtuX-g.png 552w, https://miro.medium.com/max/1280/1*KuwK-Op861rVKuoVrtuX-g.png 640w, https://miro.medium.com/max/1400/1*KuwK-Op861rVKuoVrtuX-g.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*KuwK-Op861rVKuoVrtuX-g.png?q=20"></p></div></div></div></figure><p id="42bb"><em>“For whom is this list intended?”</em> We started this exercise with this question in mind. The answer we stumble upon at some point = “<em>it’s all relative”</em>! 💡</p><p id="c4f4">Based on <a href="https://medium.com/u/d53dd768d047?source=post_page-----2d023da2a3d0--------------------------------" target="_blank" rel="noopener">Stack Overflow</a>’s latest <a href="https://insights.stackoverflow.com/survey/2020#experience" rel="noopener">Survey</a>, it’s more than clear that there’s a wide range of experience among people calling themselves ‘developers’. Looking at the survey, roughly 40% of ‘professional developers’ learned their first programming language less than 10 years ago. And as highlighted by Stack Overflow, the rest incorporates ‘seasoned developers; who learned to code more than 30 years ago (15%), but also those who learned how to code less than five years ago (17%).</p><p id="47e2">In other words, depending on your experience, age, personal opinion on dev tools, etc. this list might be interesting, and even useful. These are 20 of the best browser extensions for devs! 😁</p><blockquote><p id="8da7">Disclaimer: a big thanks goes to our dev teammates for sharing some of their secret tools with us (e.g. Octotree.. <em>🤫</em>)!</p></blockquote><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*JlAgx_FsG5VU2K1mvq5M3w.png" width="1400" height="98" srcset="https://miro.medium.com/max/552/1*JlAgx_FsG5VU2K1mvq5M3w.png 276w, https://miro.medium.com/max/1104/1*JlAgx_FsG5VU2K1mvq5M3w.png 552w, https://miro.medium.com/max/1280/1*JlAgx_FsG5VU2K1mvq5M3w.png 640w, https://miro.medium.com/max/1400/1*JlAgx_FsG5VU2K1mvq5M3w.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*JlAgx_FsG5VU2K1mvq5M3w.png?q=20"></p></div></div></div></figure><h2 id="2e17"><a href="https://chrome.google.com/webstore/detail/web-developer/bfbameneiokkgbdmiekhjnmfkcnldhhm" rel="noopener"><strong>Web Developer</strong></a></h2><p id="e9ab">This extension will add a toolbar button to your browser and include various web dev tools. You’ll find a lot of different choices under each of the proposed categories: CSS, Cookies, Forms, Outline, Informations, etc. <em>Note. Over 1 million users.</em></p><p id="aed7"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/web-developer/" rel="noopener"><strong>Mozilla</strong></a><strong> and </strong><a href="https://addons.opera.com/en/extensions/details/web-developer/" rel="noopener"><strong>Opera</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="8bfc"><a href="https://chrome.google.com/webstore/detail/lambdatest-screenshots/fjcjehbiabkhkdbpkenkhaahhopildlh" rel="noopener"><strong>LambdaTest</strong></a></h2><p id="dbf8">A handy tool for your cross-browser compatibility testing. You no longer have to type in lengthy URLs as it automatically pulls the URL across different desktop and mobile browsers. You can test it at any stage — be it integration, staging, or prod environment. It is indeed one of the best extensions out there with an easy to use UI!</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="ab47"><a href="https://chrome.google.com/webstore/detail/dailydev-news-for-busy-de/jlmpjdjjbgclbocgajdjefcidcncaied" rel="noopener"><strong>daily.dev</strong></a></h2><p id="59f3">This one will help you to stay up-to-date with what’s going on in the devs universe! Note. Might be a galaxy, I’m not sure..</p><p id="359c"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/daily/" rel="noopener"><strong>Mozilla</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="1e08"><a href="https://chrome.google.com/webstore/detail/jsonview/chklaanhfefbnpoihckbnefhakgolnmc" rel="noopener"><strong>JSONView</strong></a></h2><p id="766a">You’re probably constantly working with JSON, and it can be a pain to view and format the JSON. This extension here will show the response JSON in a proper format. It covers everything you need to read JSON docs: coloring the code, the possibility of navigating through the nodes, opening and closing them, working with paths and values.</p><p id="8e1f"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/jsonview/" rel="noopener"><strong>Mozilla</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="2fb8"><a href="https://chrome.google.com/webstore/detail/enhanced-github/anlikcnbgdeidpacdbdljnabclhahhmd" rel="noopener">Enhanced GitHub</a></h2><p id="da4a">This extension provides very useful information like the size of each file, download link, and it also helps to copy the file contents directly to the clipboard.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="a0fb"><a href="https://addons.mozilla.org/en-US/firefox/addon/reduxdevtools/" rel="noopener">Redux DevTools</a></h2><p id="6e8a">If you are using redux, you must use this one.. a cool way for debugging! Note. It also seems to be an <a href="https://github.com/zalmoxisus/redux-devtools-extension" rel="noopener">open-source</a> project. +1</p><p id="dbcd"><strong>Note. Only available on Firefox!</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="475b"><a href="https://chrome.google.com/webstore/detail/clear-cache/cppjkneekbjaeellbfkmgnhonkkjfpdn" rel="noopener"><strong>Clear Cache</strong></a></h2><p id="c002">For those of you that will need to frequently clear their browser cache.. this extension is one of the best extensions for doing this in a single click. Note. You can customize the amount of data to clear in the options tab.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="7aca"><a href="https://chrome.google.com/webstore/detail/cssviewer/ggfgijbpiheegefliciemofobhmofgce" rel="noopener"><strong>CSSViewer</strong></a></h2><p id="4e21">Great to use as a quick and easy resource that could help you avoid <em>inspecting</em> objects. This extension will show you a floating panel depending on what your mouse pointing at — info include font, text, color, background, box, positioning, and effects attributes.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="bc44"><a href="https://chrome.google.com/webstore/detail/site-palette/pekhihjiehdafocefoimckjpbkegknoh?ref=designrevision.com" rel="noopener"><strong>Site Palette</strong></a></h2><p id="ab59">Have you ever visited a webpage and simply loved the color palette? Well, Site Palette will help you see why you fell in live! With this extension, you can easily get the color palette of a page in seconds. This is definitely one of the most useful and helpful extensions for both designers and devs.</p><p id="f421"><strong>You can check </strong><a href="https://chrome.google.com/webstore/detail/colorzilla/bhlhnicpbhignbdhedgjhgdocnmhomnp?hl=en" rel="noopener"><strong>ColorZilla</strong></a><strong> if you’re using Mozilla.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="ae15"><a href="https://chrome.google.com/webstore/detail/octotree-github-code-tree/bkhaagjahfmjljalopjnoealnfndnagc" rel="noopener"><strong>Octotree</strong></a></h2><p id="ea5b">This extension lets you explore the files and folders of a repository with a tree view of the repo in a collapsible sidebar. This brings your GitHub experience to the next level. Someone, please come up with a petition for this to be a standard feature on <a href="https://medium.com/u/8df3bf3c40ae?source=post_page-----2d023da2a3d0--------------------------------" target="_blank" rel="noopener">GitHub</a>! ;)</p><p id="b22d"><strong>Also available on </strong><a href="https://addons.opera.com/en/extensions/details/octotree/" rel="noopener"><strong>Opera</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="4af8"><a href="https://chrome.google.com/webstore/detail/session-buddy/edacconmaakjimmfgnblocblbcdcpbko" rel="noopener"><strong>Session Buddy</strong></a></h2><p id="c2d6">This nifty extension will help you manage your multitasking browsing sessions. If you want to save entire Chrome sessions and recover them later, this is might be your next favorite tool.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="4272"><a href="https://chrome.google.com/webstore/detail/wappalyzer/gppongmhjkpfnbhagpmjfkannfbllamg?ref=designrevision.com" rel="noopener"><strong>Wappalyzer</strong></a></h2><p id="308b">This extension helps you identify the technologies used to build the website you’re looking at. It’ll give you info about the programming languages, analytics, marketing tools, payment processors, CRM, CDN, etc. Note. Pretty simple to use…</p><p id="ad61"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/wappalyzer/" rel="noopener"><strong>Mozilla</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="6453"><a href="https://chrome.google.com/webstore/detail/editthiscookie/fngmhnnpilhplaeedifhccceomclgfbg" rel="noopener"><strong>Edit this cookie</strong></a></h2><p id="614e">Convenient, fast, and easy solution for those who need a free cookie manager. It is a simple and brilliant way to get rid of pesky <em>cookies, </em>sites, etc.</p><p id="6cb9"><strong>Also available on </strong><a href="https://addons.opera.com/en/extensions/details/edit-this-cookie/" rel="noopener"><strong>Opera</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="7a68"><a href="https://chrome.google.com/webstore/detail/grepper/amaaokahonnfjjemodnpmeenfpnnbkco?ref=designrevision.com" rel="noopener"><strong>Grepper</strong></a></h2><p id="6872">Imagine you’re doing a Google search and the answer, the exact answer you were looking for, is just there, no searching around, it’s just there. Well, this extension is helping achieving this dream of ours. Note. +2</p><p id="57fc"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/grepper/" rel="noopener"><strong>Mozilla</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="9635"><a href="https://addons.mozilla.org/en-US/firefox/addon/multi-account-containers/" rel="noopener"><strong>Firefox Multi-Account Containers</strong></a></h2><p id="ad69">Use this one to segregate various accounts based on their “nature”. A good extension to have when you want to enhance your privacy and experience during dev testing. Note. Of course it’s on <a href="https://medium.com/u/95f4ec6ae6f6?source=post_page-----2d023da2a3d0--------------------------------" target="_blank" rel="noopener">Mozilla</a> and <a href="https://medium.com/u/7f273c236233?source=post_page-----2d023da2a3d0--------------------------------" target="_blank" rel="noopener">Firefox</a>!!</p><p id="ef51"><strong>Note. Only on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/multi-account-containers/" rel="noopener"><strong>Firefox</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="9960"><a href="https://chrome.google.com/webstore/detail/notion-web-clipper/knheggckgoiihginacbkhaalnibhilkk" rel="noopener"><strong>Notion Web Clipper</strong></a></h2><p id="e0b9">This (pretty known) extension lets you add links to <a href="https://medium.com/u/efd97a1c507b?source=post_page-----2d023da2a3d0--------------------------------" target="_blank" rel="noopener">Notion</a>’s databases directly from your web browser. Easy peasy.. lemon squeezy. Note. This will free yourself from hunting through your bookmarks.</p><p id="9568"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/notion-web-clipper/" rel="noopener"><strong>Mozilla</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="bba5"><a href="https://chrome.google.com/webstore/detail/ghostery-%E2%80%93-privacy-ad-blo/mlomiejdfkolichcflejclcbmpeaniij" rel="noopener"><strong>Ghostery</strong></a></h2><p id="1450">A must-have. This add-on will help you detect <em>threats</em> like beacons, behavioral data providers, block scripts, and more. No more inappropriate ads for you!</p><p id="d708"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/ghostery/" rel="noopener"><strong>Mozilla</strong></a><strong> and </strong><a href="https://addons.opera.com/en/extensions/details/ghostery/" rel="noopener"><strong>Opera</strong></a><strong>!</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="71e2"><a href="https://chrome.google.com/webstore/detail/moesif-origin-cors-change/digfbfaphojjndkpccljibejjbppifbc" rel="noopener"><strong>Moesif Origin &amp; CORS Changer</strong></a></h2><p id="bf07">This plugin allows you to send cross-domain requests directly from the browser without receiving Cross-origin Errors! Note. I must confess.. I didn’t try this one yet.</p><p id="1175"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/moesif-origin-cors-changer1/" rel="noopener"><strong>Mozilla</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="8ba5"><a href="https://chrome.google.com/webstore/detail/lighthouse/blipmdconlkpinefehnmjammfjpmpbjk" rel="noopener"><strong>Lighthouse</strong></a></h2><p id="4bf5">This is an open-source tool created by <a href="https://medium.com/u/991272e72e68?source=post_page-----2d023da2a3d0--------------------------------" target="_blank" rel="noopener">Google Developers</a>. It’s used as a baseline by a good number of front-end developers to assess various performance metrics of web pages. This add-on can help in improving the quality of your website by running a number of tests called “audits” under simulated conditions. (e.g. how will a webpage perform on a laptop with a slow internet connection, etc.)</p><p id="1edb"><strong>Also available on </strong><a href="https://addons.mozilla.org/en-US/firefox/addon/google-lighthouse/" rel="noopener"><strong>Mozilla</strong></a><strong>.</strong></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*PEH6OVu_TqFMG_rCQD5InA.png" width="1400" height="70" srcset="https://miro.medium.com/max/552/1*PEH6OVu_TqFMG_rCQD5InA.png 276w, https://miro.medium.com/max/1104/1*PEH6OVu_TqFMG_rCQD5InA.png 552w, https://miro.medium.com/max/1280/1*PEH6OVu_TqFMG_rCQD5InA.png 640w, https://miro.medium.com/max/1400/1*PEH6OVu_TqFMG_rCQD5InA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PEH6OVu_TqFMG_rCQD5InA.png?q=20"></p></div></div></div></figure><h2 id="0744"><a href="https://chrome.google.com/webstore/detail/marmoset/npkfpddkpefnmkflhhligbkofhnafieb?hl=en" rel="noopener">Marmoset</a></h2><p id="96fb">Used it a couple of times when writing articles that needed to include some code snippets. Ads you have probably guessed, this small extension will allow you to take code snapshots with one click.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2800/1*JlAgx_FsG5VU2K1mvq5M3w.png" width="1400" height="98" srcset="https://miro.medium.com/max/552/1*JlAgx_FsG5VU2K1mvq5M3w.png 276w, https://miro.medium.com/max/1104/1*JlAgx_FsG5VU2K1mvq5M3w.png 552w, https://miro.medium.com/max/1280/1*JlAgx_FsG5VU2K1mvq5M3w.png 640w, https://miro.medium.com/max/1400/1*JlAgx_FsG5VU2K1mvq5M3w.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*JlAgx_FsG5VU2K1mvq5M3w.png?q=20"></p></div></div></div></figure><p id="c769">While building our main product which is focused on monitoring various engineering metrics — for Engineering Managers, Developer Experience teams — we’ve built a complementary <a href="https://indorse.io/metamorph/extension" rel="noopener"><strong>free browser extension</strong></a> that can be used to inspect Git repo on GitHub, GitLab, and Bitbucket.</p><p id="f2e9">On <a href="https://chrome.google.com/webstore/detail/metamorph/fpmahcaijpfjkckfdppolkfmheooefem" rel="noopener"><strong>Chrome</strong></a><strong> </strong>or <a href="https://addons.opera.com/en/extensions/details/metamorph-2/" rel="noopener"><strong>Opera</strong></a>.</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.indorse.io/20-useful-browser-extensions-for-devs-2d023da2a3d0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197283</guid>
            <pubDate>Tue, 24 Nov 2020 10:52:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye breakfast: 6 months of Intermittent Fasting]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25197199">thread link</a>) | @beatlevic
<br/>
November 24, 2020 | https://beatletech.com/2020/11/24/goodbye-breakfast | <a href="https://web.archive.org/web/*/https://beatletech.com/2020/11/24/goodbye-breakfast">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            
            

            <p>Tuesday, 24 November 2020.</p>

            <p><img src="https://s3-eu-west-1.amazonaws.com/eu-west-1.beatletech.com/images/intermittent-fasting-mogwai-16-8-blue.png" alt="Intermittent Fasting 16/8" width="70%" title="Intermittent Fasting 16/8"></p>

<p><em><strong>DISCLAIMER:</strong> I’m not an MD, so please read this blog post only as an interesting starting point for your own research and always check with your own doctor or dietician if you want to try this at home. You are responsible for your own health.</em></p>

<hr>

<p>For the past 6 months I have been doing <code>intermittent fasting</code> (IF) by eating daily only during an 8 hour window: between noon and 8pm. On top of that I had three water-only fasts where I didn’t eat anything for multiple days (4-5) in a row.</p>

<p>That’s madness you might say! Why would you starve yourself? Breakfast is the most important meal of the day and you are skipping it!</p>

<p>Well, I currently believe that it would be madness NOT to fast, and have both scientific and 6 months of anecdotal evidence to back that up. When I was just a few weeks into intermittent fasting, I was already so positively surprised by the initial results that I wanted to tell everybody about my “discovery”, especially because I believed I could also explain why and how it works after reading into the physiology and research behind it. I decided to first see if I could stick with it for a couple of months and then write about my experiences. So here I am, 6 months later, ready to tell you all about my journey and “why” intermittent fasting is so interesting.</p>

<h3 id="benefits">Benefits</h3>

<p>Before we dive in, what’s in it for you? What kind of benefits are we talking about? There are the following immediate known and lasting benefits that I experienced:</p>
<ul>
  <li>Weight loss</li>
  <li>Higher levels of energy</li>
  <li>Feeling stronger (due to increase in human growth hormone)</li>
  <li>Better focus</li>
  <li>Decrease in hay fever symptoms (to be fair, I could have been lucky with a mild season)</li>
</ul>

<p>And there are (potential) long term benefits (<a href="https://www.nejm.org/doi/full/10.1056/nejmra1905136">1</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3106288/">2</a>, <a href="https://www.healthline.com/nutrition/10-health-benefits-of-intermittent-fasting">3</a>):</p>
<ul>
  <li>Cellular repair (Autopaghy)</li>
  <li>Decreased <a href="https://www.webmd.com/diabetes/insulin-resistance-syndrome">insulin resistance</a></li>
  <li>Decreased incidence of diseases, including cancers, obesity, neurological disorders and cardiovascular disease.</li>
  <li>Increased stress resistance</li>
  <li>Increased longevity and quality of life</li>
</ul>

<p>Fasting sounds like a miracle drug doesn’t it? You don’t even have to pay money for it! That’s also probably why you won’t see any fasting ads on your timeline or tv commercials (e.g., “Stop buying our cornflakes and just skip breakfast now!”). It is essentially free and available for you to try out.</p>

<p>Without further ado, let’s explore intermittent fasting and why it works.</p>

<h3 id="intermittent-fasting">Intermittent Fasting</h3>

<p>People have been actively fasting, i.e., periods of consciously not eating, since ancient times (<a href="https://thefastingmethod.com/fasting-a-history-part-i/">4</a>) and it has, unwillingly, been part of the eating pattern of our ancestors when food wasn’t always around (e.g. hunting on an empty stomach), although strictly speaking you would call it starvation if you don’t know when you will get your next meal. It just shows, that our bodies have been evolutionary adapted to handle feast and famine. It’s being exposed to stress, variability, volatility and randomness (up to a point and not continuously), that makes us stronger (i.e., <a href="https://en.wikipedia.org/wiki/Antifragile">antifragile</a>).</p>

<p>Recently intermittent fasting has become a more popular form of fasting, which can be defined as <strong>an eating pattern in which you cycle between periods of eating and fasting</strong>, where you stretch each fasting period long enough to force your body into switching from burning glucose (sugar) and glycogen (stored sugar) to fat burning. This is what is called <code>metabolic flexibility</code>, where your body makes use of whatever fuel is available. As a bonus, it seems that ketosis (i.e., the metabolic state running on fat for fuel) is the main driver for fat burning in the abdomen region, belly fat!</p>

<p><strong>So how long do you have to NOT eat to switch to fat burning?</strong> Apparently, energy intake restriction for 10 to 14 hours results in depletion of liver glycogen stores (<a href="https://www.nejm.org/doi/full/10.1056/nejmra1905136">1</a>, <a href="https://www.semanticscholar.org/paper/Fuel-metabolism-in-starvation.-Cahill/a8bb8327226d35259e68ecd8edcc17a3a1380f4a">5</a>) after which fat, fatty acids, are freed to form <code>ketones</code> that are used to fuel your body (as opposed to glucose). The more <code>fat adapted</code> you are, the quicker your body will switch to fat burning, something you get more adapted to as a result of prolonged intermittent fasting.</p>

<p>Given the required minimum of 10 to 14 hours of fasting to start producing ketones, you have different patterns for intermittent fasting you could follow:</p>
<ul>
  <li><strong>16/8</strong>: A daily window of 8 hours, often from noon to 8pm (so no breakfast), for eating and 16 hours of fasting (during the night and morning).</li>
  <li><strong>5:2</strong>: 5 days eating, 2 days fasting.</li>
  <li><strong>Alternate day</strong>: Alternate days of eating and fasting</li>
  <li><strong>One Meal a Day (OMAD)</strong>: Sticking to one meal a day, often dinner, and fast the rest of the day.</li>
</ul>

<p>I chose <strong>16/8</strong>, because it fits nicely with having kids that are not on a fasting schedule (nor should they ever be when they are young and still growing), having lunch and dinner together. I also like the consistency of following the same schedule every day, apart from sporadic multi-day periods of water-only fasts (more on that later).</p>

<p><strong>Aren’t you also burning up your muscles during fasting?</strong> Nope. Your body is naturally preserving your muscles by increasing <code>human growth hormone</code> (HGH), which also helps building muscles after the fasting period as HGH levels remain high.</p>

<p><strong>So all the benefits come from fat burning and the increase in human growth hormone?</strong> Actually those account for only part of the benefits. The third and arguable the most interesting process during fasting is called <code>autophagy</code>, which literally translates to “self eating”, an apt description for the cellular repair and rejuvenation that will happen in your body.</p>

<h4 id="autophagy">Autophagy</h4>

<p>Your body continuously needs amino acids, the building blocks for new cells, and when you are not eating you are not taking in new amino acids (proteins). The body already recycles your old and damaged cells to harvest these building blocks, but during fasting has to work harder to get enough of this material. It does this by increasing your immune system in order to “scavenge” in all the nooks and crannies of your body for cells to break down. Cells that otherwise would be “good enough yet mediocre” are now also recycled.</p>

<p>This is the only process known to rejuvenate neural pathways when you are getting older, and you will be safeguarding and protecting yourself against neurological and auto-immune disorders (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3106288/">2</a>).</p>

<p>The importance of autophagy has also been clearly demonstrated by Japanese cell biologist Yoshinori Ohsumi, who won, in 2016, the Nobel Prize in Medicine for his research on this very topic, showing how autophagy helps slow down the aging process (<a href="https://www.nobelprize.org/prizes/medicine/2016/press-release/">6</a>).</p>

<h4 id="key-concepts">Key concepts</h4>

<p>Now that we covered what intermittent fasting is, how it works and benefits you, by going over some of the key concepts: the metabolic switch to fat burning, the increase in human growth hormone and autophagy. I like to move on to sharing my experience of putting intermittent fasting into practice.</p>

<h3 id="my-6-month-journey">My 6 Month Journey</h3>

<p>During the first Coronavirus lockdown in April (in the Netherlands), I spent most of my time homeschooling my three kids and working for <a href="https://rekall.ai/">rekall.ai</a>, while neglecting sporting activities and not eating healthy consistently (e.g., more snacks). So when the kids were allowed to go back to school again in May, I stepped on the scale and found myself nearing 100 kg. This for me, being 1.98m tall (6’6”), meant I was being borderline overweight according to my <a href="https://www.nhlbi.nih.gov/health/educational/lose_wt/BMI/bmicalc.htm">BMI</a> calculation (&gt;25). I have never seen myself weigh more than 100 kg (220 lb) and didn’t want to see that happen, so it was time for action!</p>

<p>I set a weight goal to lose 8 kg in 6 weeks and weigh no more than 90 kg (200 lb) on my birthday (June 26th). In order to get there I wanted to follow a low-carb Paleo diet (<a href="https://www.mayoclinic.org/healthy-lifestyle/nutrition-and-healthy-eating/in-depth/paleo-diet/art-20111182">Caveman diet</a>), which I had followed 10 years prior with great <a href="https://about.me/beatlevic">results</a>. Doing some online research and catching up on Youtube with low-carb and Keto diets, is when I stumbled upon intermittent fasting videos (<a href="https://youtu.be/thZFIPOAGNQ">7</a>, <a href="https://youtu.be/thgVz3837l0">8</a>, <a href="https://youtu.be/LLVf3d0rqqY">9</a>). As you know by reading this far, the benefits of IF sounded amazing, so I decided, under the medical supervision of my wife, who is an actual MD, to go all in.</p>

<h4 id="weight-loss-results">Weight loss results</h4>

<p>In the following annotated graph you can view my weight over the course of the past 6 months. I’ll provide you with more context in the next sections.</p>







<h4 id="first-2-weeks">First 2 weeks</h4>

<p>I started May 13th weighing <strong>97.9 kg</strong> (A). To keep track of my eating window I set two alarms, one at 12.30pm labeled ‘lunch’ and the other at 8pm ‘no more eating’. For my exercise routine I started to play tennis on Monday mornings, and I tried to run 6-7 km twice a week.</p>

<p>I switched to a low-carb diet (Paleo): eating more meat, salads, fruits (primarily berries), vegetables and nuts. No longer eating bread, pasta, rice and oatmeal.</p>

<p>After one week I already lost 2 kg, and another 1 kg after the second week. I found it very easy to stick to the 8 hour eating window and I was not experiencing hunger sensations in the morning or late evenings. Probably because I was already used to skipping breakfast quite often, and because a low-carb diet also helps lowering your insulin spikes and cravings for more sugar. With lower insulin levels, as a result of lower overall blood sugar, you are also quicker in switching to fat burning!</p>

<h4 id="water-only-fasting">Water-only Fasting</h4>

<p>With this great start, I was feeling bullish about the changes and progression I had made, but I wanted to push fasting a bit harder. So I decided to try water-only fasting, i.e., eating nothing for a couple of days and only consuming water and some minerals (salt for electrolytes). In theory, your body should just switch to fat burning after 12 hours, increase your level of human growth hormone and increase your adrenaline and metabolism.</p>

<p><strong>So what about water-only fasting in practise?</strong> If you would have asked me a year ago, I would have guessed you would continuously feel very hungry and tired. Now I can tell you from experience that it is nothing like that, and that I continued to have plenty of energy throughout the 5 days that I fasted (B-C). Yes, you will feel a bit hungry around the times you would normally eat, but that feeling passes quickly. I believe being on IF together …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beatletech.com/2020/11/24/goodbye-breakfast">https://beatletech.com/2020/11/24/goodbye-breakfast</a></em></p>]]>
            </description>
            <link>https://beatletech.com/2020/11/24/goodbye-breakfast</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197199</guid>
            <pubDate>Tue, 24 Nov 2020 10:36:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Posting JSON with an HTML Form (2016)]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25197155">thread link</a>) | @graderjs
<br/>
November 24, 2020 | https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html | <a href="https://web.archive.org/web/*/https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>A coworker and I were looking at an application today that, like so many other
modern web applications, offers a RESTful API with JSON being used for
serialization of requests/responses.  She noted that the application didn’t
include any sort of CSRF token and didn’t seem to use any of the headers
(X-Requested-With, Referer, Origin, etc.) as a “poor man’s CSRF token”, but
since it was posting JSON, was it really vulnerable to CSRF?  <strong>Yes, yes,
definitely yes!</strong></p>

<p>Interestingly, this is reminiscent of many of the confusions between server and
browser that are described in Michal Zalewski’s <a href="https://amzn.to/2QyTUaH">The Tangled
Web</a>.</p>

<p>The idea that the use of a particular encoding is a security boundary is, at
worst, a completely wrong notion of security, and at best, a stopgap until W3C,
browser vendors, or a clever attacker gets hold of your API.  Let’s examine JSON
encoding as a protection against CSRF and demonstrate a mini-PoC.</p>

<h3 id="the-application">The Application</h3>

<p>We have a basic application written in Go.  Authentication checking is elided
for post size, but this is <em>not</em> just an unauthenticated endpoint.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"encoding/json"</span>
	<span>"fmt"</span>
	<span>"net/http"</span>
<span>)</span>

<span>type</span> <span>Secrets</span> <span>struct</span> <span>{</span>
	<span>Secret</span> <span>int</span>
<span>}</span>

<span>var</span> <span>storage</span> <span>Secrets</span>

<span>func</span> <span>handler</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>if</span> <span>r</span><span>.</span><span>Method</span> <span>==</span> <span>"POST"</span> <span>{</span>
		<span>json</span><span>.</span><span>NewDecoder</span><span>(</span><span>r</span><span>.</span><span>Body</span><span>)</span><span>.</span><span>Decode</span><span>(</span><span>&amp;</span><span>storage</span><span>)</span>
	<span>}</span>
	<span>fmt</span><span>.</span><span>Fprintf</span><span>(</span><span>w</span><span>,</span> <span>"The secret is %d"</span><span>,</span> <span>storage</span><span>.</span><span>Secret</span><span>)</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>handler</span><span>)</span>
	<span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>)</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>As you can see, it basically serves a secret number that can be updated via
HTTP POST of a JSON object.  If we attempt a URL-encoded or multipart POST, the
JSON decoding fails miserably and the secret remains unchanged.  We must POST
JSON in order to get the secret value changed.</p>

<h3 id="exploring-options">Exploring Options</h3>

<p>So let’s explore our options here.  The site can locally use AJAX via the
XMLHTTPRequest API, but due to the <a href="https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy">Same-Origin
Policy</a>,
an attacker’s site cannot use this.  For most CSRF, the way to get around this
is plain HTML forms, since form submission is not subject to the Same-Origin
Policy.  The W3C had a <a href="https://www.w3.org/TR/html-json-forms/">draft specification for JSON
forms</a>, but that has been abandoned
since late 2015, and isn’t supported in any browsers.  There are probably some
techniques that can make use of Flash or other browser plugins (aren’t there
always?) but it can even be done with basic forms, it just takes a little work.</p>

<h3 id="json-in-forms">JSON in Forms</h3>

<p>Normally, if we try to POST JSON as, say, a form value, it ends up being URL encoded,
not to mention including the field name.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre><span>&lt;form</span> <span>method=</span><span>'POST'</span><span>&gt;</span>
  <span>&lt;input</span> <span>name=</span><span>'json'</span> <span>value=</span><span>'{"foo": "bar"}'</span><span>&gt;</span>
  <span>&lt;input</span> <span>type=</span><span>'submit'</span><span>&gt;</span>
<span>&lt;/form&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Results in a POST body of:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>json=%7B%22foo%22%3A+%22bar%22%7D
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Good luck decoding that as JSON!</p>

<p>Doing it as the form field name doesn’t get any better.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>%7B%22foo%22%3A+%22bar%22%7D=value
</pre></td></tr></tbody></table></code></pre></div></div>

<p>It turns out you can set the enctype of your form to <code>text/plain</code> and avoid the
URL encoding on the form data.  At this point, you’ll get something like:</p>



<p>Unfortunately, we still have to contend with the form field name and the
separator (<code>=</code>).  This is a simple matter of splitting our payload across both
the field name and value, and sticking the equals sign in an unused field.  (Or
you can use it as part of your payload if you need one.)</p>

<h3 id="putting-it-all-together">Putting it All Together</h3>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>&lt;body</span> <span>onload=</span><span>'document.forms[0].submit()'</span><span>&gt;</span>
  <span>&lt;form</span> <span>method=</span><span>'POST'</span> <span>enctype=</span><span>'text/plain'</span><span>&gt;</span>
    <span>&lt;input</span> <span>name=</span><span>'{"secret": 1337, "trash": "'</span> <span>value=</span><span>'"}'</span><span>&gt;</span>
  <span>&lt;/form&gt;</span>
<span>&lt;/body&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This results in a request body of:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>{"secret": 1337, "trash": "="}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This parses just fine and updates our secret!</p>

  </div><p>This post contains affiliate links.  If you click on
a link, I may earn a small commission at no cost to you.</p></div>]]>
            </description>
            <link>https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197155</guid>
            <pubDate>Tue, 24 Nov 2020 10:26:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Curl Web Infrastructure]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197053">thread link</a>) | @virde
<br/>
November 24, 2020 | https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>The purpose of the <a href="https://curl.se/">curl web site</a> is to inform the world about what curl and libcurl are and provide as much information as possible about the project, the products and everything related to that.</p>



<p>The web site has existed in some form for as long as the project has, but it has of course developed and changed over time.</p>



<h2>Independent</h2>



<p>The curl project is completely independent and stands free from influence from any parent or umbrella organization or company. It is not even a legal entity,  just a bunch of random people  cooperating over the Internet. And a bunch of <a href="https://curl.se/sponsors.html">awesome sponsors</a> to help us.</p>



<p>This means that we have no one that provides the infrastructure or marketing for us. We need to provide, run and care for our own servers and anything else we think we should offer our users.</p>



<div><figure><a href="https://www.wolfssl.com/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png" alt="" width="187" height="144" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png 1011w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-200x155.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-450x348.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-768x594.png 768w" sizes="(max-width: 187px) 100vw, 187px"></a></figure></div>



<p>I still do a lot of the work in curl and the curl web site and I work full time on curl, for <a href="https://www.wolfssl.com/">wolfSSL</a>. This might of course “taint” my opinions and views on matters, but doesn’t imply ownership or control. I’m sure we’re all colored by where we work and where we are in our lives right now.</p>



<h2>Contents</h2>



<p>Most of the web site is static content: generated HTML pages. They are served super-fast and very lightweight by any web server software.</p>



<p>The web site source exists in the <a href="https://github.com/curl/curl-www/">curl-www</a> repository (hosted on GitHub) and the web site syncs itself with the latest repository changes several times per hour. The parts of the site that aren’t static are mostly consisting of smaller scripts that run either on demand at the time of a request or on an interval in a cronjob in the background. That is part of the reason why pushing an update to the web site’s repository can take a little while until it shows up on the live site.</p>



<p>There’s a deliberate effort at not duplicating information so a lot of the web pages you can find on the web site are files that are converted and “HTMLified” from the source code git repository.</p>



<h2>“Design”</h2>



<p>Some people say the curl web site is “retro”, others that it is plain ugly. My main focus with the site is to provide and offer all the info, and have it be accurate and accessible. The look and the design of the web site is a constant battle, as nobody who’s involved in editing or polishing the web site is really interested in or particularly good at design, looks or UX. I personally have done most of the editing of it, including CSS etc and I can tell you that I’m not good at it and I don’t enjoy it. I do it because I feel I have to.</p>



<p>I get occasional offers to “redesign” the web site, but the general problem is that those offers almost always involve rebuilding the entire thing using some current web framework, not just fixing the looks, layout or hierarchy. By replacing everything like that we’d get a lot of problems to get the existing information in there – and again, the information is more important than the looks.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-1200x459.png" alt="" width="379" height="145" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-1200x459.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-200x76.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-450x172.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-768x294.png 768w" sizes="(max-width: 379px) 100vw, 379px"></figure></div>



<p>The <a href="https://daniel.haxx.se/blog/2016/05/27/a-new-curl-logo/" data-type="post" data-id="8817">curl logo</a> is designed by a proper designer however (Adrian Burcea).</p>



<p>If you want to help out designing and improving the web site, you’d be most welcome!</p>



<h2>Who</h2>



<p>I’ve already touched on it: the web site is mostly available in git so “anyone” can submit issues and pull-requests to improve it, and we are around twenty persons who have push rights that can then make a change on the live site. In reality of course we are not that many who work on the site any ordinary month, or even year.  During the last twelve month period, 10 persons authored commits in the web repository and I did 90% of those.</p>



<h2>How</h2>



<p>Technically, we build the site with traditional makefiles and we generate the web contents mostly by preprocessing files using a C-like preprocessor called <a href="https://daniel.haxx.se/projects/fcpp/">fcpp</a>. This is an old and rather crude setup that we’ve used for over twenty years but it’s functional and it allows us to have a mostly static web site that is also fairly easy to build locally so that we can work out and check improvements before we push them to the git repository and then out to the world.</p>



<p>The web site is of course only available over HTTPS.</p>



<h2>Hosting</h2>



<div><figure><a href="https://www.haxx.se/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010.png" alt="" width="288" height="97" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010.png 1046w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-200x68.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-450x152.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-768x260.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-1038x354.png 1038w" sizes="(max-width: 288px) 100vw, 288px"></a></figure></div>



<p>The <a href="https://daniel.haxx.se/blog/2020/10/23/a-server-transition/" data-type="post" data-id="14836">curl web site is hosted</a> on an origin VPS server in Sweden. The machine is maintained by primarily by me and is paid for by <a href="https://www.haxx.se/">Haxx</a>. The exact hosting is not terribly important because users don’t really interact with our server directly… (Also, as they’re not sponsors we’re just ordinary customers so I won’t mention their name here.)</p>



<h2>CDN</h2>



<p>A few years ago we experienced repeated server outages simply because our own infrastructure did not handle the load very well, and in particular not the traffic spikes that could occur when I would post a blog post that would suddenly reach a wide audience.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-1200x630.png" alt="" width="242" height="127" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-200x105.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-450x236.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-768x403.png 768w" sizes="(max-width: 242px) 100vw, 242px"></figure></div>



<p>Enter <a href="https://www.fastly.com/">Fastly</a>. Now, when you go to <a href="https://curl.se/">curl.se</a> (or <a href="https://daniel.haxx.se/">daniel.haxx.se</a>) you don’t actually reach the origin server we admin, you will instead  reach one of Fastly’s servers that are distributed across the world. They then fetch the web contents from our origin, cache it on their edge servers and send it to you when you browse the site. This way, your client speaks to a server that is likely (much) closer to you than the origin server is and you’ll get the content faster and experience a “snappier” web site. And our server only gets a tiny fraction of the load.</p>



<p>Technically, this is achieved by the name <strong>curl.se</strong> resolving to a number of IP addresses that are <a href="https://en.wikipedia.org/wiki/Anycast">anycasted</a>. Right now, that’s 4 IPv4 addresses and 4 IPv6 addresses.</p>



<p>The fact that the CDN servers cache content “a while” is another explanation to why updated contents take a little while to “take effect” for all visitors.</p>



<h2>DNS</h2>



<p>When we just recently switched the site over to <a href="https://daniel.haxx.se/blog/2020/11/04/the-journey-to-a-curl-domain/" data-type="post" data-id="14930">curl.se</a>, we also adjusted how we handle DNS.</p>



<div><figure><a href="https://www.kirei.se/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/kirei.png" alt="" width="265" height="117"></a></figure></div>



<p>I run our own main DNS server where I control and admin the zone and the contents of it.  We then have four secondary servers to help us really up our reliability. Out of those four secondaries, three are sponsored by <a href="https://www.kirei.se/">Kirei</a> and are anycasted. They should be both fast and reliable for most of the world.</p>



<p>With the help of fabulous friends like Fastly and Kirei, we hope that the curl web site and services shall remain stable and available.</p>



<p>DNS enthusiasts have remarked that we don’t do DNSSEC or registry-lock on the curl.se domain. I think we have reason to consider and possibly remedy that going forward.</p>



<h2>Traffic</h2>



<p>The curl web site is just the home of our little open source project. Most users out there in the world who run and use curl or libcurl will not download it from us. Most curl users get their software installation from their Linux distribution or operating system provider. The git repository and all issues and pull-requests are done on GitHub.</p>



<p>Relevant here is that we have no logging and we run no ads or any analytics. We do this for maximum user privacy and partly because of laziness, since handling logging from the CDN system is work. Therefore, I only have aggregated statistics.</p>



<p>In this autumn of 2020, over a normal 30 day period, the web site serves almost 11 TB of data to 360 million HTTP requests. The traffic volume is up from 3.5 TB the same time last year. 11 terabytes per 30 days equals about 4 megabytes per second on average.</p>



<p>Without logs we cannot know what people are downloading – but we can guess! We know that the <a href="https://curl.haxx.se/docs/caextract.html">CA cert bundle</a> is popular and we also know that in today’s world of containers and CI systems, a lot of things out there will download the same packages repeatedly. Otherwise the web site is mostly consisting of text and very small images.</p>



<p>One interesting specific pattern on the server load that’s been going on for months: every morning at 05:30 UTC, the site gets over 50,000 requests within that single minute, during which 10 gigabytes of data is downloaded. The clients are distributed world wide as I see the same pattern on access points all over. The minute before and the minute after, the average traffic rate remains at 200MB/minute. It makes for a fun graph:</p>



<figure><img loading="lazy" width="1525" height="471" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-24-Fastly-Stats-curl.png" alt=""><figcaption>An eight hour zoomed in window of bytes transferred from the web site. UTC times.</figcaption></figure>



<p>Our servers suffer somewhat from being the target of weird clients like <a href="https://daniel.haxx.se/blog/2020/04/09/a-qqgamehall-storm/" data-type="post" data-id="13880">qqgamehall</a> that continuously “hammer” the site with requests at a high frequency many months after we started always returning error to them. An effect they have is that they make the admin dashboard to constantly show a very high error rate.</p>



<h2>Software</h2>



<p>The origin server runs Debian Linux and Apache httpd. It has a reverse proxy based on nginx. The DNS server is bind. The entire web site is built with free and open source. Primarily: fcpp, make, roffit, perl, curl, hypermail and enscript.</p>



<p>If you curl the curl site, you can see in response headers that <a href="https://www.fastly.com/blog/benefits-using-varnish">Fastly uses Varnish</a>.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197053</guid>
            <pubDate>Tue, 24 Nov 2020 10:09:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enterprise UX Design: Make me think]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25197041">thread link</a>) | @Dmytro_Trotsko
<br/>
November 24, 2020 | https://adamfard.com/blog/enterprise-ux | <a href="https://web.archive.org/web/*/https://adamfard.com/blog/enterprise-ux">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="article-content"><p>“Don’t make me think” is a renowned mantra in the world of design, coined by Steve Krug. It has served as a guiding principle in the world of design and UX for twenty&nbsp;years. It teaches us how to create great experiences in a straightforward and accessible manner.&nbsp;</p><p>In today’s article, we’d like to look into enterprise design and its peculiarities. It’s essential to underline that the very nature of enterprise UX slightly differs from consumer UX. As a result, some of Krug’s principles must be adjusted when designing enterprise software.&nbsp;</p><p>This article is by no means a refutation of the design principle. Please treat it as a mere asterisk with a fine print at the bottom.</p><h2><strong>Learning curves aren’t inherently bad</strong></h2><p>According to Krug, products that make people think also make people unhappy. <a href="https://uxdesign.cc/the-learning-curve-design-problem-4d4dc2965098">Products with steep learning curves</a> very rarely succeed in the modern business ecosystem. Customers will pretty much always choose the path of least resistance. This isn’t necessarily true of enterprise products.</p><p>Enterprise users are power users — and it’s imperative that we take this into account when designing products for them. They interact with niche software on a daily basis and quite possibly for many years. They know their way around the logic of the products they use.&nbsp;</p><p>Creating an interface that demands some learning results in a steeper learning curve isn’t inherently wrong. It allows users to work more efficiently once they’ve invested a certain amount of time into training and learning.&nbsp;</p><figure><img src="https://www.datocms-assets.com/16499/1606137908-figma-shortcuts-cheatsheet-1014x487.jpg?w=900&amp;auto=compress"><figcaption><a href="https://www.figmacrush.com/figma-shortcuts-cheatsheet/">Source</a></figcaption></figure><p>Take, for instance, products like Figma, Sketch, Adobe Pro, or any other professional software — most of them have a wide array of shortcuts. Features such as shortcuts may take a while to master, but they’ll ensure a significant boost in productivity once learned.&nbsp;</p><h2>Simplify cautiously&nbsp;</h2><p>We’re very well aware of the importance of keeping interfaces simple and obvious. However, it’s essential to keep in mind the complexity of the tasks typically performed in enterprise software. The pursuit for a clean UI could rid users of the vital context necessary to get work done.&nbsp;</p><p>Plus, it can be argued that by making the interface too simple, we risk generating friction rather than eliminating it. Let’s envision an interface of a product that displays a wide array of charts and data, like a trading platform.&nbsp;</p><p><img src="https://www.datocms-assets.com/16499/1606138044-image2.png?w=900&amp;auto=compress"></p><p>A professional that regularly interacts with visual data needs immediate access to it at all times. Having to perform extra actions to access vital features is both frustrating and unproductive. And here lies one of the most significant differences between consumer UX and enterprise UX (eUX).&nbsp;</p><p>Consumer UX is really passionate about sleek UIs, while enterprise software must ensure that users are able to do their work comfortably. Therefore, simplified, minimalistic interfaces aren’t really what eUX designers are after.&nbsp;</p><h2>Wizards are cool, but…</h2><p><a href="https://adamfard.com/blog/ux-onboarding">Onboarding your users</a> is a vital step aimed at ensuring optimal user experience. However, while Wizards and guided tours are an excellent solution for casual users, it’s not necessarily the case for power users.&nbsp;</p><p>In both consumer and enterprise UX, designers must aim to develop products that require <a href="https://adamfard.com/blog/stickiness">as little hand-holding as possible</a>. However, simplistic product tours can be… well, simplistic. They often fail to uncover the entire functionality of a product, which is especially relevant for experienced users.&nbsp;</p><p>After running a series of tests, we found out that enterprise users tend to prefer to leave the app or platform for instructions. While this does seem somewhat disruptive to the experience of a product — it is understandable.&nbsp;</p><p><img src="https://www.datocms-assets.com/16499/1606210515-initiative-alladded1-1.png?w=900&amp;auto=compress"></p><p>Off-page instructions can provide more in-depth explanations rather than the ones that are placed on the screen. Compare, for instance, a tool-tip and an article dedicated to a particular function.&nbsp;</p><h2>Plan for non-linear flows&nbsp;</h2><p>When it comes to designing eUX UIs, designers face a truly arduous task of creating complex, non-linear flows. These flows often involve a variety of roles, profile types, responsibilities, kinds of security, and much more. Our goal is to create a consistent and recognizable experience throughout all of these variables.&nbsp;</p><p>The complicated part, however, is not to force users into flows and scenarios. Experts and professional users need that freedom to make decisions and use the platform as they see fit.</p><p>Think of a person that is deeply versed in Microsoft Excel. They’ve been using this software for nearly a decade, and they know it like the back of their hand. More importantly, they have their style of working and solving problems. Limiting such users via linear and rigid flows could defeat the purpose of boosting their productivity.&nbsp;</p><h2>Don’t fix it if it’s not broken</h2><p>Innovation is a crucial element of UX design. We strive to continuously seek new and creative solutions to old problems. Often, we can even choose to be bold and put forth experimental solutions.&nbsp;</p><p>However, when it comes to eUX, we have to be somewhat more conservative and experiment with caution. Enterprise software isn’t quite receptive to design solutions that go against the grain.&nbsp;</p><p>Since the central purpose of such software is to deliver quality work in short amounts of time, “reinventing the wheel” isn’t always a great idea.&nbsp;</p><p>When designing for enterprise, keeping an eye on your competition is even more relevant than in consumer software.&nbsp;</p><p>Let’s go back to Excel once more — imagine <a href="https://adamfard.com/blog/website-redesign">you’re trying to reinvent</a> a complex, spreadsheet-based product. You’re looking to change the ways it represents data, or certain actions are performed. While this does sound like a laudable task, the critical question is — why?&nbsp;</p><p>In eUX, the real value of a product is in its unique selling point that is translated via a design that looks familiar and intuitive.&nbsp;</p><p>That is not to say that the light of innovation never shines on enterprise products, but user expectations often trim the lengths we can go.&nbsp;</p><h2>In conclusion</h2><p>In order to reward you, our beloved reader, for making it till the end, we’ve designed a picture that summarizes the arguments in this article. We hope it will come in handy.</p><p><img src="https://www.datocms-assets.com/16499/1606138895-enterprise-ux-summary.png?w=900&amp;auto=compress"></p><p>While the principles of “don’t make me think” will most likely outlive us, it’s crucial to outline the situations where they can be somewhat amended.&nbsp;</p><p>Enterprise user experience is a slightly more conservative field in terms of design, yet these limitations push us to become even more creative. By operating within these constraints, we have the power to make the future of work exciting and even more promising.&nbsp;</p><p>Meta: In this article, we explore the peculiarities of enterprise user experience design (eUX) through the lens of the “Don’t make me think” principle.&nbsp;</p></article></div>]]>
            </description>
            <link>https://adamfard.com/blog/enterprise-ux</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197041</guid>
            <pubDate>Tue, 24 Nov 2020 10:07:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Any hope of keeping Earth habitable requires sucking CO2 out of the atmosphere]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197019">thread link</a>) | @jeremylevy
<br/>
November 24, 2020 | https://www.businessinsider.fr/us/climate-change-too-late-carbon-capture-needed-2020-11 | <a href="https://web.archive.org/web/*/https://www.businessinsider.fr/us/climate-change-too-late-carbon-capture-needed-2020-11">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                                <h2>Even if greenhouse-gas emissions stop now, global warming will continue for centuries, a study shows. The solution: removing carbon from the air.</h2>
                            </p><div>
                                <ul><li>Even if the world were to stop emitting greenhouse gases right now, the Earth would keep warming for centuries, a new study shows.</li>
<li>The researchers suggest <a href="https://www.businessinsider.com.au/how-to-stop-gobal-warming-plan-carbon-capture-2018-10">sucking carbon dioxide out of the atmosphere</a> and storing it underground — a solution known as carbon capture and storage.</li>
<li>That's considered a type of <a href="https://www.businessinsider.com/geoengineering-how-to-reverse-climate-change-2019-4">geoengineering</a>. Other <a href="https://www.businessinsider.com/geoengineering-how-to-reverse-climate-change-2019-4">climate-hacking</a> proposals in the same category are far riskier.</li>
<li><a href="https://www.businessinsider.com/?hprecirc-bullet">Visit Business Insider's homepage for more stories</a>.</li></ul><p>Even if we stopped emitting greenhouse gas today, the Earth would continue warming for centuries. Arctic ice and permafrost are already on an irreversible path of melting.</p><p><a href="https://www.nature.com/articles/s41598-020-75481-z">That's the finding of new research</a> published Thursday in the journal Scientific Reports. The model suggests that even if emissions were to drop to zero this year, global temperatures would ultimately rise to be 5.4 degrees Fahrenheit higher in 2500 than they were in 1850 (that's 3 degrees Celsius).</p><p>"The tundra will continue to melt over the next 500 years — irrespective of how quickly humanity cuts its greenhouse-gas emissions," Jørgen Randers, the lead author of the new study, told Business Insider.</p><p>That's because climate change is a vicious, self-sustaining cycle: As permafrost thaws, it releases more greenhouse gases, like methane and carbon dioxide, which sustains warming over time. To stop that cycle, Randers said, we'll need to suck carbon dioxide back out of the atmosphere.</p><h2>8 feet of sea-level rise</h2><p>Randers' study modeled the effect of various emissions-reductions scenarios on Earth's climate between 1850 and 2500.</p><p>The data showed that if emissions stopped for good in 2020, sea levels in 2500 would still be more than 8 feet (2.5 meters) higher than in 1850.</p><figure><img src="https://i.insider.com/5fac2eb9b09abb0018626059?format=jpeg" alt="FILE - In this Aug. 16, 2019, photo, large Icebergs float away as the sun rises near Kulusuk, Greenland. The Trump administration is poised to announce an expanded diplomatic presence in Greenland and a new assistance package for the vast island aimed at thwarting growing Chinese and Russian influence in the Arctic. The announcement, expected Thursday, April 23, 2020, will come less than a year after President Donald Trump drew derision for expressing an interest in buying Greenland. (AP Photo/Felipe Dana, File)" height="2665" width="3557" charset=""><figcaption>Large icebergs float away as the sun rises near Kulusuk, Greenland, August 16, 2019.
<span>Felipe Dana/AP</span>
</figcaption></figure><p>To prevent the projected 3-degree-Celsius temperature increase, greenhouse-gas emissions would need to have ceased entirely between 1960 and 1970, the model found. In that sense, Earth blew by a climactic point of no return 50 years ago — before much of the public understood the realities of climate change.</p><p>"Yes, that is an irony," Randers said. "But of course the scientific community knew about global warming already in the 1960s."</p><h2>We need to suck carbon out of the atmosphere</h2><p>The Paris climate agreement was created with the intention to cut greenhouse-gas emissions enough to keep the world's temperature from rising more than 2 degrees Celsius by 2100. But even if all emissions stopped by 2100, according to Randers' model, sea levels in 2500 would be nearly 10 feet (3 meters) higher than they were in 1850.</p><p>Earth's temperatures are already on track to blow past the Paris agreement's goals. Last year was the <a href="https://www.ncei.noaa.gov/news/projected-ranks#:~:text=The%20warmest%20years%20globally%20have,Courtesy%20of%20NOAA%20NCEI.">second warmest on record</a> for surface temperatures and <a href="https://time.com/5765489/ocean-temperatures-warmest-ever/">the hottest ever for oceans</a>. Polar melting is <a href="https://www.businessinsider.com/sea-level-rise-3-feet-in-80-years-un-report-2019-9" data-analytics-module="body_link" data-analytics-post-depth="40">on track to raise seas 3 feet by 2100</a> and threatens to displace hundreds of millions of people.</p><p>What's needed, Randers said, is for companies and governments to "start developing the technologies for large-scale removal of greenhouse gases from the atmosphere."</p><p>In technical terms, that strategy is known as carbon capture and storage (CCS). To prevent further warming after emissions have stopped, the new study found, at least 33 gigatonnes (36.5 billion tons) of carbon dioxide would need to be sucked out of the atmosphere each year. That's roughly the total amount of carbon dioxide the global fossil-fuel industry emitted in 2018 (<a href="https://www.wri.org/blog/2018/12/new-global-co2-emissions-numbers-are-they-re-not-good#:~:text=Record%20Carbon%20Dioxide%20Emissions%20in%202018&amp;text=This%20year's%20numbers%20confirm%20their,2017%20to%2036.2%20gigatonnes%20CO20CO2">36 gigatonnes</a>).</p><p>Power plants in the US, Canada, and Switzerland have already started utilizing CCS to lower their emissions. In 2014, the Boundary Dam Power Station in Saskatchewan became one of the first in the world to successfully use the technology.</p><p>In total, 21 commercial-scale carbon-capture projects are operating around the world, and 22 more are in development, <a href="https://www.c2es.org/content/carbon-capture/">according to the Center for Climate and Energy Solutions</a>. These projects typically store carbon deep underground in depleted oil and gas fields or in bioreactor containers filled with algae that eats carbon dioxide.</p><figure><img src="https://i.insider.com/5fac4783b09abb001862611c?format=jpeg" alt="bioreactor" height="3744" width="4992" charset=""><figcaption>Bioreactors filled with green algae that eats carbon dioxide in Costa de la Luz, Spain.
<span>Santiago Urquijo/Getty Images</span>
</figcaption></figure><p>Two US carbon-capture completed in 2017 — <a href="https://www.c2es.org/content/carbon-capture/">one in Illinois, one in Texas</a> — can capture 1.1 million and 1.6 million tons of carbon dioxide, respectively, per year. But the amount of CO2 that needs to be removed from the atmosphere requires far more plants than any current plans call for.</p><p>"In other words, building 33,000 big CCS plants and keep them running for ever," the study authors wrote.</p><h2>The pros and cons of geoengineering</h2><p>Carbon capture is becoming widely accepted as a safe and potentially effective form of geoengineering. This and other climate interventions are increasingly being floated <a href="https://www.nature.com/articles/d41586-018-03036-4">by scientists</a> and politicians alike; Andrew Yang, a 2020 Democratic presidential candidate, suggested <a href="https://www.businessinsider.com/andrew-yang-thinks-geoengineering-could-lead-to-war-2019-4">budgeting $800 million</a> for further geoengineering research in the US.</p><p>But most climate-hacking proposals would be far riskier than CCS. Take solar geoengineering, for example, which involves injecting aerosols into the sky to reflect sunlight back into space. Critics of this idea point out that <a href="https://www.nature.com/articles/s41467-017-01606-0">most models predict</a> the effects of solar geoengineering wouldn't stay localized. If a country decided to independently deploy such measures, varying and unpredictable effects would likely be seen in other spots around the globe.</p><p>Aerosol injections deployed in the southern hemisphere, for instance, could impact ocean temperatures and wind speeds, leading to more hurricanes in the northern hemisphere.&nbsp;</p><figure><img src="https://i.insider.com/5c76a74726289812e8235523?format=jpeg" alt="Clouds above earth" height="2848" width="3797" charset=""><figcaption>Subtropical stratocumulus clouds above Earth.
<span>Aleksandar Georgiev/Getty Images</span>
</figcaption></figure><p>"Solar geoengineering has geopolitical ramifications, unlike carbon capture," Juan Moreno-Cruz, an associate professor at the University of Waterloo who studies geoengineering, previously told Business Insider.</p><p>Randers said his study advocates just for carbon capture, not other more experimental forms of geoengineering.&nbsp;</p><p>"I am generally against geoengineering because of its unintended side effects. But if the world continues to delay meaningful and feasible action to phase out fossil fuels, we may have to resort to geoengineering," Randers said.&nbsp;</p><p>As an immediate priority, he added, countries should invest equally in efforts to cut emissions and build more CCS plants.</p><p>"This would be a wonderful task for a government-financed <a href="https://www.businessinsider.com/alexandria-ocasio-cortez-green-new-deal-2019-1">Green New Deal</a>," he said.</p>
                            </div></div>]]>
            </description>
            <link>https://www.businessinsider.fr/us/climate-change-too-late-carbon-capture-needed-2020-11</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197019</guid>
            <pubDate>Tue, 24 Nov 2020 10:03:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Could singing spread Covid-19?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25196920">thread link</a>) | @draugadrotten
<br/>
November 24, 2020 | https://www.lunduniversity.lu.se/article/could-singing-spread-covid-19 | <a href="https://web.archive.org/web/*/https://www.lunduniversity.lu.se/article/could-singing-spread-covid-19">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
      If silence is golden, speech is silver – and singing the worst.<br>
Singing doesn’t need to be silenced, however, but at the moment the wisest thing is to sing with social distancing in place. The advice comes from aerosol researchers at Lund University in Sweden. They have studied the amount of particles we actually emit when we sing – and by extension – if we contribute to the increased spread of Covid-19 by singing.<br>

  </p><div>
  
  
      
  

            <div><p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>“There are many reports about the spreading of Covid-19 in connection with choirs singing. Therefore, different restrictions have been introduced all over the world to make singing safer. So far, however, there has been no scientific investigation of the amount of aerosol particles and larger droplets that we actually exhale when we sing”, says Jakob Löndahl, associate professor of Aerosol Technology at Lund University.</span></span></span></span></span></span></p>

<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>Aerosols are small airborne particles. To get a better understanding of the amount of aerosols and virus particles we actually emit when we sing, 12 healthy singers and two people with confirmed Covid-19 took part in a research project. Seven of the participants were professional opera singers.</span></span></span></span></span></span></p>

<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>The study shows that singing – particularly loud and consonant-rich singing – spreads a lot of aerosol particles and droplets into the surrounding air.&nbsp;</span></span></span></span></span></span></p>

<div data-embed-button="lu_media_embed_button" data-entity-embed-display="view_mode:media.lu_local_video" data-entity-type="media" data-entity-uuid="99ff6e89-19d5-406e-bfa3-856c2f311f36" data-langcode="en">

<article>
  
                  
        



<p>
  Droplets are spread in the air when we sing – here from powerful and consonant-rich singing photographed with a high-speed camera. (The film is silent.) Photo: Alexios Matamis
</p>

  </article>
</div>


<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>“Some droplets are so large that they only move a few decimetres from the mouth before they fall, whereas others are smaller and may continue to hover for minutes. In particular, the enunciation of consonants releases very large droplets and the letters B and P stand out as the biggest aerosol spreaders”, says Malin Alsved, doctoral student of Aerosol Technology at Lund University.</span></span></span></span></span></span></p>

<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>During the research experiments at Lund University’s Aerosol Laboratory, the singers had to wear clean air suits and enter a specially built chamber supplied with filtered, particle-free air. In the chamber, analysis was conducted of the number and mass of particles emitted by singers during breathing, talking, different types of singing and singing with a face mask.&nbsp;</span></span></span></span></span></span></p>

<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>What they sang was a short and plosive-rich Swedish song, “Bibbis pippi Petter”, which was repeated 12 times in two minutes at constant pitch. The same song was also repeated with the consonants removed, leaving only the vowels. During the song tests, aerosols and larger droplets were measured using strong lamps, a high-speed camera and an instrument that can measure very small particles. The louder and more powerful the song, the greater the concentration of aerosols and droplets.</span></span></span></span></span></span></p>

<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>“We also carried out measurements of virus in the air close to two people who sang when they had Covid-19. Their air samples contained no detectable amount of virus, but the viral load can vary in different parts of the airways and between different people. Accordingly, aerosols from a person with Covid-19 may still entail a risk of infection when singing”, says Malin Alsved.</span></span></span></span></span></span></p>

<div data-embed-button="lu_media_embed_button" data-entity-embed-display="view_mode:media.lu_image_large" data-entity-type="media" data-entity-uuid="8f3a5e76-5264-439d-bcb6-165acdd74feb" data-langcode="en">

<article>
  
      

            <p><img src="https://www.lunduniversity.lu.se/sites/www.lunduniversity.lu.se/files/styles/lu_full_width/public/2020-09/jakobitratt_fotograf_malin_alsved.jpg?itok=PqBLxvNK" width="1288" height="1259" alt="Person with head in funnel" typeof="foaf:Image">


</p>
        



 <p>
   During the tests, the singers sang into a funnel. The arosol particles were measured at the other end of the funnel. Photo: Malin Alsved
 </p>

  </article>
</div>


<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>Can we still have choral singing, singalongs during concerts, chanting at sporting events and loud talk in bars? The researchers consider that if we have a good understanding of the risks involved when a group of people sing together, we can also sing in a safer way. The song can be sung with social distancing, good hygiene and good ventilation, which reduces the concentration of aerosol particles in the air. Face masks can also make a difference.</span></span></span></span></span></span></p>

<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>“When the singers were wearing a simple face mask this caught most of the aerosols and droplets and the levels were comparable with ordinary speech”, says Jakob Löndahl.</span></span></span></span></span></span></p>

<p><span><span><span><span lang="EN-GB" xml:lang="EN-GB"><span><span>“Singing does not need to be silenced, but presently it should be done with appropriate measures to reduce the risk of spreading infection”, says Jakob Löndahl.</span></span></span></span></span></span></p>

</div>
      
  </div></div>]]>
            </description>
            <link>https://www.lunduniversity.lu.se/article/could-singing-spread-covid-19</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196920</guid>
            <pubDate>Tue, 24 Nov 2020 09:51:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What if every day was a pandemic day?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25196886">thread link</a>) | @tdmckinlay
<br/>
November 24, 2020 | https://www.exponentialview.co/p/-what-if-every-day-was-a-pandemic | <a href="https://web.archive.org/web/*/https://www.exponentialview.co/p/-what-if-every-day-was-a-pandemic">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>This is a member-only post I have made freely accessible. Until 27th November you can sign-up to Exponential View with a 27.18% discount. </em></p><p data-attrs="{&quot;url&quot;:&quot;https://www.exponentialview.co/subscribe?coupon=88ce10a0&quot;,&quot;text&quot;:&quot;Get 27% off for 1 year&quot;,&quot;class&quot;:null}"><a href="https://www.exponentialview.co/subscribe?coupon=88ce10a0"><span>Get 27% off for 1 year</span></a></p><p>Scientists, take a bow.&nbsp;</p><p>With the announcement of the Oxford/AstraZeneca vaccine, we now have three effective vaccines against the coronavirus with 90% efficacy or above. Even the Oxford vaccine reports 90% efficacy with a <a href="https://www.research.ox.ac.uk/Article/2020-11-23-oxford-university-breakthrough-on-global-covid-19-vaccine">particular treatment protocol</a>; more discussion <a href="https://www.statnews.com/2020/11/23/astrazeneca-covid-19-vaccine-is-70-effective-on-average-early-data-show/">about that and what remains to be understood here.</a> Two of these candidates are built on entirely new vaccine platforms, the mRNA candidate approach, while the AstraZeneca vaccine uses a more established platform, which had yet to have <a href="https://cen.acs.org/pharmaceuticals/vaccines/Adenoviral-vectors-new-COVID-19/98/i19">much success in humans</a>.&nbsp;&nbsp;We can expect to hear news from other vaccine candidates like CanSino and Johnson &amp; Johnson soon enough. </p><p>Yet, the vector was only sequenced in January, that sequence, of what was then known as&nbsp; 2019-nCov, released <a href="https://virological.org/t/preliminary-phylogenetic-analysis-of-11-ncov2019-genomes-2020-01-19/329?utm_campaign=Sunday%20Newsletter&amp;utm_source=hs_email&amp;utm_medium=email&amp;utm_content=82449951&amp;_hsenc=p2ANqtz--XAXEbjkdKE-Cv9kBQKH5n6JvAObcypjLpmk139J9YvLm9NTyNh6lJlGfr0sPl6nRjeFP0JWFmFCNNnLy21y-L1mveVQ&amp;_hsmi=82449951">to the world on 19 January 2020</a>. It has taken 310 days, 10 months and change, to achieve this. </p><p>Remarkable:&nbsp; we’ve got this outcome roughly ten times faster<a href="https://wellcome.org/sites/default/files/styles/standalone_image_full_width/public/infographic-vaccine-development-1200x1850.png?itok=y0Cq0Vr2"> than the usua</a>l. Earlier conditions like hepatitis or polio <a href="https://ourworldindata.org/vaccines-antibiotic-dependence?sf83280884=1">took one to three decades</a> from discovery of the infectious agent to a working vaccine.&nbsp;</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd41b8392-4e99-4f38-b23f-90ad643a78dc_1600x1215.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd41b8392-4e99-4f38-b23f-90ad643a78dc_1600x1215.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d41b8392-4e99-4f38-b23f-90ad643a78dc_1600x1215.png&quot;,&quot;height&quot;:1106,&quot;width&quot;:1456,&quot;resizeWidth&quot;:414,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>The race for a Covid-19 vaccine is proof that we can overcome difficult challenges. <em>EV</em> reader, Geraint Rees, <a href="https://twitter.com/profgeraintrees/status/1330782816360083457">pointed out that it’s</a> “worth recognising that this represents a partnership between large and small pharma, universities and the NHS [Britain’s universal health service] plus the use of advance purchase contracts. A public-private ecosystem we would do well to nurture when tackling complex difficult problems of global significance.”</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F47072dd7-cacb-4d26-a42b-dcefb3c7436b_1208x690.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F47072dd7-cacb-4d26-a42b-dcefb3c7436b_1208x690.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/47072dd7-cacb-4d26-a42b-dcefb3c7436b_1208x690.png&quot;,&quot;height&quot;:690,&quot;width&quot;:1208,&quot;resizeWidth&quot;:396,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>The vaccine is more than just a little bit of science. It is groundbreaking science and a complex coordination problem. And yes the pandemic has shocked us into delivering against that messy interconnected challenge. </p><p>The pandemic, for better or worse, accelerated experimentation in the exponential transition (think lower carbon emissions, more local living, remote collaboration, telehealth, widespread PCR testing, remote deliveries). At a time of rising populism worldwide, rampant conspiracy theories and economic precariousness, the fight against Covid-19 has reminded many of the collective public good and social safety nets. Without <a href="https://www.fiercepharma.com/pharma/after-nearly-1b-research-funding-moderna-takes-1-5b-coronavirus-vaccine-order-from-u-s">substantial government backing</a>, these vaccines wouldn’t have been developed so rapidly. There have been some serious bumps along the way (especially in the United States), but the direction of accomplishment is clear.&nbsp;</p><p><a href="https://observer.com/2020/11/covid19-vaccine-price-pfizer-moderna-astrazeneca-oxford/">And it will be cheap</a>. In the US, the Moderna vaccine will run from $10-50 per dose; Pfizer $20 per dose; and Astra Zeneca $4 per dose. In emerging markets, AZ will ship the vaccines at $3 per dose, assuming 2 doses. The two billion doses the firm plans to make for emerging markets in 2021 will run to about $6bn. This is a pittance in the scale of the global economy. (Or consider that the US government handed the airline industry, a sector chock full of <a href="https://www.bloomberg.com/news/articles/2020-03-16/u-s-airlines-spent-96-of-free-cash-flow-on-buybacks-chart?sref=U0wOqcqE">share-buyback addicts like United</a>, $25bn in April <a href="https://www.nytimes.com/2020/04/14/business/coronavirus-airlines-bailout-treasury-department.html#:~:text=the%20main%20story-,Crippled%20Airline%20Industry%20to%20Get%20%2425%20Billion,Part%20of%20It%20as%20Loans&amp;text=WASHINGTON%20%E2%80%94%20The%20Trump%20administration%20has,hobbled%20by%20the%20coronavirus%20pandemic.">this year</a>.)</p><h3><strong>The power of necessity</strong></h3><p>What would happen if we harnessed this pandemic mindset and applied it to other less visible pandemic-scale problems on our doorstep?&nbsp;</p><p>What of climate change? What of women’s rights? Or global poverty? Or unemployed youth? Or climate-based migration? Or water security?&nbsp; Consider the problem of <a href="https://www.statista.com/chart/23545/share-of-the-population-practicing-or-exposed-to-open-defecation/#:~:text=Progress%20to%20that%20end%20has,to%209%20percent%20in%202017)">open defecation</a>, which threatens sanitation levels and causes significant health issues around the world. More than 4bn people around the world--more than the user base of Facebook--do not have access to working, sanitary toilets. Solving this seemingly straightforward challenge requires complex coordination and, you guessed it, urgency.&nbsp;</p><p>This isn’t to underplay the fissures that Covid-19 has revealed, far from it. When the dust settles on this virus, and some form of population immunity aided by vaccines takes hold, many countries will need to seriously reflect on the lessons of Covid-19. But we can’t let that reality overshadow the work that’s been achieved in public health by scientists, governments and health services courtesy of a cocktail of coordination, cooperation and healthy competition.&nbsp;</p><p>That old catchphrase, “another world is possible” seems strangely apt here. At the beginning of 2020, who would have thought we could achieve medical breakthroughs such as the development of these vaccines as quickly or as cheaply as we have. </p><p>Looking at the planet-wide pandemic-scale problems that define our future, <strong>what will we gain if we embrace the urgency, creativity, constructive competition and collaboration of the pandemic mindset</strong>?&nbsp;</p><p>Cheers,&nbsp;</p><p>Azeem</p><p><strong>Dig deeper:</strong></p><ul><li><p><a href="https://link.chtbl.com/covid-19-impact">The Long-Term Impact of Covid-19: Azeem Azhar in Conversation with Nicholas Christakis</a></p></li><li><p><a href="https://link.chtbl.com/demis-hassabis-ev">DeepMind’s Journey from Games to Fundamental Science: Azeem Azhar in Conversation with Demis Hassabis</a></p></li><li><p>The following podcasts explore the opportunity in synthetic biology:</p><ul><li><p><a href="https://link.chtbl.com/contera-nanotech-ev">The State of Nanotechnology: Azeem Azhar in Conversation with Sonia Contera</a>.</p></li><li><p><a href="https://link.chtbl.com/NswVjjkk">Engineering Biology, the Next Frontier: Azeem Azhar in Conversation with Vijay Pande</a></p></li><li><p><a href="https://link.chtbl.com/trillion-dollar-market">The Next Trillion-Dollar Market: Azeem Azhar in Conversation with Deep Nishar</a></p></li></ul></li></ul></div></div>]]>
            </description>
            <link>https://www.exponentialview.co/p/-what-if-every-day-was-a-pandemic</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196886</guid>
            <pubDate>Tue, 24 Nov 2020 09:46:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Newsfeeds and Information Filters]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25196867">thread link</a>) | @inci90
<br/>
November 24, 2020 | https://thundergolfer.com/newsfeeds/information-retrieval/information-filtering/2019/05/05/newsfeeds-and-information-filters/ | <a href="https://web.archive.org/web/*/https://thundergolfer.com/newsfeeds/information-retrieval/information-filtering/2019/05/05/newsfeeds-and-information-filters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div role="main"> <div>   <article> <p><em>A lot</em> of my time nowadays is captured by the newsfeeds on platforms like <a href="https://www.reddit.com/">Reddit</a>,<a href="https://news.ycombinator.com/">Hacker News</a>, and <a href="https://twitter.com/">Twitter</a>. I don’t hate the fact that I’m a bit addicted to their streams, I mostly consume interesting and informative software-centric content, but I have find myself wanting more powerful information filtering tools. <a href="https://en.wikipedia.org/wiki/Information_filtering_system">Information Filtering</a> (IF) as a consumer technology seems to have either fallen out of vogue or never gotten into it, but I’d argue that strong IF tooling is becoming more and more needed by users to ensure their personal happiness and effectiveness. Currently, the world’s information geysers, great aggregators like Facebook, Google, RenRen, and Toutiauo have misaligned incentives with their users. Despite billions in recommender engine research, today’s production recommender systems are still inadequate. Further, the dominance of <em>implicit</em> signals in user profiling have seen the great aggregators serving the <a href="https://waitbutwhy.com/2013/10/why-procrastinators-procrastinate.html"><em>Instant Gratification Monkey</em></a> inside us, or the <a href="https://vignette.wikia.nocookie.net/pixar/images/7/7a/Io_Anger_standard2.jpg/revision/latest/scale-to-width-down/2000?cb=20150425021210"><em>Anger Golem</em></a>. In the absence of these problems, ie. in a system where the great aggregators are ‘perfect information retrievers’, personal IF tooling is not so much needed. But until then, it’s a thing we should begin to consider more seriously.</p> <h3 id="can-i-just-tell-you-what-i-want">Can I just tell you what I want?</h3> <p>If you’re a user of Netflix, Amazon, or Facebook, you know the powers and the weaknesses of an implicit feedback system for user profiling and recommendations. Compared with explicit, implicit has the large advantage of providing the user a super-smooth user experience. No need to tell the system what you’re interested in, it’s busy figuring that out for itself. The clear problem though, the problem that I think necessitates IFs, is many of the things that leak through in implicit feedback we would not at all claim as preferences.</p> <p>I’ll admit, I sometimes click on dumb clickbait. Frustratingly, the machine learning system behind whatever site I’m on will not notice the <em>instant regret</em> I feel having done so, and instead register a positive signal to show more me more articles like “23 times Kloé Kardashian left the house without shoes”. I don’t care about this person, any time I happen to click on anything about them was a moment of brain failure, perhaps at 2am and in a state where I might not be tapping things quite so precisely. Too late though, down the line I’ll be updated when her boyfriend is seen suspicuously grocery shopping with another woman. A woman that’s probably just his sister.</p> <p>From what I’ve come to learn about natural language processing, knowledge graphs, and information filtering generally, it <em>should</em> be more-or-less possible for me to just type in:</p> <blockquote> <p>Do not show me celebrity gossip. I do not care about the Bachelorettes, the Kardashians, or anyone Instagram famous.</p> </blockquote> <p>It <em>should</em> be possible for me to type in:</p> <blockquote> <p>I like sport, particularly Tennis, Soccer, and AFL, but do not show me anything about Cricket</p> </blockquote> <p>Currently Facebook and Google News <em>do</em> have systems that partially have this functionality, though crucially you have to <em>wait</em> for it to show up before you can click a drop down and select “don’t show me stories about X”. I think this is an anti-pattern. The filtering configuration is hidden from me, so I can only fix it through a couple of knobs that only appear once the system has made a mistake. I would <em>really</em> like these filtering configurations to be shareable. If someone discovers/designs a really good way to filter out stuff about horoscopes, they should be able to share it and I should be able to install it into my system. We could even build customisable user profiles to solve the cold-start problem. I’d really like <a href="http://www.tristanharris.com/">Tristan Harris’s</a> filtering configuration, or Noam Chomsky’s.</p> <h3 id="good-recommendation-systems-are-apparently-an-ai-complete-challenge">Good recommendation systems are apparently an AI-complete challenge</h3> <p>Beyond the struggles with the implicit vs. explicit self, for some reason recommender engines struggle immensely with <a href="https://twitter.com/kibblesmith/status/724817086309142529?lang=en">fairly straightforward things</a>. In an age where we’re getting constantly bombarded with useless, irrelevant crap, even if they wanted to our recommender systems couldn’t save us.</p> <p>I get much better recommendations from informed friends and colleagues than I do from any multi-billion dollar recommendation engine. The familiar human beings don’t need to rely on proxy signals for quality like ‘this is getting clicked a lot’, or ‘this contains a lot of words usually found in articles you’ve saved’. They have their own personal human General Intelligence, a wealth of relevant experience in specific areas, and deep understanding of my own experiences and needs. To the extent that recommendation engines succeed right now, I think most of it is driven by a well-curated group of ‘followees’. This is at least the experience I’ve had with Twitter, where much of the content delivered is relevant because I follow almost exclusively AI researchers and prominent software engineers. Francois Chollét still dumps loads of shit into my feed though, and Twitter hasn’t fixed that.</p> <p>So newsfeeds may really need a really solid group of humans to deliver relevant content and filter out rubbish, but looking beyond the current paradigm of recommender systems which optimise for the likelihood of a user clicking on the things it recommends, we can see that good recommendations are an incredibly complex problem. <a href="http://maroo.cs.umass.edu/getpdf.php?id=131">Information Filtering can be reframed as a twist on Information Retrieval (IR)</a>, and under this reframing we can think about a filtering system that blocked content under the kinds of highly complicated criteria embedded in highly complicated search queries.</p> <p>If I ask of an Information Retrieval system (ie. a search engine), “Which distributed graph database best optimises for HTTP request trace storage?”, anything not featured on the first page is essentially <em>filtered</em>. For an example of the IF &lt;-&gt; IR relationship that is more applicable to newsfeeds and online media space, think of the question “How can I engage and act politically in order to safeguard the economic futures of local miners in my community?”. The IF mirror of that is “I don’t want information that hinders my goal of safeguarding the economic futures of local miners in my community”. We recently had a period where people <em>really</em> needed answers to these kinds of questions, and unfortunately their newsfeed technologies failed them.</p> <h3 id="what-have-we-got-to-work-with">What have we got to work with</h3> <p>Wanting to whack together an information filterer myself, I went after existing implementations and research. Information Filtering was a bit of a thing 30 years ago, before even Google, and well before Facebook. Systems like <a href="http://delivery.acm.org.ezproxy.lib.rmit.edu.au/10.1145/30000/22340/p1-malone.pdf?ip=131.170.21.110&amp;id=22340&amp;acc=ACTIVE%20SERVICE&amp;key=65D80644F295BC0D%2E124032AC6F25F239%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;CFID=826579750&amp;CFTOKEN=62469482&amp;__acm__=1510028698_c214de9c28b7c096c548454bc93d06a2">“The Information Lens”</a>, <a href="https://eric.ed.gov/?id=EJ552498">INFOS</a>, <a href="http://ilpubs.stanford.edu:8090/73/1/1994-7.pdf">SIFT</a>, and NewsClip. Most were concerned with managing and improving the user experience with <a href="https://en.wikipedia.org/wiki/Usenet">UseNet</a>. God knows how they’d deal with today’s content networks, but at least they were trying and at least they seemed to be <em>for the user</em>.</p> <p>As an interesting analogue to problems with today’s platforms that ‘push’ content to the user, similar push-based system existed for research and business use-cases in the 90’s. Even with the use of information-filtering tooling, such systems were found to be <a href="https://books.google.com.au/books?id=g00Gz5nR4s0C&amp;pg=PT329&amp;lpg=PT329&amp;dq=%22BackWeb%22+information+filtering&amp;source=bl&amp;ots=VHxxIRnI5z&amp;sig=_DrzywjFBuUyevvMdbpqnbKB0xM&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjt2OHIzqvXAhXCJJQKHb2ADWYQ6AEIKjAB#v=onepage&amp;q=%22BackWeb%22%20information%20filtering&amp;f=false"><em>distracting and time-consuming for users</em></a>. The lesson here in that linked passage is so clear it’s like it leaps out of 2003 and smacks you in the face. In professional environment, <em>people recognise the value of employee time</em>, and wasted time is an expense. For social networks, user time is an <em>asset</em>, and wasted time barely makes any sense to them.</p> <p>If I had to speculate, the user experience on internet back in the late 90’s and early 2000’s was such that information filtering tools weren’t required, and now fast-forwarding to 2017 we have a paucity of good software tooling in the problem space. UseNet was created back then, and heaps of tooling around the RSS format, because they addressed the peculiar needs of the time. Then everyone and their nana joined the internet, <a href="https://stratechery.com/2015/aggregation-theory/">Aggregation Theory</a> took hold, and now the internet is a place dominated by great aggregators and ad-revenue incentives.</p> <h3 id="going-forward">Going Forward</h3> <p>For now I think the highest priority in the IF space is fostering an open-source, public community led effort to make user content preferences explicitly defined, compose-able, and shareable.</p> <ul> <li><strong>Explicitly defined:</strong> not ‘I didn’t click on this show don’t show me it’, but ‘filter out anything involving X’.</li> <li><strong>Compose-able:</strong> the characterisation of everything I <em>don’t</em> want show to me is a a complicated thing. The content-based equivalent of a hostfile blacklist won’t cut it.</li> <li><strong>Shareable:</strong> I should be able to share my IF configuration both with other people and with new content providers I want to engage with. Don’t make me select topics I’m interested in or not interested in over and over again.</li> </ul> <p>Those three above would let users take back control of their content feeds from companies whose predominant goal is to cultivate large groups of eyeballs for advertisers.</p> <hr> <p>Thank you for reading. If your interested in further exploration this stuff, <a href="https://www.evernote.com/l/AcRny-ZPqKxPJpAalW7HL95OYqWL1Ld7qvQ">here’s a link to this posts’ notes, with lots of good links</a>.</p> </article>     </div> </div> </div></div>]]>
            </description>
            <link>https://thundergolfer.com/newsfeeds/information-retrieval/information-filtering/2019/05/05/newsfeeds-and-information-filters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196867</guid>
            <pubDate>Tue, 24 Nov 2020 09:44:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing iPhone OS 1.0 with iOS 14 using tree maps]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25196720">thread link</a>) | @yankcrime
<br/>
November 24, 2020 | https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/ | <a href="https://web.archive.org/web/*/https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>If you followed the recent Apple events, you probably saw a picture of the A14 and M1 dies… that got me thinking about what you would see if you could pass iOS under X-Rays…</p>
<p>In my previous article about the <a href="https://blog.timac.org/2020/1019-evolution-of-the-programming-languages-from-iphone-os-to-ios-14/">evolution of the programming languages from iPhone OS 1.0 to iOS 14</a>, I analyzed iOS based on the number of binaries and their programming languages. As I pointed out in this past post, the size of the binaries were not taken in account. In this new article, I look at iPhone OS 1.0 and iOS 14 from a size perspective using tree maps.</p>

<p>To produce the images in this article, I extracted the root filesystem (including the dyld shared cache) of each major iOS release:</p>
<table>
<thead>
<tr>
<th>Version</th>
<th>Device</th>
</tr>
</thead>
<tbody>
<tr>
<td>iOS&nbsp;14.0 (18A373)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;13.1 (17A844)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;12.0 (16A366)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;11.1 (15B93)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;10.1 (14B72)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;9.0 (13A344)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;8.0 (12A365)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;7.0.1 (11A470a)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;6.0 (10A403)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iOS&nbsp;5.0 (9A334)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iOS&nbsp;4.0 (8A293)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;3.0 (7A341)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;2.0 (5A347)</td>
<td>iPhone 2G</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;1.0 (1A543a)</td>
<td>iPhone 2G</td>
</tr>
</tbody>
</table>
<p>I then created a tree map. You might be familiar with tree maps as they are often used to visualize a file hierarchy to give you a graphical overview of the structure. One key characteristic is that each file is shown as a rectangle with an area proportional to the file's size. The tree maps displayed in this article have been created using the awesome <a href="http://grandperspectiv.sourceforge.net/">GrandPerspective</a> and annotated with <a href="https://www.pixelmator.com/">Pixelmator</a>.</p>

<p>Let's look at what you would see if you could scan iPhone OS 1.0 using X-Rays:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1.png" alt=""></p>
<p>The diagram below highlights some of the major functional blocks:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1_structures.png" alt=""></p>
<p>We can already notice that:</p>
<ul>
<li>The structure is quite simple and has similarities to macOS</li>
<li>Frameworks are taking more than a third of the size</li>
<li>Fonts are taking more than 25% of the whole operating system</li>
</ul>
<p>We can go one level deeper and identify all the components:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1_details.png" alt=""></p>
<p>From the list of components, we can clearly determine all the main features of iPhone OS 1.0:</p>
<ul>
<li>Phone</li>
<li>SMS</li>
<li>Weather</li>
<li>Clock</li>
<li>Mail</li>
<li>Safari + Web</li>
<li>Calendar</li>
<li>Maps</li>
<li>Wallpaper</li>
<li>Ringtones</li>
<li>Office support</li>
<li>Audio player</li>
<li>Video player</li>
<li>…</li>
</ul>
<p>A couple of components worth mentioning:</p>
<ul>
<li>The UIKit framework is taking more than 13 % of the total size</li>
<li>The wallpapers and ringtones count for 6 %</li>
<li>ICU (International Components for Unicode) takes more than 5 %</li>
<li>SpringBoard is roughly 2 %</li>
</ul>

<p>On popular demand, I added this section to provide more info about the fonts.
The huge <code>Fonts</code> block is composed of 2 parts:</p>
<ul>
<li>the fonts representing 2/3 of the size</li>
<li>some caches (visible at the top of the area and representing a third of the size)</li>
</ul>
<p>For the font lovers, here is the complete list of fonts in iPhone OS 1.0:</p>
<pre><code>AmericanTypewriter.ttf
AmericanTypewriterBold.ttf
AmericanTypewriterCondensed.ttf
AmericanTypewriterCondensedBold.ttf
AmericanTypewriterCondensedLight.ttf
AmericanTypewriterLight.ttf
Arial.ttf
ArialBold.ttf
ArialBoldItalic.ttf
ArialItalic.ttf
ArialRoundedMTBold.ttf
arialuni.ttf
CourierBoldOblique.ttf
CourierNew.ttf
CourierNewBold.ttf
CourierNewBoldItalic.ttf
CourierNewItalic.ttf
CourierOblique.ttf
DB_LCD_Temp-Black.ttf
Georgia.ttf
GeorgiaBold.ttf
GeorgiaBoldItalic.ttf
GeorgiaItalic.ttf
Helvetica.ttf
HelveticaBold.ttf
HelveticaBoldOblique.ttf
HelveticaOblique.ttf
LockClock.ttf
MarkerFeltThin.ttf
MarkerFeltWide.ttf
PhonepadTwo.ttf
TimesNewRoman.ttf
TimesNewRomanBold.ttf
TimesNewRomanBoldItalic.ttf
TimesNewRomanItalic.ttf
TrebuchetMS.ttf
TrebuchetMSBold.ttf
TrebuchetMSBoldItalic.ttf
TrebuchetMSItalic.ttf
Verdana.ttf
VerdanaBold.ttf
VerdanaBoldItalic.ttf
VerdanaItalic.ttf
Zapfino.ttf
</code></pre>
<p>The cache contains info for all these fonts and includes the 2 extra files:</p>
<ul>
<li>HelveLTMM.ps</li>
<li>TimesLTMM.ps</li>
</ul>

<p>I won't give details about each iOS release but you can inspect the tree maps from iPhone OS 2.0 to iOS 13.1:</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>iPhone OS 2.0</td>
<td>iPhone OS 3.0</td>
<td>iOS 4.0</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS2.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS2_small.png" alt="" title="iPhone OS 2.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS3.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS3_small.png" alt="" title="iPhone OS 3.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS4.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS4_small.png" alt="" title="iOS 4.0"></a></td>
</tr>
<tr>
<td>iOS 5.0</td>
<td>iOS 6.0</td>
<td>iOS 7.0.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS5.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS5_small.png" alt="" title="iOS 5.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS6.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS6_small.png" alt="" title="iOS 6.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS7.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS7_small.png" alt="" title="iOS 7.0.1"></a></td>
</tr>
<tr>
<td>iOS 8.0</td>
<td>iOS 9.0</td>
<td>iOS 10.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS8.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS8_small.png" alt="" title="iOS 8.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS9.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS9_small.png" alt="" title="iOS 9.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS10.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS10_small.png" alt="" title="iOS 10.1"></a></td>
</tr>
<tr>
<td>iOS 11.1</td>
<td>iOS 12.0</td>
<td>iOS 13.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS11.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS11_small.png" alt="" title="iOS 11.1"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS12.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS12_small.png" alt="" title="iOS 12.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS13.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS13_small.png" alt="" title="iOS 13.1"></a></td>
</tr>
</tbody>
</table>
<p>Note that the number of building blocks increased with each new iOS release and the components are becoming smaller.</p>

<p>We are now in 2020 and iOS 14 is available. Without a surprise, iOS 14 is way more complex than iPhone OS 1.0:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14.png" alt=""></p>
<p>Here is the diagram highlighting the functional blocks in iOS 14:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14_structures.png" alt=""></p>
<p>We can note that the main structure is still fairly similar to the original iPhone OS 1.0 version: the fonts, frameworks, applications, library, /usr, … are still there.</p>
<p>There are however a couple of big differences:</p>
<ul>
<li>iOS 14 contains a lot of <code>Preinstalled Assets</code> and <code>Linguistic Data</code>. As far as I can tell, these components are used for on-device machine learning: language detector, voices, tokenizers, vocalizers, …</li>
<li>The dyld shared cache, a caching mechanism introduced in iPhone OS 3.1, causes the Frameworks and Private Frameworks to be split in several areas. The dyld shared cache has been marked with the red box in the diagram.</li>
<li>Health is clearly an important feature of iOS 14.</li>
</ul>
<p>There are so many components in iOS 14 that it is way more complex to identify all of them. I gave it a try nonetheless:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14_details.png" alt=""></p>
<p>Although it is now difficult to list all the features, there are some clear trends:</p>
<ul>
<li>iOS 14 is packed with on-device machine learning technologies: Face Detection, Deep Convolutional Networks, Vision frameworks, Text Recognition, Neural Network, …</li>
<li>A lot of components are related to the camera and photos: Effects, Memories, video processing, photo library, …</li>
<li>Siri and voices are clearly visible.</li>
<li>As we already mentioned, Health is an important feature.</li>
<li>We can identify a couple of features added over the years: HomeKit, Watch, CarPlay, Spotlight, Emoji 🤟, News, iWork, Wallet, Shortcuts, ARKit, …</li>
</ul>
<p>More statistics:</p>
<ul>
<li>Fonts are now counting for less than 6 % of the size</li>
<li>Linguistic Data represent almost 8 % of the size</li>
<li>Although the ICU size was multiplied by more than 3 since iPhone OS 1.0, it now represents approximatively 0.5% of the total</li>
</ul>

<p>For readability the previous tree maps in this article were all displayed using the same size. If we present iPhone OS 1.0 next to iOS 14 with a proportional area, you would see that the whole iPhone OS 1.0 is basically taking the size of the iOS 14 wallpapers:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/Compare-iOS1-iOS14.png" alt=""></p>

<p>When iPhone OS 1.0 was released in 2007, it redefined the smartphone with a limited set of core features. Nowadays iOS 14 contains an incredible amount of components. By looking at them based on their size, we can determine the most important features. We thus distinctly see Apple's AI push into on-device machine learning with technologies like object detection in images and video, language analysis, sound classification and text recognition.</p>

<p><strong>Update 24.11.2020:</strong></p>
<ul>
<li>Added fonts in the iPhone OS 1.0 tree map</li>
<li>Added fonts in the iOS 14 tree map</li>
<li>Add section with fonts info for iPhone OS 1.0</li>
</ul>
</div></div>]]>
            </description>
            <link>https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196720</guid>
            <pubDate>Tue, 24 Nov 2020 09:18:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is carbon capture a viable solution?]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 326 (<a href="https://news.ycombinator.com/item?id=25196633">thread link</a>) | @scottbucks
<br/>
November 24, 2020 | https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis | <a href="https://web.archive.org/web/*/https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.5.0"><div dir="ltr"><div><h3 id="viewer-foo"><span><strong><span>Is this technology a viable solution to beating the climate crisis or <!-- -->can it cause more harm than good?</span></strong></span></h3><p id="viewer-efp47"><span>With the climate crisis continuously getting worse, businesses and governments need to find solutions to reduce the amount of carbon going into the atmosphere. To beat the crisis, the world can't simply rely on renewable energy, governments will need to include carbon capture, usage and storage (CCUS) into the mix if they want to <span>hit their climate targets.</span></span></p><p id="viewer-4uch7"><span>According to the International Energy Agency (IEA), CCUS could <a href="https://www.iea.org/reports/transforming-industry-through-ccus" target="_blank" rel="noopener"><u>reduce carbon emissions by almost a fifth</u></a>, but can this technology deliver on its promises or is it too good to be true?</span></p><h3 id="viewer-5vpth"><span>What is <!-- -->Carbon capture, usage and storage?</span></h3><p id="viewer-pi2c"><span>Carbon capture, usage and storage (CCUS) refers to <!-- -->a chain of different technologies aimed at capturing waste <!-- -->carbon dioxide<!-- --> (<!-- -->CO2<!-- -->), usually from large <!-- -->point sources of pollution like power plants, <!-- -->transporting it to a storage site, and depositing it where it will not enter the atmosphere. Some could be used to help grow greenhouse plants, make plastics, or even carbonate fizzy drinks. The first step is to fit factory chimneys with solvent filters, which trap carbon emissions before they escape, then the gas can be piped to locations to be used or stored. For the moment, t<span>here are about 30 CCUS projects operating around the world, which is nowhere near enough to clean up all of our emissions. </span></span></p><h3 id="viewer-fds85"><span><span>Why is CCUS needed?</span></span></h3><p id="viewer-7vj3h"><span><span>Nowadays, </span>Industrial production <span>accounts for one-quarter of CO</span>2﻿<span> emissions from energy and industrial processes. With the demand for cement, steel and chemicals remaining strong to support a growing and increasingly urbanised global population, the future production of these materials will have to be more efficient and emit much less CO</span>2<span> if governments want to meet their climate goals.</span></span></p><p id="viewer-8ofv8"><span><span>In the </span><a href="https://www.iea.org/reports/material-efficiency-in-clean-energy-transitions" target="_blank" rel="noopener"><u>IEA's "Clean Technology Scenario"</u></a>, <span>more than 28 GtCO</span>2<span>﻿ could be captured from industrial facilities between now and 2060.</span></span></p><p id="viewer-5eiqn"><span><span>Carbon capture, usage and storage also offers several other potential benefits:</span></span></p><ul><li id="viewer-63jb1"><p><span>The ability to generate additional power thanks to </span><span>geologically stored CO</span>2 which<span> could be used to extract geothermal heat from the same locations in which it’s injected, producing renewable geothermal energy.</span></p></li><li id="viewer-bcq59"><p><span>CO2 can technically be turned into fuel, although it is rather difficult to achieve.</span></p></li><li id="viewer-dru7v"><p><span>Captured CO</span>2<span> could also be used to strengthen concrete, leading to increased infrastructure durability.</span></p></li></ul><div id="viewer-den6h"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_1000%2Ch_853%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><h3 id="viewer-e8ds9"><span><span><strong>Suggested Articles:</strong></span></span></h3><ul><li id="viewer-apsbb"><p><strong>🚄 </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-8crgb"><p><strong>⌚️ </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-4jk2p"><p><strong>📱 </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ♻️ </strong></p></li></ul><h3 id="viewer-9j318"><span>What's the catch?</span></h3><p id="viewer-89c60"><span>CCUS has always been controversial, m<!-- -->ost people are either heavily in favour of CCUS technology or heavily against. There are several reasons why this technology might not be the best solution.</span></p><p id="viewer-3g635"><span>Environmentalists<!-- --> tend to see CCUS as a distraction from the need to convert to <!-- -->renewable energy as quickly as possible<!-- -->. Some argue that investing in carbon capture wasting money that could be put to better use, like perfecting <!-- -->solar energy<!-- -->, <!-- -->building insulation<!-- -->, <!-- -->wind turbines or even <!-- -->tidal power. </span></p><p id="viewer-bts9g"><span>Another drawback of carbon capture, usage and storage, is the considerable amount of extra power it requires, which would increase the cost of electricity. Talking of cost, CCUS technology is said to be very expensive, however, new methods for capturing and extracting CO2 are constantly being developed, always with the aim to become cheaper.</span></p><h3 id="viewer-3q94h"><span>Where is CCUS in place?</span></h3><p id="viewer-2ukm3"><span>There are currently almost 30 carbon capture, usage and storage projects in place around the world namely in the <span>US, Canada, Norway, China and the UK.</span></span></p><p id="viewer-4rv4i"><span><span>Here are some of the biggest projects:</span></span></p><ul><li id="viewer-65sfn"><p><span>The Century natural gas processing facility in West Texas, US. The capturing plant began operations in November 2010 and is now the world’s single biggest CCS plant.</span></p></li><li id="viewer-3iluh"><p>The Boundary Dam Carbon Capture and Storage (CCS) project located in Saskatchewan, Canada. Owned by SaskPower, the <span>Boundary Dam coal-fired plant located in Estevan, Saskatchewan began operations in 2014.</span></p></li><li id="viewer-3uhge"><p><span>The Shute Creek gas processing plant, located in Wyoming, US. The CCS facility, built near LaBarge, Lincoln County, is owned by ExxonMobil and captures approximately 365 million cubic feet per day of CO</span>2<span>, which is equivalent to removing more than 1.5 million cars off the road.</span></p></li></ul><div id="viewer-eol67"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Photo of fumes, CO2 from an industrial plant."><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_1000%2Ch_851%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt="Photo of fumes, CO2 from an industrial plant."></p></div></div></div></div><h3 id="viewer-4dtjt"><span><span>The bottom line</span></span></h3><p id="viewer-1abo"><span><span>Despite the controversy, it seems that </span>carbon capture, usage and storage technology will become an important part of tackling the climate crisis. I think that if future projects aren't too expensive, it could definitely be a solution to this ever-growing problem, so long as it isn't to the expense of investing in renewable energy and other methods of reducing our CO2 emissions.</span></p><h3 id="viewer-6af0g"><span><span><strong>More from The Detechtor:</strong></span></span></h3><ul><li id="viewer-8a6vc"><p><strong>🚄 </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-63fca"><p><strong>⌚️ </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-anbaq"><p><strong>📱 </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ♻️</strong></p></li></ul><h3 id="viewer-4ja8h"><span><span>Stay updated:</span></span></h3><ul><li id="viewer-6j517"><p>📩 Want the latest on the impact of tech? <strong>Subscribe</strong> to our <strong>newsletter</strong>!</p></li><li id="viewer-91ucr"><p>🎙 <strong>NEW</strong>! <a href="http://thedetechtor.com/" target="_blank" rel="noopener"><u>The Detechtor Podcast</u></a> is now available on all podcast players!                                                      <strong>Subscribe</strong> on <a href="https://podcasts.apple.com/fr/podcast/the-detechtor-podcast/id1537457578?l=en" target="_blank" rel="noopener"><u>Apple Podcasts</u></a> | <a href="https://open.spotify.com/show/5kc8WA6nZC69bQ1sbOrlNi?si=CwAuAtpfRpe7WmLu1PlO8w" target="_blank" rel="noopener"><u>Spotify</u></a> | <a href="https://podcasts.google.com/search/The%20detechtor%20Podcast" target="_blank" rel="noopener"><u>Google Podcasts</u></a> | <a href="https://www.stitcher.com/show/the-detechtor-podcast" target="_blank" rel="noopener"><u>Stitcher</u></a> | <a href="https://tunein.com/podcasts/Technology-Podcasts/The-Detechtor-Podcast-p1377296/?topicid=158813573" target="_blank" rel="noopener"><u>Tunein</u></a></p></li><li id="viewer-3sf88"><p>📲 Let's connect! <strong>Follow</strong> <strong>us</strong> on <a href="https://twitter.com/the_detechtor" target="_blank" rel="noopener"><u>Twitter</u></a> | <a href="https://www.instagram.com/thedetechtor/" target="_blank" rel="noopener"><u>Instagram</u></a> | <a href="https://www.facebook.com/thedetechtor" target="_blank" rel="noopener"><u>Facebook</u></a> | <a href="https://www.youtube.com/channel/UCAW--4_mML4A86W3670ix3w" target="_blank" rel="noopener"><u>Youtube</u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196633</guid>
            <pubDate>Tue, 24 Nov 2020 09:04:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I went from $2k in a year to $2k in a week]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25196434">thread link</a>) | @jakeprins
<br/>
November 24, 2020 | https://jakeprins.com/blog/how-i-went-from-2k-in-a-year-to-2k-in-a-week | <a href="https://web.archive.org/web/*/https://jakeprins.com/blog/how-i-went-from-2k-in-a-year-to-2k-in-a-week">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>After many hours of work, it was finally time to give people access to my new project, a SaaS boilerplate. In the first 5 days of early access, I almost made $2k in sales ($1,901.40 to be exact).</p><p>I have made and sold a React boilerplate before, <a href="https://www.reactmilkshake.com/">React Milkshake</a>. In the week after launching React Milkshake I made just 29 dollars. I, later on, created upgraded versions of the boilerplate. Every new version sold a bit better than the previous one, but with my completely new project <a href="https://serverless.page/">Serverless SaaS</a> I have made more in one week than with all the previous projects combined in a year.</p><p>This didn’t just happen because I just got luckier this time. Here is what I did differently.</p><h3>Landing page before product building</h3><p>The first mistake I made in the previous projects was working by myself until it was time to launch. This meant I didn’t have an audience.</p><p>Inspired by the #BuildInPublic movement, I decided for my new project to first build <a href="https://serverless.page/">the landing page</a> and open up a mailing list so people could subscribe and follow the progress of me building the product. Every now and then I shared some updates and slowly grew the mailing list to over 100 people that were sincerely interested in what I was making.</p><h3>Blogging</h3><p>In the past, I had written some articles on Medium before, but I decided to at least write one or two new blog posts every month. In total, I have at least 10 new blog posts that are related to some of the technologies that are being used in <a href="https://serverless.page/">Serverless SaaS</a>. Most of them are tutorials like <a href="https://medium.com/better-programming/how-to-set-up-next-js-with-tailwind-css-b93ccd2d4164">How to setup Next.js with Tailwind</a> or <a href="https://medium.com/better-programming/how-to-implement-netlify-cms-with-next-js-4b8721bdec45">How to implement Netlify CMS with Next.js</a>, but also a series called <em>stack choices</em> in which I compare different frameworks or technologies with each other as <a href="https://codeburst.io/stack-choices-react-vs-vue-vs-angular-vs-svelte-49aa0170c634">Angular vs React vs Vue vs Svelte</a>.</p><p>Writing these blog posts had multiple purposes and ended up with benefits:</p><ul><li>Learned a lot about these subjects</li><li>Provided value for other people learning about these subject</li><li>Earned some money with the <a href="https://help.medium.com/hc/en-us/articles/115011694187-Getting-started-with-the-Medium-Partner-Program#h_01EECWD3WWHZTJMF5PTK7AAM2C">Medium Partner Program</a></li><li>Gave me the ability to drop a link to my new project</li><li>Gave me the ability to drop a link to my personal site and Twitter</li><li>Increased my followings on Medium</li></ul><p>The people who read my blog posts could also be future customers because the starter-kit is mainly for developers (or people who work with developers).</p><h3>Mailing list</h3><p>This time I had built up a mailing list with around 100 subscribers, all with people who were interested in the boilerplate. Around 50% opened the emails I had to send and around 30% clicked the links to the site. This list is still growing because I still allow people to sign up to get regular updates.</p><p>Besides that, I already had a personal mailing list of people who had signed up for previous products I have to build like <a href="https://codestash.co/">codestash</a>, <a href="https://www.makermove.com/">makermove</a>, and <a href="https://www.raterfox.com/">raterfox</a>.</p><p>Because I started blogging more I updated <a href="https://jakeprins.com/">my personal site</a> and also added a signup field for this personal mailing list to stay informed about blog posts or product updates. In total, I had around 1000 people on this list to send out an announcement, but just 20% of that list opened the email and only 2.5% clicked the link. Those numbers are not great, but most of these subscribers come from <a href="http://raterfox.com/">raterfox.com</a>, a social platform for entertainment, which is clearly not my target audience.</p><h3>Twitter</h3><p>Twitter is a great platform for talking in public about the process and updates on your products. I wasn’t very active on Twitter and mainly used it to stay informed about tech-related stuff. I decided to be more active and did manage to gain some more Twitter followers. I think the slow growth is caused mostly by being more active on not just Twitter, but also on Indie Hackers and mentioning <a href="https://twitter.com/jakeprins_nl">my handle</a> in blog posts.</p><p>With the current 581 followers, I do not believe this had a very big impact on my launch. Twitter seems great for people with a couple of thousands of followers, but with &lt; 1k followers it sometimes feels like you are talking to a black hole of nothing.</p><p>I still think it’s a great way to share your work and be reachable by others. Some people started to DM me with questions about the boilerplate. This was already a good sign. Also, people told me they were excited about the upcoming launch, even better! Besides that, someone reached out to say my guides online were really helpful, which is always great to hear.</p><h3>Building a better product</h3><p>The first boilerplate I had build, <a href="https://www.reactmilkshake.com/">React Milkshake</a>, was a bit of an experiment. I was using it myself and wasn’t sure if other people were going to pay for it. It was very basic and doesn’t have a lot of features when it launched, but the fact that people started to buy it was super exciting for me. It proved that people are willing to pay money for a starter-kit that helped them save time.</p><p>For my next project, <a href="https://serverless.page/">Serverless SaaS</a>, I decided to spend more time on it and take it to the next level. I had some proof of the market, but the product needed to provide more value.</p><p>Most Indiehackers and developers I met online were building SaaS apps. I also had some ideas for building a SaaS, so a boilerplate that could help me build new SaaS apps faster was very helpful. If the boilerplate wouldn’t sell, I could still use it myself. So I decided to implement multiple SaaS features, like a billing integration with Stripe, and market the product as a way to build SaaS apps faster.</p><p>This would be more aligned with the need for most of my target audience and also allows me to ask for a higher price. It provides much more value than my other boilerplates and people are also more willing to pay for products that help them save time or make money. This project could potentially do both.</p><p>Instead of rushing to market and going with a full-on MVP approach, I figured I should take my time and craft a product to be proud of. After that, I could soft launch it as “Early Access”, so I could ask my first customers for feedback and improve the product while it’s being used by actual paying customers. In this soft launch period, I made more money than I did in the last year of my old project, so I guess I’m doing something right.</p><h2>Conclusion</h2><p>After years of indie hacking, I have learned a lot of valuable lessons. Looking back at the months leading to the “soft” launch of my new product, I can tell that certain activities will highly increase your chances of a successful launch.</p><p>Building in public, by sharing your progress and thoughts on social platforms, could definitely help a lot.</p><p>Taking time to write articles and provide value to others helps you in building an audience and to connect with people that might end up being a customer.</p><p>Also, don’t rush the process of building a product. It can be helpful to launch fast and validate your idea as quickly as possible, but if you want to provide real value that could mean you need to put in some extra time. Once you have seen some proof of evidence that people are willing to pay for your product I think it’s good to not rush your project. Don’t put too much pressure on yourself. But, when you think that MVP is ready, just ship it.</p><p>Thanks for reading! You can find me on Twitter (<a href="https://twitter.com/jakeprins_nl">@jakeprins_nl</a>) or read more at <a href="https://jakeprins.com/blog">jakeprins.com/blog</a>.</p></article></div></div>]]>
            </description>
            <link>https://jakeprins.com/blog/how-i-went-from-2k-in-a-year-to-2k-in-a-week</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196434</guid>
            <pubDate>Tue, 24 Nov 2020 08:26:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EU on the Verge of Breaking E2ee]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25196420">thread link</a>) | @35803288
<br/>
November 24, 2020 | https://european-pirateparty.eu/pirates-call-for-clear-rejection-plans-to-break-secure-online-encryption/ | <a href="https://web.archive.org/web/*/https://european-pirateparty.eu/pirates-call-for-clear-rejection-plans-to-break-secure-online-encryption/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="entry-content" itemprop="text">
			    <p><span>Brussels, 11/11/2020 –&nbsp;On Monday</span><b> </b><span>the Austrian National Service Broadcaster (ORF) published a secret draft of a planned Council resolution seeking to undermine encryption. According to the resolution, messaging services such as Whatsapp are to allow governments to decrypt and intercept secure online communications. </span><span><b><strong>Pirates call on responsibility of representatives of the public services to uphold and protect the fundamental right to privacy as well as the security of our digital communications infrastructure. </strong></b></span></p>
<p><span><b><strong>We also call on YOU, Internet users, to contact their governments in advance of tomorrow’s deadline (12:00) for input.</strong></b></span></p>
<p><span>The proposal stands in line with regular attacks by governments on the secure encryption of content, made under the guise of the fight against organized crime and terrorism.</span></p>
<p><span>“There is no such thing as a ‘partial backdoor’ to online communications. The security of all our communications must be given priority. This has been the clear position of the European Parliament since 2017, and it is also the biggest priority of the Pirates,” says Marcel Kolaja, Pirate Vice-President of the European Parliament.&nbsp;</span></p>
<p><span>“Contrary to what governments would have us believe, we have to choose between interception and security. Those who want to sacrifice secure encryption in order to enable eavesdropping will destroy the protection of private secrets, business secrets and state secrets, and open the door to mass-spying by foreign intelligence services as well as hacker attacks,” explains Pirate Patrick Breyer, German MEP.</span></p>
<blockquote><p><span>“It is technically impossible to grant access to securely encrypted communications solely for ‘lawful’ purposes. As soon as messaging services allow for the decryption of private communications, for instance by implementing backdoors or providing master keys, the security of communications is broken once and for all – not only for the ‘legitimate’ purposes envisioned by the national governments,” adds Mikuláš Peksa, MEP and chairperson of European Pirate Party.&nbsp;</span></p></blockquote>
<p><span>“Contrary to what is argued by the Presidency, there is no middle-way between upholding the ‘fundamental rights and the digital security of governments, industry and society’ and the breaking of secure end-to-end encryption. Therefore, we demand strict rejection of the proposal by the national government’s representatives. We ask European citizens to help us now and contact their governments immediately,” stresses Markéta Gregorová, Czech Pirate MEP.&nbsp;</span></p>
<h2><span>That is why</span><span><strong>&nbsp;</strong></span><b><strong><span>we prepared the letters which can help you with contacting your Permanent&nbsp;<span>representations</span>&nbsp;of the EU</span></strong></b><span><span><strong>&nbsp;</strong></span></span><b><strong><span>in each country. Moreover, we translated the text into a few European languages. </span></strong></b></h2>
<h2><span>For every translation, we added the e-mail&nbsp;<span>address</span>&nbsp;of your specific Permanent representations of the EU. Feel free to use it and ask for redirecting the letter to the specific governments!</span></h2>
<p><strong>PS: DO NOT FORGET TO ADD YOUR SIGNATURE IN THE END OF THE LETTER.</strong></p>
<hr>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/english.pdf">Main ENGLISH version of the letter.</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/deutsch.pdf">GERMAN version</a> – send it to: <a href="mailto:info@bruessel-eu.diplo.de">info@bruessel-eu.diplo.de</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/czech.pdf">CZECH version</a> – send it to: <a href="mailto:eu.brussels@embassy.mzv.cz">eu.brussels@embassy.mzv.cz</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/french.pdf">FRENCH version</a> – send it to: <a href="mailto:courrier.bruxelles-dfra@diplomatie.gouv.fr">courrier.bruxelles-dfra@diplomatie.gouv.fr</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/greek.pdf">GREEK version</a> – send it to: <a href="mailto:mea.bruxelles@rp-grece.be">mea.bruxelles@rp-grece.be</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/slovak.pdf">SLOVAK version</a> – send it to: <a href="mailto:eu.brussels@mzv.sk">eu.brussels@mzv.sk</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/spanish.pdf">SPANISH version</a> – send it to: <a href="mailto:reper.bruselasue@reper.maec.es">reper.bruselasue@reper.maec.es</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/Italian.pdf">ITALIAN version</a> – send it to: <a href="mailto:rpue.rpue@esteri.it">rpue.rpue@esteri.it</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/Estonian.pdf">ESTONIAN version</a> – send it to: <a href="mailto:permrep.eu@mfa.ee">permrep.eu@mfa.ee</a></p>
<p><a href="https://publisher.pp-eu.eu/static/ViewerJS/#/tmp/assets/doc/Icelandic.pdf">ICELANDIC version</a> – send it to: <a href="mailto:Delegation-Iceland@eeas.europa.eu">Delegation-Iceland@eeas.europa.eu</a></p>
			    			</div></div>]]>
            </description>
            <link>https://european-pirateparty.eu/pirates-call-for-clear-rejection-plans-to-break-secure-online-encryption/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196420</guid>
            <pubDate>Tue, 24 Nov 2020 08:24:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5th UberEats cyclist killed in Sydney in 3 months: Analysis and photos]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25196375">thread link</a>) | @jakecopp
<br/>
November 24, 2020 | https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/ | <a href="https://web.archive.org/web/*/https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Last updated: November 24th, 2020. Please leave comments on <a href="https://news.ycombinator.com/item?id=25196375">Hacker News</a> (&gt;6 comments).</p>

<p><strong>Content warning</strong>: Description of a death, and photos of the cleaned site of death.</p>
<p>After <a href="https://www.theguardian.com/business/2020/nov/23/death-of-sydney-uber-eats-rider-the-fourth-food-delivery-fatality-in-two-months">four cyclists were killed by car drivers in Sydney in the last 2 months</a>, a <a href="https://www.abc.net.au/news/2020-11-24/uber-eats-vows-to-improve-safety-cyclist-killed-in-inner-sydney/12913840">37-year-old man from Malaysia</a> was killed at ~6:40pm last night - on my street, 200 metres from my front door, at an intersection I cycle through 2-4 times a day. I would have gone through that intersection within 15 minutes of that time if I didn’t skip a class. If you know me, I’m usually quite outspoken about the dangers cyclists face, but this was absolutely brutal to hear.</p>
<p>They cleaned up the body, but didn’t completely clean up the UberEats meal the man was delivering. The man likely died while earning less than minimum wage - A survey conducted by the Transport Workers’ Union in September <a href="https://www.theguardian.com/business/2020/nov/23/death-of-sydney-uber-eats-rider-the-fourth-food-delivery-fatality-in-two-months">found</a> that food deliverers earned an average of just $10.42 an hour after costs. 73% said they were worried about being “seriously hurt or killed” at work.</p>
<p><em>Content warning: Image of scattered food on road, blue glove likely from police investigation.</em></p>
</div><div>
<p>An <a href="https://www.reddit.com/r/sydney/comments/jzewgi/fifth_food_delivery_rider_dies_following_truck/gdbm0s4/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">eyewitness account on Reddit</a>:</p>
<blockquote>
<p>…I was driving along Cleveland st, and only had a glimpse of what happened: for those of you arguing about PPE - I think there was a helmet - and a crushed head and body, and a twisted bicycle, and, yes, one of those grey food delivery bags all in the middle of Chalmers st. I am crying tonight, because that was someone’s child, friend … a person - who is no more… .</p>
</blockquote>
<p><em>Content warning: Image of fragment of the helmet of the cyclist in the road gutter.</em></p>
</div><div>
<h2 id="contributing-causes">Contributing causes</h2>
<p>This is a tragedy in itself, but there are also a number of contributing causes at play here:</p>
<ul>
<li><p>In NSW, cycling on a footpath <a href="https://bicyclensw.org.au/who-can-ride-on-a-footpath-in-nsw/">is illegal and carries a fine of $114</a> for those above 15 years of age. Footpath cycling is <a href="https://www.bykbikes.com.au/blogs/bike-riding-tips/riding-bikes-on-the-footpath-the-laws-for-kids-and-adults-in-australia">legal in</a> Queensland, Tasmania, the ACT, the Northern Territory and South Australia.</p>
<ul>
<li>In the UK in 2017, there is a cyclist/pedestrian collision every <a href="https://www.cyclingweekly.com/news/rise-pedestrians-hit-cyclists-not-cause-leap-conclusions-396047">~9.9 million kilometres walked by a pedestrian</a>, or 531 in total. Of these 531 collisions 3 people were killed.</li>
</ul></li>
<li><p>Gig economy workers have little training and often no insurance. California recently proposed a law to force Uber and other platforms to treat their workers like employees. It narrowly failed to pass after <a href="https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/Uber,%20Lyft,%20and%20DoorDash%20poured%20over%20$200%20million%20into">Uber, Lyft and Doordash spent &gt; US$200m</a> campaigning against the law.</p></li>
<li><p>Dedicated infrastructure for cyclists is rare in Sydney. Not only are separated bicycle lanes hard to come by, a state government <a href="https://concreteplayground.com/sydney/design-style/sustainability/state-goverment-moves-to-rip-up-college-street-cycleway">actively removed</a> a cycleway in 2015 (which <a href="https://www.dailytelegraph.com.au/newslocal/central-sydney/college-st-syclists-four-times-as-likely-to-be-involved-in-a-crash-since-cycleway-removed/news-story/98ebe30e5c649407e45fd1aa7f023049">increased accidents by 400%</a>) <a href="https://www.bicyclenetwork.com.au/newsroom/2019/03/12/planned-removal-of-alexandra-canal-cycleway/">and in 2019</a>. Walking and cycling infrastructure typically receives <a href="https://theconversation.com/cycling-and-walking-can-help-drive-australias-recovery-but-not-with-less-than-2-of-transport-budgets-142176">0.1-2% of transport budgets</a>. Clover Moore is pushing hard on adding new dedicated cycle infrastructure in the City of Sydney - <a href="https://www.cityofsydney.nsw.gov.au/building-new-infrastructure/creating-pop-up-cycleways-in-sydney">Six pop-up cycleways</a> have been added, which may remain if their is popular support.</p></li>
<li><p>Australian car drivers have a <a href="https://www.abc.net.au/triplej/programs/hack/mythbusting-the-reasons-why-people-hate-cyclists/8689058">unique hatred of cyclists</a>. Cyclists <a href="https://www.smh.com.au/lifestyle/youre-a-cyclist-so-its-your-fault-20140205-321np.html">attract a level of vitriol</a>, if not outright malice, reserved for few subjects in the laid back Aussie’s mind. Even Tour de France winner Cadel Evans, a self described “car guy” who has a number of classic and sports cars, said <a href="https://www.smh.com.au/entertainment/books/even-tour-de-france-winner-cadel-evans-finds-cycling-in-sydney-too-intimidating-20161118-gss316.html">he doesn’t cycle in Sydney</a> due to the culture. Cyclists want to be on the road even less than car drivers want them there, but as stated earlier it is illegal to cycle on the footpath.</p></li>
</ul>
<p><em>Content warning: Image of the street where event took place, recognisable to those who live in Sydney.</em></p>
</div><div>
<h2 id="reasons-for-change">Reasons for change</h2>
<h3 id="public-safety">Public safety</h3>
<p>Car crashes are one of the <a href="https://www.seattletimes.com/life/lifestyle/the-most-dangerous-activity-driving/">leading causes of death in western countries</a>, and air pollution due to cars killed <a href="https://www.smh.com.au/politics/federal/road-death-toll-should-include-victims-of-vehicle-emissions-report-20190628-p522a8.html">two times</a> as many people as <a href="https://roadsafety.transport.nsw.gov.au/statistics/index.html">crashes do</a> in NSW each year - and they didn’t even have a choice. <a href="http://publications.jrc.ec.europa.eu/repository/bitstream/JRC89231/jrc89231-online%20final%20version%202.pdf">Half of PM10 particle emissions come from tire wear, suspended road dust and brake wear</a>- electric cars (even with regen braking) won’t fix this. In the US, drivers of cars <a href="http://vpc.org/regulating-the-gun-industry/gun-deaths-compared-to-motor-vehicle-deaths/">kill more people</a> than guns each year.</p>
<p>NSW has a program called <a href="https://towardszero.nsw.gov.au/">Towards Zero</a>, with the aim of reducing road fatalities to zero. One of the few cities to achieve this goal is Oslo, which <a href="https://twitter.com/andershartmann/status/1212465415743512576">reduced pedestrian and cyclist deaths in 2019 to 0</a> by making the <em>city centre</em> <a href="https://www.fastcompany.com/90294948/what-happened-when-oslo-decided-to-make-its-downtown-basically-car-free">effectively car free</a>, replacing more than 700 parking spots with bike lanes, plants, parks and benches, increasing business.</p>
<p><em>Content warning: Image of food on the tarmac, and diffracted reflection from fluid likely used to clean the road.</em></p>
</div><div>
<h3 id="cars-are-heavily-subsidised-in-australia">Cars are heavily subsidised in Australia</h3>
<p>By the most generous measure, drivers only contribute <a href="https://www.ptua.org.au/myths/petroltax/">two-thirds of the cost of the road system</a> through rego and petrol taxes. The damage to a road is proportional to the <em>fourth power</em> of axle weight. Many cyclists also own a car and already pay rego. Contrary to popular belief, cyclists are likely subsidising car users.</p>
<h3 id="investing-in-cycle-infrastructurereducing-car-usage-makes-economic-sense">Investing in cycle infrastructure/reducing car usage makes economic sense</h3>
<p>In one study, for each dollar of investment in cycle focused infrastructure, the best practice policy returns 24 dollars in health, congestion, and air and noise pollution related benefits (<a href="https://ec.europa.eu/environment/integration/research/newsalert/pdf/378na1_en.pdf">Macmillan, A., Connor, J., Witten, K., et al.&nbsp;(2014). The Societal Costs and Benefits of Commuter Bicycling: Simulating the Effects of Specific Policies Using System Dynamics Modeling</a>)</p>
<p>A paper submitted to Infrastructure Australia estimated the value of commuter cycling in Australian capital cities as worth approximately <a href="https://www.infrastructureaustralia.gov.au/sites/default/files/2019-06/Cycling_Infrastructure_Background_Paper_16Mar09_WEB.pdf">$0.76 per kilometre travelled</a>, equating to $2,667 for each regular commuter. Another paper <a href="https://www.infrastructureaustralia.gov.au/sites/default/files/2019-06/Cycling_Infrastructure_Background_Paper_16Mar09_WEB.pdf">estimated</a> that converting drivers to cycling in Sydney &amp; Brisbane is worth $0.74 per kilometre, $1,920 per person annually in inner Sydney.</p>
<p>Banning cars on a street in Rome led to <a href="https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/www.theguardian.com/cities/2015/mar/13/pedestrianisation-rome-italy-car-parking-ban">30% increase</a> in retail spending in that street.</p>
<p>There are <a href="https://cityobservatory.org/ten-things-more-inequitable-that-road-pricing/">a lot of things</a> in our current system more inequitable than road pricing in urban areas.</p>
<h3 id="a-lot-of-other-cities-are-reducing-car-usage">A lot of other cities are reducing car usage</h3>
<p>I know this argumentum ad populum, but hey.</p>
<p>The following cities have a <a href="https://en.wikipedia.org/wiki/Congestion_pricing">congestion tax</a> in their urban core:</p>
<ul>
<li><a href="https://theconversation.com/london-congestion-charge-what-worked-what-didnt-what-next-92478">London</a></li>
<li><a href="https://en.wikipedia.org/wiki/Congestion_pricing_in_New_York_City">New York</a> (soon)</li>
<li>Stockholm</li>
<li>Singapore</li>
<li>Milan</li>
<li>Gothenburg</li>
</ul>
<p>Other efforts to reduce car usage:</p>
<ul>
<li><p>Oslo (population 673k) <a href="https://twitter.com/andershartmann/status/1212465415743512576">reduced pedestrian and cyclist deaths in 2019 to 0</a> by making the city centre <a href="https://www.fastcompany.com/90294948/what-happened-when-oslo-decided-to-make-its-downtown-basically-car-free">effectively car free</a>, replacing more than 700 parking spots with bike lanes, plants, parks and benches. Amsterdam, New York, and San Francisco are <a href="https://www.citylab.com/perspective/2019/12/car-free-streets-plans-sf-market-street-new-york-europe-us/603391/">banning cars from their major streets</a>.</p></li>
<li><p>Madrid banned cars from its city centre during the 2018 Christmas period, <a href="https://copenhagenize.eu/news-archive/2019/3/14/the-benefits-of-car-free-streets">increasing retail profit by 9.5%</a>, and they are planning to ban cars from <a href="https://www.businessinsider.com.au/cities-going-car-free-ban-2018-12?r=US&amp;IR=T">500 acres of the city centre this year</a>.</p></li>
<li><p>In <a href="https://www.businessinsider.com.au/cities-going-car-free-ban-2018-12?r=US&amp;IR=T">Paris</a>, the first Sunday of every month is free of cars.</p></li>
</ul>
<p><em>Content warning: Image of food in the gutter of the road.</em></p>
</div><div>







<div><p>Disagree with my argument? Have I missed something or is there a mistake? I'd love to hear, please
contact me at <a href="https://jakecoppinger.blog/cdn-cgi/l/email-protection#97fdf6fcf2d7fdf6fcf2f4f8e7e7fef9f0f2e5b9f4f8fa"><span data-cfemail="0e646f656b4e646f656b6d617e7e6760696b7c206d6163">[email&nbsp;protected]</span></a>. I'm open changing my views if presented with new evidence.
</p></div></div></div>]]>
            </description>
            <link>https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196375</guid>
            <pubDate>Tue, 24 Nov 2020 08:14:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time schedule during the day for better energy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25196130">thread link</a>) | @KlimYadrintsev
<br/>
November 23, 2020 | https://klimy.co/blog/time-schedule-during-the-day-for-better-energy | <a href="https://web.archive.org/web/*/https://klimy.co/blog/time-schedule-during-the-day-for-better-energy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <h2>How do you spend your day</h2>
<p>Do you realise that you are much more productive during the morning and day than you are during the evening?</p>
<p>Productivity = Result/Time</p>
<p>If you don’t believe me, you can measure it. Not form the memory but actually measure it with the metrics. I bet you would be surprised.</p>
<p>I have already done a post about <a href="https://klimy.co/blog/morning-routines-of-most-successful-people">Morning Routines of Most Successful People</a> as well as one about <a href="https://klimy.co/blog/how-to-wake-up-early">How to wake up early</a> so if you would like to learn how or why you can do it there.</p>
<p>The main post of this is to tell you that you don’t realise how is your body reacting to the times of the day you are in.</p>
<ul>
<li>When you are feeling tired at around 12 o’clock, and you go for a coffee, that is your body telling you to stop working as it is unproductive. </li>
<li>When you come back from lunch, and you just want to have a nap, that is your body telling you to take a break. </li>
<li>When you are struggling for the last hour just to do some pretend work, or you keep on checking your emails. That is your body telling you to get the hell away from work.</li>
</ul>
<p>You might think that this is all because of your job and that you just don’t enjoy it. The actual reason is that your body’s energy has peaks and throughs and you, as the owner of your body, are responsible for utilising those peaks as much as possible.</p>
<h2>How to improve your energy through the day</h2>
<p>Your homework is to get a blank piece of paper with a pen and put it next to your bed.</p>
<p>When you wake up, you record how long was your sleep and how you felt the day before and once you woke up. Keywords could be: Sleepy, tired, sad, well-rested, energised, happy.</p>
<p>Then you take that piece of paper, and you carry it with you for the whole day.</p>
<p>Every time you have spent a good amount of time working really hard or you were proud of the work that you did. You record the time and place of where and when you did it.</p>
<p>Also every time you feel tired, and you crave caffeine, you record that down: “Feeling tired, 12:15. I want to drink coffee.”</p>
<p>Do that for at least a day. See what you got, what times were you working hard and what times were you down?</p>
<p>That would tell you at what times you should be working and at what times you should be taking a quick 5 to 15-minute break. Believe me, your boss won’t even notice that you are taking a break.</p>
<h2>Mornings and its magic</h2>
<p>Also, you might have found a particular pattern. After lunchtime, you work productively a lot less, and you are feeling tired a lot more. Before lunch, you only might have 1 or 2 slumps.</p>
<p>Well, the reason for that is because as humans are animals of the mornings. We never had any real source of light for tens of thousands of years. Our bodies and brain adapted, that before it is dark, we need to secure the space around us and prepare to sleep so that we can wake up just at the sunrise the next day and carry on with surviving.</p>
<p>Well, if you are waking up not at the sunrise but later, you are basically wasting the precious time of your life. Your body gives an extra-strong boost to your energy in the mornings. If you sleep through that, then only you can blame yourself for that.</p>
<p>I challenge you to take the same blank piece of paper and re-record yourself. But today go to sleep early and wake up much earlier as well. I bet you would be shocked. </p>
<p>Not only will your productively work in the mornings, but you will also feel a lot less tired during the day. This enables you to get your life in a natural rhythm of life where you can spend mornings, working on something significant, something that you actually care and proud about.</p>
<h4>Don’t underestimate mornings</h4>
<p>It is such a magical thing that simply get ignored by most of the population. I think if humanity as a whole put the norm to wake up at 4 or 5, we would have insane progress and much less problem with alcohol and other social problems.</p>
<p>The worst of us come out late at night.</p>
<p>I ask of you to try waking up early. There is no harm.</p>
<p>Start now. Get perfect later.</p>
<p>Klim Y</p> 
                    
                </div></div>]]>
            </description>
            <link>https://klimy.co/blog/time-schedule-during-the-day-for-better-energy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196130</guid>
            <pubDate>Tue, 24 Nov 2020 07:22:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Last Free Generation (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25196123">thread link</a>) | @lettergram
<br/>
November 23, 2020 | https://austingwalters.com/the-last-free-generation/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/the-last-free-generation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2661">

<div>
<p>My son Atlas is just over nine months old. He’s just started crawling, eating solids, and getting close to saying words.</p>
<p>One thing that’s been troubling me, is that he probably won’t have liberty (freedom) in his lifetime.</p>
<p>Liberty requires a few things:</p>
<ol>
<li>Freedom of Self-Determination</li>
<li>Freedom to Defend Self-Determination</li>
<li>Freedom of Speech</li>
<li>Freedom of Information</li>
<li>Freedom to Privacy</li>
</ol>
<p>All of the above is more-or-less enumerated in the <a href="https://en.wikipedia.org/wiki/United_States_Bill_of_Rights" target="_blank" rel="noopener noreferrer">United States Bill of Rights</a>. The premise of liberty is simple: you have the right to do anything you desire that doesn’t impede others strive for self-determination. Although easily defined, the term “impede” is where the trouble is.</p>
<h2><del>Freedom to</del> Privacy</h2>
<p>Atlas (my son) was born in a world where <em>every single person</em> is tracked to within one meter of where they are at all times (if they have a cell phone). Everyone’s personality is classified, mood tracked, and manipulated at a grand scale.</p>
<p>Hell, as a <a href="https://insideropinion.com/" target="_blank" rel="noopener noreferrer">one man startup</a>, I write systems that predict the moods in real-time of nearly a million people who are communicating on the internet (<a href="https://hnprofile.com/" target="_blank" rel="noopener noreferrer">HNProfile.com</a> &amp; <a href="https://redditprofile.com/" target="_blank" rel="noopener noreferrer">RedditProfile.com</a>). More than that, it can predict moods, identify where they likely live, family, and even <a href="https://news.ycombinator.com/item?id=17940172" target="_blank" rel="noopener noreferrer">de-anonymize them</a>:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o.jpg"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o.jpg" alt="" width="1234" height="321" srcset="https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o.jpg 1234w, https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o-300x78.jpg 300w, https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o-768x200.jpg 768w, https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o-1024x266.jpg 1024w" sizes="(max-width: 1234px) 100vw, 1234px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o.jpg" data-srcset="https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o.jpg 1234w, https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o-300x78.jpg 300w, https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o-768x200.jpg 768w, https://austingwalters.com/wp-content/uploads/2018/11/41384957_10217638849388956_4305601918492737536_o-1024x266.jpg 1024w"></a></p>
<p>What does this mean? When everyone’s thoughts, actions, and moods can be predicted, we can be manipulated. Our government can identify “trouble” makers, the definition of which may change with the political season. Without the freedom to privacy, you don’t have freedom. I don’t see how my son can get that back. Thus, I try to keep as much out of the internet as possible.</p>
<h2><del>Freedom of</del> Information</h2>
<p>Facts… the news claims to report them, we are shown videos, hear audio clips, read documents. Occasionally, we’ve seen “fake” news and information in the past, however there’s something coming that’ll change everything.</p>
<p>Synthetic data (<a href="https://medium.com/capital-one-tech/why-you-dont-necessarily-need-data-for-data-science-48d7bf503074" target="_blank" rel="noopener noreferrer">which I also work on</a>) is also becoming increasingly realistic. Meaning, the term “real news” will take on a whole new meaning. For instance, we can overlay Nicholas Cage on anyones face:</p>
<center><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/BU9YAHigNx8" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></center><p>In addition, we can do this with audio,&nbsp;<a href="https://medium.com/capital-one-tech/why-you-dont-necessarily-need-data-for-data-science-48d7bf503074" target="_blank" rel="noopener noreferrer">text from my work</a>, and I’m working on improved video too…</p>
<p>For this reason, I avoid discussing or posting images of my son on the internet. With a handful of images and a 30 second sound clip, we can start generating synthetic videos and as it relates to privacy, we can construct real-looking scenarios.</p>
<p>What does this mean? When we don’t know what’s real — <em>everything loses meaning</em>. This is the death of freedom of information; poisoning the well so-to-speak. Worse than propaganda, because we can no longer distinguish what is real. Eventually, we will all lose faith in “facts”.</p>
<h2><del>Freedom of</del> Speech</h2>
<p>Increasingly, communication occurs in a few centralized locations: Facebook (Messenger, WhatsApp, Instagram), Twitter, Google Messages, Apple iMessage, Reddit, etc.; accessed via a few devices: Windows, Mac, iPhone, Android; via several service providers: Verizon, AT&amp;T, Comcast, T-Mobile.</p>
<p>Notice, each one of those systems are gatekeepers to communication with the wider world. If they ban you, you’re locked out of your community. Discussions are not “free” on any social network, which arguably is where most of the discussions happening for younger generations. This will likely increasingly be true for people from my sons generation. These are echo chambers, further manipulating free speech. Communities are segregated and if you say something people don’t like…</p>
<figure id="attachment_2666" aria-describedby="caption-attachment-2666"><a href="https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51.png" target="_blank" rel="https://www.billboard.com/articles/business/8473944/twitter-bans-alex-jones-infowars-abusive-behavior noopener noreferrer"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51.png" alt="" width="501" height="501" srcset="https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51.png 634w, https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51-150x150.png 150w, https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51-300x300.png 300w" sizes="(max-width: 501px) 100vw, 501px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51.png" data-srcset="https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51.png 634w, https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51-150x150.png 150w, https://austingwalters.com/wp-content/uploads/2018/11/Screenshot-from-2018-11-05-01-35-51-300x300.png 300w"></a><figcaption id="caption-attachment-2666">From: billboard.com</figcaption></figure>
<p>Banning people today may seem minor and deserved, however the implications are massive. Imagine if Twitter and Facebook decided to ban liberals… It would be like silencing half the United States. Although that’s only occurring in rare cases today, it appears to be occurring at an increasing rate lately[<a href="https://news.sky.com/story/twitter-asks-users-if-it-should-ban-dehumanising-speech-11509062" target="_blank" rel="noopener noreferrer">1</a>].</p>
<p>What does this mean? If only three companies control 90% or more of discourse on the internet and those three companies start censoring their user bases, we no longer have free speech within our communities.</p>
<p>Final note on this, when the government [attempts to] prosecute(s) individuals who are whistle blowers (aka <a href="https://en.wikipedia.org/wiki/Edward_Snowden" target="_blank" rel="noopener noreferrer">Edward Snowden</a>) or journalists <em>who aren’t United States citizens</em> (aka <a href="https://en.wikipedia.org/wiki/Julian_Assange" target="_blank" rel="noopener noreferrer">Julian Assange</a>), our ability to practice “freedom of speech” is all but a farce.</p>
<h2><del>Freedom to</del> Defend Self-Determination</h2>
<p>This is a touchy subject for some. The idea is that without the ability to defend your liberties at some point, they’re bound to be taken away. That doesn’t necessarily mean arms (weapons, guns); this includes legal proceedings to defend your rights. Unfortunately, with the <a href="https://www.eff.org/deeplinks/2014/08/what-you-need-know-about-fisa-court-and-how-it-needs-change" target="_blank" rel="noopener noreferrer">FISA court</a>, they can both issue warrants and gag orders, with the court not really answering to anyone. Meaning, there is no way to defend yourself legally.</p>
<p>Historically, this is where arms (weapons, guns) come in. It’s the final, ultimate check to a government. Are we there yet? Not quite, but say the government decided to ban abortion and make it illegal to be LGTB (after so many people have come out)? The only defense those people have will be defending themselves “illegally” with weapons. That’s, in part, why we have that embedded in the constitution of the United States.</p>
<center><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/ufTEtGQZZ9g" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></center><p>What does this mean? To have self-determination, you need to have the means to defend it. Otherwise, you wont have it any more, typically when a tyrannical government comes to power. In the documentary above, a sitting representative, supposedly with the authority to review the NSA has their house broken into… by the very organization(s) it’s supposed to oversee.</p>
<h2><del>Freedom of</del> self-determination</h2>
<p>With the above eroded away, with <a href="https://www.theatlantic.com/technology/archive/2014/06/everything-we-know-about-facebooks-secret-mood-manipulation-experiment/373648/" target="_blank" rel="noopener noreferrer">mood manipulation</a> prevalent, 24/7 real-time surveillance, from devices we even install ourselves…</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2018/11/w9eLjgT.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2018/11/w9eLjgT.png" alt="" width="602" height="574" srcset="https://austingwalters.com/wp-content/uploads/2018/11/w9eLjgT.png 684w, https://austingwalters.com/wp-content/uploads/2018/11/w9eLjgT-300x286.png 300w" sizes="(max-width: 602px) 100vw, 602px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2018/11/w9eLjgT.png" data-srcset="https://austingwalters.com/wp-content/uploads/2018/11/w9eLjgT.png 684w, https://austingwalters.com/wp-content/uploads/2018/11/w9eLjgT-300x286.png 300w"></a>What hope does my son have? Self-determination requires we have access to information, the ability to choose the way we live (including privately), the ability we can decide who, what, where, when why we do what we do.</p>
<p>I was born free. My father was born free. My grand-father was born free.</p>
<p>We didn’t always have welfare, social security, and other forms of security. We’ve always had terrorism, and the risks of life. To a large degree, our society (and world) has tried to leave this Earth, better than we left it. Unfortunately, it appears as our society grows — it is suffocating what it strives to protect: life &amp; liberty.</p>
<p>Today, my son has no hope for liberty.</p>
<p>All I can do, is provide him the best opportunity for privacy I can. I don’t upload his photos, I’m working on these systems so I can control their development, I donate to the EFF, and I do my best to inform others. I’ll fight for change, but the first step is to inform.</p>
<h3>Related Articles</h3>
<ol>
<li><a href="https://austingwalters.com/is-search-solved/">Is search Solved?</a></li>
<li><a href="https://austingwalters.com/song-cannot-remember/">The Song I can’t Remember</a></li>
<li><a href="https://austingwalters.com/a-new-way-to-invest/">A new way to invest</a></li>
<li><a href="https://austingwalters.com/an-essay-on-wealth-and-freedom/">An Essay on Wealth and Freedom</a></li>
<li><a href="https://austingwalters.com/maximizing-learning-how-audiobooks-can-change-your-life/">Maximizing Learning – How Audiobooks Can Change Your Life</a></li>
</ol>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/the-last-free-generation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196123</guid>
            <pubDate>Tue, 24 Nov 2020 07:21:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Patent, Trademark or Copyright?: Get Your IP Terminology Straight (2017)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195992">thread link</a>) | @Tomte
<br/>
November 23, 2020 | https://www.knowmad.law/single-post/2017/05/30/patent-trademark-or-copyright-get-your-ip-terminology-straight | <a href="https://web.archive.org/web/*/https://www.knowmad.law/single-post/2017/05/30/patent-trademark-or-copyright-get-your-ip-terminology-straight">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.5.0"><div dir="ltr"><div><div id="viewer-3ccc1"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label=""><p><img data-pin-url="https://www.knowmad.law/single-post/2017/05/30/patent-trademark-or-copyright-get-your-ip-terminology-straight" data-pin-media="https://static.wixstatic.com/media/192a90e155664d2b84e9ccddafe7454e.jpg/v1/fit/w_500%2Ch_333%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/192a90e155664d2b84e9ccddafe7454e.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt=""></p></div></div></div></div><p id="viewer-irno"><span>The terms “patent,” “trademark,” and “copyright” are often used interchangeably in everyday conversation.  Even media reports about intellectual property sometimes get the terms mixed up. But, to IP practitioners, they represent very different concepts.

This can lead to some initial confusion when business owners contact an IP firm to discuss protecting their intangible assets. If you want to go in with some handle on the jargon, not to worry. Knowmad Law is here with some simple pointers.</span></p><p id="viewer-els3f"><span><strong>Patents</strong></span></p><p id="viewer-fvt5e"><span>Attorneys must have a science background and pass a special bar exam to file patent applications. In many firms patent <a href="https://www.knowmad.law/glossary" target="_top" rel="noopener">prosecution</a> is an entirely separate practice group from trademark, copyright and trade secret matters (sometimes somewhat-condescendingly referred to as “soft IP”). When people talk about “patents,” they’re usually talking about utility patents, but, confusingly, U.S. law also recognizes design patents and <a href="https://www.knowmad.law/post/plantpatents" target="_top" rel="noopener noreferrer"><u>plant patents</u></a>, which are technically subcategories of patent but may be better thought of as separate forms of IP.</span></p><p id="viewer-b40ff"><span><em><strong>What it protects: </strong></em>new and useful inventions, including machines and processes</span></p><p id="viewer-ar8ft"><span><em><strong>Why it exists: </strong></em>to incentivize innovation</span></p><p id="viewer-59bk8"><span><em><strong>How you get it: </strong></em>application to USPTO</span></p><p id="viewer-3hst6"><span><em><strong>What it gives you:</strong></em> the exclusive right to sell, make or use an invention for 20 years</span></p><p id="viewer-4h0if"><span><strong>Copyright</strong></span></p><p id="viewer-7v4s4"><span>Unlike patents and trademarks, there isn’t really a discreet unit of intellectual property known as “a copyright” (though the term is often used as shorthand for “copyright registration”). Instead, we find it preferable to think of “copyright” as an uncountable noun like “knowledge” and to discuss our clients’ copyright portfolios in terms of <em>works subject to copyright</em>.</span></p><p id="viewer-6b4oo"><span><em><strong>What it protects:</strong></em> works of creative expression, including any original text, graphic, audio or video content</span></p><p id="viewer-b3v8k"><span><em><strong>Why it exists:</strong></em> to incentivize creative activity</span></p><p id="viewer-fbl0u"><span><em><strong>How you get it:</strong></em> creating something (registration with Library of Congress grants additional rights)</span></p><p id="viewer-efncf"><span><em><strong>What it gives you: </strong></em>the exclusive right to reproduce, distribute or display a work for 70 years after your death (or 95 years for institutional authors)</span></p><p id="viewer-jvde"><span><strong>Trademarks</strong></span></p><p id="viewer-8ue5u"><span>Trademark law is rooted in consumer protection and market regulation. This is an important distinction from patents and copyright, which are essentially government bounties to reward inventors and artists. Whereas the Patent Act and Copyright Act are based upon a <a href="http://en.wikipedia.org/wiki/Copyright_Clause" target="_blank" rel="noopener">specific provision of the U.S. Constitution </a>directed to encouraging “science and the useful arts,” Congress relied on the regular old <a href="http://en.wikipedia.org/wiki/Commerce_Clause" target="_blank" rel="noopener">Commerce Clause</a> to pass the Trademark Act.</span></p><p id="viewer-2jqe6"><span><em><strong>What it protects:</strong></em> indications of origin for goods and services, including words and symbols</span></p><p id="viewer-1a3h"><span><em><strong>Why it exists:</strong></em> to prevent consumer confusion and deceptive business practices</span></p><p id="viewer-e9av4"><span><em><strong>How you get it: </strong></em>using a mark to sell or market particular goods or services (registration with USPTO grants additional rights)</span></p><p id="viewer-1pl7q"><span><em><strong>What it gives you:</strong></em> the right to prevent others from using similar marks to sell or market related goods or services</span></p><p id="viewer-34nun"><span><strong>Trade Secrets</strong></span></p><p id="viewer-cquao"><span>Rounding out the “big four” of intellectual property are trade secrets. Though less often discussed than patents, trademarks and copyright, trade secrets are often the only way to protect a business’s most valuable assets.</span></p><p id="viewer-a2oov"><span><em><strong>What it protects:</strong></em> valuable and confidential information</span></p><p id="viewer-epc8h"><span><em><strong>Why it exists:</strong></em> to prevent unfair business practices</span></p><p id="viewer-64v3l"><span><em><strong>How you get it: </strong></em>keeping the information secret</span></p><p id="viewer-6m0m0"><span><em><strong>What it gives you: </strong></em>a claim against anyone who obtains or spreads the information by improper means</span></p><p id="viewer-d3rvm"><span>There’s a certain amount of overlap between these spheres of protection. For example, a company might use a trademark to market its patented technology. Or a computer process might be the subject of a patent, while the specific code used to implement the process is covered by copyright. In both cases, these tangential rights would persist after the patent expires.</span></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.knowmad.law/single-post/2017/05/30/patent-trademark-or-copyright-get-your-ip-terminology-straight</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195992</guid>
            <pubDate>Tue, 24 Nov 2020 06:51:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crossing the Rubicon]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195974">thread link</a>) | @lettergram
<br/>
November 23, 2020 | https://austingwalters.com/crossing-the-rubicon/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/crossing-the-rubicon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3793">

<div>
<p>The phrase: “Crossing the Rubicon” refers to when Julius Caesar crossed the Rubicon river with a legion on January 10, 49 BC, leading to the Roman Civil War.</p>
<p>At the time of writing, the United States is at that cross roads. Make no mistake, we are witnessing a power struggle, one which could easily lead to armed conflict across the United States and perhaps the world.</p>
<p>I believe most people believe this is due to Donald Trump; perhaps. However, I contend it’s actually much deeper. Rather than Trump, I believe the corporations have crossed the Rubicon, effectively electing Joe Biden. I’m not confident it was coordinated, but it does appear there has been a concerted effort to elect Joe Biden (influencing our news). We can all see it.</p>
<p>In November 2018, I wrote “<a href="https://austingwalters.com/the-last-free-generation/" target="_blank" rel="noopener noreferrer">The Last Free Generation</a>” about how this is the last generation that will have freewill. What I didn’t expect was the 2020 elections to be so obvious.</p>
<blockquote><p>For reference: I would never vote for Trump. I believe his character is too divisive and a leader who can’t unite is not a leader.</p></blockquote>
<h2>Censorship in 2020</h2>
<p>The 2020 elections are astonishing. It is the first election I’ve experienced where literally there was a media blacking out a president. Quite literally, Donald Trump was regularly taken off the air.</p>
<center><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/nUVkFvcN08o" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></center><p>Even my posts are regularly flagged on Hacker News (all of them were flagged at one point by the community, many decisions were reversed by the community or <a href="https://news.ycombinator.com/submitted?id=dang" target="_blank" rel="noopener noreferrer">Dang</a>)</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-23-21-19-53.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-23-21-19-53.png" alt="" width="618" height="245" srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-23-21-19-53.png 618w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-23-21-19-53-300x119.png 300w" sizes="(max-width: 618px) 100vw, 618px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-23-21-19-53.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-23-21-19-53.png 618w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-23-21-19-53-300x119.png 300w"></a>Dorsey even said he was censoring real stories (the <a href="https://www.finance.senate.gov/imo/media/doc/2020-11-18%20HSGAC%20-%20Finance%20Joint%20Report%20Supplemental.pdf" target="_blank" rel="noopener noreferrer">Hunter Biden Laptop)</a>:</p>
<center><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/tWayExRuaYk" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></center><p>So what? Dorsey later corrected himself, Donald Trump was claiming inaccurate information.</p>
<p>The problem is it manipulated the information people viewed. It was clearly election interference, to remove unfavorable information about a given candidate. There’s similarly a pinned tweet from President Trump.</p>
<blockquote data-width="550" data-dnt="true">
<p lang="und" dir="ltr"><a href="https://t.co/Za1BByChjN">pic.twitter.com/Za1BByChjN</a></p>
<p>— Donald J. Trump (@realDonaldTrump) <a href="https://twitter.com/realDonaldTrump/status/1331057517095489539?ref_src=twsrc%5Etfw">November 24, 2020</a></p></blockquote>

<p>In the video, there is a claim that Google intentionally did not provide voter notifications to conservatives, while liberals were receiving voter notifications. Search history was being adjusted, websites blocked, etc. There was a 700+ person study and there’s solid evidence.</p>
<h2>The Executive Order</h2>
<p>What I think many have missed is the <a href="https://www.whitehouse.gov/presidential-actions/executive-order-imposing-certain-sanctions-event-foreign-interference-united-states-election/" target="_blank" rel="noopener noreferrer">Executive Order on Imposing Certain Sanctions in the Event of Foreign Interference in a United States Election</a>. The introduction,</p>
<blockquote><p>I, DONALD J. TRUMP, President of the United States of America, find that the ability of persons located, in whole or in substantial part, outside the United States to interfere in or undermine public confidence in United States elections, including through the unauthorized accessing of election and campaign infrastructure or the covert distribution of propaganda and disinformation, constitutes an unusual and extraordinary threat to the national security and foreign policy of the United States. Although there has been no evidence of a foreign power altering the outcome or vote tabulation in any United States election, foreign powers have historically sought to exploit America’s free and open political system. In recent years, the proliferation of digital devices and internet-based communications has created significant vulnerabilities and magnified the scope and intensity of the threat of foreign interference, as illustrated in the 2017 Intelligence Community Assessment. I hereby declare a national emergency to deal with this threat.</p></blockquote>
<p>There’s a pretty good video on this, see video below:</p>
<center><iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/p2MkvWh7poY" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></center><p>Effectively, in 45 days of the election; we’re likely to see a report on any foreign interference in the United States election.</p>
<p>For something to be considered “foreign interference” one of the following criteria must be met:</p>
<blockquote><p>(i) to have directly or indirectly engaged in, sponsored, concealed, or otherwise been complicit in foreign interference in a United States election;</p>
<p>(ii) to have materially assisted, sponsored, or provided financial, material, or technological support for, or goods or services to or in support of, any activity described in subsection (a)(i) of this section or any person whose property and interests in property are blocked pursuant to this order; or</p>
<p>(iii) to be owned or controlled by, or to have acted or purported to act for or on behalf of, directly or indirectly, any person whose property or interests in property are blocked pursuant to this order.</p></blockquote>
<p>Unfortunately, for tech companies &amp; media companies it’s quite possible this criteria is met (see subsection iii on “acted or purported to act for or on behalf of, directly or indirectly”).</p>
<h2>Where is Barr?</h2>
<p>On October 20, 2020, many states and the federal government of the United States <a href="https://www.npr.org/2020/10/20/925736276/google-abuses-its-monopoly-power-over-search-justice-department-says-in-lawsuit" target="_blank" rel="noopener noreferrer">filed an antitrust lawsuit against Google</a>. At the time, <a href="https://www.nbcnews.com/politics/justice-department/justice-department-11-states-accuse-google-antitrust-violations-n1244005" target="_blank" rel="noopener noreferrer">many including Google</a>, claimed it would not be effective; the lawyers even said they were not prepared. What if it’s about the lawsuits, but it’s also about implicating Google in manipulations of the elections. When a lawsuit of this kind is filed, discovery is allotted. Barr was animate about doing the initial lawsuit <a href="https://www.nytimes.com/2020/09/03/us/politics/google-antitrust-justice-department.html?referringSource=articleShare" target="_blank" rel="noopener noreferrer">before the election.</a></p>
<p>From the public hearings with Zuckerberg and Dorsey, they implicated their companies (and themselves) in suppressing stories (inaccurately I might add) and with the discovery allotted from the lawsuit brought by Barr, they now have the all three of them “red handed” and that executive order can be utilized to it’s full effect.</p>
<h2>Closing Thoughts</h2>
<p>I’m not saying Trump will utilize this executive order. However, he has the authority to do so until December 18, 2020 (45 days after the election). I would not at all be surprised if a plan is executed to seriously cripple the media and at the same time he presents his claims of election fraud (not claiming they’re true one way or the other).</p>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/crossing-the-rubicon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195974</guid>
            <pubDate>Tue, 24 Nov 2020 06:49:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India's WhiteHat Jr is startup hell]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195938">thread link</a>) | @mihir6692
<br/>
November 23, 2020 | https://themorningcontext.com/internet/indias-whitehatjr-is-startup-hell | <a href="https://web.archive.org/web/*/https://themorningcontext.com/internet/indias-whitehatjr-is-startup-hell">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p><strong><span>S</span>haarif Ansari got the call on 11 November</strong> at around 9 in the morning. On the phone was a police officer from Powai police station, in the suburbs of Mumbai. “Ansari please come to the police station,” said the officer. “We have received a complaint from your employer WhiteHat Jr. The company officials are here at the station already. We are waiting for you.”&nbsp;</p> <p>Ansari was taken aback. It is not everyday that you have a police officer call you. Almost immediately he clarified that he did not work at WhiteHat Jr anymore. That he was fired by the company in the first week of September and had had no contact with them since, so what was all this about? The person was in no mood to explain or chat. He cut Ansari off, and asked him to turn up at the station immediately. Caught completely by surprise and with no idea about what was in store for him, Ansari said he was on his way.</p> <p>Once he reached the station, Ansari found two people waiting for him</p></div></div></div></div></div>]]>
            </description>
            <link>https://themorningcontext.com/internet/indias-whitehatjr-is-startup-hell</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195938</guid>
            <pubDate>Tue, 24 Nov 2020 06:41:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That’s not why I did it]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25195659">thread link</a>) | @MaysonL
<br/>
November 23, 2020 | https://weaversew.com/wordblog/2020/11/07/thats-not-why-i-did-it/ | <a href="https://web.archive.org/web/*/https://weaversew.com/wordblog/2020/11/07/thats-not-why-i-did-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
<div id="content">

	
		<div id="post-11347">
			

			<p>It has been a very long time since I’ve dealt with a major loom screw up.&nbsp; A really long time.&nbsp; Like I don’t remember the last time?&nbsp; And it isn’t because I’m so very good at this whole weaving thing, but it sort of is.&nbsp; I’ve been weaving since the mid 70’s.&nbsp; If there is a mistake, or screw up, I can assure you I made it or did it at some point in my career.&nbsp; One of the glorious things about being a weaver is the pure tenacity that controls what we do and how we approach a situation.&nbsp;&nbsp;</p>
<p>Of course by now, you are all familiar with my daughter and her major accomplishments as a weaver.&nbsp; She works for me now, and is responsible for converting all of my garment patterns into <a href="https://www.weaversew.com/shop/sewing-patterns.html">digital downloads</a>.&nbsp; She is also responsible for filming, producing and editing all of my videos for my YouTube channel, <a href="https://www.youtube.com/channel/UCmz2mYvnteUP11-LvK8-eNg"><em>The Weaver Sews</em></a> and writing all of the Closed Captioning.&nbsp; (Yes, I caught that there were a couple of misspellings in previous episodes…)&nbsp; I couldn’t have moved into this next portion of my professional life without her, but that’s not why I did it…</p>
<p>My daughter, Brianna, yes she has a real name, not the one she uses on Facebook, was asked back last winter if she would give a lecture to her old weaving guild in MA, near where she went to school.&nbsp; The lecture, on differential sett, was scheduled for April of this year.&nbsp; And of course we all know what happened in the northeast by April.&nbsp; The world was cancelled.</p>
<p>Since my daughter is a soon to be 28 year old millennial, she does her best work under deadline pressure.&nbsp; (Truth be told, so do I…)&nbsp; The guild called her last week and asked if she would be willing to give the lecture remotely.&nbsp; Hahahahah!&nbsp; Of course she said yes, which is what I would have done at that age.&nbsp; I use to have a sign on&nbsp; my studio door that said, “Say yes, then worry…”</p>
<p>So my daughter had to build an entire lecture that only existed as an outline, and weave all the samples in less than two weeks (the lecture is next week), plus edit and create new content for me, plus work in the evenings on her schooling, (yes, she is still in school to get her vet tech license).&nbsp; But that’s not why I did it….</p>
<p>One of the samples Brianna decided to weave, was exploring what happens when you use differential sett with really slippery rayon, warp and weft, and then slippery rayon warp and a dragging kind of weft like Shetland wool.&nbsp; The sample with the slippery rayon warp, though challenging, was completely successful.&nbsp; She then wound a warp with the Shetland wool, and the idea was she would tie into the rayon warp and repeat the experiment with a rayon weft and a wool weft, producing an additional two samples.&nbsp;&nbsp;</p>
<p>At one point, she said to me, as I was weaving on another of the looms in the studio, “This is ridiculous, tying in a new warp, I could have started fresh, sleying and rethreading in half the time…”&nbsp; and I couldn’t disagree with her.&nbsp; I’ve never found tying in a new warp to be a time saver.</p>
<p>I went off to do something else and came back and she had only tied in about 2/3rds of the warp, and she moved onto a different loom to do other samples of different weave structures.&nbsp; She told me that she was fed up and didn’t have the time to waste tying in 600 ends on a table loom.&nbsp; But that’s not why I did it…</p>
<p>I went off to other projects of my own, like writing the script for Friday’s <a href="https://www.youtube.com/channel/UCmz2mYvnteUP11-LvK8-eNg"><em>The Weaver Sews</em></a> Youtube installment.&nbsp; I came back and decided to finish tying in the rest of the warp, which would have been 200 ends.&nbsp; It wasn’t a big deal, and I can do stuff like that in my sleep.&nbsp; I was surprised when she directed me to make a square knot, I had always tied in new warps with an overhand knot, but I learned long ago that I didn’t argue with my late husband, and I don’t argue with his daughter.&nbsp; Even though I have almost a half century of experience…</p>
<p>I finished the task and then turned the job of beaming the 1&nbsp; 1/2 yard warp of sticky Shetland wool, onto the warp beam, over to my daughter.&nbsp; I think I went off to bed…</p>
<p>I came back the next day to find the warp abandoned.&nbsp; It was a complete disaster.&nbsp; I don’t think even at my worst I’ve ever had a mess like that.&nbsp; Partly I take some responsibility because my daughter has worked along side of me since she first learned to throw a shuttle.&nbsp; She never had the opportunity to fall flat on her face, like most weavers, including me, have had to do.&nbsp; I’ve always been there to guide her, when she chooses to listen to me.&nbsp; But that’s not why I did it…</p>
<p>Largely what happened, is that when she put tensioning bars in the back of the warp, and tried to beam the new sticky Shetland warp into the old slick rayon warp, the square knots didn’t hold, they slipped right out.&nbsp; And for some reason, the Shetland wool ends, that slipped out of the knots, ended up in the front of the beater, probably about 200 of the 600 ends.&nbsp; I think this wins an award for the most messed up warp I’ve ever seen.&nbsp; That’s partly why I did it…</p>
<p><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster1.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster1-300x225.jpg" alt="" width="300" height="225" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster1-300x225.jpg 300w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster1-150x113.jpg 150w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster1.jpg 614w" sizes="(max-width: 300px) 100vw, 300px"></a><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster2.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster2-300x225.jpg" alt="" width="300" height="225" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster2-300x225.jpg 300w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster2-150x113.jpg 150w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster2.jpg 614w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>I felt really sorry for my daughter, she was trying so hard to see this lecture into fruition…&nbsp; But that’s not why I did it…</p>
<p>I felt partly responsible because I knew that when you tie in a warp, you always use overhand knots.&nbsp; There are a lot of things I know, but I don’t know why I know them.&nbsp; And because my daughter requested square knots, I obliged.&nbsp; But that’s not why I did it…</p>
<p>I laid awake all Thursday night haunted by the mess on one of the looms in the garage right underneath of me.&nbsp; I kept thinking, if that were me, I wouldn’t have gone to bed without fixing it.&nbsp; But that’s me, even though I knew I had a video to shoot in the morning. I didn’t sleep the whole night.&nbsp; My daughter just moved to a different loom, and started on a different group of samples she had been planning.</p>
<p>In fact my daughter was so upset by what happened that she couldn’t even look at the loom. She couldn’t even walk over to that area of the studio.&nbsp; &nbsp;She is not use to having major loom screw ups…&nbsp; I’ve largely protected her from that…&nbsp; But that’s not why I did it…</p>
<p>We stopped everything to shoot the new video Friday morning, and I had some computer/business stuff to attend to, but Friday afternoon, I sat at the loom and thought, it has been a very long time since I’ve bailed a loom out of a major temper tantrum, and you know what?&nbsp; I really wanted to just dive in there and fix it.&nbsp; That’s why I wanted to do it.</p>
<p>A couple of years ago, I had my new to me dog chew up a skein of yarn that was being wound into pirns for the weft yarn for a project I was working on.&nbsp; I got distracted by the doorbell, and when I returned I found&nbsp; the skein stretched around my loom, and all the way down the stairs, and the skein chewed beyond help.&nbsp; I can’t believe the number of weaver’s who offered to have me send them the skein and promised to untangle every last yard.&nbsp; There is something about fixing a monumental disaster that is really appealing for a weaver.&nbsp;&nbsp;</p>
<p><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/NoroDisaster.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/NoroDisaster-169x300.jpg" alt="" width="169" height="300" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/NoroDisaster-169x300.jpg 169w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/NoroDisaster-84x150.jpg 84w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/NoroDisaster.jpg 345w" sizes="(max-width: 169px) 100vw, 169px"></a></p>
<p>I sort of think that it has to do with creating calm in chaos.&nbsp; There is so little in the world that we have any control over.&nbsp; But what happens at our looms, that thing, we have control over.&nbsp; And if what happens on our looms becomes total chaos, then patience, tenacity, and time will make it work.&nbsp; That’s why I did it.&nbsp;&nbsp;</p>
<p>So I started Friday afternoon, after the shoot, and I began to reassess the 600 ends and how to best resolve the mess.&nbsp; Cutting the whole thing off and starting over was an option, but it would mean wasting a perfectly good 1 1/2 yard Shetland warp, that I paid good money for…</p>
<p>I decided that the best way out, was to carefully pull the warps that ended up in front of the reed, since they were only 1 1/2 yards, and resleying them where required (because this was a differential sett warp, there were dents where there were as many as five ends) and then carefully tying them back into the slippery rayon warps that went through the heddles, one by one.&nbsp; I probably spent 10 hours.&nbsp; This was really really challenging.</p>
<p><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster3.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster3-300x225.jpg" alt="" width="300" height="225" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster3-300x225.jpg 300w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster3-150x113.jpg 150w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster3.jpg 614w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>I did it because there is something intensely satisfying about bringing order to chaos.&nbsp; There is something intense about saving a project.&nbsp; I had my doubts that this was even weaveable, 5 ends of Shetland in a 12 dent reed on a table loom didn’t see realistic, but that wasn’t for me to judge.&nbsp; I grabbed my 5X glasses, a magnifying OTT lite, and a sley hook and started in.&nbsp; 10 hours later I was triumphant.&nbsp;&nbsp;</p>
<p><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster4.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster4-300x225.jpg" alt="" width="300" height="225" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster4-300x225.jpg 300w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster4-150x113.jpg 150w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster4.jpg 614w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>As I suspected, the warp was unweaveable at that dentage, Brianna had to pull some of the densest parts of the warp, but after much bitching and kvetching, she managed to get the sample she needed, but that’s not why I did it…</p>
<p><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster5.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster5-300x225.jpg" alt="" width="300" height="225" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster5-300x225.jpg 300w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster5-150x113.jpg 150w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster5.jpg 614w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>For all of you out there who have ever had to deal with the warp from hell, remember that there is something healing in finally controlling that which would not be controlled, something triumphant about making something from total chaos.&nbsp; And that’s&nbsp; why I did it.&nbsp; It has been a long time since I’ve had to bail out a major loom screw up, and I loved every minute of it.&nbsp; It wasn’t my screw up, but I felt like a warrior on a mission and I was ultimately successful.&nbsp; Mission accomplished.&nbsp; It was sort of poignant that in the middle of the last inch and a half, that the election finals were called.&nbsp; No matter who you supported, the wait is over.&nbsp; And there is a sort of relief there, and now we as a nation can move forward to what I hope is a common goal.&nbsp; My ten hours of determination over a warp from hell was finally over.&nbsp; And I won.</p>
<p>Brianna did manage to beam and weave the new samples.&nbsp; She did as I suspected have to cull some of the warps in the densest part of the reed.&nbsp; But she learned that on her own.&nbsp; And she also learned that when tying in a new warp, you should use overhand knots.&nbsp; But kids learn by falling flat on their faces and picking themselves up and reevaluating the experience.&nbsp; I never had anyone to tell me otherwise, so I learned the hard way, by trial and error, but that weaver’s tenacity kept me moving forward.&nbsp;&nbsp;</p>

<p>To say that I’m so proud of the body of samples she …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://weaversew.com/wordblog/2020/11/07/thats-not-why-i-did-it/">https://weaversew.com/wordblog/2020/11/07/thats-not-why-i-did-it/</a></em></p>]]>
            </description>
            <link>https://weaversew.com/wordblog/2020/11/07/thats-not-why-i-did-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195659</guid>
            <pubDate>Tue, 24 Nov 2020 05:43:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Kakoune – The quest for a better code editor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195467">thread link</a>) | @imran3740
<br/>
November 23, 2020 | https://kakoune.org/why-kakoune/why-kakoune.html | <a href="https://web.archive.org/web/*/https://kakoune.org/why-kakoune/why-kakoune.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Up to now, I have used vi as an example for modal text editor, mostly because
I expect most programmers have at least heard of it. However, I don’t believe
vi and clones are the best modal text editor out there.</p>
<p>I have been working, for the last 5 years, on a new modal editor called
Kakoune. It first started as a reimplementation of Vim (the most popular vi
clone) whose source code is quite dated. But, I soon realized that we could
improve a lot on vi editing model.</p>
<div>
<h3 id="_improving_on_the_editing_model">Improving on the editing model</h3>
<p>vi basic grammar is <strong>verb</strong> followed by <strong>object</strong>; it’s nice because it matches
well with the order we use in English, "delete word". On the other hand,
it does not match well with the nature of what we express: There is only
a handful of <strong>verbs</strong> in text editing (<strong>d</strong>elete, <strong>y</strong>ank, <strong>p</strong>aste,
<strong>i</strong>nsert…​), and they don’t compose, contrarily to <strong>objects</strong> which can be
arbitrarily complex, and difficult to express. That means that errors are
not handled well. If you express your object wrongly with a delete verb,
the wrong text will get deleted, you will need to undo, and try again.</p>
<p>Kakoune’s grammar is <strong>object</strong> followed by <strong>verb</strong>, combined with instantaneous
feedback, that means you always see the current object (In Kakoune we call
that the selection) before you apply your change, which allows you to correct
errors on the go.</p>
<p>Kakoune tries hard to fix one of the big problems with the vi model: its
lack of interactivity. Because of the <strong>verb</strong> followed by <strong>object</strong> grammar,
vi changes are made in the dark, we don’t see their effect until the whole
editing <strong>sentence</strong> is finished. <code>5dw</code> will delete to next five words, if
you then realize that was one word too many, you need to undo, go back to
your initial position, and try again with <code>4dw</code>. In Kakoune, you would do
<code>5W</code>, see immediately that one more word than expected was selected, type
<code>BH</code> to remove that word from the selection, then <code>d</code> to delete.  At each
step you get visual feedback, and have the opportunity to correct it.</p>
<p>At the lower level, the problem is that vi treats moving around and selecting
an object as two different things. Kakoune unifies that, moving <strong>is</strong> selecting.
<code>w</code> does not just go to the next word, it selects from current position to
the next word. By convention, capital commands tend to expand the selection,
so <code>W</code> would expand the current selection to the next word.</p>
</div>
<div>
<h3 id="_multiple_selections">Multiple selections</h3>
<p>Another particular feature of Kakoune is its support for, and emphasis
towards the use of multiple selections. Multiple selections in Kakoune
are not just one additional feature, it is the central way of interacting
with your text. For example there is no such thing as a "global replace" in
Kakoune. What you would do is select the whole buffer with the <code>%</code> command,
then select all matches for a regex in the current selections (that is the
whole buffer here) with the <code>s</code> command, which prompts for a regex. You would
end up with one selection for each match of your regex and use the insert
mode to do your change. Globally replacing foo with bar would be done with
<code>%sfoo&lt;ret&gt;cbar&lt;esc&gt;</code> which is just the combination of basic building blocks.</p>
<div>
<p>Global replace</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/global-replace.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Multiple selections provides us with a very powerful to express structural
selection: we can subselect matches inside the current selections, keep
selections containing/not containing a match, split selections on a regex,
swap selections contents…​</p>
<p>For example, convert from <code>snake_case_style</code> to <code>camelCaseStyle</code> can be done
by selecting the word (with <code>w</code> for example) then subselecting underscores
in the word with <code>s_&lt;ret&gt;</code>, deleting these with <code>d</code>, then upper casing the
selected characters with <code>~</code>. The inverse operation could be done by selecting
the word, then subselecting the upper case characters with <code>s[A-Z]&lt;ret&gt;</code>
lower casing them with ` and then inserting an underscore before them with
<code>i_&lt;esc&gt;</code> This operation could be put in a macro, and would be reusable
easily to convert any identifier.</p>
<div>
<p>Camel case to snake case</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/camel.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Another example would be parameter swapping, if you had <code>func(arg2, arg1);</code>
you could select the contents of the parenthesis with <code>&lt;a-i&gt;(</code>, split the
selection on comma with <code>S, &lt;ret&gt;</code>, and swap selection contents with <code>&lt;a-)&gt;</code>.</p>
<div>
<p>Swapping arguments</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/args-swap.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>It is as well easy to use multiple selections for alignment, as the <code>&amp;</code>
command will align all selection cursors by inserting blanks before
selection start</p>
<div>
<p>Aligning variables</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/align.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Or to use multiple selections as a way to gather some text from different
places and regroup it in another place, thanks to a special form of pasting
<code>&lt;a-p&gt;</code> that will paste every yanked selections instead of the first one.</p>
<div>
<p>Regrouping manager objects together</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/regroup.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
</div>
<div>
<h3 id="_interactive_predictable_and_fast">Interactive, predictable and fast</h3>
<p>A design goal of Kakoune is to beat vim at its own game, while providing a
cleaner editing model. The combination of multiple selections and cleaned up
grammar shows that it’s possible to have text edition that is interactive,
predictable, and fast at the same time.</p>
<p>Interactivity comes from providing feedback on every command, made possible by
the inverted <strong>object</strong> then <strong>verb</strong> grammar. Every selection modification
has direct visual feedback; regex-based selections incrementally show what
will get selected, including when the regular expression is invalid; and even
yanking some text displays a message notifying how many selections were yanked.</p>
<p>Predictability comes from the simple effect of most commands. Each command is
conceptually simple, doing one single thing. <code>d</code> deletes whatever is selected,
nothing more. <code>%</code> selects the whole buffer. <code>s</code> prompts for a regex and
selects matches in the previous selection. It is the combination of these
building blocks that allows for complex, but predictable, actions on the text.</p>
<p>Being fast, as in requiring fewer keystrokes, is provided by carefully designing
the set of editing commands so that they interact well together, and by sometimes
sacrificing beauty for useability. For example, <code>&lt;a-s&gt;</code> is equivalent to
<code>S^&lt;ret&gt;</code>: they both split on new lines, but this is such a common use case that
it deserves to have its own key shortcut. As shown in <a href="http://github.com/mawww/golf">http://github.com/mawww/golf</a>,
Kakoune manages to beat Vim at the keystroke count game in most cases,
using much more idiomatic commands.</p>
</div>
<div>
<h3 id="_discoverability">Discoverability</h3>
<p>Keyboard oriented programs tend to be at a disadvantage compared to GUI
applications because they are less discoverable; there is no menu bar on
which to click to see the available options, no tooltip appearing when you
hover above a button explaining what it does.</p>
<p>Kakoune solves this problem through the use of two mechanisms: extensive
completion support, and auto-information display.</p>
<p>When a command is written in a prompt, Kakoune will automatically open a menu
providing you with the available completions for the current parameter. It
will know if the parameter is supposed to be a word against a fixed set
of word, the name of a buffer, a filename, etc…​ Actually, as soon as <code>:</code>
is typed, entering command prompt mode, the list of existing commands will
be displayed in the completion menu.</p>
<p>Additionally, Kakoune will display an information box, describing what the
command does, what optional switches it can take, what they do…​</p>
<div>
<p>Command discoverability</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/discoverability.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>That information box gets displayed in other cases, for example if the <code>g</code>
key is hit, which then waits for another key (<code>g</code> is the <strong>goto</strong> commands
prefix), an information box will display all the recognized keys, informing
the user that Kakoune is waiting on a keystroke, and listing the available
options.</p>
<p>To go even further in discoverability, the auto information system can
be set to display an information box after each normal mode keystroke,
explaining what the key pressed just did.</p>
</div>
<div>
<h3 id="_extensive_completion_support">Extensive completion support</h3>
<p>Keyboard oriented programs are much easier to work with when they provide
extensive completion support. For a long time, completion has been prefix
based, and that has been working very well.</p>
<p>More recently, we started to see more and more programs using the so called
fuzzy completion. Fuzzy completion tends to be subsequence based, instead
of prefix based, which means the typed query needs to be a subsequence of
a candidate to be considered matching, instead of a prefix. That will generate
more candidates (all prefix matches are also subsequence matches), so it
needs a good ranking algorithm to sort the matches and put the best ones first.</p>
<p>Kakoune embraces fuzzy matching for its completion support, which kicks in both
during insert mode, and prompt mode.</p>
<div>
<p>Word completion support</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/completion.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Insert mode completion provides completion suggestions while inserting in the
buffer, it can complete words from the buffer, or from all buffers, lines,
filenames, or get completion candidates from an external source, making it
possible to implement intelligent code completion.</p>
<div>
<p>Language specific completion support</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/cpp-completion.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Prompt completion is displayed whenever we enter command mode, and provides
completion candidates that are adapted to the command being entered, and to
the current argument being edited.</p>
</div>
<div>
<h3 id="_a_better_unix_citizen">A better unix citizen</h3>
<p>Easily making programs cooperate with each others is one of the main strength
of the Unix environment. Kakoune is designed to integrate nicely with a POSIX
system: various text editing commands give direct access to the power of POSIX
tools, like <code>|</code>, which prompts for a shell command and pipe selections through
it, replacing their contents with the command output, or <code>$</code> that prompts for
a command, and keeps selections for which the command returned success.</p>
<div>
<p>Using external commands as filters</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/filters.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>This is only the tip of the iceberg. Kakoune is very easily controllable from</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kakoune.org/why-kakoune/why-kakoune.html">https://kakoune.org/why-kakoune/why-kakoune.html</a></em></p>]]>
            </description>
            <link>https://kakoune.org/why-kakoune/why-kakoune.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195467</guid>
            <pubDate>Tue, 24 Nov 2020 05:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Love Ed on CP/M]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25195420">thread link</a>) | @todsacerdoti
<br/>
November 23, 2020 | https://techtinkering.com/articles/i-love-ed-on-cpm/ | <a href="https://web.archive.org/web/*/https://techtinkering.com/articles/i-love-ed-on-cpm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>I love ED on CP/M.  It's often derided but I think it's just misunderstood and with a little practise its true value can shine through.  It's elegant, easy to learn and only has about 25 commands but these can be combined.  Once you get used to it most editing tasks are pretty quick.  If I'm editing text that is made up of separate lines, ideally not more than the width of the terminal, I find it excellent.  It does have a line limit of 128 characters so for continuous prose I will switch to something like Wordstar, but for editing source code and config files on CP/M, it's my first choice.</p>
<p>ED came as standard with CP/M and is only 7k for CP/M 2.2 and 10k for CP/M Plus.  One advantage of ED is that it will work both with teleprinters and video terminals without having to be configured for each device.  It is also good at manipulating large files even when the system is short of memory.</p>
<p><img src="https://techtinkering.com/img/articles/cpm_ed_copy_paste.png" title="Copying and Pasting with ED"></p><p>Like many early editors, ED is a modal editor which you start in command mode and while in this mode you can view existing text, move between lines and points in the line.  It allows you to do standard operations such as copy and paste, inserting text from other files, searching for and replacing text, etc.  When we want to enter input mode, we can use the 'I' command.  This is much like VI, except that you can only enter text in the non-command mode but not edit it.  To exit data input mode and return to command mode you use ^Z (CTRL-Z).  These commands can be combined together and one of the most powerful facilities that ED has is the 'M' Macro command to repeat sequences of commands.</p>
<p>Upon executing ED it creates a temporary output file and as you write out from ED it goes to this temporary file.  When editing a file we append text from it into the memory buffer and save to the temporary output file as we go or at the end.</p>
<p>ED keeps track of a number of values such as where it is in the source file,  the line number in the memory buffer and the character pointer (CP) on the line.  These are altered as you move around the file and memory buffer.</p>
<p>I'm not going to give a fuller explanation of how to use ED here because the CP/M 2.2 Operating Manual has a good section on the <a href="http://www.gaby.de/cpm/manuals/archive/cpm22htm/ch2.htm">CP/M Editor</a>.  I do, however, want to show it being used properly in the video below.  Further down in this article I have highlighted some useful command sequences.</p>
<h2>An Example Macro</h2>
<p>ED has a macro facility which allows you to repeat a sequence of commands as many times as you like.  This makes it a good example of the power of ED and the following is a typical macro which searches through the memory buffer and displays any occurrences of the text 'CPM', pauses in case you want to stop the macro and then replaces it with 'CP/M'.</p>
<pre><code>MFCPM^Z0TT6Z-3CSCPM^ZCP/M^Z
</code></pre>
<p>The 'M' command will run the sequences of commands that follows it until an error is raised, such as end of file.  If we wanted to we could prepend 'M' with a number to indicate the number of times we want it to run.  I'll break down each command in the sequence below:</p>
<table>
  <tbody><tr><td><code>M</code></td><td>Run the following command sequence until an error</td></tr>
  <tr><td><code>FCPM^Z</code></td><td>Find 'CPM' and leave Character Pointer (CP) after it</td></tr>
  <tr><td><code>0T</code></td><td>Display the line up to CP</td></tr>
  <tr><td><code>T</code></td><td>Display the rest of the line from CP to end </td></tr>
  <tr><td><code>6Z</code></td><td>Pause</td></tr>
  <tr><td><code>-3C</code></td><td>Move CP back 3 characters</td></tr>
  <tr><td><code>SCPM^ZCP/M^</code></td><td>Substitute 'CPM' for 'CP/M'</td></tr>
</tbody></table>
<p><code>^Z</code> in the above is CTRL-Z and indicates the end of an argument for a command.</p>
<p>The above macro could also be written:</p>
<pre><code>MFCPM^Z0TT6Z-3DICP/M^Z
</code></pre>
<p>In which case:</p>
<table>
  <tbody><tr><td><code>-3D</code></td><td>Delete the 3 previous characters</td></tr>
  <tr><td><code>ICPM^Z</code></td><td>Insert the text 'CP/M'</td></tr>
</tbody></table>
<h2>Video</h2>
<p>The video below shows ED being used properly and some of the things that make it great, including searching and replacing text, copying and pasting, macros and handling files bigger than the available memory.</p>
<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/7pqaj050X7g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h2>Common Command Sequences</h2>
<p>Below are some useful command command sequences which may be overlooked when reading the manual for ED.</p>
<div><table>
  <tbody><tr><th>Sequence</th><th>Explanation</th></tr>
  <tr><td>#A</td><td>Load whole file into buffer</td></tr>
  <tr><td>0A</td><td>Load enough of the file to fill half the buffer.  This is great for large files</td></tr>
  <tr><td>#W0A</td><td>Save entire buffer and load more of the source file, enough to fill half of the buffer.  Useful to move through large files.</td></tr>
  <tr><td>0W</td><td>Write half of the buffer to the new file.  Useful to make room of the buffer is full.</td></tr>
  <tr><td>-B</td><td>Move to end of the last line in the buffer</td></tr>
  <tr><td>0L</td><td>Move CP to beginning of line</td></tr>
  <tr><td>L-2C</td><td>Move to end of line before the &lt;cr&gt;&lt;lf&gt; sequence</td></tr>
  <tr><td>0P</td><td>Display page from CP without moving CP</td></tr>
  <tr><td>0LT</td><td>Move CP to beginning of line and display line (Should this be +/-n ??)</td></tr>
  <tr><td>0T</td><td>Type line up to but not including CP</td></tr>
  <tr><td>0TT</td><td>Type whole line without moving CP</td></tr>
  <tr><td>0T&lt;cr&gt;T</td><td>Type whole line without moving CP.  Display up to CP on first list and from CP on next line.  This is useful to see where CP is on line.</td></tr>
  <tr><td>B#T</td><td>Display the whole buffer</td></tr>
  <tr><td>KI</td><td>Replace a line</td></tr>
  <tr><td>0K</td><td>Delete up to CP on current line</td></tr>
  <tr><td>S^L^Z</td><td>Join current line with next</td></tr>
  <tr><td>I^L^Z</td><td>To split a line at CP</td></tr>
  <tr><td>0V</td><td>Print free/total memory buffer stats</td></tr>
  <tr><td>0X</td><td>Empties the temporary default exchange file: X$$$$$$$.LIB, used by the <em>X</em> command</td></tr>
</tbody></table></div>
<p>In the table above the following holds true:</p>
<dl>
  <dt>#</dt><dd>Represents the highest value for n</dd>
  <dt>^L</dt><dd>CTRL-L - Stands for carriage return sequence &lt;cr&gt;&lt;lf&gt;</dd>
  <dt>^Z</dt><dd>CTRL-Z - Indicates the end of a command's argument</dd>
  <dt>&lt;cr&gt;</dt><dd>Carriage Return - Actually pressing the <em>Return</em> key</dd>
</dl>
<br>
<h2>Do You Like ED Too?</h2>
<p>I know that I'm in the minority, but I'm sure there must be other people who also like ED.  I'd love to hear if I'm not alone in this.  You can leave comments via the links below or via the YouTube video above.</p>
      </div></div>]]>
            </description>
            <link>https://techtinkering.com/articles/i-love-ed-on-cpm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195420</guid>
            <pubDate>Tue, 24 Nov 2020 04:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Run Legacy Command Line Apps on Apple Silicon]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195321">thread link</a>) | @adib
<br/>
November 23, 2020 | http://cutecoder.org/software/run-command-line-apple-silicon/ | <a href="https://web.archive.org/web/*/http://cutecoder.org/software/run-command-line-apple-silicon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post_content">
        
        	
                
        	<div>
        		<h2>Software</h2>
        		
            	<h2 id="post-3555">How to Run Legacy Command Line Apps on Apple Silicon</h2>
            	
				            	            	

				
            	
				<div>

            		<p>The new <a href="https://en.wikipedia.org/wiki/Apple_M1">M1 “Apple Silicon”</a> Macs are indeed faster than others in their respective classes. They also <a href="https://techcrunch.com/2020/11/17/yeah-apples-m1-macbook-pro-is-powerful-but-its-the-battery-life-that-will-blow-you-away/">outperformed a number of higher-classed Mac</a> released just one year ago.</p>
<p>However if you’re depending on command-line applications, things aren’t so pretty. Notably open-source ones. <a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">Gnu’s Compiler Collection</a> is <a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=96168#c11">yet to support ARM64 on the Mac</a>. Which is impeding support for many numerical libraries based on <a href="https://en.wikipedia.org/wiki/Fortran">Fortran</a> such as <a href="https://www.scipy.org/scipylib/faq.html#what-is-scipy">SciPy</a>. Even <a href="https://en.wikipedia.org/wiki/Homebrew_(package_manager)">Homebrew</a> doesn’t fully support the new instruction set:</p>
<blockquote><p>
Warning: You are running macOS on a arm64 CPU architecture.<br>
We do not provide support for this (yet).<br>
Reinstall Homebrew under Rosetta 2 until we support it.<br>
You will encounter build failures with some formulae.<br>
Please create pull requests instead of asking for help on Homebrew’s GitHub,<br>
Twitter or any other official channels. You are responsible for resolving<br>
any issues you experience while you are running this<br>
unsupported configuration.
</p></blockquote>
<p>Wouldn’t it be great if you can continue using open-source command-line application on your shiny new Apple Silicon Mac? Notably since the first-generation processor is already <a href="https://www.macrumors.com/2020/11/15/m1-chip-emulating-x86-benchmark/">running Intel-based applications faster</a> than most Mac that came before it?</p>
<p>Yes you can, thanks to Rosetta 2. This is the compatibility layer that allows running <a href="https://en.wikipedia.org/wiki/Mac_transition_to_Apple_Silicon">Intel-based Mac applications on Apple Silicon</a>. The system is also available for command-line applications, although turning it on would take some work.</p>
<h2>The Rosetta Shell</h2>
<p>When your command-line application or system hasn’t support the <a href="https://en.wikipedia.org/wiki/ARM_architecture">ARM64</a> instruction set, you’ll need to run it from <a href="https://en.wikipedia.org/wiki/Terminal_(macOS)">Terminal</a> sessions in Intel mode. That way, all subsequent command line applications started from the shell would be run under Rosetta 2 – including <em>universal binaries</em>. In other words, when an application has <em>both</em> <a href="https://en.wikipedia.org/wiki/Intel">Intel</a> and <a href="https://en.wikipedia.org/wiki/Arm_Ltd.">Arm</a> variations, the Intel one would be chosen as well as any other child processes of the application.</p>
<p>Here is how you can force the shell to run in Intel mode so that you can continue working in this little command-line <a href="https://en.wikipedia.org/wiki/Rosetta_(software)#Rosetta_2">Rosetta</a> Island while waiting for native ARM64 support.</p>
<ol>
<li>
Open the <a href="https://en.wikipedia.org/wiki/Terminal_(macOS)">Terminal</a> app.
</li>
<li>
Open the Terminal app’s Preferences.
</li>
<li>
Click on the <em>Profiles</em> tab.
</li>
<li>
Select a profile, click on the ellipsis at the bottom of the profile list and then select <em>Duplicate Profile</em>.
</li>
<li>
Click on the new profile and give it a good name. I named mine as “Rosetta Shell”.
</li>
<li>
Also in the new profile, click on the <em>Window</em> tab. In the <em>Title</em>, put a name to indicate that this is for running Intel-based apps. I put “Terminal (Intel)” on mine.
</li>
<li>
Click on the <em>Shell</em> tab and use the following as its <em>Run Command</em> to force the shell run under Rosetta:
<pre>env /usr/bin/arch -x86_64 /bin/zsh --login
</pre>
</li>
<li>
Untick the <em>Run inside shell</em> checkbox. Clearing the checkbox would prevent running the shell twice, which could bloat your environment variables since <code>~/.zshrc</code> gets run twice.
</li>
<li>
Optionally set this profile as the <em>Default</em>.
</li>
</ol>
<p>That’s it. The next Terminal window would open the new profile and run command-line applications as Intel binaries.</p>
<p><img loading="lazy" title="run-terminal-rosetta@2x.png" src="https://cutecoder.org/wp-content/uploads/2020/11/run-terminal-rosetta@2x.png" alt="Run shell under Rosetta 2" width="744" height="390" data-lazy-src="https://cutecoder.org/wp-content/uploads/2020/11/run-terminal-rosetta@2x.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<h2>Installing Homebrew</h2>
<p>As of this writing, Homebrew recommends <a href="https://docs.brew.sh/Installation">two separate installations</a> for ARM64 systems:</p>
<ul>
<li><code>/usr/local/homebrew</code> – For Intel-only packages, which coincidentally the traditional install location.</li>
<li><code>/opt/homebrew</code> – To install/run packages that already has Apple Silicon support.</li>
</ul>
<p>Here is how you can install Homebrew manually on Apple Silicon systems</p>
<ol>
<li>
Open the Rosetta Shell.
</li>
<li>
Run the following commands:
<pre>cd /usr/local
sudo mkdir homebrew
sudo chgrp admin homebrew
sudo chmod g+rwx homebrew
curl -L https://github.com/Homebrew/brew/tarball/master | tar xz --strip 1 -C homebrew
</pre>
</li>
<li>
Add the following snippet to your <code>~/.zshrc</code> to automatically choose which Homebrew installation to use depending whether it is running on Rosetta:
<pre>if [ "$(sysctl -n sysctl.proc_translated)" = "1" ]; then
    local brew_path="/usr/local/homebrew/bin"
else
    local brew_path="/opt/homebrew/bin"
fi
export PATH="${brew_path}:${PATH}"
</pre>
</li>
</ol>
<h2>Next Steps</h2>
<p>Try this out and see how it goes. Install your favorite Intel-based command-line applications (suggestion: <code>gcc</code>) and see how it performs. Then have a look at <a href="https://github.com/Homebrew/brew/issues/7857">Homebrew’s ARM64 compatibility tracking</a> to see how support for the new processor is going.</p>
<br>
<hr>

<!-- Begin MailChimp Signup Form -->




<!--End mc_embed_signup-->

											

				</div>
				
    

<!-- You can start editing here. -->


		

		
		</div>
            
            
             
        
        </div></div>]]>
            </description>
            <link>http://cutecoder.org/software/run-command-line-apple-silicon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195321</guid>
            <pubDate>Tue, 24 Nov 2020 04:38:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding the Raspberry Pi HQ Raw format]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195317">thread link</a>) | @Greg_hamel
<br/>
November 23, 2020 | https://www.strollswithmydog.com/open-raspberry-pi-high-quality-camera-raw/ | <a href="https://web.archive.org/web/*/https://www.strollswithmydog.com/open-raspberry-pi-high-quality-camera-raw/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>The Raspberry Pi Foundation recently released an interchangeable lens camera module based on the Sony&nbsp; IMX477, a 1/2.3″ back side illuminated sensor with 3040×4056 pixels of 1.55um pitch.&nbsp; In this somewhat technical article we will unpack the 12-bit raw still data that it produces and render it in a convenient color space.</p>
<figure id="attachment_4271" aria-describedby="caption-attachment-4271"><a href="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/StillLife-f8-g1-ARGB.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/StillLife-f8-g1-ARGB.jpg?resize=474%2C313&amp;ssl=1" alt="still life raw capture data file raspberry pi high quality hq cam f/8 1/2s base analog gain iso adobe rgb" width="474" height="313" srcset="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/StillLife-f8-g1-ARGB.jpg?w=1662&amp;ssl=1 1662w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/StillLife-f8-g1-ARGB.jpg?resize=300%2C198&amp;ssl=1 300w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/StillLife-f8-g1-ARGB.jpg?resize=768%2C507&amp;ssl=1 768w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/StillLife-f8-g1-ARGB.jpg?resize=1536%2C1014&amp;ssl=1 1536w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/StillLife-f8-g1-ARGB.jpg?w=948&amp;ssl=1 948w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/StillLife-f8-g1-ARGB.jpg?w=1422&amp;ssl=1 1422w" sizes="(max-width: 474px) 100vw, 474px" data-recalc-dims="1"></a><figcaption id="caption-attachment-4271">Figure 1. 12-bit raw capture by Raspberry Pi High Quality Camera with 16 mm kit lens at f/8, 1/2 s, base ISO. The image was loaded into Matlab and rendered Half Height Nearest Neighbor in the Adobe RGB color space with a touch of local contrast and sharpening.&nbsp; Click on it to see it in its own tab and view it at 100% magnification. If your browser is not color managed you may not see colors properly.</figcaption></figure>

<h4>My First Open Source ILC</h4>
<p>When the HQ module was announced a couple of weeks ago I was excited to discover that it came with a CS standard mount, opening the possibility of using any lens ever made with it – as long as it respected back flange limits and an adapter were available.&nbsp; Finally an inexpensive open source ‘camera’ with a decent sensor and interchangeable lenses of potentially photographic quality.</p>
<p>Mine arrived a few days ago.&nbsp; The CS mount affixed to the board has V1.0 2018 markings and it came with a CS-C adapter, which was promptly used to attach the 16mm f/1.4-16 C ‘kit’ lens.&nbsp; The lens is from CGL Electronic Co. LTD, a Chinese company specialized “in the R&amp;D, production and sale of accessories for smartphones, as well as Bluetooth products”.&nbsp; One of their lines is Megapixel CCTV lenses, and this one is spec’d at 10 MP, as printed on the box.&nbsp; What size P that refers to, we are not told.&nbsp; Its field of view is about 27.6 degrees on the diagonal, equivalent to roughly 88mm on Full Frame.</p>
<h4>The Sensor</h4>
<p>The IMX477 was released in December 2016 by Sony.&nbsp; It is a 1/2.3″ 4:3 Back Side Illuminated, Stacked Exmor CMOS sensor designed for “consumer use camcorder” applications, though in this article I will evaluate its ability to capture still images, thus&nbsp; ignoring Sony’s stated use case.&nbsp; Given its tinkering potential, I am sure I will not be the first or last to do so.</p>
<p>There are 3040×4056 pixels usable for imaging, with a 1.55um pitch.&nbsp; This portends a sensor active area of 4.712 x&nbsp; 6.287 mm with a 7.857mm diagonal, implying a 5.51x multiplier compared to, say, a Full Frame Nikon Z7 with 5520×8288 4.35um pixels.</p>
<p>It sports a Bayer Color Filter Array in the BGGR configuration.&nbsp; If the figure reported in the MakerNote is to be trusted, its fully electronic shutter has a minimum speed of&nbsp; 1/8771.9 of a second and it has been clocked at a maximum of 239 s.&nbsp; &nbsp;It is capable of producing 12-bit raw data when in still mode.&nbsp; You can read more about its specs and performance in the <a href="https://www.strollswithmydog.com/pi-hq-cam-sensor-performance/" target="_blank" rel="noopener noreferrer">next article</a>.</p>
<h4>Unpacking the 12-bit Raw Data</h4>
<p>When the -r or –raw switch is used with the Pi’s still image command <strong>raspistill</strong> (see the post scriptum at bottom for raspiraw), 12-bit raw CFA data is appended to the resulting 8 bit jpg file, in a block starting with the characters ‘BRCM’.&nbsp; &nbsp;The first part of the block is a 2^15 byte header, which I ignore, followed by the (3040+16)x(4056+28B) sensor array data written row-wise.&nbsp; The key is realizing that there are 3056 total rows and formatting the data accordingly.</p>
<p>Each row consists of 4056 12-bit elements (4056*12/8 bytes), followed by 12 bytes of zeros and 16 bytes of&nbsp; non-imaging data.&nbsp; The 12 bytes of zeros mark the end of the active area all the way down to the 3040th row.&nbsp; After that there are 16 additional rows of full length system data.&nbsp; In the past this non-imaging system data included optical black pixels that helped determine BlackLevels dynamically, but recent sensors tend not to have clearly demarcated such patches and I was not able to identify them.&nbsp; Should you know more about these service rows and columns I would be interested in the details.</p>
<p>From the start of every row to the twelve zeros, pixel raw values are packed in triplets: three 8-bit bytes are written for every two&nbsp; 12-bit pixels in the following format</p>
<p>AAAAAAAA BBBBBBBB BBBBAAAA</p>
<p>The first two bytes represent the 8 individual&nbsp; high bits while the third one contains the 4×2 respective low bits as shown.&nbsp; Unpacking them is easily accomplished in Matlab (and with a bit of adaptation Octave or your interpreter of choice)<sup><a title="The Matlab/Octave function used in this page to open, unpack and render full resolution Raspberry Pi HQ Camera 12-bit raw stills created by raspistill -r&nbsp; and raspiraw can be downloaded from here." href="#footnote">[1]</a></sup> as follows, vector ‘bin’ holds pixel data row-wise:</p>
<figure id="attachment_4276" aria-describedby="caption-attachment-4276"><a href="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Unpack12bitRaw.png?ssl=1"><img loading="lazy" src="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Unpack12bitRaw.png?resize=474%2C59&amp;ssl=1" alt="matlab octave code unpack raspberry pi hq high quality camera raw file jpg jpeg 12 bit " width="474" height="59" srcset="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Unpack12bitRaw.png?w=559&amp;ssl=1 559w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Unpack12bitRaw.png?resize=300%2C37&amp;ssl=1 300w" sizes="(max-width: 474px) 100vw, 474px" data-recalc-dims="1"></a><figcaption id="caption-attachment-4276">Figure 2. Unpacking 12 bit raw data loaded from Raspberry Pi High Quality Camera jpeg generated by raspistill -r.&nbsp; Full Matlab code available at the bottom of the article.</figcaption></figure>
<p>The full function used in this page can be downloaded from the link at the end of the article.&nbsp; So now we have the Pi HQ Camera’s 12-bit raw CFA data in 16-bit integer format.</p>
<h4>Exif and MakerNotes</h4>
<p>There is very little information in the jpeg Exif tags and some of it is incorrect unless explicitly set by the user.&nbsp; For instance any information related to the lens, like focal length or f-number, because the module and the lens don’t speak to each other.&nbsp; The goodies are instead in the<strong> MakerNotes</strong>, where we can find white balance multipliers, a compromise color matrix and more.&nbsp; The field is made up of a few hundred characters, here is the one from the capture in Figure 3 below:</p>
<p>ev=-1 mlux=-1<br>
exp=900 ag=256 focus=255<br>
gain_r=3.238 gain_b=1.515 greenness=0 ccm=8466,-3816,-550,-476,6390,-1816,302,-1790,5588,0,0,0 md=0 tg=247 247 oth=247 216 b=0 f=247 247 fi=0<br>
ISP Build Date: Feb 12 2020, 12:39:13 VC_BUILD_ID_VERSION: 53a54c770c493957d99bf49762dfabc4eee00e45 (clean) VC_BUILD_ID_USER: dom VC_BUILD_ID_BRANCH: master</p>
<p>Ignore ev (EC) and mlux, which appear fixed.&nbsp; Then:</p>
<ul>
<li><strong>exp</strong> is Exposure Time in microseconds</li>
<li><strong>ag</strong> divided by 256 is Analog Gain, related to ISO, so in this case it had a value of 1 (the range is 1 to 16)</li>
<li><strong>gain_r</strong> and <strong>gain_b</strong> are the white balance multipliers; greenness has so far always been zero in my experience</li>
<li><strong>ccm</strong> is the Compromise Color Matrix, divide by 4096 and drop the last row of offsets that in my tests has always been zero.</li>
</ul>
<p>I don’t know what the rest of the entries are but I suspect they are related to automatic exposure because they all turn to zero when that mode is turned off (-ex off, undocumented but all I use).</p>
<h4>Decoding the Matrix</h4>
<p>The matrix in the MakerNote looks like this:</p>
<p><a href="https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/sRGB-Matrix.png?ssl=1"><img loading="lazy" src="https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/sRGB-Matrix.png?resize=284%2C53&amp;ssl=1" alt="" width="284" height="53" data-recalc-dims="1"></a></p>
<p>It changes with the lighting, so I would guess that the module interpolates it based on the estimated illuminant.&nbsp; Where does this matrix take us?&nbsp; It looks very much like a demosaiced, white-balanced data to sRGB matrix.</p>
<p>To find out I took my setup to the balcony in a veiled, sunny, city afternoon to capture a purposely slightly defocused ColorChecker 24 target.&nbsp; Here is the image produced by the Pi’s GPU-accelerated on-board engine, straight Out Of Camera:</p>
<figure id="attachment_4281" aria-describedby="caption-attachment-4281"><a href="https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?ssl=1"><img loading="lazy" src="https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?resize=474%2C355&amp;ssl=1" alt="out of camera ooc raw capture cc24 colorchecker whibal base analgo gain iso slightly out of focus oof raspberry pi hq cam high quality" width="474" height="355" srcset="https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?resize=1601%2C1200&amp;ssl=1 1601w, https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?resize=300%2C225&amp;ssl=1 300w, https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?resize=768%2C576&amp;ssl=1 768w, https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?resize=1536%2C1151&amp;ssl=1 1536w, https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?w=1900&amp;ssl=1 1900w, https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?w=948&amp;ssl=1 948w, https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/piHQ-CC24-a.jpg?w=1422&amp;ssl=1 1422w" sizes="(max-width: 474px) 100vw, 474px" data-recalc-dims="1"></a><figcaption id="caption-attachment-4281">Figure 3. Out of Camera sRGB jpeg image produced by raspistill -r with a Raspberry Pi High Quality Camera and 16mm CS lens at f/5.6. It is purposedly defocused to smooth out the impact of irregularities in the patches.</figcaption></figure>
<p>It looks a bit desaturated.&nbsp; Extracting the raw values of the 24 CC patches as described in the article on <a href="https://www.strollswithmydog.com/determining-forward-color-matrix/" target="_blank" rel="noopener noreferrer">determining the Forward Matrix</a> we obtain the following fit against BabelColor’s 30 database, assuming about a 5800K D illuminant, as suggested by the color meter:</p>
<p><a href="https://i1.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Full-Matrix.png?ssl=1"><img loading="lazy" src="https://i1.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Full-Matrix.png?resize=474%2C502&amp;ssl=1" alt="" width="474" height="502" srcset="https://i1.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Full-Matrix.png?w=510&amp;ssl=1 510w, https://i1.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Full-Matrix.png?resize=283%2C300&amp;ssl=1 283w" sizes="(max-width: 474px) 100vw, 474px" data-recalc-dims="1"></a></p>
<p>The white-balanced data to sRGB matrix looks fairly similar to the one in the HQ Camera’s MakerNotes, suggesting that its purpose is indeed the same, something I have since confirmed with subsequent captures.&nbsp; A Sensitivity Metamerism Index (SMI) of 88 indicates a pretty good fit – thus colorimetrically friendly CFA dies, well done!&nbsp; &nbsp;These are the dE2000 errors for the target under the current D5800 illuminant and the white balanced ‘raw’ to XYZ Forward Matrix above:</p>
<figure id="attachment_4289" aria-describedby="caption-attachment-4289"><a href="https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/dE2000.png?ssl=1"><img loading="lazy" src="https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/dE2000.png?resize=461%2C288&amp;ssl=1" alt="raspberry pi high quality hq cam base analog gain iso deltaE 2000 raw capture CC24 colorchecker CFA SSF spectral sensitivity functions" width="461" height="288" srcset="https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/dE2000.png?w=461&amp;ssl=1 461w, https://i2.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/dE2000.png?resize=300%2C187&amp;ssl=1 300w" sizes="(max-width: 461px) 100vw, 461px" data-recalc-dims="1"></a><figcaption id="caption-attachment-4289">Figure 4. CIEDE2000 difference from BabelColor30 ColorChecker database reference data when the derived matrix was applied to the relative raw capture. It indicates a very good fit, suggesting colorimetrically friendly CFA spectral sensitivity functions in the HQ camera.</figcaption></figure>
<p>Very good results.&nbsp; Using the D5800 Forward Matrix so discovered we can easily calculate matrices for any of the standard color spaces around this color temperature, as described in the linked article.</p>
<h4>Rendering 12-bit Raw Data to sRGB</h4>
<p>We now have the raw data, white balance multipliers and matrix necessary to render the captured raw image to a final color space.&nbsp; I used simplified demosaicing that results in a half height image with every final pixel corresponding to a BGGR quartet in the CFA, similar to dcraw -h.&nbsp; Each color channel within a pixel maintains the relative BlackLevel subtracted ‘raw’ R and B values while the two G values are averaged, as described in the <a href="https://www.strollswithmydog.com/raw-file-conversion-steps/" target="_blank" rel="noopener noreferrer">article on rendering</a>:</p>
<figure id="attachment_4400" aria-describedby="caption-attachment-4400"><a href="https://i1.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Half-Demosaic-HQ.png?ssl=1"><img loading="lazy" src="https://i1.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Half-Demosaic-HQ.png?resize=474%2C99&amp;ssl=1" alt="" width="474" height="99" srcset="https://i1.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Half-Demosaic-HQ.png?w=670&amp;ssl=1 670w, https://i1.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/Half-Demosaic-HQ.png?resize=300%2C63&amp;ssl=1 300w" sizes="(max-width: 474px) 100vw, 474px" data-recalc-dims="1"></a><figcaption id="caption-attachment-4400">Figure 5. Standard Matlab/Octave code[1] to convert raw CFA data to 16-bit standard color spaces. It produces a half-height image without interpolation.&nbsp; See the linked article for details.</figcaption></figure><p>The Black Level is about 256.3 at base gain/ISO in my unit at room temperature, as we will see in the next article.&nbsp; Applying that script to the captured raw CFA data results in the following ‘final’ sRGB image:</p>
<figure id="attachment_4283" aria-describedby="caption-attachment-4283"><a href="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?resize=474%2C355&amp;ssl=1" alt="raspberry pi high quality hq cam color checker passport cc24 5800k base analog gain iso slightly out of focus raw conversion" width="474" height="355" srcset="https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?resize=1601%2C1200&amp;ssl=1 1601w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?resize=1536%2C1151&amp;ssl=1 1536w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?w=1800&amp;ssl=1 1800w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?w=948&amp;ssl=1 948w, https://i0.wp.com/www.strollswithmydog.com/wordpress/wp-content/uploads/CC24-PiHQ-5800K.jpg?w=1422&amp;ssl=1 1422w" sizes="(max-width: 474px) 100vw, 474px" data-recalc-dims="1"></a><figcaption id="caption-attachment-4283">Figure 6. Raspberry Pi HQ Camera with 16mm kit lens at f/5.6 sRGB image.&nbsp; It was converted from raw after loading the raspistill -r jpeg, unpacking the raw data, subtracting black level, applying white balance multipliers and the matrix.</figcaption></figure>
<p>Much better, though we know from previous posts that this linear rendition probably still needs to be mapped into the smaller Contrast Ratio of typical display devices with the help of a Tone Mapping Operator or, at the very least, a bit of contrast.</p>
<h4>And Full-Rez to Adobe RGB</h4>
<p>Of course after doing all that it becomes apparent that the small size of the HQ’s pixels bump against their physical limitations.&nbsp; &nbsp;Images from this sensor are bound to look a bit fuzzy and noisy compared to those produced by larger cousins of similar resolution when demosaiced to full size and shown at 100%:&nbsp; there are only so many photoelectrons to be captured and diffraction to be oversampled when you are 1.55 …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.strollswithmydog.com/open-raspberry-pi-high-quality-camera-raw/">https://www.strollswithmydog.com/open-raspberry-pi-high-quality-camera-raw/</a></em></p>]]>
            </description>
            <link>https://www.strollswithmydog.com/open-raspberry-pi-high-quality-camera-raw/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195317</guid>
            <pubDate>Tue, 24 Nov 2020 04:38:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spacewar]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195214">thread link</a>) | @cristoperb
<br/>
November 23, 2020 | https://www.masswerk.at/spacewar/ | <a href="https://web.archive.org/web/*/https://www.masswerk.at/spacewar/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="description">
	<h2>Notes &amp; Descriptions</h2>
	<h3>Program Versions &amp; Sources</h3>
	<p>The emulation is running various versions of the original game, both from binaries copies of the original paper tapes and newly assembled from authentic code listings. The programs are loaded as virtual paper tapes (RIM-mode: Read In Memory) into the memory of the emulated DEC PDP-1.</p>
	<p><img src="https://www.masswerk.at/spacewar/images/hingham-space-warfare-2.png" alt="Spaceships (stylized) according to the Hingham Institute Study Group on Space Warfare" title="Spaceships according to the Hingham Institute Study Group on Space Warfare" width="81" height="94"></p><p><strong onclick="selectSpacewarModule('spacewar3.1');" data-title="Click to play Spacewar! 3.1"><span></span>Spacewar! 3.1</strong>, the final version of Spacewar! as left by the original programmers (Steve Russell and the other members of the <em>Hingham Institute Study Group on Space Warfare</em>), is presented here once in its original form and in a modified version showing scaled up graphics and effects for the benefit of small screen sizes. Further, there are both earlier and later versions, as <strong onclick="selectSpacewarModule('spacewar2b');" data-title="Click to play Spacewar! 2B"><span></span>Spacewar! 2B</strong> (the program described in <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html" target="SpacewarOrigin">"The Origin of Spacewar"</a> by J. M. Graetz) and some examples of <strong onclick="selectSpacewarModule('spacewar4.1f');" data-title="Click to play Spacewar! 4.1f"><span></span>version 4</strong> (adding minor features and compatibility to an upgraded hardware). Finally, there is a special version of Spacewar 3.1, demonstrating the "Winds of Space" effect.</p>
	<p><em>(Please mind that the title screens are generated by the emulator and are not part of the original games.)</em></p>
	<p>There are two display resolutions to select from:</p>
	<ul>
		<li><strong>Low resolution</strong>, plotting at 512 x 512 px, 50% of the original display.<br>Special subpixel rendering is employed in order to boost the visible resolution beyond the physical resolution provided by the display element in the browser.<br>The result corresponds closely (if not being even a bit better) to the visual resolution of the original display: While the display featured a resolution of 1024 x 1024 plotting locations, only approximately 512 points on each axis were "resolvable to the unaided eye" <cite>(DP-35-2 / PDP-1 Instruction Manual / Part 3; DEC 1971; p. 5)</cite>.<br>Compare these contemporary photos: <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html#figure-1" target="SpacewarOrigin" title="Illustrative image in &quot;The Origin of Spacewar&quot; by J. M. Graetz" onclick="if (window.showEmbeddedImage) {return showEmbeddedImage('spacewar_origins/spacewar-fig1.jpeg', 421, 418);} else {return true;}">[1]</a> <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html#figure-a3-7" target="SpacewarOrigin" title="A black and white screenshot of Spacewar!, 1963 ca." onclick="if (window.showEmbeddedImage) {return showEmbeddedImage('spacewar_origins/chm-spacewar_screenshot.jpg', 500, 391);} else {return true;}">[2]</a> <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html#figure-a3-6" target="SpacewarOrigin" title="Dan Edwards and Peter Samson playing Spacewar! (DEC material)" onclick="if (window.showEmbeddedImage) {return showEmbeddedImage('spacewar_origins/playing-spacewar-1962.jpg', 500, 340);} else {return true;}">[3]</a>.</li>
		<li><strong>High resolution</strong>, plotting at the <a href="https://www.masswerk.at/spacewar/fullscreen.html" data-title="Compare the full-scale version…"><span></span>original 1024 x 1024 px</a>, with the display element scaled to 50%.</li>
	</ul>
	<p>Versions available (by the <i>"versions menu"</i> at the top left of the emulated display):</p>
	<ul>

		<li id="spacewar3.1"><strong onclick="selectSpacewarModule('spacewar3.1');" data-title="Click to select this program."><span></span>Spacewar! 3.1</strong> <span>(24 Sep 1962)</span><br>This could be regarded as the "standard version" of Spacewar!. The program is dated <em>"24 sep 62"</em> and is loaded from an authentic binary paper-tape image (<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/SteveRussell_box1/" target="_blank" title="Archive of Steve Russell's box #1 at textfiles.com">spacewar3.1_24-sep-62.bin</a>) provided by Steve Russell via <a href="http://bitsavers.org/" target="_blank">bitsavers.org</a>.</li>

		<li><strong onclick="selectSpacewarModule('spacewar3.1bigships');" data-title="Click to select this program."><span></span>Spacewar! 3.1, scaled ships</strong> <span>(low resolution only)</span><br>Scaled up graphics and effects to show the game in greater detail on a small display. (Colission radii and turning pivots of the ships have been adjusted accordingly.) This is quite similar to the presentation seen in other emulations. Please mind that the changes have minor effects on the gameplay.<br>
		The code is based on the original PDP-1 <a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/SteveRussell_box1/_text/" target="_blank" title="Text-files in the archive of Steve Russell's box #1 at textfiles.com">assembler sources</a> by Steve Russell as available at <a href="http://bitsavers.org/" target="_blank">bitsavers.org</a> and was modified and newly assembled in 2014. (N. Landsteiner, 2014; this is not an authentic version!)</li>

		<li id="spacewar2b"><strong onclick="selectSpacewarModule('spacewar2b');" data-title="Click to select this program."><span></span>Spacewar! 2B</strong> <span>(2 Apr 1962)</span><br>This is the first complete version version of the game as presented at MIT's annual <em>Science Open House</em> in May 1962. Notably this is also the very version the background starfield (Peter Samson's <em>Expensive Planetarium</em>) was designed for, as this is annotated in the source code by <em>"stars by prs for s/w 2b"</em> and dated <em>"3/13/62, prs".</em> The program features the pre-particle-system "Crock Explosion" <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html#figure-5" target="SpacewarOrigin" title="Illustrative image in &quot;The Origin of Spacewar&quot; by J. M. Graetz" onclick="if (window.showEmbeddedImage) {return showEmbeddedImage('spacewar_origins/spacewar-fig5.jpeg', 417, 422);} else { return true;}">[4]</a> and optionally a faster movement of the starfield (sense switch 4), torpedoes are single shot only (no salvoes). Some of the differences are more cosmetical: The ships' exhaust flames are half the size of later versions, also the display of the starfield hasn't found its final form yet (starting at an other position as compared to later versions). Moreover, the original starfield routine, found here, is modulating the varying brightnesses of the stars by how often the individual stars are drawn, whereas later versions are using the built-in intensity levels of the <em>Type 30 CRT</em> display instead.<br>For more on the making-of of Spacewar! see <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html" target="SpacewarOrigin">"The Origin of Spacewar" by J. M. Graetz</a>.<br>
		<span></span>The code is run from a binary paper tape image (RIM) labeled "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/InsidePDP1_80s_box3/" target="_blank" title="&quot;spaceWar_SA-5.bin&quot; in &quot;InsidePDP1_80s_box3&quot; at textfiles.com">spaceWar_SA-5.bin</a>". This has been proven to be identical to loading the two paper tapes "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20050823/" target="_blank" title="'spacewar2B_2apr62.bin' at textfiles.com">spacewar2B_2apr62.bin</a>" and "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/SteveRussell_box1/" target="_blank" title="'stars.bin' at textfiles.com">stars.bin</a>", both to be found at bitsavers.org.<br>
		(<em>"SA-5"</em> is not a version string, but indicates the program's start address being 5, which would start the program in a setup for reading the input from the console test switches rather than from MIT's special control boxes, as would be the case with the default start address. The label suggests that this was a tape sent from MIT to an other facility.)<br>
		Spacewar! 2B is known with a date as early as 25 March 1962. This earlier version shows minor differences regarding the polarity of the sense switch settings.<br>
		<img src="https://www.masswerk.at/spacewar/images/spacewar-minskytron-hyperspace.png" alt="Spacewar! — The Hyperspace Minskytron signature" title="The Minskytron signature effected by &quot;warp-induced photonic stress emission&quot;" width="75" height="105">
		<span></span>The program is presented here with two patches applied, namely the hyperspace-patch to include Martin Graetz's original hyperspace routine, the "<strong><a href="https://www.masswerk.at/spacewar/inside/insidespacewar-minskytron-hyperspace.html" target="_blank">Minskytron hyperspace</a></strong>" <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html#figure-4" target="_blank" title="Illustrative image in &quot;The Origin of Spacewar&quot; by J. M. Graetz" onclick="if (window.showEmbeddedImage) {return showEmbeddedImage('spacewar_origins/spacewar-fig4.jpeg', 419, 416);} else {return true;}">[5]</a> and its <em>"warp-induced photonic stress emission",</em> and the auto-restart patch for seemless playing. (There are exactly three jumps to hyperspace per player.)<br>
		This represents the the game as described and depicted in J.M. Graetz's seminal article <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html" target="SpacewarOrigin">"The Origin of Spacewar"</a> and as presented at the <em>MIT Science Open House</em> in May 1962. (It still lacks a scorer-patch, which seems to be lost.)
		The patches are provided by the paper tape images "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/InsidePDP1_80s_box3/" target="_blank">hyperspace85.bin</a>" <em>(Hyperspace VIci, 2 May 1962)</em> and  "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20030408/" target="_blank">spaceWarRstrt.bin</a>" — an other tape provides the same patch as "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/InsidePDP1_80s_box3/" target="_blank">spacewAutoRestartPatch.bin</a>". (The auto-restart patch was to be applied to the hyperspace-patch and is by this officially a patch to a patch. Thus, loading the full program had become a fairly complex affair then, involving up to 6 tapes.)<br>
		<span></span>Listings of Spacewar! 2B and the patches may be found <a href="https://www.masswerk.at/spacewar/sources/" target="_blank">here</a>.<br>
		<span></span>Please mind that this is still the game early in development. The restart-patch is missing an edge case (pun in­tend­ed), where the ships would collide at the "antipode" in the corners of the display. The game requires a manual restart in this situation.</li>

		<li id="spacewar4.1f"><strong onclick="selectSpacewarModule('spacewar4.1f');" data-title="Click to select this program."><span></span>Spacewar! 4.1f</strong> <span>(20 Feb 1963; mod. for CHM 2005 – 2008)</span><br>This is the version apparently running at the <a href="http://www.computerhistory.org/" target="_blank">Computer History Museum</a> (CHM).<br>This is Spacewar! 4.1 modified by <strong>Peter Samson</strong> in 2005–2008 to include the <strong>scorer routine of Spacewar! 4.8</strong>. Moreover, version 4.1f features modified brightness settings for the background starfield (for use at the CHM), which are here remapped to usual values by the emulator. (Otherwise most of the stars would remain invisible.) Like other version of Spacewar! 4.x it requires the hardware multiply/divide option and features the single shot switch for torpedoes. The source code is dated <em>"spacewar 4.1  2/20/63 dfw"</em> and annotated <em>"mod for CHM, 2005-06-01 - 2005-11-28  --prs",</em> and <em>"changed delay in score display, 2008-08-22  --prs.".</em> The code is run from a binary paper tape image (<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/from_peter_samson/" target="_blank" title="Archive PDP-1 codes provided by Peter Samson at textfiles.com">sw41f.rim</a>) provided by Peter Samson via <a href="http://bitsavers.org/" target="_blank">bitsavers.org</a>.</li>

		<li id="spacewar4.2"><strong onclick="selectSpacewarModule('spacewar4.2a');" data-title="Click to select this program."><span></span>Spacewar! 4.2a (4.1/4.2 dfw)</strong> <span>(22 Feb 1963 ?)</span><br>This is an authentic representative of the 4.x-generation of Spacewar! (probably by "dfw", like version 4.1 above), requiring the hardware multiply/divide option of the PDP-1. Additionaly to some internal modifications it features, like all versions 4, a working single shot mode for torpedoes (sense switch 3). The code is run from a binary paper tape image (<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20040106/russell2/" target="_blank" title="Archive of Steve Russell's box #2 at textfiles.com">spacewar4.2a_sa4.bin</a>) provided by Steve Russell via <a href="http://bitsavers.org/" target="_blank">bitsavers.org</a>.<br>A visually distinctive detail of versions 4.x (4.1 and later) is the <em>"Sun"</em> (heavy star), now drawn by a dashed line like the rocket blasts, thus separating it visually a bit more from the starships (see the <a href="https://www.masswerk.at/spacewar/fullscreen.html#version=4.2a" title="Full-scale version of Spacewar! 4.2 emulated in HTML5/Javascript">high-res/full-scale version</a> for a close-up view.) Also, two ships colliding in free fall in the center will explode at the <em>"antipode"</em> rather than at the center as with earlier versions of the game.</li>

		<li id="spacewar4.3"><strong onclick="selectSpacewarModule('spacewar4.3');" data-title="Click to select this program."><span></span>Spacewar! 4.3</strong> <span>(17 May 1963)</span><br>This is a version by Monty Preonas (signing <em>"ddp"</em>), who also provided the adaptations for the automatic hardware multiply/divide option and the new gravity computations used by all flavors of Spacewar! 4 in his version 4.0 <em>(2 Feb 1962)</em> earlier.<br>
		Spacewar! 4.3 features, like Monty Preonas' flavor of version 4.2 and version 4.4 (also signed <em>"ddp",</em> but presumably by Joe Morris), a special <strong>on-screen score display</strong>, very much like the one of the 4.8-scorer-patch (see the note on scores below). Like all versions by Monty Preonas, it usues an implementation of the background starfield alike the one of Spacewar! 2B.<br>
		The game features a special <strong>Twin Star mode</strong> to be engaged by sense-switch 2 (accessible by the <em>options menu</em> <img src="https://www.masswerk.at/spacewar/images/menubutton_small.png" width="20" height="16" alt="options menu icon" title="options menu icon"> at the top right corner of the screen). This visually distorted mode puts the <em>Needle</em> in the center of the screen in between a doubled sun and draws any other objects relatively to this ship. Moreover, some items are drawn at a double offset and torpedoes are displaced for real, resulting in a quite vexing game play. This mode was probably initially intended as an <em>ego view</em> from the <em>Needle's</em> perspective and left <em>as-is</em> as an amazing novelty. (Compare "Spacewar! 2015" below.)<br>
		<span></span>The program, dated <em>"5/17/63",</em> was newly assembled from source code provided in the assorted listings available at <a href="http://www.computerhistory.org/collections/catalog/102664173" target="_blank" title="'Stars by prs for s/w 2b', CHM, catalog no. 102664173">CHM catalog no. 102664173</a> (which apparently came from Joe Morris, compare <cite><a href="https://groups.google.com/d/msg/alt.sys.pdp10/cNG89mmlbK0/V0JPyn3Mg7sJ" target="_blank">Joe Morris, alt.sys.pdp10, Jannuary 6, 2005</a></cite>).</li>

		<li id="spacewar4.8"><strong onclick="selectSpacewarModule('spacewar4.8');" data-title="Click to select this program."><span></span>Spacewar! 4.8</strong> <span>(24 Jul 1963)</span><br>Apparently the final version of MIT-Spacewar!, dated <em>"7/24/63"</em> and signed <em>"dfw"</em>. A patch for a special <strong>on-screen scorer</strong> is available for this version (see the note on scoring below).<br>
		The game was newly assembled including the dedicated scorer patch. Sources <em>("spacewar4.8part1_engl.txt", "spacewar4.8part2_engl.txt", and "spacewar4.8_scorer.txt")</em> are available at <a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20040817/" target="_blank" title="Spacewar 4.8! sources and sorer-patch at textfiles.com">textfiles.com</a> and <a href="http://bitsavers.org/" target="_blank">bitsavers.org</a>.</li>

		<li id="spacewar4.1hafb"><strong onclick="selectSpacewarModule('spacewar4.1hafb');" data-title="Click to select this program."><span></span>Spacewar! 4.1 Holloman Air Force Base Version</strong><br>This is a reconstruction of a version of PDP-1 Spacewar! as seen at the Holloman Air Force Base (New Mexico) and described by John W. Andrews in December 1966 for "The Gamesman" (<a href="https://archive.org/details/The_Gamesman_4-1967-12/page/n31" target="_blank" title="Archived copy of The Gamesman, issue 4, Dec. 1967 (archive.org)">The Gamesman, Issue 4, Dec 1967, pp 30-32</a>). Altered starting positions are probably the most interesting feature of this version. (Controls have been swapped accordingly to accommodate for this.)<br>
		<span></span><img src="https://www.masswerk.at/spacewar/images/holloman-afb-spacewar.png" alt="Starting positions in Holloman Air Force Base Spacewar." width="338" height="339" onclick="showEmbeddedImage('images/holloman-afb-spacewar_solid.png', 338, 339);return false;">These are the changes as applied …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.masswerk.at/spacewar/">https://www.masswerk.at/spacewar/</a></em></p>]]>
            </description>
            <link>https://www.masswerk.at/spacewar/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195214</guid>
            <pubDate>Tue, 24 Nov 2020 04:14:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can your boss know you're procrastinating?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25194970">thread link</a>) | @zoozla
<br/>
November 23, 2020 | https://blog.elifiner.com/your-boss-knows-youre-procrastinating/ | <a href="https://web.archive.org/web/*/https://blog.elifiner.com/your-boss-knows-youre-procrastinating/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-250">
	<!-- .entry-header -->

	
	
	<div>
		
<p>Hey, you. Yeah, you. With the pajamas. I know you haven’t washed them in a few weeks, I can feel the smell from all the way in Canada. And I get it. Because I’m wearing my pajamas right now and I haven’t washed them in a while either. We’re all in this together, so lets parse this out a little bit.</p>



<p>When the pandemic hit and we all got permission to work from home, you were probably extatic. “This is awesome,” you thought, “PAJAMAS!” But it’s not that simple. Without the energy of the office environment it’s kinda hard to get into the groove. And yes, the modern open floor plan isn’t ideal for focused work and we used to gripe about that, but not seeing anyone for weeks on end gets old quickly.</p>



<p>When no one is watching, it’s way to easy to check out Hacker News or Twitter or Reddit for a little while and then go down a rabbit hole of understanding how exactly how those mRNA vaccines work or what’s the latest projected layout of Starship is. Hours, days, sometimes weeks go by like that.</p>



<p>Without the discipline annoyingly imposed by the office environment, we’re left to our own devices, our own discipline and we often find it lacking. Instead of making actual progress on our work, we submit vague progress reports and list the problems we encounter all the while building up shame, guilt and fear.</p>



<p>Emotions are a funny thing though, especially negative emotions. We don’t like ’em. And we’d do anything to not feel them. So when the guilt, shame and that quiet terror of being found out come up, we want to run away. And what’s a better refuge than the conveniently endless feeds on social media (not to mention the autoplaying Youtube videos)?</p>



<p>But wait a sec, didn’t we just say that the guilt <em>started</em> with procrastination? Is it also causing it? Oh, now we’re in deep. Real deep.</p>



<p>I don’t know if your boss actually knows you’ve been <s>lying</s> massaging the truth. She’s likely in the same boat, fighting the same demons, too preoccupied with her own procrastination to notice yours. But <em>you</em> know, and so do your pajamas. This positive feedback loop between negative emotions and procrastination is only going to get worse – unless you do something.</p>



<p>The problem with emotions is that we only know two ways to deal with them – express them or supress them (by distracting ourselves). And neither gets us the result we are looking for, which is breaking out of the cycle.</p>



<p>Luckily, there’s a third option, not commonly taught and not well understood outside of postmodern new age circles. Emotions can be <em>released</em>. Releasing emotions isn’t about expressing them, talking about them or thinking about them. It’s about allowing ourselves to feel them, fully, staying with the unpleasantness for as long as neccessary. And letting them evaporate. It’s as natural as taking a shit, but unfortunately we’ve been taught to keep emotions bottled up (especially the men among us). Imagine eating without ever taking a dump. Yeah, that’s what holding on to emotions feels like.</p>



<p>The easiest way to release emotions is to ask yourself a simple question:</p>



<p><em>Could you allow yourself to feel this fear/anger/guilt?</em></p>



<p>Contemplate this question. Don’t try to derive an answer, the answer itself isn’t important. Let the question bounce around inside your head for a little while. You may feel something starting to shift.</p>



<p>For some of you, perhaps those who’ve had experience with meditation or therapy, this should be enough. Others need a lot more guidance.</p>



<p>That’s why I build <a href="https://wuju.app/">Wuju</a>, an app that can help you process and <em>release</em> emotions. My stats of around 2000 people show it can drop the intensity of any negative emotion by up to 90% within a few minutes. If you’re stuck in a procrastination loop, it might be worth a try.</p>



<p>(Wuju is subscription based, but you can try it for as long as you need to see if it works for you.)</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://blog.elifiner.com/your-boss-knows-youre-procrastinating/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194970</guid>
            <pubDate>Tue, 24 Nov 2020 03:27:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Could Your Job Become Permanently Remote?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25194924">thread link</a>) | @dearJulius
<br/>
November 23, 2020 | https://career.dearjulius.com/2020/11/could-your-job-become-permanently-remote.html | <a href="https://web.archive.org/web/*/https://career.dearjulius.com/2020/11/could-your-job-become-permanently-remote.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4023444617386077093" itemprop="articleBody">

<div>
<p>
Could your work be permanently remote? Here are some pieces of information that can help you determine this!
</p>

</div>

<div><p><img alt="Could Your Job Become Permanently Remote?" data-original-height="653" data-original-width="1024" src="https://1.bp.blogspot.com/-e-NTanoE24Y/X7xyeA0AbXI/AAAAAAAAGAo/9uJnza7BXsMfcWs_T2prm5Z0X_c8LC-5ACLcBGAsYHQ/s16000/remote-work.jpg" title="Remote Work">
</p>
<br>
<div><p>By <b>Ashley Campbell</b></p><div><p>2020 has seen many of our jobs completely change. The coronavirus and </p><u><a href="https://www.who.int/emergencies/diseases/novel-coronavirus-2019" target="_blank">Covid-19 pandemic</a></u><p> has wrought havoc with businesses operating in all sorts of industries. In order to comply with government guidelines and restrictions, many businesses have now had to switch to having their staff work on a remote basis, as they are unable to have everyone operating with a two meters distance between them at all times in office spaces and other commercial premises. In some ways, this is great. Working from home is seen as desirable and preferable by many employees. It cuts out expensive and time consuming commutes that have proven bad for employee health. It cuts out rushed lunch breaks with low quality packed lunches, as staff can prepare their lunch at home in their own kitchens. It also proves beneficial for the business in terms of profit margins, as it cuts out the costs and overheads associated with renting commercial property. But is remote work here to stay and could your job become permanently remote? Here are a few pieces of information that could help you determine this!</p></div><h3>Ask Your Employer Their Intentions</h3><div><p>The easiest and most trustworthy way to determine whether your job is going to become permanently remote is to </p><u><a href="https://www.careeraddict.com/talk-to-boss#:~:text=When%20you%20are%20talking%20to,and%20lean%20into%20the%20conversation." target="_blank">ask your employer</a></u><p> yourself. If they have a plan, they may be able to provide you with a straightforward yes or no answer to your question, which will allow you to prepare yourself for the change, or - if you are unhappy with the change - you can start seeking employment elsewhere. Nobody other than your employer will have a 100% certain answer as to whether your position will remain remote or not.</p></div><h3>Look at What Other Companies Are Doing</h3><div><p>If you notice that many competitor companies or similar companies in your field or industry are switching to operating on a permanently remote basis, chances are your company could be heading in a similar direction. Watching developments will give you a good indication of what the general trend in your field is. For example, </p><u><a href="https://precisionlabtesting.com/2020/09/25/blood-testing-for-traveling-physicians/" target="_blank">This Company</a></u><p> has developed blood tests that doctors can carry out outside of clinics, meaning that the trend towards staying home rather than venturing out seems to be continuing, even in the field of healthcare itself.</p></div><h3>Consider Whether It Is Benefiting Your Company</h3><p>If remote work is benefiting your company, chances are it’s here to stay. If the company is generating the same sales and profits, but has fewer outgoings due to remote work cutting rent and overhead costs, chances are the owners and managers will be content with things continuing this way. If the company is constantly facing security threats, data breaches and other issues, it’s likely they will be working to get back on site as soon as possible.</p><p>Remote work suits some people. It doesn’t suit others. Either way, you’re going to want to know whether you’ll be continuing to work remotely or not. Hopefully, some of the above advice will help you to get some answers!</p></div></div>



</div></div>]]>
            </description>
            <link>https://career.dearjulius.com/2020/11/could-your-job-become-permanently-remote.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194924</guid>
            <pubDate>Tue, 24 Nov 2020 03:20:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Summary of Measure What Matters (OKR Framework)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25194576">thread link</a>) | @productceo
<br/>
November 23, 2020 | https://www.product.ceo/measure-what-matters/ | <a href="https://web.archive.org/web/*/https://www.product.ceo/measure-what-matters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <h3 id="john-doerr-portfolio-penguin-">John Doerr (Portfolio Penguin)</h3><p>Objectives and Key Results (OKR) framework is widely used in the technology industry for setting objectives and tracking progress. The OKR framework earned its fame after Google in its infancy has adopted the method to brings its projects into order. In Measure What Matters, John Doerr, the man who brought the framework to Google, explains the OKR framework.</p><h2 id="history-of-okr-and-its-predecessors">History of OKR and Its Predecessors</h2><ul><li>Scientific Management (Taylor-Ford Model): Frederick Winslow Taylor and Henry Ford were the first to measure output systematically and analyze how to get more of it. They held that the most efficient and profitable organization was authoritarian.</li><li>Management by Objectives (MBO): Peter Drucker believed Taylor-Ford Model is not fit for knowledge work. Drucker wrote that a corporation should be a community built on trust and respect for the workers, not just a profit machine. He urged subordinates be consulted on company goals.</li><li>HP Way and iMBO: HP and Intel adopted Peter Drucker’s MBO and called it, respectively, HP Way and iMBO (Intel MBO). iMBO, by Andy Grove, amended MBO by tracking key performance indicators.</li><li>Objectives and Key Results (OKR): John Doerr learnt iMBO from Andy Grove, renamed it to OKR, and applied it to his portfolio companies at KPCB, including Google.</li></ul><h2 id="what-okr-is-and-what-okr-is-for">What OKR is and What OKR is for</h2><ul><li>OKR is “a management methodology that helps to ensure that the company focuses efforts on the same important issues throughout the organization”.</li><li>OKRs give visibility into an organization and a productive way to push back.</li><li>OKR is meant to be shared with all other employees in the organization. The lowest ranking contributor can see everybody else’s OKRs up to the CEO (and more importantly, horizontally in other teams).</li><li>Once set, progress in regard to OKRs should be checked at least once a quarter. Google checks once a month.</li><li>OKR is flexible. It is not meant to be a financial commitment or a weapon against an employee in their performance review. If this is not clarified, teams will resort to unambitious OKRs or waste time looking for the perfect OKRs.</li><li>At any point in cycle, for any Os or KRs, the team can perform any of four operations:</li><li>Continue: If team is on track and goal is not broken, then don’t fix it.</li><li>Update: Circumstance has changed and OKR needs to be revised consequently. This includes schedule and priorities.</li><li>Start: Launch a new OKR mid-cycle whenever the need arises.</li><li>Stop: When a goal has outlived its usefulness, drop it.</li><li>John Doerr sets OKRs quarterly, and starts brainstorming Q2 OKRs midway through Q1.</li></ul><h2 id="how-to-set-objectives-and-key-results">How to Set Objectives and Key Results </h2><ul><li>An objective is what is to be achieved. Objectives are significant, concrete, action oriented, and inspirational. They’re a vaccine against fuzzy thinking and fuzzy execution.</li><li>Key results benchmark and monitor how we get to the objective. Effective KRs are specific and time-bound, aggressive yet realistic. They are measurable and verifiable. You either meet a key result’s requirements or you don’t; there is no gray area.</li><li>Objectives are compared to principle and vision. Key results are compared to practice and execution.</li><li>Less is more. There should be only three to five objectives per cycle, and each objective should be tied to three to five key results only.</li><li>“All key results are completed” must be equivalent to “objective is achieved”.</li><li>Non-Numeric KRs are allowed: Marissa Mayer reportedly said, “It’s not a key result unless it has a number”, but John Doerr’s definition of KR, or the best practice examples from KPCB portfolio companies, Intel, and Google, have key results that are not numeric. However, John Doerr’s definition of KR and best practice examples from KPCB portfolio companies, Intel, and Google, allow KRs that are binary achievements (e.g. “Release X” or “Complete Migration”), and I believe adopting that flexible definition of KRs will make it easier for us (Bing MM) to ensure that “achieving every KR” is equivalent to “achieving the associated O”.</li></ul><h2 id="setting-ambitious-okrs">Setting Ambitious OKRs</h2><ul><li>Goals should be challenging.</li><li>Edwin Locke, a psychology professor at University of Maryland who influenced Andy Grove, published that hard goals drive performance more effectively than easy goals, and specific hard goals produce a higher level of output than vaguely worded ones.</li><li>If you are certain you are going to nail a key result, you’re not pushing yourself hard enough. “OKRs are big, not incremental. We don’t expect to hit all of them. If we do, we’re not setting them aggressively enough.” (Google OKR Playbook).</li><li>“You are not supposed to strive for greens on every OKR you write. . . It took courage to write an OKR that might fail, but there was no other way if we wanted to be great.” (Sundar Pichai).</li></ul><h2 id="setting-okrs-up-and-down-in-the-organiation">Setting OKRs Up and Down in the Organiation</h2><ul><li>Top Down and Bottom Up</li><li>Set goals from the bottom up. To promote engagement, teams and individuals should be encouraged to create at least half of their own OKRs, in consultation with managers. When all objectives are set top down, motivation is corroded.</li><li>An optimal OKR frees contributors to set some of their objectives and most or all of their key results.</li><li>Some, but not all, key results at a level become objectives at the level below. (Note that key results, not objectives, become objectives of the level below).</li><li>When all objectives are cascaded, the process can degrade into a mechanical, color-by-numbers exercise. Tightly cascading organizations tend to resist fast and frequent goal setting. Even minor updates can burden downstream. Tight cascading locks in vertical alignment, but is not effective in connecting peers horizontally.</li><li>Remind, a KPCB portfolio company, involves team members in voting on their quarter’s top objectives in order to ensure that OKRs are not just top down.</li></ul><h2 id="best-practice-examples">Best Practice Examples</h2><h3 id="example-an-okr-that-john-doerr-actually-used-when-he-was-at-intel">Example: An OKR that John Doerr actually used when he was at Intel</h3><p>Objective: Demonstrate the 8080’s superior performance as compared to the Motorola 6800.</p><p>Key Results: (as measured by)</p><ol><li>Deliver five benchmarks.</li><li>Develop a demo.</li><li>Develop sales training materials for the field force.</li><li>Call on three customers to prove the material works.</li></ol><h3 id="example-operation-crush-by-andy-grove-at-intel">Example: Operation Crush by Andy Grove at Intel</h3><p>Intel Corporate Objective: Establish the 8086 as the highest performance 16-bit microprocessor family, as measured by:</p><p>Key Results: (Q2 1980)</p><ol><li>Develop and publish five benchmarks showing superior 8086 family performance (Applications).</li><li>Repackage the entire 8086 family of products (Marketing).</li><li>Get the 8MHz part into production (Engineering, Manufacturing).</li><li>Sample the arithmetic coprocessor no later than June 15 (Engineering).</li></ol><p>Engineering Department Objective: Deliver 500 8MHz 8086 parts to CGW by May 30.</p><p>Key Results: (as measured by)</p><ol><li>Develop final art to photo plot by April 5.</li><li>Deliver Rev 2.3 masks to fab on April 9.</li><li>Test tapes completed by May 15.</li><li>Fab red ta start no later than May 1.</li></ol><h3 id="example-hypothetical-sports-team-by-john-doerr-to-illustrate-cross-level-okrs">Example: Hypothetical Sports Team by John Doerr to Illustrate Cross-Level OKRs</h3><p>Head Coach (Level Above) Objective: Win Super Bowl.</p><p>Key Results: (as measured by)</p><ol><li>Passing attack amasses 300+ yards per game.</li><li>Defense allows fewer than 17 points per game.</li><li>Special teams unit ranks in top 3 in punt return coverage.</li></ol><p>Offensive Coach (Level Below): Objective: Generate 300-yards-per-game-passing-attack.</p><p>Key Results: (as measured by)</p><ol><li>Achieve 65% pass completion rate.</li><li>Cut interceptions to fewer than 1 per game.</li><li>Hire new quarterbacks coach.</li></ol><p>Defensive Coach (Level Below): Objective: Give up fewer than 17 points a game.</p><p>Key Results: (as measured by)</p><ol><li>Allow fewer than 100 rushing yards per game.</li><li>Increase number of sacks to 3+ per game.</li><li>Develop a Pro Bowl cornerback.</li></ol><p>Special Teams Coach (Level Below): Objective: Improve on top 3 ranking for punt coverage team.</p><p>Key Results: (as measured by)</p><ol><li>Allow fewer than 10 yards per punt return.</li><li>Block 4+ punts over the season.</li></ol><h3 id="example-intuit">Example: Intuit</h3><p>Objective: Modernize, rationalize, and secure the technology used to run the business of Intuit.</p><p>Key Results: (as measured by)</p><ol><li>Complete the migration of Oracle eBusiness Suite to R12 and retire 11.5.9 this quarter.</li><li>Deliver wholesale billing as a platform capability by end of FY16.</li><li>Complete onboarding of agents in small business unit to Salesforce.</li><li>Create a retirement plan for all legacy technology.</li><li>Draft and get alignment on new Workforce Technology strategies, roadmaps, and principles.</li></ol><h3 id="example-google-youtube">Example: Google YouTube</h3><p>Objective: Reach 1 billion hours of watch time per day [by 2016] with growth driven by:</p><p>Key Results: (as measured by)</p><ol><li>Search team + Main App (+XX%), Living Room (+XX%)</li><li>Grow engagement and gaming watch time (X watch hours per day)</li><li>Launch YouTube VR experience and grow VR catalog from X to Y videos.</li></ol>
              </div></div>]]>
            </description>
            <link>https://www.product.ceo/measure-what-matters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194576</guid>
            <pubDate>Tue, 24 Nov 2020 02:21:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let's Go the 12 Startups in 12 Months Challenge Starts Now]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25194509">thread link</a>) | @rajatvijay
<br/>
November 23, 2020 | https://monicalent.com/12x-startup/ | <a href="https://web.archive.org/web/*/https://monicalent.com/12x-startup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

          <article>

              

              
              <figure>
                  <img src="https://monicalent.com/images/blog/banff-canada.jpg" alt="Let's go! The 12 Startups in 12 Months Challenge Starts Now">
              </figure>
              

              <section>
                  <div>
                      

<p>What would you do if I gave you $1 million today on the condition that you invest it entirely in the stock market?</p>

<p>First off, you’d probably find someone who knows way more about investing and get some
professional advice.</p>

<p>But in lieu of that, you’d divide your money among a variety of bets:</p>

<p>Stable companies with a history of profitability, growth-stage companies with a high tolerance
for risk, and maybe a few companies you just personally believe have
potential.</p>

<p>In short, you’d diversify.</p>

<p>The thought of putting all $1 million into a single company <em>probably</em> wouldn’t cross your mind.</p>

<p>Someday soon, I’d like to think a year of my time will be “worth” more than $1
million. So I won’t be putting it all into a single company either.</p>

<p>Instead I’ll build a startup a month for the next year.</p>

<h2 id="prior-art">Prior Art</h2>

<p>The first person to popularize building <a href="https://levels.io/12-startups-12-months/" alt="12 startups in 12 months (opens in a new tab)" target="_blank">12 startups in 12 months</a>
 is Pieter Levels, who
launched products like NomadList and RemoteOK in 2014.</p>

<p>Since he operates both as <a href="https://nomadlist.com/open" alt="open (opens in a new tab)" target="_blank">open</a>
 <a href="https://remoteok.io/open" alt="startups (opens in a new tab)" target="_blank">startups</a>
 we know they make a combined $600,000 per year.</p>

<p>Not bad for a solo founder with a part-time sys admin.</p>

<p>In the 5 years since, several others have taken the same challenge.</p>

<p>Jon Yongfook <a href="https://blog.yongfook.com/12-startups-in-12-months.html" alt="started (opens in a new tab)" target="_blank">started</a>

at the end of 2018, and eventually founded BannerBear. In the year he’s been
working on it, it’s grown to <a href="https://www.indiehackers.com/product/mojosaas" alt="$5.1K MRR (opens in a new tab)" target="_blank">$5.1K MRR</a>
 (monthly recurring revenue).</p>

<p>When I was chatting with Dominic Monn about the idea, he told me he’s had success with this approach too:</p>

<blockquote>
<p>I did something along the same lines where I launched 6 things in about 6 months in 2018 and <a href="https://mentorcruise.com/" alt="two (opens in a new tab)" target="_blank">two</a>
 <a href="https://remoteml.com/" alt="things (opens in a new tab)" target="_blank">things</a>
 grew out of it that make around $3.5k MRR together today, and some of the others I sold for a cumulative 5 figures as well.</p>
</blockquote>

<p>The common thread is that no one doing the challenge completes it.</p>

<p>Building 12 startups isn’t actually the goal.</p>

<p>The goal is to eliminate the most common blockers from shipping a product:
failure to stick to an MVP and finish something, fear of shipping, launching, charging money, and so forth.</p>

<p>Now, each of these things has to happen inside a month.</p>

<p><strong>The idea is that a fixed timespan helps you <em>quickly</em> find a few ideas worthy of your undivided focus.</strong></p>

<p>Instead of spending years working on an idea that won’t pan out.</p>

<p>I’m under no illusion that since Pieter’s very public success, a ton of people
have undergone the same challenge.</p>

<p>Few, if any, have seen the same financial outcomes thus far. The majority still work their
day jobs. And a quick search on Google reveals that most people don’t make it past the
first 2-3 startups.</p>

<p>That’s why I’ve adapted the challenge to tip the odds in my favor.</p>

<h2 id="it-s-dangerous-to-go-alone">It’s dangerous to go alone</h2>

<p>In <em><a href="https://www.goodreads.com/book/show/36291655-lost-and-founder" target="_blank">Lost and Founder</a></em>, Rand Fishkin, former CEO of Moz, writes:</p>

<blockquote>
<p>That’s one of the biggest things I’ve learned about startups: it’s dangerous to go alone. You want people around you who’ve been through this before and are willing to openly share their experiences.</p>
</blockquote>

<p>This is the main difference in our approach to building
12 startups in 12 months: We’re not going alone.</p>

<p><strong>We’ve created 12x Startup: A cohort of 4 motivated makers, each building their own “one startup per month”.</strong></p>

<p>Each day, we post our current task on our public <a href="https://12xstartup.com/" target="_blank">status page</a>. We correspond regularly in Slack, challenge each other’s ideas, and plan
to livestream our monthly demo sessions for you to tune into.</p>

<p><img src="https://monicalent.com/images/12xstartup.jpg" alt="12x Startup Homepage"></p>

<p>Apart from those of us who’ve built other types of profitable projects before,
we’re also inviting advisors who’re a bit further down the path than us.</p>

<p>This approach was inspired by my experience with <a href="https://medium.com/@rrhoover/turn-your-side-project-into-a-company-introducing-weekend-build-c70aebc6d716" target="_blank">Weekend Build</a>.</p>

<p>Knowing that I had to present progress every week to the group was a healthy
amount of pressure.</p>

<p>Having other makers to learn from, plus expert advice
from Ryan and Vedika, changed the trajectory of our <a href="https://affilimate.com/" alt="affiliate analytics tool (opens in a new tab)" target="_blank">affiliate analytics tool</a>
 in 8 weeks.</p>

<p>But I can’t shake the feeling…I’ve made building my first profitable startup much harder than it has to be.</p>

<p>If there were a master list of first-time founder mistakes, I’d
probably check most of the boxes.</p>

<p>18 months into that project and I’m not giving up.</p>

<p>But I am giving myself room to experiment.</p>

<h2 id="define-startup">Define startup</h2>

<p>So what “counts” as a startup? In his <a href="https://levels.io/12-startups-12-months/" target="_blank">original post</a>, Pieter addresses the myth that a startup has to begin
as a world-changing company with $1B valuation potential.</p>

<p>Meanwhile, it’s become clearer than ever that self-funded businesses
starting small can become highly successful:</p>

<ul>
<li>Product Hunt <a href="https://ryanhoover.me/post/69599262875/product-hunt-began-as-an-email-list" target="_blank">began as a newsletter</a> and was later acquired by AngelList</li>
<li>NomadList <a href="https://nomadlist.com/faq" target="_blank">started as a Google Sheet</a> and
now nets over $300K/year</li>
<li>Basecamp <a href="https://stackingthebricks.com/why-you-should-do-a-tiny-product-first/" alt="originated as a whitepaper (opens in a new tab)" target="_blank">originated as a whitepaper</a>
 and today serves 2M+ users</li>
<li>Baremetrics v1 was <a href="https://github.com/Baremetrics/baremetrics-v1" alt="built in a weekend (opens in a new tab)" target="_blank">built in a weekend</a>
 and now $1.5M ARR</li>
</ul>

<p>So for the purpose of 12x Startup, here’s my personal definition:</p>

<blockquote>
<p>An idea in the form of a product that resonates so deeply with a target
market of sufficient size, it’s worth seeing where you can take it.</p>
</blockquote>

<p>Or, to summarize in a word: Momentum.</p>

<p>The first evidence of momentum among my projects came in May when I <a href="https://bloggingfordevs.com/launch-a-newsletter/" target="_blank">launched my newsletter</a>. In just 5 months, it’s grown to over 3.8K subscribers with next to zero marketing.</p>

<p>When there’s momentum behind what you’re creating, my suspicion is you <em>just
know it</em>.</p>

<p>That’s a bit like what I’m looking for, within a few constraints.</p>

<h2 id="the-multitude-of-paths-to-a-million-dollars-a-year">The multitude of paths to a million dollars a year</h2>

<p>Let’s come back to that $1 million investment we were talking about.</p>

<p>In 2018, 17 course creators made over
<a href="https://teachable.com/blog/teachable-this-year" target="_blank">$1 million on Teachable</a>.
Fast forward to 2020, and 12 creators made over $1 million
<a href="https://mobile.twitter.com/ankurnagpal/status/1296841441575133186" target="_blank">during just the second quarter</a>. There are people doing the same on platforms like <a href="https://gaps.com/patreon-earners/" target="_blank">Patreon</a> and <a href="https://www.buzzfeed.com/alexkantrowitz/writers-have-been-trying-to-support-online-themselves-for" target="_blank">Substack</a>.</p>

<p>That is to say, you can make <em>a lot</em> of money by selling information-based products (“info products”) like
ebooks, online courses, substack subscriptions, and so forth.</p>

<p>Plus, you also don’t have to be in the top 1% to do well. As the popular essay
explains, you just need <a href="https://kk.org/thetechnium/1000-true-fans/" target="_blank">1,000 true fans</a> (or perhaps <a href="https://a16z.com/2020/02/06/100-true-fans/" target="_blank">only 100</a>).</p>

<p>That’s why it’s popular advice to start with a small ebook or a mini course before graduating to SaaS.</p>

<p>Building a SaaS product is just a <em>much, much</em> slower and more difficult path to a
million dollars or even “<a href="http://www.paulgraham.com/ramenprofitable.html" target="_blank">ramen profitability</a>”.</p>

<p>A quick ebook launch can put thousands of dollars in your pocket in
a matter of weeks and fund the next venture.</p>

<p>In comparison, our first $2K in SaaS revenue took almost a year to arrive.</p>

<p><strong>Which is to say, I didn’t follow any of this advice about starting small and building
a tiny info product.</strong></p>

<p>Like developers do, I dove headfirst into building something out of software.</p>

<p>There are a few reasons I think I made the right decision, and will continue to do
so for the 12x challenge.</p>

<p>Here are the top two:</p>

<ol>
<li><strong>Comfort can lead to complacency.</strong> I saw this happen when my travel blog reached
$5K/mo in revenue before the pandemic. It’s so easy to lose momentum when something “easy”
is already working and growing, <em>especially</em> when building a SaaS product is inherently difficult.</li>
<li><strong>It’s hard to value an info product-based business.</strong> Companies are valued based on future
earning potential. But here you’re making money based on a cycle of launches,
where you constantly have to create new material. I want to build “12x startups” I <em>could</em> sell,
if I wanted to.</li>
</ol>

<p>If I had to add a third, it’d be that it’s just more fun to build
software products.</p>

<p>I’m a developer afterall :)</p>

<h2 id="the-12x-rules-of-engagement">The 12x rules of engagement</h2>

<p>With these motivations in mind, I’ve placed the following constraints on my <em>personal</em> attempt at the 12 startups in 12 months challenge:</p>

<ul>
<li>No single-sale info products</li>
<li>Doesn’t depend on me, personally, to run it for it to be valuable</li>
<li>Low technical complexity</li>
<li>For most products, a way to test willingness to pay</li>
<li>Testable, scalable traction channels</li>
<li>A growth plan that can be sustained after the month ends</li>
<li>At least one product’s lowest price is a no-brainer at $99/mo</li>
<li>Experiment with both B2B and B2C</li>
<li>Some must leverage my unfair advantages</li>
</ul>

<p>To elaborate on the last point: I have other unique skills, connections, and
advantages above other people who might build the same products.</p>

<p>This includes things like my existing following on Twitter and my newsletter,
experience working in a high-growth tech company, and an existing SaaS codebase
full of reusable material.</p>

<p>I’m not here to prove you can build a startup in a vacuum.</p>

<h2 id="12-startups-in-12-months">12 Startups in 12 Months</h2>

<p>Keeping with tradition, this article will be updated on a monthly basis with each
startup I add to my personal portfolio.</p>

<p>If you want to keep an eye on my progress, you can follow along on Twitter
<a href="https://twitter.com/monicalent" target="_blank">@monicalent</a> and
on our status page at <a href="https://12xstartup.com/" target="_blank">12xstartup.com</a>.</p>





<p><strong>Initial idea:</strong> I’ve been all over the map in terms of my plans for a community for subscribers
of the Blogging for Devs newsletter.</p>

<p>First, I wanted to do a small group of women who blog. Then I had so many requests for a Slack or
Discord that I ended up launching a free, invite-only community built on <a href="http://circle.so/" target="_blank">Circle</a>,
capped at 100 free members.</p>

<p><img src="https://bloggingfordevs.com/images/bfd-pro-screenshot.png" alt="Blogging for Devs Community"></p>

<p>This month, I’ll convert it to a <strong>paid community</strong> for future members and adding more community features and premium content.</p>

<p>(You could say it’s cheating slightly because I’m not starting from scratch, but I’m losing 10 days of the month to my only vacation this year so 🤷🏻‍♀️)</p>

<p>Here’s my planned scope of work for the next four weeks:</p>

<ul>
<li>✨ <strong>Landing Page</strong> — A landing page to build a waitlist already exists <a href="https://bloggingfordevs.com/community/" target="_blank">over here</a>,
but it’ll need improvements and a way to pay and become a member.</li>
<li>🛠 <strong>Unified Experience</strong> — Each member will have a single login to the Community forums on
Circle and the Website, where all the other content will live. This means migrating existing members.</li>
<li>📅 <strong>Events System</strong> — We’ve had a few great virtual events, I want to build something simple
that lets me schedule events, members can RSVP, and get a calendar invite.</li>
<li>🎉 <strong>Member Feed and Goals</strong> — Something where you can see what everyone in the community
has published recently and set and see your progress towards Goals for yourself …</li></ul></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://monicalent.com/12x-startup/">https://monicalent.com/12x-startup/</a></em></p>]]>
            </description>
            <link>https://monicalent.com/12x-startup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194509</guid>
            <pubDate>Tue, 24 Nov 2020 02:11:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Desktop laser engraver: how do hobbyists use it to make money?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25194486">thread link</a>) | @Mimowork
<br/>
November 23, 2020 | https://www.mimowork.com/news/desktop-laser-engraver:-how-do-hobbyists-use-it-to-make-money.html | <a href="https://web.archive.org/web/*/https://www.mimowork.com/news/desktop-laser-engraver:-how-do-hobbyists-use-it-to-make-money.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.mimowork.com/news/desktop-laser-engraver:-how-do-hobbyists-use-it-to-make-money.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194486</guid>
            <pubDate>Tue, 24 Nov 2020 02:08:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Seekdir() Won't Seek to the Right Position (2008)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25194485">thread link</a>) | @tjalfi
<br/>
November 23, 2020 | https://msys.ch/fixing_seekdir | <a href="https://web.archive.org/web/*/https://msys.ch/fixing_seekdir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The other day, I got an email from Edd, an OpenBSD user, claiming that Samba would crash when serving files off an MS-DOS filesystem. This was Samba built from sources and not the one from ports. Since I use myself Samba a lot and for a quite large user base, I got interested in the issue and started investigating it. What I found out in the end is a surprise and was not expected: A bug that has been there in all BSDs for almost all the time, since the 4.2BSD times or for roughly 25 years... </p>
<!--break-->
<h2>The Samba Directory Cache</h2>
<p>The Problem With seekdir() In Samba's replacement code I found the following comment, stating the problem from the Samba point of view:</p>
<pre>"This is needed because the existing directory handling in FreeBSD
 and OpenBSD (and possibly NetBSD) doesn't correctly handle unlink()
 on files in a directory where telldir() has been used. On a block
 boundary it will occasionally miss a file when seekdir() is used to
 return to a position previously recorded with telldir().

 This also fixes a severe performance and memory usage problem with
 telldir() on BSD systems. Each call to telldir() in BSD adds an
 entry to a linked list, and those entries are cleaned up on
 closedir(). This means with a large directory closedir() can take an
 arbitrary amount of time, causing network timeouts as millions of
 telldir() entries are freed"
</pre><p>Apparently there are two problems: seekdir() not returning to the position initially retrieved using telldir() and a performance problem. Before digging to much into source code, I decided to check the documentation of said functions, just to make sure, they were being used like they are meant to be used. The OpenBSD manual page is clear: The <strong>seekdir()</strong> function sets the position of the next <strong>readdir()</strong> operation on the named directory stream dirp. The new position reverts to the one associated with the directory stream when the <strong>telldir()</strong> operation was performed. Values returned by <strong>telldir()</strong> are good only for the lifetime of the DIR pointer, dirp, from which they are derived. If the directory is closed and then reopened, the <strong>telldir()</strong> value may be invalidated due to undetected directory compaction. If you don't close the directory stream, seekdir() will take you back to the position previsouly obtained using telldir(). If the system behaves differently, then it's either a bug or the documentation is wrong. If the system indeed does not take you back to the right position, why do we have these functions then in the first place? A look at the closedir() function in OpenBSD reveals that the statement made by the Samba people about performance in closedir() is wrong: In OpenBSD there is no linked list, but a smarter memory handling scheme implemented by Otto Moerbeek (otto@). FreeBSD, however, uses a linked list indeed, but they can switch to our code at any time. So the performance problem really is a non-issue.</p>
<h2>Hunting the seekdir() Bug</h2>
<p><em>As the original author of the *dir() library, you probably fixed one of my bugs :-) Prior to the *dir() commands, programs just opened, read, and interpreted directories directly. I had to update a shocking 22 programs (a large percentage of the programs available on UNIX at the time) to replace their direct interpretation of directories with the *dir() library calls. (Kirk McKusick; private communication) </em></p>
<p>What I needed is a test program to exercise these functions an eventually trigger the behaviour that prevented the Samba people from enabling a directory cache on BSD systems. I wrote a C program that approximately does the following steps:</p>
<ol><li>Create a directory and populate it with a certain number of files</li>
<li>Iterate over the directory using readdir(), recording the position of the entry using telldir() before readdir(), and storing the obtained values in an array</li>
<li>Delete a random number of files and also mark them as deleted in the in-memory array</li>
<li>Iterate over the in-memory array, skipping the entries marked as deleted, and seekdir() to the others, doing a readdir() and compare the returned values with the in-memory copy</li>
<li>Output a message when the in-memory copy and the value returned by readdir() are different</li>
</ol><p>Jeremy told me that the problem occurs with large directories, so I began my tests with really large directories (up to 250'000 entries) and quite quickly I hit the issue. seekdir() won't return me to the recorded position. This kind of confirmed the problem the Samba people were seeing for more than three years. I tweaked the values of my test program, to see if I can find a pattern. But looking at thousands of directory positions, filenames, inode numbers where more likely to turn me mad than to spot the problem... I started lowering the numbers and to my surprise, I could trigger the problem with as little as 10 or 20 files and deleting just one of them. Suddenly, I had a case that shows the problem on every run, no more randomness: Create 28 files, delete file 25 and seekdir to file 26: You end up at file 27! Staring at the output of my program I suddenly saw the pattern as clear as can be: Creating the directory with 28 files had created a directory that spans more than one block on the disk (2 in this case). File 25 was the first entry of the second block. Obviously the problem occured when you delete the first entry in a block of a directory and then return to the recorded position of the second entry in the same block. This would actually get you one entry to far. By that time I had involved Otto to give me a hand and to confirm my findings. His first reaction: An interesting problem... ;) We investigated further and I began looking at the kernel code that removes a directory entry as well as the library code in libc that implements seekdir() and friends.</p>
<h2>How the Kernel Removed Directory Entries</h2>
<p>The kernel function to remove a directory entry, ufs_dirremove(), indeed treats entries that are located at the beginning of a block differently than others:</p>
<pre>        if (dp-&gt;i_count == 0) {
                /*
                 * First entry in block: set d_ino to zero.
                 */
                ep-&gt;d_ino = 0;
        } else {
                /*
                 * Collapse new free space into previous entry.
                 */
                ep-&gt;d_reclen += dp-&gt;i_reclen;
        }
</pre><p>If it is the first entry in a block, the inode number is set to zero, thus invalidating the entry. For all other entries, the record length of the to-be-deleted record is added to the record length of the previous entry. Since the library uses the record length field of an entry to proceed to the next entry in readdir(), this effectively means that the removed entry, while it is still in the block on disc, will no longer be used.</p>
<h2>How the C Library Accesses Directory Entries</h2>
<p>The C library implements the opendir(), telldir(), readdir(), seekdir(), and closedir() functions. These functions were written in the 4.2BSD times so that UNIX programs don't need to handle directories by themselves.</p>
<pre>/*
 * get next entry in a directory.
 */
int
_readdir_unlocked(DIR *dirp, struct dirent **result)
{
        struct dirent *dp;

        *result = NULL;
        for (;;) {
                if (dirp-&gt;dd_loc &gt;= dirp-&gt;dd_size)
                        dirp-&gt;dd_loc = 0;
                if (dirp-&gt;dd_loc == 0) {
                        dirp-&gt;dd_size = getdirentries(dirp-&gt;dd_fd,
                            dirp-&gt;dd_buf, dirp-&gt;dd_len, &amp;dirp-&gt;dd_seek);
                        if (dirp-&gt;dd_size == 0)
                                return (0);
                        if (dirp-&gt;dd_size &lt; 0)
                                return (-1);
                }
                dp = (struct dirent *)(dirp-&gt;dd_buf + dirp-&gt;dd_loc);
                if ((long)dp &amp; 03)      /* bogus pointer check */
                        return (-1);
                if (dp-&gt;d_reclen &lt;= 0 ||
                    dp-&gt;d_reclen &gt; dirp-&gt;dd_len + 1 - dirp-&gt;dd_loc)
                        return (-1);
                dirp-&gt;dd_loc += dp-&gt;d_reclen;
                 if (dp-&gt;d_ino == 0)
                        continue;
                *result = dp;
                return (0);
        }
}
</pre><p>At first sight, this code looks correct. It will skip deleted entries that have their inode number set to zero and it will use the record lenght otherwise. And since a directory traversal using readdir() works just fine, this is code effectively works. A close look at the seekdir() library implementation finally reveals the problem:</p>
<pre>/*
 * seek to an entry in a directory.
 * Only values returned by "telldir" should be passed to seekdir.
 */
void
__seekdir(DIR *dirp, long loc)
{
        struct ddloc *lp;
        struct dirent *dp;

        if (loc &lt; 0 || loc &gt;= dirp-&gt;dd_td-&gt;td_loccnt)
                return;
        lp = &amp;dirp-&gt;dd_td-&gt;td_locs[loc];
        dirp-&gt;dd_td-&gt;td_last = loc;
        if (lp-&gt;loc_loc == dirp-&gt;dd_loc &amp;&amp; lp-&gt;loc_seek == dirp-&gt;dd_seek)
                return;
        (void) lseek(dirp-&gt;dd_fd, (off_t)lp-&gt;loc_seek, SEEK_SET);
        dirp-&gt;dd_seek = lp-&gt;loc_seek;
        dirp-&gt;dd_loc = 0;
        while (dirp-&gt;dd_loc &lt; lp-&gt;loc_loc) {
                _readdir_unlocked(dirp, &amp;dp);
                if (dp == NULL)
                        break;
        }
}
</pre><p>This code will not work as expected when seeking to the second entry of a block where the first has been deleted: seekdir() calls readdir() which happily skips the first entry (it has inode set to zero), and advance to the second entry. When the user now calls readdir() to read the directory entry to which he just seekdir()ed, he does not get the second entry but the third. Much to my surprise I not only found this problem in all other BSDs or BSD derived systems like Mac OS X, but also in very old BSD versions. I first checked 4.4BSD Lite 2, and Otto confirmed it is also in 4.2BSD. The bug has been around for roughly 25 years or more.</p>
<h2>The Solution</h2>
<p>The fix is surprisingly simple, not to say trivial: _readdir_unlocked() must not skip directory entries with inode set to zero when it is called …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://msys.ch/fixing_seekdir">https://msys.ch/fixing_seekdir</a></em></p>]]>
            </description>
            <link>https://msys.ch/fixing_seekdir</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194485</guid>
            <pubDate>Tue, 24 Nov 2020 02:07:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quest to Disable LAN LEDs of an Intel NUC]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25194316">thread link</a>) | @hiq
<br/>
November 23, 2020 | https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/ | <a href="https://web.archive.org/web/*/https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h2>Introduction</h2>
<p>The Intel NUC <a href="http://ark.intel.com/products/76978/">D34010WYK</a> has a LAN port with two integrated LEDs. Both are permanently on when a connection is established, with one LED blinking on network activity. This can be rather distracting, particularly at night. So I went on to figure out how to disable the LEDs. It's a general solution that should work with every OS, every NUC, and every somewhat recent Intel NIC (Network Interface Card). Perhaps most devices with an Intel Ethernet controller.</p>
<p>The most obvious and low-tech solution is to tape the LEDs. I haven't tried as an observation led me on a different path. I noticed that a few seconds into booting Ubuntu, the LEDs are briefly switched off. I concluded this must be done through software somehow. This didn't turn out to be entirely correct or useful, as the driver (kernel module) merely resets the controller when it loads, but made me curious enough to proceed.</p>
<p>First, a step back to know the controller used in the NUC.</p>
<p>$ lspci | grep Ethernet
00:19.0 Ethernet controller: Intel Corporation Ethernet Connection I218-V (rev 04)</p>
<p>Intel ARK has <a href="http://ark.intel.com/products/71305/">more information</a>, including a very detailed 262-pages datasheet, which will prove essential.</p>
<h2>Kernel</h2>
<p>I wondered if the option to disable LEDs is perhaps provided through a kernel module parameter. I already knew the  module name for recent Intel Ethernet devices: <i>e1000e</i>. If I hadn't, <a href="https://downloadcenter.intel.com/search?keyword=I218">searching</a> the Intel Download Center for <i>I218</i> and filtering for <i>Linux</i> tells the same. And sure enough, the module is loaded.</p>
<p>$ lsmod | grep e1000e
e1000e                226396  0
ptp                    19395  1 e1000e</p>
<p>Many parameters, but none to change the behavior of LEDs. As confirmed by the <a href="https://www.kernel.org/doc/Documentation/networking/e1000e.txt">documentation</a>.</p>
<p>$ modinfo -p e1000e
debug:Debug level (0=none,...,16=all) (int)
copybreak:Maximum size of packet that is copied to a new buffer on receive (uint)
TxIntDelay:Transmit Interrupt Delay (array of int)
TxAbsIntDelay:Transmit Absolute Interrupt Delay (array of int)
RxIntDelay:Receive Interrupt Delay (array of int)
RxAbsIntDelay:Receive Absolute Interrupt Delay (array of int)
InterruptThrottleRate:Interrupt Throttling Rate (array of int)
IntMode:Interrupt Mode (array of int)
SmartPowerDownEnable:Enable PHY smart power down (array of int)
KumeranLockLoss:Enable Kumeran lock loss workaround (array of int)
WriteProtectNVM:Write-protect NVM [WARNING: disabling this can lead to corrupted NVM] (array of int)
CrcStripping:Enable CRC Stripping, disable if your BMC needs the CRC (array of int)</p>
<p>It turns out such a parameter was <a href="https://sourceforge.net/p/e1000/feature-requests/2/">requested</a> years ago, but denied by Intel with the following explanation.</p>
<p><span></span><span>I'm sorry, but this feature request was evaluated and denied because the majority of our customers require the LEDs to function as-is, and module parameters of this type are unacceptable.</span><span></span></p>
<p>So I downloaded the kernel model <a href="https://downloadcenter.intel.com/download/15817">source</a>, hoping to modify it, and eventually noticed a promising function.</p>
<p>
static s32 e1000_led_off_pchlan(struct e1000_hw *hw)
{
    u16 data = (u16)hw-&gt;mac.ledctl_mode1;
    u32 i, led;

    
    if (!(er32(STATUS) &amp; E1000_STATUS_LU)) {
        for (i = 0; i &lt; 3; i++) {
            led = (data &gt;&gt; (i * 5)) &amp; E1000_PHY_LED0_MASK; 
            if ((led &amp; E1000_PHY_LED0_MODE_MASK) !=
                E1000_LEDCTL_MODE_LINK_UP)
                continue;
            if (led &amp; E1000_PHY_LED0_IVRT)
                data &amp;= ~(E1000_PHY_LED0_IVRT &lt;&lt; (i * 5));
            else
                data |= (E1000_PHY_LED0_IVRT &lt;&lt; (i * 5));
        }
    }

    return e1e_wphy(hw, HV_LED_CONFIG, data);
}</p><p>Perhaps more complex than you'd expect such a simple task to be. Many constants and bit operations. Lots more in related functions. I figured this must be documented, presumably in the <a href="http://www.intel.com/content/dam/www/public/us/en/documents/datasheets/i218-ethernet-connection-datasheet.pdf">datasheet</a>. Browsing it cut my plans to modify the kernel module short, as it spells out a better alternative: NVM (Non-Volatile Memory).</p>
<p><span></span><span>The PHY has three LED outputs that can be configured via the NVM. The default values for the PHY (based on the LED NVM word 0x18 of the LAN region) are listed in the table below.</span><span></span></p>
<picture>
<source type="image/webp" media="(min-resolution:2dppx)" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/182.x2.webp?201707100332 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/182.x1.png?201706071857" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/182.x2.png?201706071857 2x">
</picture>
<p>If you're wondering why the table mentions 3 LEDs when the LAN port only has 2: the second LED is bi-colored and can switch state to either green (LED2) or amber (LED1).</p>
<p>As a closing note on the kernel module: the code does not do what it appears to. Its only purpose is to provide an interface for blinking a single LED on request, in order to identify a NIC or LAN port. It's unrelated to LEDs blinking on network activity or otherwise, which is done in hardware.</p>
<h2>NVM</h2>
<p>Writeable flash memory, which holds configuration, like the MAC address or power management settings, detailed in the table below. The LED configuration is stored in the previously mentioned word <span>0x18</span>.</p>
<picture>
<source type="image/webp" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/143+144.x1.webp?201707100332, https://storage.googleapis.com/cdn.pwmon.org/1900/143+144.x2.webp?201707100332 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/143+144.x1.png?201706071857" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/143+144.x2.png?201706071857 2x">
</picture>
<p>A minor detour first to explain the term <i>word</i>. It refers to a 2-byte (16-bit) value in little-endian order, meaning in reverse byte order. So value <span>0x1c10</span> is written <span>0x101c</span> to NVM. Very simple to do manually, by just swapping bytes, but can be done programmatically too. (These will be useful later.)</p>
<p>
def swap(value):
    return hex(value &gt;&gt; 8 | (value &amp; 0xFF) &lt;&lt; 8)

&gt;&gt;&gt; swap(0x1c10)
'0x101c'</p>
<p>
function swap(value) {
    return '0x' + ((value &gt;&gt; 8 | (value &amp; 0xFF) &lt;&lt; 8)).toString(16);
};

&gt; swap(0x1c10)
"0x101c"</p>
<p>Word <span>0x18</span> is encoded as follows.</p>
<picture>
<source type="image/webp" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/149.x1.webp?201707100332, https://storage.googleapis.com/cdn.pwmon.org/1900/149.x2.webp?201707100332 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/149.x1.png?201706071857" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/149.x2.png?201706071857 2x">
</picture>
<p>It's a bit sequence with 5 bits each per LED. The first 3 bits on each LED set the mode, detailed in the second table. The remaining 2 bits invert and blink the LED. Below is a visual explanation on how to read this, using the default values.</p>
<p><img src="https://storage.googleapis.com/cdn.pwmon.org/1900/f418.x1.png?201706071858" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/f418.x2.png?201706071858 2x"></p><p>Such a sequence can be used directly with the <span>swap</span> function defined earlier, with <span>0b</span> prefix to indicate bits.</p>
<p>&gt; swap(0b0001100011110100)
"0xf418"</p>
<p>Now to construct a bit sequence to turn LEDs off permanently. As you notice, there is no mode to just flat disable an LED. It's still possible to get effectively the same result. There are two solutions.</p>
<p><span>1</span><span>Set the mode of each LED to <span>010</span>, so LEDs are on on any connection, and set the invert bit on each LED. Ergo, LEDs are off on any connection. With a minor side effect: in case of no connection, LEDs are on. (When the network cable is pulled, or when the opposite side is off.)</span></p>
<picture>
<source type="image/webp" media="(min-resolution:2dppx)" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/4a29.x2.webp?201707100332 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/4a29.x1.png?201706071858" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/4a29.x2.png?201706071858 2x">
</picture>
<p>&gt; swap(0b0010100101001010)
"0x4a29"</p>
<p><span>2</span><span>Set the mode of each LED to <span>101</span>, so LEDs are on <b>only</b> on a 10Mbps connection. Ergo, LEDs are off for either a 100Mbps or 1Gbps connection. Without side effect, as LEDs stay off in case of no connection.</span></p>
<picture>
<source type="image/webp" media="(min-resolution:2dppx)" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/a514.x2.webp?201707100333 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/a514.x1.png?201706071858" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/a514.x2.png?201706071858 2x">
</picture>
<p>&gt; swap(0b0001010010100101)
"0xa514"</p>
<p>There are two additional variants to the second solution, which exclude the other link speed combinations each. I'll leave constructing the bit sequence for both as an exercise to the reader. Of both solutions I prefer the second due to lack of side effect when a link speed can be excluded. Usually either 10Mbps or 1Gbps definitely can be. A way to get the negotiated link speed is to use <i>dmesg</i>.</p>
<p>$ dmesg -t | grep e1000e
...
e1000e: eth0 NIC Link is Up 100 Mbps Full Duplex, Flow Control: Rx/Tx</p>
<p>So <span>0xa514</span> it is. Ready to write to NVM. The datasheet tells how.</p>
<p><span></span><span>Intel has an MS-DOS* software utility called EEupdate that is used to program the SPI Flash images in development or production line environments. A copy of this program can be obtained through your Intel Field Service representative.</span><span></span></p>
<p>That's no good. <i>EEupdate</i> is not publicly available. A bit of research reveals another Intel tool named <i>LANConf</i>, available for DOS, Linux, and Windows, which can also write to NVM, but can only be obtained by applying for a <a href="https://www-ssl.intel.com/content/www/us/en/my-intel/design-center-privileged-access-required.html">privileged account</a> and signing a Non-Disclosure Agreement. Fortunately, <i><a href="https://www.kernel.org/pub/software/network/ethtool/">ethtool</a></i> can handle NVM too.</p>
<p>To read from NVM, use as follows. (EEPROM and NVM are used interchangeably from here on.)</p>
<p>% ethtool -e|--eeprom-dump devname [raw on|off] [offset N] [length N]</p>
<p>As per the NVM Address Map, word <span>0x18</span> is at NVM byte offset <span>0x30</span>.</p>
<p>$ sudo ethtool -e eth0 offset 0x30 length 2
Offset      Values
------      ------
0x0030:     f4 18</p>
<p>It matches the default value constructed earlier. Now to the important part: writing to NVM.</p>
<p>% ethtool -E|--change-eeprom devname [magic N] [offset N] [length N] [value N]</p>
<p>So <i>offset</i>, <i>length</i>, and <i>value</i> are obvious, but what does <i>magic</i> refer to? The manual knows.</p>
<p><span></span><span>Because of the persistent nature of writing to the EEPROM, a device-specific magic key must be specified to prevent the accidental writing to the EEPROM.</span><span></span></p>
<p>Where the device-specific magic key can be obtained from isn't documented anywhere. It appears to be kept somewhat secret on purpose. Only the file <i>ethtool.c</i> in the kernel module source code explains it.</p>
<p>eeprom-&gt;magic = adapter-&gt;pdev-&gt;vendor | (adapter-&gt;pdev-&gt;device &lt;&lt; 16);</p>
<p>Here <i>vendor</i> and <i>device</i> refer to <a href="https://pcisig.com/membership">PCI IDs</a>. There are numerous ways to get them, with the easiest perhaps being <i>lspci</i>.</p>
<p>$ lspci -nnq | grep Ethernet
00:19.0 Ethernet controller [0200]: Intel Corporation Ethernet Connection I218-V [<b>8086</b>:<b>1559</b>] (rev 04)</p>
<p>The bold numbers are the <i>vendor</i> and <i>device</i> ID respectively, in hex. So this should give the magic key.</p>
<p>
&gt; '0x' + (0x8086 | (0x1559 &lt;&lt; 16)).toString(16)
"0x15598086"</p>
<p>Very simple. Alright, commence writing.</p>
<p>$ sudo ethtool -E eth0 magic 0x15598086 offset 0x30 length 2 value 0xa514
ethtool: bad command line argument(s)</p>
<p>The value of <i>value</i> can only be a single byte. The <i>length</i> parameter repeats that byte. (This isn't documented.) Both bytes must hence be written separately. </p>
<p>$ sudo ethtool -E eth0 magic 0x15598086 offset 0x30 value 0xa5
Cannot set EEPROM data: Invalid argument</p>
<p>This rather non-descriptive error took me quite a while to figure out. The <i>e1000e</i> kernel module included with the default kernel of Ubuntu 14.04.2 does not support writing to NVM, in this case at least. Intel has <a href="http://www.intel.com/content/www/us/en/support/network-and-i-o/ethernet-products/000005480.html">instructions</a> for compiling and installing the latest kernel module from source. Now it should work.</p>
<p>$ sudo ethtool -E eth0 magic 0x15598086 offset 0x30 value 0xa5
$ sudo ethtool -E eth0 magic 0x15598086 offset 0x31 value 0x14</p>
<p>And it does. Note: the LEDs remain unchanged until either the NUC is reset or the kernel module is reloaded.</p>
<h2>Windows / Mac</h2>
<p>I have not verified, but modifying NVM should also work for other OSes, unless the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/">https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/</a></em></p>]]>
            </description>
            <link>https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194316</guid>
            <pubDate>Tue, 24 Nov 2020 01:44:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantization for Neural Networks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25194218">thread link</a>) | @keyboardman
<br/>
November 23, 2020 | https://leimao.github.io/article/Neural-Networks-Quantization/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/article/Neural-Networks-Quantization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Quantization refers to techniques for performing computations and storing tensors at lower bitwidths than floating point precision. A quantized model executes some or all of the operations on tensors with integers rather than floating point values. This allows for a more compact model representation and the use of high performance vectorized operations on many hardware platforms. This technique is in particular useful at the inference time since it saves a lot of inference computation cost without sacrificing too much inference accuracies.</p>



<p>So far, major deep learning frameworks, such as TensorFlow and PyTorch, have supported quantization natively. The users have been using the built-in quantization modules successfully without knowing how it works exactly. In this article, I would like to elucidate the mathematics of quantization for neural networks so that the developers would have some ideas about the quantization mechanisms.</p>

<h3 id="quantization">Quantization</h3>

<h4 id="quantization-mapping">Quantization Mapping</h4>

<p>Quantization maps a floating point value $x \in [\alpha, \beta]$ to a $b$-bit integer $x_q \in [\alpha_q, \beta_q]$.</p>



<p>Mathematically, the de-quantization process is defined as</p><p>

\[x = c (x_q + d)\]

</p><p>and the quantization process is defined as</p><p>

\[x_q = \text{round}\big(\frac{1}{c} x - d\big)\]

</p><p>where $c$ and $d$ are variables.</p>



<p>In order to derive $c$ and $d$, we have to make sure that $\alpha$ maps to $\alpha_q$ and $\beta$ maps to $\beta_q$. So we would just have to solve the linear system</p><p>

\[\begin{align}
\beta &amp;= c (\beta_q + d) \\
\alpha &amp;= c (\alpha_q + d) \\
\end{align}\]

</p><p>The solutions is</p><p>

\[\begin{align}
c &amp;= \frac{\beta - \alpha}{\beta_q - \alpha_q} \\
d &amp;= \frac{\alpha \beta_q - \beta \alpha_q}{\beta - \alpha} \\
\end{align}\]

</p><p>In practice, we would have to ensure that $0$ in floating point is represented exactly with no error after quantization.</p>



<p>Mathematically, we need to ensure</p><p>

\[\begin{align}
x_q &amp;= \text{round}\big(\frac{1}{c} 0 - d\big) \\
&amp;= \text{round}(- d) \\
&amp;= - \text{round}(d) \\
&amp;= - d \\
\end{align}\]

</p><p>This means that</p><p>

\[\begin{align}
d &amp;= \text{round}(d) \\
&amp;= \text{round}\big(\frac{\alpha \beta_q - \beta \alpha_q}{\beta - \alpha}\big) \\
\end{align}\]

</p><p>By convention, we denote $c$ as the scale $s$ and $-d$ as the zero point $z$.</p>



<p>To summarize, the de-quantization process is defined as</p><p>

\[x = s (x_q - z)\]

</p><p>and the quantization process is defined as</p><p>

\[x_q = \text{round}\big(\frac{1}{s} x + z\big)\]

</p><p>The value of scale $s$ and zero point $z$ are</p><p>

\[\begin{align}
s &amp;= \frac{\beta - \alpha}{\beta_q - \alpha_q} \\
z &amp;= \text{round}\big(\frac{\beta \alpha_q - \alpha \beta_q}{\beta - \alpha}\big) \\
\end{align}\]

</p><p>Note that $z$ is an integer and $s$ is a <em>positive</em> floating point number.</p>

<h4 id="value-clipping">Value Clipping</h4>

<p>In practice, the quantization process will have chance to have $x$ that is outside the range of $[\alpha, \beta]$, thus the quantized value $x_q$ will also be outside the range of $[\alpha_q, \beta_q]$. If the integer type is signed <code>INTb</code> and $(\alpha_q, \beta_q) = (-2^{b-1}, 2^{b-1}-1)$, or unsigned <code>UINTb</code> and $(\alpha_q, \beta_q) = (0, 2^{b}-1)$, programming languages that have fixed type-precisions will clip the values that are outside the range.</p>



<p>More concretely, the quantization process will have an additional clip step.</p><p>

\[x_q = \text{clip}\Big( \text{round}\big(\frac{1}{s} x + z\big), \alpha_q, \beta_q \Big)\]

</p><p>where $\text{clip}(x, l, u)$ function is defined as</p><p>

\[\begin{align}
\text{clip}(x, l, u) &amp;= 
    \begin{cases}
      l &amp; \text{if $x &lt; l$}\\
      x &amp; \text{if $l \leq x \leq u$}\\
      u &amp; \text{if $x &gt; u$}\\
    \end{cases} 
\end{align}\]

</p><h4 id="affine-quantization-mapping">Affine Quantization Mapping</h4>

<p>The quantization mapping we discussed above is also called affine quantization mapping.</p>

<h4 id="scale-quantization-mapping">Scale Quantization Mapping</h4>

<p>If the integer type is signed <code>INTb</code>, $(\alpha_q, \beta_q) = (-2^{b-1} + 1, 2^{b-1}-1)$ and we force $z = 0$.</p>



<p>Mathematically, we have</p><p>

\[\begin{gather}
\alpha_q = -\beta_q \\
\text{round}\big(\frac{\beta \alpha_q - \alpha \beta_q}{\beta - \alpha}\big) = 0 \\
\end{gather}\]

</p><p>This results in $\alpha = -\beta$. Therefore, we are mapping between the floating point range $[\alpha, -\alpha]$ and the integer range $[\alpha_q, -\alpha_q]$. Because it is exactly symmetric around $0$, we also call it symmetric quantization mapping.</p>



<p>Note that scale quantization mapping is just a special case of the affine quantization mapping, and we have an unused bit in the integer range.</p>

<h4 id="summary">Summary</h4>

<p>The quantization function is defined as</p><p>

\[f_q(x, s, z) = \text{clip}\Big( \text{round}\big(\frac{1}{s} x + z\big), \alpha_q, \beta_q \Big)\]

</p><p>and the de-quantization function is defined as</p><p>

\[f_d(x_q, s, z) = s (x_q - z)\]

</p><h3 id="quantized-matrix-multiplication">Quantized Matrix Multiplication</h3>

<h4 id="quantized-matrix-multiplication-mathematics">Quantized Matrix Multiplication Mathematics</h4>

<p>Suppose we have to perform the matrix multiplication $Y = XW + b$, where $X \in \mathbb{R}^{m \times p}$, $W \in \mathbb{R}^{p \times n}$, and $b \in \mathbb{R}^{n}$ resulting in $Y \in \mathbb{R}^{m \times n}$.</p><p>

\[\begin{align}
Y_{i, j} = b_j + \sum_{k=1}^{p} X_{i,k} W_{k,j}
\end{align}\]

</p><p>We would need to do $p$ floating number multiplications and $p$ floating number additions to compute one single entry in $Y$. To complete the full matrix multiplication, given there are $mn$ entries in $Y$, we would need to do $mpn$ floating number multiplications and $mpn$ floating number additions.</p>



<p>Depending on the floating number precision, such the speed of such floating point matrix multiplication might not be favored. So the question becomes can we complete the same matrix multiplication using quantized values.</p>



<p>Here we apply the de-quantization equation.</p><p>

\[\begin{align}
Y_{i, j} &amp;= b_j + \sum_{k=1}^{p} X_{i,k} W_{k,j} \\
&amp;= s_b (b_{q, j} - z_b) + \sum_{k=1}^{p} s_X(X_{q,i,k} - z_X) s_W(W_{q, k,j} - z_W)\\
&amp;= s_b (b_{q, j} - z_b) + s_X s_W \sum_{k=1}^{p} (X_{q,i,k} - z_X) (W_{q, k,j} - z_W)\\
&amp;= s_b (b_{q, j} - z_b) + s_X s_W \Bigg[ \bigg( \sum_{k=1}^{p} X_{q,i,k} W_{q, k,j} \bigg) - \bigg( z_W \sum_{k=1}^{p} X_{q,i,k} \bigg) - \bigg( z_X \sum_{k=1}^{p} W_{q, k,j} \bigg) + p z_X z_W\Bigg]\\
&amp;= s_Y(Y_{q,i,j} - z_Y)\\
\end{align}\]

</p><p>where $X_q$, $W_q$, $b_q$ and $Y_q$ are the quantized matrix for $X$, $W$, $b$ and $Y$, respectively, $s_X$, $s_W$, $s_b$, and $s_Y$ are the scales for $X$, $W$, $b$ and $Y$, respectively, and $z_X$, $z_W$, $z_b$ and $z_Y$ are the zero points for $X$, $W$, $b$ and $Y$, respectively.</p>



<p>Therefore,</p><p>

\[Y_{q,i,j} = z_Y + \frac{s_b}{s_Y} (b_{q, j} - z_b) + \frac{s_X s_W}{s_Y} \Bigg[ \bigg( \sum_{k=1}^{p} X_{q,i,k} W_{q, k,j} \bigg) - \bigg( z_W \sum_{k=1}^{p} X_{q,i,k} \bigg) - \bigg( z_X \sum_{k=1}^{p} W_{q, k,j} \bigg) + p z_X z_W\Bigg]\]

</p><p>Note that in the above equation the following terms are constants during inference and therefore could be computed offline before inference.</p>

<ul>
  <li>$z_Y$</li>
  <li>$\frac{s_b}{s_Y} (b_{q, j} - z_b)$</li>
  <li>$z_X \sum_{k=1}^{p} W_{q, k,j}$</li>
  <li>$p z_X z_W$</li>
</ul>

<p>Term $\sum_{k=1}^{p} X_{q,i,k} W_{q, k,j}$ suggests that we could just do the integer matrix multiplication for $X_q$ and $W_q$. Such integer matrix multiplication could employ special hardware and algorithms, such as <a href="https://www.nvidia.com/en-us/data-center/tensor-cores/">NVIDIA Tensor Core</a> and <a href="https://docs.nvidia.com/cuda/ampere-tuning-guide/index.html#tensor-operations">Tensor Core IMMA operations</a>, and runs much faster than conventional integer matrix multiplication.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/article/2020-11-01-Neural-Networks-Quantization/tensor-core.png">
    <figcaption>NVIDIA Tensor Core Operations</figcaption>
</figure>
</div>

<p>One additional thing to note is that $s_X$, $s_W$, $s_Y$, $z_X$, $z_W$, and $z_Y$ are floating point and integer constants, instead of variables. So there could be some special compile-time optimizations for those multiplications.</p>



<p>This could be retrieved from the resulting integer matrix from $X_q$ and $W_q$ multiplication, which is much faster than the floating number matrix multiplication for the same sizes.</p>



<p>The significance of such quantized matrix multiplication is that the product integer matrix could be converted back to floating point matrix using the scale and the zero point of the product integer matrix and it is almost numerically equivalent. If we have to do a sequence of matrix multiplications whose inputs and outputs are floating point numbers, for example</p><p>

\[\begin{align}
X_1 &amp;= X_0 W_0 + b_0\\
X_2 &amp;= X_1 W_1 + b_1\\
&amp;\vdots \\
X_n &amp;= X_n W_n + b_n\\
\end{align}\]

</p><p>We could convert the math to the followings using quantized matrices.</p><p>

\[\begin{align}
X_{0, q} &amp;= f_q(X_0, s_{X_0}, z_{X_0})\\
X_{1, q} &amp;= f_m(X_{0, q}, W_{0, q}, b_{0, q}, s_{X_0}, z_{X_0}, s_{W_0}, z_{W_0}, s_{b_0}, z_{b_0}, s_{X_1}, z_{X_1}) \\
X_{2, q} &amp;= f_m(X_{1, q}, W_{1, q}, b_{1, q}, s_{X_1}, z_{X_1}, s_{W_1}, z_{W_1}, s_{b_1}, z_{b_1}, s_{X_2}, z_{X_2}) \\
&amp;\vdots \\
X_{n, q} &amp;= f_m(X_{n-1, q}, W_{n-1, q}, b_{n-1, q}, s_{X_{n-1}}, z_{X_{n-1}}, s_{W_{n-1}}, z_{W_{n-1}}, s_{b_{n-1}}, z_{b_{n-1}}, s_{X_n}, z_{X_n}) \\
X_n &amp;= f_d(X_{n, q}, s_{X_n}, z_{X_n})
\end{align}\]

</p><p>where $f_q$ is the quantization function, $f_m$ is the quantized matrix multiplication function, and $f_d$ is the de-quantization function.</p>

<h4 id="examples">Examples</h4>

<p>In the following example, we simulated the quantization matrix multiplication of $Y = XW + b$ using random matrix $X$, $W$ and $b$.</p>

<div><div><pre><code><span># gemm.py
</span><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>

<span>def</span> <span>quantization</span><span>(</span><span>x</span><span>,</span> <span>s</span><span>,</span> <span>z</span><span>,</span> <span>alpha_q</span><span>,</span> <span>beta_q</span><span>):</span>

    <span>x_q</span> <span>=</span> <span>np</span><span>.</span><span>round</span><span>(</span><span>1</span> <span>/</span> <span>s</span> <span>*</span> <span>x</span> <span>+</span> <span>z</span><span>,</span> <span>decimals</span><span>=</span><span>0</span><span>)</span>
    <span>x_q</span> <span>=</span> <span>np</span><span>.</span><span>clip</span><span>(</span><span>x_q</span><span>,</span> <span>a_min</span><span>=</span><span>alpha_q</span><span>,</span> <span>a_max</span><span>=</span><span>beta_q</span><span>)</span>

    <span>return</span> <span>x_q</span>

<span>def</span> <span>quantization_int8</span><span>(</span><span>x</span><span>,</span> <span>s</span><span>,</span> <span>z</span><span>):</span>

    <span>x_q</span> <span>=</span> <span>quantization</span><span>(</span><span>x</span><span>,</span> <span>s</span><span>,</span> <span>z</span><span>,</span> <span>alpha_q</span><span>=-</span><span>128</span><span>,</span> <span>beta_q</span><span>=</span><span>127</span><span>)</span>
    <span>x_q</span> <span>=</span> <span>x_q</span><span>.</span><span>astype</span><span>(</span><span>np</span><span>.</span><span>int8</span><span>)</span>

    <span>return</span> <span>x_q</span>

<span>def</span> <span>dequantization</span><span>(</span><span>x_q</span><span>,</span> <span>s</span><span>,</span> <span>z</span><span>):</span>

    <span>x</span> <span>=</span> <span>s</span> <span>*</span> <span>(</span><span>x_q</span> <span>-</span> <span>z</span><span>)</span>
    <span>x</span> <span>=</span> <span>x</span><span>.</span><span>astype</span><span>(</span><span>np</span><span>.</span><span>float32</span><span>)</span>

    <span>return</span> <span>x</span>

<span>def</span> <span>generate_quantization_constants</span><span>(</span><span>alpha</span><span>,</span> <span>beta</span><span>,</span> <span>alpha_q</span><span>,</span> <span>beta_q</span><span>):</span>

    <span># Affine quantization mapping
</span>    <span>s</span> <span>=</span> <span>(</span><span>beta</span> <span>-</span> <span>alpha</span><span>)</span> <span>/</span> <span>(</span><span>beta_q</span> <span>-</span> <span>alpha_q</span><span>)</span>
    <span>z</span> <span>=</span> <span>int</span><span>((</span><span>beta</span> <span>*</span> <span>alpha_q</span> <span>-</span> <span>alpha</span> <span>*</span> <span>beta_q</span><span>)</span> <span>/</span> <span>(</span><span>beta</span> <span>-</span> <span>alpha</span><span>))</span>

    <span>return</span> <span>s</span><span>,</span> <span>z</span>

<span>def</span> <span>generate_quantization_int8_constants</span><span>(</span><span>alpha</span><span>,</span> <span>beta</span><span>):</span>

    <span>b</span> <span>=</span> <span>8</span>
    <span>alpha_q</span> <span>=</span> <span>-</span><span>2</span> <span>**</span> <span>(</span><span>b</span><span>-</span><span>1</span><span>)</span>
    <span>beta_q</span> <span>=</span> <span>2</span> <span>**</span> <span>(</span><span>b</span><span>-</span><span>1</span><span>)</span> <span>-</span> <span>1</span>

    <span>s</span><span>,</span> <span>z</span> <span>=</span> <span>generate_quantization_constants</span><span>(</span><span>alpha</span><span>=</span><span>alpha</span><span>,</span> <span>beta</span><span>=</span><span>beta</span><span>,</span> <span>alpha_q</span><span>=</span><span>alpha_q</span><span>,</span> <span>beta_q</span><span>=</span><span>beta_q</span><span>)</span>

    <span>return</span> <span>s</span><span>,</span> <span>z</span>

<span>def</span> <span>quantization_matrix_multiplication_int8</span><span>(</span><span>X_q</span><span>,</span> <span>W_q</span><span>,</span> <span>b_q</span><span>,</span> <span>s_X</span><span>,</span> <span>z_…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/article/Neural-Networks-Quantization/">https://leimao.github.io/article/Neural-Networks-Quantization/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/article/Neural-Networks-Quantization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194218</guid>
            <pubDate>Tue, 24 Nov 2020 01:30:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Low Tech Directory]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25194202">thread link</a>) | @iuguy
<br/>
November 23, 2020 | https://emreed.net/LowTech_Directory.html | <a href="https://web.archive.org/web/*/https://emreed.net/LowTech_Directory.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tr>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;#&quot;}">#</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;URL&quot;}">URL</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Owner&quot;}">Owner</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Description&quot;}">Description</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1}">1</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://coleoptera.neocities.org/&quot;}" data-sheets-hyperlink="https://coleoptera.neocities.org/"><a href="https://coleoptera.neocities.org/" target="_blank">https://coleoptera.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Em (me!)&quot;}">Em (me!)</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Writing and curation portfolio about small games, alt games and art games&quot;}">Writing and curation portfolio about small games, alt games and art games</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2}">2</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://candle.neocities.org/&quot;}" data-sheets-hyperlink="https://candle.neocities.org/"><a href="https://candle.neocities.org/" target="_blank">https://candle.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;candle&quot;}">candle</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Blog and small games projects&quot;}">Blog and small games projects</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3}">3</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://spdrcstl.com/&quot;}" data-sheets-hyperlink="https://spdrcstl.com/"><a href="https://spdrcstl.com/" target="_blank">https://spdrcstl.com/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Freya Campbell&quot;}">Freya Campbell</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Sci-fi, games, writing and music&quot;}">Sci-fi, games, writing and music</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4}">4</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://nialltl.neocities.org/&quot;}" data-sheets-hyperlink="https://nialltl.neocities.org/"><a href="https://nialltl.neocities.org/" target="_blank">https://nialltl.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;nialltl&quot;}">nialltl</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Games and other dev projects&quot;}">Games and other dev projects</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5}">5</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://emmadaues.neocities.org/&quot;}" data-sheets-hyperlink="https://emmadaues.neocities.org/"><a href="https://emmadaues.neocities.org/" target="_blank">https://emmadaues.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Emma Daues&quot;}">Emma Daues</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Games, art and music portfolio&quot;}">Games, art and music portfolio</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6}">6</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://pooka.press/&quot;}" data-sheets-hyperlink="http://pooka.press/"><a href="http://pooka.press/" target="_blank">http://pooka.press/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Pooka Press&quot;}">Pooka Press</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Fiction and comics&quot;}">Fiction and comics</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7}">7</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://forums.transbian.love/&quot;}" data-sheets-hyperlink="http://forums.transbian.love/"><a href="http://forums.transbian.love/" target="_blank">http://forums.transbian.love/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Lesbiaboard&quot;}">Lesbiaboard</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;A forum for trans lesbians, likeminded LGBT+ people, and allies&quot;}">A forum for trans lesbians, likeminded LGBT+ people, and allies</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:8}">8</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://onionboi.neocities.org/&quot;}" data-sheets-hyperlink="https://onionboi.neocities.org/"><a href="https://onionboi.neocities.org/" target="_blank">https://onionboi.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;onion&quot;}">onion</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Home of all things onion&quot;}">Home of all things onion</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:9}">9</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://thufie.lain.haus/&quot;}" data-sheets-hyperlink="https://thufie.lain.haus/"><a href="https://thufie.lain.haus/" target="_blank">https://thufie.lain.haus/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;thufie&quot;}">thufie</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Blog plus free software and cyberpunk info&quot;}">Blog plus free software and cyberpunk info</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:10}">10</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://rumpel.neocities.org/&quot;}" data-sheets-hyperlink="https://rumpel.neocities.org/"><a href="https://rumpel.neocities.org/" target="_blank">https://rumpel.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Rumpelcita&quot;}">Rumpelcita</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Indie games and mods&quot;}">Indie games and mods</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:11}">11</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://caeth.net/&quot;}" data-sheets-hyperlink="https://caeth.net/"><a href="https://caeth.net/" target="_blank">https://caeth.net/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;caeth&quot;}">caeth</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;a variety of creative projects by caeth&quot;}">a variety of creative projects by caeth</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:12}">12</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://lnnyfrnds.neocities.org/&quot;}" data-sheets-hyperlink="https://lnnyfrnds.neocities.org/"><a href="https://lnnyfrnds.neocities.org/" target="_blank">https://lnnyfrnds.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Lenny Magner&quot;}">Lenny Magner</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Music and cute bitsy games by Lenny&quot;}">Music and cute bitsy games by Lenny</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:13}">13</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://www.vertexmeadow.xyz/&quot;}" data-sheets-hyperlink="http://www.vertexmeadow.xyz/"><a href="http://www.vertexmeadow.xyz/" target="_blank">http://www.vertexmeadow.xyz/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Ian MacLarty&quot;}">Ian MacLarty</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;A tool for generating 3D worlds from 2D images&quot;}">A tool for generating 3D worlds from 2D images</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:14}">14</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://suricrasia.online/&quot;}" data-sheets-hyperlink="https://suricrasia.online/"><a href="https://suricrasia.online/" target="_blank">https://suricrasia.online/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Suricrasia Online&quot;}">Suricrasia Online</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Demoscene, imaginary books and more&quot;}">Demoscene, imaginary books and more</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:15}">15</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://maple.pet/&quot;}" data-sheets-hyperlink="http://maple.pet/"><a href="http://maple.pet/" target="_blank">http://maple.pet/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;maple's website&quot;}">maple's website</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Music, art and coding projects&quot;}">Music, art and coding projects</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:16}">16</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://www.femicom.org/sozai/&quot;}" data-sheets-hyperlink="http://www.femicom.org/sozai/"><a href="http://www.femicom.org/sozai/" target="_blank">http://www.femicom.org/sozai/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;FEMICOM Sozai Collection&quot;}">FEMICOM Sozai Collection</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;An online archive presenting the history of pixel gifts&quot;}">An online archive presenting the history of pixel gifts</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:17}">17</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://niceware.neocities.org/&quot;}" data-sheets-hyperlink="https://niceware.neocities.org/"><a href="https://niceware.neocities.org/" target="_blank">https://niceware.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;basile&quot;}">basile</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;a site presenting baz's bitsy games&quot;}">a site presenting baz's bitsy games</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:18}">18</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://irradiate.space/&quot;}" data-sheets-hyperlink="https://irradiate.space/"><a href="https://irradiate.space/" target="_blank">https://irradiate.space/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Irradiate Space&quot;}">Irradiate Space</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;A collection of fiction and comics&quot;}">A collection of fiction and comics</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:19}">19</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://oliverblueberry.info/&quot;}" data-sheets-hyperlink="http://oliverblueberry.info/"><a href="http://oliverblueberry.info/" target="_blank">http://oliverblueberry.info/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Daniel P. Lopez&quot;}">Daniel P. Lopez</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Links to small games, comics and zines&quot;}">Links to small games, comics and zines</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:20}">20</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://harmonyzone.org/&quot;}" data-sheets-hyperlink="http://harmonyzone.org/"><a href="http://harmonyzone.org/" target="_blank">http://harmonyzone.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;thecatamites&quot;}">thecatamites</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;\&quot;dumb shit... no wait put \&quot;dumb shit (comma) games writing\&quot;\&quot;&quot;}">"dumb shit... no wait put "dumb shit (comma) games writing""</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:21}">21</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://tn5421.github.io&quot;}" data-sheets-hyperlink="https://tn5421.github.io"><a href="https://tn5421.github.io/" target="_blank">https://tn5421.github.io</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;TN's Homepage&quot;}">TN's Homepage</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;A collection of game tools and writing&quot;}">A collection of game tools and writing</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:22}">22</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://ekardnam.github.io/&quot;}" data-sheets-hyperlink="https://ekardnam.github.io/"><a href="https://ekardnam.github.io/" target="_blank">https://ekardnam.github.io/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;ekardnam&quot;}">ekardnam</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;blog on libertarian technology and infosec&quot;}">blog on libertarian technology and infosec</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:23}">23</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://thewindspirit.com/&quot;}" data-sheets-hyperlink="http://thewindspirit.com/"><a href="http://thewindspirit.com/" target="_blank">http://thewindspirit.com/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Max Anderson&quot;}">Max Anderson</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Animations and blog&quot;}">Animations and blog</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:24}">24</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://obshagce.gamemaking.tools/&quot;}" data-sheets-hyperlink="https://obshagce.gamemaking.tools/"><a href="https://obshagce.gamemaking.tools/" target="_blank">https://obshagce.gamemaking.tools/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Blueberry Soft&quot;}">Blueberry Soft</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Hypermedia game-making framework&quot;}">Hypermedia game-making framework</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:25}">25</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://bwamp.org/&quot;}" data-sheets-hyperlink="http://bwamp.org/"><a href="http://bwamp.org/" target="_blank">http://bwamp.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Kyle Reimergartin&quot;}">Kyle Reimergartin</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;rooms of various size&quot;}">rooms of various size</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:26}">26</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://xenonfiber.space/&quot;}" data-sheets-hyperlink="https://xenonfiber.space/"><a href="https://xenonfiber.space/" target="_blank">https://xenonfiber.space/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Xenon Fiber\n&quot;}">Xenon Fiber</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Discography, blog, and independently hosted video streaming&quot;}">Discography, blog, and independently hosted video streaming</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:27}">27</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://alicee.neocities.org/&quot;}" data-sheets-hyperlink="https://alicee.neocities.org/"><a href="https://alicee.neocities.org/" target="_blank">https://alicee.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Stress-Repellent Machine&quot;}">Stress-Repellent Machine</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;video games, art and other dumb projek...god damn it i mean project!!!&quot;}">video games, art and other dumb projek...god damn it i mean project!!!</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:28}">28</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://frsp.xyz/&quot;}" data-sheets-hyperlink="https://frsp.xyz/"><a href="https://frsp.xyz/" target="_blank">https://frsp.xyz/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Frederick St. Peter&quot;}">Frederick St. Peter</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;experimental music and art&quot;}">experimental music and art</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:29}">29</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://l4nn1312.neocities.org/&quot;}" data-sheets-hyperlink="https://l4nn1312.neocities.org/"><a href="https://l4nn1312.neocities.org/" target="_blank">https://l4nn1312.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;L4NN-1312&quot;}">L4NN-1312</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;robot girl blog&quot;}">robot girl blog</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:30}">30</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://hyena.network/geocity/&quot;}" data-sheets-hyperlink="https://hyena.network/geocity/"><a href="https://hyena.network/geocity/" target="_blank">https://hyena.network/geocity/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Hyena Network (HyNET)&quot;}">Hyena Network (HyNET)</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;A network of: services, personal yelling into the void and hyenas.&quot;}">A network of: services, personal yelling into the void and hyenas.</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:31}">31</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://blog.knightsofthelambdacalcul.us/&quot;}" data-sheets-hyperlink="https://blog.knightsofthelambdacalcul.us/"><a href="https://blog.knightsofthelambdacalcul.us/" target="_blank">https://blog.knightsofthelambdacalcul.us/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;hazel&quot;}">hazel</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;tech rants and personal code hosting&quot;}">tech rants and personal code hosting</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:32}">32</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://www.lartu.net/&quot;}" data-sheets-hyperlink="https://www.lartu.net/"><a href="https://www.lartu.net/" target="_blank">https://www.lartu.net/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Lartu&quot;}">Lartu</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Personal server and open source repository&quot;}">Personal server and open source repository</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:33}">33</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://cometpustoj.neocities.org/&quot;}" data-sheets-hyperlink="https://cometpustoj.neocities.org/"><a href="https://cometpustoj.neocities.org/" target="_blank">https://cometpustoj.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Comet Pustój&quot;}">Comet Pustój</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;As I fly by your nebula, I write space poetry and send zines to earth.&quot;}">As I fly by your nebula, I write space poetry and send zines to earth.</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:34}">34</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;lata.neocities.org&quot;}" data-sheets-hyperlink="http://lata.neocities.org/"><a href="http://lata.neocities.org/" target="_blank">lata.neocities.org</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;lata&quot;}">lata</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;lata’s digital artworks&quot;}">lata’s digital artworks</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:35}">35</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://domushen.neocities.org/&quot;}" data-sheets-hyperlink="https://domushen.neocities.org/"><a href="https://domushen.neocities.org/" target="_blank">https://domushen.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;domushen&quot;}">domushen</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;rumored page of the elite cyber-lackey \&quot;\&quot;domushen\&quot;\&quot;&quot;}">rumored page of the elite cyber-lackey ""domushen""</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:36}">36</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://www.lander.blue/&quot;}" data-sheets-hyperlink="https://www.lander.blue/"><a href="https://www.lander.blue/" target="_blank">https://www.lander.blue/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;matt bluelander&quot;}">matt bluelander</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Toons, games, characters, download, store, e-mail&quot;}">Toons, games, characters, download, store, e-mail</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:37}">37</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://zassoken.com/Hakurikikomugiko/&quot;}" data-sheets-hyperlink="https://zassoken.com/Hakurikikomugiko/"><a href="https://zassoken.com/Hakurikikomugiko/" target="_blank">https://zassoken.com/Hakurikikomugiko/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Zassoken&quot;}">Zassoken</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Music collective based in Fukuoka, Japan&quot;}">Music collective based in Fukuoka, Japan</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:38}">38</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://dyremyhr.no&quot;}" data-sheets-hyperlink="https://dyremyhr.no/"><a href="https://dyremyhr.no/" target="_blank">https://dyremyhr.no</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Mats&quot;}">Mats</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;El Cybre $pace&quot;}">El Cybre $pace</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:39}">39</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://garakwasatailor.neocities.org/&quot;}" data-sheets-hyperlink="https://garakwasatailor.neocities.org/"><a href="https://garakwasatailor.neocities.org/" target="_blank">https://garakwasatailor.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Alexis Ong&quot;}">Alexis Ong</td>
<td>Writings on games, internet culture and tech.</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:40}">40</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://astoundingteam.com/wordpress/&quot;}" data-sheets-hyperlink="https://astoundingteam.com/wordpress/"><a href="https://astoundingteam.com/wordpress/" target="_blank">https://astoundingteam.com/wordpress/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;In Defense of Anagorism&quot;}">In Defense of Anagorism</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;blogging on political economy in the non-market, non-state sector&quot;}">blogging on political economy in the non-market, non-state sector</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:41}">41</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://everest-pipkin.com/&quot;}" data-sheets-hyperlink="http://everest-pipkin.com/"><a href="http://everest-pipkin.com/" target="_blank">http://everest-pipkin.com/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Everest Pipkin&quot;}">Everest Pipkin</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;a portfolio of games, experimental software, drawings, and other projects&quot;}">a portfolio of games, experimental software, drawings, and other projects</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:42}">42</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://emilyinternet.zone/&quot;}" data-sheets-hyperlink="https://emilyinternet.zone/"><a href="https://emilyinternet.zone/" target="_blank">https://emilyinternet.zone/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;emily&quot;}">emily</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;site for games, animation and legos!&quot;}">site for games, animation and legos!</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:43}">43</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://www.distinctly.pink/&quot;}" data-sheets-hyperlink="http://www.distinctly.pink/"><a href="http://www.distinctly.pink/" target="_blank">http://www.distinctly.pink/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;noah's home&quot;}">noah's home</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;all the things that noah did&quot;}">all the things that noah did</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:44}">44</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://e-vil.net/&quot;}" data-sheets-hyperlink="https://e-vil.net/"><a href="https://e-vil.net/" target="_blank">https://e-vil.net/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;J&quot;}">J</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;an evil homepage&quot;}">an evil homepage</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:45}">45</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://quartzosc-chip.neocities.org/&quot;}" data-sheets-hyperlink="https://quartzosc-chip.neocities.org/mainpage.html"><a href="https://quartzosc-chip.neocities.org/mainpage.html" target="_blank">https://quartzosc-chip.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;quartz&quot;}">quartz</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;cloudy music/personal blog, dna rain 4ever&quot;}">cloudy music/personal blog, dna rain 4ever</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:46}">46</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;http://tinybird.info/&quot;}" data-sheets-hyperlink="http://tinybird.info/"><a href="http://tinybird.info/" target="_blank">http://tinybird.info/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Max Bradbury&quot;}">Max Bradbury</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;creative works and musings on software, games, art and socialism&quot;}">creative works and musings on software, games, art and socialism</td>
</tr>
<tr>
<td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:47}">47</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;https://metaparadox.neocities.org/&quot;}" data-sheets-hyperlink="https://metaparadox.neocities.org/"><a href="https://metaparadox.neocities.org/" target="_blank">https://metaparadox.neocities.org/</a></td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Olivia Montoya&quot;}">Olivia Montoya</td>
<td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;A nostalgic website in the style of the mid-00s internet, with zines and indie games&quot;}">A nostalgic website in the style of the mid-00s internet, with zines and indie games</td>
</tr>
</div></div>]]>
            </description>
            <link>https://emreed.net/LowTech_Directory.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194202</guid>
            <pubDate>Tue, 24 Nov 2020 01:29:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A fully public domain, highly portable first person shooter running on 32kb RAM]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25193953">thread link</a>) | @ClawsOnPaws
<br/>
November 23, 2020 | https://drummyfish.gitlab.io/anarch/ | <a href="https://web.archive.org/web/*/https://drummyfish.gitlab.io/anarch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://drummyfish.gitlab.io/anarch"><img src="https://drummyfish.gitlab.io/anarch/media/logo_big.png" alt="logo"></a>

    <span><i>suckless, anticapitalist, public domain game for everyone</i></span>

    

    <span><a href="https://drummyfish.itch.io/anarch">itch.io</a></span>

    <dl>
      <dt> <a href="https://forum.freegamedev.net/viewtopic.php?f=22&amp;t=14771#p95387">Easily the most plain and boring FPS I've ever played.</a> </dt> <dd> Onpon4, libre game developer </dd>
      <dt> <a href="https://talk.pokitto.com/t/anarch-doom-clone-fps/2008/70">Technically the most impressive game on Pokito yet.</a> </dt> <dd> Jonne, the creator of Pokitto </dd>
      <dt> <a href="https://archive.li/tFWrL#84%">Kill yourself.</a> </dt> <dd> Anonymous on 4chan </dd>
    </dl>

    <span>THIS IS SPECIAL</span>

    <ul>
      <li>needs only <b>200 KB</b>, <b>32 KB RAM</b>, <b>40 MHz CPU</b>!</li>
      <li><b>suckless</b>, pure C, <b>no dependencies</b>, no FPU, GPU or file I/O needed</li>
      <li>10 levels, 6 weapons, 7 enemy types, 3 ammo types</li>
      <li>varying floor/ceiling oldschool SW ray casting engine with mouse support</li>
      <li><b>100% public domain</b> CC0 free software and culture</li>
      <li>100% original work, no third party assets</li>
      <li>well documented, hackable, <b>extremely portable</b></li>
      <li>completely <b>gratis</b>, without ads, DRM or similar bullshit</li>
    </ul>

    <p>
      This isn't a 90s style retro shooter, this <b>is</b> a 90s shooter.
    </p>

    <p>
      This game runs everywhere and adheres to great <a href="https://suckless.org/">simplicity</a>.
      It is much more efficient and portable than Doom and has completely
      <b>no dependencies</b>. Not even floating point is used, in case your
      computer doesn't have the HW unit. The game can fit into <b>200 KB</b>
      (including assets!) and can run with just <b>32 KB RAM</b>. No build system,
      library, internet connection or package manager is inherently required for
      compilation as the whole game is written in pure C language.
    </p>

    <p>
      This is an experiment and art that categorically rejects capitalist
      technology.
    </p>
 
   <img src="https://drummyfish.gitlab.io/anarch/media/3screens.png" alt="screenshots">

    <span>MORE THAN A GAME</span>

    <p>
      This is not a mere entertainment or toy meant for killing time or pursuing
      low goals such as making profit or something to put on portfolio, this is
      much more. Anarch is completely <b>gratis and free as in freedom</b> and
      besides entertainment can also be used for education, research, hacking, media
      creation, as a benchmark, as a test, as an environment, as an engine, as
      a basis for something greater. You are not limited by anything, there are
      no conditions to agree to. Nothing is hidden, everything is allowed, no
      burdens are imposed. The best motivation for creating anything is only
      the <b>pure love of creation for its own sake</b>, unburdened by any other
      goal than creating something truly useful. 
    </p>

    <img src="https://upload.wikimedia.org/wikipedia/commons/8/83/Anarch_Devices.jpg" alt="screenshots">

    <span>NO ONE OWNS THIS</span>

    <p>
      Not even I, the creator, own any part of this game.
      I&nbsp;have purposefully created everything myself from scratch,
      including the engine, graphics, sounds, music, even the font and palette,
      so that I could eventually give up all my rights and
      dedicate this game fully and <b>completely to the public domain</b>,
      to you, my dear fellow human being. No one should be allowed to own
      information and art.
    </p>

    <p>
      I've done my best to ensure this is 100% free as in freedom software and
      culture, well understandable and documented. This isn't made for any
      profit. This is made out of <b>love</b>, for you and for the greater good.
    </p>

    <h2>Download</h2>

    <ul>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_linux64_sdl_elf_1-0?inline=false">GNU/Linux SDL</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_LQ_linux64_sdl_elf_1-0?inline=false">GNU/Linux SDL LQ</a></li>
      <li><a href="https://drummyfish.gitlab.io/anarch/bin/web/anarch.html">play in browser</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_pokitto_1-0.pop?inline=false">Pokitto</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_gbmeta_1-0.zip?inline=false">GB Meta</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_winshitxp_sdl_1-0.zip?inline=false">M$ Win$hit XP SDL</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/archive/master/anarch-master.zip">source code</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/tree/master/bin">more downloads</a></li>
    </ul>

    <h2>Explore</h2>

    <ul>
      <li><a href="https://gitlab.com/drummyfish/sucklessfps">source code</a></li>
      <li><a href="https://www.tastyfish.cz/">author's website</a></li>
      <li><a href="https://libregamewiki.org/Anarch">libre game wiki</a></li>
      <li><a href="">OGA assets</a></li>
    </ul>

    <h2><a href="https://gitlab.com/drummyfish/anarch#faq">FAQ in readme</a></h2>

    

  

</div>]]>
            </description>
            <link>https://drummyfish.gitlab.io/anarch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193953</guid>
            <pubDate>Tue, 24 Nov 2020 00:56:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An opinionated list of best practices for textual websites]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25193874">thread link</a>) | @Seirdy
<br/>
November 23, 2020 | https://seirdy.one/2020/11/23/website-best-practices.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2020/11/23/website-best-practices.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<p><em>The following applies to minimal websites that focus primarily on text. It does not
apply to websites that have a lot of non-textual content. It also does not apply to
websites that focus more on generating revenue or pleasing investors than being good
websites.</em></p>
<p>This is a “living document” that I add to as I receive feedback. See the
<a href="https://git.sr.ht/~seirdy/seirdy.one/log/master/content/posts/website-best-practices.md">changelog</a>.</p>
<p>I realize not everybody’s going to ditch the Web and switch to Gemini or Gopher today
(that’ll take, like, a month at the longest). Until that happens, here’s a
non-exhaustive, highly-opinionated list of best practices for websites that focus
primarily on text:</p>
<ul>
<li>Final page weight under 50kb without images, and under 200kb with images.</li>
<li>Works in Lynx, w3m, links (both graphics and text mode), Netsurf, and Dillo</li>
<li>Works with popular article-extractors (e.g.&nbsp;Readability) and HTML-to-Markdown
converters. This is a good way to verify that your site uses simple HTML and works
with most non-browser article readers (e.g.&nbsp;ebook converters, PDF exports).</li>
<li>No scripts or interactivity (preferably enforced at the CSP level)</li>
<li>No cookies</li>
<li>No animations</li>
<li>No fonts–local or remote–besides <code>sans-serif</code> and <code>monospace</code>. More on this
below.</li>
<li>No referrers</li>
<li>No requests after the page finishes loading</li>
<li>No 3rd-party resources (preferably enforced at the CSP level)</li>
<li>No lazy loading (more on this below)</li>
<li>No custom colors OR explicitly set the both foreground and background colors. More
on this below.</li>
<li>A maximum line length for readability</li>
<li>Server configured to support compression (gzip, optionally zstd as well). It’s a
free speed boost.</li>
<li>Supports dark mode via a CSS media feature and/or works with most “dark mode”
browser addons. More on this below.</li>
<li>A good score on Mozilla’s <a href="https://observatory.mozilla.org/">HTTP Observatory</a></li>
<li>Optimized images.</li>
<li>Maybe HTTP/2. There are some cases in which HTTP/2 can make things slower. Run some
tests to find out.</li>
</ul>
<p>I’d like to re-iterate yet another time that this only applies to websites that
primarily focus on text. If graphics, interactivity, etc. are an important part of
your website, less (possibly none) of this article applies.</p>
<p>Earlier revisions of this post generated some responses I thought I should address
below. Special thanks to the IRC and <a href="https://lobste.rs/s/akcw1m">Lobsters</a> users who
gave good feedback!</p>
<h2 id="about-fonts">About fonts</h2>
<p>If you <em>really</em> want, you could use <code>serif</code> instead of <code>sans-serif</code>, but serif fonts
tend to look worse on low-res monitors. Not every screen’s DPI has three digits.</p>
<p>To ship custom fonts is to assert that branding is more important than user choice.
That might very well be a reasonable thing to do; branding isn’t evil! It isn’t
<em>usually</em> the case for textual websites, though. Beyond basic layout and optionally
supporting dark mode, authors generally shouldn’t dictate the presentation of their
websites; that is the job of the user agent. Most websites are not important enough
to look completely different from the rest of the user’s system.</p>
<p>A personal example: I set my preferred fonts in my computer’s fontconfig settings.
Now every website that uses <code>sans-serif</code> will have my preferred font. Sites with
<code>sans-serif</code> blend into the users' systems instead of sticking out.</p>
<h3 id="but-most-users-dont-change-their-fonts">But most users don’t change their fonts…</h3>
<p>The “users don’t know better and need us to make decisions for them” mindset isn’t
without merits; however, in my opinion, it’s overused. Using system fonts doesn’t
make your website harder to use, but it does make it smaller and stick out less to
the subset of users who care enough about fonts to change them. This argument isn’t
about making software easier for non-technical users; it’s about branding by
asserting a personal preference.</p>
<h3 id="cant-users-globally-override-stylesheets-instead">Can’t users globally override stylesheets instead?</h3>
<p>It’s not a good idea to require users to automatically override website stylesheets.
Doing so would break websites that use fonts such as Font Awesome to display vector
icons. We shouldn’t have these users constantly battle with websites the same way
that many adblocking/script-blocking users (myself included) already do when there’s
a better option.</p>
<p>That being said, many users <em>do</em> actually override stylesheets. We shouldn’t
<em>require</em> them to do so, but we should keep our pages from breaking in case they do.
Pages following this article’s advice will probably work perfectly well in these
cases without any extra effort.</p>
<h3 id="but-wouldnt-that-allow-a-website-to-fingerprint-with-fonts">But wouldn’t that allow a website to fingerprint with fonts?</h3>
<p>I don’t know much about fingerprinting, except that you can’t do font enumeration
without JavaScript. Since text-based websites that follow these best-practices don’t
send requests after the page loads and have no scripts, fingerprinting via font
enumeration is a non-issue on those sites.</p>
<p>Other websites can still fingerprint via font enumeration using JavaScript. They
don’t need to stop at seeing what sans-serif maps to; they can see all the available
fonts on a user’s system, the user’s canvas fingerprint, window dimensions, etc. Some
of these can be mitigated with Firefox’s <code>privacy.resistFingerprinting</code> setting, but
that setting also understandably overrides user font preferences.</p>
<p>Ultimately, surveillance self-defense on the web is an arms race full of trade-offs.
If you want both privacy and customizability, the web is not the place to look; try
Gemini or Gopher instead.</p>
<h2 id="about-lazy-loading">About lazy loading</h2>
<p>For users on slow connections, lazy loading is often frustrating. I think I can speak
for some of these users: mobile data near my home has a number of “dead zones” with
abysmal download speeds, and my home’s Wi-Fi repeater setup occasionally results in
packet loss rates above 60% (!!).</p>
<p>Users on poor connections have better things to do than idly wait for pages to load.
They might open multiple links in background tabs to wait for them all to load at
once, or switch to another window/app and come back when loading finishes. They might
also open links while on a good connection before switching to a poor connection; I
know that I often open 10-20 links on Wi-Fi before going out for a walk in a
mobile-data dead-zone.</p>
<p>Unfortunately, pages with lazy loading don’t finish loading off-screen images in the
background. To load this content ahead of time, users need to switch to the loading
page and slowly scroll to the bottom to ensure that all the important content appears
on-screen and starts loading. Website owners shouldn’t expect users to have to jump
through these ridiculous hoops.</p>
<h3 id="wouldnt-this-be-solved-by-combining-lazy-loading-with-pre-loadingpre-fetching">Wouldn’t this be solved by combining lazy loading with pre-loading/pre-fetching?</h3>
<p>A large number of users with poor connections also have capped data, and would prefer
that pages don’t decide to predictively load content ahead-of-time for them. Some go
so far as to disable this behavior to avoid data overages. Savvy privacy-conscious
users also generally disable pre-loading because they don’t have reason to trust that
linked content doesn’t practice dark patterns like tracking without consent.</p>
<p>Users who click a link <em>choose</em> to load a full page. Loading pages that a user hasn’t
clicked on is making a choice for that user.</p>
<h3 id="cant-users-on-poor-connections-disable-images">Can’t users on poor connections disable images?</h3>
<p>I have two responses:</p>
<ol>
<li>If an image isn’t essential, you shouldn’t include it inline.</li>
<li>Yes, users could disable images. That’s <em>their</em> choice. If your page uses lazy
loading, you’ve effectively (and probably unintentionally) made that choice for a
large number of users.</li>
</ol>
<h2 id="about-custom-colors">About custom colors</h2>
<p>Some users' browsers set default page colors that aren’t black-on-white. For
instance, Linux users who enable GTK style overrides might default to having white
text on a dark background. Websites that explicitly set foreground colors but leave
the default background color (or vice-versa) end up being difficult to read. Here’s
an example:</p>
<picture>
<source srcset="https://seirdy.one/misc/website_colors.webp" type="image/webp">
<img src="https://seirdy.one/misc/website_colors.png" alt="This page with a grey background, a header with unreadable black/grey text, and unreadable white-on-white code snippets">
</picture>
<p>If you do explicitly set colors, please also include a dark theme using a media
query: <code>@media (prefers-color-scheme: dark)</code>. For more info, read the relevant docs
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme">on
MDN</a></p>
<h2 id="image-optimization">Image optimization</h2>
<p>Some image optimization tools I use:</p>
<ul>
<li><a href="http://pngquant.org/">pngquant</a> (lossy)</li>
<li><a href="https://github.com/shssoichiro/oxipng">Oxipng</a> (lossless)</li>
<li><a href="https://github.com/tjko/jpegoptim">jpegoptim</a> (lossless or lossy)</li>
<li><a href="https://developers.google.com/speed/webp/docs/cwebp">cwebp</a> (lossless or lossy)</li>
</ul>
<p>I put together a <a href="https://git.sr.ht/~seirdy/dotfiles/tree/3b722a843f3945a1bdf98672e09786f0213ec6f6/Executables/shell-scripts/bin/optimize-image">quick
script</a>
to losslessly optimize images using these programs in my dotfile repo.</p>
<p>You also might want to use the HTML <code>&lt;picture&gt;</code> element, using JPEG/PNG as a fallback
for more efficient formats such as WebP or AVIF. More info in the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture">MDN
docs</a></p>
<p>Most of my images will probably be screenshots that start as PNGs. My typical flow:</p>
<ol>
<li>Lossy compression with <code>pngquant</code></li>
<li>Losslessly optimize the result with <code>oxipng</code> and its Zopfli backend (slow)</li>
<li>Also create a lossless WebP from the lossy PNG, using <code>cwebp</code></li>
<li>Include the resulting WebP in the page, with a fallback to the PNG using a <code>&lt;picture&gt;</code> element.</li>
</ol>
<p>It might seem odd to create a lossless WebP from a lossy PNG, but I’ve found that it’s the best way to get the smallest possible image at the minimum acceptable quality for screenshots with solid backgrounds.</p>
<h2 id="other-places-to-check-out">Other places to check out</h2>
<p>The <a href="https://250kb.club/">250kb club</a> gathers websites at or under 250kb, and also
rewards websites that have a high ratio of content size to total size.</p>
<p>Also see <a href="https://motherfuckingwebsite.com/">Motherfucking Website</a>. Motherfucking
Website inspired several unofficial sequels that tried to gently improve upon it. My
favorite is <a href="https://bestmotherfucking.website/">Best Motherfucking Website</a>.</p>
</article></div>]]>
            </description>
            <link>https://seirdy.one/2020/11/23/website-best-practices.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193874</guid>
            <pubDate>Tue, 24 Nov 2020 00:45:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MMU Virtualization via Intel EPT: Technical Details]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25193736">thread link</a>) | @todsacerdoti
<br/>
November 23, 2020 | https://revers.engineering/mmu-ept-technical-details/ | <a href="https://web.archive.org/web/*/https://revers.engineering/mmu-ept-technical-details/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          
            
            
          <h2>Overview</h2>
<p>This article marks the first of 5 articles covering the virtualization of the <a href="https://whatis.techtarget.com/definition/memory-management-unit-MMU"><strong>memory management unit</strong></a> (MMU) using Intel EPT. This technology is used as additional support for the virtualization of physical memory and allows hypervisors to monitor memory activity. In this article, we’ll address the motivation for extended page tables, the many performance concerns associated, and the different architectural components associated with <a href="https://compas.cs.stonybrook.edu%2F~nhonarmand%2Fcourses%2Fsp17%2Fcse506%2Fslides%2fmmu_virtualization.pdf"><strong>MMU virtualization</strong></a>. The components will be covered in some detail, but the majority of information about the various components will be found in the <a href="https://software.intel.com/content/www/us/en/develop/download/intel-64-and-ia-32-architectures-sdm-combined-volumes-1-2a-2b-2c-2d-3a-3b-3c-3d-and-4.html"><strong>Intel SDM</strong></a>. We will not be discussing anything OS-specific in this article – just the architectural details necessary to understand for proper implementation.</p>
<div>
<p><i> </i> <strong>Disclaimer</strong></p>
<p>It’s important that readers should have a foundational knowledge of virtual memory, paging, address translation, and page tables. This can be found in <a href="https://software.intel.com/content/www/us/en/develop/articles/intel-sdm.html"><strong><span><span>§</span></span>4.1.0 V-3A Intel SDM</strong></a>.</p>
</div>
<h2>Memory and the MMU</h2>
<p>In this rundown, we’re going to cover some important concepts as they related to the memory management unit and paging. This is by no means a full discourse on paging and virtual memory for the Intel architecture, but more of an abstract overview to help you connect the dots a little better.</p>
<h4>— Physical and Virtual Memory</h4>
<p><a href="https://en.wikibooks.org/wiki/Operating_System_Design/Physical_Memory"><strong>Physical memory</strong></a> exists on physical cards like DIMM modules and storage devices like hard-disks. If you’re familiar with fundamental concepts in computer science then you may recall that before any process can be executed it must be mapped into physical memory. Now, on modern systems, there is a secondary memory storage space called <a href="https://en.wikibooks.org/wiki/Operating_System_Design/Virtual"><strong>virtual memory</strong></a>. In a perfect world, data required to run programs would be mapped directly into RAM where it can be accessed quickly by the processor. Sadly, we don’t live in a perfect world, and the system’s main memory can become full. Enter stage right, <a href="https://en.wikibooks.org/wiki/Operating_System_Design/Virtual"><strong>virtual memory</strong></a>. The secondary form of memory utilizes a storage device like a hard drive to free up space in physical memory. But, we’re not concerned with virtual memory for the time being. When setting up EPT we need to know some important details about physical memory, first and foremost.</p>
<p>When a computer begins its boot sequence the code executing on the bootstrapping processor is able to access physical memory directly. This is because the processor is operating in what is called <a href="https://en.wikipedia.org/wiki/Real_mode"><strong>real address mode</strong></a> which was aptly named since addresses in <a href="https://en.wikipedia.org/wiki/Real_mode"><strong>real-mode</strong></a> correspond to their physical memory addresses. There is also a number of physical memory ranges available for use by the OS/bootloader, at this point. If we were to breakpoint a system and dump the physical memory ranges present we’d be able to see what’s called the <a href="https://en.wikipedia.org/wiki/Memory_map"><strong>system memory map</strong></a>. I did just that and wanted to explain some of the different things that are relevant to this series. Below is an image of the physical memory ranges when my breakpoint prior to <code>MmInitSystem</code> was hit.</p>
<p><img loading="lazy" src="https://i0.wp.com/revers.engineering/wp-content/uploads/2020/11/windbg_8aRBTuXRKa.png?resize=346%2C164&amp;ssl=1" alt="" width="346" height="164" srcset="https://i0.wp.com/revers.engineering/wp-content/uploads/2020/11/windbg_8aRBTuXRKa.png?w=346&amp;ssl=1 346w, https://i0.wp.com/revers.engineering/wp-content/uploads/2020/11/windbg_8aRBTuXRKa.png?resize=300%2C142&amp;ssl=1 300w" sizes="(max-width: 346px) 100vw, 346px" data-recalc-dims="1"></p>
<p>The image shows the physical memory ranges and their size. The first range from <code>1000h-A0000h</code> is available as general DRAM for OS consumption. This range of memory is also called low-memory – sometimes DOS compatibility memory. So, what’s the purpose of this drivel? Well, during the boot sequence the BIOS does a number of things, but the most relevant thing to this series is applying the different caching behaviors to physical memory ranges. The BIOS programs something called a <a href="https://en.wikipedia.org/wiki/Memory_type_range_register"><strong>memory-type range register</strong></a> (MTRR) to achieve this. These are a set of control registers that give the system control over how specific memory ranges are cached. The details of the caching requirements vary from system to system. For the sake of example, the physical memory range <code>1000h-9FFFFh</code> is typically programmed to be <a href="https://www.geeksforgeeks.org/write-through-and-write-back-in-cache/"><strong>write-back</strong></a>. Whereas the range <code>A0000h-BFFFFh</code> is <strong><a href="https://en.wikipedia.org/wiki/Write_combining">write-combined</a></strong> or <strong><a href="https://groups.google.com/forum/#!msg/microsoft.public.windowsce.embedded/lYFGz_8C3xg/_wVbles8tWEJ">uncached</a></strong>.</p>
<p>If you’re wondering how MTRRs are relevant, don’t worry. We’ll get to that…</p>
<h4><strong><span><span><b>𝛿</b></span></span></strong> Memory Type Range Register (MTRR)</h4>
<p>So, physical memory is divided into ranges and each range has its own cache-control policy applied during system initialization. Why is this important? For starters, applying the proper caching policies to memory regions is vital to ensure that system performance doesn’t go down the toilet. If a frequently accessed region of memory is set to be <a href="https://groups.google.com/forum/#!msg/microsoft.public.windowsce.embedded/lYFGz_8C3xg/_wVbles8tWEJ"><strong>uncached</strong></a> then frequent data fetches will degrade system performance significantly. This would happen because applications typically access data with high measures of locality. If data isn’t present in a cache then the CPU will have to reach out to main memory to acquire it – reaching out to main memory is slow! This is important because when allocating memory and initializing <a href="https://www.anandtech.com/show/2480/10"><strong>EPT</strong></a> we’ll have to build what’s called an <strong><a href="https://www.kernel.org/doc/html/latest/x86/mtrr.html">MTRR map</a></strong>. Fortunately for us, there is already an <a href="https://www.kernel.org/doc/html/latest/x86/mtrr.html"><strong>MTRR map</strong></a> of the current physical memory regions that we can use as a reference.</p>
<p><img loading="lazy" src="https://i0.wp.com/revers.engineering/wp-content/uploads/2020/11/AcroRd32_Z2n3tVLL9m.png?resize=599%2C192&amp;ssl=1" alt="" width="599" height="192" srcset="https://i0.wp.com/revers.engineering/wp-content/uploads/2020/11/AcroRd32_Z2n3tVLL9m.png?w=599&amp;ssl=1 599w, https://i0.wp.com/revers.engineering/wp-content/uploads/2020/11/AcroRd32_Z2n3tVLL9m.png?resize=300%2C96&amp;ssl=1 300w" sizes="(max-width: 599px) 100vw, 599px" data-recalc-dims="1"></p>
<p><span>Figure 0. MTRR encoding table (Intel SDM)</span></p>
<p><img loading="lazy" src="https://i1.wp.com/revers.engineering/wp-content/uploads/2020/11/windbg_Sgn3QpgXBY.png?resize=518%2C302&amp;ssl=1" alt="" width="518" height="302" srcset="https://i1.wp.com/revers.engineering/wp-content/uploads/2020/11/windbg_Sgn3QpgXBY.png?w=518&amp;ssl=1 518w, https://i1.wp.com/revers.engineering/wp-content/uploads/2020/11/windbg_Sgn3QpgXBY.png?resize=300%2C175&amp;ssl=1 300w" sizes="(max-width: 518px) 100vw, 518px" data-recalc-dims="1"></p>
<p><span>Figure 1. MTRR map on physical machine.</span></p>
<p>From the image, you might notice the ranges are quite specific – this is due to Windows using <strong><a href="https://xem.github.io/minix86/manual/intel-x86-and-64-manual-vol3/o_fe12b1e2a880e0ce-435.html">fixed-range MTRRs</a></strong> and some <strong><a href="https://xem.github.io/minix86/manual/intel-x86-and-64-manual-vol3/o_fe12b1e2a880e0ce-434.html">variable-range MTRRs</a></strong>. Armed with this information, it’s clear that applying the appropriate caching policy to our extended page tables during initialization is imperative to preserving system performance. No need to worry either, modifying and creating an <a href="https://wiki.gentoo.org/wiki/MTRR_and_PAT"><strong>MTRR map</strong></a> for our VM is straightforward. We’ll go into more detail in the next article when we build our <strong><a href="https://sites.utexas.edu/jdm4372/tag/mtrr/">MTRR map</a></strong>. See the recommended reading if you’re eager to get ahead. With this addressed, let’s talk about the purpose of the MMU and page tables.</p>
<div>
<p><i> </i> <strong>Page Attribute Table</strong></p>
<p>In addition to MTRRs, there is an additional cache-control called the <strong>Page Attribute Table</strong> (PAT) that is primarily used by the OS to control caching policies at a finer granularity (page level). This cache control is detailed more in the next article.</p>
</div>
<h4>— The MMU</h4>
<p>Most modern processors come with a <a href="https://whatis.techtarget.com/definition/memory-management-unit-MMU"><strong>memory management unit</strong></a> (MMU) implemented which provides access protection and virtual-to-physical address translation. A virtual address is, simply put, an address that software uses; a physical address is an address that hardware outputs on the address lines of the data bus. Intel architectures divide virtual memory into 4KB <a href="https://en.wikipedia.org/wiki/Page_(computer_memory)"><strong>pages</strong></a> (with support for other sizes) and physical memory into 4KB <a href="https://cs.stackexchange.com/questions/11667/what-is-the-difference-between-a-page-of-memory-and-a-frame-of-memory"><strong>frames</strong></a>. An MMU will typically contain a <a href="https://www.sciencedirect.com/topics/computer-science/translation-lookaside-buffer"><strong>translation lookaside buffer</strong></a> (TLB) and will perform operations on the page table such as hardware table walks. Some MMU architectures won’t perform those operations. This is done to give the OS the freedom to implement its page table in whatever manner it desires. The <a href="https://en.wikipedia.org/wiki/Memory_management_unit"><strong>MMU architecture</strong></a> specifies certain caching policies for the instruction and data cache whether identifying code as cacheable or non-cacheable, or write-back and write-through data caching. These policies may also cover caching access rights.</p>
<div>
<p><i> </i> <strong>MMU Split</strong></p>
<p>In certain processors, the MMU can be split into an <strong>Instruction Memory Management Unit</strong> (IMMU) and <strong>Data Memory Management Unit</strong> (DMMU). The first is activated with instruction fetches and the latter with memory operations.</p>
</div>
<p>The MMU architecture for the <a href="https://www.intel.com/content/www/us/en/architecture-and-technology/microarchitecture/intel-64-architecture-general.html"><strong>Intel64 architecture</strong></a> provides a physical address space that covers <span><span>16-EiB</span></span>. However, only 2^57 units are addressable in current architectures with the new page table structure. That’s still ~128-PiB of address space available. The short and “simple” for how an MMU works is this – the MMU gets a virtual address and uses it to index into a table (TLB or page tables.) These entries in the table provide a physical address plus some control signals that may include the caching policy, whether the entry is valid, invalid, protected, and so on. It may also receive signals as to whether the memory referenced by the entry was accessed/modified. If the entry is valid then the virtual address is translated into the physical address; the MMU will then use information from the control signals to determine what type of memory transaction is occurring. These tables mentioned are similar to a directory structure. The MMU will traverse the page tables to translate the virtual address to the physical address. Now on x86-64 architecture, the MMU maps memory through a series of tables – 4 or 5 depending on software requirements.</p>

<p><img loading="lazy" src="https://i2.wp.com/revers.engineering/wp-content/uploads/2020/11/address_translation.png?resize=511%2C294&amp;ssl=1" alt="" width="511" height="294" srcset="https://i2.wp.com/revers.engineering/wp-content/uploads/2020/11/address_translation.png?w=511&amp;ssl=1 511w, https://i2.wp.com/revers.engineering/wp-content/uploads/2020/11/address_translation.png?resize=300%2C173&amp;ssl=1 300w" sizes="(max-width: 511px) 100vw, 511px" data-recalc-dims="1"></p>
<p><span>Figure 1. Simplified diagram of address translation.</span></p>

<p>We’ll cover a bit about TLBs and their role in a virtualization context later. Since we know the purpose of the MMU now let’s talk start talking about Intel’s EPT.</p>
<h2>Extended Page Tables (EPT)</h2>
<p>Intel’s <a href="https://en.wikipedia.org/wiki/Second_Level_Address_Translation"><strong>Extended Page Table</strong></a> (EPT) technology, also referred to as <a href="https://en.wikipedia.org/wiki/Second_Level_Address_Translation"><strong>Secondary Level Address Translation</strong></a> (SLAT), allows a VMM to configure a mapping between the physical memory as it is perceived by the guest and the real physical memory. It’s similar to the virtual page table in that EPT enables the hypervisor to specify <a href="https://www.sciencedirect.com/topics/computer-science/page-table-entry"><strong>access rights</strong></a> for a guest’s physical pages. This allows the hypervisor to generate an event called an EPT violation when a guest attempts to access a page that is either invalid or doesn’t have appropriate access rights. This <a href="https://xem.github.io/minix86/manual/intel-x86-and-64-manual-vol3/o_fe12b1e2a880e0ce-1127.html"><strong>EPT violation</strong></a> is one of the events we’ll be taking advantage of throughout this series since it triggers a VM-exit.</p>
<div>
<p><i> </i> <strong>Important Note</strong></p>
<p>Virtualization of the IOMMU is performed by a complementary technology to EPT called VT-d. This won’t be covered in this series.</p>
</div>
<p>This technology is extraordinarily useful. For instance, one can utilize EPT to protect the hypervisor’s code and data from malicious code attempting to modify it. This would be done by setting the access rights to the VMM’s code and data to read-only. In addition to that, if a VMM were to be used to whitelist certain applications it could modify the access rights of the remaining physical address space to write-only. This would force a VM-exit on any execution to allow the hypervisor to validate the faulting page. Just a fun thought experiment.</p>
<p>Enough about the potential, let’s get into the motivations for EPT and address the other various components associated…</p>
<h4>— Motivation</h4>
<p>One of the main …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://revers.engineering/mmu-ept-technical-details/">https://revers.engineering/mmu-ept-technical-details/</a></em></p>]]>
            </description>
            <link>https://revers.engineering/mmu-ept-technical-details/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193736</guid>
            <pubDate>Tue, 24 Nov 2020 00:29:37 GMT</pubDate>
        </item>
    </channel>
</rss>
