<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 15 Dec 2020 08:37:02 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 15 Dec 2020 08:37:02 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Goodreads plans to retire API access, disables existing API keys]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25405737">thread link</a>) | @buttscicles
<br/>
December 13, 2020 | https://joealcorn.co.uk/blog/2020/goodreads-retiring-API | <a href="https://web.archive.org/web/*/https://joealcorn.co.uk/blog/2020/goodreads-retiring-API">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      
<!-- site-header -->


      <div>
        <article>

  

  <div>
    <p>In news that surprises nobody, Goodreads last week quietly announced the deprecation of their public APIs. And I mean really quietly – the only people who were told about this were those unfortunate enough to have their existing <a href="https://blog.stephanieawilkinson.com/posts/2020-12-10-yonderbook-and-goodreads/" target="_blank" rel="noopener noreferrer">API keys disabled</a> without warning. Other than a small banner at the top of the API docs which mentions vague “plans to retire these tools”, nobody else appears to have heard anything from Goodreads, including those whose API keys remain active. So far it seems any key unused for 30 days has been disabled.</p>

<p><img src="https://joealcorn.co.uk/assets/img/posts/2020/12/deprecated.png" alt="Deprecation notice on Goodreads API documentation"></p>

<p>So this is an “announcement” much in the way a windshield announces its presence to bugs on a highway, and with the same consequences: dead bugs. Some developers have taken to the <a href="https://www.goodreads.com/topic/show/21788520-api-deprecation" target="_blank" rel="noopener noreferrer">API discussion boards</a> and blogs, but the overall impression I’m getting is grim acceptance. Really the surprising thing is how long it took them: Amazon has been in charge at Goodreads for almost 8 years now, and I think we’ve all been expecting this to come at some point.</p>

<p>So why now? What’s changed? Well, the fact is the market’s changing – and Goodreads isn’t. Alternative options are starting to emerge, and since Goodreads has forgotten how to innovate, it wants to use its market position to stifle innovation instead.</p>

<p>The sad thing is it really only hurts the hobbyist projects and Goodreads users themselves. Anybody seriously attempting to compete with Goodreads is well aware of the Amazon-shaped elephant in the room and is likely prepared. It’s the users and the hackers that this move will harm, and if anything it further reinforces the need for viable alternatives.</p>

<p>Personally I’m going to continue pouring my efforts into building <a href="https://beta.readng.co/?utm_source=joealcorn.co.uk" target="_blank" rel="noopener noreferrer">readng</a>. I’m already using it to keep track of my reads &amp; collections, along with a few thousand beta testers. I’m really excited by our plans and think we have the right team to execute, but we also need a shift in consumer behaviour.</p>

<p>The web has to mature beyond advertising as a business model. For this to happen people are going to have to open their wallets, pay for the services they use, and support independent businesses. That’s how we build a web where indies can thrive - one that’s more village centre than financial centre. I think the shift is underway.</p>


<hr>

<p>PS: <a href="https://beta.readng.co/user/joe?utm_source=joealcorn.co.uk" target="_blank" rel="noopener noreferrer">here’s my own readng profile</a>. You should probably use our Goodreads importer while our API key works, huh?</p>

  </div>

</article>













      </div>
      <!-- site-content -->

      
<!-- site-footer -->



<!-- <script src="/assets/js/main.js"></script> -->



<!-- Fathom - simple website analytics - https://github.com/usefathom/fathom -->

<!-- / Fathom -->
  <!-- / Fathom -->


    </div></div>]]>
            </description>
            <link>https://joealcorn.co.uk/blog/2020/goodreads-retiring-API</link>
            <guid isPermaLink="false">hacker-news-small-sites-25405737</guid>
            <pubDate>Sun, 13 Dec 2020 11:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Radicle Model for Code Collaboration]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25405727">thread link</a>) | @lftherios
<br/>
December 13, 2020 | http://eleftherios.io/the-radicle-social-model/ | <a href="https://web.archive.org/web/*/http://eleftherios.io/the-radicle-social-model/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://eleftherios.io/the-radicle-social-model/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25405727</guid>
            <pubDate>Sun, 13 Dec 2020 11:05:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Hacked Google's Bug Tracker to Claim a Google.com Email Address]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25405667">thread link</a>) | @hackerpain
<br/>
December 13, 2020 | https://www.andmp.com/2018/12/how-i-managed-to-get-google.html | <a href="https://web.archive.org/web/*/https://www.andmp.com/2018/12/how-i-managed-to-get-google.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<div id="post-body-5293827933826703807" itemprop="articleBody">
<meta content="   The Google Bug Tracker helps them(Google) in tracking through different bugs and security issues, but Gopal, a highly skilled security re..." name="twitter:description">
<div dir="ltr" trbidi="on">
<div id="760c" name="760c">
<p><i>The Google Bug Tracker helps them(Google) in tracking through different bugs and security issues, but Gopal, a highly skilled security researcher managed to leverage and pilferage Google through its own issue tracker, isn't it quite creative? A defensive mechanism, since the same tool is used to track and patch security issues was implemented to pervade through Google's protection.</i></p>

<p>
&nbsp;Every organisation have bug trackers, in fact, for example most companies use external ones like Jira bug tracker to track and resolve bugs, so what makes Google's case unique in particular is their custom tailored Issue Tracker and it's features. Security researcher <a href="https://twitter.com/gopalsinghcse" target="_blank">Gopal </a>discovered that although Google had in the past attempted to fix several security issues in their Bug Tracker, yet, it was unsafe and indeed his firm conviction led to him finding a different issue, that can be called a regression but nevertheless, he bypassed Google's previous fix proving the fact - No system can be made "secure" (completely), no matter what amount of patches you make, this again shows the need for bug bounties to motivate and attract highly talented talented individuals as Gopal, and also motivates security researchers to use offensive methods as the one mentioned in this case, and keep trying harder to circumvent all security measures kept in place, even previous patches.</p>

<p>
------------------------------------------------------</p>

<h2>
<span><span>How I managed to get a Google organisation email, bypassing their previous patch!</span></span></h2>
</div>
<p>
I came across this <a href="https://medium.freecodecamp.org/messing-with-the-google-buganizer-system-for-15-600-in-bounties-58f86cc9f9a5" target="_blank">writeup</a> by&nbsp;<a data-action-type="hover" data-action-value="7fa68cbc850e" data-action="show-user-card" data-anchor-type="2" data-href="https://medium.com/@alex.birsan" data-user-id="7fa68cbc850e" href="https://medium.com/@alex.birsan" target="_blank">Alex</a>. I started testing the issue tracker, and I wanted to see if I could somehow manage to get an @google.com Account. In the issue tracker, I found the&nbsp;<i>browse components feature. </i>There&nbsp;were two public issue trackers, I clicked on Android Public Tracker</p>
<p>
Bugs reported to <i>Android </i>showed up here. To report a Bug in Android public issue tracker you may simply send an email to-</p>
<p><span>buganizer-system+</span><em>componentID</em><span>@google.com</span></p>
<p>
In this case, android’s component id is <b>190923</b>.</p>
<p>
The issue I made, got listed in the public issue tracker. I got a confirmation email from&nbsp;<span>buganizersystem+my_email@google.com&nbsp;</span>and hence, replies to the email would be directed to-</p>
<p><span>buganizer-system+</span><em>componentID</em><span><em>+</em></span><em>issueID</em><span>@google.com</span></p>
<p>
I replied to that email and comment was posted in the conversation. I can add google email to see if I can get a confirmation code, to test this I clicked on&nbsp;<a data-href="https://mail.google.com/mail/u/0/#settings/fwdandpop" href="https://mail.google.com/mail/u/0/#settings/fwdandpop" rel="noopener nofollow" target="_blank">Forwarding and POP/IMAP</a>&nbsp;in Gmail settings and added the google email to the forwarding email address. I was surprised to see I got a confirmation code in the Android public issue tracker.</p>
<p>
There are two parts here, to get a google account.&nbsp;<span>Signup</span>&nbsp;and&nbsp;<span>verification</span>. I can verify a google account, but I could not signup for a @google.com account so my report got closed as <i>Won’t Fix. Bummer!</i></p>
<figure id="aa11" name="aa11"><div>


</div>
</figure><figure id="272e" name="272e"><div>


</div>
</figure>
<p>
Then I started visiting every subdomain of Google to see if I could use google.com email to signup and this new signup page appeared.</p>
<figure id="98a9" name="98a9"><div>


</div>
</figure>
<p>
I could feel my heartbeats racing, after coming across this new signup page. I signed up using the bug…@google.com email and then it asked me to verify by entering the code.</p>
<h3 id="295b" name="295b">
Verifying The email&nbsp;address</h3>
<p>
I was waiting for the verification code in the conversation and then received the verification code in the mail.</p>
<figure id="85a3" name="85a3"><div>


</div>
</figure><figure id="bd07" name="bd07"><div>


</div>
</figure>
<p>
After successfully signing up for the Google Account, I reopened the issue.</p>
<p><span>Nice catch!</span></p>
<figure id="18b4" name="18b4"><div>


</div>
</figure>
<p>
Finally, at 9:50 PM that day, the most awaited email arrived&nbsp;<span>$3133.70</span>. I could not sleep the whole night.</p>
<figure id="d047" name="d047"><div>


</div>
</figure><figure id="e743" name="e743"><div>


</div>
</figure><br>
<h3 id="acdd" name="acdd">
<span>Video PoC</span></h3>
<p>
<iframe allowfullscreen="" data-thumbnail-src="https://i.ytimg.com/vi/d5LjoitHkIY/0.jpg" frameborder="0" height="266" src="https://www.youtube.com/embed/d5LjoitHkIY?feature=player_embedded" width="320"></iframe></p>
<figure id="cd60" name="cd60"><div>

</div>
</figure></div>
</div>
</article></div>]]>
            </description>
            <link>https://www.andmp.com/2018/12/how-i-managed-to-get-google.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25405667</guid>
            <pubDate>Sun, 13 Dec 2020 10:51:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell Object Observation Debugger]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25405447">thread link</a>) | @jpcooper
<br/>
December 13, 2020 | https://ku-fpg.github.io/software/hood/ | <a href="https://web.archive.org/web/*/https://ku-fpg.github.io/software/hood/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <div>
                    <div>
                        <div>
    <!--
                          This use of replace: does not feel right. See if you can use css for it
    -->
                        <div>

  

  <article>
  <p>Haskell Object Observation Debugger (HOOD) is a small post-mortem
debugger for the lazy functional language
<a href="http://www.haskell.org/">Haskell</a>. It is based on the concept of
observation of intermediate data structures, rather than the more
traditional stepping and variable examination paradigm used by
imperative language debuggers.</p>

<h2 id="features">Features</h2>

<ul>
  <li>Observation of base types (Int, Bool, Float, etc)</li>
  <li>Observation of both finite and infinite structures (Lists, trees,
arrays, etc).</li>
  <li>Observation of usage patterns for functions.</li>
  <li>Observation of monadic actions, including IO actions.</li>
  <li>Hooks to add observational capabilities for new base type and used
defined types.</li>
  <li>Programmable browsing capabilities - structure browsers can be coded
and plugged in.</li>
  <li>Includes a basic structure rendering package that uses a
Haskell-like syntax.</li>
  <li>Thread-safe observations are are supported.</li>
  <li>Supports observations on exceptions (on certain compilers).</li>
</ul>

<h2 id="examples">Examples</h2>

<p>Hood can observe data structures:</p>

<div><div><pre><code>main = runO ex2

ex2 = print
      . reverse
      . (observe "intermediate")
      . reverse
      $ [0..9]
</code></pre></div></div>

<p>Running this program gives this output:</p>

<div><div><pre><code>[0,1,2,3,4,5,6,7,8,9]

-- intermediate
  9 : 8 : 7 : 6 : 5 : 4 : 3 : 2 : 1 : 0 : []
</code></pre></div></div>

<p>Hood can also observe functions, showing both the arguments and result
of each call:</p>

<div><div><pre><code>main = runO ex9

ex9 = print $ observe "foldl (+) 0 [1..4]" foldl (+) 0 [1..4]
</code></pre></div></div>

<p>Running this program gives this output:</p>

<div><div><pre><code>10

-- foldl (+) 0 [1..4]
  { \ { \ 0 1  -&gt; 1
      , \ 1 2  -&gt; 3
      , \ 3 3  -&gt; 6
      , \ 6 4  -&gt; 10
      } 0 (1 : 2 : 3 : 4 : []) 
       -&gt; 10
  }
</code></pre></div></div>

<p>Note that Hood preserves the type and strictness properties of the
function under observation. If an argument is not examined in the
function, it remains unevaluated. As an example:</p>

<div><div><pre><code>ghci&gt; runO $ print $ observe "sum xs" (\ xs ys -&gt; sum xs) [0..2] [0..]
</code></pre></div></div>

<p>Notice that ys is left unevaluated (denoted by the underscore):</p>

<div><div><pre><code>3

-- sum xs
  { \ (0 : 1 : 2 : []) _  -&gt; 3
  }
</code></pre></div></div>

<h2 id="history">History</h2>

<p>Hood was developed at OGI, in 1999, for GHC 4.X. We are looking into a
debugging toolkit for Haskell and Lava, so we ported Hood to GHC 6.X,
and re-released it on hackage. We hope you find it useful.</p>

<h3 id="key-links">Key Links</h3>

<ul>
  <li><a href="http://hackage.haskell.org/package/hood">http://hackage.haskell.org/package/hood</a></li>
</ul>

<h3 id="hood-papers">HOOD Papers</h3>

<ul>
      
      
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
		<li><p>A. Gill, “<a href="https://ku-fpg.github.io/papers/Gill-00-HOOD">Debugging <span>H</span>askell by observing intermediate data
structures</a>,” in <span><em>Proceedings of the 2000 ACM SIGPLAN
<span>W</span>orkshop on Haskell, Technical report of the University of
Nottingham</em></span>, 2000.</p>
</li>
		
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
        
        
            
	        
	    
	
      
</ul>


  </article>

</div>

                        </div>
                    </div>
                </div>
            </div></div>]]>
            </description>
            <link>https://ku-fpg.github.io/software/hood/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25405447</guid>
            <pubDate>Sun, 13 Dec 2020 09:55:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: An anti-book recommendation tool (to help you escape your echo chamber)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25405259">thread link</a>) | @padolsey
<br/>
December 13, 2020 | https://abooklikefoo.com/escape/ | <a href="https://web.archive.org/web/*/https://abooklikefoo.com/escape/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app"><div><div><div><h3>Escape your literary echo chamber! ðŸ“š</h3><p><em>Break the Bubble</em> allows you to find out which books you are statistically <strong>unlikely</strong> to read. The more narrow your reading tastes are, the more you will be challenged by the results.</p><p>Start your search by entering a book you <strong><u>do</u></strong> like. You'll then be asked to enter a second book. Etc. The more books you add, the more accurate we can be in discovering these anti-correlations and odd new reading possibilities!</p><p>Try out these examples:</p><ul><li><a href="https://abooklikefoo.com/escape/?q=Ez4,L9pX,KJJ&amp;pop=p&amp;fnf=n&amp;period=a">Bubble-breakers for readers of Ayn Rand</a>.</li><li><a href="https://abooklikefoo.com/escape/?q=lNr,jNl,49O0&amp;pop=c&amp;fnf=a&amp;period=a">Bubble-breakers that are well-acclaimed for readers of Harry Potter</a>.</li><li><a href="https://abooklikefoo.com/escape/?q=VQV9,yyo6,7lQ,gxoY&amp;pop=b&amp;fnf=a">Bubble-breakers for readers of software engineering topics</a>.</li></ul><p><strong>How does it work?</strong>: Briefly, for each book entered we find the rarest but highest rated intersections and provide those to you. The query can be summarised as: which highly rated books are least read (and enjoyed) by people who've also read the books I have? To find out more about the recommendation engine generally, visit <a href="https://abooklikefoo.com/">the homepage</a>.</p><p><small>Note: this is an experimental feature of <a href="https://abooklikefoo.com/">A Book Like Foo</a> and was created by <a href="https://twitter.com/padolsey">James Padolsey</a>.</small></p></div><p>Your query is taking a while. ðŸ˜± Sorry about that, but it's not long now! We're leaving no book unturned in order to find you your perfect matches. ðŸ¤“</p></div></div></div></div>]]>
            </description>
            <link>https://abooklikefoo.com/escape/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25405259</guid>
            <pubDate>Sun, 13 Dec 2020 09:05:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Nano Editor – Prototype, build, and publish simple web apps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25404696">thread link</a>) | @ent101
<br/>
December 12, 2020 | https://www.outpan.com/app/543e836b6a/nano-editor | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/543e836b6a/nano-editor">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/543e836b6a-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>6</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login?ref=https://www.outpan.com/app/543e836b6a/nano-editor">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/543e836b6a/nano-editor</link>
            <guid isPermaLink="false">hacker-news-small-sites-25404696</guid>
            <pubDate>Sun, 13 Dec 2020 06:16:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Who Owns the Stars: The Trouble with Urbit]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25404575">thread link</a>) | @deegles
<br/>
December 12, 2020 | http://distributedweb.care/posts/who-owns-the-stars/ | <a href="https://web.archive.org/web/*/http://distributedweb.care/posts/who-owns-the-stars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <h2>
  <a href="http://distributedweb.care/">
    Distributed Web of Care
  </a>
  </h2>
  <section>
    
    

    <p>by Francis Tseng</p>

<p>The application that introduced peer-to-peer (P2P) computing to the mainstream was file sharing, services like Napster, Kazaa, Gnutella, and BitTorrent. For me, these programs were the first time the contradiction of artificial scarcity—the imposed scarcity of infinitely replicable digital information—and the excessive measures that were used to enforce it became startlingly clear. Over time, I encountered the term P2P in other settings and alongside other ideas—democratic governance, communalism, autonomy, cooperatives—and I started to see the purchase this idea had beyond file sharing and networking protocols.</p>

<p><a href="https://p2pfoundation.net/the-p2p-foundation/about-the-p2p-foundation">The P2P Foundation’s mission and strategic priorities</a>, for example, extend the early P2P ideas of open culture and exchange into values of cooperative living and regenerative production. <a href="https://www.scuttlebutt.nz/principles/">Scuttlebutt, a more recent P2P social networking protocol, has its own “principles stack”</a> that similarly advocates pluralistic exchange and mutual interdependence. It’s beautiful how, at least in the ideal scenario, by using a P2P service we are helping others access it as well. P2P is both an acknowledgment of our shared needs and an example of how cooperation helps us fulfill those needs.</p>

<p>Over the years, I’ve followed along with P2P projects because of these shared values, and I always find it exciting when new projects emerge. It seems that P2P is experiencing something of a renaissance, likely due to the frenzy around blockchain (which purports to offer something similar to P2P) and the increasing popular anxiety around centralized internet services like Facebook.</p>

<p>Urbit, “<a href="https://urbit.org/">a personal server built from scratch</a>,” first came across my radar a couple of years ago. Urbit positions itself as a P2P project, but it stands out in contrast to other P2P projects, mainly because the person behind it, Curtis Yarvin, seems antithetical to what I understand P2P to represent.</p>

<p>My central question is this: <em>Is Urbit a project that should be supported?</em></p>

<p>We can further break this down into two parts. First, Urbit’s marketing materials correctly identify that concentrated data aggregation and decision-making power are fundamental issues of the internet-as-we-know-it. Twitter’s persistent neglect of harassment on its platform is one everyday example. It is clear that new protocols and platforms that reduce our dependency on distant power are needed to challenge these issues. What’s less clear, though, is whether or not Urbit actually offers a meaningful alternative. Does Urbit genuinely enable new kinds of relations? Or, does it merely replace the old aristocracy with a new one?</p>

<p>The second, and more urgent, question is: who and what are we supporting by supporting Urbit? Many people in tech still believe that technology can be divorced from its creators; however, those of us in tech need to recognize that we have a considerable amount of influence over which products enter the mainstream consciousness, which products get created at all, and who receives both financial and social capital (shout out to <a href="https://techworkerscoalition.org/">Tech Workers Coalition</a> et al.). For example, consider Peter Thiel , who co-founded PayPal and was an early investor in Facebook. Early support of PayPal and Facebook contributed to their financial success, which developed Thiel’s influence and made him quite rich. Thiel then turned that money and influence into Palantir Technologies, a software company that <a href="https://theintercept.com/2017/03/02/palantir-provides-the-engine-for-donald-trumps-deportation-machine/">develops technologies to help expand surveillance and deportation for the government</a>. We have to consider what similar groundwork we help to lay by supporting Urbit.</p>

<h2 id="context">Context</h2>

<p>In order to discuss Urbit’s design, we need to have an understanding of the politics of its creator, Curtis Yarvin. <a href="https://en.wikipedia.org/wiki/Curtis_Yarvin">Curtis Yarvin</a> is innocuously described on Wikipedia as an “American political theorist and computer scientist,” but to many, he is better known as <a href="https://www.theatlantic.com/politics/archive/2017/02/behind-the-internets-dark-anti-democracy-movement/516243/">one of the intellectual forebears of the alt-right</a>. From 2007 to 2014<sup id="fnref:1"><a href="#fn:1">1</a></sup>, working under the pen name Mencius Moldbug, Yarvin writings, which among other things espoused anti-democratic ideas and scientific racism and helped introduce many of what are now understood as the alt-right’s foundational ideologies to a wider public. The term “red pill,” which describes the process of reactionary radicalization and the community around it, was first used in this way by Yarvin.<sup id="fnref:2"><a href="#fn:2">2</a></sup> Defenders of Urbit are quick to dismiss any inclusion of Yarvin’s politics in discussions about Urbit as unfair or irrelevant, and might point out that Yarvin left the project in January of this year.<sup id="fnref:3"><a href="#fn:3">3</a></sup> However, given that Yarvin basically laid out the general design for Urbit independently, as he worked on it alone for 11 years<sup id="fnref:3:1"><a href="#fn:3">3</a></sup> and in parallel with his political writings<sup id="fnref:4"><a href="#fn:4">4</a></sup>, and that Urbit, as a P2P project, is a fundamentally social and thus incorporates ideas about how people should be organized, Yarvin’s politics should be considered as something that influences his design decisions and his long-term vision for the project. <a href="https://lobste.rs/s/z5j1hq/urbit_2017#c_4z4gik">Dog-whistles</a> have been identified in some of his writing about Urbit and its design, including his <a href="https://urbit.org/posts/essays/the-dao-as-a-lesson-in-decentralized-governance/">leaning on Nazi philosopher Carl Schmitt</a> for questions around Urbit’s governance.</p>

<p>To save space I’ll provide only a very brief overview of Yarvin’s political philosophy—if you like, you can read more about it <a href="https://thebaffler.com/latest/mouthbreathing-machiavellis">here</a>, <a href="https://www.viewpointmag.com/2017/03/28/the-darkness-at-the-end-of-the-tunnel-artificial-intelligence-and-neoreaction/">here</a>, <a href="https://thebaffler.com/latest/the-moldbug-variations-pein">here</a>, and <a href="https://slatestarcodex.com/2013/10/20/the-anti-reactionary-faq/">here</a>.</p>

<p>Yavin refers to his brand of political philosophy as “neocameralism.” Neocameralism, as described in his essay “<a href="https://www.unqualified-reservations.org/2007/08/against-political-freedom/">Against Political Freedom</a>,” is a political philosophy arguing that state should be run like a business, (i.e., with a CEO at its head and no democratic mechanisms). His ideas are credited as being foundational to the “<a href="https://techcrunch.com/2013/11/22/geeks-for-monarchy/">neoreactionary” movement</a>, which could be described as a neo-monarchist movement (though Yarvin himself doesn’t identify as a “monarchist” because of its association with a constitutional monarchy and not absolute monarchy). In the neoreactionary movement, “divine right” is supplanted with “genetic right” based on scientific racism reframed as “human biodiversity.” Yarvin’s writings are also popular within the right-libertarian sects of Silicon Valley, such as <a href="https://thebaffler.com/latest/the-moldbug-variations-pein">with Peter Thiel</a> (<a href="https://www.theverge.com/2017/2/21/14671978/alt-right-mencius-moldbug-urbit-curtis-yarvin-tlon">Peter Thiel also has a stake in Tlön</a>, Yarvin’s company which develops Urbit, via Thiel’s VC firm, Founders Fund). The point here is that Yarvin is not a fringe philosopher. His writings have influence over people with considerable power and contributes to the intellectual miasma that emboldens and normalizes anti-democratic, anti-immigrant, misogynistic, and racist policies and attacks.</p>

<h2 id="urbit">Urbit</h2>
<h4 id="a-self-sovereign-internet">A self-sovereign internet</h4>

<p>Urbit positions itself as infrastructure for self-sovereignty in the digital age, liberating people from ceding control of their data to corporations.<sup id="fnref:5"><a href="#fn:5">5</a></sup> The core idea is that Urbit helps you run a personal server that acts as an intermediary between you and other services, including existing services like Facebook (yes, there is a lot more to Urbit—such as its reinvention of parts of the lower-level computational stack—but its P2P layer is what’s of interest here).</p>

<p>Self-sovereignty is an important principle, and I wager that many who regularly use the internet would agree that more of it is valuable for a healthy internet: for being able to control who can access your data, who can and cannot contact you, and so on. <em>But</em>, self-sovereignty is far too vague of a concept on its own. Left- and right-libertarianism both start with self-sovereignty as a core value, but they end up with vastly different conceptions of what meaningful self-sovereignty looks like and how it can be achieved. Left-libertarianism finds that self-sovereignty arises from social organizing, care, and democratic governance, which build towards positive freedoms (freedom to learn, to flourish, and so on); whereas, right-libertarianism believes it comes from the market and that negative freedoms (freedom from restrictions and regulation) are the goal. Though Yarvin does not identify as a libertarian (he is, in his own words, sympathetic to it), his neocameralism is right-libertarianism taken to its logical conclusion<sup id="fnref:6"><a href="#fn:6">6</a></sup> of corporate tyranny and serfdom.</p>

<p>To draw an example that you might be familiar with, consider the Twitter-alternative, Gab, which markets itself as a bastion for free speech. Gab, in practice, operates as a niche platform for members of the far-right who have been banned from Twitter: “<a href="https://www.nytimes.com/2018/10/28/us/gab-robert-bowers-pittsburgh-synagogue-shootings.html">a haven for white nationalists, neo-Nazis and other extremists</a>”. We might ask then, is Gab a platform for free speech, or is it a platform for hate speech? Who’s speech does Gab prioritize? It quickly becomes clear that the concept of “free speech” that Gab deploys is not quite the same as what others see it to mean.</p>

<p>In a similar way, this slipperiness of self-sovereignty as a concept, especially in light of Yarvin’s political writings, makes me suspicious of what it really means in the context of Urbit. Is Urbit actually designed to give users more autonomy and control? Does it restore any power to internet users?</p>

<p>One central design feature of Urbit is its network hierarchy. As a participant in Urbit, you may be a galaxy (the top of the hierarchy), a star (which fall under galaxies), or a planet (which fall under stars). The description of this hierarchy <a href="https://github.com/cgyarvin/urbit/blob/6ac688960687aa9c89d4da6fff49a3125c10aca1/Spec/urbit/3-intro.txt">used to use explicitly feudal metaphors</a> as part of what Yarvin called “digital feudalism,” with himself as the “prince,” and further contributes to my suspicion of Yarvin’s conception of self-sovereignty actually entails.</p>

<p>In trying to backpedal on these naming conventions, Yarvin claims that his ideas about governance are flipped for the internet:</p>

<blockquote>
  <p>If the real world today is governed as an insanely dysfunctional republic, and the Internet today is governed as a cluster of insanely despotic corporate monarchies, it doesn’t strike me as at all inconsistent with historical thought to treat the former case of misgovernment with efficient monarchism, and the latter case with liberating republicanism.<sup id="fnref:7"><a href="#fn:7">7</a></sup></p>
</blockquote>

<p>The rationale for why the …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://distributedweb.care/posts/who-owns-the-stars/">http://distributedweb.care/posts/who-owns-the-stars/</a></em></p>]]>
            </description>
            <link>http://distributedweb.care/posts/who-owns-the-stars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25404575</guid>
            <pubDate>Sun, 13 Dec 2020 05:41:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Retrocomputing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25404546">thread link</a>) | @Rendello
<br/>
December 12, 2020 | https://blog.information-superhighway.net/retrocomputing | <a href="https://web.archive.org/web/*/https://blog.information-superhighway.net/retrocomputing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>So I should probably have a blog post that I can point to about this whole retrocomputing project that I've been up to the past year and a half.</p>

<p>I wrote a game on an MS-DOS 286 PC, using only tools I built myself or tools that were available during the era where they were still selling 286 PCs. It's called <a href="https://spindleyq.itch.io/neut-tower" rel="nofollow">Neut Tower</a> and you can play it on your MS-DOS PC, in DOSBox, or in your browser. As part of this project, I implemented a Forth system, and built most of my game and its tools using it.</p>

<p>My motivation at the start of the project was this: I was enjoying using my 286. I liked the single-tasking workflow; there were no distractions. I was downloading games and apps and it was fun! So I figured I'd take the next step and write a little game or something.</p>

<p>When I was a teenager, I had a 286, and I tried to learn low-level programming on it because my options were “low-level programming” and “BASIC”, and I had hit my limit with BASIC. Assembly might as well have been Martian to me, but I got a book about C, and I got a book about game programming, and I sort of got some stuff working. But mostly the stuff I tried to do myself from scratch, or port from other sources, didn't work, and I didn't know why. Eventually I also got access to a 486, and then a Pentium, and the internet, and <a href="http://www.delorie.com/djgpp/" rel="nofollow">djgpp</a> and <a href="https://liballeg.org/readme.html" rel="nofollow">Allegro</a>, and suddenly I had an embarrassment of nice graphics and sound libraries and tooling, segment:offset addressing didn't matter, and I never had to worry about trying to understand how Mode X worked ever again.</p>

<p>Twentyish years later, I wanted to learn all the stuff that never quite clicked for me. I wanted to dig into how everything worked, to make sense of the tutorials that once baffled me. I wanted to really understand it all. So I started writing little prototypes, and pretty soon, yeah, I had a cool EGA graphics engine, with two way scrolling of a tilemap and 16x16 sprites drawn on top, running at a decent speed on actual hardware. Everything fell into place one tiny experiment at a time.</p>

<p>With the hardware programming side of things, I learned that my teenage understanding hadn't really been all that far off the mark – my problems weren't so much that I didn't understand the tutorials and resources that were available to me, it was more that I was simply bad at debugging my beginner code, and didn't have the tools or the patience to fix it. With 20 years of professional programming experience under my belt, and a wealth of resources on the internet that explained how things worked in depth, this was no longer an issue.</p>

<p>Then I started to write a game loop in C, and didn't really like it. I knew in the back of my head that, for what I wanted to do, I really wanted some kind of scripting language. And I remembered Forth existed.</p>

<p>In my 20s, obsessed with both the world of programming languages and the world of embedded systems, it was inevitable that I would learn about Forth – it's a particularly uncommon blend of small and powerful, that could run directly on hardware, that people who loved it <em>really</em> loved. I'd tried seriously to learn it but couldn't really wrap my head around it – the weird postfix syntax, the confusing levels of meta. Why could I not use IF statements at the REPL? How was I supposed to remember all these finicky rules? I filed it away as “interesting, but not for me.”</p>

<p>This project was the perfect opportunity to revisit that evaluation. Forth fit the bill exactly – it was a tool that could be built quickly, using minimal resources, and made to do what I wanted, AND I already had a hazy half-remembered foundation from decades ago. I dove headfirst into it.</p>

<p>Relearning Forth was an altogether different experience. It turned out that once I built one myself, I understood it completely. The design of Forth is to write as little code as you possibly can, to make the computer do only as much work as it needs to. When I had to write it all myself, I had to decide – is it worth building this language feature, or can I do without it? Usually I could do without it. Usually there was a tinier way to do it. The code that I had to write wasn't really all that much uglier or worse for it, once I got used to the constraints. And I had proven designs I could pilfer; there are lots of existing open-source Forth implementations to get inspiration from. There are guides for building Forth systems. Doing Forth is not learning an existing language set in stone, it is building a language to solve your problem, and sharing ideas about useful building blocks. Chuck Moore, the inventor of Forth, hated its standardization; thought the goal of portability was absurd, thought everyone should change it as they needed, to fit their problem. He is still trying out new ideas, rebuilding, simplifying, making a system uniquely his own.</p>

<p>So why do I think all this is important enough to write about?</p>

<p>When I was a kid, I had this persistent idea in my head, that computing was a skill I could work at, get better at, and that doing so would allow me to accomplish things that were impossible for me without it. “Once I got good enough”, I could make a computer game, by myself. I could draw the graphics, I could write the code, I could make the music, I could design it all. I could make it and I could put it out into the world and it would be mine, start to finish. Every time I learned something new about computers, got some new piece of software, I gained abilities. I could do things I couldn't do before. My vision of computer literacy is that everyone has this experience, that everyone can learn the skills they want, is provided with the tools they need, to make their imagination real.  I have never really let go of this idea.</p>

<p>I'm still trying to find ways to make it true, still trying to explore the different ways that computing can be empowering. Retrocomputing is one avenue for that – people in the past had a lot of good ideas that didn't catch on. And while emulators are wonderful, running them inside a modern computing system makes it harder to experience what using an old computing system really felt like.</p>

<p>When I show people my setup, they are often curious about the qualitative difference between old tools and modern tools; it must be so much harder, right? And... for me, it's really not! I write bugs at about the same rate; I fix them at about the same rate. There are many things I can't do because of resource constraints, but that keeps the scope manageable and makes for an interesting challenge to find cool stuff I <em>can</em> do. The biggest thing I miss is having a second editor that I can use to look at &amp; edit code while my game is running — I have often resorted to taking a photo of some code with my phone so I can read it while I have the game up.</p>

<p>And I gain really valuable things from the constraints. The biggest thing is that there's no alt-tab away from the work – it's so much easier to focus without a web browser instantly at my fingertips. (I'm procrastinating at work writing this right now!) The resource constraints mean I have to focus ruthlessly on solving the problems I have, not the problems I imagine I'll have – there's no perfect, elegant, general solution if I think hard enough, there's only adding things and cleaning up what I've got, one small piece at a time. And I can take workflow seriously as one of those problems! When I'm fed up with the tools that are available for DOS on a 286 (and this happened multiple times!), I make my own that work the way I want, and I'm able to integrate them seamlessly into my engine. I'm able to intentionally craft my environment to be comfortable. I'm no artist, but multiple people have complimented my art – partly, the secret is that 16x16 sprites and tiles can only look so good with a fixed ugly 16-colour palette, so I'm able to focus on broad colour and style choices. But really, if you put me into my ugly, limited pixel editor that's two pages of code but instantly shows me what my sprite looks like in my game, I will mess around until I'm happy. Put me in front of Photoshop with 16 million colours and I will go crazy from decision fatigue; I'll avoid making more art, and I'll get myself stuck.</p>

<p>So for me, the tradeoffs are incredibly worth it. I've spent decades trying to make games as a hobby; I've put out reams of junk – failed prototypes, bad joke games, quick jam games, failed engines, half-finished tools. I've tried every way of making games that I can think of; coding engines from scratch, using Unity, Godot, Love2D, Klik &amp; Play, Game Maker, Twine, Construct, Adventure Game Studio, pygame, Allegro. Some approaches I've had more success with than others, but I've not ever been as happy with anything I've made as I am with Neut Tower. Not as a retrocomputing exercise — as a game.</p>

<p>Neut Tower is done, for now, and I am taking a break from it. (Perhaps someday I will return to it to create the next two episodes.) I'm quickly finding myself using all of these lessons and starting to build some tools for myself in Linux. I don't quite know what they'll turn into yet, but I'm looking forward to finding out, one small piece at a time.</p>
</div></div>]]>
            </description>
            <link>https://blog.information-superhighway.net/retrocomputing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25404546</guid>
            <pubDate>Sun, 13 Dec 2020 05:35:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OSM Opening Hours Integration in KDE Itinerary]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25404212">thread link</a>) | @pabs3
<br/>
December 12, 2020 | https://www.volkerkrause.eu/2020/12/12/kde-itinerary-opening-hours-integration.html | <a href="https://web.archive.org/web/*/https://www.volkerkrause.eu/2020/12/12/kde-itinerary-opening-hours-integration.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>I recently wrote about <a href="https://www.volkerkrause.eu/2020/11/21/kde-introducing-kopeninghours.html">KOpeningHours</a>,
a new library to parse and interpret <a href="https://wiki.openstreetmap.org/wiki/Key:opening_hours">OSM opening hours</a>
expressions. Here is now how we make use of this in <a href="https://apps.kde.org/en/itinerary">KDE Itinerary</a>.</p>

<h3 id="highlight-open-entities">Highlight Open Entities</h3>

<p>Based on your travel bookings KDE Itinerary knows when and for how long you are going to be at a train station or airport.
Combined with now understanding opening hours information we can determine which shop, restaurant, amenity or other entity is
open during that time span. Things closed for your entire stay will be grayed out on the station map.</p>

<figure>
  
  <img src="https://www.volkerkrause.eu/assets/posts/72/kde-itinerary-station-map-closed-entities.png" alt="Train station map using colored icons for open shops/restaurants/amenities, and gray ones for those closed ones.">
  
  <figcaption>Shops, restaurants or amenities closed during a layover are grayed out.</figcaption>
</figure>

<p>This of course is most useful at very large stations or airports and shorter layovers, where walking longer distances in vain
would be rather inconvenient.</p>

<h3 id="human-readable-opening-hours">Human-readable Opening Hours</h3>

<p>Another place where we made use of this is the information dialog for a selected element on the map.</p>

<figure>
  
  <img src="https://www.volkerkrause.eu/assets/posts/72/kde-itinerary-station-map-opening-hours-details.png" alt="Opening hours information for a selected element on the map presented both in textual and visual form.">
  
  <figcaption>Textual description of the current opening state and visual overview of the current week.</figcaption>
</figure>

<p>There are two things in here:</p>
<ul>
  <li>A textual description of the current state and the next state change. This is the information you are most likely
looking for regarding the opening time.</li>
  <li>A visual representation of the current week. The benefit of that might be less obvious for simple opening hours
expressions like <code>Mo-Fr 09:00-17:00</code>, but as soon as they get slightly more complex interpreting that manually becomes
tricky and potentially error prone. Consider for example the simple <code>PH off</code> (closed on public holidays) addition.
In your home region you likely know when there is a public holiday, in other countries you might encounter
surprises though (remember e.g. Akademy 2018).</li>
</ul>

<h3 id="outlook">Outlook</h3>

<p>At this point I considered the opening hours topic sufficiently covered, just leaving the
<a href="https://marc.info/?t=160761966300016&amp;r=1&amp;w=2">standard KDE review process</a>
to be done for integrating this into the 21.04 release service.</p>

<p>Then I however got contacted by an OSM contributor, who, after having imported the opening hours
of all French post offices into OSM and finding himself confronted with a number of false-positive
warnings by the OSM validator, was looking into improving the
<a href="https://wiki.openstreetmap.org/wiki/Osmose">Osmose OSM validator</a>
for opening hours expressions. KOpeningHours was apparently performing quite well during an evaluation for this,
and is therefore <a href="https://github.com/osm-fr/osmose-backend/issues/555">being considered as a parser for the validator</a>.</p>

<p>The requirements on the parser for validation are higher than for the evaluation use I had
originally in mind. Rejecting to evaluate things we aren’t certain about is enough for KDE Itinerary’s use,
however a validator shouldn’t produce false positives and also needs to accepts all kinds of rare edge cases
correctly. This has already resulted in a number of improvements to KOpeningHours, which of course
also benefit KDE Itinerary.</p>

<p>Said OSM contributor is a certain David Faure btw, the world is very small.</p>

  </div></div>]]>
            </description>
            <link>https://www.volkerkrause.eu/2020/12/12/kde-itinerary-opening-hours-integration.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25404212</guid>
            <pubDate>Sun, 13 Dec 2020 04:04:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China’s Radical New Vision of Globalization]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25404210">thread link</a>) | @s3v
<br/>
December 12, 2020 | https://www.noemamag.com/chinas-radical-new-vision-of-globalization/ | <a href="https://web.archive.org/web/*/https://www.noemamag.com/chinas-radical-new-vision-of-globalization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

				<div>
  <p>Credits</p>
  <p>James Crabtree is an associate professor in practice at the Lee Kuan Yew School of Public Policy at the National University of Singapore. He is the author of “The Billionaire Raj.”</p>
</div>


<p>SINGAPORE —&nbsp;Back in August, Chinese President Xi Jinping met with a group of economists in Beijing. “In the coming period, we will face more and more headwinds,” he <a href="http://www.xinhuanet.com/english/2020-08/25/c_139314902.htm" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">explained</a>, using unusually blunt language. Without naming names, Xi talked about China’s worsening trade and technology war with the United States under President Donald Trump, set against a backdrop of growing certainty in Beijing that America is bent on containing his nation’s geopolitical rise.</p>



<p>But then came the interesting part. “Since the beginning of this year, I have said on many occasions that we must promote the formation of a new development pattern, in which domestic and international cycles are the mainstay, and the domestic and international dual cycles promote each other,” Xi said. To an outsider, this might seem unremarkable, cloaked as it is in the elliptical phraseology that often marks Chinese economic ideas. But the “dual circulation” strategy Xi outlined actually represents a radical new understanding of globalization and of China’s place within it.</p>



<p>More than just a buzzword, dual circulation describes the deeply pessimistic worldview that has settled over Beijing. Once China’s leaders saw opportunity in globalization. Now, they expect the U.S. and its allies to deny China the technology it needs to build “a modern socialist country” by mid-century, meaning a wealthy superpower fit to rival the U.S. Although likely to be less pugilistic, Beijing rightly believes an incoming Biden administration will also press forward with policies designed to stop advanced technologies finding their way into Beijing’s hands. Chinese thinking has long valorized self-reliance, dating back to ideas developed by former Chinese leader Mao Zedong during the country’s civil war, which ended with the foundation of the People’s Republic of China in 1949. Now, Trump’s tariffs, as well as his campaigns against companies like Huawei and TikTok, have given new impetus to the modern form of self-reliance Xi dubs “internal” development.</p>



<p>Many experts have noted a changing Western consensus on China, as leaders in Washington abandoned the idea that economic modernization would inevitably lead to political liberalization in Beijing. But there has been a comparable shift in China’s internal conversation on the West too. Beginning with semiconductors but potentially expanding to all manner of other areas, China now expects it will have to develop technologically on its own. Xi’s new theory now sits at the heart of the country’s <a href="http://www.xinhuanet.com/english/2020-10/29/c_139476451.htm" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">14th five-year plan</a>, which covers development from 2021 to 2025, and was unveiled in draft form in October. The result will accelerate China’s decoupling from the West, while also increasing the importance of trading links forged with other parts of the world — for instance, via Xi’s signature Belt and Road Initiative. Put more bluntly, while the world was distracted by the drama of the U.S. presidential election, Xi quietly unveiled an economic strategy fit for a new Cold War. Both for China and for globalization itself, the results are likely to be profound.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “China expects the U.S. and its allies to act ever more aggressively to deny China the technology it needs.”    </p>

    
    
  </div>
</div>




<hr>



<p>To see how much China’s consensus has changed, recall Xi’s <a href="https://america.cgtn.com/2017/01/17/full-text-of-xi-jinping-keynote-at-the-world-economic-forum" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">remarks</a> at Davos in 2017. There, he portrayed globalization not as a threat, but as an inevitability. “The global economy is the big ocean that you cannot escape from,” he suggested. “China will vigorously foster an external environment of opening-up for common development.” Just as Trump was turning against the idea, China would act as steward of the existing global order. It would even help to remedy many of the problems that rapid integration had caused, Xi argued, from economic inequality to climate change.</p>



<p>Three years later and, under <a href="https://research.nus.edu.sg/eai/wp-content/uploads/sites/2/2020/10/EAIC-20-20201020.pdf" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">dual circulation</a>, things look much different. The idea splits the world into two systems. First comes external circulation, meaning China’s global trade, but also the way it invites foreigners into its domestic economy. This was the focus of Xi’s Davos remarks and the approach that powered his country’s decades of rapid growth, transforming China into an exporting powerhouse. The second component is then internal circulation, meaning domestic demand from Chinese consumers, but also domestic supply chains and “made in China” technologies.&nbsp;</p>



<p>This division shares something in common with “<a href="https://www.straitstimes.com/40-years-of-china-opening-up" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">reform and opening up</a>,” a phrase that has dominated China’s economic thinking for decades. That idea suggested Beijing should reform its domestic (or internal) economy to make it more market-led, while also opening up to the (external) world via globalization, gaining new ideas, production techniques and technologies along the way. Dual circulation also echoes longstanding attempts to wean China off a growth model dominated by exports and infrastructure investment and build instead the kind of consumption-led economy common in rich countries.</p>



<p>Such attempts have been only partially successful. A decade ago, about <a href="https://www.ceicdata.com/en/indicator/china/private-consumption--of-nominal-gdp#:~:text=China's%20Private%20Consumption%20accounted%20for,an%20average%20share%20of%2049.7%20%25." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">34%</a> of China’s economy came via domestic consumption, less than <a href="https://tradingeconomics.com/united-states/final-consumption-expenditure-etc-percent-of-gdp-wb-data.html#:~:text=(%25%20of%20GDP)%20in%20United,compiled%20from%20officially%20recognized%20sources." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">half the level</a> in the U.S. at the time. By 2019, this has reached just <a href="https://www.ceicdata.com/en/indicator/china/private-consumption--of-nominal-gdp#:~:text=China%20Private%20Consumption%3A%20%25%20of%20GDP,-1952%20%2D%202019%20%7C%20Yearly&amp;text=China%20Private%20Consumption%20accounted%20for,an%20average%20share%20of%2049.7%20%25." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">39%</a> — progress, of a sort, but hardly dramatic. When the phrase dual circulation first emerged earlier this year, many saw it as merely yet one more push toward this long-term objective of Chinese internal economic rebalancing.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Beginning with semiconductors but potentially expanding to all manner of other technologies, China now expects it will have to develop economically on its own.”    </p>

    
    
  </div>
</div>




<p>It is China’s deteriorating geopolitical environment that marks dual circulation as a decisive break from the past, however. “China thinks there is a good prospect of even worse relations with the U.S. and its friends in the coming years,” I was told recently by Li Mingjiang, a Chinese political scientist based in Singapore and long-time observer of Beijing’s intricate political economy. “So, it needs to do something about it.”</p>



<p>It is not hard to see why. Trump’s tariffs and battles over soybeans generated more headlines, but it is advanced technology that really matters in Beijing. China is a global tech leader in some sectors, from online payments to artificial intelligence. But it lags in others. Despite its geopolitical heft, it still remains a firmly middle-income economy, with a gross domestic product per capita of roughly <a href="https://www.google.com/search?q=china+gdp+per+capita&amp;rlz=1C5CHFA_enSG865SG865&amp;oq=china+gdp&amp;aqs=chrome.0.69i59j69i57j0i67l3j0j69i60j69i61.4682j0j7&amp;sourceid=chrome&amp;ie=UTF-8" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">$9,700</a> — about on par with <a href="https://www.google.com/search?rlz=1C5CHFA_enSG865SG865&amp;sxsrf=ALeKk03pfVp34z407DFWSFnQvjkGHb2akQ%3A1605820539834&amp;ei=e-C2X7m2Munfz7sP5ZGlgAE&amp;q=kazakhstan+gdp+per+capita&amp;oq=Ka+gdp+per+capita&amp;gs_lcp=CgZwc3ktYWIQAxgAMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB46BAgAEEdQoaoBWMmrAWCUswFoAHADeAGAAesBiAGeApIBBTEuMC4xmAEAoAEBqgEHZ3dzLXdpesgBCMABAQ&amp;sclient=psy-ab" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Kazakhstan</a> and roughly half that of <a href="https://www.google.com/search?rlz=1C5CHFA_enSG865SG865&amp;sxsrf=ALeKk03pfVp34z407DFWSFnQvjkGHb2akQ%3A1605820539834&amp;ei=e-C2X7m2Munfz7sP5ZGlgAE&amp;q=kazakhstan+gdp+per+capita&amp;oq=Ka+gdp+per+capita&amp;gs_lcp=CgZwc3ktYWIQAxgAMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB46BAgAEEdQoaoBWMmrAWCUswFoAHADeAGAAesBiAGeApIBBTEuMC4xmAEAoAEBqgEHZ3dzLXdpesgBCMABAQ&amp;sclient=psy-ab" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Greece</a>. Access to cutting-edge technology is critical in changing this, especially as its economy moves away from the kind of basic exported manufactured goods that have long dominated its growth model.</p>



<p>Over recent decades, China has had many routes to acquiring such technology. Often, it simply bought it, as when Chinese companies snapped up everything from Rolls Royce jet engines to Qualcomm semiconductors. Foreign businesses rushed to set up Chinese operations, often as part of local joint ventures, eager to tap into a vast consumer market. Chinese businesses bought foreign technology groups, while Chinese academics and scientists built partnerships at the world’s best universities. Beijing <a href="https://www.cigionline.org/publications/getting-beyond-forced-technology-transfers-analysis-and-recommendations-intangible" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">employed</a> darker methods too, from forced technology transfer to outright intellectual property theft. But there were always plenty of legitimate avenues to go with them.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Xi has quietly unveiled an economic strategy fit for a new Cold War.”    </p>

    
    
  </div>
</div>




<p>Now, many of these routes are closing fast. Rather than tariffs, America’s “entity list” has proved its most potent weapon. Back in 2016, President Barack Obama first used this process in <a href="https://www.cigionline.org/publications/getting-beyond-forced-technology-transfers-analysis-and-recommendations-intangible" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">accusing</a> ZTE, China’s second-largest telecoms supplier, of selling U.S. technologies to Iran, crippling the Chinese company in the process. Trump then escalated this approach, banning U.S. businesses from trading with dozens of Chinese enterprises, from state-owned giants to niche artificial intelligence providers with links to Xinjiang and its embattled Muslim Uighur minority. More recent <a href="https://www.commerce.gov/news/press-releases/2020/08/commerce-department-further-restricts-huawei-access-us-technology-and" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">measures</a> unveiled this August hit foreign suppliers too, for instance stopping semiconductor operators in Taiwan from selling to Chinese entities. Huawei has been one high-profile victim, leading experts to <a href="https://www.ft.com/content/bdd2a70f-ecd2-4aff-b6c7-c0624bfdeebb" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">question</a> whether China’s state-linked tech champion can survive.</p>



<p>What started with semiconductors is unlikely to end there, however, hence dual circulation’s underlying pessimism. Under Trump, the U.S. has unveiled a range of further measures limiting China’s technology access, from its 2018 <a href="https://www.cliffordchance.com/briefings/2018/02/the_export_controlreformactof2018risksan.html" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Export Control Reform Act</a> to more targeted measures in areas like geospatial imagery software. Allies in Europe are being cajoled to follow suit. Many Western governments have also acted to stop China from buying up advanced tech companies entirely, while also <a href="https://www.chinacenter.net/2020/china_currents/19-3/scholars-or-spies-u-s-china-tension-in-academic-collaboration/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">limiting</a> academic collaborations with Chinese partners. The recent battle over TikTok was illustrative too, showing how rapidly the U.S. has lowered the bar on what counts as a national security threat, a category that now includes not just critical 5G telecoms architecture of the sort provided by Huawei, but also jocular teenage social media platforms.</p>



<p>Elsewhere, U.S. strategists are particularly vexed by China’s doctrine of “<a href="https://www.floridadaily.com/marco-rubio-introduces-bill-to-keep-chinese-military-companies-from-accessing-american-capital-markets/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">military-civil fusion</a>,” which mandates that technologies acquired by China’s private sector must be shared with its armed forces. The problem is that, when you look hard enough, almost anything can potentially be seen as a dual-use technology, from nuclear equipment and renewable energy batteries to civilian aircraft, drones and autonomous vehicles.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Xi’s plans clearly place more emphasis on domestic production and state control.”    </p>

    
    </div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.noemamag.com/chinas-radical-new-vision-of-globalization/">https://www.noemamag.com/chinas-radical-new-vision-of-globalization/</a></em></p>]]>
            </description>
            <link>https://www.noemamag.com/chinas-radical-new-vision-of-globalization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25404210</guid>
            <pubDate>Sun, 13 Dec 2020 04:04:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Three-Word Content Strategy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25404129">thread link</a>) | @dbustac
<br/>
December 12, 2020 | https://danielbusta.com/three/ | <a href="https://web.archive.org/web/*/https://danielbusta.com/three/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-211">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>If there’s a hardcore advocate of prolific content production that’s Gary Vee.</p>



<p>He’s always emphasizing the importance of putting out a massive volume of content every day. And he walks the talk – when it comes to content, he’s one of most prolific personal brands you’ll ever find.</p>



<p>When people ask Gary how he manages to put out so much content, he always replies with his simple, three-word mantra: “document, don’t create”.</p>



<p>His point is that if you want to maximize your content output, you can’t rely on just sharing super polished content. Instead, you should show people your process. You should share with them your journey and everything that happens behind the scenes.</p>



<p>While he usually mentions practicality as the main reason why he prefers documenting over creating, I think there’s another important point to be considered: documenting allows you to tell your story in a very real and authentic way.</p>



<p>It allows you to be transparent.</p>



<p>And people love transparency. They really appreciate when you are vulnerable and genuine.</p>



<p>Also, when you share your journey in such a way, people inevitably start feeling invested and even getting involved — they start rooting for you and doing whatever they can to help you succeed.</p>



<p>So go find something interesting to do or build, and document it all. Tell us why you are doing it. And every day share with us what you’re learning, what’s working and what you’re struggling with.</p>



<p>That’s all the content strategy you need.</p>


<p><em>This piece is part of a series of 30 atomic essays where I explore what it means to be a&nbsp;<a href="https://rationalcreatives.substack.com/" target="_blank" rel="noreferrer noopener">rational creative</a>&nbsp;and the different aspects of being a creator online. You can read all the others essays&nbsp;<a href="https://twitter.com/dbustac/status/1328419048070279174?s=20" target="_blank" rel="noreferrer noopener">here</a>.</em></p>
		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://danielbusta.com/three/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25404129</guid>
            <pubDate>Sun, 13 Dec 2020 03:45:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Block Mao/Daizhige Mastodon Instances]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25403791">thread link</a>) | @yellow_lead
<br/>
December 12, 2020 | https://writee.org/salt/reasons-why-you-should-block-mao-daizhige-mastodon-instances-lw7c | <a href="https://web.archive.org/web/*/https://writee.org/salt/reasons-why-you-should-block-mao-daizhige-mastodon-instances-lw7c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>TL;DR:</p>

<p>Key reasons why you should block Mao (aka: Daizhige, domain: *.mastodonhub.com) Mastodon instances:</p>
<ol><li>Generating fake accounts by continuously duplicating at least hundreds of real Mastodon accounts from other instances without the permission of the original account owners.</li>
<li>Mislead users by claiming to be the very only official Mastodon instance, without mentioning that the most important feature of Mastodon is decentralization.</li>
<li>Jeopardized other instance admins who live in China by publishing their site information on a heavily censored Chinese social media.</li>
<li>Arbitrarily censoring and deleting user-posted contents and accounts in favour of the Chinese Communist Party (CCP).</li></ol>



<p>Mao (<a href="http://mao.mastodonhub.com/" rel="nofollow">mao.mastodonhub.com</a>) has been <a href="https://pawoo.net/@manul/105365327122838407" rel="nofollow">duplicating</a> at least hundreds of Mastodon accounts from <a href="https://pawoo.net/" rel="nofollow">Pawoo.net</a> and other instances to its own instance without the permission of the original account owners.</p>

<p>To find out whether your account has been duplicated, you can type “mao.mastodonhub.com/@your<em>mastodon</em>handle” in the address bar. Replace <code>your_mastodon_handle</code> by your account handle.</p>

<p>The mirror accounts have been <a href="https://mastodon.online/@nebulamoe/105365549000251788" rel="nofollow">cached from the Fediverse</a> since 2018 and generated by processing in the background of Mao's server. To validate this theory, <a href="https://b612.me/@star/105367643441202235" rel="nofollow">someone</a> built a test server and successfully <a href="https://b612.me/@star/105367643441202235" rel="nofollow">replicated this process</a> – those accounts were deliberately mirrored and were not created by mistake.</p>

<p><a href="https://mastodon.social/@daisyn0925/105367889441725674" rel="nofollow">One of the distinguishable differences</a> between the mirrored accounts and the original accounts is that the <code>&lt;p&gt;</code> and <code>&lt;br&gt;</code> tags are retained in the mirrored accounts.</p>

<p>Example of an account mirrored from Pawoo.net :</p>

<p><img src="https://i.imgur.com/AslgSak.png" alt="Mirrored"></p>

<p>On December 13, 2020, <strong>Mao's admin made <a href="https://archive.is/R02Ua" rel="nofollow">an announcement</a> stating that he refuses to take any responsibility or proactively delete these fake accounts.</strong> If users want to delete the mirrored accounts and contents, <a href="https://m.cmx.im/@Soyelena/105368235720685381" rel="nofollow">they need to contact Mao's admin</a> and make a request.</p>



<p>Mao <a href="https://web.archive.org/web/20200518153618/https://www.bolebook.com/mastodon/manuelofmastodoncn.html" rel="nofollow">openly advertises its own instance as the only Chinese instance</a>, and all other Chinese instances are branches of its site. They are intentionally misleading new users who have not known Mastodon's decentralization  mechanism.</p>

<p>In its user guide, Mao <a href="https://web.archive.org/web/20200715052422/https://www.bolebook.com/mastodon/manuelofmastodoncn.html#%E7%8C%AB%E7%AB%99" rel="nofollow">claims</a> itself to be the “largest Chinese mastodon instance” and uses “嘟嘟长毛象” (Toot, Mastodon) to name the mobile apps they developed, thus creating a false image of themselves as the “official Mastodon platform”, without mentioning that the most important feature of mastodon is the decentralized private instances, and so called “official platform” simply doesn't exist.</p>



<p>In early 2020, Mao had it servers <a href="https://telegra.ph/%E6%AE%86%E7%9F%A5%E9%98%81%E8%BF%90%E8%90%A5%E6%96%B9%E4%BF%A1%E6%81%AF%E8%BF%BD%E6%BA%AF-05-25" rel="nofollow">located in Beijing, China mainland</a>.</p>

<p>On May 25, 2020, Mao suddenly shut down its service (for <a href="https://donotban.com/@tommylibra/104227916723233840" rel="nofollow">unjustifiable reasons</a>) without properly informing users in advance. The instance was shut down <a href="https://bgme.me/@bgme/104227760618216048" rel="nofollow">only 30 minutes</a> after Mao's <a href="https://web.archive.org/web/20200525061226if_/https://mao.mastodonhub.com/@daizhige/104227495834927101" rel="nofollow">announcement</a>, leaving its users no time for backups.</p>

<p>The instance went live again in July 2020 and moved its servers to Hong Kong.</p>



<p>Mao published a list of instance info (including alternate domains that are used to circumvent the Chinese Great Firewall) on Weibo (Chinese social media), which is heavily censored by the Chinese government. This would very likely jeopardize those instance admins who live in China.</p>



<p>Mao intends to sell its Mastodon hosting service through subdomains of mastodonhub.com.</p>

<p>Based on an <a href="https://telegra.ph/%E6%AE%86%E7%9F%A5%E9%98%81%E8%BF%90%E8%90%A5%E6%96%B9%E4%BF%A1%E6%81%AF%E8%BF%BD%E6%BA%AF-05-25" rel="nofollow">analysis</a> of its ICP license and IP addresses, it appears that Mao is controlled by, or at least affiliated with, a China-based <a href="https://www.qcc.com/firm/9fe1032b8da990b66574bf3f4d416954.html" rel="nofollow">public company</a> with registered capital of ¥18,250,000 and total operating revenue of ¥24,542,198 in FY 2019.</p>



<p>Mao created <a href="http://dudu.today/index.html" rel="nofollow">a microblog-like, non-open source proprietary Mastodon App</a> which requests for unnecessary permission that may potentially violate user's privacy. It also advertised only its own instance in the app interface when it was published.</p>



<p>Mao's <a href="https://archive.is/7rxpv" rel="nofollow">terms of service</a> does not clearly define its terms or privacy policy.</p>

<p>It also outlines that the admins can do whatever they want and they don't accept any criticism. If you disrespect the admin, your account will get deleted.</p>



<p>Mao <a href="https://futen.work/@0/105367204866963355" rel="nofollow">censors and deletes</a> user-posted contents and accounts in favour of the Chinese Communist Party (CCP).</p>



<p>Known instances of Mao:</p>

<p>    – <a href="http://mao.mastodonhub.com/" rel="nofollow">mao.mastodonhub.com</a> (main site)
    – <a href="http://test.mastodonhub.com/" rel="nofollow">test.mastodonhub.com</a>
    – <a href="http://daizhige.mastodonhub.com/" rel="nofollow">daizhige.mastodonhub.com</a>
    – <a href="http://moyu.mastodonhub.com/" rel="nofollow">moyu.mastodonhub.com</a>
    – <a href="http://meow.mastodonhub.com/" rel="nofollow">meow.mastodonhub.com</a>
    – <a href="http://outerspace.mastodonhub.com/" rel="nofollow">outerspace.mastodonhub.com</a></p>

<p>Known server IPs:</p>

<p>    – 148.66.58.42, 148.66.57.10</p>

<p>Block by user agent (Nginx):</p>

<pre><code>    # Block MAO UA
      if ($http_user_agent ~* "mastodonhub.com") {
            return 403;
       }
</code></pre>

<p>Block IPs in Nginx:</p>

<pre><code>    # Block MAO IP
      deny 148.66.58.42;
      deny 148.66.57.10;
</code></pre>

<p>Block with iptables:</p>

<pre><code>    iptables -A INPUT -s 148.66.58.42 -j DROP
    iptables -A INPUT -s 148.66.57.10 -j DROP
</code></pre>
</div></div>]]>
            </description>
            <link>https://writee.org/salt/reasons-why-you-should-block-mao-daizhige-mastodon-instances-lw7c</link>
            <guid isPermaLink="false">hacker-news-small-sites-25403791</guid>
            <pubDate>Sun, 13 Dec 2020 02:29:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[E-Ink Monitors: Ready for Prime Time? (2020 Update)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25403462">thread link</a>) | @miles
<br/>
December 12, 2020 | https://cloudconfusing.com/2020/02/07/e-ink-monitors-ready-for-prime-time/ | <a href="https://web.archive.org/web/*/https://cloudconfusing.com/2020/02/07/e-ink-monitors-ready-for-prime-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        
            
                        <div>

                            

                                                        <p>It turns out that staring at back-lit computer monitors for 40+ hours a week might not be the best thing for you. With this in mind, many of us have started to look towards alternate technologies, largely e-ink monitors. Large e-ink monitors are, unfortunately a nascent market with a limited number of products for sale, and new products have been slow to be released, but the e-paper display is bound to be an important technology for professional computer users.</p>
<p>This article is a round-up of all the information I’ve been able to find about buying an e-ink monitor in 2020, as well as lots of historic information from 2019 and 2018.</p>
<p><strong>Last Update: 2/7/20</strong> – CES 2020 has come and gone with some big news. It looks like e-ink displays will have some moment this year (finally). It might not be the banner year we wanted, but there should be some notable improvements in the available product offers. The biggest news so far this year is the 10.3-inch Waveshare E Ink Monitor.</p>
<p><strong>Updated: 9/10/19 –</strong> Finally some big news! The Onyx BOOX Max3 e-reader has been announced and is ready for sale. This device is billed as an e-reader, but it’s actually a whole lot more than than. And, yes, it’ll work as a monitor. More information below.</p>
<p><strong>Updated 6/17/19</strong> – It’s summer 2019, time for another update! Unfortunately news from Q2 2019 has been very limited and the Paperlike Pro remains the best game in town. The Boox Max 2 is still a viable buy as well, but still has many flaws. This category has (un-officially) entered a stall, but the good news it that we know e-ink monitors are on the radar of some major players, like Benq and Lenovo.</p>

<p>The goal of this article is to help you find an e-ink monitor for your computer. At least that was my initial goal, and then I realized that I had a lot of learning to do about E-ink and its application as a (somewhat) performant display.&nbsp;What I wanted (and most people seem to be looking for) is a secondary display that extends the window of a desktop or laptop. An increasing number of people believe this is a good idea for developers and other people who spend a lot of time looking at computer screens, particularly at text (as the e-ink displays aren’t great for video).</p>
<p>These aren’t ebook readers, they are full-on displays that are capable of being used in a professional setting by a reasonably demanding user.</p>
<p>Note: The article contains <a href="http://cloudconfusing.com/affiliate-disclosure/">affiliate links</a>.</p>
<h2>Who Makes E-Ink Monitors?</h2>
<ul>
<li>Dasung Paperlike 3 13.3″ E-Ink Monitor – About $1300 <a href="https://amzn.to/2UcpslW" target="_blank" rel="noopener noreferrer">Check Price</a></li>
<li>Dasung Paperlike Pro Touchscreen 13.3″ E-Ink Monitor – About $2500 <a href="https://amzn.to/2P4GnGc" target="_blank" rel="noopener noreferrer">Check Price</a></li>
<li>Onyx BOOX Max3 E-Book Reader&nbsp;– About $850 <a href="https://amzn.to/2HZwzeu" target="_blank" rel="noopener noreferrer">Check Price</a></li>
<li>Waveshare E-Ink Monitor – About $540 <a href="https://amzn.to/39j2l1a" target="_blank" rel="noopener noreferrer">Check Price</a></li>
</ul>
<p>Older options:</p>
<ul>
<li>Onyx Boox Max2 E-Book Reader – About $800 – <a href="https://amzn.to/2QyQovt" target="_blank" rel="noopener noreferrer">Check Price</a></li>
<li>Dasung Paperlike E-Ink Monitor – About $800 <a href="https://amzn.to/2OwyW9u" target="_blank" rel="noopener noreferrer">Check Price</a></li>
<li>Dasung Paperlink Pro E-Ink Monitor – About $1000 <a href="https://amzn.to/2QAVlnw" target="_blank" rel="noopener noreferrer">Check Price</a></li>
</ul>
<p>The Onyx Boox Max 2 (sometimes spelled Max2) is technically a giant ebook reader, but it works as a monitor if you simply plugin in an HDMI cord to your computer. It has a 13.3-inch, 2200×1650 touchscreen… and it’s actually an Android tablet. So it’s not cheap, but it’s a full-fledged device on its own. Sony’DPT-RP1 has similar specs but can’t operate as a monitor.</p>
<p>The Dasung Paperlike is a dedicated monitor — it has no battery, no on-board processing, and no uses outside of being a monitor. It originally launched as a Indiegogo project and has picked up momentum since then. The Paperlike runs at up to 40 frames per second (FPS) so it’s capable of displaying video fairly well.</p>
<p><iframe src="https://www.youtube.com/embed/xW-gatdEC7w" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>Sadly, hose are about the only options available. There is a lot of talk about <a href="https://www.sharpsma.com/sharp-memory-lcd-technology">memory LCD</a> and other options, at least if you want something commercially available that won’t include a bunch of FPGA work and miscellaneous hacking.</p>
<h2>How Practical Are E-Ink Monitors?</h2>
<p>Right from the start, let’s make it clear that these devices are expensive, they come from manufacturers you probably haven’t heard of, and they come with serious trade-offs. So, generally speaking, E-Ink / e-paper displays are not very practical. They are slow (max of 40hz), expensive (at least twice the price of a professional great LED-backlit display), and use non-standard to setups.</p>
<p>That said, if you are getting headaches, you are concerned <a href="http://cloudconfusing.com/2019/04/02/lighting-for-developers-os-x-desk-lighting-and-more/">with backlighting or blue light</a>, you have symptoms of computer vision syndrome (seeing snow, etc), or you are getting frequent computer-related headaches or eyestrain then these monitors might be very practical because one might improve your health or, at least, be a respite from serious discomfort.</p>
<p>Based on my research, particularly <a href="https://www.youtube.com/watch?v=6pw-oCItgx8">great e-ink monitor comparisons</a>, these devices are not ready for professional, daily use. They are laggy, have staining/ghosting problems, and perhaps worst, are quite unreliable. It seems that the failure rate on both of these devices is quite high and user happiness is quite low. If e-ink is your only option (because of health reasons) then these might be a savior, but short of that it seems like your best best is to wait for future development in the space.</p>
<h2>Which E-Ink Monitor Is Best?</h2>
<p>I was hoping this was going to be more of a debate (more competition would be better for everyone!) but it looks like the Onyx Boox Max 2 is the clear winner here. It’s easier to setup, it doubles as ebook reader, and it has a battery so there are less cables.</p>
<p>To be far, many Dasung PaperLike owners seem happy with their product, but there are also a number of issues people have pointed out with it: glare, problems when switching displays, and a general feeling that product feels like its still in beta.</p>
<p>The Onyx Book Max 2 seems to be far from perfect, but it’s a much more fluid experience to use day-to-day. Plus it works as an Android-powered ebook reader, so you can read books, documents, PDFs, and other files on it, even without it being connected to your computer.</p>
<p>Now that the Max 3 is available it’s likely that this’ll be the way to go. This could change if prices with the Max 2 drop sharply, but that doesn’t seem to to be the case yet.</p>
<h2>E Ink Monitor News and Updates</h2>
<h3>February 2020</h3>
<p><img loading="lazy" src="https://cloudconfusing.com/wp-content/uploads/2019/09/Waveshare-e1581121322775.jpg" alt="" width="493" height="298" srcset="https://cloudconfusing.com/wp-content/uploads/2019/09/Waveshare-e1581121322775.jpg 800w, https://cloudconfusing.com/wp-content/uploads/2019/09/Waveshare-e1581121322775-300x182.jpg 300w, https://cloudconfusing.com/wp-content/uploads/2019/09/Waveshare-e1581121322775-768x465.jpg 768w" sizes="(max-width: 493px) 100vw, 493px"></p>
<p>The biggest news of the early months of 2020 is the appearance of the Waveshare 10.3-inch e-ink display (<a href="https://amzn.to/39j2l1a" target="_blank" rel="noopener noreferrer">Amazon</a> / <a href="https://www.waveshare.com/product/oleds-lcds/e-paper/eink-disp-103.htm" target="_blank" rel="noopener noreferrer">Direct</a>). Waveshare is known for smaller displays so this one came as a bit of a surprise, but it still a potentially interesting offer… so long as the price falls. This 10.3-inch monitor is an OK size, has a 1872 x 1404 (226 DPI) resolution, and runs off HDMI. It has a disappointing 5Hz refresh speed that is going to make it a non starter for most people, but I’m keeping an eye on it.</p>
<p>Here is a <a href="https://www.youtube.com/watch?time_continue=3&amp;v=Qb68B-MjmGs&amp;feature=emb_logo">video of the Waveshare</a> e-ink monitor. It’s not great, but it’s something.</p>
<p>The other big piece of news from the first months of 2020 was the announcement of the Lenovo ThinkBook Plus laptop. While it’s not an e-ink monitor, it does have an e-ink display built into the top cover. The $1200 laptop has a standard 13.3-inch display on the inside, but has a 10.8-inch E-Ink display on the outside. This display will work with the laptop open or closed, with the latter effectively turning your laptop into a e-ink tablet. While there are some computer functions that the laptop’s e-ink display can perform, it’s really designed to act like a tablet, not a monitor, so this one is only a minor win for people who are in-marker for an e-paper monitor.</p>
<p>In other miscellaneous news, Onyx showed off a <a href="https://www.youtube.com/watch?v=fyBPpwcDJgQ&amp;feature=emb_title">5.8-inch e-paper phone</a>. It was a prototype that might never be released commercially. The slow response times seems like they would be downright painful on a smartphone.</p>
<p>E Ink (the company) has released a <a href="https://shopkits.eink.com/product/atelier-with-13-3%CB%9D-acep-display-ac133ut1-%E3%80%90glass%E3%80%91/#tab-custom-tab-third">13.3-inch full-color</a> e-ink display, but only has a demo kit. At $440 it’s an expensive acquisition, and while there are some great specs to it — like Raspberry Pi comparability and micro USB connectivity — it’s just a demo kit for now.</p>
<div id="attachment_558"><p><a href="http://cloudconfusing.com/wp-content/uploads/2018/09/max3.jpg" data-slb-active="1" data-slb-asset="545430611" data-slb-internal="0"><img aria-describedby="caption-attachment-558" loading="lazy" src="https://cloudconfusing.com/wp-content/uploads/2018/09/max3-e1568142976922.jpg" alt="" width="450" height="349" srcset="https://cloudconfusing.com/wp-content/uploads/2018/09/max3-e1568142976922.jpg 768w, https://cloudconfusing.com/wp-content/uploads/2018/09/max3-e1568142976922-300x232.jpg 300w" sizes="(max-width: 450px) 100vw, 450px"></a></p><p id="caption-attachment-558">Onyx Boox Max 3 eReader</p></div>
<h3>Early Fall 2019</h3>
<p>Onyx has released the Boox Max 3 eReader (sometimes spelled “Max3”)! This will likely be the big product in this space for 2019. The specs look strong:</p>
<ul>
<li>13.3 inch monitor</li>
<li>2200×1650 pixel resolution</li>
<li>Tablet-ready features: Android 9.0, USB Type-C connection, fingerprint reader, 5GHz WiFi, dual microphones, built-in stereo speakers</li>
<li>Lots of power: 2GHz octa-core Qualcomm processor with 4GB RAM, and 64GB of storage</li>
<li>Stylus support</li>
</ul>
<p>And yes, this tablet/reader can act as a monitor! So far we know it has the same level of support as a computer display as the Max 2, but we are waiting for actual reviews and hands-on testing. This will likely happen after the IFA conference in Berlin (Sept 6-11, 2019). The know there are 4 refresh modes for “different situations,” which we need some more details on.</p>
<p>This thing will be big for a tablet (0.8 lb and 309.8 x 227.8 x 6.8mm) but it should be an interesting e-ink display.</p>
<h3>Summer 2019 Update</h3>
<p>In non-e-ink monitor news, Benq announce the curious <a href="https://www.benq.com/en/monitor/stylish/gl2780.html">GL2780 display</a>. This is a standard LED-backlit computer monitor that has an “ePaper” mode. Benq calls this the “Eye-care B.I. technology plus ePaper and color weakness mode” but this is not in any way an e-ink experience! The monitor simply simulates e-paper by entering a monochrome mode which is black and white only, with limited distractions (it’s still unclear what this means), and lower than normal brightness. This monitor should prove to be affordable and eye-friendly but not what people reading this article are searching for.</p>
<h3>Early 2019 Update: CES and Beyond</h3>
<p>CES 2019, the world’s largest unveiling of technology news, unfortunately had very little news on e-ink monitors. This year e-ink news included an <a href="https://www.nemeio.com/en/">e-ink keyboard</a> which has similar functionality to Apple’s MacBook Touchbar and Google Assistant Connect, a tiny e-ink display that is sort of a smart refrigerator magnet which displays snippets of information your your upcoming day.</p>
<p>Onyx Boox seemed to have little to no presence …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cloudconfusing.com/2020/02/07/e-ink-monitors-ready-for-prime-time/">https://cloudconfusing.com/2020/02/07/e-ink-monitors-ready-for-prime-time/</a></em></p>]]>
            </description>
            <link>https://cloudconfusing.com/2020/02/07/e-ink-monitors-ready-for-prime-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25403462</guid>
            <pubDate>Sun, 13 Dec 2020 01:28:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bypassing traditonal Linux bottlenecks: Seastar in 2020]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25403351">thread link</a>) | @ta988
<br/>
December 12, 2020 | https://www.mikelangelo-project.eu/technology/seastar-library/ | <a href="https://web.archive.org/web/*/https://www.mikelangelo-project.eu/technology/seastar-library/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><!-- class="sidebar-none", class="sidebar-left", class="sidebar-right" -->

		
		
		<div>
			<div>

				
	
		
			<div id="content" role="main">

			
					
					<h2>Introduction</h2>
<p>As we noted above, the primary goal of OSv is to run existing Linux software, because most MIKELANGELO use cases required running existing code. Today’s Linux APIs – POSIX system calls, socket API, etc. – were formed by decades of Unix and Linux legacy, and some aspects of them are inherently inefficient. OSv can improve the performance of applications which use these APIs, but not dramatically. So our second goal in the development of the guest operating system was to propose new APIs which will offer new applications dramatically better performance than unmodified Linux applications – provided that the application is rewritten to use these new APIs,</p>
<p>In the research paper “OSv — Optimizing the Operating System for Virtual Machines”[<a href="#_edn1" name="_ednref1">[i]</a>], one of the benchmarks used was Memcached, a popular cloud application used for caching of frequently requested objects to lower the load on slower database servers. Memcached demonstrated how an unmodified network application can run faster on OSv than it does on Linux – a 22% speedup was reported in the paper.</p>
<p>22% is a nice speedup that we get just by replacing Linux in the guest by OSv, without modifying the application at all. But we wanted to understand if there is something we could do to get significantly higher performance. When we profiled memcached on OSv, we quickly discovered two performance bottlenecks:</p>
<ol>
<li><strong>Inefficiencies inherent in the Posix API</strong>, so OSv cannot avoid them and still remain POSIX compatible: For example, in one benchmark we noticed that 20% of the memcached runtime was locking and unlocking mutexes – almost always uncontended. For every packet we send or receive, we lock and unlock more than a dozen mutexes. Part of OSv’s performance advantage over Linux is that OSv uses a “netchannel” design for the network stack reducing locks (see the previous section), but we still have too many of them, and the Posix API forces us to leave many of them: For example, the Posix API allows many threads to use the same socket, allows many threads to modify the list of file descriptors, to poll the same file descriptors – so all these critical operations involve locks, that we cannot avoid. The socket API is also synchronous, meaning that when a send() returns the caller is allowed to modify the buffer, which forces the network code in OSv to not be zero-copy.</li>
<li><strong>Unscalable application design: </strong>It is not easy to write an application to scale linearly in the number of cores in a multi-core machine, and many applications that work well on one or two cores, scale very badly to many cores. For example memcached keeps some global statistics (e.g., the number of requests served) and updates it under a lock – which becomes a major bottleneck when the number of cores grow. What might seem like an acceptable solution – lock-free atomic variables – is also not scalable, because while no mutex is involved, atomic operations, and the <em>cache line bounces </em>(as different CPUs read and write the same variable), both become slower as the number of cores increase. So writing a really scalable application – one which can run on (for example) 64 cores and run close to 64 times faster than it does on a single core – is a big challenge and most applications are not as scalable as they should be – which will become more and more noticeable as the number of cores per machine continues to increase.</li>
</ol>
<p>In the aforementioned OSv paper, we tried an experiment to quantify the first effect – the inefficiency of the Posix API. The subset of memcached needed for the benchmark was very simple: a request is a single packet (UDP), containing a “GET” or “PUT” command, and the result is a single UDP packet as well. So we implemented in OSv a simple “packet filter” API: every incoming ethernet packet gets processed by a function (memcached’s hash-table lookup) which immediately creates the response packet. There is no additional network stack, no locks or atomic operations (we ran this on a single CPU), no file descriptors, etc. The performance of this implementation was an impressive 4 times better than the original memcached server.</p>
<p>But while the simple “packet filter” API was useful for the trivial UDP memcached, it was not useful for implementing more complex applications, for example applications which are asynchronous (cannot generate a response immediately from one request packet), use TCP or need to use multiple cores. Fast “packet filter”-like APIs are already quite commonly used (DPDK is a popular example) and are excellent to implement routers and similar packet-processing software; But they are not really helpful if you try to write a complex, highly-asynchronous network applications of the kind that is often used on the cloud – such as a NoSQL database, HTTP server, search engine, and so on.</p>
<p>For the MIKELANGELO project, we set out to design a new API which could answer both above requirements: An API which new applications can use to achieve optimal performance (i.e., the same level of performance achieved by the “packet filtering API” implementation), while at the same time allows the creation of complex real-life applications: The result of this design is <em>Seastar</em>:</p>
<ul>
<li>Seastar is a C++14 library, which can be used on both OSv and Linux. Because Seastar bypasses the kernel for most things, we do not expect additional speed improvements by running it on OSv – though some of OSv’s other advantages (such as image size and boot time) may still be relevant.</li>
<li>Seastar is designed for the needs of complex asynchronous server applications of the type common on the cloud – e.g., NoSQL databases, HTTP servers, etc. Here “asynchronous” means that a request usually triggers a cascade of events (disk reads, communication with other nodes, etc.) and only at a later time can the reply be composed.</li>
<li>Seastar provides the application the mechanisms it needs to solve both performance bottlenecks mentioned at the top of this section: Achieve optimal efficiency on one core, as well as scalability in the number of cores. We’ll explain how Seastar does this below.</li>
<li>Seastar can bypass the legacy kernel APIs, e.g., it can directly access the network card directly using DPDK. Seastar provides a full TCP/IP stack (which DPDK does not).</li>
</ul>
<p>We’ve reimplemented memcached using Seastar, and measured 2 to 4-fold performance improvement over the original memcached as well as near-perfect scalability to 32 cores (something which the “packet filter” implementation couldn’t do). Figure below for more details.</p>
<p><a href="https://www.mikelangelo-project.eu/wp-content/uploads/2017/07/SeastarMemcached.png" data-dt-img-description=""><img src="https://www.mikelangelo-project.eu/wp-content/uploads/2017/07/SeastarMemcached.png" alt="" width="938" height="580" srcset="https://www.mikelangelo-project.eu/wp-content/uploads/2017/07/SeastarMemcached.png 938w, https://www.mikelangelo-project.eu/wp-content/uploads/2017/07/SeastarMemcached-300x186.png 300w, https://www.mikelangelo-project.eu/wp-content/uploads/2017/07/SeastarMemcached-768x475.png 768w" sizes="(max-width: 938px) 100vw, 938px"></a>Figure: Performance of stock memcached (orange) vs Seastar reimplementation of memcached (blue), using TCP and the memaslap[<a href="#_edn2" name="_ednref2">[ii]</a>] workload generator – for varying number of cores The red bars show a non-standard memcached deployment using multiple separate memcached processes (instead of one memcached with multiple threads); Such a run is partially share-nothing (the separate processes do not share memory or locks) so performance is better than the threaded server, but still the kernel and network stack is shared so performance is not as good as with Seastar.</p>
<p>Applications that want to use Seastar will need to be rewritten to use its new (and very different) APIs. This requires significant investment, but also comes with significant rewards: The creator of the Seastar library, ScyllaDB, spent the last two years reimplementing the popular Cassandra distributed database in C++ and Seastar, and the result, “Scylla” (which, like Seastar and OSv, is released as open source[<a href="#_edn3" name="_ednref3">[iii]</a>]), has much higher throughput than Cassandra: Independent benchmarks[<a href="#_edn4" name="_ednref4">[iv]</a>] by Samsung showed Scylla to have between 10 to 37 times higher throughput than Cassandra on a cluster of 24-core machines in different workloads,&nbsp; In fact, the Scylla distributed database performs so well that it has become ScyllaDB’s main product, making the company highly dependent on Seastar’s exploitation. For this reason, ScylllaDB has been investing into Seastar additional efforts beyond what is being funded by the MIKELANGELO project, and plans to continue developing Seastar even after the project ends.</p>
<p>We use Scylla, the Seastar-based reimplementation of Cassandra, in the “Cloud Bursting” use case. But our goal is for Seastar to be a general-purpose APIs which will be useful to many kinds of asynchronous server applications, which are often run on the cloud. As such, we are making an effort of providing a rich, well-balanced, and well documented API, and also writing a tutorial on writing Seastar applications (a draft of which was already included in D4.4 and D4.5). At the time of this writing, we know of at least two other companies besides ScyllaDB which based their product on Seastar, and more are considering doing this.</p>
<h2>Seastar architecture</h2>
<p>How can an application designed to use Seastar be so much faster than one using more traditional APIs such as threads, shared memory and sockets? The short answer is that modern computer architecture has several performance traps that are easy to fall into, and Seastar ensures that you don’t by using the following architecture:</p>
<ol>
<li><strong>Sharded (“share nothing”) design:</strong></li>
</ol>
<p>Modern multi-core machines have shared memory, but using it incorrectly can drastically reduce an application’s performance: Locks are very slow, and so are processor-provided “lock-free” atomic operations and memory fences. Reading and writing the same memory object from different cores significantly slows down processing compared to one core finding the object in its cache (this phenomenon is known as “cache line bouncing”). All of these slow operations already hurt one-core performance, but get progressively slower as the number of cores increases, so it also hurts the scaling of the application to many cores.</p>
<p>Moreover, as the number of cores increases, multi-core machines inevitably become multi-socket, and we start seeing NUMA (non-uniform memory access) issues. I.e., some cores are closer to some parts of memory – and accessing the …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mikelangelo-project.eu/technology/seastar-library/">https://www.mikelangelo-project.eu/technology/seastar-library/</a></em></p>]]>
            </description>
            <link>https://www.mikelangelo-project.eu/technology/seastar-library/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25403351</guid>
            <pubDate>Sun, 13 Dec 2020 01:06:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bay Area to Austin: A Breakdown of the Financial Savings]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25403248">thread link</a>) | @musks_musk
<br/>
December 12, 2020 | https://www.thriftythoughts.io/silicon-hills/ | <a href="https://web.archive.org/web/*/https://www.thriftythoughts.io/silicon-hills/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.thriftythoughts.io/silicon-hills/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25403248</guid>
            <pubDate>Sun, 13 Dec 2020 00:46:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[To listen well, get curious]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25403240">thread link</a>) | @axiomdata316
<br/>
December 12, 2020 | https://www.benkuhn.net/listen/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/listen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><figure><a href="https://www.benkuhn.net/listen/shawarma.jpg" title="fullsize"><img width="414" height="139" src="https://www.benkuhn.net/listen/shawarma_hu8d3539d292afb8dcad4d284a93a9ab60_28658_828x278_resize_q75_box.jpg" srcset="https://www.benkuhn.net/listen/shawarma_hu8d3539d292afb8dcad4d284a93a9ab60_28658_828x278_resize_q75_box.jpg 2x, https://www.benkuhn.net/listen/shawarma_hu8d3539d292afb8dcad4d284a93a9ab60_28658_414x139_resize_q75_box.jpg"></a><figcaption><a href="https://twitter.com/thecassiecao/status/1276506378388017155/photo/1">source</a></figcaption></figure><p>A common piece of interacting-with-people advice goes: “often when people complain, they don’t want help, they just want you to listen!”</p><p>For instance, <em>Nonviolent Communication</em>:<sup><label for="sn0">✻</label><span><span><sup>✻</sup>
<em>Nonviolent Communication</em>, ch. 7.</span></span></sup></p><blockquote><p>It is often frustrating for someone needing empathy to have us assume that they want reassurance or “fix-it” advice.</p></blockquote><p><em>Active Listening</em>:<sup><label for="sn1">†</label><span><span><sup>†</sup>
<a href="https://www.benkuhn.net/listen/active-listening.pdf">Active Listening</a>, p. 2</span></span></sup></p><blockquote><p>Similarly, advice and information are almost always seen as efforts to change a person and thus serve as barriers to his self-expression and the development of a creative relationship.</p></blockquote><p>You can find similar advice in most books on relationships, people management, etc.</p><p>This always used to seem silly to me. If I complain at my partner and she “just listens,” I’ve accomplished nothing except maybe made her empathetically sad. When I complain at people, I want <em>results</em>, not to grouse into the void!<sup><label for="sn2">‡</label><span><span><sup>‡</sup>
Empirically, I did notice that I usually got better results from listening than from giving advice. So I inferred that this advice was true for other people, but not me, because other people didn’t actually want to fix their problems.</span></span></sup></p><p>Frequently the “just listen” advice comes with tactical tips, like “reflect what people said back to you to prove that you’re listening.” For instance, consider these example dialogues from <em>Nonviolent Communication</em>:<sup><label for="sn3">§</label><span><span><sup>§</sup>
<em>Nonviolent Communication</em>, Chapter 7, Exercise 5.5, 5.6 and solutions.</span></span></sup></p><blockquote><p>Person A: How could you say a thing like that to me?</p><p>Person B: Are you feeling hurt because you would have liked me to agree to do what you requested?</p></blockquote><p>Or:</p><blockquote><p>Person A: I’m furious with my husband. He’s never around when I need him.</p><p>Person B: So you’re feeling furious because you would like him to be around more than he is?</p></blockquote><p>I say this with great respect for <em>Nonviolent Communication</em>, but these sound like a <a href="https://en.wikipedia.org/wiki/ELIZA" target="_blank">1970s-era chatbot</a>. If I were Person A in either of these dialogues my next line would be “yes, you dingbat—can you turn the nonviolence down a couple notches?” I’d feel alienated knowing that someone is going through their NVC checklist on me.</p><hr><p>Recently, I realized why people keep giving this weird-seeming advice. Good listeners <em>do</em> often reflect words back—but not because they read it in a book somewhere. Rather, it’s <a href="https://en.wikipedia.org/wiki/Cargo_cult_science" target="_blank">cargo cult advice</a>: it teaches you to imitate the surface appearance of good listening, but misses what’s actually important, the thing that’s <em>generating</em> that surface appearance.</p><p>The generator is curiosity.</p><p>When I’ve listened the most effectively to people, it’s because I was intensely curious—I was trying to build a <em>detailed, precise</em> understanding of what was going on in their head. When a friend says, “I’m furious with my husband. He’s never around when I need him,” that one sentence has a huge amount underneath. How often does she need him? What does she need him for? Why isn’t he around? Have they talked about it? If so, what did he say? If not, why not?</p><p>It turns out that <a href="http://johnsalvatier.org/blog/2017/reality-has-a-surprising-amount-of-detail" target="_blank">reality has a surprising amount of detail</a>, and those details can matter a lot to figuring out what the root problem or best solution is. So if I want to help, I can’t treat those details as a black box: I need to <a href="https://www.lesswrong.com/posts/B7P97C27rvHPz3s9B/gears-in-understanding" target="_blank">open it up and see the gears inside</a>. Otherwise, anything I suggest will be wrong—or even if it’s right, I won’t have enough “shared language” with my friend for it to land correctly.</p><p>Some stories from recent memory:</p><ul><li><p>When we started doing a pair programming rotation at Wave, I suggested that, to make scheduling easier, we designate a default time when pairing sessions would happen. A coworker objected that this seemed authoritarian. I was extremely puzzled, but they’d previously mentioned being an anarchist, so I was tempted to just chalk it up to a political disagreement and move on. But instead I tried to get curious and explore more deeply whatever “political” models were generating that disagreement. After a lot of digging into what was or wasn’t authoritarian for them and why, it turned out the disagreement was because they’d missed the word “default” and thought I was suggesting a single <em>mandatory</em> time for pair programming.</p></li><li><p>My partner, Eve, wrote a post about Polish attitudes about sex, with some details that upset her (Polish) parents. When her parents told her that, she initially got very stressed about having to have a conversation to calm them down. I thought she shouldn’t be worried and the conversation would be fine, but of course just telling her that wasn’t very helpful. Instead, I summoned up my curiosity and asked lots of questions about her relationship with her parents, her parents’ relationship with each other, each of their relationships with Catholicism, etc. By the end of the conversation, after thinking through all the baggage involved, Eve agreed with me, and her attitude about the upcoming conversation shifted from impending doom to compassionate curiosity about where her parents were coming from.</p></li><li><p>I was stressed by work and complained to Eve about some things that I felt frustrated and stuck about. Instead of suggesting solutions, she kept asking for more details until she had more or less a complete snapshot of my mental state. At that point, she observed that every time I mentioned feeling sad, I sounded contemptuous and exasperated with myself. She hypothesized that I wasn’t giving myself permission to be sad. The “solution” to my problem ended up being to give me a big hug and let me cry on her shoulder for a bit, after which I immediately felt much less stressed.</p></li></ul><p>In each case, the “helper” tried to learn about the “complainer’s” reality in as much detail as possible—not just the problem, but the whole person and whatever else was behind the immediate issue. And that’s what made it possible for them to actually help.</p><p>It often feels like I understand enough to be helpful without knowing all those details. But when I think that, I’m usually wrong: I end up giving bad advice, based on bad assumptions, and the person I’m talking to ends up having to do a bunch of work to argue with me and correct my bad assumptions. That makes the conversation feel disfluent and adversarial instead of collaborative.</p><p>It turns out this is a really common failure mode of helping-conversations, which is what I think generates the old saw at the beginning of this post, that “sometimes people don’t want help, just to be listened to.”</p><p>But I think that’s actually too nice to the helper, and uncharitable to the complainer (in that it assumes they weirdly don’t care about solving their problem). What’s really going on is probably that your advice is bad, because you didn’t really listen, because you weren’t curious enough.</p><hr><p>When I’m curious about what someone’s saying, I often do repeat things back to them in my own words. But it’s because I’m genuinely curious, not because I’m checking off the “reflect words” box in my “be a good listener” checklist. That means I do it in a way that sounds like my natural speech, instead of mimicking them like a chatbot.</p><p>When done this way, reflective listening feels validating rather than alienating. It’s a way of demonstrating that I care a lot about what someone has to say. Putting their idea into my own words shows them that I’ve fully digested it, and helps us establish a shared language in which to talk about it. That, in turn, makes the conversation fluent and collaborative, rather than a zigzag of bad assumptions and corrections.</p><p>So the right advice isn’t “listen harder and repeat everything back”—you won’t be genuine if you’re just imitating the surface appearance of a good listener. Instead, be humble and get curious! Remind yourself that there’s a ton of detail behind whatever you’re hearing, and try to internalize all of it that you can. Once you’ve done that, your advice will be more likely hit the mark, and you’ll be able to communicate it clearly.</p></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/listen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25403240</guid>
            <pubDate>Sun, 13 Dec 2020 00:45:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why radio receivers won’t tune 800-900 MHz]]>
            </title>
            <description>
<![CDATA[
Score 339 | Comments 120 (<a href="https://news.ycombinator.com/item?id=25403163">thread link</a>) | @jtakkala
<br/>
December 12, 2020 | https://computer.rip/2020-11-28%20the%20verboten%20band.html | <a href="https://web.archive.org/web/*/https://computer.rip/2020-11-28%20the%20verboten%20band.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://computer.rip/2020-11-28%20the%20verboten%20band.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25403163</guid>
            <pubDate>Sun, 13 Dec 2020 00:32:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Narrowing of AI Research? With Juan Mateos-Garcia]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25403088">thread link</a>) | @andreyk
<br/>
December 12, 2020 | https://www.letstalkai.show/e/narrowing-ai-research/ | <a href="https://web.archive.org/web/*/https://www.letstalkai.show/e/narrowing-ai-research/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>


		
			<div id="post-16043523">
				<p><a href="https://www.letstalkai.show/">
										<img src="https://pbcdn1.podbean.com/imglogo/image-logo/7703921/Lets_Talk_Logo.jpg"></a></p><div>
				<div>
					
					<p>Dec 11th, 2020 by <a title="Posts by Skynet Today">Skynet Today</a> </p>
				</div>

				<div>
					 <p><span>An interview with Juan Mateos-Garcia, the Director of Data Analytics at Nesta (the UK's Innovation Foundation) where he leads a team of data scientists, developers, visualisers and innovation experts who use new datasets, analytics methods and visualisation tools to inform innovation and AI policy. We focus on the recent paper <a href="https://arxiv.org/abs/2009.10385">A narrowing of AI research?</a></span><span>, which he co-wrote with Joel Klinge and Konstantinos Stathoulopoulos.</span></p>
<p>Subscribe: <a href="https://feed.podbean.com/aitalk/feed.xml">RSS</a> | <a href="https://podcasts.apple.com/us/podcast/lets-talk-ai/id1502782720">iTunes</a> | <a href="https://open.spotify.com/show/17HiNdxcoKJLLNibIAyUch">Spotify</a> | <a href="https://www.youtube.com/channel/UCKARTq-t5SPMzwtft8FWwnA">YouTube</a></p>
<div>
<p>Check out coverage of similar topics at <a href="http://www.skynettoday.com/">www.skynettoday.com</a></p>
<p>Theme: Deliberate Thought Kevin MacLeod (incompetech.com)</p>
</div>
									</div>

				

   <p><span id="postbar_16043523"> <span> | </span><a href="https://www.podbean.com/site/EpisodeDownload/PBF4CE03UT6GE" target="_blank">Download</a> </span></p>			</div>

		


	</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.letstalkai.show/e/narrowing-ai-research/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25403088</guid>
            <pubDate>Sun, 13 Dec 2020 00:19:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs as a Musical Instrument (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25402702">thread link</a>) | @mantlepro
<br/>
December 12, 2020 | https://blog.josephwilk.net/art/emacs-as-a-musical-instrument.html | <a href="https://web.archive.org/web/*/https://blog.josephwilk.net/art/emacs-as-a-musical-instrument.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A simple goal, to directly connect Emacs to running hardware and software synthesisers with <strong>realtime</strong> control. Emacs as a musical instrument.</p>

<p>I already use code to control synths (as <a href="http://www.repl-electric.com/">Repl-Electric</a>) but there is a level of indirection between the code and the effect on the music. You push keys on your computer keyboard and nothing happens. Only when you run the code does the music change. I wanted to add realtime control to my performances while still remaining in code and Emacs. Bringing the performance closer to musical instruments were instant feedback is a core part of the performance experience.</p>

<p>I could use external hardware, like a MidiFighterTwister (<a href="https://www.midifighter.com/#Twister">https://www.midifighter.com/#Twister</a>) or TouchOSC (<a href="https://hexler.net/software/touchosc">https://hexler.net/software/touchosc</a>) but I’ve found the context switch of moving between coding to twiddling dials on hardware expensive. The code is my composition process, so it makes sense for the direct control to also be there.</p>

<h2>Playing the Emacs</h2>

<p>Sculpting sound live with Emacs.</p>

<p><iframe src="https://player.vimeo.com/video/270101496?color=ff0179" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe></p>


<h2>Scratching Samples with Emacs</h2>

<p>Doing crazy things with Emacs starts to open more doors in musical expression. Since we can control music hardware with Emacs, we can control the playhead position within a sample. Much like the needle of a record player.</p>

<p>Say we map the position of your cursor in the Emacs buffer to the position of the playback head. By moving around in your buffer you can scratch the sample.</p>

<p><iframe src="https://player.vimeo.com/video/265189088?color=ff0179" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe></p>


<h2>Emacs sending Musical Controls</h2>

<p>Sending messages to musical synths using midi and OSC.</p>

<h3>Emacs Communicating with Open Sound Control</h3>

<p>First we need a client within Emacs which will send OSC (<a href="https://en.wikipedia.org/wiki/Open_Sound_Control">https://en.wikipedia.org/wiki/Open_Sound_Control</a>) using UDP packets. There is thankfully already an Emacs package for this: osc: <a href="https://delysid.org/emacs/osc.html">https://delysid.org/emacs/osc.html</a></p>

<p>Creating a client and sending OSC messages:</p>

<figure><figcaption><span></span></figcaption><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
<span>10</span>
<span>11</span>
<span>12</span>
<span>13</span>
<span>14</span>
<span>15</span>
<span>16</span>
<span>17</span>
<span>18</span>
</pre></td><td><pre><code><span><span></span><span>(</span><span>require</span> <span>'osc</span><span>)</span>
</span><span><span>(</span><span>defvar</span> <span>osc-client</span> <span>nil</span> <span>"Connection to send OSC From Emacs"</span><span>)</span>
</span><span>
</span><span><span>(</span><span>defun</span> <span>osc-make-client</span> <span>(</span><span>host</span> <span>port</span><span>)</span>
</span><span>  <span>(</span><span>make-network-process</span>
</span><span>   <span>:name</span> <span>"OSC client"</span>
</span><span>   <span>:host</span> <span>host</span>
</span><span>   <span>:service</span> <span>port</span>
</span><span>   <span>:type</span> <span>'datagram</span>
</span><span>   <span>:family</span> <span>'ipv4</span><span>))</span>
</span><span>
</span><span><span>(</span><span>defun</span> <span>osc-connect</span> <span>()</span>
</span><span>  <span>(</span><span>if</span> <span>osc-client</span>   <span>(</span><span>delete-process</span> <span>osc-client</span><span>))</span>
</span><span>  <span>(</span><span>setq</span> <span>osc-client</span> <span>(</span><span>osc-make-client</span> <span>"localhost"</span> <span>4561</span><span>)))</span>
</span><span>
</span><span><span>(</span><span>osc-connect</span><span>)</span>
</span><span>
</span><span><span>(</span><span>osc-send-message</span> <span>osc-client</span> <span>ADDRESS</span> <span>*ARGUMENTS</span><span>)</span>
</span></code></pre></td></tr></tbody></table></div></figure>


<h3>Emacs Communicating with Midi</h3>

<p>A lot of musical hardware and software only supports midi. We are sending OSC 😕. Hence we need a quick way of converting our OSC message to a midi message. Why don’t you send midi from Emacs directly? It’s not a new thought (<a href="https://www.emacswiki.org/emacs/EmacsMidi">https://www.emacswiki.org/emacs/EmacsMidi</a>), but I’ve seen no examples of getting it working. My answer here is path of least resistance, and I don’t feel like implementing the midi standard in Elisp.</p>

<p>Luis Lloret (<a href="https://github.com/llloret">https://github.com/llloret</a>) has create the lovely C++ lib <code>osmid</code> (<a href="https://github.com/llloret/osmid">https://github.com/llloret/osmid</a>) for converting between midi and OSC. And its FAST.</p>

<p>It compiles into two binary servers:</p>

<ul>
<li>m2o – midi to OSC</li>
<li>o2m – OSC to midi</li>
</ul>


<p>We launch the o2m server in a shell which will be listening on port <code>4561</code> and will forward on OSC messages as midi.</p>

<figure><figcaption><span></span></figcaption><div><table><tbody><tr><td><pre><span>1</span>
</pre></td><td><pre><code><span><span></span><span>osmid/o2m</span> <span>-b</span> <span>-i</span> <span>4561</span> <span>-O</span> <span>4562</span> <span>-m</span> <span>6</span>
</span></code></pre></td></tr></tbody></table></div></figure>


<p>Midi has a fixed argument format while OSC is very flexible. Hence this a little jiggery pokery in get the source OSC message mapping to the midi arguments.</p>

<p>OSC message format:</p>

<figure><figcaption><span></span></figcaption><div><table><tbody><tr><td><pre><span>1</span>
</pre></td><td><pre><code><span><span></span><span>(</span><span>osc-send-message</span> <span>osc-client</span> <span>MIDI_HOST</span> <span>MIDI_CHANNEL</span> <span>MIDI_CONTROL_CODE</span> <span>MIDI_VALUE</span><span>)</span>
</span></code></pre></td></tr></tbody></table></div></figure>


<p>For MIDI_HOST I’m using the <code>Inter-application communication</code> (IAC) driver on Mac. This registers <code>IAC Bus 1</code> as a midi device. I’m also sending a <code>control change</code> message, shaping the parameters rather than triggering notes. This could be any of the supported midi messages (<code>note_on</code>, <code>note_off</code>, <code>pitch_bend</code>, <code>poly_pressure</code>, etc).</p>

<p>Example of OSC to midi message:</p>

<figure><figcaption><span></span></figcaption><div><table><tbody><tr><td><pre><span>1</span>
</pre></td><td><pre><code><span><span></span><span>(</span><span>osc-send-message</span> <span>osc-client</span> <span>"/IAC Bus 1/control_change"</span> <span>9</span> <span>100</span> <span>127</span><span>)</span>
</span></code></pre></td></tr></tbody></table></div></figure>


<p>The channel <code>9</code> and control code <code>100</code> seem magical. I’m routing those to synths via Ableton Live.</p>

<p><img src="https://blog.josephwilk.net/images/midi-routing.png"></p>

<p>Any DAW would support this or you could send direct to a synth and not use <code>IAC</code>. Your MIDI_HOST would be the name your midi device registers as.</p>

<h2>Emacs GUI for Musical Controls</h2>

<p>We have the backend for sending live midi controls to hardware. Now we need some interface within Emacs to trigger it.</p>

<h3>Modelling Encoders in Emacs</h3>

<p>The design is based on the idea of dial encoders commonly found in music hardware.</p>

<p><img src="https://blog.josephwilk.net/images/pots.jpg"></p>

<p>Our dials in code are float numbers. To turn our dials we borrow the idea from the Chrome inspector of scrolling through possible numeric values with the arrow keys.</p>

<p><img src="https://blog.josephwilk.net/images/chromeinspector.png"></p>

<p>In our case every increment/decrement will send a live message to our synths.</p>

<p>We need to extract from the active Emacs buffer the thing we are trying to control. Finding the:</p>

<ul>
<li>Synth (the musical instrument)</li>
<li>Parameter (ie. amp, pan, lfo, filter)</li>
<li>Value 0-127 (whatever value we want to set param)</li>
</ul>


<p>Example changing the filter param:</p>

<figure><figcaption><span></span></figcaption><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
</pre></td><td><pre><code><span><span></span><span>zerocoast_cc</span> <span>lfo:</span> <span>0.49</span><span>,</span> <span>filter:</span> <span>&lt;0.80&gt;</span>
</span><span>
</span><span><span>;;; Synth =&gt; zerocoast</span>
</span><span><span>;;; Parameter =&gt; filter</span>
</span><span><span>;;; Value =&gt; 101.6 (127*0.80)</span>
</span></code></pre></td></tr></tbody></table></div></figure>


<p>Here comes a lot of Elisp and some hairy regexes.</p>

<h4>Emacs Code</h4>

<p>Thingatpt (<a href="https://www.emacswiki.org/emacs/ThingAtPoint">https://www.emacswiki.org/emacs/ThingAtPoint</a>) which is part of the standard lib is extremely useful here.</p>

<figure><figcaption><span></span></figcaption><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
<span>10</span>
<span>11</span>
<span>12</span>
<span>13</span>
<span>14</span>
<span>15</span>
<span>16</span>
<span>17</span>
<span>18</span>
<span>19</span>
<span>20</span>
<span>21</span>
<span>22</span>
<span>23</span>
<span>24</span>
<span>25</span>
<span>26</span>
<span>27</span>
<span>28</span>
<span>29</span>
<span>30</span>
<span>31</span>
<span>32</span>
<span>33</span>
<span>34</span>
<span>35</span>
<span>36</span>
<span>37</span>
<span>38</span>
<span>39</span>
<span>40</span>
<span>41</span>
<span>42</span>
<span>43</span>
<span>44</span>
<span>45</span>
<span>46</span>
<span>47</span>
<span>48</span>
<span>49</span>
<span>50</span>
<span>51</span>
<span>52</span>
<span>53</span>
<span>54</span>
</pre></td><td><pre><code><span><span></span><span>(</span><span>require</span> <span>'thingatpt</span><span>)</span>
</span><span>
</span><span><span>;;The patterns for matching the beginning and</span>
</span><span><span>;;end of something that looks like a float</span>
</span><span>
</span><span><span>(</span><span>put</span> <span>'float</span> <span>'end-op</span>       <span>(</span><span>lambda</span> <span>()</span> <span>(</span><span>re-search-forward</span> <span>"[0-9-]*\.[0-9-]*"</span> <span>nil</span> <span>t</span><span>)))</span>
</span><span><span>(</span><span>put</span> <span>'float</span> <span>'beginning-op</span> <span>(</span><span>lambda</span> <span>()</span> <span>(</span><span>if</span> <span>(</span><span>re-search-backward</span> <span>"[^0-9-\.]"</span> <span>nil</span> <span>t</span><span>)</span> <span>(</span><span>forward-char</span><span>))))</span>
</span><span>
</span><span><span>(</span><span>defun</span> <span>change-number-at-point</span> <span>(</span><span>fn-float-op</span><span>)</span>
</span><span>  <span>"Check if the thing under the cursor looks like a</span>
</span><span><span>  float and if so change it with `fn-float-op`.</span>
</span><span><span>  `fn-float-op` is passed the name of the synth,</span>
</span><span><span>  parameter and float value."</span>
</span><span>
</span><span>  <span>(</span><span>let*</span> <span>((</span><span>bounds</span> <span>(</span><span>bounds-of-thing-at-point</span> <span>'float</span><span>))</span>
</span><span>         <span>(</span><span>float-val</span> <span>(</span><span>buffer-substring</span> <span>(</span><span>car</span> <span>bounds</span><span>)</span> <span>(</span><span>cdr</span> <span>bounds</span><span>)))</span>
</span><span>         <span>(</span><span>cursor-point</span> <span>(</span><span>point</span><span>)))</span>
</span><span>    <span>(</span><span>goto-char</span> <span>(</span><span>car</span> <span>bounds</span><span>))</span>
</span><span>    <span>(</span><span>re-search-backward</span> <span>"^\\([^\n]+\\): "</span> <span>(</span><span>line-beginning-position</span><span>)</span> <span>t</span><span>)</span>
</span><span>    <span>(</span><span>let</span> <span>((</span><span>synth-str</span> <span>(</span><span>match-string</span> <span>1</span> <span>nil</span><span>)))</span>
</span><span>      <span>(</span><span>goto-char</span> <span>(</span><span>car</span> <span>bounds</span><span>))</span>
</span><span>      <span>(</span><span>delete-char</span> <span>(</span><span>length</span> <span>float-val</span><span>))</span>
</span><span>      <span>(</span><span>let*</span> <span>((</span><span>parts</span> <span>(</span><span>split-string</span> <span>(</span><span>string-trim</span> <span>synth-str</span><span>)</span> <span>" "</span><span>))</span>
</span><span>             <span>(</span><span>synth-and-param</span> <span>(</span><span>if</span> <span>m</span>
</span><span>                                  <span>(</span><span>concat</span>
</span><span>                                    <span>(</span><span>replace-regexp-in-string</span>
</span><span>                                     <span>"^#"</span> <span>""</span> <span>(</span><span>first</span> <span>parts</span><span>))</span>
</span><span>                                     <span>"/"</span>
</span><span>                                     <span>(</span><span>first</span> <span>(</span><span>reverse</span> <span>parts</span><span>)))</span>
</span><span>                                 <span>nil</span><span>)))</span>
</span><span>        <span>(</span><span>insert</span>
</span><span>         <span>(</span><span>format</span> <span>"%.2f"</span>
</span><span>                 <span>(</span><span>funcall</span> <span>fn-float-op</span>
</span><span>                   <span>(</span><span>string-to-number</span> <span>float-val</span><span>)</span>
</span><span>                   <span>synth-and-param</span><span>)))))</span>
</span><span>    <span>(</span><span>goto-char</span> <span>cursor-point</span><span>)))</span>
</span><span>
</span><span><span>(</span><span>defun</span> <span>inc-float-at-point</span> <span>()</span>
</span><span>  <span>"Increase a float value and send OSC message."</span>
</span><span>  <span>(</span><span>interactive</span><span>)</span>
</span><span>  <span>(</span><span>change-number-at-point</span>
</span><span>    <span>(</span><span>lambda</span> <span>(</span><span>float-val</span> <span>synth-and-param</span><span>)</span>
</span><span>      <span>(</span><span>let</span> <span>((</span><span>new-float</span> <span>(</span><span>min</span> <span>1.00</span> <span>(</span><span>+</span> <span>float-val</span> <span>0.01</span><span>))))</span>
</span><span>        <span>(</span><span>route-osc-message</span> <span>synth-and-param</span> <span>new-float</span><span>)</span>
</span><span>        <span>new-float</span><span>))))</span>
</span><span>
</span><span><span>(</span><span>defun</span> <span>dec-float-at-point</span> <span>()</span>
</span><span>  <span>"Decrease a float value and send OSC message."</span>
</span><span>  <span>(</span><span>interactive</span><span>)</span>
</span><span>  <span>(</span><span>change-number-at-point</span>
</span><span>    <span>(</span><span>lambda</span> <span>(</span><span>float-val</span> <span>synth-and-param</span><span>)</span>
</span><span>      <span>(</span><span>let</span> <span>((</span><span>new-float</span> <span>(</span><span>max</span> <span>0.00</span> <span>(</span><span>-</span> <span>float-val</span> <span>0.01</span><span>))))</span>
</span><span>        <span>(</span><span>route-osc-message</span> <span>synth-and-param</span> <span>new-float</span><span>)</span>
</span><span>        <span>new-float</span><span>))))</span>
</span></code></pre></td></tr></tbody></table></div></figure>


<p>We map our <code>synth-and-param</code> to the correct midi port and channel.</p>

<figure><figcaption><span></span></figcaption><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
</pre></td><td><pre><code><span><span></span><span>(</span><span>defun</span> <span>route</span><span>—</span><span>osc-msg</span> <span>(</span><span>synth-and-param</span> <span>float-val</span><span>)</span>
</span><span>  <span>(</span><span>when</span> <span>synth-and-param</span>
</span><span>    <span>(</span><span>let</span> <span>((</span><span>midi-val</span> <span>(</span><span>round</span> <span>(</span><span>*</span> <span>127.0</span> <span>float-val</span><span>)))</span>
</span><span>          <span>(</span><span>host</span> <span>"/IAC Bus 1/control_change"</span><span>))</span>
</span><span>      <span>(</span><span>if</span> <span>(</span><span>not</span> <span>osc-client</span><span>)</span> <span>(</span><span>osc-connect</span><span>))</span>
</span><span>      <span>(</span><span>cond</span>
</span><span>       <span>((</span><span>string-match</span> <span>synth-and-param</span> <span>"zerocoast/filter"</span><span>)</span>
</span><span>         <span>(</span><span>osc-send-message</span> <span>osc-client</span> <span>host</span> <span>9</span> <span>100</span> <span>midi-val</span><span>)))))))))</span>
</span></code></pre></td></tr></tbody></table></div></figure>


<p>Finally the keybindings that trigger our instrument mode:</p>

<figure><figcaption><span></span></figcaption><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
</pre></td><td><pre><code><span><span></span><span>(</span><span>global-set-key</span> <span>[(</span><span>meta</span> <span>up</span><span>)]</span>    <span>'inc-float-at-point</span><span>)</span>
</span><span><span>(</span><span>global-set-key</span> <span>[(</span><span>meta</span> <span>down</span><span>)]</span>  <span>'dec-float-at-point</span><span>)</span>
</span></code></pre></td></tr></tbody></table></div></figure>


<h3>Encoder ASCII Art</h3>

<p>We are almost done. For fun I’ve added a visually aid to the position of the float encoder. Midi messages are generally limited to 0-127 values, so if we map that to 0-100% we can create a visual representation of the current setting.</p>

<figure><figcaption><span></span></figcaption><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
<span>10</span>
<span>11</span>
<span>12</span>
<span>13</span>
<span>14</span>
<span>15</span>
<span>16</span>
<span>17</span>
<span>18</span>
<span>19</span>
<span>20</span>
<span>21</span>
<span>22</span>
<span>23</span>
<span>24</span>
<span>25</span>
<span>26</span>
<span>27</span>
<span>28</span>
<span>29</span>
<span>30</span>
<span>31</span>
<span>32</span>
<span>33</span>
<span>34</span>
<span>35</span>
<span>36</span>
<span>37</span>
<span>38</span>
<span>39</span>
<span>40</span>
<span>41</span>
<span>42</span>
<span>43</span>
<span>44</span>
<span>45</span>
<span>46</span>
<span>47</span>
<span>48</span>
<span>49</span>
<span>50</span>
<span>51</span>
<span>52</span>
<span>53</span>
<span>54</span>
</pre></td><td><pre><code><span><span></span><span>(</span><span>defun</span> <span>code-&gt;pots</span> <span>(</span><span>beg</span> <span>end</span><span>)</span>
</span><span>  <span>"Add a ASCII encoder bar to anything that looks like a tweakable float"</span>
</span><span>
</span><span>  <span>(</span><span>interactive</span> <span>"r"</span><span>)</span>
</span><span>  <span>(</span><span>save-excursion</span>
</span><span>    <span>(</span><span>let</span> <span>((</span><span>inhibit-read-only</span> <span>t</span><span>))</span>
</span><span>      <span>(</span><span>remove-text-properties</span> <span>beg</span> <span>end</span> <span>'</span><span>(</span><span>read-only</span> <span>t</span><span>))</span>
</span><span>      <span>(</span><span>goto-char</span> <span>end</span><span>)</span>
</span><span>      <span>(</span><span>setq</span> <span>i</span> <span>0</span><span>)</span>
</span><span>      <span>(</span><span>while</span> <span>(</span><span>re-search-backward</span> <span>"_cc .+:\s*\\([0-9]*.[0-9]+\\)\s*\n"</span> <span>beg</span> <span>t</span><span>)</span>
</span><span>        <span>(</span><span>setq</span> <span>i</span> <span>(</span><span>+</span> <span>1</span> <span>i</span><span>))</span>
</span><span>        <span>(</span><span>let</span> <span>((</span><span>full</span>     <span>(</span><span>round</span> <span>(</span><span>*</span> <span>MAX-LENGTH</span> <span>(</span><span>string-to-number</span> <span>(</span><span>match-string</span> <span>1</span><span>))))))</span>
</span><span>          <span>(</span><span>let</span> <span>((</span><span>empty</span>  <span>(</span><span>-</span> <span>MAX-LENGTH</span> <span>full</span><span>)))</span>
</span><span>            <span>(</span><span>goto-char</span> <span>(</span><span>match-beginning</span> <span>0</span><span>))</span>
</span><span>            <span>(</span><span>end-of-line</span><span>)</span>
</span><span>            <span>(</span><span>let</span> <span>((</span><span>start-pnt</span> <span>(</span><span>point</span><span>))</span>
</span><span>                  <span>(</span><span>pad</span> <span>(</span><span>if</span> <span>(</span><span>&gt;=</span> <span>empty</span> <span>0</span><span>)</span>
</span><span>                           <span>(</span><span>make-string</span> <span>empty</span> <span>?╌</span><span>)</span>
</span><span>                         <span>""</span><span>)))</span>
</span><span>              <span>(</span><span>insert</span> <span>(</span><span>concat</span> <span>" #╟"</span>
</span><span>                              <span>(</span><span>make-string</span> <span>full</span> <span>?▓</span><span>)</span>
</span><span>                              <span>"▒░"</span>
</span><span>                              <span>pad</span>
</span><span>                              <span>"╢"</span><span>))</span>
</span><span>              <span>(</span><span>put-text-property</span> <span>start-pnt</span> <span>(</span><span>point</span><span>)</span> <span>'read-only</span> <span>t</span><span>)))))</span>
</span><span>      <span>(</span><span>align-regexp</span> <span>beg</span> <span>(</span><span>+</span> <span>(</span><span>*</span> <span>i</span> <span>106</span><span>)</span> <span>end</span><span>)</span> <span>"\\(\\s-*\\)#"</span><span>))))</span>
</span><span>
</span><span><span>(</span><span>defun</span> <span>pots-update</span> <span>(</span><span>new-float</span> <span>old-float</span><span>)</span>
</span><span>  <span>"Update ASCII encoder bar for float being changed"</span>
</span><span>
</span><span>  <span>(</span><span>interactive</span><span>)</span>
</span><span>  <span>(</span><span>if</span> <span>(</span><span>not</span> <span>(</span><span>=</span> <span>new-float</span> <span>old-float</span><span>))</span>
</span><span>      <span>(</span><span>let</span> <span>((</span><span>old-full</span> <span>(</span><span>round</span> <span>(</span><span>*</span> <span>100.0</span> <span>old-float</span><span>)))</span>
</span><span>            <span>(</span><span>full</span>     <span>(</span><span>round</span> <span>(</span><span>*</span> <span>100.0</span> <span>new-float</span><span>))))</span>
</span><span>        <span>(</span><span>let</span> <span>((</span><span>empty</span>  <span>(</span><span>-</span> <span>MAX-LENGTH</span> <span>full</span><span>))</span>
</span><span>              <span>(</span><span>movement</span> <span>(</span><span>-</span> <span>full</span> <span>old-full</span><span>))</span>
</span><span>              <span>(</span><span>bmovement</span> <span>(</span><span>-</span> <span>old-full</span> <span>full</span><span>)))</span>
</span><span>          <span>(</span><span>save-excursion</span>
</span><span>            <span>(</span><span>when</span> <span>(</span><span>re-search-forward</span> <span>"#╟"</span> <span>(</span><span>line-end-position</span><span>)</span> <span>t</span><span>)</span>
</span><span>              <span>(</span><span>goto-char</span> <span>(</span><span>match-end</span> <span>0</span><span>))</span>
</span><span>              <span>(</span><span>let</span> <span>((</span><span>inhibit-read…</span></span></code></pre></td></tr></tbody></table></div></figure></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.josephwilk.net/art/emacs-as-a-musical-instrument.html">https://blog.josephwilk.net/art/emacs-as-a-musical-instrument.html</a></em></p>]]>
            </description>
            <link>https://blog.josephwilk.net/art/emacs-as-a-musical-instrument.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25402702</guid>
            <pubDate>Sat, 12 Dec 2020 23:12:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rizin – a free and open-source Reverse Engineering framework]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25402690">thread link</a>) | @homarp
<br/>
December 12, 2020 | https://rizin.re/posts/announcing-rizin/ | <a href="https://web.archive.org/web/*/https://rizin.re/posts/announcing-rizin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>We are excited to announce Rizin — a <strong>free</strong> and <strong>open-source</strong> Reverse Engineering framework, providing a complete binary analysis experience with features like Disassembler, Hexadecimal editor, Emulation, Binary inspection, Debugger, and more.</p><p>Rizin is a fork of radare2 with a focus on usability, stability, and working features, which strives to provide a welcoming environment for developers and users alike. Rizin was founded by a group of the core developers of radare2 and Cutter who contributed to the project in one way or the other in the past years and together constructed the Core group of radare2. With the establishment of Rizin, we are committed to creating an environment and a project which will be aligned with our values and vision.</p><p>During recent years, the environment that was created in radare2 was one where many of us felt stressed, disrespected, and unwelcome. Moreover, the number of users of radare2 grew every year, and we held the ultimate responsibility to provide them a stable, usable framework. As the core developer team, we have come to the conclusion that it is impossible for us to continue to pursue the goal of making radare2 better under the current circumstances and environment, and we decided to move forward on our own and fork the project. Cutter, the Graphical User Interface for radare2, and its entire team will also join Rizin and will use it as its backend.</p><p>Rizin is a newborn project that was created from radare2, hence more and more changes and differences will appear over time. A lot of efforts were put into improving our workflows, putting more tests in place, improving the API, removing redundant features, and more. We hope to provide better consistency between releases, making the framework more trustworthy to users.</p><p>We are also working to create a more inclusive and diverse community that will be inviting for new contributors and users. As an initial step, we adopted a <a href="https://rizin.re/code-of-conduct">Code of Conduct</a> that we believe is aligned with our values and with the community we want to create around Rizin.</p><p>Finally, we know and understand that now it is our turn to prove that Rizin can become a tool you can trust and enjoy using, and a community in which you feel welcome. We invite you to read our answers to your <a href="https://rizin.re/posts/faq/">Frequently Asked Questions</a> and join our communities on <a href="https://im.rizin.re/">Mattermost</a> and other chat platforms.</p></div></article></div></div>]]>
            </description>
            <link>https://rizin.re/posts/announcing-rizin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25402690</guid>
            <pubDate>Sat, 12 Dec 2020 23:11:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bulk loading into PostgreSQL: Options and comparison]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25402430">thread link</a>) | @eatonphil
<br/>
December 12, 2020 | https://www.highgo.ca/2020/12/08/bulk-loading-into-postgresql-options-and-comparison/ | <a href="https://web.archive.org/web/*/https://www.highgo.ca/2020/12/08/bulk-loading-into-postgresql-options-and-comparison/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
<p>You have a file, possibly a huge CSV, and you want to import its content into your database. There are lots of options to do this but how would you decide which one to use. More often than not the&nbsp;question is how much time would the&nbsp;bulk load would take. I found my self&nbsp;doing the same few days back when I wanted to design a data ingestion process for PostgreSQL where we needed to bulk load around 250GB of data from CSV files every 24 hours.</p>



<p>Goto solution for bulk loading into PostgreSQL is the native copy command. But one limitation with the copy command is that it requires the CSV file to be placed on the server. So I decided to do a simple comparison of bulk loading options and techniques.</p>



<p>In short I wanted to see the performance difference of loading the data into standard vs unlogged tables and want to compare the loading time difference between loading into table that has an index vs drop-index-&gt;load-&gt;recreate-index option.</p>



<p>Moreover, I wanted to see the performance difference of COPY command, client-side copy command, loading through file_fdw, and pg_bulkload for each of the above options.</p>



<h2>Database and system settings</h2>



<p>Since the intention was to do a relative performance comparison among different data loading techniques and options, so using the personal MacBook Pro running macOS Catalena with 16GB of RAM, 2.7 GHz Quad-Core Intel Core i7 processor, and 500 GB SSD disk was good enough to serve the purpose. </p>



<p>For database I compiled PostgreSQL v12 from source code with default configure options. I left most of the configuration parameter to their default values and only changed the below mentioned settings.</p>



<pre><code>shared_buffers = 2GB
work_mem = 400MB
maintenance_work_mem = 640MB
</code></pre>



<h2>Sample data and schema</h2>



<p>For the purpose of this exercise, I downloaded a sample CSV file from <a href="http://eforexcel.com/wp/downloads-18-sample-csv-files-data-sets-for-testing-sales/">http://eforexcel.com/wp/downloads-18-sample-csv-files-data-sets-for-testing-sales/</a> with 5million rows.</p>



<p>The sample CSV file contains 5 million rows, 14 columns and 624MB in size.</p>



<p><img loading="lazy" width="986" height="71" src="https://www.highgo.ca/wp-content/uploads/2020/12/1-3.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/1-3.png 986w, https://www.highgo.ca/wp-content/uploads/2020/12/1-3-300x22.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/1-3-768x55.png 768w" sizes="(max-width: 986px) 100vw, 986px"></p>



<p><img loading="lazy" width="2618" height="390" src="https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv.png 2618w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-300x45.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-1024x153.png 1024w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-768x114.png 768w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-1536x229.png 1536w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-2048x305.png 2048w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-1920x286.png 1920w" sizes="(max-width: 2618px) 100vw, 2618px"></p>



<p>To keep things simple I created a sales_record table in PostgreSQL with one to one mapping with the CSV file</p>



<pre>CREATE TABLE sales_record 
(
	region VARCHAR,
	country VARCHAR,
	item_type VARCHAR,
	sales_channel VARCHAR,
	order_priority CHAR,
	order_date DATE,
	order_id INT,
	ship_date DATE,
	unit_sold INT,
	unit_price FLOAT,
	unit_cost FLOAT,
	total_revenue FLOAT,
	total_cost FLOAT,
	total_profit FLOAT
);</pre>



<p>Along with that I also wanted to see the impact of having an index on the bulk load performance, So for tests that&nbsp;require&nbsp;an INDEX, I created a <code>btree</code> index on the <code>country</code> column.</p>



<pre><code>CREATE INDEX country_idx ON sales_record USING btree (country);</code></pre>



<h2>Load using the <a href="https://www.postgresql.org/docs/current/sql-copy.html">COPY</a> command</h2>



<p><code>COPY</code>&nbsp;moves data between&nbsp;PostgreSQL&nbsp;tables and standard file-system files. The copy command comes in two variants, COPY TO and COPY FROM. The former copies the table content to the file, while we will use the latter to load data into the table from the file.</p>



<pre><code>COPY sales_record FROM '/Users/muhammadusama/work/data/5m_Sales_Records.csv' CSV HEADER;</code></pre>



<h2>Load using <a href="https://www.postgresql.org/docs/current/app-psql.html">psql</a> ‘\copy’</h2>



<p>‘<code>\copy</code>‘ is a <code>psql</code> operation that runs an&nbsp;SQL&nbsp;<a href="https://www.postgresql.org/docs/current/sql-copy.html">COPY</a>&nbsp;command, but instead of the server reading or writing the specified file,&nbsp;<code>psql</code>&nbsp;(client) reads or writes the file and routes the data between the server and the local file system. This means that file accessibility and privileges are those of the local user, not the server, and no SQL superuser privileges are required.</p>



<pre>\copy sales_record FROM '/Users/muhammadusama/work/data/5m_Sales_Records.csv' csv header;</pre>



<h2>Through <a href="https://www.postgresql.org/docs/current/file-fdw.html">file_fdw</a></h2>



<p>The foreign-data wrapper&nbsp;<code>file_fdw</code>, can be used to access data files in the server’s file system, or to execute programs on the server and read their output.&nbsp;We can also use the file_fdw to load data from CSV to PostgreSQL tables.</p>



<pre><code>-- Create file_fdw extension and foreign server
CREATE  EXTENSION file_fdw ;
CREATE SERVER file_fdw_server FOREIGN DATA WRAPPER file_fdw; 

-- Define the foreign table that points to our CSV file
CREATE FOREIGN TABLE foreign_sales_record (
	region VARCHAR,
	country VARCHAR,
	item_type VARCHAR,
	sales_channel VARCHAR,
	order_priority CHAR,
	order_date DATE,
	order_id INT,
	ship_date DATE,
	unit_sold INT,
	unit_price FLOAT,
	unit_cost FLOAT,
	total_revenue FLOAT,
	total_cost FLOAT,
	total_profit FLOAT) SERVER file_fdw_server
		OPTIONS (
			format 'csv',
			header 'false' ,
			filename '/Users/muhammadusama/work/data/5m_Sales_Records.csv',
			delimiter ',',
			null '');

-- Copy the data from foreign table to local table
INSERT INTO sales_record SELECT * from foreign_sales_record;
</code></pre>



<p>Although <code>file_fdw</code> is not expected to be as fast as COPY command when it comes to loading the data but it provides a lot of flexibility and options when it comes to pre-processing the data before loading.</p>



<h2><a href="https://github.com/ossc-db/pg_bulkload">pg_bulkload</a> tool</h2>



<p>pg_bulkload is also a very interesting option when it comes to high speed data loading. Its an open-source tool that achieves its performance by skipping the shared buffers and WAL logging.</p>



<pre><code>-- CREATE pg_bulkload extension
$ bin/psql -c "CREATE EXTENSION pg_bulkload" postgres

-- Create control file with appropriate contents
$ more sample_csv.ctl 
WRITER = PARALLEL
OUTPUT = public.sales_record  # [&lt;schema_name&gt;.]table_name
INPUT = /Users/muhammadusama/work/data/5m_Sales_Records.csv  # Input data location (absolute path)

TYPE = CSV           # Input file type
QUOTE = "\""         # Quoting character
ESCAPE = \           # Escape character for Quoting
DELIMITER = ","      # Delimiter

-- Execute pg_bulkload utility
$ bin/pg_bulkload -d postgres -h localhost sample_csv.ctl
</code></pre>



<h2>Results</h2>



<p>Below chart shows the time taken by each tool/command to load 5 million rows from CSV file </p>



<p><img loading="lazy" width="2162" height="756" src="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM.png 2162w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-300x105.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-1024x358.png 1024w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-768x269.png 768w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-1536x537.png 1536w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-2048x716.png 2048w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-1920x671.png 1920w" sizes="(max-width: 2162px) 100vw, 2162px"></p>



<p><img loading="lazy" width="1784" height="1092" src="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM.png 1784w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM-300x184.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM-1024x627.png 1024w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM-768x470.png 768w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM-1536x940.png 1536w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM-1764x1080.png 1764w" sizes="(max-width: 1784px) 100vw, 1784px"></p>



<p><img loading="lazy" width="1904" height="1204" src="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM.png 1904w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM-300x190.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM-1024x648.png 1024w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM-768x486.png 768w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM-1536x971.png 1536w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM-1708x1080.png 1708w" sizes="(max-width: 1904px) 100vw, 1904px"></p>



<p><img loading="lazy" width="1794" height="928" src="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM.png 1794w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM-300x155.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM-1024x530.png 1024w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM-768x397.png 768w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM-1536x795.png 1536w" sizes="(max-width: 1794px) 100vw, 1794px"></p>



<h2>Conclusion</h2>



<p>Each method for data loading has its own pros and cons which may make one preferred choice over others for a particular use case. But when it comes to raw performance pg_bulkload is a clear winner with COPY and /copy line up behind while file_fdw stands at the last place.</p>



<p>While no matter which data loading method we use, loading into an indexed table is always slow, So do consider <code>drop-index-&gt;load-&gt;create-index </code>when you have a huge data to be loaded.</p>



<blockquote><p>Comparison of all the tools was an apple to apple comparison with both client and server were running on the same machine. So, /copy had no network overhead. In the case of PostgreSQL server and client are on different<em> machines the /copy command may not perform as well as these above results.</em></p></blockquote>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><a href="https://www.highgo.ca/author/muhammad-u/"><img src="https://www.highgo.ca/wp-content/uploads/2019/08/usama.jpg" alt="" itemprop="image"></a></p><div><p>Muhammad Usama is a database architect / PostgreSQL consultant at HighGo Software and also Pgpool-II core committer. Usama has been involved with database development (PostgreSQL) since 2006, he is the core committer for open source middleware project Pgpool-II and has played a pivotal role in driving and enhancing the product. Prior to coming to open source development, Usama was doing software design and development with the main focus on system-level embedded development. After joining the EnterpriseDB, an Enterprise PostgreSQL’s company in 2006 he started his career in open source development specifically in PostgreSQL and Pgpool-II. He is a major contributor to the Pgpool-II project and has contributed to many performance and high availability related features.</p></div></div>                                                                    </div></div>]]>
            </description>
            <link>https://www.highgo.ca/2020/12/08/bulk-loading-into-postgresql-options-and-comparison/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25402430</guid>
            <pubDate>Sat, 12 Dec 2020 22:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Geometry by Design: Settlement Patterns of the Mound Villages in SW Amazonia]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25402350">thread link</a>) | @Thevet
<br/>
December 12, 2020 | https://journal.caa-international.org/articles/10.5334/jcaa.45/ | <a href="https://web.archive.org/web/*/https://journal.caa-international.org/articles/10.5334/jcaa.45/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://journal.caa-international.org/articles/10.5334/jcaa.45/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25402350</guid>
            <pubDate>Sat, 12 Dec 2020 22:25:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Declouding Chinese WiFi Plugs]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25402218">thread link</a>) | @kn100
<br/>
December 12, 2020 | https://kn100.me/declouding-chinese-wifi-plugs/ | <a href="https://web.archive.org/web/*/https://kn100.me/declouding-chinese-wifi-plugs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>So, it turns out that a lot of smart gear from many manufacturers, including ones
you’ve almost certainly heard of, comes from a company called Tuya. They
seem to make all sorts of fun IOT gear, which all connects to the Tuya cloud.
What Tuya seem to do is sell whitelabeled ‘versions’ of their products to various
brands who then sell them as if they’d manufactured them themselves. Very
interesting right?</p>
<p>There exist many projects to de-cloud these products.
One such project is called Tuya-convert. Tuya convert is a tool which emulates
the update server these plugs connect to in order to deliver custom firmware to
the plug that it can run. This project is amazing, since it gives you the option
of declouding IOT gear without having to do any hardware modification at all.
Unfortunately, it seems this project is dead in the water right now since Tuya
is playing the typical cat and mouse game with the developers, and currently
Tuya is winning.</p>
<p>I wanted to open my plug up next, in order to figure out what made it tick.
Opening it was fairly difficult, given that it is held together with nothing but
clips. After running a guitar pick around the seam a few times, I finally
managed to pop the cover. What I found really surprised me. There was a board in
there that looked suspiciously like an ESP based platform. Further searching led
me to realise that the board in there that handles all the ‘smart’ of the plug
is actually an implementation of the ESP8285 - which is a cheaper (but just as
hackable) variant of the ESP8286, which is related to the ESP32.</p>
<p>Consulting the easily accessible datasheet for the TYWE-2s - we can quickly
identify the serial pins, and solder wires to them. Then, we can connect it up
to some Serial to USB adaptor and could flash whatever code we wanted to the ESP.
I however wanted a nicer solution. I found Tasmota. Tasmota is another open source
project that runs on these plugs that allows you to connect them up to HomeAssistant
or similar. It works really well. Read on for the process:</p>
<ol>
<li>Buy a WiFi plug.</li>
</ol>
<figure>
<img src="https://kn100.me/images/plug-package.jpg"> <figcaption>
<h4>My plug, the Ultrabrite Smart Power.</h4>
</figcaption>
</figure>
<ol start="2">
<li>Open it up, in order to figure out where the serial pins are. We can see on mine,
there is a nice TYWE-2S module which unfortunately due the construction of this plug
has awkward to access serial pins.</li>
</ol>
<figure>
<img src="https://kn100.me/images/plug-board-1.jpeg"> <figcaption>
<h4>Front view of the board.</h4>
</figcaption>
</figure>
<figure>
<img src="https://kn100.me/images/plug-board-2.jpeg"> <figcaption>
<h4>View of the pins we need access to. Unfortunately, the two options you have for getting access to them are to desolder the enormous blobs of solder holding the mains plug pins on, or to cut into the case. I went with cutting into the case. Ugly, but works.</h4>
</figcaption>
</figure>
<ol start="3">
<li>Put it back together, and cut a hole where the pins you need are.</li>
</ol>
<figure>
<img src="https://kn100.me/images/plug-hole.jpg"> <figcaption>
<h4>View of the hole I cut. I cut it using a hacksaw and a hot knife.</h4>
</figcaption>
</figure>
<figure>
<img src="https://kn100.me/images/plug-pins.jpg"> <figcaption>
<h4>The hole on a different plug didn't go as cleanly. This photo shows the relevant pins though.</h4>
</figcaption>
</figure><p>
See <a href="https://developer.tuya.com/en/docs/iot/device-development/module/wifi-module/we-series-module/wifie2smodule?id=K9605u79tgxug">here</a> for a data sheet to help identify which pins are which.</p>
<ol start="4">
<li>Solder some female jumper wires to the pins we need access to, and connect them to
the serial interface. You’ll want to make especially super sure that your interface
is clever enough to support 3.3v logic level input. Otherwise you risk frying the
board or just failing to flash the board repeately. Ask me how I know.</li>
</ol>
<figure>
<img src="https://kn100.me/images/plug-serial.jpg"> <figcaption>
<h4>Soldered wires, and a serial adaptor. I specifically used one of the cheap CH340G adaptors from eBay</h4>
</figcaption>
</figure>
<ol start="5">
<li>Grab <a href="https://github.com/tasmota/tasmotizer">Tasmotiser</a> and follow the instructions. Make very sure your wifi details are correct, otherwise you’ll end up having to flash the plug a second time.</li>
</ol>
<figure>
<img src="https://kn100.me/images/plug-tasmotizer.png"> <figcaption>
<h4>Soldered wires, and a serial adaptor. I specifically used one of the cheap CH340G adaptors from eBay</h4>
</figcaption>
</figure>
<ol start="6">
<li>Once your Tasmotised plug is up, and you can control it from a web interface, it’s time
to interface it with your HomeAssistant install. Your Home Assistant install must already
have the MQTT integration. Ensure you enable <em>discovery</em> in your Home Assistant MQTT config.</li>
</ol>
<figure>
<img src="https://kn100.me/images/plug-mqtt-discovery.png"> <figcaption>
<h4>Enabling MQTT discovery in Home Assistant.</h4>
</figcaption>
</figure>
<ol start="7">
<li>Go back to the web server for your WiFi Plug. Configure the MQTT server to connect to
the MQTT server your Home Assistant is connected to.</li>
</ol>
<figure>
<img src="https://kn100.me/images/plug-mqtt.png"> <figcaption>
<h4>The web interface for configuring mqtt. See the Tasmota docs for more info.</h4>
</figcaption>
</figure>
<ol start="8">
<li>In this same interface, head to console, and type <code>SetOption19 1</code>. This causes the plug
to emit an autodiscovery message which should mean Home Assistant picks up on your plug and
you should now be able to control it in Home Assistant, sans cloud!</li>
</ol>
</div></div>]]>
            </description>
            <link>https://kn100.me/declouding-chinese-wifi-plugs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25402218</guid>
            <pubDate>Sat, 12 Dec 2020 22:08:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some types of mistake that I have made: Chess and uncommitted obsession]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25401977">thread link</a>) | @nakedlunch
<br/>
December 12, 2020 | https://pkld.io/some-types-of-mistake-that-i-have-made/ | <a href="https://web.archive.org/web/*/https://pkld.io/some-types-of-mistake-that-i-have-made/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
            <p>I have recently started to play chess again after a multiple year hiatus*. I have discovered that chess is very much not like riding a bike, and I have made (many!) repeated mistakes. </p><p>As my frustration increased, I began to suspect that the cause of these mistakes was not due to a lack of brainpower, or understanding of rules of the game, or because I am bad at pattern matching. I think that they mirror a few key types of blunder that I often make in my personal and professional life, as well as pointing towards a deeper underlying fact about myself.</p><p>This seemed like a good chance for self-reflection. </p><h2 id="myopia">Myopia</h2><p>Despite the fact that the best chess is now played by computers, I still find something romantic about the game. While I'm playing, I go through intense swings of emotion: from the cold logic of the opening, probing the opponents defensive shape, to the giddy excitement of closing the net of a trap - to fear and then frustration as you realise that you were hunted rather than hunter.</p><p>I like that it is accessible to the layman, with (in my experience) a relatively consistent learning curve. As you play, you can feel yourself slowly getting better at understanding the rhythm of the game, spotting dangers earlier and mounting attacks with increasing sophistication. </p><p>However, there is one place in my game where I have seen far less improvement. I often focus hard on advancing my pieces on one part of the board, and totally miss the position that has opened at the other end. Often, I will find myself having played 5 or more moves in one corner while hunting their king, only to not see that I have opened myself up on the opposite side.</p><p>This inability to see the wood from the trees has in the past been reflected elsewhere in my personal and professional life. Sure, there are times when it is a useful attribute - being able to go deep into a subject, break it down and rebuild that understanding from the bottom up. But just like not seeing the danger on the other side of the board, this often leads to failing, or falling behind, in achieving the overall goal.</p><p>I often find myself not doing the thing I was supposed to do, because I was instead doing something simpler and/or more exciting (often deeper into the detail). On a few spare hours on a recent weekend, I was meant to be clearing out a cupboard in my flat, and ended up spending most of it cleaning up a scruffy pair of trainers. </p><p>That might not sound more interesting, but I have always enjoyed repetitive physical tasks with low decision-making load that have a visible outcome. I now have nice white shoes, but that cupboard is still full of old junk.</p><p>For a while at work, I have been trying to build a dashboard to display some key metrics about a project. When I started, I ended up finding something else out about a part of the calculation for some metric - and then spent four or so hours digging deep to see how that was being calculated, and writing up notes on how we might do it differently.</p><p>Was this entirely a waste of time? No, because I gained a far greater understanding of that underlying issue, and now have a roadmap to fixing it (or, as is probably more useful, passing on that information to someone else to fix). But I don't have a dashboard.</p><p>In chess or life, very rarely is it possible to achieve the biggest goals without strategic thinking about how to get to where you need to be, and consistent focus on that plan. I have to remind myself to at regular intervals take a step back, look at the bigger picture, and re-evaluate what's important. </p><p>Maybe then I'll stop losing so many damn games.</p><h2 id="doubling-down">Doubling down </h2><p>I recently listened to a <a href="https://www.bbc.co.uk/programmes/p074yx4h">podcast from Radio 4's More or Less series</a> about detecting fraud in chess. It was interesting that it's pretty simple to detect the difference between players who are cheating and those who are not - the players who aren't have a plan. </p><p>Computers don't need a plan, because they re-assess the situation every move and aren't afraid to work their way out of a position if that's the best thing to do.</p><p>I find myself utterly unable to think like this. When I put into place a plan - perhaps a piece exchange that will lead to pinning a bishop - if the opposition behaves differently to how I expected I will try and find another way to make it work. I lose a lot of games chasing a plan that isn't available any more.</p><p>I enjoy walks with my partner where we don't follow a trail, and therefore are reliant on getting lost then un-lost later on. On a positive note, this often leads to discovering interesting things that aren't on the map. It also leads to walking for much longer than you intended to.</p><p>A few weeks ago we were lost, and I was following what I thought was the right trail to get us back to the car. It was not, which became evident as my GPS managed to catch up with where we were (far, far away from where I assumed). </p><p>Instead of doing the smart thing, which was to turn back and figure out where we lost the trail, I attempted several madcap schemes to take us down muddy, steep bike trails which were vaguely in the right direction. We eventually turned around, much grumpier than we started (at me, in my partner's case).</p><p>When I run experiments in my job that I have a too-strongly-held hypothesis will work, the problems begin when they don't. My first reaction is to question the data, ending up with rewriting well-tested code, which is not a good use of time. My second is to wonder whether a slightly different application of the same idea would have worked better. This is a very easy trap to fall into, but where you have limited time and resources it's rarely worthwhile to tweak after a failed test (as opposed to testing something different).</p><p>When two reasonably powerful computers play checkers, which I understand to be a weakly solved game†, it always results in a draw. Which is to say - there is no such thing as an interesting game where mistakes are impossible. The important thing is to know when to reverse course once you've made one.</p><h2 id="uncommitted-obsession">Uncommitted obsession</h2><p>I'm not entirely sure whether this is a unique type of mistake, a superset of the other two, or something entirely different. </p><p>Here's a relevant example; over the past few weeks, I have played over 250 games of chess on my phone or laptop. These games are of the type where you have a 20 minute time limit between you, and I would estimate they take on average 5-8 minutes per game. </p><p>That's more than an entire day of online chess, up from 0 minutes in the last 10 years. I've just played far too much chess lately.</p><p>Being an obsessive comes with positive and negative traits, but I think there is a real difference between <em>committed </em>and<em> uncommitted</em> obsession. The former leads both to great works and occasionally madness, while the latter leads to journeyman status in a lot of subject areas. I fall very neatly into the latter category.</p><p>Being an <em>uncommitted obsessive</em> means diving into a subject in a way that is deep but not broad, and then never returning to it. It means, as previously mentioned, if I can't find an answer quickly I will waste an evening but then move on before I have true understanding of the subject area. On my laptop I have quite literally hundreds of started but unfinished novels, ideas for art, business ideas, podcasts (and much more). </p><p>At work, I have sampled everything in the growth/product/marketing cabinet, from sending physical mailers, to using MTurk to scrape targeting data, to building peer-to-peer referral schemes and creating APIs for partners. I am no expert in any of these things, but I have seen enough to know a little about each.</p><p>I have to face it now; I will never be <strong>very</strong> good at chess, because it's not in my nature to master anything - I am great at getting passably good at a lot of things.</p><p>If you're an uncommitted obsessive, I think the key thing is to set yourself an intention when you get into something new. Asking myself where a good stopping point might be - and then re-assessing once I am there - helps to reduce the number of things that feel incomplete. Perhaps I should set myself a specific ELO score to hit on chess.com, then once I'm there I can quit for good (or not!)</p><p>Understanding mistakes and where they come from allows you to lean in to where your strengths are rather than fighting against them. I am a journeyman that loves to dive deep but not broad into stuff, and I don't think I should change that. That doesn't mean accepting the negatives - I think it means giving yourself checks and balances against them so that they don't weigh you down.</p><p>Now if I could just stop playing chess for a few minutes, I might finish a second post.</p><hr><p><em>* Although I was not directly inspired by Netflix's The Queens Gambit, I think some friends mentioning they were trying chess after watching may have seeded the idea in my brain. I have since watched it and enjoyed it, though it's not really about the chess (and for good reason).</em></p><div><p>†<em> I find the subject of whether chess can be solved quite interesting. This is <a href="https://web.archive.org/web/20090325220009/http://www.spectrum.ieee.org/print/5379">an article from 2007</a> on how checkers was solved, with some discussion on why chess is much harder and may require quantum computing.</em></p></div>
    </div>
        
</article>                            </main>
</div>
        </div></div>]]>
            </description>
            <link>https://pkld.io/some-types-of-mistake-that-i-have-made/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25401977</guid>
            <pubDate>Sat, 12 Dec 2020 21:39:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ultra-Low Precision 4-Bit Training of Deep Neural Networks [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25401792">thread link</a>) | @pizza
<br/>
December 12, 2020 | https://papers.nips.cc/paper/2020/file/13b919438259814cd5be8cb45877d577-Paper.pdf | <a href="https://web.archive.org/web/*/https://papers.nips.cc/paper/2020/file/13b919438259814cd5be8cb45877d577-Paper.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>—¦ö‡›rßØO£ñWè¦šß7�-µ§ëÌ±ƒk4ƒÞp~	£xÊ
1˜¦+ýF”j`~à†&nbsp;}h»ƒ&nbsp;®žçÃ^&lt;2�ÞÖæv&amp;£AŠ}Ã+Ìg÷Ä³ß¢(îúÁÓØÃôÞLþæÔ	–ûÏ9«ýS?˜Cÿ%dQ„B¤^ä,)²`kè™z·ƒ
zKŽïuøÄ;=Ôd*¦~èàn”Sòî™b:Ë%ô&gt;$¯�°
°.˜ˆ
N#]}^Ã—uS’¸9ìä™1ÄÀ³-�º/$Éó0F"p’ë¶sZÊÙ;òkOÀN¥�Ã™p¼ú]§+³óì‚z]æÏ®ÃÓß¢$"j¢1˜OË{‹Ó©��-w¶û’%2Ð"gþË½®kÓìÜ{YÌ¶Íd`›~| ŽÉ9JÏ&amp;ö;d
Ã$ìÏ´fú¶½[bîÊ&gt;�ºìŸÆ“í¼¼½Ýßx2uÍ#ýeçIÓPæ³ÌöqŠ§#ŠÄ;*öp¤4àÆN&lt;=ÚóW�ãwmç^UA»íM«¨À±‰ÝjìØÚÊÙ„“³ÃÁT¢�Üá`¬b¤¾+I’Py
ƒ9p:P¼×&gt;àt£ë§?ÍE”umíGS€m­ö‘íT
³îÎ|&amp;»Í�\M!;ç­,˜ÌÓ‘_¥Â$ÃÎ§;ØÝù&nbsp;ƒâIÑØ™{EcÍ'S¬x¾±æøŠŸIÕkÊ•ç– \¶3BèUFið­mœžÒÔebq&amp;ŽovªLž‡PÄËS$—I¦é$Ðy"Nbf
OÍ�þhÊ¡~ó�Ÿ•‡~"¨Qµ'h³$þ ëB­:Žƒ+	˜}v©òv&gt;ÜpÉ��q¦¤"/&amp;D%Ž¾ûáÀ€`@!¸Z¡Ðãš-Ôã­��“�&nbsp;2´K/¶{çeØõ.P1Å³¸M®	ç8X\ºãàÉcÎ]&amp;Aö“(Ê¹’ÌðÉ�zgJ$n9å&lt;‚Ó¡1ÌÑôˆ¿[&amp;Ÿï—çõ³~”§ž§MÛlz»k¬KHºñïÔm¿0î/K€•’¼åiæ¾¸Tw„U©˜{]vþ¼}&lt;ÖÕgn«ö®üîio]ŒbèªÊì/p¶×]åZí
„SHijÓÍ‡K—Ø¿Ê¶uŽÞ&lt;¿*E¯‘_ðK÷¼u¤@cpùÎŠ‘7x?p8Ÿµ9Ö	±ê[¢oß‰Ô“sY§ª¾È62qÝ&nbsp;;‰'@†¨Ásám5–Nêk®# 3$wÿâ?ÎX_peíà‰ËRW&nbsp;`ùÍ£¾=s$‹VÌí’šßÜÝõ¾t&amp;T6×qô\�±Ò�nñá"È+K,ó©íG¹çÔƒ+~˜RÂe½Xˆ¡þD¨ëÔ#q#^
‡$iz²•áÑs¢m2­.¼‘fo$*Û”õX9ôG¸TCãÌÙäEB{]°&amp;.™W½Ñ’æ·8N—'ð‹ü‚J^�D]V/©&gt;:˜•Ÿ%Kb”“åKzŒiä1ïRäFD…Z’¨«C2M–TW‰X„J¥K*]&amp;A†&nbsp;Z�‘Hq1UÝ&lt;j&nbsp;£Q;€„Ù’éØ…ðÅ=WF •å—d·ËƒH®±D|uE•ˆ/&amp;ô‚šúªgçb–ÏB¤A…¦­7ƒ_F¤ÀÕæHÁÊ®k	9»5÷ÐO²kÍEÚ(àÊð"y|ðœß/QY&nbsp;:-¦ö=ˆoš(PÅ6Ãë;£9PA°È¼õì›Õ–€ËŒ¥÷S+§K?b|EGM`…fFQÅŒ¶&amp;ÔBÍÜY¯Cá+Ðˆ&nbsp;bÂÊŽRÎy:8[ø	Ä�å¾c¨íƒÏ¶\£ÊÚôá‹*IáåNÓYb’AìE"ØR¡G–Õ&lt;�ÛRŒ�„Øz$¦×B¦­¸qõ¼býi5vØ¸f�zJVvtœq Ëó¥_Ë&amp;.ØòR"™arAuŒ2S¡BâXž•^�•ƒ,VK²�žYçÆÑTÔ"k**º%¯ÃV¦©9ŸÂF,4ŸD€ï¾Ý`g¡æ¹kÇÝ¹Ëƒtß
ÏÍñ-Ï;ƒbgªÍEÓ|î@U=/o
âÆL7x¼^ù…JêpÝþyW˜Óò¶mûáÅ*�Ê§.„ÓïÑtî³ASú§0·Ãaí23¦fÑþym¹W�dî!²”ÅD¦õsäCýx.aC†y´�#e«‡™üØÚÆo-2Ä¥4(*éÔ£ð—ßÃÍÅ\¹�•­q1‚Žvî�ÆiàÏ­µ&lt;:Œõ`�µkÆgcš€‹¿æÃ•«Š%S"»ä›5Jå’ìÚëó"J]V\F_P€¼d=ë�—Í¡fŸœ©kmgI\¢sxƒÔõ·&amp;Ò±@¢J}’{›p2–2û?N4¹„Œ';g˜†²µûF“ÇÁO¦4”²}©�)R˜qÌóûÀ9îÓ'¿ËF£Ñ"Q}=Di˜'røåSO8ŠüÄ}pˆ$¶z@`AÞ#€l{ä‹žç Ì_v”û²CK¹Ã…[c&gt;¹5†³·ÒdYPi¥3=üÐø[ì‹òIX(�¤úŽÚ÷£«M
j=&nbsp;¯¸±pyÅ7åjf�†çHMþl¥&lt;¥Ñô‰çìßctÖc@á±§’Ë"Ì‡s…ê®Jaž„‘ôhäaìàQ¾-ù*Þ¨!•‡Êå}×|¡ófŠe1q&gt;t‡~ÉGM?m‹ßy¸¹ñ-ô¹O»îèªuš²ØY_Îìä`'u¿JÁ»ÃLfh�â°¾³‘jêÕ_·ÍƒéÌó=Ó¯.sC�ûÌÜ‰¿ëZ²ùÌù½ÿÚê&amp;ÔßÐÛß¿»ç…8Š#jvü/¿¸¯	�¬'yžwx­]épúÑêR.:û
endstream
endobj
164 0 obj
&lt;&lt; /Filter /FlateDecode /Length1 1499 /Length2 6795 /Length3 0 /Length 7811 &gt;&gt;
stream
xœ�xTTkÛ6Ò )%é€t]ÒÒ-ÝÂÌÃ2Cw‡t— H‡4Ò(HK	‚”t¨Ä7z&lt;ïùÎûÿkýÿšµöìçºû¹¯û™=›�YÏ€OŒ°ƒ¨ à(&gt;A~&nbsp;@IÛÀL…ù�@!B66C(
ù'd3†¸!¡¸ÔÿÒPrƒØ¢ÐØC[ZQh¸Ã‚ÂA1)Aq)  Jþ­ˆp“&lt;´õ€‚Úü
‚$dSB¸z»AQè8ß8A\AIIqÞßæˆdhÛ¢!.èˆ [À‚BPÞÿrÁùÀ…r•ðôôä·uAò#Üd¹xžP”#à	qó€€¿JèØº@þ”ÆOÈ0t„"ÿ ìQž¶n€AA8mâCÜèèu-€®+þ—²Ö_
¼€?›äü�»?Ö¿Aá¿�mA „‹«-Ü
wØCa€®Š?ÊÅ°…ƒ)ÚÂ�´½­‡-fk‡Vø�º-@EA`‹®ðO}H�Ô…äGBa¿jøå½ÍÊp°ÂÅG!	å÷ê¡÷Ý[àOs�áO¸ïß+{(lÿ«°»«€úÄ¢þð�"üs€&nbsp;¢@I11QAä	ârøÀÐÛò[øF×àïëŠpØ£Ë€øCí!è/B_¤­€rs‡øûþoÁ¿W„‚‚0„ØA&nbsp;pÂ¼£aˆý_ktÿÝ&nbsp;^ š~‚à¯Ïî¬Ð#à0ïÔ·Xà‘‚ª�Ž&gt;ÏŸ’ÿ#TTDx|ù„$|’b@€&nbsp;&nbsp;&nbsp;@\\àÿo?z¶Ð?yü/[u¸= ùWºè}ú;e�?àü3 \€ûÒA&nbsp;™pþCtK&nbsp;(„¾þÓý·Éÿ�å¿¼ü?‰þß©¸Ã`¿åœ)ür[(Ìû�š¹î(ôh#Ð³ÿoUÈ_£«
CÝ]þ[ªŽ²EOƒÜÍh&gt;A~&nbsp;È_8©õ‚€õ&nbsp;(�ã_¬ù7ú5o0(¢‡@B�0h+ ð¿dè!9£O$šš¿Eôý;®2„ÿ6!Q1€­››­7!º×è•(ÀW=•`ˆ×o2øáÚ€®Ñ`�p#üÕXqI€€î/è÷J(°³uû ÀÐñ!OÜÑúEƒ.P¸;ò54àCA]ÑYýÇ@ÀÝf}D&nbsp;7Ý¬¿%è®0wä?.þUÈÝÍ
mñ›zèrÿ^ÿ&gt;K /ˆp~’sªë¸¨U&nbsp;÷äÛÁ]^éŠN4ë‹E±Ï&gt;÷uÔÂËV�|¢ø\}w8Co®<bbÆ�žûàbÔËòmnðrºz>
C¹oMñˆ¯`ðûÉAç0&amp;ž½F~˜¤ÏHúØÛ‚#Ådæ2\¼Gxóå—¢«.ä¦¹ä.ÀPrFÆœN�ŠSÈëÚÅ|jÆÌº‚2³$‹¿ãf‘én¨n4v…ù®ØKûÝ{Í"&gt;kèÓ§w¹ý}ÂÇ…š½5bÕ´”&gt;ÌyÃÉ´TI¹¯�ìŠ¢gJåi‰,´Å.ìKX�Å—~Nö·'
»79è(ßÖ
xßìÞ€�‘ÉëY:f°YÏ1ü.@|·%9Ú‘·6ƒU‘­Œq6”yX#ËïÅ¦fà6t-ÜhO!JËÎÍ´0?6Çâ„
[¿{ñ8.;IPÈ*M&amp;1ðù…¢˜ŒÉuØÞäãåƒ4…ž:–³ÓŠûð}^þo/ú&nbsp;•¦÷Rà§[-ï:†z"�¬ŒT“Á‰¦�Ù»ow’^©‹ž} 7æVCÕiÎ"ºm¸ò¦åçaëµw©J›ËKÎ�³$“’Ïjmbdê˜I…+M‘‘P8”3¾üX%öþ¹LH‹LšD0`aüèÖCý½²ºµÛú=ßq¬íÜŽ„ð­5ó»Ì—êph&nbsp;D¡Í»‰—[Šf“ÁGâ3KùŠ×F�6e–ùöq?ã¿mž6æ›*4D™Ã¢S»'×l^¼gì4ï�gÈ|=¾×ÛÉ‘¶é¥ÖôãûˆÂnHUj€%¬VÙœ Ú¦ô©Ÿ*ÚÈ¢ßV«ã´ß­ç½}óéw"A‹si‘õ`Wë­&amp;�C×ŸOî�rÌ…K
¯Uk±KúbE&gt;$þ&amp;q‡Øv¼)DhÎ�áhßL¸“ÓüH]¸kÁú´%†¼á‡ªëÑY/Ã'Š¶:�Ð9VqˆŠÄO=áÅÏ¦ºbï¼Ýu»›V&amp;Oè†h·âF™‰,—žD´�š%L¿/4ÕS&gt;ÒºZ³j½]ÝZŽPKó%¤ñš¤¥Üáèîp§õkG_œý0Ñ¹Çø([9õ¸d?«5a
óô'{êZ&amp;ìžÊ
µe&nbsp;9æ#GÁ—L*yv_KªÇüy"aÄJV€’â…Nü0ûiD(�ýØÝ\íÝý{
þç09÷RËAµuà£ª/V.ëd&nbsp;¥ašºƒ“ñÌê·cë§ênÞýöˆüÚ5e"�Õýþkæ€»&lt;çý
÷ûRŠ©ÛFÏs}ýÖ¾}Ó÷·ÞP)ƒa¥u�HxaWÑãM¢’ÕLÊzªW¥˜?/�_+µ
Q†#2&lt;Úòö’åzRïI§æÖÉ/Êò†õ¯•VvY²T~oNË¦™x´�ãñH)m®;Wÿ¡#!-É”¼
oÞõp.i§óê8;{Ø¦‚ú…ž5fEC–ç|6E	X}PÍÇ™t.êõ3‘)f0xÏ`ÈHO½ÁÞWs´|INt0bVÓQ°/°çñ&amp;aÌ¢&nbsp;õçS‹›n�ün–ZhDÊ�Kzñ/†=’¦yûYY�JµåNvåVR\¹gÂÄ=Hfidô‘þkª¤)òE:É¢ÖGÂiÑ†
öm:oý’ÈÐV]®°Fâ*&nbsp;øÔ—I6’p‚0U¢¢É�|^PœœØoûFŽ[“?t\&lt;}°^è›•µª˜6¼3ãÿãuÿ|RÈžCéÄ{iµÖfàåÔKy+“DJœNü	G(í—[šQ—"Îº24û×•ò3F€ä²Eï'=„òÓ%š/Î˜²¸IÄñŸ`Y|dÆÝ;ÿñjtnkÊÑb=ËúŠ=vãäØŠ\––°þ
ÙÊöF quÕš+›Ùpãm�-ñ	æJÕÁüxÃ
up§K�tÂVÚ¥»5†A4¡‚èq–˜¢ùB¡|!Ëp
¿:+¡n¬ƒ%|â¼œÂJw„/Ðß7j¢P&gt;*�ç)C6”äÖU9ÈvÔ&gt;¸°Ö8õyÚ·‚X§&lt;ãÐ‘
ù½bû(€Ñ:»¢SD²¾Qeüq}t ´Û¶&lt;ÛêtKnš—sÿØUKÉt$KºÑ�òè±)Å}´ý¾A2Ñ`�¥·Ï¬ïzNð&amp;‘þ¼ÕMì¼ã�tqƒyúVwÿºÇ“¤3‘7y<u“z²·«4ÝÃÁÙ5@Ší¾`î¸ÔÑ£0«ªo9v>ªJr,l!~�OÅžÌ[ué#bqÃÅ�ô¶X¿¼j•ºéüÀ5Ø¯|n«ÌQÕ»ÑMÏ×ÚLôNC€¾Àö5Þ?r¾›&gt;vn‘†Èe8¼Æü’îm¡‰ÄØëÓù8ÐðIÓ‚r³*&amp;GK­øC›æâéIsWæ7¼'y&lt;³ 3ï´¾‘öâüœ[„6Úïc¯óÉ7àïã^ÑsœæŽÕ�Ÿ•£Ê‹HÁrŸêL©°)8CÍBÃßž;ë˜4™½ÞW™{°¥èß�¾íÜ°Ð‹·ühŸóãô˜µÐSáòjÏ%¬#v”tæçŠ˜z·W.B«¿ÑFUVàýŒÂ/%á£Ç½;‡&lt;‰EùLoS•›@ñêç±’µûwgªÏ©wQsáX—j�ìˆy=¥Æm�ƒMU1¢’=â¼ü&lt;«&amp;ÁšÄ×±©&lt;~›µœë­ÆÓ_—cTËª`â!šöô&amp;”&gt;Knù6û2?UY|9*D†#Lµ%œÝw{Óê"i}šç}&amp;µzÍÃüZ£Þbêá#ý¾TÞwmŽ¡37øÑr¢0°Y…Õðn…v®Ea=µõM'
ÖU7ªvU`�aì…Õ.d×‹æn|�”'”Ø—tax:Œ¼Ët¡&amp;È%Ž_–e‰ï=a2Î]7VöËA»ïÜ‰ö9Ù”èïóë.–ß8yfÇ÷6»|ÉX¡}RúÞAiˆ6é$épîu[ö-Iœö
Ã(¥¥@�·¨€¶¤¾ÌœR#÷~†dl¿ÛØ´úÓ„S�Ñ¾æ…—SA?/îÈ��`íLýW¢^õØC­C}s,áàóf=&gt;8â´ã¸“ãÁ¸Yç2.„oOPà‚$6_&lt;8–[Yô~8òk"&gt;Ý×J©B–õK…ÀÇ�y&lt;Šû¢
c
Ç)æŸÎÏàý‘â‘jÄ±DBŸ¦§¾Ã§8×\nAk
’þ™˜¨g£=»uDZÆÑ§ïn./\ˆ)a¶£ÄVl”{ü,%�ÛËm^ê¿‚2Ò­»¾&gt;ë‹gÂÃC&amp;cŠzó›†&amp;`1LŽ¼äúú…¡Ð°`£ä,¨™_è\Yù&gt;ÆéS`e!&gt;=èCS¡ú’qåÞ“èW	»¶å&amp;úÛl&gt;aSw5ê[çL‹è
{„QêÞÀ·]/ø±§îG÷Y¤Ü/b}x_ùCH²«k�
weÙ·º¥L�C7Ý)ð(\~»ˆ|Ë^2”»†~ÏTê[×¦ì@G¶÷È’£=æHU¯d2»m²“4£/U;0’€kü£B²Co­&amp;÷N°©fæ‚q3‡Ï¼ùÉ{Æ�\ðƒ³±Û
Ó†©ä½Y‰Z£Ë$»‡ÇÛÖ¡eW%GRÈÏ[„z˜¿R.EþðËÁH¿�û]Ô8l×~Â(fç‰^°ÿùå¤ŸÌMl6úy¦GT×O¯w™-ùµ”)Þ}#…›�‘ÇÁU!ˆ·–÷�ŒŸS¥�(¹Ò`ˆxÎ·i¢äÃôš¦Œ9²@þm•2zúÁÖa`a:êQîJ[&amp;?ƒ'„È‘Ž¶›D/è9d}ÆÅõø@#Ñ(_[·š|cs´£0(\ºªOµÝ­Èd|Àz$©\ØF�è$CøÔJP¹õÌ×§Æ†TTø¼XåÀaª»Aä™bÖÖzÎžBYå�•Î'õcGÃ¤÷–_/Mˆ4áÅ0E%Ž¾Ô³¿û�&nbsp;ê„wÆ&nbsp;/_ìt­‡á¹[Q©EÒ§7�?u4ÕýŒ£9íô:We½É§+Þã÷/h½ý&gt;õUÍâX—ÊHV*¨¶.;)Dænõ{fš[÷¸‡;+øq6=qßF?’hã”ŸŸšíCjé”ïÕaWwÉÈûôBÖ”ù�Käë�ü(ŒšÄä†eÒXImëâ™Ägšé$œÞ¹:îÄ¶©x;Åe�}ü%ý‡˜(�Æâ·Q0¡z²gu«H.íÒÀfƒÂ/7féóð&amp;º�8\Ü¬„iö2nëxÆ�$ŽK�&lt;éêÝKöWƒ~–GûŠ2Î»˜&amp;èökïÜìÌWð¤‚Hªƒšxs¸ì!dmKº2Ûta–êw|ü¶ÎQ¢“£Úx¸‚“)K‚ÙW6òÚÉªñüDØTV£ÀGnþá~�ŒÎEø­N;81cœï;3NY–y	î­§]ƒ#ÎeÞÂˆÕ˜ŒE@ÐI´ÚZqÂCÏÕÖ«¢ ¢NúDª]ðs_ådª¡âÞ§žÁó´+Yäü¬TÆ+›Žt¨Ü3gVggV+‘Ý*ì#�}KÁ�²v%l“tùãá“ŸÂÏÎ2\ïÁôkž§èÉŠÆ¶[)£p=¹ÕtòœÁ0åI—Ê„¶Íõ´yr7|—BÿÞM¡‹f¼/»�ôƒéî&lt;Ü`—ã5¨øû1êÆÝÜ_9¸©¯ž˜Þ‚£ÐOÇ:àË•¹Ðrå
�ÙŸ¶Öì§­¬^xßç\«yÌöÑ·‚ž¬”¹CŸ)WÈŽ\öj=µßT¬ä©šv{z¨¼|h�šøè&nbsp;«É§ÿ‚õk½%Ýç�Ù\¹°¼0ˆ‹ÌJ¸‚.�dgšaƒ�[Û_�¡—.k»8OZ	üb%gÐÍµ“¶V�Òé*_…œŽ¬;
ŽdD¥í«rœ¯*Y¦·¹raWs�á^çÚÜË&amp;/äª›ælý‘SÜt[[»�°©!ŒøI¿{sÍÐ¹Òò†°F³–9²ÁÓPÏÝ7‰ÙÑ6V{¡—÷”‡ïYuy�ÑÓŒ:•oFz,íš£&lt;•“f]q
9`%gÚ&gt;LOŸ­Õ(íàŒ'ùæ§™:_b,ìñËoÒ�§©6¿(Œã«I5¾|¾b¦Æh'˜Ò´Ú®6àÛâ:ðÈÚl"›–„—ð9«JÙ‡tµ‡óÇÆtr®ÇxÞ­”zKl*2í!=ýŠ‘¸gógªšszŽ
:�-ØêC6;QAJøG†Ô&gt;K“ö›¦ÒSc/ƒo=Aÿ*+Îhpt\­|b}ìÿˆ—4ïc&nbsp;eYùªŽ�³}¡í	Â]C\øY ÙNã±ÇÊN÷i&nbsp;æ‚‰o®öÔ’°ÜlB\¹ö±Õw)ZiJr�{‰ád™8¦«Ò8aŠ÷’	¢KM)øõVÔ¥åò™
‹¢ü·_!©÷°ÎŒ¬Ö_†&amp;ËL˜Æ\ß¾Jm|ä¤�’õ–©‰à^¶SÂê
°&amp;îDõÑ+¸ÕÀ8š/úJÒ.OnYžžÏå2hcî†è¥°‹£P¤˜gîª&gt;Òš"O&amp;â˜¤_¹s±l7HÿX4HKïñè&gt;ºü¦Ð ×­Ú.�¬Â"fÄ_”ÝÄÅ&lt;åYÔÔŸ
Ò²MUNÈìEn/í‡z!4¬Vf+˜ß{^Šé~â÷š„Ú%?*4^.oà©"/~UUýú’Q&lt;¦Á’ýr¦¼ß{scèm
ža~¬’è¥ª›Ãªî[2Ñ÷¬	‘±ì~µ	MÝ1øiŸT+Öç$ò2vˆjpµ=6–9�hP¥¡kËâ¯c…ð¯û9V£V}ú˜ïMî†ëÎ%ÑE¹�ðÇ¾ˆ¯&gt;"xdÑE3ž‰Ðyàtÿþ5GÈæÛÁjŠ9’×Òþ÷H�Â-µŸ�f8¥æ 	urgákæY"LšQ‘Øå}[E=å›¤ò±¹†U©€iÛ3¶~M¿ÇúšþŸß­»?ŒÈM‰&amp;ñ?aºz+!É5SÚ¾iGç¡â	Tîæ‘#-‰b‡Ižš¶êÉŽÃN	ÔU6¥äzP©s‰¸Fº£&nbsp;~'!%‹âÏ•ºâ²ÁÎ&amp;?œ‹Ë;1‡Mk8BëK¨sI©z•ÖÏê,Hh!ÀNÈYa²HY¢¬ûôt_Ó'P¦i`*Ieñº#�u\ü,p¬„oŸÕq¬Kë3�HÚÛý_ÉòÚgã©ŠÁt´OÍ0#pÍÒÏ®ïy"\)N·³˜³”ßê=W‘CÜ{ë¤G*¹z\Í’óÆ!E1æYìhß¼ÞAü©´¢µ~‚nyŠð÷nnÅÛÂ
¡îðv,ÖWËêý$;7ù6º¸�ëÇïe²¾^~âÏ'I¥/ð¶xC»”'7÷f`pg²¶éÙžã:–UL‰ÝQ7ÁÕvûN¥ÍŽÐƒ‰‹‘ô~l²=COE­ÅXn]­FÁu¹®|›v’zÈÒ61ª¤iÎ74bÚ’®UÀnm¢÷XÛX…j(z3Êã¬¾!d")kŸî_þ
@6~ñ¶ùTÙ\yÓVàTQÒëÇRÚøåô q†0`Ð‚jJ+Æ13ÞìU×BTÜ™jù:å&gt;[ žZ²%o•×¨ß)²éµ_¬–÷@E“|m=rgdß±ôv«¹ØøÝpÞ¥	G&gt;ó;	$X£w9^ÕžÉ”­/zêl<k°…uhe³^èŠ.ë­‡yöÚŒg+c˜5—„£Ç‡y¬7&¾;<¹–ÖÙ+÷sj»²È\Ùƒfùsœu‘ûÓjÃ»Ák1ºß¿î>¾3„_êšœéÛ²\¦.F£”®y¥„%àYûÌ…¯rqÈàëKýŸLJZ§…'I-Ô^™žŸ»JÃUZ–rpØ‰XÂÖ•SdG"üš¥c“öyüd»¸÷±ÆÐb4ƒkuÁŒaQÍ0¢sŠ[®Ä
óŽ9ByxMK¹ƒõ“¨ÝÍ½m(ë
Á,)/ìx6ßèFXÍÁj¼&gt;sˆy¯‰™Ö+‘u?ÔdÒÅ£}iŸÃé ïie_bœ5Üc±°+¨ò}›ÉšTAØ£Š``U7Çc²†¡Yè–¡Ï�
Ã–¥ÃÀùO”v÷ÏrnYäøx�%O³bC«œ§E3À�ösö…Ëû&amp;Êàx›ÈvE­ËþHªÙô–ÿÒwÓj´òÿ÷+…^5é�oúÑoE;ñr3»WBÛŽ|yä‡Ã4|&gt;pöB§ûúŽ%FÏæ–ÌÀs÷ƒ!?*fÙáŸÀÆ8šÞŽÖÓ/SïrMgñù¾ÒMh­Õ�ù!Dö¨¬§‘ÔëÝÖ.þ½(ý&gt;üSOE‡ñ¤ÕŽ+ƒ«ö¼–Ù
XŽÝÑ™�tk]¦º÷´¥ò,Î›á�hW·2gm¢Wò¸ò=ö×Ï…Ó2a½CÑ(ƒó/oÙƒ÷¹¶\
\,Í¿®`¹+ÔäN˜©I½ày;_‹,5?æ&nbsp;Ã§¬k-ý–ùyÓ.J¿žîô¨Öv'ß©ï�HKçƒçA‹A¶´ÀÆO¡éc©CY¶y¹vN­¼ƒÇ»1š$—Ñ¦APpQòk€Œ?IMÒÍM´È
FÍ¾Ka!íÖ7i{ª{õm"I„[×çg?¨åÄ	”ZiÆ~¹¼877F‘°·#³+~'ÕìnVãÙÅ»£^Qø�ú²JLš@®Üåû˜¬b+[$£ŽÀµÒt;&amp;	ŠfñJ-\Uèåa´“ÄÏ0&nbsp;eÿž[…¿Üpëú\©QÊ¤”„|Š©SmÙ-g-Âq�»eW&gt;Ø&gt;vï5‡”æäcOWÐ˜!Ezóâ‚Í
Ñ™Z&amp;}íELkÜ§˜ˆ¤“kFßô&gt;ê�þ×jÝ.æ(DêçÄ¥ñ¡Ê®å¤|ý¼�W]óvPÙÅ\sÝ¢R¦ça1)à6°Êt7DÈÊR™yÛïˆÂ‘ICß_‘ƒÎòVÃ%Û{±žõzá­
.&lt;…šzÃžãèŠ×¥CqnðeÒ5­½Ý¬7:‰©òMÊ&gt;›jn¬å`N¿¶ó7MÜ¸&gt;Q‹(¨JÞtTN{åÌue¬ï”¨›¡E-£Ò9±*âA!&lt;Øö)Ecö¡ðFFƒ]%­�gõ¤PbiqÕÈ­uÎ®†�®uO‹%h^&lt;{2à¥úÔµ¯ê‘ˆÃò	“ëb˜;›_¬ÛŠ÷ÄHfMø‚uÇwNÑÎ¬æ×–æýã=›NÍ¤ú†;ÄÇoËèŸ1˜GŒF´i·à\‘fÑî.‚¶½Ì´ìî�hqäù¿øH0gOHiq7šG¾Jäá$%Ø¿"÷¡Ðc®
¥úZ²­"ùm›'‰Æüu´ƒpWW%™‚È4¬z×	Põ3¾õVQŒÝ�P!á¯†Š»F¾·;§Ú•¢&amp;–ª­ggk~†ŸïOWCDMÝ¯	—X1ƒ·O*1Œ!ˆ47õÂ¬‰jå*0Ü!zè‡}¬Ãà}Y·ùž‹Çâ¤�Q·¼õÛe2LŸºP»GRê&nbsp;5ýùk¢}
%q1cœ&nbsp;|‡ §¿~‹&amp;Êl'}+¶UÊÚNû^•™Œîø´uÌ¤Ô©‘Ü7ÞQ?}bH¥QfS�avého@Üµìa9&lt;ÆMtø$°gÑ?ôöŒ&lt;óÎªxl¸Ån8�—i¦ø†©´Kpøì&lt;êjr'æðÛ²õBœµVNm„RÛpßÔ^ìƒß+±ÕÖZ‚9[&gt;ÙCÓjé'½ÏF?·œPùË¢vŒcåµ,s'sJÁâ—^¢1Š±·ïž��’O­nÛÉ}–Ä¯á½âWÿ”Ùa¼;a&amp;A¨Z�SzÞÚuíÓÖ»šã—ýbª]2•»¾§N¯gÞéùZ¤a–c°ˆá¾ì“S=EÃÇr–¹‘C¯Ç…?¯{[Šë²	7MÙOQÎŠ±Ÿ�Í¦—Fê‰˜Ð]ÞÔþ¥ù—÷]�&nbsp;ïµ¥�ÒëQåº#™ÈÈ°rÅ)áö0i|wÿ×µˆo‹êqÏãÊë¦&amp;n÷sÛ#µÇ'B†}±ÙÀ•*2ãâÏyÌÝÂhª¼UØ¾ˆ%ØèÅ]K&gt;§QåÒ%Ò8¦çö÷í¿®,ã©œž¢iU]é|›vuø–‚­ëÖ&nbsp;l21&amp;iŠ‡‡ùóìf4·ÞÁ”Å&nbsp;¥£ì�ªïúÁHÏTãäÛ÷1ÝxlóÄ
–”[C˜îór	ÙÉ¹Ôí¼9â¡i¶²Öðq›ÍtÆÏñM¸•±ÞˆcGKÎÏÆõ<c›¾�šÇ �õîÏÞ="" zé4ÉŠÐo3ïŸ»="" Ý¹="+MöæX¢" Ã*ÁÙ`8a°bò¹°ÜŠ³ÉíŒÅøÊ-"špà¥¨·ºÐþñ¥?vh="" Ëv?xÒ¤c´d’e¤qn¸8þvm0w="" endstream="" endobj="" 165="" 0="" obj="" <<="" filter="" flatedecode="" length1="" 725="" length2="" 31943="" length3="" length="" 32507="">&gt;
stream
xœlºspfßÒ6ÛÖ$wlÛ¶�LlçŽmÛœdbÛ¶m;™˜;yçœ÷<o=_}µÿéÕØëê«»öª]½È‰%€ö.jžfÌôÌ l<�u="" 55f&&&�+9¹¨“™‘‹Ð^ÌÈÅŒ if="" p5s�0³�x˜˜˜áÈ¢@o'+k�•="" õ¿•�="" [#s+;+'€Ðèfeb="" àsssrsvepr`ø'hÕÌ="" àbi0·²5ˆ**ik+h¨$Ô’föfnf¶�%wc[+€œ•‰™½³5Àè°ýÏ`´7µú&g†°w3srù˜¹Ð="" ®&,¡¨ etÙ›ä¤þ="" ·wqæùÇÛÌÄÅå_ÙÑ\þg²5úÉø¤ÿ±:yügb€cf˜z™¸�ŒÍ,¬ìáÿÅ›´½9Àñµ©«Ãmÿ�rþ€ê©¦fæÿx»ÚÚ*Ù™¨d�v®.fn�y ©™“="à_Ü»;Yý£ù¯«‘�•­çÿ¯óÿõ�v1ú‡" a{‹ècú�ÊÊyÂÊÃÌtÉÊå¾]œ\Íþ£Ö4ûomäÍl­\íþnö'ÿtÕhoëùwü'•ïÇ(&«¤¡­lû?mðo³¸½="" ÐÔÊÞ êòŸfn¦ÿ£ø·yÉÈê?ô_,ÿí(�óÿ[Ë¹8yy�t˜þÕ"lÿzþ+éý?=""  ‡7="€ž•ƒ" ÀÌÊÉàbåòý_pm\�œÌì]þmú?¹üwýïf23ó03�[_šð†x§·„•û‰Îu@ÒÎÍªÓ®0ƒ®n÷Üè z="" yš^áÝ©áå¹#ü˜="" 4æß»Ü•¾k&1Š7c8žœŠ!ŽÐ[Á{)&­°ð«Ù~sÎ­�Ð¿†ÐÀµ3q€¸‰¼uÉÜxr¢™bËÊ9¯‘q,åg•dŽ1,ëè‡dÙix[|°—¤Ö£dûõóÁì€¶eÎ2´àÚxðe,<="" xá†×À² <Ðá0üg~ý•µ¨Ž¶Ò<s—v®Î\\±í0Š·ŠÏ¸¡­="" á»+Ö}¨Œ-wá•cÝÇ<Æ‘¨¨È="">Å­�AùŠy&nbsp;³—&gt;d+ùÔ£â·ùÙ*:}#÷fÝžýf45u)£\f(õvdÄIà‚8„à½Gíöyr6d—]ä7…¼'¸7Ç×4Ñh~”[Ï%la‘TF·E%/\;�¼9ãòÛî’‹¨d@¹lš*\p€ÛClšæÚŸ È‰ž†ÁŽ�¶µÉ$!”³¾�&lt;1ŽYé3ÁÛÇ[
&amp;"-Þ˜Í¸…</o=_}µÿéõøëê«»öª]½è‰%€ö.jžfìôì></c›¾�šç></k°…uhe³^èš.ë­‡yöúœg+c˜5—„£ç‡y¬7&¾;<¹–öù+÷sj»²è\ùƒfùsœu‘ûójã»ák1ºß¿î></u“z²·«4ýãáù5@ší¾`î¸ôñ£0«ªo9v></bbæ�žûàbôëòmnðrºz></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://papers.nips.cc/paper/2020/file/13b919438259814cd5be8cb45877d577-Paper.pdf">https://papers.nips.cc/paper/2020/file/13b919438259814cd5be8cb45877d577-Paper.pdf</a></em></p>]]>
            </description>
            <link>https://papers.nips.cc/paper/2020/file/13b919438259814cd5be8cb45877d577-Paper.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25401792</guid>
            <pubDate>Sat, 12 Dec 2020 21:17:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Gemini?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25401583">thread link</a>) | @rhencke
<br/>
December 12, 2020 | https://gemini.circumlunar.space/docs/faq.html | <a href="https://web.archive.org/web/*/https://gemini.circumlunar.space/docs/faq.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>Please send corrections or suggestions for additional questions to
<a href="mailto:solderpunk@posteo.net">solderpunk@posteo.net</a></p>

<h2>1. Overview</h2>

<h3>1.1 What is Gemini?</h3>

<p>Gemini is a new application-level internet protocol for the distribution of arbitrary files, with some special consideration for serving a lightweight hypertext format which facilitates linking between files.  You may think of Gemini as "the web, stripped right back to its essence" or as "Gopher, souped up and modernised a little", depending upon your perspective.  Gemini may be of interest to people who are:</p>

<ul>
<li>Opposed to the web's ubiquitous user tracking</li>
<li>Tired of obnoxious adverts, autoplaying videos and other misfeatures</li>
<li>Interested in low-power computing and/or low-speed networks</li>
</ul>

<p>Gemini is intended to be simple, but not necessarily as simple as possible.  Instead, the design strives to maximise its "power to weight ratio", while keeping its weight within acceptable limits.  Gemini is also intended to be very privacy conscious, to be difficult to extend in the future (so that it will <em>stay</em> simple and privacy conscious), and to be compatible with a "do it yourself" computing ethos.  For this last reason, Gemini is technically very familiar and conservative: it's a protocol in the traditional client-server request-response paradigm, and is built on mature, standardised technology like URIs, MIME media types, and TLS.</p>

<h3>1.2 Whose fault is Gemini?</h3>

<p>Project Gemini was started by Solderpunk <a href="mailto:solderpunk@posteo.net">solderpunk@posteo.net</a>, who remains Benevolent Dictator For Now.  However, the protocol has been designed in collaboration with a loose and informal community of interested parties via emails, phlog and Fediverse posts.  Many people have shaped significant parts of the protocol, so Gemini should not be thought of as the work of one person.</p>

<h3>1.3 Where can I learn more?</h3>

<p>The official home of Project Gemini is the gemini.circumlunar.space server.  It serves the latest version of this FAQ document, as well the protocol specification and recommended best practices via Gemini, Gopher and HTTPS, on IPv4 and IPv6.</p>

<p>Official discussion regarding Gemini happens on a mailing list.  You can subscribe to the list and view archives at https://lists.orbitalfox.eu/listinfo/gemini.  Archives can also be viewed over Gemini at gemini://rawtext.club:1965/~sloum/geminilist/.</p>

<p>Anybody who is running a Gemini server or implementing a Gemini client or server software is strongly encouraged to subscribe to the list.</p>

<p>Casual discussion regarding Gemini also happens in the #gemini channel on the tilde.chat IRC server.  IRC logs can be viewed over Gemini at gemini://makeworld.gq/cgi-bin/gemini-irc.</p>

<h3>1.4 Do you really think you can replace the web?</h3>

<p>Not for a minute!  Nor does anybody involved with Gemini want to destroy Gopherspace.  Gemini is not intended to replace either Gopher or the web, but to co-exist peacefully alongside them as one more option which people can freely choose to use if it suits them.  In the same way that many people currently serve the same content via gopher and the web, people will be able to "bihost" or "trihost" content on whichever combination of protocols they think offer the best match to their technical, philosophical and aesthetic requirements and those of their intended audience.</p>

<h3>1.5 What's with the name?</h3>

<p>It's a reference to the pre-shuttle era of US manned spaceflight, which consisted of three projects.  The first was Project Mercury, which was a fairly minimalist "proof of concept" and part of the race to put a human in space soonest (which the Soviet Union won with their Vostok project).  Mercury was a one-man capsule with no ability to adjust to its own orbit after launch and only one Mercury flight lasted longer than a single day.  The last was Project Apollo, which was large, heavy, complicated and expensive but could, of course, fly three men to the moon and back.</p>

<p>Less well known to the modern public, Project Gemini was the "middle child": a two person capsule which could rendezvous and dock with other craft in orbit, could be depressurised and repressurised in orbit to facilitate spacewalks, and whose longest flight was almost two weeks - longer than any Apollo mission!  In terms of size, weight and cost Gemini was much closer to Mercury than to Apollo, but in terms of capabilities it was the other way around - there were even plans (which never eventuated) to do circumlunar Gemini flights!</p>

<p>Hopefully the analogy is obvious: Gopher is akin to Mercury, and the web is akin to Apollo.  Gemini hopes to sit between the two, doing more with less.</p>

<p>Gemini very deliberately didn't receive a name which had <em>anything</em> to do with gophers, or other rodents, or even other animals.  During the earliest phlog-based discussions which eventually grew into Project Gemini, a lack of careful writing meant it was sometimes unclear whether people were talking about replacing Gopher outright, or adding unofficial, compatibility-breaking upgrades into existing Gopher clients and servers.  When idle discussion turned into an actual project, it seemed wise to send a clearer message.</p>



<h2>2.1 What are the design criteria for Gemini?</h2>

<p>The following criteria were informally put in place at the beginning of the project.  It's debatable how closely some of these goals have been met, but in general Gemini is still quite close to this target.</p>

<h3>2.1.1 Simplicity</h3>

<p>In particular, Gemini strives for simplicity of client implementation.  Modern web browsers are so complicated that they can only be developed by very large and expensive projects.  This naturally leads to a very small number of near-monopoly browsers, which stifles innovation and diversity and allows the developers of these browsers to dictate the direction in which the web evolves.</p>

<p>Gemini aims to be simple, but not <em>too</em> simple.  Gopher is simpler at a protocol level, but as a consequence the client is eternally uncertain: what character encoding is this text in?  Is this text the intended content or an error message from the server?  What kind of file is this binary data?  Because of this, a robust Gopher client is made <em>less</em> simple by needing to infer or guess missing information.  Early Gemini discussion included three clear goals with regard to simplicity:</p>

<ul>
<li>It should be possible for somebody who had no part in designing the protocol to accurately hold the entire protocol spec in their head after reading a well-written description of it once or twice.</li>
<li>A basic but usable (not ultra-spartan) client should fit comfortably within 50 or so lines of code in a modern high-level language.  Certainly not more than 100.</li>
<li>A client comfortable for daily use which implements every single protocol feature should be a feasible weekend programming project for a single developer.</li>
</ul>

<p>It's debatable to what extent these goals have been met.  Experiments suggest that a very basic interactive client takes more like a minimum of 100 lines of code, and a comfortable fit and moderate feature completeness need more like 200 lines.  But Gemini still seems to be in the ballpark of these goals.</p>

<h3>2.1.2 Privacy</h3>

<p>Gemini is designed with an acute awareness that the modern web is a privacy disaster, and that the internet is not a safe place for plaintext.  Things like browser fingerprinting and Etag-based "supercookies" are an important cautionary tale: user tracking can and will be snuck in via the backdoor using protocol features which were not designed to facilitate it.  Thus, protocol designers must not only avoid designing in tracking features (which is easy), but also assume active malicious intent and avoid designing anything which could be subverted to provide effective tracking.  This concern manifests as a deliberate non-extensibility in many parts of the Gemini protocol.</p>

<h3>2.1.3 Generality</h3>

<p>The "first class" application of Gemini is human consumption of predominantly written material - to facilitate something like gopherspace, or like "reasonable webspace" (e.g. something which is comfortably usable in Lynx or Dillo).  But, just like HTTP can be, and is, used for much, much more than serving HTML, Gemini should be able to be used for as many other purposes as possible without compromising the simplicity and privacy criteria above.  This means taking into account possible applications built around non-text files and non-human clients.</p>

<h2>2.2 Which shortcomings of Gopher does Gemini overcome?</h2>

<p>Gemini allows for:</p>

<ul>
<li>Unambiguous use of arbitrary non-ASCII character sets.</li>
<li>Identifying binary content using MIME types instead of a small set of badly outdated item types.</li>
<li>Clearly distinguishing successful transactions from failed ones.</li>
<li>Linking to non-gopher resources via URLs without ugly hacks.</li>
<li>Redirects to prevent broken links when content moves or is rearranged.</li>
<li>Domain-based virtual hosting.</li>
</ul>

<p>Text in Gemini documents is wrapped by the client to fit the device's viewport, rather than being "hard wrapped" at ~80 characters with newline characters.  This means content displays equally well on phones, tablets, laptops and desktops.</p>

<p>Gemini does away with Gopher's strict directory / text dichotomy and lets you insert links in prose.</p>

<p>Gemini mandates the use of TLS encryption.</p>

<h2>2.3 Is Gopher's directory / text dichotomy <em>really</em> a shortcoming?</h2>

<p>Modern usage habits in the phlogosphere would seem to suggest that many people think it is.  An increasing number of users are serving content which is almost entirely text as item type 1, so that they can insert a relatively small number of "in line" links to other gopher content, providing some semblance of HTML's hyperlinking - a perfectly reasonable and inoffensive thing to want to do.  Without taking this approach, the best Gopher content authors can do is to paste a list of URLs at the bottom of their document, for their readers to manually copy and paste into their client.  This is not exactly a pleasant user experience.  But forcing hyperlinks into Gopher this way isn't just an abuse of the semantics of the Gopher protocol, it's also a surprisingly inefficient way to …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gemini.circumlunar.space/docs/faq.html">https://gemini.circumlunar.space/docs/faq.html</a></em></p>]]>
            </description>
            <link>https://gemini.circumlunar.space/docs/faq.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25401583</guid>
            <pubDate>Sat, 12 Dec 2020 20:51:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do people find bugs?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25401433">thread link</a>) | @URfejk
<br/>
December 12, 2020 | https://www.cryptologie.net/article/511/how-do-people-find-bugs | <a href="https://web.archive.org/web/*/https://www.cryptologie.net/article/511/how-do-people-find-bugs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>You might wonder how people find bugs. Low-hanging fruit bugs can be found via code review, static analysis, dynamic analysis (like fuzzing), and other techniques. But what about deep logic bugs. Those you can’t find easily. Perhaps the protocol implemented is quite complicated, or correctness is hard to define, and edge-cases hard to detect. One thing I’ve noticed is that re-visiting protocols are an excellent way to find logic bugs.</p>
<p>Ian Miers once said something like that: "you need time, expertise, and meaningful engagement”. I like that sentence, although one can point out that these traits are closely linked--you can’t have meaningful engagement without time and expertise--it does show that finding bugs take "effort".</p>
<p>OK. Meaningful engagement can lead to meaningful bugs, and meaningful bugs can be found at different levels.
So you're here, seating in your undies in the dark, with a beer on your side and some uber eats lying on the floor.
Your computer is staring back at you, blinking at a frequency you can't notice, and waiting for you to find a bug in this protocol.
What do you do?
Perhaps the protocol doesn't have a proof, and this leads you to wonder if you can write one for it...</p>
<p>It worked for Ariel Gabizon, who in 2018 <a href="https://electriccoin.co/blog/zcash-counterfeiting-vulnerability-successfully-remediated/">found a subtle error</a> in a <a href="https://eprint.iacr.org/2013/879">2013 zk-SNARK paper</a> used by the Zcash cryptocurrency he was working on.
He found it by trying to write a proof for the paper he was reading, realizing that the authors had winged it.
While protocols back in the days could afford to wing it, these days people are more difficult--they demand proofs.
The bug Ariel found could have allowed anyone to forge an unlimited amount of money undetected.
It was silently fixed months later in an upgrade to the network.</p>
<blockquote>
<p>Ariel Gabizon, a cryptographer employed by the Zcash Company at the time of discovery, uncovered a soundness vulnerability. The key generation procedure of [BCTV14], in step 3, produces various elements that are the result of evaluating polynomials related to the statement being proven. Some of these elements are unused by the prover and were included by mistake; but their presence allows a cheating prover to circumvent a consistency check, and thereby transform the proof of one statement into a valid-looking proof of a different statement. This breaks the soundness of the proving system.</p>
</blockquote>
<p>What if the protocol already had a proof though?
Well that doesn't mean much, people enjoy writing unintelligible proofs, and people make errors in proofs all the time.
So the second idea is that reading and trying to understand a proof might lead to a bug in the proof.
Here's some meaningful engagement for you.</p>
<p>In 2001, Shoup revisited some proofs and <a href="https://eprint.iacr.org/2000/060.pdf">found some darning gaps in the proofs for RSA-OAEP</a>, leading to a newer scheme OAEP+ which was never adopted in practice.
Because back then, as I said, we really didn't care about proofs.</p>
<blockquote>
<p>[BR94] contains a valid proof that OAEP satisfies a certain technical property which they call “plaintext awareness.” Let us call this property PA1. However, it is claimed without proof that PA1 implies security against chosen ciphertext attack and non-malleability. Moreover, it is not even clear if the authors mean adaptive chosen ciphertext attack (as in [RS91]) or indifferent (a.k.a. lunchtime) chosen ciphertext attack (as in [NY90]).</p>
</blockquote>
<p>Later in 2018, a series of discoveries on the proofs for the OCB2 block cipher quickly led to <a href="https://eprint.iacr.org/2019/311">practical attacks breaking the cipher</a>.</p>
<blockquote>
<p>We have presented practical forgery and decryption attacks against OCB2, a high-profile ISO-standard authenticated encryption scheme. This was possible due to the discrepancy between the proof of OCB2 and the actual construction, in particular the interpretation of OCB2 as a mode of a TBC which combines XEX and XE.</p>
</blockquote>
<blockquote>
<p>We comment that, due to errors in proofs, ‘provably-secure schemes’ sometimes still can be broken, or schemes remain secure but nevertheless the proofs need to be fixed. Even if we limit our focus to AE, we have many examples for this, such as NSA’s Dual CTR [37,11], EAX-prime [28], GCM [22], and some of the CAESAR submissions [30,10,40]. We believe our work emphasizes the need for quality of security proofs, and their active verification.</p>
</blockquote>
<p>Now, reading and verifying a proof is always a good idea, but it’s slow, it’s not flexible (if you change the protocol, good job changing the proof), and it’s limited (you might want to prove different things re-using parts of the proofs, which is not straight forward).
Today, we are starting to bridge the gap between pen and paper proofs and computer science: it is called formal verification.
And indeed, formal verification is booming, with a number of papers in the recent years finding issues here and there just by describing protocols in a formal language and verifying that they withstand different types of attacks.</p>
<p><a href="https://eprint.iacr.org/2019/526">Prime, Order Please! Revisiting Small Subgroup and Invalid Curve Attacks on Protocols using Diffie-Hellman</a>:</p>
<blockquote>
<p>We implement our improved models in the Tamarin prover. We find a new attack on the Secure Scuttlebutt Gossip protocol, independently discover a recent attack on Tendermint’s secure handshake, and evaluate the effectiveness of the proposed mitigations for recent Bluetooth attacks.</p>
</blockquote>
<p><a href="https://eprint.iacr.org/2019/779">Seems Legit: Automated Analysis of Subtle Attacks on Protocols that Use Signatures</a>:</p>
<blockquote>
<p>We implement our models in the Tamarin Prover, yielding the first way to perform these analyses automatically, and validate them on several case studies. In the process, we find new attacks on DRKey and SOAP’s WS-Security, both protocols which were previously proven secure in traditional symbolic models.</p>
</blockquote>
<p><img alt="tamarin" src="https://www.cryptologie.net/upload/tamarin-obseq-lemma-attack.jpg"></p>
<p>But even this kind of techniques has limitation! (OMG David when will you stop?)</p>
<p>In 2017 <a href="https://blog.cryptographyengineering.com/2017/10/16/falling-through-the-kracks/">Matthew Green wrote</a>: </p>
<blockquote>
<p>I don’t want to spend much time talking about KRACK itself, because the vulnerability is pretty straightforward. Instead, I want to talk about&nbsp;why&nbsp;this vulnerability continues to exist so many years after WPA was standardized. And separately, to answer a question: how did this attack slip through, despite the fact that the 802.11i handshake was&nbsp;formally proven secure?</p>
</blockquote>
<p>He later writes:</p>
<blockquote>
<p>The critical problem is that while people looked closely at the two components — handshake and encryption protocol —&nbsp;in isolation, apparently nobody looked closely at the two components as they were connected together. I’m pretty sure there’s an entire&nbsp;geek meme&nbsp;about this.</p>
</blockquote>
<p>pointing to the "2 unit tests. 0 integration tests." joke.</p>
<p><img alt="meme" src="https://www.cryptologie.net/upload/ezgif-3-a0aa048a0c79.gif"></p>
<p>He then recognizes that it’s a hard problem:</p>
<blockquote>
<p>Of course, the reason nobody looked closely at this stuff is that doing so is just&nbsp;plain&nbsp;hard. Protocols have an exponential number of possible cases to analyze, and we’re just about at the limit of the complexity of protocols that human beings can truly reason about, or that peer-reviewers can verify. The more pieces you add to the mix, the worse this problem gets.
In the end we all know that the answer is for humans to stop doing this work. We need machine-assisted verification of protocols, preferably tied to the&nbsp;actual source code that implements them. This would ensure that the protocol actually does what it says, and that implementers don’t further screw it up, thus invalidating the security proof.</p>
</blockquote>
<p>Well, Matthew, we do have formally generated code! <a href="https://hacl-star.github.io/">HACL*</a> and <a href="http://adam.chlipala.net/papers/FiatCryptoSP19/FiatCryptoSP19.pdf">fiat-crypto</a> are two examples.
Anybody has heard of that failing? I’d be interested…</p>
<p>In any case, what’s left for us? A lot! Formally generated code is hard, and generally covers small parts of your protocol (e.g. field arithmetic for elliptic curves).
So what else can we do?
Implementing the protocol, if it hasn’t been implemented before, is a no-brainer.
In 2016, Taylor Hornby an engineer at Zcash <a href="https://electriccoin.co/blog/fixing-zcash-vulns/">wrote about a bug he found</a> while implementing the zerocash paper into the Zcash cryptocurrency:</p>
<blockquote>
<p>In this blog post, we report on the security issues we’ve found in the Zcash protocol while preparing to deploy it as an open, permissionless financial system.
Had we launched Zcash without finding and fixing the InternalH Collision vulnerability, it could have been exploited to counterfeit currency. Someone with enough computing power to find 128-bit hash collisions would have been able to double-spend money to themselves, creating Zcash out of thin air.</p>
</blockquote>
<p>Perhaps re-implementing the protocol in a different language might work as well?</p>
<p><img alt="" src="https://www.cryptologie.net/upload/Screen_Shot_2020-11-23_at_10.16_.18_PM_.png"></p>
<p>One last thing, most of the code out there is not formally verified.
So of course, reviewing code works, but you need time, expertise, money, etc.
So instead, what about testing?
This is what <a href="https://github.com/google/wycheproof">Wycheproof</a> does by implementing a number of test vectors that are known to cause issues:</p>
<blockquote>
<p>These observations have prompted us to develop Project Wycheproof, a collection of unit tests that detect known weaknesses or check for expected behaviors of some cryptographic algorithm. Project Wycheproof provides tests for most cryptographic algorithms, including RSA, elliptic curve crypto and authenticated encryption. Our cryptographers have systematically surveyed the literature and implemented most known attacks. We have over 80 test cases which have uncovered more than&nbsp;40 bugs. For example, we found that we could recover the private key of widely-used DSA and ECDHC implementations.</p>
</blockquote>
<p>In all of that, I didn't even talk about the benefits of writing a specification... that's for another day.</p>
</article><p>Well done! You've reached the end of my post. Now you can <a href="">leave a comment</a> or read something else.</p></div>]]>
            </description>
            <link>https://www.cryptologie.net/article/511/how-do-people-find-bugs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25401433</guid>
            <pubDate>Sat, 12 Dec 2020 20:32:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Hacked into Facebook's Legal Department Admin Panel]]>
            </title>
            <description>
<![CDATA[
Score 560 | Comments 236 (<a href="https://news.ycombinator.com/item?id=25401294">thread link</a>) | @hackerpain
<br/>
December 12, 2020 | https://alaa.blog/2020/12/how-i-hacked-facebook-part-one/ | <a href="https://web.archive.org/web/*/https://alaa.blog/2020/12/how-i-hacked-facebook-part-one/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>We’ve been in this pandemic since&nbsp; March and once the pandemic started I was having plenty of free time, And I need to use that time wisely, So I’ve decided to take the OSWE certification and I finished the exam on 8 of August, after that, I took a couple of weeks to recover from the OSWE exam, then in the med of September, I said you know what? I did not register my name in the Facebook hall of fame for 2020 as I do every year. okay, let’s do it.</p>

<p>I never found a vulnerability on one of Facebook subdomains, and I took a look at some writeups and I saw one writeup in one of Facebook subdomains which It got all my attention It was a great write up you can check it out <a href="https://ysamm.com/?p=280">[HTML to PDF converter bug leads to RCE in Facebook server.]</a></p>
<p>So after reading this writeup now I took a good idea about how many vulnerabilities I could find in such a huge web app.</p>

<p>So my main target was https://legal.tapprd.thefacebook.com and my goal was RCE or something similar.</p>

<p>I ran some fuzzing tools just to get the full endpoints of this web app and I took a 2 hours nap and watched a movie, Then I got back to see the results okay I got some good results.</p>

<p>Dirs found with a 403 response:</p>
<pre><code>
Dirs found with a 403 response:

/tapprd/
/tapprd/content/
/tapprd/services/
/tapprd/Content/
/tapprd/api/
/tapprd/Services/
/tapprd/temp/
/tapprd/logs/
/tapprd/logs/portal/
/tapprd/logs/api/
/tapprd/certificates/
/tapprd/logs/auth/
/tapprd/logs/Portal/
/tapprd/API/
/tapprd/webroot/
/tapprd/logs/API/
/tapprd/certificates/sso/
/tapprd/callback/
/tapprd/logs/callback/
/tapprd/Webroot/
/tapprd/certificates/dkim/
/tapprd/SERVICES/
</code></pre>
<p>Okay, I think this result is very enough to support my previous theory about how huge this application, Then I started to read the javascript files to see how the website works and what methods it uses ..etc</p>

<p>I noticed a way to bypass the redirection into the Login SSO, https://legal.tapprd.thefacebook.com/tapprd/portal/authentication/login and after analyzing the login page, I noticed this endpoint</p>
<p><strong> /tapprd/auth/identity/user/forgotpassword</strong></p>
<p>and after doing some fuzzing on the user endpoint I’ve noticed another endpoint which its <strong>/savepassword&nbsp;&nbsp;</strong>and it was expecting a POST request, Then after reading the javascript files I knew how the page work, there should be a generated token and xsrf token.. etc The idea that first came to me okay, Lets test it and see if it will work I tried to change manually using burp suite but I got an error, the error <em>was execution this operation failed</em>.</p>

<p>I said okay, this might be because the email is wrong or something? let’s get an admin email, Then I started to put random emails in a list to make a wordlist and after that, I used the intruder and I said let’s see what will happen.</p>
<p>I got back after a couple of hours I found the same error results plus one other result, This one was 302 redirect to the login page, I said wow, I’ll be damned if this worked Haha.</p>

<p>So let’s get back to see what I’ve done here, I sent random requests using intruder with a CSRF token and random emails with a new password to this endpoint <em><strong>/savepassword</strong></em></p>
<p>and one of the results was 302 redirect.</p>
<div id="attachment_128"><p><img aria-describedby="caption-attachment-128" loading="lazy" src="https://alaa.blog/wp-content/uploads/2020/11/redirect-login.png" alt="fbredtrect" width="989" height="446" srcset="https://alaa.blog/wp-content/uploads/2020/11/redirect-login.png 1671w, https://alaa.blog/wp-content/uploads/2020/11/redirect-login-300x135.png 300w, https://alaa.blog/wp-content/uploads/2020/11/redirect-login-1024x461.png 1024w, https://alaa.blog/wp-content/uploads/2020/11/redirect-login-768x346.png 768w, https://alaa.blog/wp-content/uploads/2020/11/redirect-login-1536x692.png 1536w" sizes="(max-width: 989px) 100vw, 989px"></p><p id="caption-attachment-128">Redirect</p></div>
<p><strong>Now I went to the login page and I put the login email and the new password and BOOM I logged in Successfully into the application and I can enter the admin panel 🙂</strong></p>

<p><img loading="lazy" src="https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin.png" alt="" width="882" height="468" srcset="https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin.png 1785w, https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin-300x159.png 300w, https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin-1024x543.png 1024w, https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin-768x407.png 768w, https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin-1536x815.png 1536w" sizes="(max-width: 882px) 100vw, 882px"></p>

<p>I read the hacker report who found RCE before using the PDF and they gave him a reward of 1000$ only so I said okay, let’s make a good Impact here and a perfect exploit.</p>
<p>I wrote a quick and simple script to exploit this vulnerability with python you put the email and the new password and the script will change the password.</p>
<p><img loading="lazy" src="https://alaa.blog/wp-content/uploads/2020/11/Exploit1.png" alt="" width="983" height="123" srcset="https://alaa.blog/wp-content/uploads/2020/11/Exploit1.png 983w, https://alaa.blog/wp-content/uploads/2020/11/Exploit1-300x38.png 300w, https://alaa.blog/wp-content/uploads/2020/11/Exploit1-768x96.png 768w" sizes="(max-width: 983px) 100vw, 983px"></p>
<p><strong>The Impact here was so high because the Facebook workers used to login with their workplace accounts, Which mean they’re using their Facebook accounts access token, and maybe if another attacker wanted to exploit this it might give him the ability to gain access to some Facebook workers accounts .. etc&nbsp;</strong></p>
<p>Then I reported the vulnerability and the report triaged.</p>

<p><strong>And on 2 of October, I received a bounty of 7500$&nbsp;</strong></p>
<p><img loading="lazy" src="https://alaa.blog/wp-content/uploads/2020/11/reward.png" alt="" width="654" height="171" srcset="https://alaa.blog/wp-content/uploads/2020/11/reward.png 696w, https://alaa.blog/wp-content/uploads/2020/11/reward-300x78.png 300w" sizes="(max-width: 654px) 100vw, 654px"></p>
<p>I enjoyed exploiting this vulnerability so much, so I said that’s not enough, this is a weak script! let’s dig more and more.</p>
<p>And I found two more vulnerabilities on the same application, But we will talk about the other vulnerabilities in the Part two writeup 🙂</p>

<p>Cheers.</p>
<div id="sexy-author-bio"><p><a id="sab-Email" href="https://alaa.blog/cdn-cgi/l/email-protection#2d4c414c4c5e4c4f5f445e456d4a404c4441034e4240" target="_top"><img id="sig-Email" alt="Alaa Abdulridha on Email" src="https://alaa.blog/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sabemail.png"></a><a id="sab-Facebook" href="https://www.facebook.com/alaa.abdulridha.716" target="_top"><img id="sig-Facebook" alt="Alaa Abdulridha on Facebook" src="https://alaa.blog/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sabfacebook.png"></a><a id="sab-Github" href="https://github.com/Alaa-abdulridha" target="_top"><img id="sig-Github" alt="Alaa Abdulridha on Github" src="https://alaa.blog/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sabgithub.png"></a><a id="sab-Instagram" href="https://www.instagram.com/al_shwele" target="_top"><img id="sig-Instagram" alt="Alaa Abdulridha on Instagram" src="https://alaa.blog/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sabinstagram.png"></a><a id="sab-Twitter" href="https://twitter.com/alaa0x2" target="_top"><img id="sig-Twitter" alt="Alaa Abdulridha on Twitter" src="https://alaa.blog/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sabtwitter.png"></a></p><p><a href="https://alaa.blog/author/alaaabdulridha/" target="_top"><img src="https://alaa.blog/wp-content/uploads/2019/08/aaaaaaaaaa-150x150.jpg" width="100" height="100" alt="Alaa Abdulridha"></a></p><p>My name is Alaa Abdulridha I'm a computer engineering student and cybersecurity researcher I'm interested in web application pen-testing and game development, also I'm interested in some bug bounty programs, I like a lot of things such as reverse engineering, reading the others code to learn and then to find my own exploits and teaching it to you, Do you want to know more about me? <a href="https://alaa.blog/whoami/">Click Here</a>.</p></div>						
											</div></div>]]>
            </description>
            <link>https://alaa.blog/2020/12/how-i-hacked-facebook-part-one/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25401294</guid>
            <pubDate>Sat, 12 Dec 2020 20:17:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meetings and Team Efficiency]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25400985">thread link</a>) | @patapizza
<br/>
December 12, 2020 | https://jodent.io/posts/meetings-and-team-efficiency | <a href="https://web.archive.org/web/*/https://jodent.io/posts/meetings-and-team-efficiency">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://jodent.io/posts/meetings-and-team-efficiency</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400985</guid>
            <pubDate>Sat, 12 Dec 2020 19:47:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Agent vs. System]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25400872">thread link</a>) | @stopachka
<br/>
December 12, 2020 | https://stopa.io/post/273 | <a href="https://web.archive.org/web/*/https://stopa.io/post/273">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><span><p>Does it feel like society is heading off a cliff?</p><p>Social media companies create platforms so addicting that children can’t help but stick to their phones. Politicians make increasingly vicious personal attacks, to the point where elections look like dog-fights. Newspapers pump out so much biased click-bait that people have vilified opposing views. Companies produce such horrible food that obesity is now one of the most deadly threats. Universities teach so poorly that all the youth end up with are vague ideas and a mountain of debt.</p><p>This makes the future bleak, but it gets worse when you try to find a cause.</p><p>It feels like there are simple solutions right in front of us: Facebook could just change their algorithm to be less addicting. Politicians could just uphold a modicum of respect. Newspapers could just increase their journalistic standard. Food companies could just sell healthier food.</p><p>And when we consider those solutions, we can’t help but feel indignation: It’s like our leaders have forsaken us. They can just make those choices, but they don’t. They imperil our society, even the livelihood of their own grandchildren, for what seems like avarice and short-sightedness. </p><p>With that view, one solution sprouts up: <strong>what if we</strong> <strong><em>forced</em></strong> <strong>our leaders to do the right thing?</strong> </p><p>We could replace Mark Zuckerberg with someone who would make sure the algorithms were less addicting. We could make the New York Times and Fox News report a balanced viewpoint. We could tell food companies to remove sugar from their food. We could ask Literature professors to teach something more useful — perhaps prose.</p><p>Simple right?</p><p>Well, it turns out we’ve tried this before. Many, many times, actually. At innumerable points in our history, we’ve tried to solve moneylending, conspicuous consumption, alcohol, prostitution, various child-rearing practices, emigration, immigration, the list goes on. Most of the time, we employed the same methods and reached the same result: utter failure.</p><p>Why? </p><p>Let’s look at Facebook for clues. What would happen if Mark Zuckerberg made Facebook’s algorithm less addictive? If our conviction is that Facebook is the reason people cling to their phones, we would expect a sustained decrease in social media usage. But would that really happen? </p><p>If Facebook’s algorithm became less addictive, the only change we’d notice is a decrease in <em>Facebook’s</em> market share, not social media usage. Twitter, Tik Tok, Snapchat, and many a startup would gladly eat Facebook’s lunch.</p><p>Here we enter our first logical fallacy. We’ve ascribed too much power to Facebook. People don’t exist, so Facebook can show them ads. Facebook exists <em>because</em> people want to see what their friends are up too, and are okay with seeing ads. The underlying force that decides the demand for Facebook is people and their wants. Facebook doesn’t dictate what people <em>should</em> want.</p><p>Abstract “Facebook” and “Social Media” away, and you get to a general principle. The “system” (in this case, “Social Media”) is what drives behavior, not the “agent” (in this case, “Facebook”). The agent is merely a player, powerful to the extent that they can satisfy the system. </p><p>You can see this by looking at Facebook’s history: had Facebook failed to transition to mobile or to purchase Instagram, it would be a lot less relevant today. Social media, however, would very much remain relevant. </p><p>The other ills of society fit this abstraction. Presidential Candidates lower their standards because the people who select them respond positively to dog fights. The New York Times writes biased articles because people prefer to read them. Harvard teaches English Literature, because people still study it.</p><p>So we come to an uncomfortable truth: what you see on your feed isn’t quite as up to Mark Zuckerberg as we think. </p><p>If we really want to solve society’s ills, we need to think one level higher. How does the <em>system</em> work? Why is the current incentives in social media gluing us to phones? Why is it most profitable to share divisive news? Why do dog-fights win elections?</p><p>The answers to these questions are the clues we need to change how the system works. But, finding the answers is so hard that we’ve stopped trying. Instead, we look for solutions that come to mind immediately. </p><p>What solution comes to mind immediately? Regulation.</p><p>Instead of replacing Mark Zuckerberg, what if we regulated the algorithms that social media companies could use? Similarly, what if we made rules about what is “balanced” news? What if we specified what politicians were allowed to say? What if we made laws about college curriculums?</p><p>These ideas flower up over and over again across our civilizations.</p><p>In the middle ages for example, we tried to solve consumption with sumptuary laws: regulations on the amount of money classes could spend on clothes. If you’re a knight, your wife can spend at most this much for a coat, if you’re a doctor, this much, and so on.</p><p>More closer to home, there was prohibition. The majority agreed that alcohol was bad for society. The moral choice seemed simple: let’s just ban it. If alcohol sellers aren’t allowed to sell alcohol, then people would stop drinking, and society would be better off.</p><p>Of course, both of these ideas failed, and they look ridiculous to us now. </p><p>Why did they fail?</p><p>The consumption that sumptuary laws were trying to curb was driven by an underlying human need: the need to distinguish oneself. This is so core to our collective existence that no amount of regulation could curb it. As Montaigne astutely pointed out, the laws even made consumption <em>more attractive:</em> why not get the goods that “only princes” could wear?</p><p>The same was true for prohibition. Make alcohol illegal, and watch the bootleggers flourish. The way a river finds the shortest path down a mountain, a seller finds the shortest path to a customer. The need was too strong.</p><p>Worse still, these laws share a common blindness: they don’t consider to second order effects. Sumptuary laws failed to react to changes in fashions, and didn’t consider the counterintuitive increase in desire for distinguishing goods. Prohibition didn’t consider the bootleggers.  </p><p>This is because regulation works in large sweeps and requires concerted effort, while systems are versatile, decentralized, and can change faster than the time it takes you to finish this sentence. We used a slow, one dimension process to change a fast, multi-dimensional system. The flaw is inherent in our method.</p><p>So, our simple solutions are no longer so simple. The picture may seem bleaker, but at least we’ve now pruned some incorrect methods. So what paths are promising? </p><p>As far as I know, two methods have worked.</p><p>The first, is Natural Selection. In the same way that the environment forces a gazelle to be fast, reality forces our society to be effective. Imagine if the United States, for example, descended into socialism. This wouldn’t mean that the whole world would be doomed to it. If the consequences of socialism bear fruit, our society would lose productivity. As long as <em>some</em> society was able to maintain freedom from this kind of coercion, given enough time that society would become the world power. What we did to the Soviet Union, this more productive society would do to us.</p><p>Natural Selection works, but it is a bleak option to rely on: it takes a while and has no mercy. We’d sacrifice lives, increase suffering, and may have to wait through a new dark age. And the world isn’t so theoretical: while we wait, there are existential threats that could end society completely.</p><p>Thankfully, this is not the only option. Humanity has one trump card up its sleeve, and it’s saved us over and over again: Innovation.</p><p>Consider electric cars. If we tried to force people to buy electric cars, we’d end up with the same problems as prohibition. As long as electric cars suck compared to gas-guzzlers, people will want gas-guzzlers. Tesla solved that problem. How? they out-innovated gas-guzzlers, and better served the human want for transportation.</p><p>For news, we don’t need to force the New York Times to report fairly. Substack may do more to fix reporting quality than any regulation could have. Now, journalists can build an audience and support content that isn’t dependent on clicks. To the joy of reporters and readers alike, they changed the incentives that governed journalism.</p><p>What’s the analog of this for Facebook? Could we build a social network that made offline interactions as fun and intuitive as online ones? Could we build platforms that made constructive debate more engaging than Twitter? Could we integrate political transparency in our government, so that presidential candidates would filter to high-integrity? Could we make a University that encouraged free thinking and creation, at a hundredth the cost?</p><p>It’s hard, but once we choose to search along viable paths, the outlook is optimistic. </p><p>There have been many points in our past that imperiled our society, and innovation was up to the task. It is just as powerful, decentralized, and versatile as the most pernicious of society’s ills. </p><p>It’s a wonder that so many people today can live a life that lords could only have dreamed of a few hundred years ago. Slavery is eradicated in most of the world, and feudal societies are the rarest. Our production supports billions of people — an idea that would have seemed ridiculous to Malthus. </p><p>It has been done before, and we know this path has viable solutions, while our simple solution is known to fail. If you’re a person who wants to make a dent in the world, now you know two things: what <em>not</em> to do, and a potential path to success. Regulation or moralizing won’t help. Innovation will.</p><p>You may balk at the task ahead of you: climate change is a problem so daunting that it’s hard to think about. Luckily, innovation is opaque. You don’t need to attack problems directly. </p><p>Penicillin just showed up on Fleming’s desk. Rocket engines evolved from car engines. Ideas tend to compound together, forming ever-more complex ideas. This means you don’t have …</p></span></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stopa.io/post/273">https://stopa.io/post/273</a></em></p>]]>
            </description>
            <link>https://stopa.io/post/273</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400872</guid>
            <pubDate>Sat, 12 Dec 2020 19:36:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yo WASM – The Easy Way to WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25400837">thread link</a>) | @praveenperera
<br/>
December 12, 2020 | https://deislabs.io/posts/introducing-yo-wasm/ | <a href="https://web.archive.org/web/*/https://deislabs.io/posts/introducing-yo-wasm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>WebAssembly (Wasm) is a portable standard for bytecode, allowing code to be compiled to an efficient representation that’s amenable to just-in-time optimisation, and to be run on the operating system and runtime environment of your choice.  An ever-increasing number of languages offer compilation to Wasm, and Wasm runtimes are available in major browsers and as separate programs.  The existence of runtimes outside the browser, such as <a href="https://wasmtime.dev/"><code>wasmtime</code></a> and <a href="https://wascc.dev/"><code>waSCC</code></a>, opens up the possibility of using WASM as a general-purpose bytecode format, similar to <a href="https://en.wikipedia.org/wiki/Java_bytecode">Java bytecode</a> or <a href="https://en.wikipedia.org/wiki/Common_Intermediate_Language">.NET CIL</a>.  For example, the <a href="https://deislabs.io/posts/introducing-krustlet/">Krustlet</a> project provides a way to run WebAssembly modules as Kubernetes pods, performing compute work or serving HTTP requests.</p>

<p>Although languages such as <a href="https://rustwasm.github.io/docs/book/">Rust</a> and <a href="https://developer.mozilla.org/en-US/docs/WebAssembly/C_to_wasm">C/C++</a> can compile to WASM, it’s not always obvious how to set up projects in this way - there is extra ceremony compared to most languages’ “native” target.  Setting up debugging and deployment also involves extra steps too, and those aren’t always obvious.  So there’s a barrier to entry in the first place, and unwelcome configuration every time you create a new project.</p>

<p>To make this a bit easier, we’re building a Wasm project generator, using the popular <a href="https://yeoman.io/">Yeoman</a> code generator, to take care of this setup for you.  We’ve just released the first preview and we’d love folks to try it out and let us know how it goes.</p>

<p>To install Yeoman and the Wasm generator, you’ll need to have Node.js and NPM already installed; then run:</p>

<pre><code>npm install -g yo
npm install -g generator-wasm
</code></pre>

<p>Then generate your new project:</p>

<pre><code>mkdir myproject
cd myproject
yo wasm
</code></pre>

<p>The generator will ask you a few questions, of which two are interesting:</p>

<ol>
<li><p>Which language do you want the project generated in?  At the moment, we can do Rust, C and AssemblyScript.  We’d be delighted to have more.</p></li>

<li><p>Do you want to publish the compiled Wasm module to an OCI registry, and if so which one?  This is relevant for workloads that you envisage running in a cloud environment such as Kubernetes with Krustlet.  You don’t have to publish to an OCI registry; if you do, we currently only offer Azure Container Registry, but again would love to extend that to other OCI registries.</p></li>
</ol>

<p><img src="https://i.imgur.com/QYAQcHH.png" alt="Project setup in yo wasm"></p>

<p>The result of all this is a “hello, world” application.  The code itself is uninteresting, being just a minimal Rust, C or AssemblyScript program, but the generator also provides a bunch of things to make the development experience easier:</p>

<ol>
<li><p>Visual Studio Code tasks to build and debug the Wasm build.  This means that - if you’re a VS Code user - you can get up and running editing and debugging the project very quickly.  The Debug Wasm debug configuration uses <code>wasmtime</code> to run the program, and the LLDB debugger to support breakpoints, etc. in the running Wasm.</p>

<p><img src="https://i.imgur.com/ypz6o0P.png" alt="The Debug WASM configuration in VS Code"></p></li>

<li><p>GitHub actions to build pull requests, and to publish the compiled Wasm module to your chosen OCI registry when you merge to <code>main</code> or tag a release with a string of the form <code>v*</code> (e.g. <code>v1.0.0</code>).  (If you chose not to publish to an OCI registry, this action just creates a build artifact.)</p>

<p><img src="https://i.imgur.com/ARpY3jl.png" alt="Build and publish workflows running out of the box"></p></li>
</ol>

<p>The preview release has some limitations.  We’ve mentioned the limited language and registry options.  One important restriction is that all our current templates target WASI (WebAssembly System Interface) and the <code>wasmtime</code> runtime.  We’d love to have templates for other environments and runtimes, but we could really do with feedback on that before we invest in it.</p>

<p>We hope you’ll give <code>yo wasm</code> a try.  Please let us know if you run into any problems by raising an issue at <a href="https://github.com/deislabs/generator-wasm/issues">https://github.com/deislabs/generator-wasm/issues</a>, or feel free to send a pull request if there’s something you’d like to add or improve.  Thanks!</p>

      
      
    </div></div>]]>
            </description>
            <link>https://deislabs.io/posts/introducing-yo-wasm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400837</guid>
            <pubDate>Sat, 12 Dec 2020 19:32:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Still Rusting – One Year Later]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25400826">thread link</a>) | @praveenperera
<br/>
December 12, 2020 | https://deislabs.io/posts/still-rusting-one-year-later/ | <a href="https://web.archive.org/web/*/https://deislabs.io/posts/still-rusting-one-year-later/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>It has been about a year since the DeisLabs team starting using Rust in a “serious” project. About this time last year, we started work on what became the <a href="https://github.com/deislabs/krustlet">Krustlet</a> project. Since then, we have been using Rust extensively across our projects and have learned a ton more about the language’s strengths and weaknesses. As “Rust After the Honeymoon” posts currently seem to be all the rage, we thought we could contribute a little to the discussion with our experiences writing applications for the cloud world.</p>

<p>This post is organized using the classic (if not tired) good, bad, and ugly structure. In the bad and ugly sections, everything is stated as points of feedback and is not meant as a complaint. The whole point of this post is to go beyond the more superficial parts of the language and into things that really make a difference in our day-to-day programming work. Spoiler alert: We still <em>really</em> like Rust, so all of this is intended as helpful data for those working on the language, to give people new to the language a good idea of some of the things they might run into, and to help others evaluate Rust for their own use. We have tried to incorporate ideas of possible solutions, no matter how vague, to the problems we bring up.</p>

<p>At the very end, we also have a bonus feature about Go and Rust. Given the team’s background in many Go projects, we often hear something like this: “Well, what about Go? Do you regret moving to Rust? What do you miss from Go?” Addressing this in the context of our discussion of Rust felt like a smart decision. If you don’t care about that topic or it doesn’t interest you, feel free to skip it.</p>

<p>Now with that out of the way, let’s get going!</p>

<h2 id="the-good">The Good</h2>

<h3 id="traits">Traits</h3>

<p>First up, let’s talk about traits. We have absolutely loved the trait system in Rust. In particular, we really enjoy the conversion and reference traits (e.g. <code>TryFrom</code>/<code>From</code>, <code>AsRef</code>, <code>FromStr</code>, <code>Deref</code>, etc.). These are great examples of why traits are better than most other interface-style types – because the type itself doesn’t have to implement an interface to be used as another type. <code>FromStr</code> allows any type to implement a way to parse a bare string into a type (really useful for APIs). Another simple example can be found in the many types that implement <code>AsRef&lt;[u8]&gt;</code> or <code>Deref&lt;Type = [u8]&gt;</code>. Instead of having some sort of <code>Bytes</code> interface that all the types have to implement to be able to do operations as if it was a slice of bytes, you can just automatically pick up the methods from the underlying type. Yes, I know you could embed types or use inheritance, but the elegance of this is quite nice. This also allows me to write custom types and have easy/cheap conversions or references to them from other external types. It leads to generic parameters that look like this:</p>

<pre><code>// A function that can write anything that can be accessed as bytes:
// write_all("hello!")
// write_all(String::from("hello!"))
// write_all(b"hello!")
fn write_all&lt;T: AsRef&lt;[u8]&gt;&gt;(data: T)

// Or, I can take anything that can be converted to my custom type
fn do_something&lt;T: Into&lt;MyType&gt;&gt;(thing: T)
</code></pre>

<p>Basically, traits allow you to design flexible APIs for users that allow them to latch on to and/or extend the functionality of your code. This leads to my next point – <a href="https://serde.rs/">Serde</a>.</p>

<h3 id="a-love-letter-to-serde">A Love Letter to Serde</h3>

<p>Allow us to indulge in a brief love letter to Serde, the much-used serialization/deserialization library leveraged across the Rust ecosystem. To us, it is a first-rate product of Rust’s unique combination of features. It leverages macros, traits, and Rust’s emphasis on zero-cost abstractions to create a library that is powerful, easy to use, and performant. Developers can easily add serialization or deserialization with a simple <code>#[derive(Serialize, Deserialize)]</code> and then customize deserialization behaviors with attributes. Even if you have to implement it manually, there are plenty of docs to read. Once those traits are implemented, any serialization format that has a Serde implementation (like JSON, YAML, etc.) can then serialize or deserialize that data.</p>

<h3 id="error-handling-option-and-iter">Error handling, <code>Option</code>, and <code>Iter</code></h3>

<p>Another thing high on our “impressive Rust features” list is an amazing set of mapping, unwrapping, and iteration tools. The built in <code>Result</code> and <code>Option</code> types combined with their various mapping methods (and <code>if let</code> or <code>let thing = match {...}</code>) makes it easy to handle errors/missing data in an easy to read way. It also nudges you towards clean and readable error handling patterns (like the try <code>?</code> operator), which is helpful for people new to the language. On top of the error handling, we have the <code>Iterator</code> trait and its associated methods. There are a whole suite of chainable filters, maps, splitting, and zipping methods (similar to how LINQ and functional programming languages handle collections) along with the all-powerful <code>collect</code> method. Below is an example from Krustlet that shows unwrapping an optional value and then mapping and filtering from a collection of data:</p>

<pre><code>fn mount_setting_for(key: &amp;str, items_to_mount: &amp;Option&lt;Vec&lt;KeyToPath&gt;&gt;) -&gt; ItemMount {
    match items_to_mount {
        None =&gt; ItemMount::MountAt(key.to_string()),
        Some(items) =&gt; ItemMount::from(
            items
                .iter()
                .find(|kp| kp.key == key)
                .map(|kp| kp.path.to_string()),
        ),
    }
}
</code></pre>

<h3 id="enums">Enums</h3>

<p>We’ve found Rust enums really expressive and convenient. Rust enums aren’t just single values: they can carry associated data. What’s more, each variant can have a different data structure (like discriminated unions from other languages), and you can work with these different cases using pattern matching. They’re also full-blown types, so you can implement functions and traits on them.</p>

<p>The value of this is that you can bundle a bunch of possible cases into a single type to pass into (or return from) and function. Working with the cases is safe because you don’t need to have optional fields that only may apply to certain cases, and you can only access a case’s data when the enum matches that case. The case structure also encourages code that processes enums to adopt a clear, regular layout, making for some quite beautiful code:</p>

<pre><code>pub enum ClientError {
    /// The item already exists
    AlreadyExists,
    /// The error returned when the request is invalid. Contains the underlying HTTP status code and
    /// any message returned from the API
    InvalidRequest {
        status_code: reqwest::StatusCode,
        message: Option&lt;String&gt;,
    },
    /// A server error was encountered. Contains an optional message from the server
    ServerError(Option&lt;String&gt;),
}

pub fn handle_error(e: ClientError) {
    match e {
        ClientError::AlreadyExists =&gt; {
            println!("Item already exists")
        }
        ClientError::InvalidRequest { status_code, message } =&gt; {
            println!("Invalid request. HTTP code: {}, message: {}", status_code, message.unwrap_or_default())
        }
        ClientError::ServerError(Some(message)) =&gt; {
            println!("Server error: {}", message)
        },
        ClientError::ServerError(None) =&gt; {
            println!("Server error")
        },
        
    }
}
</code></pre>

<p>In this example, we created a simple error type and then unwrapped it according to the data contained inside of each variant. The Rust compiler makes sure we handle all variants of the enum, preventing programmer error (likely from getting distracted by a meme someone posted in chat).</p>

<h3 id="grab-bag">Grab Bag</h3>

<ul>
<li>Macros are awesome and allow you to do some powerful things (and clean up code)</li>
<li>Cargo still has our hearts. It is hands down one of the top dependency manager and build tools we’ve used</li>
<li>To quote a coworker: “NO DAMN NULL POINTERS” (emphasis theirs). You explicitly have to label code as <code>unsafe</code> to even get them</li>
</ul>

<h2 id="the-bad">The Bad</h2>

<h3 id="docs-and-clarity">Docs and Clarity</h3>

<p>As we have been using various crates across the ecosystem, we’ve found some interesting patterns in the documentation. Docs are sometimes unclear on what is happening in the actual code. They describe the functionality well, but we generally have to go digging through the code to find out whether it is truly a zero cost abstraction or if there are possible side effects to what we are doing. When you first start on projects, generally these kinds of details don’t matter. But as you start doing things that require more advanced usage, you end up digging under the hood to see what exactly is going on. For example, if we are using a library that writes data to disk, make sure to clarify which methods flush data or close things down.</p>

<p>Related to this, but slightly different, is trait documentation. As users, if we are trying to find out how we can customize behavior, we always end up jumping through a million functions, looking at all the trait bounds, before we can figure out what we need to implement (It also seems to always be a trait imported from <em>another</em> crate). An example of this from some recent work on Krustlet. We were using the <a href="https://docs.rs/tonic/0.3.1/tonic/"><code>tonic</code></a> crate and implementing a socket listener for the server. We ended up at one of the functions that allows for a custom handler, but that had 3-4 distinct bounds, 2 of which were traits from external crates. We eventually found an example in the crate repo and it wasn’t too difficult, but there was no clear documentation what needed to be implemented without digging more. This experience is <em>really really frustrating</em> for new Rust developers and we’ve seen this in multiple crates. The suggestion here would be to put a little more polish into describing what precisely needs to be implemented (even if just linking to an example) on functions with multiple trait bounds.</p>

<h3 id="missing-pieces">Missing Pieces</h3>

<p>Something to be aware of coming into the Rust ecosystem is that a lot of crates are still missing features. A recent example of this was finding out that there isn’t much support for <code>multipart</code> content types in HTTP requests except for <code>multipart/form-data</code>. This is not meant to be a complaint against any developer of any crate. We …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://deislabs.io/posts/still-rusting-one-year-later/">https://deislabs.io/posts/still-rusting-one-year-later/</a></em></p>]]>
            </description>
            <link>https://deislabs.io/posts/still-rusting-one-year-later/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400826</guid>
            <pubDate>Sat, 12 Dec 2020 19:31:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Adam Test: A Few More Steps to Better Code]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25400806">thread link</a>) | @aard
<br/>
December 12, 2020 | http://adamard.com/adam_test.html | <a href="https://web.archive.org/web/*/http://adamard.com/adam_test.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>{<br>&nbsp;&nbsp;&nbsp;&nbsp;Adam Ard<br>}</h2><br>
  <h2>The Adam Test: A Few More Steps to Better Code</h2>
  <p>In the year 2000, Joel Spolsky published <a href="https://www.joelonsoftware.com/2000/08/09/the-joel-test-12-steps-to-better-code/" target="_blank" rel="noopener">12 questions</a> for assessing the quality of any engineering team. These questions were immensely useful and are still relevant today. Over time, I have accumulated a few extra questions of my own. I hope you find them equally helpful:</p>
<h3><strong>1. Do programmers <em>REALLY</em> have quiet working conditions?</strong></h3>
<p>Even though Joel already put this one on his list, I wanted to repeat it (I added the <em>REALLY</em> for emphasis) because the industry has totally disregarded it. The norm now is to use flashy but useless open office plans that are full of noise and interruptions. Because the software engineering world is turned so backwards on this issue, I added a few follow-up questions to make it crystal clear what “quiet working conditions” <em>REALLY</em> are:</p>
<ul>
<li>Do you have individual private work spaces with doors, or at least cubicles with six foot high walls?</li>
<li>Do you have at least 100 total square feet per developer with 30 square feet of table space?¹</li>
<li>If developers do not have private offices, are they at least limited to sharing private offices with only one other person?</li>
<li>Can developers position themselves with their backs to the wall?</li>
<li>If you must have an open office do you at least implement <a href="https://m.signalvnoise.com/library-rules-how-to-make-an-open-office-plan-work-f9f6d69a2d4c" target="_blank" rel="noopener">Library Rules</a>?</li>
<li>Do you have a good work-from-home policy so developers can escape to places of solitude to concentrate?</li>
</ul>
<h3>2. Do you divide, organize and assign roles instead of&nbsp;tasks?</h3>
<p>This question may seem like a triviality, but it is hugely important. To put it simply, if you assign tasks to developers you are likely a micro-manager. But, if you assign roles (areas of major responsibility), you are utilizing the <a href="http://adamard.com/green_and_clean.html">Covey principle of stewardship delegation</a>. For motivation, and employee engagement, this distinction will make all the difference in the world.</p>
<p>For more on this read:</p>
<ul>
<li><a href="http://adamard.com/little_tasks.html">Little Tasks, Little Trust</a></li>
</ul>
<h3><strong>3. Are you careful to never fix the scope and release date for your deliverables?</strong></h3>
<p>Don’t let people fool you by trying to alter this equation. Many will comment that if you add people or resources, you can get around it. They haven’t read <a href="https://en.wikipedia.org/wiki/Brooks%27s_law" target="_blank" rel="noopener">Brook’s Law</a>. Others will say that you can cheat on the quality to push things through. But, in the end, if you aren’t aiming for high quality your team’s morale will suffer and you will lose more productivity from disengagement than you’ll gain by cutting corners. As a result, it is just better to concentrate on scope and date. Here are some good examples in the industry:</p>
<ul>
<li><a href="https://m.signalvnoise.com/how-we-set-up-our-work-cbce3d3d9cae" target="_blank" rel="noopener">Basecamp</a> has fixed release periods, with the conviction that there is a very good 6 week version of pretty much any feature. So, essentially they pick a release date and let the scope change.</li>
<li>Others (game companies are famous for this) will simply say that their next release will be ready when it is ready. Most will complain that they don’t have this luxury in their industry (they might be surprised at how long customers will wait/pay for a superior product), but it is a nice option if you can pull it off. This is how you fix your scope, but let the date change.</li>
</ul>
<p>An interesting corollary to this is that you really shouldn’t waste your time in estimation exercises either — estimation by definition is picking a date and a scope.</p>
<h3>4. Do you utilize strong code ownership?</h3>
<p><a href="https://docs.microsoft.com/en-us/azure/devops/learn/devops-at-microsoft/code-ownership-software-quality" target="_blank" rel="noopener">Microsoft ran a study</a> of their own extensive code base (if anyone has a bunch of code to run studies on, it’s Microsoft), and found that when only one person makes the majority of the commits to a file, executable or directory, those code units have a lower incidence of bugs.</p>
<p>You can whoop and holler all you want about how <em>the magic </em>happens when everyone holds hands and codes in perfect harmony, but the truth is, people need to own what they work on. They need to have separate responsibilities. They need to be able to think deeply about what they are doing, be a custodian of the conceptual integrity of their design, and they need to be left alone to work on it.</p>
<p>This doesn’t mean that people shouldn’t bounce ideas off each other, seek advice of experts and peers, and be humble enough to except constructive criticism. It also doesn’t mean that they shouldn’t be transparent about what they are planning and producing. It just means that after all the advice comes in, and the ideas have been bounced around, one person needs executive authority over the decisions in a given domain.</p>
<p>For more on this read:</p>
<ul>
<li><a href="http://adamard.com/code_ownership.html">Strong Code Ownership</a></li>
<li><a href="http://adamard.com/fountainhead.html">The Fountainhead and Software Engineering</a></li>
<li><a href="http://adamard.com/code_reviews_broke.html">Code Reviews are Broken — Here is How to Fix Them</a></li>
<li><a href="http://adamard.com/three_agile.html">Three Ways Agile has Gone Astray</a></li>
</ul>
<h3>5. Are worker metrics kept private to individuals and never revealed to management?</h3>
<p>It is best to avoid companies that rely too heavily on scientific management practices, also known as <a href="https://en.wikipedia.org/wiki/Scientific_management" target="_blank" rel="noopener">Taylorism</a>. Programming in particular is not a profession that will benefit from being managed by trying to optimize a group of performance indicators. Anyone who has been managed in this way can attest to the dysfunction that it creates. Sadly, as soon as a worker metric is used to motivate programmer output, it loses its ability to be useful. Some people call this <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law" target="_blank" rel="noopener">Goodhart’s Law</a>.</p>
<blockquote>
<p>When a measure becomes a target, it ceases to be a good measure</p>
</blockquote>
<p>Tom DeMarco and Timothy Lister, the authors of Peopleware, recommend a novel way to maintain the usefulness of metrics--don’t let management see them:</p>
<blockquote>
<p>Work measurement can be a useful tool for method improvement, motivation, and enhanced job satisfaction, but it is almost never used for these purposes. Measurement schemes tend to become threatening and burdensome.</p>
<p>In order to make the concept deliver on its potential , management has to be perceptive and secure enough to cut itself out of the loop. That means the data on individuals is not passed up to management, and everybody in the organization knows it. Data collected on the individual’s performance has to be used only to benefit that individual. The measurement scheme is an exercise in self-assessment, and only the sanitized averages are made available to the boss.²</p>
</blockquote>
<h3>6. Are you careful that managers have enough direct&nbsp;reports?</h3>
<p>I don’t know what the ideal number of direct reports actually is, but I know it isn’t 2 or 3 or even 10. It is much bigger. “It is not uncommon for google managers to have 30 direct reports”³. Why does this matter? Because good managers don’t micromanage and they can’t if they have enough people to take care of. In a way, the number of direct reports assigned to a manager is an indicator of how an organization thinks about management in general.</p>
<h3>7. Do engineers choose what they work&nbsp;on?</h3>
<p>This one is rare but wonderful if you can find it. <a href="https://steamcdn-a.akamaihd.net/apps/valve/Valve_NewEmployeeHandbook.pdf" target="_blank" rel="noopener">Valve’s employee manual</a> famously tells new employees to go find a project they like because no one is going to pick it for them. Oh what a glorious world that would be. Hat tip to the enlightened companies that do this already — you are the future of management! If you find yourself at a place like this, hold it tight, and never let go.</p>
<h3>8. Do engineers own and manage their own deployments and infrastructure?</h3>
<p>This keeps your organization lean and scalable. Setting up a centralized infrastructure team is rarely a good idea because teams have such varied needs. The burden of keeping a shared infrastructure up all the time is not trivial. Additionally, dedicated devops teams tend to want to wrap essential deployment APIs in homemade access management tools, creating bottlenecks for engineers that are clamoring to use new aws services or kubernetes resources that haven’t been exposed yet. Trust your engineers to pick and learn the best tools for what they are trying to accomplish, and to safely and effectively utilize them. If you have up-time or security concerns, focus on training (books, conferences, courses) or consider an organizational model where you have a devops expert on each team that can teach and train the other developers. But don’t create a separate devops team.</p>
<h3>9. Can engineers choose their own tools for task management and coordination?</h3>
<p>Does your organization use something awful like Team Foundation Server or Jira (or any of a million other painful task trackers) to track and manage engineers? You are not alone. Man <em>YEARS</em> are wasted keeping these red tape generators running and up to date. It is simply not healthy to make engineers track and coordinate their work with a tool that they haven’t chosen themselves. If they want to use post-it notes or emacs org-mode, then let them. Questionably valuable reports that you get from big enterprise tools are not worth the loss in productivity and morale.</p>
<h3>10. Do engineers have full administrative control of their machines? Can they choose their computer model and operating system?</h3>
<p>This one is a no-brainer. Would you hire a mechanic but tell them they can’t use their own tool box? If you hire a Linux nerd that has spent a decade or more tuning their development configuration, it makes no sense to force them to use Windows or MacOS. It is equally counterproductive to make a Windows guru suffer through setting up a Unix based environment. Virtualization is almost always sufficient for providing ways to test and develop on alternative target environments. But peoples' host machines, their home base, should be what they are most comfortable with.</p>
<p>And when they get their machine, don’t lock it down so they can’t install what they need. If people are responsible enough to load software on their home computers, they are most certainly capable of managing the software on their work machine.</p>
<h3>Summary</h3>
<p>If you want a highly satisfying and productive culture, give these suggestions a try. And if you are interviewing, make sure that you know how your potential employers score on the Adam Test — let that help you make a decision of who to work for. You won’t regret it!</p>
<h3><strong>Sources</strong></h3>
<p>1,2. <em>Peopleware</em> by Tom DeMarco and Timothy Lister</p>
<p>3. <a href="https://hbr.org/2013/12/how-google-sold-its-engineers-on-management" target="_blank" rel="noopener">https://hbr.org/2013/12/how-google-sold-its-engineers-on-management</a></p>
    </div></div>]]>
            </description>
            <link>http://adamard.com/adam_test.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400806</guid>
            <pubDate>Sat, 12 Dec 2020 19:30:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Source and Business: needs strict rules – here is my manifesto]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25400716">thread link</a>) | @metaralf
<br/>
December 12, 2020 | https://www.deskfiler.org/oss-business.php | <a href="https://web.archive.org/web/*/https://www.deskfiler.org/oss-business.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<nav>
<p><span data-responsive-toggle="topbar-responsive" data-hide-for="medium">

</span>
<a href="https://www.deskfiler.org/" title="Cross Platform Applications" rel="home">
<img src="https://www.deskfiler.org/img/main/deskfilerlogowhite.png" alt="Cross Platform Applications">
</a>
</p>

</nav>

<section>
<div>
<h2>Open Source and Business - Our Manifesto</h2><p>
Feel free to copy this and modify as you see fit. It is totally a &nbsp;
<a href="https://en.wikipedia.org/wiki/Permissive_software_license" target="_blank">BSD-like</a>
statement for you to adapt for your own company, if you work with Open Source methods! This page has explicitly no copyright! Take it, copy it, improve it!
</p></div>
</section>

<section>
<div>
<div>
<p>
This declaration of values and viewpoints on Open Source Software
development and business requirements shall reflect our common
understanding as a team in a complex world of personal preferences
and common requirements to function increasingly healthy, happily and
pleasantly together.
</p>
<div><p>
Past separations of "Open Source" AGAINST "Business" or the split
of topics and cultures have caused turmoil between colleagues and
misunderstandings to a level, that we feel it is time to address.
</p><p>

Since the concepts of Open Source and Free Software were formalized in the
80s and 90s of the last century, they have been constantly confusing people
from other industries and from outside the software business.
</p><p>

Either the fear of "Why should someone pay for freely available software?"
or the expectation that someone will copy and steal the openly accessible
product have triggered misperception of the Open Source method and by that
caused ultimateley a basic "marketing problem" for many Open Source businesses.
</p></div>
<ol>
<li>
<b>What is Open Source to us?</b>
<div><p>
We think that Open Source can be a very attractive method to develop
excellent software products. We also think, that choosing this method
does not automatically make our (or any) product better.
</p><p>

Open Source for product development has to be carefully planned out,
sensitively managed by all developers and team members and finally be
constantly adjusted to the fast paced evolvement of development best
practices and technologies.
</p><p>

It also involves a <a href="https://en.wikipedia.org/wiki/Open-source_license" target="_blank">fundamental understanding of software licensing</a>
and avoiding the pitfalls of miscommunication in a very complex group of
people with very different backgrounds and interests.
</p><p>

Some developers just want to improve the world or are drawn into solving
complex problems for the fun of it. Some want fame. Some want to use
their code as "self marketing" to make more money.
</p><p>

We are OK with this. We will try to understand and help each other with
these goals and if we do not like them, we will try to find a compromise.
Actively.
</p></div>
</li>
<li>
<b>What does Open Source development mean for us?</b>
<div><p>
a) Our code and ideas are visible to the world. It has an exemplatory
and educational meaning as well as a "marketing meaning" for us as a group.
</p><p>

We have to be more meticulous and strict in our way of development than
in closed code environments, because others might copy us and bad code
or bad coding style might be copied by others and worsen certain technologies,
that should improve the daily life of thousands.
</p><p>

In those aspects: We are taking the hard way to develop a product by choice
and we are aware of it. We value the fact, that our product shall improve
the life of users - however small the improvement is on the scale of things.
</p></div>
<div><p>
b) As a development method above the daily processes (Agile, SCRUM, XP, etc.) it
is selected by us to support the users of the product. It inherently and
actively asks the users out there to give feedback and critize our product.
</p><p>

This has to be understood, valued and accepted by the whole company or
the concept of Open Source does not work in business.
</p><p>

Feedback and ideas of users also have to be managed and evaluated in a
structured process.
</p></div>
</li>
<li>
<b>What does <a href="https://en.wikipedia.org/wiki/Business_models_for_open-source_software" target="_blank">Open Source Business</a> mean to us?</b>
<div><p>
Simply put: "Business" means to make more money that we spend in an entity
we are calling "our company". In the modern software world, solid business growth
is achieved by selling licenses and services around the software product to
users, who need the software for specific problems and therefor are willing
to pay for it.
</p><p>

Accepting and dealing with this monetary aspect for a company and as a group
of people with very different goals, values and opinions is our core challenge.
</p><p>

By upholding and expanding the Open Source method in our product development
we have to carefully decide on each module, each hour of service and each
request from the outside of our company:
</p><p>

Is this part strengthening our core product and helping us to thrive as
a company or is it following the natural desire of other business entities
to earn more than they spend (on us)?
</p></div>
</li>
<li>
<b>Establishing momentum and growth</b>
<div><p>
Growth for us means primarily to reach more users with our work and to sustain
this growth with solid internal structures and methods. Financing this growth
with money is only (however important) means for this purpose.
</p><p>

We believe our products are and continously will be useful and crucial to many
users, companies and institutions. So, whenever users want or need our software
for business purposes, we believe, we can and should be rewarded for the
product and services around it. These rewards do not necessarily need to be money,
but in order to continue to produce better software, we will continue to put prices on
certain parts of our doing and production and come up with new commercial
aspects of our work under Open Source rules.
</p></div>
</li>
</ol>
</div>

</div>
</section>












</div>]]>
            </description>
            <link>https://www.deskfiler.org/oss-business.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400716</guid>
            <pubDate>Sat, 12 Dec 2020 19:21:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built a picture frame with a greyscale e-paper that runs on battery for years]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 73 (<a href="https://news.ycombinator.com/item?id=25400702">thread link</a>) | @clash
<br/>
December 12, 2020 | https://framelabs.eu/en/ | <a href="https://web.archive.org/web/*/https://framelabs.eu/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="moove_gdpr_cookie_modal" role="complementary" aria-label="GDPR Settings Screen" data-no-translation-aria-label="">
  <div>
    <div>
      
<p><img src="https://framelabs.eu/wp-content/plugins/gdpr-cookie-compliance/dist/images/gdpr-logo.png" alt="Frame Labs">
</p>
<!--  .moove-gdpr-company-logo-holder -->      <ul id="moove-gdpr-menu">
        
<li>
  
</li>

  <li>
    
  </li>




      </ul>
      
<div>
  
		<p><a href="https://wordpress.org/plugins/gdpr-cookie-compliance" target="_blank" rel="noopener">Powered by&nbsp; <span data-no-translation="" data-trp-gettext="">GDPR Cookie Compliance</span></a>
		</p></div>
<!--  .moove-gdpr-branding -->    </div>
    <!--  .moove-gdpr-modal-left-content -->
    <div>
      
      <!-- .moove-gdpr-modal-ritle -->
      <div>

        <div>
          
<div id="privacy_overview">
      <p><span data-no-translation="" data-trp-gettext="">Privacy Overview</span></p><p data-no-translation="" data-trp-gettext="">This website uses cookies so that we can provide you with the best user experience possible. Cookie information is stored in your browser and performs functions such as recognising you when you return to our website and helping our team to understand which sections of the website you find most interesting and useful.</p>
  <!--  .moove-gdpr-tab-main-content -->

</div>
<!-- #privacy_overview -->          
  
  <!-- #strict-necesarry-cookies -->
          
          
          
        </div>
        <!--  .moove-gdpr-tab-content -->
      </div>
      <!--  .main-modal-content -->
      <div>
        
<!--  .moove-gdpr-button-holder -->      </div>
      <!--  .moove-gdpr-modal-footer-content -->
    </div>
    <!--  .moove-gdpr-modal-right-content -->

    

  </div>
  <!--  .moove-gdpr-modal-content -->
</div></div>]]>
            </description>
            <link>https://framelabs.eu/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400702</guid>
            <pubDate>Sat, 12 Dec 2020 19:19:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Female job seekers using less feminine language less likely to get hired: study]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25400631">thread link</a>) | @rustoo
<br/>
December 12, 2020 | https://www.utm.utoronto.ca/main-news/female-job-seekers-using-less-feminine-language-less-likely-get-hired-study | <a href="https://web.archive.org/web/*/https://www.utm.utoronto.ca/main-news/female-job-seekers-using-less-feminine-language-less-likely-get-hired-study">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div property="content:encoded"><p><span><span><span>Women applying to jobs in male-dominated fields often try to overcome sexism by altering their cover letters to sound less feminine. But that practice might actually be hurting their chances of landing a job, a new study out of U of T Mississauga reveals.</span></span></span></p>

<p><span><span><span>Examining real cover letters to a variety of actual jobs and analyzing applications to an MBA program, <b>Joyce He</b>, a PhD candidate at U of T’s Rotman School of Management, found that women applying for jobs in male-dominated fields would respond to anticipated bias by using less feminine language to deliberately manage gender impressions. While they did not use more masculine language, they did try to conceal their femininity.</span></span></span></p>

<p><span><span><span>That would mean avoiding words that are stereotypically associated with women, which include sensitive, interpersonal, empathetic, helpful, warm and friendly. Examples of words that people associate with masculinity, meanwhile, include competitive, ambitious, confident, outspoken and entrepreneurial.</span></span></span></p>

<p><span><span><span>Notably, words identified as masculine hold higher value in the business world. That’s why associations are made with respect to gender and probability of success, says <b>Sonia Kang</b>, an associate professor at U of T Mississauga’s Department of Management and co-author of the study published in <a href="https://journals.aom.org/doi/10.5465/amj.2018.1280">Academy of Management</a>.</span></span></span></p>

<p><span><span><span>“When we see those kinds of words, it’s a cue not only to the fact that this is going to be a man, but also this person is going to be better suited to this particular position,” explains Kang. “That’s why language in all these application materials is so important. They cue to more than just identity.”</span></span></span></p>

<p><span><span><span>He adds that research suggests women’s identity is devalued when they apply for male-dominated jobs and they tend to anticipate discrimination or bias in the selection process.</span></span></span></p>

<p><span><span><span>“They need to hide the devalued part, the feminine side, which is why they use this strategy,” she says, adding that men do not engage in the same behaviour when applying for female-dominated roles.</span></span></span></p>

<p><span><span><span>But these attempts by women applicants to manage gender impressions can actually backfire because they clash with deeply entrenched cultural stereotypes.</span></span></span></p>

<p><span><span><span>He explains that there’s an unspoken rule regarding how men and women should act. “Men should behave competitively and dominantly, and women should behave more friendly and communal,” she says. “When you go against the rules or expectations, women especially can receive this backlash or penalty.”</span></span></span></p>

<p><span><span><span>She notes that women who behave counter-stereotypically are seen as more competent but also less likable, which in turn means they are less likely to be hired or even promoted.</span></span></span></p>

<p><span><span><span>This is related to the double-bind women face, Kang continues. She explains that stereotypes suggest men should be in charge because they’re assertive and decisive and get things done. When women take on that role, they’re seen as competent but are less likely to be liked. At the same time, women contend with the stereotype that they should be more nurturing and communal. When women act in line with those gendered stereotypes, they end up being liked but are seen as less competent.</span></span></span></p>

<p><span><span><span>“You’re damned if you do, damned if you don’t,” Kang says, adding men don’t have to navigate the same no-win situation. “If (men) are super confident, people don’t care if they’re likable.”</span></span></span></p>

<p><span><span><span>He says that the onus shouldn’t be on women (or minorities) to try to navigate the different biases in the labour market. The onus should be on organizations to reduce bias, which is the root of the problem.</span></span></span></p>

<p><span><span><span>He is now shifting her research focus to design interventions that help de-bias the selection process, saying there’s promising new work focused on systemic problems that target the environment, which is a more powerful way to change behaviour. That can include anonymized evaluations or reviewing applications in sets instead of individually.</span></span></span></p>

<p><span><span><span>But systemic solutions take a long time to implement and job seekers can’t wait.</span></span></span></p>

<p><span><span><span>Kang suggests women forced to contend with existing biases in the labour market should approach job applications like an experiment and find what works for them and is successful. That might mean changing how different activities are presented or how a person writes about themself. </span></span></span></p>

<p><span><span><span>“The work really shows it doesn’t help to pretend to be something you’re not,” Kang says. “I know it sounds pithy but be yourself is the takeaway here.”</span></span></span></p></div></div></div></div>]]>
            </description>
            <link>https://www.utm.utoronto.ca/main-news/female-job-seekers-using-less-feminine-language-less-likely-get-hired-study</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400631</guid>
            <pubDate>Sat, 12 Dec 2020 19:10:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thread-Per-Core Buffer Management for a modern storage system]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25400350">thread link</a>) | @arjunnarayan
<br/>
December 12, 2020 | https://vectorized.io/blog/tpc-buffers/ | <a href="https://web.archive.org/web/*/https://vectorized.io/blog/tpc-buffers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p><a href="https://vectorized.io/blog/redpanda-raison-detre">As I have previously observed</a>, software does not run on category theory, it runs on superscalar CPUs with wide, multi-channel GB/s memory units and NVMe SSD access times in the order of 10-100’s of microseconds. The reason some software written a decade ago - on a different hardware platform - feels slow is because it fails to exploit the advances in modern hardware.</p>
<p>The new bottleneck in storage systems is the CPU. SSD devices are 100-1000x faster than spinning disks and are 10x cheaper today[1] than they were a decade ago, from $2,500 down to $200 per Terabyte. Networks have 100x higher throughput in public clouds from 1Gbps to 100Gbps.</p>
<p>Although computers did, in fact, get faster, single-core speeds remain roughly the same. The reason being that CPU frequency has a cubic dependency on power consumption, and we’ve hit a wall. Instruction level parallelism, prefetching, speculative execution, branch prediction, deep hierarchy of data caches and instruction caches, etc, have contributed to programs <em>feeling</em> faster when you interact with them, but in the datacenter, the material improvements have come from the rise in core count. While the instructions per clock are 3x higher than a decade ago, core count is up 20x.</p>
<p>This is all to say that the rise of readily available, many-core systems necessitates a different approach for building infrastructure. Case in point[9]: in order to take full advantage of 96 vCPUs on a i3en.metal on AWS, you’ll need to find a way to exploit sustained CPU clock speed of 3.1 GHz, 60 TB of total NVMe instance storage, 768 GiB of memory and NVMe devices capable of delivering up to 2 million random IOPS at 4 KB block sizes. This kind of beast necessitates a new kind of storage engine and threading model that leverages these hardware advances.</p>
<p><a href="https://vectorized.io/redpanda" target="_self" rel="nofollow">Redpanda</a> - a Kafka-API compatible system for mission critical workloads[3] - addresses all of these issues. It uses a thread-per-core architecture with Structured Message Passing (SMP) to communicate between these pinned threads. Threading is a foundational decision for any application, whether you are using a thread-pool, pinned threads with a network of Single Producer Single Consumer SPSC[7] queues, or any other of the advanced Safe Memory Reclamation (SMR) techniques, threading is your ring-0, the true kernel of your application. It tells you what your sensitivity is for blocking - which for Redpanda is less than 500 microseconds - otherwise, Seastar’s[4] reactor will print a stack trace warning you of the blocking since it effectively injects latency on the network poller.</p>
<p>Once you have decided on your threading model, the next step is your memory model and ultimately, for storage engines, your buffer management. In this post, we’ll cover the perils of buffer management in a thread-per-core environment and describe <code>iobuf</code>, our solution for a 0-copy memory management in the world of Seastar.</p>
<h2 id="Request-Flow-Architecture">Request Flow Architecture<a href="#Request-Flow-Architecture" aria-label="Request Flow Architecture permalink"></a></h2>
<p>As mentioned earlier, Redpanda uses a <em>single</em> pinned thread per core architecture to do everything. Network polling, submitting async IO to the kernel, reaping events, triggering timers, scheduling compute tasks, etc. Structurally, it means nothing can block for longer than 500 microseconds, or you’ll be introducing latency in other parts of your stack. This is an incredibly strict programming paradigm, but this opinionated idea forces a truly asynchronous system, whether you like it or not as the programmer.</p>
<p><img src="https://vectorized.io/31d1a730c507b605e6c1ebea60eb1e56/flow.svg" alt="Kafka request flow">
<small>
Figure 1: request flow architecture. Core-0 accepts the connection from the Kafka Java client and becomes the source core. After the request goes through the metadata cache(valid request) it filters through the partition router which decides to send the request to core-1, the destination core. Core-1 then accepts the write through the Raft-log interface and saves it to disk.
</small></p>
<p>The challenge in a TpC (thread-per-core) architecture[8] is that all communication between cores is explicit. This muscles the programmer into implementing algorithms that favor core-locality (d-cache, i-cache) over the straightforward multi-threaded implementations via mutexes. This imperative has to be co-designed with the asynchronicity of a <strong>future&lt;&gt;</strong>-based implementation.</p>
<p>For our Kafka-API implementation as shown in Figure 1, we explicitly trade memory usage to reduce latency and increase throughput by materializing key components. The metadata Cache is materialized on every core since every request has to know if the partition exists, and that that particular machine is, in fact, the leader of the partition. The Partition Router maintains a map of which logical core actually owns the underlying Kafka partition on the machine. Other things like Access Control Lists (ACLs) are deferred until the request reaches the destination core since they can get unwieldy in memory footprint.  We have no hard and fast rule of what we materialize on every core vs. what is deferred for the destination core, and it’s often a function of memory (smaller data structures are good candidates for broadcast), computation (how much time is spent deciding) and frequency of access (very likely operations tend to get materialized on every core).</p>
<p>One question remaining is how, exactly, does memory management work in a TpC architecture? How does data actually travel from L-core-0 to L-core-66 safely using a network of SPSC queues within a fully asynchronous execution model where things can suspend at any point in time?</p>
<h2 id="struct-iobuf--">struct iobuf { };<a href="#struct-iobuf--" aria-label="struct iobuf   permalink"></a></h2>
<h3 id="Redpandas-0-copy-buffer-management-for-TpC">Redpanda’s 0-copy buffer management for TpC<a href="#Redpandas-0-copy-buffer-management-for-TpC" aria-label="Redpandas 0 copy buffer management for TpC permalink"></a></h3>
<p>To understand <strong>iobuf</strong>, we need to understand the actual memory constraints of Seastar, our TpC framework. During program bootstrap, Seastar allocates the full memory of the computer and splits it evenly across all the cores. It consults the hardware to understand what memory belongs to each particular core, reducing inter-core traffic to main memory.</p>
<p><img src="https://vectorized.io/efa273909c5b695bf7f978f77b32c12b/seastar_model.svg" alt="Seastar mental model">
<small>
Figure 2: Copy from alexgallego.org (<a href="https://www.alexgallego.org/concurrency/smf/2017/12/16/future.html" target="_self" rel="nofollow">https://www.alexgallego.org/concurrency/smf/2017/12/16/future.html</a>) Seastar threading model. Seastar uses a network of SPS queues to send messages to neighboring cores. Similar to other message passing or actor models like Erlang, Orleans and Pony, once a function is futurized, transitive functions too will become futurized. Both approaches, however, are intrinsically safe. The programmer worries about correctness and construction while the frameworks worry about efficient execution. Counter to general wisdom, it is actually faster and more scalable than the synchronous approach. While the machine does more work, it is executing your code simultaneously. This simultaneity is the key to finishing work sooner.
</small></p>
<p>As Figure 2 suggests, memory allocated on core-0, <em>must</em> be deallocated on core-0. However, there is no way to guarantee that a Java or Go client connecting to Redpanda will actually communicate with the exact core that owns the data.</p>
<p>At its core, an iobuf is a ref-counted, fragmented-buffer-chain with deferred deletes that allows Redpanda to simply share a view of a remote core’s parsed messages as the fragments come in, without incurring a copy overhead.</p>
<p><img src="https://vectorized.io/6df6fc00e05201d068dc5d03e080606a/iobuf.svg" alt="iobuf architecture"></p>
<p>The fragmented buffers abstraction is not new. The linux kernel has <strong>sk_buff</strong>[5] and the freebsd kernel has an <strong>mbuf</strong>[6] which are roughly similar. The additional extension of an iobuf is that it works in the TCP model leveraging Seastar’s network of SPSC queues to have proper deletes in addition to being able to share sub-views arbitrarily, tailored for a storage-like workload.</p>
<p>Removing the C++ templates, allocators, pooling, pointer caching, etc, one could think of an iobuf as being equivalent to:</p>
<div data-language="cpp"><pre><code><span>struct</span> <span>fragment</span> <span>{</span>
    <span>void</span> <span>*</span> data<span>;</span>
    size_t ref_count<span>;</span>
    size_t capacity<span>;</span>
    size_t size<span>;</span>

    fragment<span>*</span> next<span>;</span>  
    fragment<span>*</span> prev<span>;</span>
<span>}</span>
<span>struct</span> <span>iobuf</span> <span>{</span>
    fragment<span>*</span> head<span>;</span>
<span>}</span><span>;</span></code></pre></div>
<p>The origins of iobuf are rooted in one of our central product tenets for building a Kafka® replacement for mission critical systems - giving users 10x lower tail latencies for most workloads. Aside from a thread-per-core architecture, the memory management would have been our second bottleneck if not designed from the ground up for latency. On long running storage systems, memory fragmentation is a real problem, and one that is eventually either met with a proper solution (iobuf), stalls or an OOM.</p>
<p>Like its predecessors skbuff and mbuff, iobuf allows us to optimize and train our memory allocator with predictable memory sizes. Here is our iobuf allocation table logic:</p>
<div data-language="cpp"><pre><code><span>struct</span> <span>io_allocation_size</span> <span>{</span>
   <span>static</span> <span>constexpr</span> size_t max_chunk_size <span>=</span> <span>128</span> <span>*</span> <span>1024</span><span>;</span>
   <span>static</span> <span>constexpr</span> size_t default_chunk_size <span>=</span> <span>512</span><span>;</span>

   
   
   
   
   
   
   <span>static</span> <span>constexpr</span> std<span>::</span>array<span>&lt;</span><span>uint32_t</span><span>,</span> <span>15</span><span>&gt;</span> alloc_table <span>=</span>
     
     <span>{</span><span>{</span><span>512</span><span>,</span>
       <span>768</span><span>,</span>
       <span>1152</span><span>,</span>
       <span>1728</span><span>,</span>
       <span>2592</span><span>,</span>
       <span>3888</span><span>,</span>
       <span>5832</span><span>,</span>
       <span>8748</span><span>,</span>
       <span>13122</span><span>,</span>
       <span>19683</span><span>,</span>
       <span>29525</span><span>,</span>
       <span>44288</span><span>,</span>
       <span>66432</span><span>,</span>
       <span>99648</span><span>,</span>
       <span>131072</span><span>}</span><span>}</span><span>;</span>

   <span>static</span> size_t <span>next_allocation_size</span><span>(</span>size_t data_size<span>)</span><span>;</span>
<span>}</span><span>;</span>   </code></pre></div>
<p>Predictability, memory pooling, fixed sizes, size capping, fragmented traversal, etc, are all known techniques to reduce latency. Asking for contiguous and variably sized memory could cause the allocator to compact all of the arenas and reshuffle a lot of bytes for what could be a short-lived request, not only injecting latency on the request path, but for the entire system since we have exactly one thread performing all operations.</p>
<p>Hardware is the platform. When we ask the network layer to give us exactly 11225 bytes in contiguous memory, we are simply asking the allocator to linearize an empty buffer of that exact size and for the network layer to copy bytes as the fragments come from the hardware into the destination buffer. There is ultimately no free lunch when it comes to trying to squeeze every single ounce of performance of your hardware and often it requires re-architecting from zero.</p>
<p>If you made it this far, I encourage you to sign up for our <a href="https://vectorized.io/slack" target="_self" rel="nofollow">Community Slack (here!)</a> and ask us questions directly or engage with us on twitter via <a href="https://twitter.com/vectorizedio" target="_self" rel="nofollow">@vectorize…</a></p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vectorized.io/blog/tpc-buffers/">https://vectorized.io/blog/tpc-buffers/</a></em></p>]]>
            </description>
            <link>https://vectorized.io/blog/tpc-buffers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400350</guid>
            <pubDate>Sat, 12 Dec 2020 18:34:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Join 347 developers learning about solving the Multi-Armed Bandit Problem]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25400348">thread link</a>) | @l1am0
<br/>
December 12, 2020 | https://simon.red/7 | <a href="https://web.archive.org/web/*/https://simon.red/7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wtr-content" data-bg="#FFFFFF" data-fg="#f44813" data-width="5" data-mute="" data-fgopacity="0.5" data-mutedopacity="0.5" data-placement="top" data-placement-offset="0" data-content-offset="0" data-placement-touch="top" data-placement-offset-touch="0" data-transparent="" data-shadow="1" data-touch="" data-non-touch="1" data-comments="0" data-commentsbg="#ffcece" data-location="page" data-mutedfg="#f44813" data-endfg="#f44813" data-rtl="">
<p>Hey upcoming data science expert,</p>
<p>this weeks topic caught my interest as I overheard some colleagues from the machine learning department. Multi-armed bandit theory is a quite old math problem from the 80s with still having relevance in the data science area. It is about choosing a optimal value from several options. As I am not a data science person I had to first learn about the basics in this <a href="https://www.youtube.com/watch?v=e3L4VocZnnQ">Youtube video</a>. The paper presented build upon this problem and gives a general framework for solving multi-armed bandit scenarios.To be 100% honest, I did not completely follow all the math in the paper. If someone of you does, it would be awesome if you could send a small “Combinatorial Multi-Armed Bandit”-For Dummies to the Telegram group. Thanks for your help!</p>
<hr>
<p>Abstract:</p>
<p><em>We define a general framework for a large class of combinatorial multi-armed bandit(CMAB) problems, where simple arms with unknown distributions form super arms. In each round, a super arm is played and the outcomes of its related simple arms are ob-served, which helps the selection of super arms in future rounds. The reward of the super arm depends on the outcomes of played arms, and it only needs to satisfy two mild assumptions, which allow a large class of nonlinear reward instances. We assume the availability of an (α,β)-approximation oracle that takes the means of the distributions of arms and outputs a super arm that with probability β generates anαfraction of the optimal expected reward. The objective o fa CMAB algorithm is to minimize (α,β)-approximation regret, which is the difference in total expected reward between theαβfrac-tion of expected reward when always playing the optimal super arm, and the expected re-ward of playing super arms according to the algorithm. We provide CUCB algorithm that achieves O(logn) regret, where n is the number of rounds played, and we further provide distribution-independent bounds for a large class of reward functions. Our regret analysis is tight in that it matches the bound for classical MAB problem up to a constant factor,and it significantly improves the regret bound in a recent paper on combinatorial bandits with linear rewards. We apply our CMAB framework to two new applications, probabilistic maximum coverage (PMC) for online advertising and social influence maximization for viral marketing, both having nonlinear re-ward structures.</em></p>
<p>Download Link:</p>
<p><a href="http://proceedings.mlr.press/v28/chen13a.pdf">http://proceedings.mlr.press/v28/chen13a.pdf</a></p>
<hr>
<p>Our little paper community is at 347 subscribers. It would be awesome if you share it with more people:</p>
<p><a href="https://simon-frey.com/weeklycspaper">simon-frey.com/weeklycspaper</a></p>
<p>If you have any paper recommendation for me, please do not hesitate to approach me via <a href="https://simon.red/cdn-cgi/l/email-protection" data-cfemail="8fffeeffeafdcffce6e2e0e1a2e9fdeaf6a1ece0e2">[email&nbsp;protected]</a> (Please keep the Backend &amp; DevOps topic focus in mind)</p>
<hr>
<p>With much love,<br>Simon Frey</p>
</div></div>]]>
            </description>
            <link>https://simon.red/7</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400348</guid>
            <pubDate>Sat, 12 Dec 2020 18:33:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zero to Production in Rust, Part Six: Using Types to Guarantee Domain Invariants]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25400332">thread link</a>) | @praveenperera
<br/>
December 12, 2020 | https://www.lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/ | <a href="https://web.archive.org/web/*/https://www.lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <article>
    
      
      
<ul id="frontmatter">
    <li>
        <time datetime="2020-12-11T15:00:10.47Z">December 11, 2020</time>
    </li>
    <span></span>
    <li> 6507 words </li>
    <span></span>
    <li> 33 min </li>
</ul>

      <p><em><a href="https://zero2prod.com/"><strong>Zero To Production In Rust</strong></a> is an opinionated introduction to backend development in Rust.<br>
You can pre-order the book on <a href="https://zero2prod.com/">zero2prod.com</a>.<br>
<a href="https://www.lpalmieri.com/subscribe">Subscribe to the newsletter</a> to be notified when a new episode is published.</em></p>

<ol>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#1-requirements">Requirements</a>
<ul>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#11-domain-constraints">1.1. Domain Constraints</a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#12-security-constraints">1.2. Security Constraints</a></li>
</ul>
</li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#2-first-implementation">First Implementation</a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#3-validation-is-a-leaky-cauldron">Validation Is A Leaky Cauldron</a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#4-type-driven-development">Type-Driven Development</a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#5-ownership-meets-invariants">Ownership Meets Invariants</a>
<ul>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#51-asref">5.1. <code>AsRef</code></a></li>
</ul>
</li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#6-panics">Panics</a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#7-error-as-values---result">Error As Values - <code>Result</code></a>
<ul>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#71-converting-parse-to-return-result">7.1. Converting <code>parse</code> To Return <code>Result</code></a></li>
</ul>
</li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#8-insightful-assertion-errors-claim">Insightful Assertion Errors: <code>claim</code></a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#9-unit-tests">Unit Tests</a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#10-handling-a-result">Handling A <code>Result</code></a>
<ul>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#101-map_err">10.1. <code>map_err</code></a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#102-the--operator">10.2. The <code>?</code> Operator</a></li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#103-400-bad-request">10.3. 400 Bad Request</a></li>
</ul>
</li>
<li><a href="https://lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/#11-summary">Summary</a></li>
</ol>
<p>Our newsletter API is live, hosted on a Cloud provider.<br>
We have a basic set of instrumentation to troubleshoot issues that might arise.<br>
There is an exposed endpoint (<code>POST /subscriptions</code>) to subscribe to our content.</p>
<p>We have come a long way!</p>
<p>But we have cut a few corners along the way: <code>POST /subscriptions</code> is fairly... permissive.<br>
Our input validation is extremely limited: we just ensure that both the name and the email fields are provided, nothing else.</p>
<p>We can add a new integration test to probe our API with some "troublesome" inputs:</p>
<pre><code><span>//! tests/health_check.rs
// [...]

</span><span>#[</span><span>actix_rt</span><span>::</span><span>test</span><span>]
async </span><span>fn </span><span>subscribe_returns_a_200_when_fields_are_present_but_empty</span><span>() {
    </span><span>// Arrange
    </span><span>let</span><span> app = </span><span>spawn_app</span><span>().await;
    </span><span>let</span><span> client = reqwest::Client::new();
    </span><span>let</span><span> test_cases = vec![
        ("</span><span>name=&amp;email=ursula_le_guin%40gmail.com</span><span>", "</span><span>empty name</span><span>"),
        ("</span><span>name=Ursula&amp;email=</span><span>", "</span><span>empty email</span><span>"),
        ("</span><span>name=Ursula&amp;email=definitely-not-an-email</span><span>", "</span><span>invalid email</span><span>"),
    ];

    </span><span>for </span><span>(body, description) in test_cases {
        </span><span>// Act
        </span><span>let</span><span> response = client
            .</span><span>post</span><span>(&amp;format!("</span><span>{}</span><span>/subscriptions</span><span>", &amp;app.address))
            .</span><span>header</span><span>("</span><span>Content-Type</span><span>", "</span><span>application/x-www-form-urlencoded</span><span>")
            .</span><span>body</span><span>(body)
            .</span><span>send</span><span>()
            .await
            .</span><span>expect</span><span>("</span><span>Failed to execute request.</span><span>");

        </span><span>// Assert
        </span><span>assert_eq!(
            </span><span>200</span><span>,
            response.</span><span>status</span><span>().</span><span>as_u16</span><span>(),
            "</span><span>The API did not return a 200 OK when the payload was {}.</span><span>",
            description 
        );
    }
}
</span></code></pre>
<p>The new test, unfortunately, passes.<br>
Although all those payloads are clearly invalid, our API is gladly accepting them, returning a <code>200 OK</code>.<br>
Those troublesome subscriber details end up straight in our database, ready to give us problems down the line when it is time to deliver a newsletter issue.</p>
<p>We are asking for two pieces of information when subscribing to our newsletter: a name and an email.<br>
This chapter will focus on name validation: what should we look out for?</p>
<blockquote>
<p><em>Discuss the article on HackerNews or <a href="https://www.reddit.com/r/rust/comments/kbddrq/zero_to_production_in_rust_part_six_using_types/">r/rust</a></em>.</p>
</blockquote>

<h2 id="1-1-domain-constraints">1.1. Domain Constraints</h2>
<p>It turns out that names are complicated<sup><a href="#patio-names">1</a></sup>.<br>
Trying to nail down what makes a name <em>valid</em> is a fool's errand. Remember that we chose to collect a name to use it in the opening line of our emails - we do not need it to match the real identity of a person, whatever that means in their geography. It would be totally unnecessary to inflict the pain of incorrect or overly prescriptive validation on our users.</p>
<p>We could thus settle on simply requiring the name field to be non-empty (as in, it must contain at least a non-whitespace character).</p>
<h2 id="1-2-security-constraints">1.2. Security Constraints</h2>
<p>Unfortunately, not all people on the Internet are good people.<br>
Given enough time, especially if our newsletter picks up traction and becomes successful, we are bound to capture the attention of malicious visitors.<br>
Forms and user inputs are a primary attack target - if they are not properly sanitised, they might allow an attacker to mess with our database (<a href="https://en.wikipedia.org/wiki/SQL_injection">SQL injection</a>), execute code on our servers, crash our service and other nasty stuff.<br>
Thanks, but no thanks.</p>
<p>What is likely to happen in our case? What should we brace for in the wild range of possible attacks?<sup><a href="#threat-modelling">2</a></sup><br>
We are building an email newsletter, which leads us to focus on:</p>
<ul>
<li>denial of service - e.g. trying to take our service down to prevent other people from signing up. A common threat for basically any online service;</li>
<li>data theft - e.g. steal a huge list of email addresses;</li>
<li>phishing - e.g. use our service to send what looks like a legitimate email to a victim to trick them into clicking on some links or perform other actions.</li>
</ul>
<p>Should we try to tackle all these threats in our validation logic?<br>
Absolutely not!<br>
But it is good practice to have a layered security approach<sup><a href="#defense-in-depth">3</a></sup>: by having mitigations to reduce the risk for those threats at multiple levels in our stack (e.g. input validation, parametrised queries to avoid SQL injection, escaping parametrised input in emails, etc.) we are less likely to be vulnerable should any of those checks fail us or be removed later down the line.</p>
<p>We should always keep in mind that software is a living artifact: holistic understanding of a system is the first victim of the passage of time.<br>
You have the whole system in your head when writing it down for the first time, but the next developer touching it will not - at least not from the get-go. It is therefore possible for a load-bearing check in an obscure corner of the application to disappear (e.g. HTML escaping) leaving you exposed to a class of attacks (e.g. phishing).<br>
Redundancy reduces risk.</p>
<p>Let's get to the point - what validation should we perform on names to improve our security posture given the class of threats we identified?<br>
I suggest:</p>
<ul>
<li>Enforcing a maximum length. We are using <code>TEXT</code> as type for our email in Postgres, which is virtually unbounded - well, until disk storage starts to run out. Names come in all shapes and forms, but 256 characters should be enough for the greatest majority of our users<sup><a href="#longest-name">4</a></sup> - if not, we will politely ask them to enter a nickname.</li>
<li>Reject names containing troublesome characters. <code>/()"&lt;&gt;\{}</code> are fairly common in URLs, SQL queries and HTML fragments - not as much in names<sup><a href="#xkcd">5</a></sup>. Forbidding them raises the complexity bar for SQL injection and phishing attempts.</li>
</ul>

<p>Let's have a look at our request handler, as it stands right now:</p>
<pre><code><span>//! src/routes/subscriptions.rs
</span><span>use </span><span>actix_web::{web, HttpResponse};
</span><span>use </span><span>chrono::Utc;
</span><span>use </span><span>sqlx::PgPool;
</span><span>use </span><span>uuid::Uuid;

#[</span><span>derive</span><span>(serde::Deserialize)]
</span><span>pub struct </span><span>FormData {
    </span><span>email</span><span>: String,
    </span><span>name</span><span>: String,
}

#[</span><span>tracing</span><span>::</span><span>instrument</span><span>(
    name = "</span><span>Adding a new subscriber</span><span>",
    </span><span>skip</span><span>(form, pool),
    </span><span>fields</span><span>(
        email = %form.email,
        name = %form.name
    )
)]
</span><span>pub</span><span> async </span><span>fn </span><span>subscribe</span><span>(
    </span><span>form</span><span>: web::Form&lt;FormData&gt;,
    </span><span>pool</span><span>: web::Data&lt;PgPool&gt;,
) -&gt; Result&lt;HttpResponse, HttpResponse&gt; {
    </span><span>insert_subscriber</span><span>(&amp;pool, &amp;form)
        .await
        .</span><span>map_err</span><span>(|_| HttpResponse::InternalServerError().</span><span>finish</span><span>())?;
    Ok(HttpResponse::Ok().</span><span>finish</span><span>())
}

</span><span>// [...]
</span></code></pre>
<p>Where should our new validation live?</p>
<p>A first sketch could look somewhat like this:</p>
<pre><code><span>//! src/routes/subscriptions.rs
 
// An extension trait to provide the `graphemes` method 
// on`String` and `&amp;str`
</span><span>use </span><span>unicode_segmentation::UnicodeSegmentation;
</span><span>// [...]

</span><span>pub</span><span> async </span><span>fn </span><span>subscribe</span><span>(
    </span><span>form</span><span>: web::Form&lt;FormData&gt;,
    </span><span>pool</span><span>: web::Data&lt;PgPool&gt;,
) -&gt; Result&lt;HttpResponse, HttpResponse&gt; {
    </span><span>if </span><span>!</span><span>is_valid_name</span><span>(&amp;form.name) {
        </span><span>return </span><span>Err(HttpResponse::BadRequestError().</span><span>finish</span><span>());
    }
    </span><span>insert_subscriber</span><span>(&amp;pool, &amp;form)
        .await
        .</span><span>map_err</span><span>(|_| HttpResponse::InternalServerError().</span><span>finish</span><span>())?;
    Ok(HttpResponse::Ok().</span><span>finish</span><span>())
}

</span><span>/// Returns `true` if the input satisfies all our validation constraints 
/// on subscriber names, `false` otherwise.
</span><span>pub fn </span><span>is_valid_name</span><span>(</span><span>s</span><span>: &amp;</span><span>str</span><span>) -&gt; </span><span>bool </span><span>{
    </span><span>// `.trim()` returns a view over the input `s` without trailing 
    // whitespace-like characters.
    // `.is_empty` checks if the view contains any character.
    </span><span>let</span><span> is_empty_or_whitespace = s.</span><span>trim</span><span>().</span><span>is_empty</span><span>();

    </span><span>// A grapheme is defined by the Unicode standard as a "user-perceived" 
    // character: `å` is a single grapheme, but it is composed of two characters 
    // (`a` and `̊`).
    //
    // `graphemes` returns an iterator over the graphemes in the input `s`.
    // `true` specifies that we want to use the extended grapheme definition set,
    // the recommended one.
    </span><span>let</span><span> is_too_long = s.</span><span>graphemes</span><span>(</span><span>true</span><span>).</span><span>count</span><span>() &gt; </span><span>256</span><span>;

    </span><span>// Iterate over all characters in the input `s` to check if any of them matches 
    // one of the characters in the forbidden array.
    </span><span>let</span><span> forbidden_characters = ['</span><span>/</span><span>', '</span><span>(</span><span>', '</span><span>)</span><span>', '</span><span>"</span><span>', '</span><span>&lt;</span><span>', '</span><span>&gt;</span><span>', '</span><span>\\</span><span>', '</span><span>{</span><span>', '</span><span>}</span><span>'];
    </span><span>let</span><span> contains_forbidden_characters = s
        .</span><span>chars</span><span>()
        .</span><span>filter</span><span>(|</span><span>g</span><span>| forbidden_characters.</span><span>contains</span><span>(g))
        .</span><span>count</span><span>()
        &gt; </span><span>0</span><span>;

    </span><span>// Return `false` if any of our conditions has been violated 
    </span><span>!(is_empty_or_whitespace || is_too_long || contains_forbidden_characters)
}
</span></code></pre>
<p>To compile the new function successfully we will have to add the <code>unicode-segmentation</code> crate to our dependencies:</p>
<pre><code><span>cargo</span><span> add unicode-segmentation
</span></code></pre>
<p>While it <em>looks like</em> a perfectly fine solution (assuming we add a bunch of tests), functions like <code>is_valid_name</code> give us a false sense of safety.</p>

<p>Let's shift our attention to <code>insert_subscriber</code>.<br>
Let's imagine, for a second, that it requires <code>form.name</code> to be non-empty otherwise something horrible is going to happen (e.g. a panic!).</p>
<p>Can <code>insert_subscriber</code> safely assume that <code>form.name</code> will be non-empty?<br>
Just by looking at its <em>type</em>, it cannot: <code>form.name</code> is a <code>String</code>. There is no guarantee about its content.<br>
If you were to look at our program in its entirety you might say: we are checking that it is non-empty at the edge, in the request handler, therefore we can safely assume that <code>form.name</code> will be non-empty every time <code>insert_subscriber</code> is invoked.</p>
<p>But we had to shift from a <em>local</em> approach (let's look at this function's parameters) to a <em>global</em> approach (let's scan the whole codebase) to make such a claim.<br>
And while it might be feasible for a small project such as ours, examining all the calling sites of a function (<code>insert_subscriber</code>) to ensure that a certain validation step has been performed beforehand quickly becomes unfeasible on larger projects.</p>
<p>If we are to stick with <code>is_valid_name</code>, the only …</p></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/">https://www.lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/</a></em></p>]]>
            </description>
            <link>https://www.lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400332</guid>
            <pubDate>Sat, 12 Dec 2020 18:30:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracking Hacker News sentiment towards Big Tech companies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25400274">thread link</a>) | @greatwave1
<br/>
December 12, 2020 | https://www.quiverquant.com/sources/hackernews | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/sources/hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><a href="https://www.quiverquant.com/">
						<img src="https://www.quiverquant.com/static/img/logo.png" alt="">
					</a></p><p>Quiver scrapes alternative stock data from across the internet and aggregates it in a free, easy-to-use web dashboard.</p>
					<div>
						<p><span>Copyright © 2020 Quiver Quantitative, Inc. All rights reserved.</span></p><ul>
							<li><a href="https://www.quiverquant.com/privacypolicy">Privacy Policy</a></li>
							<li><a href="https://www.quiverquant.com/termsofservice">Terms of Service</a></li>
						</ul>
					</div>
				</div></div>]]>
            </description>
            <link>https://www.quiverquant.com/sources/hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400274</guid>
            <pubDate>Sat, 12 Dec 2020 18:23:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Red Hat Goes Full IBM and Says Farewell to CentOS]]>
            </title>
            <description>
<![CDATA[
Score 212 | Comments 292 (<a href="https://news.ycombinator.com/item?id=25400249">thread link</a>) | @vanburen
<br/>
December 12, 2020 | https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-scaled.jpg" data-caption="Red Hat Distro Family Progression 2020-2025"><img width="696" height="391" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-696x391.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-696x391.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-400x224.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-800x449.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-1536x862.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-2048x1149.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-1068x599.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-749x420.jpg 749w" sizes="(max-width: 696px) 100vw, 696px" alt="Red Hat Distro Family Progression 2020-2025" title="Red Hat Distro Family Progression 2020-2025"></a><figcaption>Red Hat Distro Family Progression 2020-2025</figcaption></figure></div>
            <!-- content --><p>This week, Red Hat caught a lot of the Linux community off-guard by what was a shocking announcement for many: CentOS 8 as we know it, will see a reduced lifecycle, ending in December 2021. Further, while the project will still support CentOS 7, CentOS, as the community has known it, is effectively a dead project at this point. This is fairly consistent with how <a href="https://www.servethehome.com/ibm-gobbles-up-red-hat/">IBM</a> is known to do some acquisitions, but it is still shocking.<span id="more-49249"></span></p>
<h2>The Video Version</h2>
<p>Since we have been doing more content with video lately, we are also including a version of this as a video for you to listen to.</p>
<p><iframe title="Red Hat Says Sayonara to CentOS" width="696" height="392" src="https://www.youtube.com/embed/qqc3k5Ym1tA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Of course, we know most of the folks on here prefer to read, but this video is a fairly close representation of what is in the article. Feel free to open it on YouTube and check it out there.</p>
<h2>CentOS Project Key History</h2>
<p>While some will like to go back to the founding of CentOS, we instead wanted to focus on what CentOS had effectively become over the last 5-10 years: a Red Hat Enterprise Linux (RHEL) alternative without the support contract.</p>
<figure id="attachment_49262" aria-describedby="caption-attachment-49262"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-2020/" rel="attachment wp-att-49262"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-scaled.jpg" alt="Red Hat 2020" width="2560" height="1439" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-scaled.jpg 2560w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-800x450.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-1536x864.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-2048x1151.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-696x391.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-1068x600.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-747x420.jpg 747w" sizes="(max-width: 2560px) 100vw, 2560px"></a><figcaption id="caption-attachment-49262">Red Hat Distro Family Progression 2020</figcaption></figure>
<p>Even if you run on Debian derivatives, you are aware of how mature the RHEL ecosystem is. It is a testament to Red Hat being the top open-source company in the world. CentOS releases generally lagged the RHEL releases by a few months, but effectively were clones of RHEL for those that did not have the budget for RHEL. Some can say CentOS was something different, but if we are being fair, a huge portion of the usage was effectively to access key parts of the RHEL ecosystem while not paying a subscription fee.</p>
<p>In 2014, Red Hat saw the potential and the benefits to its ecosystem and brought the CentOS team in-house. There is a team inside Red Hat developing CentOS with salaries and badges. The rationale from what I have been told is that it was better to have applications built on CentOS then brought up to RHEL as they matured rather than putting more development effort into the Ubuntu/ Debian ecosystem. That is both simplistic, but also makes a lot of sense. As part of this arrangement, Red Hat effectively got control of the CentOS governing body. That makes a lot of sense since Red Hat would be paying for developers, but it also made a few folks think about what could happen with CentOS not being independent.</p>
<figure id="attachment_49263" aria-describedby="caption-attachment-49263"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-acquisition-passage/" rel="attachment wp-att-49263"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage.jpg" alt="Red Hat Acquisition Passage" width="1714" height="1602" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage.jpg 1714w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-321x300.jpg 321w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-800x748.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-1536x1436.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-696x651.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-1068x998.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-449x420.jpg 449w" sizes="(max-width: 1714px) 100vw, 1714px"></a><figcaption id="caption-attachment-49263">Red Hat Absorbs CentOS Press Release</figcaption></figure>
<p>Taking a step back to 2014, anyone building applications saw Red Hat’s signal that it was committing resources to CentOS and frankly felt fairly good about platforming on CentOS. We almost switched back our hosting infrastructure to CentOS because of that, but there was a not-insignificant risk that we would get forced into a subscription at some point.</p>
<p>Between that acquisition, and 2020, we had a period where loosely CentOS would follow RHEL releases, supported by official Red Hat resources, by a few months. It took some time to extract bits of IP in RHEL and other changes, but for years, this was the operating model.</p>
<figure id="attachment_49269" aria-describedby="caption-attachment-49269"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-centos-eol-summary/" rel="attachment wp-att-49269"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary.jpg" alt="Red Hat CentOS EOL Summary" width="1118" height="188" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary.jpg 1118w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary-400x67.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary-800x135.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary-696x117.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary-1068x180.jpg 1068w" sizes="(max-width: 1118px) 100vw, 1118px"></a><figcaption id="caption-attachment-49269">Red Hat CentOS EOL Summary</figcaption></figure>
<p>Another key factoid is that the end of support for CentOS 6 was in November 2020. Since RHEL and CentOS are known for long support cycles, a lot of organizations decided to jump from CentOS 6 to 8 instead of re-platforming on 7 since that maximizes the time until another re-platforming effort would need to be scheduled. Or that is what many in the industry thought.</p>
<figure id="attachment_49267" aria-describedby="caption-attachment-49267"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-2022/" rel="attachment wp-att-49267"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-scaled.jpg" alt="Red Hat 2022" width="2560" height="1444" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-scaled.jpg 2560w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-400x226.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-800x451.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-1536x866.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-2048x1155.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-696x392.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-1068x602.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-745x420.jpg 745w" sizes="(max-width: 2560px) 100vw, 2560px"></a><figcaption id="caption-attachment-49267">Red Hat Distro Family Progression 2022</figcaption></figure>
<p>Then, on December 8, 2020, Red Hat announced that it was going to cut the current CentOS 8 support timeframe down considerably in the process of effectively killing the project. While 2021 may not be impacted, with CentOS 6 EOL on November 30, 2020, and CentOS 8 EOL on December 31, 2021, by January 1, 2022 CentOS 7 will be the only one receiving Maintenance Updates. The CentOS name will live on but in a different part of the ecosystem than it has to date.</p>
<h2>CentOS Stream and the New Red Hat Operating Model</h2>
<p>CentOS Stream is a project that sits between the upstream Fedora Linux and RHEL. While CentOS 8 is being shut down, and we do not expect a CentOS 9 unless there is a major change in direction at Red Hat, the CentOS name will live on for now in the CentOS Stream after CentOS 7 eventually goes EOL on June 30, 2024. By the second half of 2024, and by 2025 we expect this is what the diagram will look like.</p>
<figure id="attachment_49268" aria-describedby="caption-attachment-49268"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-2025/" rel="attachment wp-att-49268"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-scaled.jpg" alt="Red Hat 2025" width="2560" height="1449" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-scaled.jpg 2560w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-400x226.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-800x453.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-1536x870.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-2048x1159.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-696x394.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-1068x605.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-742x420.jpg 742w" sizes="(max-width: 2560px) 100vw, 2560px"></a><figcaption id="caption-attachment-49268">Red Hat Distro Family Progression 2025</figcaption></figure>
<p>For those who are current CentOS users, this means that what will be known as CentOS is being moved upstream of RHEL instead of downstream. Many of the current CentOS users like the fact that it is broadly tied to the RHEL ecosystem, and by moving it upstream it becomes a different value proposition.</p>
<figure id="attachment_49272" aria-describedby="caption-attachment-49272"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-summary/" rel="attachment wp-att-49272"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-scaled.jpg" alt="Red Hat Summary" width="2560" height="1436" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-scaled.jpg 2560w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-400x224.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-800x449.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-1536x862.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-2048x1149.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-696x391.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-1068x599.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-749x420.jpg 749w" sizes="(max-width: 2560px) 100vw, 2560px"></a><figcaption id="caption-attachment-49272">Red Hat Distro Family Progression 2020-2025</figcaption></figure>
<p>As much as I have an affinity for the CentOS brand, I do not like “CentOS Stream” being used, especially without CentOS being discontinued as a downstream distribution from RHEL. It made some sense for both to be active, but CentOS Stream may as well be called “BigBlue Hat Enterprise Linux Stream” or something like that. Fedora is not RHEL Stream for a reason. In the future Fedora, CentOS Stream, then RHEL will make sense from a branding perspective, except that CentOS is so widely used that it has a history, a history that will be chronicled for decades in Q&amp;A sites, how-tos, and other user support artifacts from the CentOS (non-stream) era.</p>
<h2>What Red Hat Needs to Do, ASAP</h2>
<p>As part of the announcement, RHEL has hinted that it would be doing something with its RHEL licensing to help the CentOS community, and there is a step it could take to turn this into an amazing gambit for Red Hat: opening a non-subscription level to RHEL beyond the current developer license.</p>
<p>“There are different kinds of CentOS users, and we are working with the CentOS Project Governing Board to tailor programs that meet the needs of these different user groups. In the first half of 2021, we plan to introduce low- or no-cost programs for a variety of use cases, including options for open source projects and communities and expansion of the Red Hat Enterprise Linux Developer subscription use cases to better serve the needs of systems administrators. We’ll share more details as these initiatives coalesce.“ (<strong>Source</strong>: <a href="https://www.redhat.com/en/blog/centos-stream-building-innovative-future-enterprise-linux">Red Hat</a>)</p>
<p>This is the sort of move that could yield huge dividends for Red Hat. If the migration path was from CentOS 8 to a carefully crafted “RHEL-freemium” distribution, which is how many viewed CentOS at a high-level anyway, then it has the ability to greatly increase Red Hat’s installed base in its main RHEL distribution. There are huge ramifications for this from an IP, licensing, and even just a business perspective, but it would be an amazing move. At the same time, it is a move that if Red Hat wanted to do, it should have been announced along with the CentOS retirement to quell the confusion. Effectively, Red Hat would be doing what iXsystems did to migrate FreeNAS to TrueNAS Core just on a much grander scale.</p>
<p>Red Hat desperately needs to have a good path forward. Perhaps none are perfect, but asking CentOS users to upgrade to CentOS Stream, pay for a RHEL license, or leave the ecosystem seems like a highly imperfect set of options.</p>
<h2>Final Words</h2>
<p>The intellectually easy answer to what is happening is that IBM is putting pressure on Red Hat to hit bigger numbers in the future. Red Hat sees a captive audience in its CentOS userbase and is looking to covert a percentage to paying customers. Everyone else can go to Ubuntu or elsewhere if they do not want to pay. That seems a bit shortsighted of an explanation we have heard offered.</p>
<figure id="attachment_30704" aria-describedby="caption-attachment-30704"><a href="https://www.servethehome.com/ibm-gobbles-up-red-hat/ibm-and-red-hat-merger/" rel="attachment wp-att-30704"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger.jpg" alt="IBM And Red Hat Merger" width="1039" height="572" srcset="https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger.jpg 1039w, https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger-400x220.jpg 400w, https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger-800x440.jpg 800w, https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger-696x383.jpg 696w, https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger-763x420.jpg 763w" sizes="(max-width: 1039px) 100vw, 1039px"></a><figcaption id="caption-attachment-30704">IBM And Red Hat Merger</figcaption></figure>
<p>The strange part of the Red Hat announcement was that it sets a precedent that is not great. Both Red Hat, and IBM its parent, are very large, sophisticated companies. There is little chance they did not foresee community outcry over an abrupt change of direction like this. Sometimes, those changes have to be made, and in the technology industry change should be the status quo. At the same time, seeing a large, established company making this kind of abrupt change, that has a major operating impact on a large user base, without a clear path forward, is a scary precedent. RHEL customers are taking notice asking if this is what they can expect from the company moving forward.</p>
<p>There are basically two paths forward here. One is that Red Hat becomes the Apple (or IBM?) of the Linux ecosystem, becoming a high-priced exclusive vendor with great technology. The second is that Red Hat unveils a roadmap that does not leave the CentOS community peering over the edge of an end-of-support cliff.</p>
<p>As always, we would love to hear STH community’s thoughts on the announcement. There is a thread in our <a href="https://forums.servethehome.com/index.php?threads/centos-8-to-be-discontinued-at-end-of-2021.31052/">forums here</a>.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400249</guid>
            <pubDate>Sat, 12 Dec 2020 18:19:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tessellation Catalog]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25400198">thread link</a>) | @xingyzt
<br/>
December 12, 2020 | https://zenorogue.github.io/tes-catalog | <a href="https://web.archive.org/web/*/https://zenorogue.github.io/tes-catalog">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://zenorogue.github.io/tes-catalog</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400198</guid>
            <pubDate>Sat, 12 Dec 2020 18:11:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub Dark Mode is too Dark]]>
            </title>
            <description>
<![CDATA[
Score 354 | Comments 184 (<a href="https://news.ycombinator.com/item?id=25400139">thread link</a>) | @karenying7
<br/>
December 12, 2020 | https://blog.karenying.com/posts/github-darkmode-sucks | <a href="https://web.archive.org/web/*/https://blog.karenying.com/posts/github-darkmode-sucks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>If you hate it too this is why. Using color theory to show why GitHub dark mode is disappointing</p><div><p><span>
      <a href="https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/6389a/github-darkmode-sucks.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/8ac56/github-darkmode-sucks.webp 240w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/d3be9/github-darkmode-sucks.webp 480w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/e46b2/github-darkmode-sucks.webp 960w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/30504/github-darkmode-sucks.webp 1325w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/09b79/github-darkmode-sucks.jpg 240w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/7cc5e/github-darkmode-sucks.jpg 480w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/6a068/github-darkmode-sucks.jpg 960w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/6389a/github-darkmode-sucks.jpg 1325w" sizes="(max-width: 960px) 100vw, 960px" type="image/jpeg">
        <img src="https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/6a068/github-darkmode-sucks.jpg" alt="toggle" title="toggle" loading="lazy">
      </picture>
  </a>
    </span></p>
<p>This past week, GitHub <a href="https://twitter.com/github/status/1336362679506784256" target="_blank">released</a> a long-awaited feature — dark mode. Like many devs around the world, I was hype. In 2020, a dark mode toggle for anything remotely related to tech seems like a requirement.</p>
<p>So I flipped the switch. My immediate reaction was that it seemed a bit off. But I wanted to give it a chance and credited that feeling towards just not being used to the theme yet.</p>
<p>Flash forward a couple of days, I found myself switching to light mode for code review specifically. I didn’t feel confident code reviewing in dark mode. I was scared I would miss something. It was after a couple of instances of this did I realize, GitHub dark mode is <em>too</em> dark. And here’s why.</p>
<h2 id="the-proof-is-in-the-palette-pudding"><a href="#the-proof-is-in-the-palette-pudding" aria-label="the proof is in the palette pudding permalink"></a>The Proof is in the Palette (Pudding)</h2>
<h3 id="accessibility-and-contrast-ratio"><a href="#accessibility-and-contrast-ratio" aria-label="accessibility and contrast ratio permalink"></a>Accessibility and Contrast Ratio</h3>
<p>I explain contrast ratio in depth <a href="https://blog.karenying.com/posts/boost-visual-accessibility-by-auto-flipping-text-color#wcag-and-contrast-ratio" target="_blank">here</a> but this is what you need to know:</p>
<ul>
<li>The contrast ratio between two colors mathematically calculates how different our eyes perceive them to be</li>
<li>It ranges between <strong>1</strong> (two of the same colors) to <strong>21</strong> (black and white)</li>
<li>The smaller the text is, the larger the contrast ratio between the text color and the background color needs to be</li>
<li>The <a href="https://www.w3.org/WAI/standards-guidelines/wcag/" target="_blank">Web Content Accessibility Guidelines</a> (WCAG) defines a level <strong>AA</strong> contrast ratio as above <strong>4.5</strong> and level <strong>AAA</strong> as above <strong>7</strong> for small text</li>
<li><strong>AAA</strong> is considered the gold standard level for web accessibility</li>
</ul>
<h3 id="other-dark-mode-site-palettes"><a href="#other-dark-mode-site-palettes" aria-label="other dark mode site palettes permalink"></a>Other Dark Mode Site Palettes</h3>
<p><em>I did a deep dive into the dark mode palettes of Spotify, Twitter, Facebook and more in this <a href="https://blog.karenying.com/posts/50-shades-of-dark-mode-gray" target="_blank">post</a>.</em></p>
<p>I grabbed the dark mode colors of a couple of popular sites/apps. Every palette image shows the background color, primary text color, and secondary text color from left to right. <strong>I put the contrast ratios of the primary and secondary colors with the background color on top of the respective color.</strong></p>
<p><strong>Spotify</strong>:
<span>
      <a href="https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/cd7c1/spotify.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/8ac56/spotify.webp 240w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/d3be9/spotify.webp 480w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/e46b2/spotify.webp 960w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/f992d/spotify.webp 1440w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/0dd1a/spotify.webp 1547w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/8ff5a/spotify.png 240w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/e85cb/spotify.png 480w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/d9199/spotify.png 960w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/07a9c/spotify.png 1440w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/cd7c1/spotify.png 1547w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/d9199/spotify.png" alt="spotify" title="spotify" loading="lazy">
      </picture>
  </a>
    </span></p>
<p><strong>Facebook</strong>:
<span>
      <a href="https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/dca52/facebook.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/8ac56/facebook.webp 240w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/d3be9/facebook.webp 480w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/e46b2/facebook.webp 960w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/f992d/facebook.webp 1440w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/eb054/facebook.webp 1550w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/8ff5a/facebook.png 240w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/e85cb/facebook.png 480w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/d9199/facebook.png 960w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/07a9c/facebook.png 1440w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/dca52/facebook.png 1550w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/d9199/facebook.png" alt="facebook" title="facebook" loading="lazy">
      </picture>
  </a>
    </span></p>
<p><strong>YouTube</strong>:
<span>
      <a href="https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/acd79/youtube.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/8ac56/youtube.webp 240w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/d3be9/youtube.webp 480w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/e46b2/youtube.webp 960w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/f992d/youtube.webp 1440w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/bb338/youtube.webp 1543w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/8ff5a/youtube.png 240w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/e85cb/youtube.png 480w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/d9199/youtube.png 960w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/07a9c/youtube.png 1440w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/acd79/youtube.png 1543w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/d9199/youtube.png" alt="youtube" title="youtube" loading="lazy">
      </picture>
  </a>
    </span></p>
<p>All of these satisfy the AAA standard of a contrast ratio of at least 7 👍🏼</p>
<p>And then we have GitHub’s new look…</p>
<p><strong>GitHub</strong>:
<span>
      <a href="https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/d3deb/github.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/8ac56/github.webp 240w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/d3be9/github.webp 480w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/e46b2/github.webp 960w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/f992d/github.webp 1440w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/383eb/github.webp 1758w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/8ff5a/github.png 240w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/e85cb/github.png 480w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/d9199/github.png 960w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/07a9c/github.png 1440w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/d3deb/github.png 1758w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/d9199/github.png" alt="github" title="github" loading="lazy">
      </picture>
  </a>
    </span></p>
<p>Not only do the colors look noticeably darker than their counterparts in other apps, <strong>the secondary text color fails AAA standards</strong>! It’s important for the secondary text color to have high contrast because of how small the font is. I knew my eyes didn’t deceive me.</p>
<p><strong>While contrast ratios aren’t <a href="https://www.bounteous.com/insights/2019/03/22/orange-you-accessible-mini-case-study-color-ratio/" target="_blank">everything</a>, they are a simple way to quantify the difference between two colors.</strong> In this case, it’s clear that GitHub’s dark mode colors <em>are</em> darker. This can make it harder to read text.</p>
<h3 id="code-review-palette"><a href="#code-review-palette" aria-label="code review palette permalink"></a>Code Review Palette</h3>
<p>Finally, my main gripe with GitHub dark mode is that the red / green for code diffs looks super off to me.</p>
<p>On the right is the light mode colors and left is the new shades. I overlaid the respective background colors on top:</p>
<p><span>
      <a href="https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/c95f0/diff.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/8ac56/diff.webp 240w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/d3be9/diff.webp 480w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/e46b2/diff.webp 960w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/f992d/diff.webp 1440w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/2ac07/diff.webp 1842w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/8ff5a/diff.png 240w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/e85cb/diff.png 480w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/d9199/diff.png 960w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/07a9c/diff.png 1440w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/c95f0/diff.png 1842w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/d9199/diff.png" alt="diff colors" title="diff colors" loading="lazy">
      </picture>
  </a>
    </span></p>
<p>I did calculate the contrast ratios of both palettes and they were pretty similar (close to 1 lol). However, for some reason the lighter one is easier for me to parse at a cursory glance. Maybe I’m not used to it yet, but I really dislike how dark the new diff colors are. For something as important as code review, I’m using GitHub light mode.</p>
<p>I also investigated <strong>VSCode’s Git integration</strong> diff colors (which I enjoy!):</p>
<p><span><span>
      <a href="https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/dc61a/vscode-diff.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/8ac56/vscode-diff.webp 240w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/d3be9/vscode-diff.webp 480w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/e46b2/vscode-diff.webp 960w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/f8f9f/vscode-diff.webp 1147w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/8ff5a/vscode-diff.png 240w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/e85cb/vscode-diff.png 480w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/d9199/vscode-diff.png 960w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/dc61a/vscode-diff.png 1147w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/d9199/vscode-diff.png" alt="vscode diff colors" title="vscode diff colors" loading="lazy">
      </picture>
  </a>
    </span></span></p>
<p>IMO these shades work well even on a darker background and don’t hinder code review.</p>
<h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h2>
<p>While there is no color theory justification that GitHub’s new code diff palette is worse, its text colors are not as WCAG accessible as other dark mode apps we use daily.</p>
<p>Maybe if GitHub put as much effort into researching their dark mode palette as they did into the <a href="https://twitter.com/github/status/1336362679506784256" target="_blank">promo video</a> they released, we wouldn’t be here. This is still a beta feature so I have hope. <strong>GitHub, please give us the dark mode experience we deserve 🥺</strong></p>
<p><em>Thanks for reading. Happy hacking!</em></p></div></div>]]>
            </description>
            <link>https://blog.karenying.com/posts/github-darkmode-sucks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400139</guid>
            <pubDate>Sat, 12 Dec 2020 18:03:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I've designed Python fantasy cards to learn it easier]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25400117">thread link</a>) | @tomaszs
<br/>
December 12, 2020 | https://summonthejson.com/products/summon-the-json-python-deck | <a href="https://web.archive.org/web/*/https://summonthejson.com/products/summon-the-json-python-deck">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p data-mce-style="text-align: left;">If you are learning to code, it is often hard to discover and memorize all programming functions. STJ&nbsp;Python flashcards make it super easy. It combines state of art memory techniques to help you remember functions fast.</p>
<p data-mce-style="text-align: left;"><strong>The science behind STJ:&nbsp;Python</strong></p>
<div data-mce-style="text-align: left;"><p>According to research, images help stick the information in the long term memory, transmit messages faster, improve comprehension, trigger emotions, motivate learners. In fact, 90% of information transmitted to the brain is visual (<a href="https://www.shiftelearning.com/blog/bid/350326/studies-confirm-the-power-of-visuals-in-elearning">source</a>). That is why STJ: Python intriguing and beautiful illustrations can help you memorize faster. Side-by-side with the fantasy setting and funny descriptions STJ:&nbsp;Python cards are a great combo to help boost your memory! They are eye-catching but also cause emotions - the cornerstone of fast memorization (<a href="https://www.memory-key.com/memory/emotion">source</a>).</p><p>Dive into a fantasy world of Summon The JSON, where excellent visual design, creatures, and fun descriptions will help you remember&nbsp;Python function automagically.</p></div>
<p data-mce-style="text-align: left;"><img alt="" src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117083121_1024x1024.jpg?v=1606044111"></p>
<p data-mce-style="text-align: left;">STJ:&nbsp;Python is an excellent choice if you:</p>
<p data-mce-style="text-align: left;"><strong>Want to become a programmer</strong></p>
<div data-mce-style="text-align: left;"><p>Flashcards contain the most useful set of&nbsp;Python functions programmers use most of the time. STJ:&nbsp;Python will give you a great overview of what tools every programmer has at hand. With that knowledge, it will be easier for you to start thinking about how to create your application from these building blocks.</p><p><strong>Go to a coding job interview</strong></p></div>
<p data-mce-style="text-align: left;">A lot of companies use knowledge tests and whiteboard tasks to assess coding job candidate knowledge. STJ:&nbsp;Python helps you remember functions easier. Regular flashcards are boring and make it hard to stick programming functions to anything meaningful.&nbsp; Contrary STJ:&nbsp;Python helps your brain store information about&nbsp;Python functions in an efficient way.&nbsp; It increases the chance, that during a job interview your brain will be able to give you all information you need.<br></p>
<p data-mce-style="text-align: left;"><img alt="" src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117083241_8b6c81c4-e7f9-4e0a-b7aa-b22ca2d539a8_1024x1024.jpg?v=1606044472"></p>
<p data-mce-style="text-align: left;"><strong>Switch from another language to&nbsp;Python</strong></p>
<p data-mce-style="text-align: left;">If you are already a software developer, you know how confusing it is to switch to learn another language. Some functions are similar. Some are not. It gets even worse when you code in 2 or 3 languages at the same time. There is a lot of things to remember in every language. You need to find equivalents. STJ:&nbsp;Python will help you progress faster in learning Python. It shows you the toolset of the language and helps you remember it faster. Also, if you come back to Python, you can also take a look at cards, to recalibrate your brain easier.</p>
<p data-mce-style="text-align: left;"><img alt="" src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117082424_1024x1024.jpg?v=1606044528"></p>
<p data-mce-style="text-align: left;"><strong>Write faster without searching online</strong><br></p>
<p data-mce-style="text-align: left;">It is great, we have a lot of easily accessible sources on the Internet, we can find all information within seconds or minutes. But the Internet will never beat the human brain speed. If you remember function names, you will code faster. Moreover, your coding experience will become more fulfilling. You won't worry about connection lags, that the search engine does not give the answer you are looking for. You won't be distracted by websites and online ads. Focus is one of the most important assets of a programmer. STJ:&nbsp;Python will help you be more focused in the zone!</p>
<p data-mce-style="text-align: left;"><img src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117082538_1024x1024.jpg?v=1606044208" alt=""></p>

<div data-mce-style="text-align: left;"><p>Summon The JSON:&nbsp;Python is not only a flashcard deck. It is also a game for everyone. Up to four people can play a game with STJ: Python. The deck is divided into heroes, animals, and food.&nbsp; Some cards have points, some have super-powers. You can combine them to win battles against other players.</p><p>STJ:&nbsp;Python game can be played by everyone. You don't need to have any prior programming knowledge to do so. In fact, it is a great way to spend time in a mixed group of geeks and non-geeks. You can play it with your family, friends, colleagues, or even meet new people</p></div>
<p data-mce-style="text-align: left;">STJ:&nbsp;Python game is a great ice-breaker, conversation starter, and a way to spend time with other people, chat, and bond. Have a great time together.</p>
<p data-mce-style="text-align: left;"><img src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117082016_1024x1024.jpg?v=1606044238" alt=""></p>
<h2 data-mce-style="text-align: left;">What is inside?</h2>
<p data-mce-style="text-align: left;">One deck contains:</p>
<ul>
<li data-mce-style="text-align: left;">A complete deck of 65-cards with several custom cards (make your own cards)</li>
<li data-mce-style="text-align: left;">8-page long booklet instruction with 2 memorization modes and game instruction</li>
</ul>
<p data-mce-style="text-align: left;">Cards are premium quality with linen texture and durable UV coating. The learning game takes approx 3 minutes. Each game takes about 15 minutes and can be repeated indefinitely.&nbsp;</p>
<p data-mce-style="text-align: left;"><img src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117082811_1024x1024.jpg?v=1606044272" alt=""></p>
</div></div>]]>
            </description>
            <link>https://summonthejson.com/products/summon-the-json-python-deck</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400117</guid>
            <pubDate>Sat, 12 Dec 2020 18:00:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Foster your network to increase your career options]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25400099">thread link</a>) | @mooreds
<br/>
December 12, 2020 | https://letterstoanewdeveloper.com/2020/12/07/your-network-increases-optionality/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/12/07/your-network-increases-optionality/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><em>This is a guest post from Karl Hughes. Enjoy.</em></p>



<p>Dear new developer,</p>



<p>I was in your shoes in 2011. I was finishing up a degree in mechanical engineering that I would never use and looking for a way to join a startup as a software developer.</p>



<p>Maybe it was the entrepreneur in me, and maybe it was just naivety, but instead of applying for jobs, I decided to start emailing interesting companies instead. I made a list of technology startups in the education industry and emailed each of them my pitch.</p>



<p>Two of them got back to me and one (<a href="https://www.uloop.com/">Uloop</a>) had an office three hours away in Nashville. I drove to meet their CEO and after a few conversations, they brought me on as a freelancer. When I graduated a few months later, they offered me a full-time role managing their blog and writing custom WordPress plugins.</p>



<p>Since then, I’ve worked at three different edtech startups and never once had a formal “job interview.” Every company I’ve worked for has hired me because I met someone there and stayed in touch for months. When a job opened up, they reached out to me to see if I was interested.</p>



<p>My first job hunt showed me that your strength as a software developer is not in your resume, your knowledge of algorithms, your ability to keep up with the hottest frameworks, or even your problem-solving skills. <strong>The most powerful tool you have is your network.</strong></p>



<h2>The Employer’s Perspective</h2>



<p>As a job-seeker, you know that looking for a job is scary, but from an employer’s perspective, hiring is scary too.</p>



<p>After sitting in the hiring manager’s seat several times in the past few years, I can tell you that I’m as scared of hiring the wrong person as you are of screwing up the job interview. If I make a bad hire, I look bad to my boss, and my team’s productivity will suffer. Having to fire someone kills morale and hurts the manager’s reputation, so nobody wants to do it.</p>



<p>This fear is why managers look for people in their networks or work with recruiters. <strong>The very last place employers look for applicants is the cold resume bin.</strong></p>



<h2>How I Built My Network</h2>



<p>If you want to avoid the black hole of submitting your resume online, you need to build a network. I don’t know you well enough to give you a perfect formula for your situation, so I’ll just tell you how I built my network. I hope some of these ideas resonate.</p>



<p>First, I started as a freelancer before I ever had a “real” job as a programmer. Most people don’t recommend this approach for new developers, but it forced me to learn to “sell” myself really well. When I started with Uloop, I often had no idea how to accomplish a task, but I bet that I could learn it before they discovered I was making it up.</p>



<p>After getting that first job, I started attending meetups and conferences regularly. Uloop was a small company, so there wasn’t much opportunity to network within the organization, but I had moved to Chicago, where there were plenty of programming meetups and tech events to attend.</p>



<p>I tried meeting people at these events, but it was hard. I’m not that outgoing, so instead, I would email the event’s speaker or organizer afterward and invite them to a one-on-one coffee or lunch. Some of the people I met like this are among my closest mentors and friends today.</p>



<p>As I attended more meetups and got to know speakers and leaders, people started inviting me to give back. I was little more than a junior developer at the time, but I was asked to speak at bootcamps, meetups, and even a couple of small conferences because of my network.</p>



<p>Naturally, I was nervous the first few times I got up in front of a group to share my experience. I knew there were people in the crowd with decades of experience on me, and I expected them to stand up and call me out if I made any mistakes. I found that practice and gradually increasing the stakes helped me. By trying a talk out at a local meetup and slowly working up to larger audiences at a conference, I gained confidence over time.</p>



<p>Giving a talk at a meetup or conference is a lot of work, and you don’t typically get paid for it. That said, I knew how helpful it was hearing developers who were more experienced than me back when I was first learning to code, so I have always enjoyed the opportunity to give back.</p>



<p>One side effect of speaking is that you get even more opportunities to increase your network. At some point, I switched from being the one asking speakers to meet with me to the one that attendees were asking to speak with. I always enjoy these interactions with new developers, and the opportunity to encourage or help others is my primary motivation for speaking and writing this letter.</p>



<h2>Keeping in Touch</h2>



<p>Everyone who talks about networking tells you to go out and meet more people, but that’s <a href="https://www.karllhughes.com/posts/the-key-to-networking-keeping-in-touch">worthless if you don’t keep in touch with anyone</a>. As I started to meet more people in Chicago, I realized that I needed to come up with a way to have more encounters with each of them.</p>



<blockquote><p>“It takes on average about 3 encounters — and by that I mean intentional rather than passing interactions where you’ve gotten together primarily to just hang out — to really see if there’s potential for a relationship with someone.” – <a href="https://www.artofmanliness.com/articles/the-3-encounter-rule/">Brett McKay</a></p></blockquote>



<p>The first step was to start a spreadsheet of people I wanted to keep up with. Most of them were more experienced than me, but many were peers or newer developers I “clicked” with or found interesting.</p>



<p>Next, I made a reminder to reach out to 1-2 people on the list every week. I’d ask how they were doing and see if they wanted to get lunch or coffee sometime. I tried to find organic reasons to connect (birthdays, an article related to their industry, etc.) and ask them questions about their lives. One of the easiest ways to make someone like you is to get them talking about something they like. <a href="https://www.psychologytoday.com/us/blog/positive-prescription/201703/why-we-love-talking-about-ourselves">People love talking about themselves</a>.</p>



<p>While this sounds calculated, I do genuinely enjoy these conversations. We’re all busy, but having a system like this ensures that I don’t forget to maintain my network. If I ever feel like I’m no longer getting along with someone, I remove them from my list and no harm is done.</p>



<p>The reason most people don’t do this is that it takes a lot of time. I still spend 4-6 hours per week keeping in touch with or expanding my network. It may seem like a lot, but the investment has paid dividends and afforded me many interesting conversations and relationships along the way. This strategy of intentionally staying in touch with people has led to friendships, co-workers, job offers, and clients.</p>



<h2>Make It Yours</h2>



<p>No career advice will work for everyone.</p>



<p>I didn’t write this letter to give you a formula for networking, but rather to let you know that unconventional approaches can work. My network has been an invaluable asset, but luck and privilege played a huge part too.</p>



<p>If I hadn’t been able to drive three hours to take a meeting with my future boss, would he have hired me? If I needed to be home after work to help care for a family member, would I have been able to network at Meetups? If I weren’t a white male in an industry dominated by white males, would people have taken the time to meet with me?</p>



<p>I don’t know.</p>



<p>I have no idea what your career path will look like, but I hope my story gives you the courage to build a path that works for you.</p>



<p>Signed,<br><a href="https://twitter.com/KarlLHughes">Karl</a></p>



<p><em>Karl is a former CTO and freelance writer. He’s currently the founder of <a href="https://draft.dev/">Draft.dev</a> where he helps companies create content that reaches software developers.</em></p>
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/12/07/your-network-increases-optionality/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400099</guid>
            <pubDate>Sat, 12 Dec 2020 17:59:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to gRPC – Part 3]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25400084">thread link</a>) | @bswamina
<br/>
December 12, 2020 | https://www.polarsparc.com/xhtml/gRPC-3.html | <a href="https://web.archive.org/web/*/https://www.polarsparc.com/xhtml/gRPC-3.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <br>
    
    <br>
    
    
    <hr>
    
    <p>Overview</p>
    <div id="para-div">
      <p>Thus far in this series:</p>
      <ul id="blue-ol">
        <li>
          <p><a href="https://www.polarsparc.com/xhtml/gRPC-1.html" target="_blank"><span>Part 1</span></a> covered
            the basics of <span>gRPC</span>, installation and setup, and the demonstration of the <span>
            Unary</span> RPC</p>
        </li>
        <li>
          <p><a href="https://www.polarsparc.com/xhtml/gRPC-2.html" target="_blank"><span>Part 2</span></a> covered
            the <span>Server Streaming</span> RPC</p>
        </li>
      </ul>
      <p>In this part, we will continue the journey to the next RPC communication pattern - <span>Client Streaming</span>
        and also show how to deal with error conditions.</p>
    </div>
    <p>Client Streaming RPC</p>
    <p>The following diagram illustrates the high-level architecture of <span>Client Streaming</span> communication
        pattern:</p>
    <div id="img-outer-div"> <p><img src="https://www.polarsparc.com/xhtml/images/grpc-08.png" alt="Client Streaming Architecture"></p><p>Figure-8</p>
    </div>
    
    <p>In the Client Streaming RPC mode, the client sends a sequence (or stream) of requests to the server and the server responds
        with a response back to the client.</p>
    <p>For the Client Streaming RPC demonstration, we will implement a fictitious Best Insurance Quote service, where the client
        sends requests for their preferred 'providers' (along with their age) to the server and the server responds with the 'provider'
        offering the best quote along with the price.</p>
    <div id="para-div">
      <p>We will first demonstrate the Best Quote service using the Go programming language.</p>
      <p>In the <span>$GOPATH</span> directory, create the project directory hierarchy by executing the following
        commands:</p>
    </div>
    <div id="cmd-div">
      <p>$ cd $GOPATH/src/polarsparc.com/grpc</p>
      <p>$ mkdir -p clientstream clientstream/quotepb clientstream/server clientstream/client</p>
    </div>
    <p>The following are the contents of the file <span>best_quote.proto</span> located in the directory <span>
        $GOPATH/src/polarsparc.com/grpc/clientstream/quotepb</span> as shown below:</p>
    <fieldset id="sc-fieldset">
      <legend>best_quote.proto</legend>
      <pre>/*
    @Author: Bhaskar S
    @Blog:   https://www.polarsparc.com
    @Date:   12 Dec 2020
*/

syntax = "proto3";

package clientstream;

option go_package = "polarsparc.com/grpc/clientstream/quotepb";

option java_multiple_files = true;
option java_package = "com.polarsparc.gcs";

message BestQuoteRequest {
  string provider = 1;
  int32 age = 2;
}

message BestQuoteResponse {
  string provider = 1;
  double price = 2;
}

service BestQuoteService {
  rpc getBestQuote(stream BestQuoteRequest) returns (BestQuoteResponse);
}</pre>
    </fieldset>
    <p>The request message is defined as <span>BestQuoteRequest</span> and the response message is defined as
        <span>BestQuoteResponse</span>. The service interface is defined as <span>BestQuoteService</span>
        with an RPC method <span>getBestQuote</span> that takes in a sequence (or <span>stream</span>)
        of <span>BestQuoteRequest</span> objects and returns a <span>BestQuoteResponse</span> object.</p>
    <p>To compile the <span>best_quote.proto</span> file, execute the following commands:</p>
    <div id="cmd-div">
      <p>$ cd $GOPATH/src/polarsparc.com/grpc/clientstream</p>
      <p>$ protoc quotepb/best_quote.proto --go_out=plugins=grpc:$GOPATH/src</p>
    </div>
    <p>On success, this will generate the Go code file called <span>best_quote.pb.go</span> located in the directory
        <span>$GOPATH/src/polarsparc.com/grpc/clientstream/quotepb</span>.</p>
    <p>From the file <span>best_quote.pb.go</span>, we see the <span>BestQuoteServiceServer</span> interface,
        as shown below, that the server needs to implements:</p>
    <fieldset id="sc-fieldset">
      <legend>best_quote.pb.go</legend>
      <pre>.
.
.
type BestQuoteServiceServer interface {
	GetBestQuote(BestQuoteService_GetBestQuoteServer) error
}
.
.
.</pre>
    </fieldset>
    <p>The following are the contents of the file <span>quote_provider.go</span> that simulates an in-memory
        store for initializing and returning quotes from fictitious providers and is located in the directory <span>
        $GOPATH/src/polarsparc.com/grpc/clienttream/server</span> as shown below:</p>
    <fieldset id="sc-fieldset">
      <legend>quote_provider.go</legend>
      <pre>/*
  @Author: Bhaskar S
  @Blog:   https://www.polarsparc.com
  @Date:   12 Dec 2020
*/

package main

import (
  "errors"
  "fmt"
  "log"
)

type ProviderQuote struct {
  Provider string
  AgeLow int32
  AgeHigh int32
  Price float64
}

func (pq ProviderQuote) inRange(age int32) bool {
  if age &gt;= pq.AgeLow &amp;&amp; age &lt;= pq.AgeHigh {
    return true
  }
  return false
}

type QuotesCache map[string][]ProviderQuote

type server struct {
  cache QuotesCache
}

func (s *server) Init() {
  l1 := []ProviderQuote{{Provider: "Alice", AgeLow: 20, AgeHigh: 30, Price: 1000.0},
        {Provider: "Alice", AgeLow: 31, AgeHigh: 45, Price: 1500.0},
    {Provider: "Alice", AgeLow: 46, AgeHigh: 55, Price: 2000.0},
  }
  s.cache["Alice"] = l1

  l2 := []ProviderQuote{{Provider: "Bob", AgeLow: 20, AgeHigh: 30, Price: 1100.0},
    {Provider: "Bob", AgeLow: 31, AgeHigh: 45, Price: 1475.0},
    {Provider: "Bob", AgeLow: 46, AgeHigh: 55, Price: 1950.0},
  }
  s.cache["Bob"] = l2

  l3 := []ProviderQuote{{Provider: "Charlie", AgeLow: 20, AgeHigh: 30, Price: 975.0},
    {Provider: "Charlie", AgeLow: 31, AgeHigh: 45, Price: 1525.0},
    {Provider: "Charlie", AgeLow: 46, AgeHigh: 55, Price: 2050.0},
  }
  s.cache["Charlie"] = l3
}

func (s *server) GetProviderQuote(provider string, age int32) (*ProviderQuote, error) {
  log.Printf("Request for provider: %s, age: %d", provider, age)

  var pq *ProviderQuote

  quotes := s.cache[provider]
  if quotes == nil {
    return nil, errors.New(fmt.Sprintf("Specified provider %s invalid", provider))
  }

  for _, e := range quotes {
    if e.inRange(age) {
      pq = &amp;e
      break
    }
  }

  if pq == nil {
    return nil, errors.New(fmt.Sprintf("No Quote for the specified provider %s and age %d", provider, age))
  }

  log.Printf("Provider quote for %s and age %d - %.02f\n", provider, age, pq.Price)

  return pq, nil
}</pre>
    </fieldset>
    <p>The following are the contents of the file <span>server.go</span> for the Client Streaming RPC server that
        implements the <span>BestQuoteServiceServer</span> interface and is located in the directory <span>
        $GOPATH/src/polarsparc.com/grpc/clientstream/server</span> as shown below:</p>
    <fieldset id="sc-fieldset">
      <legend>server.go</legend>
      <pre>/*
  @Author: Bhaskar S
  @Blog:   https://www.polarsparc.com
  @Date:   12 Dec 2020
*/

package main

import (
  "google.golang.org/grpc"
  "google.golang.org/grpc/codes"
  "google.golang.org/grpc/status"
  "io"
  "log"
  "net"
  "polarsparc.com/grpc/clientstream/quotepb" // [1]
)

func (s *server) GetBestQuote(stream quotepb.BestQuoteService_GetBestQuoteServer) error { // [2]
  var provider string
  var price float64

  for {
    req, err := stream.Recv() // [3]
    if err == nil {
      pq, err := s.GetProviderQuote(req.Provider, req.Age) // [4]
      if err == nil {
        if provider == "" || price &gt; pq.Price { // [5]
          provider = pq.Provider
          price = pq.Price
        }
      } else {
        log.Printf("Encountered an error on the server: %v", err)
        return status.Errorf(codes.InvalidArgument, err.Error()) // [7]
      }
    } else if err == io.EOF {
      // Received all client requests
      log.Printf("===&gt; Best quote Provider: %s, Price: %.03f\n", provider, price)

      return stream.SendAndClose("epb.BestQuoteResponse{ // [6]
        Provider: provider,
        Price: price,
      })
    } else {
      log.Printf("Encountered an error for BestQuote at localhost:20003: %v\n", err)
      return status.Errorf(codes.FailedPrecondition, err.Error()) // [7]
    }
  }
}

func main()  {
  qs := &amp;server{
    cache: QuotesCache{},
  }
  qs.Init()

  log.Println("Ready to start the BestQuote server...")

  lis, err := net.Listen("tcp", "localhost:20003")
  if err != nil {
    log.Fatalf("Failed to create listener on localhost:20003")
  }

  srv := grpc.NewServer()

  quotepb.RegisterBestQuoteServiceServer(srv, qs)

  if err = srv.Serve(lis); err != nil {
    log.Fatalf("Failed to start server: %v", err)
  }
}</pre>
    </fieldset>
    <div id="para-div">
      <p>The following are brief descriptions for some of the Go type(s)/method(s) used in the code above:</p>
      <ul id="blue-ol">
        <li>
          <p><span>[1]</span> :: import the code from the package <span>polarsparc.com/grpc/clientstream/quotepb
            </span> generated by the <span>protoc</span> compiler</p>
        </li>
        <li>
          <p><span>[2]</span> :: when the <span>gRPC</span> server invokes the RPC method <span>
            GetBestQuote</span>, it automatically passes in a reference to the <span>stream</span> object
            <span>BestQuoteService_GetBestQuoteServer</span></p>
        </li>
        <li>
          <p><span>[3]</span> :: calling the <span>Recv()</span> method on the <span>stream</span>
            object returns the next request object. If there are no more requests, the <span>stream</span> returns an error
            in the form of an <span>io.EOF</span></p>
        </li>
        <li>
          <p><span>[4]</span> :: for each request from the client, invoke the method <span>GetProviderQuote</span>
            to find the quote for the given provider and age</p>
        </li>
        <li>
          <p><span>[5]</span> :: keep track of the best quote (lowest price) all the providers for the given age</p>
        </li>
        <li>
          <p><span>[6]</span> :: when the server receives all the requests from the client and finally sees a <span>
            io.EOF</span>, send a response back to the client with the best quote with the provider and price</p>
        </li>
        <li>
          <p><span>[7]</span> :: leverage the <span>gRPC</span> built-in error model by calling the method
            <span>status.Errorf(...)</span> to handle error conditions. The status object is composed of a standard
            status code and a user-defined message description</p>
        </li>
      </ul>
    </div>
    <p>The following are the contents of the file <span>client.go</span> that implements the Client Streaming RPC
        client for the <span>BestQuoteServiceServer</span> located in the directory <span>
        $GOPATH/src/polarsparc.com/grpc/clientstream/client</span> as shown below:</p>
    <fieldset id="sc-fieldset">
      <legend>client.go</legend>
      <pre>/*
  @Author: Bhaskar S
  @Blog:   https://www.polarsparc.com
  @Date:   12 Dec 2020
*/

package main

import (
  "context"
  "google.golang.org/grpc"
  "google.golang.org/grpc/status"
  "log"
  "polarsparc.com/grpc/clientstream/quotepb"
)

func main() {
  log.Println("Ready to start the BestQuote client...")

  conn, err := grpc.Dial("localhost:20003", grpc.WithInsecure())
  if err != nil {
    log.Fatalf("Failed to connect to localhost:20003")
  }
  defer conn.Close()

  cl := quotepb.NewBestQuoteServiceClient(conn) // [1]

  // Case - 1

  stream, err := cl.GetBestQuote(context.Background()) // [2]
  if err != nil {
    log.Fatalf("[1] Failed to create client stub to localhost:20003: %v", err)
  }

  err = stream.Send("epb.BestQuoteRequest{ // [3]
    Provider: "Bob",
    Age: 37,
  })
  if err != nil {
    log.Fatalf("[1] Failed to send …</pre></fieldset></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.polarsparc.com/xhtml/gRPC-3.html">https://www.polarsparc.com/xhtml/gRPC-3.html</a></em></p>]]>
            </description>
            <link>https://www.polarsparc.com/xhtml/gRPC-3.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400084</guid>
            <pubDate>Sat, 12 Dec 2020 17:57:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manifesto for Self-Managed Software Development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25400036">thread link</a>) | @aard
<br/>
December 12, 2020 | http://adamard.com/manifesto.html | <a href="https://web.archive.org/web/*/http://adamard.com/manifesto.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>{<br>&nbsp;&nbsp;&nbsp;&nbsp;Adam Ard<br>}</h2><br>
<h2>Manifesto for Self-Managed Software Development</h2>
<p>Believing that programmers can be self-managed, we have come to value:</p>
<p>
  <strong>Flat organizations</strong> over hierarchical ones<br>
  <strong>Strong, individual code ownership</strong> over collective code ownership<br>
  <strong>Decentralized decision making</strong> over centralized control<br>
  <strong>Equity and/or profit sharing</strong> over salary<br>
  <strong>Private, individual work spaces </strong>over communal open office layouts<br>
  <strong>Choice and self-direction</strong> over standardization and central planning<br>
  <strong>A marketplace of ideas</strong> over forced consistency<br>
  <strong>Voluntary and free collaboration</strong> over assigned interactions<br>
  <strong>Persuasion and natural authority</strong> over compulsion and formal positions<br>
  <strong>Roles and responsibilities</strong> over assigned tasks<br>
  <strong>Direct customer interaction</strong> over product organizations<br>
  <strong>Transparency of corporate information (including source code)</strong> over permission based visibility<br>
  <strong>Ad hoc demos of working software</strong> over sprints and/or fixed milestones</p>
<p>We recognize that every organization must deploy some of the methods on the right, but assert that they should be constantly focused on reducing their use to an absolute minimum.</p>
    </div></div>]]>
            </description>
            <link>http://adamard.com/manifesto.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400036</guid>
            <pubDate>Sat, 12 Dec 2020 17:48:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[More Batteries Included with Emacs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399994">thread link</a>) | @fanf2
<br/>
December 12, 2020 | https://karthinks.com/software/more-batteries-included-with-emacs/ | <a href="https://web.archive.org/web/*/https://karthinks.com/software/more-batteries-included-with-emacs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>Continuing from <a href="https://karthinks.com/software/batteries-included-with-emacs/">last time</a>, here are a dozen more tricks Emacs has up its
sleeve that it’s shy about telling you. We continue to chip away at Emacs’
discoverability problem, one demo at a time.</p>
<p>Same rules as before:</p>
<ul>
<li>
<p>No packages, <strong>stock Emacs only</strong></p>
</li>
<li>
<p>No steep learning curves. <strong>Learn each feature in under five minutes or bust</strong>. (Up from two minutes last time.)</p>
</li>
<li>
<p><strong>No gimmicks</strong>. No doctor, tetris, snake, dunnet…</p>
</li>
<li>
<p><strong>Just the deltas</strong>. No commonly mentioned packages like flymake, doc-view,
outline-minor-mode, gnus or eww. Nothing that Emacs brings up automatically or
a nonspecific Google search gets you.</p>
</li>
<li>
<p>Assume a modern Emacs, 26.3+.</p>
<p>Also, if you’re new to Emacs:</p>
<table>
<thead>
<tr>
<th>Emacs jargon</th>
<th>Modern parlance</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>M-x</code></td>
<td>Alt + x</td>
</tr>
<tr>
<td><code>C-x</code></td>
<td>Ctrl + x</td>
</tr>
<tr>
<td>Frame</td>
<td>Emacs window</td>
</tr>
<tr>
<td>Window</td>
<td>split/pane</td>
</tr>
<tr>
<td>Buffer</td>
<td>Contiguous chunk of text/data</td>
</tr>
<tr>
<td>Point</td>
<td>Cursor position in buffer</td>
</tr>
<tr>
<td>Active Region</td>
<td>Text selection</td>
</tr>
<tr>
<td>Region</td>
<td>Text selection (not highlighted)</td>
</tr>
<tr>
<td>Face</td>
<td>Font, color and display properties</td>
</tr>
</tbody>
</table>
</li>
</ul>
<p>(Sorry.)</p>
<p>Okay? Let’s go:</p>
<h2 id="strokes--m-x-strokes-help">Strokes (<code>M-x strokes-help</code>)</h2>
<p>Control Emacs with mouse gestures:</p>
<video width="700" autoplay="" controls="" loop="">
 <source src="https://karthinks.com/img/strokes-mode-demo.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>Why are you using Emacs with a mouse, you ask.</p>
<p>In this demo I used gestures to handle window management:
<img src="https://karthinks.com/img/strokes-list.png" alt=""></p>
<p>This is because I lack imagination. Consider: You can bind <em>any</em> gesture to <em>any</em> Emacs command.</p>
<p>The real utility of this feature is when you find yourself going back and forth between different interaction paradigms, like a web browser and Emacs, requiring frequent context switching between full keyboard and keyboard/mouse based interaction.</p>
<p>Want to <code>org-capture</code> or <code>org-roam-insert</code> something from your browser? Want to quickly recompile a TeX document while you’re busy mousing through the corresponding PDF? Need to tweak some markup in your document while you work on graphics in Inkscape? <a href="http://xenodium.com/emacs-clone-git-repo-from-clipboard/">Clone a repository you found online</a>?  <code>strokes-mode</code>.</p>
<p>The second use case for Strokes is to control Emacs during reading-centric activities, like email or RSS. Star or delete messages, pause or skip music tracks (with some elisp around <code>playerctl</code>), navigate info nodes, or cycle through Elfeed searches.</p>
<p><code>M-x strokes-help</code> will get you started. As with most things Emacs, there’s more to the library than meets the eye, like support for multi-part strokes you can use to edit documents in Chinese. The buffer showing the gesture being traced is for demo purposes only, you can customize <code>strokes-use-strokes-buffer</code>:</p>
<div><pre><code data-lang="emacs-lisp">(<span>global-set-key</span> (<span>kbd</span> <span>"&lt;down-mouse-3&gt;"</span>) <span>'strokes-do-stroke</span>) <span>; Draw strokes with RMB</span>
(<span>setq</span> <span>strokes-use-strokes-buffer</span> <span>nil</span>) <span>; Don't draw strokes to the screen</span>
</code></pre></div><hr>
<h2 id="minibuffer-completion-styles--c-h-v-completion-styles">Minibuffer completion styles (<code>C-h v completion-styles</code>)</h2>
<p>The default minibuffer experience is annoying enough to send anyone into the
arms of <code>ido</code>, <code>ivy</code> or <code>helm</code>. But Emacs does a lot better in the
tab-completions department than it lets on. The minibuffer can match by
substrings, regexps, initials and even (as of Emacs 27+) fuzzily, and it can do
all of them at once if you don’t mind a giant pile of matches.</p>
<p>You can do worse than</p>
<div><pre><code data-lang="emacs-lisp">(<span>setq</span> <span>completion-styles</span> <span>'</span>(<span>initials</span> <span>partial-completion</span> <span>flex</span>)) <span>; &gt; Emacs 27.1</span>
(<span>setq</span> <span>completion-cycle-threshold</span> <span>10</span>)
</code></pre></div><p>Now <code>M-x ohba</code> tab-expands to <code>org-hide-block-all</code>, <code>M-x qrr</code> to
<code>query-replace-regexp</code> and so on, allowing you to tab-cycle between up to ten
completions. Use tab to match file names fuzzily and expand short paths
(<code>~/.l/sh/g</code>) to long ones (<code>~/.local/share/git</code>).</p>
<p>Stretching the five minute rule a bit: You probably want different matching
rules for different categories, though. Flex matching on extended commands
(<code>M-x</code>) can dump hundreds of irrelevant matches on short input, for instance.
You can customize <code>completion-category-overrides</code> to set the matching style by
the category being completed.</p>
<p>Finally, note that completion styles dictate how a candidate pool is found.
Incremental completion systems like <code>ido</code> specify how found candidates are
displayed and chosen. These are orthogonal functions, so any set of completion
styles should work with any completion system. Unfortunately this isn’t the
case, because <code>ivy</code> and <code>helm</code> are off doing their own thing. Emacs’ built in
completion styles do work with <code>icomplete</code>, <code>ido</code> and possibly <code>selectrum</code>
though.</p>
<hr>
<h2 id="fake-ido--m-x-fido-mode">Fake Ido ( <code>M-x fido-mode</code>)</h2>
<p>Improves the other half of the default minibuffer experience: interacting with
selection candidates. Navigating to, from and inside the default completions
buffer takes too many key presses. <code>fido-mode</code> brings <code>ido</code> like selection to
every command in Emacs that uses <code>completing-read</code>, which is most of them.</p>
<p>Of course, <code>ido</code> is also built in, but you know all about it. It also takes some
effort to get ido to work with every command. <code>fido-mode</code> is set-and-forget, but
it’s Emacs 27+ only.</p>
<hr>
<h2 id="easier-rectangle-editing--m-x-cua-selection-mode">Easier rectangle editing (<code>M-x cua-selection-mode</code>)</h2>
<video width="700" autoplay="" controls="" loop="">
 <source src="https://karthinks.com/img/cua-selection-mode-demo.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>The default rectangle commands in Emacs (<code>C-x r</code> map) leave a little to be
desired in terms of interactivity. Emacs has fully featured rectangle editing,
but it’s presented in an odd sort of way, as a subfeature of Common User Access.
It’s pretty nifty:</p>
<video width="700" autoplay="" controls="" loop="">
 <source src="https://karthinks.com/img/cua-selection-mode-demo-2.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>Start or clear a rectangle selection with <code>C-&lt;return&gt;</code>. Cycle through rectangle
corners with <code>&lt;return&gt;</code>. Yes, you’ll need to rebind it if you use Org or ESS.</p>
<p>It’s a very handy feature, but note that <code>cua-selection-mode</code> does <em>not</em> mesh
well with undo. If you use <code>undo-tree</code>, it can lock up trying to undo a
<code>cua-selection</code> edit.</p>
<hr>
<h2 id="speedbar--m-x-speedbar">speedbar (<code>M-x speedbar</code>)</h2>
<p>A file explorer and much, much more in Emacs. If you need the Neotree or
dired-sidebar package to do anything in Emacs, check out speedbar.</p>
<p>Speedbar pops up a side frame that looks like a file browser, which it is. But
it also integrates with <code>imenu</code> to show you headings/tags inside files, and with
<code>vc</code> to show you the status of your files:</p>
<figure>
    <img src="https://karthinks.com/img/speedbar-tags-demo.png" alt="Figure 1: Speedbar showing tags and VC status"> <figcaption>
            <p>Figure 1: Speedbar showing tags and VC status</p>
        </figcaption>
</figure>

<figure>
    <img src="https://karthinks.com/img/speedbar-org-demo.png" alt="Figure 2: Speedbar showing headings in an org file"> <figcaption>
            <p>Figure 2: Speedbar showing headings in an org file</p>
        </figcaption>
</figure>

<p>From inside speedbar you can act on files with (frustratingly, <em>almost</em>
dired-like) keybindings. Most regular commands run from speedbar will be run in
the associated buffer.</p>
<p>It tracks the active buffer to show you appropriate hierarchical information.
Here I moved point into <code>info</code> and <code>latex-mode</code> buffers:</p>
<p><img src="https://karthinks.com/img/speedbar-info-demo.png" alt="">
<img src="https://karthinks.com/img/speedbar-latex-demo.png" alt=""></p>
<p>Perhaps you’d like a list of your buffers instead. Switch between buffer and
file view with <code>b</code> / <code>f</code>. (You can expand a buffer entry for tag/headings.)</p>
<figure>
    <img src="https://karthinks.com/img/speedbar-buffers-demo.png"> 
</figure>

<hr>
<h2 id="orgtbl-minor-mode--m-x-orgtbl-mode">Orgtbl minor mode (<code>M-x orgtbl-mode</code>)</h2>
<p>Org-mode is its own thing, a full fledged notetaking, publishing,
literate-programming, task tracking application with a growing ecosystem that’s
parallel to Emacs’.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>But it does provide a handy tool that’s useful in any mode: Making tables. If
you’re one of the dozen Emacs users who haven’t hopped on the Org train, this
one’s for you.</p>
<p>With <code>orgtbl-mode</code>, you can make tables by starting a line with the pipe
character and hitting tab to make a field–like you would in <code>org-mode</code>–but
<strong>without getting in the way of your major mode</strong>. You can just leave it on and
get on with your work.</p>
<video width="700" autoplay="" controls="" loop="">
 <source src="https://karthinks.com/img/orgtbl-mode-demo.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>Here I table some parameters in matlab-mode as a comment, but even more lazily
than prescribed above by calling <code>orgtbl-create-or-convert-from-region</code>
(<code>C-c |</code>) on some data.</p>
<p>With some work, you can export the table in place to html or LaTeX, but setting
this up would break the five minute rule. You can also use the table as a
spreadsheet, which is beyond me.</p>
<hr>
<h2 id="regexp-builder--m-x-re-builder">Regexp builder (<code>M-x re-builder</code>)</h2>
<p><img src="https://karthinks.com/img/re-builder-demo.png" alt="">
Emacs’ regular expressions syntax can be idiosyncratic if you’re used to <a href="https://www.pcre.org/">PCRE</a>. Are unescaped parens matched literally or do they act as capture groups? Does + need to be escaped to match multiple occurrences of a character? How do I match whitespace again?<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<p>I can never remember. For regularly confused users like me there is <code>re-builder</code>. Build your regular expressions interactively, one character at a time. Save it to the kill ring for later use. This is a godsend when testing regexes for non-interactive use, like when writing elisp helpers.</p>
<p>A cleaner approach to regular expressions in Emacs, as most package maintainers will tell you, is to use the <code>rx</code> library instead. <code>rx</code> translates regular expressions in sexp form to a regexp string:</p>
<div><pre><code data-lang="emacs-lisp">(<span>rx</span> (<span>and</span> <span>"("</span>
         (<span>or</span> <span>"use-package"</span> <span>"require"</span>)
         (<span>+</span> <span>space</span>)
         (<span>group</span> (<span>syntax</span> <span>symbol</span>))))
</code></pre></div><div><pre><code data-lang="text">(\(?:\(?:requir\|use-packag\)e\)[[:space:]]+\(\s_\)
</code></pre></div><hr>
<h2 id="future-history--m-n-in-prompts">Future history (<code>M-n</code> in prompts)</h2>
<p><code>M-p</code> and <code>M-n</code> cycle through history items in minibuffer prompts. So what happens when you press <code>M-n</code> when you’re at a blank prompt?</p>
<p>Emacs tries to Do What You Mean. If the cursor is over a file name, for instance, <code>M-n</code> at the find-file prompt inserts the file path at point into the minibuffer. From the manual:</p>
<blockquote>
<p>The “future history” for file names includes several possible alternatives you may find useful, such as the file name or the URL at point in the current buffer. The defaults put into the “future history” in this case are controlled by the functions mentioned in the value of the option file-name-at-point-functions.</p>
</blockquote>
<p>Like the DWIM behavior of Emacs commands on regions, many utilities account for <code>future-history</code>. You can usually drag whatever relevant object point is at into the minibuffer prompt with <code>M-n</code>.</p>
<hr>
<h2 id="transpose-regions--m-x-transpose-region">Transpose regions (<code>M-x transpose-region</code>)</h2>
<p>Lurking in the bevy of transposition commands in Emacs is <code>transpose-region</code>,
which does what it says on the tin<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>:</p>
<video width="700" autoplay="" controls="" loop="">
 <source src="https://karthinks.com/img/transpose-regions-demo.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>Exchange any two non-overlapping regions in a buffer. You’ll need to assign a
keybinding though.</p>
<div><pre><code data-lang="emacs-lisp">(<span>global-set-key</span> (<span>kbd</span> <span>"C-x C-M-t"</span>) <span>'transpose-regions</span>)
</code></pre></div><p>Also of note: <code>transpose-paragraphs</code>, which sounds like a text-mode utility but
works pretty well on adjacent blocks of code.</p>
<hr>
<h2 id="view-mode-again--m-x-view-mode">View mode, again (<code>M-x view-mode</code>)</h2>
<p>View-mode got an airing <a href="https://karthinks.com/software/batteries-included-with-emacs/#view-mode--m-x-view-mode">the last time around</a> but I like it so much I will repeat
myself. <strong>Turn Emacs into a pager.</strong></p>
<p>By default, pressing <code>v</code> in dired will open a file in view-mode. You can dismiss
the window and buffer with <code>q</code>, so regular buffers can essentially function as
info or help buffers do with <code>View</code>. You can scroll or isearch without pressing
any …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://karthinks.com/software/more-batteries-included-with-emacs/">https://karthinks.com/software/more-batteries-included-with-emacs/</a></em></p>]]>
            </description>
            <link>https://karthinks.com/software/more-batteries-included-with-emacs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399994</guid>
            <pubDate>Sat, 12 Dec 2020 17:43:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating Accordions with Native HTML]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399984">thread link</a>) | @championshuttle
<br/>
December 12, 2020 | https://itsopensource.com/creating-accordions-with-native-html/ | <a href="https://web.archive.org/web/*/https://itsopensource.com/creating-accordions-with-native-html/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Accordions are one of the most commonly used UI components for any website. For example FAQs section of the website, where only the question is shown, and when clicked the answer just opens up.
Generally, we handle this by creating 2 <code>divs</code> and adding some javascript to handle the open and close of the accordion. But recently I stumbled upon this hidden gem in HTML that eliminates the need of all this - <a href="https://developer.mozilla.org/docs/Web/HTML/Element/details"><code>&lt;details&gt;</code></a></p>
<p>We can simply design a simple FAQ or summary section with <code>&lt;details&gt;</code> HTML tag without using Javascript!!! 🤯🤯🤯.
And the best part… it is supported by all the modern browsers (obviously except IE :( ) - <a href="https://caniuse.com/?search=details">browser compatibility</a>.  </p>
<h3>Using <code>&lt;details&gt;</code> tag</h3>
<p>There are two elements here: <code>&lt;details&gt;</code> and <code>&lt;summary&gt;</code>. <code>&lt;details&gt;</code> is the wrapper for all the content you want to show and hide, and <code>&lt;summary&gt;</code> contains the — well, the summary and title of the section. <code>&lt;summary&gt;</code> is optional, if you do not add it, the browser will use some default text. For example, in Firefox and Chrome, it is <code>Details</code>. Below is a sample HTML markup:</p>
<div data-language="html"><pre><code><span><span><span>&lt;</span>details</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>summary</span><span>&gt;</span></span>Details<span><span><span>&lt;/</span>summary</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>p</span><span>&gt;</span></span>Something small enough to escape casual notice.<span><span><span>&lt;/</span>p</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>details</span><span>&gt;</span></span></code></pre></div>
<p>And it will render like:</p>
<p><img src="https://itsopensource.com/24758e046144be6cff4069952a25332c/1.gif" alt="part1"></p>
<p>This markup can be designed with CSS as any other HTML element. Now for creating beautiful accordions all you need is just HTML and CSS (and a will to let go of IE).</p>
<p>Demo: <a href="https://bit.ly/htmldetails">https://itsopensource.com/demos/details/</a></p>
<h3>References</h3>
<ul>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/details">MDN: details</a></li>
</ul>
<p>Cheers.</p></section></div>]]>
            </description>
            <link>https://itsopensource.com/creating-accordions-with-native-html/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399984</guid>
            <pubDate>Sat, 12 Dec 2020 17:41:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[eInk Monitor Setup for Coding]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399908">thread link</a>) | @tyler109
<br/>
December 12, 2020 | https://forum.ei2030.org/t/best-dasung-eink-monitor-setup/42 | <a href="https://web.archive.org/web/*/https://forum.ei2030.org/t/best-dasung-eink-monitor-setup/42">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
          <p><span>#4</span></p>
<ul>
<li>Minimize scrolling by using page up/down keyboard shortcuts</li>
<li>Have a plain white desktop</li>
<li>Switch off animations in accessibility</li>
<li>Reduce the animation effects in the dock settings</li>
<li>I prefer mine at 1600x1200</li>
<li>Make the mouse pointer larger</li>
<li>Use large text</li>
<li>Use a font designed for e-ink: Literata is my favourite</li>
<li>Zoom in on websites</li>
<li>I mirror my MacBook screen, but only have its brightness up to watch videos or check colours</li>
<li>Don’t use dark modes, and make customisable apps very white</li>
<li>Have warm light directional lamps pointing at the screen instead of using the built in lights</li>
<li>Have the top of the screen at eye level</li>
</ul>
<p><span>#5</span></p>
<p>So, my tips:</p>
<ul>
<li>
<p>Learn all possible shortcuts (switch tabs in browser, switch apps, validate dialog, space bar to page down, zoom size text, …)</p>
</li>
<li>
<p>You have a checkbox in “system pref / accessibility / display” to increase contrast : it add an extra border on some macos ui element (I find the slider below not useful)</p>
</li>
<li>
<p>There is an extension for firefox to improve contrast (“font contrast”). FF also have a high contrast mode that I find not practical</p>
</li>
<li>
<p>Try to understand M1/M2/M3 Vs contrast +/-. My understanding is: contrast +/- “moves the range” from light/medium to medium/dark, and M1/M2/M3 makes this range wider, at the price of less level of gray. But I may be wrong</p>
</li>
<li>
<p>There are 9 level of contrasts</p>
</li>
<li>
<p>Usually for videos you want to use lowest contrast level</p>
</li>
<li>
<p>Don’t use the software, it’s too buggy, just use the button on the screen</p>
</li>
<li>
<p>Take really care that you don’t use a software like flux or night shift. And even when quitting flux, you may still have the profile activated (Displays / colour / display profile)</p>
</li>
<li>
<p>For anything which is white with black background (video tutorial, site …), you can set an os shortcut to inverse all color of the screen: sys preference / keyboard / shortcut / accessibility / invert colors (I use ctrl+alt+cmd 8)</p>
</li>
<li>
<p>It’s nice to have a white desktop background, but you may have difficulty to read the name of the icons on the desktop. so : right click on desktop / show view options, and then increase the size of the font. Alternatively hit cmd+A to have everything selected and then readable</p>
</li>
<li>
<p>I use 1100x824</p>
</li>
</ul>
<p><span>#6</span></p>
<p>hi for code editor I have to say that i abandoned (i am using visual studio code) - syntax highlighting is so useful and not usable in B&amp;W. I am interested if you have any good configuration for it.</p>
<p>the only additional tips i could give you according to previous posts is that I put my dasung on an articulated arm of photo camera. It allows me to use it without backlight and to avoid annoying light reflection by moving it easily. I also tried a classics monitor arm but the dasung was to light for it.</p>
<p>The drivers are buggy and each time I connect my dasung on my mac I have to adjust the settings again. (i use M2 with black+)</p>
<p>Anyone knows if the config can be saved on the dasung ?</p>
<p><span>#7</span><br>
On my side I’m happy with coding on dasung, as long as I use a light theme. I use mostly phpstorm, and the difference of level of grey / background color / italic / underline makes syntax highlighting somehow noticeable enough. Definitely not perfect though</p>
<p>I think that without or with the driver installed, the settings are resetted every time you reconnect the screen. (Just that, with the driver, you have extra bugs)</p>
<p>Another tip or solution about light reflection : putting yourself (and the screen) perpendicular to a window : you’ll still have some outside lights, but no reflection</p>
<p><span>#8</span></p>
<p>I finally succeeded in activating high dpi on mac</p>
<p>I use SwitchResX and I had to add a new scaled resolution for the dasung : 2201x1650 (the real resolution does not allow hidpi (it is a mac os bug)</p>
<p>then I choose the 1101x825 and it works like a charm</p>
        </div></div>]]>
            </description>
            <link>https://forum.ei2030.org/t/best-dasung-eink-monitor-setup/42</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399908</guid>
            <pubDate>Sat, 12 Dec 2020 17:31:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtual Events Suck]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25399879">thread link</a>) | @mooreds
<br/>
December 12, 2020 | https://aparker.io/posts/virtual-events-suck/ | <a href="https://web.archive.org/web/*/https://aparker.io/posts/virtual-events-suck/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
  
  <p><time datetime="2020-12-10T09:30:00-0500">Thu, Dec 10, 2020</time></p><p><img src="https://aparker.io/images/virtualeventssuckheader.png" alt="image"></p>
<p>I mean, is this even up for argument?</p>

<p>One of the whitest-ass things in the world is our people’s obsession with songs at sporting events, and indeed, in large crowds. If you’re reading this and you’re from Europe, feel free to replace my references to Sweet Caroline with Seven Nation Army, same diff. That said, you can fairly reliably trigger this behavior in most cultures in most parts of the world by finding a sufficiently rowdy bar around midnight and playing <em>something</em> on the jukebox that gets folks going. Humans, we’re social creatures, yeah? A few bars of Neil Diamond, a couple people singing along, and by the time you’re at ‘Hands, touching hands’ you’ll have a swelling crescendo that culminates in a ear-shattering and atonal screech of ‘SWEEEEEEEEEEEEET CAR-O-LINE (WOAH OH OH)’ making the bartenders silently plot the murder of everyone in their line of sight.</p>
<p>People like being around people, and most people don’t treat everyone around them as some sort of incredibly delicate faberge egg. There’s a lot of “wow look at all these accomodations people are making that disabled people have asked for now that nobody is supposed to leave their house! hypocrisy, much??” and I’m like, yeah, duh? Pointing out hypocrisy is the lowest form of engagement in 2020. This is why virtual events suck – because nobody is actually planning on doing them any longer than they need to.</p>

<blockquote>
<p>One of the benefits of in-person conferences is that they temporarily remove you from your day-to-day work and immerse you in a community of like-minded individuals. It’s not just about getting to hear new ideas, but also about the break from your daily routine. This is one of the things that is hardest to replicate in a virtual event. DIDevOps was perhaps the most successful virtual conference I’ve seen in making their event feel like An Event. This event was clever and whimsical, the community was engaged, and it definitely didn’t feel like just another video call.</p>
</blockquote>
<p><a href="https://redmonk.com/rstephens/2020/04/30/deserted-island-devops/">Rachel Stephens, RedMonk</a></p>
<p>I wrote earlier this year about the idea of a <a href="https://aparker.io/posts/deserted-island-devops/">decisive moment</a> and how that influenced the thinking behind Deserted Island DevOps. To elaborate a bit, Cartier-Bresson was a street photographer who coined this phrase in the introduction to his 1947 book.</p>
<blockquote>
<p>Photography is the simultaneous recognition, in a fraction of a second, of the significance of an event as well as of a precise organisation of forms which give that event its proper expression.</p>
</blockquote>
<p>What is, then, the ‘decisive moment’ of a tech conference? My original criteria was that an event was <em>etherial</em> or placeless; From the smallest DevOpsDays to the largest re:Invent, an event is defined less by the where than by the who. As an attendee, you are swept away from the status quo for a time (even as it inorexably pulls you back in, given the amount of people I see working on laptops during events) into a convention center or hotel or theater or whatever, specifically to focus on something other than what you normally would. Quite literally, you are being moved out of your comfort zone. This can prime you to accept ideas that normally you wouldn’t, can rejigger your brain chemistry for a few hours to make you see things from a different perspective. That’s valuable! As a speaker, you’re transported to a new stage, with a new audience, a new set of eyes and ears to reflect off of. It’s almost like being a comedian and testing out material – you try some new lines, some new jokes, add an anecdote here, shave one off there. Repetition builds mastery. Next week, or next month, you’re going to do it all again. Our traversal through the liminal spaces between these potemkin stages lends itself to inward focus where we must Do The Work to shut out the world around us. To be less floral about it, the demands of the road make us better speakers because the only way we don’t go fuckin’ mad is to focus on the work.</p>
<p>Virtual events offer none of this, unfortunately. As attendees, another Slack, another Zoom call, another wave of talking heads and PowerPoint. As speakers, our audience disappears behind a chat window. We lose our reflection. It’s sad and terrible and great for some people, but on the balance I think we dislike it more than we like it.</p>
<p>The bad is part of the fun! You can’t replicate the feeling of gnawing on an underripe banana while chugging overly-hot-but-not-terribly-flavorful coffee watching someone who’s company paid way too much for a keynote while mentally ticking off the people you need to talk to that day while working out the soreness in your back from the bed that isn’t yours that you got maybe four productive sleeping hours in due to jet lag while figuring out who you’re going to catch up with after the show wraps that day as you muse about how it looks like your competitors have a much nicer booth than yours, and you wonder if they’re hiring except that one asshole still works there and so on and so forth. “That sounds terrible!” you may be musing, <em>and you’d be right</em>, but I love the terrible. I thrive in the terrible. I’m drinking single origin fair trade coffee beans that were roasted in small batches locally brewed in a fancy coffee maker and I can tell you that when this is all over and I can have a cuppa brewed in the backroom of a Hilton it is going to be the sweetest thing I can possibly imagine for five seconds right before I start hating everything about it again and <em>that’s fine</em>.</p>
<p>The bad of an in-person event is terrible, but it’s a terrible I can work with. I go outside like once or twice a week now to get groceries and that’s all I’ve done for the past nine months. <em>I want the workable terrible, not this horrific stasis</em>.</p>

<p>The reason that virtual events suck is that we’re trying to replicate in-person events. We’re doing old-school iOS skeumorphism but for primarily social gatherings. No wonder they suck! There’s a few broad reasons:</p>
<ul>
<li><em>Bad UX</em>: Sometimes I like to style on babies by displaying object permanance, but you wouldn’t know that given the utter contempt event platforms seem to have for their audiences by doing dumb skeumorphic “conference halls” with badly ‘shopped people standing around.</li>
</ul>
<p><img src="https://aparker.io/images/kubeconlobby.png" alt="KubeCon EU ‘Lobby’"></p>
<ul>
<li>
<p><em>Pervasive Surveillence</em>: I use ad blockers but a bunch of people don’t, on principle though it’s really fuckin’ creepy that every click you make on one of these event platforms is tracked. Simply navigating to a sponsor booth counts as a ‘lead’ to the sponsor. Yikes!</p>
</li>
<li>
<p><em>Poor AV Quality</em>: I get that people have to record from their homes but maybe recording someone’s Zoom isn’t the best way to do this? I’m sympathetic, this is legit a hard problem to solve, but many large conferences are still charging an arm and a leg to sponsors (and less for attendees but that’s a different point) so how about you do local recording then edit things later? If you’re going to charge me at <em>all</em> then I expect the production values to at least beat out a random Twitch streamer.</p>
</li>
<li>
<p><em>Poor Viewing Experience</em>: A tiny pop-out 720p video that artifacts when I change the size is… not great. Integrate chat and Q&amp;A better. Do <em>something</em> unique with the format. I sit on enough Zoom calls. Like, why would I <em>pay money</em> to <em>watch videos</em> with a <em>worse player than YouTube</em>? There’s millions of hours of shit out there for free!</p>
</li>
<li>
<p><em>Yet Another Slack</em>: I just don’t want to join more Slack channels where people are randomly @here’ing and I never know if it’s an event organizer with an announcement or some salesperson trying to coax people into their virtual booth.</p>
</li>
<li>
<p><em>Did I Mention Virtual Booths Yet</em>: I have never interacted with anyone in a Virtual Booth and I never will. This appears to be a common sentiment.</p>
</li>
</ul>

<p>Alright, let’s flip the script. I’m wearing my business hat now.</p>
<ul>
<li>
<p><em>Bad UX</em>: You think the <em>attendee</em> experience is bad, the admin/sponsor controls and views on these platforms is worse. Arbitrary requirements, poor control over look and feel, nah fam miss me with this.</p>
</li>
<li>
<p><em>Poor Interactivity</em>: You know what’s great about a real booth? People wander by and they get interested. Why do they wander by? Because they’re not at home, they need to kill time, and the snacks are on the trade floor. Maybe they just want a t-shirt or whatever, fine, but we do actually get a lot of really valuable feedback and eyes on the product by doing demos. This is extremely useful, and it simply doesn’t happen at virtual events.</p>
</li>
<li>
<p><em>Attendee Impedence Mismatch</em>: This is more of a theory but I suspect that the attendee mix for virtual events in terms of titles is significantly out-of-balance compared to in-person events. One popular (<em>n</em> = ~1300) virtual event this year had self-reported attendance of only 4% for management roles, but over 40% IC (developer/devops/ops) roles. My hypothesis is that “decision makers” are less likely to attend virtual events because they’re intensely overbooked during the in-person -&gt; distributed team transition period and are oversubscribed on other things, which translates into less useful direct sales conversations, but I could be off-base here. If nothing else, my anecdata from talking about this seems to indicate that attendees just don’t really go to virtual booths.</p>
</li>
<li>
<p><em>Success Looks Different</em>: This is one of those ‘two-way street’ problems, but I don’t think organizers did a great job in general making sponsors successful, and I don’t think sponsors had the muscle to make themselves successful in a lot of ways. Trying to be too different caused a lot of friction, however, and during a time of reinvention this friction reduced experimentation in my opinion.</p>
</li>
</ul>

<p>Last part - the speaker experience.</p>
<ul>
<li>
<p><em>My Home Is Not Your Home</em>: One of the low key worst things about the pandemic has been the idea of us ‘opening up our homes’ and letting people see how we live. Could we fuckin’ not? Like I don’t believe that I even have to discuss this but we should probably put the Room Rater person on trial for crimes against humanity. I don’t <em>want</em> to have to be super concious about my webcam or audio or whatever, I don’t <em>want</em> to …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aparker.io/posts/virtual-events-suck/">https://aparker.io/posts/virtual-events-suck/</a></em></p>]]>
            </description>
            <link>https://aparker.io/posts/virtual-events-suck/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399879</guid>
            <pubDate>Sat, 12 Dec 2020 17:28:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PyTorch Dynamic Quantization]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399867">thread link</a>) | @keyboardman
<br/>
December 12, 2020 | https://leimao.github.io/blog/PyTorch-Dynamic-Quantization/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/PyTorch-Dynamic-Quantization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Dynamic quantization quantize the weights of neural networks to integers, but the activations are dynamically quantized during inference. Comparing to floating point neural networks, the size of dynamic quantized model is much smaller since the weights are stored as low-bitwidth integers. Comparing to other quantization techniques, dynamic quantization does not require any data for calibration or fine-tuning. More details about the mathematical foundations of quantization for neural networks could be found in my article <a href="https://leimao.github.io/article/Neural-Networks-Quantization/">â€œQuantization for Neural Networksâ€�</a>.</p>



<p>Given a pre-trained floating point model, we could easily create an dynamically quantized model, run inference, and potentially achieve better latency without too much additional effort. In this blog post, I would like to show how to use PyTorch to do dynamic quantizations.</p>

<h3 id="pytorch-dynamic-quantization">PyTorch Dynamic Quantization</h3>

<p>Unlike TensorFlow 2.3.0 which supports integer quantization using arbitrary bitwidth from 2 to 16, PyTorch 1.7.0 only supports 8-bit integer quantization. The workflow is as easy as loading a pre-trained floating point model and apply a dynamic quantization wrapper.</p>



<p>In this case, I would like to use the BERT-QA model from HuggingFace Transformers as an example. I was dynamically quantizing the <code>torch.nn.Linear</code> layer for the BERT-QA model since the majority of the computation for Transformer based models are matrix multiplications. The source code could also be downloaded from <a href="https://github.com/leimao/PyTorch-Dynamic-Quantization">GitHub</a>.</p>

<div><div><pre><code><span># qa.py
</span>
<span>import</span> <span>os</span>
<span>import</span> <span>time</span>
<span>import</span> <span>torch</span>
<span>from</span> <span>transformers</span> <span>import</span> <span>BertTokenizer</span><span>,</span> <span>BertForQuestionAnswering</span>

<span>def</span> <span>measure_inference_latency</span><span>(</span><span>model</span><span>,</span> <span>inputs</span><span>,</span> <span>num_samples</span><span>=</span><span>100</span><span>):</span>

    <span>start_time</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>num_samples</span><span>):</span>
        <span>_</span> <span>=</span> <span>model</span><span>(</span><span>**</span><span>inputs</span><span>)</span>
    <span>end_time</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>elapsed_time</span> <span>=</span> <span>end_time</span> <span>-</span> <span>start_time</span>
    <span>elapsed_time_ave</span> <span>=</span> <span>elapsed_time</span> <span>/</span> <span>num_samples</span>

    <span>return</span> <span>elapsed_time_ave</span>

<span>def</span> <span>get_bert_qa_model</span><span>(</span><span>model_name</span><span>=</span><span>"deepset/bert-base-cased-squad2"</span><span>,</span> <span>cache_dir</span><span>=</span><span>"./saved_models"</span><span>):</span>

    <span># https://huggingface.co/transformers/model_doc/bert.html#transformers.BertForQuestionAnswering
</span>    <span>tokenizer</span> <span>=</span> <span>BertTokenizer</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_name</span><span>,</span> <span>cache_dir</span><span>=</span><span>cache_dir</span><span>)</span>
    <span>model</span> <span>=</span> <span>BertForQuestionAnswering</span><span>.</span><span>from_pretrained</span><span>(</span><span>model_name</span><span>,</span> <span>cache_dir</span><span>=</span><span>cache_dir</span><span>,</span> <span>return_dict</span><span>=</span><span>True</span><span>)</span>

    <span>return</span> <span>model</span><span>,</span> <span>tokenizer</span>

<span>def</span> <span>prepare_qa_inputs</span><span>(</span><span>question</span><span>,</span> <span>text</span><span>,</span> <span>tokenizer</span><span>,</span> <span>device</span><span>=</span><span>None</span><span>):</span>

    <span>inputs</span> <span>=</span> <span>tokenizer</span><span>(</span><span>question</span><span>,</span> <span>text</span><span>,</span> <span>return_tensors</span><span>=</span><span>"pt"</span><span>)</span>
    <span>if</span> <span>device</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
        <span>inputs_cuda</span> <span>=</span> <span>dict</span><span>()</span>
        <span>for</span> <span>input_name</span> <span>in</span> <span>inputs</span><span>.</span><span>keys</span><span>():</span>
            <span>inputs_cuda</span><span>[</span><span>input_name</span><span>]</span> <span>=</span> <span>inputs</span><span>[</span><span>input_name</span><span>].</span><span>to</span><span>(</span><span>device</span><span>)</span>
        <span>inputs</span> <span>=</span> <span>inputs_cuda</span>
    
    <span>return</span> <span>inputs</span>

<span>def</span> <span>move_inputs_to_device</span><span>(</span><span>inputs</span><span>,</span> <span>device</span><span>=</span><span>None</span><span>):</span>

    <span>inputs_cuda</span> <span>=</span> <span>dict</span><span>()</span>
    <span>for</span> <span>input_name</span> <span>in</span> <span>inputs</span><span>.</span><span>keys</span><span>():</span>
        <span>inputs_cuda</span><span>[</span><span>input_name</span><span>]</span> <span>=</span> <span>inputs</span><span>[</span><span>input_name</span><span>].</span><span>to</span><span>(</span><span>device</span><span>)</span>

    <span>return</span> <span>inputs_cuda</span>

<span>def</span> <span>run_qa</span><span>(</span><span>model</span><span>,</span> <span>tokenizer</span><span>,</span> <span>question</span><span>,</span> <span>text</span><span>,</span> <span>device</span><span>=</span><span>None</span><span>):</span>

    <span>inputs</span> <span>=</span> <span>prepare_qa_inputs</span><span>(</span><span>question</span><span>=</span><span>question</span><span>,</span> <span>text</span><span>=</span><span>text</span><span>,</span> <span>tokenizer</span><span>=</span><span>tokenizer</span><span>)</span>

    <span>all_tokens</span> <span>=</span> <span>tokenizer</span><span>.</span><span>convert_ids_to_tokens</span><span>(</span><span>inputs</span><span>[</span><span>"input_ids"</span><span>].</span><span>numpy</span><span>()[</span><span>0</span><span>])</span>

    <span>if</span> <span>device</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
        <span>inputs</span> <span>=</span> <span>move_inputs_to_device</span><span>(</span><span>inputs</span><span>,</span> <span>device</span><span>=</span><span>device</span><span>)</span>
        <span>model</span> <span>=</span> <span>model</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>

    <span>outputs</span> <span>=</span> <span>model</span><span>(</span><span>**</span><span>inputs</span><span>)</span>

    <span>start_scores</span> <span>=</span> <span>outputs</span><span>.</span><span>start_logits</span>
    <span>end_scores</span> <span>=</span> <span>outputs</span><span>.</span><span>end_logits</span>

    <span>answer_start_idx</span> <span>=</span> <span>torch</span><span>.</span><span>argmax</span><span>(</span><span>start_scores</span><span>,</span> <span>1</span><span>)[</span><span>0</span><span>]</span>
    <span>answer_end_idx</span> <span>=</span> <span>torch</span><span>.</span><span>argmax</span><span>(</span><span>end_scores</span><span>,</span> <span>1</span><span>)[</span><span>0</span><span>]</span> <span>+</span> <span>1</span>

    <span>answer</span> <span>=</span> <span>" "</span><span>.</span><span>join</span><span>(</span><span>all_tokens</span><span>[</span><span>answer_start_idx</span> <span>:</span> <span>answer_end_idx</span><span>])</span>

    <span>return</span> <span>answer</span>

<span>def</span> <span>get_model_size</span><span>(</span><span>model</span><span>,</span> <span>temp_dir</span><span>=</span><span>"/tmp"</span><span>):</span>

    <span>model_dir</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>join</span><span>(</span><span>temp_dir</span><span>,</span> <span>"temp"</span><span>)</span>
    <span>torch</span><span>.</span><span>save</span><span>(</span><span>model</span><span>.</span><span>state_dict</span><span>(),</span> <span>model_dir</span><span>)</span>
    <span># model.save_pretrained(model_dir)
</span>    <span>size</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>getsize</span><span>(</span><span>model_dir</span><span>)</span>
    <span>os</span><span>.</span><span>remove</span><span>(</span><span>model_dir</span><span>)</span>
    
    <span>return</span> <span>size</span>

<span>def</span> <span>main</span><span>():</span>

    <span>cuda_device</span> <span>=</span> <span>torch</span><span>.</span><span>device</span><span>(</span><span>"cuda:0"</span><span>)</span>
    <span>num_samples</span> <span>=</span> <span>100</span>

    <span>model</span><span>,</span> <span>tokenizer</span> <span>=</span> <span>get_bert_qa_model</span><span>(</span><span>model_name</span><span>=</span><span>"deepset/bert-base-cased-squad2"</span><span>)</span>
    <span>model</span><span>.</span><span>eval</span><span>()</span>
    <span># https://pytorch.org/docs/stable/torch.quantization.html?highlight=torch%20quantization%20quantize_dynamic#torch.quantization.quantize_dynamic
</span>    <span>quantized_model</span> <span>=</span> <span>torch</span><span>.</span><span>quantization</span><span>.</span><span>quantize_dynamic</span><span>(</span><span>model</span><span>,</span> <span>{</span><span>torch</span><span>.</span><span>nn</span><span>.</span><span>Linear</span><span>},</span> <span>dtype</span><span>=</span><span>torch</span><span>.</span><span>qint8</span><span>)</span>

    <span>print</span><span>(</span><span>"="</span> <span>*</span> <span>75</span><span>)</span>
    <span>print</span><span>(</span><span>"Model Sizes"</span><span>)</span>
    <span>print</span><span>(</span><span>"="</span> <span>*</span> <span>75</span><span>)</span>

    <span>model_size</span> <span>=</span> <span>get_model_size</span><span>(</span><span>model</span><span>=</span><span>model</span><span>)</span>
    <span>quantized_model_size</span> <span>=</span> <span>get_model_size</span><span>(</span><span>model</span><span>=</span><span>quantized_model</span><span>)</span>

    <span>print</span><span>(</span><span>"FP32 Model Size: {:.2f} MB"</span><span>.</span><span>format</span><span>(</span><span>model_size</span> <span>/</span> <span>(</span><span>2</span> <span>**</span> <span>20</span><span>)))</span>
    <span>print</span><span>(</span><span>"INT8 Model Size: {:.2f} MB"</span><span>.</span><span>format</span><span>(</span><span>quantized_model_size</span> <span>/</span> <span>(</span><span>2</span> <span>**</span> <span>20</span><span>)))</span>

    <span>question</span> <span>=</span> <span>"What publication printed that the wealthiest 1% have more money than those in the bottom 90%?"</span>

    <span>text</span> <span>=</span> <span>"According to PolitiFact the top 400 richest Americans </span><span>\"</span><span>have more wealth than half of all Americans combined.</span><span>\"</span><span> According to the New York Times on July 22, 2014, the </span><span>\"</span><span>richest 1 percent in the United States now own more wealth than the bottom 90 percent</span><span>\"</span><span>. Inherited wealth may help explain why many Americans who have become rich may have had a </span><span>\"</span><span>substantial head start</span><span>\"</span><span>. In September 2012, according to the Institute for Policy Studies, </span><span>\"</span><span>over 60 percent</span><span>\"</span><span> of the Forbes richest 400 Americans </span><span>\"</span><span>grew up in substantial privilege</span><span>\"</span><span>."</span>

    <span>inputs</span> <span>=</span> <span>prepare_qa_inputs</span><span>(</span><span>question</span><span>=</span><span>question</span><span>,</span> <span>text</span><span>=</span><span>text</span><span>,</span> <span>tokenizer</span><span>=</span><span>tokenizer</span><span>)</span>
    <span>answer</span> <span>=</span> <span>run_qa</span><span>(</span><span>model</span><span>=</span><span>model</span><span>,</span> <span>tokenizer</span><span>=</span><span>tokenizer</span><span>,</span> <span>question</span><span>=</span><span>question</span><span>,</span> <span>text</span><span>=</span><span>text</span><span>)</span>
    <span>answer_quantized</span> <span>=</span> <span>run_qa</span><span>(</span><span>model</span><span>=</span><span>quantized_model</span><span>,</span> <span>tokenizer</span><span>=</span><span>tokenizer</span><span>,</span> <span>question</span><span>=</span><span>question</span><span>,</span> <span>text</span><span>=</span><span>text</span><span>)</span>

    <span>print</span><span>(</span><span>"="</span> <span>*</span> <span>75</span><span>)</span>
    <span>print</span><span>(</span><span>"BERT QA Example"</span><span>)</span>
    <span>print</span><span>(</span><span>"="</span> <span>*</span> <span>75</span><span>)</span>

    <span>print</span><span>(</span><span>"Text: "</span><span>)</span>
    <span>print</span><span>(</span><span>text</span><span>)</span>
    <span>print</span><span>(</span><span>"Question: "</span><span>)</span>
    <span>print</span><span>(</span><span>question</span><span>)</span>
    <span>print</span><span>(</span><span>"Model Answer: "</span><span>)</span>
    <span>print</span><span>(</span><span>answer</span><span>)</span>
    <span>print</span><span>(</span><span>"Dynamic Quantized Model Answer: "</span><span>)</span>
    <span>print</span><span>(</span><span>answer_quantized</span><span>)</span>

    <span>print</span><span>(</span><span>"="</span> <span>*</span> <span>75</span><span>)</span>
    <span>print</span><span>(</span><span>"BERT QA Inference Latencies"</span><span>)</span>
    <span>print</span><span>(</span><span>"="</span> <span>*</span> <span>75</span><span>)</span>

    <span>model_latency</span> <span>=</span> <span>measure_inference_latency</span><span>(</span><span>model</span><span>=</span><span>model</span><span>,</span> <span>inputs</span><span>=</span><span>inputs</span><span>,</span> <span>num_samples</span><span>=</span><span>num_samples</span><span>)</span>
    <span>print</span><span>(</span><span>"CPU Inference Latency: {:.2f} ms / sample"</span><span>.</span><span>format</span><span>(</span><span>model_latency</span> <span>*</span> <span>1000</span><span>))</span>

    <span>quantized_model_latency</span> <span>=</span> <span>measure_inference_latency</span><span>(</span><span>model</span><span>=</span><span>quantized_model</span><span>,</span> <span>inputs</span><span>=</span><span>inputs</span><span>,</span> <span>num_samples</span><span>=</span><span>num_samples</span><span>)</span>
    <span>print</span><span>(</span><span>"Dynamic Quantized CPU Inference Latency: {:.2f} ms / sample"</span><span>.</span><span>format</span><span>(</span><span>quantized_model_latency</span> <span>*</span> <span>1000</span><span>))</span>

    <span>inputs_cuda</span> <span>=</span> <span>move_inputs_to_device</span><span>(</span><span>inputs</span><span>,</span> <span>device</span><span>=</span><span>cuda_device</span><span>)</span>
    <span>model</span><span>.</span><span>to</span><span>(</span><span>cuda_device</span><span>)</span>
    <span>model_cuda_latency</span> <span>=</span> <span>measure_inference_latency</span><span>(</span><span>model</span><span>=</span><span>model</span><span>,</span> <span>inputs</span><span>=</span><span>inputs_cuda</span><span>,</span> <span>num_samples</span><span>=</span><span>num_samples</span><span>)</span>
    <span>print</span><span>(</span><span>"CUDA Inference Latency: {:.2f} ms / sample"</span><span>.</span><span>format</span><span>(</span><span>model_cuda_latency</span> <span>*</span> <span>1000</span><span>))</span>

    <span># No CUDA backend for dynamic quantization in PyTorch 1.7.0
</span>    <span># quantized_model_cuda = quantized_model.to(cuda_device)
</span>    <span># quantized_model_cuda_latency = measure_inference_latency(model=quantized_model_cuda, inputs=inputs_cuda, num_samples=num_samples)
</span>    <span># print("Dynamic Quantized GPU Inference Latency: {:.2f} ms / sample".format(quantized_model_cuda_latency * 1000))
</span>
<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>

    <span>main</span><span>()</span>
</code></pre></div></div>

<p>With PyTorch 1.7.0, we could do dynamic quantization using x86-64 and aarch64 CPUs. However, NVIDIA GPUs have not been supported for PyTorch dynamic quantization yet.</p>

<div><div><pre><code>$ python qa.py 
===========================================================================
Model Sizes
===========================================================================
FP32 Model Size: 411.00 MB
INT8 Model Size: 168.05 MB
===========================================================================
BERT QA Example
===========================================================================
Text: 
According to PolitiFact the top 400 richest Americans "have more wealth than half of all Americans combined." According to the New York Times on July 22, 2014, the "richest 1 percent in the United States now own more wealth than the bottom 90 percent". Inherited wealth may help explain why many Americans who have become rich may have had a "substantial head start". In September 2012, according to the Institute for Policy Studies, "over 60 percent" of the Forbes richest 400 Americans "grew up in substantial privilege".
Question: 
What publication printed that the wealthiest 1% have more money than those in the bottom 90%?
Model Answer: 
New York Times
Dynamic Quantized Model Answer: 
New York Times
===========================================================================
BERT QA Inference Latencies
===========================================================================
CPU Inference Latency: 78.91 ms / sample
Dynamic Quantized CPU Inference Latency: 47.83 ms / sample
CUDA Inference Latency: 10.40 ms / sample
</code></pre></div></div>

<p>We could see that the model size of the INT8 quantized model is much smaller than the FP32 model. The inference latency of INT8 dynamic quantization on CPU is much faster than the FP32 ordinary inference on CPU. However, FP32 inference using NVIDIA GPU is still the fastest.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://github.com/leimao/PyTorch-Dynamic-Quantization">PyTorch Dynamic Quantization</a></li>
  <li><a href="https://leimao.github.io/article/Neural-Networks-Quantization/">Quantization for Neural Networks</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/PyTorch-Dynamic-Quantization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399867</guid>
            <pubDate>Sat, 12 Dec 2020 17:27:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A List of Dialectics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399823">thread link</a>) | @acm46
<br/>
December 12, 2020 | https://animohan.me/writings/list-of-dialectics.html | <a href="https://web.archive.org/web/*/https://animohan.me/writings/list-of-dialectics.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="writing-body-text-short-title">            
            <p><i>"The test of a first-rate intelligence is the ability to hold two opposing ideas in mind at the same time and still retain the ability to function."</i> - F. Scott Fitzgerald
            </p><p>
            Simple rules of thumb are memorable but rarely drive good decisions in a complex world. Instead I prefer dialectics: two seemingly opposing ideas whose union hints at a larger truth.
            </p><p>
            I've collected a few of my favorites below. I often explain them via startups (my world) and business. They're applicable across other domains too.
            </p><p>
            1. <b>Optimism &lt;&gt; Pessimism</b></p><p>
            Startups requires incredible optimism. You must have inordinate conviction that your vision for the business will come to bear. It's the only way to convince yourself, employees, investors, partners, and customers to part with  time and money. But things will likely get really tough. 90% of startups fail. You must remain skeptical you will defy daunting odds. You don't want to waste your (or anyone else's) time working on something that won't succeed.
            </p><p>
            2. <b>Attachment &lt;&gt; Detachment</b></p><p>
            Whether you want to perform the simplest task or achieve the grandest goal, you need to desire a positive outcome. Otherwise, how will you summon the motivation to get out of bed in the morning and do the work? But, the quality of your effort might be irrelevant. Factors beyond your control might dictate the final outcome.  If you get too attached to the fruits of your labor, you're leaving your mood and self-esteem to the whims of chance.
            </p><p>
            3. <b>Explore &lt;&gt; Exploit</b></p><p>
            The world is rich and varied. There's always something new to learn, see, feel, and taste. And you might enjoy those new things more than you've ever enjoyed anything you've experienced. It's impossible to know unless you explore further. But you already have a sense of what you prefer and what you don't. You don't want to waste your precious time on things that won't give you joy. So, you might as well double down on your favorites.
            </p><p>
            4. <b>Macro &lt;&gt; Micro</b></p><p>
            Diving into a quarterly earnings report gives you a macro view of a company. You'll get a sense of things you might model on a spreadsheet: which business units are profitable, which ones are growing, and how much cash is on hand. Spending an hour with the CEO gives you a micro view. You'll get a sense of things you might learn from a magazine profile: what affects the CEO's mood, how the CEO makes decisions, and what are the values that guide the company's priorities.
            </p><p>
            5. <b>Quantitative &lt;&gt; Qualitative</b></p><p>
            Startups force you to build something customers really, really want. Retention is a great measure of this. What % of the customers who use your product this week will use it next week? Measuring retention forces you to be honest with yourself about your product's value. But retention don't tell you why people want your product. Instead, spend 10 minutes speaking with 5 people who've ever tried your product. In under an hour, you'll get fresh ideas for who might want your product and why.
            </p><p>
            6. <b>Long term &lt;&gt; Short term</b></p><p>
            You will likely be around for a long time. Focusing on the long term frees you to prioritize the 20% that matters and disregard the noise of the remaining 80%.&nbsp; Thinking over a long time horizon leads you to value small, boring, compounding benefits. But life is short. The future might never come - it exists only in your imagination. The present is tangible and real. Savor it in as much detail as you can.
            </p><p>
            7. <b>Togetherness &lt;&gt; Solitude</b></p><p>
            What's the use of learning something new, feeling something profound, or making something grand if you can't share it with others? We're social animals, hardwired to crave connection and distinguished by our ability to cooperate with others. But, nobody else can read your mind or feel your emotions, try as they might. Making sense of it all is something you have to do for yourself in your own time.
            </p><p>
            If any of these resonate with you or you have suggestions on others to include, please let me know via <a target="_blank" href="https://twitter.com/ani_c_mohan">Twitter</a> or <a href="mailto:anirudh.c.mohan@gmail.com">email</a>!            
        </p></div></div>]]>
            </description>
            <link>https://animohan.me/writings/list-of-dialectics.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399823</guid>
            <pubDate>Sat, 12 Dec 2020 17:22:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on Compile-Time Function Evaluation and Type Systems]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399809">thread link</a>) | @pcr910303
<br/>
December 12, 2020 | https://www.ralfj.de/blog/2018/07/19/const.html | <a href="https://web.archive.org/web/*/https://www.ralfj.de/blog/2018/07/19/const.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="-content">
      <header>
    
    
</header>

<p>For some time now (since the 1.26 release, to be precise), Rust has a <a href="https://github.com/rust-lang/rust/pull/46882">very powerful machinery for CTFE</a>, or compile-time function evaluation.
Since then, there have been various discussions about which operations should be allowed during CTFE, which checks the compiler should do, how this all relates to promotion and which kinds of guarantees we should be able to expect around CTFE.
This post is my take on those topics, and it should not be surprising that I am going to take a very type-system centric view.
Expect something like a structured brain dump, so there are some unanswered questions towards the end as well.</p>

<!-- MORE -->

<h2 id="some-background">Some Background</h2>

<p>CTFE is the mechanism used by the compiler, primarily, to evaluate items like <code>const x: T = ...;</code>.
The <code>...</code> here is going to be Rust code that must be “run” at compile-time, because it can be used as a constant in the code – for example, it can be used for array lengths.</p>

<p>Notice that CTFE is <em>not</em> the same as constant propagation: Constant propagation is an optimization pass done by compilers like LLVM that will opportunistically change code like <code>3 + 4</code> into <code>7</code> to avoid run-time work.
Being an optimization, constant propagation must, by definition, not change program behavior and will not be observable at all (other than performance).
CTFE, on the other hand, is about code that <em>must</em> be executed at compile-time because the compiler needs to know its result to proceed – for example, it needs to know the size of an array to compute how to lay out data in memory.
You can statically see, just from the syntax of the code, whether CTFE applies to some piece of code or not:
CTFE is only used in places like the value of a <code>const</code> or the length of an array.</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>demo</span><span>()</span> <span>{</span>
  <span>const</span> <span>X</span><span>:</span> <span>u32</span> <span>=</span> <span>3</span> <span>+</span> <span>4</span><span>;</span> <span>// CTFE</span>
  <span>let</span> <span>x</span><span>:</span> <span>u32</span> <span>=</span> <span>4</span> <span>+</span> <span>3</span><span>;</span> <span>// no CTFE (but maybe constant propagation)</span>
<span>}</span></code></pre></figure>

<p>We say that the <code>3 + 4</code> above is in <em>const context</em> and hence subject to CTFE, but the <code>4 + 3</code> is not.</p>

<h2 id="const-safety">Const Safety</h2>

<p>Not all operations can be used in const context.
For example, it makes no sense to compute your array length as “please go read that file from disk and compute something” – we can’t know what will be on the disk when the program actually runs.
We could use the disk of the machine compiling the program, but that does not sound very appealing either.
Things get even worse when you consider letting the program send information to the network.
Clearly, we don’t want CTFE to have actually observable side-effects outside of compilation.</p>

<p>In fact, just naively letting programs read files would also be grossly unsafe:
When computing the length of an array twice, it is important that we obtain the same result.
<strong>Update:</strong> As @eddyb points out, things get even worse once you consider const generics, traits, and coherence: At that point, you have to <a href="https://internals.rust-lang.org/t/mir-constant-evaluation/3143/47">rely on evaluating the same expression in different crates to produce the same result</a>. <strong>/Update</strong></p>

<blockquote>
  <p><em>CTFE must be deterministic.</em></p>
</blockquote>

<p>If not, the compiler could end up thinking that two arrays have the same length, but then later compute different layouts.
That would be a disaster.
So, any kind of external input and any kind of non-determinism is a complete no-go for CTFE.
This does not just concern I/O, even converting a reference to a <code>usize</code> is not deterministic.</p>

<p>The compiler will throw a CTFE error if such an operation is ever attempted to be executed.
Those programs that <em>are</em> executable in const context are called <em>const safe</em>:</p>

<blockquote>
  <p><em>A program is const safe if it can be executed by CTFE without hitting an error (panics are allowed).</em></p>
</blockquote>

<p>This is very much in analogy with the idea that a <em>safe</em> (or <em>run-time safe</em>, to distinguish it from const safe) program is a program that does not cause any memory errors or data races.
In fact, we will see that this analogy between “programs that are well-behaved under CTFE” (const safety) and “programs that do not cause UB” (run-time safety) can carry us very far.</p>

<p>One very interesting question now is whether some given function <code>foo</code> should be allowed to be called in const context.
We could just always say “yes”, and rely on the fact that CTFE will throw an error when <code>foo</code> does anything fishy.
The problem with this approach is that, if <code>foo</code> is in a library, updating the library might change <code>foo</code> in a way that makes it no longer const-safe.
In other words, making <em>any</em> function not const-safe any more would be a semver violation because it could break downstream crates.</p>

<p>The typical mechanism to solve that problem is to have an annotation that explicitly marks a function as “usable in const context”.
In Rust, the proposed mechanism for this purpose is <a href="https://github.com/rust-lang/rust/issues/24111"><code>const fn</code></a>; in C++ it is called <code>constexpr</code>.
The compiler can now reject calling non-<code>const</code> functions in const context, so library authors can add non-const-safe operations without breaking semver.</p>

<h2 id="const-type-system-and-const-soundness">Const Type System and Const Soundness</h2>

<p>This leads us to the interesting situation that the compiler will reject code in const context that it would accept just fine outside of const context.
In particular, the body of a <code>const fn</code> is <em>also</em> considered to be in const context – otherwise, if we allowed calling arbitrary functions, we would have the same problem again.
One useful way to think about this is that we have a second type system, a “const type system”, that is used to type-check code in const context.
This type system does not allow calls to non-<code>const</code> functions.</p>

<p>It should probably also not allow casting a reference to an integer, because (as discussed above) that is a non-deterministic operation which cannot be performed during CTFE.
What else?</p>

<p>Before we go on and add random additional checks, let us step back and think about what our goals are here.
Typically, the purpose of a type system is to establish some sort of guarantee for a well-typed program.
For Rust’s “main” (“run-time”) type system, that guarantee is “no undefined behavior”, which means no memory errors and no data races.
What is the guarantee for our new const type system?
We have already talked about it above: It’s const safety!
This leads us to the definition of const soundness:</p>

<blockquote>
  <p><em>Our const type system is sound if well-typed programs are const-safe.</em></p>
</blockquote>

<p>Again, notice how this is very similar to the correctness statement for the run-time type system, which guarantees run-time safety.</p>

<p>However, we have to be a bit careful here.
Consider the following piece of code:</p>

<figure><pre><code data-lang="rust"><span>const</span> <span>fn</span> <span>is_eight_mod_256</span><span>(</span><span>x</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>bool</span> <span>{</span> <span>x</span> <span>%</span> <span>256</span> <span>==</span> <span>8</span> <span>}</span></code></pre></figure>

<p>We will definitely want to allow this code.
Why should <code>==</code> or <code>%</code> not be const-safe?
Well, we could call our function as follows:</p>

<figure><pre><code data-lang="rust"><span>is_eight_mod_256</span><span>(</span><span>Box</span><span>::</span><span>into_raw</span><span>(</span><span>Box</span><span>::</span><span>new</span><span>(</span><span>0</span><span>))</span> <span>as</span> <span>usize</span><span>);</span></code></pre></figure>

<p>That statement is certainly <em>not</em> const-safe as the result depends on where exactly the allocator puts our <a href="https://doc.rust-lang.org/stable/std/boxed/struct.Box.html"><code>Box</code></a>.
However, we want to blame the <code>as usize</code> for this issue, not the <code>is_eight_mod_256</code>.</p>

<p>The solution is for the const type system to not just have separate rules about which operations are allowed, we also must change our notion of which values are “valid” for a given type.
An integer obtained from a pointer is valid for <code>usize</code> at run-time, but it is <em>not</em> valid for <code>usize</code> in const mode!
After all, there are basic arithmetic operations that we expect all <code>usize</code> to support, that CTFE cannot support for pointers.</p>

<blockquote>
  <p><em>A function is const-safe if, when executed with const-valid arguments, it does not trigger a CTFE error and returns a const-valid result (if it returns at all).</em></p>
</blockquote>

<p>Under this definition, <code>is_eight_mod_256</code> is const-safe because whenever <code>x</code> is an actual integer, it will evaluate without any error.
At the same time, this shows that converting a reference into <code>usize</code> is <em>not</em> const-safe, because the input of this operation is const-valid, but the output is not!
This provides a solid justification for rejecting such casts in const context.</p>

<h2 id="ctfe-correctness">CTFE correctness</h2>

<p>In Rust, CTFE is performed by miri, a MIR interpreter that used to be a <a href="https://github.com/solson/miri/">separate project</a> but whose core engine has been integrated into rustc.
miri will execute the code in const context step-by-step and just complain and fail with an error when an operation cannot be performed.
This does not just concern non-determinism; miri does not support everything it could support because @oli-obk is <a href="https://github.com/rust-lang/rust/blob/5ba21844f6c85a0cd55c8ea0250d5cd758134f84/src/librustc_mir/interpret/const_eval.rs#L199">super careful</a> about not accidentally stabilizing behavior that should undergo an RFC.</p>

<p>In fact, right now miri will reject all operations on raw pointers.
They all raise a CTFE error and hence must all be rejected by the const type system.
The plan is to change miri so that it can support more operations, but we have to be careful in doing so.
I have already mentioned that miri must be deterministic, but there is another point to consider that you might have expected to play a much more prominent role:
CTFE, at least if it succeeds, should match run-time behavior!</p>

<blockquote>
  <p><em>CTFE is correct if, when it loops forever, completes with a result, or panics, that behavior matches the run-time behavior of the same code.</em></p>
</blockquote>

<p>We clearly do not want code to behave differently when it lives in const context and is run by CTFE, and when it is compiled to machine-code and executed “for real”.</p>

<p>Or, do we?
Don’t get me wrong, I am not advocating for deliberately breaking that property, but it sure is worth considering what would go wrong if miri was <em>not</em> CTFE-correct.
Maybe surprisingly, it turns out that this would not be a soundness issue!
All we care about for the purpose of soundness is for CTFE to be deterministic, as already discussed.
We don’t re-run the same code at run-time and rely on it still doing the same, so nothing actually breaks if CTFE behavior diverges from run-time behavior.</p>

<p>That said, not being CTFE correct is surely very surprising and we should avoid it best we can.
However, I am told that actually predicting the result of floating-point operations deterministically <a href="https://gafferongames.com/post/floating_point_determinism/">is extremely hard</a> and <a href="https://github.com/rust-lang/rust/issues/24111#issuecomment-386765720">LLVM isn’t exactly helping</a>.
So, we will likely have to live with either considering floating point operations to be const-unsafe (raising a CTFE error), or not having CTFE correctness when floating point operations are …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ralfj.de/blog/2018/07/19/const.html">https://www.ralfj.de/blog/2018/07/19/const.html</a></em></p>]]>
            </description>
            <link>https://www.ralfj.de/blog/2018/07/19/const.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399809</guid>
            <pubDate>Sat, 12 Dec 2020 17:21:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Certificate Pinning with OkHttp]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399728">thread link</a>) | @palebt
<br/>
December 12, 2020 | https://www.rockandnull.com/certificate-pinning-android/ | <a href="https://web.archive.org/web/*/https://www.rockandnull.com/certificate-pinning-android/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>If your app is doing something relatively complicated, it will likely need a server to communicate with.</p><p>The basic step for ensuring secure communication with the server is well known: use HTTPS. What's lesser-known in secure app-server communication, is the certificate pinning. Not all apps will need this, but apps that transfer sensitive data from the app to the server might benefit from one additional security clause.</p><p>In short, certificate pinning ensures that your app will only connect to a server that has a specific certificate, not just a valid certificate. By default, when you connect to your server with HTTPS you require the server to have a valid certificate for the connected domain. This opens the window of man-in-the-middle attacks that some bad actor might pose to be your server to see the data you are sending. This is not the simplest thing to do (since the attacker will require to have a valid certificate as well) but is doable.</p><h2 id="do-you-need-certificate-pinning">Do you need certificate pinning?</h2><p>I don't think all apps need to implement certificate pinning. Only if your app is sending sensitive data to your server (e.g. credit card numbers) you should consider this. Why not everyone? Because it's adding some maintenance cost. Certificates expire and you will need to update the app with the new certificate that should be trusted when this happens. If you are fine with this maintenance cost, sure go ahead and implement it even if you are not the most "sensitive" app out there.</p><h2 id="ok-i-am-using-okhttp-how-do-i-do-it">Ok, I am using OkHttp. How do I do it?</h2><p>It's quite simple actually. Modify the <a href="https://square.github.io/okhttp/">OkHttp</a> client builder as follow.</p><pre><code>val client = OkHttpClient()
    .newBuilder().certificatePinner(
        certificatePinner = CertificatePinner.Builder()
            .add("example.com",
            "sha256/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=")
            .build()
        ).build()</code></pre><p>Run your app and make a network call with this client. Search your logs for something similar to this.</p><pre><code>javax.net.ssl.SSLPeerUnverifiedException: Certificate pinning failure!
    Peer certificate chain: 
        sha256/BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB
        sha256/CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
        sha256/DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD</code></pre><p>Replace the client code above to include the actual signatures of your certificate. You are done! Your app will only connect using HTTPS to your server and refuse to connect if it fails to detect your own certificate.</p><pre><code>val client = OkHttpClient()
    .newBuilder().certificatePinner(
        certificatePinner = CertificatePinner.Builder()
            .add("example.com", "sha256/BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB")
            .add("example.com", "sha256/CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC")
            .add("example.com", "sha256/DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD")
            .build()
        ).build()</code></pre><p>Might be a good idea to repeat this process for a backup domain. This way, if one of your domain certificates expires, you app can use the other one until you update the app.</p><p>If you want to pin all the subdomains of your domain, check the <a href="https://square.github.io/okhttp/4.x/okhttp/okhttp3/-certificate-pinner/#domain-patterns">official doc</a>.</p><p>Don't forget that this is not "unhackable". A bad actor might modify your app and change these hashes. But still, it requires significantly more effort to do this. There's nothing "unhackable" anyway, we just add as many protective measures as possible to keep bad actors away.</p><h2 id="what-if-i-don-t-use-okhttp">What if I don't use OkHttp?</h2><p>It's slightly more complicated but here's the official doc (<a href="https://developer.android.com/training/articles/security-ssl#Pinning">1</a>, <a href="https://developer.android.com/training/articles/security-ssl">2</a>) on how to do this. There are also countless blog posts one search away.</p><p>Happy coding!</p>
			</section></div>]]>
            </description>
            <link>https://www.rockandnull.com/certificate-pinning-android/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399728</guid>
            <pubDate>Sat, 12 Dec 2020 17:12:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust, Python and Fish]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399709">thread link</a>) | @onidaito
<br/>
December 12, 2020 | https://benjamin.computer/posts/2020-12-12-rust-python.html | <a href="https://web.archive.org/web/*/https://benjamin.computer/posts/2020-12-12-rust-python.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

	<a href="https://benjamin.computer/"><img src="https://benjamin.computer/images/bcpu_04_flat.png" alt="benjamin.computer"></a>
  
	<ul>
	<li><a href="https://benjamin.computer/about.html">ABOUT</a></li>
  	<li><a href="http://eepurl.com/haZQoT">MAILING LIST</a></li>
	<li><a href="https://benjamin.computer/atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide Atom feed">RSS</a></li>
	<li><a href="https://mastodon.social/web/accounts/220949">MASTODON</a></li>
	<li><a href="https://www.github.com/onidaito">GITHUB</a></li>
	<li><a href="mailto:me@benjamin.computer">EMAIL</a></li>
	</ul>
 

<hr>

<p><h2>Rust, Python and Fish</h2></p> 
<em>12-12-2020</em> 
<p><em>Quick reminder! You can get my posts fresh in your inbox if you join the mailing list</em> <a href="http://eepurl.com/haZQoT">here</a></p>
<p>I'm telling a little bit of a lie here really. When I say fish, I really mean <a href="https://en.wikipedia.org/wiki/Poisson_distribution">poisson</a> and when I say poisson I really mean <a href="https://www.jasondavies.com/poisson-disc/">Poisson Disc Sampling</a>. Turns out, Poisson disc sampling is really useful in my A.I research. Problem is, it's not the fastest process in the world, particularly when python is involved. So what can we do? Turns out there are lots of options - investigating them has been fun and might be useful for other folks working in this area.</p>
<h3>Fish Discs</h3>
<p>Poisson Disc sampling is a method for creating <em>pleasing</em> random patterns, or rather, random distributions with a somewhat regular spacing. Take a look at the image below and you'll see what I mean.</p>
<figure><img src="https://shutr.benjamin.computer/inpost/poisson.png" alt="Poisson Sample"><figcaption>Random sampling vs. Poisson Sampling <a href="https://medium.com/@hemalatha.psna/implementation-of-poisson-disc-sampling-in-javascript-17665e406ce1">(image courtesy of this lovely writeup)</a></figcaption></figure>

<p>I believe the name comes from the <a href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson Distribution</a> - I'm not really sure to be honest. How I understand the algorithm is you start with one point and then add another within a circle or sphere of a set distance away with an increasing probability towards the boundary. The idea is to maintain a minimum distance from one point to any other point. This leads to a bit of a problem though as it's quite computationally expensive to check each additional point against all other points. There have been a few attempts to speed things up. I settled on <a href="http://www.cemyuksel.com/research/sampleelimination/">Sample Elimination for Generating Poisson Disk Sample Sets algorithm by Cem Yuksel</a>. This algorithm works by creating a large random set first, then removing points from the set until the Poisson property is - more or less - obtained. It relies on two data-structures - the <a href="https://en.wikipedia.org/wiki/K-d_tree">kdtree</a> and the <a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">heap</a>. </p>
<p>Sample elimination assigns weights to each point, adding them to the heap as we go. We then take a point off the heap, finding all these points nearest to this point using the tree. With this point removed, we rebuild the heap using the weight formula, and go again, until we arrive at the number of point we want. In my tests, one needs roughly 8 time the number of points you want in order to get a good final result.</p>
<h3>Python</h3>
<p>I'm a tad bored of Python; it tends to dominate the AI world at the moment. I believe there are a few other languages people can use but the vast majority of code seems to be in Python. It has some advantages - it's fairly easy to get into and works on most platforms, but like all interpreted languages, there is a bit of an overhead. <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/performance/nbody.html">Python performance has improved over the years</a> but it still isn't top. However, the first place to start in speeding up your code is to take a look at how you've built the algorithm. </p>
<p>Firstly, I removed many of the <em>sqrt()</em> calls, as we merely want to order the points in the sample rather than record the actual distances. This seemed to have some effect on performance though not as much as I'd thought. </p>
<p>One thing we can do is measure where our code is taking the most time. Python has a number of profilers such as <a href="https://docs.python.org/3/library/profile.html">cprofile</a> and <a href="https://github.com/nvdv/vprof">vprof</a> to name a couple. They are quite easy to use too. Once I measured where my program was spending it's time, I decided I needed to remove numpy from the equation and work with some simpler datatypes, reducing any unnecessary conversions. Around this time, I was made aware of a package called <a href="https://numba.pydata.org/">numba</a>. </p>
<h3>numba</h3>
<p>I thought I'd ask around to see what other people were doing to speed up their scientific code. What better place to start than the <a href="https://society-rse.org/">UK Research Software Engineering group</a>. I quickly received the answer I was looking for - some software called <a href="https://numba.pydata.org/">numba</a>.</p>
<p>Numba is a <a href="https://en.wikipedia.org/wiki/Just-in-time_compilation">JIT  -Just in Time Compiler</a> that aims to speedup certain python functions. Certain parts of python and numpy can be compiled down into a faster code blob. One need only decorate the function in question and replace a few types and <em>Boom!</em> - faster code.</p>
<p>In practice, it's a little more tricky than that. One needs to do a little conversion from complicated to more simple types that numba can handle, but this isn't too onerous. </p>
<h3>Rust</h3>
<p>I've <a href="https://benjamin.computer/posts/2019-07-31-rust-research.html">spoken before about Rust</a> and how I enjoy writing code with it. I spotted <a href="https://www.nature.com/articles/d41586-020-03382-2">an article recently about how scientists are moving to rust</a>. Rust's popularity among programmers is quite well known. I think this is partially because it's a hard language to learn initially and requires some knowledge of the machine, data-types, borrowing and the like. It certainly strokes your programmer ego, which isn't such a bad thing if kept in check. I certainly feel a sense of accomplishment when I write working code in Rust - something I never really get in Python. It definitely takes longer to write Rust code than Python, but it <em>feels</em> better and runs faster. The code seems tighter, leaner with fewer bugs and more tests (I think tests are easier to write in Rust than in any other language). It's become my goto for writing any performant code.</p>
<p>I rewrote the algorithm for Poisson Disc Sampling in Rust and received a reasonable amount of speedup over numba. Not a lot mind you, which was a surprise, but enough to keep going and see how far I could push it. </p>
<h3>Going parallel</h3>
<p>One of the easy wins for speed is to parallelise your code. In Python, I've always found this to be more difficult than it should be. I also think Rust could do better in this regard. In the past, Rust used to have the <em>scoped</em> keyword that helped in determining how long variables would live for in each individual thread. This was removed some time ago however, which was a bit of a pain. Now, if we want to do work with threads, it's somewhat tricky - even the simple pattern of <a href="https://en.wikipedia.org/wiki/Fork%E2%80%93join_model">fork-join</a>. Not exactly living up to Rust's touted 'fearless concurrency' I think.</p>
<p>Fork-Join, or divide and conquer is a really simple approach to parallelising your code. Divide up the dataset, work on each bit individually and once all the threads are done, combine the results together. Simple right? Well, perhaps not as simple as you might think.</p>
<p>Rust's main strength and it's main barrier to understanding is the borrowing mechanism it works on. Variables have lifetimes and are owned by parts of the program. Threads and concurrency mess with this sort of thing a lot. I mean, can you guarantee that a thread will stop before the code that called it ends? What happens to a shared variable, particularly something like a vector that can be modified at any time by multiple processes? It is a tricky thing to have to write yourself, made more difficult as there are a lot of options in Rust, many of which are not built in as standard. </p>
<p>Having written the fork-join algorithm a couple of times, I've found a way that I think works quite well. I used the <a href="http://kimundi.github.io/scoped-threadpool-rs/scoped_threadpool/index.html">scoped-threadpool</a> crate and some <a href="https://doc.rust-lang.org/std/sync/struct.Mutex.html">mutexes</a>. I've tried things like <a href="https://doc.rust-lang.org/std/cell/">Cells</a>, <a href="https://doc.rust-lang.org/std/sync/struct.Arc.html">Arcs</a> and a whole manner of oddly named libraries but this method seems to be the simplest:</p>
 <pre><code>let rsamples :Mutex&lt;Vec&lt;Quat&gt;&gt; = Mutex::new(vec!());
let rpoints : Mutex&lt;Vec&lt;Quat&gt;&gt; = Mutex::new(vec!());

let mut pool = Pool::new(partitions as u32);
pool.scoped(|scoped| {

    for i in 0..partitions {
        let bsamples = &amp;rsamples;
        let bpoints = &amp;rpoints;

        scoped.execute( move || {
            let ns : usize = sample_size / partitions;
            let mut tpoints : Vec&lt;Quat&gt; = vec!();
            for p in points.iter() {
                let aa = p.axis_angle();
                // DO ALL THE WORK HERE
            }
            //println!("{}, {}", i, tpoints.len() );
            let trval = sample(&amp;tpoints, ns);
            for q in trval.0.iter() {
                let mut t = bsamples.lock().unwrap();
                t.push(*q);
            }
            for q in trval.1.iter() {
                let mut t = bpoints.lock().unwrap();
                t.push(*q);
            }
        });
    }
    scoped.join_all();
});

(rsamples.into_inner().unwrap(), rpoints.into_inner().unwrap())
</code></pre> 
<p>Like so many things in life, when you figure it out, it becomes quite simple. There are many crates out there that provide fancy options for Rust concurrency but scoped-threadpool is simple enough. We create a pool first, then call <em>scoped.execute</em> as many times for as many threads as we want, using the <em>move</em> keyword to move our variables into the scope of each thread. The key here is we are moving in a reference to our shared vectors at the top of the code, so each thread can access the vectors. By wrapping the vector in a mutex we guarantee it can only be accessed by one thread at a time. This is quite similar to how we tend to write this sort of algorithm in languages like C++. Sometimes, it can be easy to be distracted by the fancy crates and syntax rust offers, but the basics are still there doing a good job.  </p>
<p>Parallelising the Poisson Disc algorithm is not without it's problems. Dividing up the space into equal chunks and performing the sampling on each chunk works <em>a bit</em>, but it one isn't careful, you can get some bad artefacts. Consider a chunk where there are a large number of samples - say 1000 - and you only want 2 points. Typically, these points will be close to the border of the space in question, which makes sense if you want to maximise the distance between all the points in your sample. However, when you combine these chunks, you get a pattern where the points all lie along the <em>joins</em> of the areas. Not ideal. </p>
<p>This basically means we can only go so far with parallelising the algorithm to get some speed up. Still, it's better than nothing. </p>
<h3>Talking to Python</h3>
<p>So Rust and threading gets us to <em>good-enough</em> performance. Now how do we get rust to talk to Python? There are a few ways, including writing results to a file and having python read it, but perhaps there's a better way? Asking around on the UKRSE group again, a few folks suggested <a href="https://docs.python.org/3/library/ctypes.html">ctypes</a>, but I decided to go with <a href="https://github.com/PyO3/PyO3">PyO3</a>. PyO3 works in both directions - either calling Rust from Python or vice-versa. In my case I want to call Rust from Python, sending some simple data in, and getting a load of points back. </p>
<p>In order to do this, we …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benjamin.computer/posts/2020-12-12-rust-python.html">https://benjamin.computer/posts/2020-12-12-rust-python.html</a></em></p>]]>
            </description>
            <link>https://benjamin.computer/posts/2020-12-12-rust-python.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399709</guid>
            <pubDate>Sat, 12 Dec 2020 17:09:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The better the chess player is the fewer captures per move they make]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25399690">thread link</a>) | @pkacprzak
<br/>
December 12, 2020 | https://blog.chessvision.ai/average-captures-per-move-by-elo/ | <a href="https://web.archive.org/web/*/https://blog.chessvision.ai/average-captures-per-move-by-elo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          

  <p>
    

    

    
      
      

      <span>
        
        
          2 minute read
        
      </span>
    
  </p>


        </header>
      

      <section itemprop="text">
        
        <p>Often when watching chess video lectures, I hear the advice of not capturing the opponent’s piece in favor of putting more pressure, for example, to get a more decisive attack. Also, often we hear the phrase:</p>

<blockquote>
  <p><strong>When you see a good move, look for a better one</strong></p>
</blockquote>

<p>and sometimes this good move can be a capture, but the better move is not a capture. The simplest example is probably going for a checkmate attack and ignore the opponent’s hanging Queen.</p>

<p>Having these ideas, I thought that we can try to form a <strong>hypothesis</strong>:</p>

<blockquote>
  <p><strong>The better the player is the fewer captures per move on average they make</strong></p>
</blockquote>

<p>Let’s see if we can prove it using real data.</p>

<h2 id="data-source">Data source</h2>

<p>Our data source is <a href="https://database.lichess.org/">Lichess game database</a>, specifically games played in October 2020 on Lichess. In order to have a more representative sample, we discard bullet games, and we take a sample of 2M remaining games. Next, we remove Elo outliers - in this case, the remaining players have Elo ranging from 1000 up to 2650.</p>

<h2 id="source-code">Source code</h2>
<p>The complete source code for this experiment in the notebook form is available here: <a href="https://github.com/chessvision-ai/average-number-of-captures-by-elo">https://github.com/chessvision-ai/average-number-of-captures-by-elo</a></p>

<h2 id="results">Results</h2>

<p>The plot  generated by the provided source code:</p>

<p><a href="https://blog.chessvision.ai/assets/images/average_captures_by_elo/plot.png"><img src="https://blog.chessvision.ai/assets/images/average_captures_by_elo/plot.png" alt="Average number of captures per move by Elo rating"></a></p>

<h2 id="observations">Observations</h2>

<ul>
  <li>
    <p>We can observe that the average number of captures per move is negatively correlated with Elo of the players. This is a great result as the common wisdom is now backed up by real data</p>
  </li>
  <li>
    <p>Also, what is probably even more important, is the fact that the average number of captures per move in a game, when averaged over many games, can be potentially used as an accurate and very simplistic estimator of a player’s Elo. There are researches about estimating players’ Elo from games they play and most methods use significantly more computationally intensive methods, e.g. <strong>average centipawn loss</strong>, which is Average is the difference of player’s move to the best computer move averaged over all moves. In the case of this new <strong>average-captures-per-move</strong> metric, computing it is as simple as going through all the moves made in a game and counting how many were captures, so it’s as optimal it could be.</p>
  </li>
</ul>

        
      </section>

      

      


      
  

    </div></div>]]>
            </description>
            <link>https://blog.chessvision.ai/average-captures-per-move-by-elo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399690</guid>
            <pubDate>Sat, 12 Dec 2020 17:07:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof of Rubys Superiority over Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25399625">thread link</a>) | @connerj
<br/>
December 12, 2020 | https://www.connerjensen.com/blog/ruby-code-examples | <a href="https://web.archive.org/web/*/https://www.connerjensen.com/blog/ruby-code-examples">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>In this post I will prove that Ruby is better than Python.</h3>
<p>.
<br>
.
<br>
.
<br>
.</p>
<p>Just kidding. <strong>I'm going to show off some cool Ruby code examples</strong>, then compare and contrast them with the same examples done in Python.</p>
<p>The reason behind this post is to have some fun comparing the two languages and to show off some of my favorite examples of Ruby's expressivness and power.</p>
<p>You may not agree with some of the examples, and might think they are difficult to understand, sub optimal, or just plain ugly.</p>
<p>That is completely understandable.</p>
<p>Let's get started with a little example of opening a file and reading it line by line.</p>
<h4>Opening and reading files by line</h4>

<p><strong>Ruby Code Example</strong></p>
<pre><code>file = File.open('example.txt').read

file.each_line do |line|
    puts line
end
</code></pre>
<p>I enjoy how simple it is to open and read text files in Ruby. The fact that Ruby has a built in <code>each_line</code> method on the <code>String</code> object speaks to how the Ruby language wants to make developers <a href="https://www.artima.com/intv/ruby.html">happy</a> by taking care of the little things for them.</p>
<blockquote>Programmers often feel joy when they can concentrate on the creative side of programming, So Ruby is designed to make programmers happy. -<b>Yukihiro Matsumoto</b> (Creator of Ruby)
</blockquote>
<p><strong>Python Code Example</strong></p>
<pre><code>file = open('example.txt', 'r') 
lines = file.readlines() 

for line in lines: 
    print(line.strip())
</code></pre>
<p>This example seems fine too. However, I don't like how one has to specify 'r' as the second parameter to <code>open</code> and how one needs to call <code>strip()</code> on each line.</p>
<p>These examples are both four lines long and they are simple enough, but I prefer the Ruby example. The way it reads is not only clearer, but there are less details for the programmer to remember.</p>
<p>Looking at the ruby example it feels very much like english. There is no remembering to specify an 'r' as the second parameter to <code>open</code>, and no need to call <code>strip()</code> on each line.</p>
<p><strong>I'd imagine that someone who knew neither Ruby or Python would have an easier time understanding the Ruby code example.</strong></p>
<p>The differences between these examples may seem small, but the way a language handles the small stuff can often times shed light on how things are handled in the language as a whole.</p>
<p>Ok, on to the next example.</p>
<h4>Returning early from a function/method</h4>
<p><strong>Ruby Code Example</strong></p>
<pre><code>def example_method(x, y)
    return if x == 7
    return unless y == 10

    x + y
end
</code></pre>
<p>One of my favorite features of Ruby is the unless keyword. It's the same as a <code>!=</code> but I think it makes the code not only look nicer, but also easier to read.</p>
<p><strong>Python Code Example</strong></p>
<pre><code>def example_method(x, y):
    if x == 7:
        return
    if y != 10:
        return

    return x + y
</code></pre>
<p>This Python example is completely fine, but I don't think it has the succinctness and character that the Ruby example has.</p>
<p>My eye much prefers the Ruby examples. It seems so clean and neat, with the return on the same line as the conditional check. The assumed return at the end of the Ruby example is also very pleasing and puts all the focus on the actual "logic" that's being preformed.</p>
<p>However, I do like how Python methods do not need an <code>end</code>, this not only makes them shorter but cleans up nested methods, functions, and classes.</p>
<h4>Defining a class with a constructor method</h4>

<p><strong>Ruby Code Example</strong></p>
<pre><code>class ExampleClass
    def initialize(a, b)
        @a, @b = a, b
    end
end

ec = ExampleClass.new(1,2)
</code></pre>
<p>In this example, I like how there is no need to pass in a reference to the object being constructed. I also think the ruby syntax of using an @ sign to denote an instance variable looks clean and reads well.</p>
<p>One thing I don't like about Ruby is how you must use the <strong>new</strong> method on the class to instantiate an object. I much prefer using just the class name, like Python does (ExampleClass()).</p>
<p><strong>Python Code Example</strong></p>
<pre><code>class ExampleClass: 
    def __init__(self, a, b): 
        self.a, self.b = a, b

ec = ExampleClass(1,2)
</code></pre>
<p>As I said above I prefer how you instantiate an object with Python, because there is no need for the <strong>new</strong> keyword.</p>
<p>I don't enjoy the name of either Ruby's or Python's constructor. In Ruby, the word initialize is difficult to type and I don't like how it is not abbreviated in any way. In Python the "dunders" (__) are unsightly, however they do make it easy to see the constructor while scanning lines of code.</p>
<p><strong>Overall, I like Ruby's constructor better, mainly because of the lack of selfs scattered all over the place.</strong></p>
<h4>Error Handling</h4>

<p><strong>Ruby Code Example</strong> </p>
<pre><code>begin
    1 + 2
    raise 'EXCEPTION'
rescue StandardError =&gt; e
    puts "An exception #{e} was raised"
end
</code></pre>
<p>This is pretty a pretty standard try catch block, but there are some cool things you can do with Ruby error handling, such as omitting the begin block in a method.</p>
<pre><code>def method_that_raises_exception
    raise 'EXCEPTION'
rescue StandardError =&gt; e
    puts "An exception #{e} was raised"
end
</code></pre>
<p>I quite like this syntax as I think it cleans up the method body and makes it clear where exception handling code begins and the "real" body of the function ends.</p>
<p><strong>Python Code Example</strong></p>
<pre><code>try:
    1 + 1
    raise Exception("EXCEPION")
except Exception as e:
    print(e)
</code></pre>
<p>I prefer the arrow syntax (=&gt;) Ruby uses to give the exception a name over Python's use of as. I also like how in Ruby you can raise a StandardError by just saying <code>raise 'What you want your exception to say'</code> without having to specify the error class. </p>
<p>The keywords of begin/rescue also flow better than try/except and the intent would be clearer to the naive reader.</p>
<h4>Conclusion</h4>
<p>Hopefully you found these Ruby code example and Pyton code example comparisons useful. </p>
<p>I did not intend to offend anyone who prefers Python, I mearly wanted to demonstrate the expressiveness and power of the Ruby programming language. </p>
<p>I think Ruby does the small things well, and gives programmers the tools to write code that makes the most sense for their specific situations.</p>
<p>If you are interested in learning more about Ruby I highly recommend checking out this <a href="https://www.connerjensen.com/blog/the_ruby_programming_language_review">book</a>.</p>
<p>Thank you very much for reading, feel free to leave a comment or reach out to me via email or twitter.</p></div></div>]]>
            </description>
            <link>https://www.connerjensen.com/blog/ruby-code-examples</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399625</guid>
            <pubDate>Sat, 12 Dec 2020 17:00:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minecraft speedrunning team catch top runner as cheater via statistical analysis [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25399567">thread link</a>) | @torranceyang
<br/>
December 12, 2020 | https://mcspeedrun.com/dream.pdf | <a href="https://web.archive.org/web/*/https://mcspeedrun.com/dream.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mcspeedrun.com/dream.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399567</guid>
            <pubDate>Sat, 12 Dec 2020 16:55:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unlimited Is a Ponzi Scheme]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399344">thread link</a>) | @svmanager
<br/>
December 12, 2020 | https://staysaasy.com/product/2020/12/12/unlimitted.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/product/2020/12/12/unlimitted.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Recently Google Photos ended their unlimited storage. You shouldn’t have been shocked, because unlimited is more often than not an unsustainable Ponzi Scheme.</p>

<h2 id="good-at-business">Good at Business</h2>

<p>When a software company gives you unlimited storage for anything, the only way for them to maintain that business in the long run is for them to make (amortized or not) incremental and recurring money from each thing they store. This is true, because storage is a recurring and forever cost.</p>

<p>Most B2C companies don’t make recurring money off of the data they store for you. They make money inversely proportional to how recent you stored the thing. Sometimes they don’t make any money at all. So it’s no surprise that unlimited is a Ponzi scheme, because that’s the only way to make the ledger look right.</p>

<h2 id="the-unlimited-ponzi-scheme">The Unlimited Ponzi Scheme</h2>

<p>Businesses will often follow a Ponzi Scheme-esque model with storage for their product. As they go through growth, newer customers are instantly delivering new revenue while their cost is very little - they haven’t started accruing much data. These customers offset older customers, who are getting more expensive as data retention continues forever.</p>

<p>Then, one day, the growth stops. You’ve gained most of the market you’re going to gain.  All of the sudden margin starts to slip. Fewer new users exist to offset the old users People look into and realize the unlimited scheme is up. Then they implement a retention policy and customers freak out.</p>

<h2 id="handling-unlimited-as-a-business">Handling Unlimited as a Business</h2>

<p>Businesses often fail at unlimited in a few ways.</p>

<p>First, companies should offer a way to pay more to get more storage. I can’t be mad that you won’t run a ridiculous business for me. I will get mad if you sink me into your product and don’t give me the option to pay a fair value to continue service.</p>

<p>Second, companies should be mindful of data retention policies from day 1.  The unlimited Ponzhi scheme is in many products not something that companies even know is happening. Things look good  until they don’t.</p>

<p>If you keep data around without retention policies, you will face a long road of performance, stability, and customer issues as you scale. Especially as your growth numbers slow, you should be mindful of the upcoming business realities sooner rather than later if you have anything that is unlimited in your product.</p>

<h2 id="summary">Summary</h2>

<p>There’s no free lunch in this world unless you’re willing to run around to different dumpsters to get it.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/product/2020/12/12/unlimitted.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399344</guid>
            <pubDate>Sat, 12 Dec 2020 16:32:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tiered Subnet Calculator in Terraform]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399302">thread link</a>) | @JayQ_One
<br/>
December 12, 2020 | https://jq1.io/posts/tiered_subnet_calculator/ | <a href="https://web.archive.org/web/*/https://jq1.io/posts/tiered_subnet_calculator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I’ve been thinking about adding support for building tiered subnets of any size
for the next iteration of the <a href="https://jq1.io/posts/dynamic_vpc/">Dynamic VPC Module</a>.
It occurred to me that auto subnet generation inside the module actually
makes the subnetting less dynamic.</p>
<p>Furthermore, auto subnet calculation should be in assistance to
the process of allocating subnets and should not be fed directly as input
to the VPC module. This is due to the fact that order matters only for the
subnetting. So when tiers or AZs are changed, added or removed,
the calculation will shift for none, some or all tiers.</p>
<p>Removing the subnet generation will simplify the module itself and it will reinforce
the notion that engineers should know their subnetting when architecting networks.
With all that in mind, I created a <a href="https://github.com/JudeQuintana/terraform-modules/tree/master/utils/tiered_subnet_calculator">Tiered Subnet Calculator</a> module to assist with allocating subnets per AZ per network tier.</p>
<p><code>tiers.auto.tfvars</code></p>
<pre><code>base_cidr_block = "10.0.0.0/16"

tiers = [
  {
    name   = "app"
    acl    = "public"
    newbit = 4
  },
  {
    name   = "db"
    acl    = "private"
    newbit = 4
  },
  {
    name   = "worker"
    acl    = "private"
    newbit = 4
  },
  {
    name   = "lbs"
    acl    = "public"
    newbit = 4
  }
]

az_newbits = {
  a = 4
  b = 4
  c = 4
  d = 4
}

</code></pre><p><code>variables.tf</code></p>
<pre><code>variable "base_cidr_block" {
  type = string
}

variable "tiers" {
  type = set(object({
    name   = string
    acl    = string
    newbit = number
  }))
}

variable "az_newbits" {
  type = map(number)
}

</code></pre><p><code>main.tf</code></p>
<pre><code>locals {
  # generate top level networks for each tier based on tier newbit + base_cidr_block mask ie /4 + /16 = /20
  tier_networks = zipmap(var.tiers[*].name, cidrsubnets(var.base_cidr_block, var.tiers[*].newbit...))

  # generate a subnet based on each az newbit (in azs_new_bits map) per tier network ie /4 + /20 = /24
  tier_subnets = { for t, n in local.tier_networks : t =&gt; cidrsubnets(n, values(var.az_newbits)...) }

  # generate azs to subnet map per tier
  tier_az_subnets = { for t, s in local.tier_subnets : t =&gt; zipmap(keys(var.az_newbits), s) }

  # build new tiers list with their associated network and az to subnets map
  tiers_with_subnets_per_az = [
    for t in var.tiers : {
      name    = t.name,
      acl     = t.acl,
      network = lookup(local.tier_networks, t.name)
      azs     = lookup(local.tier_az_subnets, t.name),
  }]

}

output "calculated_tiers" {
  value = local.tiers_with_subnets_per_az
}

</code></pre><p><code>terraform refresh</code></p>
<pre><code>$ terraform refresh

Empty or non-existent state file.

Refresh will do nothing. Refresh does not error or return an erroneous
exit status because many automation scripts use refresh, plan, then apply
and may not have a state file yet for the first run.


Outputs:

calculated_tiers = [
  {
    "acl" = "public"
    "azs" = {
      "a" = "10.0.0.0/24"
      "b" = "10.0.1.0/24"
      "c" = "10.0.2.0/24"
      "d" = "10.0.3.0/24"
    }
    "name" = "app"
    "network" = "10.0.0.0/20"
  },
  {
    "acl" = "private"
    "azs" = {
      "a" = "10.0.16.0/24"
      "b" = "10.0.17.0/24"
      "c" = "10.0.18.0/24"
      "d" = "10.0.19.0/24"
    }
    "name" = "db"
    "network" = "10.0.16.0/20"
  },
  {
    "acl" = "private"
    "azs" = {
      "a" = "10.0.32.0/24"
      "b" = "10.0.33.0/24"
      "c" = "10.0.34.0/24"
      "d" = "10.0.35.0/24"
    }
    "name" = "worker"
    "network" = "10.0.32.0/20"
  },
  {
    "acl" = "public"
    "azs" = {
      "a" = "10.0.48.0/24"
      "b" = "10.0.49.0/24"
      "c" = "10.0.50.0/24"
      "d" = "10.0.51.0/24"
    }
    "name" = "lbs"
    "network" = "10.0.48.0/20"
  },
]
</code></pre><p>If you want to see each tier transform you can open the
<code>terraform console</code> and call them to see their output.</p>
<pre><code>$ terraform console
&gt; local.tier_networks
{
  "app" = "10.0.0.0/20"
  "db" = "10.0.16.0/20"
  "lbs" = "10.0.48.0/20"
  "worker" = "10.0.32.0/20"
}
&gt; local.tier_subnets
{
  "app" = [
    "10.0.0.0/24",
    "10.0.1.0/24",
    "10.0.2.0/24",
    "10.0.3.0/24",
  ]
  "db" = [
    "10.0.16.0/24",
    "10.0.17.0/24",
    "10.0.18.0/24",
    "10.0.19.0/24",
  ]
  "lbs" = [
    "10.0.48.0/24",
    "10.0.49.0/24",
    "10.0.50.0/24",
    "10.0.51.0/24",
  ]
  "worker" = [
    "10.0.32.0/24",
    "10.0.33.0/24",
    "10.0.34.0/24",
    "10.0.35.0/24",
  ]
}
&gt; local.tier_az_subnets
{
  "app" = {
    "a" = "10.0.0.0/24"
    "b" = "10.0.1.0/24"
    "c" = "10.0.2.0/24"
    "d" = "10.0.3.0/24"
  }
  "db" = {
    "a" = "10.0.16.0/24"
    "b" = "10.0.17.0/24"
    "c" = "10.0.18.0/24"
    "d" = "10.0.19.0/24"
  }
  "lbs" = {
    "a" = "10.0.48.0/24"
    "b" = "10.0.49.0/24"
    "c" = "10.0.50.0/24"
    "d" = "10.0.51.0/24"
  }
  "worker" = {
    "a" = "10.0.32.0/24"
    "b" = "10.0.33.0/24"
    "c" = "10.0.34.0/24"
    "d" = "10.0.35.0/24"
  }
}
</code></pre><p>Filtering tiers easy too.</p>
<pre><code>locals {
  private_tiers = [for t in local.tier_subnets_per_az : t if t.acl == "private"]
}
</code></pre><p>Now I can start tweaking the <code>tiers</code> object set and <code>az_newbits</code> map
to generate different tiered network configurations.</p>
<p><code>tiers.auto.tfvars</code></p>
<pre><code>base_cidr_block = "10.0.0.0/16"

tiers = [
  {
    name   = "app"
    acl    = "public"
    newbit = 6
  },
  {
    name   = "db"
    acl    = "private"
    newbit = 6
  },
  {
    name   = "worker"
    acl    = "private"
    newbit = 4
  },
]

az_newbits = {
  b = 2
  c = 4
  d = 4
}
</code></pre><pre><code>$ terraform refresh
Empty or non-existent state file.

Refresh will do nothing. Refresh does not error or return an erroneous
exit status because many automation scripts use refresh, plan, then apply
and may not have a state file yet for the first run.


Outputs:

calculated_tiers = [
  {
    "acl" = "public"
    "azs" = {
      "b" = "10.0.0.0/24"
      "c" = "10.0.1.0/26"
      "d" = "10.0.1.64/26"
    }
    "name" = "app"
    "network" = "10.0.0.0/22"
  },
  {
    "acl" = "private"
    "azs" = {
      "b" = "10.0.4.0/24"
      "c" = "10.0.5.0/26"
      "d" = "10.0.5.64/26"
    }
    "name" = "db"
    "network" = "10.0.4.0/22"
  },
  {
    "acl" = "private"
    "azs" = {
      "b" = "10.0.16.0/22"
      "c" = "10.0.20.0/24"
      "d" = "10.0.21.0/24"
    }
    "name" = "worker"
    "network" = "10.0.16.0/20"
  },
]
</code></pre><p>I’m able to take this output, add or remove AZs and subnets
that may have not been in the original calculation. I can chop up
networks as I see fit.</p>
<pre><code>tiers = [
  {
    "acl" = "public"
    "azs" = {
      "b" = "10.0.0.0/24"
      "c" = "10.0.1.0/26"
    }
    "name" = "app"
    "network" = "10.0.0.0/22"
  },
  {
    "acl" = "private"
    "azs" = {
      "c" = "10.0.5.0/26"
      "d" = "10.0.5.64/26"
    }
    "name" = "db"
    "network" = "10.0.4.0/22"
  },
  {
    "acl" = "private"
    "azs" = {
      "b" = "10.0.16.0/22"
      "d" = "10.0.21.0/24"
      "c" = "10.0.22.0/24"
    }
    "name" = "worker"
    "network" = "10.0.16.0/20"
  },
]
</code></pre><p>Also, I can further validate tiered network ranges with <code>ipcalc</code>.</p>
<pre><code>$ ipcalc 10.0.16.0/20

Address:   10.0.16.0            00001010.00000000.0001 0000.00000000
Netmask:   255.255.240.0 = 20   11111111.11111111.1111 0000.00000000
Wildcard:  0.0.15.255           00000000.00000000.0000 1111.11111111
=&gt;
Network:   10.0.16.0/20         00001010.00000000.0001 0000.00000000
HostMin:   10.0.16.1            00001010.00000000.0001 0000.00000001
HostMax:   10.0.31.254          00001010.00000000.0001 1111.11111110
Broadcast: 10.0.31.255          00001010.00000000.0001 1111.11111111
Hosts/Net: 4094                  Class A, Private Internet
</code></pre><p>A more detailed break down of subnets within a tiered network.</p>
<pre><code>$ ipcalc 10.0.16.0/20 /24

Address:   10.0.16.0            00001010.00000000.0001 0000.00000000
Netmask:   255.255.240.0 = 20   11111111.11111111.1111 0000.00000000
Wildcard:  0.0.15.255           00000000.00000000.0000 1111.11111111
=&gt;
Network:   10.0.16.0/20         00001010.00000000.0001 0000.00000000
HostMin:   10.0.16.1            00001010.00000000.0001 0000.00000001
HostMax:   10.0.31.254          00001010.00000000.0001 1111.11111110
Broadcast: 10.0.31.255          00001010.00000000.0001 1111.11111111
Hosts/Net: 4094                  Class A, Private Internet

Subnets after transition from /20 to /24

Netmask:   255.255.255.0 = 24   11111111.11111111.11111111. 00000000
Wildcard:  0.0.0.255            00000000.00000000.00000000. 11111111

 1.
Network:   10.0.16.0/24         00001010.00000000.00010000. 00000000
HostMin:   10.0.16.1            00001010.00000000.00010000. 00000001
HostMax:   10.0.16.254          00001010.00000000.00010000. 11111110
Broadcast: 10.0.16.255          00001010.00000000.00010000. 11111111
Hosts/Net: 254                   Class A, Private Internet

 2.
Network:   10.0.17.0/24         00001010.00000000.00010001. 00000000
HostMin:   10.0.17.1            00001010.00000000.00010001. 00000001
HostMax:   10.0.17.254          00001010.00000000.00010001. 11111110
Broadcast: 10.0.17.255          00001010.00000000.00010001. 11111111
Hosts/Net: 254                   Class A, Private Internet

...

 15.
Network:   10.0.30.0/24         00001010.00000000.00011110. 00000000
HostMin:   10.0.30.1            00001010.00000000.00011110. 00000001
HostMax:   10.0.30.254          00001010.00000000.00011110. 11111110
Broadcast: 10.0.30.255          00001010.00000000.00011110. 11111111
Hosts/Net: 254                   Class A, Private Internet

 16.
Network:   10.0.31.0/24         00001010.00000000.00011111. 00000000
HostMin:   10.0.31.1            00001010.00000000.00011111. 00000001
HostMax:   10.0.31.254          00001010.00000000.00011111. 11111110
Broadcast: 10.0.31.255          00001010.00000000.00011111. 11111111
Hosts/Net: 254                   Class A, Private Internet


Subnets:   16
Hosts:     4064
</code></pre><p>The moral of the story is <code>Know Thy Subnetting</code>.</p>
<p>~jq1</p>

  </div></div>]]>
            </description>
            <link>https://jq1.io/posts/tiered_subnet_calculator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399302</guid>
            <pubDate>Sat, 12 Dec 2020 16:28:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Buy Don't Build]]>
            </title>
            <description>
<![CDATA[
Score 203 | Comments 185 (<a href="https://news.ycombinator.com/item?id=25399250">thread link</a>) | @jrott
<br/>
December 12, 2020 | https://jrott.com/posts/why-buy/ | <a href="https://web.archive.org/web/*/https://jrott.com/posts/why-buy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				

<p>Standing up and managing a service or building a custom service is a common desire for engineers. It’s usually a major mistake, that ends up costing a ton of time and money.
The desire to build custom versions of everything seems to come from a few places:</p>

<ol>
<li>The hope that it will be cheaper to build than buy.</li>
<li>The idea that their companies process is special so industry-standard stuff will not work.</li>
<li>That they need to have total control over what the service does.</li>
<li>To avoid vendor lock-in</li>
</ol>

<p>All four of those things are less true and less important than you would think. It’s worth building when something is core to your business or provides a significant competitive advantage. Otherwise, it’s probably worth using the services that your cloud provider has or another saas. Running your own stuff has a significant operational burden and a large opportunity cost.
If you only get one thing out of this let it be: Building stuff is fun, but being paged at two in the morning about a Rube Goldberg contraption of a system to handle customer analytics isn’t.</p>

<h2 id="p-align-center-running-services-isn-t-easy-p"><p> Running services isn’t easy </p></h2>

<p>Keeping systems up in production takes time and energy. Building them isn’t where most of the expense lies. Instead, that comes with running and maintaining complicated systems.
Most enterprise systems require an engineering team to keep them running. Engineers aren’t cheap to hire and there is also additional complexity that gets introduced to keep a large number of teams coordinated. This all results in slower decision making.</p>

<p>Slower decisions happen because more teams are needed to maintain more services. These teams then need to work together and coordinate. All of a sudden, to make a change there are a million teams that need to be informed and handoffs that have to be managed. That can lead to fiefdoms for managers and way more politics, since there are now more teams and a more complicated organizational structure.</p>

<p>If you are following a DevOps model, the team that builds the service will also end up maintaining it. The more moving pieces that there are for the team to maintain, the less time that they will have for new feature development. This is painful, especially in young companies with a rapidly evolving product. Slowing down the time it takes to find product-market fit in exchange for getting to run your own stuff is a bad trade.</p>

<p>You also have to consider the level of operational excellence that exists in your organization. To put it bluntly, who do you trust more for uptime - Amazon or you? The answer, for services which you absolutely depend on for survival, might be you. Other systems though may suffer from getting less time and attention, because it becomes harder to justify the expense of keeping them up and running.</p>

<h2 id="p-align-center-vendor-lock-in-p"><p> Vendor lock-in </p></h2>

<p>At this point, you might be thinking “But I don’t want to be stuck on a vendor’s special snowflake of a system”. My counter-argument to that is there is also lock-in with internal systems. The most common version of this is The Keeper of The Spreadsheet. Now, if you’re going “what spreadsheet?”, well that’s a fair question. But it’s the one that for some important internal process that has turned into The Keeper of The Spreadsheet’s job. Most large companies have at least one spreadsheet like this. If you work at a large company, you probably realize that is a gross understatement - there can be many.</p>

<p>The Keeper(s) of The Spreadsheet will defend their process, and not want to change it at all costs, because they are worried that they’ll get fired if that process gets automated or is no longer necessary. You also see this with engineering teams, where they become the Keepers of A Database or ticketing system. All of a sudden you’ve got a system that sucks, and nobody wants to advocate for getting rid of it because their co-worker is convinced that they’ll lose their job if it happens. This also creates a political trap for the unwary when they try and fix that process.</p>

<p>Being The Keeper of The Ticketing System isn’t all that fun usually either. It’s a good way to get pigeonholed into boring work. It also means that you end up with a system that isn’t the most important thing to the business, instead of allowing an outside company to take it. That outside company is likely to specialize in solving that problem, and has built deeper expertise because of that. Unless of course you’re slightly evil and looking for awful projects to exile people to.</p>

<p>All of this makes being locked into a vendor less of a concern than most people think. There is lock-in no matter what you do. The thing that you want to avoid is giving wholesale pricing power to any vendor. This can be avoided by making sure that the key differentiators for your business are in-house.</p>

<h2 id="p-align-center-engineering-time-is-expensive-p"><p> Engineering time is expensive </p></h2>

<p>Software and systems engineers aren’t cheap to hire. As a group, we also tend to undervalue our time. Think about how often you hear “Oh I could build that in a week”, or “That’ll be easy”. With luck that’s just a comment on Reddit or hacker news, but if it’s at work then it usually turns into a total slog.</p>

<p>It’s common to express the cost of owning or maintaining a service in terms of the total cost of ownership (TCO). This is often really hard to calculate since many of the things that go into TCO aren’t tracked. The major issue that you’ll run into is that it’s not just the cost of the engineer. The metric we care about is the opportunity cost of the other things that engineers could be producing.</p>

<p>Another reason that will come up for building something custom is for unique company processes. Usually with the idea that you couldn’t customize the software to make it work, or that it’d cost more than just building it. While these can be  valid reasons to build, it’s true less often than you would think. Many processes are shared across a large number of businesses. Also, processes tend to get bloated over time. Large amounts of the custom work that is needed to match up with a business’s processes are stuff that could just not be done. For an absurd example, that happened at a company I worked with:
1. Our process for recommending articles is complicated and requires tons of joins on fuzzy data
2. We can build our own database system that is designed specially to handle this.
3. A few months of intense development go by.
4. It turns out operating this thing is hard, we don’t know why some queries take the system down, and why our customers complaining about the recommendations.</p>

<p>You really don’t want that to be you. It’s demoralizing to have built and maintained a product for something that doesn’t even work correctly. When things are getting so complicated that no existing tooling will work for it, you should be asking if all of the complexity is fundamental to the domain or if the model you are using is flawed.</p>

<h2 id="p-align-center-loss-of-focus-p"><p> Loss of focus </p></h2>

<p>A significant problem that comes from running your own version of a service is that it’s another thing that engineers have to pay attention to. There is a limit on how many things can be important. What then happens to all of the non-core services that you are running is usually some form of neglect, where they are kept in a barely good enough state.</p>

<p>The problem then with that is everyone who is working on those services is usually trying to get off of them. After all, no one wants to work on something that their boss doesn’t care about. So you end up with a ton of maneuvering since people are trying to change teams, and that increases drag.</p>

<p>Compounding this problem even further is that not revenue-generating things are frequently ignored. Yes, your CI/CD system is absolutely critical, but it’s easy for executives to not think about. This leads to a failure mode where you have a lost garden of internal tools. Whereas if you are paying someone money to do the same thing, it is their business so they keep working on it.</p>

<h2 id="p-align-center-opportunity-cost-p"><p> Opportunity cost </p></h2>

<p>In many ways, the biggest problem with building a service is opportunity cost. The reason isn’t salary but instead what else could be done. It’s basically the same problem that you see when a company is building a one-off feature to close a sale. The big difference is that engineering is doing it to themselves so there may be willful blindness to the damage being done.</p>

<p>Engineers like building things, and many like to be in control of all the buttons and knobs. Many times this is a good thing. After all, it’s how anything super cool actually gets built. The problem with it arises when that impulse exists, without a keen sense of the business effects of decisions that are made.</p>

<p>The question you should be asking is what else could be done instead of tuning your own stuff or building a new internal system. The answer is usually spending more time coming up with the correct architecture,or developing actual customer-facing features, instead of fighting fires .</p>

<p>Having large operational footprints usually results in reduced velocity and fewer changes happening per engineer. Think about the difference in speed between big companies and startups. This isn’t because startups hire smarter people, instead it’s the amount of stuff that is tied up with any change at a big company.</p>

<p>This is an area where engineering can’t just think about the software that is being built. Instead, you have to think of the health of the entire product. It’s about building stuff that is useful for the customer and letting go of things that aren’t critical. By keeping a tight focus on core projects things are built faster. There is also less craft and maintenance work that goes along with the product.</p>

<h2 id="p-align-center-summing-up-p"><p> Summing up </p></h2>

<p>None of these reasons might apply in your case. There are many good reasons to build. However, if you haven’t considered whether you can just buy something to solve a problem instead of building it yourself, you should.</p>

<p>Think about if it’s worth as being paged at 2 in the morning over. If you are willing to be paged over it, also consider if someone else can …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jrott.com/posts/why-buy/">https://jrott.com/posts/why-buy/</a></em></p>]]>
            </description>
            <link>https://jrott.com/posts/why-buy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399250</guid>
            <pubDate>Sat, 12 Dec 2020 16:22:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rethinking Learning: The Hagen New Learning Manifesto]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25399008">thread link</a>) | @Tomte
<br/>
December 12, 2020 | https://www.fernuni-hagen.de/english/university/manifesto-text.shtml | <a href="https://web.archive.org/web/*/https://www.fernuni-hagen.de/english/university/manifesto-text.shtml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="inhalt" role="main">
								<!-- tennant: 'shared', realm: 'top', from: 'catmeta', list: 'breadcrumb', type: 'content'-->
	
	<!-- tennant: 'shared', realm: 'main', from: 'catmeta', list: 'title,default,zusatzinfos,autor', type: 'content'-->


    

<h2>
Preamble
</h2>
<figure>
    <p><img src="https://www.fernuni-hagen.de/imperia/md/images/presse/logos/manifest-key-visual-hoch.jpg" alt="">

        <span id="span_etikett_10_24">FernUniversität</span>

    </p>
</figure>
	<div>
		<p><span><span>How should we, how can we, how must we learn in the future? </span></span></p> <p><span><span>The digital transformation is profoundly changing our society and our work environments. In our educational institutions, in educational policy, and in society, however, we still lack an adequate understanding of how digital media and tools have fundamentally changed – and will continue to change – learning. For years, experts in education have been calling for us to transform how we conceive of and define learning.</span></span></p> <p><span><span><span>We believe it is overdue to adopt a radically new understanding of learning – New Learning. </span></span></span></p>
	</div>

<ul>

<li>
<h3></h3>
<section aria-labelledby="button_10_2_0_0">
	<p><span><span>New Learning is cooperative, situated, competence-oriented, and data-intelligent. Digital and traditional teaching and learning formats work together throughout the entire educational journey. New Learning increases learners’ self-determination and focuses on their individual needs. It is inclusive and puts the goal of equal opportunity into practice. It promotes media competence and data literacy, thereby enabling participation and self-determination in a digital society.</span></span></p>

</section>
</li>

<li>
<h3></h3>
<section aria-labelledby="button_10_2_0_1">
	<p><span><span>The coronavirus crisis has made the acute need very clear: laptops and smartphones, video conferencing, tools for collaborative work, study apps – all the things that once seemed merely convenient suddenly became real necessities in order for teaching and learning to continue at all. Until now, teaching with digital media was driven forward by a few individual pioneers. Now we are all becoming familiar with a new practice and with creative teaching and learning formats. We should see this as a starting point for the future, not as a temporary emergency solution. This does not mean saying goodbye to personal interaction or to proven in-person teaching formats. Rather, we must appropriately anchor the digital transformation in the educational sector as both an opportunity and a social requirement. A return to the old status quo in learning culture would be equivalent to capitulation in the face of the challenges of the digital transformation. </span></span></p>

</section>
</li>

<li>
<h3></h3>
<section aria-labelledby="button_10_2_0_2">
	<p><span><span>We have to face a number of challenges: Schools, universities, and other educational institutions are not just lacking the necessary technical infrastructure. What they lack most is experience and expertise on how to teach, learn, and work well online and how to productively blend digital and in-person forms of teaching and learning. </span></span></p> <p><span><span>Rethinking learning thus encompasses far more than digital technology. Yes, it needs new infrastructure, new learning platforms, and new technologies. Equally necessary, however, are concepts for hybrid teaching and learning, sustainable and cooperative forms of organization in schools and other educational institutions, and innovative policies to support learning.</span></span></p>

</section>
</li>

<li>
<h3></h3>
<section aria-labelledby="button_10_2_0_3">
	<p><span><span>For teachers, the need for continuing education to accompany this transformation is immense. But this holds true for all other professions as well: We have to familiarize ourselves with new forms of learning. The digital transformation affects the entire working world. Work and learning have become inseparable – the changes in how we work – New Work – require changes in how we learn – New Learning. New corporate cultures and concepts of work require new concepts for learning: agile, cooperative, and networked work requires agile, cooperative, and networked learning. The opportunity and willingness to engage in lifelong learning are important foundations for the success of these transformation processes.</span></span></p>

</section>
</li>

<li>
<h3></h3>
<section aria-labelledby="button_10_2_0_4">
	<p><span><span>New Learning empowers people to understand and actively participate in shaping the transformation of society and the corporate world. This is not a matter of merely adapting to technological and economic demands. Rather, New Learning aims to foster skills such as the abilities to learn together constructively and cooperatively, to be proactive, and to interact with digital realities in a reflective manner. In the process, New Learning puts learners at the center and empowers them to pursue self-directed lifelong learning within the digital reality of modern life. </span></span></p>

</section>
</li>

<li>
<h3></h3>
<section aria-labelledby="button_10_2_0_5">
	<p><span><span>Now is the time to develop concepts and guidelines for New Learning. This is the only way to harness the potential of technology to create a future with equal opportunities for all and to enable people to live fulfilled lives in a digital society.</span></span></p> <p><span><span>New Learning offers the enormous opportunity for people to shape and participate in transformation processes throughout the whole of society. For this reason, we aim to establish New Learning as a social consensus across the boundaries of individual institutions or political jurisdictions.</span></span></p>

</section>
</li>

</ul>
  
<h2>
Theses
</h2>
	<div>
		<h3>1. New Learning means lifelong education.</h3> <p><span><span>New Learning is an established part of our lives. We understand New Learning as a lifelong educational process: from early childhood education and school, to career training and academic education, to continuing education and professional development. This also includes informal learning that takes place outside of the formal educational system.</span></span></p> <p><span><span><i>New Learning requires: </i></span></span></p> <ul> <li><span><span><span>new opportunities and development of new skills to allow self-directed and self-organized learning;</span></span></span></li> <li><span><span><span>educational policies which situate the topic of learning in all areas of society and which incorporate all active parties at educational institutions as well as representatives from industry and civil society.</span></span></span></li> </ul>
	</div>

	<div>
		<h3><span><span> 2. New Learning promotes equal opportunities.</span></span></h3> <p><span><span>All learners have the right to a high quality education. It is imperative to remove social, material, and cultural obstacles in order to facilitate new and modern ways of learning for all learners. This includes the use of digital media. New Learning sensitizes teaching staff and educational institutions to social divisions in a digitalized society and enables learners to participate in shaping the digital transformation of society.</span></span></p> <p><span><span><i>New Learning requires:</i></span></span></p> <ul> <li><span><span><span>teaching staff’s awareness of the danger that digitalization will (re)create inequalities;</span></span></span></li> <li><span><span><span>a perspective on digital learning processes which emphasizes diversity, inclusivity and equal opportunities; </span></span></span></li> <li><span><span><span>resources that empower all people to confidently participate in educational processes and in the digital transformation of society.</span></span></span></li> </ul>
	</div>

	<div>
		<h3>3. New Learning puts learners at the center.</h3> <p><span><span>Each person learns in their own way. This is why we consistently center our thinking about New Learning on learners. New Learning supports their individual strengths and uniqueness both through personal guidance and through digitally-supported systems that create adaptive learning environments. </span></span></p> <p><span><span><i>New Learning requires:</i></span></span></p> <ul> <li><span><span><span>personal guidance for learners and adaptive learning environments that adjust to learners’ individuality and diversity;</span></span></span></li> <li><span><span><span>adequate and well-reflected coordination of digital and in-person learning; </span></span></span></li> <li><span><span><span>the ability of teachers and learners to initiate and utilize learning processes beyond formalized structures in order to provide the broadest possible opportunity for individual strengths and interests to flourish.</span></span></span></li> </ul>
	</div>

	<div>
		<h3>4. New Learning rethinks the roles of teachers and learners.</h3> <p><span><span>In our view, teachers are neither all-knowing, nor should they solely determine the learning process. They understand themselves as learners who simultaneously create a framework for others to learn. They develop adaptive learning paths, create the space for learning, and guide collaborative learning processes. They adapt their teaching to learners’ needs and to relevant topics in society. </span></span></p> <p><span><span><i>New Learning requires:</i></span></span></p> <ul> <li><span><span><span>a reflective and participatory process in which teachers and learners negotiate and reflect upon suitable learning paths and goals together;</span></span></span></li> <li><span><span><span>a culture of learning which breaks down the barriers between participants in the learning process.</span></span></span></li> </ul>
	</div>

	<div>
		<h3>5. New Learning means networked learning.</h3> <p><span><span>For us, New Learning means designing learning in a networked way. Learning settings must connect to the world of learners’ everyday, career, and life experiences. Only then can they promote experience-based and motivated learning and create emotional and sensory access to learning on a number of levels. New Learning simultaneously requires and makes possible new methods of networked learning in order to implement digital media in a didactically appropriate way.</span></span></p> <p><span><span><i>New Learning requires:</i></span></span></p> <ul> <li><span><span><span>digital and networked teaching and learning concepts that are consistently applied across all levels of education and which appropriately combine digital and analog formats;</span></span></span></li> <li><span><span><span>time for productive exchange to develop fundamentally new, efficient types of networks and cooperation.</span></span></span></li> </ul>
	</div>

	<div>
		<h3>6. New Learning makes flexible and self-directed learning possible.</h3> <p><span><span>New Learning develops the learning culture further: Learning in projects and via digital formats is gradually replacing purely lecture-based teaching. People learn in an individual, self-directed and team-oriented way, with flexible times and locations. At the same time, they become part of a supportive community of individuals who learn from and with one another, with a sense of social responsibility.</span></span></p> <p><span><span><i>New Learning requires:</i></span></span></p> <ul> <li><span><span><span>a learning culture that enhances new freedoms, collaboration, and self-reliant learning in education;</span></span></span></li> <li><span><span><span>institutionalized educational structures which enable flexible and self-organized forms of learning.</span></span></span></li> </ul>
	</div>

	<div>
		<h3>7. New Learning measures learning success by individual goals.</h3> <p><span><span>We are convinced that success in learning is not determined just by degrees completed. It is at least as important to be and to remain capable of learning and to achieve individual goals (for example, to expand one’s own skills and qualifications or to pursue personal development). Making mistakes is also a part of the learning process; a culture that deals positively with mistakes is conducive to learning success.</span></span></p> <p><span><span><i>New Learning requires:</i></span></span></p> <ul> <li><span><span><span>recognition of learning success beyond existing degrees and qualifications, both in society and in educational policy;</span></span></span></li> <li><span><span><span>alternative, modular educational formats and certifications that are firmly established in the …</span></span></span></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.fernuni-hagen.de/english/university/manifesto-text.shtml">https://www.fernuni-hagen.de/english/university/manifesto-text.shtml</a></em></p>]]>
            </description>
            <link>https://www.fernuni-hagen.de/english/university/manifesto-text.shtml</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399008</guid>
            <pubDate>Sat, 12 Dec 2020 15:58:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Reason Why NES Cartridges Are So Big]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398987">thread link</a>) | @jslakro
<br/>
December 12, 2020 | https://retrogamestart.com/answers/reason-why-nes-cartridges-are-so-big | <a href="https://web.archive.org/web/*/https://retrogamestart.com/answers/reason-why-nes-cartridges-are-so-big">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>NES cartridges were a departure from the standard form factor at the time. They are thinner, but bigger overall. The first time I opened up an NES cartridge, I was surprised at the small size of the actual electronics, and large amount of empty space. Why is the cartridge so big?</p>

<p>Why are NES cartridges so big, when the actual contents are so small?Â&nbsp;<strong>There are a variety of factors, but it boils down to design and perception. Nintendo wanted to reshape how people looked at video games. To understand this, you have to consider the world of video games in the mid 1980s.</strong></p>

<section><h3>Table of Contents</h3>

<ul><li><a href="#differentiate-atari">Nintendo Had to Differentiate From Atari</a></li>
	<li><a href="#dress-nes">Dress the NES For Success</a></li>
	<li><a href="#feel-value">The Feel of Value &amp; Substance</a></li>
	<li><a href="#technical-benefits">Technical Benefits of the Larger Cartridge</a></li>
	<li><a href="#head-rd">Head of R&amp;D on the NES Project</a></li>
</ul></section><p>When Nintendo was readying the NES for the U.S. market, they were entering a world where the ideaÂ&nbsp;of â€œhome video gamesâ€� was poison. The Atari 2600 had dominated and defined the US market for home video game consoles, and had flamed out spectacularly only shortly before, in 1983. This was largely due to a flood of low-quality games produced by 3rd party creators. Nintendoâ€™s design choices for both the NES console itself, as well as the cartridges came out of wanting to create new associations for buyers, so that the dark cloud over the Atari catastrophe didnâ€™t carry over to their new product, and doom it before it even got going.</p>

<p><img alt="NES cartridge housing and board sizes compared" data-entity-type="" data-entity-uuid="" id="" src="https://retrogamestart.com/sites/default/files/site-assets/why-are-nes-cartridges--housing-board.jpg" title="NES cartridge housing and board sizes compared"></p>

<h2 id="differentiate-atari">Nintendo Had to Differentiate From Atari</h2>

<p>You have to understand that in the mid-80s, EVERYONE was familiar with Atari. The very conceptÂ&nbsp;of a home video game (as opposed to going to the arcade), was pretty much owned by the Atari 2600. When the public soured on the 2600, the whole industry went down the tubes with them. Many thought Nintendo were foolishly beating a dead horse, and wasting millions of dollars trying to introduce a console into a market that was not coming back.</p>

<p>So foremost on Nintendoâ€™s collective mind was to make it clear that they were different. Instead of a â€œvideo game console,â€� they insisted they were selling an â€œentertainment system.â€� Looking back, it feels like splitting hairs over words, but they had to make sure people didnâ€™t place them in what many considered an extinctÂ&nbsp;category. So Nintendo decided to create a unit that felt more like a VCR, which was quite popular at the time. They designed the unit to be boxier, and most famously, it used a front-loading system for inserting game cartridges, much like VCRs did with tapes.</p>

<p><img alt="NES console with controller" data-entity-type="" data-entity-uuid="" id="" src="https://retrogamestart.com/sites/default/files/site-assets/why-are-nes-cartridges--nes.jpg" title="NES console with controller"></p>

<p>So then, as part of making it both different, and more VCR-like, they created a large, very distinct cartridge design. The NES cartridge housing also had a much more futuristic, sophisticated look to it than the relatively plain black box that Atari carts had.</p>

<p><img alt="NES Cartridge - Strider next to Atari Cartridge - Combat" data-entity-type="" data-entity-uuid="" id="" src="https://retrogamestart.com/sites/default/files/site-assets/why-are-nes-cartridges--nes-atari.jpg" title="NES Cartridge - Strider next to Atari Cartridge - Combat"></p>

<h2 id="dress-nes">Dress the NES For Success</h2>

<p>Before you write this off as slippery marketing sleight-of-hand, consider that the NES provided a demonstrably better gaming ecosystem than the troubled Atari did, and so they were trying to make sure people didnâ€™t unconsciously dismiss it before giving it a chance - just because they thought it was more of the same. They decided to dress it up very differently in order to make sure it stood out as distinct, and people judged it on its own merits.</p>

<p><em>An aside: This story of Nintendo wading into what many considered sure death is covered beautifully in a book I recently read - Steven L. Kentâ€™s <a href="https://www.amazon.com/Ultimate-History-Video-Games-Pokemon/dp/0761536434/" target="_blank">The Ultimate History of Video Games</a>. Itâ€™s a rollicking ride that details the wild ups and downs, and behind-the-scenes drama in the early years of an industry that is now bigger than Hollywood. Itâ€™s fun read, with many surprising anecdotes and insights from the actual people who were involved.</em></p>

<p>To drive home the fact that this was a conscious design choice for the U.S. market, take a look at the console and cartridge for the Japanese version of the NES - known as the â€œFamicomâ€� (for â€œFamily Computerâ€�). The Famicom console looks COMPLETELY different from the NES, and the cartridges are much smaller - matching the size of the actual electronics much more closely.</p>

<p><img alt="Famicom console with controller" data-entity-type="" data-entity-uuid="" id="" src="https://retrogamestart.com/sites/default/files/site-assets/why-are-nes-cartridges--famicom.jpg" title="Famicom console with controller"></p>

<p><em>Personal note: As someone who has been in the design world for 25 years, I think the Famicom looks hopelessly dated and locked into the early 80s, while the NES has a strangely timeless feel to it. Making it different for the U.S. made it not only popular, but iconic.</em></p>

<p><img alt="NES Cartridge - Strider next to Famicom Cartridge - Air Fortress" data-entity-type="" data-entity-uuid="" id="" src="https://retrogamestart.com/sites/default/files/site-assets/why-are-nes-cartridges--nes-famicom.jpg" title="NES Cartridge - Strider next to Famicom Cartridge - Air Fortress"></p>

<p>Itâ€™s also worth noting at this point that wanting to elevate the feel of the systems was also related to the shift toward home computers. This is especially relevant when you consider the Commodore VIC-20 and wildly successful Commodore 64 which had launched a few years prior, and whose advertising hinged on getting something more than just a video game system. Nintendo had to at least feel like it was better than the old-school approach that Commodore was aggressively replacing. In addition to styling, Nintendo attempted to prove their elevated status as an â€œentertainment systemâ€� through bringing other items into the mix: the much-beloved Zapper (light gun), and largely forgotten robot called â€œR.O.B.â€� (Robot Operating Buddy).</p>

<p><img alt="R.O.B. robot and the Zapper" data-entity-type="" data-entity-uuid="" id="" src="https://retrogamestart.com/sites/default/files/site-assets/why-are-nes-cartridges--rob-zapper.jpg" title="R.O.B. robot and the Zapper"></p>

<h2 id="feel-value">The Feel of Value &amp; Substance</h2>

<p>Besides just being distinct from the Atari, and trying to come off as more sophisticated, the NES also needed to establish a strong sense of value and substance. While todayâ€™s product design trends favor the svelte and delicate, prizing small sizes - the 80s were a completely different scenario. Consider that in the 80s, an NES cartridge retailed for $40-50 dollars. That about $100 (adjusted for inflation) at the time of this writing in 2019.</p>

<p>When youâ€™re shelling out that kind of cash, what you buy had better feel pretty special, and valuable. At that time, being chunky and having some heft made the NES game cartridges seem special. Front-loading them into the â€œplayer,â€� or â€œdeckâ€� (console) accentuated this. This was no mere game systemâ€¦ you were engaged in more serious pursuits. Donâ€™t laugh. The design of things, and basic factors like size, weight, materialâ€¦ even color have a storied history of making an important difference in how people perceive things.</p>

<p>Additionally, remember that the whole idea of ergonomics started getting real traction in the U.S. in the 80s, so the concept of human factors is part of the mix here as well. How do the size, shape, feel, and weight of the NES cart relate to the human hand? Proportion is important, and when grasping one of these things, it feels more substantial than people had been used to with the Atari (the real basis of comparison). While an Atari cart is about a handbreadth across, fitting within the hand, the NES cartridgeâ€™s size makes it extend well beyond the average grasp in two dimensions, while feeling intriguingly slender in its depth. It also has a little more weight, and (if you shake it slightly), feels quite solid, compared to the Atari cart which rattles slightly (due to the retracting protector that covers the electronic connectors).</p>

<p>TheÂ&nbsp;more substantial size and weight Nintendo went with suggested something very different than what people were used to in gaming. The flatter, wider feel was vaguely more like a videotape, or a CD case (which was sexy cool, and cutting edge at the time). The more substantial feel, combined with the more sophisticated design elements (various notches, the stand-out grip texture stripe, the direction arrow) all made it feel a step above. It felt like it dropped out of a science-fiction universe. It really felt like it was from the future, man!</p>

<p><img alt="Illustration of NES cartridge size compared to a hand" data-entity-type="" data-entity-uuid="" id="" src="https://retrogamestart.com/sites/default/files/site-assets/why-are-nes-cartridges--cart-hand.png" title="Illustration of NES cartridge size compared to a hand"></p>

<p>As noted above, the NES cartâ€™s specific design factors made the thing transcend its immediate needs for even being impressive and ergonomic, and they launched it into the place of being a design icon. With all of the game systems that have come and gone, NES cartridges are the design that has stuck in peopleâ€™s minds these many years, and continue to inspire everything from DIY mods to clever aftermarket re-imaginings.</p>

<p>Witness the <a href="https://www.amazon.com/Nintendo-Cartridge-Merchandise-Graduation-Bachelorette/dp/B0779NNG7B/" target="_blank">NES cartridge flask</a> and <a href="https://www.instructables.com/id/NES-Cartridge-Wireless-Router/" target="_blank">DIY wireless router enclosure</a>:</p>

<p><img alt="NES cartridge flask and DIY wireless router enclosure" data-entity-type="" data-entity-uuid="" id="" src="https://retrogamestart.com/sites/default/files/site-assets/why-are-nes-cartridges--flask-router.jpg" title="NES cartridge flask and DIY wireless router enclosure"></p>

<h2 id="technical-benefits">Technical Benefits of the Larger Cartridge</h2>

<p><img alt="Full size circuit board from NES game Bandit Kings of Ancient China" data-entity-type="" data-entity-uuid="" id="" src="https://retrogamestart.com/sites/default/files/site-assets/why-are-nes-cartridges--largest-pcb.jpg" title="Full size circuit board from NES game Bandit Kings of Ancient China"></p>

<p>Itâ€™s worth noting here, that while a thingâ€™s origin may be rooted in one set of considerations, those decisions can in turn create additional opportunities. All of that extra space in the NES game cartridge housing didnâ€™t end up going to waste. As time went on, and NES games become more sophisticated, the electronics did eventually fill up that space. Between adding batteries (for saved games) extra chips, and even performance-enhancing processor chips to take over and extend what the NES was capable of, game creators were able to expand NES possibilities by hot-rodding it with fancy extras.</p>

<p><a href="https://www.reddit.com/r/nintendo/comments/6zos4n/why_do_cartridges_have_so_much_empty_space_in_them/dmx83qi/" target="_blank">This Reddit comment</a> unpacks this aspect a bit more.</p>

<p>Another important bit of history: In the early boom of NES sales, game board (the electronics in the cartridge) manufacturing fell behind the market demand, so in order to get games in peopleâ€™s hands, Nintendo took Famicom game boards and put them, along with 60-72-pin adapters into NES cartridge housings. This saved their skin, and means one of your NES cartridges might even have an adapter that will let you play Japanese Famicom gamesÂ&nbsp;in your NES!</p>

<h2 id="head-rd">Head of R&amp;D on the NES Project</h2>

<p><img alt="Masayuki Uemura" data-entity-type="" data-entity-uuid="" id="" src="https://retrogamestart.com/sites/default/files/site-assets/why-are-nes-cartridges--masayuki-uemura.jpg" title="Masayuki Uemura">Masayuki Uemura was head of Nintendoâ€™s research &amp; development group during the NES project, and it was him and his team that made these brilliant decisions which have us discussing their work more than 30 years after the fact. When we consider that they werenâ€™t just designing a game system, but ingeniously reviving the nearly dead industry of home video game consoles, what they accomplished is astounding. It took a lot of guts, strategic thinking, and creative solutions to pull this off. Importantly, their success wasnâ€™t just to sell a few consoles, but they actually outsold the formerly dominant Atari 2600 2-to-1 worldwide.Â&nbsp;Clearly, they were doing something right.</p>
</div></div>]]>
            </description>
            <link>https://retrogamestart.com/answers/reason-why-nes-cartridges-are-so-big</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398987</guid>
            <pubDate>Sat, 12 Dec 2020 15:55:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Semgrep for Cloud Security]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25398963">thread link</a>) | @okram87
<br/>
December 12, 2020 | https://www.marcolancini.it/2020/blog-semgrep-for-cloud-security/ | <a href="https://web.archive.org/web/*/https://www.marcolancini.it/2020/blog-semgrep-for-cloud-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<ul id="markdown-toc">
<li><a href="#what-is-semgrep" id="markdown-toc-what-is-semgrep">What is Semgrep?</a></li>
<li><a href="#semgrep-for-infrastructure-as-code" id="markdown-toc-semgrep-for-infrastructure-as-code">Semgrep for Infrastructure as Code</a> <ul>
<li><a href="#terraform" id="markdown-toc-terraform">Terraform</a> <ul>
<li><a href="#unencrypted-ebs-volumes" id="markdown-toc-unencrypted-ebs-volumes">Unencrypted EBS Volumes</a></li>
<li><a href="#open-security-groups" id="markdown-toc-open-security-groups">Open Security Groups</a></li>
</ul>
</li>
<li><a href="#kubernetes" id="markdown-toc-kubernetes">Kubernetes</a></li>
</ul>
</li>
<li><a href="#conclusions" id="markdown-toc-conclusions">Conclusions</a></li>
</ul>
<p><a href="https://semgrep.dev/" target="_blank">Semgrep</a> is an emerging
static analysis tool which is getting traction within the AppSec
community. Its broad support to multiple programming languages, together with
the easiness with which is possible to create rules, makes it a
powerful tool that can help AppSec teams scaling their efforts into preventing
complete classes of vulnerabilities from their codebases.</p>
<p>But what about cloud security? In the era of Infrastructure as Code,
where tools like Terraform, CloudFormation, Pulumi (and many others) are used
to provision infrastructure from (de-facto) source code, can we apply the
same approach to eradicate classes of cloud-related vulnerabilities from a
codebase?</p>

<p>I decided to spend part of my weekend experimenting with this,
and to get an idea of what Semgrep can provide to cloud/platform security teams.</p>

<p>Before jumping into the details, it is worth explaining what Semgrep
actually is.
As per their <a href="https://github.com/returntocorp/semgrep" target="_blank">website</a>, Semgrep is:</p>
<blockquote>
<p>A fast, open-source, static analysis tool that excels at expressing code standards — without complicated queries — and surfacing bugs early at editor, commit, and CI time.</p>
<p>Precise rules look like the code you’re searching; no more traversing abstract syntax trees or wrestling with regexes.</p>
<p>The Semgrep Registry has 1,000+ rules written by the Semgrep community covering security, correctness, and performance bugs. No need to DIY unless you want to.</p>
</blockquote>
<p>At a high level, Semgrep leverages Abstract Syntax Trees (ASTs)
to build a model of the code you are analyzing. Unlike other tools based on ASTs,
though, Semgrep lowers the entry bar by abstracting away the AST syntax itself.</p>
<figure>
<a href="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_ast.jpg">
<img src="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_ast.jpg" alt="Code as ASTs">
</a>
<figcaption>Code as ASTs. Image courtesy of <a href="https://docs.google.com/presentation/d/1j9uqQsMlePEuSzOD6E4Th2IYY4Hi7dl5XYbHdSDMkrc/edit#slide=id.g787344da8e_0_1645" target="_blank">Clint Gibler</a>.</figcaption>
</figure>
<p>Out of the box, Semgrep supports mainstream programming languages
(e.g., Go, Java, Python, Ruby, Javascript, etc.) and has a library of
<a href="https://github.com/returntocorp/semgrep-rules" target="_blank">open source rules</a>
ready to be re-used.</p>
<p>Explaining how to use Semgrep is out of scope for this blog post,
but the <a href="https://semgrep.dev/docs/" target="_blank">official documentation</a>
is really well made, and the
<a href="https://semgrep.dev/editor" target="_blank">online playground</a>
is an excellent space where to start playing with it
(without having to spend time installing anything).</p>
<hr>

<p>As briefly mentioned earlier, the benefit that Semgrep can bring to AppSec teams
is obvious (and if you are still not convinced, I recommend you to watch this
<a href="https://docs.google.com/presentation/d/1j9uqQsMlePEuSzOD6E4Th2IYY4Hi7dl5XYbHdSDMkrc/" target="_blank">this presentation</a> from <a href="https://twitter.com/clintgibler/" target="_blank">Clint Gibler</a>).</p>
<p>What I was curious to try was how well the same approach could fit a codebase
made of Terraform (HCL) and YAML files, as those languages are not currently
supported by Semgrep. Hence, I relied on its <code>Generic Pattern Matching</code> engine.</p>
<h2 id="terraform">Terraform</h2>
<p>The official <a href="https://github.com/returntocorp/semgrep-rules/tree/develop/terraform/lang/security" target="_blank">semgrep-rules</a> repository already contains a folder dedicated to Terraform.</p>
<figure>
<a href="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_terraform_rules.jpg">
<img src="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_terraform_rules.jpg" alt="Open source Terraform rules">
</a>
<figcaption>Open source Terraform rules.</figcaption>
</figure>
<p>Within this folder, we can see 7 rules already made open source, mainly focusing
on <a href="https://github.com/bridgecrewio/terragoat" target="_blank">Terragoat</a>
scenarios and S3 buckets.</p>
<h3 id="unencrypted-ebs-volumes">Unencrypted EBS Volumes</h3>
<p>Let’s start wrapping our head around it by picking the <code>unencrypted-ebs-volume</code> rule.
In the repo we can see a sample <a href="https://github.com/returntocorp/semgrep-rules/blob/develop/terraform/lang/security/ebs-unencrypted-volume.tf" target="_blank">Terraform file</a> (shown here below):</p>
<figure><pre><code data-lang="terraform"><span>resource</span> <span>"aws_ebs_volume"</span> <span>"web_host_storage"</span> <span>{</span>
  <span>availability_zone</span> <span>=</span> <span>"ap-southeast-2"</span>
  <span>encrypted</span>         <span>=</span> <span>false</span>
  <span>size</span> <span>=</span> <span>1</span>
  <span># ruleid: unencrypted-ebs-volume</span>
  <span>tags</span> <span>=</span> <span>{</span>
    <span>Name</span> <span>=</span> <span>"abcd-ebs"</span>
  <span>}</span>
<span>}</span></code></pre></figure>
<p>Quite straightforward, with an <code>aws_ebs_volume</code> resource declaring an EBS volume
with encryption disabled (as it can bee seen from <code>encrypted = false</code>).</p>
<p>So what we want to <code>grep</code> here is for an occurrence of <code>encrypted = false</code>
(or the lack of <code>encrypted = true</code>), as shown in the
<a href="https://github.com/returntocorp/semgrep-rules/blob/develop/terraform/lang/security/ebs-unencrypted-volume.yaml" target="_blank">corresponding rule</a>:</p>
<figure><pre><code data-lang="yaml"><span>rules</span><span>:</span>
<span>-</span> <span>id</span><span>:</span> <span>unencrypted-ebs-volume</span>
  <span>patterns</span><span>:</span>
    <span>-</span> <span>pattern-either</span><span>:</span>
      <span>-</span> <span>pattern</span><span>:</span> <span>|</span>
          <span>{...}</span>
    <span>-</span> <span>pattern-not-inside</span><span>:</span> <span>|</span>
        <span>resource "aws_ebs_volume" "..." {... encrypted=true ...}</span>
    <span>-</span> <span>pattern-inside</span><span>:</span> <span>|</span>
        <span>resource "aws_ebs_volume" "..." {...}</span>
  <span>languages</span><span>:</span>
    <span>-</span> <span>generic</span>
  <span>paths</span><span>:</span>
    <span>include</span><span>:</span>
    <span>-</span> <span>'</span><span>*.tf'</span>
  <span>message</span><span>:</span> <span>|</span>
    <span>An EBS volume is configured without encryption enabled.</span>
  <span>severity</span><span>:</span> <span>WARNING</span></code></pre></figure>
<p>You can try this rule in the Semgrep playground:
<a href="https://semgrep.dev/s/ZWrA/" target="_blank">https://semgrep.dev/s/ZWrA/</a>.</p>
<h3 id="open-security-groups">Open Security Groups</h3>
<p>As a second test, I wanted to create my first Semgrep rule to detect
a Security Group open to the world (<code>0.0.0.0/0</code>), like the one below:</p>
<figure><pre><code data-lang="terraform"><span>resource</span> <span>"aws_security_group"</span> <span>"allow_tls"</span> <span>{</span>
  <span>name</span>        <span>=</span> <span>"allow_tls"</span>
  <span>description</span> <span>=</span> <span>"Allow TLS inbound traffic"</span>
  <span>vpc_id</span>      <span>=</span> <span>aws_vpc</span><span>.</span><span>main</span><span>.</span><span>id</span>

  <span>ingress</span> <span>{</span>
    <span>description</span> <span>=</span> <span>"TLS from VPC"</span>
    <span>from_port</span>   <span>=</span> <span>443</span>
    <span>to_port</span>     <span>=</span> <span>443</span>
    <span>protocol</span>    <span>=</span> <span>"tcp"</span>
    <span>cidr_blocks</span> <span>=</span> <span>[</span><span>"10.0.1.0/24"</span><span>,</span> <span>"0.0.0.0/0"</span><span>]</span>
  <span>}</span>

  <span>tags</span> <span>=</span> <span>{</span>
    <span>Name</span> <span>=</span> <span>"allow_tls"</span>
  <span>}</span>
<span>}</span></code></pre></figure>
<p>What we want to <code>grep</code> here is any occurrence of <code>0.0.0.0/0</code> within an <code>ingress</code> block:</p>
<figure><pre><code data-lang="yaml"><span>rules</span><span>:</span>
<span>-</span> <span>id</span><span>:</span> <span>open-security-group</span>
  <span>patterns</span><span>:</span>
    <span>-</span> <span>pattern-inside</span><span>:</span> <span>ingress { ... }</span>
    <span>-</span> <span>pattern</span><span>:</span> <span>"</span><span>0.0.0.0/0"</span>
  <span>languages</span><span>:</span>
    <span>-</span> <span>generic</span>
  <span>paths</span><span>:</span>
    <span>include</span><span>:</span>
    <span>-</span> <span>'</span><span>*.tf'</span>
  <span>message</span><span>:</span> <span>|</span>
    <span>A security group is allowing inbound traffic from the public internet (0.0.0.0/0).</span>
  <span>severity</span><span>:</span> <span>WARNING</span></code></pre></figure>
<figure>
<a href="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_rule_sg.jpg">
<img src="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_rule_sg.jpg" alt="open-security-group rule">
</a>
<figcaption>open-security-group rule.</figcaption>
</figure>
<p>You can try this rule in the Semgrep playground:
<a href="https://semgrep.dev/s/ne51/" target="_blank">https://semgrep.dev/s/ne51/</a>.</p>
<p>Of course this is a vary basic case, where the offending string (<code>0.0.0.0/0</code>)
is directly hardcoded within the security group definition. The rule
will have to be extended if we want to take into account cases where
the CIDR can be specified, for example, via variables.</p>
<h2 id="kubernetes">Kubernetes</h2>
<p>Next, I wanted to create a rule more focused on Kubernetes (or, more precisely, YAML files).</p>
<p>Let’s take as a sample the case where you might want to enforce all your
Kubernetes Ingresses to be private, removing all the <code>public</code> ones:</p>
<figure><pre><code data-lang="yaml"><span>apiVersion</span><span>:</span> <span>extensions/v1beta1</span>
<span>kind</span><span>:</span> <span>Ingress</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>test-ingress</span>
  <span>annotations</span><span>:</span>
    <span>kubernetes.io/ingress.class</span><span>:</span> <span>public</span>
<span>spec</span><span>:</span>
  <span>rules</span><span>:</span>
  <span>-</span> <span>http</span><span>:</span>
      <span>paths</span><span>:</span>
      <span>-</span> <span>path</span><span>:</span> <span>/testpath</span>
        <span>pathType</span><span>:</span> <span>Prefix</span>
        <span>backend</span><span>:</span>
          <span>service</span><span>:</span>
            <span>name</span><span>:</span> <span>test</span>
            <span>port</span><span>:</span>
              <span>number</span><span>:</span> <span>80</span></code></pre></figure>
<p>In this example, we want to <code>grep</code> for the <code>kubernetes.io/ingress.class</code>
annotation, and ensure it has the approved value of <code>nginx-internal</code>:</p>
<figure><pre><code data-lang="yaml"><span>rules</span><span>:</span>
<span>-</span> <span>id</span><span>:</span> <span>public-ingress</span>
  <span>patterns</span><span>:</span>
    <span>-</span> <span>pattern</span><span>:</span> <span>kubernetes.io/ingress.class</span>
    <span>-</span> <span>pattern-not-inside</span><span>:</span> <span>|</span>
        <span>kubernetes.io/ingress.class: nginx-internal</span>
  <span>languages</span><span>:</span>
    <span>-</span> <span>generic</span>
  <span>paths</span><span>:</span>
    <span>include</span><span>:</span>
    <span>-</span> <span>'</span><span>*.yaml'</span>
  <span>message</span><span>:</span> <span>|</span>
    <span>An Ingress has been made public.</span>
  <span>severity</span><span>:</span> <span>WARNING</span></code></pre></figure>
<p>You can try this rule in the Semgrep playground:
<a href="https://semgrep.dev/s/ErGE/" target="_blank">https://semgrep.dev/s/ErGE/</a>.</p>
<hr>

<p>I have to say the extensibility, and simple syntax, of Semgrep are making it
very promising for cloud security teams as well.
In a few hours, thanks to the official documentation and Playground, I was able
to go from absolute 0 to writing my first rules.</p>
<p>The main challenge I can think of at the moment is: how much does Semgrep
overlap with <a href="https://github.com/open-policy-agent/conftest" target="_blank">OPA Conftest</a>?
Although Conftest has been created with cloud resources in mind,
and benefits from the sinergies
with the rest of the OPA offering (like <a href="https://github.com/open-policy-agent/gatekeeper" target="_blank">Gatekeeper</a>), basically everyone in the
industry at some point complained about how cumbersome the <a href="https://www.openpolicyagent.org/docs/latest/policy-language/" target="_blank">Rego</a> language is.
In my opinion, this could be a defining factor that might help expand the adotpion
of Semgrep from platform teams.</p>
<p>I’m quite curious to hear other people’s opinions on this, so please
feel free to reach out to me on <a href="https://twitter.com/lancinimarco" target="_blank">Twitter</a>.</p>
</div></div>]]>
            </description>
            <link>https://www.marcolancini.it/2020/blog-semgrep-for-cloud-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398963</guid>
            <pubDate>Sat, 12 Dec 2020 15:51:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Someone created Chinese flashcards for TV shows and movies ordered by difficulty]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398823">thread link</a>) | @ilamont
<br/>
December 12, 2020 | http://www.jiong3.com/gradedwatching/ | <a href="https://web.archive.org/web/*/http://www.jiong3.com/gradedwatching/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>This table lists 70 tv series and 19 movies in Chinese, ordered by <a href="#Metrics">difficulty</a>. Click the number in the <b>words</b> column to download <a href="#VocabLists">flashcards</a> compatible with <a href="#Pleco">Pleco</a>.</p><div>
    <h2>Tools</h2>
    <p id="Pleco"><a href="https://www.pleco.com/">Pleco</a> is a free dictionary app for Chinese, available for iOS and Android. Flashcard functionality is available as an in-app purchase.</p>
    <p><a href="http://languagelearningwithnetflix.com/">Language Learning with Netflix</a>
    is a free extension for Chrome. It provides several useful features for working with subtitles on Netflix.</p>
    <h2 id="VocabLists">Vocabulary Lists</h2>
    <p>The <a target="_blank" href="http://www.jiong3.com/gradedwatching/Lists/Jiong3comGradedWatchingBasic1kWords.txt">Basic 1k list</a> covers the most common 1000 words used by more than 90% of all shows in the list.
    Those words cover around 75% of all content and are excluded from the individual vocabulary lists and statistics.
    </p><p>
    Click the link in the words column to get a vocabulary list which covers all the remaining words used in the corresponding show.
    The words in the list are in the order of appearance in the show, each word is only listed once at the time it first appears.
</p><p>
    All words can be found in the free <a href="https://www.mdbg.net/">CC-CEDICT</a>, which is also available in Pleco.
    The list format follows the <a href="https://iphone.pleco.com/manual/30200/flash.html#importexportfileformat">Pleco convention</a>.
    Both simplified and traditional characters are included, pinyin and definitions can be added by Pleco during the import.
    </p>
    <p><b>Note: </b> Since automatic word segmentation is not perfect, the lists might contain odd words and some words might be missing.</p>
    <h2 id="Metrics">Word Metrics</h2>
    <h3>Words</h3>
    <p><img src="http://www.jiong3.com/gradedwatching/Plots/words_histogram.svg" alt="histogram of number of words"></p><p>The total number of unique words that a show uses indicates how many words you have to learn in order to understand the whole show. This obviously also depends on how long the show is.</p>
    <h3>Words per hour (w/h) (w/h 4h)</h3>
    <p><img src="http://www.jiong3.com/gradedwatching/Plots/wph_avg.svg" alt="words per hour over time"></p><p>The number of new, unique words a show introduces per hour (w/h). Naturally, the number of new words is highest in the beginning of a show. For a better comparison of shows with different lengths use the (w/h 4h) metric which only considers the first four hours of each show.</p>
    <p><img src="http://www.jiong3.com/gradedwatching/Plots/wph_histogram.svg" alt="histogram of number of words per hour">
    <img src="http://www.jiong3.com/gradedwatching/Plots/wph4h_histogram.svg" alt="histogram of number of words per hour in first 4h"></p><h2>Contact</h2>
    <p>In case you find any errors on the website or in the vocabulary lists feel free to contact me via email.</p>
    <p>I'd be happy to add more shows to the list. If you have subtitles that you'd be willing to share please send me an email. The format would have to be a text based subtitle format, either in simplified or traditional, ideally both.</p>
    <p><img src="http://www.jiong3.com/gradedwatching/Svg/contact.svg"></p>
</div></div>]]>
            </description>
            <link>http://www.jiong3.com/gradedwatching/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398823</guid>
            <pubDate>Sat, 12 Dec 2020 15:33:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paying the Privacy Tax]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398501">thread link</a>) | @reimbar
<br/>
December 12, 2020 | https://www.getrevue.co/profile/themarkup/issues/paying-the-privacy-tax-298830 | <a href="https://web.archive.org/web/*/https://www.getrevue.co/profile/themarkup/issues/paying-the-privacy-tax-298830">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.getrevue.co/profile/themarkup/issues/paying-the-privacy-tax-298830</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398501</guid>
            <pubDate>Sat, 12 Dec 2020 14:45:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No, engineers don't suck at time estimates]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398344">thread link</a>) | @kiyanwang
<br/>
December 12, 2020 | https://blog.nukemberg.com/post/no-engineers-dont-suck-at-estimates/ | <a href="https://web.archive.org/web/*/https://blog.nukemberg.com/post/no-engineers-dont-suck-at-estimates/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main"><div><div><article role="main"><p>No, engineers don’t suck at time estimates - and generally speaking humans are better estimators than what most people believe. This seems rather surprising given all we’ve heard about the problems of bad time estimations, projects going overboard, etc and of course, your personal experience with software time estimates. But if people are really bad at estimation, how does that fit with our obvious evolutionary need to make quick decisions based on partial data? if we can’t estimate well how did we decide if a gap is wide enough to jump over, if an animal is worth the hunt, if a certain area is more likely to have water and shade? Without estimation skills we wouldn’t survive. So what’s going on?</p><p>One obvious explanation is that we are only good at estimating physical things such as sizes and distances. However, this does not seem likely given the large number of non-physical decisions we needed to make, like selecting a mate.
Another, more likely explanation is that the estimates are good, but the interpretation and usage of the estimates is flawed. In other (slightly cynical) words: the engineers are good at estimating, it’s the project managers who suck at using the estimates.</p><p>Let me explain.</p><p>“your estimate was wrong” - is something i’ve heard many times. But this sentence doesn’t make any sense… after all, an estimate is by definition not exact; in fact, if the results would always agree with estimates foul play would be immedialy suspected. If I estimated one day and the actual time was 1.5 days, was I “wrong”? most people would say I wasn’t. But if if the actual time was 20 days most people would argue I was wrong. Somewhere between one and 20 days there is an implicit “reasonable error” threshold we never discussed! I never gave an error margin for my estimate, did I?</p><p>Since we don’t expect an estimate to be an exact guess of the actual value, what do we expect from an estimate? When we make decisions based on estimates, we can only be right or wrong in our decision, you can’t be “a lot more right”. We need to guess a value beyond a certain threshold and within a certain tolerance, with high probability of being right because that our lives depend on that gap being just short enough for us to jump over. Decisions are almost always non-linear like that and it should not be surprising given the nature of knowledge and learning. We take in examples and extrapolate patterns and behaviours. Which means we are dealing with groups, and probability distributions. This may be surprising at first, because when you are estimating this one <em>particular</em> job, you don’t think of a distribution of a million other <em>different</em> jobs. An estimate is predicting the future in which we see the actual value.
</p><div><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><p><img itemprop="thumbnail" src="https://blog.nukemberg.com/img/time-estimate.jpg" alt="/img/time-estimate.jpg"></p><a href="https://blog.nukemberg.com/img/time-estimate.jpg" itemprop="contentUrl"></a></figure></div><p>What we need to know, is that in a certain number of futures, say 90% of them, a value won’t be over or under a certain threshold. Or phrased mathematically, that the 90th percentile of the distribution of futures will be over (or under) a certain number. An estimate is a percentile! but which percentile? is it the median? the 99th?
For software time estimates it has been <a href="https://erikbern.com/2019/04/15/why-software-projects-take-longer-than-you-think-a-statistical-model.html">observed to be the median</a> (50th percentile), meaning to be right about half the times. Is this inherent? Estimates can desmonstrably be calibrated to higher percentiles by as little as <a href="https://www.tonym-v.com/blog/2019/10/2/improve-your-estimations-with-the-equivalent-bet-test">brief emotional self manipulation</a>; You could easily estimate the 90th percentile of many things - just read <a href="https://www.amazon.com/How-Measure-Anything-Intangibles-Business-ebook/dp/B00INUYS2U">How to measure anything</a>.</p><p>Usally when I tell this to people, they often respond with “we’ll train to estimate the average”. Sadly, this is not possible. The mean is a statistically “unstable” or “unrobust” aggregate, where as percentiles are “stable” or “robust”. Consider a group of task completion times [73, 67, 12, 38, 18, 11, 42]. The mean is ~37.29 and the median is pretty close, 38. But as soon as we get another measurement, say 293, the mean changes significantly to 69.25 while the median changes only slightly to 42. The mean is sensitive to outliers, and the more skewed and high variance the distribution the less robust and stable it will be.</p><p>Having estimated tasks, what do we do with them? We sum them up.</p><p>Either for project budget or for by enqueuing with the next tasks, we sum them. But wait, we know that percentiles are not additive! how can this ever work? it never does. Summing up percentiles compounds errors and with skewed distributions, and in particular heavy tailed distributions, the errors are very large. Let’s have a look at what a task completion time distribution would look like:</p><div><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><p><img itemprop="thumbnail" src="https://blog.nukemberg.com/img/task-time-distribution.png" alt="/img/task-time-distribution.png"></p><a href="https://blog.nukemberg.com/img/task-time-distribution.png" itemprop="contentUrl"></a></figure></div><p>A task has some minimum time it has to take, but beyond that it can pretty much take as long as inifinity. We all know from experience, that when things get out of control they go wayyyy out of control. Once you hit a rare bug, you might be chasing a wild goose for two months. That 10% over the estimate might be a day late or a year, the higher percentile you pick the more extreme the errors relatively.</p><p>To be honest, it’s old news; This has been known for a long time. Percentile based project predictions have been done as early as World War II, perhaps even before that - yet they remain fairly unknown in the industry. Not only are we ignorant of proven methods, we invent new ones which are outright harmful. Remember that burn down chart? the <em>backlog</em> is nothing more than a sum of time estimates! And every two weeks, sitting in the famous sprint retrospective people work to calibrate their estimates to the random walk sum of task completion times on the burndown chart. How do you calibrate a percentile to a sum? If the distribution is something like a log-normal distribution, the random walk sum will converge to the mean, and the median is relatively close to the mean - which is summable, and both are pretty stable. So by repeatedly calibrating estimates to the running-sum of task completion times (the backlog) you will converge close to the median. Now go tell your project manager there is a 50% chance of their project running late, anywhere between a day and eternity, and see how they respond. A 50% chance of uncapped delay is a useless estimate.</p><p><strong>Scrum is a training method for useless time estimates</strong>. It actively destroys your ability to manage your project.</p><p>Don’t get me wrong, I’m not against Agile; The spirit of Agile, some of the methods and ceremonies of Scrum have value. But Scrum <em>as a system</em> is actively harmful, especially in high variance situations where the work is far from the nice log-normal distribution. If you <a href="https://blog.nukemberg.com/post/the-burndown-chart-fallacy/">optimize for an arbitrary metric</a>, you will get arbitrary results. In ops/SRE and pure research many people have intuitive sense that Scrum and traditional project management are wrong, although they can’t quite articulate why. The reasons become very clear when we consider what happens to sum based project management methods if the task distribution becomes heavy tailed. A task that is one week late is likely to take <em>at least</em> one more week - is a common thumb rule in such domains; This is called a “Power law” and can be modeled by the famous Pareto distribution. The thing about the Pareto distribution is that its mean does not converge! In other words, using sum based planning methods with such distributions is equivalent to managing by rolling dice. A little worse actually, as dice are a cheap method of generating random numbers where as time estimates are intrusive and sometimes expensive. This isn’t a problem unique to Scrum, nor does it originate from it. The problem is the assumption of determinism and accuracy which is the prevaling “machine age” mindset. Pretty much all of the common project management tools have the same issue - have a look at a Gantt chart, it has no probability intervals or error ranges. They are all worse than useless. It shouldn’t be a surprise that despite people being bad at estimating large tasks naive estimates are reliably more accurate than project management tools.</p><p>Recognizing the probabilistic nature of the world is key. Probability isn’t a tool for making predictions, it is a tool for quantifiying uncertainty. Instead of managing resources (which are usually highly certain) we should be managing uncertainty, with probabilistic methods appropriate for the task. With this mindset, the first thing to do is understand the business context and the distributions involed: are you in a low or high variation domain? Industrial methods which aim to improve throughput and efficiency all assume low variance, sometimes actively force low variance by getting rid of outliers; this isn’t necessarily possible in your business context. Industrial methods are good when used in context, but horrible when used in high variability and unpredictable domains. For those we have other methods, which emphasize low latency and rapid adaptation. Instead of Scrum, you could try:</p><ul><li><a href="https://www.joelonsoftware.com/2007/10/26/evidence-based-scheduling/">Monte-Carlo simulations based on time estimates</a></li><li><a href="https://basecamp.com/shapeup/2.1-chapter-07">Time boxing and bets</a></li><li>Latency optimizing methods which dispense with time estimates, like Kanban</li></ul><p>I’ve listed the methods above in order of rising uncertainty, Monte-Carlo simulations or time boxing would probably be easiest to start with. The biggest obstacle in implementing these is convincing managers that “predictability” isn’t so important as they imagine. For high variation domains it’s nothing more than a fantasy anyway.</p><p>So there you have it: people don’t suck at estimation. They suck at management 🤷</p><hr></article></div></div></div></div>]]>
            </description>
            <link>https://blog.nukemberg.com/post/no-engineers-dont-suck-at-estimates/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398344</guid>
            <pubDate>Sat, 12 Dec 2020 14:18:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Problem Today Is Not Tribalism but Its Absence]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25398325">thread link</a>) | @blindm
<br/>
December 12, 2020 | https://www.discoursemagazine.com/culture-and-society/2020/05/20/the-problem-today-is-not-tribalism-but-its-absence/ | <a href="https://web.archive.org/web/*/https://www.discoursemagazine.com/culture-and-society/2020/05/20/the-problem-today-is-not-tribalism-but-its-absence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                                <p>The dirtiest word in US politics these days is tribalism. For pundits and policymakers, tribalism is blind group loyalty that is tearing our country apart. Mindless tribal affiliations, they say, drive our polarizations and prevent us from finding common ground. The greatest danger of tribalism, we are told, is that it morphs political leanings into social identities, creating political morass, gridlock, and decay.</p>
<p>But these pundits and policymakers have the story backwards. Indeed, we have enormous political challenges because we no longer value or know how to live like tribes: to make rules together, to develop consensus, to work out difficult problems without calling for outside help. In fact, tribes—real tribes—provide a great deal of meaning, community, and connection. Let me take this a step further: if American society were to adopt some “tribal” characteristics, we would all be a lot better off.</p>
<p>During the medieval period, Arab historian Ibn Khaldun (b. 1332) developed a sophisticated theory of tribal politics that has enormous resonance today. In his treatise&nbsp;<em>Muqaddimah</em>&nbsp;he wrote that tribal societies are defined by their social cohesion and a sense of group interconnectedness. This solidarity brings groups together in ways that are crucial for the creation of public goods. The secret to success was what he termed&nbsp;<em>asabiyya</em>—or group feeling. Tribes that had strong&nbsp;<em>asabiyya&nbsp;</em>could build strong empires, forge strong armies, and develop effective governance structures. Leaders who could not cultivate this group feeling among members struggled to find legitimacy, and ultimately collapsed.</p>
<p><em>Asabiyya</em>&nbsp;is a kind of social capital. It is the glue that holds a society together. It is central to the success and failure of tribal governance structures. Yet, we would never know that if we looked at how tribes are described in modern parlance. Contemporary political “tribalism” is just the opposite of all of this. It is an ephemeral factionalism manifested in 280-character tweets or by an endless cycle of cable news pundits.</p>
<p>The problem is compounded by the abuse of the term “tribes.” Today, “tribalism” has become a basket category for our nasty state of affairs; that is, the things we believe cause our increased polarization. In her popular recent book&nbsp;<a href="https://www.penguinrandomhouse.com/books/535371/political-tribes-by-amy-chua/"><em>Political Tribes</em></a>, Amy Chua decries political tribalism as a source of political decay but never defines what tribes are. Similarly,&nbsp;<a href="https://journals.sagepub.com/doi/10.1177/0963721419862289">psychologists</a>&nbsp;argue that so-called tribalism is “a natural and nearly ineradicable form of human cognition and that no group—not even one’s own—is immune.” For writers like George Packer, tribes are&nbsp;<a href="https://www.newyorker.com/news/daily-comment/a-new-report-offers-insights-into-tribalism-in-the-age-of-trump">badges of identity</a>, not of ideology or thought.</p>
<h3>Tribes Protect and Provide</h3>
<p>Anthropologists view tribes differently, seeing them as foundational social units that do a wide range of things. At minimum they are an identity marker. At maximum they provide public goods, such as dispute resolution, self-defense, and even small-scale infrastructure. Anthropologist&nbsp;<a href="https://anthrosource.onlinelibrary.wiley.com/doi/abs/10.1525/aa.1977.79.2.02a00090">Emanuel Marx</a>&nbsp;described tribes as “units of subsistence.” There is huge variation in the way tribes work all over the world, and it is dangerous to generalize, but it in broad strokes tribes are lineage structures that can protect and provide. They even nurture.</p>
<p>No doubt, there are ugly sides to tribes in blood feuds and seemingly internecine conflicts. Yet, as political scientists&nbsp;<a href="https://doi.org/10.1017/S0003055403000534">James Fearon and David Laitin</a>&nbsp;pointed out almost two decades ago, groups with differences exist side by side all around the world but very few of them engage in violent conflict. In other words, conflict among groups with strong affinities is an aberration rather than the norm.</p>
<p>By contrast, for pundits and policymakers the idea of tribe has provided a conceptual hook that helps them explain the loss of community we see around the world. This idea has become an empty vessel for something larger. Indeed, I would argue that what they describe as tribalism is actually its absence. They describe a derisive politics that is a yearning for group feeling. It is a yearning for&nbsp;<em>asabiyya</em>.</p>
<p>In my wanderings around dozens of Afghan villages, I found something unexpected: the death of tribal and other forms of customary authority was greatly exaggerated. Instead, communities worked quickly to resurrect customary structures out of the ashes of conflict. Why? Because they provided the kinds of public goods and services that were of value to people when they could not rely on a state that was unwilling or unable to help.</p>
<p>Not only did communities resurrect tribal and other forms of customary governance structures, they created new institutions that would encompass diversity. This means they updated technologies of custom to help them solve the most challenging of modern conflicts.</p>
<p>For years, American strategists in Afghanistan ignored the positive role tribes and customary authorities could play in politics as they fixated on strengthening top-down government institutions. Several years into the war, young soldiers posted to remote locations started demanding change. Unlike the designers of the intervention who sat in Washington, Brussels, or Kabul, these boots on the ground faced life or death every day. What many of them found was that maintaining good relations with community leaders was key to their survival. On message boards and blogs, they argued the United States was losing in Afghanistan because it was not working with customary structures.</p>
<p>One of these voices, Maj. James Gant wrote a famous white paper, “<a href="https://smallwarsjournal.com/blog/one-tribe-at-a-time">One Tribe at a Time</a>,” where he argued that tribal systems in Afghanistan were the key to victory because they protected residents from abuses by the Taliban and the state. Gant was no anthropologist and there is much he got wrong about the social order he thought he was describing, but he was onto something: the power of community and local self-governance in rural Afghanistan.</p>
<p>Gant’s perspective was important because it contrasted with the standard script, which stated that Afghanistan required a strong state because the tribes had withered away due to decades of conflict. According to conventional wisdom, the collapse of the tribal system led directly to the&nbsp;<a href="https://yalebooks.yale.edu/book/9780300095197/fragmentation-afghanistan">fragmentation of the state</a>; it also&nbsp;<a href="https://yalebooks.yale.edu/book/9780300163681/taliban">created a vacuum</a>&nbsp;that religious extremists, like the Taliban, could fill.</p>
<h3>A Sense of Community and Belonging</h3>
<p>In my book&nbsp;<a href="https://www.cambridge.org/core/books/informal-order-and-the-state-in-afghanistan/5B0FB8D4B407988910AE737DB46C0E66"><em>Informal Order and the State in Afghanistan</em></a><em>,&nbsp;</em>I found that customary leaders were able to build legitimacy because they cultivated a sense of group belonging. They did this by treating most people with dignity, fairness, and respect—even those with whom they disagreed. A far cry from the tribalism frequently weaponized in the US.</p>
<p>The real danger facing the United States now is not tribalism but factionalism. America’s Founders warned us against this even before the Constitution was signed. In&nbsp;<a href="https://avalon.law.yale.edu/18th_century/fed10.asp">Federalist 10</a>, James Madison famously wrote of these dangers. They have always been here; they are not new. The key is to have leaders who can help us overcome divisiveness and rely on one another, just as leaders within tribes must build consensus.</p>
<p>In Afghanistan and beyond, tribal structures are not the primary driver of division. It is the politicians, warlords, and insurgents feeding off donor largesse whose thirst for state power have undermined a sense of common meaning—<em>asabiyya</em>.</p>
<p>In the US, it is not tribalism driving our profane politics, but its absence. Without a strong sense of&nbsp;<em>asabiyya</em>—of group feeling that we are all in this together—we are going nowhere fast. Khaldun’s theory of tribal politics, while written centuries ago, is a powerful parable. It shows how the breakdown of meaningful social relationships leads to political decay.</p>
<p>What society has lost is<em>&nbsp;asabiyya</em>—the glue that holds us together. Tribes can provide us this glue, a sense of community and belonging. Certainly, tribes can exclude, but this is not their&nbsp;<em>raison d’être</em>, which is to provide, to give meaning, and to protect.</p>
					</div></div>]]>
            </description>
            <link>https://www.discoursemagazine.com/culture-and-society/2020/05/20/the-problem-today-is-not-tribalism-but-its-absence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398325</guid>
            <pubDate>Sat, 12 Dec 2020 14:15:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Badges of kindness for your website footers, repos, and more]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25398272">thread link</a>) | @Nathanael
<br/>
December 12, 2020 | https://kindspeech.org/badges/ | <a href="https://web.archive.org/web/*/https://kindspeech.org/badges/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article class="page" id="post-190">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Badges are a discrete and simple way to offer kindness:</p>



<figure><img src="https://api.kindspeech.org/v1/badge" alt=""></figure>



<p>They display a changing, short, kind message, which aspires to make the recipient feel good about who they are and what they already have.</p>



<h2>How to Use Them</h2>



<p>They can easily be embedded online, any place where an image can be displayed from a URL:</p>



<pre><code>https://api.kindspeech.org/v1/badge</code></pre>



<p>The background color can also be customized:</p>



<figure><img src="https://api.kindspeech.org/v1/badge?color=plum" alt=""></figure>



<pre><code>https://api.kindspeech.org/v1/badge?color=plum</code></pre>



<p>For detailed technical information see <a href="https://api.kindspeech.org/">the API documentation.</a></p>



<h4>Markdown</h4>



<pre><code>![](https://api.kindspeech.org/v1/badge)</code></pre>



<h4>HTML</h4>



<pre><code>&lt;img src="https://api.kindspeech.org/v1/badge" /&gt;</code></pre>



<h2>Where to Use Them</h2>



<p>Just a few suggestions! The rest is entirely up to you. 😄</p>



<h4>Website Footers</h4>



<p>A little surprise for those who reach the bottom of your pages.</p>



<figure><img src="https://api.kindspeech.org/v1/badge?color=1e8296" alt=""></figure>



<h4>GitHub Repository Documentation</h4>



<p>Many GitHub repositories use badges to display dynamic information about the state of their project. The Kind Speech badges were designed to have a consistent look and feel so that you can share some love along with the state of your build:</p>



<p>
<img src="https://img.shields.io/badge/contributors-9000-green">
<img src="https://img.shields.io/badge/build-passing-green">
<img src="https://api.kindspeech.org/v1/badge">
</p>



<h4>Email Signatures</h4>



<p>Share some love with every email you send out! Note that some email providers block outside images by default, so recipients may need to explicitly allow the image to load before they can see it. 🤷</p>



<blockquote><p>Dear Doug,</p><p>I was so glad to meet you from your wonderful email. It was interesting to know about your fish and how you take care of them.</p><p>You’re special — just because you’re you.</p><p>Your television friend,</p><cite>—<br>Mister Rogers<p><img src="https://api.kindspeech.org/v1/badge?color=dc5830"></p></cite></blockquote>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://kindspeech.org/badges/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398272</guid>
            <pubDate>Sat, 12 Dec 2020 14:04:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Show the current application's shortcuts on Windows, Linux and macOS]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25398232">thread link</a>) | @tkainrad
<br/>
December 12, 2020 | https://tkainrad.dev/posts/app-to-show-shortcuts-of-current-application-windows-linux-macos/ | <a href="https://web.archive.org/web/*/https://tkainrad.dev/posts/app-to-show-shortcuts-of-current-application-windows-linux-macos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contentdiv">

<p>Looking up keyboard shortcuts on the web takes you out of the current context and breaks your workflow. That’s why, <a href="https://tkainrad.dev/posts/setting-up-linux-workstation/">as a Linux user</a>, I have always been a bit envious of macOS users, who had access to tools that could instantly show the current application’s shortcuts, such as <a href="https://www.mediaatelier.com/CheatSheet/">CheatSheet</a>, and <a href="https://github.com/amiechen/pretzel">Pretzel</a>.</p>
<p>On Windows and Linux, there was no such thing. You had to find shortcut information in the software’s documentation and hope that it was searchable. Or even worse, suffer a massive context switch and google for the shortcuts, until now. KeyCombiner Desktop is free to use and can show the active application’s shortcuts on Windows, Linux, and macOS.</p>
<p>Suppose you are on macOS and already use one of the existing solutions. In that case, you might still want to read further because KeyCombiner goes far beyond looking up the active application’s shortcuts.</p>

<p>If a picture says more than 1000 words, an animation will speak for itself:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/lookup-three-apps2.gif" alt="Instant shortcut lookup for three example applications."> <figcaption>
<p>Instant shortcut lookup for three example applications.</p>
</figcaption>
</figure>
<p>Upon pressing the global trigger, the lookup will appear with a search field in focus, where you can start to type right away. The default trigger is <kbd>super</kbd>+<kbd>shift</kbd>+<kbd>c</kbd> on Windows and Linux, and <kbd>cmd</kbd>+<kbd>shift</kbd>+<kbd>k</kbd> on macOS. This can be configured, I use <kbd>super</kbd>+<kbd>c</kbd> on Linux.</p>
<p>The search terms will be applied to the shortcut description, the key binding, and some hidden fields like the shortcut category. Do you want to search for all file-related bindings that use <kbd>Ctrl</kbd>? Type something like <code>file ctrl</code> and you have your answer.</p>
<p>The lookup window disappears whenever you click outside of it, when you press <kbd>esc</kbd>, or when you switch to another application via <kbd>cmd</kbd>/<kbd>ctrl</kbd>+<kbd>tab</kbd>. If you close via <kbd>esc</kbd>, the search term will be cleared. If you use <kbd>cmd</kbd>/<kbd>ctrl</kbd>+<kbd>tab</kbd>, you can switch back to the active application without losing the cursor position.</p>

<p>If you carefully watched the animation above, you might have noticed that the rows are grouped. The first group has the prefix <code>Active:</code> and is highlighted with a blue background. This group shows the shortcuts for the active application. Everything that is shown below this group is from the user’s personal shortcut and command collections.</p>
<p>To explain what these are, I have to provide some background. KeyCombiner is an application to organize, learn, and practice keyboard shortcuts. A core idea is to learn precisely the shortcuts you need. The only way to achieve this is to choose them yourself, which is done by creating personal collections of shortcuts and text snippets. I like to compare this concept to how you build playlists in music software. Instead of browsing your favorite artists’ albums, KeyCombiner allows you to browse shortcut collections of your favorite applications. Instead of adding songs to your playlists, you can add keyboard shortcuts and text snippets to your personal collections.</p>
<p>The instant lookup of KeyCombiner Desktop profits immensely from these collection building features, and vice-versa. Having instant access to your collections makes them a lot more valuable. In short, these two features complete each other.</p>
<p>The instant lookup works offline. Your personal collections are downloaded only on application startup. If you modified your collections while KeyCombiner Desktop was running, you may reload the lookup via (<kbd>Ctrl</kbd>/<kbd>Cmd</kbd>+<kbd>R</kbd>).</p>
<p>I will try to illustrate this with my personal experience. Currently, I have 10 personal KeyCombiner collections. My largest one contains more or less all shortcuts that I already knew when I started to use KeyCombiner. This collection is publicly accessible via this <a href="https://keycombiner.com/collecting/collections/shared/89e47af4-0f2e-4d5d-98fa-6966bc7453cc/">shareable link</a>. Then, I did a <a href="https://tkainrad.dev/posts/how-i-learned-50-new-keyboard-shortcuts-in-42-minutes/">blog post challenge to learn 50 new keyboard shortcuts as fast as possible</a>. More recently, I <a href="https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">learned <em>all</em> VSCode keyboard shortcuts</a>, which evolved my developing habits and added another collection with 151 shortcuts to my repertoire.
Add to that a few smaller collections I used for learning the shortcuts of Chrome DevTools, Nautilus, Spotify, and Vimium. Having instant access to all of these shortcuts without leaving my current context feels like a superpower, even though I admit that some of those superpowers you see in movies look even more powerful.</p>
<p>My most recent new use case is to look up regular expressions. There is an <a href="https://tkainrad.dev/posts/automatically-add-kbd-tags-with-a-single-regex/">article</a> on how to automatically add HTML &lt;kbd&gt;-tags to any text via a single regex replace operation. I use this for all of my blog posts, all &lt;kbd&gt; tags you see in this post are added this way. However, it wouldn’t be so convenient if I couldn’t instantly look up and copy-paste the required regular expression:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/lookup-regex.gif" alt="The lookup also shows shortcuts and text snippets from your personal collections."> <figcaption>
<p>The lookup also shows shortcuts and text snippets from your personal collections.</p>
</figcaption>
</figure>
<p>KeyCombiner’s instant lookup is a cheatsheet of sorts. But it is context-aware, searchable, and you can expand it quickly by importing from public or shared collections. It is also friendlier to the environment than printing out PDFs and hanging them next to your desk.</p>

<p>There is a very boring answer to this question: By maintaining an extensive public database of keyboard shortcuts. You might have noticed from reading this post that I am quite excited about Keycombiner. That’s why I spend considerable time to parse the documentation pages of software tools for their keyboard shortcuts. It’s not as dull as it sounds like; creative use of regular expressions makes it quite fun. Don’t judge me; everyone has a weird hobby.</p>
<p>You can browse the database at <a href="https://keycombiner.com/collections/">https://keycombiner.com/collections/</a>.<br>
The instant lookup works for all desktop-based applications that are listed there. In particular, it should work for all apps that an average software developer uses (VSCode, JetBrains IDEs, Vim, Eclipse, Chrome, Firefox, Safari, Nautilus, Finder, Notion, Slack, Explorer, Terminal, iTerm2, Obsidian,…). This list is growing fast, and I am happy to take suggestions.</p>
<p>One downside of this approach is that KeyCombiner can only show the default bindings for the active application. If you have changed these bindings, that’s not ideal. Fortunately, If you went through the trouble of changing a binding, you usually won’t need to look it up. In any case, you can add the customized binding to a personal collection, and the lookup will show it as explained above.</p>
<p>Existing tools for macOS use a different approach. They rely on a macOS API to retrieve menu keyboard shortcuts for the current application. This has its advantages and disadvantages. The great thing about it is that it works automatically for all applications that have a menu. On the other hand, applications
don’t necessarily register all of their shortcuts as menu shortcuts.</p>



<p>Simply go to <a href="https://keycombiner.com/desktop/">https://keycombiner.com/desktop/</a> and grab the installer for your system. On macOS, you need to grant some permissions for the instant lookup to work. Please refer to the bottom of the linked page for instructions on how to do that.</p>
<p>KeyCombiner is a SaaS with a generous free tier. <strong>All features described in this article are entirely free to use.</strong> If you use KeyCombiner a lot, please consider upgrading to a Pro subscription to get access to additional features and to support hosting and development efforts.</p>


<p>KeyCombiner can do a lot more things than what’s described in this post. However, the instant lookup has quickly become one of my favorite features. Admittedly, I don’t use KeyCombiner every day for learning shortcuts. Usually, after I have <a href="https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">mastered all shortcuts</a> of a new collection, it takes a couple of days or even weeks until I get back to frequent practice.</p>
<p>In contrast, I use the instant lookup <em>all the time</em>. If I am on a different computer without KeyCombiner installed, I notice that something is missing after a couple of minutes.</p>
<p><strong>Enough about me, though. I’d be thrilled to hear about your experience with the software.</strong></p>
<br>
</div></div>]]>
            </description>
            <link>https://tkainrad.dev/posts/app-to-show-shortcuts-of-current-application-windows-linux-macos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398232</guid>
            <pubDate>Sat, 12 Dec 2020 13:56:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Image codec comparison: AVIF (aom, rav1e, svt), JPEG XL, WebP 2]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398218">thread link</a>) | @jonsneyers
<br/>
December 12, 2020 | https://eclipseo.github.io/image-comparison-web | <a href="https://web.archive.org/web/*/https://eclipseo.github.io/image-comparison-web">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <h2>Statistics</h2>
        <p><a href="https://eclipseo.github.io/speed_results.html" target="_blank">Lossless compression ratio and encoding speed</a>.
        </p><p><a href="https://eclipseo.github.io/lossy_results.html" target="_blank">Lossy compression metrics</a>.
        </p><p><a href="https://eclipseo.github.io/avif_results.html" target="_blank">Comparison between AVIF encoders</a>.
        </p><p><a href="https://eclipseo.github.io/webp_results.html" target="_blank">Comparison between WebP and WebP2</a>.
        </p><p><a href="https://eclipseo.github.io/report.html" target="_blank">Full methodology</a>.
        </p><h2>Notes</h2>
        <p>Large images were first encoded with BPG at q24 filesizes. Big images are 180% of Large. Medium is 60% of Large. Small is 60% of Medium. Tiny is
            60% of Small. Everything else was matched to +/- 5% filesize.</p>
        <p>All the pictures have been compressed from RGB PNGs except SVT-AV1. SVT-AV1 only supports YUV420 input so the filesizes reported are not comparable with other encoders supporting RGB input.</p>
        <p>Both rav1e ard svt-av1 do not support lossless compression, the pictures presented here are only near lossless, so their filesizes is not representative of actual lossless.</p>
        <p>Use Shift to swap images.</p>
        <p>This page is based on <a href="http://people.xiph.org/~xiphmont/demo/daala/update1-tool2b.shtml" target="_blank">Xiph.org's</a>            Daala comparison page. <a href="https://github.com/xooyoozoo/yolo-octo-bugfixes" target="_blank">Originally developed by xooyoozoo</a>.
            A list of sources for the images can be found in <a href="http://eclipseo.github.io/image-comparison-web/cite_images.txt" target="_blank">this text file</a>.</p>
        <p>Last updated: December 2020.</p>
    </div></div>]]>
            </description>
            <link>https://eclipseo.github.io/image-comparison-web</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398218</guid>
            <pubDate>Sat, 12 Dec 2020 13:53:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple's M1 Chip Benchmarks focused on the real-world programming]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398201">thread link</a>) | @ssut
<br/>
December 12, 2020 | https://tech.ssut.me/apple-m1-chip-benchmarks-focused-on-the-real-world-programming/ | <a href="https://web.archive.org/web/*/https://tech.ssut.me/apple-m1-chip-benchmarks-focused-on-the-real-world-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://tech.ssut.me/content/images/size/w300/2020/12/Apple_m1-chip-8-core-cpu-chart_11102020.jpg 300w,
                            https://tech.ssut.me/content/images/size/w600/2020/12/Apple_m1-chip-8-core-cpu-chart_11102020.jpg 600w,
                            https://tech.ssut.me/content/images/size/w1000/2020/12/Apple_m1-chip-8-core-cpu-chart_11102020.jpg 1000w,
                            https://tech.ssut.me/content/images/size/w2000/2020/12/Apple_m1-chip-8-core-cpu-chart_11102020.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://tech.ssut.me/content/images/size/w2000/2020/12/Apple_m1-chip-8-core-cpu-chart_11102020.jpg" alt="Apple's M1 Chip Benchmarks focused on the real-world programming">
            </figure>

            <section>
                <div>
                    <p>I'm pretty impressed by what I've seen with Apple's M1 Chip. It's really fast and powerful for essential everyday tasks, which include browsing the web, working with Intel-based apps, and using programming apps. Yes – the ecosystem is moving, and that may take time, but I think M1 is worth paying for it because of its phenomenal performance.</p><p>M1 is fast, and many benchmarks have proved its performance. However, I was curious about the performance of the programming languages using M1. So I decided to test it for the most popular workloads here.</p><p>Before you see the results, you should know that some benchmark suites are memory-intensive, some are CPU-intensive, and some have no benefits with multi-core processing because of its overhead or its difficulty for utilizing. It means that M1 can have an advantage over the desktop-class multi-core Ryzen processor even though the core count is lesser. <strong>Most importantly, I've focused more on real-world development performance testing rather than synthetic, production tests.</strong></p><p>You can check the raw benchmark data <a href="https://docs.google.com/spreadsheets/d/1g4U7LAImfEcXRihJbySZcRr32tn6WSWAtslfXltds58/edit?usp=sharing">here</a>.</p><p>I add the following comment as of Dec 14: we care how fast our dev computer runs. the multi-core advantage of 3900X is useless for most of the benchmarks here that don't represent the real-world production performance at all but devs usually work on their laptops, desktops, etc most of the time so I think such real-world development performance benchmarks make it worthwhile though. of course, Ryzen 3900X will perform way better than M1 and Intel when it comes to production, mostly achieved by parallelizing.</p><h2 id="test-environment">Test Environment</h2><ul><li>Apple M1: Mac Mini (16GB RAM), MacBook Air (8GB RAM) / macOS Big Sur 11.0.1 (All executables used for benchmarks are natively compiled for Apple Silicon.)</li><li>Ryzen 3900X: ASRock Rack X570D4I-2T / 16GB DDR4-3200 x 2 / Ubuntu 20.04.1 LTS (tested after shutting down background tasks.) – You may wonder why I used 3900X instead of Ryzen 5000-series CPUs: Because I don't have it. And note that it doesn't make sense overclocking memory in a server motherboard.</li><li>Intel i7-9750H: MacBook Pro 16" / 16GB / macOS Big Sur &nbsp;11.0.1</li><li>Intel i9-9880H: MacBook Pro 16" / 32GB / macOS Big Sur 11.0.1</li></ul><h2 id="java-renaissance">Java Renaissance</h2><p><strong>Less is better</strong></p><figure><img src="https://tech.ssut.me/content/images/2020/12/Java-Renaissance-Benchmarks--3-.svg" alt=""></figure><p>Renaissance is a modern, open, and diversified benchmark suite for the JVM, aimed at testing JIT compilers, garbage collectors, profilers, analyzers and other tools.</p><p>Since JVM is memory intensive, and memory is one of the largest bottlenecks for any Java applications, Apple M1 performance is stunning compared to Ryzen 3900X.</p><h2 id="java-scimark-2-0-nist-">Java SciMark 2.0 (NIST)</h2><p><strong>Higher is better</strong></p><figure><img src="https://tech.ssut.me/content/images/2020/12/Java-SciMark-2.0-Benchmarks--NIST---1-.svg" alt=""></figure><p>SciMark 2.0 is a Java benchmark for scientific and numerical computing. It measures several computational <a href="https://math.nist.gov/scimark2/about.html">kernels</a> and reports a composite score in approximate Mflops (Millions of floating point operations per second).</p><h2 id="java-dacapo">Java DaCapo</h2><p><strong>Less is better</strong> </p><figure><img src="https://tech.ssut.me/content/images/2020/12/Java-DaCapo-Benchmarks--309e1fa---1-.svg" alt=""></figure><p>DaCapo benchmark suite is intended as a tool for Java benchmarking by the programming language, memory management and computer architecture communities. It consists of a set of open source, real world applications with non-trivial memory loads.</p><h2 id="python-pyperformance">Python PyPerformance</h2><p><strong>Less is better</strong></p><figure><img src="https://tech.ssut.me/content/images/2020/12/PyPerformance-Benchmarks.svg" alt=""></figure><figure><img src="https://tech.ssut.me/content/images/2020/12/PyPerformance-Benchmarks--Total-Seconds-Elapsed---2-.svg" alt=""></figure><p>The pyperformance project is intended to be an authoritative source of benchmarks for all Python implementations. The focus is on real-world benchmarks, rather than synthetic benchmarks, using whole applications when possible.</p><p>Edit (Dec 15, at 01:55 KST): Fixed an issue I made a mistake that the actual unit is Seconds instead of Milliseconds in the last 'Total Seconds Elapsed' chart while I reuse the subtitles for the benchmark charts.</p><h2 id="go-golang-org-x-benchmarks-">Go (golang.org/x/benchmarks)</h2><p><strong>Less is better</strong></p><figure><img src="https://tech.ssut.me/content/images/2020/12/golang.org_x_benchmarks--3-.svg" alt=""></figure><p>Note here that Go utilized all cores during this benchmark.</p><h2 id="go-golang-benchmarks-">Go (<a href="https://github.com/SimonWaldherr/golang-benchmarks">golang-benchmarks</a>)</h2><p><strong>(Unit: ns/op, Less is better)</strong></p><!--kg-card-begin: html--><table xmlns="http://www.w3.org/1999/xhtml" dir="ltr"><colgroup><col width="221"><col width="129"><col width="151"><col width="100"><col width="100"></colgroup><tbody><tr><td></td><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Apple M1 (Mac Mini)&quot;}">Apple M1 (Mac Mini)</td><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Apple M1 (MacBook Air)&quot;}">Apple M1 (MacBook Air)</td><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Ryzen 3900X&quot;}">Ryzen 3900X</td><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;Intel i7-9750H&quot;}">Intel i7-9750H</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkBase64decode-24&quot;}">BenchmarkBase64decode-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:68.65}">68.65</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:69.77}">69.77</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:137.1}">137.1</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:103}">103</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkBase64regex-24&quot;}">BenchmarkBase64regex-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:12001}">12001</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:12250}">12250</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:32803}">32803</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:18255}">18255</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkNumberRegEx-24&quot;}">BenchmarkNumberRegEx-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7759}">7759</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7931}">7931</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:23379}">23379</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:12206}">12206</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkFulltextRegEx-24&quot;}">BenchmarkFulltextRegEx-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6388}">6388</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6957}">6957</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:18627}">18627</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:10014}">10014</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkNumberParse-24&quot;}">BenchmarkNumberParse-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:48.69}">48.69</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:50.19}">50.19</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:66.83}">66.83</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:58}">58</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkFulltextParse-24&quot;}">BenchmarkFulltextParse-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:726.3}">726.3</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:729.7}">729.7</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:933.2}">933.2</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:839}">839</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkConcatString-24&quot;}">BenchmarkConcatString-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:21949}">21949</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:22810}">22810</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:65498}">65498</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:43343}">43343</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkConcatBuffer-24&quot;}">BenchmarkConcatBuffer-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4.338}">4.338</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4.648}">4.648</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.258}">6.258</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.24}">6.24</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkConcatBuilder-24&quot;}">BenchmarkConcatBuilder-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2.37}">2.37</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3.1}">3.1</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2.934}">2.934</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3.02}">3.02</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkContains-24&quot;}">BenchmarkContains-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5.007}">5.007</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5.204}">5.204</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7.467}">7.467</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7.94}">7.94</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkContainsNot-24&quot;}">BenchmarkContainsNot-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.322}">6.322</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.406}">6.406</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7.693}">7.693</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:8.9}">8.9</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkContainsBytes-24&quot;}">BenchmarkContainsBytes-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5.33}">5.33</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5.511}">5.511</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7.5}">7.5</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:8.49}">8.49</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkContainsBytesNot-24&quot;}">BenchmarkContainsBytesNot-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.57}">6.57</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.773}">6.773</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:9.188}">9.188</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:10.3}">10.3</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkCompileMatch-24&quot;}">BenchmarkCompileMatch-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:70.66}">70.66</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:75.09}">75.09</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:110.1}">110.1</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:83}">83</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkCompileMatchNot-24&quot;}">BenchmarkCompileMatchNot-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:31.65}">31.65</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:32.08}">32.08</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:62.42}">62.42</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:42.1}">42.1</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMatch-24&quot;}">BenchmarkMatch-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:800.2}">800.2</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:804.6}">804.6</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2376}">2376</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1313}">1313</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMatchNot-24&quot;}">BenchmarkMatchNot-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:758.1}">758.1</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:779.3}">779.3</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2311}">2311</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1262}">1262</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkForMap-24&quot;}">BenchmarkForMap-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:18.89}">18.89</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:18.92}">18.92</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:20.37}">20.37</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:20.6}">20.6</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkRangeMap-24&quot;}">BenchmarkRangeMap-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:47.66}">47.66</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:48.59}">48.59</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:53.25}">53.25</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:56.7}">56.7</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkRangeSlice-24&quot;}">BenchmarkRangeSlice-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3.446}">3.446</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3.47}">3.47</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2.022}">2.022</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3.4}">3.4</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkRangeSliceKey-24&quot;}">BenchmarkRangeSliceKey-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4.072}">4.072</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4.121}">4.121</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2.906}">2.906</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3.15}">3.15</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkAdler32-24&quot;}">BenchmarkAdler32-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:699}">699</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:719.4}">719.4</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:644.4}">644.4</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:700}">700</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkBlake2b256-24&quot;}">BenchmarkBlake2b256-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2340}">2340</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2415}">2415</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2026}">2026</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1932}">1932</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkBlake2b512-24&quot;}">BenchmarkBlake2b512-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2343}">2343</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2400}">2400</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1985}">1985</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1945}">1945</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkBlake3256-24&quot;}">BenchmarkBlake3256-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5753}">5753</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5854}">5854</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2489}">2489</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2634}">2634</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMMH3-24&quot;}">BenchmarkMMH3-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:374.3}">374.3</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:383.2}">383.2</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:294}">294</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:377}">377</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkCRC32-24&quot;}">BenchmarkCRC32-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:255.5}">255.5</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:260.4}">260.4</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:152.9}">152.9</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:122}">122</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkFnv128-24&quot;}">BenchmarkFnv128-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4468}">4468</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4502}">4502</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5540}">5540</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4210}">4210</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMD5-24&quot;}">BenchmarkMD5-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3193}">3193</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3211}">3211</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2464}">2464</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2534}">2534</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkSHA1-24&quot;}">BenchmarkSHA1-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:900.4}">900.4</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:910.9}">910.9</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1898}">1898</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1961}">1961</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkSHA256-24&quot;}">BenchmarkSHA256-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:913.5}">913.5</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:927.6}">927.6</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4016}">4016</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4525}">4525</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkSHA512-24&quot;}">BenchmarkSHA512-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6999}">6999</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7033}">7033</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2883}">2883</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:3249}">3249</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkSHA3256-24&quot;}">BenchmarkSHA3256-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4213}">4213</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4231}">4231</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5957}">5957</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5878}">5878</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkSHA3512-24&quot;}">BenchmarkSHA3512-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7329}">7329</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7429}">7429</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:10233}">10233</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:10394}">10394</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkWhirlpool-24&quot;}">BenchmarkWhirlpool-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:32042}">32042</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:32624}">32624</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:35714}">35714</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:39205}">39205</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMapStringKeys-24&quot;}">BenchmarkMapStringKeys-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:68.14}">68.14</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:70.66}">70.66</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:87.62}">87.62</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:100}">100</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMapIntKeys-24&quot;}">BenchmarkMapIntKeys-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:43.6}">43.6</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:48.49}">48.49</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:42.51}">42.51</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:60}">60</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkJsonMarshal-24&quot;}">BenchmarkJsonMarshal-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1240}">1240</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1261}">1261</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:2258}">2258</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1720}">1720</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkJsonUnmarshal-24&quot;}">BenchmarkJsonUnmarshal-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4969}">4969</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5102}">5102</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:9597}">9597</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6484}">6484</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathInt8-24&quot;}">BenchmarkMathInt8-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3128}">0.3128</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3235}">0.3235</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.2298}">0.2298</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.24}">0.24</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathInt32-24&quot;}">BenchmarkMathInt32-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3145}">0.3145</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3166}">0.3166</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.2324}">0.2324</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.239}">0.239</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathInt64-24&quot;}">BenchmarkMathInt64-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3131}">0.3131</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3158}">0.3158</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.2367}">0.2367</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.237}">0.237</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathAtomicInt32-24&quot;}">BenchmarkMathAtomicInt32-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.9}">6.9</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.965}">6.965</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4.02}">4.02</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4.33}">4.33</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathAtomicInt64-24&quot;}">BenchmarkMathAtomicInt64-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:6.898}">6.898</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7.051}">7.051</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4.044}">4.044</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4.27}">4.27</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathMutexInt-24&quot;}">BenchmarkMathMutexInt-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:13.51}">13.51</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:13.63}">13.63</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:8.118}">8.118</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:12.1}">12.1</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathFloat32-24&quot;}">BenchmarkMathFloat32-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3142}">0.3142</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3142}">0.3142</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.2356}">0.2356</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.241}">0.241</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathFloat64-24&quot;}">BenchmarkMathFloat64-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.313}">0.313</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.3167}">0.3167</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.239}">0.239</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.239}">0.239</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkParseBool-24&quot;}">BenchmarkParseBool-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1.427}">1.427</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1.43}">1.43</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.2252}">0.2252</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:0.308}">0.308</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkParseInt-24&quot;}">BenchmarkParseInt-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:10.97}">10.97</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:11.15}">11.15</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:11.84}">11.84</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:13.5}">13.5</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkParseFloat-24&quot;}">BenchmarkParseFloat-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:64.52}">64.52</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:65.74}">65.74</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:90.89}">90.89</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:87}">87</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMathRand-24&quot;}">BenchmarkMathRand-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:13.55}">13.55</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:13.71}">13.71</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:17.27}">17.27</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:21.5}">21.5</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkCryptoRand-24&quot;}">BenchmarkCryptoRand-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:106.6}">106.6</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:112}">112</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:1311}">1311</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:145}">145</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkCryptoRandString-24&quot;}">BenchmarkCryptoRandString-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:107.6}">107.6</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:110.7}">110.7</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:222}">222</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:138}">138</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMatchString-24&quot;}">BenchmarkMatchString-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:4957}">4957</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:5148}">5148</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:13869}">13869</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:7616}">7616</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMatchStringCompiled-24&quot;}">BenchmarkMatchStringCompiled-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:475.5}">475.5</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:496.2}">496.2</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:499.2}">499.2</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:464}">464</td></tr><tr><td data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;BenchmarkMatchStringGolibs-24&quot;}">BenchmarkMatchStringGolibs-24</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:479.3}">479.3</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:496.3}">496.3</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:491.3}">491.3</td><td data-sheets-value="{&quot;1&quot;:3,&quot;3&quot;:480}">480</td></tr></tbody></table><!--kg-card-end: html--><h2 id="sqlite-bench">SQLite Bench</h2><p><strong>Less is better</strong></p><figure><img src="https://tech.ssut.me/content/images/2020/12/SQLite-Bench--1--1.svg" alt=""></figure><figure><img src="https://tech.ssut.me/content/images/2020/12/SQLite-Bench.svg" alt=""></figure><h2 id="redis">Redis</h2><p><strong>Higher is better</strong></p><figure><img src="https://tech.ssut.me/content/images/2020/12/Redis-v6.0.9-Benchmark--1-000-000-Requests-.svg" alt=""></figure><p><strong>Higher is better</strong></p><figure><img src="https://tech.ssut.me/content/images/2020/12/JavaScript-Web-Tooling-Benchmark--v8---1-.svg" alt=""></figure><p>V8 Web Tooling Benchmark is a benchmark suite designed to measure the JavaScript-related workloads commonly used by web developers, such as the core workloads in popular tools like <a href="https://github.com/babel/babel">Babel</a> or <a href="https://github.com/Microsoft/TypeScript">TypeScript</a>. The goal is to measure <strong>only</strong> the JavaScript performance aspect (which is affected by the JavaScript engine) and not measure I/O or other unrelated aspects.</p><p>See the <a href="https://github.com/v8/web-tooling-benchmark/blob/master/docs/in-depth.md">in-depth analysis</a> for a detailed description of the tests included in this benchmark suite.</p><h2 id="javascript-octane-2-0">JavaScript <a href="https://developers.google.com/octane/">Octane 2.0</a></h2><p><strong>Higher is better</strong></p><figure><img src="https://tech.ssut.me/content/images/2020/12/JavaScript-Octane-2.0.svg" alt=""></figure><figure><img src="https://tech.ssut.me/content/images/2020/12/JavaScript-Octane-2.0-Overall.svg" alt=""></figure><h2 id="webpack-build">Webpack Build</h2><p><strong>Less is better</strong></p><p>Target build project: <a href="https://github.com/zuiidea/antd-admin">antd-admin</a></p><figure><img src="https://tech.ssut.me/content/images/2020/12/Antd-admin-webpack-build-time--2-.svg" alt=""></figure><h2 id="conclusion">Conclusion</h2><p>It is very impressive to see the performance of Apple's M1 Chip. It performs better than the existing x86 does in such real-world benchmarks.</p><p>I don't feel like I need to say much: <strong>Just Buy M1 if you'd like to have a low-power, long-lasting, quiet, and performant dev machine.</strong><br><em>M1은 사드세요 제발.</em></p><p><em>The results of MacBook Air (M1) and MacBook Pro 16" (i9-9880H) were provided by courtesy of <a href="https://github.com/zinozzino">Jinho Jeong (@zinozzino)</a>.</em></p>
                </div>
            </section>



            

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://tech.ssut.me/apple-m1-chip-benchmarks-focused-on-the-real-world-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398201</guid>
            <pubDate>Sat, 12 Dec 2020 13:50:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Packaging AWS Lambda functions as container images]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398113">thread link</a>) | @kiyanwang
<br/>
December 12, 2020 | https://acloudguru.com/blog/engineering/packaging-aws-lambda-functions-as-container-images | <a href="https://web.archive.org/web/*/https://acloudguru.com/blog/engineering/packaging-aws-lambda-functions-as-container-images">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="8a920a5" data-element_type="widget" data-widget_type="theme-post-content.default"><div><p>Container image support for <a href="https://aws.amazon.com/lambda/pricing/">AWS Lambda</a> was announced during <a href="https://reinvent.awsevents.com/">AWS re:Invent 2020</a>. This is a major new addition to the AWS functions-as-a-service offering. Lambda provides many benefits to developers in managing scaling, high availability and fault tolerance, and also enabling a pay-per-value model. By supporting container packaging for functions, Lambda is now an option for a broader audience of developers.&nbsp;</p><p>In this post, I explain what this new functionality offers and walk through a tutorial showing how to build a container image and run in a Lambda function.</p><h2 id="h-why-did-aws-add-support-for-container-packaging">Why did AWS add support for container packaging?</h2><p>Before this change, the Lambda deployment package was a zip file. The zip file contains the code and any libraries and dependencies. You could upload this file manually or use automation tools like <a href="https://aws.amazon.com/serverless/sam/">AWS Serverless Application Model</a> (AWS SAM), <a href="https://aws.amazon.com/cdk/">AWS CDK</a>, or <a href="https://www.serverless.com/">Serverless Framework</a>.&nbsp;</p><p>However, many customers have existing investments in container-based deployment tools and workflows. These include Docker in addition to CI/CD, security, and governance tools. With this change, developers can benefit from a uniform development and deployment process.</p><h2 id="h-the-benefits-of-using-container-packaging-for-functions">The benefits of using container packaging for functions</h2><p>Lambda treats container-based functions as immutable entities. When invoked, functions deployed as container images are run as-is. This means that the deployment package is immutable across your different environments, including desktop, the CI/CD process, and the Lambda execution environment.</p><p>For developers with larger workloads, a container-based deployment package can now be up to 10 GB in size. This unlocks many new workload possibilities, especially for data-heavy or-dependency-heavy applications. For machine learning or data analytics, this allows developers to take advantage of the benefits of serverless compute. If you use PyTorch, NumPy and similar libraries, the previous 250 MB deployment package limit prevented many workloads from using Lambda.</p><p>This new approach also offers increased portability across different AWS compute options. You choose a preferred based image for your code and it’s simpler to achieve portability between services like AWS Fargate or Amazon EC2.</p><h2 id="h-how-it-works">How it works</h2><p>With container image support, Lambda supports the <a href="https://docs.docker.com/registry/spec/manifest-v2-2/">Docker image manifest schema</a> and the <a href="https://opencontainers.org/">Open Container Initiative (OCI) specification</a> (version 1.0 onwards). It supports container image deployments from the <a href="https://aws.amazon.com/ecr/">Amazon Elastic Container Registry</a> (ECR).</p><p>The Lambda service provides a variety of base image options with pre-installed runtimes. These base images will be patched and maintained by AWS. Currently, the runtimes supported include dotnetcore2.1, dotnetcore3.1, go1.x, java8, java8.al2, java11, nodejs12.x, nodejs10.x, python3.8, python3.7, python3.6, python2.7, ruby2.5, ruby2.7, provided.al2, and provided. Developers can also provide their own images based on Linux kernels.</p><p>One new interesting component here is the <a href="https://docs.aws.amazon.com/lambda/latest/dg/runtimes-images.html">runtime interface client</a> (RIC). RICs are wrappers that integrate customer function code with the Lambda API at runtime. These are preinstalled on the AWS-provided base images. For images you build, you must ensure that a RIC is present. There is an <a href="https://github.com/aws/aws-lambda-python-runtime-interface-client">open source version available</a> for custom base images.</p><p>There is also a runtime interface emulator (RIE) that enables you to test function code locally. It’s useful in development and other pre-production environments for testing the function by sending HTTP requests. The emulator listens for HTTPS requests on a port inside the container, then it wraps those requests and serves as events to the function. This is also an <a href="https://github.com/aws/aws-lambda-runtime-interface-emulator/">open source project</a>.</p><p>The Lambda execution environment provides a read-only file system at runtime. To write files, you have access to the 512MB /tmp storage space. The default user is the only supported user, which enables Lambda to provide least privilege security permissions during invocation.</p><h2 id="h-many-things-don-t-change">Many things don’t change</h2><p>The ability to package Lambda functions as container images brings new capabilities but many things don’t change. If you are an existing Lambda developer who is happy with your current method of building and deploying applications, you don’t need to change anything. If you want to use this new type of packaging, you can rely on many things continuing to work as they did before.</p><p>The resource and operational models for Lambda are exactly the same. This means that automatic scaling characteristics, high availability across multiple Availability Zones, and the security and isolation models are identical.</p><p>Performance profiles also still depend upon image size, runtime choice, and dependencies in your function. Many of the optimization tips I discuss in this <a href="https://www.youtube.com/watch?v=FTCaOQJvG6Y">YouTube video</a> still work for container-based Lambda functions. Lambda pricing is also the same, regardless of which packaging method you use.</p><p>Major Lambda features are still available to container-based functions. You can continue to use Provisioned Concurrency, extensions, Amazon Elastic File System (EFS), and X-Ray integration. You can also provide these functions access to your VPC as before, use reserved concurrency, or route success and failure handling to Lambda destinations.&nbsp;</p><h2 id="h-how-to-package-a-lambda-function-as-a-container-image">How to package a Lambda function as a container image</h2><p>To show how this works in practice, this walkthrough uses a Linux-based environment with the <a href="https://aws.amazon.com/cli/">AWS CLI</a>, <a href="https://nodejs.org/en/download/">Node.js</a>, and <a href="https://docs.docker.com/get-docker/">Docker</a> already installed.</p><p>1. Create an application directory, set up npm, install the <a href="https://www.npmjs.com/package/faker">Faker.js package</a> for generating test data:</p><pre>mkdir getCustomerFunction
cd getCustomerFunction
npm init –y
npm i faker --save</pre><p>2. Create a file called <em>app.js</em> and paste the following code. This the same Lambda handler code you use in a regular zip-file deployment:</p><div><div><pre>const faker = require('faker')
module.exports.lambdaHandler = async (event, context) =&gt; {
&nbsp; &nbsp; return faker.helpers.createCard()
}</pre></div></div><p>3. Create a file called <em>Dockerfile</em> and paste the following code. This instructs Docker how to build the container, installs any necessary packages, and shows where the Lambda handler is available.</p><pre>FROM public.ecr.aws/lambda/nodejs:12
COPY app.js package*.json ./
RUN npm install
CMD [ "app.lambdaHandler" ]</pre><p id="block-68856527-9a0f-4418-bfde-cf25aa148df1">After these steps, my IDE looks like this:</p><figure><img loading="lazy" width="1092" height="235" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image1.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image1.png 1092w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image1.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image1.png 1024w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image1.png 768w" sizes="(max-width: 1092px) 100vw, 1092px"></figure><p>4. Use Docker to build an image using this function code:</p><pre>docker build -t get-customer .</pre><p>5. Create a new repository in ECR and push the Docker image to the repo. Replace &lt;accountID&gt; with your AWS account ID and &lt;region&gt; with your preferred AWS Region:</p><pre>aws ecr create-repository --repository-name get-customer --image-scanning-configuration scanOnPush=true

docker tag get-customer:latest &lt;accountID&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com/get-customer:latest

aws ecr get-login-password | docker login --username AWS --password-stdin &lt;accountID&gt;.dkr.ecr.us-east-1.amazonaws.com

docker push &lt;accountID&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com/get-customer:latest</pre><figure><img loading="lazy" width="1022" height="287" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image2.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image2.png 1022w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image2.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image2.png 768w" sizes="(max-width: 1022px) 100vw, 1022px"></figure><h2 id="h-invoking-container-image-as-a-lambda-function">Invoking container image as a Lambda function</h2><p>Once the image is pushed to the ECR, you can use it in a new Lambda function. In the <a href="https://console.aws.amazon.com/lambda/home">Lambda console</a>, choose <strong>Create function</strong>, and then select the new container image in the <em>Basic information</em> panel. Choose <strong>Create function</strong> to finish the process.</p><figure><img loading="lazy" width="1245" height="887" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image3.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image3.png 1245w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image3.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image3.png 1024w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image3.png 768w" sizes="(max-width: 1245px) 100vw, 1245px"></figure><p>In the next page, a notification appears when the function is successfully created with the container image. You can test this function in the same way as any regular Lambda function. After choosing <strong>Test</strong>, you see the random test data returned by the function code:</p><figure><img loading="lazy" width="1119" height="523" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image4.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image4.png 1119w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image4.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image4.png 1024w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image4.png 768w" sizes="(max-width: 1119px) 100vw, 1119px"></figure><p>In the Lambda console, you can set the timeout (1–900 seconds) and the memory allocation (128 MB to 10,240 MB). The 10 GB limit is a new feature, raising the previous memory maximum of 3 GB.</p><h2 id="h-using-aws-sam-to-automate-the-process">Using AWS SAM to automate the process</h2><p>Using AWS SAM can automate the build and deployment of container-based Lambda functions. To do this, you need the <a href="https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-install.html">AWS SAM CLI</a> installed. You need the ECR repo URI – to find this, navigate to the <a href="https://console.aws.amazon.com/ecr/repositories">ECR console</a> and copy the URI from the <em>get-customer</em> repo.</p><figure><img loading="lazy" width="1216" height="411" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image5.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image5.png 1216w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image5.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image5.png 1024w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image5.png 768w" sizes="(max-width: 1216px) 100vw, 1216px"></figure><p>This walkthrough deploys exactly the same function, using the ECR repo created earlier. First, you use AWS SAM to initialize a project to generate a sample function and <em>Dockerfile</em>. Next, you use the build and deploy commands to automate to build the image, push to the ECR repo, and create the Lambda function.</p><p>From a terminal:</p><p>1. Enter <em>sam init</em> to start the AWS SAM wizard.</p><p>2. Choose ‘1 – AWS Quick Start Templates’.</p><p>3. You have a choice of zip or image deployment. Choose 2 – Image.</p><p>4. You can select your preferred runtime base image. In this case, choose 1 – amazon/nodejs12.x-base.</p><figure><img loading="lazy" width="723" height="519" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image6.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image6.png 723w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image6.png 300w" sizes="(max-width: 723px) 100vw, 723px"></figure><p>5. For <em>Project </em>name, enter ‘my-sam-function’. This creates a sample project complete with an AWS SAM template, README file, and unit tests.</p><p>6. Navigate into the <em>hello-world</em> function directory in the <em>my-sam-function</em> project, and open the app.js. Paste the following function code and save the changes:</p><pre>const faker = require('faker')
module.exports.lambdaHandler = async (event, context) =&gt; {
&nbsp; &nbsp; return faker.helpers.createCard()
}</pre><p>7. With the terminal in the <em>my-sam-function</em> project directory, build the project:</p><pre>sam build</pre><p>8. Deploy the container-based function using the guided mode of AWS SAM deployment:</p><pre>sam deploy –guided</pre><p>For <em>Stack Name</em>, enter ‘my-sam-project’, enter a preferred Region, then enter the ECR repository URI copied from earlier.</p><figure><img loading="lazy" width="803" height="241" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image7.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image7.png 803w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image7.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image7.png 768w" sizes="(max-width: 803px) 100vw, 803px"></figure><p>After the deployment is complete, the new functions appears in the Lambda console. You can invoke the function by using the <em>Test</em> options used earlier.</p><figure><img loading="lazy" width="1184" height="749" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image8.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image8.png 1184w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image8.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image8.png 1024w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/12/image8.png 768w" sizes="(max-width: 1184px) 100vw, 1184px"></figure><h2 id="h-conclusion">Conclusion</h2><p>With the new container image support for Lambda, you can use Docker to package your custom code and dependencies for Lambda functions. The 10 GB deployment package limit makes it possible to deploy larger workloads that do not fit into the existing 250 MB quota for zip files.&nbsp;</p><p>In this post, I show how to build a Docker image and deploy the image in the Lambda service. I also show how to use AWS SAM to simplify the generation of a boilerplate project, build the image, and deploy the function.</p><p>For more tips and tricks to help you get the most from your Lambda-based applications, visit <a href="https://serverlessland.com/">Serverless Land</a>.</p></div></div></div>]]>
            </description>
            <link>https://acloudguru.com/blog/engineering/packaging-aws-lambda-functions-as-container-images</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398113</guid>
            <pubDate>Sat, 12 Dec 2020 13:29:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizing Lambda Cost with Multi-Threading]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398091">thread link</a>) | @kiyanwang
<br/>
December 12, 2020 | https://www.sentiatechblog.com/aws-re-invent-2020-day-3-optimizing-lambda-cost-with-multi-threading | <a href="https://web.archive.org/web/*/https://www.sentiatechblog.com/aws-re-invent-2020-day-3-optimizing-lambda-cost-with-multi-threading">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><!--## AWS re:Invent 2020 Day 3: Optimizing Lambda Cost with Multi-Threading-->
<p>Amazon has released support for up to 10 GB memory and 6 vCPUs for your Lambda functions. In this article we will explore how these new memory configuration options can drive down costs and execution times for compatible workloads.</p>
<p>Let’s quickly review the Lambda pricing scheme. We’ll ignore the free tier. Lambda is billed at $0.0000166667 for every GB-second. A GB-second is the unit of measurement for 1 GB of memory running for 1 second. Lambdas are often very short lived, so let’s say a particular function has an average execution time of 100ms, and is executed 100 times every minute. That’s 10 seconds of execution time per minute, 14.400 seconds per day, and 432.000 seconds per 30 days. This function is configured to use 128 MB or RAM (1/8th of a GB), so you’re billed for 432.000 / 8 = 54.000 GB-seconds per month. At $0.0000166667 per GB-second, this function will cost a whopping $0.90 per month.</p>
<p>The only tunable performance configuration for Lambda is the amount of memory available to the function. The CPU performance scales with the memory configuration. Lambda functions used to always have 2 vCPU cores, regardless of memory. These cores would be throttled at certain memory configurations. The <a rel="noopener noreferrer" href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-memory.html">documentation</a> states that at 1,769 MB, a function has the equivalent of one vCPU.</p>
<p>With the increased maximum memory of 10GB, up from 3008 MB (<a rel="noopener noreferrer" href="https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-supports-10gb-memory-6-vcpu-cores-lambda-functions/">AWS News</a> - <a rel="noopener noreferrer" href="https://aws.amazon.com/blogs/aws/new-for-aws-lambda-functions-with-up-to-10-gb-of-memory-and-6-vcpus/">AWS Blog</a>), the number of CPUs has become more flexible. We ran some tests and found out that Lambda now has the following CPU tiers:</p>
<table>
<thead>
<tr>
<th>Memory</th>
<th>vCPUs</th>
</tr>
</thead>
<tbody>
<tr>
<td>128 - 3008 MB</td>
<td>2</td>
</tr>
<tr>
<td>3009 - 5307 MB</td>
<td>3</td>
</tr>
<tr>
<td>5308 - 7076 MB</td>
<td>4</td>
</tr>
<tr>
<td>7077 - 8845 MB</td>
<td>5</td>
</tr>
<tr>
<td>8846+ MB</td>
<td>6</td>
</tr>
</tbody>
</table>
<p>This opens up a number of new price tuning options. If a workload supports multi-threading, for example, we can try to optimize the number of vCPUs to reduce execution time. A multi-threading function configured at 3009 MB might execute 1.5x as fast as a 3008 MB function, a 33.3% cost reduction! Let’s see if we can produce these results in real life benchmarks.</p>
<h3>Running tests with ffmpeg</h3>
<p>To test Lambda’s performance we compiled <code>ffmpeg</code> from source and packaged it together with a 100 MB sample video and a simple Python app. Because this package exceeds the maximum size for Lambda deployment packages, we used the new Lambda  Container Image Support (<a rel="noopener noreferrer" href="https://aws.amazon.com/about-aws/whats-new/2020/12/aws-lambda-now-supports-container-images-as-a-packaging-format/">AWS News</a> - <a rel="noopener noreferrer" href="https://aws.amazon.com/blogs/aws/new-for-aws-lambda-container-image-support">AWS Blog</a>) to put <code>ffmpeg</code> and the video together in a container and create a Lambda function from that container. Our performance benchmark will consist of 100 iterations of a video format conversion. The exact command for our initial run of benchmarks is <code>ffmpeg -i source.mkv -c:v libx264 -b:a 128k -threads 1 -y /tmp/target.mp4</code></p>
<p>As you can see, this command is hardcoded to use only one thread. This allows us to set a single-threaded baseline on various memory configurations. We ran 100 iterations on the key memory sizes in the table below. The values chosen are the top and bottom values for every CPU tier. 832 MB was the minimum required to successfully convert the video within 15 minutes.</p>
<h3>Single thread results</h3>
<table>
<thead>
<tr>
<th>Memory</th>
<th>vCPUs</th>
<th>Threads</th>
<th>Average Execution Time</th>
<th>Cost for 100 Executions</th>
</tr>
</thead>
<tbody>
<tr>
<td>832 MB</td>
<td>2</td>
<td>1</td>
<td>832308 ms (832.31 s)</td>
<td>$1.1271</td>
</tr>
<tr>
<td>1769 MB</td>
<td>2</td>
<td>1</td>
<td>396342 ms (396.34 s)</td>
<td>$1.1412</td>
</tr>
<tr>
<td>3008 MB</td>
<td>2</td>
<td>1</td>
<td>361768 ms (361.77 s)</td>
<td>$1.7712</td>
</tr>
<tr>
<td>3009 MB</td>
<td>3</td>
<td>1</td>
<td>361907 ms (361.91 s)</td>
<td>$1.7724</td>
</tr>
<tr>
<td>5307 MB</td>
<td>3</td>
<td>1</td>
<td>362551 ms (362.55 s)</td>
<td>$3.1316</td>
</tr>
<tr>
<td>5308 MB</td>
<td>4</td>
<td>1</td>
<td>359439 ms (359.44 s)</td>
<td>$3.1053</td>
</tr>
<tr>
<td>7076 MB</td>
<td>4</td>
<td>1</td>
<td>360534 ms (360.53 s)</td>
<td>$4.1523</td>
</tr>
<tr>
<td>7077 MB</td>
<td>5</td>
<td>1</td>
<td>359426 ms (359.43 s)</td>
<td>$4.1401</td>
</tr>
<tr>
<td>8845 MB</td>
<td>5</td>
<td>1</td>
<td>359287 ms (359.29 s)</td>
<td>$5.1724</td>
</tr>
<tr>
<td>8846 MB</td>
<td>6</td>
<td>1</td>
<td>360957 ms (360.96 s)</td>
<td>$5.1970</td>
</tr>
<tr>
<td>10240 MB</td>
<td>6</td>
<td>1</td>
<td>361495 ms (361.49 s)</td>
<td>$6.0249</td>
</tr>
</tbody>
</table>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/2usIrwWt5S0vVYYUpe5lKY/cc8d1b2aa761055af87c205a5b96d245/single_threaded.png" alt="Single-threaded Results"></p>
<p>This data clearly shows that any memory configuration above 3008 MB does not improve single thread performance. Memory configurations up to 1769 MB are throttled, from 1769 MB to 3008 MB there are some minor performance increases, and from 3008 MB and up you’re using the full capacity of a single core, which means the average execution time plateaus. At the same time the costs for higher memory configurations are skyrocketing. Clearly, if you’re running single-threaded processes in Lambda you would do well to fit your Lambda’s memory closely to your function’s actual requirements.</p>
<h3>Multi-threaded results</h3>
<p>For our multi-threaded tests, we obtain the number of CPUs from <code>/proc/cpuinfo</code> and configure <code>ffmpeg</code> to use as many threads as there are cores. Let’s take a look at the results.</p>
<table>
<thead>
<tr>
<th>Memory</th>
<th>vCPUs</th>
<th>Threads</th>
<th>Average Execution Time</th>
<th>Diff vs. Single-threaded</th>
<th>Cost for 100 Executions</th>
</tr>
</thead>
<tbody>
<tr>
<td>832 MB</td>
<td>2</td>
<td>2</td>
<td>880404 ms (880.40 s)</td>
<td>+5.78%</td>
<td>$1.1922</td>
</tr>
<tr>
<td>1769 MB</td>
<td>2</td>
<td>2</td>
<td>402968 ms (402.97 s)</td>
<td>+1.67%</td>
<td>$1.1602</td>
</tr>
<tr>
<td>3008 MB</td>
<td>2</td>
<td>2</td>
<td>241733 ms (241.73 s)</td>
<td>-33.18%</td>
<td>$1.1835</td>
</tr>
<tr>
<td>3009 MB</td>
<td>3</td>
<td>3</td>
<td>237562 ms (237.56 s)</td>
<td>-34.36%</td>
<td>$1.1635</td>
</tr>
<tr>
<td>5307 MB</td>
<td>3</td>
<td>3</td>
<td>168755 ms (168.76 s)</td>
<td>-53.45%</td>
<td>$1.4577</td>
</tr>
<tr>
<td>5308 MB</td>
<td>4</td>
<td>4</td>
<td>150779 ms (150.78 s)</td>
<td>-58.05%</td>
<td>$1.3026</td>
</tr>
<tr>
<td>7076 MB</td>
<td>4</td>
<td>4</td>
<td>142042 ms (142.04 s)</td>
<td>-60.60%</td>
<td>$1.6359</td>
</tr>
<tr>
<td>7077 MB</td>
<td>5</td>
<td>5</td>
<td>104318 ms (104.32 s)</td>
<td>-70.98%</td>
<td>$1.2016</td>
</tr>
<tr>
<td>8845 MB</td>
<td>5</td>
<td>5</td>
<td>95304 ms (95.30 s)</td>
<td>-73.47%</td>
<td>$1.3720</td>
</tr>
<tr>
<td>8846 MB</td>
<td>6</td>
<td>6</td>
<td>90039 ms (90.04 s)</td>
<td>-75.06%</td>
<td>$1.2964</td>
</tr>
<tr>
<td>10240 MB</td>
<td>6</td>
<td>6</td>
<td>87455 ms (87.46 s)</td>
<td>-75.81%</td>
<td>$1.4576</td>
</tr>
</tbody>
</table>
<p><img src="https://images.ctfassets.net/9gzi1io5uqx8/3U0RNbpfoWamiGYTzgQvxK/4437e7a6b9f8baa6ae6f5fd841ef2a44/multi_threaded.png" alt="Multi-threaded Results"></p>
<p>What jumps out immediately is that at 832 MB using two threads is actually slower than the single-threaded benchmark. This likely relates to the CPU throttling applied to Lambda functions below 1769 MB: two threads competing for the same limited resources are slower than a single thread having those resources to itself.</p>
<p>At 1769 MB the multi-threaded measurement is almost exactly equal to the single-threaded result. This makes sense, since the documentation states that at 1769 MB, a function has the equivalent of one vCPU. At this level contestation is apparently no longer an issue.</p>
<p>At 3008 MB, the old maximum memory configuration, we start to benefit from using multiple cores. But it starts to get interesting at exactly 1 MB higher, at 3009 MB. This is the first time we get to use more than two cores, and we would expect an immediate performance bump. However, the results at three cores and 3009 MB are only 1.73% better than at two cores and 3008 MB. Apparently, the three cores at 3009 MB do not offer 1.5x the performance of the two cores at 3008 MB, and some throttling is taking place. This is corroborated by the benchmark at 5307 MB: even though this configuration has the same amount of cores, its performance is 28.96% higher than at 3009 MB. This means that AWS is dynamically limiting the amount of processing power available to the function, based on its memory configuration.</p>
<p>Next, at 5308 MB, we have our first four-core benchmark. Here we see that the fourth core adds a significant improvement. Although we added only 0.0188% of memory, performance jumped by 10.65%. The other four-core measurement at 7076 MB yields further improvements, but not enough to offset the additional cost.</p>
<p>Then at 7077 MB, the first five-core benchmark, we see another BIG jump. Again, we only added a single MB of memory, but the fifth core increased performance by an incredible 26.56%. Increasing memory to 8845 MB adds another improvement of 8.64%, but like in the four-core block, this doesn’t offset the additional cost.</p>
<p>At 8846 MB the additional MB and 6th core yields a 5.52% performance boost, and the maximum configuration of 10240 MB is 2.87% faster than the 8846 MB setting.</p>
<h3>Understanding these results</h3>
<p>The single-threaded benchmarks showed that a single core maxes out at relatively low memory configurations. The same logic doesn’t apply to multi-threaded solutions: every tier increased multi-threaded performance. Adding an additional core sometimes adds a big performance gain, and sometimes it hardly adds value.</p>
<p>This leads me to conclude that AWS applies a sort of dynamic capacity ceiling to Lambda functions. For example, this ceiling might be set at 0.5 at 832 MB, which means you can at max use half a core. It’s set to 1.0 at 1769 MB, which means we can use one full core. At 3008 it seems to be set to 1.6667. A full list of ceiling values can be found in the table below:</p>
<table>
<thead>
<tr>
<th>Memory</th>
<th>vCPUs</th>
<th>CPU Ceiling</th>
</tr>
</thead>
<tbody>
<tr>
<td>832 MB</td>
<td>2</td>
<td>0.50</td>
</tr>
<tr>
<td>1769 MB</td>
<td>2</td>
<td>1.00</td>
</tr>
<tr>
<td>3008 MB</td>
<td>2</td>
<td>1.67</td>
</tr>
<tr>
<td>3009 MB</td>
<td>3</td>
<td>1.70</td>
</tr>
<tr>
<td>5307 MB</td>
<td>3</td>
<td>2.39</td>
</tr>
<tr>
<td>5308 MB</td>
<td>4</td>
<td>2.67</td>
</tr>
<tr>
<td>7076 MB</td>
<td>4</td>
<td>2.84</td>
</tr>
<tr>
<td>7077 MB</td>
<td>5</td>
<td>3.86</td>
</tr>
<tr>
<td>8845 MB</td>
<td>5</td>
<td>4.23</td>
</tr>
<tr>
<td>8846 MB</td>
<td>6</td>
<td>4.48</td>
</tr>
<tr>
<td>10240 MB</td>
<td>6</td>
<td>4.72</td>
</tr>
</tbody>
</table>
<p>This explains how single-threaded functions can completely utilize a single core, but multi-threaded applications can’t do the same on multiple cores.</p>
<p>Please note that these values are for my specific video conversion benchmark. This benchmark might not be able to max out all the cores available to it. Other benchmarks might be able to use multiple cores more efficiently and produce different results.</p>
<p>The core take-away is that this benchmark has run exactly the same process under different memory configurations, and consistently produces better results for higher memory configurations in the same CPU tier.</p>
<p>The second finding is that adding an additional core always yields a performance benefit for multi-threaded processes. Some cores (the third and sixth) provide smaller benefits than others (the fourth and fifth). If your function is configured just below one of these thresholds, slightly increasing the value might result in big gains.</p>
<h3>Determining the ideal price point</h3>
<p>Multi-threaded Lambda functions complete faster at higher memory settings, leading to lower costs. In general, the lower execution time offsets a big chunk of the higher memory costs. This is especially visible at 1769, 3009 and 7077 MB: the first configuration costs $1.1602 for 100 executions. The second configuration completes its operation 41.05% faster, at a 0.28% price increase ($1.1635). The 7077 MB setting completes 74.11% faster than the 1769 MB variant, at a 3.57% price increase ($1.2016).</p>
<p>Deciding which price point is best for your workload depends on your requirements: if it’s purely cost-driven, 1769 MB or 3009 MB might be a good starting point. If it’s performance driven, do run some tests at 5308, 7077 and 8846 MB. These memory configurations might perform significantly better at a marginally higher cost.</p>
<h3>Conclusion</h3>
<p>You might have hoped that the new high-memory Lambda functions would also improve single-threaded performance, but alas - the functions seem to run on exactly the same hardware as their lowly 3008 MB siblings. However, the higher Lambda tiers do include three, four, five and six CPU cores. In multi-threaded processes, a single MB …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sentiatechblog.com/aws-re-invent-2020-day-3-optimizing-lambda-cost-with-multi-threading">https://www.sentiatechblog.com/aws-re-invent-2020-day-3-optimizing-lambda-cost-with-multi-threading</a></em></p>]]>
            </description>
            <link>https://www.sentiatechblog.com/aws-re-invent-2020-day-3-optimizing-lambda-cost-with-multi-threading</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398091</guid>
            <pubDate>Sat, 12 Dec 2020 13:23:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Accidental Observations]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398025">thread link</a>) | @bondarchuk
<br/>
December 12, 2020 | https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/strange.html | <a href="https://web.archive.org/web/*/https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/strange.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<br>


<h2><a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/strange2.html">Continued here …</a></h2>
<a name="qringe"></a>
<h2>Quetelet rings</h2>

<p>Quetelet rings may be not very rare, but until now I have only seen artificially produced ones. Impressive examples due to dust particles or algae on the surface of a pond or puddle may be found in the web <a href="http://www.uni-muenster.de/imperia/md/content/fachbereich_physik/didaktik_physik/publikationen/433_colored_rings_on_dusty_surfaces.pdf">[1]</a>, <a href="http://www.atoptics.co.uk/fz96.htm">[2]</a>,<a href="http://www.atoptics.co.uk/fza151.htm">[3]</a>, <a href="https://atoptics.wordpress.com/tag/quetelet-rings/">[4]</a>.
</p><p>
Recently Aleksandr Berdnikov uploaded three photographs of a dusty mirror which show this phenomenon very clearly:</p>
<p>
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/Qu-close.jpg" alt="" width="36%"></span>
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/Qu-far.jpg" alt="" width="25%"></span>
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/Qu-par.jpg" alt="" width="34%"></span>
</p>
<p>The images (source: Wikimedia Commons <a href="https://commons.wikimedia.org/wiki/File:Quetelet_close.jpg">[A]</a>, <a href="https://commons.wikimedia.org/wiki/File:Quetelet_far.jpg">[B]</a>, <a href="https://commons.wikimedia.org/wiki/File:Quetelet_par.jpg">[C]</a>) have been taken with lhe light source closer to the mirror than the camera (about half as far, left image), with the flashlight twice as far as the camera (middle), and with camera and light approximately at the same distance (right).</p>
<p>Aleksandr in his comments to the images describes the relative positions of the flashlight to the camera; but this can be deduced from the images, if only the relative distances are known. In the right picture, the mirror images of the light source and the camera are visible, therefore the arrangement is clear. The other two photos show only the flashlight mirrored. But the dark area in the lower right corner of the first picture must be the back of the light, thus it is to the right and lower than the camera, while in the second picture there  certainly it is the shadow of the camera which obscures part of the lower right, which means that the light is to the left and higher up. There are some reflections of the surroundings in this shadow and below. (Click on the pictures to enlarge!)
</p><p>
As seen on the photographs, the rings are circular, but unlike coronas or aureoles they are not centred around the light source. 
</p>
<p><span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/figuren/QuSkizze1.png" alt="" width="256"></span><br>
&nbsp;&nbsp;<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/figuren/QuSkizze4.png" alt="" width="128"></span><span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/figuren/QuSkizze3.png" alt="" width="128"></span>
</p>
<p>I first deal with the case (which I haven't yet seen) of algae like Chromulina rosanoffii <!--or other dust particles--> over a calm water surface. As shown by Marko Riikonen <a href="https://atoptics.wordpress.com/tag/quetelet-rings/">[4]</a> “this unique sort of alga separates itself from the water surface by forming a stalk on top of which it rests”. 
</p><p>
The colours are due to the <a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/twobeams.html">interference</a> of light rays coming from the same point of the source and arriving at the same point of the retina (or the camera's sensor), but having travelled different paths. The two interfering beams are: light, which is reflected at the water surface and is afterwards scattered to the observer by the particle (an alga), the black line in the neighbouting sketch, and light which first is scattered by a particle, then is reflected by the water surface and finally reaches the observer (white line). 
</p><p>
The sketch to the right is not to scale, actually the particle (white circle) and its mirror image (light grey circle) are so close together that they cannot be resolved by the eye (or camera). 
</p><p>
Knowing that the rings are concentric circles (I shall show this later), it is not difficult to find the position of the centre. Consider the brightest circle which goes through the mirror image of the sun, which is the locus of all points where the two paths have the same length. Another easily to locate point on this circle is the antisolar point in the shadow of one's head. The centre of the rings is just halfway between the antisolar point and the image of the sun, and this is just under the feet of the observer, the nadir.
</p><p>
This is not the case if the light source is close, comparable with the distance of the observer from the mirror. Instead of the antisolar point now the point has to be considered which is just hidden by the lamp (B in the adjacent sketch) or where the shadow of the observer's eye would be (B in the rightmost sketch). If produced by dust on a mirror, the rings are only seen if the illumination angle and viewing angle (as measured from the normal) are small. The pair of sketches to the right illustrates how to find the centre of the rings in this case, and they also illustrate that the rings on the mirror are not changed when the positions of observer and lamp are exchanged.</p>
<a name="mehr"></a>
<p>
The three photos below have been taken with a small circular mirror with 11&nbsp;cm diameter. For the left and middle one, a small incandescent lamp was positioned approximately 5&nbsp;m far from it, and the camera at about half that distance. These two images differ only in focusing: the rings get more pronounced if the light source is in focus, not the grains on the glass. 
</p><p>The third photograph below has been taken with the camera at 2.5&nbsp;m and the lamp at 80&nbsp;cm effective distance. A glass plate has been used to reflect its light to the mirror, therefore “point B” is not obscured by the lamp's case.
</p>  
<center>
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/P1060005-33.jpg" alt="Quetelet rings" width="25%"></span>
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/P1060021-33.jpg" alt="Quetelet rings" width="25%"></span>
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/P1060238-33.jpg" alt="Quetelet rings" width="25%"></span><br>
</center>
<h4>Circles on water</h4>
<p>
To show that the coloured rings are circular, I first treat the simpler case … <a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/qrings.html#mehr">READ MORE</a></p><br>


<a name="Pholcus"></a>
<h2>Glistening spider silk</h2>
<p>Optical effects on spider webs have already been treated here <a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/spiderweb.html">[1],</a> <a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/strange.html#spiderweb">[2].</a> There, the main focus was on the colours seen on the sticky threads of orb webs lit from behind. The non-sticky strands show less conspicuous colours to the eye, but recently I saw a series of surprisingly candy-striped out-of-focus highlights in the blog “The Natural History of Bodega Head” by Jackie Sones <a href="http://bodegahead.blogspot.com/2017/06/silk-road-to-enlightenment.html">[3a,</a>
<a href="http://bodegahead.blogspot.com/2017/07/questions-about-colors.html">b,</a> 
<a href="http://bodegahead.blogspot.com/2017/07/color-combinations.html">c,</a> 
<a href="http://bodegahead.blogspot.com/2017/07/game-of-threads.html">d,</a> 
<a href="http://bodegahead.blogspot.com/2017/07/shifting-sun.html">e,</a> 
<a href="http://bodegahead.blogspot.com/2017/08/the-thread-continues.html">f]</a> 
, which puzzled me. Here are two examples (shown with permission):
</p><p>
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/strand3_sones_jun2017.jpg" alt="" width="49%"></span>&nbsp;&nbsp;
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/strand5_sones_jun2017.jpg" alt="" width="49%"></span>&nbsp;&nbsp;
</p><p> Why are many of the glints cigar-shaped? Shouldn't one expect that the blurred image of the gloss is everywhere as wide as that of the strand so that the shape would be more or less rectangular?</p><p>
Fortunately a cellar spider provided the possibility to investigate this. Cigar shaped striped highlights could be obtained, but the results seemingly depend on the camera. The above pictures have been taken with a SLR camera with a 22.5&nbsp;×&nbsp;15&nbsp;mm sensor; my camera's sensor measures 6&nbsp;×&nbsp;4.5&nbsp;mm.
</p>
<p><span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/P1040880p10.jpg" alt="spider web colours" width="49%"></span>&nbsp;&nbsp;
<span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/P1040710m10r.jpg" alt="spider web colours" width="49%"></span></p>
<p>Glossy strands of the web of Pholcus phalangioides (longbodied cellar spider). Left side: strands slightly out of focus, right side: focused to infinity.
</p>
<a name="MORE"></a>
<p>
With bare eyes this could not be seen because one involuntarily focuses on the spot where one looks, and then most of the colours vanish. But even if one succeeds to focus on the far background with a glistening silk strand nearby, the colours will not be as beautiful as in a photograph. With the camera arbitrary defocussing is easy, and moreover, details of a high resolution image can be enlarged. The larger the sensor of a digital camera, and the larger the aperture, the more impressive are the results.
</p>
<p>
When focused to infinity, so to say to the sun's one-dimensional mirror image, the highlights are only thin stripes orthogonal to the threads. The width of the coloured stripes is the apparent diameter of the sun, their length is the apparent breadth of the out-of-focus strands (which are not seen in the right picture except for their glints). The closer the strands, the longer the stripes. If, however, the strand is focussed at, the (one-dimensional) image of the sun gets blurred  and the gloss is seen on a longer stretch which is given by the apparent diameter of the blurred sun.
</p>
<p>The colours are due to the fact that the surfaces of the silk strands are not smooth, but slightly wrinkled. If out of focus, light arriving at one point of the sensor comes from nearby points of the strand and has travelled different path lengths because of the wrinkles. Interference can result in extinction of parts of the spectrum and enhancement of  other parts. This is perceived as colour. </p>
<p>But what is the reason for the peculiar shapeof the highlights?
<a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/Pholcus.html#MORE">Read more …</a></p>
<br>

<a name="behaucht"></a>
<h2>Dewed windowpane aureole II</h2>
<p>After having written about the <a href="#dewcorona">dewed windowpane,</a> I did not see again such a colourful aureole. But it is possible to see a quite similar one when breathing on the window glass while looking at a distant street lamp. In this case, one can to some extent vary the sizes of the droplets and their distances. The following images have been obtained in that way. </p>

<p><span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/qDSC08622.jpg" alt="window dew aureole" width="500"></span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</p><p><br>
As only a small part of a window can be breathed at, the produced mist is not uniform. Therefore, the diffraction image is not easily interpreted. Towards the rim of the misted area, the droplets get smaller and their distances increase. In the adjacent image the outermost region is grey, which means that the scattered light is white, though dim. The droplets are so small that the product of scattering angle times droplet radius corresponds to the central region of the diffraction image of a small disc.  The small picture below shows the computed colours for diffraction by a circular black disc; the scale gives the product of deflection angle (in degrees) and radius (in micrometers). (The similarity of the diffraction patterns of small drops and black discs has been demonstrated <a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/miecolor.html#aureole">elsewhere.</a> More on that can be found in the section on <a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/diffraction.html">diffraction.</a>)



</p><p>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bildchen/irisiwo4.png" alt="">
</p>
<p> 
Towards the centre of the misted area, the sizes of the droplets increase, and though the scattering angle gets smaller, the product of angle times radius at first increases and the colour becomes straw yellow, brownish, then dark purple and dark green. Still closer to the centre, one might expect the colour sequence to be reversed, as the product mentioned decreases again, but now the density of the droplets is so high that the interference effects due to short-range correlations take over, and the <a href="#dewcorona">previous description</a> is valid. For the smallest scattering angles, there is almost complete destructive interference, the immediate surrounding of the lamp, i.e. the centre of the aureole is dark, and then follows a ringed “spectrum”, blue, then white, then red. In the following, only this central region is dealt with.
</p>
<p><span>
<img src="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/bilder/qDSC08879.jpg" alt="window dew aureole" width="300"></span>
</p>

<p>
It is remarkable how the diffraction image changes when the breathing on the glass is continued so that the density of the mist is slowly increased, or when one first looks throught the outer region of the mist and then moves towards the centre. At first, there is a large dark central region surrounded by greenish grey, then yellow and red. Then, almost suddenly, the radii of the rings decrease and also their colours change. 
</p>
<p>
This can be seen in the image to the right. The photograph has been taken looking not through the centre of the misted region, but to the left of it, so …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/strange.html">https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/strange.html</a></em></p>]]>
            </description>
            <link>https://www.itp.uni-hannover.de/fileadmin/arbeitsgruppen/zawischa/static_html/strange.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398025</guid>
            <pubDate>Sat, 12 Dec 2020 13:09:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dangers of Believing in Freedom]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398017">thread link</a>) | @Ninroot
<br/>
December 12, 2020 | https://reflexio.debec.eu/danger-of-believing-in-freedom | <a href="https://web.archive.org/web/*/https://reflexio.debec.eu/danger-of-believing-in-freedom">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        
        <figure>
            <img alt="cover" src="https://reflexio.debec.eu/assets/panoptique.svg">
            <figcaption><a href="http://ferbos.jeanfrancois.free.fr/psychanalyse-et-creation/spip.php?article137" target="_blank">credit</a></figcaption>
            
        </figure>
        
        <p>A fraction of our behaviors are governed by patterns that, upon closer examination, reveal significant steps in personal development. This article is intended for those who wish to introspect and recognize their patterns as part of the necessary step to grow and prevent becoming an oppressor.</p>

<p>In common use, to believe oneself free is to deny the existence of the causes that explain one’s behavior. To say “I was free to go by the left or by the right” actually means “I don’t know the reasons that make me take one path rather than another”, the reasons exist, we just don’t know them<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. This is the principle of <a href="https://en.wikipedia.org/wiki/Causality_(physics)">causality</a>.</p>

<p>Those who believe they are free tend to believe that others are free for the same reasons. Believing that others act freely is then equivalent to denying the existence of causes in their actions. To say “this person is free to become an engineer or an artist” actually means “I don’t know why this person is in this career rather than another”.</p>

<h2 id="deny">Deny</h2>

<p>Denying the existence of causes is not an isolated problem and Etienne Klein illustrates this very well through a funny anecdote (video in French):</p>

<iframe src="https://www.youtube-nocookie.com/embed/Fj5r1ry2TTU?start=217" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<blockquote>
  <p>The other day […], I was giving a lecture at Central [Grande École in France] on relativity and I was doing the same calculation of Einstein’s 1905 calculation in which they show that the duration of a phenomenon depends on the speed of the observer in relation to this phenomenon […]. At the end of the demonstration a pupil asks to speak and says to everyone “Sir, I do not agree with Einstein”. I was happy, I had a student who had a critical mind, I ask him to argue. I was expecting him to talk about Poincaré who restores the luminiferous aether… in short, to argue. That he would argue from arguments that come from physics and the guy says “Sir I don’t believe the dilation of time because I don’t feel it”. In other words, this young man who was accepted in Centrale, <em>thought that his feeling, his subjectivity, had a power great enough to be able to discredit what a century of objectification has made it possible to establish</em>. - Etienne Klein</p>
</blockquote>

<p>In our case, it is not about physical phenomena but about human behavior. People denying (consciously or not) the deterministic character on which our behavior depends, oppose the theories that are more than a century old, such as the social determinism of Emile Durkeim for example. This attitude, in addition to being obsolete, is dangerous.</p>

<h2 id="dangers">Dangers</h2>

<p>Omitting the reasons for human behavior leads to difficult situations that are encountered in many different contexts:</p>
<ul>
  <li>A bad parent gets angry at its child without trying to understand the reasons for its child’s misbehavior. In fact, the child felt lonely throughout dinner and wanted to get someone’s attention.</li>
  <li>A bad manager blames an employee without trying to find the reasons for the delay. In fact, what was asked for in the first place didn’t make much sense when looking at it more closely and a redesign was required, making the delivery as late as necessary.</li>
  <li>A bad engineer denigrates the misuse of a system by a user without ever trying to meet the person. In fact, no user input control was implemented, leaving the system capable of harming itself.</li>
  <li>etc.</li>
</ul>

<p>Getting rid of the need to understand others generates a lot of frustration, especially if it involves a hierarchical relationship. If at the level of a team, “first accountability and then blame” is disastrous, imagine at the level of a nation.</p>

<blockquote>
  <p>Moreover, the frequency of torture is always a sign of faith or laziness in the Government. There is no evil that cannot be made good for something. Jean-Jacques Rousseau — Du contrat social (1762)</p>
</blockquote>

<h2 id="reasons">Reasons</h2>

<p>So where does this trend come from? There are many reasons. Etienne Klein explains it by laziness and narcissism: “I find that this relativism, when it is too strong, is a perfect legitimization of <em>intellectual laziness</em>, that you can judge what is going on in Nature from your subjectivity alone, sometimes even from your narcissism alone. It relieves you of having to learn a couple of things about quantum mechanics, particle physics or the Higgs boson”.</p>

<p>Confirmation bias or <em>conflict of interest</em> stem also that tendency. This is why, a manager of a team prefers to believe that another team is intrinsically incompetent rather than investing some of my resources in training them.</p>

<p>Last example: <em>who would boast of not being free?</em> It is even the first term of the French national motto “liberty, equality, fraternity”.</p>

<p>Although these reasons can be explained, they are no less dangerous. So what can be done?</p>

<h2 id="solution">Solution</h2>

<p>Recognize that <em>freedom is limited</em>. Don’t see this as a fatality; on the contrary, it is the essential point for growing up. Consider this as a constraint of the system you are designing, which hidden, cannot help to find the appropriate solution.</p>

<p>Once acknowledged, areas for improvement will come naturally. Some disciplines such as UX design have understood this early on. A designer will adjust the interface if many users interact in unexpected ways. User behaviors prevail over the designer’s wishes or predictions. Thanks to the trends in human behavior that UX has been able to establish principles, evaluate them, refine them, etc.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Are we free? Should we fight for our freedom? This article does not pretend to answer these questions. On the other hand, a fraction of our behaviors seem to be governed by patterns that, if we take the time to look into them, reveal actionable steps for personal development. Denying these patterns and neglecting the need to understand them is a lost opportunity to improve and may turn into oppression.</p>

<p>Assuming our behavior as the result of an unpredictable phenomenon is firstly a sign of narcissism, but above all a denial of the ability to introspect, to recognize our patterns, to understand ourselves, in other words, to grow. Expanding that idea to others is dangerous. Considering the behavior of others as absolutely unforeseeable is first naive toward the social sciences, but it is above all to rid ourselves of the responsibility to understand, to empathize, in fact to free the other. <a href="https://twitter.com/arnaud_debec/status/1332434506112970753">So acknowledge you live in a cage before planning to escape</a>.</p>

<hr>



    </div></div>]]>
            </description>
            <link>https://reflexio.debec.eu/danger-of-believing-in-freedom</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398017</guid>
            <pubDate>Sat, 12 Dec 2020 13:08:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Reliably Scale Your Data Platform for High Volumes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398009">thread link</a>) | @oedmarap
<br/>
December 12, 2020 | https://shopify.engineering/reliably-scale-data-platform | <a href="https://web.archive.org/web/*/https://shopify.engineering/reliably-scale-data-platform">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p><strong>By&nbsp;Arbab Ahmed and Bruno Deszczynski</strong></p>
<p><strong></strong>Black Friday and Cyber Monday—or as we like to call it, BFCM—is one of the largest sales events of the year. It’s also one of the most important moments for Shopify and our merchants. To put it into perspective, this year our merchants across more than 175 countries sold a record breaking $5.1+ billion over the sales weekend.&nbsp;</p>
<p>That’s a lot of sales. That’s a lot of data, too.</p>
<p>This BFCM, the Shopify data platform saw an average throughput increase of 150 percent. Our mission as the Shopify Data Platform Engineering (DPE) team is to ensure that our merchants, partners, and internal teams have access to data quickly and reliably. It shouldn’t matter if a merchant made one sale per hour or a million; they need access to the most relevant and important information about their business, without interruption. While this is a must all year round, the stakes are raised during BFCM.</p>
<p>Creating a data platform that withstands the largest sales event of the year means our platform services need to be ready to handle the increase in load. In this post, we’ll outline the approach we took to reliably scale our data platform in preparation for this high-volume event.&nbsp;</p>

<p>Shopify’s data platform is an interdisciplinary mix of processes and systems that collect and transform data for use by our internal teams and merchants. It enables access to data through a familiar pipeline:</p>
<ul>
<li>
<strong>Ingesting data</strong> in any format, from any part of Shopify. “Raw” data (for example, pageviews, checkouts, and orders) is extracted from Shopify’s operational tables without any manipulation. Data is then conformed to an Apache Parquet format on disk.</li>
</ul>
<ul>
<li>
<strong>Processing data,</strong> in either <em>batches</em> or <em>streams,</em> to form the foundations of business insights. Batches of data are “enriched” with models developed by data scientists, and processed within Apache Spark or <a href="https://shopify.engineering/build-production-grade-workflow-sql-modelling" target="_blank" title="How to Build a Production Grade Workflow with SQL Modelling" rel="nofollow noopener noreferrer">dbt</a>.&nbsp;</li>
</ul>
<ul>
<li>
<strong>Delivering</strong> <strong>data</strong> to our merchants, partners, and internal teams so they can use it to make great decisions quickly. We rely on an internal collection of streaming and serving applications, and libraries that power the merchant-facing analytics in Shopify. They’re backed by BigTable, GCS, and CloudSQL.</li>
</ul>
<p>In an average month, the Shopify data platform processes about 880 billion MySQL records and 1.75 trillion Kafka messages.</p>
<h2>Tiered Services</h2>
<p>As engineers, we want to conquer every challenge <em>right now.</em> But that’s not always realistic or strategic, especially when not all data services require the same level of investment. At Shopify, a <strong>tiered services</strong> taxonomy helps us prioritize our reliability and infrastructure budgets in a broadly declarative way. It’s based on the potential impact to our merchants and looks like this:</p>
<table>
<tbody>
<tr>
<td>
<p><strong>Tier 1</strong></p>
</td>
<td>
<p>This service is <em>critical</em> <em>externally</em>, for example. to a merchant’s ability to run their business</p>
</td>
</tr>
<tr>
<td>
<p><strong>Tier 2</strong></p>
</td>
<td>
<p>This service is <em>critical</em> <em>internally</em> to business functions, e.g. a operational monitoring/alerting service</p>
</td>
</tr>
<tr>
<td>
<p><strong>Tier 3</strong></p>
</td>
<td>
<p>This service is <em>valuable internally</em>, for example, internal documentation services</p>
</td>
</tr>
<tr>
<td>
<p><strong>Tier 4</strong></p>
</td>
<td>
<p>This service is an <em>experiment</em>, in very early development, or is otherwise disposable. For example, an emoji generator</p>
</td>
</tr>
</tbody>
</table>

<p>The highest tiers are top priority. Our ingestion services, called <em>Longboat</em> and <em>Speedboat</em>, and our merchant-facing query service <em>Reportify</em> are examples of services in Tier 1.</p>

<p>As we’ve mentioned, each BFCM the Shopify data platform receives an unprecedented volume of data and queries. Our data platform engineers did some forecasting work this year and predicted nearly two times the traffic of 2019. The challenge for DPE is ensuring our data platform is prepared to handle that volume.&nbsp;</p>
<p>When it comes to BFCM, the primary risk to a system’s reliability is directly proportional to its throughput requirements. We call it <em>throughput risk.</em> It increases the closer you get to the front of the data pipeline, so the systems most impacted are our <strong><em>ingestion</em></strong> and <strong><em>processing systems</em></strong>.</p>
<p>With such a titillating forecast, the risk we faced was unprecedented throughput pressure on data services. In order to be BFCM ready, we had to prepare our platform for the tsunami of data coming our way.</p>

<p>We tasked our Reliability Engineering team with Tier 1 and Tier 2 service preparations for our ingestion and processing systems. Here’s the steps we took to prepare our systems most impacted by BFCM volume:</p>
<h2>1. Identify Primary Objectives of Services</h2>
<p>A data ingestion service's main operational priority can be different from that of a batch processing or streaming service. We determine upfront what the service is optimizing for. For example, if we’re extracting messages from a limited-retention Kafka topic, we know that the ingestion system needs to ensure, above all else, that no messages are lost in the ether because they weren’t consumed fast enough. A batch processing service doesn’t have to worry about that, but it may need to prioritize the delivery of one dataset versus another.</p>
<p>In Longboat’s case, as a batch data ingestion service, its primary objective is to ensure that a raw dataset is available within the interval defined by its data freshness service level objective (SLO). That means Longboat is operating reliably so long as every dataset being extracted is no older than eight hours— the default <em>freshness</em> SLO. For Reportify<strong>, </strong>our main query serving service, its primary objective is to get query results out as fast as possible; its reliability is measured against a <em>latency </em>SLO.</p>
<h2>2. Pinpoint Service Knobs and Levers</h2>
<p>With primary objectives confirmed, you need to identify what you can “turn up or down” to sustain those objectives.</p>
<p>In Longboat’s case, extraction jobs are orchestrated with a batch scheduler, and so the first obvious lever is <em>job frequency</em>. If you discover a raw production dataset is stale, it could mean that the extraction job simply needs to run more often. This is a service-specific lever.</p>
<p>Another service-specific lever is Longboat’s “overlap interval” configuration, which configures an extraction job to redundantly ingest some overlapping span of records in an effort to catch late-arriving data. It’s specified in a number of hours.</p>
<p>Memory and CPU are universal compute levers that we ensure we have control of. Longboat and Reportify run on Google Kubernetes Engine, so it’s possible to demand that jobs request more raw compute to get their expected amount of work done within their scheduled interval (ignoring total compute constraints for the sake of this discussion).</p>
<p>So, in pursuit of data freshness in Longboat, we can manipulate:</p>
<ol>
<li>Job frequency</li>
<li>Longboat overlap interval</li>
<li>Kubernetes Engine Memory/CPU requests</li>
</ol>
<p>In pursuit of <em>latency</em> in Reportify, we can turn knobs like its:</p>
<ol>
<li>BigTable node pool size&nbsp;</li>
<li>ProxySQL connection pool/queue size</li>
</ol>
<h2>3. Run Load Tests!</h2>
<p>Now that we have some known controls, we can use them to deliberately constrain the service’s resources. As an example, to simulate an unrelenting N-times throughput increase, we can turn the infrastructure knobs so that we have 1/N the amount of compute headroom, so we’re at N-times nominal load.</p>
<p>For Longboat’s simulation, we manipulated its “overlap interval” configuration and tripled it. Every table suddenly looked like it had roughly three times more data to ingest within an unchanged job frequency; throughput was tripled.</p>
<p>For Reportify, we leveraged our <a href="https://shopify.engineering/performance-testing-shopify" target="_blank" title="Pummelling the Platform–Performance Testing Shopify - Shopify Engineering" rel="nofollow noopener noreferrer">load testing tools</a> to simulate some truly haunting throughput scenarios, issuing an increasingly extreme volume of queries, as seen here:</p>
<figure><img alt="A line graph showing streaming service queries per second by source. The graph shows increase in the volume of queries over time during a load test." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/streaming-queries-per-second-graph.jpg?v=1607444696" src="https://cdn.shopify.com/s/files/1/0779/4361/files/streaming-queries-per-second-graph.jpg?v=1607444696">
<figcaption>Streaming service queries per second metric after the load test</figcaption>
</figure>
<p>In this graph, the doom is shaded purple.&nbsp;</p>
<p>Load testing answers a few questions immediately, among others:</p>
<ul>
<li>Do infrastructure constraints affect service uptime?&nbsp;</li>
<li>Does the service’s underlying code gracefully handle memory/CPU constraints?</li>
<li>Are the raised service alarms expected?</li>
<li>Do you know what to do in the event of every fired alarm?</li>
</ul>
<p>If any of the answers to these questions leave us unsatisfied, the reliability roadmap writes itself: we need to engineer our way into satisfactory answers to those questions. That leads us to the next step.&nbsp;</p>
<h2>4. Confirm Mitigation Strategies Are Up-to-Date</h2>
<p>A service’s reliability depends on the speed at which it can recover from interruption. Whether that recovery is performed by a machine or human doesn’t matter when your CTO is staring at a service’s reliability metrics! After deliberately constraining resources, the operations channel turns into a (controlled) hellscape and it's time to act as if it were a real production incident.</p>
<p>Talking about mitigation strategy could be a blog post on its own, but here are the tenets we found most important:</p>
<ol>
<li>
<strong>Every alert must be directly actionable</strong>. Just saying “the curtains are on fire!” without mentioning “put it out with the extinguisher!” amounts to noise.</li>
<li>
<strong>Assume that mitigation instructions will be read by someone broken out of a deep sleep</strong>. Simple instructions are carried out the fastest.</li>
<li>
<strong>If there is </strong><strong><em>any </em></strong><strong>ambiguity or unexpected behavior during controlled load tests, you’ve identified new reliability risks.</strong> Your service is less reliable than you expected. For Tier 1 services, that means everything else drops and those risks should be addressed immediately.</li>
<li>
<strong>Plan another controlled load test</strong> and ensure you’re confident in your recovery.</li>
<li>
<strong>Always over-communicate, even if acting alone</strong>. Other engineers will devote their brain power to your struggle.</li>
</ol>
<h2>5. Turn the Knobs Back</h2>
<p>Now that we know what can happen with an overburdened infrastructure, we can make an informed decision whether the service carries real throughput risk. If we absolutely hammered the service and it skipped along smiling without risking its primary objective, we can leave it alone (or even scale <em>down</em>, which will have the CFO smiling too).</p>
<p>If we don’t feel confident in our ability to recover, we’ve unearthed new risks. The service’s development team can use this information to plan resiliency projects, and we can collectively scale our infrastructure to minimize throughput risk in the interim.</p>
<p>In general, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/reliably-scale-data-platform">https://shopify.engineering/reliably-scale-data-platform</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/reliably-scale-data-platform</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398009</guid>
            <pubDate>Sat, 12 Dec 2020 13:05:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Resiliency Planning for High-Traffic Events]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25398002">thread link</a>) | @oedmarap
<br/>
December 12, 2020 | https://shopify.engineering/resiliency-planning-for-high-traffic-events | <a href="https://web.archive.org/web/*/https://shopify.engineering/resiliency-planning-for-high-traffic-events">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>Each year, Black Friday Cyber Monday weekend represents the peak of activity for Shopify. Not only is this the most traffic we see all year, but it’s also the time our merchants put the most trust in our team. Winning this weekend each year requires preparation, and it starts as soon as the weekend ends.</p>
<h2>Load Testing &amp; Stress Testing:&nbsp;How Does the System React?</h2>
<p>When preparing for a high traffic event, load testing regularly is key. We have discussed some of the tools we use <a href="https://shopify.engineering/performance-testing-shopify" target="_blank" rel="nofollow noopener noreferrer">already</a>, but I want to explain how we use these exercises to build towards a more resilient system.</p>
<p>While we use these tests to confirm that we can sustain required loads or probe for new system limits, we can also use regular testing to find potential regressions. By executing the same experiments on a regular basis, we can spot any trends at easily handled traffic levels that might spiral into an outage at higher peaks.</p>
<p>This same tool allows us to run similar loads against differently configured shops and look for differences caused by the theme, configuration, and any other dimensions we might want to use for comparison.</p>
<h2>Resiliency Matrix:&nbsp;What are Our Failure Modes?</h2>

<figure>
<p><img alt="This user-centric resiliency matrix shows the potential failures and their impact on user experience. For example, can a user browse (yes) or check out (no) if MySQL is down. " data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/resiliency_matrix.png?format=jpg&amp;quality=90&amp;v=1607622786" src="https://cdn.shopify.com/s/files/1/0779/4361/files/resiliency_matrix.png?format=jpg&amp;quality=90&amp;v=1607622786"></p>
<figcaption>User-centric resiliency matrix documenting expected user experience and possible failures</figcaption>
</figure>
<div><p>The act of writing this matrix serves as a very basic tabletop chaos exercise. It forces teams to consider how well they understand their dependencies and what the expected behaviors are.</p><p>This exercise also provides a visual representation of the interactions between dependencies and their failure modes. Looking across rows and columns reveals areas where the system is most fragile. This provides the starting point for planning work to be done. In the above example, this matrix should start to trigger discussion around the ‘User can check out’ experience and what can be done to make this more resilient to a single dependency going ‘down’.</p></div>
<h2>Game Days:&nbsp;Do Our Models Match?</h2>
<div><p>So, we’ve written our resilience matrix. This is a representation of our mental model of the system, and when written, it's probably a pretty accurate representation. However, systems change and adapt over time, and this model can begin to diverge from reality. </p><p>This divergence is often unnoticed until something goes wrong, and you’re stuck in the middle of a production incident asking “Why?”. Running a <a href="https://shopify.engineering/four-steps-creating-effective-game-day-tests" target="_blank" rel="nofollow noopener noreferrer">game day</a> exercise allows us to test the documented model against reality and adjust in a controlled setting.</p><p>The plan for the game day will derive from the resilience matrix. For the matrix above, we might formulate a plan like:</p></div>
<figure><img alt="This game day exercise allows us to test the model against reality and adjust in a controlled setting. This plan lays out scenarios to be tested and how they will be accomplished." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Game_day_exercise_480x480.png?format=jpg&amp;quality=90&amp;v=1607622968" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Game_day_exercise_480x480.png?format=jpg&amp;quality=90&amp;v=1607622968">
<figcaption>Game day planning scenarios&nbsp;</figcaption>
</figure>
<p>Here, we are laying out what scenarios are to be tested, how those will be accomplished, and what we expect to happen.&nbsp;</p>
<p>We’re not only concerned with external effects (what works, what doesn’t), but internally do any expected alerts fire, are the appropriate on-call teams paged, and do those folks have the information available to understand what is happening?</p>
<p>If we refer back to How Complex Systems Fail, the defences against failure are technical, human, and organizational. On a good game day, we’re attempting to exercise all of these.</p>
<ul>
<li>Do any automated systems engage?</li>
<li>Do the human operators have the knowledge, information and tools necessary to intervene?</li>
<li>Do the processes and procedures developed help or hinder responding to the outage scenario?</li>
</ul>
<p>By tracking the actual observed behavior, we can then update the matrix as needed or make changes to the system in order to bring our mental model and reality back into alignment.</p>
<h2>Incident Analysis:&nbsp;How Do We Get Better?</h2>
<div><p>During the course of the year, incidents happen which disrupt service in some capacity. While the primary focus is always in restoring service as fast as possible, each incident also serves as a learning opportunity.</p><p>This article is not about why or how to run a post-incident review; there are more than enough well-written pieces by folks who are experts on the subject. But to refer back to How Complex Systems Fail, one of the core tenets in how we learn from incidents is “<a href="https://how.complexsystems.fail/#7" title="Post-accident attribution to a ‘root cause’ is fundamentally wrong" target="_blank" rel="nofollow noopener noreferrer">Post-accident attribution to a ‘root cause’ is fundamentally wrong</a>.” </p><p>When focusing on a single root cause, we stop at easy, shallow actions to resolve the ‘obvious’ problem. However, this ignores deeper technical, organizational, and cultural issues that contributed to the issue and will again if uncorrected.</p></div>
<h2>What’s Special About BFCM?</h2>
<div><p>We’ve talked about the things we’re constantly doing, year-round to ensure we’re building for reliability and resiliency and creating an anti-fragile system that gets better after every disruption. So what do we do that’s special for the big weekend?</p><p>We’ve already mentioned How Complex Systems Fail several times, but to go back to that well once more, “<a href="https://how.complexsystems.fail/#14" target="_blank" title="Change introduces new forms of failure" rel="nofollow noopener noreferrer">Change introduces new forms of failure</a>.” As we get closer to Black Friday, we slow down the rate of change.</p><p>This doesn’t mean we’re sitting on our hands and hoping for the best, but rather we start to <a href="https://shopify.engineering/organizing-2000-developers-bfcm-remotely" target="_blank" rel="nofollow noopener noreferrer">shift where we’re investing our time</a>. Fewer new services and features as we get closer, and more time spent dealing with issues of performance, reliability, and <a href="https://shopify.engineering/capacity-planning-shopify" target="_blank" rel="nofollow noopener noreferrer">scale</a>. </p><p>We review defined resilience matrices carefully, start running more frequent game days and <a href="https://shopify.engineering/performance-testing-shopify" target="_blank" rel="nofollow noopener noreferrer">load tests</a> and working on any issues or bottlenecks those reveal. This means updating runbooks, refining internal tools, and shipping fixes for issues that this activity brings to light.</p><p>All of this comes together to provide a robust, reliable platform to power over $5.1 billion in sales.</p></div>
<p><strong>Ryan</strong> is a Senior Development Manager at Shopify. He currently leads the Resiliency team, a centralized globally distributed SRE team responsible for keeping commerce better for everyone.</p>
<hr>
<p>We're planning to DOUBLE our engineering team in 2021 by hiring 2,021 new technical roles (see what we did there?). Our platform handled record-breaking sales over BFCM and commerce isn't slowing down.&nbsp;<a href="https://www.shopify.com/careers/2021" target="_blank" title="We’re planning to double our engineering team in 2021 by hiring 2,021 new technical roles" rel="noopener noreferrer">Help us scale &amp; make commerce better for everyone</a>.</p>
</div><div><div><div><h3>Get stories like this in your inbox!</h3><p>Stories from the teams who build and scale Shopify, the leading cloud-based, multi-channel commerce platform powering over 1,000,000 businesses around the world.</p><p>Share your email with us and receive monthly updates.</p></div></div></div></div>]]>
            </description>
            <link>https://shopify.engineering/resiliency-planning-for-high-traffic-events</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398002</guid>
            <pubDate>Sat, 12 Dec 2020 13:04:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Upgrading your Smartphone is Destroying the Planet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25397811">thread link</a>) | @scottbucks
<br/>
December 12, 2020 | https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades | <a href="https://web.archive.org/web/*/https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.7.1"><div dir="ltr"><div><h3 id="viewer-foo"><span><span>Haven't you wondered where your smartphone goes when you're done?</span></span></h3><div id="viewer-16t2j"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" data-pin-media="https://static.wixstatic.com/media/f361a8_da6af0458bd5469fb370e704386f86a3~mv2.jpeg/v1/fit/w_1000%2Ch_635%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_da6af0458bd5469fb370e704386f86a3~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg"></p></div><p><span dir="auto">Photo by Daniel Romero on Unsplash</span></p></div></div></div><p id="viewer-7arqh"><span>Smartphone technology is evolving rapidly. Every year there are better cameras, performance, refresh rates, screens and batteries. Tempted by a host of new features, people can't help but upgrade to the latest model, but what happens to all the smartphones we go through?

</span></p><p id="viewer-5pqsj"><span><strong>Catch our episode of </strong><a href="http://thedetechtor.com/podcast" target="_blank" rel="noopener"><strong><u>The Detechtor Podcast</u></strong></a><strong> about smartphone upgrades on </strong><a href="https://www.youtube.com/watch?v=osLMB-JBJgc&amp;t=5s" target="_blank" rel="noopener"><strong><u>Youtube</u></strong></a><strong>:</strong></span></p><p id="viewer-c1ios"><span><strong>Or just the audio version:</strong></span></p><p id="viewer-5o3kt"><span>The average lifespan of a smartphone is 3 to 4 years, perhaps even 5, but by that time the battery's capacity is likely to have decreased significantly. After an average lifespan has been reached, most people will throw away their smartphone and upgrade to a more recent model.</span></p><blockquote id="viewer-cmiam"><span><em>On average only 12,5% of electronic waste is recycled, with approximately 20 to 50 million metric tons of e-waste disposed of worldwide every year.</em></span></blockquote><p id="viewer-74ml0"><span>This is a huge problem for the environment due to the chemicals in these devices leaching into the groundwater system from landfills, polluting the land, water and air.</span></p><div id="viewer-bm1b6"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" data-pin-media="https://static.wixstatic.com/media/f361a8_e577402e314d40939016a7c158736c28~mv2.jpeg/v1/fit/w_794%2Ch_528%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_e577402e314d40939016a7c158736c28~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg"></p></div></div></div></div><p id="viewer-87pmv"><span>With companies constantly encouraging people to upgrade by stopping updates for older models, it renders them obsolete.</span></p><h3 id="viewer-2bkk7"><span><span>Suggested Articles:</span></span></h3><ul><li id="viewer-6se6h"><p><strong>🚄 </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-f2kho"><p><strong>⌚️ </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-6mit5"><p><span>🏭 </span><a href="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" target="_blank" rel="noopener"><u><strong>Carbon Capture, Usage and Storage: The Solution to the Climate Crisis?</strong></u></a></p></li></ul><p id="viewer-23r51"><span>Not only is this a problem for the environment, but by throwing away these devices, we are wasting precious metals such as copper, silver, gold, palladium and other raw materials, that would require significant resources to mine and manufacture.</span></p><div id="viewer-d1tql"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" data-pin-media="https://static.wixstatic.com/media/nsplsh_6a58643246537663527238~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/nsplsh_6a58643246537663527238~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-bqd9o"><span>
This is why it is important to recycle old cell phones and preserve these increasingly scarce materials where possible.</span></p><p id="viewer-c1me1"><span>Here are some suggestions on how to alleviate these problems:

</span></p><ol><li id="viewer-4p3cu"><p>Instead of buying a new phone, why not change the battery? Often the smartphone is still in good condition.</p></li><li id="viewer-bqu6i"><p>Once you have had your smartphone for several years and have already changed the battery, you could recycle it and buy a new one. Some companies offer trade-ins fo credit to use on your next phone.</p></li><li id="viewer-16hl3"><p>You could buy a refurbished product; they are often as good as brand new with the added benefit it helps the environment and saves you money.</p></li><li id="viewer-1aql"><p>Instead of throwing the phone away you could sell it, or give it to a friend/family member.</p></li></ol><h3 id="viewer-7q0i1"><span>Bottom line</span></h3><p id="viewer-26bo7"><span>The bottom line is currently we change smartphones too often. There is no specific amount of time that you should keep the same phone but when changing, think about where your phone may end up if you don't recycle it, sell it or pass it on to someone else.</span></p><h3 id="viewer-25qho"><span><span><strong>More from The Detechtor</strong>:</span></span></h3><ul><li id="viewer-abbf5"><p><strong>🚄 </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-ai204"><p><strong>⌚️ </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-fkhoe"><p><span>🏭 </span><a href="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" target="_blank" rel="noopener"><u><strong>Carbon Capture, Usage and Storage: The Solution to the Climate Crisis?</strong></u></a></p></li></ul><h3 id="viewer-ev2eg"><span><span>Stay updated:</span></span></h3><ul><li id="viewer-4tvgg"><p>📩 Want the latest on the impact of tech? <strong>Subscribe</strong> to our <strong>newsletter</strong>!</p></li><li id="viewer-dos7v"><p>🎙 <strong>NEW</strong>! <a href="http://thedetechtor.com/" target="_blank" rel="noopener"><u>The Detechtor Podcast</u></a> is now available on all podcast players!                                 <strong>Subscribe</strong> on <a href="https://podcasts.apple.com/fr/podcast/the-detechtor-podcast/id1537457578?l=en" target="_blank" rel="noopener"><u>Apple Podcasts</u></a> | <a href="https://open.spotify.com/show/5kc8WA6nZC69bQ1sbOrlNi?si=CwAuAtpfRpe7WmLu1PlO8w" target="_blank" rel="noopener"><u>Spotify</u></a> | <a href="https://podcasts.google.com/search/The%20detechtor%20Podcast" target="_blank" rel="noopener"><u>Google Podcasts</u></a> | <a href="https://www.stitcher.com/show/the-detechtor-podcast" target="_blank" rel="noopener"><u>Stitcher</u></a> | <a href="https://tunein.com/podcasts/Technology-Podcasts/The-Detechtor-Podcast-p1377296/?topicid=158813573" target="_blank" rel="noopener"><u>Tunein</u></a></p></li><li id="viewer-f94ja"><p>📲 Let's connect! <strong>Follow</strong> <strong>us</strong> on <a href="https://twitter.com/the_detechtor" target="_blank" rel="noopener"><u>Twitter</u></a> | <a href="https://www.instagram.com/thedetechtor/" target="_blank" rel="noopener"><u>Instagram</u></a> | <a href="https://www.facebook.com/thedetechtor" target="_blank" rel="noopener"><u>Facebook</u></a> | <a href="https://www.youtube.com/channel/UCAW--4_mML4A86W3670ix3w" target="_blank" rel="noopener"><u>Youtube</u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades</link>
            <guid isPermaLink="false">hacker-news-small-sites-25397811</guid>
            <pubDate>Sat, 12 Dec 2020 12:23:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Tools Instead of Platforms for Funding Distribution in Open Source]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25397663">thread link</a>) | @protontypes
<br/>
December 12, 2020 | https://podcast.sustainoss.org/63 | <a href="https://web.archive.org/web/*/https://podcast.sustainoss.org/63">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  


<header>
  <div>
    <div>
        <h5>Episode 63</h5>
      

      <div>
          
<div id="fireside-player" data-started="false" data-theme="minimal-light" data-player-type="embed" data-player-download="https://aphid.fireside.fm/d/1437767933/27729c65-f4a6-4496-8c86-820e7f13b285/94bb0f4e-8ef5-40ea-b964-9e5d8cb4911d.mp3" data-player-duration="2103" data-player-share="/63" data-player-theme="minimal-light" data-player-time="0">
  

  <div>
    <p><audio preload="none">
      <source src="https://media.fireside.fm/file/fireside-audio/podcasts/audio/2/27729c65-f4a6-4496-8c86-820e7f13b285/episodes/9/94bb0f4e-8ef5-40ea-b964-9e5d8cb4911d/94bb0f4e-8ef5-40ea-b964-9e5d8cb4911d.mp3" type="audio/mpeg">
      Your browser does not support the audio tag.
    </audio></p>

    

    

    

    </div>

  

</div>

      </div>
      <div>
        <div>
          <p>
            <i></i>
            December 10th, 2020
          </p>
          <p>
            <i></i>
            35 mins 3 secs
          </p>
        </div>
        
      </div>
      <div>
        
        <div>
            <h5>
              Special Guest
            </h5>
            <ul>
                <li>
                  <a title="Tobias Augspurger" href="https://podcast.sustainoss.org/guests/tobias-augspurger">
                    <img src="https://assets.fireside.fm/file/fireside-images/podcasts/images/2/27729c65-f4a6-4496-8c86-820e7f13b285/guests/9/9d9c5113-e970-4539-81c5-b9963cf10fb2/avatar_small.jpg?v=0">
</a>                </li>
            </ul>
        </div>
      </div>
    </div>
  </div>
</header>

<nav>
  <ul>
      <li><a href="https://podcast.sustainoss.org/rss"> RSS</a></li>
      <li><a href="https://podcasts.apple.com/us/podcast/sustain/id1491968393"><i></i> Apple Podcasts</a></li>
      <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9zdXN0YWluLmNvZGVmdW5kLmZtL3Jzcw%3D%3D"><i></i> Google Podcasts</a></li>
      <li><a href="https://www.iheart.com/podcast/269-sustain-62779472/"><i></i> iHeartRadio</a></li>
      <li><a href="https://open.spotify.com/show/5bPuwMYMc2le8FdTCNUCu6?si=9TapvwagR6mOyniE1H9_UQ"><i></i> Spotify</a></li>
      <li>
    <a href="#share_modal" data-modal=""> Share</a>
  </li>

  </ul>
</nav>


<section>
  <div>
    

    <h4>Panelists</h4>

<p>Eric Berry | Justin Dorfman | Richard Littauer</p>

<h4>Guest</h4>

<p>Tobias Augspurger</p>

<h4>Show Notes</h4>

<p>Hello and welcome to Sustain! Our special guest today is Tobias Augspurger, founder of Protontypes. Today, we learn all about Protontypes and LibreSelery.  We will also talk about his sustainable awesome-list. We cover the robotics industry, and how open source has influenced it. We cover other sustainability projects, like FarmBot, which blend together community and open source. Tobias tells us other projects he’s interested in doing with ProntonTypes.  Download this episode now to find out! </p>

<p>[00:00:55] Tobias tells us what Protontypes is. He also talks about sustainability for open source, and whether that means environmentally sustainable or sustainable for the maintainers.</p>

<p>[00:02:50] We learn all about LibreSelery, which launched this fall.</p>

<p>[00:10:26] Justin asks Tobias his thoughts on bringing more exposure to projects that are deep down in the stack that the others are standing above and how can you get those projects. Justin mentions checking out the Sustain discourse.</p>

<p>[00:13:56] Tobias tells us how his accelerator works. He talks about his sustainability awesome list.</p>

<p>[00:19:02] Richard asks Tobias if he’s had any students through Protontypes, or any projects come out of it . Tobias talks about the robotics industry as well.  Richard mentions FarmBot, an open source DIY gardening tool.</p>

<p>[00:24:21] Richard wonders if Tobias has any interests from other projects that aren’t robotics, or in general if he’s using other sorts of projects in Protontypes.</p>

<p>[00:31:10] Find out here where can you learn more about Protontypes and LibreSelery.</p>

<h4>Spotlight</h4>

<ul>
<li>  [00:32:17] Justin’s spotlight is a website called, WTFisQF.com.</li>
<li>  [00:33:00] Eric’s spotlight is books and jigsaw puzzles.</li>
<li>  [00:33:26] Richard’s spotlight is FarmBot.</li>
<li>  [00:33:44] Tobias’s spotlight is the Wind Turbine published by the International Energy Agency.</li>
</ul>

<h4>Quotes</h4>

<blockquote>
<p>[00:28:55] “I also think that people that work for something should get money if somebody is donating into such a project. You cannot really take donations and do not distribute it into contributors. So then stop taking donations if you don’t need them and give it to something else.”</p>
</blockquote>

<h4>Links</h4>

<ul>
<li><a href="https://github.com/Ly0n" rel="nofollow">Tobias Augspurger GitHub</a></li>
<li><a href="https://github.com/protontypes" rel="nofollow">Protontypes-GitHub</a></li>
<li><a href="https://github.com/protontypes/LibreSelery" rel="nofollow">Protontypes LibreSelery-GitHub</a></li>
<li><a href="https://discourse.sustainoss.org/" rel="nofollow">SustainOSS Discourse</a></li>
<li><a href="https://discourse.sustainoss.org/t/continuous-donation-distribution-to-your-project-contributors/467" rel="nofollow">Continuous Donation Distribution to your Project Contributors-Tobias Augspurger</a></li>
<li><a href="https://wtfisqf.com/?grant=&amp;grant=&amp;grant=&amp;grant=&amp;match=1000" rel="nofollow">WTF is QF</a></li>
<li><a href="https://farm.bot/" rel="nofollow">FarmBot</a></li>
<li><a href="https://www.iea.org/fuels-and-technologies/wind" rel="nofollow">International Energy Agency Wind Turbine</a></li>
</ul>

<h4>Credits</h4>

<ul>
<li>Produced by <a href="https://www.burntfen.com/" rel="nofollow">Richard Littauer</a></li>
<li>Edited by Paul M. Bahr at <a href="https://www.peachtreesound.com/" rel="nofollow">Peachtree Sound</a></li>
<li>Show notes by DeAnn Bahr at <a href="https://www.peachtreesound.com/" rel="nofollow">Peachtree Sound</a></li>
</ul>


      <p><a target="_blank" rel="payment" href="https://opencollective.com/sustain-podcast">Support Sustain</a>


  </p></div>

  
</section>


  <nav>
      <a href="https://podcast.sustainoss.org/62">← Previous episode</a>
      <a>
        Next episode →
</a>  </nav>
</div></div>]]>
            </description>
            <link>https://podcast.sustainoss.org/63</link>
            <guid isPermaLink="false">hacker-news-small-sites-25397663</guid>
            <pubDate>Sat, 12 Dec 2020 11:42:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ransomware – how to stay one step ahead of the cybercriminals]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25397639">thread link</a>) | @henrikwm
<br/>
December 12, 2020 | https://security.christmas/2020/12 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/12">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="main-content"><article><img src="https://www.stockvault.net/data/2016/07/04/203783/preview16.jpg" alt=""><div><section><p>Ransomware is extremely costly and difficult to get rid of, and once your files are encrypted you may have lost that data permanently. Giving in to the ransom demand is expensive, gives no guarantee that your data will be restored, and only encourages cybercriminals to keep attacking and extorting money from individuals and companies alike. Clearly, the best way to deal with the increased rise in ransomware attacks is to implement solid preventative measures to avoid getting infected in the first place. And, if the worst should happen and all your files do get encrypted, to have alternative ways of restoring your data. </p>
</section><article><section><p>This article will go over some good measures to reduce the risk of getting ransomware on your computer, as well as some advice what to do if you do get infected. Ransomware was covered in our <a href="https://security.christmas/2020/11">previous post</a>, so check it out for more details about what ransomware is, how it works, and the most common ways your computer gets infected. </p>
<p>The main way ransomware gets installed on your computer is through <a href="https://www.csoonline.com/article/2117843/what-is-phishing-how-this-cyber-attack-works-and-how-to-prevent-it.html">phishing</a>, a form of social engineering where an individual is tricked into installing the malware. There are several things to look out for:</p>
<h2>Social engineering – reduce the people factor</h2>
<ol>
<li>Do not click on any links that are not verified. These can come through a seemingly legit email or website. Downloads will usually start as soon as you click on a link, so use extra caution, and if in doubt do not click on it. </li>
<li>Do not open email attachments from untrusted sources. Also, be aware that some phishing attacks are highly specialized and could be adapted for you specifically or the company you work in (so-called spear phishing). One tip is to use the show file extensions feature to see if any attachments are executable, e.g. ending in .bat, .sh, .dmg, or .exe. If so, do not open it. </li>
<li>If an colleague sends a genuine email that looks like phishing, let them know so that the culture for writing good a proper emails will improve in your company. </li>
<li>Use caution when downloading from websites. Browsers will give an indication if the site is verified, usually in the form of a lock symbol or a shield. However, even verified websites may have security vulnerabilities or may even be phishing sites, so it is still necessary to exercise caution. Also, make sure the site uses HTTPS instead of HTTP to ensure secure encryption of requests and responses. </li>
<li>Be careful not to share personal information. Criminals may use this information to send personalized emails specifically to you, increasing the likelihood of doing what they ask of you. </li>
<li>For companies, provide training for employees so that they can recognize malicious emails and phishing attempts more easily. </li>
</ol>
<p>Ransomware can also exploit technological vulnerabilities. There are a few dos and don’ts to make sure your technological routines are up to scratch. </p>
<h2>Limit technological vulnerabilities</h2>
<ol>
<li>Make sure you scan all your emails and attachments using content scanning and filtering on your mail servers. This will reduce the chance of a malicious email ending up in your inbox. </li>
<li>Outdated versions on browsers, software, and operating systems may have vulnerabilities that can be exploited, so make sure to always update to the latest versions when possible. </li>
<li>Use good antivirus software that also include ransomware, and a firewall. There are several good ones that will block infected files and prevent your computer from being encrypted, but only use from reputable sources as there are also a lot of fake antivirus software out there. </li>
<li>When connecting to the Internet from a public WIFI, make sure you use a VPN. </li>
<li>Only give admin privileges when necessary. Restricted access for normal users may reduce the spread of the malware if one employee’s computer is attacked by ransomware.</li>
</ol>
<h2>Backup your data!</h2>
<p>This cannot be stressed enough and may be the most important measure you do. Having a good backup system is key to protect yourself from losing your data. Instead of paying the ransom, it is better to reinstall everything from good and recent backups, so make sure you have a backup on an external hard drive or in the cloud so that the backup data doesn’t get infected along with your computer. </p>
<h2>Worst case scenario – all my files are encrypted</h2>
<p>First off, make sure it is actual ransomware and not just an imitation (such as screen-locking ransomware). The latter may be more easily removed, and is often characterized by trying to shame the victim (eg having been caught looking at adult websites) and pretending to from a source such as the FBI or the police. If you can read most of your files and navigate through your computers system, it is most likely a fake. </p>
<p>However, if the ransomware is authentic there are three main paths you could chose:</p>
<h3>Paying the ransom</h3>
<p>First off, it is not recommended to pay the ransom. This will only encourage this type of attack, and there is no guarantee that you will receive the decryption key. Some may even ask for the ransom one more time before they give what you payed for. </p>
<p>That being said, some have chosen to recover the data by paying the fee, especially in the case of medical records or where there is no good backup to reinstall your files from. This is not an easy issue, and the pros and cons can be discussed at length. Again, take good backups of your data, and you will not have to be faced with this dilemma should you be so unfortunate to have all your files encrypted. </p>
<h3>Restoring your system from backups</h3>
<p>Disconnect your infected computer or system from the Internet and other devices, and use an antivirus to remove the ransomware. Note, this will not recover your files, but should remove the virus from your system. Check if there are any deleted files you might recover. Also, finding the exact type of ransomware strain might help you decrypt the files (though not in most cases). There are some online tools like <a href="https://id-ransomware.malwarehunterteam.com/">ID Ransomware</a> and <a href="https://www.nomoreransom.org/crypto-sheriff.php">Crypto Sheriff</a> that will help you with this. There are also some decryption tools available for some strains, so checkout <a href="https://www.nomoreransom.org/en/index.html">No More Ransom</a> if a decryption key exist for a specific strain. </p>
<p>If decryption is not possible, then restore the files from your backups. The best is to wipe your computer or system completely, reinstall the operating system, and then restore the files to make sure all traces of the virus is removed. Make sure your backup is not infected before you start. This is the fastest and cheapest way of getting your systems up and running again.</p>
<h3>Restore your system and lose you data</h3>
<p>This may not be optimal, but if your data is not very important or something you can’t replace, then simply choosing to reinstall you affected system may be a good solution. </p></section></article></div></article></main></div></div>]]>
            </description>
            <link>https://security.christmas/2020/12</link>
            <guid isPermaLink="false">hacker-news-small-sites-25397639</guid>
            <pubDate>Sat, 12 Dec 2020 11:37:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Trend in Darkmode Adoption Is a Sign for a Huge Demand for E-Ink Technology]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25397589">thread link</a>) | @tyler109
<br/>
December 12, 2020 | https://forum.ei2030.org/t/the-trend-in-darkmode-adoption-is-showing-actually-a-huge-demand-for-eink-technology/47 | <a href="https://web.archive.org/web/*/https://forum.ei2030.org/t/the-trend-in-darkmode-adoption-is-showing-actually-a-huge-demand-for-eink-technology/47">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
          <p>There are more and more websites / apps / softwares using Darkmode, and it has become a huge design trend over the past years, e.g. see here: <a href="https://mobiteam.medium.com/what-is-dark-mode-and-why-is-it-a-web-design-trend-in-2020-c638b6f22e17">https://mobiteam.medium.com/what-is-dark-mode-and-why-is-it-a-web-design-trend-in-2020-c638b6f22e17</a></p>
<p>HOWEVER</p>
<p>“Dark Mode” needs to be implemented on the hardware side, not the software side.</p>
<p>At the end of the day the idea is to minimize brightness to:</p>
<ul>
<li>Save energy</li>
<li>Reduce Eye Strain</li>
<li>Reduce blue light emission</li>
<li>Improve sleep quality</li>
</ul>
<p>However, there is lots of research suggesting, that Dark Mode is more of a placebo <a href="https://www.wired.co.uk/article/dark-mode-chrome-android-ios-science">than it actually works</a>. There is already a set of new display technologies being developed that have the benefits of “Dark Mode” without the need of extra software, namley E-Paper technology and RLCD. Those are having several advantages over “old” Display technologies:</p>
<div><a href="https://forum.ei2030.org/uploads/default/original/1X/75a8fec61d40a5f5244cd7937f244fdac33d7ed4.jpeg" data-download-href="https://forum.ei2030.org/uploads/default/75a8fec61d40a5f5244cd7937f244fdac33d7ed4" title="image"><img src="https://forum.ei2030.org/uploads/default/optimized/1X/75a8fec61d40a5f5244cd7937f244fdac33d7ed4_2_690x424.jpeg" alt="image" data-base62-sha1="gMRVWE0mXFyMIntK3UAalXzuKgs" width="690" height="424" srcset="https://forum.ei2030.org/uploads/default/optimized/1X/75a8fec61d40a5f5244cd7937f244fdac33d7ed4_2_690x424.jpeg, https://forum.ei2030.org/uploads/default/original/1X/75a8fec61d40a5f5244cd7937f244fdac33d7ed4.jpeg 1.5x, https://forum.ei2030.org/uploads/default/original/1X/75a8fec61d40a5f5244cd7937f244fdac33d7ed4.jpeg 2x" data-small-upload="https://forum.ei2030.org/uploads/default/optimized/1X/75a8fec61d40a5f5244cd7937f244fdac33d7ed4_2_10x10.png"></a></div>
<p>Dark mode, blue light blocking glasses, etc. are just part of a bigger trend nameley the shrinking backlight industry in the display industry.</p>
<p>There are some intersting players developing backlight free screens already and in 5-10 years it will be the standard. Also in terms of screen economics, not even mentioning the material and energy savings.</p>
<p>The thing is, that our body/eye has been trained for thousands of years to work with reflective light (to see things/objects through the light reflection of the sun). The screen trend to look directly into backlight over the past decades is very unnatural to our body/vision and <a href="http://www.bluelightexposed.com/#bluelightexposed">caused many problems</a>. We need a screen technology that is very aligned with on how our body is designed and works.</p>
<p>Big players in the display market are realizing this and building alternatives. Big players include Sharp, Lenovo, BOE Technologies, JDI, Flex Lightning, Hisense, ONYX, Dasung etc.</p>
<p>You can read about screen alternatives (like eink and rlcd) here: <a href="https://www.reddit.com/r/eink/comments/h179j5/new_eink_alternative_flexs_optional_front_light/">https://www.reddit.com/r/eink/comments/h179j5/new_eink_alter…</a></p>
<p>PS: There was recently aready a Tablet released with the new RLCD screen technolgoy by BOE-Technologies, check here: <a href="https://boingboing.net/2020/06/11/tablet-with-high-refresh-rate.html">https://boingboing.net/2020/06/11/tablet-with-high-refresh-r…</a></p>
        </div></div>]]>
            </description>
            <link>https://forum.ei2030.org/t/the-trend-in-darkmode-adoption-is-showing-actually-a-huge-demand-for-eink-technology/47</link>
            <guid isPermaLink="false">hacker-news-small-sites-25397589</guid>
            <pubDate>Sat, 12 Dec 2020 11:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A one-click WordPress-to-static tool]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25397515">thread link</a>) | @m1guelpf
<br/>
December 12, 2020 | https://sitesauce.app/for/wordpress | <a href="https://web.archive.org/web/*/https://sitesauce.app/for/wordpress">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>If you have an existing website, migrating your theme, plugins and content can be a hard task. You'd also lose the simplicity of having an admin panel and allowing multiple users to work on your content together.</p><p>Part of this problem could be solved by having your static site pull data from WordPress on build, but this brings up other problems, like having to manage two different codebases for a single website, migrating your themes over or needing to deploy to preview your content.</p><p>Sitesauce takes care of all this for you. After signing up and entering a URL, we'll generate a production-ready static version of your website and deploy it. You keep your dashboard and remove unnecessary complexity.</p></div></div></div></div>]]>
            </description>
            <link>https://sitesauce.app/for/wordpress</link>
            <guid isPermaLink="false">hacker-news-small-sites-25397515</guid>
            <pubDate>Sat, 12 Dec 2020 11:10:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The rise of 15-minute cities (profiling startup: Reef)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25397474">thread link</a>) | @mikerubini
<br/>
December 12, 2020 | https://treendly.com/blog/15-minute-cities | <a href="https://web.archive.org/web/*/https://treendly.com/blog/15-minute-cities">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>by <b><a href="https://treendly.com/">Treendly Team</a></b></p><p>December 7th, 2020</p>
                                
                                    
                                    
                                    <center>
                                <img src="https://images.pexels.com/photos/5845673/pexels-photo-5845673.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=2&amp;h=750&amp;w=1260">
                                </center>
                                <p><span><br>Imagine a city in which anything you need is 15 minutes away.<br>That’s the goal of 15-minutes cities.<span>&nbsp;</span></span></p>
                                
                               <p><span>It’s the road to a sustainable future and sustainable cities. In a short walk or with a fast bicycle ride, people will find everything. Underutilized urban spaces will become healthy and friendly ecosystems.<span>&nbsp;</span></span></p>

<p><span><b>15-minutes cities are getting traction right now</b>. With Covid, as people are confined in their homes and social gatherings are discouraged, staying in the neighborhood is their only choice.<span>&nbsp;</span></span></p>

<p><span>In this report, we will take a look at the American startup Reef, founded to “connect the world to your block."<span>&nbsp;</span></span></p>


<p><span><a href="https://reeftechnology.com/">Reef</a></span><span>&nbsp;is present in 4,500 locations and, in each of them, it plans to create “Neighborhood hubs.” The startup focuses on five aspects of urban living and they all make cities more accessible.<span>&nbsp;</span></span></p>

<ul>
    <li><span><b>Proximity</b>. Micro-distribution centers will ensure people won’t need to drive far to find what they need. The parking spaces turn into warehouses and direct-to-consumer lockers. Reef collaborates with couriers (such as DHL in Miami) to promote easy delivery and micro-mobility. Instead of using polluting vans, delivery companies will use electric vehicles or bikes.<span>&nbsp;</span></span></li>
</ul>

<ul>
    <li><span><b>Kitchens.</b> The “15-minute cities” promote and support local restaurants. The goal is sustainable expansion. Reef focuses on preparation and distribution to reach new customers. Business owners don’t need capital investment. Restaurants will grow with the community and not despite it. Urban farms create green spaces and communal ones, in which people will learn sharing.<span>&nbsp;</span></span></li>
</ul>

<ul>
    <li><span><b>Parking</b>. Reef operates one of the world’s largest parking networks that spreads to 70 percent of North America urban spaces. Real estate owners generate new revenue. On the other hand, customers have an easy experience, thanks to kiosks, cameras, and mobile applications.<span>&nbsp;</span></span></li>
</ul>

<ul>
    <li><span><b>Real estate</b>. Reef collaborates with owners to improve their experience and their tenants’. The staff will be aided by technology. The customers won’t ever be without concierge service, mail room, and package management. Building safety is improved as well as traffic management. Owners will provide tenants with a better experience, which in turn will lead to growth.<span>&nbsp;</span></span></li>
</ul>

<ul>
    <li><span><b>Healthcare</b>. Providers will come to the neighborhood, instead of patients standing in lines or the waiting room. Reef encourages healthy living too. Since people will find anything they need with a short walk, they will leave their car home. Pop-up clinics can help with Covid-19 tracking as well, since they make testing accessible.<span>&nbsp;</span></span></li>
</ul>

<p><span>The connected network of the “15-minute city” has identified the flaws of urban ecosystems and it has built strategies to tackle them. Everyone will see and enjoy the benefits, consumers as well as business owners.<span>&nbsp;</span></span></p>


<p><span>The connected network of the Reef Platform has something to offer to everyone. Its positive effects impact the whole community of the neighborhood and they create a trustworthy network.<span>&nbsp;</span></span></p>

<ul>
    <li><span><b>Sustainability.</b> If cars stay at home, pollution lessens. Thanks to micro-mobility and e-vehicles, the cities will be less congested. Traffic won’t be an issue anymore and your commute will be easier. Cities will lead the way to an eco-friendly future, setting an example instead of a setback.<span>&nbsp;</span></span></li>
</ul>

<ul>
    <li><span><b>Supporting the local economy.</b> People will stay in their “neighborhood hub” because they will find high-end restaurants and services in their block. Small businesses will have a chance to cater to their community. And the community will get a chance to give back.<span>&nbsp;</span></span></li>
</ul>

<ul>
    <li><span><b>Staying healthy.</b> This goes beyond using bike-sharing programs or electric scooters. Pop-up clinics will make a difference in many people’s lives. Healthcare will be more accessible, releasing patients from stressful situations. The clinics can be a life saver, literally.<span>&nbsp;</span></span></li>
</ul>

<ul>
    <li><span><b>People-friendly.</b> Thanks to the “15-minutes cities” concept, cities will serve people, not the other way around. Just think of the urban farms, a way to reclaim space and air.</span></li>
</ul>

<ul>
    <li><span><b>An equal system.</b> People will have access to the same quality service, no matter their looks and beliefs. For example, healthcare won’t be a restricted service, but a service for everyone.<span>&nbsp;</span></span></li>
</ul>

<ul>
    <li><span><b>Easy and efficient deliveries.</b> No matter what you order, someone close to you will deliver it. That someone will be on an e-bike, to reduce pollution. And they will be equipped with the latest technology, to make the whole experience smoother -for you and the courier.<span>&nbsp;</span></span></li>
</ul>

<ul>
    <li><span><b>A steady revenue stream.</b> To make sure providers and businesses don’t leave their neighborhood, Reef works with them. It helps local companies develop a sustainable and community-friendly approach. As people find solutions in their block, the businesses will succeed.<span>&nbsp;</span></span></li>
</ul>

<p><span>The concept of “15-minute cities” is designed to create a hospitable neighborhood, in which people feel welcome. And where they want to stay. People don’t want to leave because the block is customized to their needs and it reflects their heritage. Reef personalizes its urban space and it builds it to respect the neighborhood’s essence.<span>&nbsp;</span></span></p>


<p><span>In New York City, Reef has applied its vision to commuters with the <a href="https://www.barrierbyreef.com/"><span>Barrier</span></a> initiative. A team of professionals sanitizes vehicles with non-toxic sanitizers. They also deliver a package to drivers with three masks, two pairs of gloves, and one hand sanitizer. In only ten minutes, the car is ready and safe for new passengers.</span></p>

<p><span>In Miami, San Francisco, Seattle, and Los Angeles, Reef organized Covid-19 pop-up testing hubs. When the pandemic is finally over, these clinics will become points for primary care. A win-win for the neighborhoods.<span>&nbsp;</span></span></p>

<p><span>The startup is setting an example in the industry to tackle present challenges. It sets the tone for a better future as well. Investors believe in it and Reef has recently raised $1 billion for developments. Claudio Innocente is the Head of REEF's Fulfillment Network.</span></p>

<div><p><span>“<i>Our mission at Reef is to connect the world to your block by taking underused urban spaces, such as parking lots, warehouses and use that real estate to connect neighborhoods to the goods, services, and experiences they need to thrive</i>,” Innocente said during an interview with <a href="https://finance.yahoo.com/news/reef-technology-wellness-global-partner-140000399.html"><span>Yahoo Finance</span></a>.<span>&nbsp;</span></span></p></div>
<p><span>The mission includes parking spaces, sustainable micro-mobility, and clinics. The underused urban spaces become urban farms, kitchens, and healthy ecosystems.<p>The “15-minute cities” are sustainable, connected, and fun. The city can finally go back to human-friendly size, forgetting about cars, noise pollution, and stressful commutes. It’s worth the investment and the hustle.<span>&nbsp;</span></p></span></p>
                            </div></div>]]>
            </description>
            <link>https://treendly.com/blog/15-minute-cities</link>
            <guid isPermaLink="false">hacker-news-small-sites-25397474</guid>
            <pubDate>Sat, 12 Dec 2020 11:03:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handling hyperlinks in the Google Sheets C# SDK – tietokone.io]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25397405">thread link</a>) | @lukedawilson
<br/>
December 12, 2020 | https://blog.tietokone.io/handling-hyperlinks-in-google-sheets-c-sdk/ | <a href="https://web.archive.org/web/*/https://blog.tietokone.io/handling-hyperlinks-in-google-sheets-c-sdk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Recently, when writing a script to import data from Google Sheets into a database using the <a href="https://developers.google.com/sheets/api/quickstart/dotnet">C# SDK</a>, I came across a problem handling pasted hyperlinks in the source spreadsheet. The solution in the end was, thankfully, fairly straightforward, but Google’s documentation was quite poor, and I found little useful information on the web. Hopefully this post will save a few developers some time (and prevent a few grey hairs in the process).</p>

<p>As Martin Hawksey explains in his <a href="https://mashe.hawksey.info/2020/04/everything-a-google-apps-script-developer-wanted-to-know-about-reading-hyperlinks-in-google-sheets-but-was-afraid-to-ask/">blog</a>, Google Sheets (and indeed Excel) handles hyperlinks in three different ways:</p>

<ul>
  <li>Plain text that Google sheets detects as links</li>
  <li>The <code>HYPERLINK</code> <a href="https://support.google.com/docs/answer/3093313?hl=en-GB">formula</a></li>
  <li>Hidden links – scenarios such as copy/pasting links from a website to Google Sheets</li>
</ul>

<p>The SDK handles the first two types of link without problems, but when it comes to the third kind, it simply returns the link title, losing the link address! This seems a particularly poor design, but there we are.</p>

<p><img src="https://mcdn.hawksey.info/wp-content/uploads/2020/04/hyperlink.gif" alt="Example from Martin Hawksey's blog">
<em>In Martin’s example, the C# SDK would process the first two links correctly, but would only return <code>HOME</code> for the third link, losing the address entirely.</em></p>

<p>Fortunately, the <a href="https://developers.google.com/sheets/api/reference/rest/v4/spreadsheets/get?apix_params=%7B%22spreadsheetId%22%3A%221UAAnqHrIL9fvVSq626NcoBcPwJ5U-jrnmoqeV6pFBD0%22%2C%22ranges%22%3A%5B%22B1%3AB3%22%5D%2C%22fields%22%3A%22sheets%2Fdata%2FrowData%2Fvalues%2FuserEnteredValue%2Csheets%2Fdata%2FrowData%2Fvalues%2Fhyperlink%22%7D">REST API</a> can be made to return both the title and the address, by specifying the <code>sheets/data/rowData/values/userEnteredValue</code> and <code>sheets/data/rowData/values/hyperlink</code> fields:</p>

<div><div><pre><code><span>$ </span>curl <span>\</span>
  <span>'https://sheets.googleapis.com/v4/spreadsheets/1UAAnqHrIL9fvVSq626NcoBcPwJ5U-jrnmoqeV6pFBD0?ranges=B1%3AB3&amp;fields=sheets%2Fdata%2FrowData%2Fvalues%2FuserEnteredValue%2Csheets%2Fdata%2FrowData%2Fvalues%2Fhyperlink&amp;key=[YOUR_API_KEY]'</span> <span>\</span>
  <span>--header</span> <span>'Authorization: Bearer [YOUR_ACCESS_TOKEN]'</span> <span>\</span>
  <span>--header</span> <span>'Accept: application/json'</span> <span>\</span>
  <span>--compressed</span>
</code></pre></div></div>

<p>The response will look something like this:</p>

<div><div><pre><code><span>{</span><span>
  </span><span>"sheets"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>{</span><span>
      </span><span>"data"</span><span>:</span><span> </span><span>[</span><span>
        </span><span>{</span><span>
          </span><span>"rowData"</span><span>:</span><span> </span><span>[</span><span>
            </span><span>{</span><span>
              </span><span>"values"</span><span>:</span><span> </span><span>[</span><span>
                </span><span>{</span><span>
                  </span><span>"userEnteredValue"</span><span>:</span><span> </span><span>{</span><span>
                    </span><span>"stringValue"</span><span>:</span><span> </span><span>"https://developers.google.com/apps-script/"</span><span>
                  </span><span>},</span><span>
                  </span><span>"hyperlink"</span><span>:</span><span> </span><span>"https://developers.google.com/apps-script/"</span><span>
                </span><span>}</span><span>
              </span><span>]</span><span>
            </span><span>},</span><span>
            </span><span>{</span><span>
              </span><span>"values"</span><span>:</span><span> </span><span>[</span><span>
                </span><span>{</span><span>
                  </span><span>"userEnteredValue"</span><span>:</span><span> </span><span>{</span><span>
                    </span><span>"formulaValue"</span><span>:</span><span> </span><span>"=HYPERLINK(</span><span>\"</span><span>https://developers.google.com/apps-script/</span><span>\"</span><span>, </span><span>\"</span><span>This is a HYPERLINK</span><span>\"</span><span>)"</span><span>
                  </span><span>},</span><span>
                  </span><span>"hyperlink"</span><span>:</span><span> </span><span>"https://developers.google.com/apps-script/"</span><span>
                </span><span>}</span><span>
              </span><span>]</span><span>
            </span><span>},</span><span>
            </span><span>{</span><span>
              </span><span>"values"</span><span>:</span><span> </span><span>[</span><span>
                </span><span>{</span><span>
                  </span><span>"userEnteredValue"</span><span>:</span><span> </span><span>{</span><span>
                    </span><span>"stringValue"</span><span>:</span><span> </span><span>"HOME"</span><span>
                  </span><span>},</span><span>
                  </span><span>"hyperlink"</span><span>:</span><span> </span><span>"https://developers.google.com/apps-script/"</span><span>
                </span><span>}</span><span>
              </span><span>]</span><span>
            </span><span>}</span><span>
          </span><span>]</span><span>
        </span><span>}</span><span>
      </span><span>]</span><span>
    </span><span>}</span><span>
  </span><span>]</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>By reverse-engineering the SDK, I was able to determine how it builds up the request, and found that it exposes the authenticated HTTP client that it uses to send requests. From there, it was a simple matter to construct the appropriate request, grab the client, and parse the response JSON:</p>

<div><div><pre><code><span>// Configure and authorise service</span>
<span>using</span> <span>var</span> <span>stream</span> <span>=</span> <span>new</span> <span>FileStream</span><span>(</span><span>"path/to/credentials"</span><span>,</span> <span>FileMode</span><span>.</span><span>Open</span><span>,</span> <span>FileAccess</span><span>.</span><span>Read</span><span>,</span> <span>FileShare</span><span>.</span><span>Read</span><span>);</span>

<span>var</span> <span>credential</span> <span>=</span> <span>(</span><span>ServiceAccountCredential</span><span>)</span><span>GoogleCredential</span><span>.</span><span>FromStream</span><span>(</span><span>stream</span><span>).</span><span>UnderlyingCredential</span><span>;</span> <span>// this example is for a service account, but you could also use web authorisation</span>
<span>credential</span> <span>=</span> <span>new</span> <span>ServiceAccountCredential</span><span>(</span><span>new</span> <span>ServiceAccountCredential</span><span>.</span><span>Initializer</span><span>(</span><span>credential</span><span>.</span><span>Id</span><span>)</span>
<span>{</span>
    <span>User</span> <span>=</span> <span>"MyUsername"</span><span>,</span>
    <span>Key</span> <span>=</span> <span>credential</span><span>.</span><span>Key</span><span>,</span>
    <span>Scopes</span> <span>=</span> <span>new</span><span>[]</span> <span>{</span> <span>SheetsService</span><span>.</span><span>Scope</span><span>.</span><span>Spreadsheets</span> <span>}</span>
<span>});</span>

<span>var</span> <span>options</span> <span>=</span> <span>new</span> <span>BaseClientService</span><span>.</span><span>Initializer</span>
<span>{</span>
    <span>HttpClientInitializer</span> <span>=</span> <span>credential</span><span>,</span>
    <span>ApplicationName</span> <span>=</span> <span>"MyApplication"</span><span>,</span>
<span>};</span>

<span>var</span> <span>sheetsService</span> <span>=</span> <span>new</span> <span>SheetsService</span><span>(</span><span>options</span><span>);</span>

<span>// Define the request, specifying the 'hyperlink' field</span>
<span>var</span> <span>request</span> <span>=</span> <span>sheetsService</span><span>.</span><span>Spreadsheets</span><span>.</span><span>Get</span><span>(</span><span>mySpreadsheetId</span><span>);</span>
<span>request</span><span>.</span><span>Ranges</span> <span>=</span> <span>new</span> <span>Repeatable</span><span>&lt;</span><span>string</span><span>&gt;(</span><span>new</span><span>[]</span> <span>{</span> <span>myRange</span> <span>});</span>
<span>request</span><span>.</span><span>Fields</span> <span>=</span> <span>"sheets/data/rowData/values/userEnteredValue,sheets/data/rowData/values/hyperlink"</span><span>;</span>

<span>// Make the http request, and parse the response</span>
<span>using</span> <span>var</span> <span>httpRequest</span> <span>=</span> <span>request</span><span>.</span><span>CreateRequest</span><span>();</span>
<span>var</span> <span>response</span> <span>=</span> <span>await</span> <span>sheetsService</span><span>.</span><span>HttpClient</span><span>.</span><span>SendAsync</span><span>(</span><span>httpRequest</span><span>);</span>
<span>var</span> <span>content</span> <span>=</span> <span>await</span> <span>response</span><span>.</span><span>Content</span><span>.</span><span>ReadAsStringAsync</span><span>();</span>
<span>var</span> <span>rows</span> <span>=</span> <span>JsonConvert</span><span>.</span><span>DeserializeObject</span><span>&lt;</span><span>GoogleSheetsResponse</span><span>&gt;(</span><span>content</span><span>);</span> <span>// Newtonsoft.Json</span>
</code></pre></div></div>

<p>The response structure has a bit of nesting, so I defined the following classes to deserialise it into:</p>

<div><div><pre><code><span>public</span> <span>class</span> <span>GoogleSheetsResponse</span>
<span>{</span>
    <span>public</span> <span>Sheet</span><span>[]</span> <span>Sheets</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
<span>}</span>

<span>public</span> <span>class</span> <span>Sheet</span>
<span>{</span>
    <span>public</span> <span>Data</span><span>[]</span> <span>Data</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
<span>}</span>

<span>public</span> <span>class</span> <span>Data</span>
<span>{</span>
    <span>public</span> <span>RowData</span><span>[]</span> <span>RowData</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
<span>}</span>

<span>public</span> <span>class</span> <span>RowData</span>
<span>{</span>
    <span>public</span> <span>Value</span><span>[]</span> <span>Values</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
<span>}</span>

<span>public</span> <span>class</span> <span>Value</span>
<span>{</span>
    <span>public</span> <span>UserEnteredValue</span> <span>UserEnteredValue</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
    <span>public</span> <span>string</span> <span>Hyperlink</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>

    <span>public</span> <span>string</span> <span>GetString</span><span>()</span> <span>=&gt;</span> <span>UserEnteredValue</span><span>?.</span><span>StringValue</span> <span>??</span> <span>UserEnteredValue</span><span>?.</span><span>NumberValue</span><span>?.</span><span>ToString</span><span>();</span>

    <span>public</span> <span>long</span> <span>GetNumber</span><span>()</span> <span>=&gt;</span>
        <span>UserEnteredValue</span><span>?.</span><span>NumberValue</span> <span>??</span>
            <span>(</span><span>long</span><span>.</span><span>TryParse</span><span>(</span><span>UserEnteredValue</span><span>?.</span><span>StringValue</span><span>,</span> <span>out</span> <span>var</span> <span>parsed</span><span>)</span> <span>?</span> <span>parsed</span> <span>:</span> <span>(</span><span>long</span><span>?)</span><span>null</span><span>)</span> <span>??</span>
                <span>throw</span> <span>new</span> <span>InvalidOperationException</span><span>();</span>
<span>}</span>

<span>public</span> <span>class</span> <span>UserEnteredValue</span>
<span>{</span>
    <span>public</span> <span>string</span> <span>StringValue</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
    <span>public</span> <span>long</span><span>?</span> <span>NumberValue</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>So there we have it. I do hope Google update their SDK to handle this, or at least improve the documentation, but for now, we have a viable workaround.</p>

<p>In my next post, I’ll be continuing the Google Sheets theme, looking at how to convert Excel workbooks into Google spreadsheets.</p>

  </div></div>]]>
            </description>
            <link>https://blog.tietokone.io/handling-hyperlinks-in-google-sheets-c-sdk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25397405</guid>
            <pubDate>Sat, 12 Dec 2020 10:50:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AstraZeneca begins programme to assess Covid-19 vaccine combinations]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25397253">thread link</a>) | @siberianbear
<br/>
December 12, 2020 | https://www.astrazeneca.ru/media/news/2020/20201211-ru201.html | <a href="https://web.archive.org/web/*/https://www.astrazeneca.ru/media/news/2020/20201211-ru201.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>
<h3><b><i>Company to cooperate with Gamaleya Research Institute, Russian Direct Investment Fund and R-Pharm&nbsp;</i></b></h3>
</p>
</div><div>
<div>

<p>Combinations of different COVID-19 vaccines may be an important step in generating wider protection through a stronger immune response and better accessibility.</p>
<p>This is why it is important to explore heterologous boosting to make immunisation programmes more flexible, by allowing physicians greater choice at the time of administering vaccines. It is expected that combining vaccines may lead to improved immune response.</p>
<p>The UK government recently announced that it will begin a clinical trial combining the adenovirus vaccines with mRNA technology. AstraZeneca is also considering how it can explore heterologous combinations of different adenovirus vaccines.</p>
<p>Today we announce a clinical trial programme to assess safety and immunogenicity of combination of AZD1222, developed by AstraZeneca and Oxford University and Sputnik V, developed by Russian Gamaleya Research institute. It will begin enrolling adults aged 18 years and older.</p>
<p>Both AZD1222 and Sputnik V are adenoviral vector vaccines that contain genetic material of SARS-CoV-2 virus spike protein. The adenovirus itself is unable to replicate so it can only act as a carrier of genetic material.</p>
<p>Scientific collaboration with Gamaleya Research Institute is important to explore the potential of vaccine combinations unlocking synergies in protection and accessibility through a portfolio approach.</p>
<p>***</p>
<h3><b>Компания планирует провести исследования в сотрудничестве с НИЦ имени Н.Ф. Гамалеи, Российским фондом прямых инвестиций и «Р-Фарм»</b></h3>
<p>Комбинации различных вакцин могут стать важным шагом в профилактике COVID-19 за счет усиления иммунного ответа и повышения доступности препаратов.&nbsp;&nbsp;</p>
<p>Исследование разных режимов применения вакцин необходимо для того, чтобы оценить возможность создания более гибких программ вакцинации, которые дадут врачам широкий выбор подходов к профилактике заболевания. Комбинации различных вакцин потенциально могут вызвать более устойчивый и продолжительный иммунный ответ.</p>
<p>Правительство Великобритании недавно сообщило о предстоящем запуске клинических исследований комбинации вакцин на основе аденовирусного вектора и матричной РНК. В настоящее время компания «АстраЗенека» изучает возможности комбинации разных аденовирусных векторных вакцин.</p>
<p>Сегодня мы объявляем о начале программы клинических исследований по оценке безопасности и иммуногенности комбинированного применения вакцины AZD1222, разработанной компанией «АстраЗенека» совместно с Оксфордским университетом, и вакцины «Спутник V», разработанной Национальным исследовательским центром эпидемиологии и микробиологии имени Н.Ф. Гамалеи, с участием добровольцев в возрасте от 18 лет и старше.</p>
<p>AZD1222 и «Спутник V» созданы на основе аденовирусных векторов, в которые встроен шиповидный белок вируса SARS-CoV-2. Сами аденовирусы при этом лишены способности к репликации и являются системой доставки генетического материала (антигена) в клетки организма человека.</p>
<p>Научное сотрудничество компании «АстраЗенека» с Национальным исследовательским центром эпидемиологии и микробиологии имени Н.Ф. Гамалеи имеет большое значение не только для изучения потенциала комбинированного применения вакцин и оценки их синергизма в отношении иммунного ответа, но и для повышения в будущем доступности вакцинации за счет широкого портфеля препаратов.</p>
<p><b>Для получения дополнительной информации, пожалуйста, обращайтесь:</b></p>
<p><b>Евгения Касьяненко</b></p>
<p>Руководитель отдела по корпоративным коммуникациям «АстраЗенека», Россия и Евразия Тел: +7 (495) 799 5699, эл.&nbsp;почта: <a href="mailto:evgeniya.kasyanenko@astrazeneca.com">evgeniya.kasyanenko@astrazeneca.com</a></p>
<p><b>Екатерина Марченко</b></p>
<p>Менеджер по внешним коммуникациям</p>
<p>Тел: +7 (495) 799 5699, эл.&nbsp;почта: <a href="mailto:ekaterina.marchenko@astrazeneca.com">ekaterina.marchenko@astrazeneca.com</a></p>

</div>
</div></div>]]>
            </description>
            <link>https://www.astrazeneca.ru/media/news/2020/20201211-ru201.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25397253</guid>
            <pubDate>Sat, 12 Dec 2020 10:17:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Functional TypeScript with FP-Ts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25397089">thread link</a>) | @bendiksolheim
<br/>
December 12, 2020 | https://functional.christmas/2020/12 | <a href="https://web.archive.org/web/*/https://functional.christmas/2020/12">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><section><p>I know, I know, I’m not really supposed to feel this way. It’s supposed to be this weird language full of flaws that never follows established rules and conventions, and we’re all supposed to not like it. But that’s just not the case for me – despite all the quirks and unusual behavior I still enjoy it.</p>
<p>There are, of course, sides of it I enjoy less. The two things I dislike the most are lack of strong, static typing, and a well-built standard library. The standard library is still growing, and the newer parts of it are not too bad – the older parts, though, are all over the place: they mutate, and lack consistency.</p>
<p>Not too long ago I came across this library named <code>fp-ts</code>, that together with <code>TypeScript</code> made my whole JavaScript experience <em>a lot</em> better. This blog post aims to give you a short introduction to this library, and show you some of its strenghts. To keep this blog post short, I will assume you know both JavaScript and TypeScript. You will probably still understand most of it even if you are not fluid in any of them, but consider yourself warned.</p>
<h2>fp-ts</h2>
<p><a href="https://github.com/gcanti/fp-ts">fp-ts</a> introduces <em>many</em> functional concepts. If you come from Java or Kotlin, you can compare it to <a href="https://www.vavr.io/">Vavr</a> or <a href="https://arrow-kt.io/">Arrow</a>, respectively. It provides several well known data types, type classes, a consistent library of functions, and several other functional abstractions.</p>
<p>Wading through every feature of fp-ts would be an enourmous task, and one way too overkill for this blog. Instead, I will take you through some of the simpler concepts that anyone can benefit from. My goal is to show you exactly how to make use of some of these concepts, so you can take use of them right after.</p>
<p>Let’s get started!</p>
<h3>The Data Types</h3>
<p>Let’s start with two data types I use more or less daily: <code>Option</code> and <code>Either</code>. If you are completely new to functional programming, I suggest starting with these as they encourage a coding style that is safe, and can help you understand other aspects of functional programming later on.</p>
<p>An <code>Option</code> type represents an optional value. Something you either have, or don’t have. This is useful when lacking a value is valid in your domain, or when a function may or may not return a value. Let’s see some code.</p>
<div data-language="ts"><pre><code><span>import</span> <span>{</span> Option<span>,</span> some<span>,</span> none<span>,</span> map <span>}</span> <span>from</span> <span>"fp-ts/Option"</span>

<span>type</span> <span>User</span> <span>=</span> <span>{</span>
  id<span>:</span> <span>number</span><span>,</span>
  username<span>:</span> <span>string</span><span>,</span>
  expiration<span>:</span> Date
<span>}</span>

<span>function</span> <span>getUserById</span><span>(</span>id<span>:</span> <span>number</span><span>)</span><span>:</span> Option<span>&lt;</span>User<span>&gt;</span> <span>{</span> <span>.</span><span>.</span> <span>}</span>

<span>const</span> userOne <span>=</span> <span>getUserById</span><span>(</span><span>1</span><span>)</span> 
<span>const</span> userTwo <span>=</span> <span>getUserById</span><span>(</span><span>2</span><span>)</span> 

<span>const</span> getUserName <span>=</span> <span>(</span>u<span>:</span> User<span>)</span><span>:</span> <span>string</span> <span>=&gt;</span> u<span>.</span>username

<span>const</span> usernameOne <span>=</span> <span>map</span><span>(</span>getUserName<span>)</span><span>(</span>userOne<span>)</span> 
<span>const</span> usernameTwo <span>=</span> <span>map</span><span>(</span>getUserName<span>)</span><span>(</span>userTwo<span>)</span> </code></pre></div>
<p>Before we go through the code, I’d just like to point out the use of <a href="https://en.wikipedia.org/wiki/Partial_application">partial application</a> in the two last lines. Lots of functions in <code>fp-ts</code> are <a href="https://en.wikipedia.org/wiki/Currying">curried</a> by default, as is often common in functional languages. This pattern is really convenient when you want to bind some, but not all, parameters of a function.</p>
<p>So, an <code>Option</code>&nbsp;wraps a value, and allows operations to be performed through functions such as <code>map</code>, <code>filter</code>, <code>fold</code> and others. This example demonstrates a really nice property of the <code>Optional</code>: your business code can describe the "happy path" – error handling is abstracted into the <code>Option</code> itself. We never have to check for <code>null</code>&nbsp;values before getting the username from the user, because the function <code>getUserName</code> is run in a safe context. <code>map</code> runs the provided function on an <code>Option</code> only if it is a <code>some</code>, and not a <code>none</code>. The same is true for other functions on the <code>Option</code>.</p>
<p>But what if you wanted to display, or use, the username? You can’t just extract the value from inside an <code>Option</code>, as you don’t know whether it is a <code>some</code> or a <code>none</code>. To get the actual value from the <code>Option</code>, you need to specify what to do both when it is a <code>none</code>, and a <code>some</code>. Let’s take a look at two safe ways of extracting your value from the <code>Option</code>.</p>
<div data-language="ts"><pre><code><span>import</span> <span>{</span> fold<span>,</span> getOrElse <span>}</span> <span>from</span> <span>"fp-ts/Option"</span><span>;</span>


<span>const</span> usernameLength <span>=</span> <span>fold</span><span>(</span>
  <span>(</span><span>)</span> <span>=&gt;</span> <span>0</span><span>,</span>
  <span>(</span>username<span>:</span> <span>string</span><span>)</span> <span>=&gt;</span> username<span>.</span>length
<span>)</span><span>;</span>

<span>const</span> usernameOneLength<span>:</span> <span>number</span> <span>=</span> <span>usernameLength</span><span>(</span>usernameOne<span>)</span><span>;</span> 
<span>const</span> usernameTwoLength<span>:</span> <span>number</span> <span>=</span> <span>usernameLength</span><span>(</span>usernameTwo<span>)</span><span>;</span> 

<span>const</span> getOrEmpty <span>=</span> <span>getOrElse</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>""</span><span>)</span><span>;</span>

<span>const</span> usernameOneValue<span>:</span> <span>string</span> <span>=</span> <span>getOrEmpty</span><span>(</span>usernameOne<span>)</span><span>;</span> 
<span>const</span> usernameTwoValue<span>:</span> <span>string</span> <span>=</span> <span>getOrEmpty</span><span>(</span>usernameTwo<span>)</span><span>;</span> </code></pre></div>
<p>With both <code>fold</code> and <code>getOrElse</code>, the type system forces us to handle both the missing and the non-missing state. You now have a safe way of handling missing values, and even a safe way of getting them out as well – no more checking for <code>null</code> all over the place!</p>
<p>Let’s modify the function <code>getUserById</code> from the first example a bit. Instead of just returning a <code>none</code>, we would like to know <em>why</em> it was not returned. An <code>Option</code> can’t help you with this. Instead, you need something like the <code>Either</code>. Where an <code>Option</code> is either a <code>none</code> or a <code>some</code>, the <code>Either</code> is either a <code>left</code> or a <code>right</code>. It holds a value in both cases. The <code>Either</code> is often used to model situations where an operation can either fail or succeed. By convention, the <code>left</code> case represents the failure, and the <code>right</code> case represents success.</p>
<p>Aaaaaanyway. As stated, let’s change our <code>getUserById</code> function to also tell us <em>why</em> it was unsuccessful.</p>
<div data-language="ts"><pre><code><span>import</span> <span>{</span> Either<span>,</span> right<span>,</span> left<span>,</span> map <span>}</span> <span>from</span> <span>"fp-ts/Either"</span>

<span>type</span> <span>UserError</span> <span>=</span> <span>"UserNotFound"</span> <span>|</span> <span>"UserExpired"</span>

<span>function</span> <span>getUserById</span><span>(</span>id<span>:</span> <span>number</span><span>)</span><span>:</span> Either<span>&lt;</span>UserError<span>,</span> User<span>&gt;</span> <span>{</span> <span>.</span><span>.</span> <span>}</span>


<span>const</span> userOne <span>=</span> <span>getUserById</span><span>(</span><span>1</span><span>)</span> 
<span>const</span> userTwo <span>=</span> <span>getUserById</span><span>(</span><span>2</span><span>)</span> 

<span>const</span> usernameOne <span>=</span> <span>map</span><span>(</span>getUserName<span>)</span><span>(</span>userOne<span>)</span> 
<span>const</span> usernameTwo <span>=</span> <span>map</span><span>(</span>getUserName<span>)</span><span>(</span>userTwo<span>)</span> </code></pre></div>
<p>This is not too far from the first example with the <code>Option</code>, with the added value that we now also know why it failed. It was either not found, or it was expired. Just as with the <code>Option</code>, <code>Either</code> is also a wrapper around your value(s), abstracting away the error case until you need the actual value. <code>Either</code> has its own version of <code>fold</code>, among others, which can be used to extract the value. I’ll leave you with the task of implementing this – if you need a hint, I can tell you it’s more or less the same as with <code>Option</code>!</p>
<p>So, which type should you use? It’s the usual, booring answer: it all the depends. It all depends on how the operation might fail, and what it would result in. It also boils down to semantics – is the lack of a value valid in your domain, or is it an error? In the former case, and <code>Option</code> is more suitable. In the latter, an <code>Either</code> might be better. As always: if you are unsure, just try one of them – you will soon find out if it was right or wrong.</p>
<h3>Pipes and flows</h3>
<p>Function composition is a central concept in functional programming. It is the act of combining simple functions to build more complicated ones. Smaller and simpler functions are easier to reason about and test, but can’t perform complex operations by themselves.</p>
<p>You could of course just call your simple functions in succession in a larger function. Either by saving the result of each step, or wrapping your functions inside each other. Both of these gets more and more tedious the more functions you need to call, and hides the important details: the actual logic and transformation. Let’s take a look at two functions called&nbsp;<code>pipe</code> and <code>flow</code>, which both make composition easier. They are quite alike, but have different use cases.</p>
<div data-language="ts"><pre><code><span>import</span> <span>{</span> pipe<span>,</span> flow <span>}</span> <span>from</span> <span>"fp-ts/function"</span><span>;</span>

<span>const</span> <span>square</span> <span>=</span> <span>(</span>x<span>:</span> <span>number</span><span>)</span> <span>=&gt;</span> x <span>*</span> x<span>;</span>
<span>const</span> <span>timesTen</span> <span>=</span> <span>(</span>x<span>:</span> <span>number</span><span>)</span> <span>=&gt;</span> x <span>*</span> <span>10</span><span>;</span>

<span>const</span> result <span>=</span> <span>pipe</span><span>(</span><span>3</span><span>,</span> square<span>,</span> timesTen<span>)</span><span>;</span> 

<span>const</span> squareAndMultiply <span>=</span> <span>flow</span><span>(</span>square<span>,</span> timesTen<span>)</span><span>;</span>

<span>const</span> result2 <span>=</span> <span>squareAndMultiply</span><span>(</span><span>3</span><span>)</span><span>;</span> </code></pre></div>
<p><code>result</code> and <code>result2</code> have the same value, but are computed differently. <code>pipe</code> gives us the ability to pipe a value through a list of functions, and produce an output. This is nice for those one-off situations where you need to combine a few functions to produce a result. <code>flow</code> is more suited for those situations where you want to compose functions and create a new function permanently. In both cases, everything needs to typecheck – the input to one function needs to be of the same type as the output from the previous, all the way through.</p>
<h3>Extended built-ins</h3>
<p>As I said in the beginning of this post, JavaScripts standard library is in a bit of a weird position. If we take <code>Array</code> as an example, there is a distinction between functions that mutates in place, and functions that instead returns a new value. Things are moving to a better place, but we still have these old, mutating, functions that we have to live with. <code>fp-ts</code>&nbsp;fixes this by providing a consistent library even for JavaScript built-ins such as <code>Array</code> and <code>Map</code>. It’s not only consistent on the different types themselves, but also across the types thanks to extensive use of type classes <sup id="fnref-1"><a href="#fn-1">1</a></sup>. Every class that adheres to the <code>Functor</code> type class supports the <code>map</code> function, and every class that adheres to the <code>Filterable</code> type class can be filtered and partitioned. If this is greek to you, just ignore the lingo and appreciate the fact that most types has <code>map</code>, <code>filter</code>, <code>reduce</code> and loads of other functions implemented on them. You can even implement them on types you create yourself as well!</p>
<h3>... and so much more</h3>
<p>We have only really scratched the surface here. These concepts should give you enough to get you started, and hopefully see the value in this library. When you’re ready, there are tons of other concepts to dive into, which can make your code even more readable and safe. I haven’t had the time to wade through it all myself, so I still keep finding small gems which makes my day just a bit easier.</p>
<p>If you want to know more, the <a href="https://gcanti.github.io/fp-ts/learning-resources/">learning resources section</a> of the <a href="https://gcanti.github.io/fp-ts/">documentation</a> is actually quite good. As the author states, fp-ts does not really aim to teach functional programming from the ground up, but the resources are still good and manages to convince at least me quite well.</p>
<p>I also recommend reading the source code. It is surprisingly readable, even to me – a person who is neither fluent in advanced typescript or an FP zealot.</p>
<p><sup id="fnref-1"><a href="#fn-1">1</a></sup> – These are not «real» type classes, they are type classes implementet with interfaces. You can’t use the same <code>map</code> function on all <code>Functor</code>s, but all <code>Functor</code>s has …</p></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://functional.christmas/2020/12">https://functional.christmas/2020/12</a></em></p>]]>
            </description>
            <link>https://functional.christmas/2020/12</link>
            <guid isPermaLink="false">hacker-news-small-sites-25397089</guid>
            <pubDate>Sat, 12 Dec 2020 09:47:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interior Mutability in Rust: Understanding the Cell Type]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25397054">thread link</a>) | @lukastyrychtr
<br/>
December 12, 2020 | https://ibraheem.ca/posts/rust-interior-mutability-understanding-cell | <a href="https://web.archive.org/web/*/https://ibraheem.ca/posts/rust-interior-mutability-understanding-cell">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>This post was partly derived from Jon Gjenset's stream <a href="https://www.youtube.com/watch?v=8O0Nt9qY_vo&amp;ab_channel=JonGjengset">Crust of Rust: Smart Pointers and Interior Mutability</a>.</em></p>
<h3 id="introduction"><a href="#introduction" aria-label="introduction permalink"></a>Introduction</h3>
<p>Today we are going to be talking about smart pointers and interior mutability, specifically, the <code>Cell</code> type. <code>Cell</code> is a type that you come across frequently in Rust programs and it can help to have a deeper understanding of what it is and how it works. One of the best ways to understand <code>Cell</code> and the fundamental concepts behind its implementation is to actually write it yourself. So that is what we are going to do!</p>
<h3 id="cell"><a href="#cell" aria-label="cell permalink"></a>Cell</h3>
<p>The Rust standard library has a module called <a href="https://doc.rust-lang.org/std/cell/index.html"><code>cell</code></a> which contains "shareable mutable containers". You probably already know that the Rust ownership model has the concept of shared references (<code>&amp;T</code>) and exclusive (mutable) references (<code>&amp;mut T</code>). Having an exclusive reference means that the borrow checker <em>guarantees</em> that you are the exclusive owner of the pointer, which allows you to mutate the value behind it. A <em>shareable mutable container</em> sounds pretty weird at first, because you should not be allowed to mutate a value if someone else has mutable access to it, right? However, the <code>cell</code> module provides primitives that allow shared mutability in a controlled manner under specific circumstances. This is often referred to as "interior mutability", because it allows mutation from an immutable reference. The <code>cell</code> module contains a couple of different interior mutability primitives. In this post, we will look at <code>Cell</code>.</p>
<p>Let's start by looking at the basic API of <code>Cell</code>. You can create a new <code>Cell</code> with the <code>new</code> method:</p>

<p>You can mutate the cell's interior with the <code>set</code> method. Notice that <code>set</code> takes an immutable reference to <code>self</code>, and yet still allows you to mutate the contained value. This is how <code>Cell</code> provides interior mutability:</p>
<div data-language="rust"><pre><code>

<span>let</span> c <span>=</span> Cell<span>::</span><span>new</span><span>(</span><span>5</span><span>)</span><span>;</span>
c<span>.</span><span>set</span><span>(</span><span>10</span><span>)</span><span>;</span></code></pre></div>
<p>You can also <code>get</code> the cell's inner value:</p>
<div data-language="rust"><pre><code>


<span>let</span> c <span>=</span> Cell<span>::</span><span>new</span><span>(</span><span>5</span><span>)</span><span>;</span>
<span>let</span> five <span>=</span> c<span>.</span><span>get</span><span>(</span><span>)</span><span>;</span></code></pre></div>
<p>Notice that the <code>get</code> method requires <code>T</code> to be <code>Copy</code>. This is because instead of returning a reference to the inner value, <code>get</code> returns a copy of it. If you look through all the methods on <code>Cell</code>, you would see that there is no (safe) way to get a reference to it's inner value. You can replace it, set it, or swap it, but you can never get a reference to it. This concept is what allows <code>Cell</code> to provide interior mutability, because it guarantees that nobody else has a reference to <code>Cell</code>:</p>
<blockquote>
<p>If we know that no one else has a pointer to the value that we are storing inside of <code>Cell</code>, then changing that value is fine.</p>
</blockquote>
<p>The other mechanism that <code>Cell</code> uses to provide safe interior mutability is that it does not implement <code>Sync</code>:</p>
<div data-language="rust"><pre><code><span>impl</span><span>&lt;</span>T<span>&gt;</span> <span>!</span>Sync <span>for</span> Cell<span>&lt;</span>T<span>&gt;</span>
<span>where</span>
    T<span>:</span> <span>?</span>Sized<span>,</span> </code></pre></div>
<p>This means that references to a <code>Cell</code> cannot be shared between threads. If two threads both have mutable access to the value inside of <code>Cell</code>, then they could both try to change the value <em>at the same time</em>, which would cause many of the problems that Rust was built to prevent. These two compile-time guarantees are what allow <code>Cell</code> to provide safe interior mutability:</p>
<ul>
<li>No one has a shared reference to <code>Cell</code>'s inner value</li>
<li><code>Cell</code> cannot be shared between threads</li>
</ul>
<h3 id="why-is-cell-useful"><a href="#why-is-cell-useful" aria-label="why is cell useful permalink"></a>Why is Cell useful?</h3>
<p>So why is <code>Cell</code> useful? <code>Cell</code> provides the ability to have multiple mutable references to a single value. For example, we might have a graph containing a <code>total_count</code> and a vector of nodes:</p>
<div data-language="rust"><pre><code><span>struct</span> Graph <span>{</span>
    total_count<span>:</span> u8<span>,</span>
    nodes<span>:</span> Vec<span>&lt;</span>Node<span>&gt;</span><span>,</span>
<span>}</span>

<span>struct</span> Node <span>{</span>
    count<span>:</span> u8<span>,</span>
<span>}</span></code></pre></div>
<p>We now want to traverse the graph updating every node's count and the graph's total count:</p>
<div data-language="rust"><pre><code><span>impl</span> Node <span>{</span>
    <span>fn</span> <span>update</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>{</span>
        <span>self</span><span>.</span>count <span>+=</span> <span>1</span><span>;</span>
    <span>}</span>   
<span>}</span>

<span>impl</span> Graph <span>{</span>
    <span>fn</span> <span>traverse</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>{</span>
        <span>for</span> node <span>in</span> <span>self</span><span>.</span>nodes<span>.</span><span>iter_mut</span><span>(</span><span>)</span> <span>{</span>
            node<span>.</span><span>update</span><span>(</span><span>)</span><span>;</span>
            <span>self</span><span>.</span><span>update</span><span>(</span>node<span>.</span>count<span>)</span><span>;</span>
        <span>}</span>
    <span>}</span>

    <span>fn</span> <span>update</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> node_count<span>:</span> u8<span>)</span> <span>{</span>
        <span>self</span><span>.</span>total_count <span>+=</span> node_count<span>;</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>However, this poses a problem, because we are trying to borrow <code>self</code> as mutable multiple times:</p>
<div data-language="rust"><pre><code>error<span>[</span>E0499<span>]</span><span>:</span> cannot borrow `<span>*</span><span>self</span>` <span>as</span> mutable more than <span>once</span> at a time
  <span>-</span><span>-&gt;</span> src<span>/</span>lib<span>.</span>rs<span>:</span><span>20</span><span>:</span><span>13</span>
   <span>|</span>
<span>18</span> <span>|</span>     <span>for</span> node <span>in</span> <span>self</span><span>.</span>nodes<span>.</span><span>iter_mut</span><span>(</span><span>)</span> <span>{</span>
   <span>|</span>                      <span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span>
   <span>|</span>                      <span>|</span>
   <span>|</span>                      first mutable borrow occurs here
   <span>|</span>                      first borrow later used here
<span>19</span> <span>|</span>         node<span>.</span><span>update_count</span><span>(</span><span>)</span><span>;</span>
<span>20</span> <span>|</span>         <span>self</span><span>.</span><span>update_count</span><span>(</span>node<span>.</span>count<span>)</span><span>;</span>
   <span>|</span>         <span>^</span><span>^</span><span>^</span><span>^</span> second mutable borrow occurs here</code></pre></div>
<p>This is a perfect use case for <code>Cell</code>. If we wrap the value in a <code>Cell</code>, then we can modify the values entirely through shared references:</p>
<div data-language="rust"><pre><code><span>struct</span> Graph <span>{</span>
    total_count<span>:</span> Cell<span>&lt;</span>u8<span>&gt;</span><span>,</span>
    nodes<span>:</span> Vec<span>&lt;</span>Node<span>&gt;</span><span>,</span>
<span>}</span>

<span>struct</span> Node <span>{</span>
    count<span>:</span> Cell<span>&lt;</span>u8<span>&gt;</span><span>,</span>
<span>}</span>

<span>impl</span> Node <span>{</span>
    <span>fn</span> <span>update</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>{</span>
        <span>self</span><span>.</span>count<span>.</span><span>set</span><span>(</span><span>self</span><span>.</span>count<span>.</span><span>get</span><span>(</span><span>)</span> <span>+</span> <span>1</span><span>)</span><span>;</span>
    <span>}</span>   
<span>}</span>

<span>impl</span> Graph <span>{</span>
    <span>fn</span> <span>traverse</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>{</span>
        <span>for</span> node <span>in</span> <span>self</span><span>.</span>nodes<span>.</span><span>iter</span><span>(</span><span>)</span> <span>{</span>
            node<span>.</span><span>update</span><span>(</span><span>)</span><span>;</span>
            <span>self</span><span>.</span><span>update</span><span>(</span>node<span>.</span>count<span>.</span><span>get</span><span>(</span><span>)</span><span>)</span><span>;</span>
        <span>}</span>
    <span>}</span>

    <span>fn</span> <span>update</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> node_count<span>:</span> u8<span>)</span> <span>{</span>
        <span>self</span><span>.</span>total_count<span>.</span><span>set</span><span>(</span><span>self</span><span>.</span>count<span>.</span><span>get</span><span>(</span><span>)</span> <span>+</span> node_count<span>)</span><span>;</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Because <code>Cell</code> guarantees that no-one else has a pointer to the value, we can mutate the values through shared references and our code now compiles. </p>
<h3 id="implementing-cell"><a href="#implementing-cell" aria-label="implementing cell permalink"></a>Implementing <code>Cell</code></h3>
<p>Now that we understand what <code>Cell</code> is, let's try implementing it ourselves. We can start with a basic API for the <code>Cell</code> struct:</p>
<div data-language="rust"><pre><code><span>pub</span> <span>struct</span> Cell<span>&lt;</span>T<span>&gt;</span> <span>{</span>
  value<span>:</span> T
<span>}</span>

<span>impl</span><span>&lt;</span>T<span>&gt;</span> Cell<span>&lt;</span>T<span>&gt;</span> <span>{</span>
  <span>pub</span> <span>fn</span> <span>new</span><span>(</span>value<span>:</span> T<span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
    Cell <span>{</span> value <span>}</span>
  <span>}</span>

  <span>pub</span> <span>fn</span> <span>set</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> value<span>:</span> T<span>)</span> <span>{</span>
    <span>self</span><span>.</span>value <span>=</span> value<span>;</span>
  <span>}</span>

   <span>pub</span> <span>fn</span> <span>get</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> value<span>:</span> T<span>)</span> <span>-&gt;</span> T <span>{</span>
    <span>self</span><span>.</span>value
  <span>}</span>
<span>}</span></code></pre></div>
<p>Right now our code will not compile, because we are trying to mutate a value through a shared reference, which violates Rust's fundemental borrowing rules:</p>
<div data-language="rust"><pre><code>error<span>[</span>E0594<span>]</span><span>:</span> cannot assign to `<span>self</span><span>.</span>value` which is behind a `<span>&amp;</span>` reference
  <span>-</span><span>-&gt;</span> src<span>/</span>lib<span>.</span>rs<span>:</span><span>11</span><span>:</span><span>5</span>
   <span>|</span>
<span>10</span> <span>|</span>   <span>pub</span> <span>fn</span> <span>set</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> value<span>:</span> T<span>)</span> <span>{</span>
<span>11</span> <span>|</span>     <span>self</span><span>.</span>value <span>=</span> value<span>;</span>
   <span>|</span>     <span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span> `<span>self</span>` is a `<span>&amp;</span>` reference<span>,</span> so the data it refers to cannot <span>be</span> written</code></pre></div>
<p>So, how do we mutate an immutable reference? At the heart of the <code>Cell</code> type in the standard library is a type called <code>UnsafeCell</code>. <code>UnsafeCell</code> is the core primitive for interior mutability in Rust. On its own, it is completely unsafe to use. <code>UnsafeCell</code> allows you to get a raw mutable pointer to it's underlying value. It is up to the user to cast that raw pointer to an exclusive reference in a safe manner. The <strong>only</strong> way in Rust to correctly go from a shared reference to an exclusive reference is through <code>UnsafeCell</code>. This is due to compiler mechanisms specific to <code>UnsafeCell</code>.</p>
<p>Let's try wrapping the value <code>T</code> in an <code>UnsafeCell</code>:</p>
<div data-language="rust"><pre><code><span>use</span> std<span>::</span>cell<span>::</span>UnsafeCell<span>;</span>

<span>pub</span> <span>struct</span> Cell<span>&lt;</span>T<span>&gt;</span> <span>{</span>
  value<span>:</span> UnsafeCell<span>&lt;</span>T<span>&gt;</span>
<span>}</span></code></pre></div>
<p>Now, the <code>new</code> method creates a new <code>UnsafeCell</code> that the wraps <code>value</code>:</p>
<div data-language="rust"><pre><code><span>impl</span><span>&lt;</span>T<span>&gt;</span> Cell<span>&lt;</span>T<span>&gt;</span> <span>{</span>
  <span>pub</span> <span>fn</span> <span>new</span><span>(</span>value<span>:</span> T<span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
    Cell <span>{</span> value<span>:</span> UnsafeCell<span>::</span><span>new</span><span>(</span>value<span>)</span> <span>}</span>
  <span>}</span>
<span>}</span></code></pre></div>
<p>The <code>set</code> method needs to modify the inner value of <code>UnsafeCell,</code> so we can get a raw pointer to the value with the <code>UnsafeCell::get</code> method, and set it to <code>value</code>:</p>
<div data-language="rust"><pre><code>

<span>impl</span><span>&lt;</span>T<span>&gt;</span> Cell<span>&lt;</span>T<span>&gt;</span> <span>{</span>
  <span>pub</span> <span>fn</span> <span>set</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> value<span>:</span> T<span>)</span> <span>{</span>
    <span>*</span><span>self</span><span>.</span>value<span>.</span><span>get</span><span>(</span><span>)</span> <span>=</span> value<span>;</span>
  <span>}</span>
<span>}</span></code></pre></div>
<p>This however, poses a problem:</p>
<div data-language="rust"><pre><code>error<span>[</span>E0133<span>]</span><span>:</span> dereference of raw pointer is <span>unsafe</span> and requires <span>unsafe</span> function or block
  <span>-</span><span>-&gt;</span> src<span>/</span>lib<span>.</span>rs<span>:</span><span>13</span><span>:</span><span>5</span>
   <span>|</span>
<span>13</span> <span>|</span>     <span>*</span><span>self</span><span>.</span>value<span>.</span><span>get</span><span>(</span><span>)</span> <span>=</span> value<span>;</span>
   <span>|</span>     <span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span> dereference of raw pointer</code></pre></div>
<p>In Rust, dereferencing a raw pointer is an <code>unsafe</code> operation. The compiler does not know that it is okay for us to mutate a value through an immutable reference. We have to wrap the operation in an <code>unsafe</code> block to tell the compiler that we know dereferencing <code>self.value</code> here is safe:</p>
<div data-language="rust"><pre><code><span>pub</span> <span>fn</span> <span>set</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> value<span>:</span> T<span>)</span> <span>{</span>
  <span>unsafe</span> <span>{</span> <span>*</span><span>self</span><span>.</span>value<span>.</span><span>get</span><span>(</span><span>)</span> <span>=</span> value <span>}</span><span>;</span>
<span>}</span></code></pre></div>
<p>Even though the compiler accepts our code, how do <em>we</em> know that it is safe? Right now, the code is simply <strong>wrong</strong>. Let's create a test case to illustrate the problems with our code:</p>
<div data-language="rust"><pre><code><span>#[cfg(test)]</span>
<span>mod</span> test <span>{</span>
  <span>use</span> <span>super</span><span>::</span><span>*</span><span>;</span>
  <span>use</span> std<span>::</span>sync<span>::</span>Arc<span>;</span>

  <span>#[test]</span>
  <span>fn</span> <span>bad</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> x <span>=</span> Arc<span>::</span><span>new</span><span>(</span>Cell<span>::</span><span>new</span><span>(</span><span>42</span><span>)</span><span>)</span><span>;</span>
    
    <span>let</span> x1 <span>=</span> x<span>.</span><span>clone</span><span>(</span><span>)</span><span>;</span>
    std<span>::</span>thread<span>::</span><span>spawn</span><span>(</span><span>move</span> <span><span>|</span><span>|</span></span> <span>{</span>
      x1<span>.</span><span>set</span><span>(</span><span>1</span><span>)</span><span>;</span>
    <span>}</span><span>)</span><span>;</span>

    <span>let</span> x2 <span>=</span> x<span>.</span><span>clone</span><span>(</span><span>)</span><span>;</span>
    std<span>::</span>thread<span>::</span><span>spawn</span><span>(</span><span>move</span> <span><span>|</span><span>|</span></span> <span>{</span>
      x2<span>.</span><span>set</span><span>(</span><span>2</span><span>)</span><span>;</span>
    <span>}</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre></div>
<p>Until now we have not written anything to prevent the above code from being written. Two threads could potentially try to modify the same memory at the same time. This could result in data races or lost memory. We need some way to tell the <code>Cell</code> is not safe to be shared between threads. We can do this through negative trait bounds.</p>
<div data-language="rust"><pre><code><span>impl</span><span>&lt;</span>T<span>&gt;</span> <span>!</span>Sync <span>for</span> Cell<span>&lt;</span>T<span>&gt;</span> <span>{</span><span>}</span></code></pre></div>
<p><code>!Sync</code> tells the compiler that it is not safe to share references to <code>Cell</code> between threads. However, negative trait bounds are currently an unstable feature. For now, the work around is to store a <code>!Sync</code> value in our <code>Cell</code> type, which would cause the entire <code>Cell</code> type to be <code>!Sync</code>. And guess what type is <code>!Sync</code>?</p>
<div data-language="rust"><pre><code><span>impl</span><span>&lt;</span>T<span>&gt;</span> <span>!</span>Sync <span>for</span> UnsafeCell<span>&lt;</span>T<span>&gt;</span>
<span>where</span>
    T<span>:</span> <span>?</span>Sized<span>,</span> </code></pre></div>
<p><code>UnsafeCell</code> is already <code>!Sync</code>. Even though we have not explicitly marked <code>Cell</code> as <code>!Sync</code>, it is already implied by <code>UnsafeCell</code>. This means that our test suite will not compile:</p>
<div data-language="rust"><pre><code>error<span>[</span>E0277<span>]</span><span>:</span> `UnsafeCell<span>&lt;</span>i32<span>&gt;</span>` cannot <span>be</span> shared between threads safely
   <span>-</span><span>-&gt;</span> src<span>/</span>lib<span>.</span>rs<span>:</span><span>32</span><span>:</span><span>5</span>
    <span>|</span>
<span>32</span>  <span>|</span>     std<span>::</span>thread<span>::</span><span>spawn</span><span>(</span><span><span>|</span><span>|</span></span> <span>{</span>
    <span>|</span>     <span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span><span>^</span> `UnsafeCell<span>&lt;</span>i32<span>&gt;</span>` cannot <span>be</span> shared between threads safely
    <span>=</span> help<span>:</span> within `Cell<span>&lt;</span>i32<span>&gt;</span>`<span>,</span> the <span>trait</span> `Sync` is not implemented <span>for</span> `UnsafeCell<span>&lt;</span>i32<span>&gt;</span>`
    <span>=</span> note<span>:</span> required because it appears within the <span>type</span> `Cell<span>&lt;</span>i32<span>&gt;</span>`</code></pre></div>
<p>Now that we know our <code>set</code> method is safe, we can write the <code>get</code> method:</p>
<div data-language="rust"><pre><code><span>pub</span> <span>fn</span> <span>get</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> T
<span>where</span>
  T<span>:</span> Copy<span>,</span>
<span>{</span>
  <span>unsafe</span> <span>{</span> <span>*</span><span>self</span><span>.</span>value<span>.</span><span>get</span><span>(</span><span>)</span> <span>}</span>
<span>}</span></code></pre></div>
<p>As explained above, we have to return a copy of the inner value, not a reference. If we returned a reference, then we are opening the doors to undefined behavior. Look what could potentially happen if <code>get</code> returned a reference instead of a copy:</p>
<div data-language="rust"><pre><code><span>impl</span><span>&lt;</span>T<span>&gt;</span> Cell<span>&lt;</span>T<span>&gt;</span> <span>{</span>
  
  
  <span>pub</span> <span>fn</span> <span>get</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> T
  <span>{</span>
    <span>unsafe</span> <span>{</span> <span>&amp;</span><span>*</span><span>self</span><span>.</span>value<span>.</span><span>get</span><span>(</span><span>)</span> <span>}</span>
  <span>}</span>
<span>}</span>

<span>#[test]</span>
<span>fn</span> <span>bad2</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> x <span>=</span> Cell<span>::</span><span>new</span><span>(</span><span>vec!</span><span>[</span>String<span>::</span><span>from</span><span>(</span><span>"Hello"</span><span>)</span><span>]</span><span>)</span><span>;</span>
  
  
  <span>let</span> hello<span>:</span> <span>&amp;</span>String <span>=</span> <span>&amp;</span>x<span>.</span><span>get</span><span>(</span><span>)</span><span>[</span><span>0</span><span>]</span><span>;</span>
  <span>assert_eq!</span><span>(</span>h…</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ibraheem.ca/posts/rust-interior-mutability-understanding-cell">https://ibraheem.ca/posts/rust-interior-mutability-understanding-cell</a></em></p>]]>
            </description>
            <link>https://ibraheem.ca/posts/rust-interior-mutability-understanding-cell</link>
            <guid isPermaLink="false">hacker-news-small-sites-25397054</guid>
            <pubDate>Sat, 12 Dec 2020 09:38:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Cross-Compiling Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25397045">thread link</a>) | @jmillikin
<br/>
December 12, 2020 | https://john-millikin.com/notes-on-cross-compiling-rust | <a href="https://web.archive.org/web/*/https://john-millikin.com/notes-on-cross-compiling-rust">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 slot="title">Rustup and Cargo</h2><p><img src="https://john-millikin.com/by-sha256/b049b899f6e55fbbd9a80a31a44c7689068b1ac7050ec5a1a6d425e50cfde69f/Cargo-Logo-Small.png"></p><p>The first build tool I tried is <a href="https://github.com/rust-lang/cargo">Cargo</a>, which I installed with <a href="https://rustup.rs/">rustup</a>. I dislike building with Cargo because it's primitive and inflexible, but since it's the official Rust build tool I hoped it would be the best documented.</p><div><blog-code syntax="toml"><pre># Cargo.toml

[package]
name = "helloworld"
version = "0.0.1"
edition = "2018"

[[bin]]
name = "helloworld"
path = "helloworld.rs"
</pre></blog-code></div><p>Cargo uses the <tt>--target</tt> flag to enable cross-compilation.</p><blog-code syntax="commands"><pre>cargo build --target armv7-unknown-linux-gnueabihf
#    Compiling helloworld v0.0.1 (/Users/john/src/rust-cross-compilation)
# error[E0463]: can't find crate for `std`
#   |
#   = note: the `armv7-unknown-linux-gnueabihf` target may not be installed</pre></blog-code><p>Whereas Go will build its standard library from source when cross-compiling, Rust relies on precompiled libraries<blog-footnote-ref>[<a href="#fn:3">3</a>]</blog-footnote-ref>. We can use <tt>rustup</tt> to fetch a prebuilt <tt>std</tt> for Linux on ARMv7.</p><blog-code syntax="commands"><pre>rustup target add armv7-unknown-linux-gnueabihf
# info: downloading component 'rust-std' for 'armv7-unknown-linux-gnueabihf'
# info: installing component 'rust-std' for 'armv7-unknown-linux-gnueabihf'
# info: using up to 500.0 MiB of RAM to unpack components
#  18.2 MiB /  18.2 MiB (100 %)  11.5 MiB/s in  1s ETA:  0s</pre></blog-code><blog-code syntax="commands"><pre>cargo build --target armv7-unknown-linux-gnueabihf
#    Compiling helloworld v0.0.1 (/Users/john/src/rust-cross-compilation)
# error: linking with `cc` failed: exit code: 1
#   |
#   = note: "cc" "-Wl,--as-needed" "-Wl,-z,noexecstack" "-Wl,--eh-frame-hdr" "-L"
#   [...]
#   "-Wl,-Bdynamic" "-lgcc_s" "-lc" "-lm" "-lrt" "-lpthread" "-lutil" "-ldl" "-lutil"
#   = note: clang: warning: argument unused during compilation: '-pie' [-Wunused-command-line-argument]
#           ld: unknown option: --as-needed
#           clang: error: linker command failed with exit code 1 (use -v to see invocation)</pre></blog-code><p>The source file was successfully compiled, but it couldn't be linked into an executable. It looks like Cargo is trying to use the host system's linker, which will sometimes work, but fails in this particular case because the macOS linker only supports Apple targets.</p><p>Luckily the LLVM project, in addition to the compilation framework, also distributes the cross-platform <a href="https://lld.llvm.org/">LLD</a> linker. While it doesn't cover every platform supported by <tt>rustc</tt>, it does support the common ones. We can configure Cargo to use it for linking our ARMv7 Linux binary.</p><p>I downloaded <a href="https://github.com/llvm/llvm-project/releases/download/llvmorg-11.0.0/clang+llvm-11.0.0-x86_64-apple-darwin.tar.xz"><tt>clang+llvm-11.0.0-x86_64-apple-darwin.tar.xz</tt></a> from <a href="https://releases.llvm.org/download.html">https://releases.llvm.org/download.html</a> and extracted it to <tt>~/.opt/</tt>, then added a <tt>.cargo/config.toml</tt> to my workspace.</p><blog-code syntax="toml"><pre># .cargo/config.toml
[build]

[target.armv7-unknown-linux-gnueabihf]
linker = "/Users/john/.opt/clang+llvm-11.0.0-x86_64-apple-darwin/bin/lld"
</pre></blog-code><blog-code syntax="commands"><pre>cargo build --target armv7-unknown-linux-gnueabihf
#    Compiling helloworld v0.0.1 (/Users/john/src/rust-cross-compilation)
# error: linking with `/Users/john/.opt/clang+llvm-11.0.0-x86_64-apple-darwin/bin/lld` failed: exit code: 1
#   |
#   = note: "/Users/john/.opt/clang+llvm-11.0.0-x86_64-apple-darwin/bin/lld" "-flavor" "gnu" "--eh-frame-hdr" "-L"
#   [...]
#    "-Bdynamic" "-lgcc_s" "-lc" "-lm" "-lrt" "-lpthread" "-lutil" "-ldl" "-lutil"
#   = note: lld: error: unable to find library -lgcc_s
#           lld: error: unable to find library -lc
#           lld: error: unable to find library -lm
#           lld: error: unable to find library -lrt
#           lld: error: unable to find library -lpthread
#           lld: error: unable to find library -lutil
#           lld: error: unable to find library -ldl
#           lld: error: unable to find library -lutil</pre></blog-code><p>Getting closer!</p><p>The linker is being told to build an executable that dynamically links against the GNU libc, which I don't have a copy of. One option here is to download it from (for example) the Ubuntu package hosting, but I don't want to do that because I don't think a Rust binary should be depending on <tt>libc</tt> at all. Rust ought to be considered a replacement for C, rather than a thin layer on top.</p><p>Therefore I'm going to switch the Cargo target to the MUSL variant, which treats <tt>libc</tt> as an implementation detail rather than a core component of the platform.</p><blog-code syntax="commands"><pre>rustup target add armv7-unknown-linux-musleabihf
# info: downloading component 'rust-std' for 'armv7-unknown-linux-musleabihf'
# info: installing component 'rust-std' for 'armv7-unknown-linux-musleabihf'
# info: using up to 500.0 MiB of RAM to unpack components
#  15.8 MiB /  15.8 MiB (100 %)  12.1 MiB/s in  1s ETA:  0s</pre></blog-code><blog-code syntax="toml"><pre># .cargo/config.toml
[build]

[target.armv7-unknown-linux-musleabihf]
linker = "/Users/john/.opt/clang+llvm-11.0.0-x86_64-apple-darwin/bin/lld"
</pre></blog-code><blog-code syntax="commands"><pre>cargo build --target armv7-unknown-linux-musleabihf
#    Compiling helloworld v0.0.1 (/Users/john/src/rust-cross-compilation)
#     Finished dev [unoptimized + debuginfo] target(s) in 1.50s</pre></blog-code><p>Success! The resulting binary is a valid executable for ARMv7 Linux, and can be run as-is on the Raspberry Pi.</p><blog-code syntax="commands"><pre>file target/armv7-unknown-linux-musleabihf/debug/helloworld
# target/armv7-unknown-linux-musleabihf/debug/helloworld: ELF 32-bit LSB executable, ARM, EABI5 version 1 (SYSV), statically linked, with debug_info, not stripped</pre></blog-code></div><div><h2 slot="title">Bazel</h2><p><img src="https://john-millikin.com/by-sha256/05daef8103f981c102f1b8486bd7c97f625bdffb14e0ce4875dc4a2ea2b5941e/bazel-icon.svg"></p><p><a href="https://bazel.build/">Bazel</a> is a language-agnostic build system. Its configuration language deals in actions and dependency graphs, rather than executables and libraries, which gives it some interesting scaling properties:</p><ul><li>Building single-language projects with Bazel can be more difficult than using language-specific tools.</li><li>Building multi-language projects is substantially easier in Bazel than in any other build system.</li></ul><p>This makes Bazel a natural choice of build tool for any system that involves (1) FFI, (2) generated code, or (3) well-factored subsystems. It is uniquely capable when compared to Cargo because it can build multiple Rust libraries ("crates") within a single workspace.</p><p>The first step to build Rust with Bazel is to configure the <tt>WORKSPACE</tt> to depend on <a href="https://github.com/bazelbuild/rules_rust">rules_rust</a>. This will also define the default Rust version and edition. There's no need to install toolchains or targets, because Bazel will fetch them on demand.</p><blog-code syntax="python"><pre># WORKSPACE
load("@bazel_tools//tools/build_defs/repo:http.bzl", "http_archive")

http_archive(
    name = "io_bazel_rules_rust",
	# HEAD commit as of 2020-12-05
    urls = ["https://github.com/bazelbuild/rules_rust/archive/67f0c5ec0397d24ccc14264a0eda86915ddf63e8.tar.gz"],
    sha256 = "c587d402e4502100b01e4ba7d9584809cf4f4eb2d2f6634097883637bfb512b1",
	strip_prefix = "rules_rust-67f0c5ec0397d24ccc14264a0eda86915ddf63e8",
)

load("@io_bazel_rules_rust//rust:repositories.bzl", "rust_repositories")

rust_repositories(
    edition = "2018",
    version = "1.48.0",
)
</pre></blog-code><p>Next we need to create a top-level <tt>BUILD</tt> file. This will define a <tt>rust_binary</tt> target for our hello-world executable, and also a <tt>platform</tt> describing what sort of system we want to build for.</p><blog-code syntax="python"><pre># BUILD.bazel
load("@io_bazel_rules_rust//rust:rust.bzl", "rust_binary")

rust_binary(
    name = "helloworld",
    srcs = ["helloworld.rs"],
)

platform(
    name = "linux-armv7",
    constraint_values = [
        "@platforms//os:linux",
        "@platforms//cpu:arm",
    ],
)
</pre></blog-code><p>In the future the Platform would use a more specific <tt>"cpu:armv7"</tt> constraint (<a href="https://github.com/bazelbuild/rules_rust/pull/509">bazelbuild/rules_rust#509</a>) and support constraining on the Rust release channel (<a href="https://github.com/bazelbuild/rules_rust/pull/510">bazelbuild/rules_rust#510</a>).</p><p>Anyway, that should be enough, but if we try running it we'll hit an error about missing toolchains.</p><blog-code syntax="commands"><pre>bazel build //:helloworld --platforms=//:linux-armv7
# [...]
# ERROR: While resolving toolchains for target //:helloworld: no matching toolchains found for types @io_bazel_rules_rust//rust:toolchain</pre></blog-code><p>This is because rules_rust doesn't pre-register toolchains for all supported target platforms – it makes the user register each (host, target) mapping explicitly. We need to tell rules_rust to register a toolchain that can run on macOS (Darwin) and build for ARMv7 Linux.</p><blog-code syntax="python"><pre># WORKSPACE
load("@io_bazel_rules_rust//rust:repositories.bzl", "rust_repository_set")

rust_repository_set(
    name = "rust_linux_armv7",
    edition = "2018",
    exec_triple = "x86_64-apple-darwin",
    extra_target_triples = ["arm-unknown-linux-musleabihf"],
    rustfmt_version = "1.4.20",
    version = "1.48.0",
)
</pre></blog-code><blog-code syntax="commands"><pre>bazel build //:helloworld --platforms=//:linux-armv7
# [...]
# INFO: From Compiling Rust bin helloworld (1 files):
# error: linking with `external/local_config_cc/cc_wrapper.sh` failed: exit code: 1
#   |
#   = note: "external/local_config_cc/cc_wrapper.sh" "-Wl,--as-needed" "-Wl,-z,noexecstack" "-Wl,--eh-frame-hdr" "-nostartfiles"
#   = note: clang: warning: argument unused during compilation: '-no-pie' [-Wunused-command-line-argument]
#           ld: unknown option: --as-needed
#           clang: error: linker command failed with exit code 1 (use -v to see invocation)</pre></blog-code><p>This is the same linker error as we saw with Cargo, and the solution is to tell rules_rust that it should use LLD. However, there's a problem – rules_rust doesn't have its own linker toolchain, it uses the C/C++ toolchain to find a linker.</p><p>We must now contend with the Bazel C/C++ configuration system, which is designed to handle the world's wide range of strange C compilers. I'm not going to give a blow-by-blow here because none of it is relevant to Rust, but a summary is:</p><ul><li>We create a new Bazel package <tt>//cc-toolchain</tt> that will contain the C/C++ configuration. I'm just going to pull in the linker from the filesystem rather than properly <tt>repository_rule</tt> it, so the toolchain file sets will be empty stubs.</li><li>The <tt>CcToolchainConfigInfo</tt> itself requires the path to a bunch of different tools; since the only one needed here is <tt>lld</tt> I'll hardcode the rest to <tt>/bin/false</tt>.</li><li>This project doesn't need to build any C/C++ code for the host (e.g. for codegen), so I'm going to override <tt>--host_crosstool_top</tt> rather than define a true host-compatible toolchain.</li></ul><p>A more complete solution would probably involve the Clang-based toolchains defined in <a href="https://github.com/bazelbuild/bazel-toolchains">https://github.com/bazelbuild/bazel-toolchains</a>.</p><blog-code syntax="python"><pre># cc-toolchain/BUILD

load(":config.bzl", "cc_toolchain_config")

filegroup(name = "empty")

cc_toolchain_suite(
    name = "clang_suite",
    toolchains = {</pre></blog-code></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://john-millikin.com/notes-on-cross-compiling-rust">https://john-millikin.com/notes-on-cross-compiling-rust</a></em></p>]]>
            </description>
            <link>https://john-millikin.com/notes-on-cross-compiling-rust</link>
            <guid isPermaLink="false">hacker-news-small-sites-25397045</guid>
            <pubDate>Sat, 12 Dec 2020 09:37:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Containerd Development with Multipass]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25397043">thread link</a>) | @alexellisuk
<br/>
December 12, 2020 | https://blog.alexellis.io/containerd-development-multipass/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/containerd-development-multipass/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <div><p>About 18 months ago <a href="https://blog.alexellis.io/faas-containerd-serverless-without-kubernetes/">I started a project</a> which developed directly against containerd. This presented a problem which I'd not really encountered before - <a href="https://www.docker.com/">Docker</a> and <a href="https://kubernetes.io/">Kubernetes</a> on my Mac were no longer enough, I needed a Linux environment.</p>
<p>To begin with I just used an old 2016 model Dell XPS which gave me everyting I needed, but when others started to contribute, they were using Macs and so we had a problem. <a href="https://multipass.run/">Multipass</a> was the answer to our woes and we were pleasantly surprised by it and wondered why more people weren't using it every day.</p>
<p>I want to tell you a bit about our experience in the <a href="http://github.com/openfaas/">OpenFaaS community</a> developing <a href="https://github.com/openfaas/faasd">faasd</a> - a portable FaaS framework, just like OpenFaaS, but without the complexity and overheads of a Kubernetes cluster.</p>
<h2 id="whatscontainerdeverdoneforus">What's containerd ever done for us?</h2>
<p>Some time ago the original version of Docker was actually written in Python, and then morphed over time into a Go re-write. The Go version was seen as monolithic by some consumers, particularly the Kubernetes community.</p>
<blockquote>
<p>Docker did many things, and at one point clustering and multi-node orchestration was even added to that list (think Docker Swarm and Docker EE)</p>
</blockquote>
<p>As the codebase was refactored two projects emmerged: containerd and runc.</p>
<ul>
<li><a href="https://github.com/opencontainers/runc">runc</a> was a tiny Go binary that had one job: run a container based upon a spec. runc was also the driver for the <a href="https://opencontainers.org/">OCI specification</a></li>
<li><a href="https://github.com/containerd/containerd">containerd</a>'s job was to get things ready for runc - such as pulling images and defining specs</li>
</ul>
<p>Docker then remained as a thiner layer on top of both of these tools to bring a user-friendly developer-experience, networking, high-level API and CLI.</p>
<p>Over time containerd has shifted into the lime-light and in Kubernetes 1.20, it will take over duties for running containers in Kubernetes clusters. Now not a lot changes, because containerd was always there along with runc, we just skip a few levels of indirection.</p>
<p>containerd doesn't provide networking out of the box, and that was one of the hardest challenges.</p>
<blockquote>
<p>Not because it's technically complex, but there was a severe lack of documentation.</p>
</blockquote>
<p><a href="https://github.com/containernetworking/cni">Container Network Initiative (CNI)</a> filled a gap for us and enabled us to build a network between our containers.</p>
<p>When you squint at faasd, you see something that looks a lot like a single-node Kubernetes cluster, using the same projects you'd find on most nodes: containerd, runc and CNI.</p>
<h2 id="whywouldyoudevelopwithcontainerd">Why would you develop with containerd?</h2>
<p>There were two main reasons for creating "faasd" - the first was that we were hearing from users that they didn't want to run an entire Kubernetes cluster just to run a handful of functions, APIS or webpages. The second was that I fancied doing some learning and low-level coding.</p>
<p>Whilst containerd has a socket available, and can be mounted or forwarded, it doesn't work as you would expect. The containerd client tries to run containers on the host it's executing on and just synchronises state with the containerd socket. I found that very confusing, but was reassured that is the way it was designed to work.</p>
<p>You can see our code which has developed into two main services shipped in a single binary.</p>
<ul>
<li><a href="https://github.com/openfaas/faasd/blob/master/cmd/up.go">faasd</a> - starts all the core services for OpenFaaS: the gateway, NATS, Prometheus and our queue worker. <a href="https://github.com/openfaas/faasd/blob/master/docker-compose.yaml">A docker-compose file</a> is used to define versions of images, and the dependency graph for starting up services.</li>
<li><a href="https://github.com/openfaas/faasd/tree/master/pkg/provider">faasd-provider</a> - a HTTP interface that performs invoke and CRUD for functions and secrets</li>
</ul>
<p>Both are installed with systemd unit files, it was refreshing to lean on the host system for once, instead of using abstractions.</p>
<h3 id="theshortversion">The short-version</h3>
<p><a href="https://multipass.run/">multipass</a> is a <a href="https://canonical.com/">Canonical</a> and its open source components and usage instructions are <a href="https://github.com/canonical/multipass">available on GitHub</a>.</p>
<blockquote>
<p>Multipass is a lightweight VM manager for Linux, Windows and macOS. It's designed for developers who want a fresh Ubuntu environment with a single command.</p>
<p>Since it supports metadata for cloud-init, you can simulate a small cloud deployment on your laptop or workstation.</p>
</blockquote>
<p>On MacOS it is currently using hyperkit to run VMs, which is another thing we can thank Docker for building. On Windows and Linux it uses different virtualization technology, but has the same simple user-experience which means we get to write one tutorial and to be done with it. As a busy maintainer, I see that as a big win.</p>
<p>Here's how you get a VM launched with the latest version of Ubuntu Server:</p>
<pre><code>multipass launch --name faasd
</code></pre>
<p>Shell into the VM:</p>
<pre><code>multipass exec faasd /bin/bash
</code></pre>
<p>We then realised that multipass supported cloud-init, so morphed our README to the following:</p>
<pre><code>curl -sSLO https://raw.githubusercontent.com/openfaas/faasd/master/cloud-config.txt
multipass launch --cloud-init cloud-config.txt  --name faasd
</code></pre>
<p>I had the pleasure of speaking to the engineering manager and PM for multipass on Zoom today and they told me you can even pass the cloud-init file as a URL, so our tutorial becomes even simpler:</p>
<pre><code>multipass launch --cloud-init https://raw.githubusercontent.com/openfaas/faasd/master/cloud-config.txt  --name faasd
</code></pre>
<p>From there, you have a full Linux system with a working version of containerd and Container Network Initiative (CNI) plugins running, and most importantly faasd is up and running.</p>
<pre><code>faas-cli list
faas-cli store deploy figlet
faas-cli invoke figlet &lt;&lt;&lt; "faasd"
</code></pre>
<p>Whilst I've not used it yet, I'm told you can also mount folders from your base system to synchronise your GOPATH. So you could write code using VSCode and have the built-in terminal pane running "multipass exec /bin/bash" or an ssh session.</p>
<p>I recently wrote a post on <a href="https://blog.alexellis.io/memory-lane-raspberry-pi-zero/">One last trip down memory lane with the Raspberry Pi Zero</a> where I tried to port faasd to a Raspberry Pi Zero. The Go build for faasd was taking so long that I gave up, opened multipass and cross-compiled it. That whole process was quicker than waiting for the poor little armv6 service to finish its work.</p>
<h3 id="multipassforkubernetes">multipass for Kubernetes</h3>
<p>You can also use multipass to run other workloads, I tried to deploy Kubernetes with microk8s, but ran into some issues with the default limits.</p>
<p>First of all: there was not enough RAM alloacted, then there was not enough disk, finally there were not enough vCPUs. After working all that out I came up with the following:</p>
<pre><code>multipass launch --name microk8s -m 8G -c 2 -d 80G
</code></pre>
<p>Now it's not that much of a surprise that we never ran into that issue, because faasd is designed to be ridicuously lean. It even runs on a Raspberry Pi 3 which only has 1GB of RAM.</p>
<h2 id="wrappingup">Wrapping up</h2>
<p>multipass has been useful for us whenever we need to access a Linux VM from a Mac. It could even be used for running a Kubernetes cluster, but I would usually prefer to deploy Kubernetes in a Docker container using either <a href="https://kind.sigs.k8s.io/">KinD</a> or <a href="https://github.com/rancher/k3d">k3d</a> for the sheer speed and efficiency of it.</p>
<p>multipass is a much leaner alternative to tooling like VirtualBox and Vagrant. The team are looking for feedback and are already planning for a way to launch custom images. Think: <code>multipass launch openfaas</code> or <code>multipass launch gitlab</code> for instance.</p>
<blockquote>
<p>We see multipass being an important part of enabling collaboration with users from all-over the world, whether they use Linux, MacOS or Windows on their desktop.</p>
</blockquote>
<p>Around 20 people have contributed to faasd directly, and many more indirectly. It worked very well for us and we believe that multipass deserves more attention.</p>
<p>Go and try it out, let them know what works for you and where it can be improved for your workflow.</p>
<blockquote>
<p>Users have already suggested using <a href="https://github.com/canonical/multipass/issues?q=is%3Aissue+is%3Aopen+qemu">qemu on MacOS</a>, and the new <a href="https://developer.apple.com/documentation/virtualization">Virtualization.Framework</a> introduced in Big Sur could also have some impact on the future roadmap and M1 support.</p>
</blockquote>
<ul>
<li><a href="https://multipass.run/">multipass.run</a></li>
</ul>
<h3 id="whataboutfaasdvsopenfaasonkubernetes">what about faasd vs. OpenFaaS on Kubernetes?</h3>
<p>faasd now fills a nice gap where Docker Swarm used to live in the OpenFaaS ecosystem. If you're working your way up to production with Kubernetes, or already have experience then you may benefit from a cluster and installing OpenFaaS to it.</p>
<p>If you're wanting to run a few functions, start small, keep costs down, then faasd may be a better fit. Managing and keeping up with Kubernetes versions can be its own challenge. So if you want to deploy code for a customer and barely give it another thought, then package faasd as a VM or cloud-init script and be done with it.</p>
<p>faasd can be run for 5-10 USD on a cloud VPS, or on your Raspberry Pi for free using <a href="https://docs.inlets.dev/">an inlets tunnel</a> to get it a public IP address.</p>
<p>Learn more about faasd and OpenFaaS at our Birthday event - join us on the 18th and participate in the Prize Draw too: <a href="https://github.com/openfaas/faas/issues/1592">Save the date 🎂 - OpenFaaS 4th birthday!</a></p>
<p>Did you enjoy this article? Follow me through GitHub Sponsors and get a weekly email from me and regular updates on my OSS work: <a href="https://github.com/sponsors/alexellis">github.com/sponsors/alexellis</a></p>
</div>
        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>https://blog.alexellis.io/containerd-development-multipass/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25397043</guid>
            <pubDate>Sat, 12 Dec 2020 09:36:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Germany's State Distance-Learning University]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25396999">thread link</a>) | @Tomte
<br/>
December 12, 2020 | https://www.fernuni-hagen.de/english/ | <a href="https://web.archive.org/web/*/https://www.fernuni-hagen.de/english/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>The FernUniversität in Hagen is Germany’s only state distance-learning university, and its largest in terms of student numbers. Its flexible degree programs and continuing education options make higher education accessible to students in a variety of life situations. Its five faculties conduct a wide range of theoretical and applied research in their subject areas of Humanities and Social Sciences, Psychology, Mathematics and Computer Science, Economics and Business Administration, and Law.</p> <p><a href="https://www.fernuni-hagen.de/english/university/index.shtml">Learn more</a></p>
	</div><div>
		<h2>The Hagen New Learning Manifesto</h2> <p><span><span>How should we, how can we, how must we learn in the future?</span></span> The FernUniversität in Hagen and leading educational experts address these questions in a new position paper about New Learning.</p> <p><a href="https://www.fernuni-hagen.de/english/university/hagen-manifesto.shtml">Learn more and read the Manifesto</a></p>
	</div></div>]]>
            </description>
            <link>https://www.fernuni-hagen.de/english/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396999</guid>
            <pubDate>Sat, 12 Dec 2020 09:27:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oracle Migration to Austin to Take Place over Next 100 Years]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25396874">thread link</a>) | @markthethomas
<br/>
December 12, 2020 | https://unicorn.computer/oracle-migration-to-austin-taking-place-over-next-100-years | <a href="https://web.archive.org/web/*/https://unicorn.computer/oracle-migration-to-austin-taking-place-over-next-100-years">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>(San Francisco, CA) - Another longtime corporate resident of the San Francisco Bay Area is leaving town. Oracle, maker of acronym-based software (CRM, ERP, HCM, SCM, and more) as well as database technology is pulling up roots and moving to Austin, Texas. The move comes as a number of other companies have announced similar plans to migrate their corporate headquarters out of California, including Tesla, Palantir, and Hewlett Packard Enterprise.</p>
<p>A difference for Oracle, however, is that the migration process will take much, much longer than other companies. We were able to reach an Oracle spokesperson to help us understand why the migration will take so long:</p>
<blockquote>
<p>"Well, our legal units will move first. They're the heart of our company and comprise about 125,000 of our 135,000 employees. That should be fast. 3-5 years, tops. The real challenge comes for migrating our database teams and technologies. That will be a herculean effort. Our team's earliest estimates show it taking anywhere between 75 and 100 years to complete the migration"</p>
</blockquote></div></div>]]>
            </description>
            <link>https://unicorn.computer/oracle-migration-to-austin-taking-place-over-next-100-years</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396874</guid>
            <pubDate>Sat, 12 Dec 2020 08:59:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Positive habits are underestimated [All the time]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25396845">thread link</a>) | @KlimYadrintsev
<br/>
December 12, 2020 | https://klimy.co/blog/positive-habits-12-12-2020 | <a href="https://web.archive.org/web/*/https://klimy.co/blog/positive-habits-12-12-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <p>We, humans, tend to have a very tough time taking breaks and regenerating. We tend to set for ourself goals that are either too hard to achieve or straight up take too much of our time.</p>
<p>We have all been there. We decide to learn an additional skill, or we decided to lose that last weight that has been bringing us down.</p>
<p>The problem starts when we have outlined the goal, and we decide on the path of reaching it. We get motivated to start by motion which as a result, at the beginning we fill that we are superhumans. That can cause you to overestimate your free time and capabilities.</p>
<p>How many of us quit the gym completely, just because going there every day was not sustainable? How many of us stopped learning a new language because cramming study sessions on the weekends is not healthy and neither fun? Raise your hands. I know that I did both of those.</p>
<p>I have been a victim for underestimating how much time could the task take and the effort that will be required to finish it. I am <a href="https://klimy.co/blog/why-small-habits-11-12-2020">raising a hand for that.</a></p>
<h2>How human usually deal with no energy</h2>
<p>So if you constantly do something too challenging, you are draining your energy instead of getting the boost of cognitive resources. That, of course, can not go forever and at one point you will realise that you are not able to do the task and even the idea of starting makes you want to do anything, but that.</p>
<p>That is the point at which people can either:</p>
<ol>
<li>Quit</li>
<li>Preserver and quit in a week</li>
<li>Take a break and quit in a month</li>
<li>Change the task completely so that it is sustainable</li>
</ol>
<p>As you could imagine, the 4th option is the optimal one. But it is also the one that is chosen the least. </p>
<p>If you have driven yourself to the point of hate, it will be tough to make you like the habit ever again.</p>
<p>The worst part of our lives is that this is an essential step in understanding how to become more efficient. I don’t know a single person that has become productive and coincidentally achieved greatness in life but hasn’t burned out at least once.</p>
<p>Why is that? It seems to start small and improve everything with little steps(which is <a href="https://link.springer.com/chapter/10.1007%2F978-3-030-58565-5_6">proven to be the best way to achieve great goals</a>), you have to fail in achieving something couple of times.</p>
<p>This knowledge is not programmed into our brain or genes. That is why we need to learn on our own mistakes to understand the right course of actions.</p>
<h2>Why does this matter?</h2>
<p>I understand that some people don’t want to do anything that is not immediately satisfactory. I understand that good habits are boring and not fun at all. </p>
<p>The main reason they are not fun is that the effect and the result are postponed so much into the future that our brain, due to smartphones and social media, has been reprogrammed to expect low-cost dopamine hits in everything that we do. </p>
<p>Why do people still perform good, boring habits, then?</p>
<p>Because in the long run, the total amount of dopamine that you get will increase with every time you do the task, and eventually it will snowball into the most amazing feeling you will ever experience.</p>
<p>Writing a chapter of a book is boring and most likely is <a href="https://klimy.co/blog/when-productivity-increases">extremely unrewarding</a>. You spent your time researching, writing and editing. It was super boring and maybe even painful. There is literally no dopamine there.</p>
<p>But, once you write your book, the combined effect of all the sessions will hit your right in the face with the most amazing and happy feeling ever. Maybe even that book will let you retire and become the happiest human on earth, who knows?</p>
<p><img alt="progress vs happiness" src="https://i.gyazo.com/ee36f0c65178aca1860c7e924f182fc2.png"></p>
<p>The thing is that every good habit is like this. Don’t underestimate what you can achieve by just doing <a href="https://klimy.co/blog/impact-through-motion">the right thing, consistently.</a></p>
<p>Start now. Get perfect later.</p>
<p>Klim Y</p> 
                    
                </div></div>]]>
            </description>
            <link>https://klimy.co/blog/positive-habits-12-12-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396845</guid>
            <pubDate>Sat, 12 Dec 2020 08:52:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tacit Programming (APL)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25396753">thread link</a>) | @jpcooper
<br/>
December 12, 2020 | https://aplwiki.com/wiki/Tacit_programming | <a href="https://web.archive.org/web/*/https://aplwiki.com/wiki/Tacit_programming">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en-GB" dir="ltr"><div><p>Tacit functions apply to implicit arguments. This is in contrast to the explicit use of arguments in <a href="https://aplwiki.com/wiki/Dfns" title="Dfns">dfns</a> (<code dir="ltr"><span>⍺</span> <span>⍵</span></code>) and <a href="https://aplwiki.com/wiki/Tradfns" title="Tradfns">tradfns</a> (which have named arguments). Some APL dialects allow to combine functions into <b>trains</b> following a small set of rules. This allows creating complex derived functions without specifying any arguments explicitly.
</p><p>Known dialects which implement trains are <a href="https://aplwiki.com/wiki/Dyalog_APL" title="Dyalog APL">Dyalog APL</a>, <a href="https://aplwiki.com/wiki/Dzaima/APL" title="Dzaima/APL">dzaima/APL</a>, <a href="https://aplwiki.com/wiki/Ngn/apl" title="Ngn/apl">ngn/apl</a> and <a href="https://aplwiki.com/wiki/NARS2000" title="NARS2000">NARS2000</a>.
</p>


<h2><span id="Primitives">Primitives</span></h2>
<p>All <a href="https://aplwiki.com/wiki/Primitive_functions" title="Primitive functions">primitive functions</a> are tacit. Some APLs allow primitive functions to be named.
</p>
<div dir="ltr"><pre><span></span>      <span>plus</span> <span>←</span> <span>+</span>
      <span>times</span> <span>←</span> <span>×</span>
      <span>6</span> <span>times</span> <span>3</span> <span>plus</span> <span>5</span>
<span>48</span>
</pre></div>
<h2><span id="Derived_functions">Derived functions</span></h2>
<p>Functions derived from a monadic operator and an operand, or from a dyadic operator and two operands are tacit functions:
</p>
<div dir="ltr"><pre><span></span>      <span>Sum</span> <span>←</span> <span>+</span><span>/</span>
      <span>Sum</span> <span>⍳</span><span>10</span>
<span>55</span>

      <span>Dot</span> <span>←</span> <span>+</span><span>.</span><span>×</span>
      <span>3</span> <span>1</span> <span>4</span> <span>dot</span> <span>2</span> <span>7</span> <span>1</span>
<span>17</span>
</pre></div>
<h2><span id="Derived_operators">Derived operators</span></h2>
<p>A dyadic operator with its right operand forms a tacit monadic operator:
</p>
<div dir="ltr"><pre><span></span>      <span>1</span><span>(</span><span>+</span><span>⍣</span><span>2</span><span>)</span><span>10</span>
<span>12</span>
      <span>Twice</span> <span>←</span> <span>⍣</span><span>2</span>
      <span>1</span> <span>+</span><span>Twice</span> <span>10</span>
<span>12</span>
</pre></div>
<h2><span id="Trains">Trains</span></h2>
<p>A train is a series of functions in isolation. An isolated function is either surrounded by parentheses or named. Below, <code dir="ltr"><span>⍺</span></code> and <code dir="ltr"><span>⍵</span></code> refer to the arguments of the train. <code dir="ltr"><span>f</span></code>, <code dir="ltr"><span>g</span></code>, and <code dir="ltr"><span>h</span></code> are functions (which themselves can be tacit or not), and <code dir="ltr"><span>A</span></code> is an array. The arguments are processed by the following rules:
</p>
<h3><span id="Forks">Forks</span></h3>
<p>A 3-train is a <i>fork</i>:
</p>

<p>The <i>left tine</i> of a fork can be an array:
</p>

<h3><span id="Atops">Atops</span></h3>
<p>A 2-train is an <i>atop</i>:
</p>

<p>Only <a href="https://aplwiki.com/wiki/Dzaima/APL" title="Dzaima/APL">dzaima/APL</a> allows <code dir="ltr"><span>(</span><span>A</span> <span>h</span><span>)</span></code>, which it treats as <code dir="ltr"><span>A</span><span>∘</span><span>h</span></code>.<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup> See <a href="https://aplwiki.com/wiki/Bind" title="Bind">Bind</a>.
</p>
<h2><span id="Debugging">Debugging</span></h2>
<p>In <a href="https://aplwiki.com/wiki/Dyalog_APL" title="Dyalog APL">Dyalog APL</a>, analysis of trains is assisted by a <a href="https://aplwiki.com/wiki/User_command" title="User command">user command</a> <code dir="ltr"><span>]</span><span>Boxing</span> <span>on</span></code>. This is achieved by executing the command <code dir="ltr"><span>]</span><span>Boxing</span> <span>on</span></code> and then entering a train without any parameters. A structure of the train will be displayed.
</p><p>For example, the "accursed train" from the section below can be analysed like this:
</p>
<div dir="ltr"><pre><span></span>      <span>]</span><span>Boxing</span> <span>on</span>
<span>Was</span> <span>OFF</span>
      <span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span>     <span>⍝ the train to be analysed</span>
<span>┌───────────────────────────────┬───────┐</span>
<span>│┌───────────┬─────────────────┐│┌─┬─┬─┐│</span>
<span>││┌───────┬─┐│┌─┬─┬───────────┐│││</span><span>1</span><span>│</span><span>↓</span><span>│</span><span>⍳</span><span>││</span>
<span>│││┌─┬─┬─┐│</span><span>⍨</span><span>│││</span><span>⊢</span><span>│</span><span>~</span><span>│┌───────┬─┐│││└─┴─┴─┘│</span>
<span>││││</span><span>+</span><span>│</span><span>.</span><span>│</span><span>×</span><span>││</span> <span>│││</span> <span>│</span> <span>││┌─┬─┬─┐│</span><span>⍨</span><span>││││</span>       <span>│</span>
<span>│││└─┴─┴─┘│</span> <span>│││</span> <span>│</span> <span>│││</span><span>∘</span><span>│</span><span>.</span><span>│</span><span>×</span><span>││</span> <span>││││</span>       <span>│</span>
<span>││└───────┴─┘││</span> <span>│</span> <span>││└─┴─┴─┘│</span> <span>││││</span>       <span>│</span>
<span>││</span>           <span>││</span> <span>│</span> <span>│└───────┴─┘│││</span>       <span>│</span>
<span>││</span>           <span>│└─┴─┴───────────┘││</span>       <span>│</span>
<span>│└───────────┴─────────────────┘│</span>       <span>│</span>
<span>└───────────────────────────────┴───────┘</span>
</pre></div>
<p>Alternatively, a train can be represented in form of a tree:
</p>
<div dir="ltr"><pre><span></span>      <span>]</span><span>Boxing</span> <span>on</span> <span>-</span><span>trains</span><span>=</span><span>tree</span>
<span>Was</span> <span>ON</span> <span>-</span><span>trains</span><span>=</span><span>box</span>
      <span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span>     <span>⍝ the train to be analysed</span>
     <span>┌───┴───┐</span>  
   <span>┌─┴─┐</span>   <span>┌─┼─┐</span>
   <span>⍨</span> <span>┌─┼─┐</span> <span>1</span> <span>↓</span> <span>⍳</span>
 <span>┌─┘</span> <span>⊢</span> <span>~</span> <span>⍨</span>      
 <span>.</span>     <span>┌─┘</span>      
<span>┌┴┐</span>    <span>.</span>        
<span>+</span> <span>×</span>   <span>┌┴┐</span>       
      <span>∘</span> <span>×</span>
</pre></div>
<p>Or fully parenthesised:
</p>
<div dir="ltr"><pre><span></span>      <span>]</span><span>Boxing</span> <span>on</span> <span>-</span><span>trains</span><span>=</span><span>parens</span>
<span>Was</span> <span>OFF</span> <span>-</span><span>trains</span><span>=</span><span>box</span>
      <span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span>     <span>⍝ the train to be analysed</span>
<span>(((</span><span>+</span><span>.</span><span>×</span><span>)</span><span>⍨</span><span>)(</span><span>⊢~</span><span>((</span><span>∘.</span><span>×</span><span>)</span><span>⍨</span><span>)))(</span><span>1</span><span>↓⍳</span><span>)</span>
</pre></div>
<h2><span id="Examples">Examples</span></h2>
<p>One of the major benefits of tacit programming is the ability to convey a short, well-defined idea as an isolated expression. This aids both human readability (<a href="https://aplwiki.com/wiki/Semantic_density" title="Semantic density">semantic density</a>) and the computer's ability to interpret code, potentially executing special code for particular <a href="https://aplwiki.com/index.php?title=Idiom&amp;action=edit&amp;redlink=1" title="Idiom (page does not exist)">idioms</a>.
</p>
<h3><span id="Plus_and_minus">Plus and minus</span></h3>
<div dir="ltr"><pre><span></span>      <span>(</span><span>+,-</span><span>)</span> <span>2</span>     <span>⍝ ±2</span>
<span>2</span> <span>¯2</span>
      <span>5</span> <span>(</span><span>+,-</span><span>)</span> <span>2</span>   <span>⍝ 5±2</span>
<span>7</span> <span>3</span>
</pre></div>
<h3><span id="Arithmetic_mean">Arithmetic mean</span></h3>
<div dir="ltr"><pre><span></span>      <span>(</span><span>+</span><span>⌿</span><span>÷≢</span><span>)</span> <span>⍳</span><span>10</span>       <span>⍝ Mean of the first ten integers</span>
<span>5.5</span>
      <span>(</span><span>+</span><span>⌿</span><span>÷≢</span><span>)</span> <span>5</span> <span>4</span><span>⍴⍳</span><span>4</span>    <span>⍝ Mean of columns in a matrix</span>
<span>1</span> <span>2</span> <span>3</span> <span>4</span>
</pre></div>
<h3><span id="Fractions">Fractions</span></h3>
<p>We can convert decimal numbers to fractions. For example, we can convert <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ace31f232e5ba24a1a418586f322f06724e5e12d" aria-hidden="true" alt="{\displaystyle 2.625}"></span> to the improper fraction <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1c58d4e0e0fdb69d9aa1ea7296259ddb24d56e39" aria-hidden="true" alt="{\displaystyle {\tfrac {21}{8}}}"></span> with
</p>

<p>Alternatively, we can convert it to the mixed fraction <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3a15740caaa334e457b2766a3bcfc22366196cec" aria-hidden="true" alt="{\displaystyle 2{\tfrac {5}{8}}}"></span> with a mixed fraction:
</p>

<h3><span id="Is_it_a_palindrome?"></span><span id="Is_it_a_palindrome.3F">Is it a palindrome?</span></h3>
<div dir="ltr"><pre><span></span>      <span>(</span><span>⌽≡⊢</span><span>)</span><span>'racecar'</span>
<span>1</span>
      <span>(</span><span>⌽≡⊢</span><span>)</span><span>'racecat'</span>
<span>0</span>
</pre></div>
<h3><span id="Split_delimited_text">Split delimited text</span></h3>
<div dir="ltr"><pre><span></span>      <span>','</span><span>(</span><span>≠</span><span>⊆</span><span>⊢</span><span>)</span><span>'comma,delimited,text'</span>
<span>┌─────┬─────────┬────┐</span>
<span>│</span><span>comma</span><span>│</span><span>delimited</span><span>│</span><span>text</span><span>│</span>
<span>└─────┴─────────┴────┘</span>
      <span>' '</span><span>(</span><span>≠</span><span>⊆</span><span>⊢</span><span>)</span><span>'space delimited text'</span>
<span>┌─────┬─────────┬────┐</span>
<span>│</span><span>space</span><span>│</span><span>delimited</span><span>│</span><span>text</span><span>│</span>
<span>└─────┴─────────┴────┘</span>
</pre></div>
<h3><span id="Component_of_a_vector_in_the_direction_of_another_vector">Component of a vector in the direction of another vector</span></h3>
<p>Sometimes a train can make an expression nicely resemble its equivalent definition in traditional mathematical notation. As an example, here is a program to compute the component of a vector <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/af9f1604cec45bc8d60e31610f9ec1b7c6599b68" aria-hidden="true" alt="{\displaystyle {\textbf {a}}}"></span> in the direction of another vector <span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/29890eb931b98e8816c928582f07d7eaa86cc348" aria-hidden="true" alt="{\displaystyle {\textbf {b}}}"></span>:
</p>
<dl><dd><dl><dd><dl><dd><span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8bd13a4409c254c27e5740a13f040bac84cb6a93" aria-hidden="true" alt="{\displaystyle {\textbf {a}}_{\textbf {b}}=({\textbf {a}}\cdot {\hat {\textbf {b}}}){\hat {\textbf {b}}}}"></span></dd></dl></dd></dl></dd></dl>
<div dir="ltr"><pre><span></span>      <span>Root</span> <span>←</span> <span>*</span><span>∘</span><span>÷</span><span>⍨</span>              <span>⍝ Nth root</span>
      <span>Norm</span> <span>←</span> <span>2</span> <span>Root</span> <span>+</span><span>.</span><span>×</span><span>⍨</span>       <span>⍝ Magnitude (norm) of numeric vector in Euclidean space</span>
      <span>Unit</span> <span>←</span> <span>⊢÷</span><span>Norm</span>            <span>⍝ Unit vector in direction of vector ⍵</span>
      <span>InDirOf</span> <span>←</span> <span>(</span><span>⊢×+</span><span>.</span><span>×</span><span>)</span><span>∘</span><span>Unit</span>   <span>⍝ Component of vector ⍺ in direction of vector ⍵</span>
      <span>3</span> <span>5</span> <span>2</span> <span>InDirOf</span> <span>0</span> <span>0</span> <span>1</span>      <span>⍝ Trivial example</span>
<span>0</span> <span>0</span> <span>2</span>
</pre></div>
<p>For a more parallel comparison of the notations, see the <a href="https://aplwiki.com/wiki/Comparison_with_traditional_mathematics#Practical_example" title="Comparison with traditional mathematics">comparison with traditional mathematics</a>.
</p>
<h3><span id="The_Number_of_the_Beast">The Number of the Beast</span></h3>
<p>The following expression for computing the <a href="https://en.wikipedia.org/wiki/666_(number)" title="wikipedia:666 (number)">number of the Beast</a> (and of <a href="https://aplwiki.com/wiki/I.P._Sharp" title="I.P. Sharp">I.P. Sharp</a>'s APL-based email system, <a href="https://aplwiki.com/index.php?title=666_BOX&amp;action=edit&amp;redlink=1" title="666 BOX (page does not exist)">666 BOX</a>) nicely illustrates how to read a train.
</p>
<div dir="ltr"><pre><span></span>      <span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span><span>17</span> <span>⍝ Accursed train</span>
<span>666</span>
</pre></div>
<p>First, <code dir="ltr"><span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span></code> is supplied with only one argument <code dir="ltr"><span>17</span></code> and is thus interpreted monadically.
</p><p>Second, <code dir="ltr"><span>(</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span></code> is a 4-train: reading right-to-left, the last 3 components are interpreted as the fork <code dir="ltr"><span>1</span><span>↓⍳</span></code> and the 4-train is interpreted as the atop <code dir="ltr"><span>(</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)(</span><span>1</span><span>↓⍳</span><span>)</span></code>.
Similarly, <code dir="ltr"><span>(</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span></code> is also a 4-train and interpreted as the atop <code dir="ltr"><span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span></code>. 
</p><p>Thus the accursed train is interpreted as <code dir="ltr"><span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>))(</span><span>1</span><span>↓⍳</span><span>))</span><span>17</span></code>. Having read the train, we now evaluate it monadically.
</p>
<div dir="ltr"><pre><span></span>      <span>((</span><span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>))(</span><span>1</span><span>↓⍳</span><span>))</span><span>17</span> <span>⍝ Accursed train as an atop over a fork atop a fork</span>
      <span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>⊢~</span><span>∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>17</span>       <span>⍝ Atop evalution</span>
      <span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>⊢</span><span>1</span><span>↓⍳</span><span>17</span><span>)</span><span>~</span><span>∘.</span><span>×</span><span>⍨</span><span>1</span><span>↓⍳</span><span>17</span>  <span>⍝ Fork evalution</span>
      <span>+</span><span>.</span><span>×</span><span>⍨</span><span>(</span><span>1</span><span>↓⍳</span><span>17</span><span>)</span><span>~</span><span>∘.</span><span>×</span><span>⍨</span><span>1</span><span>↓⍳</span><span>17</span>   <span>⍝ ⊢ evaluation</span>
      <span>+</span><span>.</span><span>×</span><span>⍨</span><span>2</span> <span>3</span> <span>5</span> <span>7</span> <span>11</span> <span>13</span> <span>15</span> <span>17</span> <span>⍝ numbers 2 through 17 without those appearing in their multiplication table are primes</span>
<span>666</span>                           <span>⍝ the sum of the squares of the primes up to 17</span>
</pre></div>
<p>Note that <code dir="ltr"><span>((</span><span>⊢</span><span>⍨∘.</span><span>×</span><span>⍨</span><span>)</span><span>1</span><span>↓⍳</span><span>)</span></code> is a train computing primes up to the given input.
</p><p>A more satisfying variation of the accursed train is the following.
</p>
<div dir="ltr"><pre><span></span>      <span>(</span><span>⍎⊢,⍕</span><span>∘</span><span>≢</span><span>)</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)'</span>                    <span>⍝ Accursed train 2.0</span>
      <span>⍎</span><span>(</span><span>⊢,⍕</span><span>∘</span><span>≢</span><span>)</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)'</span>                    <span>⍝ 4-train intepreted as an atop</span>
      <span>⍎</span><span>(</span><span>⊢</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)'</span><span>)</span><span>,⍕</span><span>∘</span><span>≢</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)'</span> <span>⍝ fork evaluation</span>
      <span>⍎</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)'</span><span>,</span><span>'17'</span>                      <span>⍝ ⊢ evaluation and ⍕∘≢ evaluation</span>
      <span>⍎</span><span>'((+.×⍨⊢~∘.×⍨)1↓⍳)17'</span>                         <span>⍝ , evaluation</span>
<span>666</span>                                                  <span>⍝ ⍎ executes original Accursed train</span>
</pre></div>
<h2><span id="External_links">External links</span></h2>
<h3><span id="Tutorials">Tutorials</span></h3>
<ul><li>Dyalog: <a rel="nofollow" href="https://help.dyalog.com/16.0/Content/RelNotes14.0/Function%20Trains.htm">version 14.0 release notes</a></li>
<li><a href="https://aplwiki.com/wiki/APL_Cultivation" title="APL Cultivation">APL Cultivation</a>: <a rel="nofollow" href="https://chat.stackexchange.com/rooms/52405/conversation/lesson-23-transcribing-to-and-reading-trains">Transcribing to and reading trains</a></li>
<li><a href="https://aplwiki.com/wiki/APLtrainer" title="APLtrainer">APLtrainer</a>: <a rel="nofollow" href="https://www.youtube.com/watch?v=kt4lMZbn-so">How to read trains in Dyalog APL code</a> (video)</li>
<li><a href="https://aplwiki.com/wiki/APLtrainer" title="APLtrainer">APLtrainer</a>: <a rel="nofollow" href="https://www.youtube.com/watch?v=A2LqqBosvY0">Function trains in APL</a> (video)</li>
<li><a href="https://aplwiki.com/wiki/Dyalog_webinar" title="Dyalog webinar">Dyalog webinar</a>: <a rel="nofollow" href="https://www.youtube.com/watch?v=Enlh5qwwDuY?t=440">Train Spotting in Dyalog APL</a> (video)</li>
<li><a href="https://aplwiki.com/wiki/Dyalog_%2713" title="Dyalog '13">Dyalog '13</a>: <a rel="nofollow" href="https://www.youtube.com/watch?v=7-93GzDqC08">Train Spotting in Version 14.0</a> (video)</li></ul>
<h3><span id="Documentation">Documentation</span></h3>
<ul><li><a rel="nofollow" href="https://help.dyalog.com/16.0/Content/RelNotes14.0/Function%20Trains.htm">Announcement</a></li>
<li><a rel="nofollow" href="https://help.dyalog.com/latest/Content/Language/Introduction/Trains.htm">Dyalog</a></li></ul>
<h2><span id="References">References</span></h2>


<table>
<tbody><tr>
<th colspan="2"><b><big>APL syntax</big></b> [<a rel="nofollow" href="https://aplwiki.com/index.php?title=Template:APL_syntax&amp;action=edit">edit</a>]
</th></tr>
<tr>
<th><a href="https://aplwiki.com/wiki/APL_syntax" title="APL syntax">General</a>
</th>
<td><a href="https://aplwiki.com/wiki/Comparison_with_traditional_mathematics" title="Comparison with traditional mathematics">Comparison with traditional mathematics</a> ∙ <a href="https://aplwiki.com/index.php?title=Precedence&amp;action=edit&amp;redlink=1" title="Precedence (page does not exist)">Precedence</a> ∙ <a>Tacit programming</a>
</td></tr>
<tr>
<th><a href="https://aplwiki.com/wiki/Array" title="Array">Array</a>
</th>
<td><a href="https://aplwiki.com/index.php?title=Numeric_literal&amp;action=edit&amp;redlink=1" title="Numeric literal (page does not exist)">Numeric literal</a> ∙ <a href="https://aplwiki.com/wiki/String" title="String">String</a> ∙ <a href="https://aplwiki.com/wiki/Strand_notation" title="Strand notation">Strand notation</a> ∙ <a href="https://aplwiki.com/index.php?title=Object_literal&amp;action=edit&amp;redlink=1" title="Object literal (page does not exist)">Object literal</a> ∙ <a href="https://aplwiki.com/wiki/Array_notation" title="Array notation">Array notation</a>
</td></tr>
<tr>
<th><a href="https://aplwiki.com/wiki/Function" title="Function">Function</a>
</th>
<td><a href="https://aplwiki.com/wiki/Argument" title="Argument">Argument</a> ∙ <a href="https://aplwiki.com/wiki/Function_valence" title="Function valence">Function valence</a> ∙ <a href="https://aplwiki.com/wiki/Derived_function" title="Derived function">Derived function</a> ∙ <a href="https://aplwiki.com/wiki/Derived_operator" title="Derived operator">Derived operator</a> ∙ <a href="https://aplwiki.com/wiki/Niladic_function" title="Niladic function">Niladic function</a> ∙ <a href="https://aplwiki.com/wiki/Monadic_function" title="Monadic function">Monadic function</a> ∙ <a href="https://aplwiki.com/wiki/Dyadic_function" title="Dyadic function">Dyadic function</a> ∙ <a href="https://aplwiki.com/wiki/Ambivalent_function" title="Ambivalent function">Ambivalent function</a> ∙ <a href="https://aplwiki.com/wiki/Tradfn" title="Tradfn">Tradfn</a> ∙ <a href="https://aplwiki.com/wiki/Dfn" title="Dfn">Dfn</a> ∙ <a href="https://aplwiki.com/wiki/Function_train" title="Function train">Function train</a>
</td></tr>
<tr>
<th><a href="https://aplwiki.com/wiki/Operator" title="Operator">Operator</a>
</th>
<td><a href="https://aplwiki.com/wiki/Operand" title="Operand">Operand</a> ∙ <a href="https://aplwiki.com/wiki/Operator_valence" title="Operator valence">Operator valence</a> ∙ <a href="https://aplwiki.com/wiki/Tradop" title="Tradop">Tradop</a> ∙ <a href="https://aplwiki.com/wiki/Dop" title="Dop">Dop</a> ∙ <a href="https://aplwiki.com/wiki/Derived_operator" title="Derived operator">Derived operator</a>
</td></tr>
<tr>
<th><a href="https://aplwiki.com/index.php?title=Assignment&amp;action=edit&amp;redlink=1" title="Assignment (page does not exist)">Assignment</a>
</th>
<td><a href="https://aplwiki.com/index.php?title=Multiple_assignment&amp;action=edit&amp;redlink=1" title="Multiple assignment (page does not exist)">Multiple</a> ∙ <a href="https://aplwiki.com/index.php?title=Indexed_assignment&amp;action=edit&amp;redlink=1" title="Indexed assignment (page does not exist)">Indexed</a> ∙ <a href="https://aplwiki.com/index.php?title=Selective_assignment&amp;action=edit&amp;redlink=1" title="Selective assignment (page does not exist)">Selective</a> ∙ <a href="https://aplwiki.com/index.php?title=Modified_assignment&amp;action=edit&amp;redlink=1" title="Modified assignment (page does not exist)">Modified</a>
</td></tr>
<tr>
<th>Other
</th>
<td><a href="https://aplwiki.com/wiki/Function_axis" title="Function axis">Function axis</a> ∙ <a href="https://aplwiki.com/wiki/Branch" title="Branch">Branch</a> ∙ <a href="https://aplwiki.com/wiki/Quad_name" title="Quad name">Quad name</a> ∙ <a href="https://aplwiki.com/wiki/System_command" title="System command">System command</a> ∙ <a href="https://aplwiki.com/wiki/User_command" title="User command">User command</a> ∙ <a href="https://aplwiki.com/index.php?title=Keyword&amp;action=edit&amp;redlink=1" title="Keyword (page does not exist)">Keyword</a> ∙ <a href="https://aplwiki.com/index.php?title=Dot_notation&amp;action=edit&amp;redlink=1" title="Dot notation (page does not exist)">Dot notation</a> ∙ <a href="https://aplwiki.com/wiki/Function-operator_overloading" title="Function-operator overloading">Function-operator overloading</a>
</td></tr></tbody></table>
<!-- 
NewPP limit report
Cached time: 20201113092414
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.439 seconds
Real time usage: 14.465 seconds
Preprocessor visited node count: 606/1000000
Preprocessor generated node count: 1305/1000000
Post‐expand include size: 1601/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 2/40
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 26166/5000000 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00% 10147.365      1 -total
  0.06%    5.898      6 Template:←→
  0.05%    5.146      1 Template:APL_syntax
-->

<!-- Saved in parser cache with key aplwiki:pcache:idhash:487-0!canonical!math=5 and timestamp 20201113092359 and revision id 5726
 -->
</div></div></div>]]>
            </description>
            <link>https://aplwiki.com/wiki/Tacit_programming</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396753</guid>
            <pubDate>Sat, 12 Dec 2020 08:30:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Balance Your Full-Time Job with a Side Hustle]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25396731">thread link</a>) | @RichardHanson
<br/>
December 12, 2020 | https://career.dearjulius.com/2020/12/balance-your-full-time-job-with-side-hustle.html | <a href="https://web.archive.org/web/*/https://career.dearjulius.com/2020/12/balance-your-full-time-job-with-side-hustle.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>
    Starting a side hustle can be a great way to bring in extra income,
    especially if you need money to grow your emergency fund or pay down debt.
    With so many ways to make money online or in person, it’s possible to work a
    side gig around your regular 9-to-5 job.
  </p>
  
  <p>
    Figuring out how to balance a full-time job with a side hustle can put your
    time management skills to the test. As a full-time freelance writer who also
    runs three blogs and homeschools two kids, I understand the struggle. If
    you’re working a full-time job and side hustle at the same time, we’ve got
    some tips from side hustle experts on how to do both.
  </p>
  
  <p>
    Starting a side hustle can help you to flex your entrepreneurial muscles,
    and it’s become an increasingly popular way to make money. But there’s some
    thought that needs to go into it, especially if you’re also working a
    full-time job.
  </p>
  
  <p>
    It’s helpful to think about what your goals are, what kind of side hustle
    you’re most interested in pursuing, and how much time you can realistically
    commit to it.
  </p>
  
  <p>
    There’s no magic bullet for how to balance your full-time job with a side
    hustle. It takes planning and patience to make it all work.
  </p>
  
  <p>
    But whether you’re spending a few hours a day on your side hustle or just a
    few hours a week, these strategies can help you find a happy medium between
    working for your boss and trying to become your own boss in your spare time.
  </p>
  
  
  
  <h3>1. Pick a side hustle you’re passionate about</h3>
  <p><img alt="Pick a side hustle you’re passionate about" data-original-height="661" data-original-width="1024" src="https://1.bp.blogspot.com/-43lJkK63EJc/X9R6UET8QDI/AAAAAAAAGIQ/Pm7381XLNrAJgOcZF-blMqAfjZm0xy7zQCLcBGAsYHQ/s16000/1.-pick-a-side-hustle-you%2527r.jpg">
  </p>
  
  <p>
    Making a full-time job and side hustle work can be a lot easier if you’re
    making money doing something that gets you motivated. Gowtham Kandavel, a
    senior user interface (UX) designer who also runs Thrilla, a website for
    other UX designers, said that’s key to making a full-time job and side gig
    work.
  </p>
  
  <p>
    “Only if you are passionate will you be able to burn the midnight oil
    without breaking down,” he said.
  </p>
  
  <p>
    Kandavel learned that from experience with his first two side hustles, both
    of which failed. The problem is that those side hustles didn’t reflect his
    passions or interests, which hindered his success.
  </p>
  
  <p>
    If your goal for starting a side hustle is to eventually turn it into a
    business, think about what you could see yourself doing for the long term.
    Consider your passions and use those to generate side hustle ideas so you’re
    doing something you love. That way, having a full-time job and side hustle
    feels less like having two jobs.
  </p>
  
  
  
  <h3>2. Set clear boundaries</h3>
  <p><img alt="Set clear boundaries" data-original-height="661" data-original-width="1024" src="https://1.bp.blogspot.com/-c2pMtAvYIbk/X9R6fpbfQXI/AAAAAAAAGIU/4-dBOjUQiRchaM3hipv898TFjcgcy5G4wCLcBGAsYHQ/s16000/2.-set-clear-boundaries.jpg">
  </p>
  
  <p>
    Being an entrepreneur with a full-time job means you only have so much time.
    You need to be clear about what you are and aren’t willing to sacrifice,
    said Andrew Chen, a product manager at Google who has three side hustles,
    including running the personal finance website Hack Your Wealth.
  </p>
  
  <p>
    Altogether, Chen estimates he spends 55 to 60 hours a week working on his
    day job and another 15 to 25 hours a week on side hustles. That means
    getting enough sleep and having a social life sometimes end up on the back
    burner.
  </p>
  
  <p>
    Chen said it’s important to set boundaries with yourself and others about
    how far you’re willing to go to succeed if you’re trying to have a full-time
    job and side hustle.
  </p>
  
  <p>
    “That will make it easier to have conversations with family members and
    friends in a way that makes you feel less guilty,” he said.
  </p>
  
  
  
  <h3>3. Have a schedule</h3>
  <p><img alt="Have a schedule" data-original-height="661" data-original-width="1024" src="https://1.bp.blogspot.com/-YXy8j5KpEtA/X9R6mwRdgYI/AAAAAAAAGIc/cg_GZtGVBYcahASL7yCLe_UsoCh71t2AgCLcBGAsYHQ/s16000/3.-have-a-schedule.jpg">
  </p>
  
  <p>
    A routine is crucial for keeping up with a side gig while working full time,
    said Mayuri Kashyap, a full-time human resources consultant who also runs
    the travel blog To Someplace New.
  </p>
  
  <p>
    “Setting up a weekly and monthly schedule helps me stay on track,” Kashyap
    said.
  </p>
  
  <p>
    That means using her daily two-hour commute on public transportation to
    tackle small tasks like posting to social media or responding to emails via
    her smartphone. She also wakes up early to dedicate an hour to her side
    hustle before work.
  </p>
  
  <p>
    Having a set schedule for working on your side gig can help with maximizing
    your productivity. If you don’t follow a schedule, try keeping a time log
    for a week to see where your time goes each day. Then, figure out where you
    can carve out extra time for your hustle.
  </p>
  
  
  
  <h3>4. Take advantage of small pockets of time</h3>
  <p><img alt="Take advantage of small pockets of time" data-original-height="661" data-original-width="1024" src="https://1.bp.blogspot.com/-P8YFXHOD10w/X9R6vhBBiMI/AAAAAAAAGIk/nj1oc_nG2uM46OYk_91R9X8usMyAvzwDQCLcBGAsYHQ/s16000/4.-take-advantage-of-small-.jpg">
  </p>
  
  <p>
    One misconception about how to balance your full-time job with a side hustle
    is thinking you can only work on either one in big blocks of time. Albert
    Lee, a doctor who works 50 to 55 hours a week and also runs the home
    improvement website Home Living Lab, said how you use small moments of
    downtime can be just as important.
  </p>
  
  <p>
    For example, instead of spending your entire lunch hour on social media, use
    that time to work on your hustle.
  </p>
  
  <p>
    “These little snippets of time may seem insignificant, but they do add up,”
    Lee said. “I personally find that if I make full use of them, I can squeeze
    in about 45 to 60 minutes of good solid work during my day job.”
  </p>
  
  <p>
    Again, this is where keeping a time log can help you find those small
    opportunities in your day. And once you find them, use the next tip to make
    the most of them.
  </p>
  
  
  
  <h3>5. Eliminate distractions</h3>
  <p><img alt="Eliminate distractions" data-original-height="661" data-original-width="1024" src="https://1.bp.blogspot.com/-lBmbcWvHxH4/X9R63zQN78I/AAAAAAAAGIo/mtm4HBs11GALfg1ioHSaaeI1YiNmnV3jwCLcBGAsYHQ/s16000/5.-eliminate-distractions.jpg">
  </p>
  
  <p>
    One of the biggest struggles with how to balance your full-time job with a
    side hustle is making the most of the time you have available for your side
    gig.
  </p>
  
  <p>
    Brendan Heffernan, owner of Dunk or Three, has a 45-hour full-time job
    working with high school students and a lucrative part-time freelance
    writing and editing gig. Since he’s also a parent, he maximizes his side
    hustle hours by eliminating distractions as much as possible.
  </p>
  
  <p>
    “When you have time set aside to work, you better be working that entire
    time and not perusing the internet or watching YouTube videos,” Heffernan
    said.
  </p>
  
  <p>
    Whether you side hustle before work or after your regular job, make a point
    of cutting out distractions. Leave your phone in another room, turn off the
    TV, and consider using a special web browser extension like StayFocusd to
    block websites or apps that could lead you off task.
  </p>
  
  
  
  <h3>6. Take care of your health</h3>
  <p><img alt="Take care of your health" data-original-height="661" data-original-width="1024" src="https://1.bp.blogspot.com/-jarTusHpmdw/X9R6_d4TXWI/AAAAAAAAGIw/V2p8Am7pbxc7LuWeGTUwAlKtXAAlTHyagCLcBGAsYHQ/s16000/6.-take-care-of-your-health.jpg">
  </p>
  
  <p>
    When balancing a side gig while working full time, it’s easy to neglect
    basic self-care. But that’s a guaranteed way to end up burned out. You have
    to make health a priority so you have enough energy to work on both.
  </p>
  
  <p>
    Chris Panteli spends 50 hours a week running his restaurant while also
    working on his personal finance blog, Life Upswing. After being diagnosed
    with Type 1 diabetes at age 32, he’s realized the importance of good
    self-care when keeping up with a side hustle and full-time job.
  </p>
  
  <p>
    “My key to balancing both is getting a good night’s sleep and making sure
    the quality of sleep is good as well,” Panteli said.
  </p>
  
  <p>
    It’s tempting to work long hours to grow your side hustle, but consider what
    the trade-off may be health-wise. If you’re tired, that can hurt your
    productivity at work, potentially endangering your day job. And once you get
    home from work, you may have zero energy to focus on your hustle.
  </p>
  
  
  
  <h3>7. Put side hustle tasks on autopilot</h3>
  <p><img alt="Put side hustle tasks on autopilot" data-original-height="661" data-original-width="1024" src="https://1.bp.blogspot.com/-BiubaY806D4/X9R7JxsecnI/AAAAAAAAGI4/dZTaRtlOv3UISiMuJXOZ6QHFN1z_cbR3wCLcBGAsYHQ/s16000/7.-put-side-hustle-tasks-on.jpg">
  </p>
  
  <p>
    As an entrepreneur with a full-time job, it’s impossible to do everything by
    yourself. That’s where automation comes in.
  </p>
  
  <p>
    Jonathan Sanchez works full time as a software engineer while running a side
    hustle as a real estate investor and founder of ParentPortfolio. He uses
    schedulers to keep up with social media posts and email campaigns that drive
    traffic to his website.
  </p>
  
  <p>
    If your side hustle is website or blog-based, you could try using similar
    automation tools or so that you don’t have to be as hands-on with your
    business. You can also use automation to manage other parts of your life so
    you have more time to focus on your side gig.
  </p>
  
  <p>
    For instance, you could set up automatic bill payments so you don’t have to
    worry about due dates. Budgeting apps can help with tracking your spending
    automatically, taking the hassle out of doing it manually.
  </p>
  
  
  
  <h3>8. Remember your why</h3>
  <p><img alt="Remember your why" data-original-height="661" data-original-width="1024" src="https://1.bp.blogspot.com/-q8Ft99nayP4/X9R7RrjgdvI/AAAAAAAAGJA/eBsR4nrfLy0mFYyHgH5xpcSSwEh6MexjwCLcBGAsYHQ/s16000/8.-remember-your-why.jpg">
  </p>
  
  <p>
    Working full time with a side hustle can be demanding, to say the least.
    It’s important to have a clear reason for what you’re doing from day one.
  </p>
  
  <p>
    Lucy Reyes is a supply chain specialist and mom who side hustles with
    multiple blogs, including her main site, Cheers to Life Blogging. She said
    staying focused on why you started your side hustle is what will keep you
    motivated to continue working on it when you’re exhausted or feeling stuck.
  </p>
  
  <p>
    If you’ve lost sight of your why, take time to remind yourself what your
    goals for side hustling were when you started. Whether it’s getting out of
    debt, creating financial security for your family, or being able to walk
    away from your day job one day, use your goals as an anchor for staying
    grounded and focused.
  </p>
  
  
</div></div>]]>
            </description>
            <link>https://career.dearjulius.com/2020/12/balance-your-full-time-job-with-side-hustle.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396731</guid>
            <pubDate>Sat, 12 Dec 2020 08:26:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why self-learning is important as a developer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25396692">thread link</a>) | @kitsao
<br/>
December 12, 2020 | https://tipjarr.net/post/Why-self-learning-is-important-for-developers | <a href="https://web.archive.org/web/*/https://tipjarr.net/post/Why-self-learning-is-important-for-developers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img alt="self learning" data-srcset="https://images.unsplash.com/photo-1521714161819-15534968fc5f?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1350&amp;q=80"></p><h2>Let's start by defining what self learning is in General</h2><p>In broad context â€œSelf study/learning is a process by which individuals take the initiative, with or without the assistance of others, in diagnosing their learning needs, formulating learning goals, identifying human and material resources for learning, and evaluating learning outcomesâ€�. <a href="https://medium.com/wondr-blog/self-learning-why-its-essential-for-us-in-the-21st-century-9e9729abc4b8">what is self learning</a></p><p>In plain terms Self-studying is a learning method where you get to direct your own studying without direct supervision</p><h2>Why self learning is  important</h2><p>As a developer or an aspiring one you will quickly find out that you constantly need to learn new skills and keep up with the trend, also gain more knowledge that you can use as an edge for future opportunities. Learning  also helps you as a developer to understand deeply some of the aspects of languages and technologies you have been using for years and that you hadn't realized yet.</p><p>As a developer whose gone through both the selft taught method, college and recently bootcamp i higly suggest taking the self learning path </p><p>lets have a look at why thats important</p><ul><li><p><strong>It is a Stress-Free Process</strong></p><p>  There is no pressure to learn the required content within a certain time, You choose what you want to learn when you want to learn, and how you want to learn. The overall outcome is an internalization of content and this is why self-taught developers tend to internalize 
  and become good at what they learn, more than those who take part in directed learning i.e college and bootcamps</p></li><li><p><strong>Self teaching drives Curiosity</strong></p><p>  A <a href="https://www.sciencedaily.com/releases/2011/10/111027150211.htm">neurological study</a> has shown that curiosity makes our brains more receptive for learning, and that as we learn, we enjoy the sensation of learning. It's no secret that curiosity makes learning more effective and enjoyable.
  This, therefore, means that you will be motivated to learn and you will get to acquire much more knowledge when the drive comes from within than from outside sources. It becomes an adventure and your capabilities are expanded each time you successfully learn something new.</p></li><li><p><strong>You Get to Choose What to learn and how you learn it</strong></p><p>  Weather its YouTube tutorials, Udemy courses, books, or  other modes of learning that are at your disposal when you decide to learn. With all these modes of learning within your reach, you get to choose one that suits you best and one that you find most engaging. You donâ€™t have to stick to one mode of learning just because it is what is available.  This makes it easy for you to understand certain topics and concepts Because you get to learn at your own Pace</p></li><li><p><strong>Its fun and Meaningful</strong></p><p>  From my expirience i found out that teaching yourself a certain concept can be really fun  because  you have a clear purpose of why you are learning and the information gained is often relevant, making it meaningful. Additionally, you are inclined to search deeper information about a topic since you are not just learning for the sake of learning. Learning now has a purpose and is enjoyable, leading to good and meaningful results.</p></li></ul><h2>Self Learning can be difficult and challenging at times</h2><p><img alt="exhausted person" data-srcset="https://images.unsplash.com/photo-1605827211207-194dc6ec319b?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1563&amp;q=80"></p><p>In my expirience teaching yourself anything can be difficult,challenging, draining and quite a lonely</p><p> Self-learning requires lots of discipline and  can be challenging at times. If you are the person who gets distracted easily you may have a hard time teaching yourself, but i believe with the right determination and discipline almost anyone can Learn anything by themselves
 You have to be ready to learn and take on challenges by yourself.</p><p> Dont forget to always keep yourself motivated with the right reason of why you started Learning in the first place.  When your learning make your goals clear, you will be able to evaluate your progress and whether you have gained any knowledge and this sets the stage for a fruitful learning process.
 The beauty of self-driven learning is that you are not limited to a specific way of learning. The availability of different tools also gives you the chance to learn the same subject from different angles, which makes it easier to grasp the main subject matter.</p><p>If you are just starting out You can find resources here that will help you learn :</p><p>"When youâ€™re just getting started exploring the world of tech, having the right programming tools for beginners makes a world of difference. You want coding resources that make it easy and fun to learn the skills you wantâ€”not dry, incomprehensible teaching that you can barely wrap your head around."
 <a href="https://learntocodewith.me/resources/coding-tools/">Top Coding Resources and Tools for Beginners (+ Beyond)</a></p><h2>Conclusion</h2><p>If you are a developer or you are in the process of becoming one, you'll  certainly  notice that you almost always have to 
update or refine your skills to keep up with the changes developing the ability to teach yourself  new skills without direct supervision at your own pace 
with your own methods of choosing
I believe is a key advantage to succeed in this field in the long run.</p></div></div>]]>
            </description>
            <link>https://tipjarr.net/post/Why-self-learning-is-important-for-developers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396692</guid>
            <pubDate>Sat, 12 Dec 2020 08:19:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a beautiful purple theme for Jupyter Notebooks]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25396553">thread link</a>) | @DataCrayon
<br/>
December 11, 2020 | https://datacrayon.com/posts/tools/jupyter/theme-purple-please-for-jupyter-lab/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/tools/jupyter/theme-purple-please-for-jupyter-lab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
    <div>
        <!--Body content-->
        
        
<article itemscope="itemscope" itemtype="http://schema.org/Article"><div>
    
        <div>
            <div>
            <div>
                <div>
                <div>
                    <h2>Get the Books</h2>
                    <p>
                    Enjoying these notebooks and want to support the work? Check out the practical books on Data Science, Visualisation, and Evolutionary Algorithms.
                    </p>
                    <p><a href="https://datacrayon.com/shop/product/data-is-beautiful/">Get the books</a>
                </p></div>
                <p><img src="https://datacrayon.com/images/datacrayon/shop/covertops.jpg">
</p>
                </div>
            </div>
            </div>
        </div>
    
    
    <header>

        
        

    </header><div itemprop="articleBody text">
    <!--% if post.meta('has_toc'):-->
    

        

        
            

            
<div>

<div>

<div>
<div>
<h2 id="Installation-through-Jupyter-Lab">Installation through Jupyter Lab<a href="#Installation-through-Jupyter-Lab">¶</a>
</h2>
<p>You can install it through the Jupyter Lab Extension Manager UI, or with the following command:</p>
<p><code>jupyter labextension install @shahinrostami/theme-purple-please</code></p>
<h2 id="GitHub-Repository">GitHub Repository<a href="#GitHub-Repository">¶</a>
</h2>
<p>You can navigate and download the source code at <a href="https://github.com/shahinrostami/theme-purple-please">https://github.com/shahinrostami/theme-purple-please</a>.</p>

</div>
</div>
</div>

</div>




                    <div id="support-this-work-bottom">
                                    <p>Support this work</p>
                                    <p>
        You can support this work by <a href="https://datacrayon.com/shop/">getting the e-books</a>. This notebook will always be available for free in its online format.
        </p>
                                </div>
                            </div>
                            <!-- Modal -->

                            <!-- Modal -->
</div>
                    </article><!--End of body content-->
</div>
</div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/tools/jupyter/theme-purple-please-for-jupyter-lab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396553</guid>
            <pubDate>Sat, 12 Dec 2020 07:52:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The iPad Pro is not a development machine, but it so easily could be]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25396551">thread link</a>) | @headmelted
<br/>
December 11, 2020 | https://headmelted.com/no-the-ipad-pro-is-not-a-development-machine-but-it-so-easily-could-be-41f24b56e6cb | <a href="https://web.archive.org/web/*/https://headmelted.com/no-the-ipad-pro-is-not-a-development-machine-but-it-so-easily-could-be-41f24b56e6cb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3970/1*vdUAbPrY38373UHaK05SBA.png" width="1985" height="1120" srcset="https://miro.medium.com/max/552/1*vdUAbPrY38373UHaK05SBA.png 276w, https://miro.medium.com/max/1104/1*vdUAbPrY38373UHaK05SBA.png 552w, https://miro.medium.com/max/1280/1*vdUAbPrY38373UHaK05SBA.png 640w, https://miro.medium.com/max/1400/1*vdUAbPrY38373UHaK05SBA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*vdUAbPrY38373UHaK05SBA.png?q=20"></p></div></div></div><figcaption>An iPad Pro with the Logitech Folio Touch keyboard. So close to replacing my laptop, but yet so far.</figcaption></figure><div><div><div><div><p><a href="https://medium.com/@headmelted?source=post_page-----41f24b56e6cb--------------------------------" rel="noopener"><img alt="Jay Rodgers" src="https://miro.medium.com/fit/c/96/96/1*8LYNs4YhAT9M15slEmpZEw.png" width="48" height="48"></a></p></div></div></div></div><p id="3ed6">Anyone that’s been following my blog for any amount of time will be familiar with my writings about leveraging the devices people already have (<em>or can easily and inexpensively get access to</em>) in order to learn to code.</p><p id="e408">The Raspberry Pi is an incredibly versatile device in this regard, as it can be had for less than $30 used in most parts of the world, and provides more than enough power for low-end computing tasks and getting started with development.</p><p id="e4a4">I’ve also written extensively about leveraging Chromebooks as cheap development laptops with long battery life via workarounds and shell scripts, most of which is (thankfully) no longer necessary in the most recent versions of Chrome OS thanks to Linux application support.</p><p id="74aa">That said, I’ve been asked a bunch of times about whether or not it would be possible to run a tool like Visual Studio Code, or indeed any common development tools, on an iPad. The answer is a frustrating.. <strong><em>sort of</em></strong>.</p><p id="253f">iPads, which is to say <em>any</em> iPad made in the last three years (<em>yes, even the base models</em>) has more than enough power to run development tools and compile most codebases you would care to. The more recent iPad Pro models even give modern Core i9 laptops a run for their money in some metrics.</p><p id="0892">Why then do we not see development tools on the iPad? Or at least, why do we not see more of the development tools we’re used to seeing on the platform. The reason, unfortunately, is iPadOS.</p><p id="742a">Where development machines typically run what we’ve come to think of as general purpose operating systems (the big three of which being Windows, macOS and Linux), iPads are significantly different.</p><p id="5d09">iPadOS applications are strictly sandboxed, meaning that these devices (<em>much like iPhones</em>) are prevented from executing arbitrary code. There are genuinely good reasons for this. Having this kind of strictly policed environment prevents a great many security threats that have plagued less strongly opinionated platforms for years. Unfortunately it’s also for this exact reason that the iPad is not, and cannot in it’s current form, make a truly useful or pleasant development machine.</p><p id="b7bc">There are workarounds of course. Some folks have had success with buying an additional device (<em>usually a Raspberry Pi</em>) and connecting to that to edit and build their code. Others are quite happy to connect to a remote server and edit their code in Safari. These are solutions that may work for some people, but fundamentally you aren’t able to just take an iPad and start coding freely without another device, because of the sandbox.</p><blockquote><p id="da00">Even if you get Visual Studio Code, or IDEA, or a new iPadOS-specific native editor that you’ve developed running on the iPad, you still have no way to run arbitrary code.</p></blockquote><p id="1b82">I’ve looked at how one might solve this problem within the confines of the iPad’s security policy. I’ve looked at what might be involved in running Visual Studio Code directly in a WKWebView panel (<em>and pursued this enough to be satisfied that it can definitely be done — although several Electron calls would need to be re-implemented</em>). Unfortunately, this line of thinking always falls down in the same place. Even if you get Visual Studio Code, or IDEA, or a new iPadOS-specific native editor that you’ve developed running on the iPad, you still have no way to run arbitrary code.</p><p id="0c7e">There are some tools available that come <em>so close</em> to realizing this goal. <a href="http://omz-software.com/pythonista/" rel="noopener">Pythonista</a> is an example of a tool that pushes right up to the edge of the iPad’s restrictions — and allows for writing and debugging Python code within the application’s folder and with the understanding that external tools and native code can’t be executed.</p><p id="4a1f">But for arbitrarily and freely developing code in a language of the user’s choice? No dice.</p><p id="5bd6">Apple have their reasons for keeping the sandbox as it is. They’re not about to roll back these policies to appease a relatively small subset of their users — but I’m also not convinced they have to.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1930/1*sxW1lWdRgpOarSmjIwZAmA.png" width="965" height="452" srcset="https://miro.medium.com/max/552/1*sxW1lWdRgpOarSmjIwZAmA.png 276w, https://miro.medium.com/max/1104/1*sxW1lWdRgpOarSmjIwZAmA.png 552w, https://miro.medium.com/max/1280/1*sxW1lWdRgpOarSmjIwZAmA.png 640w, https://miro.medium.com/max/1400/1*sxW1lWdRgpOarSmjIwZAmA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*sxW1lWdRgpOarSmjIwZAmA.png?q=20"></p></div></div></div><figcaption>When life gives you sandboxes, build sandcastles! (Image © Courtney Hall)</figcaption></figure><p id="1f29">If iPadOS were to include a Terminal application for developers, the user could be allowed to execute arbitrary code <strong><em>that is still sandboxed and subject to the Terminal application’s own granted permissions. </em></strong>In so doing, the security stack is largely preserved, in that the Terminal application cannot access the filesystem outside of its own directory, but most of the roadblocks for developers go away.</p><p id="e7b4">While this would inevitably raise concerns, macOS’ Terminal application deploys this same principle to good effect already. The code executed inside Terminal on macOS still requires permissions to be granted to the Terminal application by the user, but any commands subsequently executed by tools that Terminal runs are treated as coming directly from Terminal by the permission system.</p><p id="e1f8">Providing this feature wouldn’t enable the free side-loading of arbitrary applications that larger compromises on the security system would entail, and there isn’t a risk to the App Store of people freely distributing applications for use via the Terminal app as this code wouldn’t be in the form of iPhone applications that exist with an interface (<em>or even in their own application context</em>) at all.</p><p id="eedf">All this would allow is the compiling and running of limited code in a command-line environment that an iPad application could interact with. That’s all most simple code editors really need to be for most users.</p><p id="e9a2">The outcome of this would be enabling developers, and those who want to be, to use their device for learning new skills and <strong><em>helping people do their jobs with their own devices</em></strong>, which is kind of what’s implied when you’re selling many of these devices with the word “Pro” printed in large letters on the box.</p></div></div></section></div>]]>
            </description>
            <link>https://headmelted.com/no-the-ipad-pro-is-not-a-development-machine-but-it-so-easily-could-be-41f24b56e6cb</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396551</guid>
            <pubDate>Sat, 12 Dec 2020 07:52:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning Interview Questions: Theory Edition]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25396283">thread link</a>) | @mise1
<br/>
December 11, 2020 | https://www.blog.confetti.ai/post/26-top-machine-learning-interview-questions-and-answers-theory | <a href="https://web.archive.org/web/*/https://www.blog.confetti.ai/post/26-top-machine-learning-interview-questions-and-answers-theory">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.7.1"><div dir="ltr"><div><div id="viewer-2q0um"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.blog.confetti.ai/post/26-top-machine-learning-interview-questions-and-answers-theory" data-pin-media="https://static.wixstatic.com/media/4feadc_a0edd772aac842d0ac0daa74490322af~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/4feadc_a0edd772aac842d0ac0daa74490322af~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-6anpj"><span>If you're in the market for a machine learning job, you'll definitely have to go through technical screens. That means your interviewers will often spend some time evaluating your knowledge of core machine learning theory concepts.</span></p><p id="viewer-9hsn1"><span>In this post, we will describe 26 essential machine learning interview questions and provide their answers. Here we will focus on the machine learning theory you should definitely know for acing your machine learning interviews. In a later post, we will provide additional machine learning questions focusing on systems and engineering concepts.</span></p><p id="viewer-fjlth"><span>We can <strong>practically guarantee</strong> that some flavor of at least one of these questions will be asked at your next machine learning interview. </span></p><p id="viewer-a50r0"><span><em>As a heads-up, we have an additional expert-curated collection of over 300 data science and machine learning interview questions covering topics like deep learning, SQL, MLOps, Pandas, and more for full-stack data science and machine learning engineering roles which can </em><a href="https://www.confetti.ai/questions" target="_blank" rel="noopener"><em><u>be found here</u></em></a><em>.</em> </span></p><p id="viewer-5gdmt"><span>With that, let's get started!</span></p><h3 id="viewer-807c3"><span><span><strong>1. What is the difference between supervised learning and unsupervised learning?</strong></span></span></h3><p id="viewer-dl0tb"><span><span>The fundamental difference between supervised and unsupervised learning is that supervised model algorithms use training data with labelled outputs while unsupervised learning does not use data with labels. In other words, supervised learning typically takes a set of labelled (X, Y) pairs and seeks to learn a function mapping from X to Y. Meanwhile unsupervised learning typically involves learning structure from data through techniques like clustering. </span></span></p><h3 id="viewer-flpdp"><span><span><strong>2. Give a few examples of commonly used supervised learning algorithms.</strong></span></span></h3><p id="viewer-baef1"><span><span>Commonly used algorithms in supervised learning include Naive Bayes, k-nearest neighbors classification, decision trees, random forests, and support vector machines. Neural networks are also very often used for supervised learning. </span></span></p><h3 id="viewer-3v5oi"><span><span><strong>3. Explain the difference between classification and regression.</strong></span></span></h3><p id="viewer-4bscr"><span><span>Classification refers to supervised learning algorithms that use discrete output labels whereas regression algorithms use continuous output labels. Hence when learning a model from (X, Y) pairs, in classification, Y takes on values like [0, 1, 2, 3, ...] whereas in regression Y may take on any non-integral numbers like 1.012, -3.4221, etc. </span></span></p><h3 id="viewer-3scv2"><span><span><strong>4. What is a commonly used linear regression cost function?</strong></span></span></h3><p id="viewer-7hq3b"><span><span>One of the go-to cost functions for evaluating linear regression models is least-squares. It is commonly written as a residual sum of squares between the gold labels and predicted labels of a model's output on a dataset.</span></span></p><h3 id="viewer-4on34"><span><span><strong>5. Describe the k-nearest neighbors algorithm.</strong></span></span></h3><p id="viewer-amb0t"><span><span>In k-nearest neighbors, the label for a point is determined by taking the average (in the case of regression) or majority (in the case of classification) label of the k nearest points to our point-of-interest. For example, in the image below if we were performing k-nearest neighbors with k=3, we would classify <strong>P</strong> as </span><span>green</span><span> because its nearest 3 neighbors are all green. </span></span></p><div id="viewer-745rd"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.blog.confetti.ai/post/26-top-machine-learning-interview-questions-and-answers-theory" data-pin-media="https://static.wixstatic.com/media/4feadc_1c8be1d4881c4e27a8be49935f01ef29~mv2.png/v1/fit/w_1000%2Ch_800%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/4feadc_1c8be1d4881c4e27a8be49935f01ef29~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><h3 id="viewer-f0blo"><span><span><strong>6. What is a key assumption in the Naive Bayes algorithm?</strong></span></span></h3><p id="viewer-2q3go"><span><span>Naive Bayes is a frequently used algorithm for classification that assumes that the input features are conditionally independent given the output label. In other words, if we have input features (x1, x2, ..., xn) and output Y, then Naive Bayes allows us to say that p(Y, x1, x2, ..., xn) is proportional to p(Y)*p(x1|Y)*p(x2|Y)*...*p(xn|Y). In theory this is a pretty strong independence assumption, but in practice it makes certain classification problems tractable and still produces fairly performant models.</span></span></p><h3 id="viewer-d77v5"><span><span><strong>7. Describe how a decision tree is learned.</strong></span></span></h3><p id="viewer-8pj4b"><span><span>Decision trees are built in a top-down fashion by splitting a set of observations according to a certain feature and feature value. This recursive partitioning is done greedily whereby the feature and value split are determined by which split will enable the largest reduction in some error metrics such as </span><a href="https://victorzhou.com/blog/gini-impurity/" target="_blank" rel="noopener"><span><u>Gini impurity</u></span></a><span> in the dataset.</span></span></p><h3 id="viewer-f9nsa"><span><span><strong>8. What are the differences between k-nearest neighbors and k-means clustering?</strong></span></span></h3><p id="viewer-9r0o1"><span><span>K-nearest neighbors is a supervised learning algorithm whereas k-means clustering is an unsupervised algorithm. They work very differently: k-nearest neighbors uses the k closest neighbors to a given point with an unknown label to calculate its label. This is often done via majority vote for classification and averaging for regression. K-means clustering works by splitting a dataset into k clusters by minimizing a measure of "spread" in the data known as </span><a href="https://avidml.wordpress.com/2016/10/29/easily-understand-k-means-clustering/" target="_blank" rel="noopener"><span><u>distortion</u></span></a><span>. </span></span></p><h3 id="viewer-2vdqs"><span><span><strong>9. In a K-Nearest Neighbors classifier, what effect does picking a smaller number of neighbors have for classification?</strong></span></span></h3><p id="viewer-c61u3"><span><span>Reducing the the number of neighbors in k-nearest neighbors classification tends to make the model's label very susceptible to the closest neighbors, leading to a very "jagged" decision boundary. This tends to make the model overfit on its training data. See the image below from </span><a href="https://stats.stackexchange.com/questions/367010/training-error-in-knn-classifier-when-k-1/367015" target="_blank" rel="noopener"><span><u>here</u></span></a><span>.</span></span></p><div id="viewer-e3qst"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.blog.confetti.ai/post/26-top-machine-learning-interview-questions-and-answers-theory" data-pin-media="https://static.wixstatic.com/media/4feadc_268c81a935ec45ab8da2f3f55c618657~mv2.png/v1/fit/w_476%2Ch_395%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/4feadc_268c81a935ec45ab8da2f3f55c618657~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><h3 id="viewer-5gutq"><span><span><strong>10. Describe how support vector machines work.</strong></span></span></h3><p id="viewer-crhpr"><span><span>At their core, support vector machines are max-margin classifiers that seek to maximize the minimum distance of all points to some linear separator. Ultimately they strive to find linear separators of data even if that means projecting data into some higher-dimensional space where that data may be linearly separable (even if it isn't in a lower-dimensional space).</span></span></p><h3 id="viewer-51o25"><span><span><strong>11. What are the differences between L1​ and L2​ regularization?</strong></span></span></h3><p id="viewer-9m2cq"><span><span>L1 and L2 are both forms of regularization but L1 includes an absolute value of the weights term while L2​ uses a squared magnitude term. In practice, L1 tends to induce sparsity in the model weights which L2 does not really do. </span></span></p><div id="viewer-4hcjq"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.blog.confetti.ai/post/26-top-machine-learning-interview-questions-and-answers-theory" data-pin-media="https://static.wixstatic.com/media/4feadc_f3b58f39621544298862ce8b8a44655e~mv2.png/v1/fit/w_980%2Ch_380%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/4feadc_f3b58f39621544298862ce8b8a44655e~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><h3 id="viewer-1caeb"><span><span><strong>12. Explain the bias-variance tradeoff.</strong></span></span></h3><p id="viewer-5dkbt"><span><span>The bias-variance tradeoff is the process of </span>simultaneously trying to minimize two sources of error (bias and variance) during supervised learning which determine the extent to which a model can generalize from a training set to an unseen test set. </span></p><h3 id="viewer-1f03r"><span><span><strong>13. You have a model suffering from low bias and high variance. What does this mean?</strong></span></span></h3><p id="viewer-67vv3"><span><span>Low bias and high variance usually means the model is overfitting. If we have more features than datapoints, this could easily lead to overfitting. Typically this behavior may require us to add some form of regularization to the model objective that we are optimizing.</span></span></p><h3 id="viewer-3f7j9"><span><span><strong>14. Why is it not recommended to assess a model's quality using only its train error?</strong></span></span></h3><p id="viewer-7f617"><span><span>When building models we are always more interested in generalization error, or how the model performs on data it hasn't seen during training (i.e. the unseen test set). Therefore if we only focus on training error and we see for example a very low training error, we could draw incorrect conclusions about the actual model quality. That being said, training error is a reasonable proxy during model development for a model's performance since it is generally assumed that train data is sampled from the same distribution as test data. Training error typically can be computed relatively easily during model training.</span></span></p><h3 id="viewer-ev8qm"><span><span><strong>15. What are commonly-used forms of cross-validation?</strong></span></span></h3><p id="viewer-cfdda"><span><span>K-fold validation and leave-one-out-validation are very commonly used forms of cross-validation, with the latter being especially useful for very small datasets. In fact, leave-one-out can actually be considered a special case of k-fold cross validation with k being equal to the number of points in the dataset. In k-fold validation, the data is split into k different folds and then for each fold we execute a separate training run where the model is trained on all folds but the fold in interest and then evaluated on the held-out fold. The model's performance is then aggregated as an average across all the k-fold runs. </span></span></p><div id="viewer-1j56j"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.blog.confetti.ai/post/26-top-machine-learning-interview-questions-and-answers-theory" data-pin-media="https://static.wixstatic.com/media/4feadc_8555fb21c28441f3b35c6e6a56f26469~mv2.png/v1/fit/w_1000%2Ch_868%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/4feadc_8555fb21c28441f3b35c6e6a56f26469~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><h3 id="viewer-mfcn"><span><span><strong>16. Define principal components analysis.</strong></span></span></h3><p id="viewer-b0924"><span><span>Principal components analysis (PCA) is a dimensionality reduction technique for data whereby we search for the axes along which data variance is maximized. It is commonly-used as a preprocessing technique or for visualizing high-dimensional data in 2 or 3 dimensions.</span></span></p><h3 id="viewer-1eu7"><span><span><strong>17. What are examples of dimensionality reduction?</strong></span></span></h3><p id="viewer-cctjf"><span><span>A few examples of dimensionality reduction include principal components analysis, non-negative matrix factorization, and autoencoders. All of these often take high-dimensional data and reduce them to lower dimensional subspace for reasons including computational considerations or removing redundancy/repetition in the data.</span></span></p><h3 id="viewer-9e8j3"><span><span><strong>18. What is model bagging?</strong></span></span></h3><p id="viewer-enhsd"><span><span>Bagging (or <strong>b</strong>ootstrap <strong>agg</strong>regat<strong>ing</strong>) is an ensembling technique in which we create a number of bootstrapped datasets by sampling with replacement from a larger dataset. We then train models on each of these smaller datasets and combine their outputs to form the larger model output.</span></span></p><h3 id="viewer-5hj37"><span><span><strong>19. What are gradient boosted trees?</strong></span></span></h3><p id="viewer-crcdr"><span><span>Gradient boosted trees are a machine learning technique that ensembles weak-performing decision trees (weak learners) via a learned and weighted function of the trees. Gradient boosted trees are built in an interative fashion by progressively adding new learners whose weights are chosen by optimizing a differentiable objective function. </span></span></p><h3 id="viewer-eh4no"><span><span><strong>20. What is an F1​ score?</strong></span></span></h3><p id="viewer-ako75"><span><span>The F1 metric computes the harmonic mean of the precision and recall of a model. This metric is often more useful when dealing with very imbalanced datasets in which a measure like accuracy may give misleading impressions about overall model performance. </span></span></p><h3 id="viewer-2j3te"><span><span><strong>21. You are doing a classification task where you achieve 95% accuracy. Why should you be wary of these results?</strong></span></span></h3><p id="viewer-9j5r7"><span><span>First off it is very difficult to assess how good a certain accuracy is without the context of the problem. If we are predicting whether someone will click an ad with 95% accuracy that could be really good, but if we have a 95% accuracy for whether or not someone will survive a certain daredevil stunt, that number may not be adequate. Metrics without relevant context really do not mean that much, so we should be careful about dealing with absolute number judgments. In general a fairly high accuracy could imply a label-imbalanced dataset, which may suggest an alternate metric such as F1 may be more appropriate and worth computing.</span></span></p><h3 id="viewer-5i49h"><span><span><strong>22. …</strong></span></span></h3></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.blog.confetti.ai/post/26-top-machine-learning-interview-questions-and-answers-theory">https://www.blog.confetti.ai/post/26-top-machine-learning-interview-questions-and-answers-theory</a></em></p>]]>
            </description>
            <link>https://www.blog.confetti.ai/post/26-top-machine-learning-interview-questions-and-answers-theory</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396283</guid>
            <pubDate>Sat, 12 Dec 2020 06:58:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bit Manipulation with C++20]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25396151">thread link</a>) | @todsacerdoti
<br/>
December 11, 2020 | http://www.modernescpp.com/index.php/bit-manipulation-with-c-20 | <a href="https://web.archive.org/web/*/http://www.modernescpp.com/index.php/bit-manipulation-with-c-20">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blogContent">
				<p>This post concludes my presentation of library features in C++20. Today I write about the class<code> std::source_location</code> and a few functions for bit manipulation.</p>

<h2 id="h1-std-source-location"><img src="http://www.modernescpp.com/images/blog/Cpp20/BitManipulation/TimelineCpp20CoreLanguage2.png" alt="TimelineCpp20CoreLanguage2" width="650" height="265"><code>std::source_location</code></h2>
<p><code>std::source_location</code> represents information about the source code. This information includes file names, line numbers, and function names. The information is precious when you need information about the call site, such as for debugging, logging, or testing purposes. The class <code>std::source_location</code> is the better alternative for the predefined C++11 macros <code>__FILE__</code> and<code> __LINE__</code> and should, therefore, be used.</p>
<p>The following table shows the interface of <code>std::source_location</code>.</p>
<p><img src="http://www.modernescpp.com/images/blog/Cpp20/BitManipulation/sourceLocation.png" alt="sourceLocation" width="500" height="161"></p>
<p>The call <code>std::source_location::current()</code> creates a new source location object<code> src. sr</code>c represents the information of the call site. Now, no C++ compiler supports <code>std::source_location</code>. Consequently, the following program <code>sourceLocation.cpp</code> is from <a href="https://en.cppreference.com/w/cpp/utility/source_location">cppreference.com/source_location</a>.</p>

<!-- HTML generated using hilite.me -->
<div>
<pre><span>// sourceLocation.cpp</span>
<span>// from cppreference.com</span>

<span>#include &lt;iostream&gt;</span>
<span>#include &lt;string_view&gt;</span>
<span>#include &lt;source_location&gt;</span>
 
<span>void</span> <span>log</span>(std<span>::</span>string_view message,
         <span>const</span> std<span>::</span>source_location<span>&amp;</span> location <span>=</span> std<span>::</span>source_location<span>::</span>current())
{
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"info:"</span>
              <span>&lt;&lt;</span> location.file_name() <span>&lt;&lt;</span> <span>':'</span>
              <span>&lt;&lt;</span> location.line() <span>&lt;&lt;</span> <span>' '</span>
              <span>&lt;&lt;</span> message <span>&lt;&lt;</span> <span>'\n'</span>;
}
 
<span>int</span> <span>main</span>()
{
    log(<span>"Hello world!"</span>);  <span>// info:main.cpp:19 Hello world!</span>
}
</pre>
</div>

<p>The output of the program is part of its source code.</p>
<p>C++20 makes it quite comfortable to access or manipulate bits or bit sequences.</p>
<h2 id="h2-bit-manipulation">Bit Manipulation</h2>
<p>Thanks to the new type std::endian, you get the endianness of a scalar type.</p>
<h3 id="h2-1-endianness">Endianness</h3>
<ul>
<li>Endianness can be big-endian or little-endian. Big-endian means that the most significant byte comes first; little-endian means that the least significant byte comes first.</li>
<li>A scalar type is either an arithmetic type, an <code>enum</code>, a pointer, a member pointer, or a <code>std::nullptr_t</code>.</li>
</ul>
<p>The class <code>endian</code> provides the endianness of all scalar types:</p>
<div>
<pre><span>enum</span> <span>class</span> <span>endian</span>
{
    little <span>=</span> <span>/*implementation-defined*/</span>,
    big    <span>=</span> <span>/*implementation-defined*/</span>,
    native <span>=</span> <span>/*implementation-defined*/</span>
};
</pre>
</div>

<ul>
<li>If all scalar types are little-endian, <code>std::endian::native</code> is equal to <code>std::endian::little</code>.</li>
<li>If all scalar types are big-endian,<code> std::endian::native</code> is equal <code>to std::endian::big</code>.</li>
</ul>
<p>Even corner cases are supported:</p>
<ul>
<li>If all scalar types have <code>sizeof</code> 1 and therefore endianness does not matter; the values of the enumerators <code>std::endian::little</code>, <code>std::endian::big</code>, and <code>std::endian::native</code> are identical.</li>
<li>If the platform uses mixed endianness, <code>std::endian::native</code> is neither equal to <code>std::endian::big</code> nor <code>std::endian::little</code>.</li>
</ul>
<p>When I perform the following program <code>getEndianness.cpp</code> on an x86 architecture, I get the answer little-endian.</p>

<div>
<div>
<div>
<pre><span>// getEndianness.cpp</span>

<span>#include &lt;bit&gt;</span>
<span>#include &lt;iostream&gt;</span>

<span>int</span> <span>main</span>() {

    <span>if</span> constexpr (std<span>::</span>endian<span>::</span>native <span>==</span> std<span>::</span>endian<span>::</span>big) {
        std<span>::</span>cout <span>&lt;&lt;</span> <span>"big-endian"</span> <span>&lt;&lt;</span> <span>'\n'</span>;
    }
    <span>else</span> <span>if</span> constexpr (std<span>::</span>endian<span>::</span>native <span>==</span> std<span>::</span>endian<span>::</span>little) {
        std<span>::</span>cout <span>&lt;&lt;</span> <span>"little-endian"</span>  <span>&lt;&lt;</span> <span>'\n'</span>;      <span>// little-endian</span>
    }

}
</pre>
</div>

<p><a href="https://en.cppreference.com/w/cpp/language/if"><code>constexpr if</code></a> enables it to compile source code conditionally. This means that the compilation depends on the endianness of your architecture. If you want to know more about endianness, read the same-named <a href="https://en.wikipedia.org/wiki/Endianness">Wikipedia page</a>.</p>
</div>
</div>
<h3 id="h2-2-accessing-or-manipulating-bits-or-bit-sequences">Accessing or Manipulating Bits or Bit Sequences</h3>
<p>The following table gives you the first overview of all functions.</p>

<p><img src="http://www.modernescpp.com/images/blog/Cpp20/BitManipulation/bitInterface5.png" alt="bitInterface5" width="600" height="222"></p>

<p>The functions except of <code>std::bit_cast</code> require an unsigned integer type (<code>unsigned char, unsigned short, unsigned int, unsigned long,</code> or<code> unsigned long long</code>).</p>
<p>The program<code> bit.cpp</code> shows the usage of the functions.</p>

<!-- HTML generated using hilite.me -->
<div>
<pre><span>// bit.cpp</span>

<span>#include &lt;bit&gt;</span>
<span>#include &lt;bitset&gt;</span>
<span>#include &lt;iostream&gt;</span>
 
<span>int</span> <span>main</span>() {
    
    std<span>::</span><span>uint8_t</span> num<span>=</span> <span>0</span>b00110010;
    
    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>boolalpha;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::has_single_bit(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>has_single_bit(num) 
              <span>&lt;&lt;</span> <span>'\n'</span>;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::bit_ceil(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(std<span>::</span>bit_ceil(num)) 
              <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::bit_floor(0b00110010): "</span> 
              <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(std<span>::</span>bit_floor(num)) <span>&lt;&lt;</span> <span>'\n'</span>;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::bit_width(5u): "</span> <span>&lt;&lt;</span> std<span>::</span>bit_width(<span>5u</span>) <span>&lt;&lt;</span> <span>'\n'</span>;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::rotl(0b00110010, 2): "</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(std<span>::</span>rotl(num, <span>2</span>)) 
              <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::rotr(0b00110010, 2): "</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(std<span>::</span>rotr(num, <span>2</span>)) 
              <span>&lt;&lt;</span> <span>'\n'</span>;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::countl_zero(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>countl_zero(num) <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::countl_one(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>countl_one(num) <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::countr_zero(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>countr_zero(num) <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::countr_one(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>countr_one(num) <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"std::popcount(0b00110010): "</span> <span>&lt;&lt;</span> std<span>::</span>popcount(num) <span>&lt;&lt;</span> <span>'\n'</span>;
    
}
</pre>
</div>

<p>Here is the output of the program:</p>
<p><img src="http://www.modernescpp.com/images/blog/Cpp20/BitManipulation/bit2.png" alt="bit2" width="411" height="286"></p>
<p>The next program shows the application and the output of the functions&nbsp;<code>std::bit_floor</code>,<code> std::bit_ceil</code>, <code>std::bit_width</code>, and <code>std::bit_popcount</code> for the numbers 2 to 7.&nbsp;</p>
<!-- HTML generated using hilite.me -->
<div>
<pre><span>// bitFloorCeil.cpp</span>

<span>#include &lt;bit&gt;</span>
<span>#include &lt;bitset&gt;</span>
<span>#include &lt;iostream&gt;</span>
 
<span>int</span> <span>main</span>() {

    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>endl;
    
    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>boolalpha;
    
    <span>for</span> (<span>auto</span> i <span>=</span> <span>2u</span>; i <span>&lt;</span> <span>8u</span>; <span>++</span>i) {
         std<span>::</span>cout <span>&lt;&lt;</span> <span>"bit_floor("</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(i) <span>&lt;&lt;</span> <span>") = "</span> 
                   <span>&lt;&lt;</span> std<span>::</span>bit_floor(i) <span>&lt;&lt;</span> <span>'\n'</span>;

        std<span>::</span>cout <span>&lt;&lt;</span> <span>"bit_ceil("</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(i) <span>&lt;&lt;</span> <span>") = "</span> 
                  <span>&lt;&lt;</span> std<span>::</span>bit_ceil(i) <span>&lt;&lt;</span> <span>'\n'</span>;

        std<span>::</span>cout <span>&lt;&lt;</span> <span>"bit_width("</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(i) <span>&lt;&lt;</span> <span>") = "</span> 
                  <span>&lt;&lt;</span> std<span>::</span>bit_width(i) <span>&lt;&lt;</span> <span>'\n'</span>;
                  
        std<span>::</span>cout <span>&lt;&lt;</span> <span>"bit_popcount("</span> <span>&lt;&lt;</span> std<span>::</span>bitset<span>&lt;</span><span>8</span><span>&gt;</span>(i) <span>&lt;&lt;</span> <span>") = "</span> 
                  <span>&lt;&lt;</span> std<span>::</span>popcount(i) <span>&lt;&lt;</span> <span>'\n'</span>;   
        
        std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>endl;
    }
    
    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>endl;
    
}
</pre>
</div>

<p><img src="http://www.modernescpp.com/images/blog/Cpp20/BitManipulation/bitFloorCeil.PNG" alt="bitFloorCeil" width="250" height="644"></p>
<h2 id="h3-what-s-next">What's next?</h2>
<p>Additionally to coroutines, C++20 has much to offer for concurrency First, C++20 has new atomics. The new atomics exists for floating-point values and smart pointers. C++20 also enables waiting on atomics. To coordinate threads, semaphore, latches, and barriers come into play. Also, the <code>std::thread</code> was improved with <code>std::jthread</code>. The execution of a&nbsp;<code>std::jthread </code>can be interrupted and joins automatically in its destructor.<code><br></code></p>

<div>
	<p><strong>Thanks a lot to my <a href="https://www.patreon.com/rainer_grimm">Patreon Supporters</a></strong><strong>: Matt Braun, Roman Postanciuc, Tobias Zindl, Marko, </strong><span title="Emyr Williams"><strong>G Prvulovic, Reinhold Dröge, Abernitzke,</strong> </span><strong><span title="Emyr Williams">Frank Grimm</span></strong><span title="Emyr Williams"><strong>, Sakib, Broeserl, </strong></span><strong><span title="Emyr Williams">António Pina, Darshan Mody, Sergey Agafyin, <span data-tag="user-details-full-name">Андрей Бурмистров, Jake, GS, Lawton Shoemake, Animus24, Jozo Leko, John Breland, espkk, Wolfgang Gärtner</span></span><span title="Emyr Williams"><span><span></span></span></span>,&nbsp; Louis St-Amour, Stephan Roslen, Venkat Nandam, Jose Francisco, Douglas Tinkham, Kuchlong Kuchlong, Avi Kohn, Robert Blanch, Truels Wissneth, Kris Kafka, Mario Luoni, Neil Wang, Friedrich Huber, Sudhakar Balagurusamy, lennonli, and Pramod Tikare Muralidhara.</strong></p>

<p><strong>Thanks in particular to Jon Hess, Lakshman,</strong> <strong>Christian Wittenhorst, Sherhy Pyton, and Dendi Suhubdy<br></strong></p>

<h2>Seminars</h2>
<p>I'm happy to give online-seminars or face-to-face seminars world-wide. Please call me if you have any questions.</p>
<h3>Bookable (Online)</h3>
<h4>Deutsch</h4>
<ul>
<li><a href="https://www.modernescpp.de/index.php/c/2-c/29-embedded-programmierung-mit-modernem-c20201029102414">Embedded Programmierung mit modernem C++:&nbsp; </a>26.01.2021 - 28.01.2021</li>
</ul>
<h4>English</h4>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/2-c/31-c-20">C++20 - A Deep Insight: </a>Feb. 1. 2021 - Feb. 3. 2021 (16:00 - 20:00 UTC)</li>
</ul>
<h3>Standard Seminars&nbsp;</h3>
<p>Here is a compilation of my standard seminars. These seminars are only meant to give you a first orientation.</p>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/22">C++ - The Core Language</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/23">C++ - The Standard Library</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/23">C++ - Compact</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/18">C++11 and C++14</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/19">Concurrency with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/21">Design Patterns and Architecture Patterns with C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/17">Embedded Programming with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/17">Generic Programming (Templates) with C++</a></li>
</ul>
<h4>New</h4>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/16">Clean Code with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/25">C++20</a></li>
</ul>
<h3>Contact Me</h3>
<ul>
<li>Tel.: +49 7472 917441</li>
<li>Mobil: +49 152 31965939</li>
<li>Mail: <a href="http://www.modernescpp.com/%3Ca%20href="><span id="cloakf00a7481bb27e10074c195e7b90b6be2">This email address is being protected from spambots. You need JavaScript enabled to view it.</span></a></li>
<li>German Seminar Page: <a href="https://www.modernescpp.de/">www.ModernesCpp.de</a></li>
<li>English Seminar Page: <a href="http://www.modernescpp.net/">www.ModernesCpp.net</a></li>
</ul>
<h3>Modernes C++,</h3>
<p><img src="http://www.modernescpp.com/images/signatur/RainerGrimmSmall.png" alt="RainerGrimmSmall"></p></div>

			</div></div>]]>
            </description>
            <link>http://www.modernescpp.com/index.php/bit-manipulation-with-c-20</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396151</guid>
            <pubDate>Sat, 12 Dec 2020 06:34:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AirPods Max Pro vs. AirPods Pro Max]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25396054">thread link</a>) | @blymd
<br/>
December 11, 2020 | https://brianli.com/airpods-max-pro-vs-airpods-pro-max/ | <a href="https://web.archive.org/web/*/https://brianli.com/airpods-max-pro-vs-airpods-pro-max/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container"><main><article role="article"><div><p>A few days ago, I was contemplating the product name for the “next level up” from the AirPods Max – and I think there will be a higher-end model in the future because Apple will need a <a href="https://brianli.com/apple-airpods-pricing-strategy-2021/">more accessible (not $549)</a> over-the-ear headphone to saturate the market after the initial round of AirPods Max hype dies down.</p><p>The idea here is the current AirPods Max would get a price cut and become “the mainstream headphone”, and a more expensive model with the latest technologies would occupy the $549 (or higher) price point. The question is whether this new model would be named “AirPods Max Pro” or “AirPods Pro Max”. I’m leaning towards AirPods Pro Max, so let me explain why.</p><p>When I first started thinking about this question, the obvious answer was AirPods Max Pro. The reasoning behind this is simple. The current headphone-style product is named AirPods Max, so the “pro” version of it should be “AirPods Max + Pro”, or AirPods Max Pro. Logically speaking, this makes sense.</p><p>However, it quickly starts not making sense when you consider Apple already has an iPhone named “iPhone 12 Pro Max”. For me, the presence of two sets of descriptors (“Pro Max” and “Max Pro”) that basically mirror each other is a big branding no-no –&nbsp;maybe Apple thinks differently. Imagine a customer going to the Apple Store and saying, “Hi, I’d like to buy an iPhone Pro Max and a pair of AirPods Max Pro… oh wait I mean AirPods Pro Max and iPhone Max Pro… is that right?” See where I’m going with this?</p><p>In the recent past, Apple has established a fairly standardized naming scheme –&nbsp;just “Product Name”, or “Product Name followed by Pro, Max, mini, etc. –&nbsp;or some combination of these descriptors”. An example of the former is HomePod or iMac, and an example of the latter is Mac mini or iPhone 12 Pro Max.</p><p>With this in mind, it would make sense for a future upgraded version of AirPods Max to be called AirPods Max Pro –&nbsp;“AirPods Max” is the product name, and “Pro” is the descriptor in this case. This here is the root of the issue. Apple messed up with its planning and naming of the AirPods line, and now they’ve painted themselves into a corner where “AirPods Max Pro” is the only logical name for the upgraded version of AirPods Max.</p><p>This is what I think I Apple should do.</p><ol><li>Rebrand the current AirPods to “AirPods mini”.</li><li>Rebrand the current AirPods Pro to “AirPods”.</li><li>Rebrand the current AirPods Max to “AirPods Pro”.</li><li>Brand the future high end over-the-ear AirPods as “AirPods Pro Max”.</li></ol><p>I think this makes sense for the following reasons.</p><ol><li>The current AirPods were perhaps revolutionary for their time, but they seem a little outdated now. If you asked me today, I think the anchor of the current AirPods lineup is AirPods Pro. In other words, I don’t see the current AirPods Pro as an upgraded version of AirPods. Instead, I see the current AirPods as a stripped down version of AirPods Pro –&nbsp;more specifically, a stripped down version that will be shipped with iPhones within 2-3 years. Thus, it makes sense to shift the anchor point of the AirPods line so that the current AirPods become AirPods mini.</li><li>There’s nothing “Pro” about the current AirPods Pro – and this is by far my biggest gripe with Apple’s AirPods naming scheme. When I hear the word “Pro” in the context of personal listening equipment like earphones and headphones, my mind immediately jumps to over-the-ear models with wired connections, which AirPods Max do support via the <a href="https://www.apple.com/shop/product/MR2C2AM/A/lightning-to-35mm-audio-cable-12m">Lightning to 3.5 mm cable</a>. Think about when audio professionals use earphones or headphones –&nbsp;when they’re recording, monitoring, mixing, mastering, performing, etc. These are latency-sensitive situations where Bluetooth wireless headphones just wouldn’t work (even 5 ms of latency is noticeable when recording music). The fact that AirPods Pro are wireless-only means audio professionals can’t reliably use them for work. Since the current AirPods Max support wired connections, it’s the only product in the AirPods line I would consider to be “Pro”. Thus, I think AirPods Max are the real AirPods Pro.</li><li>If AirPods Pro were the “lower-tier” over-the-ear headphones in the lineup, a future upgraded model could be called “AirPods Pro Max”, and this naming scheme would finally make sense! AirPods Pro would be a product that can be used for professional latency-sensitive audio applications, and AirPods Pro Max would be a maxed out version of AirPods Pro with higher-end components for professionals who demand more.</li></ol><p>With this naming scheme, the most expensive AirPods product would be AirPods Pro Max, which is syntactically in line with the iPhone 12 Pro Max. So, not only would the AirPods lineup naming make sense from a product utility perspective (the over-the-ear model is the “Pro” one), it would also live in harmony with the iPhone lineup from a naming standpoint. What do you think about the product naming for Apple’s AirPods lineup? Do you like it, or do you think Apple messed up royally? Let me know via <a href="https://brianli.com/contact/">email</a> or reach out to me on <a href="https://twitter.com/bwhli" rel="nofollow">Twitter</a>!</p><p><strong>Update (December 13, 2020):</strong> Thinking about it more, I guess another option for the highest-end model is “AirPods Studio” (as was previously rumored). Though if the top model were over-the-ear headphones like AirPods Max, maybe “AirPods Max Studio” would make more sense.</p></div></article></main></div></div>]]>
            </description>
            <link>https://brianli.com/airpods-max-pro-vs-airpods-pro-max/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25396054</guid>
            <pubDate>Sat, 12 Dec 2020 06:16:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Colab Python Notebooks Useful Tips]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25395858">thread link</a>) | @sean_pedersen
<br/>
December 11, 2020 | https://amitness.com/2020/06/google-colaboratory-tips/ | <a href="https://web.archive.org/web/*/https://amitness.com/2020/06/google-colaboratory-tips/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
<p>Colab is one of the best products to come from Google. It has made GPUs freely accessible to learners and practitioners like me who otherwise wouldn’t be able to afford a high-end GPU.</p>
<p>While the interface is very easy to use, there are many lesser-known and undocumented features in colab. In this post, I will share those features that I’ve discovered from basic usage and their official talks.</p>
<h2 id="1-scratchpad-notebook">1. Scratchpad Notebook</h2>
<p>It’s a pretty common scenario that we have a bunch of cluttered untitled notebooks created when we try out temporary stuff on colab.</p>
<p><img src="https://amitness.com/images/colab-clutter.png" alt="Clutter of Untitled Notebooks in Colab"><br>
To solve this, you can bookmark the link given below. It will open a special <strong>scratch notebook</strong> and any changes you make to that notebook are not saved to your main account.</p>
<blockquote>
<p><a href="https://colab.research.google.com/notebooks/empty.ipynb">https://colab.research.google.com/notebooks/empty.ipynb</a></p>
</blockquote>
<h2 id="2-timing-execution-of-cell">2. Timing Execution of Cell</h2>
<p>It’s pretty common that we manually calculate the difference between start and end times of a piece of code to gauge the time taken.</p>
<p>Colab provides an inbuilt feature to do this. After a cell is executed, just hover over the cell run icon and you will get an estimate of the execution time taken.</p>
<p><img src="https://amitness.com/images/colab-cell-hover.png" alt="Execution Time by hovering on run cell"></p>
<h2 id="3-run-part-of-a-cell">3. Run part of a cell</h2>
<p>You can also run only a part of the cell by selecting it and pressing the <code>Runtime &gt; Run Selection</code> button or using the keyboard shortcut <code>Ctrl + Shift + Enter</code>.</p>
<p><img src="https://amitness.com/images/colab-run-few-lines.gif" alt="Running specific line in colab"></p>
<h2 id="4-jupyter-notebook-keyboard-shortcuts">4. Jupyter Notebook Keyboard Shortcuts</h2>
<p>If you are familiar with keyboard shortcuts from Jupyter Notebook, they don’t work directly in Colab. But I found a mental model to map between them.</p>
<p>Just add <code>Ctrl + M</code> before whatever keyboard shortcut you were using in Jupyter. This rule of thumb works for the majority of common use-cases.</p>
<table>
<thead>
<tr>
<th>Action</th>
<th>Jupyter Notebook</th>
<th>Google Colab</th>
</tr>
</thead>
<tbody>
<tr>
<td>Add a cell above</td>
<td>A</td>
<td>Ctrl + <strong>M</strong> + A</td>
</tr>
<tr>
<td>Add a cell below</td>
<td>B</td>
<td>Ctrl + <strong>M</strong> + B</td>
</tr>
<tr>
<td>See all keyboard shorcuts</td>
<td>H</td>
<td>Ctrl + <strong>M</strong> + H</td>
</tr>
<tr>
<td>Change cell to code</td>
<td>Y</td>
<td>Ctrl + <strong>M</strong> + Y</td>
</tr>
<tr>
<td>Change cell to markdown</td>
<td>M</td>
<td>Ctrl + <strong>M</strong> + M</td>
</tr>
<tr>
<td>Interrupt the kernel</td>
<td>II</td>
<td>Ctrl + <strong>M</strong> + I</td>
</tr>
<tr>
<td>Delete a cell</td>
<td>DD</td>
<td>Ctrl + <strong>M</strong> + D</td>
</tr>
<tr>
<td>Checkpoint notebook</td>
<td>Ctrl + S</td>
<td>Ctrl + <strong>M</strong> + S</td>
</tr>
</tbody>
</table>
<p>Below are some notable exceptions to this rule for which either the shortcut is changed completely or kept the same.</p>
<table>
<thead>
<tr>
<th>Action</th>
<th>Jupyter Notebook</th>
<th>Google Colab</th>
</tr>
</thead>
<tbody>
<tr>
<td>Restart runtime</td>
<td>00</td>
<td>Ctrl + <strong>M</strong> + <strong>.</strong></td>
</tr>
<tr>
<td>Run cell</td>
<td>Ctrl + Enter</td>
<td>Ctrl + Enter</td>
</tr>
<tr>
<td>Run cell and add new cell below</td>
<td>Alt + Enter</td>
<td>Alt + Enter</td>
</tr>
<tr>
<td>Run cell and goto the next cell below</td>
<td>Shift + Enter</td>
<td>Shift + Enter</td>
</tr>
<tr>
<td>Comment current line</td>
<td>Ctrl + /</td>
<td>Ctrl + /</td>
</tr>
</tbody>
</table>
<h2 id="5-jump-to-class-definition">5. Jump to Class Definition</h2>
<p>Similar to an IDE, you can go to a class definition by pressing <code>Ctrl</code> and then clicking a class name. For example, here we view the class definition of the Dense layer in Keras by pressing Ctrl and then clicking the <code>Dense</code> class name.</p>
<p><img src="https://amitness.com/images/colab-goto-class.gif" alt="Demo of jumping to class definition"></p>
<h2 id="6-open-notebooks-from-github">6. Open Notebooks from GitHub</h2>
<p>The Google Colab team provides an official chrome extension to open notebooks on GitHub directly on colab. You can install it from <a href="https://chrome.google.com/webstore/detail/open-in-colab/iogfkhleblhcpcekbiedikdehleodpjo">here</a>.</p>
<p>After installation, click the colab icon on any GitHub notebook to open it directly.</p>
<p><img src="https://amitness.com/images/colab-from-github.png" alt="Extension for opening github notebook in colab"></p>
<p>Alternatively, you can also manually open any GitHub notebook by replacing <code>github.com</code> with <code>colab.research.google.com/github</code>.</p>
<blockquote>
<p>https://<strong>github.com</strong>/fastai/course-v3/blob/master/nbs/dl1/00_notebook_tutorial.ipynb</p>
</blockquote>
<p>to</p>
<blockquote>
<p>https://<strong>colab.research.google.com/github</strong>/fastai/course-v3/blob/master/nbs/dl1/00_notebook_tutorial.ipynb</p>
</blockquote>
<p>An even easier way is to replace <code>github.com</code> with <code>githubtocolab.com</code>. It will redirect you to a colab notebook.</p>
<blockquote>
<p>https://<strong>github.com</strong>/fastai/course-v3/blob/master/nbs/dl1/00_notebook_tutorial.ipynb</p>
</blockquote>
<p>to</p>
<blockquote>
<p>https://<strong>githubtocolab.com</strong>/fastai/course-v3/blob/master/nbs/dl1/00_notebook_tutorial.ipynb</p>
</blockquote>
<h2 id="7-run-flask-apps-from-colab">7. Run Flask apps from Colab</h2>
<p>With a library called <a href="https://github.com/gstaff/flask-ngrok">flask-ngrok</a>, you can easily expose a Flask web app running on colab to demo prototypes. First, you need to install <code>flask</code> and <code>flask-ngrok</code>.</p>
<div><div><pre><code><span>!</span><span>pip</span> <span>install</span> <span>flask</span><span>-</span><span>ngrok</span> <span>flask</span><span>==</span><span>0.12</span><span>.</span><span>2</span>
</code></pre></div></div>
<p>Then, you just need to pass your flask app object to <code>run_with_ngrok</code> function and it will expose a ngrok endpoint when the server is started.</p>
<div><div><pre><code><span>from</span> <span>flask</span> <span>import</span> <span>Flask</span>
<span>from</span> <span>flask_ngrok</span> <span>import</span> <span>run_with_ngrok</span>

<span>app</span> <span>=</span> <span>Flask</span><span>(</span><span>__name__</span><span>)</span>
<span>run_with_ngrok</span><span>(</span><span>app</span><span>)</span>

<span>@</span><span>app</span><span>.</span><span>route</span><span>(</span><span>'/'</span><span>)</span>
<span>def</span> <span>hello</span><span>():</span>
    <span>return</span> <span>'Hello World!'</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span><span>:</span>
    <span>app</span><span>.</span><span>run</span><span>()</span>
</code></pre></div></div>
<p><img src="https://amitness.com/images/colab-flask.png" alt="Example of running flask-ngrok"></p>
<p>You can try this out from the package author’s <a href="https://colab.research.google.com/github/gstaff/flask-ngrok/blob/master/examples/flask_ngrok_example.ipynb">official example</a> on Colab.</p>
<h2 id="8-switch-between-tensorflow-versions">8. Switch between Tensorflow versions</h2>
<p>You can easily switch between Tensorflow 1 and Tensorflow 2 using this magic flag. <br>
To switch to Tensorflow 1.15.2, use this command:</p>

<p>To switch to Tensorflow 2.2, run this command:</p>

<p>You will need to restart the runtime for the effect to take place. Colab recommends using the pre-installed Tensorflow version instead of installing it from <code>pip</code> for performance reasons.</p>
<h2 id="9-tensorboard-integration">9. Tensorboard Integration</h2>
<p>Colab also provides a magic command to use Tensorboard directly from the notebook. You just need to set the logs directory location using the <code>--logdir</code> flag. You can learn to use it from the <a href="https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb">official notebook</a>.</p>
<div><div><pre><code><span>%</span><span>load_ext</span> <span>tensorboard</span>
<span>%</span><span>tensorboard</span> <span>--</span><span>logdir</span> <span>logs</span>
</code></pre></div></div>
<p><img src="https://amitness.com/images/colab-tensorboard.png" alt="Embedded Tensorboard in Colab"></p>
<h2 id="10-gauge-resource-limits">10. Gauge resource limits</h2>
<p>Colab provides the following specs for their free and pro versions. Based on your use case, you can switch to the pro version at $10/month if you need a better runtime, GPU, and memory.</p>
<table>
<thead>
<tr>
<th>Version</th>
<th>GPU</th>
<th>GPU Ram</th>
<th>RAM</th>
<th>Storage</th>
<th>CPU Cores</th>
<th>Idle Timeout</th>
<th>Maximum Runtime</th>
</tr>
</thead>
<tbody>
<tr>
<td>Free</td>
<td>Tesla K80</td>
<td>11.44GB</td>
<td>13.7GB</td>
<td>37GB</td>
<td>2</td>
<td>90 min</td>
<td>12 hrs</td>
</tr>
<tr>
<td>Pro</td>
<td>Tesla P100</td>
<td>16GB</td>
<td>27.4GB</td>
<td>37GB</td>
<td>4</td>
<td>90 min</td>
<td>24 hrs</td>
</tr>
</tbody>
</table>
<p>You can view the GPU you have been assigned by running the following command</p>

<p>For information on the CPU, you can run this command</p>

<p>Similarly, you can view the RAM capacity by running</p>
<div><div><pre><code><span>import</span> <span>psutil</span>
<span>ram_gb</span> <span>=</span> <span>psutil</span><span>.</span><span>virtual_memory</span><span>().</span><span>total</span> <span>/</span> <span>1e9</span>
<span>print</span><span>(</span><span>ram_gb</span><span>)</span>
</code></pre></div></div>
<h2 id="11-use-interactive-shell">11. Use interactive shell</h2>
<p>There is no built-in interactive terminal in Colab. But you can use the <code>bash</code> command to try out shell commands interactively. Just run this command and you will get an interactive input.</p>

<p>Now, you can run any shell command in the given input box.</p>
<p><img src="https://amitness.com/images/colab-bash.png" alt="Using interactive shell in colab"></p>
<p>To quit from the shell, just type <code>exit</code> in the input box.</p>
<p><img src="https://amitness.com/images/colab-bash-exit.png" alt="Exiting interactive shell in colab"></p>
<h2 id="12-current-memory-and-storage-usage">12. Current memory and storage usage</h2>
<p>Colab provides an indicator of RAM and disk usage. If you hover over the indicator, you will get a popup with the current usage and the total capacity.</p>
<p><img src="https://amitness.com/images/colab-ram-usage.png" alt="Showing current memory and ram usage in colab"></p>
<h2 id="13-open-in-colab-badge">13. “Open in Colab” Badge</h2>
<p>You can add a ‘Open in Colab’ badge to your <code>README.md</code> or jupyter notebooks using the following markdown code.<br>
<img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></p>
<p>In the markdown code, we’re loading an SVG image and then linking it to a colab notebook.</p>
<div><div><pre><code><span>[</span><span>![Open In Colab</span><span>](</span><span>https://colab.research.google.com/assets/colab-badge.svg</span><span>)</span>](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)
</code></pre></div></div>
<h2 id="14-interactive-tables-for-pandas">14. Interactive Tables for Pandas</h2>
<p>Colab provides a notebook extension to add interactive sorting and filtering capabilities to pandas dataframes. To use it, run the following code.</p>
<div><div><pre><code><span>%</span><span>load_ext</span> <span>google</span><span>.</span><span>colab</span><span>.</span><span>data_table</span>
</code></pre></div></div>
<p>You can see the regular pandas dataframe and the interactive dataframe after loading the extension below.<br>
<img src="https://amitness.com/images/pandas-table-before.png" alt="Regular pandas dataframe output"><br>
<img src="https://amitness.com/images/colab-pandas-after.png" alt="Interactive pandas dataframe output"></p>
<h2 id="15-setup-conda-environment">15. Setup Conda environment</h2>
<p>If you use miniconda as your python environment manager, you can setup it on colab by running these commands at the top of your notebook.</p>
<div><div><pre><code><span># Download Miniconda installation script</span>
<span>!</span>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

<span># Make it executable</span>
<span>!</span><span>chmod</span> +x Miniconda3-latest-Linux-x86_64.sh

<span># Start installation in silent mode</span>
<span>!</span>bash ./Miniconda3-latest-Linux-x86_64.sh <span>-b</span> <span>-f</span> <span>-p</span> /usr/local

<span># Make conda packages available in current environment</span>
import sys
sys.path.append<span>(</span><span>'/usr/local/lib/python3.7/site-packages/'</span><span>)</span>
</code></pre></div></div>
<p>After the cell is executed, you can use conda to install packages as usual.</p>

<h2 id="16-manage-colab-notebooks-from-command-line">16. Manage Colab Notebooks from Command Line</h2>
<p>You can use a library called <a href="https://github.com/Akshay090/colab-cli">colab-cli</a> to easily create and sync colab notebooks with your local notebooks.</p>
<p><a href="https://asciinema.org/a/314749"><img src="https://asciinema.org/a/314749.svg" alt="colab-cli-demo"></a></p>
<h2 id="17-run-background-tasks">17. Run background tasks</h2>
<p>There are use-cases when we need to start some web server or background tasks before we can execute our regular program.</p>
<p>To run background tasks, use the <code>nohup</code> command followed by your regular shell command and add <code>&amp;</code> to the end to run it in the background. This makes sure that you can run cells afterward in the notebook without your background task blocking it.</p>

<h2 id="18-notify-on-training-completion">18. Notify on Training Completion</h2>
<p>If you’re running a long task such as training a model, you can setup Colab to send a desktop notification once it’s completed.</p>
<p>To enable that, goto Tools ⮕ Settings ⮕ Site and enable <code>Show desktop notifications</code> checkbox.</p>
<p><img src="https://amitness.com/images/colab-notification.png" alt=""></p>
<p>You will get a popup to enable browser notification. Just accept it and colab will notify you on task completion even if you are on another tab, window or application.</p>
<h2 id="19-run-javascript-code">19. Run javascript code</h2>
<p>You can run javascript code by using the <code>%%javascript</code> magic command.</p>
<p><img src="https://amitness.com/images/colab-javascript.png" alt=""></p>
<h2 id="20-run-vscode-on-colab">20. Run VSCode on Colab</h2>
<p>You can run a full-fledged VSCode editor on Colab by following the method I have explained in another <a href="https://amitness.com/vscode-on-colab/">article</a>.</p>
<p><img src="https://amitness.com/images/colab-code-step-3.png" alt=""></p>
<h2 id="21-custom-snippets">21. Custom snippets</h2>
<p>You can save your own collections of useful snippets and access them easily in any colab notebook.</p>
<ul>
<li>
<p>Create a colab notebook called <code>snippets.ipynb</code>. To add each of your snippets, create a markdown cell and add name of the snippet as header. Below, the markdown cell, add a code cell with the snippet code.</p>
<p><img src="https://amitness.com/images/custom-snippets-step-1.png" alt=""></p>
</li>
<li>
<p>Copy the link of this notebook from the browser tab.</p>
<p><img src="https://amitness.com/images/custom-snippets-step-2.png" alt=""></p>
</li>
<li>
<p>Click <code>Tools &gt; Settings</code> in your menu bar to open preference of colab.<br>
<img src="https://amitness.com/images/custom-snippets-step-3.png" alt=""></p>
</li>
<li>
<p>Paste the link into the <code>Custom snippet notebook URL</code> textbox and click save.</p>
</li>
</ul>
<p><img src="https://amitness.com/images/custom-snippets-step-4.png" alt=""></p>
<ul>
<li>Now, the snippets are available in any colab notebook you use. Just click the <strong>&lt;&gt;</strong> icon on sidebar, search for your snippet name and click <strong>Insert</strong>. The code will be inserted into a new cell.</li>
</ul>
<p><img src="https://amitness.com/images/custom-snippets-usage.gif" alt=""></p>
<h2 id="22-run-jupyterlab-on-google-colab">22. Run JupyterLab on Google Colab</h2>
<p>You can start a JupyterLab instance on colab by running the following commands in a cell.</p>
<div><div><pre><code><span>!</span><span>pip</span> <span>install</span> <span>jupyterlab</span> <span>pyngrok</span> <span>-</span><span>q</span>

<span># Run jupyterlab in the background
</span><span>!</span><span>nohup</span> <span>jupyter</span> <span>lab</span> <span>--</span><span>ip</span><span>=</span><span>0.0</span><span>.</span><span>0.0</span> <span>&amp;</span>

<span># Get ngrok URL mapped to port 8888
</span><span>from</span> <span>pyngrok</span> <span>import</span> <span>ngrok</span>
<span>print</span><span>(</span><span>ngrok</span><span>.</span><span>connect</span><span>(</span><span>8888</span><span>))</span>
</code></pre></div></div>
<p>Once executed, click the printed ngrok URL to access the JupyterLab interface.</p>
<p><img src="https://amitness.com/images/colab-jupyterlab.png" alt=""></p>
<h2 id="references">References</h2>
<ul>
<li>Timothy Novikoff, <a href="https://www.youtube.com/watch?v=pnClcwTCyc0">“Making the most of Colab (TF Dev Summit ‘20)”</a></li>
<li>Gal Oshri, <a href="https://www.youtube.com/watch?v=xM8sO33x_OU">“What’s new in TensorBoard (TF Dev Summit ‘19)”</a></li>
</ul>
</section></div>]]>
            </description>
            <link>https://amitness.com/2020/06/google-colaboratory-tips/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395858</guid>
            <pubDate>Sat, 12 Dec 2020 05:33:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Flows Toward Order]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25395794">thread link</a>) | @akeck
<br/>
December 11, 2020 | http://m.nautil.us/issue/93/forerunners/time-flows-toward-order | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/93/forerunners/time-flows-toward-order">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>T</span>he one law of physics that virtually all scientists believe will never be found to be wrong is the second law of thermodynamics. Despite this exalted status, it has long been associated with a great mystery and a bleak implication. The mystery is that all the known laws of nature except one do not distinguish a temporal direction. The second law, however, asserts the existence of an all-powerful unidirectionality in the way all events throughout the universe unfold. According to standard accounts, the second law says that entropy, described as a measure of disorder, will always (with at most small fluctuations) increase. That’s the rub: Time has an arrow that points to heat death.</p><p>Surprisingly, evidence that a more nuanced account is needed is hiding in plain sight: the universe itself. Very soon after the Big Bang, the universe was in an extremely uniform state, which since then has become ever more varied and structured. Even if uniformity equates to order, that initial state was surely bland and dull. And who can see disorder in the fabulously structured galaxies or the colors and shapes of the trees in the fall? In fact, the sequence in which two of the greatest discoveries in science were made resolves the paradox: The second law was discovered eight decades before the expansion of the universe.</p><figure data-alt="Barbour_BREAKER"><img src="http://static.nautil.us/17977_f1b4a1e8b4c12f7c7f2e390c76b4cc12.png" width="733" alt=""><figcaption><span><strong>BOTH SIDES NOW:</strong> Two people walking down opposite sides of Mount Fuji would see the terrain change in much the same way. To author Julian Barbour, the hikers’ perceptions offers an apt analogy for how beings on either side of what he calls a “Janus Point” in the universe would experience moving orderly in time.</span><span>Martina Badini / Shutterstock</span></figcaption></figure><p>The time lag is critical for one simple reason. The laws of thermodynamics, discovered in 1850 by William Thomson (later ennobled to Lord Kelvin) and Rudolf Clausius, emerged from a brilliant study that Sadi Carnot (son of Napoleon’s greatest general) published in 1824. In a slim booklet that laid out all but one of the foundational principles of thermodynamics, he sought to establish the maximum efficiency steam engines could achieve. Steam engines can only function if their working medium is confined in a cylinder. This led all early work on thermodynamics to be based on systems in a conceptual box. Clausius’s discovery and definition of entropy—one of the wonders of science—relied totally on infinitesimal changes from one equilibrium state of a confined system to another. The pioneers of statistical mechanics, the theoretical framework created above all by Clausius, James Clerk Maxwell, and Ludwig Boltzmann to provide a microscopic atomistic explanation of phenomenological thermodynamics, invariably considered models of gas molecules trapped in a box and forced to bounce off its walls and each other.<br></p><p>A rich conceptual framework, completely valid and immensely fruitful for confined systems, developed out of this simple model, and reached its definitive form in the work of J. Willard Gibbs. The model proved the existence of atoms and molecules, established their sizes, determined the incredible number of them in a grain of sand, and struck the death knell of Newtonian classical physics. That was when Planck discovered the first quantum effect in 1900. What’s more, both the first and second law appeared to be founded on a rock-solid principle: the impossibility of creating perpetual motion machines.</p><blockquote><p>I don’t deny the arrow of time. But the “box mentality” has led us to misunderstand what is happening in the universe.</p> </blockquote><p>It’s therefore not surprising that few, if any, scientists have disagreed with the great astrophysicist Arthur Eddington’s warning, “If your theory is found to be against the second law of thermodynamics I can give you no hope; there is nothing for it but to collapse in deepest humiliation.” Einstein, surely a greater scientist than Eddington, was more cautious. A few years before his death, Einstein said of thermodynamics, “It is the only physical theory of universal content which I am convinced that, within the framework of applicability of its basic concepts, will never be overthrown.” The caveat is all important: Do conditions in an expanding universe remain within the framework of applicability?<br></p><p>That is what I question. I don’t suggest we can ever alter the facts that Thomson and Clausius first brought to light. Neither you nor I are going to get younger or see a shattered cup miraculously reassemble itself and jump back onto the table. There is a pervasive unidirectionality, an arrow of time, about the way things happen in the universe. Kelvin, the first to recognize its significance, called it “a universal tendency in nature to the dissipation of mechanical energy.” I don’t deny the existence of the arrow, but I do suggest that the “box mentality” has led us to misunderstand what is happening in the universe and even blinded us to the beauty that it is creating. A one-way street need not lead to a scrap yard; it might bring us to a finely landscaped park.</p><p>Compare two situations. First, the molecules in their box. If, every now and then, you open it to look at them, you can be sure to find them filling the box uniformly and going through their habitual routine—bumping into each other with random outcomes. Nothing of interest develops. This, nevertheless, was the model used to interpret mundane measurements of pressure and temperature. It led to all those marvelous discoveries and much of the technology on which today we so depend. No wonder it inspired confidence.</p><p>But now picture the box in space with its walls suddenly removed. What will the molecules do? The answer’s in Siegfried Sassoon’s poem “Everyone Sang”:</p><p>As prisoned birds must find in freedom, Winging wildly across the white<br>Orchards and dark-green fields; on – on – and out of sight.</p><p>In mathematical rather than poetic terms, the molecules soon cease to interact and fly apart, maintaining forever their release velocities and getting ever further from each other. In fact, a simple calculation may surprise you: The speed with which the molecules move apart approximates ever better the law of galactic recession that Hubble announced in 1929. This simple Big Bang model does not look like disorder on the increase.</p><p><span>T</span>here is a greater mismatch between entropic disorder and reality in the very heart of Newton’s theory of universal gravitation. He achieved fame by explaining not only Kepler’s laws of planetary motion but also the fall of an apple. However, the problem of three bodies—he had in mind the earth, sun, and moon moving in their mutual gravitational fields—gave him headaches. Although a famously difficult problem, in 1772 the great mathematician Joseph-Louis Lagrange made some progress, including a significant discovery about the behavior of a “three-body universe” that was later shown to be true for any number of bodies. It concerns what is now called the center-of-mass moment of inertia, <i>I</i>. This measures the extent of the system—for bees it would be about the diameter of a swarm—and behaves in a characteristic universal way if a single condition is satisfied: The total energy of the system is not negative.</p><blockquote><p>The beauty is in the ratios, and they persist forever even in the expanding universe.</p> </blockquote><p>To understand what the behavior is, assume with Newton that time flows forever forward from past to future. Then what Lagrange found is that <i>I</i> decreases from infinity in the distant past, passes through a unique minimum, and grows to infinity in the distant future. I call this unique minimum a Janus Point. The Roman divinity can be invoked because he looks simultaneously in two opposite directions of time at once. What he sees is striking. In the region around the threshold on which he traditionally stands, the distribution of the particles (especially when there are many) is more uniform than anywhere else on the timeline of the universe. Then, in both directions, the particles cluster, taking on a shape that is more ordered and forming “galaxies.” From his vantage point, Janus can see this, but if you, being a mere mortal, were in such a universe you would necessarily be on one or the other side of the Janus point and could not “see through it” to the other side. You would find that the laws of nature around you do not distinguish a direction of time but that your universe gets ever more clumpy in one direction.</p><p>There is a precise, mathematically significant quantity that may be called complexity and increases (with small fluctuations) in both directions from Janus. The big difference from what entropy does is that growth of complexity reflects an increase of order, not disorder. The effects in confined and unconfined systems are the exact opposites of each other. Moreover, the increase of complexity in unconfined systems follows directly from the governing dynamical law whereas entropy increases in confined systems for statistical reasons.</p><div>
<article>
<p><a href="http://m.nautil.us/issue/33/Attraction/describing-people-as-particles-isnt-always-a-bad-idea" data-trval="describing-people-as-particles-isnt-always-a-bad-idea" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/8356_b45f8e4366b41a30994d6b5b3bb2d51b.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>


</article>
</div><p>Traditional arguments assume that somehow, for an as yet unfathomable reason, the universe gets in a special state of low entropy and correspondingly high order that is then remorselessly destroyed. A model often given is molecules confined to a little box in the corner of a big box. That’s the special initial condition. Now lift the lid of the little box; the laws of dynamics allow two quite different outcomes. It’s conceivable, but barely so, that the molecules will collect in the corner of the little box and then be in an even more special state. But it is statistically more likely that the molecules will spread out into the large box and eventually fill it uniformly. This is a statistical explanation of the entropic arrow. Applied to the whole universe, a special initial condition of this kind has been dubbed the “Past Hypothesis” by the philosopher of science David Albert. The difficulty is that nothing in the known laws of nature explains the special initial condition.</p><p><span>L</span>et’s now think about the Janus point. It’s unique and a special point. It isn’t there for some …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/93/forerunners/time-flows-toward-order">http://m.nautil.us/issue/93/forerunners/time-flows-toward-order</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/93/forerunners/time-flows-toward-order</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395794</guid>
            <pubDate>Sat, 12 Dec 2020 05:15:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Regex literals optimization (or how to cheat on benchmarks)]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25395709">thread link</a>) | @nitely
<br/>
December 11, 2020 | https://nitely.github.io/2020/11/30/regex-literals-optimization.html | <a href="https://web.archive.org/web/*/https://nitely.github.io/2020/11/30/regex-literals-optimization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The regex literals optimization avoids running the regex engine on parts of the input text that cannot possibly ever match the regex.</p>

<p>An example of a regex this can be applied to is <code>\w+@\w+\.\w+</code>, where the algorithm <em>quickly</em> finds the first <code>@</code>, then matches <code>\w+</code> backwards to find the start of the match, and then matches <code>\w+\.\w+</code> forward to find the end of the match. It then finds the second <code>@</code>, starting from the end of the previous match, and so on. This is a fairly naive (and incorrect) implementation, but it gives the idea of how it works.</p>

<p>I’ve recently implemented it in my pet project <a href="https://github.com/nitely/nim-regex/pull/68">nim-regex</a>, an NFA based regex engine that runs in (super)linear time. The results show it’s around ~100x faster than before in some benchmarks. It’s up to ~60x faster than PCRE when the optimization kicks in. The tests are based on <a href="https://github.com/mariomka/regex-benchmark">mariomka/regex-benchmark</a>.</p>

<p>This is not to be confused with <em>Chivers’ String Prefix Optimization</em>.</p>

<h2 id="literals-optimization">Literals Optimization</h2>

<p>Since nim-regex has to guarantee linear time, I’ll describe optimizations that are guaranteed to take linear time. We must also ensure the matches are not overlapped.</p>

<p>Here’s a high-level description of the algorithm:</p>

<ul>
  <li>We pick a literal that is <code>memchr</code>‘ed to skip parts of the text.</li>
  <li>The prefix is the regex part before the literal; none of the
characters or symbols within the prefix must match the literal.</li>
  <li>The prefix is ran backwards to find the start of the match.</li>
  <li>A full scan is ran from the start of the match
until a character that cannot be matched is found (safe break point)
or the end is reached. The scan tries to start the match at every character (NFAs can do this in linear time).</li>
  <li>Go to step one and repeat from the last scanned char. Make the prefix
match until the previous last scanned char.</li>
</ul>

<p>There are two important constraints to picking a literal:</p>

<ul>
  <li><em>“none of the characters or symbols within the prefix must match the literal”</em>, why? consider the regex: <code>\d\w+x</code>, and the input text: <code>xxxxxxxxxxx</code>; this would take quadratic time, as the prefix will match until the start of the string every time. What about the limit? while the limit does avoid the excessive matching, sometimes we’d need to match past the limit, ex: regex: <code>\d\w+x</code>, and text: <code>1xxx</code>. If we add this constraint, the literal becomes a delimeter, and these cases are solved.</li>
  <li>The literal cannot be part of a repetition, nor it can be part of an alternation. For example: <code>(abc)*def</code> the first literal candidate is <code>d</code>, since <code>(abc)*</code> may or may not be part of the match. Same thing for alternations.</li>
</ul>

<p>Here’s the main algorithm in <a href="https://nim-lang.org/">Nim</a>:</p>

<figure><pre><code data-lang="nim"><span>func</span> <span>findAll</span><span>(</span>
  <span>matches</span><span>:</span> <span>var</span> <span>Matches</span><span>,</span>
  <span>text</span><span>:</span> <span>string</span><span>,</span>
  <span>regex</span><span>:</span> <span>Regex</span><span>,</span>
  <span>start</span><span>:</span> <span>int</span>
<span>):</span> <span>int</span> <span>=</span>
  <span>var</span> <span>i</span> <span>=</span> <span>start</span>
  <span>var</span> <span>limit</span> <span>=</span> <span>start</span>
  <span>while</span> <span>i</span> <span>&lt;</span> <span>text</span><span>.</span><span>len</span><span>:</span>
    <span>limit</span> <span>=</span> <span>i</span>  <span># rather pointless since the literal is a delimiter</span>
    <span>i</span> <span>=</span> <span>memchr</span><span>(</span><span>text</span><span>,</span> <span>regex</span><span>.</span><span>lit</span><span>,</span> <span>i</span><span>)</span>
    <span>if</span> <span>i</span> <span>==</span> <span>-</span><span>1</span><span>:</span>
      <span>return</span> <span>-</span><span>1</span>
    <span>var</span> <span>litIdx</span> <span>=</span> <span>i</span>
    <span>i</span> <span>=</span> <span>matchPrefix</span><span>(</span><span>text</span><span>,</span> <span>regex</span><span>,</span> <span>i</span><span>,</span> <span>limit</span><span>)</span>
    <span>if</span> <span>i</span> <span>==</span> <span>-</span><span>1</span><span>:</span>
      <span>i</span> <span>=</span> <span>litIdx</span><span>+</span><span>1</span>
    <span>else</span><span>:</span>
      <span>i</span> <span>=</span> <span>findSome</span><span>(</span><span>matches</span><span>,</span> <span>text</span><span>,</span> <span>regex</span><span>,</span> <span>i</span><span>)</span>
      <span>if</span> <span>i</span> <span>==</span> <span>-</span><span>1</span><span>:</span>
        <span>return</span> <span>-</span><span>1</span>
      <span>if</span> <span>matches</span><span>.</span><span>len</span> <span>&gt;</span> <span>0</span><span>:</span>
        <span>return</span> <span>i</span>  <span># this is used as "start" to resume the matching</span>
  <span>return</span> <span>-</span><span>1</span></code></pre></figure>

<p>A given character may be consumed only twice, once by the backward prefix match, and a second time by the forward scan. Hence the algorithm runs in linear time.</p>

<p>I may describe how <code>matchPrefix</code> and <code>findSome</code> work, how to construct the reversed NFA in the right order, and how to pick the literal in a future article. The nim-regex code contains descriptions of the algorithms, though.</p>

<h2 id="benchmarks">Benchmarks</h2>

<p>The <a href="https://github.com/nitely/nim-regex/tree/master/bench">benchmarks</a> regexes are based on <a href="https://github.com/mariomka/regex-benchmark">mariomka/regex-benchmark</a>. The only difference is the regexes are pre-compiled, so just the matching is tested. The results show nim-regex is ~63x faster than PCRE in the email test, and ~2x faster in the URI and IP tests.</p>

<p>Why is nim-regex so fast in the email case? The regex engine doesn’t run as often. There are orders of magnitud more IP/URI candidates than email candidates (<code>@</code> chars within the text) to match. In the former case the time is dominated by the regex engine, while in the latter case it’s dominated by searching the char literal.</p>

<div><div><pre><code>==================================================
GlobalBenchmark       relative  time/iter  iters/s
==================================================
GlobalBenchmark                  294.86ps    3.39G
==================================================
bench.nim             relative  time/iter  iters/s
==================================================
pcre_email                        21.76ms    45.96
nim_regex_email       3247.14%   670.02us    1.49K
nim_regex_email_macro 6335.93%   343.38us    2.91K
pcre_uri                          22.15ms    45.14
nim_regex_uri           92.82%    23.87ms    41.90
nim_regex_uri_macro    256.29%     8.64ms   115.68
pcre_ip                            5.73ms   174.58
nim_regex_ip            88.70%     6.46ms   154.84
nim_regex_ip_macro     214.75%     2.67ms   374.91
</code></pre></div></div>

<blockquote>
  <p>Note Nim’s PCRE is at the top of the mariomka/regex-benchmark. I ran those benchmarks, and IIRC nim-regex was just a bit faster, mainly because the non-macro regex engine is slower (see the above results), and the regex compilation is also tested.</p>
</blockquote>

<h2 id="other-optimizations">Other optimizations</h2>

<p>Here are other possible optimizations:</p>

<ul>
  <li>Picking a literal —even if the prefix matches it— should take linear time as long as the prefix is bounded (i.e: does not contain repetitions), ex: <code>\d\wx</code>.</li>
  <li>Picking a literal within a “one or more” repetition/repetition group should be possible, since <code>(abc)+</code> matches the same as <code>abc(abc)*</code>.</li>
  <li>It’s better to pick the last literal within the first literal sequence, since that way we always try to match as many literals as possible early on, and potentially fail early. We want to keep the prefix regex as short as possible, so the picking a literal in the first sequence is best.</li>
  <li>Alternations can be optimized this very same way in some cases, ex: <code>bar|baz</code>, since both alternations have <code>ba</code> in common, <code>a</code> can be picked as the literal.</li>
  <li>Alternations can be optimized in other cases. PCRE seems to use <code>memchr</code> or similar for up to two alternation terms. A DFA could be used to quickly match candidates instead of <code>memchr</code>, as that’s a more general solution.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Literals optimization is not a general optimization as it does not work on every regex, but when it does, it can greatly improve the matching speed.</p>

<p>Can a backtracker like PCRE implement this? PCRE in particular already has some sort of similar optimization, but it’s not as good/fast as this one. Backtrackers cannot implement this as described here exactly, but they can do something similar that requires backtracking. If they provide a resumable <code>find</code> function, then probably yes.</p>

<p>Hopefully, more regex engines will implement these sort of optimizations, so they are more compelling alternatives to backtrackers such as PCRE.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://nitely.github.io/2020/11/30/regex-literals-optimization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395709</guid>
            <pubDate>Sat, 12 Dec 2020 04:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Various Projects: Vehicle Routing, Music Composition, and DRL for POMDPs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25395458">thread link</a>) | @iciac
<br/>
December 11, 2020 | https://www.camerongordon.site/post/projects | <a href="https://web.archive.org/web/*/https://www.camerongordon.site/post/projects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.7.1"><div dir="ltr"><div><p id="viewer-foo"><span>I've decided to a release a few projects that I've worked on over the last year and a half. Most of these are better described as 'assignments', but project just sounds fancier. While none of these are particularly ground-breaking, they will hopefully serve as an introduction or inspiration to explore some fascinating fields of study. </span></p><p id="viewer-9vaoc"><span><strong>Deep Reinforcement Learning for Partially-Observable Markov Decision Processes </strong></span></p><p id="viewer-22ed2"><span>This project served as my thesis. Partially-Observable Markov Decision Processes (POMDPs) are a broad class of decision problems in which the agent is missing some information about the environment. The definition is broad enough to cover many decision problems humans and businesses need to deal with, and it's a notoriously difficult problem for artificial agents to solve for even toy problems.</span></p><p id="viewer-9ra2j"><span>Deep Reinforcement Learning uses a neural network to approximate the value of taking actions given some observed state of the environment. Trial and error exploration reinforces rewarding actions and disincentivises negative ones - much like humans learn that eating a 1.5M Scoville Carolina Reaper chilli is a bad idea, while a chocolate éclair is a tasty one. </span></p><p id="viewer-ftf1s"><span>For this project I trialled a number of Deep Reinforcement Learning algorithms against toy problems. Performance was inconsistent (there's a tendency for the model to choose safe, risk averse responses), but in some instances interesting and complex behaviour was learned (beating my own scores for simple problems!). </span></p><p id="viewer-526lk"><span>Github: <a href="https://github.com/iciac/POMDP" target="_blank" rel="noopener"><u>https://github.com/iciac/POMDP</u></a> </span></p><p id="viewer-5s4vu"><span><strong>Reviewing the Vehicle Routing Problem with Stochastic Requests (VRPSR) </strong></span></p><p id="viewer-d5kv8"><span>I completed this project with David Banh. The Vehicle Routing Problem involves planning efficient delivery paths for a vehicle - similar to the problem faced by food delivery companies such as Deliveroo or Uber Eats. Stochastic requests means that new potential waypoints can arise randomly. The goal is to service as many customers as possible during a limited amount of time. Once customer has been accepted they must be served in the tour. The question is whether the agent should accept distant customers (locking up travel time) or hope for better fares later on. </span></p><p id="viewer-eqt8g"><span>The two gifs below show the general idea. On the left we have a tour made up of stochastic request. The potential tour starts off as loose with only a few customers to be serviced. As new requests are added to the potential tour, it becomes more constrained. On the right we have a heatmap of the customer requests as they are received showing the 'hotspots' of customer activity.  Our solution methods investigated a number of heuristic and simulation based solvers.  </span></p><div id="viewer-ed9r7"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.camerongordon.site/post/projects" data-pin-media="https://static.wixstatic.com/media/1d7133_ca83a6d1cb884f91bf9d2ec10cb683b4~mv2.gif/v1/fit/w_640%2Ch_480%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/1d7133_ca83a6d1cb884f91bf9d2ec10cb683b4~mv2.gif"></p></div></div></div></div><div id="viewer-apacr"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.camerongordon.site/post/projects" data-pin-media="https://static.wixstatic.com/media/1d7133_768c1789cbe243a29b0d2f55964b1960~mv2.gif/v1/fit/w_640%2Ch_480%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/1d7133_768c1789cbe243a29b0d2f55964b1960~mv2.gif"></p></div></div></div></div><p id="viewer-8nppa"><span>Github: <a href="https://github.com/david-b-123/SVRP_MATH7202" target="_blank" rel="noopener"><u>https://github.com/david-b-123/SVRP_MATH7202</u></a> </span></p><p id="viewer-bo4av"><span><strong>Algorithmic Music Composition </strong></span></p><p id="viewer-bluu0"><span>I completed this project with Taotao Pan and Jingye Liu. Music has long been regarded as one of the most human endeavours. It is considered an art, respected not only for the technical skill involved in composition but also the ability to communicate and emotionally move an audience. But music is also a physical signal: it is a wave of energy carried through the air, from the instrument, and onto the listener’s ear. It can be decomposed through a Fourier transform into its constituent elements - be converted to a form that a machine can electronically record, represent, and reproduce. Like speech, it is comprised of semantic elements and regularities - rhythm, meter, patterns that recur and modify and transmit new meaning with each new variation. And because it can be represented with patterns it represents a tantalising challenge for Artificial Intelligence and Deep Learning researchers: to see whether a machine, comprised at its core by a series of electric switches shifting between one and zero, can reproduce an act thought to lie at the heart of how humanity sees itself - whether a machine can compose and whether what is created can be said to be an artistic creation.</span></p><p id="viewer-ci04"><span>In this project we investigated a number of algorithmic models, including Long-Short Term Memory (LSTM), Generative Adversarial Networks (GANs), and Transformer models. This was a very fun project and I highly recommend listening to the computer generated pieces below. </span></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.camerongordon.site/post/projects</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395458</guid>
            <pubDate>Sat, 12 Dec 2020 04:14:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon owns more than $2B worth of IPv4 addresses]]>
            </title>
            <description>
<![CDATA[
Score 338 | Comments 338 (<a href="https://news.ycombinator.com/item?id=25395432">thread link</a>) | @dangoldin
<br/>
December 11, 2020 | https://dangoldin.com/2020/12/11/amazon-owns-more-than-2b-worth-of-ipv4-addresses/ | <a href="https://web.archive.org/web/*/https://dangoldin.com/2020/12/11/amazon-owns-more-than-2b-worth-of-ipv4-addresses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <article>
    

    <section>
      
<p>While listening to a <a href="https://softwareengineeringdaily.com/2020/12/02/bgp-with-andree-toonk/">podcast discussing BGP</a> I heard the fact that AWS owns more than $2B worth of IP addresses. I knew AWS was massive but this came as a big shock so I decided to do some digging around. I came across a <a href="https://ipv4marketgroup.com/ipv4-pricing/">site</a> that listed the market prices of IP addresses and the range looks to be anywhere from $20 to $30 per IP depending on the block size. Now it was time to figure out the IP addresses owned by Amazon. I figured this would be difficult but lucky for us AWS actually <a href="https://ip-ranges.amazonaws.com/ip-ranges.json">publishes</a> their entire set of IP addresses as JSON.</p>

<p>The work is simply to download the JSON and then convert the CIDR blocks to the number of IPs and add them all up. As of today, December 11, 2020 AWS self reports owning 109,847,486 IPV4 addresses - at a price of $20 this is almost $2.2B and at $30 it’s almost $3.3B. That’s wild.</p>

<figure><pre><code data-lang="python"><span>import</span> <span>urllib.request</span>
<span>import</span> <span>json</span>

<span>with</span> <span>urllib</span><span>.</span><span>request</span><span>.</span><span>urlopen</span><span>(</span><span>' https://ip-ranges.amazonaws.com/ip-ranges.json'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
    <span>j</span> <span>=</span> <span>json</span><span>.</span><span>loads</span><span>(</span><span>f</span><span>.</span><span>read</span><span>().</span><span>decode</span><span>(</span><span>'utf-8'</span><span>))</span>

<span>print</span><span>(</span><span>'All keys'</span><span>,</span> <span>j</span><span>.</span><span>keys</span><span>())</span>

<span>print</span><span>(</span><span>'IPV4 prefixes'</span><span>,</span> <span>len</span><span>(</span><span>j</span><span>[</span><span>'prefixes'</span><span>]))</span>

<span>ips</span> <span>=</span> <span>0</span>
<span>for</span> <span>prefix</span> <span>in</span> <span>j</span><span>[</span><span>'prefixes'</span><span>]:</span>
    <span>cidr</span> <span>=</span> <span>int</span><span>(</span><span>prefix</span><span>[</span><span>'ip_prefix'</span><span>].</span><span>split</span><span>(</span><span>'/'</span><span>)[</span><span>1</span><span>])</span>
    <span>ips</span> <span>+=</span> <span>2</span><span>**</span><span>(</span><span>32</span><span>-</span><span>cidr</span><span>)</span>

<span>print</span><span>(</span><span>'# IPS'</span><span>,</span> <span>ips</span><span>)</span></code></pre></figure>

    </section>

    
    <br>
    

    

    

    

  </article>
</div></div>]]>
            </description>
            <link>https://dangoldin.com/2020/12/11/amazon-owns-more-than-2b-worth-of-ipv4-addresses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395432</guid>
            <pubDate>Sat, 12 Dec 2020 04:08:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Full Text Search in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25395237">thread link</a>) | @imshashank
<br/>
December 11, 2020 | https://system.camp/databases/full-text-search-in-postgresql/ | <a href="https://web.archive.org/web/*/https://system.camp/databases/full-text-search-in-postgresql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="primary">
		
	<article id="post-2458">
		<div>
			


			
<div>
	

<h3>What is wrong with the good old SQL searches?</h3>



<ul><li>There is no support for common languages. Regular expressions do not suffice because they cannot easily handle words that essentially mean the same, i.e., blocked and blocking is one such example. You might miss documents that contain blocked, although you probably would like to find them when searching for blocking. Now don’t tell me you are going to use OR through all the derived words – that’s not what a good developer would do 😉</li><li>There is no support for indexes and thus, you have to process the whole document every time you need to search something which is rather tedious and slow.</li></ul>



<h3>What is full text search?</h3>



<p>As the <a href="https://www.postgresql.org/docs/9.5/textsearch-intro.html" target="_blank" rel="noopener">official documentation</a> defines it – Full Text Searching (or just text search) provides the capability to identify natural-language documents that satisfy a query, and optionally to sort them by relevance to the query. The most common type of search is to find all documents containing given query terms and return them in order of their similarity to the query. Notions of query and similarity are very flexible and depend on the specific application. The simplest search considers query as a set of words and similarity as the frequency of query words in the document.</p>



<p>This essentially means that you can now just search for block and you’re going get all it’s derivatives in the document that you want! Isn’t that cool?</p>



<h3>How does it work though?</h3>



<p>PostgreSQL has two utility functions that will help us through this quest – <code>to_tsvector()</code> and <code>to_tsquery()</code></p>



<ul><li>The <code>to_tsvector()</code> command will create a set of lexemes using the document provided to it. It’ll conveniently omit any words that have little meaning – words like ‘the’, ‘an’, etc. When you run this,<br><code>SELECT to_tsvector('english', 'Full text search is an awesome feature');</code></li></ul>



<p>The result is a ‘map’ of words or a dictionary which represents the location of each word.<br><code>’awesom’:6’featur’:7’full’:1’search’:3’text’:2</code></p>



<ul><li>The <code>to_tsquery()</code> takes in a list of words that will be searched against the result of our <code>to_tsvector()</code> function.</li></ul>



<p><code>SELECT to_tsvector(‘Full text search is an awesome feature’) @@ to_tsquery(‘full’);</code></p>



<p>The query above will give us a result <code>true</code>.</p>



<p>Now how to use it? The most apt use would be to create a <code>tsvector</code> of the columns of your database you want to search on and run a <code>tsquery</code> command against that to select the rows you need. What’s more interesting is that you can use operators like <code>&amp;</code>, <code>|</code>, <code>!</code>, etc in your queries!</p>



<p>The official documentation does an awesome job of explaining things! This is just an overview – for more details please go through <a href="https://www.postgresql.org/docs/9.6/functions-textsearch.html" target="_blank" rel="noopener">this</a> link.</p>






<div>
    <div>
        <div>
            <p><a href="https://system.camp/profile/pratyush/" rel="author">
					<img alt="" src="https://secure.gravatar.com/avatar/d80daceadb74f29f9ebe0abf4519d748?s=80&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/d80daceadb74f29f9ebe0abf4519d748?s=160&amp;d=mm&amp;r=g 2x" height="80" width="80" loading="lazy">                </a>
            </p>
            <div>
                <p><span>
                    
                </span>
                <span>
                    <span>Member since</span>
                     <time datetime="2020-12-06 05:37">
                        October 6, 2020                     </time>
                </span>
            </p></div>

			
	    

			
        </div>
		    </div>

	
	</div>
</div>
		</div>

		
<!-- .entry-footer -->
	</article><!-- #post-2458 -->

	

	</div></div>]]>
            </description>
            <link>https://system.camp/databases/full-text-search-in-postgresql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395237</guid>
            <pubDate>Sat, 12 Dec 2020 03:34:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recent Papers Related to Fuzzing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25395122">thread link</a>) | @kmwyard
<br/>
December 11, 2020 | https://wcventure.github.io/FuzzingPaper/ | <a href="https://web.archive.org/web/*/https://wcventure.github.io/FuzzingPaper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      
<p>remark: This website is only used for collecting and grouping the related paper. If there are any paper need to be updated, you can contribute PR.</p>



<ul>
  <li><strong>Survey/Review</strong>
    <ul>
      <li><a href="#fuzzing-challenges-and-reflections">Fuzzing: Challenges and Reflections</a></li>
      <li><a href="#sok-the-progress-challenges-and-perspectives-of-directed-greybox-fuzzing">SoK: The Progress, Challenges, and Perspectives of Directed Greybox Fuzzing</a></li>
      <li><a href="#fuzzing-hack-art-and-science-cacm-2020">Fuzzing: Hack, Art, and Science</a></li>
      <li><a href="#survey-of-directed-fuzzy-technology">Survey of Directed Fuzzy Technology</a></li>
      <li><a href="#a-review-of-machine-learning-applications-in-fuzzing">A Review of Machine Learning Applications in Fuzzing</a></li>
      <li><a href="#a-systematic-review-of-fuzzing-based-on-machine-learning-techniques">A systematic review of fuzzing based on machine learning techniques</a></li>
      <li><a href="#the-art-science-and-engineering-of-fuzzing-a-survey">The Art, Science, and Engineering of Fuzzing: A Survey</a></li>
      <li><a href="#fuzzing-art-science-and-engineering">Fuzzing: Art, Science, and Engineering</a></li>
      <li><a href="#fuzzing-a-survey">Fuzzing: a survey</a></li>
      <li><a href="#fuzzing-state-of-the-art">Fuzzing: State of the art</a></li>
      <li><a href="#a-review-of-fuzzing-tools-and-methods">A Review of Fuzzing Tools and Methods</a></li>
    </ul>
  </li>
  <li><strong>USENIX Security 2021</strong>
    <ul>
      <li><a href="#unifuzz-a-holistic-and-pragmatic-metrics-driven-platform-for-evaluating-fuzzers-usenix-security2021">UNIFUZZ: A Holistic and Pragmatic Metrics-Driven Platform for Evaluating Fuzzers</a></li>
      <li><a href="#nyx-greybox-hypervisor-fuzzing-using-fast-snapshots-and-affine-types-usenix-security2021">Nyx: Greybox Hypervisor Fuzzing using Fast Snapshots and Affine Types</a></li>
    </ul>
  </li>
  <li><strong>CCS 2020</strong>
    <ul>
      <li><a href="#freedom-engineering-a-state-of-the-art-dom-fuzzer-ccs-2020">FREEDOM: Engineering a State-of-the-Art DOM Fuzzer</a></li>
      <li><a href="#squirrel-testing-database-management-systems-with-language-validity-and-coverage-feedback-ccs-2020">SQUIRREL: Testing Database Management Systems with Language Validity and Coverage Feedback</a></li>
    </ul>
  </li>
  <li><strong>ASE 2020</strong>
    <ul>
      <li><a href="#bigfuzz-efficient-fuzz-testing-for-data-analytics-using-framework-abstraction-ase-2020">BigFuzz: Efficient Fuzz Testing for Data Analytics using Framework Abstraction</a></li>
      <li><a href="#mofuzz-a-fuzzer-suite-for-testing-model-driven-software-engineering-tools-ase-2020">MoFuzz: A Fuzzer Suite for Testing Model-Driven Software Engineering Tools</a></li>
      <li><a href="#zeror-speed-up-fuzzing-with-coverage-sensitive-tracing-and-scheduling-ase-2020">Zeror: Speed Up Fuzzing with Coverage-sensitive Tracing and Scheduling</a></li>
      <li><a href="#generating-highly-structured-input-data-by-combining-search-based-testing-and-grammar-based-fuzzing-ase-2020">Generating Highly-structured Input Data by Combining Search-based Testing and Grammar-based Fuzzing</a></li>
    </ul>
  </li>
  <li><strong>ISSTA 2020</strong>
    <ul>
      <li><a href="#active-fuzzing-for-testing-and-securing-cyber-physical-systems-issta-2020">Active Fuzzing for Testing and Securing Cyber-Physical Systems</a></li>
      <li><a href="#learning-input-tokens-for-effective-fuzzing-issta-2020">Learning Input Tokens for Effective Fuzzing</a></li>
      <li><a href="#weizz-automatic-grey-box-fuzzing-for-structured-binary-formats">WEIZZ: Automatic Grey-Box Fuzzing for Structured Binary Formats</a></li>
    </ul>
  </li>
  <li><strong>FSE 2020</strong>
    <ul>
      <li><a href="#fuzzing-on-the-exponential-cost-of-vulnerability-discovery-fse-2020">Fuzzing: On the Exponential Cost of Vulnerability Discovery</a></li>
      <li><a href="#boosting-fuzzer-efficiency-an-information-theoretic-perspective-fse-2020">Boosting Fuzzer Efficiency: An Information Theoretic Perspective</a></li>
      <li><a href="#crfuzz-fuzzing-multi-purpose-programs-through-input-validation-fse-2020">CrFuzz: Fuzzing Multi-purpose Programs through Input Validation</a></li>
      <li><a href="#detecting-critical-bugs-in-smt-solvers-using-blackbox-mutational-fuzzing-fse">Detecting Critical Bugs in SMT Solvers using Blackbox Mutational Fuzzing</a></li>
      <li><a href="#intelligent-rest-api-data-fuzzing-fse-2020">Intelligent REST API Data Fuzzing</a></li>
      <li><a href="#mtfuzz-fuzzing-with-a-multi-task-neural-network-fse-2020">MTFuzz: Fuzzing with a Multi-task Neural Network</a></li>
    </ul>
  </li>
  <li><strong>ACSAC 2020</strong>
    <ul>
      <li><a href="#dpifuzz-a-differential-fuzzing-framework-to-detect-dpi-elusion-strategies-for-quic-acsac-2020">DPIFuzz: A Differential Fuzzing Framework to Detect DPI Elusion Strategies for QUIC</a></li>
      <li><a href="#cupid-automatic-fuzzer-selection-for-collaborative-fuzzing-acsac-2020">Cupid: Automatic Fuzzer Selection for Collaborative Fuzzing</a></li>
      <li><a href="#omnifuzz-a-flexible-framework-for-expediting-bug-finding-by-leveraging-past-mis-behavior-to-discover-new-bugs-acsac-2020">OmniFuzz: A Flexible Framework for Expediting Bug Finding by Leveraging Past (Mis-)Behavior to Discover New Bugs</a></li>
    </ul>
  </li>
  <li><strong>PLDI 2020</strong>
    <ul>
      <li><a href="#validating-smt-solvers-via-semantic-fusion-pldi-2020">Validating SMT Solvers via Semantic Fusion</a></li>
    </ul>
  </li>
  <li><strong>USENIX Security 2020</strong>
    <ul>
      <li><a href="#analysis-of-dtls-implementations-using-protocol-state-fuzzing-usenix-security2020">Analysis of DTLS Implementations Using Protocol State Fuzzing</a></li>
      <li><a href="#frankenstein-advanced-wireless-fuzzing-to-exploit-new-bluetooth-escalation-targets-usenix-security2020">Frankenstein: Advanced Wireless Fuzzing to Exploit New Bluetooth Escalation Targets</a></li>
      <li><a href="#specfuzz-bringing-spectre-type-vulnerabilities-to-the-surface-usenix-security2020">SpecFuzz: Bringing Spectre-type vulnerabilities to the surface</a></li>
      <li><a href="#fuzzgen-automatic-fuzzer-generation-usenix-security2020">FuzzGen: Automatic Fuzzer Generation</a></li>
      <li><a href="#muzz-thread-aware-grey-box-fuzzing-for-effective-bug-hunting-in-multithreaded-programs-usenix-security2020">MUZZ: Thread-aware Grey-box Fuzzing for Effective Bug Hunting in Multithreaded Programs</a></li>
      <li><a href="#montage-a-neural-network-language-model-guided-javascript-engine-fuzzer-usenix-security2020">Montage: A Neural Network Language Model-Guided JavaScript Engine Fuzzer</a></li>
      <li><a href="#greyone-data-flow-sensitive-fuzzing-usenix-security2020">GREYONE: Data Flow Sensitive Fuzzing</a></li>
      <li><a href="#fuzzguard-filtering-out-unreachable-inputs-in-directed-grey-box-fuzzing-through-deep-learning-usenix-security2020">FuzzGuard: Filtering out Unreachable Inputs in Directed Grey-box Fuzzing through Deep Learning</a></li>
      <li><a href="#parmesan-sanitizer-guided-greybox-fuzzing-usenix-security2020">ParmeSan: Sanitizer-guided Greybox Fuzzing</a></li>
      <li><a href="#ecofuzz-adaptive-energy-saving-greybox-fuzzing-as-a-variant-of-the-adversarial-multi-armed-bandit-usenix-security2020">EcoFuzz: Adaptive Energy-Saving Greybox Fuzzing as a Variant of the Adversarial Multi-Armed Bandit</a></li>
      <li><a href="#fans-fuzzing-android-native-system-services-via-automated-interface-analysis-usenix-security2020">FANS: Fuzzing Android Native System Services via Automated Interface Analysis</a></li>
      <li><a href="#fuzzing-error-handling-code-using-context-sensitive-software-fault-injection-usenix-security2020">Fuzzing Error Handling Code using Context-Sensitive Software Fault Injection</a></li>
      <li><a href="#usbfuzz-a-framework-for-fuzzing-usb-drivers-by-device-emulation-usenix-security2020">USBFuzz: A Framework for Fuzzing USB Drivers by Device Emulation</a></li>
      <li><a href="#afl-combining-incremental-steps-of-fuzzing-research-usenix-woot2020">AFL++: Combining Incremental Steps of Fuzzing Research (USENIX Woot2020)</a></li>
    </ul>
  </li>
  <li><strong>ICSE 2020</strong>
    <ul>
      <li><a href="#typestate-guided-fuzzer-for-discovering-use-after-free-vulnerabilities-icse-2020">Typestate-Guided Fuzzer for Discovering Use-after-Free Vulnerabilities</a></li>
      <li><a href="#memlock-memory-usage-guided-fuzzing-icse2020">MemLock: Memory Usage Guided Fuzzing</a></li>
      <li><a href="#ankou-guiding-grey-box-fuzzing-towards-combinatorial-difference-icse-2020">Ankou: Guiding Grey-box Fuzzing towards Combinatorial Difference</a></li>
      <li><a href="#jvm-fuzzing-for-jit-induced-side-channel-detection-icse-2020">JVM Fuzzing for JIT-Induced Side-Channel Detection</a></li>
      <li><a href="#targeted-greybox-fuzzing-with-static-lookahead-analysis-icse-2020">Targeted Greybox Fuzzing with Static Lookahead Analysis</a></li>
      <li><a href="#fuzz-testing-based-data-augmentation-to-improve-robustness-of-deep-neural-networks-icse-2020">Fuzz Testing based Data Augmentation to Improve Robustness of Deep Neural Networks</a></li>
      <li><a href="#sfuzz-an-efficient-adaptive-fuzzer-for-solidity-smart-contracts-icse-2020">sFuzz: An Efficient Adaptive Fuzzer for Solidity Smart Contracts</a></li>
      <li><a href="#hydiff-hybrid-differential-software-analysis-icse-2020">HyDiff: Hybrid Differential Software Analysis</a></li>
      <li><a href="#automatically-testing-string-solvers-icse-2020">Automatically Testing String Solvers</a></li>
    </ul>
  </li>
  <li><strong>NDSS 2020</strong>
    <ul>
      <li><a href="#hyper-cube-high-dimensional-hypervisor-fuzzing-ndss-2020">HYPER-CUBE: High-Dimensional Hypervisor Fuzzing</a></li>
      <li><a href="#hotfuzz-discovering-algorithmic-denial-of-service-vulnerabilities-through-guided-micro-fuzzing-ndss-2020">HotFuzz: Discovering Algorithmic Denial-of-Service Vulnerabilities Through Guided Micro-Fuzzing</a></li>
      <li><a href="#hfl-hybrid-fuzzing-on-the-linux-kernel-ndss-2020">HFL: Hybrid Fuzzing on the Linux Kernel</a></li>
      <li><a href="#not-all-coverage-measurements-are-equal-fuzzing-by-coverage-accounting-for-input-prioritization-ndss-2020">Not All Coverage Measurements Are Equal: Fuzzing by Coverage Accounting for Input Prioritization</a></li>
    </ul>
  </li>
  <li><strong>S&amp;P 2020</strong>
    <ul>
      <li><a href="#savior-towards-bug-driven-hybrid-testing-sp-2020">SAVIOR: Towards Bug-Driven Hybrid Testing</a></li>
      <li><a href="#retrowrite-statically-instrumenting-cots-binaries-for-fuzzing-and-sanitization-sp-2020">RetroWrite: Statically Instrumenting COTS Binaries for Fuzzing and Sanitization</a></li>
      <li><a href="#ijon-exploring-deep-state-spaces-via-fuzzing-sp-2020">IJON: Exploring Deep State Spaces via Fuzzing</a></li>
      <li><a href="#pangolin-incremental-hybrid-fuzzing-with-polyhedral-path-abstraction-sp-2020">PANGOLIN: Incremental Hybrid Fuzzing with Polyhedral Path Abstraction</a></li>
      <li><a href="#krace-data-race-fuzzing-for-kernel-file-systems-sp-2020">KRace: Data Race Fuzzing for Kernel File Systems</a></li>
      <li><a href="#fuzzing-javascript-engines-with-aspect-preserving-mutation-sp-2020">Fuzzing JavaScript Engines with Aspect-preserving Mutation</a></li>
    </ul>
  </li>
  <li><strong>SANER 2020</strong>
    <ul>
      <li><a href="#ethploit-from-fuzzing-to-efficient-exploit-generation-against-smart-contracts-saner2020">ETHPLOIT: From Fuzzing to Efficient Exploit Generation against Smart Contracts</a></li>
      <li><a href="#sequence-directed-hybrid-fuzzing-saner-2020">Sequence directed hybrid fuzzing</a></li>
    </ul>
  </li>
  <li><strong>ICST 2020</strong>
    <ul>
      <li><a href="#language-agnostic-generation-of-compilable-test-programs-icst-2020">Language-Agnostic Generation of Compilable Test Programs</a></li>
      <li><a href="#ct-fuzz-fuzzing-for-timing-leaks-icst-2020">ct-fuzz: Fuzzing for Timing Leaks</a></li>
      <li><a href="#aflnet-a-greybox-fuzzer-for-network-protocols-icst-2020">AFLNET: A Greybox Fuzzer for Network Protocols</a></li>
    </ul>
  </li>
  <li><strong>ASIACCS 2020</strong>
    <ul>
      <li><a href="#pathafl-path-coverage-assisted-fuzzing-asia-ccs-2020">PathAFL: Path-Coverage Assisted Fuzzing</a></li>
    </ul>
  </li>
  <li><strong>Others 2020</strong>
    <ul>
      <li><a href="#csefuzz-fuzz-testing-based-on-symbolic-execution-access-2020">CSEFuzz: Fuzz Testing Based on Symbolic Execution (Access 2020)</a></li>
      <li><a href="#a-quantitative-comparison-of-covera-ast-2020">A Quantitative Comparison of Covera (AST 2020)</a></li>
      <li><a href="#finding-bugs-in-file-systems-with-an-extensible-fuzzing-framework-tos-2020">Finding Bugs in File Systems with an Extensible Fuzzing Framework (TOS 2020)</a></li>
      <li><a href="#ics-protocol-fuzzing-coverage-guided-packet-crack-and-generation-dac-2020">ICS Protocol Fuzzing: Coverage Guided Packet Crack and Generation (DAC 2020)</a></li>
      <li><a href="#finding-security-vulnerabilities-in-network-protocol-implementations-arxiv-2020">Finding Security Vulnerabilities in Network Protocol Implementations (Arxiv 2020)</a></li>
      <li><a href="#coverage-guided-differential-adversarial-testing-of-deep-learning-systems-tnse-2020">Coverage Guided Differential Adversarial Testing of Deep Learning Systems</a></li>
      <li><a href="#fw%e2%80%90fuzz-a-code-coverage%e2%80%90guided-fuzzing-framework-for-network-protocols-on-firmware-2020">Fw‐fuzz: A code coverage‐guided fuzzing framework for network protocols on firmware</a></li>
      <li><a href="#greybox-fuzzing-based-on-ant-colony-algorithm-aina-2020">Greybox Fuzzing Based on Ant Colony Algorithm</a></li>
      <li><a href="#meuzz-smart-seed-scheduling-for-hybrid-fuzzing">MEUZZ: Smart Seed Scheduling for Hybrid Fuzzing</a></li>
      <li><a href="#binary-level-directed-fuzzing-for-use-after-free-vulnerabilities-raid-2020">Binary-level Directed Fuzzing for Use-After-Free Vulnerabilities</a></li>
      <li><a href="#smart-seed-selection-based-effective-black-box-fuzzing-for-iiot-protocol">Smart seed selection-based effective black box fuzzing for IIoT protocol</a></li>
      <li><a href="#rdfuzz-accelerating-directed-fuzzing-with-intertwined-schedule-and-optimized-mutation-2020">RDFuzz: Accelerating Directed Fuzzing with Intertwined Schedule and Optimized Mutation</a></li>
      <li><a href="#a-deep-convolution-generative-adversarial-networks-based-fuzzing-framework-for-industry-control-protocols">A deep convolution generative adversarial networks based fuzzing framework for industry control protocols</a></li>
      <li><a href="#tofu-target-oriented-fuzzer-arxiv-2020">TOFU: Target-Oriented FUzzer</a></li>
      <li><a href="#basesafe-baseband-sanitized-fuzzing-through-emulation-wisec-2020">BaseSAFE: Baseband SAnitized Fuzzing through Emulation</a></li>
    </ul>
  </li>
  <li><strong>ACSAC 2019</strong>
    <ul>
      <li><a href="#Opening-Pandoras-Box-through-ATFuzzer-Dynamic-Analysis-of-AT-Interface-for-Android-Smartphones-ACSAC-2019">Opening Pandora’s Box through ATFuzzer: Dynamic Analysis of AT Interface for AndroidSmartphones</a></li>
    </ul>
  </li>
  <li><strong>OOPSLA 2019</strong>
    <ul>
      <li><a href="#fuzzfactory-domain-specific-fuzzing-with-waypoints-oopsla-2019">FuzzFactory: Domain-Specific Fuzzing with Waypoints</a></li>
      <li><a href="#compiler-fuzzing-how-much-does-it-matter-oopsla2019">Compiler Fuzzing: How Much Does It Matter</a></li>
    </ul>
  </li>
  <li><strong>TSE 2019</strong>
    <ul>
      <li><a href="#the-art-science-and-engineering-of-fuzzing-a-survey">The Art, Science, and Engineering of Fuzzing: A Survey</a></li>
      <li><a href="#smart-greybox-fuzzing-tse-2019">Smart Greybox Fuzzing</a></li>
    </ul>
  </li>
  <li><strong>Access 2019</strong>
    <ul>
      <li><a href="#neufuzz-efficient-fuzzing-with-deep-neural-network-access-2019">NeuFuzz: Efficient Fuzzing With Deep Neural Network</a></li>
      <li><a href="#learnafl-greybox-fuzzing-with-knowledge-enhancement-access-2019">LearnAFL: Greybox Fuzzing With Knowledge Enhancement</a></li>
    </ul>
  </li>
  <li><strong>CCS 2019</strong>
    <ul>
      <li><a href="#intriguer-field-level-constraint-solving-for-hybrid-fuzzing-ccs-2019">Intriguer: Field-Level Constraint Solving for Hybrid Fuzzing</a></li>
      <li><a href="#learning-to-fuzz-from-symbolic-execution-with-application-to-smart-contracts-ccs-2019">Learning to Fuzz from Symbolic Execution with Application to Smart Contracts</a></li>
      <li><a href="#matryoshka-fuzzing-deeply-nested-branches-ccs-2019">Matryoshka: fuzzing deeply nested branches</a></li>
      <li><a href="#different-is-good-detecting-the-use-of-uninitialized-variables-through-differential-replay-ccs-2019">Different is Good: Detecting the Use of Uninitialized Variables through Differential Replay</a></li>
      <li><a href="#gollum-modular-and-greybox-exploit-generation-for-heap-overflows-in-interpreters-ccs-2019">Gollum: Modular and Greybox Exploit Generation for Heap Overflows in Interpreters</a></li>
      <li><a href="#poster-fuzzing-iot-firmware-via-multi-stage-message-generation-ccs-2019">Poster: Fuzzing IoT Firmware via Multi-stage Message Generation</a></li>
    </ul>
  </li>
  <li><strong>S&amp;P 2019</strong>
    <ul>
      <li><a href="#neuzz-efficient-fuzzing-with-neural-program-smoothing-sp-2019">NEUZZ: Efficient Fuzzing with Neural Program Smoothing</a></li>
      <li><a href="#fuzzing-file-systems-via-two-dimensional-input-space-exploration-sp-2019">Fuzzing File Systems via Two-Dimensional Input Space Exploration</a></li>
      <li><a href="#profuzzer-on-the-fly-input-type-probing-for-better-zero-day-vulnerability-discovery-sp-2019">ProFuzzer: On-the-fly Input Type Probing for Better Zero-day Vulnerability Discovery</a></li>
      <li><a href="#razzer-finding-kernel-race-bugs-through-fuzzing-sp-2019">Razzer: Finding Kernel Race Bugs through Fuzzing</a></li>
      <li><a href="#full-speed-fuzzing-reducing-fuzzing-overhead-through-coverage-guided-tracing-sp-2019">Full-speed Fuzzing: Reducing Fuzzing Overhead through Coverage-guided Tracing</a></li>
    </ul>
  </li>
  <li><strong>USENIX Security 2019</strong>
    <ul>
      <li><a href="#mopt-optimize-mutation-scheduling-for-fuzzers-usenix-security2019">MOPT: Optimize Mutation Scheduling for Fuzzers</a></li>
      <li><a href="#antifuzz-impeding-fuzzing-audits-of-binary-executables-usenix-security2019">Antifuzz: impeding fuzzing audits of binary executables</a></li>
      <li><a href="#fuzzification-anti-fuzzing-technique-usenix-security2019">FUZZIFICATION: Anti-Fuzzing Technique</a></li>
      <li><a href="#enfuzz-ensemble-fuzzing-with-seed-synchronization-among-diverse-fuzzers-usenix-security2019">EnFuzz: Ensemble Fuzzing with Seed Synchronization among Diverse Fuzzers</a></li>
      <li><a href="#grimoire-synthesizing-structure-while-fuzzing-usenix-security2019">GRIMOIRE : Synthesizing Structure while Fuzzing</a></li>
      <li><a href="#rvfuzzer-finding-input-validation-bugs-in-robotic-vehicles-through-control-guided-random-testing-usenix-security2019">RVFuzzer: Finding Input Validation Bugs in Robotic Vehicles through Control-Guided Random Testing</a></li>
      <li><a href="#firm-afl-high-throughput-greybox-fuzzing-of-iot-firmware-via-augmented-process-emulation-usenix-security2019">FIRM-AFL: High-Throughput Greybox Fuzzing of IoT Firmware via Augmented Process Emulation</a></li>
      <li><a href="#unicorefuzz-on-the-viability-of-emulation-for-kernelspace-fuzzing-usenix-woot19">Unicorefuzz: On the Viability of Emulation for Kernelspace Fuzzing</a></li>
    </ul>
  </li>
  <li><strong>ASE 2019</strong>
    <ul>
      <li><a href="#learning-guided-network-fuzzing-for-testing-cyber-physical-system-defences-ase-2019">Learning-Guided Network Fuzzing for Testing Cyber-Physical System Defences</a></li>
    </ul>
  </li>
  <li><strong>NDSS 2019</strong>
    <ul>
      <li><a href="#redqueen-fuzzing-with-input-to-state-correspondence-ndss2019">REDQUEEN: Fuzzing with Input-to-State Correspondence</a></li>
      <li><a href="#periscope-an-effective-probing-and-fuzzing-framework-for-the-hardware-os-boundary-ndss2019">PeriScope: An Effective Probing and Fuzzing Framework for the Hardware-OS Boundary</a></li>
      <li><a href="#life-after-speech-recognition-fuzzing-semantic-misinterpretation-for-voice-assistant-applications-ndss-2019">Life after Speech Recognition: Fuzzing Semantic Misinterpretation for Voice Assistant Applications</a></li>
      <li><a href="#send-hardest-problems-my-way-probabilistic-path-prioritization-for-hybrid-fuzzing-ndss-2019">Send Hardest Problems My Way: Probabilistic Path Prioritization for Hybrid Fuzzing</a></li>
      <li><a href="#codealchemist-semantics-aware-code-generation-to-find-vulnerabilities-in-javascript-engines-ndss-2019">CodeAlchemist: Semantics-Aware Code Generation to Find Vulnerabilities in JavaScript Engines</a></li>
      <li><a href="#nautilus-fishing-for-deep-bugs-with-grammars-ndss-2019">NAUTILUS: Fishing for Deep Bugs with Grammars</a></li>
    </ul>
  </li>
  <li><strong>ICSE 2019</strong>
    <ul>
      <li><a href="#diffuzz-differential-fuzzing-for-side-channel-analysis-icse-2019">DifFuzz: Differential Fuzzing for Side-Channel Analysis</a></li>
      <li><a href="#deep-differential-testing-of-jvm-implementations-icse-2019">Deep Differential Testing of JVM Implementations</a></li>
      <li><a href="#rest-ler-stateful-rest-api-fuzzing-icse-2019">REST-ler: Stateful REST API Fuzzing</a></li>
      <li><a href="#slf-fuzzing-without-valid-seed-inputs-icse-2019">SLF: Fuzzing without Valid Seed Inputs</a></li>
      <li><a href="#superion-grammar-aware-greybox-fuzzing-icse-2019">Superion: Grammar-Aware Greybox Fuzzing</a></li>
      <li><a href="#hunting-for-bugs-in-code-coverage-tools-via-randomized-differential-testing-icse-2019">Hunting for bugs in code coverage tools via randomized differential testing</a></li>
    </ul>
  </li>
  <li><strong>FSE 2019</strong>
    <ul>
      <li><a href="#cerebro-context-aware-adaptive-fuzzing-for-effective-vulnerability-detection-fse-2019">Cerebro: Context-aware Adaptive Fuzzing for Effective Vulnerability Detection</a></li>
      <li><a href="#just-fuzz-it-solving-floating-point-constraints-using-coverage-guided-fuzzing-fse-2019">Just Fuzz It: Solving Floating-Point Constraints Using Coverage-guided Fuzzing</a></li>
      <li><a href="#fudge-fuzz-driver-generation-at-scale-fse-2019">FUDGE: Fuzz Driver Generation at Scale</a></li>
    </ul>
  </li>
  <li><strong>ISSTA 2019</strong>
    <ul>
      <li><a href="#semantic-fuzzing-with-zest-issta-2019">Semantic Fuzzing with Zest</a></li>
      <li><a href="#deephunter-a-coverage-guided-fuzz-testing-framework-for-deep-neural-networks-issta-2019">DeepHunter: A Coverage-Guided Fuzz Testing Framework for Deep Neural Networks</a></li>
      <li><a href="#deferred-concretization-in-symbolic-execution-via-fuzzing-issta-2019">Deferred Concretization in Symbolic Execution via Fuzzing</a></li>
    </ul>
  </li>
  <li><strong>PLDI 2019</strong>
    <ul>
      <li><a href="#parser-directed-fuzzing-pldi-2019">Parser-Directed Fuzzing</a></li>
    </ul>
  </li>
  <li><strong>ASIACCS 2019</strong>
    <ul>
      <li><a href="#ptrix-efficient-hardware-assisted-fuzzing-for-cots-binary-asiaccs-2019">Ptrix: Efficient Hardware-Assisted Fuzzing for COTS Binary</a></li>
      <li><a href="#a-feature-oriented-corpus-for-understanding-evaluating-and-improving-fuzz-testing-asiaccs-2019">A Feature-Oriented Corpus for understanding, Evaluating and Improving Fuzz Testing</a></li>
    </ul>
  </li>
  <li><strong>ICST 2019</strong>
    <ul>
      <li><a href="#memfuzz-using-memory-accesses-to-guide-fuzzing-icst-2019">MemFuzz: Using Memory Accesses to Guide Fuzzing</a></li>
      <li><a href="#seqfuzzer-an-industrial-protocol-fuzzing-framework-in-deep-learning-perspective-icst-2019">SeqFuzzer: An Industrial Protocol Fuzzing Framework in Deep Learning Perspective</a></li>
    </ul>
  </li>
  <li><strong>Other 2019</strong>
    <ul>
      <li><a href="#leveraging-textual-specifications-for-grammar-based-fuzzing-of-network-protocols-aaai-2019">Leveraging Textual Specifications for Grammar-Based Fuzzing of Network Protocols (AAAI 2019)</a></li>
      <li><a href="#deepfuzzer-accelerated-deep-greybox-fuzzing-tdsc-2019">DeepFuzzer: Accelerated Deep Greybox Fuzzing (TDSC 2019)</a></li>
      <li><a href="#cagfuzz-coverage-guided-adversarial-generative-fuzzing-testing-of-deep-learning-systems-2019">CAGFuzz: Coverage-Guided Adversarial Generative Fuzzing Testing of Deep Learning Systems</a></li>
      <li><a href="#suzzer-a-vulnerability-guided-fuzzer-based-on-deep-learning-inscrypt-2019">Suzzer: A Vulnerability-Guided Fuzzer Based on Deep Learning</a></li>
      <li><a href="#confuzz-a-concurrency-fuzzer-2019">ConFuz: A Concurrency Fuzzer</a></li>
      <li><a href="#instrcr-lightweight-instrumentation-optimization-based-on-coverage-guided-fuzz-testing-ccet-2019">INSTRCR: Lightweight instrumentation optimization based on coverage-guided fuzz testing</a></li>
      <li><a href="#hfuzz-towards-automatic-fuzzing-testing-of-nb-iot-core-network-protocols-implementations-fgcs-2019">HFuzz: Towards automatic fuzzing testing of NB-IoT core network protocols implementations</a></li>
      <li><a href="#study-and-comparison-of-general-purpose-fuzzers">Study and Comparison of General Purpose Fuzzers</a></li>
      <li><a href="#from-proof-of-concept-to-exploitable-cybersecurity-2019">From proof-of-concept to exploitable</a></li>
      <li><a href="#sequence-coverage-directed-greybox-fuzzing-icpc-2019">Sequence coverage directed greybox fuzzing</a></li>
      <li><a href="#field-aware-evolutionary-fuzzing-based-on-input-specifications-and-vulnerability-metrics-2019">Field-aware Evolutionary Fuzzing Based on Input Specifications and Vulnerability Metrics</a></li>
      <li><a href="#fuzzing-ipc-with-knowledge-inference-srds-2019">Fuzzing IPC with Knowledge Inference</a></li>
      <li><a href="#be-sensitive-and-collaborative-analyzing-impact-of-coverage-metrics-in-greybox-fuzzing-raid-2019">Be Sensitive and Collaborative: Analyzing Impact of Coverage Metrics in Greybox Fuzzing</a></li>
      <li><a href="#hydra-an-extensible-fuzzing-framework-for-finding-semantic-bugs-in-file-systems-sosp-2019">Hydra: An Extensible Fuzzing Framework for Finding Semantic Bugs in File Systems</a></li>
      <li><a href="#exploring-effective-fuzzing-strategies-to-analyze-communication-protocols-feast-2019">Exp…</a></li></ul></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wcventure.github.io/FuzzingPaper/">https://wcventure.github.io/FuzzingPaper/</a></em></p>]]>
            </description>
            <link>https://wcventure.github.io/FuzzingPaper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395122</guid>
            <pubDate>Sat, 12 Dec 2020 03:21:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code Reviews Not Code Approvals]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25394597">thread link</a>) | @aard
<br/>
December 11, 2020 | http://adamard.com/code_reviews.html | <a href="https://web.archive.org/web/*/http://adamard.com/code_reviews.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>{<br>&nbsp;&nbsp;&nbsp;&nbsp;Adam Ard<br>}</h2><br>
  <h2>Code Reviews Not Code Approvals</h2>
  <p>In our brave new world of remote work, asynchronous methods of
 collaboration are especially important. When you are working in
 different locations, perhaps on different schedules, you need
 communication mediums that allow you to send a message and go on to
 something else. When someone on the other end of that message finds
 time, they will respond and quickly go on with <em>their</em> own
 work. No one is blocked. The alternative would be
 intolerable. Waiting for responses that may not come for hours, or
 even days, before continuing your work would be a colossal waste of
 time. And being forced to stop whatever activity you are engaged in
 to immediately respond to incoming requests, all to avoid making
 someone wait, is equally problematic.</p><p>While there are times
 when you need information quickly and are truly blocked, if this is
 common, there are likely issues with how your project is being
 managed. Is your manager feeding you tasks, one after another,
 without giving necessary high-level direction? Is your engineering
 organization failing to collect on-boarding information into
 documentation that is available for reference when you get stuck?
 Whatever the reason, it is clear that people need the ability to work
 independently without having to continuously ask for
 guidance.</p><p>But assuming you are able to code independently most
 of the time and have good asynchronous ways to communicate with
 coworkers, there is still the issue of code reviews. If you really
 want to stick with an asynchronous working paradigm, then code
 reviews are totally backwards. When a piece of code is ready to
 deploy, it always gets stuck waiting for a code review. Progress
 comes to a screeching halt. Isn’t this a synchronous wait? Blocking
 the pipeline with a manual approval step? You may wait for days
 before someone can look it over. Sure you can work on some other
 project, but context switching is expensive. And when you are pushing
 forward with momentum on your highest priority item being stopped for
 a code review is about as wasteful as it gets. Efficiency experts
 shed tears over this kind of stuff. Even assuming that you could move
 forward on a secondary project, what happens when you finish another
 task and the first project’s task still hasn’t been approved? Do you
 work on a third project? At some point the madness must
 stop.</p><p>The real problem here is that code reviews are really
 not <em>reviews</em> at all. The word r<em>eview</em> implies that
 something has been completed, and you are just looking it
 over — after the fact. What we do now should be called a code
 approval. Something is almost done (your scrum master will be quick
 to point out that nothing is ‘done’ until it is in production), and
 someone needs to check a box so it can move to completion. It is held
 up because it is hitting against a gatekeeper. If it were truly
 a <em>review</em>, you could have pushed it up and been on your
 way. But instead, you are waiting for permission. You’re stopped,
 sitting on the side of the road, watching while your competitors run
 by.</p><p>In an ideal world, you could deploy and then someone would
 immediately get a notification that there was new stuff to look
 at. Then, when they had a chance, when their brain wasn’t deep in
 another problem, they could look over it. In the meantime you can
 make progress on your next item.</p><p>I am aware that this would
 give some managers heartburn, but it needn’t. If something is broken
 in code that goes live, it can be fixed in a future commit (that will
 go up nice and quick since it doesn’t have to sit waiting for a
 review). If it is a serious issue, hopefully a basic smoke test would
 catch it and automatically roll it back. Truthfully, I would trust a
 test suite to catch a problem more than a human reviewer
 anyway. Wouldn’t time spent on reviews be better spent building more
 comprehensive tests anyway?</p><p>Have I convinced you? Are you
 ready to start doing actual code reviews and leave code approvals to
 the birds?</p></div></div>]]>
            </description>
            <link>http://adamard.com/code_reviews.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25394597</guid>
            <pubDate>Sat, 12 Dec 2020 02:04:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rizin]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25394254">thread link</a>) | @todsacerdoti
<br/>
December 11, 2020 | https://rizin.re/posts/announcing-rizin/ | <a href="https://web.archive.org/web/*/https://rizin.re/posts/announcing-rizin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>We are excited to announce Rizin — a <strong>free</strong> and <strong>open-source</strong> Reverse Engineering framework, providing a complete binary analysis experience with features like Disassembler, Hexadecimal editor, Emulation, Binary inspection, Debugger, and more.</p><p>Rizin is a fork of radare2 with a focus on usability, stability, and working features, which strives to provide a welcoming environment for developers and users alike. Rizin was founded by a group of the core developers of radare2 and Cutter who contributed to the project in one way or the other in the past years and together constructed the Core group of radare2. With the establishment of Rizin, we are committed to creating an environment and a project which will be aligned with our values and vision.</p><p>During recent years, the environment that was created in radare2 was one where many of us felt stressed, disrespected, and unwelcome. Moreover, the number of users of radare2 grew every year, and we held the ultimate responsibility to provide them a stable, usable framework. As the core developer team, we have come to the conclusion that it is impossible for us to continue to pursue the goal of making radare2 better under the current circumstances and environment, and we decided to move forward on our own and fork the project. Cutter, the Graphical User Interface for radare2, and its entire team will also join Rizin and will use it as its backend.</p><p>Rizin is a newborn project that was created from radare2, hence more and more changes and differences will appear over time. A lot of efforts were put into improving our workflows, putting more tests in place, improving the API, removing redundant features, and more. We hope to provide better consistency between releases, making the framework more trustworthy to users.</p><p>We are also working to create a more inclusive and diverse community that will be inviting for new contributors and users. As an initial step, we adopted a <a href="https://rizin.re/code-of-conduct">Code of Conduct</a> that we believe is aligned with our values and with the community we want to create around Rizin.</p><p>Finally, we know and understand that now it is our turn to prove that Rizin can become a tool you can trust and enjoy using, and a community in which you feel welcome. We invite you to read our answers to your <a href="https://rizin.re/posts/faq/">Frequently Asked Questions</a> and join our communities on <a href="https://im.rizin.re/">Mattermost</a> and other chat platforms.</p></div></article></div></div>]]>
            </description>
            <link>https://rizin.re/posts/announcing-rizin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25394254</guid>
            <pubDate>Sat, 12 Dec 2020 01:24:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launching an open start up Interviewing SaaS Business Owners]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25394221">thread link</a>) | @hustld
<br/>
December 11, 2020 | https://hustld.com/blog/launching-an-open-start-up-journey | <a href="https://web.archive.org/web/*/https://hustld.com/blog/launching-an-open-start-up-journey">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
          
<p>This is the date that I, <a href="https://twitter.com/itsdevdaniel" target="_blank" rel="noopener">Daniel Lasek</a>, have launched Hustld. It's meant to be a community of business owners (specifically SaaS owners) who tell their story on how they got started. My goal was to target individuals who want to create their own companies and who might require guidence or inspiration from other entrepreneurs.&nbsp; I only got 5 interviews and soon after I decided I wanted to work on other projects. I closed down the server and stopped the site.</p>

<p>Here we are today. I remembered that I had purchased a server for a year on AWS and enjoyed when users visited Hustld to read business interviews. In addition I want to log my journey of Hustld and how I plan to grow it. I am turning Hustld into an "<a href="https://hackernoon.com/what-does-it-mean-to-be-an-open-startup-f4446984189" target="_blank" rel="noopener">open start up</a>". I will share all my progress on my twitter (<a href="https://twitter.com/itsdevdaniel">@itsdevdaniel</a>) and write blogs on here. As of right now the site is not monetized in anyway but I do plan do add some sponsored posts, subscription and cool features in the future! My primary goal as of now isn't MRR (Monthly Reccuring Revenue) it is the # of interviews I can get per month. I am hoping to get at least 5 interviews before 2021 and 10 interviews in January 2021.</p>
<div><p>If you are a business owner (Saas preferred) and would like me to interview you <a href="https://hustld.com/contact">send me a message</a>.</p></div>

<p>5 New Interviews</p>
          
        </div></div>]]>
            </description>
            <link>https://hustld.com/blog/launching-an-open-start-up-journey</link>
            <guid isPermaLink="false">hacker-news-small-sites-25394221</guid>
            <pubDate>Sat, 12 Dec 2020 01:19:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most important metric in commercial real estate is outdated and inaccurate]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25394187">thread link</a>) | @rcvictorino
<br/>
December 11, 2020 | https://www.density.io/blog/the-most-important-metric-in-corporate-real-estate | <a href="https://web.archive.org/web/*/https://www.density.io/blog/the-most-important-metric-in-corporate-real-estate">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="blogContent"><p>Commercial real estate is regularly measured by the key metric: square feet per person.</p><p>The average square footage per U.S. office worker has been steadily declining as real estate costs rise and open offices are replacing private offices and cubicles.</p><p>In 2010, companies averaged 225 square feet per employee. By 2017, that average was 151 sq ft. Numbers for collaborative spaces are even smaller, as little as 60 to 80 square feet per person.</p><p><em>Tip: If you're in the market for commercial real estate, remember to add up to 20% to your immediate square footage requirements. This will address any future growth your company realizes (saving you from having to terminate a lease early, which is costly).</em></p><h2>Why the square footage calculation is outdated</h2><p>Square foot per employee is calculated with a simple equation: the usable square feet of space a company leases or owns divided by the number of employees assigned to each respective space: X square feet divided by Y employees.</p><p>Companies assign certain employees to the buildings, floors, or areas where their teams work. The more senior an employee, the more square feet they're (usually) designated.</p><p>For decades, this approach seemed to accurately measure the average space employees use (and need).</p><p>The problem is, the modern workforce is far more dynamic than in the past.</p><p>Employees from the same teams work remotely and collaborate across departments. Many employees don't come into the office every day — if they come into the office at all.</p><p>Some employees are on their feet, spending their days in and out of various buildings connecting with teams across the organization. Others are visiting clients and tracking down sales prospects in the field.</p><p>None of these use cases are predictable. The average office employee's work schedule (and habits) look far more flexible today than ever before.</p><p>A simple calculation no longer suffices.</p><blockquote>What happens to the 'X square feet divided by Y employees' rule of thumb? The whole equation breaks down.</blockquote><p>Inconsistent attendance and changing work patterns destroy the old method of calculating square feet per employee. No wonder <strong>40% percent of global corporate real estate sits empty</strong>. This underutilization of office space is due in part to the rapidly changing way we work in offices.</p><p>It's also a result of inefficient and inexact approaches to how we calculate commercial space requirements.</p><h2>Using data — not guesswork — to calculate space needs</h2><p>Knowing how space is <em>actually</em> used can help you maximize your real estate portfolio and revolutionize your approach to office design.</p><p>Innovative workplace strategists use Density's historical and real-time data to analyze exactly how much — and what kind of — space each employee needs.</p><p>With data from Density, companies realize more value from their existing real estate portfolio, know when new office space is needed, and increase employee productivity and happiness.</p><p>Below are two examples.</p><h3>Calculating how much space is actually used in a Fortune 1000 company</h3><p>One of our Fortune 1000 clients operates nearly 288,440 sq ft of real estate and employs 1,800 people. When using the traditional calculation, they concluded that they allotted an average of 160 sq ft per employee.</p><p>That's in line with overall market trends.</p><p>However, they weren't satisfied with the guesswork approach of this calculation. So, they installed our occupancy sensors to get a data-backed measure of the <em>actual</em> amount of space used by their employees.</p><p>With Density, they realized the average square foot per employee was actually 603 sq ft (a difference of more than 150 sq ft per employee).</p><p>Our space utilization analytics revealed that only during brief peak times did the average square foot per employee drop to 310.</p><figure id="w-node-0a1e36a0e908-665b10f0"><p><img src="https://assets-global.website-files.com/5f4a004f01308268d80d6e85/5f73bf74c54ecea943068991_sqft-chart-2-1024x336.jpeg" alt="Measuring accurate space allocation in commercial real estate"></p></figure><p>Even then, the number was still 100% higher than their initial build-out. Using this data, our client was able to redesign their floor plan and optimize their existing space.</p><h3>Measuring true space allocation in a tech startup</h3><p>A startup company used Density to measure space allocation across its different teams. The teams were predominantly distributed by different floors ranging from 32,523 sq ft to 43,822 sq ft. Our data revealed that the company's sales team was inadvertently allocating 1,056 sq ft per employee while the engineering team was allotted 391 sq ft per employee.</p><figure id="w-node-15458921f292-665b10f0"><p><img src="https://assets-global.website-files.com/5f4a004f01308268d80d6e85/5f73bf74975b99ab9de1b991_ckeGmx22jjp0yQqZE5jwENlhtZ5Ay35WBctQ6o5RZSI_Wrso0-YgorPsltS9czcMhMc3-ZwwGyGH3rUgbdgLvFaK9evovYKqByCJda4l3hDfVFPgr2maS5VwAK6Mq5ieadyUyP7t.png" alt="Square Feet Per Person Metrics Separated by Team in Density's Dashboard"></p></figure><p>This discrepancy in the amount of office space used across teams can hinder workplace productivity.</p><p>An engineer testing product quality may need to take up more than the assigned sq ft allotted to her role.</p><p>Meanwhile, a salesperson may regularly take meetings in phone booths, conference rooms, or even offsite locations like restaurants or co-working spaces — meaning they may need less space than is allotted to them.</p><p>Our data helped our client make changes to their office layout to ensure a more evenly (and flexible) approach to space allocation.</p><h2>The power of people count</h2><p>Workplace managers use Density to make safer, more cost-effective decisions about their space. Our sensors gather real-time, accurate data about how employees use space, giving you the power to design and build based on data — not guesswork.</p><p><strong>What to read next</strong>: <a href="https://www.density.io/blog/what-is-space-utilization-analytics"><em>Using space utilization data to optimize your workspace (with examples)</em></a><em>.</em></p><p>‍</p></div></div></div>]]>
            </description>
            <link>https://www.density.io/blog/the-most-important-metric-in-corporate-real-estate</link>
            <guid isPermaLink="false">hacker-news-small-sites-25394187</guid>
            <pubDate>Sat, 12 Dec 2020 01:16:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principle of Maximum Entropy]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25394064">thread link</a>) | @keyboardman
<br/>
December 11, 2020 | https://leimao.github.io/blog/Maximum-Entropy/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Maximum-Entropy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>The principle of maximum entropy states that the probability distribution which best represents the current state of knowledge is the one with largest entropy, in the context of precisely stated prior data (such as a proposition that expresses testable information). These prior data serves as the constrains to the probability distribution.</p>



<p>Given the second law of thermodynamics (principle of increase of entropy), isolated systems spontaneously evolve towards thermodynamic equilibrium, the state with maximum entropy, maximum entropy distributions become the most natural distributions under certain constrains. In this blog post, I would like to discuss entropy maximization and a couple of maximum entropy distributions.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="gaussian-integral">Gaussian Integral</h4><p>

\[\begin{align}
\int_{-\infty}^{\infty} e^{-x^2} dx = \sqrt{\pi} \\
\end{align}\]

</p><p>I will skip the proof here, since the proof from <a href="https://en.wikipedia.org/wiki/Gaussian_integral">Wikipedia</a> is not that difficult to understand.</p>

<h4 id="useful-integrals">Useful Integrals</h4><p>

\[\begin{align}
\int_{-\infty}^{\infty} x e^{-x^2} dx &amp;= -\frac{1}{2} \int_{-\infty}^{\infty} e^{-x^2} d(-x^2) \\
&amp;= -\frac{1}{2} e^{-x^2} \big\rvert_{-\infty}^{\infty}\\
&amp;= 0 \\
\end{align}\]

\[\begin{align}
\int_{-\infty}^{\infty} x^2 e^{-x^2} dx &amp;= -\frac{1}{2} \int_{-\infty}^{\infty} x d (e^{-x^2}) \\
&amp;= -\frac{1}{2} \Big( x e^{-x^2} \big\rvert_{-\infty}^{\infty} - \int_{-\infty}^{\infty} e^{-x^2} dx \Big) \\
&amp;= -\frac{1}{2} \Big( 0 - \sqrt{\pi} \Big) \\
&amp;= \frac{\sqrt{\pi}}{2} \\
\end{align}\]

</p><p>Notice that here we used integral by parts.</p>

<h3 id="entropy-maximization">Entropy Maximization</h3>

<h4 id="discrete-probability-distribution">Discrete Probability Distribution</h4>

<p>Suppose $P$ is a discrete probability distribution. The entropy is defined as</p><p>

\[\begin{align}
H(P) &amp;= - \sum_{x \in X}^{} P(x) \log P(x) \\
\end{align}\]

</p><p>We further have some constrains on $P$:</p>

<ul>
  <li>$P(x) \geq 0$</li>
  <li>$\sum_{x \in X}^{} P(x) = 1$</li>
  <li>$\sum_{x \in X}^{} P(x) r_i(x) = \alpha_i$ for $1 \leq i \leq m$</li>
</ul>

<p>The first two constrains are trivial given $P$ is a probability distribution. The third constrain is optional and it indicates a constrain on the entire system. Notice that there could be more than one constrain if $m &gt; 1$.</p>



<p>We would like to maximize the entropy.</p><p>

\[\max_{P} H(P) = \max_{P} \Big( - \sum_{x \in X}^{} P(x) \log P(x) \Big)\]

</p><p>Letâ€™s try to solve this optimization problem. We would use Lagrange multiplier for the constrains.</p><p>

\[\begin{align}
L(P, \lambda_0, \lambda_1, \cdots, \lambda_m) &amp;= - \sum_{x \in X}^{} P(x) \log P(x) + \lambda_0 \Big(\sum_{x \in X}^{} P(x) - 1 \Big) + \sum_{i=1}^{m} \lambda_i \sum_{x \in X}^{} \Big(P(x) r_i(x) - \alpha_i \Big) \\
\end{align}\]

</p><p>We take the derivative of $L(P, \lambda_0, \lambda_1, \cdots, \lambda_m)$ with respect to $P(x)$ and the derivative should be $0$.</p><p>

\[\begin{align}
\frac{\partial}{\partial P(x)} L(P, \lambda_0, \lambda_1, \cdots, \lambda_m) &amp;= - \log P(x) - 1 + \lambda_0 + \sum_{i=1}^{m} \lambda_i r_i(x) \\
&amp;= 0 \\
\end{align}\]

</p><p>Therefore,</p><p>

\[\begin{align}
P(x) &amp;= e^{\big(\sum_{i=1}^{m} \lambda_i r_i(x)\big) + \lambda_0 - 1 } \\
&amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{e^{1 - \lambda_0}} \\
\end{align}\]

</p><p>Because $\sum_{x \in X}^{} P(x) = 1$,</p><p>

\[\begin{align}
\sum_{x \in X}^{} P(x) &amp;= \sum_{x \in X}^{} e^{\big(\sum_{i=1}^{m} \lambda_i r_i(x)\big) + \lambda_0 - 1 } \\
&amp;= e^{\lambda_0 - 1} \sum_{x \in X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} \\
&amp;= 1 \\
\end{align}\]

</p><p>Therefore,</p><p>

\[e^{1 - \lambda_0} = \sum_{x \in X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)}\]

</p><p>With this, we could rewrite $P(x)$ as</p><p>

\[\begin{align}
P(x) &amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{ \sum_{x \in X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} } \\
\end{align}\]

</p><h4 id="continuous-probability-distribution">Continuous Probability Distribution</h4>

<p>Similarly, suppose $P$ is a continuous probability distribution. The entropy is defined as</p><p>

\[\begin{align}
H(P) &amp;= - \int_{X}^{} P(x) \log P(x) dx \\
\end{align}\]

</p><p>With the following constrains</p>

<ul>
  <li>$P(x) \geq 0$</li>
  <li>$\int_{X}^{} P(x) dx = 1$</li>
  <li>$\int_{X}^{} P(x) r_i(x) dx = \alpha_i$ for $1 \leq i \leq m$</li>
</ul>

<p>Similarly, to maximize the entropy, we maximize the Lagrangian for the continuous case.</p><p>

\[\begin{align}
L(P, \lambda_0, \lambda_1, \cdots, \lambda_m) &amp;= - \int_{X}^{} P(x) \log P(x) dx + \lambda_0 \Big(\int_{X}^{} P(x)  dx - 1 \Big) + \sum_{i=1}^{m} \lambda_i \Big( \int_{X}^{} P(x) r_i(x)  dx - \alpha_i \Big) \\
\end{align}\]

</p><p>We take the derivative of $L(P, \lambda_0, \lambda_1, \cdots, \lambda_m)$ with respect to $P(x)$ and the derivative should be $0$. We will also use the <a href="https://en.wikipedia.org/wiki/Calculus_of_variations">calculus of variations</a> to compute the derivative, which is slightly more complicated. Without going into all the details, we have the following derivatives.</p><p>

\[\begin{align}
\frac{\partial}{\partial P(x)} L(P, \lambda_0, \lambda_1, \cdots, \lambda_m) &amp;= - \frac{\partial}{\partial P(x)} \int_{X}^{} P(x) \log P(x)  dx + \lambda_0 \frac{\partial}{\partial P(x)} \Big(\int_{X}^{} P(x)  dx - 1 \Big) + \sum_{i=1}^{m} \lambda_i \frac{\partial}{\partial P(x)} \Big( \int_{X}^{} P(x) r_i(x)  dx - \alpha_i \Big) \\
&amp;= - \int_{X}^{} \frac{\partial}{\partial P(x)} \big( P(x) \log P(x) \big)  dx + \lambda_0 \frac{\partial}{\partial P(x)} \Big(\int_{X}^{} P(x)  dx - 1 \Big) + \sum_{i=1}^{m} \lambda_i \frac{\partial}{\partial P(x)} \Big( \int_{X}^{} P(x) r_i(x)  dx - \alpha_i \Big) \\
&amp;= - \log P(x) - 1 + \lambda_0 + \sum_{i=1}^{m} \lambda_i r_i(x) \\
&amp;= 0 \\
\end{align}\]

</p><p>Therefore,</p><p>

\[\begin{align}
P(x) &amp;= e^{\big(\sum_{i=1}^{m} \lambda_i r_i(x)\big) + \lambda_0 - 1 } \\
&amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{e^{1 - \lambda_0}} \\
\end{align}\]

</p><p>Because $\int_{X}^{} P(x) dx = 1$,</p><p>

\[\begin{align}
\int_{X}^{} P(x) dx &amp;= \int_{X}^{} e^{\big(\sum_{i=1}^{m} \lambda_i r_i(x)\big) + \lambda_0 - 1 } dx \\
&amp;= e^{\lambda_0 - 1} \int_{X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} dx \\
&amp;= 1 \\
\end{align}\]

</p><p>Therefore,</p><p>

\[e^{1 - \lambda_0} = \int_{X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} dx\]

</p><p>With this, we could rewrite $P(x)$ as</p><p>

\[\begin{align}
P(x) &amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{ \int_{X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} dx } \\
\end{align}\]

</p><h3 id="maximum-entropy-distribution-examples">Maximum Entropy Distribution Examples</h3>

<h4 id="roll-dice">Roll Dice</h4>

<p>A conventional dice has 6 faces. $X = \{ 1, 2, 3, 4, 5, 6 \}$. Because we donâ€™t have additional constrains, therefore</p><p>

\[\lambda_1 = \lambda_2 = \cdots = \lambda_m = 0\]

</p><p>So, the maximum entropy probability distribution of getting each face of the dice is</p><p>

\[\begin{align}
P(x) &amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{ \sum_{x \in X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} } \\
&amp;= \frac{ e^{0} }{ \sum_{x \in X}^{} e^{0} } \\
&amp;= \frac{ 1 }{ 6 } \\
\end{align}\]

</p><h4 id="uniform-distribution">Uniform Distribution</h4>

<p>The only constrain we put on a distribution is $X = [a, b]$. Because we donâ€™t have additional constrains, therefore</p><p>

\[\lambda_1 = \lambda_2 = \cdots = \lambda_m = 0\]

</p><p>So the maximum entropy probability distribution is actually uniform distribution.</p><p>

\[\begin{align}
P(x) &amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{ \int_{X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} dx } \\
&amp;= \frac{ e^{0} }{ \int_{a}^{b} e^{0} dx } \\
&amp;= \frac{ 1 }{ b - a } \\
\end{align}\]

</p><h4 id="gaussian-distribution">Gaussian Distribution</h4>

<p>We could also derive Gaussian Distribution using entropy maximization. The constrains for the maximum entropy distribution are</p>

<ul>
  <li>$X = (-\infty, \infty)$</li>
  <li>$\mathbb{E}[X] = \int_{-\infty}^{\infty} x P(x) dx = \mu$</li>
  <li>$\mathbb{V}[X] = \mathbb{E}[X^2] - \mathbb{E}[X]^2 = \mathbb{E}[X^2] - \mu^2 = \int_{-\infty}^{\infty} x^2 P(x) dx - \mu^2 = \sigma^2$</li>
</ul>

<p>which translates to</p>

<ul>
  <li>$m = 2$</li>
  <li>$r_1(x) = x$, $\alpha_1 = \mu$</li>
  <li>$r_2(x) = x^2$, $\alpha_2 = \sigma^2$</li>
</ul><p>

\[\begin{align}
P(x) &amp;= e^{\lambda_0 - 1 + \lambda_1 x + \lambda_2 x^2} \\
\end{align}\]

</p><p>Because</p><p>

\[\begin{align}
\int_{-\infty}^{\infty} P(x) dx &amp;= 1 \\
\end{align}\]

</p><p>We have</p><p>

\[\begin{align}
\int_{-\infty}^{\infty} P(x) dx &amp;= \int_{-\infty}^{\infty} e^{\lambda_0 - 1 + \lambda_1 x + \lambda_2 x^2} dx  \\
&amp;= \int_{-\infty}^{\infty} e^{\lambda_0 - 1 + \lambda_1 x + \lambda_2 x^2} dx  \\
&amp;= \int_{-\infty}^{\infty} \exp \big( \lambda_0 - 1 + \lambda_1 x + \lambda_2 x^2 \big) dx  \\
&amp;= \int_{-\infty}^{\infty} \exp \bigg( \lambda_2 \Big[ \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2^2} \Big] \bigg) dx  \\
&amp;= \int_{-\infty}^{\infty} \exp \bigg( \lambda_2 \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2} \bigg) dx  \\
&amp;= \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( \lambda_2 \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 \bigg) dx  \\
&amp;= \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( -(-\lambda_2) \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 \bigg) dx  \\
\end{align}\]

</p><p>Here we assume $\lambda_2 &lt; 0$, we further have</p><p>

\[\begin{align}
\int_{-\infty}^{\infty} P(x) dx &amp;= \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( -(-\lambda_2) \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 \bigg) dx  \\
&amp;= \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( - \Big( \sqrt{ -\lambda_2 }\big(x + \frac{\lambda_1}{2\lambda_2}\big) \Big)^2 \bigg) dx  \\
&amp;= \frac{1}{\sqrt{ -\lambda_2 }} \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( - \Big( \sqrt{ -\lambda_2 }\big(x + \frac{\lambda_1}{2\lambda_2}\big) \Big)^2 \bigg) d \Big( \sqrt{ -\lambda_2 }\big(x + \frac{\lambda_1}{2\lambda_2}\big) \Big)  \\
\end{align}\]

</p><p>To make it more clear, we set</p><p>

\[y = \sqrt{ -\lambda_2 }\big(x + \frac{\lambda_1}{2\lambda_2}\big)\]

</p><p>So using Gaussian integral, we further have</p><p>

\[\begin{align}
\int_{-\infty}^{\infty} P(x) dx &amp;= \frac{1}{\sqrt{ -\lambda_2 }} \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( - …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Maximum-Entropy/">https://leimao.github.io/blog/Maximum-Entropy/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Maximum-Entropy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25394064</guid>
            <pubDate>Sat, 12 Dec 2020 01:05:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do people find bugs?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25393945">thread link</a>) | @baby
<br/>
December 11, 2020 | https://www.cryptologie.net/article/511/how-do-people-find-bugs/ | <a href="https://web.archive.org/web/*/https://www.cryptologie.net/article/511/how-do-people-find-bugs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>You might wonder how people find bugs. Low-hanging fruit bugs can be found via code review, static analysis, dynamic analysis (like fuzzing), and other techniques. But what about deep logic bugs. Those you can’t find easily. Perhaps the protocol implemented is quite complicated, or correctness is hard to define, and edge-cases hard to detect. One thing I’ve noticed is that re-visiting protocols are an excellent way to find logic bugs.</p>
<p>Ian Miers once said something like that: "you need time, expertise, and meaningful engagement”. I like that sentence, although one can point out that these traits are closely linked--you can’t have meaningful engagement without time and expertise--it does show that finding bugs take "effort".</p>
<p>OK. Meaningful engagement can lead to meaningful bugs, and meaningful bugs can be found at different levels.
So you're here, seating in your undies in the dark, with a beer on your side and some uber eats lying on the floor.
Your computer is staring back at you, blinking at a frequency you can't notice, and waiting for you to find a bug in this protocol.
What do you do?
Perhaps the protocol doesn't have a proof, and this leads you to wonder if you can write one for it...</p>
<p>It worked for Ariel Gabizon, who in 2018 <a href="https://electriccoin.co/blog/zcash-counterfeiting-vulnerability-successfully-remediated/">found a subtle error</a> in a <a href="https://eprint.iacr.org/2013/879">2013 zk-SNARK paper</a> used by the Zcash cryptocurrency he was working on.
He found it by trying to write a proof for the paper he was reading, realizing that the authors had winged it.
While protocols back in the days could afford to wing it, these days people are more difficult--they demand proofs.
The bug Ariel found could have allowed anyone to forge an unlimited amount of money undetected.
It was silently fixed months later in an upgrade to the network.</p>
<blockquote>
<p>Ariel Gabizon, a cryptographer employed by the Zcash Company at the time of discovery, uncovered a soundness vulnerability. The key generation procedure of [BCTV14], in step 3, produces various elements that are the result of evaluating polynomials related to the statement being proven. Some of these elements are unused by the prover and were included by mistake; but their presence allows a cheating prover to circumvent a consistency check, and thereby transform the proof of one statement into a valid-looking proof of a different statement. This breaks the soundness of the proving system.</p>
</blockquote>
<p>What if the protocol already had a proof though?
Well that doesn't mean much, people enjoy writing unintelligible proofs, and people make errors in proofs all the time.
So the second idea is that reading and trying to understand a proof might lead to a bug in the proof.
Here's some meaningful engagement for you.</p>
<p>In 2001, Shoup revisited some proofs and <a href="https://eprint.iacr.org/2000/060.pdf">found some darning gaps in the proofs for RSA-OAEP</a>, leading to a newer scheme OAEP+ which was never adopted in practice.
Because back then, as I said, we really didn't care about proofs.</p>
<blockquote>
<p>[BR94] contains a valid proof that OAEP satisfies a certain technical property which they call “plaintext awareness.” Let us call this property PA1. However, it is claimed without proof that PA1 implies security against chosen ciphertext attack and non-malleability. Moreover, it is not even clear if the authors mean adaptive chosen ciphertext attack (as in [RS91]) or indifferent (a.k.a. lunchtime) chosen ciphertext attack (as in [NY90]).</p>
</blockquote>
<p>Later in 2018, a series of discoveries on the proofs for the OCB2 block cipher quickly led to <a href="https://eprint.iacr.org/2019/311">practical attacks breaking the cipher</a>.</p>
<blockquote>
<p>We have presented practical forgery and decryption attacks against OCB2, a high-profile ISO-standard authenticated encryption scheme. This was possible due to the discrepancy between the proof of OCB2 and the actual construction, in particular the interpretation of OCB2 as a mode of a TBC which combines XEX and XE.</p>
</blockquote>
<blockquote>
<p>We comment that, due to errors in proofs, ‘provably-secure schemes’ sometimes still can be broken, or schemes remain secure but nevertheless the proofs need to be fixed. Even if we limit our focus to AE, we have many examples for this, such as NSA’s Dual CTR [37,11], EAX-prime [28], GCM [22], and some of the CAESAR submissions [30,10,40]. We believe our work emphasizes the need for quality of security proofs, and their active verification.</p>
</blockquote>
<p>Now, reading and verifying a proof is always a good idea, but it’s slow, it’s not flexible (if you change the protocol, good job changing the proof), and it’s limited (you might want to prove different things re-using parts of the proofs, which is not straight forward).
Today, we are starting to bridge the gap between pen and paper proofs and computer science: it is called formal verification.
And indeed, formal verification is booming, with a number of papers in the recent years finding issues here and there just by describing protocols in a formal language and verifying that they withstand different types of attacks.</p>
<p><a href="https://eprint.iacr.org/2019/526">Prime, Order Please! Revisiting Small Subgroup and Invalid Curve Attacks on Protocols using Diffie-Hellman</a>:</p>
<blockquote>
<p>We implement our improved models in the Tamarin prover. We find a new attack on the Secure Scuttlebutt Gossip protocol, independently discover a recent attack on Tendermint’s secure handshake, and evaluate the effectiveness of the proposed mitigations for recent Bluetooth attacks.</p>
</blockquote>
<p><a href="https://eprint.iacr.org/2019/779">Seems Legit: Automated Analysis of Subtle Attacks on Protocols that Use Signatures</a>:</p>
<blockquote>
<p>We implement our models in the Tamarin Prover, yielding the first way to perform these analyses automatically, and validate them on several case studies. In the process, we find new attacks on DRKey and SOAP’s WS-Security, both protocols which were previously proven secure in traditional symbolic models.</p>
</blockquote>
<p><img alt="tamarin" src="https://www.cryptologie.net/upload/tamarin-obseq-lemma-attack.jpg"></p>
<p>But even this kind of techniques has limitation! (OMG David when will you stop?)</p>
<p>In 2017 <a href="https://blog.cryptographyengineering.com/2017/10/16/falling-through-the-kracks/">Matthew Green wrote</a>: </p>
<blockquote>
<p>I don’t want to spend much time talking about KRACK itself, because the vulnerability is pretty straightforward. Instead, I want to talk about&nbsp;why&nbsp;this vulnerability continues to exist so many years after WPA was standardized. And separately, to answer a question: how did this attack slip through, despite the fact that the 802.11i handshake was&nbsp;formally proven secure?</p>
</blockquote>
<p>He later writes:</p>
<blockquote>
<p>The critical problem is that while people looked closely at the two components — handshake and encryption protocol —&nbsp;in isolation, apparently nobody looked closely at the two components as they were connected together. I’m pretty sure there’s an entire&nbsp;geek meme&nbsp;about this.</p>
</blockquote>
<p>pointing to the "2 unit tests. 0 integration tests." joke.</p>
<p><img alt="meme" src="https://www.cryptologie.net/upload/ezgif-3-a0aa048a0c79.gif"></p>
<p>He then recognizes that it’s a hard problem:</p>
<blockquote>
<p>Of course, the reason nobody looked closely at this stuff is that doing so is just&nbsp;plain&nbsp;hard. Protocols have an exponential number of possible cases to analyze, and we’re just about at the limit of the complexity of protocols that human beings can truly reason about, or that peer-reviewers can verify. The more pieces you add to the mix, the worse this problem gets.
In the end we all know that the answer is for humans to stop doing this work. We need machine-assisted verification of protocols, preferably tied to the&nbsp;actual source code that implements them. This would ensure that the protocol actually does what it says, and that implementers don’t further screw it up, thus invalidating the security proof.</p>
</blockquote>
<p>Well, Matthew, we do have formally generated code! <a href="https://hacl-star.github.io/">HACL*</a> and <a href="http://adam.chlipala.net/papers/FiatCryptoSP19/FiatCryptoSP19.pdf">fiat-crypto</a> are two examples.
Anybody has heard of that failing? I’d be interested…</p>
<p>In any case, what’s left for us? A lot! Formally generated code is hard, and generally covers small parts of your protocol (e.g. field arithmetic for elliptic curves).
So what else can we do?
Implementing the protocol, if it hasn’t been implemented before, is a no-brainer.
In 2016, Taylor Hornby an engineer at Zcash <a href="https://electriccoin.co/blog/fixing-zcash-vulns/">wrote about a bug he found</a> while implementing the zerocash paper into the Zcash cryptocurrency:</p>
<blockquote>
<p>In this blog post, we report on the security issues we’ve found in the Zcash protocol while preparing to deploy it as an open, permissionless financial system.
Had we launched Zcash without finding and fixing the InternalH Collision vulnerability, it could have been exploited to counterfeit currency. Someone with enough computing power to find 128-bit hash collisions would have been able to double-spend money to themselves, creating Zcash out of thin air.</p>
</blockquote>
<p>Perhaps re-implementing the protocol in a different language might work as well?</p>
<p><img alt="" src="https://www.cryptologie.net/upload/Screen_Shot_2020-11-23_at_10.16_.18_PM_.png"></p>
<p>One last thing, most of the code out there is not formally verified.
So of course, reviewing code works, but you need time, expertise, money, etc.
So instead, what about testing?
This is what <a href="https://github.com/google/wycheproof">Wycheproof</a> does by implementing a number of test vectors that are known to cause issues:</p>
<blockquote>
<p>These observations have prompted us to develop Project Wycheproof, a collection of unit tests that detect known weaknesses or check for expected behaviors of some cryptographic algorithm. Project Wycheproof provides tests for most cryptographic algorithms, including RSA, elliptic curve crypto and authenticated encryption. Our cryptographers have systematically surveyed the literature and implemented most known attacks. We have over 80 test cases which have uncovered more than&nbsp;40 bugs. For example, we found that we could recover the private key of widely-used DSA and ECDHC implementations.</p>
</blockquote>
<p>In all of that, I didn't even talk about the benefits of writing a specification... that's for another day.</p>
</article><p>Well done! You've reached the end of my post. Now you can <a href="">leave a comment</a> or read something else.</p></div>]]>
            </description>
            <link>https://www.cryptologie.net/article/511/how-do-people-find-bugs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25393945</guid>
            <pubDate>Sat, 12 Dec 2020 00:52:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China’s Radical New Vision of Globalization]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25393779">thread link</a>) | @DimiD
<br/>
December 11, 2020 | https://www.noemamag.com/chinas-radical-new-vision-of-globalization/ | <a href="https://web.archive.org/web/*/https://www.noemamag.com/chinas-radical-new-vision-of-globalization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

				<div>
  <p>Credits</p>
  <p>James Crabtree is an associate professor in practice at the Lee Kuan Yew School of Public Policy at the National University of Singapore. He is the author of “The Billionaire Raj.”</p>
</div>


<p>SINGAPORE —&nbsp;Back in August, Chinese President Xi Jinping met with a group of economists in Beijing. “In the coming period, we will face more and more headwinds,” he <a href="http://www.xinhuanet.com/english/2020-08/25/c_139314902.htm" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">explained</a>, using unusually blunt language. Without naming names, Xi talked about China’s worsening trade and technology war with the United States under President Donald Trump, set against a backdrop of growing certainty in Beijing that America is bent on containing his nation’s geopolitical rise.</p>



<p>But then came the interesting part. “Since the beginning of this year, I have said on many occasions that we must promote the formation of a new development pattern, in which domestic and international cycles are the mainstay, and the domestic and international dual cycles promote each other,” Xi said. To an outsider, this might seem unremarkable, cloaked as it is in the elliptical phraseology that often marks Chinese economic ideas. But the “dual circulation” strategy Xi outlined actually represents a radical new understanding of globalization and of China’s place within it.</p>



<p>More than just a buzzword, dual circulation describes the deeply pessimistic worldview that has settled over Beijing. Once China’s leaders saw opportunity in globalization. Now, they expect the U.S. and its allies to deny China the technology it needs to build “a modern socialist country” by mid-century, meaning a wealthy superpower fit to rival the U.S. Although likely to be less pugilistic, Beijing rightly believes an incoming Biden administration will also press forward with policies designed to stop advanced technologies finding their way into Beijing’s hands. Chinese thinking has long valorized self-reliance, dating back to ideas developed by former Chinese leader Mao Zedong during the country’s civil war, which ended with the foundation of the People’s Republic of China in 1949. Now, Trump’s tariffs, as well as his campaigns against companies like Huawei and TikTok, have given new impetus to the modern form of self-reliance Xi dubs “internal” development.</p>



<p>Many experts have noted a changing Western consensus on China, as leaders in Washington abandoned the idea that economic modernization would inevitably lead to political liberalization in Beijing. But there has been a comparable shift in China’s internal conversation on the West too. Beginning with semiconductors but potentially expanding to all manner of other areas, China now expects it will have to develop technologically on its own. Xi’s new theory now sits at the heart of the country’s <a href="http://www.xinhuanet.com/english/2020-10/29/c_139476451.htm" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">14th five-year plan</a>, which covers development from 2021 to 2025, and was unveiled in draft form in October. The result will accelerate China’s decoupling from the West, while also increasing the importance of trading links forged with other parts of the world — for instance, via Xi’s signature Belt and Road Initiative. Put more bluntly, while the world was distracted by the drama of the U.S. presidential election, Xi quietly unveiled an economic strategy fit for a new Cold War. Both for China and for globalization itself, the results are likely to be profound.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “China expects the U.S. and its allies to act ever more aggressively to deny China the technology it needs.”    </p>

    
    
  </div>
</div>




<hr>



<p>To see how much China’s consensus has changed, recall Xi’s <a href="https://america.cgtn.com/2017/01/17/full-text-of-xi-jinping-keynote-at-the-world-economic-forum" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">remarks</a> at Davos in 2017. There, he portrayed globalization not as a threat, but as an inevitability. “The global economy is the big ocean that you cannot escape from,” he suggested. “China will vigorously foster an external environment of opening-up for common development.” Just as Trump was turning against the idea, China would act as steward of the existing global order. It would even help to remedy many of the problems that rapid integration had caused, Xi argued, from economic inequality to climate change.</p>



<p>Three years later and, under <a href="https://research.nus.edu.sg/eai/wp-content/uploads/sites/2/2020/10/EAIC-20-20201020.pdf" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">dual circulation</a>, things look much different. The idea splits the world into two systems. First comes external circulation, meaning China’s global trade, but also the way it invites foreigners into its domestic economy. This was the focus of Xi’s Davos remarks and the approach that powered his country’s decades of rapid growth, transforming China into an exporting powerhouse. The second component is then internal circulation, meaning domestic demand from Chinese consumers, but also domestic supply chains and “made in China” technologies.&nbsp;</p>



<p>This division shares something in common with “<a href="https://www.straitstimes.com/40-years-of-china-opening-up" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">reform and opening up</a>,” a phrase that has dominated China’s economic thinking for decades. That idea suggested Beijing should reform its domestic (or internal) economy to make it more market-led, while also opening up to the (external) world via globalization, gaining new ideas, production techniques and technologies along the way. Dual circulation also echoes longstanding attempts to wean China off a growth model dominated by exports and infrastructure investment and build instead the kind of consumption-led economy common in rich countries.</p>



<p>Such attempts have been only partially successful. A decade ago, about <a href="https://www.ceicdata.com/en/indicator/china/private-consumption--of-nominal-gdp#:~:text=China's%20Private%20Consumption%20accounted%20for,an%20average%20share%20of%2049.7%20%25." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">34%</a> of China’s economy came via domestic consumption, less than <a href="https://tradingeconomics.com/united-states/final-consumption-expenditure-etc-percent-of-gdp-wb-data.html#:~:text=(%25%20of%20GDP)%20in%20United,compiled%20from%20officially%20recognized%20sources." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">half the level</a> in the U.S. at the time. By 2019, this has reached just <a href="https://www.ceicdata.com/en/indicator/china/private-consumption--of-nominal-gdp#:~:text=China%20Private%20Consumption%3A%20%25%20of%20GDP,-1952%20%2D%202019%20%7C%20Yearly&amp;text=China%20Private%20Consumption%20accounted%20for,an%20average%20share%20of%2049.7%20%25." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">39%</a> — progress, of a sort, but hardly dramatic. When the phrase dual circulation first emerged earlier this year, many saw it as merely yet one more push toward this long-term objective of Chinese internal economic rebalancing.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Beginning with semiconductors but potentially expanding to all manner of other technologies, China now expects it will have to develop economically on its own.”    </p>

    
    
  </div>
</div>




<p>It is China’s deteriorating geopolitical environment that marks dual circulation as a decisive break from the past, however. “China thinks there is a good prospect of even worse relations with the U.S. and its friends in the coming years,” I was told recently by Li Mingjiang, a Chinese political scientist based in Singapore and long-time observer of Beijing’s intricate political economy. “So, it needs to do something about it.”</p>



<p>It is not hard to see why. Trump’s tariffs and battles over soybeans generated more headlines, but it is advanced technology that really matters in Beijing. China is a global tech leader in some sectors, from online payments to artificial intelligence. But it lags in others. Despite its geopolitical heft, it still remains a firmly middle-income economy, with a gross domestic product per capita of roughly <a href="https://www.google.com/search?q=china+gdp+per+capita&amp;rlz=1C5CHFA_enSG865SG865&amp;oq=china+gdp&amp;aqs=chrome.0.69i59j69i57j0i67l3j0j69i60j69i61.4682j0j7&amp;sourceid=chrome&amp;ie=UTF-8" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">$9,700</a> — about on par with <a href="https://www.google.com/search?rlz=1C5CHFA_enSG865SG865&amp;sxsrf=ALeKk03pfVp34z407DFWSFnQvjkGHb2akQ%3A1605820539834&amp;ei=e-C2X7m2Munfz7sP5ZGlgAE&amp;q=kazakhstan+gdp+per+capita&amp;oq=Ka+gdp+per+capita&amp;gs_lcp=CgZwc3ktYWIQAxgAMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB46BAgAEEdQoaoBWMmrAWCUswFoAHADeAGAAesBiAGeApIBBTEuMC4xmAEAoAEBqgEHZ3dzLXdpesgBCMABAQ&amp;sclient=psy-ab" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Kazakhstan</a> and roughly half that of <a href="https://www.google.com/search?rlz=1C5CHFA_enSG865SG865&amp;sxsrf=ALeKk03pfVp34z407DFWSFnQvjkGHb2akQ%3A1605820539834&amp;ei=e-C2X7m2Munfz7sP5ZGlgAE&amp;q=kazakhstan+gdp+per+capita&amp;oq=Ka+gdp+per+capita&amp;gs_lcp=CgZwc3ktYWIQAxgAMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB46BAgAEEdQoaoBWMmrAWCUswFoAHADeAGAAesBiAGeApIBBTEuMC4xmAEAoAEBqgEHZ3dzLXdpesgBCMABAQ&amp;sclient=psy-ab" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Greece</a>. Access to cutting-edge technology is critical in changing this, especially as its economy moves away from the kind of basic exported manufactured goods that have long dominated its growth model.</p>



<p>Over recent decades, China has had many routes to acquiring such technology. Often, it simply bought it, as when Chinese companies snapped up everything from Rolls Royce jet engines to Qualcomm semiconductors. Foreign businesses rushed to set up Chinese operations, often as part of local joint ventures, eager to tap into a vast consumer market. Chinese businesses bought foreign technology groups, while Chinese academics and scientists built partnerships at the world’s best universities. Beijing <a href="https://www.cigionline.org/publications/getting-beyond-forced-technology-transfers-analysis-and-recommendations-intangible" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">employed</a> darker methods too, from forced technology transfer to outright intellectual property theft. But there were always plenty of legitimate avenues to go with them.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Xi has quietly unveiled an economic strategy fit for a new Cold War.”    </p>

    
    
  </div>
</div>




<p>Now, many of these routes are closing fast. Rather than tariffs, America’s “entity list” has proved its most potent weapon. Back in 2016, President Barack Obama first used this process in <a href="https://www.cigionline.org/publications/getting-beyond-forced-technology-transfers-analysis-and-recommendations-intangible" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">accusing</a> ZTE, China’s second-largest telecoms supplier, of selling U.S. technologies to Iran, crippling the Chinese company in the process. Trump then escalated this approach, banning U.S. businesses from trading with dozens of Chinese enterprises, from state-owned giants to niche artificial intelligence providers with links to Xinjiang and its embattled Muslim Uighur minority. More recent <a href="https://www.commerce.gov/news/press-releases/2020/08/commerce-department-further-restricts-huawei-access-us-technology-and" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">measures</a> unveiled this August hit foreign suppliers too, for instance stopping semiconductor operators in Taiwan from selling to Chinese entities. Huawei has been one high-profile victim, leading experts to <a href="https://www.ft.com/content/bdd2a70f-ecd2-4aff-b6c7-c0624bfdeebb" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">question</a> whether China’s state-linked tech champion can survive.</p>



<p>What started with semiconductors is unlikely to end there, however, hence dual circulation’s underlying pessimism. Under Trump, the U.S. has unveiled a range of further measures limiting China’s technology access, from its 2018 <a href="https://www.cliffordchance.com/briefings/2018/02/the_export_controlreformactof2018risksan.html" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Export Control Reform Act</a> to more targeted measures in areas like geospatial imagery software. Allies in Europe are being cajoled to follow suit. Many Western governments have also acted to stop China from buying up advanced tech companies entirely, while also <a href="https://www.chinacenter.net/2020/china_currents/19-3/scholars-or-spies-u-s-china-tension-in-academic-collaboration/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">limiting</a> academic collaborations with Chinese partners. The recent battle over TikTok was illustrative too, showing how rapidly the U.S. has lowered the bar on what counts as a national security threat, a category that now includes not just critical 5G telecoms architecture of the sort provided by Huawei, but also jocular teenage social media platforms.</p>



<p>Elsewhere, U.S. strategists are particularly vexed by China’s doctrine of “<a href="https://www.floridadaily.com/marco-rubio-introduces-bill-to-keep-chinese-military-companies-from-accessing-american-capital-markets/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">military-civil fusion</a>,” which mandates that technologies acquired by China’s private sector must be shared with its armed forces. The problem is that, when you look hard enough, almost anything can potentially be seen as a dual-use technology, from nuclear equipment and renewable energy batteries to civilian aircraft, drones and autonomous vehicles.&nbsp;</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Xi’s plans clearly place more emphasis on domestic production and state control.”    </p>

    
    </div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.noemamag.com/chinas-radical-new-vision-of-globalization/">https://www.noemamag.com/chinas-radical-new-vision-of-globalization/</a></em></p>]]>
            </description>
            <link>https://www.noemamag.com/chinas-radical-new-vision-of-globalization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25393779</guid>
            <pubDate>Sat, 12 Dec 2020 00:34:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse Engineering the TP-Link HS110]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25393505">thread link</a>) | @zdw
<br/>
December 11, 2020 | https://www.softscheck.com/en/reverse-engineering-tp-link-hs110/ | <a href="https://web.archive.org/web/*/https://www.softscheck.com/en/reverse-engineering-tp-link-hs110/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<div>
			
<article id="post-3286">

<div>
<div>
	<!-- .entry-header -->

		<div>
      
		<p><em>by Lubomir Stroetmann, Consultant and Tobias Esser, Consultant</em></p>
<p><teaser><br>The <strong>TP-Link HS110 Wi-Fi</strong> is a cloud-enabled power plug that can be turned on and off remotely via app and offers energy monitoring and scheduling capabilities. As part of ongoing research into Internet of Things security, we performed a security analysis by reverse engineering the device firmware and Android app, sniffing app-to-device and device-to-app communications and <a href="https://www.softscheck.com/de/fuzzing-de/" target="_blank" rel="noopener noreferrer">fuzzing</a> the proprietary protocols being used.</teaser></p>
<p>While cloud communication was found to be reasonably secure for an IoT device, we discovered two insecure proprietary local configuration protocols: A human-readable JSON protocol “encrypted” with an easily reversible autokey XOR cipher and a binary DES-encrypted configuration and debugging protocol (<strong>TDDP – TP-Link Device Debug Protocol</strong>). TDDP is in use across most of the TP-Link product line including routers and access points and thus merits further research. We also release a <a href="https://github.com/softScheck/tplink-smartplug" target="_blank" rel="noopener noreferrer">Wireshark dissector and two python clients</a> for the proprietary protocols on GitHub.</p>

<p><strong id="nav">Contents</strong> </p>
<ol>
<li><a href="#Security Analysis Summary">Security Analysis Summary</a></li>
<li><a href="#Device Setup">Device Setup</a></li>
<li><a href="#Reverse Engineering the firmware">Reverse Engineering the firmware</a></li>
<li><a href="#Busybox">Busybox</a></li>
<li><a href="#Portscan">Portscan</a></li>
<li><a href="#TP-Link Smart Home Protocol">TP-Link Smart Home Protocol</a></li>
<li><a href="#Test Mode">Test Mode</a></li>
<li><a href="#TP-Link Device Debug Protocol">TP-Link Device Debug Protocol</a></li>
</ol>
<p><strong id="Security Analysis Summary">1. Security Analysis Summary</strong> <a href="#nav"></a></p>
<p><strong>The Good:</strong></p>
<ul>
<li>Cloud functionality can be turned off</li>
<li>Cloud communication uses HTTPS and CA pinning</li>
<li>Stores energy monitoring data locally</li>
<li>Firmware update checks signature against RSA keys</li>
</ul>
<p><strong>The Bad:</strong></p>
<ul>
<li>Useless encryption for local communication</li>
<li>No authentication: Anybody on the local network can turn the Smart Plug on and off, reset it or render it inoperable</li>
<li>TLS cloud connection could be intercepted with any valid Symantec EV certificate (only Root CA is checked)</li>
<li>Phones home even if set up as local-only</li>
<li>Undocumented configuration and debug service (TDDP)</li>
</ul>
<p><strong id="Device Setup">2. Device Setup</strong> <a href="#nav"></a></p>
<p>The Smart Plug has two physical buttons: An on/off relay switch and a device reset button that resets the device if pushed for five seconds or longer. When plugged in, an unconfigured or freshly reset Smart Plug will start an unsecured open Access Point with the SSID “<code>TP-LINK_Smart Plug_XXXX</code>” where XXXX are four hexadecimal numbers. A quick search on <a href="https://www.wigle.net/" target="_blank" rel="noopener noreferrer">WiGLE</a> reveals several unconfigured TP-Link Smart Plugs in the wild:</p>
<p><img src="https://www.softscheck.com/assets/img/blog/wigle-suche-1.png" alt="wigle-suche"></p>
<p>&nbsp;<br>
TP-Link’s Smart Home app “<a href="https://play.google.com/store/apps/details?id=com.tplink.kasa_android" target="_blank" rel="noopener noreferrer">Kasa</a>” makes the smartphone connect to this access point, sends UDP broadcast packets to <code>255.255.255.255</code> to find the Smart Plug IP and proceeds to configure it with the SSID and password that the user entered into the app. The Smart Plug then turns off the Access Point and connects to the configured WiFi as a client.</p>
<p>We perform a KARMA attack using the Sensepost <a href="https://github.com/sensepost/mana" target="_blank" rel="noopener noreferrer">MANA Toolkit</a>, forcibly deauthenticating the Smart Plug and trying to get it to connect to a rogue Access Point with the same SSID and no security. The attack is not successful; however repeated deauthentication can be used to perform a temporary Denial of Service attack against the device.</p>
<p><strong id="Reverse Engineering the firmware">3. Reverse Engineering the TP-Link HS110 firmware</strong> <a href="#nav"></a></p>
<p>We download the current official firmware for the device (<code>HS110(US)_V1_151016.zip</code>) and use binwalk to extract the contents of the .bin file:</p>
<p><img src="https://www.softscheck.com/assets/img/blog/binwalk-1.png" alt="binwalk"></p>
<p>&nbsp;<br>
As we can see, the firmware is a typical embedded Linux system and contains three parts:</p>
<ul>
<li>U-Boot Bootloader 1.1.4 (Oct 16 2015 – 11:22:22)</li>
<li>Linux Kernel 2.6.31—LSDK-9.2.0_U11.14 (yt@yangtao.localdomain)</li>
<li>Squashfs filesystem</li>
</ul>
<p>Examining the contents of the filesystem, we find the following interesting files:</p>
<ul>
<li>/bin/busybox v1.01 (2015.10.16-03:17+0000)</li>
<li>/etc/newroot2048.crt</li>
</ul>
<p>This is the certificate used to verify the identity of the cloud server. The file contains the “<a href="https://www.symantec.com/theme/roots">VeriSign Class 3 Public Primary Certification Authority – G5</a>” root certificate. This means the only check performed when establishing a TLS connection to the cloud is if the provided server certificate has been signed by the Symantec/VeriSign CA for Extended Validation (EV) certificates (<a href="https://www.owasp.org/index.php/Certificate_and_Public_Key_Pinning" target="_blank" rel="noopener noreferrer">CA pinning</a>). A determined attacker could buy his own EV certificate and use it to impersonate a cloud server.</p>
<ul>
<li>/etc/shadow</li>
</ul>
<pre>root:7KBNXuMnKTx6g:15502:0:99999:7:::</pre>
<p>The oldschool descrypt password is trivially broken, the password is “media”.</p>
<ul>
<li>/usr/bin/shd – the main server application</li>
<li>/usr/bin/shdTester – client for energy monitor calibration</li>
<li>/usr/bin/calDump – dumps wifi calibration data from /dev/caldata</li>
</ul>
<p>All proprietary server logic is contained in the shd (“Smart Home Daemon”) binary, which is <code>MIPS32 R2 Big Endian</code>:</p>
<pre>shd: ELF 32-bit MSB executable, MIPS, MIPS32 rel2 version 1 (SYSV), 
dynamically linked, interpreter /lib/ld-uClibc.so.0, corrupted section header size
</pre>
<p>The shd binary also contains a copy of <code>OpenSSL 1.0.1j 15 Oct 2014</code> for establishing TLS connections to the cloud server.<br>
We load the shd binary into IDA and start analyzing!</p>
<p><strong id="Busybox">4. Busybox</strong> <a href="#nav"></a></p>
<p>The Busybox version provided in the firmware is vulnerable to <a href="https://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2011-2716" target="_blank" rel="noopener noreferrer">CVE-2011-2716</a>, a command injection vulnerability in the udhcpc DHCP client component of Busybox, which allows to inject shell commands into one of the following DHCP options: (12) Hostname, (15) Domainname, (40) NIS Domain or (66) TFTP Server Name. For this to work, those values have to be actually used by the shell script invoking udhcpc. Analyzing the firmware we find that the shd binary creates a shell script <code>/tmp/udhcpc.script</code> containing:</p>
<pre>#!/bin/sh
if[ $1 = renew –o $1 = bound]
then
    ifconfig $interface $ip netmask $subnet
    route del default
    route add default gw $router
   echo "nameserver $dns" &gt; /tmp/resolv.conf
fi
</pre>
<p>It then executes udhcpc:</p>
<pre>/sbin/udhcpc –b –H "HS100(US)" –i br0 –s /tmp/udhcpc.script
</pre>
<p>As we can see, the hostname is hardcoded and none of the other options are used. Unfortunately, the udhcpc vulnerability is not exploitable in this case.</p>
<p><strong id="Portscan">5. Portscan</strong> <a href="#nav"></a></p>
<p>An nmap port scan on all TCP and UDP ports reveals the following:</p>
<table>
<thead>
<tr>
<th><strong>Port</strong></th>
<th><strong>Protocol</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>80/tcp</td>
<td>HTTP</td>
</tr>
<tr>
<td>9999/tcp</td>
<td>TP-Link Smart Home Protocol</td>
</tr>
<tr>
<td>1040/udp</td>
<td>TP-Link Device Debug Protocol (TDDP)</td>
</tr>
</tbody>
</table>
<p>The Webserver on Port <code>80</code> replies with a meaningless ellipsis, no matter what the request is:</p>
<pre>HTTP/1.1 200 OK
Server: TP-LINK Smart Plug
Connection: close
Content-Length: 5
Content-Type: text/html

…
</pre>
<p>Looking through the shd binary we see that the HTTP Server routine is called “<code>fake_httpd</code>” and will always return this hardcoded reply.</p>
<p>Port <code>9999 TCP</code> is used for controlling the Smart Plug on the local network via the Kasa app and is described in the <a href="#TP-Link Smart Home Protocol">TP-Link Smart Home Protocol section</a>. Port <code>1040 UDP</code> is described in the <a href="#TP-Link Device Debug Protocol">TP-Link Device Debug Protocol section</a>.</p>
<p><strong id="TP-Link Smart Home Protocol">6. TP-Link Smart Home Protocol</strong> <a href="#nav"></a></p>
<p>Sniffing the local wireless network traffic reveals that the TP-Link Kasa SmartHome app talks to the HS110 Smart Plug on TCP port 9999 using what looks like encrypted data.</p>
<p>After decompiling the Kasa app for Android, we find the encryption function:</p>
<p><img src="https://www.softscheck.com/assets/img/blog/tphome-encryption-1.png" alt="hs110 tphome-encryption"></p>
<p>We see the initial key (initialization vector) i has a hardcoded value of <code>-85 (= 171)</code>. The first byte of the plaintext is <code>XORed</code> with the key. The key is then set to the plaintext byte. During the next iteration, the next plaintext byte is <code>XORed</code> with the previous plaintext byte. Decryption works the same, with the keystream made out of cyphertext bytes. This is known as an <a href="https://en.wikipedia.org/wiki/Autokey_cipher" target="_blank" rel="noopener noreferrer">autokey cipher</a> and while it has better statistical properties than simple XOR encryption with a repeating key, it can be easily broken by known plaintext attacks.</p>
<p>Now that we know the algorithm and the key, we implement a Wireshark dissector in LUA which automatically decrypts TP-Link Smart Home packets on port <code>9999</code>. It turns out that the protocol uses JSON, so we also pass the decrypted contents to the JSON dissector. We can now monitor communications between the Kasa app and the Smart Plug on the local WiFi:</p>
<p><a href="https://www.softscheck.com/assets/img/blog/wireshark-dissector-1.png" target="_blank" rel="noopener noreferrer"><img src="https://www.softscheck.com/assets/img/blog/wireshark-dissector-1.png" alt="wireshark-dissector"></a></p>
<p>&nbsp;<br>
The Smart Plug commands are grouped into the following categories:</p>
<ul>
<li>system</li>
<li>netif (WLAN interface commands)</li>
<li>cnCloud (cloud connection)</li>
<li>time</li>
<li>emeter (energy meter)</li>
<li>schedule (scheduled on/off)</li>
<li>count_down (countdown on/off)</li>
<li>anti_theft (random scheduled on/off)</li>
</ul>
<p>We provide a comprehensive list of JSON commands (<a href="https://github.com/softScheck/tplink-smartplug/blob/master/tplink-smarthome-commands.txt" target="_blank" rel="noopener noreferrer">tplink-smarthome-commands.txt</a>) and a python client to send them with (<a href="https://github.com/softScheck/tplink-smartplug/blob/master/tplink_smartplug.py" target="_blank" rel="noopener noreferrer">tplink_smartplug.py</a>).</p>
<p><strong>System Commands</strong></p>
<p>We can read out information about the system using the <code>get_sysinfo</code> command:</p>
<pre>{"system":{"get_sysinfo":{}}}</pre>
<p>To send the command using our python client, invoke it with the <code>–c</code> info option:</p>
<pre>./tplink_smartplug.py –t 192.168.0.1 –c info</pre>
<p>We provide several predefined commands to read out information from the HS110 Smart Plug using <code>–c</code> options.<br>
Alternatively, you can use the <code>–j</code> option and provide the full JSON string:</p>
<pre>./tplink_smartplug.py –t 192.168.0.1 –j '{"system":{"get_sysinfo":{}}}'</pre>
<p>This allows to send any of the commands listed in <code>tplink-smarthome-commands.txt</code>.<br>
The <code>get_sysinfo</code> reply will contain the following information:</p>
<p><a href="https://www.softscheck.com/assets/img/blog/sysinfo.png" target="_blank" rel="noopener noreferrer"><img src="https://www.softscheck.com/assets/img/blog/sysinfo.png" alt="hs110 sysinfo"></a></p>
<p>&nbsp;<br>
We can turn the HS110 Smart Plug on and off using the <code>set_relay_state</code> command, using <code>1</code> for on and <code>0</code> for off:</p>
<pre>{“system":{"set_relay_state":{"state":1}}}</pre>
<p>We can reboot the HS110 Smart Plug using the <code>reboot</code> command which requires a <code>delay</code> parameter in seconds:</p>
<pre>{"system":{"reboot":{"delay":1}}}</pre>
<p>The HS110 Smart Plug can be reset to factory settings, making it act as an open Access Point again:</p>
<pre>{"system":{"reset":{"delay":1}}}</pre>
<p>Note that since the protocol does not provide authentication, anybody on your network can send this command and force a reset. Here, a prankster would set a high delay value, giving them time to leave the premises.</p>
<p>There are further commands to change the MAC address, change the Device and Hardware IDs, turn off the device LED (night mode) etc.</p>
<p>Of special interest are the firmware flashing commands. You can download a&nbsp; firmware file from an arbitrary URL using:</p>
<pre>{"system":{"download_firmware":{"url":"http://..."}}}</pre>
<p>While downloading, you can get the download state using:</p>
<pre>{"system":{"get_download_state":{}}}</pre>
<p>Once the download is finished, you can flash the firmware using:</p>
<pre>{"system":{"flash_firmware":{}}}</pre>
<p>Flashing a modified image will not work since the image’s signature has to match one of four hardcoded RSA keys (we won’t go into wild speculations why there are four keys here):</p>
<p><a href="https://www.softscheck.com/assets/img/blog/checkfirmware2-1.png" target="_blank" rel="noopener noreferrer"><img src="https://www.softscheck.com/assets/img/blog/checkfirmware2-1.png" alt="hs110 checkfirmware2"></a></p>
<p>&nbsp;<br>
<strong>WiFi Commands</strong></p>
<p>You can instruct the …</p></div></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.softscheck.com/en/reverse-engineering-tp-link-hs110/">https://www.softscheck.com/en/reverse-engineering-tp-link-hs110/</a></em></p>]]>
            </description>
            <link>https://www.softscheck.com/en/reverse-engineering-tp-link-hs110/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25393505</guid>
            <pubDate>Sat, 12 Dec 2020 00:05:04 GMT</pubDate>
        </item>
    </channel>
</rss>
