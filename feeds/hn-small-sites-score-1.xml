<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 10 Sep 2020 08:23:53 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 10 Sep 2020 08:23:53 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Using Nvidia Jetson and OpenDataCam to Explore Computer Vision and IoT Analytics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24407272">thread link</a>) | @Dwolb
<br/>
September 8, 2020 | https://www.hologram.io/blog/using-nvidia-jetson-and-opendatacam | <a href="https://web.archive.org/web/*/https://www.hologram.io/blog/using-nvidia-jetson-and-opendatacam">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Computer vision is an incredibly fast growing field, and recent developments have made it possible to quickly start experimenting with almost no previous experience. In this post we’ll show you how to set up a practical computer vision analytic system using the $99 Nvidia Jetson Nano Developers Kit, running OpenDataCam. With OpenDataCam we can recognise, track and count people and a variety of vehicles from a USB webcam feed. We will send the collected data to InfluxDB for visualization and analysis, and set up the Jetson Nano for remote operation and management using a cellular modem and a Hologram SIM.<br></p><p>The video below shows a recording of a live field test I did outside a filling station, counting vehicles and pedestrians travelling in different directions.<br></p><p><a href="https://youtu.be/bjrMs8JFYdo">https://youtu.be/bjrMs8</a><br></p><p>To get started, you will need the following hardware:</p><ul role="list"><li>Jetson Nano Developers kit</li><li>5V 4A Power Supply with barrel connector</li><li>Micro SD Card, class 10 or better, 64 GB recommended</li><li>Wi-Fi adaptor (<a href="https://www.sparkfun.com/products/15449">Edimax N150</a> or <a href="https://www.sparkfun.com/products/15841">Intel 8265.NGWMG M.2 card</a> recommended) or Ethernet cable</li><li>USB Webcam</li><li>4G Modem - USB or Raspberry Pi Hat (Tested with D-Link DWM-222)</li><li>Hologram SIM Card</li><li>HDMI monitor</li><li>USB Mouse and Keyboard</li></ul><figure><p><img src="https://assets-global.website-files.com/5d716c2c4df04f586b7912e3/5f2c5dacd16d7c48f0c455f9_20200724_143026.jpg" alt=""></p></figure><h2>How to set up the Nvidia Jetson Nano<br></h2><p>The Nvidia Jetson Nano is a powerful little single board computer with a GPU for running neural networks to do things like image classification, object detection or speech processing. It’s size and low cost means that it’s perfect for edge computing applications like retail analytics or various industrial uses. Combined with a cellular modem and USB webcam, it allows for quick and easy remote deployments, with the only field requirement being a power supply.<br></p><p>The Jetson Nano has no shortage of documentation and online resources, with Nvidia really having put effort into making machine learning approachable for almost anyone. It’s possible to get a basic object demo running in <a href="https://news.developer.nvidia.com/realtime-object-detection-in-10-lines-of-python-on-jetson-nano/">10 lines of python code</a>.</p><ol role="list"><li>Download the latest <a href="https://developer.nvidia.com/embedded/downloads">SD card image</a> for the Jetson Nano</li><li>Flash the image to the SD Card from your computer. On a Windows PC I prefer <a href="https://www.balena.io/etcher/">BalenaEtcher</a>. If you haven’t done this before, complete instructions are on the <a href="https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#write">Nvidia website</a>.</li><li>If you're using the barrel socket power supply, place a jumper on the J48 pins, just behind the barrel socket. This deactivates the micro USB port as a power supply.</li><li>Insert the micro SD card into the slot on the Nano</li><li>Plug in the power supply, mouse, keyboard, and Wi-Fi adaptor or network cable<br></li></ol><p>The Jetson should now start up, and direct you through the system and network configuration, and login credentials set up. On the user setup page select the “Log in automatically” to allow all services to start without user intervention.<br></p><p>Once done, you should see the desktop. Open a terminal window and do the following:</p><p>Check for updates, and update all packages. This might take a while.</p><p><code>
sudo apt update &amp;&amp; sudo apt upgrade
</code></p><p>‍</p><p>Install the Nano text editor and curl</p><p><code>
sudo apt install nano curl
</code></p><p>‍</p><p>For deployment a cellular connection is really convenient, but for testing and initial setup and ethernet or WiFi connection is quicker to set up. If you are using a Wi-Fi adaptor for testing, disable Wi-Fi power management to improve connection stability.</p><p><code>
sudo nano /etc/NetworkManager/conf.d/default-wifi-powersave-on.conf
</code></p><p>‍</p><p>It will open a file with the following file</p><p><code>
[connection]
wifi.powersave = 3
</code></p><p>Disable Wi-Fi power saving by changing <strong>3</strong> to <strong>2</strong>.<br></p><p>‍</p><p>Get the IP address of your Jetson Nano by running</p><p><code>
ifconfig
</code></p><p>Restart the Jetson before continuing. Any command line operation from this point forward can be done either directly on the Nano with the keyboard, mouse and monitor, or you can use SSH from any computer on the same network.&nbsp;</p><p>Now that you have a running Nano, it’s time to jump into the computer vision software.<br></p><h2>How to Install OpenDataCam</h2><p><a href="https://github.com/opendatacam/opendatacam">OpenDataCam</a> is an open source tool for computer vision analytics, that can track and count objects in almost any video feed. It is probably the easiest to use and setup tool that I have seen for this purpose. It is licensed under the permissive MIT license, which allows for use in commercial products.</p><p>‍<br>OpenDataCam runs on the Docker platform, and requires access to CUDA, Nvidia’s tool for running parallel processing tasks on GPUs. First we need to make sure CUDA is defined in the PATH on the Nano, by editing the <em>.bashrc</em> file</p><p><code>
sudo nano .bashrc
</code></p><p>‍<br></p><p>Add the following two lines to the end of the file, then save and close it.</p><p><code>
export PATH=${PATH}:/usr/local/cuda/bin
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/cuda/lib64
</code></p><p>Increase swap partition size of the Jetson to 6 GB to improve performance and reliability</p><p><code>
git clone https://github.com/JetsonHacksNano/installSwapfile
cd installSwapfile
chmod 777 installSwapfile.sh
./installSwapfile.sh
</code></p><p>‍<br></p><p>Install Docker-compose and dependencies</p><p><code>
sudo apt install -y python3-pip libssl-dev libffi-dev python-openssl
sudo pip3 install docker-compose
</code></p><p>Allow docker to run on startup</p><p><code>
sudo systemctl enable docker
</code></p><p>Install OpenDataCam. You will be asked for your sudo password during this process, and it may take a while.</p><p><code>
mkdir ~/opendatacam
cd ~/opendatacam
wget -N https://raw.githubusercontent.com/opendatacam/opendatacam/v3.0.1/docker/install-opendatacam.sh
chmod 777 install-opendatacam.sh
./install-opendatacam.sh --platform nano
</code></p><h2>How to configure OpenDataCam</h2><p>Once the installation is complete, open Chromium and go to <em>localhost:1880</em> from the Jetson, or <em>*JetsonIP*:1880</em> from any computer on the same network. Once OpenDataCam has started, you will see the following video feed. It is a demo file included in OpenDataCam and demonstrates its object detection capabilities. We’ll use this as an example to get familiar with the interface before changing the video feed for our specific use case.</p><figure><p><img src="https://assets-global.website-files.com/5d716c2c4df04f586b7912e3/5f29889973b49b0b09f6e922_UFzR3FTem-uv1i--ef_6ImhdEpBDpt2KfhSRH-nKZV0pb-fzcXfRg8O0PQY3TbOj2PztqHk-4w3Vd2TxSfclRoaW-4s2Y4LzfuUgjATLtWqQF4bczSNDX8J6xo4QGwdqlm1tRpqq.png" alt=""></p></figure><p>Click on the “Pathfinder” button in the upper left corner, and you will see the “tracks” generated by each car as it’s identified and tracked.<br></p><p>To count the vehicles, click the “Counter” button to add counting lines as shown below. These lines act as checkpoints, counting objects that pass over them. In the example below, I’ve added lines for oncoming, leaving, and crossing traffic. You can also toggle the direction of travel for objects to be counted, by clicking on the arrow in the centre of the line. To start counting, click the “Start recording” button.</p><figure><p><img src="https://assets-global.website-files.com/5d716c2c4df04f586b7912e3/5f298899354fcf9d9df68f0d_GLWKyNi1Xs8Jq7lWGDHkCKCNnvh9syNBk2Lk-1gC1OEQEvHgJEs21VJ8oPYtk1Wc-nbns8Kj_GdcqaA25lKE2UaPU82ZRAQzUcFRCuBuUh23XW0RZsZaK3c3CIqIKH6-UhMRzuhd.png" alt=""></p></figure><p>To increase the reliability of the counters, it is important to place them in areas with high detection confidence. By clicking the hamburger menu in the upper right-hand corner, you can activate the tracker accuracy heatmap, which will highlight the areas with the <strong>lowest</strong> detection confidence levels.</p><figure><p><img src="https://assets-global.website-files.com/5d716c2c4df04f586b7912e3/5f2988983b96a20a4ae37c21_D6BXJhyf_Dj-V7Ee6Xfa5q2Np7CTB_E5WITOkrOwuLSi73JBZjK2gWLf5Iz36E1Bn71D6-om6ao_-lE2HugxczT_NT_y0ojc_2DHNJGRQnvQ3adJOsHddTUM8LhB3z7tXt8GVYzL.png" alt=""></p></figure><figure><p><img src="https://assets-global.website-files.com/5d716c2c4df04f586b7912e3/5f29889972d197251894544b_BuLB_wQ_upuv3Vg3rZMNuyXJmQ0GNx0UyaJB5cmIJ-uJbQEcKPVdKE56PmnNvJBW_ft_Dl2oio5QcaScWLRZoK506Yx-L4BfFnNc8uAo4cmMGXlW1jBLDMBAA_D5DD02V-ZifngK.png" alt=""></p></figure><p>This means that you should avoid these areas when placing counting lines. It might also be a good idea to move the camera to a different perspective, or even improve the detection model using <a href="https://towardsdatascience.com/training-yolo-for-object-detection-in-pytorch-with-your-custom-dataset-the-simple-way-1aa6f56cf7d9">transfer learning</a>.<br></p><p>If you have a sample video file that you want to test, you can simply drag and drop it into the OpenDataCam window and it will start playing the new file.<br></p><p>To use a webcam or IP camera stream, you need to <a href="https://github.com/opendatacam/opendatacam/blob/master/documentation/CONFIG.md#video-input">edit the config.json</a> file in ~/opendatacam/ to specify the desired video source. Complete details are available on the <a href="https://github.com/opendatacam/opendatacam/blob/master/documentation/CONFIG.md#video-input">OpenDataCam Github page</a>, including all the other settings you can change. For now will stick to the demo file while we link all the different parts of the project together, and I will describe the final setup I did for deployment at the end of the post.</p><p>To load and updated config file, restart the Docker container</p><p><code>
sudo docker-compose restart
</code></p><h2>How to Install Node-RED for Cloud Data Collection and Analysis</h2><p>I want to collect traffic data in set intervals and store it for analysis. InfluxDB is a database solution built specifically for time series data, which is exactly what we get from OpenDataCam. It also has some built-in visualisation tools. You can install and run InfluxDB locally on the Jetson, but in a production environment we will likely have multiple sources of data, so sending it to the cloud for analysis makes more sense.<br></p><p>OpenDataCam provides a simple but effective <a href="https://opendatacam.github.io/opendatacam/apidoc/">API </a>for interacting with it and extracting data, but we need to create a simple app to do this. I’ll be using Node-RED, flow-based GUI wrapper for Node.js, which also allows us to see at a glance how data flows through the app, and quickly make changes</p><figure><p><img src="https://assets-global.website-files.com/5d716c2c4df04f586b7912e3/5f298898cf4cb2839161f831_wUmPP-WAF2sNZpv2qt-pTAv6j4twJzsVmUR3MPQSDpX9roRV8JLq8PxcGqSejBnJc7z-RTxFWb7XIFEDAJNGIBgcPjBmHh4DDmMNuapQ3jL2agcDopb5UghwI4yRnsSB_TFLrEIp.png" alt=""></p></figure><p>The above screenshot gives you a good idea of how the flow works. First it checks the status of OpenDataCam (ODC), and starts it if it is not running yet, and if no recording is active, it starts one. If a recording is running, it retrieves the recording and then stop it, and immediately starts a new recording. The data from the completed recording is retrieved, and sent to InfluxDB.<br></p><p>This process is repeated at intervals set in the blue <em>timestamp</em> inject node. The dark green nodes provide output for debugging purposes.<br></p><p>To install Node-RED, open a terminal on your Jetson, and run:</p><p><code>
bash (curl -sL https://raw.githubusercontent.com/node-red/linux-installers/master/deb/update-nodejs-and-nodered)
</code></p><p>Install additional nodes for easy interaction with InfluxDB</p><p><code>
cd ~/.node-red &amp;&amp; npm install node-red-contrib-stackhero-influxdb-v2
</code></p><p>We want to let Node-RED start automatically when the Jetson starts</p><p><code>
sudo systemctl enable nodered.service
</code></p><p>Start Node-RED as a background service</p><p><code>
node-red-start
</code></p><p>Open the Node-RED UI by going to <em>localhost:1880</em> from the Jetson, or <em>*JetsonIP*:1880</em> from any computer on the same network.</p><p>To import the flow, click the menu icon in the upper right corner, and select <em>Import</em>.</p><p>Copy the flow code from this <a href="https://github.com/CuriousMongoose/opendatacam-nodered-influxdb/blob/master/nodered-flow.json">GitHub repo</a>, paste it into the import window, and click <em>Import</em>. The flow will now show in your Node-RED editor. Before we can deploy it, we need to set up InfluxDB to receive data, and get its authentication details.</p><h2>How to configure InfluxDB Cloud</h2><p>Now we need to set up a InfluxDB instance to receive the data. First go to the <a href="https://www.influxdata.com/products/influxdb-cloud/">InfluxDB Cloud page</a>, register for a free account, and create an instance on the cloud platform of your choice. I used AWS.&nbsp;</p><figure><p><img src="https://assets-global.website-files.com/5d716c2c4df04f586b7912e3/5f29889817f6f13ef9861283_iy66hKVJonggHuEE97zGCmEVwrBnvAR0HzJKug2-sTenFZKkAqmzCzpErKJZ_FLEBe6JGaS8v3kr9Kg05pUCwDJKJtK-cwoFw27Jr4ULD90M90_tiYSn5X5kffZhbMXp1udSCsFR.png" alt=""></p></figure><p>Once the instance is created and you are logged in, go to the <em>Buckets</em> tab on the <em>Dat…</em></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.hologram.io/blog/using-nvidia-jetson-and-opendatacam">https://www.hologram.io/blog/using-nvidia-jetson-and-opendatacam</a></em></p>]]>
            </description>
            <link>https://www.hologram.io/blog/using-nvidia-jetson-and-opendatacam</link>
            <guid isPermaLink="false">hacker-news-small-sites-24407272</guid>
            <pubDate>Tue, 08 Sep 2020 11:15:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is the web getting slower? Depends on your device, connection, most-used sites]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24407039">thread link</a>) | @Terretta
<br/>
September 8, 2020 | https://www.debugbear.com/blog/is-the-web-getting-slower | <a href="https://web.archive.org/web/*/https://www.debugbear.com/blog/is-the-web-getting-slower">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>
    <div>
    
      
      

      

      <div>
        
        

        <p>A story on Hacker News recently argued that webpage speeds haven't improved, even as internet speeds have gone up.</p>
<p>This article explains why that conclusion can't be drawn from the original data.</p>
<p>We'll also look at how devices and the web have changed over the past 10 years, and what those changes have meant for web performance.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/hn-article.png" alt="Webpage speeds article on Hacker News"></p>
<ol>
<li><a href="#interpreting-the-http-archive-data">Interpreting the HTTP Archive data</a></li>
<li><a href="#how-have-mobile-networks-and-devices-changed-over-the-last-10-years">How have mobile networks and devices changed over the last 10 years?</a></li>
<li><a href="#how-have-websites-changed">How have websites changed?</a></li>
<li><a href="#data-from-the-chrome-user-experience-report">Data from the Chrome User Experience Report</a></li>
<li><a href="#modelling-page-load-times">Modelling page load times</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<h2 id="interpreting-the-http-archive-data">Interpreting the HTTP Archive data</h2>
<p>This chart from the <a href="https://www.nngroup.com/articles/the-need-for-speed/">Nielsen Norman Group article</a> suggested that increasing mobile network bandwidth hasn't resulted in faster page load times.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/nngroup-mobile-webperf-chart.png" alt="Chart showing increasing bandwidth along increasing page load times"></p>
<p>However, <strong>the connection speed used by HTTP Archive has not actually increased over time.</strong></p>
<p>Instead it went down in 2013, <a href="https://httparchive.org/faq#what-changes-have-been-made-to-the-test-environment-that-might-affect-the-data">switching from wifi to an emulated 3G connection</a>.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/nngroup-mobile-webperf-chart-annotated.png" alt="Annotation for page loads time showing when methodology changed"></p>
<p>The onLoad metric has increased 55% since 2013, from 12.7s to 19.7s. If you bought a phone in 2013 and have been on a 3G connection ever since, then the web has become slower for you.</p>
<p>Before looking at how devices and the web have changed over the last 10 years, here are a few notes on how to think about this data.</p>
<h3 id="why-look-at-on-load">Why look at onLoad?</h3>
<p>The <code>load</code> event is emitted by the page when all page resources like scripts or images have been downloaded.</p>
<p>If the top of a page renders quickly, but the page also loads 20 images further down, then the onLoad metric will suggest that the page is slow.</p>
<p>A different page might not initially render anything useful at all, and only start loading additional resources and rendering content long after the onLoad event. Yet this page will appear fast.</p>
<p>As a result, onLoad doesn't do a good job measuring whether a user experiences the page as fast.</p>
<p>So why do we even look at this metric? <strong>Because it's been around for a long time</strong>, and HTTP Archive has been tracking it since 2010. Newer metrics like <a href="https://www.debugbear.com/docs/metrics/first-contentful-paint">First Contentful Paint</a> or Time to Interactive were only added to HTTP Archive in 2017.</p>
<h3 id="should-we-expect-increasing-bandwidth-to-result-in-faster-page-load-times">Should we expect increasing bandwidth to result in faster page load times?</h3>
<p>Increasing bandwidth will only make a page load faster if bandwidth is the bottleneck at some point. It won't help if you're on a Gigabit connection with a 1s network roundtrip time.</p>
<p>However, the 1.6Mbps 3G connection emulated by HTTP Archive is very slow, so we should expect significant performance improvements as bandwidth improves. The average website downloads 1.7MB of data in 2020, which will take at least 9s to download on the HTTP Archive connection.</p>
<h3 id="some-more-http-archive-caveats">Some more HTTP Archive caveats</h3>
<p>I'll talk a lot about "the average website" in this article. It's worth noting that HTTP Archive only collects data on homepages, not pages deeper down in the site. The corpus of tested domains has also grown over time.</p>
<p>The tests weren't always run on the same device. Initially a physical iPhone 4 was used, today the tests are run on an emulated Android device.</p>
<p>We'll look at median metric values in this article. If most websites are fast but one in five websites freeze your phone for 20s we won't be able to pick this up.</p>
<h3 id="performance-on-desktop">Performance on desktop</h3>
<p>This article will focus on mobile performance in the US. However, if you're looking at the desktop data from the original article, it's worth noting that the test bandwidth was increased and latency was reduced in 2013.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/desktop-performance.png" alt="Chart showing desktop connection speeds and when emulated connection speed changed"></p>
<h2 id="how-have-mobile-networks-and-devices-changed-over-the-last-10-years">How have mobile networks and devices changed over the last 10 years?</h2>
<p>Let's look at 4 factors:</p>
<ul>
<li>network bandwidth</li>
<li>network latency</li>
<li>processor speeds</li>
<li>browser performance</li>
</ul>
<h3 id="mobile-network-bandwidth-in-the-us">Mobile network bandwidth in the US</h3>
<p>This chart shows average mobile bandwidth in the US by year, according to different sources. It increased from 1 Mbps to around 30 Mbps.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/us-mobile-bandwidth.png" alt="Mobile bandwidth in the US by year"></p>
<p>(I've not been very careful when collecting this data. For example, I didn't consistently distinguish when data was collected from when it was published. <a href="https://docs.google.com/spreadsheets/d/1ifZ_ngADpT3YzezNQLpXKCsr74-BvaBJUkYm6PGpv1g/edit?usp=sharing">You can find my sources here</a>.)</p>
<h3 id="mobile-network-latency-in-the-us">Mobile network latency in the US</h3>
<p>This was harder to find data on, but the results indicate that latency dropped from around 200ms in 2011 to 50ms in 2020.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/us-mobile-latency.png" alt="Mobile latency in the US by year, going down from 200ms in 2011 to 50ms in 2020"></p>
<h3 id="mobile-device-cpu-speeds">Mobile device CPU speeds</h3>
<p>I've not been able to find data on average mobile device speeds in the US. But <a href="https://infrequently.org/">Alex Russel</a> and <a href="https://surma.dev/">Surma</a> have published a <a href="https://twitter.com/slightlylate/status/1233275220275818498">chart showing GeekBench 4 scores alongside the release years of different phones</a>.</p>
<p>Even budget phones have become 4x faster, with iPhones now being up to 20x more powerful.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/mobile-cpu-benchmark.jpeg" alt="Mobile CPU performance over time"></p>
<h3 id="how-have-browsers-changed">How have browsers changed?</h3>
<p>A lot of work has been done on browsers over the last 10 years. JavaScript has become a larger part of the web, so many improvements have focussed here.</p>
<p>Looking at <a href="https://v8.dev/blog/10-years">this chart from the V8 blog</a>, page CPU usage for gone down by a factor of 4.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/v8-performance.png" alt="V8 Speedometer 1 benchmark results 2013 to 2018"></p>
<h4 id="networking">Networking</h4>
<p>Browser networking has also improved, for example with the introduction of HTTP/2 in 2015. 64% of requests are now served over HTTP/2.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/http2.png" alt="HTTP/2 adoption over time"></p>
<h2 id="how-have-websites-changed">How have websites changed?</h2>
<p>Let's look at some data from HTTP Archive to see how websites have changed.</p>
<h3 id="page-weight">Page weight</h3>
<p><a href="https://httparchive.org/reports/page-weight">Mobile page weight</a> increased by 337% between 2013 and 2020. This is primarily driven by an increase in images and JavaScript code.</p>
<p>Other resources also increased a lot –&nbsp;I suspect these are mostly videos.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/page-weight.png" alt="Page weight by resource type over time"></p>
<p>The chart starts in 2013 as HTTP Archive changed its methodology in October 2012. Before page weight was undercounted, as the test stopped when the page load event was triggered, even if more data was still being loaded.</p>
<h3 id="java-script-execution-time">JavaScript execution time</h3>
<p>JavaScript would be the most likely culprit if pages are getting slower despite faster mobile networks. Unfortunately, HTTP Archive only started collecting this data in late 2017, and it seems to have been mostly stable since then.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/javascript-execution-time.png" alt="HTTP Archive JavaScript execution time chart"></p>
<p>The drop in mid-2018 can probably be attributed to a URL corpus change.</p>
<p>Note that the absolute run duration (0.5s) is less than what you'd normally see in a tool like Lighthouse. These tools normally slow down JavaScript execution to emulate a mobile device, but <a href="https://almanac.httparchive.org/en/2019/methodology#lighthouse">this was broken for the HTTP Archive tests</a>. So while this number might be realistic for mid-range phones, a common assumption is that budget phones are around 4x slower.</p>
<h2 id="answering-whether-the-web-has-become-slower">Answering whether the web has become slower</h2>
<p>Has the web become slower? Well, it depends on what your device, network connection, and most-used websites are.</p>
<p>We'd need to weigh real-world performance data to get a distribution that shows how different users experienced the web over time. And should the experience of someone opening thousands of pages a day count as much as someone who only visits Facebook once a week?</p>
<p>I don't have detailed per-user data, but we can take a look at the question in a few different ways:</p>
<ol>
<li>Real-user data from the <a href="https://developers.google.com/web/tools/chrome-user-experience-report">Chrome UX Report (CrUX)</a></li>
<li>Naive modelling based on how websites and devices have changed</li>
</ol>
<p>I also tried downloading old page versions from archive.org and testing them with Lighthouse, but wasn't able to get meaningful results in the time I had available. For example, often some images are missing from the page archive.</p>
<h2 id="data-from-the-chrome-user-experience-report">Data from the Chrome User Experience Report</h2>
<p>The big limitation of CrUX data is that it's only been collected since late 2017. But we can still use it to see if the web has become slower in the last two and a half years.</p>
<p>Note that, unlike HTTP Archive, CrUX looks at the whole domain instead of just homepages.</p>
<p>The data we'll look at is the 75th percentile, meaning pages load at least this fast for 75% of users.</p>
<p>(I'm taking the average across websites rather than the median, which is not great.)</p>
<h3 id="us-page-load-times">US page load times</h3>
<p>CrUX data for the US does not show page performance getting worse.</p>
<p>The onLoad metric shows a slight improvement, maybe due to an increase in bandwidth. Or maybe more activity is now happening after the initial page load.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/crux-us.png" alt="Page load speeds in the US"></p>
<p>The paint metrics seem fairly stable. Largest Contentful Paint is a new metric that has only been collected since mid-2019.</p>
<h3 id="the-rest-of-the-world">The rest of the world</h3>
<p>The downward trend in the US onLoad metric is matched by the global data. There are however signifianct differences in page load times across countries, with onLoad timings in India being almost twice those in South Korea.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/crux-global.png" alt="Page load speeds globally, in the US, UK, Korea, and India"></p>
<p>We can use CrUX data to put HTTP Archive data into perspective. In January 2020 HTTP Archive reported a median (50% percentile) load time of 18.7s, based on its synthetic data.</p>
<p>In contrast, CrUX suggests a load time of just 5.8s –&nbsp;and this is the 75th percentile.</p>
<p>(Note that the Global values here just take an average and are not weighed by population.)</p>
<h2 id="modelling-page-load-times">Modelling page load times</h2>
<p>We can create a theoretical model of how changes in devices, networks, and websites might affect overall performance.</p>
<p>This won't be a great model, but hopefully it will still provide some insight.</p>
<h3 id="theoretical-page-download-time">Theoretical page download time</h3>
<p>Page weight has increased over time, but so has bandwidth. Round-trip latency has also gone down.</p>
<p>Downloading a file the size of the median mobile website would have taken 1.7s in 2013. If your connection hasn't improved since then downloading this much data would now take 4.4s. But with an average connection today it would only take 0.9s.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/minimum-page-download-time.png" alt="TCP download time"></p>
<p>In practice, a website wouldn't consist of just a single request, and other factors like CPU processing or server latency would also affect how quickly the page loads. The onLoad times reported by HTTP Archive are 2-3 times this lower bound.</p>
<p>But we can still use this as an indicator that reduced latency and increased bandwidth have helped make websites load faster overall.</p>
<p>(I'm starting in 2013 rather than 2011, as the HTTP Archive page weight metric has only been measured consistently since then.)</p>
<h3 id="cpu">CPU</h3>
<p>I'm not quite sure how to think about this, but I'll make some guesses anyway.</p>
<p>Someone who used a Galaxy S4 in 2013 and now uses a Galaxy S10 will have seen their CPU processing power go up by a factor of 5. Let's assume that browsers have become 4x more efficient since then. If we naively multiply these numbers we get an overall 20x improvement.</p>
<p>Since 2013, JavaScript page weight has increased 3.7x from 107KB to 392KB. Maybe minification and compression have improved a bit …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.debugbear.com/blog/is-the-web-getting-slower">https://www.debugbear.com/blog/is-the-web-getting-slower</a></em></p>]]>
            </description>
            <link>https://www.debugbear.com/blog/is-the-web-getting-slower</link>
            <guid isPermaLink="false">hacker-news-small-sites-24407039</guid>
            <pubDate>Tue, 08 Sep 2020 10:32:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Diamond (Deep Learning in Clojure Is Fast, Simpler Than Keras)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24406978">thread link</a>) | @tosh
<br/>
September 8, 2020 | https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-is-Fast-and-Simpler-than-Keras | <a href="https://web.archive.org/web/*/https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-is-Fast-and-Simpler-than-Keras">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
You can <a href="https://www.patreon.com/posts/22476035">adopt a pet function!</a>
Support my work <a href="https://patreon.com/draganrocks">on my Patreon page</a>, and access my <a href="https://www.patreon.com/posts/im-ditching-and-22476348">dedicated discussion server</a>. Can't afford to <a href="https://patreon.com/draganrocks">donate</a>? Ask for a free invite.
<p>September 5, 2020</p>
<p>
    Please share: .
</p>

<p>
    <a href="https://aiprobook.com/">New books are available for subscription.</a>
    </p><p><a href="https://aiprobook.com/deep-learning-for-programmers">
            <img src="http://aiprobook.com/img/dlfp-cover.png">
        </a>
        <a href="https://aiprobook.com/numerical-linear-algebra-for-programmers">
            <img src="http://aiprobook.com/img/lafp-cover.png">
        </a>
    </p>


<p>
through the direct equivalent of a fine Convolutional network example in Keras.
</p>

<p>
Good News: <a href="https://github.com/uncomplicate/deep-diamond">Deep Diamond</a>() preview release is in Clojars, and is already quite useful! And fast!
It is yet to be fully polished, but you can try it now and, I hope, you'll like it.
</p>

<p>
It now covers the functionality that is being explained from scratch in the <a href="http://aiprobook.com/">books that I'm writing</a>.
Convolutions work, too; at the speed of Road Runner!
</p>

<p>
In accordance with my philosophy, "less talk, more walk", I introduce Deep Diamond
through the direct equivalent of this fine <a href="https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py">MNIST CNN example in Keras</a>.
</p>

<div id="outline-container-org54ea652">
<h2 id="org54ea652">Specify the network blueprint</h2>
<div id="text-org54ea652">
<p>
We specify the network by plain Clojure vectors and functions, and create the blueprint.
No need for special compilers and whatnot. The structure of internal parts would be
picked up automatically, or we can specify these explicitly.
</p>

<div>
<pre><span>(</span><span>def</span> <span>net-spec</span> <span>[</span><span>(</span>convo <span>[</span>32<span>]</span> <span>[</span>3 3<span>]</span> <span>:relu</span><span>)</span>
               <span>(</span>convo <span>[</span>64<span>]</span> <span>[</span>3 3<span>]</span> <span>:relu</span><span>)</span>
               <span>(</span>pooling <span>[</span>2 2<span>]</span> <span>:max</span><span>)</span>
               <span>(</span>dropout<span>)</span>
               <span>(</span>dense <span>[</span>128<span>]</span> <span>:relu</span><span>)</span>
               <span>(</span>dropout<span>)</span>
               <span>(</span>dense <span>[</span>10<span>]</span> <span>:softmax</span><span>)</span><span>]</span><span>)</span>

<span>(</span><span>defonce</span> <span>net-bp</span>
  <span>(</span>network <span>(</span>desc <span>[</span>128 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span>
           net-spec<span>)</span><span>)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-orgb8d8bce">
<h2 id="orgb8d8bce">Create the network</h2>
<div id="text-orgb8d8bce">
<p>
The blueprint is a Clojure function that can instantiate the network
object that holds the parameter tensors that the network should learn by using
one of the built-in optimization algorithms. In this case, I'll use adaptive moments,
<code>:adam</code>. Xavier initialization is, again, a plain function that initializes
the network with appropriate weights.
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>net</span> <span>(</span>init! <span>(</span>net-bp <span>:adam</span><span>)</span><span>)</span><span>)</span>
</pre>
</div>

<p>
That's it! The network is ready to learn.
</p>
</div>
</div>

<div id="outline-container-orgae4dec0">
<h2 id="orgae4dec0">Train the network on MNIST data (CPU)</h2>
<div id="text-orgae4dec0">
<p>
The original MNIST data is distributed through four binary files that
you can download <a href="http://yann.lecun.com/exdb/mnist/">here</a>. To demonstrate how nice Clojure is, I'm not
using any special MNIST-specific code that is magically imported
from the framework's model Zoo. The complete code, from scratch, is at the
end of the article (I'm just pushing it there so it doesn't steal the spotlight :).
</p>

<div>
<pre><span>(</span>time <span>(</span>train net train-images y-train <span>:crossentropy</span> 12 <span>[]</span><span>)</span><span>)</span>
</pre>
</div>

<p>
The network learns in mini-batches of 128 images of the total of 60000,
with adaptive moments, through 12 full epochs. That makes 5625 forward/backward
update cycles.
</p>

<p>
The total time for that on my old 2013. i7-4790k CPU is: <b>368</b> seconds.
<b>6 minutes for 6000 cycles. A thousand cycles per minute.</b>
</p>

<p>
Isn't that a lot? You should try and run this in Keras with TensorFlow, and
see that we got a pretty nice performance! (I'll publish some comparisons soon,
and in the meantime you can try for yourself!).
</p>
</div>
</div>

<div id="outline-container-org7c0813e">
<h2 id="org7c0813e">Has it learned anything?</h2>
<div id="text-org7c0813e">
<p>
See the metrics:
</p>

<div>
<pre><span>(</span><span>-&gt;&gt;</span> <span>(</span>infer net test-images<span>)</span>
     <span>(</span>dec-categories<span>)</span>
     <span>(</span>classification-metrics test-labels-float<span>)</span>
     <span>:metrics</span><span>)</span>
</pre>
</div>

<pre>{:accuracy 0.9919,
 :f1 0.9918743606319073,
 :ba 0.9954941141884774,
 :sensitivity 0.9918944358825683,
 :specificity 0.9990937924943865,
 :precision 0.9918542861938476,
 :fall-out 9.062075056135655E-4}
</pre>

<p>
Accuracy is 99.2% which is in the ballpark of what the Keras example gives.
</p>
</div>
</div>


<div id="outline-container-org78cec4a">
<h2 id="org78cec4a">GPU</h2>
<div id="text-org78cec4a">
<p>
Want to go faster? No problem, Deep Diamond supports GPU, in the same process,
at the same time, with the same code!
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>gpu</span> <span>(</span>cudnn-factory<span>)</span><span>)</span>

<span>(</span><span>def</span> <span>gpu-net-bp</span> <span>(</span>network gpu
                         <span>(</span>desc <span>[</span>128 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span>
                         net-spec<span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>gpu-net</span> <span>(</span>init! <span>(</span>gpu-net-bp <span>:adam</span><span>)</span><span>)</span><span>)</span>

<span>(</span><span>def</span> <span>gpu-x-train</span>
  <span>(</span>transfer! train-images <span>(</span>tensor gpu <span>[</span>60000 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span><span>)</span><span>)</span>

<span>(</span><span>def</span> <span>gpu-y-train</span>
 <span>(</span>transfer! y-train <span>(</span>tensor gpu <span>[</span>60000 10<span>]</span> <span>:float</span> <span>:nc</span><span>)</span><span>)</span><span>)</span>

<span>(</span>time <span>(</span>train gpu-net gpu-x-train gpu-y-train <span>:crossentropy</span> 12 <span>[]</span><span>)</span><span>)</span>
</pre>
</div>

<p>
Elapsed time? <b>20 seconds</b> on my Nvidia GTX 1080Ti (which is a few generations old)!
</p>
</div>
</div>

<div id="outline-container-org2c2d651">
<h2 id="org2c2d651">The books</h2>
<div id="text-org2c2d651">
<p>
Should I mention that the book <a href="https://aiprobook.com/deep-learning-for-programmers/">Deep Learning for Programmers: An Interactive Tutorial with
CUDA, OpenCL, DNNL, Java, and Clojure</a> teaches the nuts and bolts of neural networks and deep learning
by showing you how Deep Diamond is built, <b>from scratch</b>? In interactive sessions. Each line of code
can be executed and the results inspected in the plain Clojure REPL. The best way to master something is to build
it yourself!
</p>

<p>
It' simple. But fast and powerful!
</p>

<p>
Please subscribe, read the drafts, get the full book soon, and support my work on this free open source library.
</p>
</div>
</div>

<div id="outline-container-orga8b021d">
<h2 id="orga8b021d">Appendix: Reading, encoding, and decoding data</h2>
<div id="text-orga8b021d">
<p>
The code that reads the raw image data and converts it to proper tensors
should go up in the sequence of execution, but is not that interesting.
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>train-images-file</span> <span>(</span>random-access <span>"data/mnist/train-images.idx3-ubyte"</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>train-labels-file</span> <span>(</span>random-access <span>"data/mnist/train-labels.idx1-ubyte"</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-images-file</span> <span>(</span>random-access <span>"data/mnist/t10k-images.idx3-ubyte"</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-labels-file</span> <span>(</span>random-access <span>"data/mnist/t10k-labels.idx1-ubyte"</span><span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>train-images</span>
  <span>(</span>map-tensor train-images-file <span>[</span>60000 1 28 28<span>]</span> <span>:uint8</span> <span>:nchw</span> <span>:read</span> 16<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>train-labels</span>
  <span>(</span>map-tensor train-labels-file <span>[</span>60000<span>]</span> <span>:uint8</span> <span>:x</span> <span>:read</span> 8<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-images</span>
  <span>(</span>map-tensor test-images-file <span>[</span>10000 1 28 28<span>]</span> <span>:uint8</span> <span>:nchw</span> <span>:read</span> 16<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-labels</span>
 <span>(</span>map-tensor test-labels-file <span>[</span>10000<span>]</span> <span>:uint8</span> <span>:x</span> <span>:read</span> 8<span>)</span><span>)</span>

<span>(</span><span>defn</span> <span>enc-categories</span> <span>[</span>val-tz<span>]</span>
  <span>(</span><span>let</span> <span>[</span>val-vector <span>(</span>view-vctr val-tz<span>)</span><span>]</span>
    <span>(</span><span>let-release</span> <span>[</span>cat-tz <span>(</span>tensor val-tz <span>[</span><span>(</span>first <span>(</span>shape val-tz<span>)</span><span>)</span> <span>(</span>inc <span>(</span>long <span>(</span>amax val-vector<span>)</span><span>)</span><span>)</span><span>]</span> <span>:flo</span><span>at</span><span> </span><span>:nc</span><span> </span><span>)</span>
                  cat-matrix <span>(</span>view-ge <span>(</span>view-vctr cat-tz<span>)</span> <span>(</span>second <span>(</span>shape cat-tz<span>)</span><span>)</span> <span>(</span>first <span>(</span>shape cat-t<span>z</span><span>)</span><span>)</span><span>)</span><span>]</span>
      <span>(</span><span>dotimes</span> <span>[</span>j <span>(</span>dim val-vector<span>)</span><span>]</span>
        <span>(</span>entry! cat-matrix <span>(</span>entry val-vector j<span>)</span> j 1.0<span>)</span><span>)</span>
      cat-tz<span>)</span><span>)</span><span>)</span>

<span>(</span><span>defn</span> <span>dec-categories</span> <span>[</span>cat-tz<span>]</span>
  <span>(</span><span>let</span> <span>[</span>cat-matrix <span>(</span>view-ge <span>(</span>view-vctr cat-tz<span>)</span> <span>(</span>second <span>(</span>shape cat-tz<span>)</span><span>)</span> <span>(</span>first <span>(</span>shape cat-tz<span>)</span><span>)</span><span>)</span><span>]</span>
    <span>(</span><span>let-release</span> <span>[</span>val-tz <span>(</span>tensor cat-tz <span>[</span><span>(</span>first <span>(</span>shape cat-tz<span>)</span><span>)</span><span>]</span> <span>:float</span> <span>:x</span><span>)</span>
                  val-vector <span>(</span>view-vctr val-tz<span>)</span><span>]</span>
      <span>(</span><span>dotimes</span> <span>[</span>j <span>(</span>dim val-vector<span>)</span><span>]</span>
        <span>(</span>entry! val-vector j <span>(</span>imax <span>(</span>col cat-matrix j<span>)</span><span>)</span><span>)</span><span>)</span>
      val-tz<span>)</span><span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>train-labels-float</span> <span>(</span>transfer! train-labels <span>(</span>tensor <span>[</span>60000<span>]</span> <span>:float</span> <span>:x</span><span>)</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>y-train</span> <span>(</span>enc-categories train-labels-float<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-labels-float</span> <span>(</span>transfer! test-labels <span>(</span>tensor <span>[</span>10000<span>]</span> <span>:float</span> <span>:x</span><span>)</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>y-test</span> <span>(</span>enc-categories test-labels-float<span>)</span><span>)</span>
</pre>
</div>
</div>
</div>


    </article></div>]]>
            </description>
            <link>https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-is-Fast-and-Simpler-than-Keras</link>
            <guid isPermaLink="false">hacker-news-small-sites-24406978</guid>
            <pubDate>Tue, 08 Sep 2020 10:22:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This Month in Rust GameDev #13 – August 2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24406787">thread link</a>) | @agluszak
<br/>
September 8, 2020 | https://rust-gamedev.github.io/posts/newsletter-013/ | <a href="https://web.archive.org/web/*/https://rust-gamedev.github.io/posts/newsletter-013/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
            
    <article itemscope="" itemtype="http://schema.org/BlogPosting">
        

        <div itemprop="articleBody">
            <p>Welcome to the 13th issue of the Rust GameDev Workgroup’s
monthly newsletter.
<a href="https://rust-lang.org/">Rust</a> is a systems language pursuing the trifecta:
safety, concurrency, and speed.
These goals are well-aligned with game development.
We hope to build an inviting ecosystem for anyone wishing
to use Rust in their development process!
Want to get involved? <a href="https://github.com/rust-gamedev/wg#join-the-fun">Join the Rust GameDev working group!</a></p>
<p>You can follow the newsletter creation process
by watching <a href="https://github.com/rust-gamedev/rust-gamedev.github.io/issues?q=label%3Acoordination">the coordination issues</a>.
Want something mentioned in the next newsletter?
<a href="https://github.com/rust-gamedev/rust-gamedev.github.io">Send us a pull request</a>.
Feel free to send PRs about your own projects!</p>
<p>Table of contents:</p>
<ul>
<li><a href="https://rust-gamedev.github.io/posts/newsletter-013/#rust-gamedev-podcast">Rust GameDev Podcast</a></li>
<li><a href="https://rust-gamedev.github.io/posts/newsletter-013/#game-updates">Game Updates</a></li>
<li><a href="https://rust-gamedev.github.io/posts/newsletter-013/#learning-material-updates">Learning Material Updates</a></li>
<li><a href="https://rust-gamedev.github.io/posts/newsletter-013/#library-tooling-updates">Library &amp; Tooling Updates</a></li>
<li><a href="https://rust-gamedev.github.io/posts/newsletter-013/#popular-workgroup-issues-in-github">Popular Workgroup Issues in Github</a></li>
<li><a href="https://rust-gamedev.github.io/posts/newsletter-013/#meeting-minutes">Meeting Minutes</a></li>
<li><a href="https://rust-gamedev.github.io/posts/newsletter-013/#requests-for-contribution">Requests for Contribution</a></li>
</ul>
<!--
Ideal section structure is:

```
### [Title]

![image/GIF description](image link)

A paragraph or two with a summary and [useful links].

_Discussions:
[/r/rust](https://reddit.com/r/rust/todo),
[twitter](https://twitter.com/todo/status/123456)_

[Title]: https://first.link
[useful links]: https://other.link
```

Discussion links are added only if they contain
some actual interesting discussions.

If needed, a section can be split into subsections with a "------" delimiter.
-->
<h2 id="rust-gamedev-podcast"><a href="https://rustgamedev.com/">Rust GameDev Podcast</a>&nbsp;
</h2>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-013/podcast.jpeg" alt="text logo"></p>
<p>This month <a href="https://richardpatching.com/">Richard @patchfx Patching</a> started
<a href="https://rustgamedev.com/">Rust GameDev Podcast</a>!</p>
<blockquote>
<p>Over the lockdown period I have been working on a new podcast
for Rust game developers. I have been interviewing indie teams
and library creators, discussing custom engines, procedural generation,
open source and the business of games development.</p>
</blockquote>
<ul>
<li>
<p><a href="https://rustgamedev.com/episodes/interview-with-team-veloren">The first episode</a> is an interview
with the team behind Veloren, an open-source multiplayer
voxel RPG written in Rust.</p>
<p>Find out about the game's origin, its engine development,
pros and cons of a big open-source project, CI and build pipeline,
importance of artists, procedural generation,
community building, managing players' expectations,
and upcoming developments.</p>
</li>
<li>
<p><a href="https://rustgamedev.com/episodes/interview-with-herbert-wolverson-bracket-lib">The second episode</a> is an interview with Herbert Wolverson,
creator of <a href="https://crates.io/crates/bracket-lib">bracket-lib</a> (pka RLTK), <a href="http://bfnightly.bracketproductions.com/">Rust Roguelike Tutorial</a>,
and <a href="https://thebracket.itch.io/nox-futura">Nox Futura</a>.</p>
<p>A very wide-ranging interview covering many interesting topics:
where the bracket-lib came from and what the creator is doing now,
as well as practical questions and issues discovered
in the course of creating their game, [Nox Futura].
Lots of interesting talk about a new Rust games development book
Herbert is writing, C++ vs Rust, learning Rust, code architecture and
ECS's in roguelikes, emergent behavior, and hilarious bugs in Dwarf Fortress.</p>
</li>
</ul>
<p>The show has been distributed on most major platforms
for you to listen and subscribe:
<a href="https://rustgamedev.com/">Rust Game Dev Podcast (simplecast)</a>,
<a href="https://podcasts.apple.com/gb/podcast/rust-game-dev/id1526304768">Apple Podcasts</a>,
<a href="https://open.spotify.com/show/7HRfGnTcXkLkQd9fxJbDGj">Spotify</a>,
<a href="https://feeds.simplecast.com/C6NQglnL">RSS Feed</a>,
<a href="https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9DNk5RZ2xuTA">Google Podcasts</a>.</p>
<h2 id="game-updates">Game Updates&nbsp;
</h2>
<h3 id="crate-before-attack"><a href="https://cratebeforeattack.com/">Crate Before Attack</a>&nbsp;
</h3>
<p><a href="https://cratebeforeattack.com/"><img src="https://rust-gamedev.github.io/posts/newsletter-013/crate-before-attack.jpeg" alt="Camera debugging in Crate Before Attack"></a>
<em>Debugging camera motion: highlighted areas are points of interest</em></p>
<p><a href="https://cratebeforeattack.com/">Crate Before Attack</a> by <a href="https://twitter.com/CrateAttack">koalefant (@CrateAttack)</a>
is a skill-based multiplayer game where frogs combat their friends
while navigating the landscape with their sticky tongues.</p>
<p>A <a href="https://cratebeforeattack.com/play">playable browser build</a> can be tried online.</p>
<p>Recent changes are:</p>
<ul>
<li>Training mode improvements, including a new map <a href="https://youtu.be/cukyVXQ0n0c">Dungeon</a>
by <a href="https://www.behance.net/spoon_tar">Kesha Astafyev</a>.</li>
<li><a href="https://youtu.be/3y7Hfa-v3e8">Better camera motion</a>:
multiple points of interest are tracked dynamically.</li>
<li>Improved GPU performance by merging multiple render passes into one.</li>
<li>Added control hints.</li>
<li>Numerous bugfixes and tweaks.</li>
</ul>
<p>More details are in <a href="https://cratebeforeattack.com/posts/20200831-august-update/">August DevLog-entry</a>.</p>
<h3 id="veloren"><a href="https://veloren.net/">Veloren</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-013/veloren-landscape1.jpeg" alt="Landscape">
<em>Landscape with new LoD and lighting</em></p>
<p><a href="https://veloren.net/">Veloren</a> is an open world, open-source voxel RPG inspired by Dwarf
Fortress and Cube World.</p>
<p>In August, Veloren 0.7 was released! Airshipper, Veloren's launcher, also got
updated to 0.4.0. Veloren was featured in the inaugural episode of the <a href="https://rustgamedev.com/episodes/interview-with-team-veloren">Rust
Game Dev Podcast</a>. Although the 0.7 release party saw the
largest number of concurrent players at 57, it ran into some significant issues
which you can read about below.</p>
<p>The largest merge in Veloren so far also happened in August. It included
monumental changes to lighting and added level of detail functionality to see
far-off mountains. Lots of work has been done on the animation, combat, SFX, and
UX front. Animations for movement and combat were added and improved. Work
continued on particle systems, which have been added to Veloren in places like
campfires, fireworks, and weapons.</p>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-013/veloren-sceptre.gif" alt="Healing sceptre">
<em>Healing sceptre with the new particle system</em></p>
<p>You can read more about some specific topics from August:</p>
<ul>
<li><a href="https://veloren.net/devblog-79#airshipper-0-4-progress-by-songtronix">Airshipper 0.4.0 Progress</a></li>
<li><a href="https://veloren.net/devblog-79#animation-and-movement-updates-by-slipped">Animation and Movement Updates</a></li>
<li><a href="https://veloren.net/devblog-80#particle-timing-by-lobster">Particle Timing</a></li>
<li>0.7 Release: <a href="https://veloren.net/devblog-81#0-7-release-party-statistics">Party Statistics</a>
and <a href="https://veloren.net/devblog-81#0-7-release-party-kick-disaster-by-xmac94x">Kick Disaster</a></li>
<li><a href="https://veloren.net/devblog-81#sharp-s-lighting-and-world-changes-branch">Lighting and World Changes</a></li>
<li><a href="https://veloren.net/devblog-82#0-8-intro-meeting">0.8 Intro Meeting</a></li>
<li><a href="https://veloren.net/devblog-82#audio-with-ellinia">Audio SFX</a></li>
<li><a href="https://veloren.net/devblog-83#photo-gallery">Photo Gallery</a></li>
</ul>
<p>August's full weekly devlogs: "This Week In Veloren...":
<a href="https://veloren.net/devblog-79">#79</a>,
<a href="https://veloren.net/devblog-80">#80</a>,
<a href="https://veloren.net/devblog-81">#81</a>,
<a href="https://veloren.net/devblog-82">#82</a>,
<a href="https://veloren.net/devblog-83">#83</a>.</p>
<p>In September, work on 0.8 will continue. Some large systems being worked on
include networking, improved persistence stability, and player experience. Game
design is working on improving the connection between the experience a new
player has, and the current game design. The in-progress 0.8 version will likely
be completed more quickly than 0.7, as to not include too many changes.</p>
<h3 id="a-b-street"><a href="https://abstreet.org/">A/B Street</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-013/abstreet.png" alt="Two-way cycletracks and shared left-turn lanes"></p>
<p><a href="https://abstreet.org/">A/B Street</a> is a traffic simulation game exploring how small changes
to roads affect cyclists, transit users, pedestrians, and drivers. Any city
with OpenStreetMap coverage can be used!</p>
<p>Some of this month's updates:</p>
<ul>
<li>Multiple traffic signals can be edited together.</li>
<li>An <a href="https://dabreegster.github.io/abstreet/dev/api.html">API</a> and tools were added, to control maps and simulation
from any language.</li>
<li><a href="https://github.com/michaelkirk">Michael Kirk</a>, a new team member, fixed HiDPI scaling issues in a
consistent way.</li>
<li>Many new cities imported, with better support for countries that drive on the
left and support for using alternate languages from OpenStreetMap for roads
and buildings.</li>
<li>Backwards compatibility for a player's edits to the map.</li>
<li>Two-way cycletracks and roads with multiple direction changes.</li>
</ul>
<h3 id="egregoria"><a href="https://github.com/Uriopass/Egregoria">Egregoria</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-013/egregoria.png" alt="Egregoria buildings screenshot"></p>
<p><a href="https://github.com/Uriopass/Egregoria">Egregoria</a>'s objective is to become a granular society simulation,
filled with fully autonomous agents interacting with their world in real time.
Egregoria was previously known as Scale,
but was renamed to fit the theme better.</p>
<p>The <a href="http://douady.paris/blog/egregoria_5.html">5th devlog</a> was published, talking about
the renaming, project management, buildings and scripting.</p>
<p>A <a href="https://discord.gg/CAaZhUJ">Discord</a> server was launched to discuss the project.</p>
<p><em>Discussions:
<a href="https://reddit.com/r/rust_gamedev/comments/igzbl9/egregoria_devblog_5">/r/rust_gamedev</a></em></p>
<h3 id="cary"><a href="https://specificprotagonist.itch.io/cary">Cary</a>&nbsp;
</h3>
<p><a href="https://specificprotagonist.itch.io/cary"><img src="https://rust-gamedev.github.io/posts/newsletter-013/cary_screenshot.png" alt="Dodging bullets and carrying Cary to temporary safety"></a></p>
<p>In <a href="https://specificprotagonist.itch.io/cary">Cary</a> the player has to bring the titular character to the exit by carrying
them or otherwise making sure they don't – nor the player themselves –
touch any of the traps.
Easier said than done when you have limited stamina and Cary keeps running
into spikes.</p>
<p>Made with hecs and wgpu (no framework), but uses WebGL on the web
because of the current implementation status of WebGPU.</p>
<p>Made during the <a href="https://itch.io/jam/extra-credits-game-jam-6">Extra Credits game jam</a>,
it's a rather small game.
It can be played in the browser or downloaded at <a href="https://specificprotagonist.itch.io/cary">itch.io</a>.</p>
<h3 id="way-of-rhea"><a href="https://store.steampowered.com/app/1110620/Way_of_Rhea/">Way of Rhea</a>&nbsp;
</h3>
<p><a href="https://store.steampowered.com/app/1110620/Way_of_Rhea/"><img src="https://rust-gamedev.github.io/posts/newsletter-013/way-of-rhea-play-nyc.png" alt="Anthropic's virtual booth at Play NYC"></a>
<em>Anthropic's virtual booth at <a href="https://www.play-nyc.com/">Play NYC</a></em></p>
<p><a href="https://store.steampowered.com/app/1110620/Way_of_Rhea/">Way of Rhea</a> is a puzzle platformer that takes place in a world where you can
only interact with items that match your current color.</p>
<p>Way of Rhea has a <a href="https://store.steampowered.com/app/1110620/Way_of_Rhea/">free Steam demo</a> temporarily available as part of
<a href="https://www.play-nyc.com/">Play NYC</a>!
The new demo includes a level that wasn't part of the Steam Game Festival,
showing off how circuit puzzles will work in the game. Since Play NYC
couldn't be in person this year, the devs temporarily themed this level to look
like last year's Play NYC venue, included placing virtual booths for other games
throughout the level.</p>
<p>Follow <a href="https://twitter.com/anthropicst">@AnthropicSt</a> or <a href="https://twitter.com/masonremaley">@masonremaley</a> on Twitter or
<a href="https://www.anthropicstudios.com/newsletter/signup/tech">sign up for the mailing list</a> for updates.</p>
<h3 id="vange-rs"><a href="https://github.com/kvark/vange-rs">vange-rs</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-013/vangers-shadows.jpeg" alt="vangers-shadow"></p>
<p><a href="https://github.com/kvark/vange-rs">vange-rs</a> is the project of re-implementing the <a href="https://en.wikipedia.org/wiki/Vangers">Vangers</a> game (from 1998)
in Rust using modern development practices, parallel computations, and GPU.</p>
<p>This month vange-rs got real-time shadows!
See <a href="https://reddit.com/r/rust_gamedev/comments/i32p6r/realtime_hybrid_shadows_in_vangers">video on /r/rust_gamedev</a> and technical description
on the <a href="https://kvark.github.io/vange-rs/2020/08/04/shadows.html">Hybrid Shadows</a> post of the blog.</p>
<p>Another exciting development - the new bruteforce rendering technique allowing
to shift the camera behind the mechos as in 3rd person view.
See <a href="https://reddit.com/r/rust_gamedev/comments/igejxy/vangers_3rd_person_camera">video on /r/rust_gamedev</a> and technical description on
the <a href="https://kvark.github.io/vange-rs/2020/08/29/bar-painting.html">Bar Painting</a> post of the blog.</p>
<h3 id="garden"><a href="https://epcc.itch.io/garden">Garden</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-013/garden.jpeg" alt="screenshot: concrete, trees, shadows"></p>
<p><a href="https://epcc.itch.io/garden">Garden</a> is an upcoming game centered around growing realistic plants.
Some of the updates from <a href="https://cyberplant.xyz/posts/july-august/">the July &amp; August devlog</a>:</p>
<ul>
<li>A new player inventory system;</li>
<li>Better collision detection and camera movement;</li>
<li>Minimalist, scrollable text-based GUI for choosing which species to plant
or the type of material to build with (or destroy) something;</li>
<li>Plant growth now depends directly on the amount of light
every individual leaf receives, calculated on the GPU;</li>
<li>Variable leaf alignment and ease of creating variety;</li>
<li>Better bark, detailed trunks, and new species;</li>
<li>Completely new lighting using GI.</li>
</ul>
<h3 id="chillscapes"><a href="https://khonsulabs.itch.io/chillscapes">Chillscapes</a>&nbsp;
</h3>
<p><img src="https://rust-gamedev.github.io/posts/newsletter-013/chillscapes_main_menu.png" alt="Chillscapes Main Menu"></p>
<p><a href="https://github.com/khonsulabs/chillscapes">Chillscapes</a> is a lo-fi
rhythm experience created for the <a href="https://itch.io/jam/neoc03-rhythm-jam">NEOC#03 Rhythm Game Jam</a>. Using
layerable lo-fi music tracks, the game has you tap with the rhythm of the loops
being added, before changing the music up by adding another loop into the mix.
Last week, <a href="https://community.khonsulabs.com/t/chillscapes-retrospective-and-kludgine-update/28">a retrospective update was published</a>
reflecting on what the developer's takeaways were from the experience.</p>
<p>Chillscapes is written using an early-in-development 2d engine,
<a href="https://github.com/khonsulabs/kludgine">Kludgine</a>. For audio playback, rodio was utilized. The source code is
<a href="https://github.com/khonsulabs/chillscapes">available on GitHub</a>.</p>
<h3 id="dwarf-seeks-fortune"><a href="https://github.com/amethyst/dwarf_seeks_fortune">Dwarf Seeks Fortune</a>&nbsp;
</h3>
<p><a href="https://github.com/amethyst/dwarf_seeks_fortune"><img src="https://rust-gamedev.github.io/posts/newsletter-013/dwarf_seeks_fortune.png" alt="Dwarf Seeks Fortune"></a>
<em>Collect all keys to unlock the door to the next level</em></p>
<p><a href="https://github.com/amethyst/dwarf_seeks_fortune">Dwarf Seeks Fortune</a> is a puzzle-platformer made with the Amethyst game
engine. Its developer, Jazarro, has partnered with the Amethyst organization
to make it an official Amethyst showcase game. It aims to be a learning
resource for anyone looking to get started with Amethyst.</p>
<p>The game currently sports a growing feature set, two playable levels and an
early version of an integrated level editor. It is ready for your
contributions, so if you're interested, check out the
<a href="https://github.com/amethyst/dwarf_seeks_fortune/blob/master/CONTRIBUTING.md">contributor's guide</a> or the <a href="https://github.com/amethyst/dwarf_seeks_fortune/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22">good first issues</a>.
If you have any questions, open an issue on GitHub or approach
Jazarro on <a href="https://discord.com/invite/amethyst">the Amethyst discord</a>.</p>
<h3 id="akigi"><a href="https://akigi.com/">Akigi</a>&nbsp;
</h3>
<p><a href="https://akigi.com/">Akigi</a> is a WIP online multiplayer game.</p>
<p>This month was mostly dedicated to the custom engine's scenery placement tool
(<a href="https://devjournal.akigi.com/august-2020/082-2020-08-30.html">video demo</a>).
Some of the updates:</p>
<ul>
<li><a href="https://devjournal.akigi.com/august-2020/080-2020-08-16.html">Terrain code refactoring and other required groundwork</a>.</li>
<li><a href="https://devjournal.akigi.com/august-2020/082-2020-08-30.html#mouse-terrain-intersection">Mouse-terrain intersection</a>.</li>
<li><a href="https://devjournal.akigi.com/august-2020/082-2020-08-30.html#play-mode-place-mode">Switching between Play and Place modes</a>.</li>
<li><a href="https://devjournal.akigi.com/august-2020/082-2020-08-30.html#user-interfaces">Custom UI system</a>.</li>
</ul>
<p>Full devlogs:
<a href="https://devjournal.akigi.com/august-2020/078-2020-08-02.html">#078</a>,
<a href="https://devjournal.akigi.com/august-2020/079-2020-08-09.html">#079</a>,
<a href="https://devjournal.akigi.com/august-2020/080-2020-08-16.html">#080</a>,
<a href="https://devjournal.akigi.com/august-2020/081-2020-08-23.html">#081</a>,
<a href="https://devjournal.akigi.com/august-2020/082-2020-08-30.html">#082</a>.</p>
<h3 id="simple-physics"><a href="https://mkhan45.github.io/SIMple-Physics/">SIMple Physics</a>&nbsp;
</h3>
<p><a href="https://mkhan45.github.io/SIMple-Physics/posts/Gifs/"><img src="https://rust-gamedev.github.io/posts/newsletter-013/simple-physics-wave.gif" alt="SIMple Mechanics wave preset"></a>
<em>One of SIMple Mechanic's Lua presets, a colorful wave of bouncing circles</em></p>
<p><a href="https://mkhan45.github.io/SIMple-Physics/">SIMple Physics</a> by <a href="https://github.com/mkhan45">@mkhan45</a> is a set of educational physics
simulators meant to help students and teachers conduct labs without expensive equipment
or in person classes. Each simulator uses serializable graphs, object inspection,
Lua scripting, and a few other features to help students …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rust-gamedev.github.io/posts/newsletter-013/">https://rust-gamedev.github.io/posts/newsletter-013/</a></em></p>]]>
            </description>
            <link>https://rust-gamedev.github.io/posts/newsletter-013/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24406787</guid>
            <pubDate>Tue, 08 Sep 2020 09:44:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the environment influences health and well-being in Europe]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24406757">thread link</a>) | @hmartiniano
<br/>
September 8, 2020 | https://www.eea.europa.eu/publications/healthy-environment-healthy-lives | <a href="https://web.archive.org/web/*/https://www.eea.europa.eu/publications/healthy-environment-healthy-lives">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-core">
                                    <div>

  

  

  

  

  <div>
    <!--<div class="visualClear"></div>-->

    <p><strong>A significant proportion of the burden of disease in Europe continues to be attributed to environmental pollution resulting from human activity. This report highlights how the quality of Europe’s environment plays a key role in determining our health and well-being. </strong>
    </p>


    

      <!--<h2 class="publicationHidden" i18n:translate="" tal:condition="has_children">Content</h2>-->

      

      

      
      <div>
          
          
              
                  

    


<!-- LANGUAGE SWITCHER DEFINITION -->


    

        

    



    <p><span>Publication</span>

            

            

            <span>
                <span></span>
                Created 18 Aug 2020
            </span>
            <span>
                <span></span>
                Published 08 Sep 2020
            </span>
            
        

        

        
        


      

    </p>





    
    
    
            
        




<!-- environmental topics tags -->


    

      

    




              
          
          
      </div>
      

      <p>EEA Report No 21/2019</p>

      <p><strong>A significant proportion of the burden of disease in Europe continues to be attributed to environmental pollution resulting from human activity. This report highlights how the quality of Europe’s environment plays a key role in determining our health and well-being. </strong>
      </p>

      <h2>Download</h2>
      <ul> 
        <li>
          <a href="https://www.eea.europa.eu/publications/healthy-environment-healthy-lives/at_download/file">
            <img src="https://www.eea.europa.eu/publications/healthy-environment-healthy-lives/pdf.png">
            <span>Healthy Environment_TH-AL-20-005-EN-N.pdf</span>
          </a>
          <span>[38.6 MB]</span>
        </li>
      </ul>

      

      

      <h2>Additional Files</h2>
      <ul id="report-files">
        
      </ul>
    

    

    
      
    

    

  </div>

</div>
                                </div><div>
                                  <div>
                                    
  



    
    

    
    
            

          
            
          
        





<!-- Geographic coverage -->

  <div>
        
        
    
      
        
                
                <h3>Geographic coverage</h3>
            
            
        
               
                <p><span rel="tag">Albania</span>
                    
                        <span rel="tag">Austria</span>
                    
                        <span rel="tag">Belgium</span>
                    
                        <span rel="tag">Bosnia and Herzegovina</span>
                    
                        <span rel="tag">Bulgaria</span>
                    
                        <span rel="tag">Croatia</span>
                    
                        <span rel="tag">Cyprus</span>
                    
                        <span rel="tag">Czechia</span>
                    
                        <span rel="tag">Denmark</span>
                    
                        <span rel="tag">Estonia</span>
                    
                        <span rel="tag">Finland</span>
                    
                        <span rel="tag">France</span>
                    
                        <span rel="tag">Germany</span>
                    
                        <span rel="tag">Greece</span>
                    
                        <span rel="tag">Hungary</span>
                    
                        <span rel="tag">Iceland</span>
                    
                        <span rel="tag">Ireland</span>
                    
                        <span rel="tag">Italy</span>
                    
                        <span rel="tag">Kosovo</span>
                    
                        <span rel="tag">Latvia</span>
                    
                        <span rel="tag">Liechtenstein</span>
                    
                        <span rel="tag">Lithuania</span>
                    
                        <span rel="tag">Luxembourg</span>
                    
                        <span rel="tag">Malta</span>
                    
                        <span rel="tag">Montenegro</span>
                    
                        <span rel="tag">Netherlands</span>
                    
                        <span rel="tag">North Macedonia</span>
                    
                        <span rel="tag">Norway</span>
                    
                        <span rel="tag">Poland</span>
                    
                        <span rel="tag">Portugal</span>
                    
                        <span rel="tag">Romania</span>
                    
                        <span rel="tag">Serbia</span>
                    
                        <span rel="tag">Slovakia</span>
                    
                        <span rel="tag">Slovenia</span>
                    
                        <span rel="tag">Spain</span>
                    
                        <span rel="tag">Sweden</span>
                    
                        <span rel="tag">Switzerland</span>
                    
                        <span rel="tag">Turkey</span>
                    
                        <span rel="tag">United Kingdom</span>
                    
                </p>
            
            
      
    
  

  </div>


<!-- Temporal coverage -->



    
    
            <!-- Title -->
     <div>
            <h3>Temporal coverage</h3>

            <!--- Body -->
            
              <p><span>
                    <span rel="tag">Dynamic</span>
                </span>
              </p>
            
       </div>
    






<!-- Exclude coverage -->

    








                                  </div>
                                     </div></div>]]>
            </description>
            <link>https://www.eea.europa.eu/publications/healthy-environment-healthy-lives</link>
            <guid isPermaLink="false">hacker-news-small-sites-24406757</guid>
            <pubDate>Tue, 08 Sep 2020 09:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PandaDoc Employees Arrested in Belarus After Founders Protest Against Violence]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24406366">thread link</a>) | @perch56
<br/>
September 8, 2020 | https://savepandadoc.org/en/ | <a href="https://web.archive.org/web/*/https://savepandadoc.org/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>Friends,</p>
          <p>On&nbsp;September 2, the Belarus government ordered searches to&nbsp;be&nbsp;conducted at&nbsp;the Minsk office of&nbsp;PandaDoc. During the search, more than 20 employees were prevented from leaving and 7 of&nbsp;them were taken into custody and detained for further interrogation. Some of&nbsp;these employees were subsequently taken into custody from their homes.</p>
          <p>Over the next two days, the Financial Investigation Department (FID) arm of&nbsp;the Belarus government interviewed more than one hundred company employees. During those two days, the employees that had been taken into custody were also denied the rights to&nbsp;legal counsel.</p>
          <p>Today, on&nbsp;September 4, 2020 we&nbsp;were told that a&nbsp;criminal case was retroactively initiated against PandaDoc employees under part 4 of&nbsp;article 210 of&nbsp;the Criminal Code of&nbsp;the Republic of&nbsp;Belarus. Our employees are accused of&nbsp;taking one hundred and seven thousand Belarusian rubles (~40k USD) from the corporate accounts of&nbsp;the company in&nbsp;Minsk abusing their positions, thus causing damage to&nbsp;the&nbsp;State. As&nbsp;a&nbsp;result, our employees have now been placed into custody for two months.</p>
          <p>We&nbsp;declare that this accusation by&nbsp;the State of&nbsp;Belarus is&nbsp;completely untrue and has no&nbsp;grounds.</p>
          <p>All the company’s activities in&nbsp;Belarus were conducted since its inception in&nbsp;full compliance with the&nbsp;law. Several international audits and inspections by&nbsp;EY&nbsp;and other reputable companies over the last years prove that the company adhered to&nbsp;all regulations and laws prevalent in&nbsp;Belarus.</p>
          <p>As&nbsp;recent events in&nbsp;Belarus have demonstrated, it&nbsp;is&nbsp;a&nbsp;common practice of&nbsp;the Belarusian government to&nbsp;oppress political opponents. In&nbsp;this case, the authorities have taken four completely innocent people hostage.</p>
          <p>This action is&nbsp;purely an&nbsp;act of&nbsp;repression against the founders of&nbsp;PandaDoc who have been supporting some of&nbsp;the victims of&nbsp;the Belarussian government in&nbsp;the weeks since the stolen Presidential election. The only purpose of&nbsp;this private initiative by&nbsp;Mikita and Sergey has been intended to&nbsp;help stop the violence and is&nbsp;in&nbsp;no&nbsp;way related to&nbsp;PandaDoc.</p>
          <p>In&nbsp;response the government has imprisoned:</p>
          <ul>
            <li><strong>Yulia Shardyko</strong>, Accountant</li>
            <li><strong>Dmitry Rabtsevich</strong>, Director&nbsp;— Minsk office</li>
            <li><strong>Viktor Kuvshinov</strong>, Product director</li>
            <li><strong>Vladislav Mikholap</strong>, HR</li>
          </ul>
          <p>The law in&nbsp;Belarus has ceased to&nbsp;exist. The authorities do&nbsp;not even bother to&nbsp;act according to&nbsp;the prevailing rules and laws of&nbsp;the country. The case and charges are fabricated cases upon political orders ordered from somewhere in&nbsp;the government. This affects everyone in&nbsp;Belarus.</p>
          <h2>We&nbsp;ask of&nbsp;you:</h2>
          <ol>
            <li>Record a&nbsp;video in&nbsp;our support with the tag <strong>#SavePandaDoc</strong>.</li>
            <li>To&nbsp;express your disagreement in&nbsp;the press, media and social networks with the <strong>#SavePandaDoc</strong> tag.</li>
            <li>Connect us&nbsp;to&nbsp;journalists and reporters that you&nbsp;know. Our contact is&nbsp;<a href="mailto:savepandadoc@gmail.com">savepandadoc@gmail.com</a>.</li>
          </ol>
          <p>We&nbsp;are hoping that maximum publicity will show solidarity and pressure to&nbsp;have our colleagues released.</p>
          <p>—&nbsp;Pandas</p>
        </div></div>]]>
            </description>
            <link>https://savepandadoc.org/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24406366</guid>
            <pubDate>Tue, 08 Sep 2020 08:29:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Link to WayBackMachine Instead of Original Web Content]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 82 (<a href="https://news.ycombinator.com/item?id=24406193">thread link</a>) | @puggo
<br/>
September 8, 2020 | https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/ | <a href="https://web.archive.org/web/*/https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <div>
        <div id="content">
          <article>
    
    

    
    <div>
      <p><img src="https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/wayback.jpg" alt="WayBackMachine"></p>
<hr>
<p>When linking to a page for the <strong>purpose of reference</strong>, it seems better to me to <em><strong>link to the <a href="https://archive.org/">archive</a> of a given page</strong></em>, rather than to the original site itself.</p>
<p>This ensures that after some years have gone by, <strong>my article is guaranteed to be consistent</strong>. Due the  changing nature of the web, there is a chance that after some years, the link could lead to a:</p>
<ul>
<li>404 /  Not Found (most common)</li>
<li>Changed or edited content, or entirely replaced content</li>
<li>Content that, due to a rise in popularity, is now shielded, demanding the user to make an account to read the entire article.</li>
</ul>
<hr>

<p>Take defensive measures. To future-proof your content, rather than reference the general web, its far more reliable to link to an archive.</p>
<h2 id="example">Example:</h2>
<p>The Epoch Times wrote an article on Smartphones data-mining their users. This is the archived article here:</p>
<p><a href="https://web.archive.org/web/20190214015500/https://www.theepochtimes.com/smartphone-app-users-are-data-mined-even-when-not-using-the-apps_2787202.html">The Archive Version (fully readable)</a></p>
<h3 id="article-content-before">Article Content Before</h3>
<p>You can see its perfectly “normal” readable useful  content.</p>
<p><img src="https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/link-content-before.png" alt="Article Link Content Before"></p>
<h3 id="article-content-after">Article Content After</h3>
<p>Now it’s spam from a site suffering financial need.</p>
<p><img src="https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/link-content-after.png" alt="Article Link Content Before"></p>
<p>So in Feb 14 2019 your users would have seen the content you intended. However in Sep 07 2020, your users are being asked to support independent Journalism instead.</p>
<h2 id="if-an-archive-record-doesnt-exist-make-one">If an Archive Record Doesn't Exist, Make One</h2>
<p>Its worth the extra moment, in referencing a site, to make an archive of the page you wish to reference, if one does not exist. After that, immediately use the link from the archive.org entry, rather than the blog, news, info, or forum site you wish to refer to.</p>
<h2 id="in-unstable-times-take-measures-for-stability">In Unstable Times, Take Measures for Stability</h2>
<p>The web is a fast changing place. Even more during the Covid pandemic and suffering financial markets. Since times are financially harder, websites are disappearing, heaping up advertising, demanding user response, and things like this.</p>
<p>To avoid your content losing quality due to these things, linking to a solid, unchanging static copy of the page is far more reliable.</p>

    </div>

    <div>
  <p>
    <span>Author</span>
    <span>Leo Blanchette</span>
  </p>
  <p>
    <span>LastMod</span>
    <span>
        2020-09-07
        
    </span>
  </p>
  
  
</div>

  </article>
        </div>
        

  

  

      </div>
    </div></div>]]>
            </description>
            <link>https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24406193</guid>
            <pubDate>Tue, 08 Sep 2020 08:03:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Past Attempts of Software Metrics Have Failed Us]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24406030">thread link</a>) | @abyx
<br/>
September 8, 2020 | https://www.usehaystack.io/blog/software-development-metrics-pros-cons-and-why-past-attempts-have-failed | <a href="https://web.archive.org/web/*/https://www.usehaystack.io/blog/software-development-metrics-pros-cons-and-why-past-attempts-have-failed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="0ea0c8ae-8333-a516-8908-f86a85ef9373"><p>TLDR; Software engineering is a black box. It's incredibly complex and nuanced. The industry makes attempts to stack rank and measure via simplified metrics. This is the wrong approach and hurts engineering culture. Software is complex, previous attempts don't take that into account. There is a better solution.</p><p>‍</p><p><strong>Software engineering is a black box because</strong></p><ol role="list"><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#990eff2e60e346b282c47abcb5687b96" target="_blank">Software engineering is complex and invisible</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#d32d356b92594f6cbb8a4993cdf1c2d0" target="_blank">The output of software development varies</a></li></ol><p>‍</p><p><strong>There have been several attempts at quantifying developer productivity. The limited content you'll find fits into a few categories.</strong></p><ol role="list"><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#128c578b6c9c489d8c53525166e0f932" target="_blank">KPIs used to measure software engineer performance</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#8d31dd02f20a42a6b1b586b955207ce4" target="_blank">Methods of measuring developer performance and their fall backs</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#dbf2216d7f134396bcfe69185e96c1a9" target="_blank">Opinion pieces on if measurement is even possible</a></li></ol><p>‍</p><p><strong>You'll notice a pattern prevalent in the space. The industry is obsessed with finding</strong></p><ol role="list"><li>Golden metrics to stack rank and compare teams and individuals.</li><li>KPIs to objectively determine an engineer's performance.</li></ol><p>‍</p><p><strong>The result?</strong></p><p>Attempts to measure software engineer and team productivity using the same, simplified metrics and KPIs.</p><p>‍</p><p><strong>But that's the wrong approach..</strong></p><ol role="list"><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#5f58624ed1f6432087fa3ef21378cf0b" target="_blank">Attempting to stack rank is fundamentally flawed</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#447680dd5e204f8a8bb526db55ebbe5c" target="_blank">'Successful outcomes' are situational</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#ea18251c7c0a4d50a1eb57e1e34f7ff8" target="_blank">Simplified metrics hurt engineering culture</a></li></ol><p>‍</p><p><strong>Focus on productivity, not yard sticks</strong></p><ol role="list"><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#c685ee9fc42c4c678d86b85f01006df8" target="_blank">Measure engineers and teams independently</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#dcd2a669df6a4e97afa9ec24e25fbc14" target="_blank">Compare relative to individual history</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#b0b75fb866ee44d29f9a5862be9e2579" target="_blank">Identify the main risks and bottlenecks of productivity</a></li></ol><p>‍</p><p><strong>Why is this better?</strong></p><ol role="list"><li><a href="https://www.notion.so/usehaystack/Footnotes-f56dc18398104dca8534fc1e1ddd4ff2#95433ef2f1cb46c5ac5b116b3221ac69" target="_blank">Accurately measures productivity</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#f20c40f07837457ea2dc431fbbeb4c6c" target="_blank">Handles situational outcomes</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#0f37d98374d64ea3a76d2b179cc16a74" target="_blank">Supports engineering culture</a></li><li><a href="https://www.notion.so/usehaystack/Footnotes-f56dc18398104dca8534fc1e1ddd4ff2#d09f4a9a554643139c1c3d9f0987e1a4" target="_blank">Enables early risk identification</a></li></ol><p>‍</p><p><strong>Main takeaway:</strong></p><p>From the nature of the work to the culture that supports it, engineering is incredibly complex and nuanced. Previous attempts at measuring engineering performance have done a poor job of taking this complexity into account. Making attempts to measure each engineer and team against the same yard stick not only hurts culture, but gives no true indication of productivity to begin with.</p><p>‍</p><p>To date, the industry has been attempting this 'holy grail' of software development metrics from the wrong perspective. By focusing on drivers and blockers of productivity rather than KPIs and stack ranking; we can start to measure engineers and teams in a healthy way. More importantly, this new perspective enables engineering leaders to introduce a software development metrics to help improve while maintaining the highest impact driver of productivity (culture).</p><p>‍</p><p>Check out Haystack's approach <a href="https://usehaystack.io/">here</a>!</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5ef130052901e5cad8432b81_Haystack_Designed_Presentation.png" alt=""></p></figure><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=3%20git%20signals%20to%20identify%20blockers&amp;utm_campaign=inside%20blog">Haystack</a> helps engineering leaders identify blockers and trends. Directly from Github. Instead of guessing if you're improving, or constantly bothering your team for progress updates, simply use Haystack to get alerts in your inbox every morning. Plus a dashboard to track improvements over time.</p><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=3%20git%20signals%20to%20identify%20blockers&amp;utm_campaign=inside%20blog">Try it for free</a></p><p>‍</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.usehaystack.io/blog/software-development-metrics-pros-cons-and-why-past-attempts-have-failed</link>
            <guid isPermaLink="false">hacker-news-small-sites-24406030</guid>
            <pubDate>Tue, 08 Sep 2020 07:32:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Escape from creek fire]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24405981">thread link</a>) | @twohey
<br/>
September 8, 2020 | https://www.jmeshe.co/escape-from-creek-fire | <a href="https://web.archive.org/web/*/https://www.jmeshe.co/escape-from-creek-fire">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><span>
By subscribing to the mailing list of
<strong>
Jaymie Shearer
</strong>
your email address is stored securely, opted into new post notifications and related communications. We respect your inbox and privacy, you may unsubscribe at any time.
</span></p><div>
<p><a href="https://www.exposure.co/privacy" rel="noopener" target="_blank" title="Link to Jaymie Shearer Privacy Policy">
Privacy Policy
</a>
<a href="https://www.exposure.co/terms" rel="noopener" target="_blank" title="Link to Jaymie Shearer Terms of Service">
Terms of Service
</a>
<a href="https://www.exposure.co/report" rel="noopener" target="_blank" title="Report a story or story">
Report
</a>
</p></div>

</div>
</div></div>]]>
            </description>
            <link>https://www.jmeshe.co/escape-from-creek-fire</link>
            <guid isPermaLink="false">hacker-news-small-sites-24405981</guid>
            <pubDate>Tue, 08 Sep 2020 07:22:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[12 HTML Tags You Don't Know]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24405930">thread link</a>) | @fazlerocks
<br/>
September 8, 2020 | https://jatinrao.dev/12-html-tags-you-dont-know | <a href="https://web.archive.org/web/*/https://jatinrao.dev/12-html-tags-you-dont-know">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1599487255172/h-E8UqMpi.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>HTML (Hyper Text Markup Language) is used to design web pages using a  combination of Hypertext and Markup language.</p>
<p>In this post, we're going to take a look at some cool stuff that can be done using HTML. Let's look at some of the html tags, you might not be knowing even existed.
ould be making use of today.</p>
<p>Let's get started 💪</p>
<hr>
<h2 id="1-the-lessfiguregreater-tag">1. The <code>&lt;figure&gt;</code> tag</h2>
<p>This can be used to mark up a photo. The <code>&lt;figure&gt;</code> element can also contain a <code>&lt;figcaption&gt;</code>.</p>
<pre><code><span>&lt;<span>figure</span>&gt;</span>
  <span>&lt;<span>img</span> <span>src</span>=<span>"https://images.unsplash.com/photo-1593642634315-48f5414c3ad9"</span> <span>alt</span>=<span>"Person using lack laptop computer on brown wooden table"</span> <span>style</span>=<span>"width:100%"</span>&gt;</span>
  <span>&lt;<span>figcaption</span>&gt;</span>Person using lack laptop computer on brown wooden table<span>&lt;/<span>figcaption</span>&gt;</span>
<span>&lt;/<span>figure</span>&gt;</span>
</code></pre>
<h2 id="2-the-lessaudiogreater-tag">2. The <code>&lt;audio&gt;</code> tag</h2>
<p>⁣<code>&lt;audio&gt;</code> element provides a way to add audio resources to a web page without the need to use any other plugin.⁣ It's used to play a sound much as music or an audio stream. It supports mp3, wav and ogg.
⁣
A fallback text is enclosed within the tag to be shown to browsers that don't support the element.⁣
⁣
By default, the browser does not show any controls. ⁣
To add the ability for users to play, pause, adjust volume, etc. the 'controls' attribute can be used.</p>
<pre><code><span>&lt;<span>audio</span> <span>controls</span>&gt;</span>
  <span>&lt;<span>source</span> <span>src</span>=<span>"music.mp4"</span> <span>type</span>=<span>"audio/mp4"</span>&gt;</span>
  <span>&lt;<span>source</span> <span>src</span>=<span>"mucis.ogg"</span> <span>type</span>=<span>"audio/ogg"</span>&gt;</span>
<span>&lt;/<span>audio</span>&gt;</span>
</code></pre>
<h2 id="3-the-lessvideogreater-tag">3. The <code>&lt;video&gt;</code> tag</h2>
<p>This allows you to embed a media player for video playback. 
It's used to play a video clop or a video stream without embedding youtube or vimeo videos. It supports mp4, webm and ogg.</p>
<p>For example, you can upload your video on AWS S3 and use the <code>&lt;video&gt;</code> tag to embed it on your website.</p>
<p>You can also specify certain attributes, such as width, height, autoplay, loop, controls, etc.</p>
<pre><code><span>&lt;<span>video</span> <span>width</span>=<span>"960"</span> <span>height</span>=<span>"540"</span> <span>controls</span>&gt;</span>
  <span>&lt;<span>source</span> <span>src</span>=<span>"video.mp4"</span> <span>type</span>=<span>"video/mp4"</span>&gt;</span>
  <span>&lt;<span>source</span> <span>src</span>=<span>"video.ogg"</span> <span>type</span>=<span>"video/ogg"</span>&gt;</span>
<span>&lt;/<span>video</span>&gt;</span>
</code></pre>

<h2 id="4-the-lessprogressgreater-tag">4. The <code>&lt;progress&gt;</code> tag</h2>
<p>The <code>&lt;progress&gt;</code> tag represents the progress of a task.</p>
<p>The <code>&lt;progress&gt;</code> tag should not be confused with the <code>&lt;meter&gt;</code> tag (which represents a gauge). It has two attributes value and max.⁣⁣</p>
<pre><code><span>&lt;<span>progress</span> <span>value</span>=<span>"57"</span> <span>max</span>=<span>"100"</span>&gt;</span>
<span>&lt;/<span>progress</span>&gt;</span>
</code></pre>

<h2 id="5-the-lessmetergreater-tag">5. The <code>&lt;meter&gt;</code> tag</h2>
<p>You can use the meter element to measure data within a given range (a gauge).</p>
<p>This can be achieved with min and max values or with a percentage.</p>
<pre><code><span>&lt;<span>meter</span> <span>value</span>=<span>"7"</span> <span>min</span>=<span>"0"</span> <span>max</span>=<span>"10"</span>&gt;</span>7 out of 10<span>&lt;/<span>meter</span>&gt;</span>

<span>&lt;<span>meter</span> <span>value</span>=<span>"0.4"</span>&gt;</span>40%<span>&lt;/<span>meter</span>&gt;</span>
</code></pre>

<h2 id="6-the-lessdatagreater-tag">6. The <code>&lt;data&gt;</code> tag</h2>
<p>It specifies the machine-readable translation of the content of the element. It also provides a human-readable text.</p>
<pre><code><span>&lt;<span>ul</span>&gt;</span>
  <span>&lt;<span>li</span>&gt;</span>
    <span>&lt;<span>data</span> <span>value</span>=<span>"010"</span>&gt;</span>Dogs<span>&lt;/<span>data</span>&gt;</span>
  <span>&lt;/<span>li</span>&gt;</span>
  <span>&lt;<span>li</span>&gt;</span>
    <span>&lt;<span>data</span> <span>value</span>=<span>"011"</span>&gt;</span>Cats<span>&lt;/<span>data</span>&gt;</span>
  <span>&lt;/<span>li</span>&gt;</span>
<span>&lt;/<span>ul</span>&gt;</span>
</code></pre>
<h2 id="7-the-lessdatalistgreater-tag">7. The <code>&lt;datalist&gt;</code> tag</h2>
<p>⁣The <code>&lt;datalist&gt;</code> tag is used to provide autocomplete feature in the input field of the form.⁣
⁣
It specifies the set of predefined suggestions for the user to input.⁣</p>
<pre><code><span>&lt;<span>input</span> <span>type</span>=<span>"text"</span> <span>list</span>=<span>"days"</span> <span>placeholder</span>=<span>"Choose a Day"</span>&gt;</span>
<span>&lt;<span>datalist</span> <span>id</span>=<span>"days"</span>&gt;</span>
  <span>&lt;<span>option</span> <span>value</span>=<span>"Monday"</span>&gt;</span><span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span> <span>value</span>=<span>"Tuesday"</span>&gt;</span><span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span> <span>value</span>=<span>"Wednesday"</span>&gt;</span><span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span> <span>value</span>=<span>"Thursday"</span>&gt;</span><span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span> <span>value</span>=<span>"Friday"</span>&gt;</span><span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span> <span>value</span>=<span>"Saturday"</span>&gt;</span><span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span> <span>value</span>=<span>"Sunday"</span>&gt;</span><span>&lt;/<span>option</span>&gt;</span>
<span>&lt;/<span>datalist</span>&gt;</span>
</code></pre>

<h2 id="8-the-lessnoscriptgreater-tag">8. The <code>&lt;noscript&gt;</code> tag</h2>
<p>The content inside the <code>&lt;noscript&gt;</code> element is rendered by the browser only when JavaScript is disabled. It provides a fallback mechanism for the components that will stop working without JavaScript.</p>
<pre><code><span>&lt;<span>noscript</span>&gt;</span><span>&lt;<span>h2</span>&gt;</span>JavaScript is disabled in your browser.<span>&lt;/<span>h2</span>&gt;</span><span>&lt;/<span>noscript</span>&gt;</span>
</code></pre>
<h2 id="9-the-lessdetailgreater-tag">9. The <code>&lt;detail&gt;</code> tag</h2>
<p>The <code>&lt;⁣detail&gt;</code> tag is used to make collapsible sections when it is required to provide extra information about a subject that users can hide or view by their choice.
⁣
It uses the <code>&lt;summary&gt;</code> tag which specifies the title that can be clicked to expand or collapse the details.⁣</p>
<pre><code><span>&lt;<span>details</span>&gt;</span>
  <span>&lt;<span>summary</span>&gt;</span>Click To Open<span>&lt;/<span>summary</span>&gt;</span>
  Hey, I am natively collapsable section. My content remains hidden till you click on summary.
<span>&lt;/<span>details</span>&gt;</span>
</code></pre>

<h2 id="10-the-lesswbrgreater-tag">10. The <code>&lt;wbr&gt;</code> tag</h2>
<p>The <code>&lt;wbr&gt;</code> tag stands for word break 🍞 opportunity which is used when a word is too long, and you don't want the browser to break it at the random place,  helps to break the word where you want.⁣</p>
<pre><code><span>&lt;<span>p</span>&gt;</span>This is a lonnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnngggggggggggggggggggggggggggggggggggggggggg<span>&lt;<span>wbr</span>&gt;</span>word.<span>&lt;/<span>p</span>&gt;</span>
</code></pre>
<h2 id="11-the-lessmarkgreater-tag">11. The <code>&lt;mark&gt;</code> tag</h2>
<p><code>&lt;mark&gt;</code> is a very simple and useful native tag used to add some nice highligting in your webpage without any CSS. </p>
<pre><code><span>&lt;<span>p</span>&gt;</span>HTML can do <span>&lt;<span>mark</span>&gt;</span> MAGIC <span>&lt;/<span>mark</span>&gt;</span>.<span>&lt;/<span>p</span>&gt;</span>
</code></pre>

<h2 id="12-the-lessinsgreater-and-lessdelgreater-tag">12. The <code>&lt;ins&gt;</code> and <code>&lt;del&gt;</code> tag</h2>
<p><code>&lt;ins&gt;</code> element indicates text that has been added to the document.⁣⁣
<code>&lt;del&gt;</code> is used for the text that has been deleted from the document.⁣⁣</p>
<pre><code><span>&lt;<span>p</span>&gt;</span>Jatin is a
  <span>&lt;<span>del</span>&gt;</span>spider man<span>&lt;/<span>del</span>&gt;</span>
  <span>&lt;<span>ins</span>&gt;</span>web developer<span>&lt;/<span>ins</span>&gt;</span>
  from India.
<span>&lt;/<span>p</span>&gt;</span>
</code></pre>

<hr>
<h2 id="references">References</h2>
<ul>
<li><p><a target="_blank" href="https://dev.to/ananyaneogi/html-can-do-that-c0n">HTML can do that?</a> by <a target="_blank" href="http://twitter.com/_ananyaneogi">Ananya Neogi</a></p>
</li>
<li><p><a target="_blank" href="https://dev.to/emmabostian/10-html-element-you-didnt-know-you-needed-3jo4">10 HTML Elements You Didn't Know You Needed</a> by <a target="_blank" href="http://twitter.com/EmmaBostian">Emma Bostian</a></p>
</li>
<li><p><a target="_blank" href="https://htmlreference.io/">HTML Reference</a> for overview of various HTML tags.</p>
</li>
</ul>
<hr>
<p>You can also connect with me on <a target="_blank" href="https://discord.gg/3Ks7sMA">Discord</a> .</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://jatinrao.dev/12-html-tags-you-dont-know</link>
            <guid isPermaLink="false">hacker-news-small-sites-24405930</guid>
            <pubDate>Tue, 08 Sep 2020 07:13:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Invisible Salamanders in AES-GCM-SIV]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24405583">thread link</a>) | @some_furry
<br/>
September 7, 2020 | https://keymaterial.net/2020/09/07/invisible-salamanders-in-aes-gcm-siv/ | <a href="https://web.archive.org/web/*/https://keymaterial.net/2020/09/07/invisible-salamanders-in-aes-gcm-siv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-95">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>By now, many people have run across the <a href="https://eprint.iacr.org/2019/016.pdf">Invisible Salamander</a> paper about the interesting property of AES-GCM, that allows an attacker to construct a ciphertext that will decrypt with a valid tag under two different keys, provided both keys are known to the attacker. On some level, finding properties like this isn’t too surprising: AES-GCM was designed to be an AEAD, and nowhere in the AEAD definition does it state anything about what attackers with access to the keys can do, since the usual assumption is that attackers don’t have that access, since any Alice-Bob-Message model would be meaningless in that scenario.</p>



<p>What is interesting to me is that this property comes up more often than one would think, I ran across it several times now during my work reviewing cryptographic designs, it’s far from an obscure property for real world systems. The general situation these systems have in common is that they involve three parties: Alice, Bob, and Trent. Trent is a trusted third party for Bob, who is allowed to read messages and scan them, with details like when and why depending on the crypto system in question. While Trent and Bob agree on the ciphertext<em>—</em>say because Trent hands Bob the ciphertext or because Alice presents Trent’s signature on it<em>—</em>Alice has the option of giving Trent and Bob different keys. The challenge for Alice is to come up with a ciphertext that has a valid authentication tag and still decrypts to different messages for Trent and Bob.</p>



<h4>Mitigations</h4>



<p>Before I dive deeper into how to construct invisible salamanders for AES-GCM and AES-GCM-SIV, a few words on how to defend against these problems. The easiest option here is to add a hash of the key to the ciphertext. This technically violates indistinguishability, as the identity of the key is leaked, i.e. an attacker now knows which key was used for the message. If indistinguishability is necessary, using the IV as a salt for the hash works well, constructions like <code>HMAC-SHA-2(key=IV, message=key)</code> (i.e. aka HKDF-expand) work well here, as long as attention is paid on whether or not this key hash can be used in any other context. In general, it shouldn’t because the key already should only be used for AES-GCM/AES-GCM-SIV, but real world systems sometimes have weird properties.</p>



<h4>Constructing Salamanders</h4>



<p>With the mitigation out of the way, onto the fun part: Constructing the messages. In order to understand why and how these attacks work, we first have to talk about <span data-katex-display="false">\mathbb{F}_{2^{128}}</span> and the way AES-GCM and AES-GCM-SIV use this field to construct their respective tags. As a finite field <span data-katex-display="false">\mathbb{F}_{2^{128}}</span> supports addition, multiplication, and division, following the usual field axioms. The field has characteristic 2, which means addition is just the xor operator, and subtraction is the exact same operation as addition. Multiplication and division is somewhat more complicated and not in scope for this article, it suffices to say that multiplication can be implemented with a very fast algorithm if the hardware supports certain instruction sets (carryless multiplication). The division algorithm uses the Euclidean algorithm and will at most take 256 multiplications in a naive implementation, so while slower than the other operations, it will still be extremely fast. I will use <span data-katex-display="false">+</span> for the addition operation and <span data-katex-display="false">\cdot</span> for the multiplication operation. The most important caveat is to not confuse these operations with integer arithmetic.</p>



<h5>AES-GCM</h5>



<p>Next, on to <a href="https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-38d.pdf">AES-GCM</a>. This AEAD is a relatively straightforward implementation of an AEAD that uses a UHF based MAC for authentication. Our IV is 12 byte long, we use a 4 byte counter and CTR mode to encrypt the message. The slightly odd feature is that we start the counter at 2, for reasons we will see later. For authentication, we first derive an authentication key <span data-katex-display="false">H</span> by encrypting the zero block (This is why we don’t start the counter at zero, otherwise the zero IV would be invalid). Now, using the ciphertext blocks, additional data blocks (both padded with zeros as needed for the last block), and adding a special length block containing the size of the additional data and the ciphertext, we get a collection of blocks, all of which I will refer to as <span data-katex-display="false">C_i</span>. To compute the tag, we now compute the polynomial</p>



<p><span data-katex-display="true">GHASH(H, C, T) = C_0\cdot H^{n+1} + C_1\cdot H^{n}+\dots + C_{n-1}\cdot H^2+C_n\cdot H+T</span></p><p>The constant term, <span data-katex-display="false">T</span> is the encrypted counter block associated to the counter variable of 1 (Which is why we started at 2 for the CTR mode). Remember that in characteristic 2 <span data-katex-display="false">+</span> is xor, so we could equivalently say that we compute the polynomial without the constant term and then encrypt it with CTR mode as the first block.</p>



<p>Now, how do we get two different plaintexts to agree on both ciphertext and tag, we first choose two keys and produce the corresponding keystreams, choosing the plaintexts so that the ciphertexts agree (If you want two plaintext that make sense, this part is the hardest step, you first brute force the first few bytes in order to be valid in one format and a comment opening statement in the other, so that you can switch which parts of the ciphertext will appear as valid plaintext and which parts appear as commented out). We leave one ciphertext block open for now, as a sacrificial block that we will modify in order to make the tags turn out to be the same. Next derive the corresponding authentication keys <span data-katex-display="false">H_1</span> and <span data-katex-display="false">H_2</span> and our constant terms <span data-katex-display="false">T_1, T_2</span>. This means, we have <span data-katex-display="false">C_i</span> fixed, except for a specific index, say <span data-katex-display="false">j</span>, and can now solve</p>



<p><span data-katex-display="true">GHASH(H_1, C, T_1) =GHASH(H_2, C, T_2)</span>



<span data-katex-display="true">\sum_{i=0}^n C_i\cdot H_1^{n+1-i}+T_1=\sum_{i=0}^n C_i\cdot H_2^{n+1-i}+T_2</span>



<span data-katex-display="true">C_j\cdot\left(H_1^{n+1-j}+H_2^{n+1-j}\right)=\sum_{\substack{i=0\\i\neq j}}^n C_i\cdot \left(H_1^{n+1-i}+H_2^{n+1-i}\right)+T_1+T_2</span>



<span data-katex-display="true">C_j=\left(H_1^{n+1-j}+H_2^{n+1-j}\right)^{-1}\cdot\left(\sum_{\substack{i=0\\i\neq j}}^n C_i\cdot \left(H_1^{n+1-i}+H_2^{n+1-i}\right)+T_1+T_2\right)</span></p><p>by solving for the sacrificial block <span data-katex-display="false">C_j</span>.</p>



<h5>AES-GCM-SIV</h5>



<p>So far so good, but, what about <a href="https://tools.ietf.org/html/rfc8452">AES-GCM-SIV</a>? GCM is famous for having many weird properties that make it extremely fragile, like leaking the authentication key on a single IV reuse, or allowing for insecure tags smaller than 128 bits. In many ways, AES-GCM-SIV is how AES-GCM should look like for real world applications, much more robust against IV reuse, only revealing the damaging properties of an UHF with a reused IV if both IV and tag are the same. This is accomplished through using the tag as a synthetic IV, meaning the tag is computed over the plaintext, and then used as IV for CTR mode to encrypt. Even though this kind of SIV construction uses MAC-then-Encrypt, they are secure against the usual downsides due to CTR mode always succeeding in constant time, independent of the plaintext. This means the receiver can decrypt the message and validate the tag without revealing information about the plaintext in case of an invalid tag. The library needs to take care that the plaintext is properly discarded and not exposed to the user in case the tag does not validate.</p>



<p>The actual IV for AES-GCM-SIV is used primarily derive a per message key. This means that if the IV of two messages is different, both encryption and authentication keys will be unrelated and can not be used to infer things about each other.</p>



<p>All in all AES-GCM-SIV works like this:</p>



<ul><li><span data-katex-display="false">H, K_E = \operatorname{KDF}(K, IV)</span></li><li><span data-katex-display="false">T=\operatorname{AES}(K_E, P_0\cdot H^{n+1}+\dots+P_n\cdot H)</span></li><li><span data-katex-display="false">C=\operatorname{AES-CTR}(K_E, IV=T)</span></li></ul>



<p>where the plaintext blocks <span data-katex-display="false">P_i</span> again contain additional data and length, and some extra hardening and efficiency tricks having been stripped for clarity.</p>



<p>Our previous approach of first creating the ciphertext and then balancing things out to get the tags to agree clearly cannot work here anymore. The keystream, and therefore the ciphertext, depend on the tag, so if we want to have any chance of finding a salamander, we have to fix the tag before we do any calculation at all. So after having chosen <span data-katex-display="false">T</span>, we decrypt it under each of our keys to get the result of our polynomial <span data-katex-display="false">S_i=\operatorname{AES}^{-1}(K_{E,i}, T)</span>. What we are left with is finding plaintexts <span data-katex-display="false">P_1, P_2</span> such that</p>



<p><span data-katex-display="true">S_i=\sum_{j=0}^n P_{j, i} H_i^{n+1-j}</span></p><p>which gives us a system of two linear equations with <span data-katex-display="false">2n</span> unknowns. But this isn’t all constraints we need to satisfy, since we still need to encrypt these plaintexts once we have the tag balanced. Here, we are lucky that everything is over characteristic 2: The CTR encryption is just an addition of the plaintext and the encrypted counter block <span data-katex-display="false">C_i=\operatorname{AES}(K_E, CB_i)+P_i</span>. To say that two plaintexts result in the same ciphertext under two different keys is just fulfilling the equation</p>



<p><span data-katex-display="true">\operatorname{AES}(K_{E, 1}, CB_{j, 1})+P_{j, 1}=\operatorname{AES}(K_{E, 2}, CB_{j, 2})+P_{j, 2}</span>.</p>



<p>This, like our two equations for the tag, is a linear equation. So in the end, for a plaintext that has a size of <span data-katex-display="false">n</span> blocks, we get <span data-katex-display="false">n+2</span> linear equations with <span data-katex-display="false">2n</span> variables. This means, in almost all cases, we can construct an invisible salamander with only adding two sacrificial blocks, with the same caveat that the two plaintexts need to be partially brute forced.</p>



<h4>Test Code</h4>



<p>I’ve put this to the test and have written code to produce <a href="https://github.com/sophieschmieg/fun-with-gcm/blob/master/FunWithGcm.java">AES-GCM</a> (Java) and <a href="https://github.com/sophieschmieg/fun-with-gcm/blob/master/fun_with_gcm_siv.cc">AES-GCM-SIV</a> (C++) salamanders.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://keymaterial.net/2020/09/07/invisible-salamanders-in-aes-gcm-siv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24405583</guid>
            <pubDate>Tue, 08 Sep 2020 06:00:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Basic Random Number Generation (PRNG)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24405573">thread link</a>) | @aryamansharda
<br/>
September 7, 2020 | https://blog.digitalbunker.dev/2020/09/08/how-do-computers-generate-random-numbers/ | <a href="https://web.archive.org/web/*/https://blog.digitalbunker.dev/2020/09/08/how-do-computers-generate-random-numbers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainEntityOfPage">
<p>Anyone with any programming experience understands that computers are deterministic machines. If you provide the same input, you’ll always get the same output. That’s why having computers generate something by chance is trickier than it may seem.</p>
<p>Computers use random numbers for everything from cryptography to gambling, generative algorithms, video games, and more. However, computers are inherently incapable of being random. Instead, programmers rely on pseudorandom number generators (PRNGs). These are simply a category of algorithms that programmatically generate new random numbers from a given starting value called the seed.&nbsp;</p>
<p>These algorithms are not without their own limitations. Since the random numbers are programmatically generated, if someone were able to identify the seed value and the PRNG algorithm you were using, they’d be able to predict the next random number in the sequence. This would allow an attacker to break encryption, predict the next playing card in a sequence, cheat in a video game, etc. </p>
<p>Despite this concern, PRNGs are extremely useful in situations involving modeling and simulations as it allows you to “replay” a series of random events by initializing your random number generator with the same seed.&nbsp;</p>
<p>In situations where the randomness of the random numbers is critical, we use a “true” random number generator (TRNGs). Unlike PRNGs that have an arbitrary seed value, TRNGs pick a seed value from their environment / external data. </p>
<p>Here are a few potential options:</p>
<ul><li>Mouse movements</li><li>Fan noise</li><li>Atmospheric pressure</li><li>Number of microseconds since the last whole second</li></ul>
<p>We just need to pick a seed that an attacker wouldn’t be able to predict. This seed value will then be passed into an algorithm, similar to PRNGs, that will generate a random number to use.&nbsp;</p>
<p>The use case will generally dictate whether a PRNG will suffice or if a “true” RNG is needed. Regardless, it’s important to understand the practical differences between both approaches. </p>
<p>PRNGs are faster than TRNGs and their determinism is extremely useful in cases where you want to replay a series of “random” events. Additionally, some PRNGs are periodic in nature, but modern PRNGs with the right initialization parameters have a period long enough that it’s not a major concern. Conversely, TRNGs are slower than PRNGs, are non-deterministic, and are not periodic.</p>
<h2>Linear Congruential Generator</h2>
<p>Let’s take a look at implementing a simple PRNG. We’ll implement a variant called the <a href="https://en.wikipedia.org/wiki/Linear_congruential_generator">linear congruential generator</a> (LCG) algorithm. LCG was previously one of the most commonly used and studied PRNGs (<a href="https://en.wikipedia.org/wiki/Linear_congruential_generator">more info</a>).&nbsp;</p>
<p>Here’s the recurrence relation for LCG:</p>
<div><figure><img src="https://lh3.googleusercontent.com/iNcDHvHA6BvD1fpYntUkZ-11dzW6EYoW5dHv7mMhPZhDNo5fJaIMZXUh7SmZq0AoobvHxg7K5MMvqoWav7ee0xHase0fhAjWmNWoW7RcT5GzAao1jVwtGY11q2yL6iuvWiYFgyHS" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>The <a href="https://en.wikipedia.org/wiki/Linear_congruential_generator">Wikipedia page on LCG</a> documents a few commonly used values for modulus, multiplier, and increment. There’s no consensus on the best values to use hence the differing values across implementations.&nbsp;</p>
<p>We have to be mindful of what values we use for these parameters. Choosing the wrong values can create a period that is too short which would render our random number generator useless. </p>
<p>In the image below, you can see that small changes to our parameters can greatly impact the period length.</p>
<div><figure><img src="https://lh4.googleusercontent.com/FVum2kuYt4oMYjOdzHx2txpQH0NgheDDSUSxyQJamzGbZgPcUALt3Mmv4H-BElodwXwTzcLaqicG8IdsPFAgolV4DK8NkZXtghDQ_hX6MyMsxU_irWeOxR1ijaoYgecOU3fbuPbQ" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<h2>Implementation</h2>
<p>For our implementation, we’ll use the values documented in previous standards of the C languages (C90/C99/ANSI C,&nbsp; and C11).&nbsp;</p>
<p><code>a = 1103515245</code></p>
<p><code>m = 2³¹</code></p>
<p><code>c = 12345</code></p>
<blockquote><p>Whatever PRNG algorithm you choose should result in a uniform distribution of random numbers and a sufficiently long period.&nbsp;&nbsp;</p></blockquote>
<p>Here’s a simple implementation in Swift:</p>

<h2>Simulating Dice Rolls</h2>
<p>Let’s say you wanted to simulate a dice roll. </p>
<p>It might seem reasonable to change the modulus to 6, but this would create a period far too short to be usable. We need to stick with well-chosen and tested values for our parameters. </p>

<p>Instead, using the approach in the code above, we can simulate 10,000 dice rolls:</p>
<div><figure><img src="https://lh6.googleusercontent.com/uVT2lMlmWHcYIio5WmgkMMXz9nkkA_P4lzIVWeyVETxasCDn5s_5qQWgBh5FAvfPDwHipyMaqHWmb_lOp_J7oOXiRdxo_3lywqvrIo4Ky40QoDUYIrJ15w5mC6B9XWVLWvyySRWr" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>Dice Value: 10,000 Roll Simulations</p>
<blockquote><p>Looking at the results, we can see that it is indeed a uniform distribution of values.</p></blockquote>
<h2>Generating Random Numbers In A Range</h2>
<p>Next, let’s consider generating random numbers that fall in a range. Again, we shouldn’t change our parameters without fully understanding how it affects the period. </p>
<p>Instead, we should map our PRNG’s results to values in our desired range.&nbsp;</p>

<div><figure><img src="https://lh4.googleusercontent.com/A2h_s4Z_eN-qGkjEZabgPwWpOjMmIDdD9fQlYcdM344voNTlxPIvammtm6RRXJ6aDgG83h67zZYf4E4olN7jz5VRiIK10D_XeRTf0whcfHLZhn8Q9142vJBZU9Ma40DIvFVw7FdU" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>After a million simulations across the specified range [30, 80)</p>
<h2>Further Reading</h2>
<p>If you’re interested in <a href="https://en.wikipedia.org/wiki/List_of_random_number_generators">more modern PRNGs</a>, I’d recommend exploring the <a href="https://en.wikipedia.org/wiki/Mersenne_Twister">Mersenne-Twister</a> approach. It’s currently the most popular PRNG algorithm and currently used in Python (numpy), Ruby, PHP, R, and C++.&nbsp;</p>
<p>Hope you enjoyed this article! Feel free to check out my other articles below!</p>
 
</div></div>]]>
            </description>
            <link>https://blog.digitalbunker.dev/2020/09/08/how-do-computers-generate-random-numbers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24405573</guid>
            <pubDate>Tue, 08 Sep 2020 05:58:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kitens Game]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24405522">thread link</a>) | @the_dripper
<br/>
September 7, 2020 | https://bloodrizer.ru/games/kittens/ | <a href="https://web.archive.org/web/*/https://bloodrizer.ru/games/kittens/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bloodrizer.ru/games/kittens/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24405522</guid>
            <pubDate>Tue, 08 Sep 2020 05:46:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Get Started with Azure Bicep – Alternative to ARM Templates]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24405187">thread link</a>) | @crpietschmann
<br/>
September 7, 2020 | https://build5nines.com/get-started-with-azure-bicep/ | <a href="https://web.archive.org/web/*/https://build5nines.com/get-started-with-azure-bicep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>Azure Bicep is an abstraction built on top of Azure ARM Templates and Azure Resource Manager that offers a cleaner code syntax with better support for modularity and code re-use. Azure Bicep moves away from the JSON syntax used by ARM Templates and is much easier to both read and write Infrastructure as Code (IaC) in Azure! This is the latest tool from Microsoft for deploying Azure resources in a DevOps process, and its even open source!</p>



<p>Let’s get started!</p>



<blockquote><p><strong>Warning</strong>: Before you start using Azure Bicep, know that it is in an early Alpha state and is not supported for use in production environments just yet. Also, it doesn’t support all the functionality it eventually will. However, it does support some really great features already that makes Azure<a href="https://build5nines.com/what-is-infrastructure-as-code/"> Infrastructure as Code </a>(IaC) even easier to write and read!</p></blockquote>







<br><h2><span id="what_is_azure_bicep"></span>What is Azure Bicep?<span></span></h2>



<p>Azure Bicep is a new declarative Domain Specific Language (DSL) for deploying Azure resources. The goal of this new language is to make it easier to write Infrastructure as Code (IaC) targeting Azure Resource Manager (ARM) using a syntax that’s more friendly than the JSON syntax of Azure ARM Templates.</p>



<p>Azure Bicep works as an abstraction layer built on top of ARM Templates. Anything that can be done with Azure ARM Templates can be done with Azure Bicep as it provides a “transparent abstraction” over ARM (Azure Resource Manager). With this abstraction, all the <code>types</code>, <code>apiVersions</code>, and <code>properties</code> valid within ARM Templates are also valid with Azure Bicep.</p>



<figure></figure>



<p>Azure Bicep is a transpiled language. This means that the Azure Bicep code converted into ARM Template code. Then, the resulting ARM Template code is used to deploy the Azure resources. This transpiling enables Azure Bicep to use it’s own syntax and compiler for authoring Azure Bicep files that compile down to Azure Resource Manager (ARM) JSON as a sort of intermediate language (IL).</p>



<p>The way that Azure Bicep is transpiled into ARM JSON is similar to how there are many different languages that can be written in, then transpiled into JavaScript that can be run within the web browser. One popular example of this type of transpiled language is TypeScript. A transpiled language offers benefits of adding an abstraction layer to make it easier and / or more feature full to write code that then gets compiled down to IL code that gets executed. This is also similar to how C# and VB.NET code compile down to MSIL in .NET code.</p>



<p>In the development world, it’s common to encounter the use of transpiled languages. It’s also common in the DevOps world where YAML and JSON are converted between one or the other. Azure Bicep offers some similarity in how it’s transpiled into ARM JSON. This enables you to use an alternative syntax and feature set for writing declarative Infrastructure as Code than the often-cumbersome ARM JSON syntax.</p>



<blockquote><p>Azure Bicep offers some similarity in how it’s transpiled into ARM JSON. This enables you to use an alternative syntax and feature set for writing declarative Infrastructure as Code than the often-cumbersome ARM JSON syntax.</p></blockquote>



<p>Azure Bicep will have limits in its ability to support features that are not natively supported by ARM Templates when deploying Azure resources. However, Azure Bicep will also be able to implement additional code reuse and other features that the Azure Bicep compiler will be able to translate into valid ARM JSON features. Through all this, Azure Bicep has a goal of offering a cleaner syntax along with better support for modularity and code re-use than is offered by ARM JSON.</p>



<h2><span id="why_use_azure_bicep"></span>Why use Azure Bicep?<span></span></h2>



<p>Azure Resource Manager and ARM Templates are written in a JSON syntax that can be cumbersome to work with. Azure Bicep is a Domain Specific Language (DSL) that offers a transparent abstraction over Azure Resource Manager and ARM Templates that offers support for a cleaner code syntax with better support for modularity and code re-use. Azure Bicep offers a few improvements for authoring Azure IaC over the use of ARM Template JSON.</p>



<br><h3><span id="azure_bicep_benefits"></span>Azure Bicep Benefits<span></span></h3>



<p>Here are the primary benefits of using Azure Bicep that are integrated as core goals into the Azure Bicep project and are the foundations for why Microsoft is building Azure Bicep:</p>



<ol><li>Create a better language for writing Infrastructure as Code (IaC) for describing, validating, and deploying Azure resources.</li><li>The Azure Bicep language is a transparent abstraction that does not require any updates or onboarding to the underlying platform in order to support a new Azure resource <code>type</code> and / or <code>apiVersion</code>.</li><li>Azure Bicep code should be easily understood and straightforward to learn for those both new and experienced with other programming languages.</li><li>Code re-use should be a primary feature allowing users freedom to modularize and re-use code without ‘copy/paste’.</li><li>Azure Bicep tooling should offer a high level of discoverability and validation. The tooling should also be developed alongside the compiler; rather than added afterwards.</li><li>Azure Bicep should enable users to have high confidence that the code is ‘syntactically valid’ before it’s deployed.</li></ol>



<p>Also, Azure Bicep is being specifically designed so that it is not a general-purpose language for meeting any need. It is a Domain Specific Language (DSL) meant for writing declarative IaC. It’s also not meant to provide a model for non-Azure related tasks.</p>



<h2><span id="install_azure_bicep"></span>Install Azure Bicep<span></span></h2>



<p>Azure Bicep is a DevOps tool built for authoring IaC used to deploy Azure resources from any environment. As a result, this means Azure Bicep supports Windows, Linux, and macOS.</p>



<p>The primary component for Azure Bicep is the Bicep CLI. This is the required tool used for compiling Bicep code into ARM JSON; plus, it’s open source and cross-platform.</p>



<p>Let’s take a look at installing Azure Bicep in different environments!</p>



<h3><span id="download_bicep_cli_binaries"></span>Download Bicep CLI Binaries<span></span></h3>



<p>When installing Azure Bicep, you will need to first download the Bicep CLI binary built for your operating system. All the binaries for the different supported operating systems can be downloaded from the official <a href="https://github.com/Azure/bicep/releases" target="_blank" rel="noopener">releases page</a> of the Azure Bicep open source project.</p>



<p>You can either manually download the Bicep CLI binary and install it, or you can use the following helper script examples to install Azure Bicep more easily.</p>



<h3><span id="install_on_windows"></span>Install on Windows<span></span></h3>



<p>On Windows machines, Azure Bicep can be installed using PowerShell with the following script:</p>



<pre><code># Create the install folder
$installPath = "$env:USERPROFILE\.bicep"
$installDir = New-Item -ItemType Directory -Path $installPath -Force
$installDir.Attributes += 'Hidden'
# Fetch the latest Bicep CLI binary
(New-Object Net.WebClient).DownloadFile("https://github.com/Azure/bicep/releases/latest/download/bicep-win-x64.exe", "$installPath\bicep.exe")
# Add bicep to your PATH
$currentPath = (Get-Item -path "HKCU:\Environment" ).GetValue('Path', '', 'DoNotExpandEnvironmentNames')
if (-not $currentPath.Contains("%USERPROFILE%\.bicep")) { setx PATH ($currentPath + ";%USERPROFILE%\.bicep") }
if (-not $env:path.Contains($installPath)) { $env:path += ";$installPath" }
# Verify you can now access the 'bicep' command.
bicep --help
# Done!</code></pre>



<h3><span id="install_on_macos"></span>Install on macOS<span></span></h3>



<p>On macOS machines, Azure Bicep can be installed using the terminal with the following script:</p>



<pre><code># Fetch the latest Bicep CLI binary
curl -Lo bicep https://github.com/Azure/bicep/releases/latest/download/bicep-osx-x64
# Mark it as executable
chmod +x ./bicep
# Add Gatekeeper exception (requires admin)
sudo spctl --add ./bicep
# Add bicep to your PATH (requires admin)
sudo mv ./bicep /usr/local/bin/bicep
# Verify you can now access the 'bicep' command
bicep --help
# Done!</code></pre>



<h3><span id="install_on_linux"></span>Install on Linux<span></span></h3>



<p>On Linux machines, Azure Bicep can be installed using the following script:</p>



<pre><code># Fetch the latest Bicep CLI binary
curl -Lo bicep https://github.com/Azure/bicep/releases/latest/download/bicep-linux-x64
# Mark it as executable
chmod +x ./bicep
# Add bicep to your PATH (requires admin)
sudo mv ./bicep /usr/local/bin/bicep
# Verify you can now access the 'bicep' command
bicep --help
# Done!</code></pre>



<h3><span id="install_in_azure_cloud_shell"></span>Install in Azure Cloud Shell<span></span></h3>



<p>The Azure Cloud Shell runs on Ubuntu server, so to install Azure Bicep, you will need to install the Linux binary for the Bicep CLI. However, you cannot simply use the above script for installing Azure Bicep on Linux due to a limitation of the Azure Cloud Shell that prevents you from modifying the PATH.</p>



<p>Here are some steps you can follow to basically “install” Azure Bicep for use in the Azure Cloud Shell environment:</p>



<ol><li>Connect to the Azure Cloud Shell; either within the Azure Portal or at <code><a href="https://shell.azure.com/" rel="nofollow">https://shell.azure.com</a></code>.</li><li>First, you likely want to create a directory within the Azure Cloud Shell environment to save the Bicep CLI to. For example, creating a <code>~/tools</code> directory:<br><code>mkdir ~/tools</code></li><li>Next, navigate to the directory created and download the Linux binary for the Bicep CLI into the Azure Cloud Shell environment into this directory:</li></ol>



<pre><code># Navigate to "tools" directory
cd ~/tools
# Fetch the latest Bicep CLI binary
curl -Lo bicep https://github.com/Azure/bicep/releases/latest/download/bicep-linux-x64
# Mark it as executable
chmod +x ./bicep</code></pre>



<p>Using the above steps will place the Azure Bicep CLI in the location of <code>~/tools/bicep</code> within you Azure Cloud Shell environments. Once placed here, you can execute the Bicep CLI from anywhere within the Azure Cloud Shell environment by referencing it within the <code>~/tools</code> directory.</p>



<p>For example, when located within the <code>~/bicep</code> directory, you can run the following command to utilize the <code>~/tools/bicep</code> executable to build some Azure Bicep code in the <code>main.bicep</code> file:</p>



<pre><code>chris@Azure:~/bicep$ ~/tools/bicep build main.bicep</code></pre>



<p>With the Azure Bicep CLI installed into the Azure Cloud Shell environment, then you’ll be able to utilize Azure Bicep easily from anywhere without the need to install it on your local machine.</p>



<h2><span id="compiling_and_deploying_azure_bicep_code"></span>Compiling and Deploying Azure Bicep code<span></span></h2>



<p>Azure Bicep code is written in files with the <code>.bicep</code> extension. These Bicep …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://build5nines.com/get-started-with-azure-bicep/">https://build5nines.com/get-started-with-azure-bicep/</a></em></p>]]>
            </description>
            <link>https://build5nines.com/get-started-with-azure-bicep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24405187</guid>
            <pubDate>Tue, 08 Sep 2020 04:23:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cracking the Culture Interview]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24405093">thread link</a>) | @benshuyichen
<br/>
September 7, 2020 | https://heybenchen.com/cracking-the-culture-interview-1 | <a href="https://web.archive.org/web/*/https://heybenchen.com/cracking-the-culture-interview-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1599532527250/Gm0E0xbTo.jpeg?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>The most successful companies are built upon great working cultures that are thoughtful about the <a target="_blank" href="https://hbr.org/2020/01/the-new-analytics-of-culture">cultural contribution</a> each hire will make to their company. If you're a candidate looking to land your dream job, you'll need to be well prepared for these cultural or behavioral interviews. </p>
<p>As a hiring manager, I've interviewed over 200 engineering candidates and a significant portion of that  has been evaluating the soft skills each candidate embodies. I've rejected extremely strong technical performers and and fought to hire some more junior candidates based on the signal I've identified from the culture interview. Because every company has their own culture, their own values, and their own questions, the culture interview can be extremely hard to prepare for. However, there's still plenty you can do to set yourself up for success instead of jumping in blind.</p>
<p>While my interviewing experience as both a hiring manager and a candidate have been primarily within engineering, I believe the tools in this kit will be mostly applicable across product, design, and other disciplines within product development organizations. </p>
<h2 id="stories-to-prepare">Stories to Prepare</h2>
<p>Why should you prepare stories instead of answers to specific questions? The simple reason is that you can't prepare and memorize an answer to every question an interviewer might ask. Often times these conversations are organic and the real signal comes from how you respond to follow-up questions. The best answers are rooted in real examples from your personal experience and by "loading" these stories into your brain ahead of time, you'll be better equipped to handle questions on the spot.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1599089431543/WeopvfKLq.png?auto=format&amp;q=60" alt="https://cdn.hashnode.com/res/hashnode/image/upload/v1599089431543/WeopvfKLq.png"></p>
<h3 id="story-1-your-career-narrative">Story #1: Your career narrative</h3>
<p>Almost everyone you talk to will give an intro of themselves and then ask you to share a brief intro as well. Depending on who you're talking to, that intro can be anywhere from 30 seconds to 3 minutes. In some cases, a hiring manager or recruiter might ask you to go deeper into your background and spend up to 30 minutes digging into your experiences.</p>
<h4 id="what-to-prepare">What to prepare</h4>
<ol>
<li>A narrative that connects your career together. While many careers are not linear, it can help to show that you were deliberate about the jobs you took and what you wanted to learn at each one. You may find that as you look back on your career, there's a story you can weave together that ties together where you started, where you're at now, and the trajectory you're on. A story that shows strong growth, surmounting challenges, and a high forward trajectory can help get companies excited about you. Finish your story such that the company you're talking to easily makes sense as the next step on your career journey.<ul>
<li>A weak narrative merely lists what's on your resume, e.g., "in 2013 I joined X and did these projects, in 2014 I joined Y and did these projects, and recently I've done Z and B. I want to join this company because it's doing really well."</li>
<li>A stronger narrative gives context on your decisions and motivations, e.g., "In college, I was excited about electronics and human-computer interfaces, so I looked for companies that specialized in consumer hardware. X company was one of the companies that stood out, and when I joined I got to work on the interface for Product P. This taught me [so and so] but after 2 years there, I really wanted to get better at [this other thing], so I reached out to Company Y. From there, I grew into [some role], helped the company do [these things], and now I'm [doing something impressive]. Going forward, I'm looking for an opportunity where I can put my front end architecture skills to good use while learning how to build complex systems at scale. I admire [company name] for being able to build high quality user interfaces while being super fast and reliable. I think this might be a great fit for my expertise and give me opportunities to grow my backend skills."</li>
</ul>
</li>
<li>What specific things you're looking for in your next role. These should apply to more than one company to show that you're not just pandering to the company, but try to be opinionated at the same time.<ul>
<li>A weak answer is too vague, uncertain, or demonstrates that you haven't put much thought to it.<ul>
<li>e.g., "I'm looking for a place where I can advance my career." or "I wanted to get into AI and Machine Learning because it's a really hot industry right now."</li>
</ul>
</li>
<li>A stronger answer shows that you've clearly thought about what you want, have had enough experience to know what you don't want, and implicitly show why the company you're talking to is a good fit.<ul>
<li>e.g., "Over my career, I've found that it's really important for me to have a strong sense of ownership over my work. I enjoy taking an ambiguous customer problem, breaking it down with a PM or designer, and then being able to see the whole project through from start to finish. I like to solve problems and not just execute on tasks, even if that means working through some dealing with a lot of uncertainty at times and wearing many hats."</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="what-the-interviewer-is-looking-for">What the interviewer is looking for</h4>
<ul>
<li>For quick intros, interviewers are generally not evaluating your storytelling ability. Instead, they want to know why you might be a good fit for the role and what your motivations are.</li>
<li>For hiring managers and recruiters, your career narrative can be a useful lens to interpret the interview feedback and make a decision on whether or not to move forward.<ul>
<li>For example, if your background is primarily backend engineering and the interviews demonstrate weakness in UI implementation, then your narrative can help interviewers focus more on your strengths over your weaker areas.</li>
</ul>
</li>
<li>If you under-represent yourself at this stage, you may miss an opportunity to move forward in the interview process or get an offer.<ul>
<li>On the flip side, you should avoid changing your narrative too much simply to suit the role or company you're talking to. It's often better to be rejected for a role that really doesn't fit you than to get a role doing something that doesn't actually align with what you want.</li>
</ul>
</li>
</ul>
<h4 id="questions-that-interviewers-may-ask">Questions that interviewers may ask</h4>
<ul>
<li>Tell me about yourself.</li>
<li>What are you looking for in your next role?</li>
<li>Why are you interested in [company]?</li>
</ul>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1599088479939/uCQDKllBU.png?auto=format&amp;q=60" alt="https://cdn.hashnode.com/res/hashnode/image/upload/v1599088479939/uCQDKllBU.png"></p>
<h3 id="story-2-two-impressive-projects">Story #2: Two Impressive Projects</h3>
<p>You should be prepared to talk in depth about at least two meaningful projects you've worked on where you played a significant role. Why two? If you use the same example for every question, the interviewer may think you're lacking experience or have a weak track record. Having at least two substantial projects in your pocket will help you balance breadth and depth to respond to a variety of questions.</p>
<p>Keep your initial explanation short (between 3-5 minutes) and offer to go deeper afterwards. This will help keep the conversation focused and avoid wasting time on unimportant details.</p>
<p>A good format to use whenever you're giving an example of something that happened is to use the <a target="_blank" href="https://www.mindtools.com/pages/article/situation-behavior-impact-feedback.htm">SBI framework</a> or <a target="_blank" href="https://www.vawizard.org/wiz-pdf/STAR_Method_Interviews.pdf">STAR framework</a>. For these examples I'll use the SBI model. </p>
<h4 id="what-to-prepare">What to prepare</h4>
<ul>
<li><strong>Situation</strong>: Share context on the project before jumping into what you did.<ul>
<li>Where did the project come from?</li>
<li>Why was it important? How did you or your team prioritize it?</li>
<li>What were the goals of the project?</li>
</ul>
</li>
<li><strong>Behavior</strong>: Describe your specific role on that project. If you played a technical role, describe how the system was designed.<ul>
<li>Project management<ul>
<li>What was your role in defining the scope or solution?</li>
<li>How did you ensure the project was on track?</li>
<li>What obstacles came up during the project? How did you overcome them?</li>
</ul>
</li>
<li>System design of the project<ul>
<li>How was the system architected?</li>
<li>What were the biggest points of failure?</li>
<li>How did you approach this design?</li>
<li>Who else was involved in the design?</li>
</ul>
</li>
</ul>
</li>
<li><strong>Impact</strong>: What was the result of this project?<ul>
<li>What went well on that project?<ul>
<li>Did the project succeed?</li>
<li>How did you measure success?</li>
<li>Can you share some of your success metrics and how they performed?</li>
</ul>
</li>
<li>What did you learn on that project?<ul>
<li>What skills did you build?</li>
<li>What didn't go well on that project?</li>
<li>If you were to do the project again, what might you do differently? Try to come up with at least one or two examples.</li>
</ul>
</li>
<li>If the project didn't succeed, why not?<ul>
<li>Demonstrate that you can take ownership of your mistakes and avoid blaming others. Most interviewers are looking for a growth mindset.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="what-interviewers-are-looking-for">What interviewers are looking for</h4>
<ul>
<li>Does the work align with the level and scope of the role?<ul>
<li>Are they applying for a role that's realistic with what they've done historically?</li>
<li>What kind of domain expertise do they have?</li>
<li>Have they had enough technical leadership experience for the role? (More relevant for senior/tech lead roles and above.)</li>
</ul>
</li>
<li>Can the candidate clearly articulate the benefit and impact of their work?<ul>
<li>It's surprising how often some people don't know or think about the result of their work beyond completing the tasks that were assigned to them. Strong candidates think about the entire workflow, from idea conception to evaluating success.</li>
</ul>
</li>
<li>Do they have a growth mindset?<ul>
<li>Are they able to reflect on both the successes and misses of that project?</li>
<li>Do they take credit for all the things that went well and blame others for all the things that didn't go well? (This would be a red flag.)</li>
<li>Can they clearly explain both the technical and non-technical portions of their work?</li>
</ul>
</li>
</ul>
<h4 id="questions-that-interviewers-may-ask">Questions that interviewers may ask</h4>
<ul>
<li>What's the most significant project you worked on in the last year?</li>
<li>Tell me about a project that didn't go as well as you had hoped. What happened?</li>
<li>Give me an example of how you learned an area/product that you knew nothing about. What was the outcome?</li>
</ul>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1599089660735/RwoSL0oEm.png?auto=format&amp;q=60" alt="https://cdn.hashnode.com/res/hashnode/image/upload/v1599089660735/RwoSL0oEm.png"></p>
<h3 id="story-3-resolving-a-conflict">Story #3: Resolving a conflict</h3>
<p>Delivering successful projects often require working with a lot of stakeholders and collaborators. Demonstrate that you can work well with others, share critical feedback, and resolve situations on your own.</p>
<p>I've been surprised at how often candidates talk about a situation where they ultimately failed to resolve a conflict. It can be hard to think of a good example on the spot, so definitely prepare this ahead of time and consider what you want the interviewer to take away.</p>
<h4 id="what-to-prepare">What…</h4></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://heybenchen.com/cracking-the-culture-interview-1">https://heybenchen.com/cracking-the-culture-interview-1</a></em></p>]]>
            </description>
            <link>https://heybenchen.com/cracking-the-culture-interview-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24405093</guid>
            <pubDate>Tue, 08 Sep 2020 04:04:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Multifaceted William Shockley]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24404968">thread link</a>) | @the-mitr
<br/>
September 7, 2020 | http://wwww.tikalon.com/blog/blog.php?article=2020/Shockley | <a href="https://web.archive.org/web/*/http://wwww.tikalon.com/blog/blog.php?article=2020/Shockley">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://wwww.tikalon.com/blog/blog.php?article=2020/Shockley</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404968</guid>
            <pubDate>Tue, 08 Sep 2020 03:31:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tearing Apart the Wyze Outdoor Camera Base Station – Surprise, Its OpenWRT]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24404931">thread link</a>) | @miniman1337
<br/>
September 7, 2020 | https://illumo.com/tearing-apart-the-wyze-outdoor-cam-base-station/ | <a href="https://web.archive.org/web/*/https://illumo.com/tearing-apart-the-wyze-outdoor-cam-base-station/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-96">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>In this blog post we will take a look inside the Wyze Outdoor Base Station and see whats going on. Many people were very excited to hop on board the Wyze train when they announced the outdoor camera – however it has mostly been met with bad reviews and buggy, half baked features. </p>



<figure><img loading="lazy" src="https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-1024x401.jpg" alt="" width="1024" height="401" srcset="https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-1024x401.jpg 1024w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-300x117.jpg 300w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-768x301.jpg 768w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-1536x601.jpg 1536w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-2048x802.jpg 2048w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-1200x470.jpg 1200w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-1980x775.jpg 1980w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A few small screws removed and we are into the Wyze Base Station</figcaption></figure>



<p>Lets get this thing out of the plastic case to take a closer look, carefully removing the RF1.13 IPX connectors for the antenna signal wire.</p>



<figure><img loading="lazy" src="https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside2-1024x483.jpg" alt="" width="1068" height="503" srcset="https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside2-1024x483.jpg 1024w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside2-300x141.jpg 300w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside2-768x362.jpg 768w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside2-1536x724.jpg 1536w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside2-2048x965.jpg 2048w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside2-1200x566.jpg 1200w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside2-1980x933.jpg 1980w" sizes="(max-width: 1068px) 100vw, 1068px"><figcaption>The guts</figcaption></figure>



<p>We can see that the board is labeled 9531_HL_CORE_AM7</p>



<figure><img loading="lazy" width="403" height="318" src="https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-2.jpg" alt="" srcset="https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-2.jpg 403w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-2-300x237.jpg 300w" sizes="(max-width: 403px) 100vw, 403px"><figcaption>The SoC is a Qualcom QCA9531-BL3A</figcaption></figure>



<p>Qualcomm marketing says:</p>



<blockquote><p>The QCA9531 is a highly integrated and feature-rich IEEE 802.11n 2×2 2.4 GHz System-on-a-Chip (SoC) for advanced WLAN platforms.</p><cite><a href="https://www.qualcomm.com/products/qca9531">https://www.qualcomm.com/products/qca9531</a></cite></blockquote>



<p>The Specifications sheet on Qualcomms website is very light on details, but this looks like a common SoC for low end networking and cheapo wireless routers. </p>



<blockquote><p><strong>Specifications:</strong></p><p><strong>CPU Clock Speed:&nbsp;</strong>Up to 650 MHz</p><p><strong>Wi-Fi Standards:&nbsp;</strong>802.11a/b/g,&nbsp;802.11n</p><p><strong>Peak Speed:&nbsp;</strong>300 Mbps</p><p><strong>Channel Utilization:&nbsp;</strong>20/40 MHz</p><p><strong>MIMO Configuration:&nbsp;</strong>2×2 (2-stream)</p><p><strong>Ethernet Standards:&nbsp;</strong>IEEE 802.3</p><p><strong>Ethernet Network:&nbsp;</strong>10/100</p><p><strong>Supported Ports:&nbsp;</strong>5 ports</p><p><strong>USB Version:&nbsp;</strong>USB 2.0</p><p><strong>Memory speed:&nbsp;</strong>300MHz,&nbsp;200MHz</p><p><strong>Memory Type:&nbsp;</strong>DDR1,&nbsp;DDR2</p><p><strong>Supported Interfaces:&nbsp;</strong>JTAG,&nbsp;SPI,&nbsp;UART,&nbsp;USB 2.0,&nbsp;PCIe 1.1</p><p><strong>General Purpose I/Os:&nbsp;</strong>17x</p><p><strong>Package Type:&nbsp;</strong>DRQFN</p><p><strong>Package Size:&nbsp;</strong>12 x 12 mm</p></blockquote>



<figure><img loading="lazy" width="515" height="662" src="https://illumo.com/wp-content/uploads/2020/08/image.png" alt="" srcset="https://illumo.com/wp-content/uploads/2020/08/image.png 515w, https://illumo.com/wp-content/uploads/2020/08/image-233x300.png 233w" sizes="(max-width: 515px) 100vw, 515px"></figure>



<p>It seems like this might be a board built by Nova Electronics that Wyze is putting into a nice package. Looks Familiar right?</p>



<p>The 3 pins on the right side of the board look like they could be SPI – so we tried to solder some pins on and get a terminal open</p>



<p>I guessed the TX / RX pins, and the ground was labeled nicely on the board. For Reference: </p>



<ul><li>Ground to GND (Duh!)</li><li>TX is L1</li><li>RX is L2</li></ul>



<figure><img loading="lazy" src="https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorSPI-1024x485.jpg" alt="" width="610" height="288" srcset="https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorSPI-1024x485.jpg 1024w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorSPI-300x142.jpg 300w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorSPI-768x363.jpg 768w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorSPI-1536x727.jpg 1536w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorSPI-2048x969.jpg 2048w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorSPI-1200x568.jpg 1200w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorSPI-1980x937.jpg 1980w" sizes="(max-width: 610px) 100vw, 610px"><figcaption>Wyze Outdoor Camera Base Station UART / SPI pins</figcaption></figure>



<p>I connected with a cheapo CP2102 USB to UART adapter, set the baud rate to 115200 and was off to the races… kinda</p>



<figure><img src="https://media.discordapp.net/attachments/391521801286451213/742921748214972556/unknown.png" alt=""></figure>



<p>Well this is interesting, this little guy is running OpenWRT.  I guessed all of the normal user / password combos I could think of and didn’t get anywhere – If anyone has any ideas on how to get into this shoot me a message / comment!</p>



<p>Lets watch it boot up and see if there is anything interesting going on here: </p>



<pre>U-Boot 1.1.4-gf13eb91d-dirty (Apr  2 2020 - 14:39:10)

ap147 - Honey Bee 2.0DRAM:
sri
Honey Bee 2.0
ath_ddr_initial_config(195): (16bit) ddr2 init
tap = 0x00000003
Tap (low, high) = (0x6, 0x21)
Tap values = (0x13, 0x13, 0x13, 0x13)
128 MB
Top of RAM usable for U-Boot at: 88000000
Reserving 201k for U-Boot at: 87fcc000
Reserving 192k for malloc() at: 87f9c000
Reserving 44 Bytes for Board Info at: 87f9bfd4
Reserving 36 Bytes for Global Data at: 87f9bfb0
Reserving 128k for boot params() at: 87f7bfb0
Stack Pointer at: 87f7bf98
Now running in RAM - U-Boot at: 87fcc000
Flash Manuf Id 0x1c, DeviceId0 0x70, DeviceId1 0x18
flash size 16MB, sector count = 256
Flash: 16 MB
*** Warning *** : PCIe WLAN Module not found !!!
In:    serial
Out:   serial
Err:   serial
Net:   ath_gmac_enet_initialize...
No valid address in Flash. Using fixed address
No valid address in Flash. Using fixed address
ath_gmac_enet_initialize: reset mask:c02200
Scorpion ----&gt;S27 PHY*
S27 reg init
: cfg1 0x800c0000 cfg2 0x7114
eth0: <redacted>
athrs27_phy_setup ATHR_PHY_CONTROL 4 :1000
athrs27_phy_setup ATHR_PHY_SPEC_STAUS 4 :10
eth0 up
Honey Bee ----&gt;  MAC 1 S27 PHY *
S27 reg init
ATHRS27: resetting s27
ATHRS27: s27 reset done
: cfg1 0x800c0000 cfg2 0x7214
eth1: <redacted>
athrs27_phy_setup ATHR_PHY_CONTROL 0 :1000
athrs27_phy_setup ATHR_PHY_SPEC_STAUS 0 :10
athrs27_phy_setup ATHR_PHY_CONTROL 1 :1000
athrs27_phy_setup ATHR_PHY_SPEC_STAUS 1 :10
athrs27_phy_setup ATHR_PHY_CONTROL 2 :1000
athrs27_phy_setup ATHR_PHY_SPEC_STAUS 2 :10
athrs27_phy_setup ATHR_PHY_CONTROL 3 :1000
athrs27_phy_setup ATHR_PHY_SPEC_STAUS 3 :10
eth1 up
eth0, eth1
Setting 0x181162c0 to 0x50a1a100
update_flag:000
===== fythons! ====
Hit any key to stop autoboot:  0
## Booting image at 9f050000 ...
   Image Name:   MIPS Linux-3.3.8
   Created:      2020-04-02   6:39:26 UTC
   Image Type:   MIPS Linux Multi-File Image (lzma compressed)
   Data Size:    1137996 Bytes =  1.1 MB
   Load Address: 80060000
   Entry Point:  80060000
   Contents:
   Image 0:  1137988 Bytes =  1.1 MB
   Verifying Checksum at 0x9f050040 ...OK
   Uncompressing Multi-File Image ... OK
No initrd
## Transferring control to Linux (at address 80060000) ...
## Giving linux memsize in bytes, 134217728

Starting kernel ...

[    0.000000] Linux version 3.3.8 (bai@bai) (gcc version 4.6.3 20120201 (prerel                                                                                             ease) (Linaro GCC 4.6-2012.02) ) #39 Tue Mar 31 13:44:16 CST 2020
[    0.000000] bootconsole [early0] enabled
[    0.000000] CPU revision is: 00019374 (MIPS 24Kc)
[    0.000000] SoC: Qualcomm Atheros QCA9531 rev 2
[    0.000000] Clocks: CPU:650.000MHz, DDR:597.607MHz, AHB:216.666MHz, Ref:25.00                                                                                             0MHz
[    0.000000] Determined physical RAM map:
[    0.000000]  memory: 08000000 @ 00000000 (usable)
[    0.000000] Initrd not found or empty - disabling initrd
[    0.000000] Zone PFN ranges:
[    0.000000]   Normal   0x00000000 -&gt; 0x00008000
[    0.000000] Movable zone start PFN for each node
[    0.000000] Early memory PFN ranges
[    0.000000]     0: 0x00000000 -&gt; 0x00008000
[    0.000000] Built 1 zonelists in Zone order, mobility grouping on.  Total pag                                                                                             es: 32512
[    0.000000] Kernel command line:  board=AP147 console=ttyS0,115200 mtdparts=s                                                                                             pi0.0:256k(u-boot)ro,64k(u-boot-env),1280k(kernel),6336k(rootfs),2176k(driver),1                                                                                             536k(app),2176k(backd),1536k(backa),256K(config),640k(para),64k(flag),64k(art),1                                                                                             0560k@0x50000(firmware) rootfstype=squashfs,jffs2 noinitrd
[    0.000000] PID hash table entries: 512 (order: -1, 2048 bytes)
[    0.000000] Dentry cache hash table entries: 16384 (order: 4, 65536 bytes)
[    0.000000] Inode-cache hash table entries: 8192 (order: 3, 32768 bytes)
[    0.000000] Primary instruction cache 64kB, VIPT, 4-way, linesize 32 bytes.
[    0.000000] Primary data cache 32kB, 4-way, VIPT, cache aliases, linesize 32                                                                                              bytes
[    0.000000] Writing ErrCtl register=00000000
[    0.000000] Readback ErrCtl register=00000000
[    0.000000] Memory: 126020k/131072k available (2396k kernel code, 5052k reser                                                                                             ved, 662k data, 224k init, 0k highmem)
[    0.000000] SLUB: Genslabs=9, HWalign=32, Order=0-3, MinObjects=0, CPUs=1, No                                                                                             des=1
[    0.000000] NR_IRQS:83
[    0.000000] Calibrating delay loop... 432.53 BogoMIPS (lpj=2162688)
[    0.060000] pid_max: default: 32768 minimum: 301
[    0.060000] Mount-cache hash table entries: 512
[    0.070000] Performance counters: mips/24K PMU enabled, 2 32-bit counters ava                                                                                             ilable to each CPU, irq 13
[    0.080000] Initialized recycle list for cpu 0.
[    0.080000] NET: Registered protocol family 16
[    0.090000] gpiochip_add: registered GPIOs 0 to 17 on device: ath79
[    0.090000] ath79_jtag_function_disable
[    0.100000] MIPS: machine is Qualcomm Atheros AP147 reference board
[    0.110000] ar724x-pci ar724x-pci.0: PCIe link is down
[    0.110000] registering PCI controller with io_map_base unset
[    0.120000] ar71xx: invalid MDIO id 1
[    0.330000] bio: create slab <bio-0> at 0
[    0.330000] PCI host bridge to bus 0000:00
[    0.340000] pci_bus 0000:00: root bus resource [mem 0x10000000-0x11ffffff]
[    0.340000] pci_bus 0000:00: root bus resource [io  0x0000]
[    0.350000] Switching to clocksource MIPS
[    0.350000] NET: Registered protocol family 2
[    0.360000] IP route cache hash table entries: 1024 (order: 0, 4096 bytes)
[    0.360000] TCP established hash table entries: 4096 (order: 3, 32768 bytes)
[    0.370000] TCP bind hash table entries: 4096 (order: 2, 16384 bytes)
[    0.370000] TCP: Hash tables configured (established 4096 bind 4096)
[    0.380000] TCP reno registered
[    0.380000] UDP hash table entries: 256 (order: 0, 4096 bytes)
[    0.390000] UDP-Lite hash table entries: 256 (order: 0, 4096 bytes)
[    0.390000] NET: Registered protocol family 1
[    0.410000] squashfs: version 4.0 (2009/01/31) Phillip Lougher
[    0.420000] JFFS2 version 2.2 (NAND) (SUMMARY) (ZLIB) (LZO) (LZMA) (RTIME) (C                                                                                             MODE_PRIORITY) (c) 2001-2006 Red Hat, Inc.
[    0.430000] msgmni has been set to 246
[    0.430000] io scheduler noop registered
[    0.430000] io scheduler deadline registered (default)
[    0.440000] Serial: 8250/16550 driver, 1 ports, IRQ sharing disabled
[    0.470000] serial8250.0: ttyS0 at MMIO 0x18020000 (irq = 11) is a 16550A
[    0.470000] console [ttyS0] enabled, bootconsole disabled
[    0.470000] console [ttyS0] enabled, bootconsole disabled
[    0.490000] m25p80 spi0.0: found en25qh128a, expected m25p80
[    0.490000] m25p80 spi0.0: en25qh128a (16384 Kbytes)
[    0.500000] 13 cmdlinepart partitions found on MTD device spi0.0
[    0.500000] Creating 13 MTD partitions on "spi0.0":
[    0.510000] 0x000000000000-0x000000040000 : "u-boot"
[    0.520000] 0x000000040000-0x000000050000 : "u-boot-env"
[    …</bio-0></redacted></redacted></pre></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://illumo.com/tearing-apart-the-wyze-outdoor-cam-base-station/">https://illumo.com/tearing-apart-the-wyze-outdoor-cam-base-station/</a></em></p>]]>
            </description>
            <link>https://illumo.com/tearing-apart-the-wyze-outdoor-cam-base-station/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404931</guid>
            <pubDate>Tue, 08 Sep 2020 03:19:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First impressions of NEAR smart contract development in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24404830">thread link</a>) | @brson
<br/>
September 7, 2020 | https://brson.github.io/2020/09/07/near-smart-contracts-rust | <a href="https://web.archive.org/web/*/https://brson.github.io/2020/09/07/near-smart-contracts-rust">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Rust is increasingly used as a programming language for smart contracts.
Whereas the first generation blockchains used specialized VMs,
newer blockchains are running general purpose VMs,
especially <a href="https://webassembly.org/">WASM</a>.
And of course,
Rust is a modern language that runs just about everywhere,
and is especially good at targetting WASM.
Somewhat serendipitously,
this has made Rust one of the best candidate languages for writing
smart contracts on the new generation of blockchains.</p>

<p>Lately I’ve been learning more about the smart contract programming landscape,
and this post is about my first dive into smart contract programming in
Rust on the <a href="https://github.com/nearprotocol/nearcore">NEAR</a> platform.</p>

<p>NEAR is a sharded, proof-of-stake blockchain that runs WASM.
It not only supports smart contracts written in Rust
(in addition to <a href="https://www.assemblyscript.org/">AssemblyScript</a>),
but is also itself written in Rust.
While one the most prominent Rust blockchain projects,
it is perhaps not yet widely known in the broader blockchain development community.</p>

<p>Based on my experiences here though,
I’m quite enthusiastic about the NEAR developer experience,
and I intend to spend more time hacking on NEAR.</p>

<p>These are my first impressions of NEAR,
as someone with moderate knowledge of blockchains,
but limited previous blockchain programing experience.
I have previously written similarly about my first experiences
with other blockchains: <a href="https://talk.nervos.org/t/experience-report-first-time-building-and-running-ckb/4518/">Nervos</a>, <a href="https://github.com/Aimeedeer/bigannouncement/blob/master/doc/hacklog.md">Ethereum</a>.</p>

<h2 id="starting-at-the-start-of-the-docs">Starting at the start of the docs</h2>

<p>The <a href="https://docs.near.org/">NEAR documentation</a> seems refreshingly thorough,
if a bit confusing to navigate.
There are different docs to follow depending on your role in the network,
whether a validator,
smart contract programmer,
etc.
and I find myself jumping between multiple sections,
without quite understanding how the docs are organized overall,
perhaps because there isn’t a single table of contents that covers the entire site.</p>

<p>Anyway, after browsing the docs to get a general idea of their organization,
I go back to the front page and I click “Basics”.
This seems to be leading me down the path of being a smart contract developer,
not running my own local node,
not building NEAR itself.</p>

<p>For sake of understanding,
I generally want to build the entire stack I’m working on,
but for now I’m going to follow the docs exactly and see where that gets me,
and not build NEAR on my own.</p>

<h2 id="account-creation">Account creation</h2>

<p>Setting up an account is done through a web interface at:</p>

<blockquote>
  <p><a href="https://wallet.testnet.near.org/">https://wallet.testnet.near.org/</a></p>
</blockquote>

<p>I create a testnet account,
<code>floopy.testnet</code>,
and a recovery phrase.</p>

<p>The NEAR explorer page for my account is</p>

<blockquote>
  <p><a href="https://explorer.testnet.near.org/accounts/floopy.testnet">https://explorer.testnet.near.org/accounts/floopy.testnet</a></p>
</blockquote>

<p>Instead of a hash for an ID,
as in most blockchains,
you get an actual string name.
And the system can optionally do account recovery over email or phone.
While this is convenient, it seems suspiciously centralized for a public blockchain,
and I wonder if it is possible to create accounts without any central authority.
I imagine it is, and this website is mostly a convenience, but don’t know yet.</p>

<h2 id="installation">Installation</h2>

<p>Following <a href="https://docs.near.org/docs/development/near-cli">the docs</a>, I install <code>near-cli</code>, a Node app.</p>

<div><div><pre><code>$ npm install -g near-cli
/home/ubuntu/.nvm/versions/node/v12.16.2/bin/near -&gt; /home/ubuntu/.nvm/versions/node/v12.16.2/lib/node_modules/near-cli/bin/near

&gt; node-hid@1.3.0 install /home/ubuntu/.nvm/versions/node/v12.16.2/lib/node_modules/near-cli/node_modules/node-hid
&gt; prebuild-install || node-gyp rebuild


&gt; usb@1.6.3 install /home/ubuntu/.nvm/versions/node/v12.16.2/lib/node_modules/near-cli/node_modules/usb
&gt; prebuild-install --verbose || node-gyp rebuild

prebuild-install info begin Prebuild-install version 5.3.5
prebuild-install info looking for cached prebuild @ /home/ubuntu/.npm/_prebuilds/f5a2d7-usb-v1.6.3-node-v72-linux-x64.tar.gz
prebuild-install http request GET https://github.com/tessel/node-usb/releases/download/v1.6.3/usb-v1.6.3-node-v72-linux-x64.tar.gz
prebuild-install http 200 https://github.com/tessel/node-usb/releases/download/v1.6.3/usb-v1.6.3-node-v72-linux-x64.tar.gz
prebuild-install info downloading to @ /home/ubuntu/.npm/_prebuilds/f5a2d7-usb-v1.6.3-node-v72-linux-x64.tar.gz.26621-920b88608b4cf.tmp
prebuild-install info renaming to @ /home/ubuntu/.npm/_prebuilds/f5a2d7-usb-v1.6.3-node-v72-linux-x64.tar.gz
prebuild-install info unpacking @ /home/ubuntu/.npm/_prebuilds/f5a2d7-usb-v1.6.3-node-v72-linux-x64.tar.gz
prebuild-install info unpack resolved to /home/ubuntu/.nvm/versions/node/v12.16.2/lib/node_modules/near-cli/node_modules/usb/build/Release/usb_bindings.node
prebuild-install info unpack required /home/ubuntu/.nvm/versions/node/v12.16.2/lib/node_modules/near-cli/node_modules/usb/build/Release/usb_bindings.node successfully
prebuild-install info install Successfully installed prebuilt binary!
</code></pre></div></div>

<p>Semes to work fine.</p>

<p>From previous doc reading I know that running a full node typically involves running <a href="https://github.com/near/nearup">nearup</a>.
It appears though that I don’t need that now,
so probably for the purposes of developing on near,
<code>near-cli</code> will just talk to existing public nodes.</p>

<p>At this point I seem to hit the end of the “basics” documentation flow,
without really accomplishing anything,
but I remember <a href="https://docs.near.org/docs/quick-start/new-to-near#how-do-i-get-started">from the beginning of these docs</a> that “choose a starter project”
is step 2.</p>

<p>I back up and choose the <a href="https://examples.near.org/rust-status-message"><code>rust-status-message</code></a> starter project.</p>

<h2 id="running-a-contract">Running a contract</h2>

<p>The examples say to install <code>near-shell</code>,
but that project has been renamed to <code>near-cli</code>.
I see that there are already PRs submitted to fix this,
but they are about a month old.
There are a number of relatively old PRs in NEAR repos that haven’t been reviewed.</p>

<p>I clone the example:</p>

<div><div><pre><code>$ git clone https://github.com/near-examples/rust-status-message
$ cd rust-status-message
</code></pre></div></div>

<p>And build per the instructions:</p>



<p>This is an npm build that wraps a cargo build.
I’m curious if there’s any JavaScript involved,
but I suspect they are just using npm as the primary interface
for the sake of familiarity and for consistency with
the build process for AssemblyScript smart contracts.</p>

<p>Looking at <code>package.json</code> it’s true that npm isn’t doing much here,
but it <em>is</em> adding a post-build step that cargo is incapable of:</p>

<div><div><pre><code><span>  </span><span>"scripts"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"build"</span><span>:</span><span> </span><span>"cargo build --target wasm32-unknown-unknown --release"</span><span>,</span><span>
    </span><span>"postbuild"</span><span>:</span><span> </span><span>"cp target/wasm32-unknown-unknown/release/status_message.wasm ./res/"</span><span>
  </span><span>}</span><span>,</span><span>
</span></code></pre></div></div>

<p>There is an error in the build:</p>

<div><div><pre><code>error[E0463]: can't find crate for `core`
  |
  = note: the `wasm32-unknown-unknown` target may not be installed

error: aborting due to previous error

For more information about this error, try `rustc --explain E0463`.
error: could not compile `byte-tools`.
warning: build failed, waiting for other jobs to finish...
error: build failed
npm ERR! code ELIFECYCLE
npm ERR! errno 101
npm ERR! rust-status-message-builder@1.0.0 build: `cargo build --target wasm32-unknown-unknown --release`
npm ERR! Exit status 101
npm ERR!
npm ERR! Failed at the rust-status-message-builder@1.0.0 build script.
npm ERR! This is probably not a problem with npm. There is likely additional logging output above.
npm WARN Local package.json exists, but node_modules missing, did you mean to install?

npm ERR! A complete log of this run can be found in:
npm ERR!     /home/ubuntu/.npm/_logs/2020-09-06T22_44_16_397Z-debug.log
</code></pre></div></div>

<p>This is an easy error to understand to somebody familiar with embedded Rust development,
but probably not to other newbies.
The toolchain just doesn’t have the <code>wasm32-unknown-unknown</code> target installed.
I don’t know if I missed the documentation that explained this,
but the user experience here could be better.</p>

<p>I add the wasm target:</p>

<div><div><pre><code>$ rustup target add wasm32-unknown-unknown
info: downloading component 'rust-std' for 'wasm32-unknown-unknown'
info: installing component 'rust-std' for 'wasm32-unknown-unknown'
</code></pre></div></div>

<p>After that the build works:</p>

<div><div><pre><code>$ npm run build

&gt; rust-status-message-builder@1.0.0 build /home/ubuntu/near/rust-status-message
&gt; cargo build --target wasm32-unknown-unknown --release

   Compiling near-sdk v0.11.0
   Compiling status-message v0.1.0 (/home/ubuntu/near/rust-status-message)
    Finished release [optimized] target(s) in 3.99s

&gt; rust-status-message-builder@1.0.0 postbuild /home/ubuntu/near/rust-status-message
&gt; cp target/wasm32-unknown-unknown/release/status_message.wasm ./res/
</code></pre></div></div>

<p>I try to deploy to the testnet using a temporary developer account:</p>

<div><div><pre><code>$ near dev-deploy --wasmFile res/status_message.wasm --helperUrl https://near-contract-helper.onrender.com
We would like to collect data on near-cli usage to improve developer experience. We will never send private information. We only collect which commands are run via an anonymous identifier. Would you like to opt in (y/n)?
</code></pre></div></div>

<p>NEAR wants me to opt in to telemetry.
I’m sympathetic,
but since this command presumably will have access to private keys,
I’m not confident that the developers have been suitably careful
about avoiding collection of private data.
For now I say “n”, until I can review that code.</p>

<p>The command continues:</p>

<div><div><pre><code>$ near dev-deploy --wasmFile res/status_message.wasm --helperUrl https://near-contract-helper.onrender.com
We would like to collect data on near-cli usage to improve developer experience. We will never send private information. We only collect which commands are run via an anonymous identifier. Would you like to opt in (y/n)? n
Starting deployment. Account id: dev-1599433413131-7008906, node: https://rpc.testnet.near.org, helper: https://near-contract-helper.onrender.com, file: res/status_message.wasm
Transaction Id 6cT3Su1BTo52i1EwSgaD6Wm9mTvA8238PWQmUFYPkS11
To see the transaction in the transaction explorer, please open this url in your browser
https://explorer.testnet.near.org/transactions/6cT3Su1BTo52i1EwSgaD6Wm9mTvA8238PWQmUFYPkS11
Done deploying to dev-1599433413131-7008906
</code></pre></div></div>

<p><code>near dev-deploy</code> has apparently created a script <code>neardev/dev-account.env</code>
that will set the <code>CONTRACT_NAME</code> environment variable to my
temporary account id, <code>dev-1599433413131-7008906</code>.
I call it with <code>source neardev/dev-account.env</code>.</p>

<p>I call <code>near call</code> to set the status message in the contract:</p>

<div><div><pre><code>$ near call $CONTRACT_NAME set_status …</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://brson.github.io/2020/09/07/near-smart-contracts-rust">https://brson.github.io/2020/09/07/near-smart-contracts-rust</a></em></p>]]>
            </description>
            <link>https://brson.github.io/2020/09/07/near-smart-contracts-rust</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404830</guid>
            <pubDate>Tue, 08 Sep 2020 02:54:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[URL query parameters and how laxness creates de facto requirements on the web]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24404814">thread link</a>) | @oftenwrong
<br/>
September 7, 2020 | https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>URL query parameters and how laxness creates de facto requirements on the web</h2>

	<p><small>September  7, 2020</small></p>
</div><div><p>One of the ways that <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a> (the code behind <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>) is unusual is that it strictly validates the query parameters
it receives on URLs, including on HTTP <code>GET</code> requests for ordinary
pages. If a HTTP request has unexpected and unsupported query
parameters, such a <code>GET</code> request will normally fail. When I made
this decision it seemed the cautious and conservative approach, but
<a href="https://utcc.utoronto.ca/~cks/space/blog/web/CautionIsAMistakeToday">this caution has turned out to be a mistake on the modern web</a>. In practice, all sorts of sites will
generate versions of your URLs with all sorts of extra query
parameters tacked on, give them to people, and expect them to work.
If your website refuses to play along, (some) people won't get to
see your content. <strong>On today's web, you need to accept (and then
ignore) arbitrary query parameters on your URLs</strong>.</p>

<p>(Today's new query parameter is 's=NN', for various values of NN
like '04' and '09'. I'm not sure what's generating these URLs, but
it may be Slack.)</p>

<p>You might wonder how we got here, and that is a story of lax behavior
(or, if you prefer, being liberal in what you accept). In the
beginning, both Apache (for static web pages) and early web
applications often ignored extra query parameters on URLs, at least
on <code>GET</code> requests. I suspect that other early web servers also
imitated Apache here, but I have less exposure to their behavior
than Apache's. My guess is that this behavior wasn't deliberate,
it was just the simplest way to implement both Apache and early
web applications; you paid attention to what you cared about and
didn't bother to explicitly check that nothing else was supplied.</p>

<p>When people noticed that this behavior was commonplace and widespread,
they began using it. I believe that one of the early uses was for
embedding 'where this link was shared' information for your own web
analytics (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/AnalyticsVsSecurity">cf</a>), either based on your logs
or using JavaScript embedded in the page. In the way of things,
once this was common enough other people began helpfully tagging
the links that were shared through them for you, which is why I
began to see various 'utm_*' query parameters on inbound
requests to <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a> even though I never
published such URLs.
Web developers don't leave attractive nuisances alone for long, so
soon enough people were sticking on extra query parameters to your
URLs that were mostly for them and not so much for you. Facebook
may have been one of the early pioneers here with their 'fbclid'
parameter, but other websites have hopped on this particular train
since then (as I saw recently with these 's=NN' parameters).</p>

<p>At this point, the practice of other websites and services adding
random query parameters to your URLs that pass through them is so
wide spread and common that accepting random query parameters is
pretty much a practical requirement for any web content serving
software that wants to see wide use and not be irritating to the
people operating it. If, like <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a>, you stick to your guns and
refuse to accept some or all of them, you will drop some amount of
your incoming requests from real people, disappointing would be
readers.</p>

<p>This practical requirement for URL handling is not documented in
any specification, and it's probably not in most 'best practices'
documentation. People writing new web serving systems that are
tempted to be strict and safe and cautious get to learn about it
the hard way.</p>

<p>In general, any laxness in actual implementations of a system can
create a similar spiral of de facto requirements. Something that
is permitted and is useful to people will be used, and then supporting
that becomes a requirement. This is especially the case in a
distributed system like the web, where any attempt to tighten the
rules would only be initially supported by a minority of websites.
These websites would be 'outvoted' by the vast majority of websites
that allow the lax behavior and support it, because that's what
happens when the vast majority work and the minority don't.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404814</guid>
            <pubDate>Tue, 08 Sep 2020 02:50:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to negotiate a higher salary and why you should]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24404769">thread link</a>) | @yacc79
<br/>
September 7, 2020 | https://www.dollartrak.com/negotiate-salary-to-achieve-your-financial-goals/ | <a href="https://web.archive.org/web/*/https://www.dollartrak.com/negotiate-salary-to-achieve-your-financial-goals/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p>Many people concentrate on saving and investing as a way to achieve their financial goals.  Both of these are easier to grow with a higher income.  No matter what your <a href="https://www.dollartrak.com/set-and-achieve-financial-goals/">financial goals</a> are, negotiating a higher salary will make them easier to achieve.</p>



<p>The time you spend researching your fair market value, preparing requests for raises, and making requests for adjustments might very well be the most valuable use of your time.</p>



<p>Considering the importance of salary you would think that people would constantly be on top of their market value ensuring they are compensated fairly.  In my experience this is often not the case.</p>



<h2>Many People are Underpaid and Don’t Even Know it</h2>



<p>Like most people I knew, I never talked about my salary with my friends or co-workers.  It’s taboo for many Americans.  This lack of transparency makes it easy to be underpaid while being unaware of it.  This benefits your employer, but not you!</p>



<p>Once I took on a senior leadership position I begun to understand the severity of differences in how people are compensated for similar positions.  In some cases employees with the same job title were compensated double what others were.</p>



<p>I am sure that most people are aware these inequities exist and might blame them on <a href="https://www.wsj.com/articles/study-finds-salary-history-bans-boost-pay-for-african-americans-women-11592472602?mod=e2fb" target="_blank" rel="noreferrer noopener">discrimination</a>, differences in quality of work, education or level of education.  In my experience a lack of salary negotiation and keeping their salary up to date is the main driver. </p>



<p>Negotiating your salary can be uncomfortable, and asking for raises can be even more so.  This doesn’t mean you shouldn’t do it though!  Many will shy away from it and those that do not will end up making much more money over time to do the same job.</p>



<h2>Increases in Salary Compound Over Your Career</h2>



<p>As people get further along in their careers these differences can grow to nearly overwhelming numbers.  Employees can literally make over double what others make for the same job.  This is because of the compounding nature of raises on your salary over the course of your career.</p>



<p>Raises are generally given on a percentage basis of your current salary.  What this means is every single time you get a raise you are also getting a raise on all of your previous raises.  This adds up the same way compound interest adds up.  Over time the numbers can get large and with a 40 year long career for many there can be a lot of time for this to happen.</p>



<h2>Examples of Compounding Salary</h2>



<p>Lets look at a few simple scenarios over a 20 year job with a company.  The first scenario shows the affect of negotiating a higher starting salary and the second one shows the affect of negotiating occasional large raises.</p>



<h3>Affect of Negotiating a Higher Starting Salary</h3>



<p>Jack and Jill both were offered the same job, but Jill negotiated a very modest 10% higher salary than Jack.  They both did well and received 3% raises over the course of 20 years working for the company.</p>



<figure><table><tbody><tr><td></td><td>Base</td><td>Year 5</td><td>Year 10</td><td>Year 15</td><td>Year 20</td><td>Total</td></tr><tr><td>Jack</td><td>$45000</td><td>$52,167</td><td>$60,476</td><td>$70,108</td><td>$81,275</td><td>$1.29M</td></tr><tr><td>Jill</td><td>$50,000</td><td>$57,963</td><td>$67,195</td><td>$77,898</td><td>$90,305</td><td>$1.43M</td></tr></tbody></table><figcaption>3% annual raises over 20 years</figcaption></figure>



<p>The $5,000 starting difference turns into a little over $9,000 a year difference over 20 years.  This resulted in Jill making an extra $140,000 over the course of her job with this company.</p>



<h3>Affects of Negotiating Larger Raises</h3>



<p>Here we will modify the above table to show Jill negotiating a 10% raise for herself every 5 years while Jack happily accepts the standard 3%.</p>



<figure><table><tbody><tr><td></td><td>Base</td><td>Year 5</td><td>Year 10</td><td>Year 15</td><td>Year 20</td><td>Total</td></tr><tr><td>Jack</td><td>$45000</td><td>$52,167</td><td>$60,476</td><td>$70,108</td><td>$81,275</td><td>$1.29M</td></tr><tr><td>Jill</td><td>$50,000</td><td>$61,903</td><td>$76,640</td><td>$94,884</td><td>$117,473</td><td>$1.63M</td></tr></tbody></table><figcaption>3% annual raises over 20 years, Jill get’s 10% every 5 years</figcaption></figure>



<p>After 20 years with a salary of $81,275 jack would need a whopping 45% raise just to catch up to Jill and still would be behind by $340,000 in lifetime earnings!</p>



<h2>How do I Keep My Salary Up to Date</h2>



<h3>Know Your Fair Market Value</h3>



<p>This always starts with knowing what your fair market value is.  There are several websites that can help here.  I like <a rel="noreferrer noopener" href="https://www.glassdoor.com/" target="_blank">Glassdoor</a> and <a rel="noreferrer noopener" href="https://www.salary.com/" target="_blank">Salary.com</a>.  Do a little research and come up with a range that you feel is reasonable.  </p>



<figure><img loading="lazy" width="640" height="548" src="https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/image.png?resize=640%2C548&amp;ssl=1" data-src="https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/image.png?resize=640%2C548&amp;ssl=1" alt="salary chart" data-srcset="https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/image.png?w=731&amp;ssl=1 731w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/image.png?resize=300%2C257&amp;ssl=1 300w" data-sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"><figcaption>Taken from salary.com</figcaption></figure>



<p>You should be honest with yourself about your skills and experience, but I recommend starting at the high end of the range and working down from there.  If someone else can make $100,000 a year doing your job, why not you?</p>



<h3>Getting Your Salary Right to Start</h3>



<p>In my experience the majority of people will accept the first salary offer given.  This is generally a mistake.  Why would a hiring manager make you his absolute top dollar offer to start?  He is generally wise to leave a little room for negotiation for the candidates that do counteroffer.  Some candidates will want to counteroffer no matter what you offer them first!</p>



<p>Once you accept a lower salary it is VERY difficult to get it corrected.  You may have some success here at smaller companies but with larger companies and their bureaucracy don’t get your hopes up.  In my experience the best way to fix this is to find a new job.  You can avoid it by knowing your market value and negotiating a proper base to start.</p>



<h3>Constantly Update Skills</h3>



<p>The job market is always changing.  You need to keep up with it and try to stay out in front of it to maximize your earning potential.  Whatever field you are in set annual goals to achieve certifications, complete continuing education, learn a new tool or attend a conference.  </p>



<p>While one of these things by itself may not change your career, the culmination of annual self improvement over 5 to 10 years can make a massive difference in your marketability.  Senior level employees with relevant certifications and experience can be worth many times what an entry level employee is.</p>



<h3>Take Advantage of Your Time at Work</h3>



<p>You are going to be there for 8 hours a day so you might as well make the most of it.  Always seek out new projects that allow you to learn and develop your skills.  Ask about company paid training, certification or tuition.  Look for ways to add value above and beyond normal for your task.</p>



<p>Most employers will provide you with the tools, money or time to improve your skills because it directly benefits them.  If they won’t help you out here, you may want to re-consider if working there is good for your long term success.</p>



<h3>Write Down Accomplishments as They Happen</h3>



<p>Many companies do a once per year salary adjustment.  Isn’t it basically impossible to remember what all you did when walking into this conversation?</p>



<figure><img loading="lazy" width="640" height="426" src="https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist.jpg?resize=640%2C426&amp;ssl=1" data-src="https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist.jpg?resize=640%2C426&amp;ssl=1" alt="checklist" data-srcset="https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist-scaled.jpg?resize=1024%2C681&amp;ssl=1 1024w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist-scaled.jpg?resize=300%2C200&amp;ssl=1 300w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist-scaled.jpg?resize=768%2C511&amp;ssl=1 768w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist-scaled.jpg?resize=1536%2C1022&amp;ssl=1 1536w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist-scaled.jpg?resize=2048%2C1363&amp;ssl=1 2048w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist-scaled.jpg?w=1280&amp;ssl=1 1280w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist-scaled.jpg?w=1920&amp;ssl=1 1920w" data-sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"><figcaption>Keep a running list of your accomplishments</figcaption></figure>



<p>The best way to remember it all is to write it down as it happens.  Keep a running log of your accomplishments. Write them all down and come into the annual review process armed with the information you need.</p>



<h3>Frequently Update Your Fair Market Value</h3>



<p>Your fair market value is likely always changing.  Make sure to check the websites and understand if you are compensated fairly on a regular basis.  Always do this before an annual review.  </p>



<p>If the market has shifted for your skill set, or a new skill you learned is valuable, make sure your employer knows!  This is the time to ask for a larger than standard raise.  That new certification you acquired could be a great reason to go after a 5 or 10% raise this year.</p>



<h2>Asking for an Adjustment When You are Underpaid</h2>



<p>If you want to stick it out with your company, but found that you were underpaid you will need to ask for an adjustment to market value.  I find that the request should have the following basic supporting documentation:</p>



<ol><li>Report’s on salary range for your job from multiple sources.  If you are underpaid, show them multiple sources that validate this.  The more you can find the better.</li><li>Detail any recent skills you have developed or certifications that you have obtained. </li><li>List of recent accomplishments at work that show you have gone above and beyond.  You have been keeping the list like I recommend above right?</li></ol>



<p>I have asked for larger raises(&gt;10%) multiple times in my career and always gotten what I wanted by using the above method.  I have also been asked for raises by quite a few employees over the years.  Those with accompanying documentation like above were taken much more seriously.</p>



<h2>Leave If Your Employer Doesn’t Value You Correctly</h2>



<p>Some employers will never pay you fair market value.  This could be because they don’t value you fairly or because they don’t need the skills you have.  They may also just not have the money in the budget for someone of your skill level.  </p>



<p>Don’t let their decisions hold you back.  If they won’t pay you fairly then be prepared to get up and leave.  If you have been updating your skills regularly as I mentioned above you may find that moving to a better position is surprisingly easy.</p>



<h2>Conclusion</h2>



<p>I hope this has shed a little light onto the importance of salary negotiations when being hired and frequently during the course of your career.  If you ignore these conversations because they can be uncomfortable you will pay dearly for it over the long term.  </p>



<p>Ultimately, your <a href="https://www.dollartrak.com/2020/06/09/net-worth-explained/">net worth</a> can be dramatically reduced and result in you having to work for many extra years in order to meet your <a href="https://www.dollartrak.com/set-and-achieve-financial-goals/">financial goals</a>.  You should take charge of this part of your career before you look back and wish you had.</p>

			</div></div>]]>
            </description>
            <link>https://www.dollartrak.com/negotiate-salary-to-achieve-your-financial-goals/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404769</guid>
            <pubDate>Tue, 08 Sep 2020 02:40:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git/serve: A Git server for Plan 9]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24404681">thread link</a>) | @todsacerdoti
<br/>
September 7, 2020 | https://orib.dev/gitserve.html | <a href="https://web.archive.org/web/*/https://orib.dev/gitserve.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>A while ago, I released <a href="https://orib.dev/git9.html">git9</a>, a git client for
Plan 9. However, it always felt like it was missing something: A git server.
over a few weekends of work, I sat down and put one together. This Labor
Day weekend, I took the opportunity to labor on it, and got something working.</p>

<h3>usage</h3>

<p><code>Git/serve</code> is a git server designed to fit into the Plan
9 ecosystem, allowing hosting of, and interacting with, code on a Plan 9
server, while still allowing legacy clients running on Unix to get a copy
of the code.</p>

<p><code>Git/serve</code> only speaks the <code>git://</code> protocol.
But because it runs behind
<a href="http://man.9front.org/8/listen">aux/listen</a>
and 
<a href="http://man.9front.org/8/tlssrv"><code>tlssrv</code></a>, we
effectively get two additional protocols for free: <code>gits://</code>, or
TLS-encrypted <code>git://</code>, and <code>hjgit://</code>, which is
<code>git://</code> but with Plan 9 authentication to support user login
over TLS. Unfortunately, only the unencrypted <code>git://</code> protocol
is supported out of the box by upstream git. There may be ways to solve
this, using <a href="https://rovaughn.github.io/2015-2-9.html">custom
transports</a>, and a unix port of tlsclient</p>

<p>To start a <code>git://</code> server, just run it under aux/listen1.
To enable encryption and user authentication, run it under
<code>tlssrv -a</code>. This doesn't need a certificate, because
the Plan 9 authentication generates the secret used for TLS. And,
finally, if you just want encryption, you can use <code>tlsclient</code>
with a certificate.</p>

<pre># git:// server, serving every repository under the current directory
% aux/listen1 'tcp!*!9418' git/serve -r `{pwd}

# gits:// server, doing the same: But with encryption.
% aux/listen1 'tcp!*!9418' tlsclient -c /path/to/cert.pem git/serve -r `{pwd}

# hjgit:// server doing the same: Requires account on server to connect
% aux/listen1 'tcp!*!9418' tlsclient -a git/serve -r `{pwd}
</pre>

<p>If you want to allow people to write, you can just add the
<code>-w</code> flag to git/serve. While you can do this on
any of the protocols, keep in mind that only <code>hjgit://</code>
authenticates the users. Push to the world, but don't let the
world push to you!</p>



<p>All the protocols git uses are closely related. The <code>ssh://</code>
protocol is just the <code>git://</code> protocol, with the command selected
sightly differently. The smart <code>http://</code> protocols are the same
as the <code>git://</code> protocol, with a different handshake, and split
over multiple post requests.</p>

<p>Git9 implements the git protocol in under 500 lines of C. The
full code is available on github, in
<a href="https://github.com/oridb/git9/blob/1770b8f94bb1d97fdeb6f7db293ed36da9751826/serve.c">serve.c</a>.
</p>

<p>The protocol look something like this for pushing:</p>

<pre>&lt;=w= 0030:	"git-fetch-pack /oridb/git9\0host=github.com\n"
=r=&gt; 0086:	"747e9e80f710c0b8bbd928080745915ad2493322 HEAD\n"
=r=&gt; 009d:	"747e9e80f710c0b8bbd928080745915ad2493322 refs/heads/master\n"
&lt;=w= 0076:	"747e9e80f710c0b8bbd928080745915ad2493322 dc802c499dc7164aa208b919a07c5bd18701b0e1 refs/heads/master\0report-status\n"
&lt;=w= 0000
&lt;=w= <pack-data>
=r=&gt; 000e:	unpack ok
=r=&gt; 0019:	ok refs/heads/master
</pack-data></pre>

<p>And this for pulling:</p>

<pre>&lt;=w= 0030:	"git-upload-pack /oridb/git9\0host=github.com\n"
=r=&gt; 013b:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 HEAD\n"
=r=&gt; 003f:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 refs/heads/master\n"
=r=&gt; 0000
&lt;=w= 0032:	"want 5d761590cfdce23e4b17e94050b0776c8804d4a1\n"
&lt;=w= 0032:	"want 8f0eb1386a2c748cb7bf26917684479ff8c6d5b5\n"
&lt;=w= 0032:	"want dc4a9d467c6a28dab3927c8611a1bfbc571f1568\n"
&lt;=w= 0000
&lt;=w= 0033:	"have dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
&lt;=w= 0009:	"done\n"
=r=&gt; 0031:	"ACK dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
<pack-data>
</pack-data></pre>

<p>The git protocol consists of pkt-lines, which are strings with a
hex-formatted length prefix.  The length prefix includes itself.  So,
the string <code>"hi"</code> would be formatted as
<code>0006hi</code>. A zero lenth packet where the length prefix
is not included is special. This is called a 'flush packet', and
is used to terminate a phase of negotiation.</p>

<p> All negotiation is with these packet lines, at
which git flips over to pure binary mode to transfer a pack file
over.</p>

<p>In the <code>git://</code> protocol, the client always starts off
by saying which action it wants to do: Either it wants the server to
fetch a pack from the client, or it wants the server to upload a pack
to the client.  That's this line:</p><pre>&lt;=w= 0030:	"git-fetch-pack /oridb/git9\0host=github.com\n"
</pre>

<p>The upload side of this protocol is simpler on the server side so
we'll go through it first.</p>

<h3>pushing</h3>

<p>In the upload protocol, the server begins by sending a list of
references that the client may update. In <code>git/serve</code>
we grab all the refs in the repository, and filter down to just
the ones beginning with <code>heads/</code>.</p>

<pre>	if((nrefs = listrefs(&amp;refs, &amp;names)) == -1)
		sysfatal("listrefs: %r");
	for(i = 0; i &lt; nrefs; i++){
		if(strncmp(names[i], "heads/", strlen("heads/")) != 0)
			continue;
		if(fmtpkt(c, "%H refs/%s\n", refs[i], names[i]) == -1)
			goto error;
	}
	if(flushpkt(c) == -1)
		goto error;
</pre>

<p>With the first phase of the protocol, the client then
sends the list of references it wants to update. This
takes the form of:</p>

<pre>	OLDHASH NEWHASH heads/refs/updateme\n"
</pre>

<p>Because the client knows what the reference versions are on
the server, it can compute what commits are between the version
on the server and the version that it has. If the new hash
is the zero hash, this signals to the server that the reference
should be deleted. This list of updates is terminated with a
flush packet. The code in git9 that handles this is below:

</p><pre>	while(1){
		/* Did we get a packet? */
		if((n = readpkt(c, pkt, sizeof(pkt))) == -1)
			goto error;
		/* Was it a flush packet? */
		if(n == 0)
			break;
		/* Split it up into the 3 parts: old, new, reference */
		if(getfields(pkt, sp, nelem(sp), 1, " \t\n\r") != 3){
			fmtpkt(c, "ERR  protocol garble %s\n", pkt);
			goto error;
		}
		/* verify that these are valid hashes */
		if(hparse(&amp;old, sp[0]) == -1){
			fmtpkt(c, "ERR bad old hash %s\n", sp[0]);
			goto error;
		}
		if(hparse(&amp;new, sp[1]) == -1){
			fmtpkt(c, "ERR bad new hash %s\n", sp[1]);
			goto error;
		}
		/* and valid refs */
		if(!validref(sp[2])){
			fmtpkt(c, "ERR invalid ref %s\n", sp[2]);
			goto error;
		}
		/* and then remember them for when we do the update */
		*cur = erealloc(*cur, (*nupd + 1)*sizeof(Hash));
		*upd = erealloc(*upd, (*nupd + 1)*sizeof(Hash));
		*ref = erealloc(*ref, (*nupd + 1)*sizeof(Hash));
		(*cur)[*nupd] = old;
		(*upd)[*nupd] = new;
		(*ref)[*nupd] = estrdup(sp[2]);
		*nupd += 1;
	}
</pre>

<p>Next, the client uploads the pack. This is a blob containing
the commit data. It goes into <code>.git/objects/packs/recv-$pid.pack</code>,
at least until we can index it and rename it.</p>

<pre>	while(1){
		n = read(c-&gt;rfd, buf, sizeof(buf));
		if(n == 0)
			break;
		if(n == -1 || write(pfd, buf, n) != n)
			return -1;
		packsz += n;
	}
	if(checkhash(pfd, packsz, &amp;h) == -1){
		dprint(1, "hash mismatch\n");
		goto error1;
	}
	if(indexpack(packtmp, idxtmp, h) == -1){
		dprint(1, "indexing failed\n");
		goto error1;
	}
	if(rename(packtmp, idxtmp, h) == -1){
		dprint(1, "rename failed: %r\n");
		goto error2;
	}
</pre>

<p>Finally, we update the references. Note that we haven't
locked the repository yet. This is because none of the data
we have here can conflict: All objects are addressed by hash,
so a race would simply leave us with a duplicate hash in the
packfile. Eventually, a <code>git/repack</code> will clean
that up.</p>

<p>However, updating the references can conflict. So,
for updating the references, we acquire a lock file.
We then read all the references, make sure that they
match the old reference, and then write in the new
reference.</p>

<pre>	for(i = 0; i &lt; nupd; i++){
		if(resolveref(&amp;h, ref[i]) == 0 &amp;&amp; !hasheq(&amp;h, &amp;cur[i])){
			fmtpkt(c, "ERR old ref changed: %s", ref[i]);
			goto error;
		}
		if((o = readobject(upd[i])) == nil){
			fmtpkt(c, "ERR update to nonexistent hash %H", upd[i]);
			goto error;
		}
		if(o-&gt;type != GCommit){
			fmtpkt(c, "ERR not commit: %H", upd[i]);
			goto error;
		}
		unref(o);
		if(snprint(refpath, sizeof(refpath), ".git/%s", ref[i]) == sizeof(refpath)){
			fmtpkt(c, "ERR ref path too long: %s", ref[i]);
			goto error;
		}
		if((fd = create(refpath, OWRITE, 0644)) == -1){
			fmtpkt(c, "ERR open ref: %r");
			goto error;
		}
		if(fprint(fd, "%H", upd[i]) == -1){
			close(fd);
			fmtpkt(c, "ERR upate ref: %r");
			goto error;
		}
		close(fd);
	}
</pre>

<p>And that's pushing.

</p><h3>pulling</h3>

<p>Pulling takes more work on the server side, because the
server needs to compute a reasonable packfile to send to
the client. The protocol itself is still fairly simple.</p>

<p>It begins the same way as pushing, by sending all the
branches that a client may want to obtain from the git
repository.</p>

<pre>=r=&gt; 013b:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 HEAD\n"
=r=&gt; 003f:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 refs/heads/master\n"
=r=&gt; 0000
</pre>

<p>The client then starts telling us what commits they want,
and what commits they have. This lets us find a graph difference
between the server and client graph, and generate a pack file
that contains few, if any, extraneous commits. </p>

<pre>&lt;=w= 0032:	"want 5d761590cfdce23e4b17e94050b0776c8804d4a1\n"
&lt;=w= 0032:	"want 8f0eb1386a2c748cb7bf26917684479ff8c6d5b5\n"
&lt;=w= 0032:	"want dc4a9d467c6a28dab3927c8611a1bfbc571f1568\n"
&lt;=w= 0000
&lt;=w= 0033:	"have dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
&lt;=w= 0009:	"done\n"
=r=&gt; 0031:	"ACK dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
</pre>

<p>Computing the commits that go into a pack is not always trivial.
The comits that the client may be on may have "bubbles" in the graph,
so simply walking back from the start of the graph to the commits
that the client has may end up walking around the commit, leading
to nearly the whole history of the repository being sent, instead
of just one or two commits.</p>

<p>Consider a repo where the server is ahead of the client, and
now the client is trying to pull the changes. The client has commits
<code>c</code>, and we're trying to compute a pack with only the
commits <code>o</code>.</p>


<pre>                o---o
               /     \
    --c---c---c---c---o---o &lt;-- server
                  ^
                client
</pre>

<p>The client does a git/pull, and sends that it has the
commit marked <code>[c]</code>. Since the server has
every commit the client does, and more, it can look at
all ancestors of the client commit. If we're smart, we
would, but a naive …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://orib.dev/gitserve.html">https://orib.dev/gitserve.html</a></em></p>]]>
            </description>
            <link>https://orib.dev/gitserve.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404681</guid>
            <pubDate>Tue, 08 Sep 2020 02:19:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On writing and selling science fiction stories (2018)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24404555">thread link</a>) | @forrestbrazeal
<br/>
September 7, 2020 | https://forrestbrazeal.com/2018/11/08/on-writing-and-selling-science-fiction-stories/ | <a href="https://web.archive.org/web/*/https://forrestbrazeal.com/2018/11/08/on-writing-and-selling-science-fiction-stories/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section>
          <section>
              

              
              
              <article>
                  

<p>Each year, I try to set a few personal goals that stretch me in some way.</p>

<p>In 2017, for example, I <a href="https://forrestbrazeal.com/2017/12/03/how-to-read-100-books-in-a-year-and-still-have-a-life/">read one hundred books</a>, which turned out to be more a test of endurance than skill.</p>

<p>This year, I decided to see if I could write a fictional short story and get it published somewhere. Though I do a fair amount of technical writing in the course of my work, I’d never seriously attempted to write and sell a short story before, or even taken a creative writing class.</p>

<p>This meant I had no knowledge of the market, no connections, and generally no idea what I was doing.</p>

<p>So, a challenge!</p>

<h2 id="goals">Goals</h2>

<p>I decided to focus on the <a href="https://en.wikipedia.org/wiki/Speculative_fiction">speculative fiction genre</a>, partly because it seemed more accessible and mostly because unlike literary journals, the best speculative fiction magazines still pay their authors.</p>

<p>My goals, in descending order of likelihood, were as follows:</p>

<ol>
<li><p>Get something published somewhere, even if unpaid</p></li>

<li><p>Get something published and get paid something for it, even a token amount</p></li>

<li><p>Get something published at <a href="https://www.sfwa.org/about/join-us/sfwa-membership-requirements/#short">Science Fiction Writers of America (SFWA) professional rates</a> (currently 6 cents a word)</p></li>

<li><p>Get at least 1000 words published at SFWA-qualifying markets (the standard for <a href="https://www.sfwa.org/about/join-us/sfwa-membership-requirements/#associate">SFWA associate member status</a>)</p></li>

<li><p>Get at least three stories published, totaling more than 10,000 words, at SFWA-qualifying professional markets (<a href="https://www.sfwa.org/about/join-us/sfwa-membership-requirements/#active">SFWA Active Member status</a>, my self-imposed standard for a legit “professional” science fiction writer)</p></li>
</ol>

<h2 id="results-through-nov-8">Results (through Nov. 8)</h2>

<p>After many form rejections on several terrible stories, I sold my <a href="https://dailysciencefiction.com/science-fiction/biotech/forrest-brazeal/memory-foam">first story</a> on March 23rd, 2018, to Daily Science Fiction (an SWFA pro market). At 1010 words, this sale actually crossed the first four goals off my list at once.</p>

<p>However, I continued to write and improve over the spring and summer of 2018, selling several more stories along the way, eventually totaling more than 16,000 words of fiction. Some publications have long wait times, but by the time “Empathy Bee” <a href="http://www.diabolicalplots.com/the-diabolical-plots-year-five-fiction-lineup/">is published</a> in March 2019, I should have the wordcount needed for active SFWA membership status, my most insane stretch goal.</p>

<h3 id="by-the-numbers">By the numbers</h3>

<ul>
<li><p>Stories Written: 22</p></li>

<li><p>Total Wordcount: ~60,000, the length of a medium-sized novel</p></li>

<li><p>Total Submissions: 70</p></li>

<li><p>Stories Sold: 8</p></li>

<li><p>SFWA-qualifying professional sales: 6</p></li>

<li><p>Rejections: 50 (15 personal)</p></li>

<li><p>Withdrawals: 2</p></li>

<li><p>Still Pending: 10</p></li>

<li><p>Other Results: <a href="https://www.writersofthefuture.com/writers-of-the-future-3rd-quarter-standings-for-year-35/">Honorable Mention, Writers of the Future</a></p></li>
</ul>

<h2 id="what-i-learned">What I Learned</h2>

<h3 id="have-no-ego">Have no ego</h3>

<p>It turns out writing short stories that sell is really, really hard. It’s hard to think of good ideas, it’s hard to write them down in a form that anyone would want to read, and it’s even harder when those readers are magazine editors who get literally hundreds of unsolicited submissions every month. Don’t attempt it if you have an easily bruised sense of self-worth, or you will be depressed a lot.</p>

<p>I’m grateful to have sold some stories this year, but my identity is not tied up in “being a writer”. It can’t be, because I have to…</p>

<h3 id="embrace-failure">Embrace failure</h3>

<p>I learned to view rejections as a badge of honor, which is a helpful mental trick to keep from going insane after a few dozen forms. As I told Jason Bougger in an <a href="http://www.themeofabsence.com/2018/11/author-interview-forrest-brazeal/">author interview</a> over at Theme of Absence, rejections are like the good soreness you feel after working out – it means you’re growing.</p>

<h3 id="keep-your-feedback-loop-short">Keep your feedback loop short</h3>

<p>Early on, when I was getting form rejections from big magazines with no accompanying feedback, I got really frustrated because I knew my work was obviously not up to par – I just didn’t know why. A submission to a smaller publication, Abyss and Apex (who I later ended up selling a different story to!) brought back a personalized rejection with a helpful piece of advice: try signing up for the <a href="https://sff.onlinewritingworkshop.com/">Online Writing Workshop</a>.</p>

<p>At the time I had never heard of writers’ workshops and didn’t really understand why they would be helpful. But I paid a few dollars and signed up. The other writers there provided generous feedback on how to improve my work, and I learned just as much from critiquing their pieces. The OWW membership more than paid for itself when several readers pointed out an obvious plot hole in my story “Empathy Bee”, which subsequently sold in revised form to Diabolical Plots.</p>

<p>Later, once I had professional credits, I was able to join the wonderful <a href="http://www.codexwriters.com/">Codex</a> writers’ community, which has hugely expanded my horizons and understanding of the industry. The more I write, the less I trust myself to be a good judge of my work’s quality, and the more I seek out and appreciate feedback from others.</p>

<h3 id="write-smart-not-just-hard">Write smart, not just hard</h3>

<p>Some writers recommend keeping insane writing regimens, cranking out thousands of words a day, saying it’s the only way to improve. And I wrote a fair amount this year. But stepping back and getting feedback on my work was just as important.</p>

<p>I had a music teacher who used to ask: “Did you practice ten hours, or just the same hour ten times?” When I took time to evaluate my work and deliberately build on it, I improved faster than just by vomiting words indiscriminately onto the page.</p>

<h3 id="keep-reading-good-prose">Keep reading good prose</h3>

<p>No, I didn’t read a hundred books again this year. But I did try to keep my ear filled with good prose. For example, this summer I got on a southern realist kick: Flannery O’Connor, Eudora Welty, Carson McCullers. Studying how those writers crafted characters and situations helped me nail down a couple of southern-set stories that ended up selling. My science fiction writing improved more from reading good writers, period, than from reading science fiction.</p>

<h3 id="just-because-you-wrote-something-good-enough-to-get-published-somewhere-that-doesn-t-mean-the-next-thing-you-write-won-t-be-terrible">Just because you wrote something good enough to get published somewhere, that doesn’t mean the next thing you write won’t be terrible</h3>

<p>This sounds stupid in hindsight, but for a long time I had it in my head that once I sold a story, I’d have figured out what it took to get published, and I wouldn’t have any trouble after that. Instead, I still get tons of rejections, and often my writing seems just as lifeless and terrible to me as it did before I sold my first story.</p>

<p>The good news is that with practice, the overall trend appears to be upward. At least, when I look back at my work from the beginning of the year, I can’t believe how bad it is. So I must be improving, right?</p>

<h2 id="what-s-next">What’s next?</h2>

<p>Like many people who start out in the short fiction game, I would love to publish a novel. So I think that might be a 2019 goal. But I’m sure I’ll continue to write short stories, too. There’s real satisfaction in creating something that you can hold in your head all at once, knowing how it will turn out and why it’s effective.</p>

<p><em>Some of the stories I sold this year are free to read online. You can check them out in my <a href="https://forrestbrazeal.com/bibliography/">bibliography</a></em></p>

              </article>
              <center>
              <p>
                      If you enjoy my articles, comics, and stories, why not sign up for the mailing list?
                  </p>
              
            </center>
              
          </section>
          <br>
          

      </section>

    </div></div>]]>
            </description>
            <link>https://forrestbrazeal.com/2018/11/08/on-writing-and-selling-science-fiction-stories/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404555</guid>
            <pubDate>Tue, 08 Sep 2020 01:53:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[After-the-Fact Warnings]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24404337">thread link</a>) | @arkadiyt
<br/>
September 7, 2020 | https://emilymstark.com/2020/09/07/after-the-fact-warnings.html | <a href="https://web.archive.org/web/*/https://emilymstark.com/2020/09/07/after-the-fact-warnings.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In my line of work, we talk a lot about security warning design and
effectiveness. Usually, the task of a warning is to prevent a user from doing
something dangerous, such as accepting an invalid certificate or installing
malware. There’s another class of warnings which tell users that something bad
has <em>already</em> happened, with the aim of helping them recover. I’ll call this
category <strong>after-the-fact warnings</strong>.</p>

<p>I don’t know much about after-the-fact warnings, such as best practices for how
to design them or how effective they can be. In fact I know so little that I had
to make up a name for this category of warnings, when there probably already
exists a fancy academic name. So I
<a href="https://twitter.com/estark37/status/1301545990848094208">asked</a> for some
research pointers on Twitter and collected an interesting reading list. I’ll
summarize some of my observations here. Note that this isn’t a comprehensive
survey – just some thoughts from the papers that caught my eye the most.</p>



<p>To set the stage, here are some real world examples of after-the-fact warnings.
Again, this isn’t comprehensive, just some examples that I can think of:</p>

<ul>
  <li>Antivirus notifications telling people that they have malware on their device</li>
  <li>Password breach notifications, either from a first-party (LinkedIn notifying
users that their LinkedIn password has been leaked) or third-party service
provider (<a href="https://haveibeenpwned.com/">HaveIBeenPwned</a>,
<a href="https://security.googleblog.com/2019/12/better-password-protections-in-chrome.html">a web browser</a>)</li>
  <li>Chrome has a feature
(“<a href="https://www.blog.google/technology/safety-security/new-security-protections-tailored-you/">predictive phishing protection</a>”)
that notices when you type a saved password on a suspected phishing site and
warns you that you may have been phished and should change your password. This
is similar to a password breach notification, but has some different
considerations because the suspected attack is phishing rather than credential
stuffing.</li>
  <li>Other (non-password) data breach notifications, for example an email from
Equifax telling people that their personal data has been leaked</li>
  <li>Some browsers have persistent UI telling the user that they’ve bypassed a
security warning in the past. For example, after a person clicks through a
certificate, phishing, or malware warning in Chrome, the address bar shows a
red “Not Secure” chip to let them know that they’re in an unsafe state. It
might be a bit of a stretch to call this an after-the-fact warning, as it’s
not clear what action the warning is asking the user to take.</li>
</ul>

<figure>
  <img src="https://emilymstark.com/assets/after_cert_error.png" alt="Chrome UI after bypassing a certificate error">
  <figcaption><i>Google
Chrome UI after bypassing a certificate error. The page loads normally but the
address bar shows a red “Not Secure” chip to emphasize that the user is in an
unsafe state.</i></figcaption>
</figure>

<p>Finally, there are some interesting hypothetical examples of after-the-fact
warnings, which is what originally got me interested in this area.
<a href="https://emilymstark.com/2020/07/20/certificate-transparency-a-birds-eye-view.html">Certificate Transparency</a>
introduces an asynchronous certificate verification step. The browser might
accept a certificate as valid, but then find out that it was actually not valid,
days or weeks later. It’s generally been considered beyond the pale for the
browser to warn the user at this point. How might the browser communicate that a
website the user visited in the past was potentially compromised? What is the
user supposed to do about it? I think the answer to these questions is probably
that the browser shouldn’t try to communicate this message, because it’s too
hard to understand and there’s nothing the user can be expected to do about it.
But I’m not totally sure that’s the right answer, and that’s what got me
interested in how successful after-the-fact warnings can be.</p>



<p>I read 5 papers on this topic:</p>

<ul>
  <li><a href="https://www.mobsec.ruhr-uni-bochum.de/media/mobsec/veroeffentlichungen/2018/09/10/ccsf266-finalv1.pdf">“What was that site doing with my Facebook password?” Designing Password-Reuse Notifications</a> <em>Golla et al.</em>
    <ul>
      <li>This paper describes two surveys about notifications that companies send
when they discover a user’s password in a password dump from another
service. The first survey studies representative examples of real-world
notifications, and the second survey uses a model notification designed
using the lessons from the first survey. Comprehension was pretty poor
across the board. Most users reported that they would change their
password upon receiving the model notification, but very few said they
would change their password to something unrelated. (And of course,
surveys don’t always give us the best information about what someone would
do in real life.)</li>
    </ul>
  </li>
  <li><a href="https://www.ieee-security.org/TC/SPW2020/ConPro/papers/bhagavatula-conpro20.pdf">(How) Do People Change Their Passwords After a Breach?</a> <em>Bhagavatula et al.</em>
    <ul>
      <li>This paper makes use of the Security Behavior Observatory, which is a
large group of participants who have agreed to run research software on
their machines to collect information about their security behaviors. This
allowed the researchers to observe how many users changed their password
when their accounts were actually breached in real life. The answer is
that not so many participants did change their passwords (33%), and of
those, many participants didn’t do so for quite a long time after the
breach.</li>
    </ul>
  </li>
  <li><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8835359">“Should I Worry?” A Cross-Cultural Examination of Account Security Incident Response</a> <em>Redmiles</em>
    <ul>
      <li>This paper describes a set of interviews with Facebook users from 5
countries. The interviewers asked participants about how they responded to
notifications from Facebook that their account had a suspicious login.
These notifications tell the user that their account may have been
compromised and then ask them to complete a secondary authentication task,
such as identifying photos of their friends. One finding that particularly
caught my eye was that, when asked what alerted them to the suspicious
login, participants sometimes identified the secondary authentication task
rather than the initial notification. The paper hypothesizes that this may
be due to warning fatigue blinding users to the initial notification.
(Warning fatigue is when users see many warnings and get habituated to
them, ceasing to take action on them.)</li>
    </ul>
  </li>
  <li><a href="http://lersse-dl.ece.ubc.ca/record/316/files/CHI-17_huh_paper.pdf">I’m too Busy to Reset my LinkedIn Password: On the Effectiveness of Password Reset Emails</a> <em>Huh et al.</em>
    <ul>
      <li>This paper describes a Mechanical Turk survey of participants who had
received password breach notifications from LinkedIn. For a methodological
contrast, “‘What was that site doing with my Facebook password?’ Designing
Password-Reuse Notifications” asked people what they would do
hypothetically, and “(How) Do People Change Their Passwords After a
Breach?” observed what people actually did (with a slight caveat that
there were some heuristics used to figure out what people actually did
from the available data). In this Huh et al. paper, the researchers asked
people to recall what they did. Each of these methods has its pros and
cons; asking people to recall what they did can suffer from <a href="https://en.wikipedia.org/wiki/Recall_bias">recall
bias</a>, though in this case the
authors took some steps to combat this bias by asking participants to
provide screenshots to verify that they had actually received the
notification and changed their password (if applicable). The results
showed a somewhat higher rate of password change (~50%) than other work,
but identified some other themes in common with other work: a substantial
delay before participants took action, and a tendency to choose weak or
related passwords when they did eventually change their password.</li>
    </ul>
  </li>
  <li><a href="https://yixinzou.github.io/publications/chi2019-zou.pdf">You ‘Might’ Be Affected: An Empirical Analysis of Readability and Usability Issues in Data Breach Notifications</a> <em>Zou et al.</em>
    <ul>
      <li>This paper analyzes a dataset of real-world data breach notifications
downloaded from government databases. Most were mailed notifications.
Because I’m mostly interested in experimental results from electronic
notifications, I only skimmed this paper. The paper compiles a list of
best practices and recommendations for notification design (such as using
clear and concise language and highlighting key information visually) as
well as public policy (such as encouraging that notifications are
delivered across multiple channels). These recommendations seem to broadly
make sense, but I would be hesitant to apply them too dogmatically to
computer security warnings without verifying them experimentally.</li>
    </ul>
  </li>
</ul>

<p>Finally, there’s a body of adjacent work about vulnerability and
misconfiguration notifications sent to server operators. For example, Durumeric
et al. conducted an experiment notifying 150,000 server operators that their
servers were vulnerable to the Heartbleed vulnerability. I’m more familiar with
this area of research because I’ve done work in it
<a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/06a75f932595f27a60092007965934c957b5de21.pdf">myself</a>.
My overall impression is that the effectiveness of this type of notifications
varies quite widely depending on the severity and urgency of the issue and the
effort needed to remedy it. Regardless, I view this area as mostly tangential
because I’m particularly interested in after-the-fact warnings for end users,
which is a substantially different population than server operators.</p>



<p>Here’s a collection of questions that I was hoping to find in these papers but
didn’t:</p>

<ul>
  <li>There’s a bit of an elephant in the room: <strong>is it possible for users to
actually recover once they’ve been compromised?</strong> Most of the work I described
above focuses on getting users to complete a particular action, such as
changing their password to a new, strong, unique password. But what if that’s
not enough? Data may have already been leaked or the account’s integrity
violated. The Redmiles paper (“‘Should I Worry?’”) touches on this issue by
describing follow-up actions that participants performed to verify their
account integrity, such as checking whether any unauthorized messages had been
sent from their account. But I think the research community hasn’t grappled
with what’s involved in truly recovering from an account compromise, and I
could spend a long time meditating on whether it makes sense to do
after-the-fact warnings at all if we don’t know what to tell users to do to
recover. (Also relevant: my colleague Chris Palmer pondering
<a href="https://noncombatant.org/2019/08/24/recoverability/">recoverability</a>.)</li>
  <li><strong>How well do antivirus notifications work?</strong> When AV software pops up a
warning that the user has some malware installed, how likely are users to
comprehend the risks and respond effectively? (And, reiterating the elephant
in the room, what does “effectively” even mean in this case?) …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://emilymstark.com/2020/09/07/after-the-fact-warnings.html">https://emilymstark.com/2020/09/07/after-the-fact-warnings.html</a></em></p>]]>
            </description>
            <link>https://emilymstark.com/2020/09/07/after-the-fact-warnings.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404337</guid>
            <pubDate>Tue, 08 Sep 2020 01:14:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case for Comments in Code]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24404170">thread link</a>) | @eatonphil
<br/>
September 7, 2020 | https://notes.eatonphil.com/the-case-for-comments-in-code.html | <a href="https://web.archive.org/web/*/https://notes.eatonphil.com/the-case-for-comments-in-code.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <p>When I first started programming, especially when asked for code
samples, my comments lacked purpose and would often duplicate in
English what the code clearly indicated. I knew that "commenting is
good" but as a beginner I had no further insight.</p>
<p>Over time with the help of books like Clean Code, I grew disdainful of
comments. Good code should be self-documenting. Whenever I needed to
write a comment to explain something, I'd realize I could easily
rename some key variable or function. I grew more comfortable with
variables and functions with a few words in the title. Better to spend
time on good code structure and naming.</p>
<p>
  I have always left TODOs though, since TODOs can't so easily be
  expressed in variable names. But even these TODOs concerned me
  because they existed in my issue tracker, or maybe should have.
</p><p>As I watched mature open source projects and mature engineers, I came
to value well-documented pull requests. Solid pull requests include or
link to all necessary background, opportunities failed or ignored, how
to use, links to external bugs requiring workarounds and the results
of performance evaluation.</p>
<p>Beyond pull request descriptions, when I really wanted to grease a
pull request I'd use the pull request UI to add comments calling
reviewer attention to key changes in lines of the diff.</p>
<p>Both kinds of guidance are a massive aid to reviewers, saving a lot of
time.</p>
<p>But when I'd find a bug in code -- and I knew there was good pull
request documentation, even for pull requests as recent as six months
ago -- I've been repeatedly failed by the pull request and <em>pull
request comment</em> search exposed by Github and Gitlab.</p>
<p>I <em>knew</em> there were links to documented oddities or bug reports in
pull request threads. But practically speaking, for historic pull
requests, pull request comments are useless.</p>
<p>This is the single biggest reason I've started to push for more
comments in code. More so than all other tools (issue tracker, code
management system, etc.) comments in code have the greatest chance of
still being around and <em>easily searchable</em> if they haven't been
deleted.</p>
<p>
  Don't get me started on pull request documentation in an external
  medium like Slack. It's so rewarding to get or give instant feedback
  on changes on instant messengers, but good luck finding that
  discussion 3 months later.
</p><p>Every time I have to call out a line of code in a pull request, that's
immediate cause for that code to be modified with comments.</p>
<p>Maybe I wouldn't do this if Github/Gitlab exposed a Google Docs-like
interface for browsing code line by line with links to all pull
request comment threads.</p>
<p>Please reply on Twitter with questions or comments.</p>
<blockquote><p lang="en" dir="ltr">The biggest reason to add comments in code (often linking to documented oddities or bug reports) is because it's impossible to search pull request threads historically in every source control management UI I've used.<a href="https://t.co/JlHWfbUH5z">https://t.co/JlHWfbUH5z</a></p>— Phil Eaton (@phil_eaton) <a href="https://twitter.com/phil_eaton/status/1303130504993136642?ref_src=twsrc%5Etfw">September 8, 2020</a></blockquote> 

      </div>
    </div></div>]]>
            </description>
            <link>https://notes.eatonphil.com/the-case-for-comments-in-code.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404170</guid>
            <pubDate>Tue, 08 Sep 2020 00:43:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ReportCrash High CPU and How to Disable Reportcrash in Mac OS X]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24404079">thread link</a>) | @ai_ja_nai
<br/>
September 7, 2020 | https://www.gregoryvarghese.com/reportcrash-high-cpu-disable-reportcrash/ | <a href="https://web.archive.org/web/*/https://www.gregoryvarghese.com/reportcrash-high-cpu-disable-reportcrash/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

			<section>

				<article>

					
	


					<section>
						<p>For a while now, all of my MacBooks have run extremely hot and the fans have gone nuts. While <a href="https://www.gregoryvarghese.com/category/troubleshooting/"></a><a href="https://www.gregoryvarghese.com/tag/troubleshooting/">troubleshooting</a> the issue, Activity Monitor showed that an app named <a href="https://www.gregoryvarghese.com/tag/reportcrash/">reportcrash</a> has run very high on the CPU and has killed my battery life. Force quitting the app didn’t help as it would start right back up in a few seconds and climb back to 80-100% usage of the CPU.</p>
<h2>What is CrashReporter?</h2>
<p>CrashReporter runs in any time an application crashes and it’s designed to saves the application state to aid developers in working out why the app crashed. Basically aÂ&nbsp;process isÂ&nbsp;launching, crashing (and invoking CrashReporter) and then re-launching, repeating this cycle never ending.</p>
<h2>How to Identify What’s Crashing</h2>
<p>To show which process is triggering this cycle and stop it, CrashReporter is pretty verbose in its logging which makesÂ&nbsp;finding the problem app somewhat easier. Open up the <a href="https://www.gregoryvarghese.com/tag/console/">console</a>.app (/<a href="https://www.gregoryvarghese.com/category/admin/windows/applications/"></a><a href="https://www.gregoryvarghese.com/tag/applications/">Applications</a>/<a href="https://www.gregoryvarghese.com/category/admin/windows/utilities/">Utilities</a>/<a href="https://www.gregoryvarghese.com/tag/console/">Console</a>.app) and look towards the end of your system.log to see what app is crashing.</p>
<p>Unfortunately for me, the problem is a driver by some company called EFI and getting the latest drivers didn’t resolve the issue. The next obvious solution was to disable <a href="https://www.gregoryvarghese.com/tag/reportcrash/">reportcrash</a>.</p>
<h2>How to Disable <a href="https://www.gregoryvarghese.com/tag/reportcrash/">ReportCrash</a></h2>
<p>Fire up <a href="https://www.gregoryvarghese.com/category/admin/mac-admin/terminal/"></a><a href="https://www.gregoryvarghese.com/category/admin/linux/ssh/terminal-ssh/"></a><a href="https://www.gregoryvarghese.com/tag/terminal/">terminal</a> and run the following commands to disable <a href="https://www.gregoryvarghese.com/tag/reportcrash/">reportcrash</a>:</p>
<pre title="How to Disable ReportCrash OSX">launchctl unload -w /System/Library/LaunchAgents/com.apple.<a href="https://www.gregoryvarghese.com/tag/reportcrash/">ReportCrash</a>.plist
sudo launchctl unload -w /System/Library/LaunchDaemons/com.apple.<a href="https://www.gregoryvarghese.com/tag/reportcrash/">ReportCrash</a>.Root.plist</pre>
<h2>How to Enable <a href="https://www.gregoryvarghese.com/tag/reportcrash/">ReportCrash</a></h2>
<p>If you need to reenable crash report, run the following commands in <a href="https://www.gregoryvarghese.com/category/admin/mac-admin/terminal/"></a><a href="https://www.gregoryvarghese.com/category/admin/linux/ssh/terminal-ssh/"></a><a href="https://www.gregoryvarghese.com/tag/terminal/">terminal</a>:</p>
<pre title="Enable Reportcrash">launchctl load -w /System/Library/LaunchAgents/com.apple.<a href="https://www.gregoryvarghese.com/tag/reportcrash/">ReportCrash</a>.plist
sudo launchctl load -w /System/Library/LaunchDaemons/com.apple.<a href="https://www.gregoryvarghese.com/tag/reportcrash/">ReportCrash</a>.Root.plist</pre>

											</section>

					
	

					
	

				</article>

				
	


				
	<section>

		<a id="comments"></a>

		

		
	</section>


			</section>

			
	

			
		</section></div>]]>
            </description>
            <link>https://www.gregoryvarghese.com/reportcrash-high-cpu-disable-reportcrash/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404079</guid>
            <pubDate>Tue, 08 Sep 2020 00:25:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast.ai and why Python is not the future of ML with Jeremy Howard]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24404002">thread link</a>) | @tosh
<br/>
September 7, 2020 | https://www.wandb.com/podcast/jeremy-howard | <a href="https://web.archive.org/web/*/https://www.wandb.com/podcast/jeremy-howard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Jeremy Howard is a founding researcher at fast.ai, a research institute dedicated to making Deep Learning more accessible. Previously, he was the CEO and Founder at Enlitic, an advanced machine learning company in San Francisco, California. </p><p>Howard is a faculty member at Singularity University, where he teaches data science. He is also a Young Global Leader with the World Economic Forum, and spoke at the World Economic Forum Annual Meeting 2014 on "Jobs For The Machines." </p><p>Howard advised Khosla Ventures as their Data Strategist, identifying the biggest opportunities for investing in data-driven startups and mentoring their portfolio companies to build data-driven businesses. Howard was the founding CEO of two successful Australian startups, FastMail and Optimal Decisions Group. Before that, he spent eight years in management consulting, at McKinsey &amp; Company and AT Kearney.</p><p><strong>TOPICS COVERED:</strong></p><p>0:00 Introduction</p><p>0:52 Dad things</p><p>2:40 The story of Fast.ai</p><p>4:57 How the courses have evolved over time</p><p>9:24 Jeremy’s top down approach to teaching</p><p>13:02 From Fast.ai the course to Fast.ai the library</p><p>15:08 Designing V2 of the library from the ground up</p><p>21:44 The ingenious type dispatch system that powers Fast.ai</p><p>25:52 Were you able to realize the vision behind v2 of the library</p><p>28:05 Is it important to you that Fast.ai is used by everyone in the world, beyond the context of learning</p><p>29:37 Real world applications of Fast.ai, including animal husbandry</p><p>35:08 Staying ahead of the new developments in the field</p><p>38:50 A bias towards learning by doing</p><p>40:02 What’s next for Fast.ai</p><p>40.35 Python is not the future of Machine Learning</p><p>43:58 One underrated aspect of machine learning</p><p>45:25 Biggest challenge of machine learning in the real world</p><p>Follow Jeremy on Twitter:</p><p><a href="https://twitter.com/jeremyphoward" target="_blank">https://twitter.com/jeremyphoward</a><br></p><p>Links:</p><p>Deep learning R&amp;D &amp; education: <a target="_blank" href="https://t.co/ZvDGNlehRt?amp=1">http://fast.ai</a></p><p>Software: <a target="_blank" href="https://t.co/GMYkPDXNW3?amp=1">http://docs.fast.ai</a></p><p>Book: <a target="_blank" href="https://t.co/1YSqXvWW87?amp=1">http://up.fm/book</a></p><p>Course: <a target="_blank" href="https://t.co/Q2qMl59EfH?amp=1">http://course.fast.ai</a></p><p>Papers:</p><p><a target="_blank" href="https://dl.acm.org/doi/10.1145/2487575.2491127"><strong>The business impact of deep learning</strong></a></p><p><a target="_blank" href="https://dl.acm.org/doi/10.1145/2487575.2491127">https://dl.acm.org/doi/10.1145/2487575.2491127</a></p><p><a target="_blank" href="https://www.linkedin.com/redir/redirect?url=http%3A%2F%2Fwww%2Ejmir%2Eorg%2F2012%2F1%2Fe33%2F&amp;amp;urlhash=gLU-&amp;trk=public_profile_publication-title"><strong>De-identification Methods for Open Health Data</strong></a></p><p><a href="https://www.jmir.org/2012/1/e33/">https://www.jmir.org/2012/1/e33/</a><br></p><p>Visit our podcasts homepage for transcripts and more episodes!</p><p><a target="_blank" href="https://www.wandb.com/podcast">www.wandb.com/podcast</a></p><p> Get our podcast on Soundcloud, Apple, and Spotify!</p><p>Soundcloud: <a target="_blank" href="https://bit.ly/2YnGjIq">https://bit.ly/2YnGjIq</a></p><p>Apple Podcasts: <a target="_blank" href="https://bit.ly/2WdrUvI">https://bit.ly/2WdrUvI</a></p><p>Spotify: <a target="_blank" href="https://bit.ly/2SqtadF">https://bit.ly/2SqtadF</a></p><p>We started Weights and Biases to build tools for Machine Learning practitioners because we care a lot about the impact that Machine Learning can have in the world and we love working in the trenches with the people building these models. One of the most fun things about these building tools has been the conversations with these ML practitioners and learning about the interesting things they’re working on. This process has been so fun that we wanted to open it up to the world in the form of our new podcast called Gradient Dissent. We hope you have as much fun listening to it as we had making it!</p><p>Weights and Biases:</p><p>We’re always free for academics and open source projects. Email carey@wandb.com with any questions or feature suggestions.</p><ul role="list"><li>Blog: <a target="_blank" href="https://www.wandb.com/articles">https://www.wandb.com/articles</a></li><li>Gallery: See what you can create with W&amp;B - <a target="_blank" href="https://app.wandb.ai/gallery">https://app.wandb.ai/gallery</a></li><li>Continue the conversation on our slack community - <a href="http://bit.ly/wandb-forum" target="_blank">http://bit.ly/wandb-forum</a><br></li></ul><p>Host: Lukas Biewald - <a href="https://twitter.com/l2k" target="_blank">https://twitter.com/l2k</a></p><p>Producer: Lavanya Shukla - <a href="https://twitter.com/lavanyaai" target="_blank">https://twitter.com/lavanyaai</a></p><p>TRANSCRIPT:</p><p><strong>Lukas: </strong>You're listening to Gradient Dissent, a show where we learn about making machine learning models work in the real world. I'm your host Lukas Biewald. Jeremy Howard created the Fast.ai course, which is maybe the most popular course to learn machine learning and there are a lot out there. He's also the author of the book Deep Learning for Coders with Fast.ai and PyTorch and in that process, he made the Fast.ai library which lots of people use independently to write deep learning. Before that, he was the CEO and co-founder of Enlitic, an exciting startup that applies deep learning to health care applications. And before that, he was the president of Kaggle, one of the most exciting earliest machine learning companies. I'm super excited to talk to him. So Jeremy, it's nice to talk to you. And in preparing the questions, I realized that every time I've talked to you there have been a few gems that I've remembered that I would never think to ask about. Like one time you told me about how you learned Chinese and another time you gave me Dad parenting advice, very specific advice and it's been actually super helpful. </p><p><strong>Jeremy: </strong>Oh great. Tell me what Dad parenting advice worked out?</p><p><strong>Lukas: </strong>Well, what you told me was when you change diapers, use a blow dryer to change a really frustrating experience to a really joyful experience and it's like such good advice. I don't know how you.. I guess I can imagine how you thought of it, but it's...</p><p><strong>Jeremy: </strong>Yeah, yeah, I know they love the whooshing sound, they love the warmth. I'm kind of obsessed about Dad things. So I'm always happy to talk about Dad things. That is this podcast.</p><p><strong>Lukas: </strong>Can we start with that? Now that my daughter is eight months old. Do you have any suggestions for her?</p><p><strong>Jeremy: </strong>Oh my goodness! Eight months old. You know, it's like the same with any kind of learning. It's all about consistency. So I think that the main thing we did right with Claire was just, you know, this delightful child now is we were just super consistent. Like if we said you can't have X unless you do Y, we would never give her X if she didn't do Y. If you want to take your scooter down to the bottom of the road, you have to carry it back up again. We read this great book that was saying if you're not consistent, it becomes like this thing, it's like a gambler. It's like sometimes you get the thing you want, so you just have to keep trying so that's my number one piece of advice. It's the same with teaching machine learning. We always tell people that tenacity is the most important thing for students. To stick with it, do it every day.</p><p><strong>Lukas: </strong>I guess just in the spirit of questions, I'm genuinely curious about, you know, you've built this amazing framework and teaching thing that I think is maybe the most popular and most appreciated framework. I was wondering if you could start by telling me the story of what inspired you to do that and what was the journey to making Fast.ai, the curriculum and Fast.ai, the ML framework.</p><p><strong>Jeremy: </strong>So it was something that my wife Rachel and I started together. Rachel has a math PhD, super technical background, early data scientist and engineer, Uber. I don't. I have just scraped by a philosophy undergrad and have no technical background. But from both of our different directions, we both had this frustration that neural networks in 2012 were super important, clearly going to change the world, but super inaccessible and so we would go to meetups and try to figure out like how do we... Like I knew the basic idea, I'd coded neural networks 20 years ago, but how do you make them really good? There wasn't any open source software at the time for running on GPUs. You know, Dan Seresen's thing was available, but you had to pay for it. There was no source code and we just thought, oh, we've got to change this, because the history of technology leaps has been that it generally increases inequality because the people with resources can access the new technology and then that leads to societal upheaval and a lot of unhappiness. So we thought, well, we should just do what we can. So we thought how are we going to fix this? Basically the goal was, and still is, to be able to use deep learning without requiring any code so that, you know, because the vast majority of the world can't code, we kind of thought, well, to get there, we should, first of all, see what exists right now? Learn how to use it as best as we can ourselves, teach people how to best use it as we can and then make it better, which requires doing research and then turning that into software and then changing the course to teach the hopefully slightly easier version and repeat that again and again for a few years. And so we're kind of in that process.</p><p><strong>Lukas: </strong>That's so interesting. Do you worry that the stuff you're teaching, you're sort of trying to make it obsolete, right? Because you're trying to build higher level abstractions? Like I think one of the things that people really appreciate your course is that it's really clear, in-depth explanations of how these things work. Do you think that that's eventually going to be not necessary or how do you think about that?</p><p><strong>Jeremy: </strong>Yeah, to some extent. I mean, so if you look at the new book and the new course, chapter one starts with really, really foundational stuff around what is a machine learning algorithm? What do we mean to learn an algorithm? What's the difference between traditional programming and machine learning to solve the same problem? And those kinds of basic foundations I think will always be useful, even at the point you're not using any code. I feel like even right now, if somebody is using like PlatformAI or some kind of code-free framework, you still need to understand these basics of an algorithm can only learn based on the data you provide. It's generally not going to be able to extrapolate to patterns it's not seen yet, stuff like that. Um, but yeah, I mean, we have so far released two new courses every year, you know, a part one and part two every year because every year, it's totally out of date. And we always say to our students at the start of part one, Look, you know, none of the details you're learning are going to be of any use in a year or two's time. There's a time when we're doing Piano and then TensorFlow and Keras, and then playing PyTorch. We always say, look, don't worry too much about the software we're using because none of it's still any good, you know, it's goal changing rapidly, you know, faster than JavaScript frameworks, but the concepts are important and yeah, you can pick up a new library and I don't know by weekend, I …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.wandb.com/podcast/jeremy-howard">https://www.wandb.com/podcast/jeremy-howard</a></em></p>]]>
            </description>
            <link>https://www.wandb.com/podcast/jeremy-howard</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404002</guid>
            <pubDate>Tue, 08 Sep 2020 00:10:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Manage Your Team's Bugs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24403674">thread link</a>) | @cauliflower99
<br/>
September 7, 2020 | http://www.dcaulfield.com/a-framework-for-managing-bugs/ | <a href="https://web.archive.org/web/*/http://www.dcaulfield.com/a-framework-for-managing-bugs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-15723">
<small>
    <a href="http://www.dcaulfield.com/2020/09/07/">September 7, 2020</a></small>
    			<small>
				<a href="http://www.dcaulfield.com/author/admin/"></a></small>
		
<h2>The Problem</h2>



<p>If you lead a software team, then a significant part of your tasks will involve some sort of bug fixing or support for other teams. In particular, if your team works on a product used by a lot of customers, you can expect to sped 10% or more of your team’s time fixing bugs from your customers.</p>



<p>When it comes to bug fixing, your customers expect a high standard from your team, so you should expect the same from them. As part of your team lead duties, you need to look for opportunities to reduce the team’s work as much as possible. In my case, I discovered that the team spent longer trying to understand a bug’s description than actually fixing it.</p>



<p>A poorly written bug means your team is getting distracted trying to figure out what the bug means instead of fixing it. Distraction leads to context switching leads to frustration leads to slower completion of work. And there are few things more distracting than a badly written bug.</p>



<p>Rather than trying to fix the bug, a lot of time is wasted trying to understand the bug’s context and the steps leading up to the incident. In the end, your team practically writes the bad bug themselves!</p>



<p>This was the case for the product I worked on a few years ago. Although the product was relatively mature, there was very little structure around the processes used to make the product better.</p>



<p>A quick search through the bugs history showed poorly written one-liner bugs marked as closed with no explanation or code fix attached. Clearly, the developers were conversing directly with the stakeholders via email and not attaching the information afterwards.</p>



<p>When my team joined the product, the most frustrating part of our days was solving bug tickets which had no useful information attached. Furthermore, we had no method of prioritising our bugs against our current list of tasks – the loudest person won the priority. </p>



<p>After 2 months of this and identifying it as a major pain point in our retros, we decided to fix our bug process.</p>



<h2>The Bug Template</h2>



<p>Our bug template was revolutionary to our workflow. First of all, by filling in a template, the bug author was required to think about their problem.</p>



<p>What did I do leading up to this? <br>How could this have happened?</p>



<p>Occasionally, the bug author even figured out the solution by themselves while filling in the template.</p>



<p>Secondly, the bug ticket required some effort to create. A good rule we discovered was if you make it easy for someone to do something, they will do it. In this case, if you make it easy to create bad bugs, then bad bugs will get created.</p>



<p>By putting a list of questions to answer in the template, the author is less inclined to raise trivial questions since it would be quicker to figure it out themselves. Most importantly, you won’t be left with some ‘critical’ bugs that just have a one-liner description.</p>



<pre><strong>Bug Logging Template</strong>
&nbsp;
<strong>1&nbsp; OVERVIEW</strong>
------------------------------------------------------------
1.1. Technical problem description
------------------------------------------------------------
Give an overview of your problem.

&nbsp;
------------------------------------------------------------
1.2. Product impact
------------------------------------------------------------
What part of the product/project/system is this impacting?

&nbsp;
&nbsp;
------------------------------------------------------------
1.3. Conditions
------------------------------------------------------------
Are there any unique parameters or conditions you think are relevant? 

&nbsp;
<strong>2&nbsp; &nbsp;AFTER ANALYSIS</strong>
------------------------------------------------------------
2.1. Software version
------------------------------------------------------------
&nbsp; What version of software did you find this in?
&nbsp;
------------------------------------------------------------
2.2. Steps to Reproduce Fault (<strong>Mandatory</strong>)
------------------------------------------------------------
Please give exact steps on house we can reproduce this issue.
Give specific commands if necessary.
Attach screenshots if necessary.
&nbsp;
&nbsp;
------------------------------------------------------------
2.3. Logs
------------------------------------------------------------
Attach relevant log files

&nbsp;
------------------------------------------------------------
2.4. Frequency of fault
------------------------------------------------------------
When / how often does this occur?

&nbsp;
------------------------------------------------------------
2.5. Expected result
------------------------------------------------------------
What do you expect should happen?

------------------------------------------------------------
2.6. Actual result
------------------------------------------------------------
What actually happened instead?
<strong>

</strong>
<strong>3&nbsp; &nbsp;REACTION</strong>
------------------------------------------------------------
3.1. System restore
------------------------------------------------------------
Did you take any steps to restore the system?

&nbsp;
&nbsp;
------------------------------------------------------------
3.2. Temporary fix / Workaround
------------------------------------------------------------
Did you find a solution or workaround?</pre>



<p>Whenever you see a badly written bug, attach the following to the comments section:</p>



<p>“Hi Sam, We need more information to begin working on this quickly. Please fill out this template with relevant details.” Then paste in the above template.</p>



<h2>Prioritise Your Bugs</h2>



<p>As the team lead, each day you should work with your team to identify the highest priority work. If critical bugs are coming in, you may need to down-prioritise other tasks.</p>



<p>I have a general rule I use to decide what to prioritise: </p>



<p>“If it hurts, put it first.” </p>



<p>If the ticket is a big customer or is likely to cause your team embarrassment, then get it closed out asap. It is important to keep the pressure off your team as much as possible, so getting painful bugs closed quickly can give them the head space they need.</p>



<p>Furthermore, there is little point in having your team work on edge case bugs that were accidentally found in-house when there are customers shouting for a fix on another bug.</p>



<h2>Argue Against the Bug</h2>



<p>Before you assign any bug to your team, make sure it is something suitable for your team to work on. Don’t confuse a ‘loud’ bug with a high priority bug. Very often, there are stakeholders that create tickets and need them worked on immediately. Always question the validity of their priority.</p>



<p>Firstly, you don’t want to be the ‘pushover team’ that will hop on tickets when someone shouts loud enough. It is very beneficial to your team if you can disagree against tickets with the hope of either delaying their priority (especially if your have a large backlog) or get it moved to a more relevant team.</p>



<p>To argue against the bug, ask a few simple questions:</p>



<ul><li>Is this bug for your team?</li><li>Is there enough info for someone to begin working on it?</li><li>What level of expertise is required here (senior / junior)?</li></ul>



<p>By asking some basic questions, your team gets more context to the ticket and can empathise with the ticket author. If the ticket does not already have your template, make sure you attach it and ask the author to fill it out.</p>



<h2>Emails are not Bugs!</h2>



<p>As the team lead, I am often pulled into an email chain with stakeholders such as QA or customer support teams with questions such as:</p>



<ul><li>“David – Can you get someone to have a look at these logs?”</li><li>“David – Can we secure someone from your team to look at this?”</li><li>“David – It is critical that we fix this bug by Monday. Who is available to work over the weekend?”</li></ul>



<p>Do not take requests like this. My response is always the same:</p>



<ul><li>“I’m sure we can help. Please raise a ticket with all relevant details so that we can track this.”</li></ul>



<p>Without a ticket, your team don’t know where to attach their information or ask more questions. Moreover, if you revisit the bug in the future, without a ticket there is nothing for you to reference.</p>
							</article></div>]]>
            </description>
            <link>http://www.dcaulfield.com/a-framework-for-managing-bugs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24403674</guid>
            <pubDate>Mon, 07 Sep 2020 23:04:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Walmart Sponsored Products Ads Guide]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24403206">thread link</a>) | @WalterJT
<br/>
September 7, 2020 | https://jungletopp.com/walmart-sponsored-products/ | <a href="https://web.archive.org/web/*/https://jungletopp.com/walmart-sponsored-products/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="310ca8db" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>What are Walmart Sponsored Products and where do they come into play? Walmart allows advertisers to easily advertise on their platforms with this feature being a really lucrative option for them. We’ll discuss what it entails, how they work and the different ad formats that can be selected for the different types of campaigns you’re choosing to run.&nbsp;</p>



<p>Let’s begin!&nbsp;</p>



<h2><strong>What are Walmart Sponsored Products?&nbsp;</strong></h2>



<p>Walmart Sponsored Products are also called Performance Ads, and they are also known as <a href="https://jungletopp.com/walmart-ad-costs/">cost-per-click ads</a> that can appear on the Walmart Marketplace. They are able to appear within search results, category pages, and product pages on Walmart’s app, mobile site, and desktop site.&nbsp;&nbsp;&nbsp;</p>



<p>When utilizing these types of ads, they are able to increase your visibility by allowing you to reach and engage shoppers at all stages of their shopping journey. The ads appear on the first page of search results too.&nbsp;</p>



<p>If anything, you’re not only advertising your products, but you’re also helping consumers find and purchase products in a much easier and convenient manner. Plus, the advertiser will only have to pay when the shopper clicks on the ad. It’s quite the win-win situation!&nbsp;&nbsp;</p>



<h2><strong>How Do <strong>Walmart Sponsored Products</strong> Work?&nbsp;</strong></h2>



<p>So, how are these sponsored products selected for exposure to your customers? They are actually based on a combination of relevancy and bid. They also rely on the following two factors.&nbsp;</p>



<ul><li>Products being advertised must win the buy box&nbsp;</li><li>Products being advertised must be in stock&nbsp;</li></ul>



<p>These cool ads are designed to help you do the following too.&nbsp;</p>



<ul><li>Boost product sales&nbsp;</li><li>Increase share of wallet&nbsp;</li><li>Uncover new customers&nbsp;</li><li>Grow or protect market share&nbsp;</li><li>Maximize profitable SKUs&nbsp;</li><li>Improve brand and product visibility&nbsp;</li><li>Launch new products or brand extensions&nbsp;</li><li>Present your products to a massive audience already ready to purchase&nbsp;</li></ul>



<p>Which benefit are you to achieve in your <a href="https://jungletopp.com/walmart-search-advertising/">advertising campaign</a>? We’d love to know your thoughts and your mission to execute your own products to potential customers.&nbsp;</p>



<h2><strong>Types of Walmart Sponsored Products</strong></h2>



<p>With all of the great <a href="https://jungletopp.com/walmart-stats/" target="_blank" rel="noreferrer noopener">capabilities</a> this type of advertising has to offer, there are also different formats in the way they can be executed. This is perfect for those who are interested in various campaign ideas and need a mix of how to present their product launches.&nbsp;</p>



<p>These are all of the following ways Walmart Sponsored Products may be used on the online platform.&nbsp;</p>



<p><strong><em>Search In-Grid: </em>&nbsp;</strong>Did you know that one in four online Walmart purchases begin with a search? This type of ad allows for your product to get the premium placement on the first page of search results.&nbsp;</p>



<p><strong><em>Brand Amplifier: </em></strong>This type of ad really helps to provide brand recognition and showcase your product portfolio. The logo, custom headline and up to three of the SKUs appear at the top of relevant search results.&nbsp;</p>



<p><strong><em>Product Carousel: </em></strong>&nbsp;The product appears on search, category and item pages as relevant alternate purchase options. This is an ad that appears as more of a disguise and it gives the customer options.&nbsp;</p>



<p><strong><em>Buy Box: </em></strong>&nbsp;This ad will have your products appear at the most relevant alternate purchase option on product detail pages.&nbsp;</p>



<h2><strong>Two Different Campaign Types</strong></h2>



<p>When looking at how to set up the overall campaigns, there are two different methods that Walmart offers to advertisers. Look at the following to see what will work best for your current needs in product/brand awareness. <strong>&nbsp;</strong></p>



<p><strong><em>Automatic: </em></strong>This is a method in the way a campaign runs where the advertiser doesn’t have to monitor as heavily as if it were manual. It’s set to serve all customers searching for products like yours.&nbsp;</p>



<p>This specific type of campaign is perfect for brands that are new to the advertising field. They hope to widen their existing customer base or are launching a product.&nbsp;</p>



<p>These are a few of its features that advertisers look for when running their campaign.&nbsp;</p>



<ul><li>Easy setup&nbsp;</li><li>No keyword management&nbsp;</li><li>High impression volume&nbsp;</li></ul>



<p><strong><em>Manual: </em></strong>On the other hand, manual advertising is set to serve to customers based on their select keyword choice.&nbsp;</p>



<p>This is an ideal situation for brands who have products with a long history on Walmart or brands that already know the successful keywords in their customer use.&nbsp;&nbsp;</p>



<p>These are a few of its features that advertisers look for when running their campaign.</p>



<ul><li>Access to Walmart’s Keyword Analytics tool</li><li>Select your own keywords&nbsp;</li><li>Full campaign control&nbsp;&nbsp;</li></ul>



<h2><strong>Final Thoughts</strong></h2>



<p>Do you think that Walmart Sponsored Products are right for you?&nbsp;Contact a <a href="https://jungletopp.com/walmart-ads-agency/">Walmart ads agency</a> to talk about launching your ad campaigns.</p>



<p>We find that with the combination of different ways to execute the ads as well as having Walmart being a powerhouse for a variety of products, it’s always going to be desirable to a large number of consumers.&nbsp;</p>



<p>Plus, with the different bidding keywords and use of CPC, advertisers will have much more financial freedom. They’ll also be able to measure their results.&nbsp;</p>



<p>Let us know your final thoughts to this method of advertising and if you have or are considering this method for your own campaign.</p>
<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->		</div>
				</div></div>]]>
            </description>
            <link>https://jungletopp.com/walmart-sponsored-products/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24403206</guid>
            <pubDate>Mon, 07 Sep 2020 21:46:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If you can’t code, what do you do?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24403144">thread link</a>) | @ZnZirconium
<br/>
September 7, 2020 | https://www.cambridgembastories.com/2018/01/25/sudo-hackathon-if-you-cant-code-what-do-you-do/ | <a href="https://web.archive.org/web/*/https://www.cambridgembastories.com/2018/01/25/sudo-hackathon-if-you-cant-code-what-do-you-do/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2024" itemscope="itemscope" itemtype="http://schema.org/Article">

	<!-- .row .post-meta .align-items-top -->
    <div itemprop="description">

		<p><a href="https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?ssl=1"><img data-attachment-id="2026" data-permalink="https://www.cambridgembastories.com/2018/01/25/sudo-hackathon-if-you-cant-code-what-do-you-do/sudo-hackathon/" data-orig-file="https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?fit=660%2C330&amp;ssl=1" data-orig-size="660,330" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Sudo Hackathon" data-image-description="" data-medium-file="https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?fit=300%2C150&amp;ssl=1" data-large-file="https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?fit=610%2C305&amp;ssl=1" loading="lazy" src="https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?resize=610%2C305&amp;ssl=1" alt="Sudo Hackathon" width="610" height="305" srcset="https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?w=660&amp;ssl=1 660w, https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?resize=300%2C150&amp;ssl=1 300w" sizes="(max-width: 610px) 100vw, 610px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?w=660&amp;ssl=1 660w, https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?resize=300%2C150&amp;ssl=1 300w" data-lazy-src="https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?resize=610%2C305&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>
<p>“If you can’t code, what do you do?” I often get this question when I say I went to a hackathon. The simple answer is twofold: partner with developers to make sure you’re getting the right stuff done; and surround great code with a concise and compelling business story. There are other ways to go about it, but in general you have to be enormously flexible and wear many hats with various levels of comfort.</p>
<p>At the Sudo Hackathon, I had the pleasure of working with a genuinely incredible team. The prompt was: “How can virtual reality be utilised in health and infrastructure?” Our team worked on a healthcare tool for macular dystrophy&nbsp;<strong>–</strong> the number one cause of vision loss in people over 50.</p>
<p>Over the weekend, our team created four key deliverables:</p>
<ul>
<li>A retinal-mapping game using Google Cardboard</li>
<li>An algorithm to quickly and precisely define patient blind spot borders</li>
<li>A real-Time video morphing visualization</li>
<li>A 5-minute pitch presentation including business case</li>
</ul>
<p>We were able to track down an eye surgeon and prepare patient-focused and physician-focused questions. The information informed our MVP (minimum viable product), then we just needed the facts to back up our story. For example, sight loss is a 28 billion GBP market in the UK alone. The NHS also had an upcoming grant our product would be eligible for, an incredibly desirable path for extending our runway without diluting our equity.</p>
<p>Up until the last minute we were building, refining, adding, and editing. Our team had that contagious feeling of great code being stitched together. To quote one of my teammates: “This code is magic.” With only one previous run-through, we went in front of the judges, and we WON!</p>
<p>It was a great feeling for everyone on the team to leave the hackathon in equal parts excited and exhausted. Lots of gratitude to Allia for hosting this Serious Impact Challenge Weekend in partnership with the European Union’s European Regional Development Fund. It was an amazing event, and I highly encourage people to check out their <a href="https://www.sudochallenge.com/">next event</a> in Agritech this April.</p>


    </div><!-- .post-content -->

	
        <!-- .row .post-meta .post-meta-footer .align-items-top -->

	
</article></div>]]>
            </description>
            <link>https://www.cambridgembastories.com/2018/01/25/sudo-hackathon-if-you-cant-code-what-do-you-do/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24403144</guid>
            <pubDate>Mon, 07 Sep 2020 21:38:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stellar Cartography With Self Organizing Maps]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24403011">thread link</a>) | @bruhfeefee
<br/>
September 7, 2020 | https://ken-myers.github.io/2020/09/01/stellar-cartography-with-self-organizing-maps | <a href="https://web.archive.org/web/*/https://ken-myers.github.io/2020/09/01/stellar-cartography-with-self-organizing-maps">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    	<h4>
	September 1st, 2020
</h4>



<h5><i>A bored high-schooler's foray into astronomy, because what else was I supposed to do during lockdown?</i></h5>


<div>
	<figure>
		
		
		
		
		
			<img src="https://ken-myers.github.io/assets/images/starmapPretty.png">
		
		
			<figcaption>Distance optimized map of the 10 closest stars to Earth, Sol included. This one has an average error of around 8.9% </figcaption>
		
	</figure>
</div>

<p>There was something of a family debate over whether a reduced-dimensionality starmap could still be accurate enough as to be useful, so I made a covid-quarantine experiment of it.</p>

<h2 id="process">Process</h2>
<p>The idea is pretty simple: create a 2D starmap in which the distances between each star are as accurate as possible.</p>

<div>
	<figure>
		
		
		
		
		
			<img src="https://ken-myers.github.io/assets/images/starGenDemo.gif">
		
		
			<figcaption>Generation of a map of our 30 nearest stars.</figcaption>
		
	</figure>
</div>

<p>I tried to implement something like a <a href="https://en.wikipedia.org/wiki/Self-organizing_map">Kohonen map</a>. I’m not sure if it actually falls under that name, but it does follow the same principles of iteratively changing the position of each node towards a more ideal state, which in this case would be one in which the distances between each pair on the board are most accurate. Here’s my algorithm:</p>

<ul>
  <li>Randomly initialize each item’s position.</li>
  <li>Repeat the following n times or until convergence:
    <ul>
      <li>For each item in the dataset:
        <ol>
          <li>Calculate and store the average pairwise error (discrepancy between true distance and distance on the map) between the given item and all other items.</li>
          <li>Shift the item’s position by a certain increment in both directions on each axis, calculating and storing the item’s average error for each possible move.</li>
          <li>Commit the move which yields the lowest error, and move onto the next item.</li>
        </ol>
      </li>
      <li>If the average error of the whole map has not changed since last iteration, either
        <ul>
          <li>Decrease the increment size if the results will still be significant, or otherwise</li>
          <li>Stop. The map’s error has converged.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>A few nuances have been glossed over in this overview. You can view the full code on <a href="https://github.com/ken-myers/stargen">my Github</a>.</p>

<h2 id="results">Results</h2>

<p>One of the principal arguments against the usability of these maps was that “it’s like putting cities in a line.” I made sure to generalize my code for data of any dimension and fed it the largest 20 cities in Texas. If you’re from around here, I think you’d agree with me that this map looks like it’d be helpful to any one-dimensional creatures attempting to traverse the state.</p>

<div>
	<figure>
		
		
		
		
		<p><img src="https://ken-myers.github.io/assets/images/linearCities.png">
		</p>
		
			<figcaption>The 20 largest cities in Texas plotted linearly, optimized for distance. (The Metroplex is a bit clustered, as expected.)</figcaption>
		
	</figure>
</div>

<p>Here are a few more of the starmaps I’ve generated, without any post-processing. (You can click on any of these to view them in more detail.)</p>


<p>As for the error indication, the blue lines represent specific distances that are over a user-inputted threshold (in this case, 85%), the red text simply lists the average error of all distances involving the given star, and the red halos are proportional to said error. All of this is toggle-able.</p>

<p>Something to note is that these maps are quite sensitive to initial conditions, so you may have to re-roll a few times until you get a map you’re happy with. In my experience, the average map error for a given dataset could fall anywhere between 10-30%, but I’m sure this number changes when you’re working with something other than stars or cities.</p>

<h2 id="beyond-starmaps">Beyond Starmaps</h2>

<p>Even though the code is capable, there’s not much use in stepping down higher-dimensional data to one, two, or three dimensions because, since it is primarily intended to be used as a cartography tool, my program does not normalize the data you feed it, and uniform higher dimensional coordinates are hard to come by. (If you were, say, a novelist trying to world-build a universe in which there were seven spatial dimensions, then yes, it could be useful.)</p>

<p>I intend to continue working on this project. Besides the obvious refactoring, bug-squashing, and polishing, I’d also like to add support for wrap-around/toroidal space and perhaps globular, a GUI that shows live generation (like the GIF you saw earlier), and the ability to import CSV files.</p>


<div id="imageModal" tabindex="-1" role="dialog">
  <div>
    <div>
        <p><img id="modalImg" src="">
        </p>
    </div>
  </div>
</div>
	  </div></div>]]>
            </description>
            <link>https://ken-myers.github.io/2020/09/01/stellar-cartography-with-self-organizing-maps</link>
            <guid isPermaLink="false">hacker-news-small-sites-24403011</guid>
            <pubDate>Mon, 07 Sep 2020 21:20:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Amiga and CD-ROMs]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24402543">thread link</a>) | @erickhill
<br/>
September 7, 2020 | https://www.amigalove.com/viewtopic.php?f=6&t=1569 | <a href="https://web.archive.org/web/*/https://www.amigalove.com/viewtopic.php?f=6&t=1569">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.amigalove.com/viewtopic.php?f=6&amp;t=1569</link>
            <guid isPermaLink="false">hacker-news-small-sites-24402543</guid>
            <pubDate>Mon, 07 Sep 2020 20:30:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimize Onboarding]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24402419">thread link</a>) | @tekdude
<br/>
September 7, 2020 | https://staysaasy.com/management/2020/08/28/Optimize-Onboarding.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/08/28/Optimize-Onboarding.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>It takes roughly 2 weeks to form a habit; it takes roughly two weeks to get comfortable in a new environment. A common mistake is to treat a new report’s first couple weeks like college orientation - social, light hearted, get-to-know-you stuff. If your report spends the first two weeks reading C# documentation and having lunch out on the town with the team, guess what, they’ve just normalized that behavior as what the role is.</p>

<p>The answer: start your report doing real work as soon as possible. If they’re a software engineer, they should be committing code week one (ideally day 2 or 3); If they’re a product manager, they should be attending meetings and picking up supporting activities on a similar time frame. Then the tone has been set - working here means getting things done.</p>

<p>This means as manager you need to give your report tractable work in the first week. Managers not being ready for a report to start is the number one reason people end up normalizing underperformance, because they had nothing meaningful to do. If a manager describes a report as not having initiative in the first couple weeks it’s a red flag - it’s the manager’s job to provide new hires with clear paths to contribute immediately.</p>

<p>Another main reason people fall into onboarding traps is because your organization has painfully slow onboarding. Endless HR videos, slow security processes, a mountain of fragile technology setup - these all make for a shitty and counterproductive start at a company. Optimize your onboarding to get people doing what you hired them to do. Look to formalize performance indicators of your onboarding. For example, for engineers this could be time-to-first-commit and time-to-joining-sprints.</p>

<p>This approach holds for managers and executives as well. In that cohort it’s also common and a common red flag for people to spend the first couple weeks putzing around under the guise of “getting to know what’s going on”. Managers and executives should be involved in the decisions of the team from day 1 and developing artifacts - plans, TODO lists, strategy documents - in the first couple weeks. With good managers and executives you see them day 1 adding perspective and insight into conversations, and everyone collectively appreciates that the right person has been hired.</p>

<p>Onboarding is one of the most critical periods in a person’s time at a company. It’s one of the highest ROI periods when managing someone. Take that opportunity to set expectations properly and measure success quantiatively.</p>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/08/28/Optimize-Onboarding.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24402419</guid>
            <pubDate>Mon, 07 Sep 2020 20:18:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Embedded Linux Security]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24402322">thread link</a>) | @simonpure
<br/>
September 7, 2020 | https://embeddedbits.org/introduction-embedded-linux-security-part-1/ | <a href="https://web.archive.org/web/*/https://embeddedbits.org/introduction-embedded-linux-security-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        <p>This article is going to be an introduction to <strong>embedded Linux security</strong>.</p>
<p>Since this topic is quite extensive, I divided into two parts. In this first part, we will have a small introduction to security concepts and threat modeling and then focus on some mitigation techniques to improve the security of an embedded Linux device, including secure boot, code/data encryption and secure key storage.</p>
<p>If you prefer a one hour talk instead of reading this article, you can also watch the webinar <a href="https://www.youtube.com/watch?v=QcUKAgVKSxQ">“Introduction to embedded Linux security”</a> I recorded for <a href="https://www.toradex.com/">Toradex</a>. I also gave the same talk at Embedded Linux Conference North America 2020, but as I write this article it was not yet published on YouTube.</p>
<p>Let’s first start with some concepts…</p>
<h2 id="security-concepts">Security concepts</h2>
<p>Security is all about risk mitigation.</p>
<p>On the one hand, we have <strong>owners</strong>, those who benefit from a product or service (user, manufacturer, business owner, etc). And owners want to protect <strong>assets</strong>, anything that has some value in the product or service (data, code, reputation, etc).</p>
<p>On the other hand, we have <strong>threat actors</strong>, a person or thing (malicious hacker, government, etc) that can manifest a <strong>threat</strong>, anything that is capable of acting against an asset in a manner that can result in harm.</p>
<p>To manifest a threat, the threat actor will explore <strong>vulnerabilities</strong> (weakness in the system) via an <strong>attack vector</strong>, a method or pathway used by the threat actor to access or penetrate the target system.</p>
<p>The diagram below express very well all those concepts:</p>
<p><a href="https://www.enisa.europa.eu/publications/hardware-threat-landscape/at_download/fullReport"><img src="https://embeddedbits.org/images/20200906-security-concepts.png" alt="Security Concepts"></a></p>
<p>In the end, is a cat-and-mouse game between owners and threat actors. How far will the owner go to protect the assets? How far will the threat actor go to compromise the assets? It really depends on the value of the assets. Indeed, the perception of value may not be the same for owners and threat actors.</p>
<p>Identifying assets (and their value) to mitigate the risks of being compromised can be done in a process called <strong>threat modeling</strong>.</p>
<h2 id="threat-modeling">Threat modeling</h2>
<p>Threat modeling is a process where potential threats can be identified, enumerated, and mitigations can be prioritized. It is basically a risk assessment process where you evaluate the value of your assets and the cost to protect them. The result of a threat modeling is the <strong>threat model</strong> of your product.</p>
<p><img src="https://embeddedbits.org/images/20200906-threat-modeling.png" alt="Threat modeling"></p>
<p>There are several techniques and methodologies that can help during threat modeling, including STRIDE, DREAD, VAST, OCTAVE, and many others.</p>
<p>To have a very basic introduction to the topic, let’s talk about STRIDE and DREAD.</p>
<p>The <a href="https://en.wikipedia.org/wiki/STRIDE_(security)">STRIDE model</a> is a very useful tool to help classify threats. It was developed by Microsoft and the name is an acronym for the six main types of threats: <strong>S</strong>poofing, <strong>T</strong>ampering, <strong>R</strong>epudiation, <strong>I</strong>nformation disclosure, <strong>D</strong>enial of service and <strong>E</strong>scalation of privileges. STRIDE can be used to identify all threats the assets of a system could be exposed to.</p>
<p><a href="https://allabouttesting.org/stride-acronym-of-threat-modeling-system/"><img src="https://embeddedbits.org/images/20200906-stride.png" alt="STRIDE"></a></p>
<p>The <a href="https://en.wikipedia.org/wiki/DREAD_(risk_assessment_model)">DREAD methodology</a> is a tool for risk-assessing computer security threats. The name is an acronym for five categories of security threats: <strong>D</strong>amage (how bad would an attack be), <strong>R</strong>eproducibility (how easy is it to reproduce the attack), <strong>E</strong>xploitability (how much work is it to launch the attack), <strong>A</strong>ffected users (how many people would be impacted) and <strong>D</strong>iscoverability (how easy is it to discover the threat).</p>
<p><a href="https://www.slideshare.net/SecurityInnovation/threat-modeling-to-reduce-software-security-risk"><img src="https://embeddedbits.org/images/20200906-dread.png" alt="DREAD"></a></p>
<p>While the STRIDE model helps to identify the threats, the DREAD methodology helps to rank them. For each threat in the system, you would go over each threat category and classify it in low (1 point), medium (2 points), or high (3 points). In the end, you would have a ranked list of threats and mitigation strategies. Example:</p>
<p><img src="https://embeddedbits.org/images/20200906-threat-modeling-example.png" alt="Threat modeling example"></p>
<p>We can see that threat modeling will provide a very clear view of what we want to protect, how we plan to protect it, and associated costs. This is part of the <strong>threat model</strong> of the product, which needs to be re-evaluated for every development cycle. As a result, the threat model will provide a prioritized list of threats to work on, so we can focus on implementing the mitigations to improve the security of the product.</p>
<p>How to protect the integrity and authenticity of your code? How to ensure the privacy of the data? Where to store cryptographic keys? How to minimize the risks of an application to be exploited? Let’s try to answer all of those questions and many more, starting with secure boot!</p>
<h2 id="secure-boot">Secure Boot</h2>
<p>How to make sure the code you are running was built by a trustworthy person or company? Implementing a <strong>secure boot</strong> process.</p>
<p>The objective of a secure boot process is to protect the integrity and authenticity of the code.</p>
<p>Secure boot is usually based on the verification of digital signatures. An embedded Linux system normally has three major components: bootloader, kernel and root filesystem (rootfs). All these components are signed and the signatures are checked during boot.</p>
<p>For example, some hardware mechanism can be used to check the signature of the bootloader, that will check the signature of the kernel, that will use a ramdisk image to check the signature of the root filesystem. Since we have one component checking the signature of the next one in the boot chain, this process is often called a <strong>chain-of-trust</strong>.</p>
<p><img src="https://embeddedbits.org/images/20200906-secure-boot-1.png" alt="Secure boot"></p>
<p>Let’s take a look at a real example on an <a href="https://www.nxp.com/imx6">NXP iMX6</a> device.</p>
<p>Everything starts in the ROM code inside the SoC. On NXP iMX6, there is a hardware component called High Assurance Boot (HAB) that it is able to validate the signature of the first stage bootloader, making it possible to implement a secure boot process. The High Assurance Boot inside iMX6 devices can also be called the <strong>Root of Trust</strong>, since if it is compromised, all the secure boot process is also compromised.</p>
<p>The ROM code inside the iMX6 SoC, using the HAB component, will check the signature of the bootloader. For that, it is necessary to generate a pair of keys (public and private), sign the bootloader with the private key and store the public key inside the SoC. On iMX6, OTP fuses are used to store the keys. Actually, to make it less expensive, only the hash of the public key is stored in the SoC.</p>
<p>When the bootloader boots (e.g. <a href="https://www.denx.de/wiki/U-Boot">U-Boot</a>), it will have to check the signature of the Linux kernel. For that, it is common to use an image format called <strong>FIT image</strong>. The FIT image is a container for multiple binaries with hashing and signature support, and usually contains the Linux kernel image, device tree files and an initial ramdisk. After generating a pair of keys, we need to sign the binaries inside the FIT image with the private key e configure U-Boot to use the public key to check the signature of the FIT image.</p>
<p>After the kernel boots, it will run the <em>init</em> program from the ramdisk image. The ramdisk will have the logic to verify the integrity of the final root filesystem before mounting it. There are some options to implement this. One common option is using the device-mapper verity (<a href="https://www.kernel.org/doc/html/latest/admin-guide/device-mapper/verity.html">dm-verity</a>) kernel module. The <strong>dm-verity</strong> kernel module provides integrity checking of block devices and requires a read-only rootfs (squashfs can be a good solution). Other approaches would be <a href="https://wiki.gentoo.org/wiki/Integrity_Measurement_Architecture">IMA</a> or <a href="https://www.kernel.org/doc/html/latest/admin-guide/device-mapper/dm-integrity.html">dm-integrity</a> if you want a read-write root filesystem.</p>
<p>Here is a diagram of the complete secure boot process:</p>
<p><img src="https://embeddedbits.org/images/20200906-secure-boot-2.png" alt="Secure boot on NXP iMX6"></p>
<p>This is only one example of a secure boot implementation, although it could be applied to a different set of boards and ARM SoCs.</p>
<p>Yet nothing is 100% secure!</p>
<p>Secure boot vulnerabilities in the ROM code of several NXP devices (i.MX6, i.MX50, i.MX53, i.MX7, i.MX28 and Vybrid families) were <a href="https://blog.quarkslab.com/vulnerabilities-in-high-assurance-boot-of-nxp-imx-microprocessors.html">publicly disclosed</a> on July 17th, 2017. And if your chain of trust is compromised, everything is compromised! So we need to be aware of these types of vulnerabilities (in this case, they were fixed with new silicon).</p>
<p>While secure boot ensures authenticity and integrity, it does not protect the device from being counterfeited or threat actors from extracting code/data from the device. So if you want to protect your intellectual property or ensure data confidentiality, you will need to use encryption.</p>
<h2 id="code-and-data-encryption">Code and data encryption</h2>
<p>You may want to encrypt data or code in an embedded Linux device.</p>
<p>Data encryption is a common approach when you need to protect the privacy and confidentiality of the users. Data is any information generated during the executing of the device, including databases, configuration files, and so on.</p>
<p>Code encryption depends on the situation, and encrypting the full root filesystem is not that common. Usually, most of the components are free and open source software, so there is nothing to hide. There is also the issue of GPLv3 and Tivoization (using any GPLv3 software will force you to provide a mechanism for the user to update the software, and that would make it more difficult if you are encrypting it). A more common use case is to encrypt only the applications you developed for the device. It’s usually where your intellectual property is.</p>
<p>There are basically two main approaches to encryption in Linux: <strong>full disk encryption</strong> and <strong>file-based encryption</strong>.</p>
<p>Full disk encryption provides encryption at the block level and the whole disk or a disk partition is encrypted. For that, we can use <a href="https://en.wikipedia.org/wiki/Dm-crypt">dm-crypt</a>, the Linux kernel’s device mapper crypto target.</p>
<p>File-based encryption provides encryption at the file system level, where each directory may be separately and optionally encrypted with a different key. The two most common implementations of file-based encryption are <a href="https://wiki.archlinux.org/index.php/Fscrypt">fscrypt</a> and <a href="https://wiki.archlinux.org/index.php/ECryptfs">eCryptFS</a>. fscrypt is an API available on some filesystems like EXT4, UBIFS and F2FS, and eCryptFS is a more generic solution implemented as a layer that stacks on top of an existing filesystem.</p>
<p>But what about the keys used for encryption?</p>
<h2 id="encryption-keys">Encryption keys</h2>
<p>Since an asymmetric key algorithm is too slow to be used in encryption, usually a symmetric-key algorithm is used in encryption. That means the same key is used for encryption and decryption, and the key should be available somewhere in the filesystem so the encrypted code/data can be decrypted.</p>
<p>But we can’t just leave the key lying around in the filesystem, right?</p>
<p>There are several cases where companies …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://embeddedbits.org/introduction-embedded-linux-security-part-1/">https://embeddedbits.org/introduction-embedded-linux-security-part-1/</a></em></p>]]>
            </description>
            <link>https://embeddedbits.org/introduction-embedded-linux-security-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24402322</guid>
            <pubDate>Mon, 07 Sep 2020 20:07:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[iPhones Pixels and lazy Android developers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24402295">thread link</a>) | @sorcercode
<br/>
September 7, 2020 | https://blog.jkl.gg/iphones-pixels-lazy-android-developers/ | <a href="https://web.archive.org/web/*/https://blog.jkl.gg/iphones-pixels-lazy-android-developers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    

<p>So Ben Thompson<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> recently
<a href="https://twitter.com/benthompson/status/1302185265524617217">tweeted</a>:</p>

<blockquote>
  <p>I’ve been using Android for the last couple of weeks, and honestly, the core OS is pretty good!</p>

  <p>The big problem is that Android apps are garbage relative to iOS apps.
If developers actually care about pushing back against Apple they should give a damn. They don’t.</p>
</blockquote>

<p>He then went on to attribute the garbage quality of Android apps to developer
laziness. This <em>understandably</em>
<a href="https://twitter.com/ZacSweers/status/1302082690179629057?s=20">infuriated</a> some of us #AndroidDev
unleashing the droid rage. To Ben’s credit, he has
<a href="https://twitter.com/benthompson/status/1302185265524617217?s=20">since deleted</a>
the specific tweet calling out developer laziness.</p>

<p>I’m not going to spend time dissecting his tweets<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>. We are all human and
occasionally tweet dumb things. But there’s a shred of truth nestled in that
starting tweet that just got me thinking.</p>



<p>Serendipitously, I’ve been
<a href="https://twitter.com/kaushikgopal/status/1298692928081027072?s=20">thinking</a> and <a href="https://twitter.com/kaushikgopal/status/1298692084954587136?s=20">tweeting</a>
about similar things <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>I’ll summarize the obvious points so we can get those out of the way:</p>

<ul>
  <li>iOS does better with <strong>privacy</strong> overall. It’s <a href="https://www.androidcentral.com/apple-may-have-ditched-encrypted-backups-google-hasnt">not always a slam
  dunk</a>
  but all things considered the Android experience is
  <a href="https://www.cnet.com/news/more-than-1000-android-apps-harvest-your-data-even-after-you-deny-permissions/">worse</a> on <a href="https://media.ccc.de/v/35c3-9941-how_facebook_tracks_you_on_android/">this</a> <a href="https://news.ycombinator.com/item?id=15141077">front</a>.</li>
  <li>iPhone hardware is better than Pixel hardware especially when it comes to integration
  with bluetooth accessories like the Apple Watch, AirPods, CarPlay etc.</li>
  <li>Camera is dicey. <em>I think</em> the Pixel shoots better still photos than the
  iPhone. The computational photography voodoo that Google does on pictures
  after the fact makes the photos more appealing to my eyes. iPhones still
  have the better Camera (hardware) though which is abundantly clear when
  you try to shoot videos.</li>
  <li>Siri is a steaming pile of garbage. It’s a crying shame how bad it is given the
  better hardware. Google Assistant alone makes me switch back to my Pixel
  time and again<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>.</li>
</ul>

<p>But there’s one important point that came up from this imbroglio that
has been hard to shake off …and wherein lies the more interesting argument:</p>



<p>In my <a href="https://twitter.com/kaushikgopal/status/1298692928081027072?s=20">original
tweet</a> I was
careful to say the iPhone has better “3rd party” apps.</p>

<p>Here’s a fair question to ask retorting that position: Give me examples of apps
that exist on both Android and iOS where the iOS experience is better?</p>

<p>Sure, I can give examples<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup> where it’s true most of the time but my point is
subtly different. If I rephrase that question however, it helps make my
point better:</p>

<blockquote>
  <p>Give me the best “insert category” app on the iPhone and on the Pixel. Which
one do you think works better?</p>
</blockquote>

<p>Let’s try that for a few categories:</p>

<ul>
  <li>Give me the best Todo list app on the iPhone and Pixel. Which one do you think
  works better? (See <a href="https://culturedcode.com/things/">Things</a>)</li>
  <li>Give me the best RSS feed reader app on the iPhone and Pixel. Which one do you
  think works better? (See <a href="https://reederapp.com/">Reeder</a>)</li>
  <li>Give me the best music making app on the iPhone and Pixel. Which one do you think
  works better? (See <a href="https://www.apple.com/ios/garageband/">GarageBand</a>)</li>
</ul>

<p>Some will immediately jump in defense saying this is subjective.</p>

<p>Sure… Maybe? I’m open to being challenged here. But I build Android apps for a
living and I mostly use an iPhone today as my daily driver, so take it for what
that’s worth. Also chatting with other (dev) friends, I’ve heard I’m not alone.</p>

<h2 id="so-why-are-iphone-apps-better">So why are iPhone apps better?</h2>

<h3 id="android-tools-are-worse">Android Tools are worse?</h3>

<p>Actually it’s the opposite! After dabbling with some iOS development, I can
confidently say Android Studio is <del>like a glass of ice water</del> much better
than Xcode<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup>. I also think Google as a company listens more closely and cares
about improving the developer experience. Many of their recent changes have been
in direct response to developer outcries.</p>

<p>How many iOS developers can say the same of Apple?</p>

<h3 id="android-devs-are-lazy">Android devs are lazy?</h3>

<p>Abso-fucking-lutely not.</p>

<p>I’d even go so far as to argue that Android
developers care way more about clean architecture and good engineering practices
than iOS developers. I mean I’m biased here but consider the fact that Android
devs are typically early adopters of industry best
practices like <a href="https://github.com/ReactiveX">Rx</a>, MVI/Unidirectional State Flow,
Reactive UIs etc. You’ll find chatter, curiosity and first implementations
about these topics much earlier in the Android development community. But
here’s the rub:</p>

<blockquote>
  <p>iOS devs didn’t have to care about these things.</p>
</blockquote>

<h3 id="ios-devs-didnt-have-to-care">iOS devs didn’t have to care</h3>

<p>You want to know why Android devs jumped on Rx? Because every time you
hang for a few extra seconds on the main thread you would get hit with a gnarly
<a href="https://developer.android.com/topic/performance/vitals/anr">ANR</a>. iPhones were
built to make single threaded processing blazingly fast. You can execute
database calls on the main thread and not worry for the most part. Try that on
an Android phone.</p>

<p>You want to know why Android devs have heated week long discussions about
Dependency Injection and Dagger? Because we can’t use constructors in our
classes! iOS devs think we’re crazy cause our ViewControllers don’t just take in
our dependencies.</p>

<p>You want to know why Android devs experiment and come up with all kinds of
different architectures to build apps? Because Google for the longest time
intentionally chose not to have an opinion. This changed in <strong>2017</strong>. You know
how long Android has been around? since 2005. 12 years, if you’re doing the math.</p>

<p>I also don’t need to reiterate the trope around Android being fragmented<sup id="fnref:7" role="doc-noteref"><a href="#fn:7">7</a></sup>. While
we would spend nights battling platform specific bugs, our iOS counterparts
could spend their time focusing on silky smooth UIs. They had the luxury of
perfecting and polishing (and good on them for doing that). <code>minSdk 14</code> was
never a thing for iOS devs.</p>

<p>So yes, we might have better tools courtesy Android Studio but make no mistake
it is easier to build higher quality apps on iOS than it is on Android.</p>

<h2 id="one-more-thing">One more thing</h2>

<p>There’s also this other big factor that accounts for better third party apps:
iOS users are more willing to spend money through the app ecosystem. Android
may have the bigger market share today but <a href="https://www.prnewswire.com/news-releases/iphone-users-spend-101-every-month-on-tech-purchases-nearly-double-of-android-users-according-to-a-survey-conducted-by-slickdeals-300739582.html?c=n">more money is spent through iPhones</a>.</p>

<p>If iPhone users are willing to spend more money, companies <strong>and
indie developers</strong> are going to spend more time and resources building iOS apps
instead of Android apps.  When more time and resources are spent instead on iOS
apps it follows that iOS is likely to have the better apps.</p>

<p>It’s harder technically to build a better Android app but Google is doing its
part to close that gap quickly. But unless Android users actually start
spending more money through apps, iOS is going to have the lead.</p>



  </article></div>]]>
            </description>
            <link>https://blog.jkl.gg/iphones-pixels-lazy-android-developers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24402295</guid>
            <pubDate>Mon, 07 Sep 2020 20:03:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Entanglement with SVD]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24402242">thread link</a>) | @jonbaer
<br/>
September 7, 2020 | https://www.math3ma.com/blog/understanding-entanglement-with-svd | <a href="https://web.archive.org/web/*/https://www.math3ma.com/blog/understanding-entanglement-with-svd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div href=""><p><em>Quantum</em> <em>entanglement</em> is, as you know, a phrase that's jam-packed with meaning in physics. But what you might not know is that the linear algebra behind it is quite simple.&nbsp;If you're familiar with singular value decomposition (SVD), then you're 99% there. My goal for this post is to close that 1% gap. In particular, I'd like to explain something called the<em> </em><strong>Schmidt rank</strong> in the hopes of helping the math of entanglement feel a little less... tangly. And to do so, I'll ask that you momentarily forget about the previous sentences. Temporarily ignore the title of this article. Forget we're having a discussion about entanglement. Forget I mentioned that word. And let's start over. Let's just chat math. </p><p>Let's talk about SVD. </p><figure><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5b527d2844acede360b8e7ae_hline.jpg" loading="lazy" alt=""></p></figure><h2>Singular Value Decomposition</h2><p>SVD is arguably one of the most important, well-known tools in linear algebra. You are likely already very familiar with it, but here's a lightning-fast recap. Every matrix $M$ can be factored as $M=UDV^\dagger$ as shown below, called the <strong>singular value decomposition</strong> of $M$. The entries of the diagonal matrix $D$ are nonnegative numbers called <em>singular values</em>, and the number of them is equal to the rank of $M$, say $k$. What's more, $U$ and $V$ have exactly $k$ columns, called the <em>left and right singular vectors</em>, respectively.</p><figure id="w-node-c5cffac943b5-24b29fc4"><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f5562528e82aa6ab6d78ae1_open.png" loading="lazy" alt=""></p></figure><p>There are different ways to think about this, depending on which applications you have in mind. I like to think of singular vectors as encoding meaningful "concepts" inherent to $M$, and of singular values as indicating how important those concepts are. For instance, this perspective arises naturally in a study of the <a href="https://arxiv.org/abs/1810.10531">learning dynamics of deep neural networks</a>. As another example, you can imagine a matrix whose rows are indexed by people, and whose columns are indexed by movies.&nbsp;The $ij$th entry could be a 0 or 1, indicating whether or not person $i$ has watched movie $j$. In an applied setting—a recommender system, for instance—one may wish to compute a <em>truncated SVD </em>of this matrix. Here, only the top largest singular values are kept. The rest are viewed as containing little information and are set to zero. In this way, the diagonal matrix $D$&nbsp;operates on a low-dimensional "feature space," which provides a nice way to <a href="https://developers.google.com/machine-learning/recommendation/collaborative/basics">compress and glean information about the data</a>.</p><p>Either way, I like to think of $D$ as providing a bridge between two worlds: information about the columns of $U$ (e.g. people) and information about the columns of $V$ (e.g. movies). Below is a very <em>non</em>-mathematical cartoon of this. You can imagine the thickness of the blue bridge relates to the number of singular values. Lots of singular values?&nbsp;The bridge is wide and lots of information passes through. Only a few singular values?&nbsp;The bridge is narrow and not much information gets through.</p><figure id="w-node-fc7a2c3b2624-24b29fc4"><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f55643d546e4a903f261c30_bridge2.png" loading="lazy" alt=""></p></figure><p>An actual mathematical picture is found in a <a href="https://www.math3ma.com/blog/matrices-as-tensor-network-diagrams">tensor network diagram</a> representation of SVD.&nbsp;There, $D$&nbsp;really is a bridge! As a visual cue, we might draw the edges adjacent to the blue node as very thick if the number of singular values is large, and draw them to be thin otherwise. This again represents the idea of information "flowing" between systems described by $U$ and $V$.</p><figure id="w-node-235ea1f864dc-24b29fc4"><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f5564d7d7916c43e6f8c4ce_TN2.png" loading="lazy" alt=""></p></figure><p>Alternatively still, if you enjoy thinking of <a href="https://www.math3ma.com/blog/matrices-probability-graphs">matrices as bipartite graphs</a>, then you might have in mind the graphs below. If we have lots of blue nodes—i.e. lots of singular values—then there are lots of pathways between the pink and green nodes (i.e. people and movies). But if we have only a <em>few</em> blue nodes—i.e. a few singular values—then there are fewer pathways between pink and green.</p><figure id="w-node-9ef538caa942-24b29fc4"><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f577be8bc99498290bfcb81_graph2.jpg" loading="lazy" alt=""></p></figure><p>Either way we wish to visualize it, the role of the singular values—that is, the role of the diagonal matrix $D$—is key. Intuitively, they indicate the amount of "interaction" between the information stored by $U$ and $V$, and they mediate how those interactions contribute to the information represented by the original matrix $M$.</p><p><em>And this precisely idea behind the mathematics of entanglement</em>.</p><p>In the context of physics, one simply applies SVD to a particular matrix and then looks at the number of nonzero singular values of that matrix. This is the main idea behind something called the <em>Schmidt rank</em> of a quantum state (explained below), which is an integer that indicates how much entanglement is present. </p><blockquote>Entanglement is measured by the number of nonsingular values of a particular matrix. </blockquote><p>So what makes a physicist's application of SVD different from that of, say, someone building a movie recommender system?&nbsp;Well, in physics, your matrix $M$ presumably encodes information about a physical system and takes spatial considerations into account (ex. particles in a lattice). Its entries may also contain complex numbers, and the sum of their squares should satisfy $\sum_{ij}|M_{ij}|^2=1$. In this case—as I'll explain below—$M$ represents a <strong>quantum state</strong>. But lingo aside, the template is much the same: singular values convey important information about how two things—whether users and movies, or two quantum subsystems—are related.</p><p>I could stop here, but I'd like to dig a little deeper. In the next section, let me restate this punchline using slightly more specialized language.</p><figure><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5b527d2844acede360b8e7ae_hline.jpg" loading="lazy" alt=""></p></figure><h2>Singular Values vs. Schmidt&nbsp;Rank</h2><p>To start, let's back up a bit. In a discussion of physics, what exactly is the matrix to which we apply SVD?&nbsp;In the opening example, we applied SVD to a user-by-movie matrix. But what's going on now?</p><p>Rather than starting with a matrix, we instead start with a <em>unit vector</em>. To that end, suppose $\psi$ is any unit vector in a <strong>tensor product</strong> of vector spaces $\mathbb{C}^n\otimes\mathbb{C}^m$. Here, it's important that our discussion takes place in a tensor product. After all, entanglement is defined <em>between two things</em> (So, if someone were to ask you, "How much entanglement is there?" one proper response would be, "Entanglement <em>between</em> <em>what</em>?"), and in quantum mechanics, the tensor product is the mathematical operation used to combine two systems. Now, if the phrase "tensor product" is unfamiliar to you, I recommend the article "<a href="https://www.math3ma.com/blog/the-tensor-product-demystified">The Tensor Product, Demystified</a>." I&nbsp;think you'll be pleasantly surprised at how easy the concept is!</p><p>Alright, now that we have the vector $\psi$, it's easy to get a linear map $\mathbb{C}^m\to\mathbb{C}^n$ from it. Simply reshape the entries of $\psi$ into an $n\times m$ matrix $M$. (Said more formally, look at $\psi$&nbsp;under the isomorphism $A\otimes B^*\cong\text{hom}(B,A)$ for finite-dimensional vector spaces $A$&nbsp;and $B$.)</p><figure><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f5517185b36106928a313a9_reshape.jpeg" loading="lazy" alt=""></p></figure><p>In the language of physics, $\psi$ is called a <strong>quantum state</strong>, and $M$&nbsp;is simply the matrix associated with it. More generally, the terms&nbsp;"unit vector" and "quantum state" are synonymous. That's because the squares of the entries of any unit vector define a probability distribution, and—in the context of physics—that probability distribution tells you about the <em>state</em> of the system you're studying. (This is the Born rule.)</p><p>But I&nbsp;digress. Let's get back to SVD.</p><p>Suppose the singular value decomposition of our matrix $M$ is given by $UDV^\dagger$. Here I'm using the dagger to denote the conjugate transpose of $V$ since we're allowing $M$ to have complex entries. Now I'd like to use this decomposition&nbsp;to rewrite $M$ in a slightly messier way. Let $\mathbf{u}_i$ and $\mathbf{v}_i$ denote the $i$th columns of $U$ and $V$, respectively, and let $d_i$ denote the $i$th singular value of $M$. Then we can expand the matrix $M$ as the following sum, where $k$&nbsp;is the rank of $M$. </p><figure id="w-node-dc0fefa9bd0b-24b29fc4"><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f556da578cb1b3bbc952fdd_expand2.png" loading="lazy" alt=""></p></figure><p>We're almost at the punchline, but let me first introduce a definition and then make one final cosmetic change.</p><p>For any two vectors $\mathbf{u}$&nbsp;and $\mathbf{v}$, the matrix $\mathbf{uv}^\dagger$ is called their <strong>outer product</strong>. This simple operation is also denoted with a tensor product symbol $\mathbf{u}\otimes \mathbf{v}$ or in physicists' bra-ket notation by $|u\rangle\langle v|$. So for example, if $\mathbf{u}=\begin{bmatrix}1&amp;2&amp;3\end{bmatrix}^\top$ and $\mathbf{v}=\begin{bmatrix}4&amp;5\end{bmatrix}^\top$, then their outer product is the following little matrix.</p><figure id="w-node-c2af2f15f3fb-24b29fc4"><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f551c63f2d18fc4ccbcb28b_outer.jpg" loading="lazy" alt=""></p></figure><p>Why introduce this?&nbsp;Let's think back that expansion of $M$&nbsp;above. Under the correspondence $\mathbf{uv}^\dagger \leftrightarrow \mathbf{u}\otimes \mathbf{v}$, we can write $\psi$&nbsp;explicitly using the columns of $U$ and $V$, weighted by the singular values of $M$ like this:</p><figure id="w-node-3ff996165bf0-24b29fc4"><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f556f9788b112261c051ef6_decomp0.jpg" loading="lazy" alt=""></p></figure><p>At this point, you might think we haven't done much (and we haven't, really), <em>and yet</em> familiar things are now given <em>new names</em>. In the context of physics, the above decomposition of $\psi$ is called its <strong>Schmidt decomposition</strong>. The integer $k$, which is the rank of the original matrix $M$, is called its <strong>Schmidt rank</strong>. And the singular values $d_1,d_2,\ldots, d_k$ are called its <strong>Schmidt coefficients.</strong></p><figure><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f556fb589f1f866fb28a990_decomp1.jpg" loading="lazy" alt=""></p></figure><p>Although terminology is new, the ingredients aren't. And that's the punchline.</p><blockquote>Punchline: the quantum state $\psi$ is said to be <strong>entangled</strong> if its Schmidt rank&nbsp;(i.e. number of singular values) is strictly greater than 1, and is <strong>not entangled</strong> otherwise.</blockquote><p>So, do you see the connection with our discussion above? As we stressed earlier, singular values can be thought of as providing a "bridge" between two subsystems. They are a measure of how much interaction exists between them. In the context of physics, this interaction is understood as entanglement.</p><p>The upshot is that a large number of singular values—i.e. a high Schmidt rank or a "wide bridge"—corresponds to lots of communication between two subsystems. A small number of singular values—i.e. a low Schmidt rank or a "narrow bridge"—corresponds to little communication. At the lowest extreme, <em>one</em> singular value corresponds to <em>zero</em> entanglement, and we might as well omit the thin bridge in the image below.</p><figure><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f559310bc99491aa62d994a_zero1.jpg" loading="lazy" alt=""></p></figure><p>Indeed, notice that if the Schmidt rank of $\psi$ is equal to <em>one</em>—that is, if $M$&nbsp;is a rank one matrix $M=\mathbf{uv}^\dagger$—then we can write $\psi=\mathbf{u\otimes v}$. In the mathematics literature, vectors of this form (i.e. a tensor product of vectors) are sometimes called <strong>simple tensors</strong>.&nbsp;For this reason, some mathematicians associate entanglement with "linear combinations of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.math3ma.com/blog/understanding-entanglement-with-svd">https://www.math3ma.com/blog/understanding-entanglement-with-svd</a></em></p>]]>
            </description>
            <link>https://www.math3ma.com/blog/understanding-entanglement-with-svd</link>
            <guid isPermaLink="false">hacker-news-small-sites-24402242</guid>
            <pubDate>Mon, 07 Sep 2020 19:58:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Transclude for Networked Writing]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24402202">thread link</a>) | @jil
<br/>
September 7, 2020 | http://subpixel.space/entries/open-transclude/ | <a href="https://web.archive.org/web/*/http://subpixel.space/entries/open-transclude/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>tl;dr: If you follow this blog you’ve seen me experiment with iframe-based citations; this post is about open-sourcing that tooling. <a href="#tutorial-start" target="_self">Skip</a> to demo, implementation tutorial, and GitHub link.</p>

<hr>

<p>Knowledge tooling is happily becoming a hot topic again. With this trend is coming revived interest in <a href="https://en.wikipedia.org/wiki/Project_Xanadu">Xanadu</a>, bi-directional hyperlinking, knowledge databases, visualizing knowledge graphs, and so on. At this moment, I see most of the emphasis being put on tooling for the research side, with Notion, Workflowy, and the new and hyped Roam Research leading the way.</p>

<p><img src="http://subpixel.space/uploads/xanadu-shot.png" alt="Screenshot of the OpenXanadu prototpye"></p>

<p>Where I see less focus is the <em>writing</em> part of the knowledge production process, where older apps like Scrivener are still the thing to beat. And almost nobody at all is working on the reader’s experience. As a blogger who largely caters to a wide audience, I’m especially interested in these areas.</p>

<p>Written information is largely still presented as a single document, and writing tools are geared toward the production of long pages. But before I say what’s wrong with this, let me sing the praises of documents for a moment.</p>

<p>People often get carried away when they discover the original vision of hypertext, which involves a network of documents, portions of which are “transcluded” (included via hypertext) into one another. The implication is that readers could follow any reference and see the source material—and granted, this would be transformative. However, there’s a limit to the effectiveness of the knowledge network as a reading experience. “Hypertext books,” online books which are made up of an abundance of interlinked HTML pages, are mostly unpopular. The failure of this experiment is, in my opinion, very revealing.</p>

<p><img src="http://subpixel.space/uploads/sprawlingplaces-shot.jpg" alt="Screenshot of tinderbox map of hypertext book Sprawling Places by David Kolb">
<span>Tinderbox map of a portion of David Kolb’s hypertext book Sprawling Places</span></p>

<p>Knowledge is not an accumulation of facts, nor is it even a set of facts and their relations. Facts are only rendered meaningful within narratives, and the single-page document is a format very conducive to narrative structure. The hypertext books that have gained popularity (I’m thinking here of <a href="http://meaningness.com/">Meaningness.com</a>) have largely conformed to this in two ways: 1) there is an intended reading order, and 2) the longer essays within the project do most of the heavy lifting in terms of imparting the author’s perspective to readers.</p>

<p>On the other hand, the notion of the “document” that is intrinsic to web development today is overdetermined by the legacy of print media. The web document is a static, <em>finished</em> artifact that does not bring in dynamic data. This is strange because it lives on a medium that is alive, networked, and dynamic, a medium which we increasingly understand more as a <em>space</em> than a thing.</p>

<p>For example, consider how silly it is to include MLA-style citations at the bottom of a text when we have the vast capabilities of linked documents on the web. Why should the reader have to read every citation or trust that an author is not taking a citation out of context, when hyperlinks are available?</p>

<p>This all suggests that a compromise must be struck between the coherence of a text and the new opportunities for knowledge work afforded by the fundamental capabilities of the medium: the internet’s connectivity, the screen’s frame rate.</p>

<hr>

<p>My own blogging is one context in which I’ve seen this tension play out, and have been working to explore ways of making my texts richer. A lot of the ideas I talk about in various pieces of writing are connected to one another. When I publish an essay, I’m not done with it. The ideas live on and get renewed, reused, and recycled in later works. Some sentences contain definitions that are core to my mental models, and there are whole paragraphs that might be useful out of context. I’m building my knowledge network in mind maps and behind various SaaS APIs, but how can I publicly show my thinking to be part a cohesive worldview?</p>

<p>Normally people solve this by simply block quoting themselves, but this is a waste of an opportunity. The indented block quote is a print medium invention <a href="https://en.wikipedia.org/wiki/Block_quotation#Origins">almost as old as typesetting</a>. The block quote is <em>plaintext</em>, it is not actually linked to the original text or its context.</p>

<p>I’ve been experimenting with one idea for a solution, and if you’ve read the last couple blog posts you’ll have seen it there. My stab at an answer is an iframe which shows the quote within its original context and gives a hint at its surroundings. Effectively, it’s a transclusion within my own blog. I’m currently satisfied with what I have as a v1, and am interested to see if others find it useful, so I’m open sourcing it here and including a tutorial.</p>



<p>Open Transclude is a UX pattern, a spec for networked writing within your own blog. Here’s how it looks:</p>



<!-- <script src="/portal.js"></script> -->



<p>What you are looking at is an scroll-locked iframe that links to a quote I picked out of my blog post “Notes on Comparative Psychology.” You can use Open Transclude anywhere you can drop an <code>&lt;a&gt;</code> tag on your own site.</p>

<p>Open Transclude:</p>
<ul>
  <li>Works anywhere on your own domain</li>
  <li>Compatible with most static site generators / templating engines</li>
  <li>12 lines of HTML, 80 lines of SCSS, 22 lines of JS (4.5 kb total)</li>
  <li>Has 0 dependencies&nbsp;— this is native web technology</li>
</ul>

<p>Open Transclude is extremely simple, and the heaviest part of the code is the CSS, which you can simplify at your whim. That’s why I am referring to it as a UX pattern. This is not a protocol. The code is really a commodity. What’s interesting about it is the idea and the design, and this is just one viable implementation! Feel free to adapt it however you like.</p>

<p>The principal improvement over a block quotation is <em>sense of context</em>.</p>

<p>Over on GitHub you’ll find the <a href="https://github.com/tobyshorin/Open-Transclude/">reference implementation for Jekyll</a>. Below is a tutorial for implementing it yourself, by way of also explaining some of the technical design decisions.</p>

<hr>

<h2 id="implementation-recipe">Implementation Recipe</h2>

<p>Here’s what you need to do to get Open Transclude up and running.</p>

<ol>
  <li>Create an anchor tag in the blog post where you want to cite yourself.</li>
  <li>Create the HTML for the reusable transclusion component.</li>
  <li>Call the portal into any document and passing it Jekyll variables.</li>
  <li>A small piece of Javascript which populates your transclusion into the document.</li>
  <li>Create the SCSS file with the component’s styles.</li>
</ol>

<h3 id="1-create-the-anchor-tag-where-you-want-to-cite-yourself">1. <strong>Create the anchor tag where you want to cite yourself</strong></h3>

<p>To quote yourself, you’ll need to create an <code>&lt;a&gt;</code> anchor tag in the markdown file for the post you want to quote. If you wish to highlight a specific piece of text, instead create a <code>&lt;span&gt;&lt;/span&gt;</code> around the section you want to quote. Note that this can <em>only be on your own website</em>—it doesn’t work cross domain.</p>

<p>Here’s what it looks like for the example iframe above.</p>

<figure><pre><code data-lang="markdown">It will, for one thing, become newly conscious of itself, and, to the degree that it is, <span>**it will tend to undermine its own experiential integrity**</span>" (emphasis mine).

<span>&lt;span</span> <span>name=</span><span>"mainstream-magic"</span><span>&gt;</span>Ironically, psychology remains one of the closest things we have to a mainstream magic or a mystical art today. Not only is it plainly the direct descendent of medieval magic, as I learned when I read Ioan Coulianou's <span>*Eros and Magic in the Renaissance*</span> earlier this year. <span>**It is a theory of the self that is phenomenologically accurate, objectively wrong, and is based on magical thinking even as it deconstructs itself**</span>.<span>&lt;/span&gt;</span> Some magical thinking processes that happen in psychotherapy, such as <span>[</span><span>transference to the psychologist</span><span>](</span><span>https://en.wikipedia.org/wiki/Transference#Transference_and_countertransference_during_psychotherapy</span><span>)</span>, are even intended to stay unmentioned to the patient in order to be utilized most effectively by the therapist!</code></pre></figure>

<h3 id="2-create-your-iframe-component">2. Create your iframe component</h3>

<p>This is most useful as a standardized component which can be used across the site, so we are going to take advantage of Jekyll’s templating features. Jekyll and other static site generators like Kirby and Zola support HTML “partials” or “includes” so that you can create reusable components.</p>

<p>In your <code>/_scss</code> or <code>/_sass</code> folder make a new file, <code>portal.scss</code>. I called it “portal” because it’s shorter than “transclusion” and less prone to spelling errors.</p>

<p>Here’s our component:</p>

<figure><pre><code data-lang="html"><span>&lt;div</span> <span>class=</span><span>"portal-container"</span><span>&gt;</span>
    <span>&lt;div</span> <span>class=</span><span>"portal-head"</span><span>&gt;</span>
        <span>&lt;div</span> <span>class=</span><span>"portal-backlink"</span> <span>&gt;</span>
            <span>&lt;div</span> <span>class=</span><span>"portal-title"</span><span>&gt;</span>From <span>&lt;span</span> <span>class=</span><span>"portal-text-title"</span><span>&gt;</span>{{ include.title }}<span>&lt;/span&gt;&lt;/div&gt;</span>
            <span>&lt;a</span> <span>href=</span><span>"{{ include.link }}"</span> <span>class=</span><span>"portal-arrow"</span><span>&gt;</span>Go to text <span>&lt;span</span> <span>class=</span><span>"right-arrow"</span><span>&gt;</span>→<span>&lt;/span&gt;&lt;/a&gt;</span>
        <span>&lt;/div&gt;</span>
    <span>&lt;/div&gt;</span>
    <span>&lt;div</span> <span>id=</span><span>"portal-parent-{{include.anchor}}"</span> <span>class=</span><span>"portal-parent"</span><span>&gt;</span>
        <span>&lt;div</span> <span>class=</span><span>"portal-parent-fader-top"</span><span>&gt;&lt;/div&gt;</span>
        <span>&lt;div</span> <span>class=</span><span>"portal-parent-fader-bottom"</span><span>&gt;&lt;/div&gt;</span>        
        <span>&lt;!-- We'll use Javascript to populate the iframe right here --&gt;</span>
    <span>&lt;/div&gt;</span>    
<span>&lt;/div&gt;</span></code></pre></figure>

<p>You’ll notice immediately that the iframe isn’t there yet. Like I mentioned above, we’re going to be populating it with Javascript.</p>

<p>You’ll also see that in various places we’re using <code>{{ include.___}}</code>. A cool thing about Jekyll includes its that it’s possible to define variables and pass them to our include, so we can create reusable components across our site. Dave Rupert has a <a href="https://daverupert.com/2017/07/jekyll-includes-are-cool/">nice blog post about this</a> called if you want to see more advanced examples!</p>

<h3 id="3-calling-the-component">3. Calling the component</h3>

<p>Anytime you want to pull this component into a blog post, all you have to do is <code>include</code> it in the markdown of another blog post, like this:</p>

<figure><pre><code data-lang="html">  {% include portal.html title="Notes On Comparative Psychology" link="/entries/notes-on-comparative-psychology/#mainstream-magic" anchor="emotional-deficit" %} </code></pre></figure>

<p>When you include it, you’ll need to pass in those three variables - title, link, and anchor, that fill in the includes above. If you’re following along now and making a build in Jekyll, you’ll see an empty, unstyled component with the link. So good so far!</p>

<h3 id="4-populating-with-javascript">4. Populating with Javascript</h3>

<p>This is a good time to address why we need Javascript. Web developers reading this are probably asking why we don’t simply put the full <code>/link#with-anchor</code> into the iframe src and be done with it. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://subpixel.space/entries/open-transclude/">http://subpixel.space/entries/open-transclude/</a></em></p>]]>
            </description>
            <link>http://subpixel.space/entries/open-transclude/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24402202</guid>
            <pubDate>Mon, 07 Sep 2020 19:54:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Algae provide blueprint for super-efficient future solar cells (2019)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24402169">thread link</a>) | @restalis
<br/>
September 7, 2020 | https://www.uu.nl/en/news/ingenious-control-panel-in-algae-provides-blueprint-for-super-efficient-future-solar-cells | <a href="https://web.archive.org/web/*/https://www.uu.nl/en/news/ingenious-control-panel-in-algae-provides-blueprint-for-super-efficient-future-solar-cells">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A single ingenious protein complex makes it possible for algae and cyanobacteria to use and store solar energy more efficiently than any other organism on earth. Scientists at the universities of Utrecht and Birmingham have unravelled the mechanism, which could serve as a source of inspiration for super-efficient photovoltaic cells. They published their results in the respected scientific journal CellChem.</p></div><div><p>Like plants, algae store the sun’s energy in biomass via photosynthesis, but while plants only store an average of 12 percent of the energy, algae can store up to 98 percent. “That enormous degree of efficiency makes algae ideal for energy storage and conversion”, explains <a href="https://www.uu.nl/staff/STamara">Sem Tamara</a>, PhD Candidate at Utrecht University.</p></div><div><div><div><div> <picture> <source srcset="https://www.uu.nl/sites/default/files/styles/image_1600xn/public/image_2_red_alga_crop_web_0.jpg?mt=1590568076&amp;itok=yLcSOV5M 1x" media="(min-width: 1200px)" type="image/jpeg"> <source srcset="https://www.uu.nl/sites/default/files/styles/image_1200xn/public/image_2_red_alga_crop_web_0.jpg?mt=1590528766&amp;itok=JfD-pdEP 1x" media="(min-width: 800px)" type="image/jpeg"> <source srcset="https://www.uu.nl/sites/default/files/styles/image_800xn/public/image_2_red_alga_crop_web_0.jpg?mt=1590687607&amp;itok=lyOUSlq2 1x" media="(min-width: 480px)" type="image/jpeg"> <source srcset="https://www.uu.nl/sites/default/files/styles/image_480xn/public/image_2_red_alga_crop_web_0.jpg?mt=1590529175&amp;itok=jwNyO5ud 1x" media="(min-width: 0px)" type="image/jpeg"> <img alt="" src="https://www.uu.nl/sites/default/files/styles/image_1600xn/public/image_2_red_alga_crop_web_0.jpg?itok=yLcSOV5M"> </picture></div></div><p> Red algae are among the most efficient energy converting organisms on Earth.</p></div></div><div><div><h2>Highly complex light harvesting system</h2>
<p>Tamara conducts research into the molecular structure that facilitates the efficient photosynthesis process in algae. A single algae has many protrusions on its surface, called antennae, which form vital components of its light harvesting system. “It’s a highly complex system. Each protrusion is made up of stacks of tiny disks. Inside each disk, there is a ‘gamma’ building block that passes the light efficiently into the system.”</p>
<h2>Different forms of a single molecule</h2>
<p>Tamara used mass spectrometry (MS) to discover that there may be up to 20 different types of gamma building blocks. “MS allows you to determine the weight of molecules. Each specific molecule has its own weight. The number of peaks in our mass spectrum then displays the number of different forms of a specific type of molecule.” So far, Tamara has accurately defined four different gamma building blocks. “And some of them can convert the light better than others.”</p></div></div><div><div><blockquote><p>The system is more complicated than a Swiss watch. This is the product of three billion years of evolution, and engineers could learn a lot from it.</p> </blockquote></div></div><div><div><h2>Efficient through diversity</h2>
<p>The wide diversity of molecules that let light through does not mean that one form of the light harvesting system is more efficient than another, however. According to Professor of Mass Spectrometry <a href="https://www.uu.nl/staff/AJRHeck">Albert Heck</a>, Tamara’s PhD supervisor: “I think that the diversity of gamma building blocks is what makes the system work optimally under all circumstances. It can constantly adapt, so it is much more refined than we earlier thought.”</p>
<h2>New generation of solar panels</h2>
<p>Heck hopes that today’s solar panels, which have a yield of 20 percent at most, may eventually be improved with help from the same system that algae use. “The ingenious control panel that algae use to convert sunlight into usable energy is more complicated than a Swiss watch. This is the product of three billion years of evolution, and engineers could learn a lot from it. A primal organism that gives us the blueprint for the ultimate super-efficient solar cells.”</p>
<h2>Publication</h2>
<p><a href="https://www.sciencedirect.com/science/article/pii/S245192941930110X?dgcid=author">A Colorful Pallet of B-phycoerythrin Proteoforms Exposed by a Multimodal Mass Spectrometry Approach</a><br>
Sem Tamara*, Max Hoek*, Richard A. Scheltema*, Aneika C. Leney and Albert J.R. Heck*<br>
CellChem, 9 May 2019</p>
<p>* Affiliated with Utrecht University</p></div></div></div>]]>
            </description>
            <link>https://www.uu.nl/en/news/ingenious-control-panel-in-algae-provides-blueprint-for-super-efficient-future-solar-cells</link>
            <guid isPermaLink="false">hacker-news-small-sites-24402169</guid>
            <pubDate>Mon, 07 Sep 2020 19:50:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY IoT door monitor with ESP8266]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24402163">thread link</a>) | @christian_fei
<br/>
September 7, 2020 | https://cri.dev/posts/2020-09-03-DIY-IoT-door-monitor-with-ESP8266/ | <a href="https://web.archive.org/web/*/https://cri.dev/posts/2020-09-03-DIY-IoT-door-monitor-with-ESP8266/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Using an ESP8266 for IoT projects makes me go fast while prototyping.</p><p>The compact format is perfect for small DIY devices.</p><p>Wi-Fi connectivity is built-in, and it's super affordable.</p><blockquote><p>The ESP8266 is a low-cost Wi-Fi microchip, with a full TCP/IP stack and microcontroller capability (<a href="https://en.wikipedia.org/wiki/ESP8266">wikipedia</a>)</p></blockquote><hr><h2>Table of Contents</h2><ul><li><a href="#tldr">tldr;</a></li><li><a href="#requirements">Requirements</a></li><li><a href="#circuit-explanation">Circuit explanation</a></li><li><a href="#coding">Coding</a><ul><li><a href="#install-libraries-for-esp8266">Install libraries for ESP8266</a><ul><li><a href="#adding-the-esp8266-board">Adding the ESP8266 Board</a></li><li><a href="#additional-libraries">Additional libraries</a></li></ul></li><li><a href="#flash-it">Flash it</a></li></ul></li><li><a href="#try-it-out">Try it out!</a></li><li><a href="#next-steps">Next steps</a></li><li><a href="#rest-api">REST API</a></li><li><a href="#web-ui">Web UI</a></li><li><a href="#demo">Demo</a></li></ul><h2>tldr;</h2><p>The door monitor running in my home activates a buzzer when the proximity sensor detects that the door is opened.</p><p>Additionally, it creates an AP for Wi-Fi configuration using a Web interface, and can connect to a desired Wi-Fi network afterwards. <a href="#web-ui">Read more about this below</a></p><p>Source code can be found on <a href="https://github.com/christian-fei/door-monitor-esp8266">GitHub christian-fei/door-monitor-esp8266</a></p><pre><code>git clone https://github.com/christian-fei/door-monitor-esp8266.git
</code></pre><p>The worst photo I could take of the "Gate keeper" in action:</p><p><a href="https://github.com/christian-fei/door-monitor-esp8266/blob/master/Gatekeeper.svg"><img src="https://cri.dev/assets/images/posts/door-monitor/project.jpg" alt="project photo"></a></p><p>The Web UI that this thing has (see home-assistant integration <a href="#next-steps">at the end</a>)</p><p><img src="https://cri.dev/assets/images/posts/door-monitor/gate-keeper-ui.png" alt="gate-keeper-ui"></p><h2>Requirements</h2><p>To build your own, this is what you need:</p><ul><li>Microcontroller ESP8266 (LoLin)</li><li>Active Piezo Buzzer</li><li>Proximity Sensor FC-51</li><li>optionally a breadboard</li></ul><p>Arduino IDE or the Arduino Plug-in for VSCode will work fine for flashing the ESP8266.</p><h2>Circuit explanation</h2><p>Here the schematics for the circuit</p><p><img src="https://cri.dev/assets/images/posts/door-monitor/schematics.svg" alt="schematics door monitor"></p><p>The piezo buzzer is connected to GPIO D6, as an <code>OUTPUT</code> pin.</p><p>The proximity sensor is connected to GPIO D5, as an <code>INPUT</code> pin.</p><p>When the proximity sensor detects that the door is open, the GPIO D5 pin will read <code>HIGH</code>.</p><p>This is when the piezo buzzer is activated, and a simple alarm sound is played.</p><h2>Coding</h2><p>Clone the repository</p><pre><code>git clone https://github.com/christian-fei/door-monitor-esp8266.git
</code></pre><p>Open the project with Arduino IDE by clicking on the <a href="https://github.com/christian-fei/door-monitor-esp8266/blob/master/Gatekeeper.ino"><code>Gatekeeper.ino</code></a> file.</p><p>There is no need to change the code.</p><h3>Install libraries for ESP8266</h3><h4>Adding the ESP8266 Board</h4><p>Using the "Library Manager" in the Arduino IDE, you need to install support for ESP8266.</p><p>Here you can find <a href="https://arduino-esp8266.readthedocs.io/en/latest/installing.html#instructions">the official installation guide</a></p><h4>Additional libraries</h4><p>The project uses <a href="https://github.com/me-no-dev/ESPAsyncTCP/archive/master.zip"><code>ESPAsyncTCP</code></a> and <a href="https://github.com/me-no-dev/ESPAsyncWebServer/archive/master.zip"><code>ESPAsyncWebServer</code></a>.</p><p>Download both ZIP files, and add them either to your Arduino IDE installation libraries or via <code>Add .ZIP Library</code>.</p><h3>Flash it</h3><p>Connect your ESP8266 via USB to your PC.</p><p>Select the <code>usbserial</code> port and <code>NodeMCU 1.0 (ESP - 12 E Module)</code> board in the Arduino IDE.</p><p>Click <code>Upload</code> and flash the ESP8266.</p><h2>Try it out!</h2><p>Now you're ready to apply the board near a door you want to monitor.</p><p>The proximity sensor can both be placed on the door itself or on a wall near the door.</p><p>You'll need to calibrate the sensitivity of the sensor by rotating the potentiometer on the FC-51 chip.</p><h2>Next steps</h2><p>From here I went the following route:</p><p>Made the Gatekeeper available as an iframe element in my <a href="https://www.home-assistant.io/">homeassistant</a> installation. The URL I used was <code>http://gatekeeper.fritz.box</code> (after I connected it to my Wi-Fi network using <a href="#web-ui">the Web UI</a>)</p><p>On the Web UI of the Gatekeeper I can "disarm" the alarm sound and check whether the door is open or closed.</p><p>It looks like this:</p><p><img src="https://cri.dev/assets/images/posts/door-monitor/gate-keeper-homeassistant.png" alt="gate-keeper-homeassistant"></p><p>The next challenge is to register the door monitor as a "sensor" (or "entity" I think it's called in homeassistant lingo).</p><h2>REST API</h2><p>The Gatekeeper can already be called via HTTP on its REST API:</p><pre><code>  HTTP GET /
    -&gt; replies with the client html
  HTTP GET /door
    -&gt; returns the status of the door, whether it's "open" or "closed"
  HTTP GET /alarm
    -&gt; returns the status of the alarm, whether it's "on" or "off"
  HTTP POST /toggle-alarm
    -&gt; toggles the alarm and returns the current status of it
  HTTP POST /setup
    -&gt; to save the Wi-Fi credentials and connect to the desired access point
</code></pre><h2>Web UI</h2><p>The Web UI give you the current status of the door.</p><p>It also features a form where you can input the Wi-Fi credentials to connect to your home network.</p><p><img src="https://cri.dev/assets/images/posts/door-monitor/gate-keeper-ui.png" alt="gate-keeper-ui"></p><p>This means that once the door monitor is connected to Wi-Fi, it's accessible via the hostname <code>gatekeeper</code>.</p><p>E.g. with my FritzBox setup, it's available under <code>gatekeeper.fritz.box:80</code></p><h2>Demo</h2></div></div>]]>
            </description>
            <link>https://cri.dev/posts/2020-09-03-DIY-IoT-door-monitor-with-ESP8266/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24402163</guid>
            <pubDate>Mon, 07 Sep 2020 19:50:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disposable Mask Under the Microscope]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24401984">thread link</a>) | @callmekit
<br/>
September 7, 2020 | http://sdymphoto.com/post/2020/09/07/disposable-mask/ | <a href="https://web.archive.org/web/*/http://sdymphoto.com/post/2020/09/07/disposable-mask/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Here is how one type of now ubiquitous blue disposable mask looks under the microscope.</p>
<p>Using 2x objective:
<img src="http://sdymphoto.com/img/2020/Protective%20mask%202x%20x1.4.jpg" alt="Disposable mask using 2x objective"></p>
<p>Using 4x objective:
<img src="http://sdymphoto.com/img/2020/Protective%20mask%204x%20x1.4.jpg" alt="Disposable mask using 4x objective"></p>
<p>If you like this image, prints and apparel available via Redbubble: <a href="https://www.redbubble.com/people/sdymchenko/works/54778063-disposable-protective-face-mask-under-the-microscope">https://www.redbubble.com/people/sdymchenko/works/54778063-disposable-protective-face-mask-under-the-microscope</a></p>
<p>You can license the photos for commercial and personal use via Alamy: <a href="https://www.alamy.com/outer-layer-of-disposable-protective-face-mask-under-the-microscope-horizontal-field-of-view-is-about-6mm-image368204969.html">https://www.alamy.com/outer-layer-of-disposable-protective-face-mask-under-the-microscope-horizontal-field-of-view-is-about-6mm-image368204969.html</a></p>

</div></div>]]>
            </description>
            <link>http://sdymphoto.com/post/2020/09/07/disposable-mask/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401984</guid>
            <pubDate>Mon, 07 Sep 2020 19:29:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The new generation of software engineers who can't code]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24401968">thread link</a>) | @ZnZirconium
<br/>
September 7, 2020 | https://codebots.com/future-of-work/the-new-generation-of-software-engineers-who-cant-code | <a href="https://web.archive.org/web/*/https://codebots.com/future-of-work/the-new-generation-of-software-engineers-who-cant-code">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://codebots.com/future-of-work/the-new-generation-of-software-engineers-who-cant-code</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401968</guid>
            <pubDate>Mon, 07 Sep 2020 19:28:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minimum Viable Phoenix]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24401845">thread link</a>) | @Whitespace
<br/>
September 7, 2020 | http://www.petecorey.com/blog/2019/05/20/minimum-viable-phoenix/ | <a href="https://web.archive.org/web/*/http://www.petecorey.com/blog/2019/05/20/minimum-viable-phoenix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    <article>
        <h2 id="starting-at-the-beginning"><a href="https://github.com/pcorey/minimum_viable_phoenix/commit/6f8c9d84ea05d8dd4e137ae6133db4ad06fb6498">Starting at the Beginning</a></h2>

<p>Phoenix ships with quite a few bells and whistles. Whenever you fire up <code><span>mix</span> <span>phx</span><span>.</span><span>new</span></code> to create a new web application, forty six files are created and spread across thirty directories!</p>

<p>This can be overwhelming to developers new to Phoenix.</p>

<p>To build a better understanding of the framework and how all of its moving pieces interact, let’s strip Phoenix down to its bare bones. Let’s start from zero and slowly build up to a <strong>minimum viable Phoenix application</strong>.</p>

<h2 id="minimum-viable-elixir"><a href="https://github.com/pcorey/minimum_viable_phoenix/commit/4e2e319595415ff66fdc18679547ac49247979e7">Minimum Viable Elixir</a></h2>

<p>Starting at the beginning, we need to recognize that all Phoenix applications are Elixir applications. Our first step in the process of building a minimum viable Phoenix application is really to build a minimum viable Elixir application.</p>

<p>Interestingly, the simplest possible Elixir application is simply an <code><span>*.</span><span>ex</span></code> file that contains some source code. To set ourselves up for success later, let’s place our code in <code><span>lib</span><span>/</span><span>minimal</span><span>/</span><span>application</span><span>.</span><span>ex</span></code>. We’ll start by simply printing <code><span>"Hello."</span></code> to the console.</p>

<pre><code>
IO.puts("Hello.")
</code></pre>

<p>Surprisingly, we can execute our newly written Elixir application by compiling it:</p>

<pre><code>
➜ elixirc lib/minimal/application.ex
Hello.
</code></pre>

<p>This <a href="https://twitter.com/petecorey/status/1122629600800989184">confused me at first</a>, but it was explained to me that in the Elixir world, <a href="https://stackoverflow.com/a/41235949">compilation is also evaluation</a>.</p>

<p>lib/minimal/application.ex</p>
<pre><code>
+IO.puts("Hello.")
</code></pre>

<h2 id="generating-artifacts"><a href="https://github.com/pcorey/minimum_viable_phoenix/commit/f36703771756c1d149a58584e242c0e4d6ce607e">Generating Artifacts</a></h2>

<p>While our execution-by-compilation works, it’s really nothing more than an on-the-fly evaluation. We’re not generating any compilation artifacts that can be re-used later, or deployed elsewhere.</p>

<p>We can fix that by moving our code into a module. Once we compile our newly modularized <code><span>application</span><span>.</span><span>ex</span></code>, a new <code><span>Elixir</span><span>.</span><span>Minimal</span><span>.</span><span>Application</span><span>.</span><span>beam</span></code> file will appear in the root of our project.</p>

<p>We can run our compiled Elixir program by running <code><span>elixir</span></code> in the directory that contains our <code><span>*.</span><span>beam</span></code> file and specifying an expression to evaluate using the <code><span>-</span><span>e</span></code> flag:</p>

<pre><code>
➜ elixir -e "Minimal.Application.start()"
Hello.
</code></pre>

<p>Similarly, we could spin up an interactive shell (<code><span>iex</span></code>) in the same directory and evaluate the expression ourselves:</p>

<pre><code>
iex(1)&gt; Minimal.Application.start()
Hello.
</code></pre>

<p>.gitignore</p>
<pre><code>
+*.beam
.DS_Store
</code></pre>

<p>lib/minimal/application.ex</p>
<pre><code>
-IO.puts("Hello.")
+defmodule Minimal.Application do
+  def start do
+    IO.puts("Hello.")
+  end
+end
</code></pre>

<h2 id="incorporating-mix"><a href="https://github.com/pcorey/minimum_viable_phoenix/commit/7c2fcd8300e13f04dd0c20a9ae2153b9c21ecebe">Incorporating Mix</a></h2>

<p>This is great, but manually managing our <code><span>*.</span><span>beam</span></code> files and bootstrap expressions is a little cumbersome. Not to mention the fact that we haven’t even started working with dependencies yet.</p>

<p>Let’s make our lives easier by incorporating <a href="https://hexdocs.pm/mix/Mix.html">the Mix build tool</a> into our application development process.</p>

<p>We can do that by creating a <code><span>mix</span><span>.</span><span>exs</span></code> Elixir script file in the root of our project that defines a module that uses <code><span>Mix</span><span>.</span><span>Project</span></code> and describes our application. We write a <code><span>project</span><span>/</span><span>0</span></code> callback in our new <code><span>MixProject</span></code> module who’s only requirement is to return our application’s name (<code><span>:minimal</span></code>) and version (<code><span>"0.1.0"</span></code>).</p>

<pre><code>
def project do
  [
    app: :minimal,
    version: "0.1.0"
  ]
end
</code></pre>

<p>While Mix only requires that we return the <code><span>:app</span></code> and <code><span>:version</span></code> configuration values, it’s worth taking a look at the other configuration options available to us, especially <a href="https://hexdocs.pm/mix/Mix.html"><code><span>:elixir</span></code> and <code><span>:start_permanent</span></code></a>, <a href="https://hexdocs.pm/mix/Mix.Tasks.Compile.html#module-configuration"><code><span>:build_path</span></code></a>, <a href="https://hexdocs.pm/mix/Mix.Tasks.Compile.Elixir.html#module-configuration"><code><span>:elixirc_paths</span></code></a>, and others.</p>

<p>Next, we need to specify an <code><span>application</span><span>/</span><span>0</span></code> callback in our <code><span>MixProject</span></code> module that tells Mix which module we want to run when our application fires up.</p>

<pre><code>
def application do
  [
    mod: {Minimal.Application, []}
  ]
end
</code></pre>

<p>Here we’re pointing it to the <code><span>Minimal</span><span>.</span><span>Application</span></code> module we wrote previously.</p>

<p>During the normal application startup process, Elixir will call the <code><span>start</span><span>/</span><span>2</span></code> function of the module we specify with <code><span>:normal</span></code> as the first argument, and whatever we specify (<code><span>[]</span></code> in this case) as the second. With that in mind, let’s modify our <code><span>Minimal</span><span>.</span><span>Application</span><span>.</span><span>start</span><span>/</span><span>2</span></code> function to accept those parameters:</p>

<pre><code>
def start(:normal, []) do
  IO.puts("Hello.")
  {:ok, self()}
end
</code></pre>

<p>Notice that we also changed the return value of <code><span>start</span><span>/</span><span>2</span></code> to be an <code><span>:ok</span></code> tuple whose second value is a PID. Normally, an application would spin up a supervisor process as its first act of life and return its PID. We’re not doing that yet, so we simply return the current process’ PID.</p>

<p>Once these changes are done, we can run our application with <code><span>mix</span></code> or <code><span>mix</span> <span>run</span></code>, or fire up an interactive Elixir shell with <code><span>iex</span> <span>-</span><span>S</span> <span>mix</span></code>. No bootstrap expression required!</p>

<p>.gitignore</p>
<pre><code>
 *.beam
-.DS_Store
+.DS_Store
+/_build/
</code></pre>

<p>lib/minimal/application.ex</p>
<pre><code>
 defmodule Minimal.Application do
-  def start do
+  def start(:normal, []) do
     IO.puts("Hello.")
+    {:ok, self()}
   end
</code></pre>

<p>mix.exs</p>
<pre><code>
+defmodule Minimal.MixProject do
+  use Mix.Project
+
+  def project do
+    [
+      app: :minimal,
+      version: "0.1.0"
+    ]
+  end
+
+  def application do
+    [
+      mod: {Minimal.Application, []}
+    ]
+  end
+end
</code></pre>

<h2 id="pulling-in-dependencies"><a href="https://github.com/pcorey/minimum_viable_phoenix/commit/b5dd4d3ffeea0cc136004e762576b873a6ca1d4d">Pulling in Dependencies</a></h2>

<p>Now that we’ve built a minimum viable Elixir project, let’s turn our attention to the Phoenix framework. The first thing we need to do to incorporate Phoenix into our Elixir project is to install a few dependencies.</p>

<p>We’ll start by adding a <code><span>deps</span></code> array to the <code><span>project</span><span>/</span><span>0</span></code> callback in our <code><span>mix</span><span>.</span><span>exs</span></code> file. In <code><span>deps</span></code> we’ll list <code><span>:phoenix</span></code>, <code><span>:plug_cowboy</span></code>, and <code><span>:jason</span></code> as dependencies.</p>

<p>By default, Mix stores downloaded dependencies in the <code><span>deps</span><span>/</span></code> folder at the root of our project. Let’s be sure to add that folder to our <code><span>.</span><span>gitignore</span></code>. Once we’ve done that, we can install our dependencies with <code><span>mix</span> <span>deps</span><span>.</span><span>get</span></code>.</p>

<p>The reliance on <code><span>:phoenix</span></code> makes sense, but why are we already pulling in <code><span>:plug_cowboy</span></code> and <code><span>:jason</span></code>?</p>

<p>Under the hood, Phoenix uses the <a href="https://github.com/ninenines/cowboy">Cowboy</a> web server, and <a href="https://github.com/elixir-plug/plug">Plug</a> to compose functionality on top of our web server. It would make sense that Phoenix relies on <code><span>:plug_cowboy</span></code> to bring these two components into our application. If we try to go on with building our application without installing <code><span>:plug_cowboy</span></code>, we’ll be greeted with the following errors:</p>

<pre><code>** (UndefinedFunctionError) function Plug.Cowboy.child_spec/1 is undefined (module Plug.Cowboy is not available)
    Plug.Cowboy.child_spec([scheme: :http, plug: {MinimalWeb.Endpoint, []}
    ...</code></pre>

<p>Similarly, Phoenix relies on a JSON serialization library to be installed and configured. Without either <code><span>:jason</span></code> or <code><span>:poison</span></code> installed, we’d receive the following warning when trying to run our application:</p>

<pre><code>warning: failed to load Jason for Phoenix JSON encoding
(module Jason is not available).

Ensure Jason exists in your deps in mix.exs,
and you have configured Phoenix to use it for JSON encoding by
verifying the following exists in your config/config.exs:

config :phoenix, :json_library, Jason</code></pre>

<p>Heeding that advice, we’ll install <code><span>:jason</span></code> and add that configuration line to a new file in our project, <code><span>config</span><span>/</span><span>config</span><span>.</span><span>exs</span></code>.</p>

<p>.gitignore</p>
<pre><code>
 /_build/
+/deps/
</code></pre>

<p>config/config.exs</p>
<pre><code>
+use Mix.Config
+
+config :phoenix, :json_library, Jason
</code></pre>

<p>mix.exs</p>
<pre><code>
   app: :minimal,
-  version: "0.1.0"
+  version: "0.1.0",
+  deps: [
+    {:jason, "~&gt; 1.0"},
+    {:phoenix, "~&gt; 1.4"},
+    {:plug_cowboy, "~&gt; 2.0"}
+  ]
 ]
 </code></pre>

<h2 id="introducing-the-endpoint"><a href="https://github.com/pcorey/minimum_viable_phoenix/commit/6e654aa2b5ea693e3cd28fbb4cfd46049a6cf852">Introducing the Endpoint</a></h2>

<p>Now that we’ve installed our dependencies on the Phoenix framework and the web server it uses under the hood, it’s time to define how that web server incorporates into our application.</p>

<p>We do this by defining an “endpoint”, which is our application’s interface into the underlying HTTP web server, and our clients’ interface into our web application.</p>

<p>Following Phoenix conventions, we define our endpoint by creating a <code><span>MinimalWeb</span><span>.</span><span>Endpoint</span></code> module that uses <code><span>Phoenix</span><span>.</span><span>Endpoint</span></code> and specifies the <code><span>:name</span></code> of our OTP application (<code><span>:minimal</span></code>):</p>

<pre><code>
defmodule MinimalWeb.Endpoint do
  use Phoenix.Endpoint, otp_app: :minimal
end
</code></pre>

<p>The <a href="https://github.com/phoenixframework/phoenix/blob/714b21d3ab8d0329d26a48cf2cae98427df22a01/lib/phoenix/endpoint.ex#L488-L497"><code><span>__using__</span><span>/</span><span>1</span></code> macro</a> in <code><span>Phoenix</span><span>.</span><span>Endpoint</span></code> does quite a bit of heaving lifting. Among many other things, it loads the endpoint’s <a href="https://github.com/phoenixframework/phoenix/blob/714b21d3ab8d0329d26a48cf2cae98427df22a01/lib/phoenix/endpoint.ex#L499-L515">initial configuration</a>, sets up a <a href="https://github.com/phoenixframework/phoenix/blob/858f1ea439e8cef3cb1206812fc41db7199ba884/lib/phoenix/endpoint.ex#L588-L613">plug pipeline</a> using <a href="https://github.com/phoenixframework/phoenix/blob/858f1ea439e8cef3cb1206812fc41db7199ba884/lib/phoenix/endpoint.ex#L590"><code><span>Plug</span><span>.</span><span>Builder</span></code></a>, and <a href="https://github.com/phoenixframework/phoenix/blob/858f1ea439e8cef3cb1206812fc41db7199ba884/lib/phoenix/endpoint.ex#L621-L634">defines helper functions</a> to describe our endpoint as an OTP process. If you’re curious about how Phoenix works at a low level, start your search here.</p>

<p><code><span>Phoenix</span><span>.</span><span>Endpoint</span></code> uses the value we provide in <code><span>:otp_app</span></code> to look up configuration values for our application. Phoenix will complain if we don’t provide a bare minimum configuration entry for our endpoint, so we’ll add that to our <code><span>config</span><span>/</span><span>config</span><span>.</span><span>exs</span></code> file:</p>

<pre><code>
config :minimal, MinimalWeb.Endpoint, []
</code></pre>

<p>But there are a few configuration values we want to pass to our endpoint, like the host and port we want to serve from. These values are usually environment-dependent, so we’ll add a line at the bottom of our <code><span>config</span><span>/</span><span>config</span><span>.</span><span>exs</span></code> to load another configuration file based on our current environment:</p>

<pre><code>
import_config "#{Mix.env()}.exs"
</code></pre>

<p>Next, we’ll create a new <code><span>config</span><span>/</span><span>dev</span><span>.</span><span>exs</span></code> file that specifies the <code><span>:host</span></code> and <code><span>:port</span></code> we’ll serve from during development:</p>

<pre><code>
use Mix.Config
</code></pre>

<pre><code>
config :minimal, MinimalWeb.Endpoint,
  url: [host: "localhost"],
  http: [port: 4000]
</code></pre>

<p>If we were to start our application at this point, we’d still be greeted with <code><span>Hello</span><span>.</span></code> printed to the console, rather than a running Phoenix server. We still need to incorporate our Phoenix endpoint into our application.</p>

<p>We do this by turning our <code><span>Minimal</span><span>.</span><span>Application</span></code> into a proper supervisor and instructing it to load our endpoint as a supervised child:</p>

<pre><code>
use Application
</code></pre>

<pre><code>
def start(:normal, []) do
  Supervisor.start_link(
    [
      MinimalWeb.Endpoint
    ],
    strategy: :one_for_one
  )
end
</code></pre>

<p>Once we’ve done that, we can fire up our application using <code><span>mix</span> <span>phx</span><span>.</span><span>server</span></code> or <code><span>iex</span> <span>-</span><span>S</span> <span>mix</span> <span>phx</span><span>.</span><span>server</span></code> and see that our endpoint is listening on <code><span>localhost</span></code> port <code><span>4000</span></code>.</p>

<p>Alternatively, if you want to use our old standby of <code><span>mix</span> <span>run</span></code>, either configure Phoenix to serve all endpoints on startup, <a href="https://github.com/phoenixframework/phoenix/blob/858f1ea439e8cef3cb1206812fc41db7199ba884/lib/mix/tasks/phx.server.ex#L31">which is what <code><span>mix</span> <span>phx</span><span>.</span><span>server</span></code> does under the hood</a>:</p>

<pre><code>
config :phoenix, :serve_endpoints, true
</code></pre>

<p>Or configure your application’s endpoint specifically:</p>

<pre><code>
config :minimal, MinimalWeb.Endpoint, server: true
</code></pre>

<p>config/config.exs</p>
<pre><code>
+config :minimal, MinimalWeb.Endpoint, []
+
 config :phoenix, :json_library, Jason
+
+import_config "#{Mix.env()}.exs"
</code></pre>

<p>config/dev.exs</p>
<pre><code>
+use Mix.Config
+
+config …</code></pre></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.petecorey.com/blog/2019/05/20/minimum-viable-phoenix/">http://www.petecorey.com/blog/2019/05/20/minimum-viable-phoenix/</a></em></p>]]>
            </description>
            <link>http://www.petecorey.com/blog/2019/05/20/minimum-viable-phoenix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401845</guid>
            <pubDate>Mon, 07 Sep 2020 19:14:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doom Eternal – Graphics Study]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 32 (<a href="https://news.ycombinator.com/item?id=24401805">thread link</a>) | @todsacerdoti
<br/>
September 7, 2020 | https://www.simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html | <a href="https://web.archive.org/web/*/https://www.simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="markdown-content">
            


<p>30 Aug 2020 - Simon Coenen - Reading time: <span title="Estimated read time">
  
  
    23 mins
  
</span><span></span> - <a href="#comment-section">Comments</a>
</p>
<p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/image1.jpeg" alt=""></p>

<h2 id="background">Background</h2>

<p>Doom Eternal is the successor of Doom 2016. It’s developed using the 7th iteration of id Tech, id Software’s in-house game engine. Doom 2016 has inspired me greatly on a technologic level due to its simplicity and elegance while still having a high visual quality. For Doom Eternal, this is no different. Doom Eternal has improved in many areas of which a few are worth investigating which I will try to cover in this frame breakdown.</p>

<!--more-->

<p>This frame breakdown is inspired by <a href="http://www.adriancourreges.com/blog/2016/09/09/doom-2016-graphics-study/">Adrian Courreges’s study on Doom 2016</a>. I believe these graphics studies give a lot of insight into how certain rendering problems are solved in a AAA game and are greatly educational. In this breakdown I aim to stay at a high level and not go too in-depth of each rendering technique/pass. Some passes might not be covered here because they are very similar to Doom 2016 and are well covered in Adrian Courreges’s study.</p>

<p>I do want to stress here that these studies are absolutely nothing more than <strong>educational</strong>. I do not in any way support the reverse engineering for malicious purposes and stealing intellectual property. If you haven’t played the game yet, don’t worry about spoilers! The section I used for this study is in the beginning of the game which doesn’t give away any of the details.</p>

<p>Now, let’s get down to business.</p>

<p>With Id Tech 7, the engine has moved away from OpenGL and is entirely built with a <strong>Vulkan</strong> backend allowing them to make better use of current generation GPU features, bindless resources in particular.</p>

<hr>



<p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/image2.png" alt=""></p>

<p>We’re looking at a section in the game close to the start. It’s an interior with a few enemies and a large portion of volumetric lighting. Just like its predecessor, Doom Eternal is using a <strong>forward rendering</strong> pipeline. Doom 2016 was mostly forward rendered with a thin G-Buffer for screen space reflections. However this time, everything is fully forward rendered omitting the G-Buffer.</p>

<hr>

<h2 id="step-away-from-mega-texture">Step away from Mega-Texture</h2>

<p>With id Tech 5 used in <a href="https://en.wikipedia.org/wiki/Rage_(video_game)">Rage</a>, there was a texture streaming concept introduced called ‘Mega-Texture’ which was also used in the previous Doom installment. This system works by rendering a so called ‘feedback texture’ each frame that contains the information of what texture data was visible, that texture is analysed next frame to determine which textures get streamed in from disk. This has an obvious flaw because once a texture is on screen, it’s basically already too late to load it and this causes blurry textures the first few frames it is on screen. In id Tech 7, id Software has stepped away from this approach.</p>

<hr>

<h2 id="gpu-skinning">GPU Skinning</h2>

<p>The first thing that happens even before anything gets drawn to a texture, is evaluating skinning. This is commonly done in a vertex shader before shading. An alternative approach used here, is to do skinning beforehand in a compute shader which writes out skinned vertices to a buffer. This has a couple of advantages mainly not having to do skinning in the vertex shader for every geometry pass. This results in having less shader permutations because the vertex shader doesn’t have to know about skinning.</p>

<p>Skinning in a compute shader is not much different from in a vertex shader except that the output gets written to an intermediate buffer which can then be consumed in a vertex shader that can treat it as a regular static mesh. Just like in a vertex shader, for each vertex, a compute shader thread retrieves the transform of each bone affecting the vertex, transforms its position with each bone transform and adds up these positions based on the skin weights stored on the vertex.</p>

<p>János Turánszki wrote a wonderful write-up of how it can be implemented using a compute shader:
<a href="https://wickedengine.net/2017/09/09/skinning-in-compute-shader/">https://wickedengine.net/2017/09/09/skinning-in-compute-shader/</a>.</p>

<p>Another thing that is worth noting here is the use of <strong>Alembic Caches</strong> in Doom Eternal. These caches contain baked animation which get streamed and decompressed at runtime. As <a href="https://www.youtube.com/watch?v=UsmqWSZpgJY">Digital Foundry described in their tech breakdown</a>, this is used for a wide range of animations going from large cinematic pieces to small tentacles on the floor. This is especially useful for animations that are hard to achieve using skinned animation like organics and cloth simulation. You can compare an Alembic Cache with a video that can be played back and is highly compressed by looking ahead. I suggest watching <a href="https://www.youtube.com/watch?v=zlz-7V_XiUA">Axel Gneiting’s talk at Siggraph 2014</a> if you’re interested in learning more.</p>

<hr>

<h2 id="shadow-mapping">Shadow Mapping</h2>

<p>Next up is shadow rendering. There doesn’t seem to be any large changes in how shadow maps are approached in id Tech 7 compared to its predecessor.</p>

<p>As seen below, shadows get rendered in a large 4096x8196px 24-bit depth texture which may vary across quality levels. The texture is persistent across frames and as described in “Devil is in the Details” at Siggraph 2016, the static geometry in the shadow map is cached to save having to redraw the shadow maps each frame. The technique is fairly simple: as long as nothing in the view of the light moves, there is no need to update the shadows. If a dynamic object in the frustum moves, a ‘cached’ shadow map is copied into the actual shadow map and the dynamic geometry is re-drawn on top. This cached shadow map is the same shadow map but only with static geometry because you can make the assumption that these will never change. This saves having to draw the entire scene in the frustum every time it needs to update. Of course, when the light moves, the entire scene has to be redrawn from scratch.</p>

<p>When sampling the shadow map during lighting, a 3x3 PCF sampling approach is used to smoothen the shadow edges. For the sun light, <strong>cascaded shadow maps</strong> are used to distribute the quality better as it covers such a large portion of the environment.</p>

<p>Here is a closer look at the shadow atlas. A light with higher importance, larger screen area or that is closer to the camera, will get a larger portion of the atlas assigned for better resolution. These heuristics are evaluated dynamically.</p>

<p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/image3.jpeg" alt=""></p>

<hr>

<h2 id="depth-pre-pass-and-velocity">Depth Pre-pass and Velocity</h2>

<p>Opaque geometry gets rendered to a depth-only target starting with the player’s gun, then static geometry, and finally dynamic geometry. A depth pre-pass is common to avoid unnecessary pixel shader calculations later down the pipeline where geometry overlaps. A depth pre-pass is especially important in a forward renderer where redundant pixel calculations are extremely wasteful due to pixel overdraw. With a depth pre-pass, the actual forward lighting pixel shader can reject pixels by comparing with the depth buffer before execution, saving a lot of performance.</p>

<div id="prepassCarousel" data-ride="carousel">
  <ol>
    <li data-target="#prepassCarousel" data-slide-to="0"></li>
    <li data-target="#prepassCarousel" data-slide-to="1"></li>
    <li data-target="#prepassCarousel" data-slide-to="2"></li>
  </ol>
  <div>
    <div>
      <p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/Prepass0.png"></p><p>First person gun</p>
    </div>
    <div>
      <p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/Prepass1.png"></p><p>Static objects</p>
    </div>
    <div>
      <p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/Prepass2.png"></p><p>Dynamic objects</p>
    </div>
  </div>
  <p><a href="#prepassCarousel" role="button" data-slide="prev">
    
    <span>Previous</span>
  </a>
  <a href="#prepassCarousel" role="button" data-slide="next">
    
    <span>Next</span>
  </a>
</p></div>

<p>Besides rendering depth, the pre-pass also renders to another color target. For dynamic geometry, the velocity is rendered using motion vectors which is the position of the current position subtracted from the position of the pixel in the previous frame. We only need the motion on the X and Y axis so the motion is stored in the red and green channel of a 16-bit floating point render target. This information is later used in post processing for applying motion blur and reprojection for temporal anti-aliasing. The image below is exaggerated because this snapshot doesn’t have a lot of motion. Static geometry does not need motion vectors as their motion can be derived from the camera motion because they have only “moved” relative to the camera.</p>

<p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/image6.jpeg" alt=""></p>

<hr>

<h2 id="hierarchical-z-depth">Hierarchical-Z Depth</h2>

<p>Next up, a hierarchical mip chain of the depth buffer is generated which is similar to a mip map but instead of averaging 4 neighboring pixels, the maximum is taken. This is commonly done in graphics for various purposes like accelerating screen space reflections and occlusion culling. In this case, this mip chain is used to accelerate the light and decal culling which is covered later. More recently, mip generation is done in a single pass by writing into multiple mips at once. In Doom Eternal, it still traditionally does a dispatch for every mip separately.</p>

<p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/image7.gif" alt=""></p>

<hr>

<h2 id="mesh-decals">Mesh Decals</h2>

<p>Up until what I’ve covered so far, there haven’t been many noticeable changes compared to Doom 2016. However, “mesh decals” is an addition to the mesh rendering pipeline introduced in Doom Eternal. Unlike the common decal workflow - which are placed freely in the environment - a mesh decal is placed during the mesh authoring pipeline by artists and so belong to the mesh. Before, Doom heavily relied on decals and stepped it up with the addition of so called “mesh decals” in this game for even better detailing and flexibility. “Mesh decals” are small decals like bolts, grills, bumps, stickers, … Just like a traditional decal, it can modify any property of the underlying surface like the normal, roughness, base color, …</p>

<p>To achieve this, the following geometry pass renders each of the decals’s ID into an 8-bit render target. Later during shading, this texture is sampled to retrieve the ID which is used to retrieve a projection matrix bound with each draw call. The matrix projects the pixel’s position from world space into texture space. These coordinates are then used to sample the decal and blend with the underlying material. This is extremely fast and allows artists to go crazy with massive amounts of decals. Because the IDs are rendered to an 8-bit texture, the maximum amount of decals per mesh would theoretically be 255.</p>

<p>One requirement for this, is that all decals are bound to the pipeline when drawing meshes. Doom Eternal uses a fully bindless render pipeline which allows them to bind all decal textures at once and dynamically index them in the shader. More on this bindless pipeline later as this is important to pull off other tricks they’ve done in this game.</p>

<p>Below, the mesh decal texture. The different IDs are coloured to visualize it better.</p>

<p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/image8.jpeg" alt=""></p>

<hr>

<h2 id="light-and-decal-culling">Light and …</h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html">https://www.simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html</a></em></p>]]>
            </description>
            <link>https://www.simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401805</guid>
            <pubDate>Mon, 07 Sep 2020 19:10:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An quick intro to what's possible with Zapier and Integromat]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24401756">thread link</a>) | @entreprenerd
<br/>
September 7, 2020 | https://www.entreprenerd.blog/live-streams/integrating-apps-with-zapier-and-integromat | <a href="https://web.archive.org/web/*/https://www.entreprenerd.blog/live-streams/integrating-apps-with-zapier-and-integromat">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>No app does it all - but luckily for us non-tech people, you can tie apps together and end up with truly useful automations.</p><p>The four platforms I've been able to find that help tie stuff together are:</p><ul role="list"><li>Zapier (the most common one)</li><li>Integromat (very similar to Zapier but a bit more visual)</li><li>Parabola (specifically useful for moving data)</li><li>IFTTT (mostly for hardware, like Amazon Alexa, Ring, etc.)</li></ul><p>I didn't really test IFTTT (Which stands for If This Then That) - as I don't own much smart home stuff, but it seems like they have a series of pre-built recipes to tie your smart home hardware together.</p><p>But the two main ones are Zapier and Integromat. These things are crazy.<br></p><p>As an example, let's say I run a blog, and I use Webflow/WordPress to host it.</p><p>Let's say I often don't have access to my laptop, but the submission process for my blog articles on Webflow/WordPress only works on desktop.</p><p>With a tool like Zapier, I could connect something more mobile-friendly like Google Forms to my Webflow/WordPress site, and actually write and submit my blog articles from Google Forms.</p><p>Then, let's say I have a newsletter on Mailchimp that I use to notify my audience when I post a new blog article. Usually, I fill in a template and copy-paste the summary info from the blog article into the email, and schedule it for the upcoming Monday. However, with that same Google Form, I could have a series of inputs that cover all the information needed in the newsletter, then send it out directly after I submit the form.</p><p>My whole blog/newsletter process has now been compressed into one single form that I don't even need my laptop to use.<br></p><p>That's a super basic example, but it shows how powerful these tools can be. I eventually want to get to the point where I can create fully functional products out of a subset of smaller apps.<br></p><p>Another common use case is connected databases to front ends. So, for instance, if I had a google sheet with data I wanted to display on my website, I could do that through Zapier. Connect Google Sheet data to Webflow or Wix collection items, and it's done. The updates won't be completely live, but they'll be close.<br></p><p>I would love to hear more use cases for this - obviously, mine are relatively simple - any ideas? Any stories you've heard?</p><p>Also, no pressure, but a retweet would be super amazing. :)</p></div></div>]]>
            </description>
            <link>https://www.entreprenerd.blog/live-streams/integrating-apps-with-zapier-and-integromat</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401756</guid>
            <pubDate>Mon, 07 Sep 2020 19:05:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Doom Eternal Renders a Frame]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24401682">thread link</a>) | @corysama
<br/>
September 7, 2020 | https://simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html | <a href="https://web.archive.org/web/*/https://simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="markdown-content">
            


<p>30 Aug 2020 - Simon Coenen - Reading time: <span title="Estimated read time">
  
  
    23 mins
  
</span><span></span> - <a href="#comment-section">Comments</a>
</p>
<p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/image1.jpeg" alt=""></p>

<h2 id="background">Background</h2>

<p>Doom Eternal is the successor of Doom 2016. It’s developed using the 7th iteration of id Tech, id Software’s in-house game engine. Doom 2016 has inspired me greatly on a technologic level due to its simplicity and elegance while still having a high visual quality. For Doom Eternal, this is no different. Doom Eternal has improved in many areas of which a few are worth investigating which I will try to cover in this frame breakdown.</p>

<!--more-->

<p>This frame breakdown is inspired by <a href="http://www.adriancourreges.com/blog/2016/09/09/doom-2016-graphics-study/">Adrian Courreges’s study on Doom 2016</a>. I believe these graphics studies give a lot of insight into how certain rendering problems are solved in a AAA game and are greatly educational. In this breakdown I aim to stay at a high level and not go too in-depth of each rendering technique/pass. Some passes might not be covered here because they are very similar to Doom 2016 and are well covered in Adrian Courreges’s study.</p>

<p>I do want to stress here that these studies are absolutely nothing more than <strong>educational</strong>. I do not in any way support the reverse engineering for malicious purposes and stealing intellectual property. If you haven’t played the game yet, don’t worry about spoilers! The section I used for this study is in the beginning of the game which doesn’t give away any of the details.</p>

<p>Now, let’s get down to business.</p>

<p>With Id Tech 7, the engine has moved away from OpenGL and is entirely built with a <strong>Vulkan</strong> backend allowing them to make better use of current generation GPU features, bindless resources in particular.</p>

<hr>



<p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/image2.png" alt=""></p>

<p>We’re looking at a section in the game close to the start. It’s an interior with a few enemies and a large portion of volumetric lighting. Just like its predecessor, Doom Eternal is using a <strong>forward rendering</strong> pipeline. Doom 2016 was mostly forward rendered with a thin G-Buffer for screen space reflections. However this time, everything is fully forward rendered omitting the G-Buffer.</p>

<hr>

<h2 id="step-away-from-mega-texture">Step away from Mega-Texture</h2>

<p>With id Tech 5 used in <a href="https://en.wikipedia.org/wiki/Rage_(video_game)">Rage</a>, there was a texture streaming concept introduced called ‘Mega-Texture’ which was also used in the previous Doom installment. This system works by rendering a so called ‘feedback texture’ each frame that contains the information of what texture data was visible, that texture is analysed next frame to determine which textures get streamed in from disk. This has an obvious flaw because once a texture is on screen, it’s basically already too late to load it and this causes blurry textures the first few frames it is on screen. In id Tech 7, id Software has stepped away from this approach.</p>

<hr>

<h2 id="gpu-skinning">GPU Skinning</h2>

<p>The first thing that happens even before anything gets drawn to a texture, is evaluating skinning. This is commonly done in a vertex shader before shading. An alternative approach used here, is to do skinning beforehand in a compute shader which writes out skinned vertices to a buffer. This has a couple of advantages mainly not having to do skinning in the vertex shader for every geometry pass. This results in having less shader permutations because the vertex shader doesn’t have to know about skinning.</p>

<p>Skinning in a compute shader is not much different from in a vertex shader except that the output gets written to an intermediate buffer which can then be consumed in a vertex shader that can treat it as a regular static mesh. Just like in a vertex shader, for each vertex, a compute shader thread retrieves the transform of each bone affecting the vertex, transforms its position with each bone transform and adds up these positions based on the skin weights stored on the vertex.</p>

<p>János Turánszki wrote a wonderful write-up of how it can be implemented using a compute shader:
<a href="https://wickedengine.net/2017/09/09/skinning-in-compute-shader/">https://wickedengine.net/2017/09/09/skinning-in-compute-shader/</a>.</p>

<p>Another thing that is worth noting here is the use of <strong>Alembic Caches</strong> in Doom Eternal. These caches contain baked animation which get streamed and decompressed at runtime. As <a href="https://www.youtube.com/watch?v=UsmqWSZpgJY">Digital Foundry described in their tech breakdown</a>, this is used for a wide range of animations going from large cinematic pieces to small tentacles on the floor. This is especially useful for animations that are hard to achieve using skinned animation like organics and cloth simulation. You can compare an Alembic Cache with a video that can be played back and is highly compressed by looking ahead. I suggest watching <a href="https://www.youtube.com/watch?v=zlz-7V_XiUA">Axel Gneiting’s talk at Siggraph 2014</a> if you’re interested in learning more.</p>

<hr>

<h2 id="shadow-mapping">Shadow Mapping</h2>

<p>Next up is shadow rendering. There doesn’t seem to be any large changes in how shadow maps are approached in id Tech 7 compared to its predecessor.</p>

<p>As seen below, shadows get rendered in a large 4096x8196px 24-bit depth texture which may vary across quality levels. The texture is persistent across frames and as described in “Devil is in the Details” at Siggraph 2016, the static geometry in the shadow map is cached to save having to redraw the shadow maps each frame. The technique is fairly simple: as long as nothing in the view of the light moves, there is no need to update the shadows. If a dynamic object in the frustum moves, a ‘cached’ shadow map is copied into the actual shadow map and the dynamic geometry is re-drawn on top. This cached shadow map is the same shadow map but only with static geometry because you can make the assumption that these will never change. This saves having to draw the entire scene in the frustum every time it needs to update. Of course, when the light moves, the entire scene has to be redrawn from scratch.</p>

<p>When sampling the shadow map during lighting, a 3x3 PCF sampling approach is used to smoothen the shadow edges. For the sun light, <strong>cascaded shadow maps</strong> are used to distribute the quality better as it covers such a large portion of the environment.</p>

<p>Here is a closer look at the shadow atlas. A light with higher importance, larger screen area or that is closer to the camera, will get a larger portion of the atlas assigned for better resolution. These heuristics are evaluated dynamically.</p>

<p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/image3.jpeg" alt=""></p>

<hr>

<h2 id="depth-pre-pass-and-velocity">Depth Pre-pass and Velocity</h2>

<p>Opaque geometry gets rendered to a depth-only target starting with the player’s gun, then static geometry, and finally dynamic geometry. A depth pre-pass is common to avoid unnecessary pixel shader calculations later down the pipeline where geometry overlaps. A depth pre-pass is especially important in a forward renderer where redundant pixel calculations are extremely wasteful due to pixel overdraw. With a depth pre-pass, the actual forward lighting pixel shader can reject pixels by comparing with the depth buffer before execution, saving a lot of performance.</p>

<div id="prepassCarousel" data-ride="carousel">
  <ol>
    <li data-target="#prepassCarousel" data-slide-to="0"></li>
    <li data-target="#prepassCarousel" data-slide-to="1"></li>
    <li data-target="#prepassCarousel" data-slide-to="2"></li>
  </ol>
  <div>
    <div>
      <p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/Prepass0.png"></p><p>First person gun</p>
    </div>
    <div>
      <p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/Prepass1.png"></p><p>Static objects</p>
    </div>
    <div>
      <p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/Prepass2.png"></p><p>Dynamic objects</p>
    </div>
  </div>
  <p><a href="#prepassCarousel" role="button" data-slide="prev">
    
    <span>Previous</span>
  </a>
  <a href="#prepassCarousel" role="button" data-slide="next">
    
    <span>Next</span>
  </a>
</p></div>

<p>Besides rendering depth, the pre-pass also renders to another color target. For dynamic geometry, the velocity is rendered using motion vectors which is the position of the current position subtracted from the position of the pixel in the previous frame. We only need the motion on the X and Y axis so the motion is stored in the red and green channel of a 16-bit floating point render target. This information is later used in post processing for applying motion blur and reprojection for temporal anti-aliasing. The image below is exaggerated because this snapshot doesn’t have a lot of motion. Static geometry does not need motion vectors as their motion can be derived from the camera motion because they have only “moved” relative to the camera.</p>

<p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/image6.jpeg" alt=""></p>

<hr>

<h2 id="hierarchical-z-depth">Hierarchical-Z Depth</h2>

<p>Next up, a hierarchical mip chain of the depth buffer is generated which is similar to a mip map but instead of averaging 4 neighboring pixels, the maximum is taken. This is commonly done in graphics for various purposes like accelerating screen space reflections and occlusion culling. In this case, this mip chain is used to accelerate the light and decal culling which is covered later. More recently, mip generation is done in a single pass by writing into multiple mips at once. In Doom Eternal, it still traditionally does a dispatch for every mip separately.</p>

<p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/image7.gif" alt=""></p>

<hr>

<h2 id="mesh-decals">Mesh Decals</h2>

<p>Up until what I’ve covered so far, there haven’t been many noticeable changes compared to Doom 2016. However, “mesh decals” is an addition to the mesh rendering pipeline introduced in Doom Eternal. Unlike the common decal workflow - which are placed freely in the environment - a mesh decal is placed during the mesh authoring pipeline by artists and so belong to the mesh. Before, Doom heavily relied on decals and stepped it up with the addition of so called “mesh decals” in this game for even better detailing and flexibility. “Mesh decals” are small decals like bolts, grills, bumps, stickers, … Just like a traditional decal, it can modify any property of the underlying surface like the normal, roughness, base color, …</p>

<p>To achieve this, the following geometry pass renders each of the decals’s ID into an 8-bit render target. Later during shading, this texture is sampled to retrieve the ID which is used to retrieve a projection matrix bound with each draw call. The matrix projects the pixel’s position from world space into texture space. These coordinates are then used to sample the decal and blend with the underlying material. This is extremely fast and allows artists to go crazy with massive amounts of decals. Because the IDs are rendered to an 8-bit texture, the maximum amount of decals per mesh would theoretically be 255.</p>

<p>One requirement for this, is that all decals are bound to the pipeline when drawing meshes. Doom Eternal uses a fully bindless render pipeline which allows them to bind all decal textures at once and dynamically index them in the shader. More on this bindless pipeline later as this is important to pull off other tricks they’ve done in this game.</p>

<p>Below, the mesh decal texture. The different IDs are coloured to visualize it better.</p>

<p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/image8.jpeg" alt=""></p>

<hr>

<h2 id="light-and-decal-culling">Light and …</h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html">https://simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html</a></em></p>]]>
            </description>
            <link>https://simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401682</guid>
            <pubDate>Mon, 07 Sep 2020 18:56:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Examples of adapting everyday objects using informal engineering]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24401620">thread link</a>) | @uxamanda
<br/>
September 7, 2020 | http://engineeringathome.org/adaptations | <a href="https://web.archive.org/web/*/http://engineeringathome.org/adaptations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://engineeringathome.org/adaptations</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401620</guid>
            <pubDate>Mon, 07 Sep 2020 18:50:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Elves and a Journey into the DMT Spirit World]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24401502">thread link</a>) | @jelliclesfarm
<br/>
September 7, 2020 | https://doubleblindmag.com/machine-elves-clockwork-elves-dmt-rick-strassman-terence-mckenna/ | <a href="https://web.archive.org/web/*/https://doubleblindmag.com/machine-elves-clockwork-elves-dmt-rick-strassman-terence-mckenna/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
		
<p>The second time he tried DMT, Ali <em>broke through</em>. (His name isn’t actually Ali, but that’s what we’ll call him for privacy’s sake.) The initial onslaught of kaleidoscopic shapes gave way to a more familiar scene: The bedroom, twin mattress and all, from which he embarked on his DMT experience. Only, the room’s features weren’t quite right. They were distorted somehow, like an unfinished rendering—and he had company.&nbsp;</p>



<p>Five silvery beings surrounded him, he describes, their towering, slender bodies cloaked in what can only be described as alien skin (or maybe just gray spandex). But their imposing nature wasn’t the most unusual thing about them; it was their faces. Their faces matched Ali’s friends, who had already been in the room before his DMT experience began.&nbsp;</p>



<div><p>And yet, these entities <em>weren’t</em> just his friends; they were distinctly different. Their faces were jumbled, abstracted, and leaking colored light. Ali had the uncanny sense that these beings were of their own world entirely.</p><p>Ali had journeyed into the spirit world.&nbsp;&nbsp;</p></div>




<h2><span id="What_Are_Clockwork_Elves_Machine_Elves">What Are Clockwork Elves (Machine Elves)?</span></h2>



<p>Dimethyltryptamine (DMT) is a powerful and fast-acting hallucinogen produced naturally by many plants and animals, humans included. (Yes, DMT is found in the <a href="https://www.psypost.org/2019/07/study-provides-evidence-that-dmt-is-produced-naturally-from-neurons-in-the-mammalian-brain-54051">mammalian brain</a>.)&nbsp; In all of 15 minutes, the molecule can inspire a bombardment of visuals that begin with a snow of overwhelming shapes and colors and peaks—if you’re lucky—with an entry into another realm, a step into what feels like a different world.&nbsp;&nbsp;&nbsp;</p>



<p>“It was such sensory overload, it was so dense, that even if I describe it, it doesn’t really give any indication of what [the experience] was actually like,” says Ali. “It felt like [time was] completely arbitrary, kinda scary like maybe you could live like a year in there.”&nbsp;</p>



<p>There’s a reason why DMT has well-earned its nickname as “<a href="https://www.amazon.com/DMT-Molecule-Revolutionary-Near-Death-Experiences/dp/0892819278">the spirit molecule</a>.” For some, the molecule may only inspire intense and awesome visuals. But, many who try DMT do so looking for something, or rather, someone specific—the spirits.&nbsp;</p>



<p>Seeing DMT entities or experiencing some kind of “presence” is a common experience for those who cross a certain dosage threshold with this unusual drug. For Terence McKenna, psychedelic activist and second-wave pioneer, these entities are best described as “self-transforming elf machines.” McKenna is one of the first and loudest activists to speak openly about his (many) DMT experiences.</p><div>
<div>
    <div>
        <section id="email-signup">
            <row>
                <h2>Join Our Community<br>
                </h2>
                                    <h5>Psychedelic news delivered right to your inbox, twice monthly.<br></h5></row>
                                        <row>
                                            
            </row>
        </section>
    </div>
</div></div>




<p>“I encounter self-transforming elf machines, which are creatures, entities perhaps, although they’re not made out of matter,” McKenna <a href="https://www.youtube.com/watch?v=uJjR3aUhsOk">explains in a recorded interview</a>. “They’re made out of, as nearly as I can figure it out, syntax-driving light.” By syntax, McKenna really does mean language.&nbsp;</p>



<p>“They use a language which you <em>see</em>,” he continues. “It is made out of sound, it <em>is</em> sound, but you see it. And the entire point of the encounter, from their perspective, is to teach you to do this.”&nbsp;</p>



<p>Language took on visual quality in Ali’s trip, too. “They were speaking and words were coming out of their mouths, just floating along,” he says. Instead, this mysterious speech drifted out like rainbow-glowing vapors constructed out of an indiscernible rune-like language. “It was like captions coming out of their mouths, very cartoon-like,” he adds. “I felt totally focused on it, like I was going to understand it, but I’m not sure that I ever did.” What Ali did understand was the deep-seated feeling of tranquility that presided despite the intense visualizations. “I felt like I was meditating,” he says. It felt intuitive.</p>




<h3><span id="Why_Are_They_Called_Machine_Elves">Why Are They Called “Machine Elves”?</span></h3>



<p>The answer to this question is simple: They’re called “machine elves” or “clockwork elves” because that is the terminology that McKenna introduced to the world. McKenna’s openness and honesty about his personal experiences on DMT created a pathway that others could eventually use to describe and interpret their own psychedelic experiences. Through his description of “machine elves,” McKenna donated trip terminology that has been widely adopted by psychonauts who follow in his footsteps.&nbsp;</p>



<p>But machine elves are not unique to McKenna; many people who try DMT relate to features the ethnobotanist described in his trips. Geometric shapes, visualized speech, beings, vibrant colors, and sparkling, ethereal light are commonplace in DMT trips. And yet this isn’t always the case; many people may not even remember their DMT visualizations upon waking from their journey.&nbsp;</p>



<h3><span id="What_Do_Machine_Elves_Look_Like">What Do Machine Elves Look Like?&nbsp;</span></h3>



<p>Forget images of gears, steam, computers, and engine parts. For some people, these “machine elves” can be a far cry from the robotic and mechanized creations we commonly see in sci-fi space operas today—DMT spirits can be fractal, or they can be humanoids, animals, faces, or aliens. They can be merely a presiding voice, or simply the feeling of a presence, or anything else the mind can conjure up.&nbsp;&nbsp;&nbsp;</p>



<p>The diversity of the DMT hallucinatory experience was reported early on by famed psychedelic researcher, <a href="https://www.rickstrassman.com/biography/">Dr. Rick Strassman</a>. Strassman is undoubtedly accomplished. He currently holds an associate professorship in psychiatry at the University of New Mexico School of Medicine, but his work and research on DMT span decades. In 2000, he authored the first major book on the hallucinogen, <em>DMT: The Spirit Molecule</em>. Drawing from his <a href="https://maps.org/research-archive/w3pb/1994/1994_Strassman_22714_1.pdf">early research</a>, Strassman tells <em>DoubleBlind, </em>“not that many people in our study saw ‘elves,’ but many saw beings possessing other shapes and forms.”</p>







<p><strong><em>Read: <a href="https://doubleblindmag.com/entheon-dmt-addiction/">This Startup is Developing a DMT-Based Addiction Treatment</a></em></strong></p>







<p>Strassman’s findings are confirmed by more recent research. In 2019, a<a href="https://www.youtube.com/watch?v=bWTT4778IIQ&amp;t=910s"> small study of DMT users</a> found that, more often than not, when consumers did see DMT elves, they didn’t look like elves at all. Rather, most entities appeared more amorphous and hard to describe. The study was performed by <a href="https://stockton.edu/social-behavioral-sciences/sobl-faculty-staff.html">Dr. Jennifer Lyke</a>, professor of psychology at Stockton University, who surveyed the popular site Erowid for common descriptions of DMT deities.&nbsp;</p>



<p>In a much larger study published in the <em>Journal of Psychopharmacology</em>, a research team led by Alan Davis <a href="https://journals.sagepub.com/doi/pdf/10.1177/0269881120916143">gathered and analyzed survey data</a> from a grand total of 2,561 different DMT consumers about their best experiences with the hallucinogen. In this study, only 10 to 16 percent of respondents used terms like “angel” or “elf” to describe DMT entities. Instead, words like “being” and “guide” were far more common. Although, it’s important to mention that the vast majority of the study participants were white, male, and Western. In Lyke’s study, 90 percent of the respondents were male.&nbsp;</p>



<h3><span id="What_Do_DMT_Elves_Do">What Do DMT Elves Do?</span></h3>



<div><p>While the visualizations inspired by DMT are certainly noteworthy, it’s the spiritual qualities of the trip that are perhaps the most impactful—and no one can articulate this impact better than Strassman. “The function of the beings is to communicate, and what they communicate is information,” he says. “Their shape or form may contain that information, but more importantly, there is an exchange, a relationship between the observer and the beings, sometimes verbal, sometimes nonverbal. Then it’s up to our mind, our intellect, to decipher the communication, to extract meaning from it.”</p><p>Strassman’s interpretation is supported by data pooled from recent surveys, like the Davis study. According to Davis’ study, most consumers interact with DMT spirits via emotional, intuitive, and telepathic means. These clockwork elves often <em>feel</em> real, like the arbiters of a deep, true, and hidden truth. Many report that experiencing them is a hallmark or life-changing experience, with notable impact on mood, wellbeing, and life outlook.&nbsp;</p></div>



<p>In Davis’ study, an impressive majority of psychonauts reported feelings of love, trust, kindness, and joy both coming from themselves and the perceived spirit entities. A large majority of people also reported that they felt like the entities had intelligence, a consciousness of their own. Most felt that they were sacred, that they existed in their own world, and that they had a message to deliver. Over half of those who had identified as atheists before the DMT experience no longer identified as such afterward.&nbsp;</p>







<blockquote><p>Over half of those who had identified as atheists before the DMT experience no longer identified as such afterward.&nbsp;</p></blockquote>







<p>But, Davis and his team aren’t the only scientists to find that DMT can have a positive impact on life outlook. A 2018 study suggested that <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5869920/">combining frequent Ayahuasca sessions with mindfulness therapy </a>increased participants’ capacity for acceptance, a key component of mental health. Another study from 2015 found that a single dose of ayahuasca <a href="https://pubmed.ncbi.nlm.nih.gov/25806551/?dopt=Abstract">successfully improved mood in six patients with recurrent depression,</a> even 21 days after treatment. DMT is one of the primary active compounds in the hallucinogenic drink. Although, freebasing DMT, like Ali did, produces a notably different psychoactive experience.&nbsp;</p>



<p>And of course, this isn’t to say that everyone will have a positive DMT trip. A good number of people may not enter the “spirit realm.” Nor is there any guarantee that experiencing DMT entities will have spiritual significance. For many people, DMT hallucinations may actually be quite frightening. The Davis survey found that 41 percent of consumers felt fear during their experience. A total of 23 percent reported that they felt that the beings had an authoritative presence, 16 percent felt negatively judged by the beings, and 11 percent felt maliciousness—not to mention, how these experiences may be compounded by the health, safety, and legal hazards of experimenting with Schedule I substances.</p>



<p>Even Ali experienced some …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://doubleblindmag.com/machine-elves-clockwork-elves-dmt-rick-strassman-terence-mckenna/">https://doubleblindmag.com/machine-elves-clockwork-elves-dmt-rick-strassman-terence-mckenna/</a></em></p>]]>
            </description>
            <link>https://doubleblindmag.com/machine-elves-clockwork-elves-dmt-rick-strassman-terence-mckenna/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401502</guid>
            <pubDate>Mon, 07 Sep 2020 18:38:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ireland Lacrosse sacrifice place in 'Medicine Game' tournament for greater good]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24401498">thread link</a>) | @bryanrasmussen
<br/>
September 7, 2020 | https://www.rte.ie/sport/other-sport/2020/0905/1163463-iroquois-nationals-lacrosse-ireland-world-games/ | <a href="https://web.archive.org/web/*/https://www.rte.ie/sport/other-sport/2020/0905/1163463-iroquois-nationals-lacrosse-ireland-world-games/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody" data-epic-field="content">
<p>Getting one over on your opponent is the norm in sports, stepping aside for the greater good is a rare occurrence.</p>
<p>The International World Games is due to take place in Alabama&nbsp;in the summer of 2022, but Ireland's lacrosse team, despite having qualified,&nbsp;won't be there.&nbsp;</p>
<p>The Games, which aim to showcase and provide a pathway to the Olympics for sports&nbsp;who want to take the next step,&nbsp;were supposed to be held&nbsp;next year&nbsp;but the coronavirus pandemic pushed it back.</p>
<p>Ireland had secured a select invite to the men’s tournament, which is&nbsp;run as&nbsp;an abbreviated version of the full game, with six players per team instead of the usual 10.</p>
<p>Only eight teams, based on finishing places at the 2018 World Championships, were picked to take part and Ireland was among that number.&nbsp;</p>
<p>And we have all seen in recent years what gold runs can do for minority sports&nbsp;on the island, creating profiles and stars and careers.&nbsp;</p>
<p>The whole country rowed in behind the O’Donovan brothers when they pulled like dogs in Rio in 2016.</p>
<p>The Green Army swelled in numbers when&nbsp;Graham Shaw’s side, against all odds, reached the&nbsp;2018 Women's Hockey World Cup&nbsp;final.</p>
<p>Fair weather fans, band-wagon hoppers&nbsp;and Johnny-come-latelys&nbsp;all welcome as the sports built up their profiles on a world stage, encouraging young and not so young to give them a try.&nbsp;</p>
<p>Ireland&nbsp;Lacrosse CEO Michael Kennedy&nbsp;says&nbsp;the team&nbsp;"punch above their weight" on the international stage so a&nbsp;decent run in a small-field tournament was not beyond the bounds of possibility.&nbsp;</p>
<p>But they’ve just handed away their golden ticket.</p>
<p>There are more important things, reckons Kennedy, than&nbsp;just playing the sport they love, especially not at the expense of another, more deserving brother.&nbsp;</p>
<p>The reason?&nbsp;The&nbsp;Iroquois Nationals, having placed third in the same tournament from which Ireland qualified,&nbsp;were originally deemed&nbsp;ineligible&nbsp;to compete.</p>
<p>Who, you might ask, are the&nbsp;Iroquois Nationals?&nbsp;</p>
<p>Well, the sport itself originated among the Mohawk, Cayuga,&nbsp;Onondaga, Seneca, Oneida and Tuscarora Nations, collectively known as the&nbsp;Haudenosaunee&nbsp;Confederacy&nbsp;in the northeastern United States.</p>
<p>They compete in international lacrosse as the Iroquois Nationals.&nbsp;</p>
<p><img alt="" src="https://img.rasset.ie/00152323-614.jpg?ratio=1.5"></p>
<p>They believe that the game is a "medicine", a&nbsp;gift from the Creator, played for his enjoyment,&nbsp;for healing.&nbsp;</p>
<p>They are the soul of the sport, says Kennedy, and for a men’s lacrosse tournament, making its debut in the World Games, to go ahead without&nbsp;the Iroquois Nationals was not something they could allow.</p>
<p>International World Games&nbsp;organisers&nbsp;initially excluded them on the grounds that they were not&nbsp;a sovereign&nbsp;nation,&nbsp;without an Olympic Committee and therefore could not compete.&nbsp;</p>
<p>That upset the lacrosse community across the world and it&nbsp;prompted&nbsp;Kennedy and Ireland Lacrosse to make the ultimate sacrifice, moving aside once the association indicated that decision would be changed if a place could be found for the&nbsp;Iroquois.</p>
<p>"There's something special about lacrosse," Kennedy tells RTÉ Sport.</p>
<p>"It originated with&nbsp;Native&nbsp;American&nbsp;Indians, the&nbsp;Iroquois.</p>
<p>"They are the spiritual&nbsp;part of the game and they say that they received the game from the Creator, it's something&nbsp;special&nbsp;to have that connection.</p>
<p>"There was so much more to be gained for the sport as a whole than for Ireland to gain from that one tournament.&nbsp;It was the right decision to pull out to enable the&nbsp;Iroquois&nbsp;to take part."</p>
<figure><img alt="" src="https://img.rasset.ie/00152327-614.jpg?ratio=1.25">
<figcaption>Michael Kennedy and Oren Lyons, a key member of the Iroquois leadership</figcaption>
</figure>
<p>But it's a decision that comes with a cost for Ireland, who won't benefit from the publicity that they would have gained during the tournament.&nbsp;</p>
<p>"That was running through our minds when we were considering this," he says but&nbsp;felt it was worth the short-term pain for the good of the game.&nbsp;</p>
<p>Have they considered, as one administrator from&nbsp;a different sporting body did once, of asking to be added to the tournament? Not a 33rd team in this case, but a ninth team.&nbsp;</p>
<p>"That has been a topic of conversation between ourselves and World Lacrosse," he says.&nbsp;</p>
<p>"We've been in constant discussions but part of the issue is that it isn’t World Lacrosse that make that decision. It’s the International World Games Association.</p>
<p>"Our sport is targetting&nbsp;the LA Games in 2028. We are the rookie at the table in this event and trying to upset the apple cart by making all&nbsp;kinds of additional requests is a little tricky.</p>
<p>"We&nbsp;would be open to it if&nbsp;World Lacrosse wants to go down that path that would be great for us but we don’t want to push it."</p>
<p><img alt="" src="https://img.rasset.ie/00152328-614.jpg?ratio=0.87"></p>
<p>For their part World Lacrosse spokesman Darryl Seibel told RTÉ Sport that Ireland's gesture was "emblematic of the very best ideals of international sport", while the IWGA did not respond.&nbsp;</p>
<p>Ireland may not get in as the ninth team, or rake in a load of cash for not pestering anyone about it, but there's a chance that karma will come into play when the University of Limerick hosts the 2021 Lacrosse Men's U20 World&nbsp;Championship, originally an U19 tournament supposed to be played last July.&nbsp;</p>
<p>"There is so much more for us to gain from that event that playing in the 6s in America," says Kennedy.&nbsp;</p>
<p>"Iroquois&nbsp;leadership is extremely grateful and they want to know how they can help us.</p>
<p>"We want to increase the number of native&nbsp;American&nbsp;teams that come to Limerick next summer."</p>
<p>The Iroquois Nationals Board told RTÉ Sport: "We plan to bring more teams and fans to the tournament and the accompanying festival.</p>
<p>"We look forward to plenty of craic in Limerick next summer, and continuing to build the strong bond we have with Ireland Lacrosse.</p>
<p>"Words do not do justice in expressing the depth of our appreciation for the tremendous sacrifice of Ireland Lacrosse.</p>
<p>"Their genuine concern, empathy, and selflessness demonstrates a true understanding of the ideals of our Medicine Game.&nbsp;</p>
<p>"We are honored to share the world lacrosse stage with our Irish brethren, and we are especially excited about being part of the [tournament in Ireland]."&nbsp;</p><blockquote>
<div><p>To <a href="https://twitter.com/IrelandLacrosse">@IrelandLacrosse</a>,</p><p>

You have gone above and beyond not only for us, but for what you believe is right.<br>
Your actions have spoken louder than words showing everyone the true power of sport, and the spirit of lacrosse.</p><p>

We will never forget that.<br>
I dteannta a chéile<a href="https://twitter.com/hashtag/TogetherAsOne">#TogetherAsOne</a> <a href="https://t.co/qmDSYauaM5">pic.twitter.com/qmDSYauaM5</a></p></div>
— IROQUOIS NATIONALS LACROSSE (@IRQ_Nationals) <a href="https://twitter.com/IRQ_Nationals/status/1301556056913477632">September 3, 2020</a></blockquote>
<p>It may well be a case of the goodwill Ireland Lacrosse has engendered coming back in spades and perhaps they'll get a taste of their own medicine.&nbsp;</p>
 </section></div>]]>
            </description>
            <link>https://www.rte.ie/sport/other-sport/2020/0905/1163463-iroquois-nationals-lacrosse-ireland-world-games/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401498</guid>
            <pubDate>Mon, 07 Sep 2020 18:38:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keep Chrome Debugger window always on top – OS X]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24401380">thread link</a>) | @bebrws
<br/>
September 7, 2020 | https://bradbarrows.com/post/chromedevtools | <a href="https://web.archive.org/web/*/https://bradbarrows.com/post/chromedevtools">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><article><div><h2>Keep your Chrome Dev Tools Debugger on top of all windows on OSX Catalina</h2><p><img alt="An animated gif of the usage of these scripts" src="https://bradbarrows.com/static/ChromeDevToolsOnTop.gif"></p><p>I was getting tired of having to search for my Chrome Dev Tools Debugger window and thought I would see how hard it would be to write a dylib I could
add as a dylib load instruction eventually to my Google Chrome binary.</p><p>I eventually will make a script and dylib that does all this but for now I wrote a quick frida-cycript script to take care of this.</p><h3>Issues I encountered</h3><p>So for some reason.. sometimes.. I can't use 
<code>[NSApplication shared]</code>
to get a reference to the main application. I am not sure why this is for some programs.</p><p>One way I thought of around this is to just use the heap!</p><p>Here we will search for all NSApplication instances in the heap and grab the last one we find (there should only be one).</p><pre><code>ObjC.choose(ObjC.classes.NSApplication, {
    onMatch: function (aarg) {
        a = aarg;
    },      
    onComplete: function () {    
        console.log('Done searching for NSApplication.');    
    }      
});  </code></pre><p>I did a similar trick with this script since I couldn't do a NSApplication.windows or mainWindow or keyWindow on Google Chrome without it crashing:</p><pre><code>var ws=[];
ObjC.choose(ObjC.classes.NSWindow, {
    onMatch: function (aarg) {
        ws.push(aarg);
    },      
    onComplete: function () {    
        console.log('done');    
    }      
});  </code></pre><p>Just creates a list of all the Windows.</p><p>I then checked out the class names and titles one by one.</p><p>I noticed that Chrome will crash when I even check the title of some of these windows so I had to write my filter functions in a specific order.</p><p>Then I set the window level to always be on top finally.</p><p>The code is below:</p><pre><code>var ws=[];
ObjC.choose(ObjC.classes.NSWindow, {
    onMatch: function (aarg) {
        ws.push(aarg);
    },      
    onComplete: function () {    
        console.log('done');    
    }      
});  

var possibleWindows = ws.filter((w) =&gt; w.className().toString() === "NativeWidgetMacNSWindow")
var devToolWindows = possibleWindows.filter((w) =&gt; w.title().toString().includes("DevTools"))
devToolWindows.forEach((w) =&gt; {
    w.setLevel_(9);
});</code></pre><h3>To use:</h3><p>Run:</p><pre><code>function toppid() { ps -ef | grep $1 | grep -v grep | awk '{ if (NR == 1) print $2 }'  }
sudo cycript -p `toppid "Google Chrome.app"` keepDevToolsOnTop.cy</code></pre><p>NOTE:</p><ul><li>Requires SIP be disabled</li><li><a href="https://github.com/nowsecure/frida-cycript/releases">frida-cycript</a> installed </li></ul></div></article></div></div></section></div>]]>
            </description>
            <link>https://bradbarrows.com/post/chromedevtools</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401380</guid>
            <pubDate>Mon, 07 Sep 2020 18:24:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scientists predict unprecedented magnitude of mammal extinctions in near future]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24401354">thread link</a>) | @makerofspoons
<br/>
September 7, 2020 | https://www.ctvnews.ca/sci-tech/scientists-predict-unprecedented-magnitude-of-mammal-extinctions-in-near-future-1.5094250?taid=5f547ae6ca23fc0001228169&utm_campaign=trueAnthem%3A+Trending+Content&utm_medium=trueAnthem&utm_source=twitter | <a href="https://web.archive.org/web/*/https://www.ctvnews.ca/sci-tech/scientists-predict-unprecedented-magnitude-of-mammal-extinctions-in-near-future-1.5094250?taid=5f547ae6ca23fc0001228169&utm_campaign=trueAnthem%3A+Trending+Content&utm_medium=trueAnthem&utm_source=twitter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>TORONTO -- 
	Scientists have examined fossil records from the past 126,000 years and predict an “unprecedented magnitude” of mammal extinctions in the near future.</p>
<p>
	A <a href="https://advances.sciencemag.org/content/6/36/eabb2313" target="_blank">new study</a> from the U.S. journal Science Advances looked into the impact humans had on past and present extinction of mammals. Researchers found that human population size in many parts of the world will “undoubtedly pose a serious challenge for the future conservation of biodiversity."</p>
<p>
	Researchers suggest that human activity is almost entirely to blame for the extinctions of mammals in past decades, and will likely be the cause of at least 558 extinctions within the next century.</p>
<p>
	“By the year 2100, we predict all areas of the world to have entered a second wave of extinctions,” the study says. “We find that Australia and the Caribbean in particular have already today entered the second extinction wave [...] we can already see these future scenarios being manifested in parts of the world.”</p>
<p>
	Despite the findings, scientists say there is still a window of opportunity to prevent many species from going extinct by improving conservation efforts.</p>
<p>
	The International Union for the Conservation of Nature (IUCN) currently has more than 120,000 species on their red list of threatened species. Many conservation successes have taken place in recent years, with some species moving toward less threatened IUCN categories.</p>
<p>
	The Ethiopian wolf and giant Chinese pandas are two species who have benefited greatly from renewed conservation efforts and public awareness campaigns, according to the IUCN. In Ethiopia, conservationists have been working to preserve the wolf’s existing habitat, and in China, a number of large-scale initiatives have been implemented to protect the panda's main source of food, bamboo. The number of pandas has since increased and&nbsp;<a href="https://www.theverge.com/2016/9/6/12816588/giant-pandas-endangered-vulnerable-iucn-list" target="_blank">the species has moved from endangered to vulnerable</a>.</p>
<p>
	Researchers say they hope their alarming predictions will “foster increased realization on the urgency and scale of the conservation efforts needed to safeguard the future of mammalian diversity.”</p>
<p>
	According to the IUCN, more than 32,000 are currently threatened with extinction.&nbsp;</p>
                                              </div></div>]]>
            </description>
            <link>https://www.ctvnews.ca/sci-tech/scientists-predict-unprecedented-magnitude-of-mammal-extinctions-in-near-future-1.5094250?taid=5f547ae6ca23fc0001228169&amp;utm_campaign=trueAnthem%3A+Trending+Content&amp;utm_medium=trueAnthem&amp;utm_source=twitter</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401354</guid>
            <pubDate>Mon, 07 Sep 2020 18:21:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Configs for privacy-hating software, like Firefox and Chrome]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24401340">thread link</a>) | @vital303
<br/>
September 7, 2020 | http://r-36.net/scm/privacy-haters | <a href="https://web.archive.org/web/*/http://r-36.net/scm/privacy-haters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://r-36.net/scm/privacy-haters</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401340</guid>
            <pubDate>Mon, 07 Sep 2020 18:19:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Kubernetes: A single OAuth2 proxy for multiple ingresses]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24401287">thread link</a>) | @theykk
<br/>
September 7, 2020 | https://www.callumpember.com/Kubernetes-A-Single-OAuth2-Proxy-For-Multiple-Ingresses/ | <a href="https://web.archive.org/web/*/https://www.callumpember.com/Kubernetes-A-Single-OAuth2-Proxy-For-Multiple-Ingresses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="article" id="scroll" itemprop="articleBody">
                <p>One of the problems most Kubernetes administrators will eventually face is protecting an Ingress from public access. There are a number of ways to do this, including IP whitelisting, TLS authentication, use an internal only service for the ingress controller, and many more.</p>

<p>One of my favorite ways is to use <a href="https://github.com/pusher/oauth2_proxy">oauth2_proxy</a>. I’ve used it a number of times over the years, but there was always a drawback that bothered me - with the <a href="https://github.com/kubernetes/ingress-nginx/tree/master/docs/examples/auth/oauth-external-auth">documented setup</a> and other countless examples online, they use a deployment of the oauth2_proxy container per deployment/service/ingress that the user is wanting to protect. Although the resource footprint of oauth2_proxy is small, that is needless waste.</p>

<p>Now, onto some oauth2_proxy details. You can use various different providers, like GitHub, Google, GitLab, LinkedIn, Azure and Facebook. What’s one thing nearly every developer in the world has in common? They almost certainly have a GitHub account, so that’s what I use as a provider normally.  There are some strict rules though around GitHub OAuth2 and redirection:</p>

<p><img src="https://www.callumpember.com/assets/attachments/github-oauth2/github-oauth-redirection-rules.png" alt="GitHub OAuth2 Redirection rules"></p>

<p>What this means is that if you are using oauth2_proxy as-is, you need a separate deployment for each domain you want to secure.</p>

<blockquote>
  <p>But I want to secure https://prometheus.mydomain.com, https://grafana.mydomain.com and https://alertmanager.mydomain.com. So I need separate deployments of oauth2_proxy for that?</p>
</blockquote>

<p>Out of the box, sadly yes. But with a slight modification of the deployment, we can use a single oauth2_proxy instance for any domain we want. To do this we do the following:</p>

<ul>
  <li>Attach an nginx sidecar container to the oauth2_proxy deployment. This container will redirect to anything after <code>/redirect/</code> in the request URI.</li>
  <li>Make the oauth2_proxy have it’s own domain</li>
  <li>Add an upstream to oauth2_proxy for the /redirect path</li>
  <li>Set the cookie domain in oauth2_proxy to include all subdomains</li>
  <li>Setup a GitHub OAuth2 app and point it at the oauth2_proxy domain</li>
  <li>In the ingresses that we want to protect, use the following annotations (replace $DNS_ZONE_INTERNAL with your own domain):</li>
</ul>

<figure><pre><code data-lang="yaml"><span>---</span>
<span>nginx.ingress.kubernetes.io/auth-url</span><span>:</span> <span>"</span><span>https://oauth2.$DNS_ZONE_INTERNAL/oauth2/auth"</span>
<span>nginx.ingress.kubernetes.io/auth-signin</span><span>:</span> <span>"</span><span>https://oauth2.$DNS_ZONE_INTERNAL/oauth2/start?rd=/redirect/$http_host$request_uri"</span></code></pre></figure>

<h3 id="oauth2_proxy-deployment">oauth2_proxy deployment:</h3>

<p>Here is a full, working (at least in my cluster) deployment spec for oauth2_proxy with the nginx sidecar.</p>

<p>If you want to use it, you’d need to replace all the variables. I personally use envsubst in my deployment pipelines for this. The variables that need replacing are <code>$DNS_ZONE_INTERNAL</code> <code>$OAUTH2_CLIENT_ID</code> <code>$OAUTH2_CLIENT_SECRET</code> and you would want to set your GitHub org.</p>

<p><a href="https://www.callumpember.com/assets/attachments/github-oauth2/full-deployment.yml.txt">Full Deployment Spec</a></p>

<h3 id="ingress-example">Ingress example</h3>

<p>Once you’ve got the deployment above working, you can protect an ingress like so (key takeaways are the annotations):</p>

<figure><pre><code data-lang="yaml"><span>---</span>

<span>apiVersion</span><span>:</span> <span>extensions/v1beta1</span>
<span>kind</span><span>:</span> <span>Ingress</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>prometheus</span>
  <span>namespace</span><span>:</span> <span>istio-system</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>prometheus</span>
  <span>annotations</span><span>:</span>
    <span>kubernetes.io/ingress.class</span><span>:</span> <span>"</span><span>nginx-public"</span>
    <span>nginx.ingress.kubernetes.io/auth-url</span><span>:</span> <span>"</span><span>https://oauth2.$DNS_ZONE_INTERNAL/oauth2/auth"</span>
    <span>nginx.ingress.kubernetes.io/auth-signin</span><span>:</span> <span>"</span><span>https://oauth2.$DNS_ZONE_INTERNAL/oauth2/start?rd=/redirect/$http_host$escaped_request_uri"</span>
<span>spec</span><span>:</span>
  <span>rules</span><span>:</span>
  <span>-</span> <span>host</span><span>:</span> <span>"</span><span>prometheus.$DNS_ZONE_INTERNAL"</span>
    <span>http</span><span>:</span>
      <span>paths</span><span>:</span>
      <span>-</span> <span>path</span><span>:</span> <span>/</span>
        <span>backend</span><span>:</span>
          <span>serviceName</span><span>:</span> <span>prometheus</span>
          <span>servicePort</span><span>:</span> <span>http</span></code></pre></figure>

<p>Hopefully this saves you some resources in your cluster and some time creating multiple oauth2_proxy deployments!</p>

            </article></div>]]>
            </description>
            <link>https://www.callumpember.com/Kubernetes-A-Single-OAuth2-Proxy-For-Multiple-Ingresses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401287</guid>
            <pubDate>Mon, 07 Sep 2020 18:11:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bootstrap: Sleek, intuitive, and Retro]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24401266">thread link</a>) | @behnamoh
<br/>
September 7, 2020 | https://kristopolous.github.io/BOOTSTRA.386/index.html | <a href="https://web.archive.org/web/*/https://kristopolous.github.io/BOOTSTRA.386/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  <div>

    
    <p>Need reasons to love Bootstrap? Look no further.</p>

    <div>
      <div>
        <h2>By nerds, for nerds.</h2>
        <p>Built at Twitter by <a href="http://twitter.com/mdo">@mdo</a> and <a href="http://twitter.com/fat">@fat</a>, Bootstrap utilizes <a href="http://lesscss.org/">LESS CSS</a>, is compiled via <a href="http://nodejs.org/">Node</a>, and is managed through <a href="http://github.com/">GitHub</a> to help nerds do awesome stuff on the web.</p>
      </div>
      <div>
        <h2>Made for everyone.</h2>
        <p>Bootstrap was made to not only look and behave great in the latest desktop browsers (as well as IE7!), but in tablet and smartphone browsers via <a href="https://kristopolous.github.io/BOOTSTRA.386/scaffolding.html#responsive">responsive CSS</a> as well.</p>
      </div>
      
    </div>

    <hr>

    
    <p>For even more sites built with Bootstrap, <a href="http://builtwithbootstrap.tumblr.com/" target="_blank">visit the unofficial Tumblr</a> or <a href="https://kristopolous.github.io/BOOTSTRA.386/getting-started.html#examples">browse the examples</a>.</p>
    

  </div>

</div></div>]]>
            </description>
            <link>https://kristopolous.github.io/BOOTSTRA.386/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401266</guid>
            <pubDate>Mon, 07 Sep 2020 18:08:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Polyglot Code Explorer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24401227">thread link</a>) | @derkoe
<br/>
September 7, 2020 | https://blog.korny.info/2020/09/06/introducing-the-polyglot-code-explorer.html | <a href="https://web.archive.org/web/*/https://blog.korny.info/2020/09/06/introducing-the-polyglot-code-explorer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main"><article>
<header>

<time>Sep  6 2020</time>
</header>
<p><img src="https://blog.korny.info/2020-09-01-polyglot-explorer/main_ui_sample.png" alt="Main UI"></p>

<p><em>If you want a quick look at the explorer, you can see <a href="http://polyglot-code-explorer.s3-website.eu-west-2.amazonaws.com/">a simple demo here</a> or <a href="http://polyglot-code-explorer-openmrs.s3-website.eu-west-2.amazonaws.com/">a more complex one here</a>.  There is also a documentation site at  <a href="https://polyglot.korny.info/">https://polyglot.korny.info</a> (currently a work-in-progress).</em></p>

<h2 id="welcome-to-the-polyglot-code-explorer">Welcome to the Polyglot Code Explorer</h2>

<p>The Polyglot Code Explorer is an open-source tool for visualising complex codebases written in multiple programming languages.</p>

<p>In this article I am going to explain its purpose, how you can run it yourself, and what it does.</p>

<h2 id="what-is-it-for">What is it for?</h2>

<p>Fundamentally, I wanted to answer the question:</p>

<blockquote>
  <p>How can we visualise large codebases without needing complex language-specific parsers and logic?</p>
</blockquote>

<p>Partly I wanted to easily spot toxic code - my colleague <a href="https://erik.doernenburg.com/2013/06/toxicity-reloaded/">Erik Dörnenberg wrote some great articles on Toxic code visualisation</a> and I wanted a way to spot some of these problem areas myself.</p>

<p>But also, I just wanted to be able to explore the code quickly.  I'm a visual thinker, so my main focus is on visualisation - especially when trying to spot patterns in millions of lines of code.</p>

<p>It is far quicker for me to look at a diagram and see some unusual colouring in one area, than to see the same information in a table of numbers.</p>

<h3 id="why-polyglot">Why polyglot?</h3>

<p>Polyglot means "speaking multiple languages" - in this case, it means these tools should work, to some degree, for any text-based programming language.</p>

<p>I've worked in many programming languages over the years, and a lot of them don't have good or easy code quality tools - either they are too new for a community to have built them, or they are from ancient projects where even if such tools exist, getting them up and running is a headache.  And each tool probably produces different metrics in different formats - it's hard to get any sort of big-picture view.</p>

<p>Also many real world systems don't use a single language - often it is better to use specialist languages for different tasks, rather than one general-purpose one.  For example one project might have a UI built in JavaScript and HTML, a microservice built in Kotlin and a platform automation tool build in Rust.</p>

<p>Also I was inspired by reading Adam Tornhill's book <a href="https://www.goodreads.com/book/show/23627482-your-code-as-a-crime-scene">"Your code as a crime scene"</a> - he talks about all the things you can learn from really simple metrics like lines of code, and indentation, and change history.  None of these need a complex language parser - and complex language parsers tend to be touchy and flaky.  Most of my code uses no language parser at all, or just a very simple which can distinguish code from comments.</p>

<p>And finally - supporting all the various languages out there is a lot of work!  Quite a few of the other tools I found linked from Erik's articles, and elsewhere, seem to have parsers for a number of languages - but progress is slow, and often they don't keep up with new languages or language changes.  Staying largely language-agnostic makes it much easier for me to maintain my code, and not have to worry about it stagnating.</p>

<h2 id="how-to-run-the-explorer">How to run the Explorer</h2>

<p>The explorer is actually the front end component of three tightly coupled applications:</p>

<p><img src="https://blog.korny.info/2020-09-01-polyglot-explorer/flowchart.png" alt="Tools flowchart"></p>

<ul>
  <li>The Polyglot Code Scanner is a rust application, which scans the source code and produces a JSON data file</li>
  <li>The Polyglot Code Offline Layout tool is a node.js script which adds layout information to the JSON data file</li>
  <li>The Polyglot Code Explorer is a react/D3 web app which provides the user interface for exploring the code</li>
</ul>

<p>The code is open source, you can find it on GitHub:</p>

<ul>
  <li><a href="https://github.com/kornysietsma/polyglot-code-scanner">https://github.com/kornysietsma/polyglot-code-scanner</a></li>
  <li><a href="https://github.com/kornysietsma/polyglot-code-offline-layout">https://github.com/kornysietsma/polyglot-code-offline-layout</a></li>
  <li><a href="https://github.com/kornysietsma/polyglot-code-explorer">https://github.com/kornysietsma/polyglot-code-explorer</a></li>
</ul>

<blockquote>
  <p>I should add a disclaimer - I am not a rust guru, and I am definitely not a react guru!  This is side project code, not commercial-quality - it may well have bugs, mistakes, ugliness, and it has far less testing than I'd usually expect :)</p>
</blockquote>

<p>You may prefer to run these tools from source code - not all the executables have been tested on all platforms! There are some <a href="https://polyglot.korny.info/tools/explorer/howto">more detailed how-to guides on the docs site</a> if you want to build them yourself, or need more details than the brief instructions below.</p>

<h3 id="getting-the-executable-files">Getting the executable files</h3>

<p>Each of the tools is packaged up as an executable file - the Scanner is written in rust, so it's easy to just compile a binary.  The Layout app is a node.js script, I've used <a href="https://www.npmjs.com/package/pkg">pkg</a> to build a bundled executable.  And the Explorer can be run as a static website, so the packages are a zipped up bundle of all files needed to build the website, which you can run yourself.</p>

<ul>
  <li>Scanner executables can be downloaded from <a href="https://github.com/kornysietsma/polyglot-code-scanner/releases">https://github.com/kornysietsma/polyglot-code-scanner/releases</a></li>
  <li>Layout executables can be downloaded from <a href="https://github.com/kornysietsma/polyglot-code-offline-layout/releases">https://github.com/kornysietsma/polyglot-code-offline-layout/releases</a></li>
  <li>Explorer bundles can be downloaded from <a href="https://github.com/kornysietsma/polyglot-code-explorer/releases">https://github.com/kornysietsma/polyglot-code-explorer/releases</a></li>
</ul>

<p>If you are on a Mac you will need to strip Apple's quarantine attributes from the binary files to avoid the "app is from an unknown developer" error:</p>

<div><pre><code><span>tar </span>zxf polyglot-code-scanner-vwhatever-x86_64-apple-darwin.tar.gz
<span>cd </span>polyglot-code-scanner-vwhatever-x86_64-apple-darwin
xattr <span>-d</span> com.apple.quarantine polyglot_code_scanner

unzip polyglot-code-offline-layout-macos.zip
xattr <span>-d</span> com.apple.quarantine polyglot-code-offline-layout
</code></pre></div>
<p>The Explorer is not an executable file - it's a zip file containing the HTML, CSS and JavaScript files needed to run the site.  You can run them locally by running a tiny web server yourself using Python - <a href="https://developer.mozilla.org/en-US/docs/Learn/Common_questions/set_up_a_local_testing_server">there are more detailed instructions here</a> or there's a big list of similar servers in other languages <a href="https://gist.github.com/willurd/5720255">here</a> - I'll use Python 3 below.</p>

<h3 id="running-them">Running them</h3>

<p>A short sample of running these together might help:</p>

<div><pre><code><span>$ </span><span>cd</span> ~/work
<span>$ </span>polyglot_code_scanner <span>--coupling</span> <span>--years</span> 3 <span>-o</span> my_project_1.json ~/src/my_project
<span># this can be slow for big projects, or if you scan back through many years of history</span>
<span># coupling is optional, remove --coupling to speed it up if you don't want it</span>
<span># Check there are no errors and the my_project_1.json file is there</span>

<span>$ </span>polyglot-code-offline-layout <span>-i</span> my_project_1.json <span>-o</span> my_project_2.json
<span># this can be slow for big files</span>
<span># Check there are no errors and the my_project_2.json file is there</span>

<span># the first time, you need to unzip the explorer files</span>
<span>$ </span>unzip ~/downloads/polyglot-code-explorer.zip
Archive:  polyglot-code-explorer.zip
   creating: polyglot-code-explorer/
<span>$ </span>cp my_project_2.json polyglot-code-explorer/data/default.json
<span>$ </span><span>cd </span>polyglot-code-explorer
<span>$ </span>python3 <span>-m</span> http.server
Serving HTTP on 0.0.0.0 port 8000 <span>(</span>http://0.0.0.0:8000/<span>)</span>
</code></pre></div>
<p>Then open a browser to <a href="http://0.0.0.0:8000/">http://0.0.0.0:8000</a> to start exploring!</p>

<h2 id="using-the-ui">Using the UI</h2>

<p>The Explorer front end looks somewhat like this:</p>

<p><img src="https://blog.korny.info/2020-09-01-polyglot-explorer/Main_UI.png" alt="Main UI"></p>

<p>There is more about how to use the UI <a href="http://localhost:2222/tools/explorer/ui">on the docs site</a></p>

<p>The centre of the display shows the files in your project - I'm using a <a href="https://en.wikipedia.org/wiki/Weighted_Voronoi_diagram">Weighted Voronoi Diagram</a> which has the big advantage of showing files roughly in proportional to their size.  And by size I'm using lines of code, which is generally much more useful than bytes - especially as research tends to show that high lines of code is correlated with complexity and defects - so just looking for large lines of code is a good starting point for finding problems.</p>

<h3 id="viewing-by-programming-language">Viewing by programming language</h3>

<p><img src="https://blog.korny.info/2020-09-01-polyglot-explorer/vis_language.png" alt="language visualisation"></p>

<p>This view is very simple - it just colours each file by programming language, showing the 10 most common languages.  Mostly useful for getting an overview of what goes where - it's usually easy to spot the front-end vs back-end code by the colours used.  (only 10 languages are shown because beyond that, it's hard to visually see different colours)</p>

<h3 id="lines-of-code">Lines of code</h3>

<p><img src="https://blog.korny.info/2020-09-01-polyglot-explorer/vis_loc.png" alt="lines of code"></p>

<p>This view is simple enough - it uses a scale from blue for tiny files, through to yellow for giant files.</p>

<p>Note that this is not a linear scale - a lot of these use what I call a "Good/Bad/Ugly" scale - blue (0) is good, red (1000) is bad, and yellow (10000 and above) is just ugly.  If I used a linear scale, it'd be harder to distinguish the good/bad files from each other.  (yes, I could use a log scale, but that has it's own problems)</p>

<h3 id="indentation">Indentation</h3>

<p><img src="https://blog.korny.info/2020-09-01-polyglot-explorer/vis_indentation.png" alt="indentation"></p>

<p>This metric is an interesting one. In <a href="https://doi.org/10.1109/ICPC.2008.13">Hindle, Abram, Michael W. Godfrey, and Richard C. Holt. 2008. ‘Reading Beside the Lines: Indentation as a Proxy for Complexity Metric’</a> they found that indentation is often useful as a way of looking for complexity - which makes common sense; files with a lot of indentation are often files with deeply nested "if" and "case" statements.  You can choose a few sub-visualisations using the drop-down near the top-left - the default shows the standard deviation of indentation, which is often the most useful metric; you can also see the worst indentation in each file, and the "total area" which is useful for showing files which are both large and deeply indented.</p>

<p>Of course this metric can have false positives - heavy indentation might be due to a particular formatting style for long lines, or an actually valid data structure, or other valid reasons.  But it is often surprisingly useful.</p>

<h3 id="age-since-last-change">Age since last change</h3>

<p><img src="https://blog.korny.info/2020-09-01-polyglot-explorer/vis_age.png" alt="age since last change"></p>

<p>This view shows how long it is since each file was changed (from git history) - blue files are recently changed, red files haven't changed in a year, yellow files haven't changed in 4 years.  Note that this is affected by the date selector down the bottom of the page:</p>

<p><img src="https://blog.korny.info/2020-09-01-polyglot-explorer/date_selector.png" alt="date selector"></p>

<p>Files that haven't changed at all in the selected date range will show in grey.  You need to select the whole project (drag the left side of the selector to the left of the screen) to see change information across the whole scanned date range.</p>

<p>This is a good/bad/ugly scale again, largely because generally files that haven't changed for a long time are, in my experience, parts of the system that nobody understands or feels safe to touch.</p>

<p>However this is a bit contentious - it depends a lot on the culture of the organisation, and the kind of code - a lot of research in this field shows the flip-side of this, that files that haven't changed for ages are stable. If they had bugs, people would have touched them …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.korny.info/2020/09/06/introducing-the-polyglot-code-explorer.html">https://blog.korny.info/2020/09/06/introducing-the-polyglot-code-explorer.html</a></em></p>]]>
            </description>
            <link>https://blog.korny.info/2020/09/06/introducing-the-polyglot-code-explorer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401227</guid>
            <pubDate>Mon, 07 Sep 2020 18:03:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google One blocks transnational families]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24401097">thread link</a>) | @alangibson
<br/>
September 7, 2020 | https://landshark.io/2020/09/06/google-one-blocks-transnational-families.html | <a href="https://web.archive.org/web/*/https://landshark.io/2020/09/06/google-one-blocks-transnational-families.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p>Here’s one for the Unfortunate Error Message hall of fame.</p>

<p><img src="https://landshark.io/assets/2020-09-06-google-one-bans-separated-families/no-family-for-you.png" width="400"></p>

<p>I got this while trying to add my wife (who is not from the USA) to my Google One storage plan. Apparently Google never counted on family members living in different countries.</p>

<p>I see this as a rather embarassing example of Conway’s Law. Our family structure isn’t compatible with the structure of Google’s business, so no family plan for us.</p>

<p>Hey Google: things are complicated outside of Mountain View. Try putting a little more effort into covering us edge cases. Don’t make us pay for your convenience.</p>


</div></div>]]>
            </description>
            <link>https://landshark.io/2020/09/06/google-one-blocks-transnational-families.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401097</guid>
            <pubDate>Mon, 07 Sep 2020 17:45:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HTML Tags You Probably Didn't Know]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24400936">thread link</a>) | @Sandeepg33k
<br/>
September 7, 2020 | https://jatinrao.dev/12-html-tags-you-dont-know | <a href="https://web.archive.org/web/*/https://jatinrao.dev/12-html-tags-you-dont-know">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1599487255172/h-E8UqMpi.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>HTML (Hyper Text Markup Language) is used to design web pages using a  combination of Hypertext and Markup language.</p>
<p>In this post, we're going to take a look at some cool stuff that can be done using HTML. Let's look at some of the html tags, you might not be knowing even existed.
ould be making use of today.</p>
<p>Let's get started 💪</p>
<hr>
<h2 id="1-the-lessfiguregreater-tag">1. The <code>&lt;figure&gt;</code> tag</h2>
<p>This can be used to mark up a photo. The <code>&lt;figure&gt;</code> element can also contain a <code>&lt;figcaption&gt;</code>.</p>
<pre><code><span>&lt;<span>figure</span>&gt;</span>
  <span>&lt;<span>img</span> <span>src</span>=<span>"https://images.unsplash.com/photo-1593642634315-48f5414c3ad9"</span> <span>alt</span>=<span>"Person using lack laptop computer on brown wooden table"</span> <span>style</span>=<span>"width:100%"</span>&gt;</span>
  <span>&lt;<span>figcaption</span>&gt;</span>Person using lack laptop computer on brown wooden table<span>&lt;/<span>figcaption</span>&gt;</span>
<span>&lt;/<span>figure</span>&gt;</span>
</code></pre>
<h2 id="2-the-lessaudiogreater-tag">2. The <code>&lt;audio&gt;</code> tag</h2>
<p>⁣<code>&lt;audio&gt;</code> element provides a way to add audio resources to a web page without the need to use any other plugin.⁣ It's used to play a sound much as music or an audio stream. It supports mp3, wav and ogg.
⁣
A fallback text is enclosed within the tag to be shown to browsers that don't support the element.⁣
⁣
By default, the browser does not show any controls. ⁣
To add the ability for users to play, pause, adjust volume, etc. the 'controls' attribute can be used.</p>
<pre><code><span>&lt;<span>audio</span> <span>controls</span>&gt;</span>
  <span>&lt;<span>source</span> <span>src</span>=<span>"music.mp4"</span> <span>type</span>=<span>"audio/mp4"</span>&gt;</span>
  <span>&lt;<span>source</span> <span>src</span>=<span>"mucis.ogg"</span> <span>type</span>=<span>"audio/ogg"</span>&gt;</span>
<span>&lt;/<span>audio</span>&gt;</span>
</code></pre>
<h2 id="3-the-lessvideogreater-tag">3. The <code>&lt;video&gt;</code> tag</h2>
<p>This allows you to embed a media player for video playback. 
It's used to play a video clop or a video stream without embedding youtube or vimeo videos. It supports mp4, webm and ogg.</p>
<p>For example, you can upload your video on AWS S3 and use the <code>&lt;video&gt;</code> tag to embed it on your website.</p>
<p>You can also specify certain attributes, such as width, height, autoplay, loop, controls, etc.</p>
<pre><code><span>&lt;<span>video</span> <span>width</span>=<span>"960"</span> <span>height</span>=<span>"540"</span> <span>controls</span>&gt;</span>
  <span>&lt;<span>source</span> <span>src</span>=<span>"video.mp4"</span> <span>type</span>=<span>"video/mp4"</span>&gt;</span>
  <span>&lt;<span>source</span> <span>src</span>=<span>"video.ogg"</span> <span>type</span>=<span>"video/ogg"</span>&gt;</span>
<span>&lt;/<span>video</span>&gt;</span>
</code></pre>

<h2 id="4-the-lessprogressgreater-tag">4. The <code>&lt;progress&gt;</code> tag</h2>
<p>The <code>&lt;progress&gt;</code> tag represents the progress of a task.</p>
<p>The <code>&lt;progress&gt;</code> tag should not be confused with the <code>&lt;meter&gt;</code> tag (which represents a gauge). It has two attributes value and max.⁣⁣</p>
<pre><code><span>&lt;<span>progress</span> <span>value</span>=<span>"57"</span> <span>max</span>=<span>"100"</span>&gt;</span>
<span>&lt;/<span>progress</span>&gt;</span>
</code></pre>

<h2 id="5-the-lessmetergreater-tag">5. The <code>&lt;meter&gt;</code> tag</h2>
<p>You can use the meter element to measure data within a given range (a gauge).</p>
<p>This can be achieved with min and max values or with a percentage.</p>
<pre><code><span>&lt;<span>meter</span> <span>value</span>=<span>"7"</span> <span>min</span>=<span>"0"</span> <span>max</span>=<span>"10"</span>&gt;</span>7 out of 10<span>&lt;/<span>meter</span>&gt;</span>

<span>&lt;<span>meter</span> <span>value</span>=<span>"0.4"</span>&gt;</span>40%<span>&lt;/<span>meter</span>&gt;</span>
</code></pre>

<h2 id="6-the-lessdatagreater-tag">6. The <code>&lt;data&gt;</code> tag</h2>
<p>It specifies the machine-readable translation of the content of the element. It also provides a human-readable text.</p>
<pre><code><span>&lt;<span>ul</span>&gt;</span>
  <span>&lt;<span>li</span>&gt;</span>
    <span>&lt;<span>data</span> <span>value</span>=<span>"010"</span>&gt;</span>Dogs<span>&lt;/<span>data</span>&gt;</span>
  <span>&lt;/<span>li</span>&gt;</span>
  <span>&lt;<span>li</span>&gt;</span>
    <span>&lt;<span>data</span> <span>value</span>=<span>"011"</span>&gt;</span>Cats<span>&lt;/<span>data</span>&gt;</span>
  <span>&lt;/<span>li</span>&gt;</span>
<span>&lt;/<span>ul</span>&gt;</span>
</code></pre>
<h2 id="7-the-lessdatalistgreater-tag">7. The <code>&lt;datalist&gt;</code> tag</h2>
<p>⁣The <code>&lt;datalist&gt;</code> tag is used to provide autocomplete feature in the input field of the form.⁣
⁣
It specifies the set of predefined suggestions for the user to input.⁣</p>
<pre><code><span>&lt;<span>input</span> <span>type</span>=<span>"text"</span> <span>list</span>=<span>"days"</span> <span>placeholder</span>=<span>"Choose a Day"</span>&gt;</span>
<span>&lt;<span>datalist</span> <span>id</span>=<span>"days"</span>&gt;</span>
  <span>&lt;<span>option</span> <span>value</span>=<span>"Monday"</span>&gt;</span><span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span> <span>value</span>=<span>"Tuesday"</span>&gt;</span><span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span> <span>value</span>=<span>"Wednesday"</span>&gt;</span><span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span> <span>value</span>=<span>"Thursday"</span>&gt;</span><span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span> <span>value</span>=<span>"Friday"</span>&gt;</span><span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span> <span>value</span>=<span>"Saturday"</span>&gt;</span><span>&lt;/<span>option</span>&gt;</span>
  <span>&lt;<span>option</span> <span>value</span>=<span>"Sunday"</span>&gt;</span><span>&lt;/<span>option</span>&gt;</span>
<span>&lt;/<span>datalist</span>&gt;</span>
</code></pre>

<h2 id="8-the-lessnoscriptgreater-tag">8. The <code>&lt;noscript&gt;</code> tag</h2>
<p>The content inside the <code>&lt;noscript&gt;</code> element is rendered by the browser only when JavaScript is disabled. It provides a fallback mechanism for the components that will stop working without JavaScript.</p>
<pre><code><span>&lt;<span>noscript</span>&gt;</span><span>&lt;<span>h2</span>&gt;</span>JavaScript is disabled in your browser.<span>&lt;/<span>h2</span>&gt;</span><span>&lt;/<span>noscript</span>&gt;</span>
</code></pre>
<h2 id="9-the-lessdetailgreater-tag">9. The <code>&lt;detail&gt;</code> tag</h2>
<p>The <code>&lt;⁣detail&gt;</code> tag is used to make collapsible sections when it is required to provide extra information about a subject that users can hide or view by their choice.
⁣
It uses the <code>&lt;summary&gt;</code> tag which specifies the title that can be clicked to expand or collapse the details.⁣</p>
<pre><code><span>&lt;<span>details</span>&gt;</span>
  <span>&lt;<span>summary</span>&gt;</span>Click To Open<span>&lt;/<span>summary</span>&gt;</span>
  Hey, I am natively collapsable section. My content remains hidden till you click on summary.
<span>&lt;/<span>details</span>&gt;</span>
</code></pre>

<h2 id="10-the-lesswbrgreater-tag">10. The <code>&lt;wbr&gt;</code> tag</h2>
<p>The <code>&lt;wbr&gt;</code> tag stands for word break 🍞 opportunity which is used when a word is too long, and you don't want the browser to break it at the random place,  helps to break the word where you want.⁣</p>
<pre><code><span>&lt;<span>p</span>&gt;</span>This is a lonnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnngggggggggggggggggggggggggggggggggggggggggg<span>&lt;<span>wbr</span>&gt;</span>word.<span>&lt;/<span>p</span>&gt;</span>
</code></pre>
<h2 id="11-the-lessmarkgreater-tag">11. The <code>&lt;mark&gt;</code> tag</h2>
<p><code>&lt;mark&gt;</code> is a very simple and useful native tag used to add some nice highligting in your webpage without any CSS. </p>
<pre><code><span>&lt;<span>p</span>&gt;</span>HTML can do <span>&lt;<span>mark</span>&gt;</span> MAGIC <span>&lt;/<span>mark</span>&gt;</span>.<span>&lt;/<span>p</span>&gt;</span>
</code></pre>

<h2 id="12-the-lessinsgreater-and-lessdelgreater-tag">12. The <code>&lt;ins&gt;</code> and <code>&lt;del&gt;</code> tag</h2>
<p><code>&lt;ins&gt;</code> element indicates text that has been added to the document.⁣⁣
<code>&lt;del&gt;</code> is used for the text that has been deleted from the document.⁣⁣</p>
<pre><code><span>&lt;<span>p</span>&gt;</span>Jatin is a
  <span>&lt;<span>del</span>&gt;</span>spider man<span>&lt;/<span>del</span>&gt;</span>
  <span>&lt;<span>ins</span>&gt;</span>web developer<span>&lt;/<span>ins</span>&gt;</span>
  from India.
<span>&lt;/<span>p</span>&gt;</span>
</code></pre>

<hr>
<h2 id="references">References</h2>
<ul>
<li><p><a target="_blank" href="https://dev.to/ananyaneogi/html-can-do-that-c0n">HTML can do that?</a> by <a target="_blank" href="http://twitter.com/_ananyaneogi">Ananya Neogi</a></p>
</li>
<li><p><a target="_blank" href="https://dev.to/emmabostian/10-html-element-you-didnt-know-you-needed-3jo4">10 HTML Elements You Didn't Know You Needed</a> by <a target="_blank" href="http://twitter.com/EmmaBostian">Emma Bostian</a></p>
</li>
<li><p><a target="_blank" href="https://htmlreference.io/">HTML Reference</a> for overview of various HTML tags.</p>
</li>
</ul>
<hr>
<p>You can also connect with me on <a target="_blank" href="https://discord.gg/3Ks7sMA">Discord</a> .</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://jatinrao.dev/12-html-tags-you-dont-know</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400936</guid>
            <pubDate>Mon, 07 Sep 2020 17:24:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Soft Skills for Managers]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24400840">thread link</a>) | @hackitup7
<br/>
September 7, 2020 | https://staysaasy.com/product/2020/09/06/soft-skills-for-managers.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/product/2020/09/06/soft-skills-for-managers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Many of the hard technical skills that make a great manager are testable. You can easily evaluate technical expertise – for example, an engineering manager should demonstrate their ability to produce or at least understand code. Similarly, in-depth discussions will quickly reveal whether someone can clearly and concisely communicate nuanced concepts.</p>

<p>The softer skills of management are more difficult to assess but just as important. Below are a few of the soft skills that I value most highly in managers, some ideas on how to assess them, and common traps.</p>

<h2 id="soft-skill-1-initiative">Soft Skill #1: Initiative</h2>

<p>Managers set the tempo for their teams – if they aren’t actively looking for ways to help the business, they will set an example that being proactive is optional. The sad truth is that once you’re a manager you can survive a long time by simply maintaining existing processes, reacting to personnel issues, or (worse) creating busywork and taking credit. Many managers collect fine paychecks drifting like an inert gas within a broader bureaucratic cloud. To scale a company effectively, managers need to be proactive rather than existing simply to push virtual papers across their desks.</p>

<p>Initiative tends to be pretty obvious when evaluating internal management candidates. For external candidates, I usually ask deep-dive questions about a meaty project from their past. The goal: learn about what they did, their role, and most importantly the “why” behind their decisions, diving into the details of what really went down. A sample prompt: “Tell me about a significant project that you led, and I’ll ask a bunch of questions to dive deeper.” This is usually fun to ask and I expect to learn something new from strong candidates – after all, they know much more than I do about the project they worked on, so if they can’t teach me something that’s a red flag.</p>

<p>Searching for the “why” behind their decisions is a good test for initiative – being able to explain why certain decisions were made indicates that a candidate can think critically about what a project actually needs, rather than just executing on someone else’s plan.</p>

<h2 id="soft-skill-2-emotional-control">Soft Skill #2: Emotional Control</h2>

<p>Management can be stressful, <a href="https://staysaasy.com/scaling/2020/05/07/startup-is-this-normal.html">especially at a high growth startup company</a>. You’re the first point of escalation for all manner of problems: inter- or intra-team conflict, critical last-minute blockers, HR issues, and other corporate delights. You don’t have a safety net to fall back on if a situation gets too heated – you are the safety net.</p>

<p>Managers can’t be emotionally reactive. They need to remain rational even in the face of severe stressors, allowing them to remain unflappable when shit goes down (more calm also comes with experience). Sometimes, the downsides of reacting are minor: if someone says something dumb during a presentation and you visibly scowl, you can cause them to get flustered. Others are much more important: for example, if someone comes into a 1:1 very upset over their compensation, you need to remain calm as it can be disastrous to make promises or comments that could be misconstrued.</p>

<p>This skill is challenging to assess when hiring managers. Unlike in, say, the Marine Corps, it’s frowned upon in the tech industry to throw someone into a stressful situation and assess their emotional control. References are imperfect but can help, and this skillset is one of the reasons that internal manager candidates can be such tempting known quantities.</p>

<p>The very best managers take this a step further and demonstrate durability – the ability to not only exercise control, but to do so repeatedly over months and emerge on the other side energized and positive. High growth companies are challenging, and more significantly, they’re challenging <a href="https://staysaasy.com/scaling/2020/07/29/the-rogue-wave-of-enterprise-saas.html">over a very long time</a> – typically years. People who are a consistent force for optimistic calm are the pillars around which you should build your team.</p>

<h2 id="soft-skill-3-dispassionate-empathy">Soft Skill #3: Dispassionate Empathy</h2>

<p>Managers need dispassionate empathy: the ability to logically breakdown how their teams will react to new situations by viewing things from multiple perspectives – without allowing viewpoints that they’re sympathetic to cloud their judgment. If someone on your team is passed over for a promotion that goes to their teammate, how will they react? If someone gets really tough feedback, how will they handle it? Managers need to be able to assess factors such as incentives and egos as they chart a course for their entire team.</p>

<p>Promotions provide a common example: when you promote someone you’re affirming the behaviors that you will reward (as well as other behaviors that you tolerate…), and everyone else on the team will observe, calculate, and react differently according to their own interpretation. If you promote Alice, will her peer Bob freak out that it was unfair, become apathetic, or work harder? What message will it send to their more junior team member Charlie?</p>

<p>Empathizing with others’ viewpoints dispassionately is surprisingly difficult as there’s little in day-to-day life that prepares you for it. When a friend or family member is in a difficult situation, they’re typically looking for empathy without reservations, and we’re trained as primates to deliver it. Mirroring the emotions of people we’re close to is often a feature, not a bug. Many managers need to fight the urge to over-empathize.</p>

<p>I assess this trait in interviews by asking about challenging situations that occurred on a prior team. Examples include:</p>

<ul>
  <li>Tell me about a time that someone asked for something (eg a raise or promotion), and you didn’t give it to them.</li>
  <li>Tell me about a time when a member of your team was in conflict with a member of another team, and you needed to help out.</li>
  <li>Tell me about a time that someone on your team was underperforming.</li>
</ul>

<p>In asking about these scenarios, I’m first looking for the candidate’s ability to articulate the different motivations or incentives involved: do they understand the situation? Did they view it through others’ eyes rather than just their own? I also assess their ability to discuss the situation in a calm way: are they getting emotionally biased?</p>

<p>While emotional life isn’t as cut and dried as a Python script, I find that most great managers can break down situations like an algorithm: look at all of the different incentives and personalities on the team, add a new decision or situation, and guess at what will happen next.</p>

<h2 id="the-soft-skill-trap">The Soft Skill Trap</h2>

<p>Especially for internal candidates for management positions, beware the most common soft skill trap: mistaking a likeable personality for leadership or management aptitude.</p>

<p>It’s easy to misinterpret a gregarious, likeable personality for innate management skill. “Timmy is a ‘people person’ – of course he’ll be able to manage a team!” This is simply not how life works. Timmy might be great as a manager, or he might suck, but in my experience his likeability is unlikely to correlate strongly with the soft skills that matter.</p>

<p>I blame this phenomenon on Hollywood’s stereotypical portrayal of what it means to be a “leader.” Many great managers are gregarious, sociable, and charismatic, but many others are introverted, quiet in group settings, or somewhat socially awkward. I’ve met managers whom I actually somewhat disliked in a social capacity but who were extremely effective at their jobs. However, I have yet to meet a great manager who didn’t take initiative, couldn’t regulate their own emotions, and didn’t understand the incentives that would motivate their team.</p>

<p><img src="https://staysaasy.com/assets/soft_skills/gladiator.jpg" alt="Gladiator">
Good leader overall, but perhaps too much shouting for your average tech company</p>

<p>There’s also a potential element of bias here: does someone seem like they should be in a leadership position just because they’re really confident? Do they feel like they should be in charge because they’re often the loudest voice in the room? These sorts of subjective judgements are also minefields for bias. For a random example, some of the behaviors that say “leader” in American culture scream “jerk” in East Asian culture. I highly recommend assessing management potential according to the dimensions listed above and trying to remove likeability or sociability from your decision calculus.</p>

<h2 id="takeaways">Takeaways</h2>
<ul>
  <li>Great management requires both hard and soft skills. Soft skills are often harder to assess.</li>
  <li>When assessing a manager’s soft skills, look for the following traits: initiative, emotional control, and an ability to understand how others will perceive and react to situations.</li>
  <li>Promoting from within is a great way to remove manager hiring risk.</li>
  <li>Don’t mistake sociability for management skill.</li>
</ul>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/product/2020/09/06/soft-skills-for-managers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400840</guid>
            <pubDate>Mon, 07 Sep 2020 17:13:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Post-Open Source]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24400738">thread link</a>) | @hodgesrm
<br/>
September 7, 2020 | https://www.boringcactus.com/2020/08/13/post-open-source.html | <a href="https://web.archive.org/web/*/https://www.boringcactus.com/2020/08/13/post-open-source.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <p>i’m writing this like a day after <a href="https://www.fastcompany.com/90539632/mozilla-vows-mdn-isnt-going-anywhere-as-layoffs-cause-panic-among-developers">big mozilla layoffs</a> that included a lot of people working on cool and important shit.
the consensus i’m seeing is that it reflects mozilla’s search for profit over impact, mismanagement, and disproportionate executive compensation.
this is taking place in a larger trend of corporatization of open source over the past several years, an ongoing open source sustainability crisis, and of course COVID-19, the all-consuming crisis that makes all our other crises worse.
all of this was summed up most concisely by <a href="https://twitter.com/zkat__/status/1293626135142477825">Kat Marchán</a>:</p>

<blockquote>
  <p>Imo, open source as a community endeavor is falling apart right before our eyes, and being replaced by open source as Big Corp entrenchment strategy.</p>

  <p>I mean it’s been happening for a while, but seeing Mozilla sinking like this is just driving the point home for me.</p>

  <p>FOSS is dead</p>
</blockquote>

<p>how did we get here?
where even are we?
what happens next?</p>

<p>i am incredibly unqualified to answer any of this - i didn’t show up until right around the peak of SourceForge, i wasn’t there for most of this - but i’m not gonna let that stop me.</p>

<h2 id="names">names</h2>

<p>to start this funeral service for FOSS, we have to unpack the term itself.
“free and open source software” as a term already contains multitudes.
on one hand, “free software”, an explicitly political movement with a decidedly anti-charismatic leader.
on the other hand, “open source software”, defanged and corporate-friendly by design.
the free software people (correctly) criticize “open source” as milquetoast centrism.
the open source people (correctly) criticize “free software” as stubborn idealism fighting tooth and nail to reject the real world as it actually exists.
they have as much in common as leftists and liberals (but they’re more prepared to work together), and although their short-term goals were similar enough that it made sense to lump them together (hence the cooperation), now that the movement is dead i think there’s more to gain from considering them separately.
most software licenses that i’m going to bring up technically qualify as both, but they’re popular with one or the other, so i’ll refer to “free software licenses” and “open source licenses” as licenses that are more directly tied to those movements, even though any given license likely meets both definitions.</p>

<p>i’d say free software died a while ago, and open source went horribly right.</p>

<h2 id="freedom">freedom</h2>

<p>the free software movement, for all its faults, has always known <a href="https://www.gnu.org/philosophy/free-sw.html.en">what it’s about</a>:</p>

<blockquote>
  <ol>
    <li>The freedom to run the program for any purpose.</li>
    <li>The freedom to study how the program works, and change it to make it do what you wish.</li>
    <li>The freedom to redistribute and make copies so you can help your neighbour.</li>
    <li>The freedom to improve the program, and release your improvements (and modified versions in general) to the public, so that the whole community benefits.</li>
  </ol>
</blockquote>

<p>it’s concise, it’s understandable, and it’s… kinda useless.
this point was <a href="https://lu.is/blog/2016/03/23/free-as-in-my-libreplanet-2016-talk/">raised better by actual lawyer Luis Villa</a> (Karl Marx slander notwithstanding), but those freedoms don’t actually mean shit to the average end user.
only programmers care if they have access to the source code, and most people aren’t programmers.
and i <em>am</em> a programmer, and i don’t give a shit.
the freedom to not think about my operating system and just get work done overrules all of those for me, so i use windows.
like, yeah, those things are all in principle nice to have, and between two otherwise equally good programs i’d take the free one.
but they’re really fuckin specific things, and even if i have the freedom to do them i’m not likely to have the ability or desire to do them, so there’s no good reason for me as a user to use software that’s worse in other ways because it gives me freedoms i don’t need.</p>

<p>the free software movement is explicitly political, but its politics suck.
it’s a movement by and for ideological diehards but the ideology is extremely esoteric.
theirs was a losing battle from day one.
so what was it that actually killed them?
i think in a very real way it was the GPLv3.</p>

<h2 id="losing">losing</h2>

<p>the flagship projects of the free software movement are probably Linux and the GNU pile of tools.
the Linux kernel being released under a free software license doesn’t directly create more free software, though, since even things that tie closely to the kernel aren’t obligated to also be free software, and of course user-level applications can have whatever license they want.
and also most of the people using Linux right now are using it by accident, distributed as ChromeOS or Android, neither of which is free software.
so Linux is a win for the free software movement but a useless one.</p>

<p>the GNU userland tools are, for the most part, even more underwhelming.
it may be technically more accurate to call it GNU/Linux, but the only time i remember my linux userland tools are GNU or free software at all is when there’s <a href="https://twitter.com/boring_cactus/status/1166408436386430976">some weird inconsistency between a GNU tool and its BSD equivalent</a>, and that’s not exactly ideal.
gcc had, as far as i can tell, been basically <em>the</em> C compiler for a while, if you weren’t stuck with MSVC or something worse.
the free software movement were stubborn ideologues with weird priorities, but they still had one big technical advantage.
then the GPLv3 happened.</p>

<p>the GPLv2 was pretty popular at the time, but there were a couple notable loopholes some big corporations had been taking advantage of, which the free software people wanted to close.
a whole bunch of people thought the GPLv2 was fine the way it was, though - closing the loopholes as aggressively as the GPLv3 did cut off some justifiable security measures, and some people said that it could do more harm than good.
the linux kernel, along with a lot more stuff, declared it was sticking with the GPLv2 and not moving to the GPLv3.
when your movement says “here is the new version of The Right Way To Do Things” and several of your largest adherents say “nah fuck you we’re going with the old version” that is not a good sign.
around the same time, free software organizations were starting to successfully sue companies who were using free software but not complying with the license.
so big companies, like Apple, saw new restrictions coming in at the same time as more aggressive enforcement, and said “well shit, we want to base our software on these handy convenient tools like GCC but we can’t use GPLv3 software while keeping our hardware and software as locked together as we’d like.”
so they started pouring money into a new C compiler, LLVM, that was instead open source.</p>

<p>and LLVM became at least as good as GCC, and a less risky decision for big companies, and easier to use to build new languages.
so the free software movement’s last technical advantage was gone.
its social advantages also kinda went up in flames with the GPLv3, too: the software that was the foundation for the GPL enforcement lawsuits stuck with the GPLv2.
the discourse over that decision was so nasty that the lead maintainer (Rob Landley; he’ll come up later) started an identical project which he wound up relicensing under an open source license because the lawsuits had completely backfired: instead of complying with the terms of the GPL, companies were just avoiding GPL software.</p>

<p>the free software movement, in the end, burned itself out, by fighting for a tiny crumb of success and then turning around and lighting that success on fire.
the death of free software tells us that we can’t use a license to trick corporations into sharing our values: they want to profit, and if good software has a license that puts a limit on how much they can do that, they’ll put more resources into writing their own alternative than they would spend complying with the license in the first place.</p>

<h2 id="openness">openness</h2>

<p>the open source movement manages to share the same short term goals as the free software movement but be bad in almost entirely disjoint ways.
the <a href="https://opensource.org/about">mission of the Open Source Initiative</a> says</p>

<blockquote>
  <p>Open source enables a development method for software that harnesses the power of distributed peer review and transparency of process.
The promise of open source is higher quality, better reliability, greater flexibility, lower cost, and an end to predatory vendor lock-in.</p>
</blockquote>

<p>this is so profoundly different from the free software definition that it’s almost comical.
where free software says “we value freedom, which we define in these ways,” open source says “your code will get better.”
the free software movement was prepared to start fights with corporations that used their work but didn’t play by their rules.
the open source movement was invented to be a friendly, apolitical, pro-corporate alternative to the free software movement.</p>

<p>the contrast between “use free software because it preserves your freedom” and “use open source software because it’s better” is profound and honestly a little disappointing to revisit this explicitly.
free software preserves freedoms i don’t need or care about as a user, but it does at least do that.
open source software is frequently not in fact better than closed source alternatives, and “use open source software because on rare occasions it manages to be almost as good” is an even more underwhelming sales pitch than anything free software can give.</p>

<p>where free software is misguided and quixotic, open source is spineless and centrist.
and as tends to happen with spineless centrism, it has eaten the world.</p>

<h2 id="winning">winning</h2>

<p>if there’s anything corporations love more than rewriting software so it lets them make all the money they can dream of, it’s letting other people do that work for them.
it took a while to take off, because the conservative approach of “keep things closed source” was pretty solidly entrenched in a lot of places, but now even the once conservative holdouts have accepted the gospel of centrism.
corporations have little to nothing to lose by publishing existing source code, and can gain all sorts of unpaid volunteer labor.
if they start a new internal project, important enough that they’re …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.boringcactus.com/2020/08/13/post-open-source.html">https://www.boringcactus.com/2020/08/13/post-open-source.html</a></em></p>]]>
            </description>
            <link>https://www.boringcactus.com/2020/08/13/post-open-source.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400738</guid>
            <pubDate>Mon, 07 Sep 2020 16:58:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Got an Offer at Facebook, Turned It Down, and Moved On]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24400606">thread link</a>) | @iuliangulea
<br/>
September 7, 2020 | https://iuliangulea.com/blog/how-i-got-an-offer-at-facebook-turned-it-down-and-went-on/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/blog/how-i-got-an-offer-at-facebook-turned-it-down-and-went-on/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    
    <p><img src="https://iuliangulea.com/images/offer-from-fb-cover.png" alt="Cover Image"></p>
<p>Software Engineering (SWE) is among the most desired jobs nowadays. It is a vibrant and dynamic domain that changed the way we do things, and that improved our lifestyle. It has its own peculiarities, though, with holy wars between groups of people who argue which programming language is better, with haters of JavaScript, scripting languages, and dynamically typed languages, with complete assholes as well as some very nice and considerate people (although this is not related only to SWE).</p>
<p>Even with a global pandemic, software engineers’ workstyle changed only a little. There are many benefits to working as a software engineer, as well as there are downsides. But this article is not about the perks and drawbacks—you can find a myriad of posts on that subject.</p>
<p>There are lots of questions and answers online about how to get into one of the FAANG (facebook, amazon, apple, netflix, google) companies. This article is my experience and some recommendations.</p>
<h2 id="briefly-about-me">Briefly About Me</h2>
<p>I am a Full Stack Software Engineer with 10+ years of experience and a keen interest (and 8+ years of experience) in Data Visualization. I am a freelancer on <a href="https://toptal.com/">Toptal</a>, and currently, I work for PepsiCo.</p>
<p>My main stack is Python/Django [REST] on the backend, JavaScript/TypeScript, and all major JS frameworks on the frontend. There are many more things. If you are interested, this is my <a href="https://www.toptal.com/resume/iulian-gulea">online</a> resume.</p>
<h2 id="the-beginning-of-search">The Beginning Of Search</h2>
<p>Generally speaking, switching jobs requires effort. You must not only prepare for the interviews but also spend time on operational stuff like searching for companies to apply, adjusting your CV, etc.</p>
<p>In Jun 2019, while I had a nice job at a NY-based startup, but I planned to move with my family to the United States. And the easiest way to do that was to apply to some companies that provide an H1B visa. Due to some circumstances, we had to stay for at least one year at home, so I decided to slowly, but steadily plan my preparation for interviews at the big tech companies.</p>
<h2 id="the-preparation-phase">The Preparation Phase</h2>
<p>After doing some research, I found out the most common stages of the recruitment process:</p>
<ul>
<li>technical</li>
<li>behavioral</li>
<li>management</li>
<li>analytical</li>
<li>system design</li>
<li>object-oriented design</li>
</ul>
<p>You might not go through all of them. It depends on the job position you apply and on the company. What you will for sure have are the <em>behavioral</em> and <em>technical</em> interviews. <em>System design</em> is often present, especially if you apply to a position that requires experienced candidates.</p>
<p>Let’s briefly describe each type of the interview before moving further.</p>
<h3 id="technicalcoding-interview">Technical/Coding Interview</h3>
<p>This type of interview aims at understanding your algorithms skills. Usually, you are given 1, 2, or 3 problems, and you have to solve them in the allocated time (usually somewhere between 15 to 60 mins, depending on the complexity of the problem), considering edge cases and time and space complexity.</p>
<p>There are many platforms online where you can practice solving such problems. Here are just a few to name:</p>
<ul>
<li>LeetCode</li>
<li>HackerRank</li>
<li>Codility</li>
<li>GeeksForGeeks</li>
</ul>
<p>I created a habit of solving at least one problem per day, and in almost ten months, I had solved 299 problems.</p>
<p><img src="https://iuliangulea.com/images/leetcode-submissions.png#c" alt="Image of submissions on leetcode"></p>
<p><img src="https://iuliangulea.com/images/leetcode-solved-problem-types.png#c" alt="Image with amount and types of problems solved on leetcode"></p>
<p>Another thing to note is that a candidate usually has several technical interviews: over the phone and onsite.</p>
<h3 id="behavioral-interview">Behavioral Interview</h3>
<p>This type of interview aims at understanding the competency and soft-skills part of your professional profile. How good can you get along with people, how do you perform and behave in different situations with your coworkers, etc. Some developers see this interview as a useless step (or one with minimal importance). That is a delusional thought. Developers have to work in teams the same way as people in many other professions, and understanding “the human” side of a potential employee is essential.</p>
<p>To prepare for this step, there are lots of resources online about behavioral interviews. _ “Cracking the Coding Interview”_ by Gayle Laakmann McDowell is a book that might help you as well. Actually, it is an exhaustive resource to prepare for interviews, so check it out.</p>
<h3 id="management-interview">Management Interview</h3>
<p>I had this type of interview only at one company. It is about looking for examples of how you deal with different scenarios, usually around being a team player, helpful and engaging. I didn’t really see a difference from a behavioral interview, but it was explicitly labeled a “Management Interview,” so there it is.</p>
<h3 id="analytical-interview">Analytical Interview</h3>
<p>This type of interview aims to understand how you work with data, how you make sense of it, and if you have made any data-driven decisions in your previous work. It has minor aspects of a behavioral interview as well, but more focused on your analytical skills.</p>
<h3 id="system-design-interview">System Design Interview</h3>
<p>This type of interview is about designing scalable, distributed systems. It might be tough to prepare for because sometimes you might not have the experience of working on a distributed system. Therefore, you must learn the theory only, without having practical experience.</p>
<p>This step is also more challenging because there are a lot of concepts, use cases, and tools that solve various problems, and you need to know what those are to be able to design a viable solution.</p>
<p>To prepare for this interview, I took the long route (since I had plenty of time). There are many great (and free!) resources on GitHub, and here are the ones that I used:</p>
<ul>
<li><a href="https://github.com/binhnguyennus/awesome-scalability">Awesome Scalability</a> - a reading list on scalability, availability, principles of distributed systems, best case practices at different companies, and many more. I was reading five articles a day and was almost done with the relevant concepts in 7 months. It gave me a broad perspective on what tools exist out there, what problems other teams and companies face, and how to approach solving those problems.</li>
<li><a href="https://github.com/donnemartin/system-design-primer">The System Design Primer</a> - a similar resource, but much more concise, and focused on the theoretical aspects of the concepts more (rather than providing real-life examples from companies, as in the previous link). But the main advantage of it is that it has examples of system design questions and answers.</li>
<li><a href="https://github.com/yangshun/tech-interview-handbook">Tech Interview Handbook</a> offers full support in preparation for the interviews, but I used it for some hints only.</li>
</ul>
<h3 id="object-oriented-design-interview">Object-Oriented Design Interview</h3>
<p>In OOD, you have to design the interface of some API or class. It aims at understanding how you think in terms of code and how you structure it. There should be some resources online on the topic, but I haven’t prepared for this one additionally since that is what I do as part of my job.</p>
<h2 id="quitting-and-searching">Quitting And Searching</h2>
<p>In March 2020, I decided to quit my job at the NY startup and enjoy some time while I was going to search for a job. I was okay financially and was quite confident I would get a job at some company. But then the pandemic hit, and I got a bit nervous.</p>
<p>Anyway, I needed companies that can sponsor a visa. That’s pretty much all big tech firms. Here is the list of companies and openings I have applied to:</p>
<ul>
<li>Full Stack Developer @ Google in Zurich</li>
<li>Software Engineer, Core Languages @ Google in Munich</li>
<li>Software Engineer, Engineering Productivity @ Google in Munich</li>
<li>Senior Backend Engineer @ Airbnb in Dublin</li>
<li>Software Developer - Frontend Tools for AWS @ Amazon in Berlin</li>
<li>Software Developer Engineer - Backend @ Amazon in Berlin</li>
<li>Developer Support Engineer @ Facebook in Dublin</li>
<li>Enterprise Engineer @ Facebook in Dublin</li>
<li>Full Stack Software Engineer - Python/JS @ Apple in Zurich</li>
</ul>
<p>Out of these, I had referrals at all companies except Airbnb. So I got a reply from Google for the Full Stack role, both Amazon jobs, the Airbnb one, and Facebook’s Developer Support Engineer. The only email I received from Apple was the one in which they asked me about feedback on the recruitment process. That was weird.</p>
<p>So, it was exciting, and I was looking forward to it!</p>
<h2 id="interviewing">Interviewing</h2>
<p>If you have worked for a corporation, you probably know that things there take time to progress. The most responsible and fast were Google and Facebook, followed by Airbnb, and Amazon being the least responsive and considerate.</p>
<p>The first step at all companies except Amazon was a phone call to discuss about my application. I perceived this step as an ice-breaker where the recruiter gets to know you, that you are a real person, and that you have intelligible English.</p>
<p>After that, there were coding rounds, but things started to diverge, so I’ll describe the experience with each company separately:</p>
<h3 id="google">Google</h3>
<p>Google was among my favorites. The experience with the recruiter was among the best I had. Initially, we had a call to introduce myself, and the recruiter told me about the process.</p>
<p>The next step was a coding round with an interviewer. I was delighted about how it went. The code was well commented and organized in testable functions. I walked the interviewer throughout the whole thinking process by telling how and why I’m writing that code. I did introduce a small bug (incorrect upper bound in python’s <code>range()</code> function) that the interviewer showed me immediately, which I fixed. Also, while I was close to finalizing the problem, I figured out some use cases that wouldn’t pass, so I clarified the expected outcome and did the corresponding changes. I even answered a follow-up question, but I didn’t get to code it because of a lack of time.</p>
<p>After waiting for one week, it turned out that I didn’t pass. And the feedback was a bit suspicious to me:</p>
<ul>
<li>the pace was a bit on the slow side</li>
<li>I didn’t account for a bug (the one that he told me about the moment I did it)</li>
<li>I didn’t think about the design of the algorithm and data structures at the abstract level before coding (this one is subjective since I did think and explain my choices)</li>
</ul>
<p>Anyway, it seemed very unfair. The only thing I could do is to tell about this to the recruiter, so hopefully, other candidates will be evaluated more fairly.</p>
<h3 id="amazon">Amazon</h3>
<p>With Amazon, I had the least pleasant experience as a candidate. It took ages until they were responding to emails and moving with the recruitment process. So, after the intro call, I had two rounds of coding exercises for two …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://iuliangulea.com/blog/how-i-got-an-offer-at-facebook-turned-it-down-and-went-on/">https://iuliangulea.com/blog/how-i-got-an-offer-at-facebook-turned-it-down-and-went-on/</a></em></p>]]>
            </description>
            <link>https://iuliangulea.com/blog/how-i-got-an-offer-at-facebook-turned-it-down-and-went-on/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400606</guid>
            <pubDate>Mon, 07 Sep 2020 16:40:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alexei Navalny’s condition has improved]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24400503">thread link</a>) | @doener
<br/>
September 7, 2020 | https://www.charite.de/en/service/press_reports/artikel/detail/fifth_statement_by_charite_universitaetsmedizin_berlin_alexei_navalnys_condition_has_improved/ | <a href="https://web.archive.org/web/*/https://www.charite.de/en/service/press_reports/artikel/detail/fifth_statement_by_charite_universitaetsmedizin_berlin_alexei_navalnys_condition_has_improved/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>The condition of Alexei Navalny, who has been receiving treatment at <span lang="fr">Charité</span> – <span lang="de">Universitätsmedizin Berlin</span> since August 22, 2020, has improved.</strong></p><p>  The patient has been removed from his medically induced coma and is being weaned off mechanical ventilation. He is responding to verbal stimuli. It remains too early to gauge the potential long-term effects of his severe poisoning.</p><p>  The treating physicians remain in close contact with Mr. Navalny's wife. After consultation with the patient's wife, <span lang="fr">Charité</span> is reassured that the decision to make details of the patient’s condition public would be in accordance with his wishes.</p></div><p><a href="mailto:presse@charite.de" title="E-Mail an:">Manuela Zingl</a><br> Corporate Spokesperson<br> <span lang="fr">Charité</span> – <span lang="de">Universitätsmedizin Berlin</span><br> Tel: +49 30 450 570 400</p></div>]]>
            </description>
            <link>https://www.charite.de/en/service/press_reports/artikel/detail/fifth_statement_by_charite_universitaetsmedizin_berlin_alexei_navalnys_condition_has_improved/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400503</guid>
            <pubDate>Mon, 07 Sep 2020 16:28:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AMD is selling bikes now]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24400442">thread link</a>) | @UncleOxidant
<br/>
September 7, 2020 | https://amdfanstore.com/amd-custom-cruiser-bike/ | <a href="https://web.archive.org/web/*/https://amdfanstore.com/amd-custom-cruiser-bike/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tab-description">
    <p><span size="5"><b><span color="#FF0000">Due to popular demand, this item is currently sold out.</span></b></span></p>
<p>Custom AMD Cruiser Bikes. This cruiser is the perfect designed bike for cruising the streets and beaches in style. From its bobtail fenders to the double spring saddle, this model is not only fun to ride, but you look good doing it! Customized with AMD logo and coordinating tire and grip colors. Large tube frame, 3 Piece Crank, Aluminum 26” Wheels, Alloy Stem, Double Spring Cruiser Saddle, Front &amp; Rear Fenders, Coaster Brake, Frame size 18.5".</p>
<p><strong><span color="red"><span color="#000000"><span>Please note, this item is only able to ship within the continental United States. Shipping to Hawaii, Alaska, or other regions is not available at this time. Shipping charge of $50 per bike. Please allow 6-8 weeks for delivery.</span> </span><br></span></strong></p>


  </div></div>]]>
            </description>
            <link>https://amdfanstore.com/amd-custom-cruiser-bike/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400442</guid>
            <pubDate>Mon, 07 Sep 2020 16:20:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Erwin Schrödinger Said About the Upanishads – The Wire Science]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24400429">thread link</a>) | @thedday
<br/>
September 7, 2020 | https://science.thewire.in/the-sciences/erwin-schrodinger-quantum-mechanics-philosophy-of-physics-upanishads/ | <a href="https://web.archive.org/web/*/https://science.thewire.in/the-sciences/erwin-schrodinger-quantum-mechanics-philosophy-of-physics-upanishads/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://science.thewire.in/the-sciences/erwin-schrodinger-quantum-mechanics-philosophy-of-physics-upanishads/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400429</guid>
            <pubDate>Mon, 07 Sep 2020 16:18:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RESTful APIs Principles]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24400359">thread link</a>) | @lobo_tuerto
<br/>
September 7, 2020 | https://www.parse.ly/help/api/restful-apis/ | <a href="https://web.archive.org/web/*/https://www.parse.ly/help/api/restful-apis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>If you were to describe the integration approach with the Parse.ly API to a colleague in one line, you
could say, "it's a RESTful API implemented with HTTP and JSON". That's a mouth-full. This page describes some the principles behind the design of the API.</p>

<ul>
<li><strong>HTTP and HTTPS as transports</strong>: We chose HTTP for its ubiquity. You should
be able to test our API right from your web browser. It should be a single
line of code to start making requests from your programming language of
choice, including JavaScript.</li>
<li><strong>JSON as an interchange format</strong>: JSON is a lightweight and human-readable
format.  JSON's only real drawback vs. something like XML is that there is no
good way to define a JSON "schema" to document the formats formally. So, we
will just substitute out a formal schema for documentation and examples.</li>
<li><strong>Documented</strong>: We should document our API and interchange formats in a way
that makes it easy for our users to find what they're looking for and make the
requests and interactions that they need to get their work done. That's what
this documentation is all about.</li>
<li><strong>Practicality beats purity</strong>: There is a lot of talk about "purely RESTful"
APIs out there. But a lot of this talk isn't rooted in reality. REST suggests
you use HTTP methods like GET, POST, PUT, and DELETE. However, making HTTP
requests with a method other than GET is complicated in web browsers. We only
support the GET method, which allows us to support JSON-P and client-side
JavaScript integrations easily. It also means there's one less thing to
remember when working with our API: just use GET.</li>
<li><strong>Meaningful error states</strong>: When there are problems finding requested data or
if a service is down, we should have some well-established error states that
can be handled gracefully by our clients. This also involves being practical:
for example, it might mean returning HTTP status code 200, but with an error
message encoded in the JSON response document, allowing graceful client-side
error handling.</li>
<li><strong>Supports JSON-P</strong>: For purely client-side (JavaScript) integrations with our
API, the most convenient standard available is "JSON with padding", aka
JSON-P. This is not a standard part of REST, but it is supported throughout
our API via the <code>callback</code> query parameter.</li>
<li><strong>Well-tested</strong>: The API should be tested, and, once it leaves "beta" state,
it should be versioned and have a high degree of reliability and consistency.</li>
<li><strong>Performant</strong>: No endpoints should be slow. Practically speaking, most
endpoints should return in &lt;200ms and should rarely take longer than 1000ms.</li>
</ul>

<p>We were inspired in our design guidelines by the excellent book by Leanard
Richardson and Sam Ruby, <em>RESTful Web Services</em>, published by O'Reilly. We
highly recommend you
<a href="http://shop.oreilly.com/product/9780596529260.do" target="" rel="">pick up a copy of the book</a>
if you ever need to design a service of your own.</p>

<p>As described by the author:</p>
<blockquote>
<p>Use URIs to identify everything that merits being identifiable, specifically, all of the “high-level” resources that your application provides, whether they represent individual items, collections of items, virtual and physical objects, or computation results.</p>
</blockquote>

<p>This quote summarizes it best:</p>
<blockquote>
<p>It's important to stress that although REST includes the idea of statelessness, this does not mean that an application that exposes its functionally cannot have state -- in fact, this would render the whole approach pretty useless in most scenarios.  REST mandates that state be either turned into resource state, or kept on the client.</p>
</blockquote>
<p>The way the Parse.ly team interprets this guideline is to "prefer stateless
communication, otherwise, idempotence, otherwise, <em>documentation</em>!".  Obviously,
you can't make things stateless, but making them idempotent is probably a good
idea, and if you can't at least make it idempotent, then we better have
documented it.</p>

<p>We assign unique URIs to various analytics listings, metadata drill-downs,
recommendation/search engines, etc. This follows the practice described here:</p>
<blockquote>
<p>An application might add a few million customer URIs to the Web; if it's designed the same way applications have been designed in CORBA times, its contribution usually is a single "endpoint" -- comparable to a very small door that provides entry to a universe of resource only for those who have the key.</p>
</blockquote></div></div></div>]]>
            </description>
            <link>https://www.parse.ly/help/api/restful-apis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400359</guid>
            <pubDate>Mon, 07 Sep 2020 16:07:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a $100 ROS2 differential drive robot]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24400232">thread link</a>) | @jackp510
<br/>
September 7, 2020 | https://www.hadabot.com/build-hadabot.html | <a href="https://web.archive.org/web/*/https://www.hadabot.com/build-hadabot.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          
          <p>
            <small>
              COPYRIGHT 2020 - www.hadabot.com
            </small>
          </p>
        </div>
      </div></div>]]>
            </description>
            <link>https://www.hadabot.com/build-hadabot.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400232</guid>
            <pubDate>Mon, 07 Sep 2020 15:53:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Generate Passive Income]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24400148">thread link</a>) | @sjohn93
<br/>
September 7, 2020 | https://www.startupjohn.com/blog/the-10-best-ways-to-generate-passive-income | <a href="https://web.archive.org/web/*/https://www.startupjohn.com/blog/the-10-best-ways-to-generate-passive-income">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <p><span data-preserver-spaces="true">What comes in your mind when you hear the term Passive Income? Well, if you think it is easy money that can be earned while sitting on a beach without doing anything, you are wrong. Yes, it can be an excellent supplementary source of funds for a lot of people, but it requires lots of work as well. Passive income demands an upfront investment and a lot of nourishing in the start. However, after some time, these income streams can sustain themselves and bring you a significant amount of money. We will show the 10 best ways to generate passive income in this article.</span></p>
<p><strong><span data-preserver-spaces="true">What is Passive Income?&nbsp;</span></strong></p>
<p><span data-preserver-spaces="true">People love to hear about this earning method, yet it is the most misunderstood concept. In simple words, Passive income is when you keep getting paid for work, even after it is completed. It involves royalties from movies, books, songs, etc. It also includes the wealth that comes from investments in the real state or business investments where your physical presence is not necessary.&nbsp;</span></p>
<p><strong><span data-preserver-spaces="true">Why is it important?&nbsp;</span></strong></p>
<p><span data-preserver-spaces="true">The reason why everyone must start working on Passive Income ideas is its unmatchable significance. Let's suppose you wake up one day, and out of nowhere, you find out that you are fired from your job. That's where Passive Income proves its worth. The most recent example is the recent lockdown that was imposed by the government due to the Coronavirus outbreak. A lot of people have gone through a financial crisis during this pandemic, except the individuals who had secondary earning sources. So, whenever you lose your job or face any kind of financial hardship, passive income will ensure the cash flow does not stop.&nbsp;</span></p>
<p><strong><span data-preserver-spaces="true">How to generate Passive Income?&nbsp;</span></strong></p>
<p><span data-preserver-spaces="true">This is the most common question asked by the people who are willing to earn through different sources. There are a lot of Passive Income ideas and strategies that can help everyone. Some of them may require a lot of investment, but you can start making money even with as little as $5! Sounds unbelievable, right? We have discussed more of such strategies below.&nbsp;</span></p>
<ol>
<li><strong><span data-preserver-spaces="true">Rental Income:&nbsp;&nbsp;</span></strong><span data-preserver-spaces="true">A cash flowing rental property is an excellent way to earn passive income, but it requires a lot of work. Before investing in a real state, you must learn how to make it a profitable investment, otherwise, there are a lot of risks involved. Also, if you want to make it truly passive, outsourcing your property to a management company is the best option. However, this is not something you can start with a little extra cash.&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">Dividend Stocks:&nbsp;</span></strong><span data-preserver-spaces="true">This is an authentic and tested way to earn passive income. Your job will be to do extensive research and find good stocks where you can invest money and receive a significant number of dividends. If you keep investing in dividend stocks, you can accumulate a good residual revenue with time. Choosing the right company to invest in is the tricky part. If you succeed in selecting the right company, you will receive payment at regular intervals.&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">Peer-to-peer Lending:&nbsp;</span></strong><span data-preserver-spaces="true">Peer to peer, commonly known as P2P is the method of lending money to borrowers who do not qualify for conventional loans. This kind of lending is usually facilitated by a third-party agent, such as LendingClub. As a lender, your income source will be the interest payments made on the loans. However, there is some risk factor as the loan is unsecured.&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">Affiliate Marketing:&nbsp;</span></strong><span data-preserver-spaces="true">If you are a social media influencer, a blogger, or a website owner, this method can be the best option for you to earn some extra cash. It is a commission-based job, where you promote a third party's product on your website, and on every purchase, you will get your share. The most popular affiliate partner is Amazon, but there are other platforms like Awin, ShareASale, and eBay as well. Please remember that you will need to invest a lot of time in the start to attract traffic on your website.&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">Investing in CDs:&nbsp;</span></strong><span data-preserver-spaces="true">If you are a risk-averse person, investing in Certificates of Deposits (CD) can be a pretty good option for you. It is often more profitable to go with an online bank than your local bank. This way, you will be able to select the best rate of return available in your country.&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">Selling Information Product:&nbsp;</span></strong><span data-preserver-spaces="true">If you are good at something, you can always record an audio or a video course and sell it to interested people. Also, writing an E-book can be a pretty good source for earning passive income. The only problem with this method is that you must put a lot of effort into creating such a product. Some popular examples in this regard are Udemy, Coursera, Skillshare, etc.&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">REIT:&nbsp;</span></strong><span data-preserver-spaces="true">Real Estate Investment Trusts are specially made for people who are not comfortable investing directly in the real state. REITs have a kind of legal structure that enables them to pay little to no corporate income tax if they pass along most of their revenue to shareholders. You can easily purchase the shares of REITs from the Stock Market just like other companies.&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">Invest in a Business:&nbsp;</span></strong><span data-preserver-spaces="true">This is another great way to make passive income. You can invest in a business and be a silent partner. This is the riskiest method we have discussed until now, but if you are a risk-taker, you will understand the high returns that are associated with high risk. For example, did you know that Uber and Lyft were looking for private investors once? Well, both of these companies are worth billions now!&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">Car Advertisement:&nbsp;</span></strong><span data-preserver-spaces="true">Earning money while driving your car around town - doesn't it sound fascinating? Well, it surely does, and a lot of people are doing it. You can contact any experienced advertising agency, and after making some inquiries, they will link you to one of their advertisers.&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">Renting out a room in your house:&nbsp;</span></strong><span data-preserver-spaces="true">This is a straightforward method of earning passive income. In simple words, you are taking advantage of the space that you were probably not using anyway.&nbsp;</span></li>
</ol>
<p><span data-preserver-spaces="true">The ideas discussed above are only a few out of hundreds through which you can make passive income easily. It is about time we start looking for additional income sources that can improve our living. However, there is no such thing as easy money. If you are looking for high returns, make sure to put the significant effort.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Disclaimer:&nbsp;</span><strong><span data-preserver-spaces="true">This is not a financial advice.&nbsp;</span></strong><span data-preserver-spaces="true">StartupJohn doesn`t bear any responsibility for any financial losses you might incur as a result of this article and website. StartupJohn or anyone involved with StartupJohn will not accept any liability for loss or damage as a result of reliance on the information including data contained within this website.</span></p>
            </div></div>]]>
            </description>
            <link>https://www.startupjohn.com/blog/the-10-best-ways-to-generate-passive-income</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400148</guid>
            <pubDate>Mon, 07 Sep 2020 15:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A beginner’s guide to practical quantum computing (2020)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24400141">thread link</a>) | @kahmos
<br/>
September 7, 2020 | https://randomtechthoughts.blog/2020/09/01/a-beginners-guide-to-practical-quantum-computing/ | <a href="https://web.archive.org/web/*/https://randomtechthoughts.blog/2020/09/01/a-beginners-guide-to-practical-quantum-computing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2468">
	<!-- .entry-header -->

	<div>
		
<p>I recently started dabbling with quantum computing, and this post is kind of the introduction I wish I’d found before I started.&nbsp; It’s not intended to be anything other than a very small tip of a very big iceberg.&nbsp; Hopefully, this will give you enough to help you know if quantum computing is worth your time, what to expect if you start, and some links to resources I’ve found useful.&nbsp; Also, “beginner’s” has a double meaning – it’s <em>for</em> a beginner, <em>by</em> a beginner – I’m probably in ‘knows enough to be dangerous’ territory.</p>



<p>Also, “practical” is there on purpose, because this will be about what’s involved in writing code on your own computer.&nbsp; I won’t be going into theory much, or its consequences for society etc.&nbsp; I’ve played with only the Microsoft Quantum Computing stack (details below), so this post will be in that context.&nbsp; If you search for <em>Quantum Development Kit</em> online you can find alternatives, but I don’t know how they compare to Microsoft’s.</p>



<p>I was inspired to start dabbling by the podcast <a href="https://feeds.captivate.fm/impact-quantum/">Impact Quantum</a>, which is from the same people (<a href="http://franksworld.com/">Frank La Vigne</a> and <a href="https://andyleonard.blog/">Andy Leonard</a>) as do the podcast <a href="http://datadriven.tv/">Data Driven</a>.&nbsp; This blog is also partly because of the <a href="https://www.ministryoftesting.com/">Ministry of Testing</a> <em>I wish I knew</em> blogging challenge (more below).</p>



<h2>Getting started – the short version</h2>



<p>Even though quantum computers aren’t generally available, you can write quantum computing code today on normal hardware (such as your laptop) with the aid of emulators.&nbsp; These help your laptop to present a quantum-computing-like interface, but the lack of proper quantum computing hardware means that the emulator (and hence your code) will run more slowly than the real thing.&nbsp;</p>



<p>This will probably limit the scope of what you can realistically tackle, as big things will simply take too long.&nbsp; The good news is that when quantum computers do eventually become generally available, the code you’ve been running against emulators should run unchanged (and much faster) on the real thing.</p>



<p>With all that out of the way, here’s the short version of how to get started.&nbsp; (There’s a longer and less simple-sounding version, and also links for where to download things, below.)</p>



<ol type="1"><li>Download Visual Studio Code (not Visual Studio) if you don’t already have it.&nbsp; It can run on Windows, OS X and Linux.</li><li>Download the Microsoft Quantum Development Kit, which is an add-on to Visual Studio Code.&nbsp; This includes a quantum computing emulator, and support for the language Q#.</li><li>Write programs in Q# and run them.</li></ol>



<p>This assumes an awful lot of important details, some of which I’ll go into below.</p>



<div><figure><img data-attachment-id="2470" data-permalink="https://randomtechthoughts.blog/512px-rubiks_cube/" data-orig-file="https://randomtechthoughtsblog.files.wordpress.com/2020/09/512px-rubiks_cube.jpg" data-orig-size="512,297" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="512px-rubiks_cube" data-image-description="" data-medium-file="https://randomtechthoughtsblog.files.wordpress.com/2020/09/512px-rubiks_cube.jpg?w=300" data-large-file="https://randomtechthoughtsblog.files.wordpress.com/2020/09/512px-rubiks_cube.jpg?w=512" src="https://randomtechthoughtsblog.files.wordpress.com/2020/09/512px-rubiks_cube.jpg?w=512" alt="" srcset="https://randomtechthoughtsblog.files.wordpress.com/2020/09/512px-rubiks_cube.jpg 512w, https://randomtechthoughtsblog.files.wordpress.com/2020/09/512px-rubiks_cube.jpg?w=150 150w, https://randomtechthoughtsblog.files.wordpress.com/2020/09/512px-rubiks_cube.jpg?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Quantum code uses matrices to rotate points representing complex probabilities around the surface of a Bloch sphere, like rotating the faces of a Rubik’s cube – easy! Image credit: <a href="https://commons.wikimedia.org/wiki/File:Rubik%27s_Cube.jpg">Acdx</a> / <a href="https://creativecommons.org/licenses/by-sa/3.0">CC BY-SA</a></figcaption></figure></div>



<h2>Quantum computing programs</h2>



<p>Before I go into some of the lower-level details, I ought to describe quantum computer code in general because it’s not like any normal code that you’ve already written.&nbsp; (There’s a section below where I draw comparisons with other bits of computing I’ve already used, but they’re more helpful when you’ve already got the idea than in trying to introduce it.)</p>



<p>Pretty much all the quantum code I’ve seen relies on the quantum theory phenomenon of <em>superposition</em>.&nbsp; (Some uses <em>entanglement</em> or <em>quantum tunnelling</em>, but these seem rare enough to ignore at least for now.)&nbsp; Without going into the brain-melting details, what this means for your code is that instead of variables having exactly one value at a time (which could be null or a random unassigned value, or which could change often) special variables called <em>qubits</em> can have all possible values <strong>at the same time­</strong><em>. </em>This is quantum computing’s main secret sauce – the ability to evaluate many alternatives very quickly i.e. in parallel.</p>



<p>Yes, this is very weird and takes some getting used to.&nbsp; You can have normal variables that have only one value at a time (as you’d expect), but the power comes from the qubits.&nbsp; These have all possible values at once until a point in the code where you decide to <em>measure</em> their value.&nbsp; At this point, the multiple possibilities and related weirdness evaporate, and you have a single value as per normal computing.&nbsp; From here on there’s no more quantum secret sauce, so you tend to do this as late as possible.</p>



<p>This doesn’t sound very useful, because it seems like variables start off with all possible values, and then magically pick one possible value at random.&nbsp; This isn’t true but the reality involves more weirdness and details.</p>



<p>Before the point of measurement, a qubit is an array of N values (actually, 2: for 0 and 1).&nbsp; The values in the array aren’t the candidate values that measurement picks from.&nbsp; Instead, the value in element X of the array is the probability that measurement will pick that element’s value.&nbsp; I.e. element 0 is the probability that you will end up with 0, and element 1 is the probability you will end up with 1.</p>



<p>To initialise a qubit, you set the correct probabilities for the different elements in the array.&nbsp; The operations that make up your code then modify the probabilities, including the relationship between the probabilities inside qubit A and the probabilities inside qubit B.&nbsp; Then, at measurement time, the computer effectively rolls dice to decide which value to pick per qubit, based on the probabilities that were around by then.&nbsp; I tend to think of this as: <strong>quantum code deals in meta data rather than data</strong>.&nbsp; The numbers that slosh around in the code are probabilities associated with values, rather than the values themselves.</p>



<p>Note this adds yet another bit of weirdness – quantum code is probabilistic rather than deterministic.&nbsp; Correctly-constructed code <em>should­ </em>produce the correct result <em>most</em> of the time.&nbsp; I.e. if you ran the same correctly constructed code many times with the same inputs you might get different outputs per run, but <em>most</em> of the time the outputs will be correct.</p>



<h2>Getting started – the much longer version</h2>



<p>You can probably see now why the shorter version of getting started was a bit on the unhelpfully optimistic side.&nbsp; The good news is that it doesn’t appear that you need to understand quantum theory beyond a fairly superficial level to write quantum computing code.&nbsp; However, there are probably still quite a few barriers to overcome.</p>



<p>The first potential barrier is the fact that qubits and operations on them are expressed in terms of matrices.&nbsp; You might already be familiar with them, you might have dim memories from long ago, or they might be completely new.&nbsp; This is things like tensors, transposing etc.</p>



<p>The second potential barrier is the probabilistic nature of the code, and probability is another thing you need to know and be comfortable with, at least a bit.</p>



<p>The third potential barrier is the fact that the probabilities in the matrices are expressed in terms of complex numbers, i.e. numbers that might include a multiple of <em>i</em> – the square root of -1.&nbsp; This also comes with its own set of notation, such as <em>Dirac notation</em>.&nbsp; This means you’ll see things like |a&gt; (pronounced “ket a”), &lt;a|(“bra a”), &lt;a|a&gt; (“bra-ket a”), |+&gt;, |-&gt;, |0&gt; and |1&gt;.</p>



<p>Complex numbers mean that each number will have two parts.&nbsp; In general, a number will be of the form <em>x + iy</em>, where <em>x </em>is called the real part and <em>iy</em> is the imaginary part.&nbsp; You might think that you will therefore be dealing with diagrams that have numbers on a 2D number plane rather than a 1D number line.&nbsp; Unfortunately, this isn’t always true – you will also see a single probability displayed on the surface of a sphere (called a <em>Bloch sphere</em>).</p>



<p>Points on the surface of a sphere have only two degrees of freedom (e.g. <a href="https://randomtechthoughts.blog/2020/07/05/how-far-away-is-the-eu/">longitude and latitude</a>), even though they exist in 3D space, so you might be asking why a 3D representation of a complex probability helps.&nbsp; I.e. imagine a sphere with x, y and z axes, where the y axis goes through the North and South poles.&nbsp; If you have a point on the surface and you increase longitude while keeping latitude constant, the point draws a circle through space.&nbsp; The circle will be on a plane of constant y, and x and z will trade size as the point goes around the circumference of the circle.</p>



<p>The short and possibly not very helpful answer is that different useful operations rotate a point (a particular probability) around the x, y and / or z axes, like when you twist the different faces of a Rubik’s cube.&nbsp; Just as combining a pattern of twists of a Rubik’s cube about the different axes can produce useful outputs (e.g. unscrambling it), quantum operations combine patterns of rotations about all three axes to do useful work.</p>



<p>A slightly longer answer is that the size of a point’s probability is determined by two of its three co-ordinates.  The third co-ordinate, its <em>phase</em>, is an extra property of the point that you can effectively put in the point’s back pocket, and then use later to affect the two main co-ordinates.  (Rotating the point about e.g. the y axis means that its x and z values swap around.  You can use the extra co-ordinate to swap a new value into one of the main co-ordinates via rotations.)</p>



<p>Once you’ve understood enough quantum theory concepts (superposition on its own seems to take you a long way), matrices, probability and complex numbers, you then have the relatively simple task of learning Q#.&nbsp; It’s a Domain-Specific Language (DSL) for quantum computing, that’s a bit like C# and a bit like F# (apparently).</p>



<p>You are now in the position of understanding someone else’s Q# code.&nbsp; You might be able to write new Q# code, which is likely to involve working out how to re-frame the problem at hand in terms of problems that already have quantum computing solutions, such as <a href="https://github.com/microsoft/QuantumKatas/tree/master/GraphColoring">graph colouring</a>. You might even be able to solve new kinds of problems using Q# code if you’re much cleverer than me.</p>



<p>Q# code is one way of creating qubits and using the standard quantum operators, but the other quantum development kits are alternative ways to interact with …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://randomtechthoughts.blog/2020/09/01/a-beginners-guide-to-practical-quantum-computing/">https://randomtechthoughts.blog/2020/09/01/a-beginners-guide-to-practical-quantum-computing/</a></em></p>]]>
            </description>
            <link>https://randomtechthoughts.blog/2020/09/01/a-beginners-guide-to-practical-quantum-computing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400141</guid>
            <pubDate>Mon, 07 Sep 2020 15:41:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Heroku terminates Ruqqus site and account without a warning or an explanation]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24400102">thread link</a>) | @ecmascript
<br/>
September 7, 2020 | https://ruqqus.com/post/301l/you-cant-cancel-freedom-that-easily | <a href="https://web.archive.org/web/*/https://ruqqus.com/post/301l/you-cant-cancel-freedom-that-easily">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body">
<p>At 16:09 EDT on 04 Sep 2020 (about 26 hours ago), SalesForce (the owner of web hosting company Heroku) notified us that they had suspended the Ruqqus live and test server environments, with account termination to follow twenty-four hours later.</p>
<p>At the time of this writing, we have not been given a reason as to why we were being kicked. I do not believe we violated Heroku ToS (though Heroku may think otherwise) and we did not exceed Heroku usage limits. Our account manager was friendly but was unfortunately unable to provide us with any information. It is my opinion that by not warning us first (ex. "please remove X which violates Heroku's acceptable use policy") that Heroku actually violated their own terms of service.</p>
<p>We immediately downloaded all of the Ruqqus data, and began working on setting up shop at another host.</p>
<p>I'd like to give a massive shoutout to <a href="https://ruqqus.com/@p2hang"><img src="https://ruqqus.com/@p2hang/pic/profile">@p2hang</a> for lending his considerable expertise in support of getting Ruqqus operational as quickly as possible. He is the third recipient of the super-rare Fire Extinguisher badge.</p>
<p>All (or at least, almost all) functionality is restored. There are a few things which aren't quite yet back to normal, which I hope to fix over the course of tonight and tomorrow.</p>
<p>Known issues:</p>
<ul>
<li>
<p><del>hCaptcha verification issues on attempted signups</del></p>
</li>
<li>
<p><del>Custom guild colors are currently disabled. This was an intentional decision by me, as there were issues loading the style files needed for custom coloring, so it was easier to just disable that for the sake of getting up and running.</del></p>
</li>
<li>
<p><del>Notification bell stuck on.</del></p>
</li>
<li>
<p><del>Lastly, and most importantly, we have no idea how well the current server will be able to handle user load. For that reason, I will be continuing to monitor and make adjustments as needed. Performance may be spotty and unreliable as load resumes.~~ ~~Doesn't seem to be an issue, but we'll have to see how it goes with everyone trying to get on.</del> There are some load/efficiency problems that I'm trying to sort out.</p>
</li>
<li>
<p><del>hCaptcha on signup is malfunctioning.</del></p>
</li>
<li>
<p><del><a href="http://i.ruqqus.com/">i.ruqqus.com</a> image uploads don't save.</del></p>
</li>
<li>
<p>The most recent 30k or so comments didn't make it into the new host. Also possibly some post votes. I <em>think</em> all the comment votes made it in. The missing data is something I'm still working on, but you will probably see rep fluctuating unpredictably as vanished stuff is no longer counted.</p>
</li>
</ul>
<hr>
<p>If you'd like to contribute to the future of freedom, please consider donating via <a href="https://patreon.com/ruqqus" rel="nofollow noopener" target="_blank">Patreon</a> or <a href="https://paypal.me/ruqqus" rel="nofollow noopener" target="_blank">Paypal</a> to help cover current and future server costs. <a href="https://ruqqus.com/help/donate">Cryptocurrency is also accepted</a>.</p>
</div></div>]]>
            </description>
            <link>https://ruqqus.com/post/301l/you-cant-cancel-freedom-that-easily</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400102</guid>
            <pubDate>Mon, 07 Sep 2020 15:35:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handling Terminal Outputs with Redirection]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24400051">thread link</a>) | @mkfeuhrer
<br/>
September 7, 2020 | https://www.mohitkhare.com/blog/terminal-output-with-redirection/ | <a href="https://web.archive.org/web/*/https://www.mohitkhare.com/blog/terminal-output-with-redirection/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-d484fe6c=""><p data-v-d484fe6c="">Handling terminal outputs with Redirection</p> </div></div>]]>
            </description>
            <link>https://www.mohitkhare.com/blog/terminal-output-with-redirection/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400051</guid>
            <pubDate>Mon, 07 Sep 2020 15:27:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Java: The Programmer Environment That Has It All]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24400045">thread link</a>) | @zdw
<br/>
September 7, 2020 | https://deprogrammaticaipsum.com/java-the-programmer-environment-that-has-it-all/ | <a href="https://web.archive.org/web/*/https://deprogrammaticaipsum.com/java-the-programmer-environment-that-has-it-all/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p>Let me start with an admission: it took me <em>weeks</em> to work out what to talk about for the Java issue of <em>De Programmatica Ipsum</em>. There is just so much to it.</p>
<p>I recently took <a href="https://github.com/iamleeg/grotag" target="_blank" rel="noopener noreferrer">a twelve-year old Swing app</a> and—with no code changes and minimal project changes—compiled it on the latest JDK. It now runs on the latest Java Runtime Environment, and every JRE back to 2014’s version 8 (which is still supported for Oracle customers until December 2030, by the way). The previous version: no code changes, just built on an earlier JDK, worked back to at least 2004’s J2SE 5.0 release. So I could talk about the phenomenal compatibility and future-proofing of Java programming.</p>
<p>However, that Swing UI does not necessarily look the best, so I thought maybe I could talk about the embarrasment of riches available when it comes to designing user interfaces for Java software. The original, classic Abstract Window Toolkit (AWT) is still there, and still not deprecated, so I <em>could</em> make the UI out of native platform widgets. Then my code would be compatible back to the first-ever release of Java, back in 1995. Or I could use something more modern: <a href="https://openjfx.io/" target="_blank" rel="noopener noreferrer">JavaFX</a> and <a href="http://pivot.apache.org/" target="_blank" rel="noopener noreferrer">Apache Pivot</a> are the choices for working with marked-up UI files like Microsoft’s XAML, Apple’s Interface Builder, or Vue.js. A more Java-ish way to build UIs is <a href="https://www.eclipse.org/swt/" target="_blank" rel="noopener noreferrer">Eclipse’s SWT</a> with the <a href="https://wiki.eclipse.org/JFace" target="_blank" rel="noopener noreferrer">JFace</a> helpers.</p>
<p>If I am modernising, why would I limit myself to Java? The JVM ecosystem directly supports interesting languages like <a href="https://clojure.org/" target="_blank" rel="noopener noreferrer">Clojure</a>, <a href="https://scala-lang.org/" target="_blank" rel="noopener noreferrer">Scala</a> and <a href="https://kotlinlang.org/" target="_blank" rel="noopener noreferrer">Kotlin</a>. And then there are JVM-native ports of <a href="https://www.jython.org/" target="_blank" rel="noopener noreferrer">Python</a>, <a href="https://www.jruby.org/" target="_blank" rel="noopener noreferrer">Ruby</a>, <a href="http://www.redline.st/" target="_blank" rel="noopener noreferrer">Smalltalk</a>, and others. That is before we even start on the possibilities when you switch to a modern runtime environment like <a href="https://www.graalvm.org/" target="_blank" rel="noopener noreferrer">GraalVM</a>.</p>
<p>I could carry on. This has not been merely a fraction of the Java-based technology available, it has been a fraction of the Java-based technology <em>I have used</em> in the last couple of decades. We did not talk about build systems, about server technologies, about education environments, about developer environments, about mobile, about smart cards…</p>
<p>Because that is the <em>real</em> story of Java. Once the ownership questions had been sorted out by Apple’s <a href="https://www.infoworld.com/article/2076580/apple-releases-macos-runtime-for-java--mrj--version-2-0.html" target="_blank" rel="noopener noreferrer">Mac Runtime for Java</a> dying out, by <em>Sun versus Microsoft</em> killing the (deliberately incompatible) Microsoft JRE, by Sun’s open-sourcing their own implementation to create the <a href="https://openjdk.java.net/" target="_blank" rel="noopener noreferrer">OpenJDK</a>, we were left with the simple observation: the Java Runtime Environment is everywhere computers are (give or take), and the Java Developer Kit lets you do whatever your developers are interested in.</p>
<p>And all of that in a hassle-free, continuous way. No “ground-up rewrite” to support some new language the senior dev on your team insists is the next big thing: JVM classes all interoperate so you let them try their thing on the edges of your existing, well-maintained project. Some people see that as tedium: they observe code that is steeped in the 1990s design patterns phraseology, like <a href="https://docs.spring.io/spring-framework/docs/2.5.x/api/org/springframework/aop/framework/AbstractSingletonProxyFactoryBean.html" target="_blank" rel="noopener noreferrer">AbstractSingletonProxyFactoryBean</a>, and see this as a sign of a staid technology, beloved of managers but not deserving serious technical interest.</p>
<p>Meanwhile, others see signs of <em>success</em>. That code (actually from 2006) is still there because, well, it is <em>still there</em>, because its authors did not get distracted by the shiny shiny and get bogged down in another rewrite, because as manufacturers and markets came and went, the Java runtime was still there, and the bytecode could still execute.</p>
<p>Some of the people who do not use Java have good reasons. Many of the “write once, run anywhere” people are getting the same value out of Google’s Chromium runtime environment. Others have hitched their carts to a particular vendor’s horse and get more support (from the vendor and the associated community) by using that vendor’s tools. But for many people, the Java Runtime Environment represents the most widely-adopted computer ever designed, and the wealth of technologies available in the ecosystem represents a broad guarantee that when they reach for “the best tool for the job”, it is available for their platform.</p>
<p>Photo by <a href="https://unsplash.com/@annidenkova?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Anni Denkova</a> on <a href="https://unsplash.com/s/photos/java?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>
	</div></div>]]>
            </description>
            <link>https://deprogrammaticaipsum.com/java-the-programmer-environment-that-has-it-all/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400045</guid>
            <pubDate>Mon, 07 Sep 2020 15:26:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[100 Data Privacy and Data Security Statistics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24400000">thread link</a>) | @GranularRecipe
<br/>
September 7, 2020 | https://dataprivacymanager.net/100-data-privacy-and-data-security-statistics-for-2020/ | <a href="https://web.archive.org/web/*/https://dataprivacymanager.net/100-data-privacy-and-data-security-statistics-for-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://dataprivacymanager.net/100-data-privacy-and-data-security-statistics-for-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400000</guid>
            <pubDate>Mon, 07 Sep 2020 15:19:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[States experiment with automation to bolster cybersecurity]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399968">thread link</a>) | @rhinoh
<br/>
September 7, 2020 | https://www.route-fifty.com/tech-data/2020/09/states-experiment-automation-bolster-cybersecurity/168270/ | <a href="https://web.archive.org/web/*/https://www.route-fifty.com/tech-data/2020/09/states-experiment-automation-bolster-cybersecurity/168270/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.route-fifty.com/tech-data/2020/09/states-experiment-automation-bolster-cybersecurity/168270/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399968</guid>
            <pubDate>Mon, 07 Sep 2020 15:14:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The prisoner's dilemma of training your employees]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399867">thread link</a>) | @akdas
<br/>
September 7, 2020 | https://hiringfor.tech/2020/09/07/the-prisoners-dilemma-of-training-your-employees.html | <a href="https://web.archive.org/web/*/https://hiringfor.tech/2020/09/07/the-prisoners-dilemma-of-training-your-employees.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content"><figure id="cover-img">
  <p><img src="https://hiringfor.tech/assets/images/posts/2020-09-07-the-prisoners-dilemma-of-training-your-employees.jpg" alt="A chessboard with some pieces on it"></p>
  <figcaption>
    <p>Training your employees doesn’t have to be a game of chess. Photo by <a href="https://unsplash.com/@csolorzanoe?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Charlie Solorzano</a> on <a href="https://unsplash.com/@csolorzanoe?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>
  </figcaption>
</figure>

<p>A common trope in hiring is the lack of experienced candidates. This is certainly thought to be true for the entire tech industry, but it’s especially compounded for minority candidates: “it’s a pipeline problem”. On the flip side, the question inexperienced developers face is how they can gain experience without having prior experience.</p>

<p>No matter what type of experienced candidate you’re trying to hire, <strong>your company needs to invest in its junior employees</strong>. That means provide them with mentorship, formal training, and the opportunity to work on meaningful projects. But, there are some common objections:</p>

<ul>
  <li>
    <p>Building up experienced candidates takes time, when you need them <em>now</em>!</p>
  </li>
  <li>
    <p>Employees will take the investment you put into them and go to another company. Now, the other company will get an experienced candidate without paying the upfront cost.</p>
  </li>
</ul>

<p>It sounds like you’re better off asking developers to level up on their own time.</p>

<p>However, <strong>like many hard problems, the root cause is systemic</strong>. If every company invested in their industries, there would be a large pool of experienced candidates moving from employer to employer. This is, fundamentally, the <em>only</em> way to end up with experienced candidates in the system.</p>

<h2 id="the-prisoners-dilemma">The prisoner’s dilemma</h2>

<p>The problem is <a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma">a prisoner’s dilemma</a>: it’s best for all the employers to work together, training their employees. In return, they all get access to the trained candidates who move around in the future. But, like in the prisoner’s dilemma, one company doesn’t know what the other companies will do, so the best strategy seems to not reward other companies with trained candidates.</p>

<p>Luckily, there’s a silver lining here. It still makes sense to invest in your employees for two reasons.</p>

<p>Most importantly, your employees will be happier! You’ll still have to compete on pay, of course, but if someone is being treated well, wouldn’t they want to stay around for at least a little longer?</p>

<p>Besides, you’re not alone, even today. The big tech companies, like Google and Facebook, are absolutely investing in their employees. These companies have extensive formal training programs, structured mentorship and a wide variety of interesting problems for engineers to solve. In fact, investing in your employees may be another plus for those looking to jump out of the big tech companies.</p>

<p>Basically, if you’re not investing in your employees, you’re already falling behind.</p>

<h2 id="effective-investment">Effective investment</h2>

<p>Finally, there’s the question of <em>how</em>: how do you build up your employees into experienced engineers. I’ve already talked about a few ways, but let’s get into some more detail.</p>

<p>First, provide <em>formal</em> training programs, including mentorship. This means giving developers access to the experienced engineers in your company, and giving the experience engineers guidance on how to mentor others. But, it also means classes and educational material employees can take advantage of. Think paid classes to learn a new skill, the way I learned mobile development.</p>

<p>Next, send engineers to conferences, or better yet, coach them to speak at conferences and other industry events. Engineers need access to resources outside your company too. As a side effect, the company ends up with representation within these industry events, which can help with recruitment down the line.</p>

<p>Finally, let developers stretch themselves on harder projects. With the right guardrails and mentorship, this is exactly how engineers gain experience.</p>

<hr>

<p>Investing in your employees is key to creating an industry with a healthy level of experienced engineers to draw from. Along the way, the investment results in happier employees and more recruitment opportunities. And despite the fact it seems less than ideal to do this investment alone, you’re not actually alone: the most coveted companies are already ahead of the game here.</p>
</section></div>]]>
            </description>
            <link>https://hiringfor.tech/2020/09/07/the-prisoners-dilemma-of-training-your-employees.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399867</guid>
            <pubDate>Mon, 07 Sep 2020 15:01:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Luftwaffe's Doomed Mission [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399863">thread link</a>) | @RickJWagner
<br/>
September 7, 2020 | http://airforceapp.forces.gc.ca/CFAWC/eLibrary/Journal/2012-Vol1/Iss3-Summer/Sections/06-Unrealistic_Expectations-The_Luftwaffes_Doomed_Mission_During_the_Battle_of_Britain_e.pdf | <a href="https://web.archive.org/web/*/http://airforceapp.forces.gc.ca/CFAWC/eLibrary/Journal/2012-Vol1/Iss3-Summer/Sections/06-Unrealistic_Expectations-The_Luftwaffes_Doomed_Mission_During_the_Battle_of_Britain_e.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>Íaòžj«ŸæNŸÃ¿š—÷¿`d—)‰EÅÇ~[Åu‰'ðóQ�mÂDA'@¯êîÇÇm�Ÿ¬ùv[�ªãÔ(­•�v€'àŒ¯ÀpÄšÏ3“$§½“ö3”ÅœÀB—&gt;	ÌJ­§r¶Æ¡VÔp™&amp;HìÈ'
gÉH&amp;¯d’`“¸I*k�0§º4S@„‚¸Sk‚„$	ºK¡NBáH=
\=‹Q	P¤ÚCª�2œ�ÉŠI%`¡m{š¦’HhZ×5
\È&nbsp;Am?zIZ½TÍRT›^Õ6¤¥B}�L	QIHî¦»=¡ÃÌJ¨î…Šÿ¢ÒÙð*ñ¤Ó	)Ä»êÖÝk|ù8*wt&lt;Šõ
ú¥u3)ˆIOv¬Ô´�ì&nbsp;&lt;9Ú&gt;I¶;B­À¢ï§[OÉ%&lt;Ÿ¬í$qâŠÂÒ&amp;~Kuý‡ý9UÝõ}Ìþmàù	!Ì
×•#A�ì0åyÝ+!&nbsp;{ø³YY÷0ˆJÒVë[{^!ÁUÑ¼|ÕüœoPHÐª²Ã�šJà‡º
-Wì ™×”60ÂL¹Ð¨Zx[�çæ�€<jž'mÈµ°y´è¤ügÐv=±Ü$ªk�zd"†6Ñ1¨qxÑe·€ŠcÕ -±øŽö«uÙêi&²�p{qs]÷_1Ê}¤©;ÊÆ­!;|Òµ1="" ="">Å0AKà’˜¥¶Q[CÜtiEf
§óRU5v´ÙÓ\y "Ž˜ÑÉ”àUÃn;+—+�¨­
ð«gdpÆ·€R6€)Îm.4ŸŠ=xî$Ìš²ã¢M”ÕÅ’—¤Æk
[ƒŒƒÇ�P}“ÙÄÁ¤n˜ŽÉ:•
äøy¦Ü…&gt;–[0ñºø¤†_¨	#J·Ê:®ÀÉ}MàDO˜UÿPÊÂëw†î5 XGµÞD*wtQ[öÞÇ†‘»h'lð¤p=ÜÄ‚-ô¶¢^#‘?ÅäÛ �0Ñ:rÕr�2R’—P!I:JF™H€š%5+Btð”%Jtþ®ÿJþÁ]1\×ÕÁ9Ø+§‚£žìsÝ§ÔÇêÖ.x]Rav;ÀÇåOÒþ¯VÚÛeà—vž­’svnò™áƒ	2ë=òphÃ»,�[	žñ¢ë:GJnqËÏÒ?Á\®¦ÖÐÖ€€Dd…&amp;<bîx9ŽryÇ pÇ·uœeo="" w="”ë­¿z™§(ÞÊSñªžÐÙ" ÚÏ4xè²¬‚€l)p˜m²atá2[¡®="" §lœ¯¢š»="McNÞi8nL'I!’tÒ”&nbsp;•ÉNAN" !="" h¤="" ‰t¦®½ÜŸt :ÀÛb4¤‡dÅÉ·j‰Õ¨û“†Âv„‰„’´%”ÈlhŸÁ%="" 0�@j¤="" iv£#„¥<Â`’‚�)‰o4$¥Ú!<¦ƒ*g@ŠÂ‹ekžs6@Ùb’ˆÇŽi\u="" -äƒgjÆ·wv'Ëed:sÌ&="" 1Ñ±aúŠ±v-t}òe”¹i*c¾‘{o~è‰Š*y{h­Å¤ðaw.ƒ§g©ô¦Úït'Ÿ="" ±ëìŽy(¢‘vÑxÝovÇ8b="" Ù,?%"4="" òŠŒ{ŒƒÙ'Ñ[ùht0®-pëi%"”Ì­©Œá |“j’jw="" Š~—jœ'„ÈzuÊb¤�eiÕdò”lvs="">J$s­¤W	‚9üª±~¡²fiä��eaÃ]Sâ¶Aiq�Ú˜
d§Ð�‰�¸H™ò	ábˆÔh’}‡lN±â’J|y*ÜRMn-‘;�4$¹R2²§LÑ
IÁjÐ�(”‘RÉÒM))t‰I$”Å%(LR’„“¤§Oêàœ¿ìÔ€¹«Òÿ°å×SA·Èx¨§»÷_�aÜîñVœ`B›Z !¸ÊK-iDfº&nbsp;Ê;RC-¨•#DÍÇDzÙ	%‘­Ïi×·‚-xî#TìÐ…m¼h™)º0v«€nˆ%ÆU«5U^B+f)EéÁî„]	Úe=m¥ÜžP‹&nbsp;ÇŠ�))™09O¸9JM³Üœ=Î�*;ÉAp	½@Õ6&lt;«L¢5Ð‚i;ÝÄ(¹Ð¡¾TI’‚WtÀžÉBP’YÇ)½XPw)Gd’Ú©Û‚™ÕV¬–é*Ã]&lt;&nbsp;B­�lò¢c… R &amp;¥�l Õ ¤à’‘BEJ#…HEK„ÀwHKºJdt”��œ¤…ž[¡RÜ)Iî¦Ø* ‚¦´€Éºhˆ4CñS”Ò¼2O)¥4&nbsp;¹”öLíTe10Š—sCÚZ{¬›ðî¦Nà@ûájo&nbsp;aÓ&lt;#H· ×¼:ø&nbsp;7˜&lt;£çã?îaöŸÁUi$ê’›-il¸�â´¨~ö�f*&nbsp;Äê±æ�ŽýŽˆ€RU6á8	â®¼Wí¤µ!Ñ4¨Qo¨ŽÊ*d¨´©!IµÊŠ”&amp;„‚å¹A�Äò¬
tPsh‹IOlsª°[Â…�	à¨Å¬&nbsp;î‹c@”.Ó3ðN¶)
a¼Æœ‘a¾~	#hú¾4„’
eì†©Ò	'!I$’JRhN’HRI'IK(Ês©L�HT©5¥ÇNOdª­×=¬h’âù¯@èWñºpkžíWÇù)¦Uº%!+êßÕûqÝö‹ý²Ò;ëâº=±¼"½»PÁ0›,&amp;\[¯	¡;�Ba%ªÚŸ„Ñ&lt;ø©%$6qª€€ !Ô4ÕšId×m(‚ÒuA×…xm­¯lÈå-|I;'.$xj…g2ˆLLª–=ÀÂ™dG$¨¸í˜ØE’âœ´w,Nœ«-˜M§)ÃüP_&lt;œu¥Rçâ”ÊŒ‚a-²tì‚'p…ôS¹ÆTBƒ)N¡0™³©A)|yST(Si„’�’$�¢–Ô¡8&amp;ÕŒÑÇö"cÝ]¾Ö¸;wI	še9±¬ä¤æÀ0²2²Ã©ôÃÃœxÚ/Áììµà÷S™¯	øà\.0íZ8]IÏ�òyê‘	Õ0K® YÖ(°¾¶?Ü:3¼Öî|IåºLz˜1©U[f²Q}PäPØ	Pd)”�“tè“Œ=ä(’¥[7Xà4Ô¢µä ÖàQ4@¤J)Ã¦7B�rž&amp;À·U-òªîR„¸R&amp;S%½zmÉRî4„Ê`J€rp’®Ù¹­°mp�V&gt;V)Ä‘à­€!+inCK\‚mÉ¡òxVÇŠ©mÆqäQë²B­Ðm€W¸öT�ŽŸ4Bw0´!¶R´U¶qy(ð…Œ&amp;J&lt;#h!ŽÔãDé•³ ‘Ñ2EÚæª'XH÷LHÝÛ^ß5q®ˆÑ0%E­¨D!pãDÅ»»ê’ÀB›ðDKf³ª�Hå%"=ã_šIìÅñdà&amp;�º+#VR¨„¡$‚+WÚ›j�NŠ˜–¦R"S‚˜§J„’­°�‡Óïêl¡…çË�ñ(ý7ìŽ.¯,85Ño-?Ü»oªØtâã&lt;ÒððëAo—XM‘¥²—‹Ñ~ªY�g­”!Í µ&nbsp;÷Êéëh&lt;«¾˜v¤*—80�We†R26QXðÓ
¯)¢L§„PºbHî‘1Âhä¤¡â¹’tRaÚa0§¶5ðIž§Îž
bÀâc�‡·h™…6ÉÇÉ·£!'U&amp;¼“h&nbsp;4U'T©3‰ñA²=å¸ò†ÉÔ¬&lt;‚›]aÚ‰î¤RM%iHÂ‹\”IILëòˆÇm�†ÏgtBÙ(Û£v²ž°n°AA6£YP�U™žV¨$"¢	ƒ!äTÒAxŸ•iÚS‰ì«·:‘ùÓòKö• O¸ü’Kh !Sý¯Lh×!ž²ÁÃÞ‚šLº¼›4È&gt;*¹ÎunˆpW2ú‹2cs6Æ»§P³òžËµi×·šJUƒ�^}aì?àW9Õq[‹sƒH{y&nbsp;ôŽ&nbsp;Ü'&lt;¼1&nbsp;W:ž]9ì�Â8?Þ’âÕ£.Ö4Ôñ-‚[äU\¼ƒºXbéÊ{[ñS§·ØZ\ÁÈá$&amp;Â
µ›¶ÁîU&lt;ÚŠàíÆ¤Ø«öYUö×9UŸÔÚùah è’­×éÙ‡5†G¹±&gt;~jßÑ×UÏÕu¸Ì{iqiïâ†zŽdiiJIŽÏN×HÕM€žã¬ê9Æ?Lå`u&lt;Î=W}é*FžžÉóQ
q\Ã³s4µÿz³1æ¯“æR[o\Ùgd@âWûrë%¶=ÓñOëÚ¶;ã))ì	 ¢Å«��Qßz(¾Èã÷¥J{	G�•Ê,é½I–½§é’­ëC“8ÊÃÅêo­À8È&gt;+aŽß¯d)7Ñ3tÕ	ùÔÕË§áª}vZÏa:r<v_¦d¤«§\õvn�*mê¾ üvsl"b‘*-ûófcv–g�ðuØkjt"7t)x•¶[dj›{<f¸bºÝ="" r˜ÙÐ£="" ªÏu–Ò¦=""  ›u­<ü¬à¦[Âj¦ìÂsÝvmîjl¼9ªÒi<¦+,="" "o*aó¨f”$ÈitÜ§—íàs�ðr-ï('¢Í)½­2lµ3‡sÊŒjuç�’4´•¤l�ŸŠj_ïžÉ$Š|s+§Š™ërñeeÛaáÍ<Ã‚¬Ñø™m©–Ôù-±¿sÇÑ(�è®„j¼%="" l§nr€i&ƒÊdÂjyÊxìe–5¯~Àn®‰…ªb‚©¿ohÊ©ÐÚÍ€‰g¹¤|b�Ý#.‡4="">—{¸ï?r¯^eÕVjmŽ&lt;´î�×mé/&lt;¹†e³ßÄ!ª=C³Vœ+òƒ�U¹Ûy�+¼ú»MxXŒmn'w¸“ûÇ•�Ò~¶S&amp;«XÚ›$µÍ&gt;qÝUÎú×u·µ¸€5�ÝÇÓøøÙ\´Y.)éT÷Aä…N×2Ç�	‰Ô,¬�®¸Õ�‡}‘ôGßO«½=øôºë�é.;Ý=‡dÎÝŒÄ�e¿éî(ún˜„�ÒÎ"Ô:h�­&lt;¢&gt;²SVÈ(&amp;ô]�á­€� 'ã”Vî´(½úÞS�x*cåÂJÊOt„Ä•c•($$RÏ)ßQvª=ÑCµMH(£±M¢9&nbsp;8Ÿ—3JaKd¨Çà‚WÝ&gt;ô"vÌ¤×îIp	&nbsp;r£Y‚ˆêÉ2‚™TäBw(°§ß'Dk8jÞ›êM•óÜx­¨”€%&lt;àw¢èwÜ¦Ëš‚ÙÊÃ«,CÆ½ˆåQ³¡8�cÁøè‚ø£g¦d|
{ý²$ˆDIÈg,?ªf´Öaìã�5JÒCFêÝ[½ãOã—û†ƒò+ÍÙ!äéÁTí`aÐéÝ%–CQì5Ÿ0‰SÆØMakþ�=Ô[YjIÝ”A'Í»Vƒº¬ÛÍ.âG‡Š²%§O“JuÁì3÷'Æs-‚GˆQcK?êŽi¯	(dXÐðð=ß�æY^á¹¿ ¥f‚,ù†ÀXtÕ§Y�]UÕ®ÊÉ2èE
“òG!®qÿYLæi§ŠEiðë`x.;@àò®dÖÛL°Yî˜RoPµšqø„…£vÈ{œ@ÚÒ|J§•�éÉ$I&lt;'¿=×:`ä‚÷Ù{¤êa#s"˜Ïjñ.·è°•s¢Úãî $¦®ÄÅ�„­ªº;+ún.ü–bS_
æ‚k»��ˆûœâ·ZÏM�ƒP"†˜ö…‡²V®K´žèvâ²Ã1ÉTNªB³ÝU&lt;ôîíwÞ¡öpV¯¦!Gl•NgÙ-š—¢öŸ¢VœÁ…$’æ¶t�S¹§Áh†™�T‹C¹à¹­iðSkO‚ÒH‚àçµ§Á0ø{D�\Óôœ{&amp;Îi•q(DY(ñ5Hž|Q5òSe&amp;WQ2Z"»\¯š™
:©&amp;ÚðÅà;I×•Üj¥`ŸðJ²v‚ïŠ=îW-ãCÇ	&amp;Úã¤iÌø¤‚_"H™Ih-TÂ�r„öN’™BŒÊdò’—”¥DÊyAK¦)Jv‚âO%1Ju]gLú¡_¤,Ë'w%&nbsp;ÀÍaãtóÔóMT·k75
`&gt;(XZ&amp;
ø:¿V:	½ÍÊ¼{¬iüããð]€.&gt;
V*hkF€&gt;J`Âa6×”¸‹&amp;�Tá®“#„iIaXLëÂFóAÊÌ«Ž{Ý¼Ç+ÿ­µƒÖçXÀM”ãË.._.o’$�Áè`'+§}f«(ì´zní¯´üÖÈ;µÆBBÁ[—ðžÄÄ¬D
[¨Ïu=PÜí’ç�îN‰Ë–ÈR¯Nu&lt;ÖËç0ee6í&lt;&amp;:G›D
¼"¢ZJIZwH�µM„wAr�Ú†LËŽˆ¦	@¹Íf¯phã]HQ÷$aE¶ÖýZöŸš‘Is*Õ†•Xhˆ%+õ”6˜&lt;©4’ŸÓkˆ((S0t„àx¨º*]ÙÅ§V<f©*›q)4Â6mydügu78$†Ío�Ëþ@?y¯‚Âšbðx[ƒe³º±òtnèt¼ciŠÐÞrs�0� Ýçîú·cnêÞ—="" µ�-±íŸšêbye@<e½:æòÇiä–6nÿ�cÜ»#ªi(‡ö5ž”�7b¡aØ5ø.¨h¹þ»…clõÙiæ;‘³eìüÔ~Îêõn‡ˆì�n+šÙq“áà¢ëkhk’rõÓeÑ="" “äœâÜiŠÏÜ¥vq ËojŒ–ä48|Ò¤9#¤ßo0="">(Ÿ°cé?îX˜ˆM«’VÎs:5:Ë¾%[«ºGµ€#D$èì’iˆk!…0îÉŠ	!#LÀLÏs•–Ý—+�´Bp!<j[ia*‰kj� %h¤p¢:9(jÑh`§næmlvª\y©="" �¦v�="" å7="" ‹�]tÊa<Êýrsà%hâj="" r�êÊ[äêráwúÊœ·ïp�ym="" �5!@4¹‚uÉm®�\t»²n="" -×¶¨radñ'åø¦k�Àà¢â4="Óz£ÁN©ƒ´”�}S" %Â®'ÄÒlrå]bé“¦ij="" 'l%%);aq�jo="" -žœ(éxã6Ø}Ž$tÏ?8¥²="" ¦uactš}lÖlË+žgò¼‘pþ²ÔëØëñëk[0æ·Üß‚ÃÈÈ³.Çyc‹œíi(p…wg="" îôýcë{îŠñyv¤ü–ïh¦ú¨="" 4<êcz°0°~¬ôºê`Í¼´sé‡�Öî'xÆËs˜×´8"yóºiìg[dm¹oÏ‚y•o'¨cá‚ë,h'î\¯yúÏnt×d²¿Îr�z#-ž�½kÜ£ŠÂ\áÉgo5rÌ¡v…¦w="" õeå™€ÌŽ]sìsù)kcjž:4‹¬¿ÕÆµÇ˜•rË¡êdŒk="">ò®t9Tæ&gt;aäë|0V)öÕ¼^©“…üÝ„¨TÉKrˆ5
éF3 $<uz\­Æ"ê¤ø´¬Î£Ö²:ŒµÇk'fŽ>k8Hã’rK&gt;S9qFþÚòu&gt;¯JþÉ]@.Êåþ®ŸÖ¿°WPJ›Éõs&gt;#üÿø!¥Öz•øU5Õ:	tj'²ÏÄúÓ}@‹Z&lt;GúÉýŸ×þ�
Äv`Çc¨zùØè¡ßUS7¯]šÃ\‚gNcÁe… �AŽŽž?Öªl‡#QüPsú•½Eòýá£€ªè$D]Ó:žkppä[¯X/o®áµÚqßÅc„ð¢UÄöc.Ÿß
MÉ©Ü&lt;}ëŸéÆìÂ[†Ž{£–lt9°˜XH¢ìÛ`}nxŸŠÏvcØá$Ê+o#‚¥un×ƒÂ
.›²¾ÛŽâÃµÍÔøªŒËsAð&gt;&lt;ªÔä;ûù¨e0·QÁå%6ëËŸLÃ¼TßŸe|ãºÌÆp©þà�ÑoÈ/;v’@zrYsCšdpâW1NEø&gt;ÖißP�ûw iµ²‚^Ž°aM`³ë
­°)³ë	t~�$Û¹ ¦…�þ»é�X�ŸXYÝ‡ïI6ê‘ÙIe¬–”AÖè&amp;))ÑžÊ„Bud˜­ÓåÜ"9Ð’Ëú{«væ;O™—X²G~U»y2„ìa� Ž;¤‡›­¥¦¡Z¸xÝÃ¾åÎœZ �ƒ•_´œqéØÝ{$”ôM!ñæ…�˜0ZÕÇ…S¦ä�XãÁU,Éuö9ÏƒàRA.¯IÍvvádHÔG‚ºk±z#ˆ¹Þ·ÚÐ�P6€W¹H²ÄÉÊ¹…lÛ¢+'
æ¤Ñ¸Ó„”�µÁc4„î¢Á/ô†©¸áL¦„­T¶ÐåO�S)p•©®ZZžQœ@°B;¨è¢äÐJ`¥Â+wbæÊA®î�LBH&nbsp;ÀW&lt;¤X§2—)Zh1Æà–ØNd
U1o·”+£�»Dm§ð@{÷�[+¦þ£A�õáAî‰…(=ü!üx÷R2Jþ¯o.QôšNèà$Ž‹l¾DBh…2˜«4ÌÁ(R!2	Y:I$¥'{Í‘¸ÌI¥lôü›v;Íù¶}Á¿Þ’	§Œp˜“À]@ú¿]Ö:ËœËÓ

2×5['£ôìzƒ¾Û%Àgä5WëëX9ÍÄq	òïÞ@›Ùd¤HôÚN¹fNÇ³¬îÕ¬ça?�ä¹¢%÷¿%î²Ã¹ÎÔ”4@¥Ñ�\’yL’I.u&gt;®KþÃ—QÂå¾®Öÿ°WS*9îÅ=Ú½S\[&gt;ò®mt�Sú5ŸùW6ªgù‡“§ðßæ¥ýÿØ	$‘*ò¥KrŠd”ëý]×$Ÿ•ÓÌ…Ì}\Ò÷ä®�®&lt;+8~_«�ñy¿ÁÖú_ø.}tX´Çgõÿ‚ç•ˆìÃ�åe¤¢
tW®
I€Sh”¸R)§
„èô;�Y-og+¥}-´Cš
ãñžê¬kš`ƒ¡]•{ƒFè&amp;5!4±ä±éUK	lýÊ9&nbsp;txh¯‚'MQ@”Ö=žzüXÐ‚ñP¥ñì³äWLkäJ¸Yô˜?"J·#Ä·ï@kßXx]p+¬é1á*§PÂ`föŽ9I.e¹.K´r§:‰”ï¨‡mÕMÂÚu%ø+&lt;5†`ôtë3É- È%[gÕëF¦Æ�Å%,±¦ÜÒÐ¬ë^Òý­:O+cþo·óžuðŒè˜Ìäñ)%Â�ñÕLÖçhÖ’ºZ°¨¯ŠÚ­V8|’\Ìôî�•ë6Í¥°y:hº(ÄÊØ
KNŒ@ÝÊN{kÔ�žˆ�&nbsp;…Õzmö¼¼8¼xO	!Ñ»?­;íl}ë*Ükýµ»tñ#…Mø¯n�aC}1À!$]6)õ(py#·Óy'ty|²ÈkÄÇYuBïÒ³æ)½[½0ÑCœ]`…¯U�&lt;8ñ\®ÍÇP¤âæèÓÂšzñîá&nbsp;.[.úxqûÖ¿OêO¼†9²|Bi\¤Z¥
*aÁp¥
#E)ApXð&nbsp;Ý‰Hj’ä’#„¢
JT¥)D¨¹#²ÈP6nMc€B”ð¥-YÉTƒç…âRÚ•"ÏD­)åEºrœ¶P\-“\Ì(5¾IÊ	¶@§•©)(Úàà&nbsp;Y¸Ÿ’˜¼iðLÙdš	ßv½”’F“)½)è®FîP¬¯w·¶‡_$D–˜5×†È“ÏŠJï§î™ÓÁ$î$p&gt;&amp;™&lt;&amp;á\J”H*A$”Å<jßªÜ_«Ý*œë1y“ve¯k³é±•ó îªÿ�Ï¦ÿ�åvù‡ûÕyóp„Œh:61ò¹2ÇŠ;9pg¯üúoþua˜½ ùòÏüªÂÿ�0ÿ�zoß!Ø®ûŽ^ÎgÍ.v¸úðÓ é8_æï[·ÙÒèèõõá€Ãe‘x¢o ,Üæ—gÉÍÀô(—)’5cso™kÏ–ånù‡ûÓ�¯-ãönù‡ûÐûä;ßqËÙÈå="" waÕy�Ôúuvœvã¼Üêlc="" Øâ‡4v\úž"$ó�Ç#¸u~­ÿ�kþÃ—næÊåþ®ËþÃ—rl="" )³Ý¯?™§Ôçì¶iØ~uÍ®›ªe³à?*æ•lÿ�0òu="">®)ö¸JR)¢-åÒL�%;?W„XOˆ+xè~+&nbsp;xói[¤L«8~_«‘Ï=ôo^þŽßëÿ…w®ÿ0Ïë…·pŽñÙ†3kSì•NÆäUôL…æ[ä|£TW·kbxDÔ¬—ßê8¸ˆ(õå‡VXÿ—‘IN�ÉôÀ.a…¯‚®ÒEe¯c@�yPCÑaa»2ÐÁñ'Éu”ÖÐÑÀ³&gt;®º¶cPØîgŸ%«½¢!ÂIc”¸´f©…D5bà¦)
çT’À¨úzÖyS1)÷h’\¼Ž’Il|]´šµÚ.œù…_#¼¶í°|‚
q¨¹øä=Ÿwå[¸ù-É`{~ïÏåâ[€íuggz|&gt;¢qcPG	%Òê½_ìD1&nbsp;’Ž�‘öÊCÝÏrÖXëís¬úDÊÙ³ª7êïF~o¤,s\Ö“
—’„�²º3�ˆêíÂ–áÙy÷þ:ù¿÷þ—÷¥ÿŽ¾oýÃÆÿ¥ýê?z-¯¸æ{ùÜ”®�lÓÿh±¿ézëúZÿœ&gt;¼ÇT*y±ÌsZ}²ÞâQŽXÈÐbËÊdÅ)lßß	�¹LV×ç¸5­Îqá­•ÃuŸñžêÜêºUM
zÖ
Îw›[ÀùýÈË †ëpòóÌ}/rÜg¿ó	'àH÷T&gt;åãy_[:¾k·Y›wÁ®Øß¹°a}cêØ¶S™vá¬—4ÆºµÒ
�ï
¿ôl«æ}uØXçšÄün%-Ñ¬�‚R=W1Í
uÕË€ãsL&gt;*Ë\§‰ÐœN9ž…‹p)ä´ŠÌ
Ò°§_*ÃBEGT¡ùƒîE­¡œDÚèm}1	I”ü¤&nbsp;¥oRL@*\Üjì¹ÿF¶9çàÑ).M3™•`è¼ŒÿŒ~½sÉnCZ	$4VÈÃP½'&nbsp;uKz§LÃÊ¾=KXw Ò[0™‰eÍËÏD¥Të!&gt;åËˆºã&gt;³ÿŒªú]¯ÅÀ­¶½„µÖ?ù¶¸rÒ„dDwY�²šˆ{_s¸EÌ³÷Jñlï®�k¨³2Æ�Ý¬úmÿ£
�]{©Öàæf^?éýé¾ðc‘�jCíoÓø&nbsp;�
Ëú©Öò:ßKõ²àÛU¦§:#|A&gt;z­"ø:«—°çsöæbw	Zé
s³…X¼
T›l”êb²Ó"Q¢Ø€�¦Te˜ù)B�
[PM!‚Ò&lt;Ê)òOµ1aUR¸Õ&amp;Æ¾*.¸HáL”É³üÔ·MDø§`Ø?/Å9ät`.äÆ“óIJ5ŽÓà’V·^ïˆÊI�Z+V:$‘Õ$ô7tÛ~²ôLZpö¾ìK-/ª@{™f¡Í•Å½Ž­Å®`ƒ¡v+s¦Øêr¨{Zác ƒ�¥õí�g]Í
/iù–´•ŸÍãà—?3§ðüÆCÛ­ƒ�	Bt•GEÔè}&amp;Î£cSwØòEl˜
\ãÙ­]›èÁÌé£êÍW±÷ÖÁc,ýòC‹�X?5�õþ³w–A„m#B Ê³Ëâ'ÉÎçsJŒGOR¬Kpm}°±ì0æžAVº_MvkÛµ®q.ÚÆ7éØî`yx•­þ1åË¿âéÿ¨ŸQls3æ˜,ÄÈsOîº9
Ux¶ýÃìûŸÕ¶×Z¨ô&gt;�GL¹ÌûC²{ØÇúMˆÑßUÎkêïF=o$Vë645ÖYa÷mcD¸ù•§»ê°Óí9‡ÌV þF2†ˆ’ääæ$d#~M«ŸÒÿ°åÓ�&lt;¬œ¡õcÏQ—å“kXî´?çWÕßô¹?öØM–x¡c—)˜� Xu_èÖ|?Šæ—U™nWé™9=&gt;×¸TZ×¶ÆípÜt+:Ÿ«ÂŠFOR½¸•£¿[_ýVr&nbsp;Ë!2ìÝä¢pc”g¡ãÛèyIh»­ý[Å0Ì|¬�å9Â±òJ¾©õo¨×7'ŸÎ$[XøòTZwmñ�øeçNZ\-­Ñ-é[¹¶ÓfµÚÃ,xþR¦—_c+f®sƒGÅÆH�:��¾ŠÝ¶ü…µÂÏ·7¡ý_Èu7&gt;Úý¯ôëö5ÝÆªóÃêïúLŸûmMŽqˆ¢\îcL³âŒI�®4Š[?¿ü(c3ë7ÕÌÆ†ºÜ��+wôü|Œzrúu�º«l5C›µí³÷OÅM±:Äpä„nQ!Í
.¡–r5ñZyöt�«NfºÌŒˆ—UI•Ïg?ÅK§dt�¬®4á‹1² –Wie‘Ù®ñKß…Õ®ö2pñpšpíé›Ìµßz«f
µ™"Vá­Õ¸µÂIA	B•…çý-ú¯¡é=c�mÂ]Ø~ïûV‡HèÇ5þ³ÚÖSYÜû
`�2¬u/­ÿW±Àë256þs£ðQÏ$c¡*ö²eÒ‹™&gt;ööåFÒmƒÇ!Q_z91öÀñ	û¥_éÝ_¢õwãdº‹¼m&gt;N(Æh©—'žÌWo«YåÑØ„Q›m@�å_¿¤_Y-sÃ~H¢‡jë	ùB~ízh±’Óô•†õ¬�50®7¡cÆ¥ÇæŒÞ™�WŸ‰IKáfýªw?‚¶
ƒë«¯V÷×C?yä7î•…“õ÷¡a˜cî¼ŽìnÖýï„ÙN1Ü³CLŸ,KÐƒª9øVdë]…±Û±X/ÿ:tÁ¸�ö�ïE«üet‡ý&lt;|Šþ_ÿ~L÷¡Ý—îYÆ¼+dtü¶È-qøTÃl¯Úö¸|Šé0&gt;°ôžªàÜlÆo&lt;2Àkwý.Uë©u&amp;,oßÂx�–Å†Xç
$x»=Ný•É?X:}ý.Ë]ŽÚêK´isÑ'ÍtvcSx‡0xø(?¦ã&lt;�Ñ7‘Ù)!J„Ì$èøîv
Ý6û1²²ÊÌ8sø&nbsp;Bé?Æ7ü¿•ð¯þ¡«œTH¢ô8ägÈõÖ=íø…éRÝ³¢Uÿ†­^k_ÓoÄ/HúŸÿ"Uÿ†­ü‰ø~p×çÿ™&gt;n÷UÅ·©t¬ÜjGé,¨†Žî�cæ¼`ÔêÜXñ±ÀÁö�~kÚ³º¦'DÅnV]®cK¶·h.{�Î�±¯úûõo,ÎEn´ø¿®?z“(;µy,“Çè2¨|Å˜áÆ
�	qû‚êz'Ôëò›êXÓ�AúwÜ6¼·»jg:ø®‘Ÿ^þ®ãÿGc©?½^3AUoúßÐrÝºìŒ·žÛ™&nbsp;øÈÂ=Kc&amp;|ÄT1‘æìW‘]…•c·e50WXþK{ŸŠÓ¥²ª¦-8ïª«ñŸ¾«[¹Žˆ1æ¯0F�Z�VŽFKâ&lt;[Þ©X%¡gunµƒõ~°üÛv	mm¬Á«�?ã[§µÐÜKËx¹&nbsp;ýÒ™)ÄueÅËä˜±ö“	‹û,ž�õ·¥õøn=Û,?àíö?åØü–w^úÿƒÐ²ß†h²ç×ÜÒÐâ&amp;ojípÁ”Ë„GW¨”òKê”õŒ:³h
²F×}&amp;¹¦0›ªu|&gt;‰KnÍ´Ö×;k@isœF½“¬UôYÃ&gt;.
õvtA“q?ã#ëC1hwKÇtÙdzÄ~c?sâïÈ¨ußñ&nbsp;lc©éuº¹ÐÝdoþËu�‰\œç¸¹Ä’L’L’Or¡žA°or¼œ¬Jb«£*¼¯eë?V[Ñºd~ãÿêÊòjÎ×½êÿ×.�‡Ó°ñ²_kl¥®k%¾çÊn"µìÍÏã–L@DY·¾£Ý¤Á €~!x7Pé÷ôÌ‹1òZXö¸ƒ»¿˜=Áñ^á~MxÎÊ²Ø¡µ‹7€uc¸ÓÍs·ÿŒ/«ÙCmáö�À²€ÿÊ¤Ê«V¯'9ã'Ðd-m ócÎ"ßè?Uòº‰Ç¨ÀÔßhôègò„êè]s&gt;»ýX§ZiôÝÙÍÆl„¿®�;K²²Ü?wÓ¿pÑF!²mO˜ÊG§ú¶ñÝ�Ói«
Åìc‹ßiÿk¹wÁiK€Tº{0z†0ËÁ±Ï¯ycƒÛµÍpª³Ç
î1Ã³‹ŸŒä—ñuJë%·•\h­cTëA2Öêç
Ì§šŠ6M
[5Z§º
çs¾¿ô^˜ïM�³!ÃŸH{?Îq‚¢?ÆŸO{½ØWâÒ~å\å…îÝ‡)˜€D^Õ¯”Rt\ÿHúÝÒ:Óƒ(¼×aâ»†ÂO‘àýëd¸ÖK]¡D-ŠÙ‰c50bœ˜Põ'@„ë'IL,Ø•,3l7„ƒ•qy#ø)zƒOŠ\*ã	÷¯t·xUÄ2@î›qƒ'îG…mÂà’ÿoÉ$8SÆø¼¤Â‹š¯!xLL&amp;„œRµ&amp;Áþ“N¿áÿTþ¿Ë¹ŸÖoýCUlúÍ?ñŒÿª
××ßù{3úÌÿ¨j¥ÎíÿÃœ&gt;O&gt;’”%
‹¯OMõúMÿøFõ�Ž ’Úú�ý*ÿü#zÆ£�òWù/”ù¸ÿþty:Ÿãþ\»þ.Ÿú€§õú]¿øK#ò(ÿŒOùrïøºêŸÔ�úÝ¿øK#ò*å&gt;­ïüþ?¨ÎgÚßSœnÇ¶¦h7¼h¹¼î›‘Ò.v6Me–3�|<gˆg¨{gÁm}zqì¢âi85É<�jµÎca £oáÙ™…nòé)bp©:Ôõv="">³cý\ÁÎ.cl²ÇÔ*¬ýZ	Üï&amp;®o¨õž¯{²2¬6=ÝÏx4vKO£}\»ª¸6ªýG‘¸ÉÛ]Mýëüú¯Õ+q1¬Ê§#!´Çª)tšÁ1:ò½Dx0V(d$ŸTžq%(JYéê~£çŒ§?£d§$NÁ^Ñ ·â›¥Î'P£ÔÓÓ¹»§¶Çkù/D{©ÍÆ±¦o¨�ó—GÖ™³­e´¥qûõþ*HM\±™­¥ú¹_]º^FUÉ¶ÚÈ®û]eoå�kµÐ¬ÜõÇºÏ«o$ìË¬6uÚ{."f(²ròâ…ÑÑf‰#â½ê†u]#êæ^cÚ	£"ÇV?áZÆ~.^tÑ¨ø­¼Ž¡¼jë3,±Àsµ�hoÞOà”MW1�Üˆ�yË{ÝeŽ.sÉs‰ä¸êJ–=ÏÅ±—Vaõ¸=§À´Êg0°Á¥SdŸê»ò&amp;Û/º&gt;‡õ�Í³"¼–@nM5Ü#ÅÃUZU™¹ŽÙ�OÒ=ÞîÌo™PÉÇ³&amp;¾�Cu{ñ+ûGE‹õë«6ü†ôÌsúOiÿ„»óÜ~}êì²ðcÈq±òþîc°.Ö/­?X^EŽÏæèoÑhx•�‡‰ö’díky1?rPanýMclê˜U¸H7‡æÁ#ñTìÈêëpGØ1êSúž9É~%�¬	$–—4x¹�Ô,({'K©Ù9×›	slõðx-3¢ñÝ»I±#î)ù!ÁLŸ2y‘+p—µú“õÉÕ9�;¨&lt;º§Ú¬q÷TîÀŸÝü‹®^úív9‘·Ÿ9î¼®%z7LÏý½Ò*È³Ýv+…6ø¹Ÿ˜â¤Á“^Õø—*÷b?¼ïtç³×»Áë/ÖJ~«cµå¢Ì‹Gè«&lt;ûïòEéµeYUA$¹y�Öž¨î³Õ2r	–ï,g•löµIž|#N­_‡òã&lt;ìü±iõ&gt;©•Ön7åÚë|~‹|š8VkKˆjSÂ6+½'›;´&gt;=•;·tDDPÛ£&nbsp;däËiªËžß¤Ú˜_³ÉÇ‰T21ìÅ±ÕZÇ1Í0ZáµÃâ</gˆg¨{gám}zqì¢âi85é<�jµîca></jßªü_«ý*œë1y“ve¯k³é±•ó îªÿ�ï¦ÿ�åvù‡ûõyóp„œh:61ò¹2çš;9pg¯üúoþua˜½></uz\­æ"ê¤ø´¬î£ö²:œµçk'fž></j[ia*‰kj�></f©*›q)4â6mydügu78$†ío�ëþ@?y¯‚âšbðx[ƒe³º±òtnèt¼cišðþrs�0�></v_¦d¤«§\õvn�*mê¾></bîx9žryç></jž'mèµ°y´è¤ügðv=±ü$ªk�zd"†6ñ1¨qxñe·€šcõ></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://airforceapp.forces.gc.ca/CFAWC/eLibrary/Journal/2012-Vol1/Iss3-Summer/Sections/06-Unrealistic_Expectations-The_Luftwaffes_Doomed_Mission_During_the_Battle_of_Britain_e.pdf">http://airforceapp.forces.gc.ca/CFAWC/eLibrary/Journal/2012-Vol1/Iss3-Summer/Sections/06-Unrealistic_Expectations-The_Luftwaffes_Doomed_Mission_During_the_Battle_of_Britain_e.pdf</a></em></p>]]>
            </description>
            <link>http://airforceapp.forces.gc.ca/CFAWC/eLibrary/Journal/2012-Vol1/Iss3-Summer/Sections/06-Unrealistic_Expectations-The_Luftwaffes_Doomed_Mission_During_the_Battle_of_Britain_e.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399863</guid>
            <pubDate>Mon, 07 Sep 2020 15:00:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[URL query parameters and how laxness creates de facto requirements on the web]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24399774">thread link</a>) | @todsacerdoti
<br/>
September 7, 2020 | https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>URL query parameters and how laxness creates de facto requirements on the web</h2>

	<p><small>September  7, 2020</small></p>
</div><div><p>One of the ways that <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a> (the code behind <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>) is unusual is that it strictly validates the query parameters
it receives on URLs, including on HTTP <code>GET</code> requests for ordinary
pages. If a HTTP request has unexpected and unsupported query
parameters, such a <code>GET</code> request will normally fail. When I made
this decision it seemed the cautious and conservative approach, but
<a href="https://utcc.utoronto.ca/~cks/space/blog/web/CautionIsAMistakeToday">this caution has turned out to be a mistake on the modern web</a>. In practice, all sorts of sites will
generate versions of your URLs with all sorts of extra query
parameters tacked on, give them to people, and expect them to work.
If your website refuses to play along, (some) people won't get to
see your content. <strong>On today's web, you need to accept (and then
ignore) arbitrary query parameters on your URLs</strong>.</p>

<p>(Today's new query parameter is 's=NN', for various values of NN
like '04' and '09'. I'm not sure what's generating these URLs, but
it may be Slack.)</p>

<p>You might wonder how we got here, and that is a story of lax behavior
(or, if you prefer, being liberal in what you accept). In the
beginning, both Apache (for static web pages) and early web
applications often ignored extra query parameters on URLs, at least
on <code>GET</code> requests. I suspect that other early web servers also
imitated Apache here, but I have less exposure to their behavior
than Apache's. My guess is that this behavior wasn't deliberate,
it was just the simplest way to implement both Apache and early
web applications; you paid attention to what you cared about and
didn't bother to explicitly check that nothing else was supplied.</p>

<p>When people noticed that this behavior was commonplace and widespread,
they began using it. I believe that one of the early uses was for
embedding 'where this link was shared' information for your own web
analytics (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/AnalyticsVsSecurity">cf</a>), either based on your logs
or using JavaScript embedded in the page. In the way of things,
once this was common enough other people began helpfully tagging
the links that were shared through them for you, which is why I
began to see various 'utm_*' query parameters on inbound
requests to <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a> even though I never
published such URLs.
Web developers don't leave attractive nuisances alone for long, so
soon enough people were sticking on extra query parameters to your
URLs that were mostly for them and not so much for you. Facebook
may have been one of the early pioneers here with their 'fbclid'
parameter, but other websites have hopped on this particular train
since then (as I saw recently with these 's=NN' parameters).</p>

<p>At this point, the practice of other websites and services adding
random query parameters to your URLs that pass through them is so
wide spread and common that accepting random query parameters is
pretty much a practical requirement for any web content serving
software that wants to see wide use and not be irritating to the
people operating it. If, like <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a>, you stick to your guns and
refuse to accept some or all of them, you will drop some amount of
your incoming requests from real people, disappointing would be
readers.</p>

<p>This practical requirement for URL handling is not documented in
any specification, and it's probably not in most 'best practices'
documentation. People writing new web serving systems that are
tempted to be strict and safe and cautious get to learn about it
the hard way.</p>

<p>In general, any laxness in actual implementations of a system can
create a similar spiral of de facto requirements. Something that
is permitted and is useful to people will be used, and then supporting
that becomes a requirement. This is especially the case in a
distributed system like the web, where any attempt to tighten the
rules would only be initially supported by a minority of websites.
These websites would be 'outvoted' by the vast majority of websites
that allow the lax behavior and support it, because that's what
happens when the vast majority work and the minority don't.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399774</guid>
            <pubDate>Mon, 07 Sep 2020 14:50:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interactive Grass in Godot]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399747">thread link</a>) | @notcodingtoday
<br/>
September 7, 2020 | https://notcoding.today/blog/godot-interactive-grass | <a href="https://web.archive.org/web/*/https://notcoding.today/blog/godot-interactive-grass">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>2020-09-08</p><h2 id="overview">Overview</h2><p><iframe src="https://www.youtube-nocookie.com/embed/Ofk4SSngGb8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><p>This post will go through how we can make interactive grass without destroying the frame rate. The demo runs at around <a href="https://notcoding.today/cdn-cgi/l/email-protection" data-cfemail="380a08085e484b780908000848">[email&nbsp;protected]</a>, with the following PC spec:</p><pre><code>CPU: Ryzen 2600
GPU: GTX 960
RAM: 16 GB</code></pre><p>Yes, I need an upgrade :P</p><h2 id="planting-grass-and-swaying-in-the-wind">Planting grass and swaying in the wind</h2><p>Follow <a href="https://youtu.be/usdwhhZWIJ4">BotW style grass tutorial by lonegamedev</a>. In this tutorial, you will:</p><ul><li>Generate custom mesh with triangles representing grass.</li><li>Generate randomized continuous pattern that represent wind.</li><li>Create shaders that will change vertex position according to the wind.</li></ul><p>The result looks something like this:</p><p><img src="https://notcoding.today/images/godot-interactive-grass/wind_strong_compressed.gif" alt="Strong wind"></p><p>I personally am not a fan of how winds are exaggerated in BotW. I tweaked the shader parameters to make it look more natural:</p><p><img src="https://notcoding.today/images/godot-interactive-grass/wind_gentle_compressed.gif" alt="Gentle wind"></p><p>Unfortunately, the tutorial does not cover light shaders (it uses built-in default diffuse and specular shader). This is fine (as long as you use bulit-in toon diffuse), but we want to make grass wet <em>partially</em> and with fine control. I implemented a simple Blinn-Phong shader. It looks something like this:</p><pre><code>diffuse = DIFFUSE_LIGHT + LIGHT_COLOR * ATTENUATION * ALBEDO;

<span>vec3</span> h = <span>normalize</span>(VIEW + LIGHT);
<span>float</span> gloss = <span>3.5</span>;
<span>float</span> ndoth = <span>dot</span>(NORMAL, h);
<span>float</span> intensity = <span>pow</span>(<span>max</span>(<span>0.0</span>, ndoth), gloss*gloss);
<span>float</span> specular_value = <span>smoothstep</span>(<span>0.0</span>, <span>1.0</span>, intensity);
specular = (is_tip*<span>0.95</span> + <span>0.05</span>) * specular_value * LIGHT_COLOR * (<span>0.01</span> + <span>0.035</span> * wetness);</code></pre><p>Note that <code>wetness</code> variable is set elsewhere. This is covered later. Note that <code>NORMAL</code> has also been rotated around. This is also covered later.</p><h2 id="step-able-grass">Step-able grass</h2><p>The aim is to bend the grass according to physical constraints - someone stepped on it or something is pushing it. With wind sway implemented from above, grass' pitch and yaw are set from a generated value. From here, I think there are two ways of extending the wind sway to make the grass 'step-able':</p><ol><li>Grass shader can keep track of objects that enter its area. Physical information should also be passed into the shader. This is similar to how simple lighting shaders are created from scratch.</li><li>Grass shader has a texture channel that defines pitch/sway value. Wind sway can add on top of this.</li></ol><p>The first solution has bad faults - passing in arrayed data is limited in optimization and extendability. Furthermore, we want the shader to focus on manipulating vertices and fragments, not figure out game logic.</p><p>The second solution allows us to do complex calculations outside shader code and simply pass in the results as a texture. We'll cover later why this is extremely advantageous.</p><h3 id="implementation---logic">Implementation - logic</h3><p>We are going to introduce a texture that wraps the entire grass area. We need to define UV coordinates for the vertices. Reminding ourselves that a single mesh instance is created for all the grass pieces in an area, we can map our UV coordinates as the following:</p><p><img src="https://notcoding.today/images/godot-interactive-grass/uv_example.jpg" alt="UV example"></p><p>The <em>position</em> of the vertex <em>within the area</em> determines the UV coordinate. This means a pixel in the texture map will map to the specific area of grass.</p><p>One catch is that, if you followed the grass tutorial above, UV and UV2 channels are being used for something else. This is fine, we have color channel empty! Note that the grass colour is being derived elsewhere so we can use vertex colour channel. The planter script will contain something like this:</p><pre><code>
rel_pos.x = (pos.x + span) / span / <span>2</span>
rel_pos.z = (pos.z + span) / span / <span>2</span>
multimesh.set_instance_color(index, Color(rel_pos.x, rel_pos.y, rel_pos.z))</code></pre><p>Now that we can pass in 4-dimensional float data (rgba) to a group of grass, we can define a new texture channel as the following:</p><pre><code>r: pitch amount
g: nothing
b: yaw amount
a: how much generated wind impacts</code></pre><p>We can map float values like the following:</p><ul><li>Color 0.5 = 0 degrees sway/pitch. This means color 0.0 = -90 degrees, 1.0 = 90 degrees.</li><li>Alpha 1.0 = full wind impact. Alpha 0.0 = no wind impact.</li></ul><p>Here are some examples:</p><pre><code>Color(0.5, 0, 0.5, 1.0) = normal. No sway, no pitch, generated wind fully impacts.
Color(0.0, 0, 0.5, 0.5) = Pitch by -90 degrees. Generated wind only impacts in half the strength.</code></pre><h3 id="implementation---script">Implementation - script</h3><p>We first initialize dynamic texture:</p><pre><code>func init_wind_texture():
  wind_img = Image.new()
  wind_img.create(wind_texture_size, wind_texture_size, false, Image.FORMAT_RGBA8)
  wind_img.fill(Color(<span>0.5</span>, <span>0.0</span>, <span>0.5</span>, <span>1.0</span>))
  wind_img.lock()

  wind_img_texture = ImageTexture.new()
  wind_img_texture.create_from_image(wind_img, <span>0</span>)

  multimesh.material_override.set_shader_param(<span>"wind_override"</span>, wind_img_texture)</code></pre><p>We can now modify this texture to apply 'stepping'.</p><p>I think the most generic 'stepping' shape is a circle. In order to create a smooth sphere, we need to get <em>gradient</em> of the sphere at each point. I did this by simply 'stepping' to the direction instead of insane vector calculous:</p><pre><code>func draw_wind_override_circle(pos_x, pos_y, rad, strength=<span>1.0</span>, noise=<span>0.0</span>, step_factor=<span>0.01</span>):
  <span>for</span> x <span>in</span> range(max(<span>0</span>, pos_x - rad), min(wind_texture_size, pos_x + rad)):
    <span>for</span> y <span>in</span> range(max(<span>0</span>, pos_y - rad), min(wind_texture_size, pos_y + rad)):
      
      var dist = sqrt(pow(x - pos_x, <span>2</span>) + pow(y - pos_y, <span>2</span>)) / rad
      <span>if</span> dist &lt; <span>1</span> - step_factor:
        
        var x_rot = <span>0.5</span>
        var z_rot = <span>0.5</span>

        var x_pos = (x - pos_x) / rad
        var y_pos = (y - pos_y) / rad

        var root_pos = Vector2(x_pos, y_pos)
        
        var step_vector = root_pos.normalized() * step_factor
        var step_pos = root_pos + step_vector

        
        var root_z = <span>1</span> - sqrt(<span>1</span> - root_pos.x*root_pos.x - root_pos.y*root_pos.y)
        var step_z = <span>1</span> - sqrt(<span>1</span> - step_pos.x*step_pos.x - step_pos.y*step_pos.y)

        var gradient_vector = Vector3(step_pos.x, step_pos.y, step_z) - Vector3(root_pos.x, root_pos.y, root_z)

        
        var a = sqrt(gradient_vector.x * gradient_vector.x + gradient_vector.y * gradient_vector.y)

        var a_rot_factor = <span>0.5</span>
        var x_rot_factor = <span>0.5</span>

        <span>if</span> gradient_vector.z != <span>0</span>:
          a_rot_factor = atan(a / gradient_vector.z) / PI
          x_rot_factor = atan(gradient_vector.x / gradient_vector.z) / PI

        <span>if</span> y_pos &gt; <span>0</span>:
          z_rot = <span>0.5</span> + a_rot_factor * strength
        <span>else</span>:
          z_rot = <span>0.5</span> - a_rot_factor * strength
        x_rot = <span>0.5</span> + x_rot_factor * strength

        x_rot += rand_range(-noise, noise)
        z_rot += rand_range(-noise, noise)

        wind_img.set_pixel(x, y, Color(x_rot, <span>0.0</span>, z_rot, dist))</code></pre><p>Once we draw to <code>wind_img</code>, we need to explicitly re-apply the image to the texture if we want to render in-game:</p><pre><code>wind_img_texture.create_from_image(wind_img, <span>0</span>)</code></pre><h3 id="implementation---shader">Implementation - shader</h3><p>First, save the rotational matrix from generated wind:</p><pre><code><span>mat3</span> rot_right = mat3_from_axis_angle(sway_pitch, wind_right);
<span>mat3</span> rot_forward = mat3_from_axis_angle(sway_yaw, wind_forward);
rotation_factor = rot_right * rot_forward;</code></pre><p>Derive angle from the color value of the texture and find out which axis quadrant the angle is in. Note that X and Z implementations are identical:</p><pre><code>
<span>float</span> wind_override_z = <span>texture</span>(wind_override, COLOR.rb).b;
<span>float</span> z_factor = <span>1.0</span>;
<span>float</span> z_override = <span>0.0</span>;
<span>if</span> (wind_override_z &gt; <span>0.51</span> || wind_override_z &lt; <span>0.49</span>) {
  
  z_override = PI * (wind_override_z - <span>0.5</span>) - <span>0.1</span>;
  <span>if</span> (wind_override_z &lt; <span>0.5</span>) {
    z_factor = <span>-1.0</span>;
  }
}
<span>mat3</span> rot_z = mat3_from_axis_angle(z_override, to_model * <span>normalize</span>(wind_override_z_origin));</code></pre><p>Then apply the rotational matrix:</p><pre><code>
<span>if</span>(x_factor * z_factor &gt; <span>0.0</span>) {
  rotation_factor = rot_z * rot_x * rotation_factor;
} <span>else</span> {
  rotation_factor = rot_x * rot_z * rotation_factor;
}
vertex = rotation_factor * vertex;</code></pre><p>To ensure our light shaders work correctly, <code>rotation_factor</code> needs to rotate <code>NORMAL</code>:</p><pre><code><span>float</span> side = front_facing ? <span>1.0</span> : <span>-1.0</span>;
NORMAL = rotation_factor * NORMAL * side;</code></pre><h3 id="result">Result</h3><p>The result of drawing a circle (sphere) looks like this:</p><p><img src="https://notcoding.today/images/godot-interactive-grass/stepped_simple_compressed.gif" alt="Stepped simple"></p><p>Notice that we have <code>noise</code> argument in the function. This allows us to randomly add noise to the circle. For example:</p><p><img src="https://notcoding.today/images/godot-interactive-grass/stepped_random_compressed.gif" alt="Stepped random"></p><p>This is a handy effect for various scenarios. For example, <a href="https://en.wikipedia.org/wiki/Goku">Goku</a> might go <a href="https://dragonball.fandom.com/wiki/Super_Saiyan">Super Saiyan</a> in the grass. We want the grass to shake and sway as Goku charges Chi.</p><h3 id="detecting-physical-objects-on-the-grass">Detecting physical objects on the grass</h3><p>To detect physical objects, I created collision <code>Area</code> as a child of grass mesh, covering the entire grass area:</p><p><img src="https://notcoding.today/images/godot-interactive-grass/collision_box.png" alt="Grass collision"></p><p>In this <code>Area</code>, an object is tracked upon entering <code>Area</code>. Then, the parent grass reads the tracked objects. determined which <code>draw_wind_override</code> function to use at what size, then manipulate wind texture.</p><p>Note that, for optimization, I made tracking of physical objects strictly 30 fps (ie. on a <code>Timer</code> instead of <code>_delta</code>). This allows smooth-enough reaction from the grass without killing the framerate. This is perfectly fine, since grass moving is just an aesthetic component of the game.</p><h3 id="advantages">Advantages</h3><p>Texture mapping method (over doing this purely on shader) has great performance advantages:</p><ol><li>We have full control over how granular our detail is. If we had done the first solution, we would have to manipulate all impacted grass vertices, one by one (ie. complexity grows with the number of grass pieces). Texture map instead groups vertices together, reducing number of calculations (ie. complexity stays the same with the number of grass pieces).</li><li>We don't have to update sway/pitch information every frame.</li></ol><h2 id="preparing-to-make-grass-for-cut-wet-and-burn">Preparing to make grass for cut, wet and burn</h2><p>We are going to utilize similar texture-to-area mapping that was used above. We will introduce two new texture channels:</p><ol><li>Color override. This texture will change the color of the grass.</li><li>Cut-wet-burn metadata. This texture will define how much the grass is cut, wet or burnt.</li></ol><h2 id="cut-able-grass">Cut-able grass</h2><p>The aim is to make grass cut-able when someone swings a sword. Since vertex manipulation is expensive, we will simulate this by simply making the grass shorter.</p><p>Let <code>r</code> of cut-wet-burn metadata texture as how short the grass is. <code>r=0.0</code> is full length, <code>r=1.0</code> is no length. Shader can read this value and alter the vertex position:</p><pre><code>
vertex.y *= INSTANCE_CUSTOM.y * (<span>1.0</span> - <span>texture</span>(cut_wet_burn_metadata, COLOR.rb).r);</code></pre><p>I think you can come up with good script logic if you have gone through wind texture logic. Manipulate the metadata texture according to your needs :)</p><p>With this, we can …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://notcoding.today/blog/godot-interactive-grass">https://notcoding.today/blog/godot-interactive-grass</a></em></p>]]>
            </description>
            <link>https://notcoding.today/blog/godot-interactive-grass</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399747</guid>
            <pubDate>Mon, 07 Sep 2020 14:45:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Basic Uptime Monitor]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399724">thread link</a>) | @todsacerdoti
<br/>
September 7, 2020 | https://blog.mattclemente.com/2020/09/06/pipedream-uptime-monitoring.html | <a href="https://web.archive.org/web/*/https://blog.mattclemente.com/2020/09/06/pipedream-uptime-monitoring.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>06 Sep 2020</span></p><p>During a <a href="https://www.youtube.com/watch?v=Ce7nvF45GNk">recent live-coding session</a>, I tried to build a website uptime monitor with <a href="https://pipedream.com/">Pipedream</a>. Even with a few digressions, I managed to get most of it done within the hour, and figured that the process and platform were worth sharing.
<!--more--></p>

<h2 id="some-pipedream-context">Some Pipedream Context</h2>

<p>If you’re unfamiliar, Pipedream is a severless platform with a particular focus on making it easy for developers to integrate with external services. I was introduced to it as “Zapier + AWS Lambda,” which doesn’t quite do it justice, but does convey the general idea.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p>

<p>Pipedream provides the ability to build <a href="https://docs.pipedream.com/workflows/">workflows</a>, which are a series of steps that can run code (Node.js) and interact with external services. These can be <a href="https://docs.pipedream.com/workflows/steps/triggers/#app-based-triggers">triggered in a variety of ways</a>, including email, HTTP/webhooks, a growing number of apps, and of particular interest to this post, via a cron schedule<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>. Within the Node.js steps, you can install and use most npm packages, and you can set and pass variables along the steps of your workflow.</p>

<p>All of this seemed pretty powerful, and after getting a feel for the platform, I wanted to use it to make something practical. So, I set out to make a workflow for monitoring my blog’s uptime.</p>

<h2 id="the-uptime-monitor-workflow">The Uptime Monitor Workflow</h2>

<p>So as not to bury the lede too far, here’s the <a href="https://pipedream.com/@mjclemente/website-monitor-p_KwCrmN/readme">finished workflow</a>, that you can use or customize to suit your needs. And here’s an outline of the steps it currently uses:</p>

<ol>
  <li><strong>Trigger</strong> - Because I wanted to check the uptime of my blog regularly, I used the <a href="https://docs.pipedream.com/workflows/steps/triggers/#cron-scheduler">Cron Scheduler</a>. Depending on how aggressive you want to be with monitoring, you could have it run the workflow every minute. Just keep in mind that these will eat into your daily free compute limit<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>, so a more relaxed schedule - say every 5 minutes - might be more appropriate for a non-critcal website.</li>
  <li><strong>Make the HTTP request</strong> - I’m using <a href="https://www.npmjs.com/package/axios">axios</a>, but you could use <a href="https://www.twilio.com/blog/2017/08/http-requests-in-node-js.html">any number of approaches</a> to making the HTTP request. When building your workflow, you’ll want to make sure that it’s handling error response codes properly. I used <a href="https://httpstat.us/">httpstat.us</a> to simulate 400 error codes while testing. I also decided that monitoring the response time would be helpful, so I added this, using <a href="https://github.com/axios/axios#interceptors">axios request/response interceptors</a>.</li>
  <li><strong>Determine if the website is down</strong> - Based on the result of the HTTP request, this step returns a boolean parameter, indicating if the website is down. Nothing fancy here - if it doesn’t return a 200 response, it’s considered down.</li>
  <li><strong>Send an alert email (or not)</strong> - The job of this step is to send the downtime alert email. However, in most cases the website isn’t down. There isn’t a built-in way to skip steps in a workflow, so the body of this function is wrapped in an if-statement, evaluating the boolean result of the previous step. If it’s not down, it doesn’t send the email.</li>
  <li><strong>Bonus - track metrics with Datawaves</strong> - While not necessary for uptime monitoring, this additional step provides some interesting reporting/analytics about the website being monitored. While browsing Pipedream’s <a href="https://docs.pipedream.com/apps/all-apps/#apps">list of integrated apps</a>, I came across <a href="https://datawaves.io/">Datawaves</a> - an event analytics platform that provides a generous free tier. So, I set up a free account and the results of the uptime check (status code, status text, and request duration) get pushed into Datawaves. In their dashboard, I can easily analyze the results of my uptime checks - average response duration, number of downtime results, etc. Pretty nifty!</li>
</ol>

<p>And that’s it - a free, and pretty powerful website uptime monitor with Pipedream.</p>

<p>Now, there’s certainly more that we could do to improve this workflow. For example, we could limit the frequency with which the error alert emails are sent - because if you’re checking the uptime every minute, you probably don’t want an email every minute about it being down. We could also build in some degree of fault tolerance; for example, if you’re checking every minute, don’t send the alert unless you get two consecutive downtime readings. And, while we’re brainstorming, we could abstract the workflow further, triggering it via a webhook and passing in the website dynamically; that way we could use it to monitor multiple websites. All that said, I think it’s a perfectly sufficient starting point.</p>

<p>Finally, if you’re interested in trial and error, here’s the live-coding session where I started the project.</p>

<p>
  <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/Ce7nvF45GNk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<hr>



</div>


	



    </div></div>]]>
            </description>
            <link>https://blog.mattclemente.com/2020/09/06/pipedream-uptime-monitoring.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399724</guid>
            <pubDate>Mon, 07 Sep 2020 14:41:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Would you have survived the Titanic?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24399573">thread link</a>) | @aliabd
<br/>
September 7, 2020 | https://www.gradio.app/hub/hub-titanic#2 | <a href="https://web.archive.org/web/*/https://www.gradio.app/hub/hub-titanic#2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.gradio.app/hub/hub-titanic#2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399573</guid>
            <pubDate>Mon, 07 Sep 2020 14:20:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Playwright and Puppeteer – Intercept Request and Response]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399552">thread link</a>) | @hlenke
<br/>
September 7, 2020 | https://theheadless.dev/posts/request-interception/ | <a href="https://web.archive.org/web/*/https://theheadless.dev/posts/request-interception/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>When we browse the web, a series of HTTP requests and responses are exchanged between our browser and the pages we are visiting. There are scenarios in which it is useful to monitor or manipulate this traffic, instead of letting it happen as-is.</p> <h2 id="request-interception"><a href="#request-interception">#</a> Request interception</h2> <p>Request interception enables us to observe which requests and responses are being exchanged as part of our script's execution. For example, this is how we could print them out when we load our <a href="https://danube-webshop.herokuapp.com/" target="_blank" rel="noopener noreferrer">test website</a>:</p>  <p>We might want to intervene and filter the outgoing requests. For example, when <a href="https://theheadless.dev/posts/basics-scraping.html">scraping web pages</a>, we might want to block unnecessary elements from loading in order to speed up the procedure and lower bandwidth usage.</p> <p>In the following snippet we are going to abort all requests for images on our test website. We will identify them based off of their <a href="https://pptr.dev/#?product=Puppeteer&amp;version=v5.2.1&amp;show=api-httprequestresourcetype" target="_blank" rel="noopener noreferrer"><code>resourceType</code></a>, while letting all other requests through without modification.</p>  <p>As a result, you will see the website logo not being loaded.</p> <p><img src="https://theheadless.dev/request-interception-image.png" alt="test site without images"></p> <p>Similarly, switching the <code>resourceType</code> to <code>stylesheet</code> would result in the target website loading without any CSS styling.</p> <p><img src="https://theheadless.dev/request-interception-css.png" alt="test site without css"></p> <h2 id="response-interception"><a href="#response-interception">#</a> Response interception</h2> <p>Isolating one or more software components from their dependencies makes them easier to test. We can do so by substituting interactions with such dependencies with simulated, simplified ones. This is also known as <em>stubbing</em>.</p> <p>Puppeteer makes it easy for us, as for every request we can intercept we also can stub a response. This functionality is <a href="https://github.com/microsoft/playwright/issues/1774" target="_blank" rel="noopener noreferrer">not yet available in Playwright</a>.</p> <p>Every time we load it, our test website is sending a request to its backend to fetch a list of best selling books. For our example, we are going to intercept this response and modify it to return a single book we define on the fly.</p>  <p>Here is what the homepage will look like with our stubbed response:</p> <p><img src="https://theheadless.dev/response-interception.png" alt="test site with stubbed response"></p> <p>Run the above examples as follows:</p>  <h2 id="takeaways"><a href="#takeaways">#</a> Takeaways</h2> <ol><li>Puppeteer and Playwright give us control over outgoing HTTP requests.</li> <li>With Puppeteer we can easily stub HTTP responses.</li></ol> <h2 id="further-reading"><a href="#further-reading">#</a> Further reading</h2> <ol><li>Official documentation on this topic from <a href="https://pptr.dev/#?product=Puppeteer&amp;version=v5.2.1&amp;show=api-class-httprequest" target="_blank" rel="noopener noreferrer">Puppeteer</a> and <a href="https://playwright.dev/#version=v1.3.0&amp;path=docs%2Fnetwork.md&amp;q=handle-requests" target="_blank" rel="noopener noreferrer">Playwright</a>.</li> <li><a href="https://martinfowler.com/articles/mocksArentStubs.html" target="_blank" rel="noopener noreferrer">Mocks Aren't Stubs</a> by Martin Fowler.</li></ol></div></div>]]>
            </description>
            <link>https://theheadless.dev/posts/request-interception/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399552</guid>
            <pubDate>Mon, 07 Sep 2020 14:16:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Co-Occurrence of Movie Genres with Chord Diagrams]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399550">thread link</a>) | @shahinrostami
<br/>
September 7, 2020 | https://datacrayon.com/posts/statistics/data-is-beautiful/co-occurring-pokemon-types/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/statistics/data-is-beautiful/co-occurring-pokemon-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
            <div>
                <div>
                <div>
                    <h2>Data is Beautiful</h2>
                    <p>
                    A practical book on data visualisation that shows you how to
                    create static and interactive visualisations that are engaging and
                    beautiful.
                    </p>
                    <p><a href="https://datacrayon.com/shop/product/data-is-beautiful/">Get the book</a>
                </p></div>
                <p><img src="https://datacrayon.com/images/datacrayon/shop/covertop_dib.jpg">
</p>
                </div>
            </div>
            </div>
        </div><div itemprop="articleBody text">
    <!--% if post.meta('has_toc'):-->
    

        

        


    
    
                
                    

                        

    <div id="support-this-work-top">
                                <p>Made with Chord Pro</p>
                                <p>
                        You can create beautiful interactive visualisations like this one with <a href="https://datacrayon.com/shop/product/chord-pro/">Chord Pro</a>. Learn how to make beautiful visualisations with the book, <a href="https://datacrayon.com/shop/product/data-is-beautiful/">Data is Beautiful</a>.</p>
                            </div>

            

    


                    <div id="support-this-work-bottom">
                                    <p>Made with Chord Pro</p>
                                    <p>
        You can create beautiful interactive visualisations like this one with <a href="https://datacrayon.com/shop/product/chord-pro/">Chord Pro</a>. Learn how to make beautiful visualisations with the book, <a href="https://datacrayon.com/shop/product/data-is-beautiful/">Data is Beautiful</a>.
        </p>
                                </div>
                            </div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/statistics/data-is-beautiful/co-occurring-pokemon-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399550</guid>
            <pubDate>Mon, 07 Sep 2020 14:16:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jazz Musician Becomes a Developer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399514">thread link</a>) | @Pete-Codes
<br/>
September 7, 2020 | https://www.nocsdegree.com/musician-developer-makers-bootcamp/ | <a href="https://web.archive.org/web/*/https://www.nocsdegree.com/musician-developer-makers-bootcamp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://www.nocsdegree.com/content/images/size/w300/2020/07/dani_booysen.jpg 300w,
                                https://www.nocsdegree.com/content/images/size/w600/2020/07/dani_booysen.jpg 600w,
                                https://www.nocsdegree.com/content/images/size/w1200/2020/07/dani_booysen.jpg 1000w,
                                https://www.nocsdegree.com/content/images/size/w2000/2020/07/dani_booysen.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://www.nocsdegree.com/content/images/size/w2000/2020/07/dani_booysen.jpg" alt="From musician to developer at Vodafone thanks to Makers bootcamp">
                </figure>
                <section>
                    <div>
                        <p>Danielle became a programmer after learning to code at <a href="https://makers.tech/?utm_campaign=NoCSdegree&amp;utm_source=paulablog">Makers</a> coding bootcamp in London. She now works as a Front End Developer at UK telecoms giant Vodafone. In this interview she talks about her transition from musician to developer, her experience learning to code at Makers and her tips for beginners on getting better and getting hired.</p><h2 id="hey-can-you-introduce-yourself">Hey, can you introduce yourself?</h2><p>Hiya! I’m Dani, a frontend developer at Vodafone. I'm normally based in their London office when not working from home in beautiful Richmond. (gotta find the silver lining in 2020). Originally hailing from sunny South Africa, I’ve been a performing musician for as long as I can remember.</p><p>Although my former career as jazz pianist and vocalist only really took off during a 4-year stint in Dubai in 2010. After that I moved back to South Africa with my partner (now husband). I took up copywriting, emigrated to the UK and decided I wanted to learn to code. &nbsp;</p><p>I spent 4 months on a luxury cruiseliner entertaining people and saving up money. I came back to London, adopted the loveliest tabby moggie on the planet, and got into Makers (woohoo!). I landed my job at Vodafone in week 10 of the course and started to work there 3 weeks after graduation. 20 months later I’m still there!</p><h2 id="what-does-a-typical-day-as-a-software-developer-at-vodafone-look-like-for-you">What does a typical day as a software developer at Vodafone look like for you?</h2><p>I’m in the team responsible for checkout. Like most tech companies we follow Agile methodologies. So a typical day starts with enough time to grab a coffee and catch up on emails and unfinished tasks from the previous day. This is followed by a standup meeting at 10:15 am during which we briefly share things the rest of the team need to know (blockers, dependencies, tasks outside our scope, etc.). </p><p>Once a week our scrum master will use this time to quickly go over the Azure DevOps board. It help us tetris-slam those blockers and get back to what we do best - solving problems by building stuff with code (and drink coffee). </p><p>After that we’ll each pick up or carry on with a ticket. I mostly work solo, sometimes pairing and sometimes in mob-sessions if there’s a conundrum that needs looking at from more than 2 angles. During permanent lockdown everyone’s encouraged to take 12-1pm off completely. As in “move away from the computer.” There’s a strong mental health initiative at Vodafone which I greatly appreciate. </p><p>The rest of the day is spent coding, making and reviewing PRs. I also liase with other teams in Vodafone on data, APIs, environments, and testing and creating independent releases. I have fun in the Slack Random channel, and attend company meetings/lightning talks/workshops.</p><h2 id="how-did-you-first-get-interested-in-coding">How did you first get interested in coding?</h2><p>My husband is a brilliant self-taught principal frontend engineer. I’ve been watching from the sidelines for years, but was too scared to try it for myself. Don’t get me wrong: I wanted to. I felt that I had waited too long to start, and I had no idea where to start, and the longer I waited… well, you get the gist. </p><p>As a kid I was always on my dad’s computer; I loved logic-based puzzles and was that nerdy girl on our school’s chess team. I still regret not having learnt the basics of programming then. Times were different, especially in South Africa, and I had my music to focus on. </p><p>Fast-forward to December 2017. It was pretty much a combo of me itching to learn. Plus, some health issues made my 8 gigs-a-week schedule less appealing and viable as a full-time job. As well as a desire to challenge myself on a cognitive level… and I’ve definitely succeeded there! </p><figure><img src="https://www.nocsdegree.com/content/images/2020/07/hackathon-dani--1-.jpg" alt="Dani at a Hackathon" srcset="https://www.nocsdegree.com/content/images/size/w600/2020/07/hackathon-dani--1-.jpg 600w, https://www.nocsdegree.com/content/images/size/w1000/2020/07/hackathon-dani--1-.jpg 1000w, https://www.nocsdegree.com/content/images/2020/07/hackathon-dani--1-.jpg 1600w" sizes="(min-width: 720px) 720px"></figure><h2 id="what-attracted-you-to-the-makers-coding-bootcamp">What attracted you to the Makers coding bootcamp?</h2><p>I initially found out about another London-based bootcamp, Founders &amp; Coders. It sounded amazing. But the entry requirements were pretty strict for an absolute beginner. I decided to train for it anyway. If I didn’t get accepted by their next application date then I’d probably be ready for a junior dev role anyway. In April 2018 I looked at different bootcamps again. </p><p>Makers was the only one that appealed to me. They weren’t ageist in the slightest (I was 35 at the time). They had a plethora of success stories. The people there seemed genuinely happy. &nbsp;The one thing that put me off was that it seemed too good to be true. I applied all the same, and the rest is magical did-this-really-happen history.</p><h2 id="what-did-you-enjoy-about-learning-to-code-at-makers">What did you enjoy about learning to code at Makers?</h2><p>Everything. </p><ul><li>Dana (Chief Joy Officer/therapist/yoga instructor/awesome human being)</li><li>the students and the coaches</li><li>the culture</li><li>the excitement of learning and applying new theories all the time </li><li>the ancient brick building letting sun dance through its giant windowsthe workshops, </li><li>the lunchtime excursions</li><li>the “aha!” moments when an alien concept suddenly hit home</li><li>the pairing exercisesthe staying-until-7:30pm-to-soak-up-all-the-knowledge days</li><li>the lovely angels who clean and run the show, Johanna and Kinga</li><li>the falling-over-and-laughing-at-yourself yoga sessions- the District Line hour each way with my laptop making tests fail then pass</li><li>the free fruit and breakfast goodies (and fresh bread with Nutella at the start of the week)</li><li>the caring career team. </li></ul><p>I’m terrible at ping pong, but that too would be on my list if I weren’t. Mainly, Makers gave me hope, and the belief that I could really be a dev. It was a wonderful time (even though I burnt myself out over weekend projects).</p><h2 id="what-advice-do-you-have-for-someone-without-a-cs-degree-who-wants-to-get-into-programming">What advice do you have for someone without a CS degree who wants to get into programming?</h2><p>Start small, and keep going. Find a good resource that works for you. I’ll forever sing freeCodeCamp’s praises. Then work through it and reference trusted guides. W3Schools when you’re new, and MDN docs when you’re more competent and confident. There’s a LOT of info out there and it’s easy to get sucked into the rabbit hole of “patching a problem” and “throwing sh** at a wall”. Also, read books and blogs on programming. And take breaks! </p><p>If you don’t want to be a script-kiddy who copy-pastas (which you don’t, I promise you), then practice writing from scratch. You’ll of course learn from copying examples first, but the only way to actually become a coder is to code. </p><p>Make peace with the fact that people who studied CS will probably have a wealth of knowledge drilled into them. To this day I know and understand music, especially Jazz theory, better than most professional performing musicians I’ve met. But that doesn’t mean that I’m better than them. On the contrary. A lot of them are masters at their instruments because they practice. And that’s what makes them brilliant. </p><p>If you’re learning on your own, it’s a good idea to go to regular meetups with &nbsp;coaches and people at your level. Free Code Camp’s online community is a great starting point. You can’t go wrong with #100DaysOfCode on Twitter either. TL;DR? Don’t be intimidated, work hard, use good source materials, read books, take breaks, code from scratch, go to meetups, and have fun.</p><h2 id="have-you-ever-had-imposter-syndrome-as-a-developer">Have you ever had imposter syndrome as a developer?</h2><p>Um, I had constant imposter syndrome as a lifelong musician. So needless to say it followed me into the world of Javascript, NodeJS, React, MobX, Jest, Codecept, Docker, WebPack and AWS. </p><p>The amount of times I’ve channelled the “I have no idea what I’m doing” Golden Retriever is embarrassing. It’s also hard sometimes to know whether it’s imposter syndrome or whether you’re really just not cut out for this job. I’ll give you a hint: it’s imposter syndrome. My secret for beating it? Always learning and improving, and gathering empirical evidence of my accomplishments. Being nice to yourself doesn’t hurt, either.</p><figure><img src="https://www.nocsdegree.com/content/images/2020/07/dani-panel-talk-voda-paddington.jpg" alt="Dani talks on a panel discussion at Vodafone" srcset="https://www.nocsdegree.com/content/images/size/w600/2020/07/dani-panel-talk-voda-paddington.jpg 600w, https://www.nocsdegree.com/content/images/size/w1000/2020/07/dani-panel-talk-voda-paddington.jpg 1000w, https://www.nocsdegree.com/content/images/2020/07/dani-panel-talk-voda-paddington.jpg 1080w" sizes="(min-width: 720px) 720px"></figure><h2 id="how-did-you-get-your-first-job-before-even-completing-the-makers-course">How did you get your first job before even completing the Makers course? </h2><p>Sometimes after years of struggle, upheaval, stress, and hopelessness, all your determination pays off. There <em>is</em> light at the end of the career-change tunnel. Throughout the course the career coaches would meet with students. They would find out what we wanted and what our strengths were. During week 9 Elspeth Coates, asked me whether I was up for meeting Rob Greville, the head of development at Vodafone. He would interview nine other candidates - &nbsp;all Makers alumni - for two junior frontend roles. </p><p>I was the final interviewee of the day. He was genuinely enthusiastic about Vodafone transforming from a telecoms into a tech company. Plus the fantastic dev culture they were building, so when he asked me if I wanted to do the tech test I nearly saluted. And when I saw the test, a simple UI spec, I thought: I can do this. But if I wanted the job I had to do it in React, a framework I hadn’t touched yet, and with tests. </p><p>I recreated the designs in HTML, CSS and jQuery. Ben Tomkins, a friend and former Maker, told me exactly what Udemy course to do at 1.5 speed. He graciously lent me his expensive headphones so that I could complete it at class. Thus I learnt React’s barebone-basics in a few hours, and applied it to my test in a few days. </p><p>My husband told me about PropTypes and did a quick sanity check before I submitted the final product. A few days later I got the email offer! It was a good week. :) After that, I had the pleasure of having the amazing Lauren Lindsey as my programme manager for the year. She made sure I was in good hands and she checked in weekly.</p><h2 id="what-are-your-career-ambitions-for-the-future">What are your career ambitions for the future?</h2><p>I want to become really good at development. There’s so much to know, and there’s always a better way of doing things. New versions/methods/libraries/frameworks are always being released. So at the moment I’m focused on refining my knowledge and usage of React functional components with hooks. We use classical components with MobX state management at work. Also, TypeScript, and performance improvements. </p><p>Maybe I’ll build a few handy delightful-to-use apps first, but a game is the long-term goal. As long as I’m also part of the creative storyboarding and UX/UI, I’m happy. I’d also like to get involved …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nocsdegree.com/musician-developer-makers-bootcamp/">https://www.nocsdegree.com/musician-developer-makers-bootcamp/</a></em></p>]]>
            </description>
            <link>https://www.nocsdegree.com/musician-developer-makers-bootcamp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399514</guid>
            <pubDate>Mon, 07 Sep 2020 14:11:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Slow Is Smooth, Smooth Is Fast; We Spend 25% of Our Time Refactoring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399511">thread link</a>) | @lanecwagner
<br/>
September 7, 2020 | https://qvault.io/2020/09/01/slow-is-smooth-smooth-is-fast-25-of-our-time-refactoring/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/09/01/slow-is-smooth-smooth-is-fast-25-of-our-time-refactoring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p><a href="https://app.qvault.io/">My team</a> has been spending less of our “free” time working on bugs and features from the backlog, and more time refactoring our codebases and test suites. As a result, and perhaps somewhat counterintuitively, we’ve noticed a significant increase in our throughput of features and bug fixes.</p>



<p>As it turns out, its easy to find bugs and add features to a well-written codebase that the entire team is familiar with. Go figure.</p>



<p>My team started a loose goal to spend 25% of our time refactoring, revisiting, and restyling existing code and tests. Let’s go over some of the benefits we’ve seen since making the change.</p>



<h2>Context and Caveats</h2>



<p>I’ve found that in articles like this it’s important to give as much context to the situation as possible, as certain development methodologies may work better or worse in teams with a different size, tech stack, or development process. Here are some notable things about our situation:</p>



<ul><li>3 engineers on my team, ~16 in the company</li><li>Tech stack – Go, Postgres, ElasticSearch and RabbitMQ</li><li>Microservices architecture on Kubernetes</li><li>Kanban-style development process – <a href="https://qvault.io/2020/05/18/leave-scrum-to-rugby-i-like-getting-stuff-done/">no scrum</a></li><li>Our team is responsible for ~14 repositories</li><li>Each repo represents a small service in a data pipeline process that handles sorting and NLP of social media posts</li></ul>



<div><figure><img loading="lazy" src="https://qvault.io/wp-content/uploads/2020/09/go_kubernetes-1024x592.png" alt="Go Kubernetes" width="512" height="296" srcset="https://qvault.io/wp-content/uploads/2020/09/go_kubernetes-1024x592.png 1024w, https://qvault.io/wp-content/uploads/2020/09/go_kubernetes-300x173.png 300w, https://qvault.io/wp-content/uploads/2020/09/go_kubernetes-768x444.png 768w, https://qvault.io/wp-content/uploads/2020/09/go_kubernetes-150x87.png 150w, https://qvault.io/wp-content/uploads/2020/09/go_kubernetes.png 1245w" sizes="(max-width: 512px) 100vw, 512px" title="go kubernetes"></figure></div>



<h2>Code Familiarity</h2>



<p>With only 3 engineers on the pipeline team and ~14 repositories (Mostly REST APIs and ETL processes), it was hard for all three of us to be super familiar with all the code. When we needed a new microservice, one team member typically wrote the first iteration, and one other team member did a quick code review. The engineer who did the first iteration would then be primarily responsible for bug fixes and new features relating to that project.</p>



<p>By focusing more of our time on reviewing and refactoring existing code, it gave us a chance to hop into projects that we never would have had a reason to become familiar with. Not only does getting more eyes on a project mean the overall code quality will likely go up, but it also means we aren’t hosed when the original maintainer has gone.</p>



<h2>Slow to Fix Bugs</h2>



<p>When you get deep into spaghetti code, it can be really hard to find bugs. Not only that but in a messy codebase, sometimes fixing a bug can actually <em>add</em> to the “uncleanliness” of the code. You may have to exacerbate or extend an already bad architectural pattern in order to get a bug fix in.</p>



<p>Ideally, you would do the refactoring first and then fix the bug (assuming the bug still exists after a good refactoring). Unfortunately, oftentimes there isn’t enough time to refactor a project before fixing a critical bug. For this reason, we should always be refactoring so that bug fixes can happen quickly and won’t make the code quality worse than it is.</p>



<h2>Slow to Add Features</h2>



<p>I don’t want to beat a dead horse, the reasoning here is largely the same as with bug fixes. Adding features to a messy codebase just makes it messier. It’s like frosting a cake that’s been thrown on the ground – it might taste marginally better but now it’s even harder to clean up.</p>



<div><figure><img loading="lazy" width="500" height="261" src="https://qvault.io/wp-content/uploads/2020/09/happy_birthday_to_ground.gif" alt="Happy Birthday to the Ground" title="happy birthday to ground"></figure></div>



<h2>Try It Yourself</h2>



<p>Since adding a consistent refactoring process to our team’s routine, we’ve been able to put <em>more</em> features through to production while spending <em>less</em> time working on them. Let me know what you think and if you have a different experience.</p>





		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/09/01/slow-is-smooth-smooth-is-fast-25-of-our-time-refactoring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399511</guid>
            <pubDate>Mon, 07 Sep 2020 14:11:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons Learned from SSH Credential Honeypots]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399463">thread link</a>) | @ProfDreamer
<br/>
September 7, 2020 | https://systemoverlord.com/2020/09/04/lessons-learned-from-ssh-credential-honeypots.html | <a href="https://web.archive.org/web/*/https://systemoverlord.com/2020/09/04/lessons-learned-from-ssh-credential-honeypots.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <div>
    <p>For the past few months, I’ve been running a handful of SSH Honeypots on some
cloud providers, including <a href="https://cloud.google.com/">Google Cloud</a>,
<a href="https://m.do.co/c/b2cffefc9c81">DigitalOcean</a>, and
<a href="https://shareasale.com/r.cfm?b=1380239&amp;u=2497236&amp;m=46483&amp;urllink=&amp;afftrack=">NameCheap</a>.
As opposed to more complicated honeypots looking at attacker behavior, I decided
to do something simple and was only interested in where they were coming from,
what tools might be in use, and what credentials they are attempting to use to
authenticate.  My dataset includes 929,554 attempted logins over a period of a
little more than 3 months.</p>

<p>If you’re looking for a big surprise, I’ll go ahead and let you down easy: my
analysis hasn’t located any new botnets or clusters of attackers.  But it’s been
a fascinating project nonetheless.</p>

<!--more-->

<h2 id="honeypot-design">Honeypot Design</h2>

<p>With a mere 200ish lines of Go, I implemented a honeypot server using the
<a href="https://pkg.go.dev/golang.org/x/crypto/ssh?tab=doc"><code>golang.org/x/crypto/ssh</code></a>
library as the underlying implementation.  I advertised a portable OpenSSH
version as the server version string (sent to clients on connection).  I then
logged each connection to a SQLite database, including the timestamp, IP
address, client version, and credentials used to (attempt to) authenticate.</p>

<h2 id="analysis-of-credentials">Analysis of Credentials</h2>

<p>In a surprise to absolutely nobody, <code>root</code> is by far the most commonly tried
username for login sessions.  I suspect there must be many attackers trying
lists of passwords with just <code>root</code> as the username, as 78% of attempted logins
were with username <code>root</code>.  None of the remainder of the top 10 are particularly
surprising, although <code>usuario</code> was not one I expected to see.  (It is Spanish
for <code>user</code>.)</p>

<p>Blank passwords are the most common attempted passwords, followed by other
obvious choices, like <code>123456</code> and <code>password</code>.  Just off the top 10 list was a
surprising choice of password: <code>J5cmmu=Kyf0-br8CsW</code>.  Interestingly, a Google
search for this password only finds other people with experience running
credential honeypots.  It doesn’t appear in any of the password wordlists I
have, including <a href="https://github.com/danielmiessler/SecLists">SecLists</a> and
others.  If anyone knows what this is a password for, I’d love to know.</p>

<p>There were a number of other interesting passwords such as <code>7ujMko0admin</code>, used
for a bunch of networked DVRs, and also known to be used by malware attacking
IoT devices.  There are other passwords that don’t look obvious to a US-centric
view of the world, like:</p>

<ul>
  <li><code>baikal</code> – a lake in Siberia</li>
  <li><code>prueba</code> – Spanish for test</li>
  <li><code>caonima</code> – a Mandarin profanity written in Pinyin</li>
  <li><code>meiyoumima</code> – Mandarin for “no password”</li>
  <li><code>woaini</code> – Mandarin for “I love you”</li>
  <li><code>poiuyt</code> – <strike>The name for an optical illusion also known as the "devil's tuning
fork"</strike> <strong>Edit:</strong> multiple redditors pointed out this is the begginning
of the top row of the keyboard from right to left.</li>
</ul>

<p>There are also dozens and dozens of keyboard walks, like <code>1q2w3e</code>, <code>1qaz@WSX</code>,
and <code>!QAZ2wsx</code>.  There are many more that took me much longer to realize they
were keyboard walks, such as <code>4rfv$RFV</code> and <code>qpwoei</code>.</p>

<p>It has actually fascinated me to look at some of the less obvious passwords and
discern their background.  Many are inexplicable, but I assume they are from
hardcoded passwords in devices or something along those lines.  Or perhaps
someone let their cat walk across the keyboard to generate it.  I’ve certainly
had that experience.</p>

<p>Overall, the top 10 usernames and top 10 passwords (not necessarily together)
are:</p>

<table>
  <thead>
    <tr>
      <th>Username</th>
      <th>Count</th>
      <th>Password</th>
      <th>Count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>root</code></td>
      <td>729108</td>
      <td>&lt;blank&gt;</td>
      <td>40556</td>
    </tr>
    <tr>
      <td><code>admin</code></td>
      <td>23302</td>
      <td><code>123456</code></td>
      <td>14542</td>
    </tr>
    <tr>
      <td><code>user</code></td>
      <td>8420</td>
      <td><code>admin</code></td>
      <td>7757</td>
    </tr>
    <tr>
      <td><code>test</code></td>
      <td>7547</td>
      <td><code>123</code></td>
      <td>7355</td>
    </tr>
    <tr>
      <td><code>oracle</code></td>
      <td>6211</td>
      <td><code>1234</code></td>
      <td>7099</td>
    </tr>
    <tr>
      <td><code>ftpuser</code></td>
      <td>4012</td>
      <td><code>root</code></td>
      <td>6999</td>
    </tr>
    <tr>
      <td><code>ubuntu</code></td>
      <td>3657</td>
      <td><code>password</code></td>
      <td>6118</td>
    </tr>
    <tr>
      <td><code>guest</code></td>
      <td>3606</td>
      <td><code>test</code></td>
      <td>5671</td>
    </tr>
    <tr>
      <td><code>postgres</code></td>
      <td>3455</td>
      <td><code>12345</code></td>
      <td>5223</td>
    </tr>
    <tr>
      <td><code>usuario</code></td>
      <td>2876</td>
      <td><code>guest</code></td>
      <td>4423</td>
    </tr>
  </tbody>
</table>

<p>There were a total of 128,588 unique pairings of username and password
attempted, though only 38,112 were attempted 5 or more times.  You can
<a href="https://systemoverlord.com/static/attachments/gopot/creds.csv">download the full list of pairs with counts</a>
here, but I’ve omitted those attempted less than 5 times in case a legitimate
user typo’d an IP or otherwise was mistaken.  The top 25 pairings are:</p>

<table>
  <thead>
    <tr>
      <th>username</th>
      <th>password</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>root</td>
      <td>&nbsp;</td>
      <td>37580</td>
    </tr>
    <tr>
      <td>root</td>
      <td>root</td>
      <td>4213</td>
    </tr>
    <tr>
      <td>user</td>
      <td>user</td>
      <td>2794</td>
    </tr>
    <tr>
      <td>root</td>
      <td>123456</td>
      <td>2569</td>
    </tr>
    <tr>
      <td>test</td>
      <td>test</td>
      <td>2532</td>
    </tr>
    <tr>
      <td>admin</td>
      <td>admin</td>
      <td>2531</td>
    </tr>
    <tr>
      <td>root</td>
      <td>admin</td>
      <td>2185</td>
    </tr>
    <tr>
      <td>guest</td>
      <td>guest</td>
      <td>2143</td>
    </tr>
    <tr>
      <td>root</td>
      <td>password</td>
      <td>2128</td>
    </tr>
    <tr>
      <td>oracle</td>
      <td>oracle</td>
      <td>1869</td>
    </tr>
    <tr>
      <td>ubuntu</td>
      <td>ubuntu</td>
      <td>1811</td>
    </tr>
    <tr>
      <td>root</td>
      <td>1234</td>
      <td>1681</td>
    </tr>
    <tr>
      <td>root</td>
      <td>123</td>
      <td>1658</td>
    </tr>
    <tr>
      <td>postgres</td>
      <td>postgres</td>
      <td>1594</td>
    </tr>
    <tr>
      <td>support</td>
      <td>support</td>
      <td>1535</td>
    </tr>
    <tr>
      <td>jenkins</td>
      <td>jenkins</td>
      <td>1360</td>
    </tr>
    <tr>
      <td>admin</td>
      <td>password</td>
      <td>1241</td>
    </tr>
    <tr>
      <td>root</td>
      <td>12345</td>
      <td>1177</td>
    </tr>
    <tr>
      <td>pi</td>
      <td>raspberry</td>
      <td>1160</td>
    </tr>
    <tr>
      <td>root</td>
      <td>12345678</td>
      <td>1126</td>
    </tr>
    <tr>
      <td>root</td>
      <td>123456789</td>
      <td>1069</td>
    </tr>
    <tr>
      <td>ubnt</td>
      <td>ubnt</td>
      <td>1069</td>
    </tr>
    <tr>
      <td>admin</td>
      <td>1234</td>
      <td>1012</td>
    </tr>
    <tr>
      <td>root</td>
      <td>1234567890</td>
      <td>967</td>
    </tr>
    <tr>
      <td>ec2-user</td>
      <td>ec2-user</td>
      <td>963</td>
    </tr>
  </tbody>
</table>

<p>Again, no real surprises here.  <code>ubnt</code> is a little bit higher than I would have
thought (for Ubiquiti networking gear) but I suppose there’s a fair bit of their
gear on the internet.  It’s interesting to see the mix of “lazy admin” and
“default credentials” here.  It’s <em>mildly</em> interesting to me that all substrings
of the first 10 digits (3 or longer) are included, <em>except</em> for 7 digits.  I
guess 7 digit passwords are less common?</p>

<h2 id="timing-information">Timing Information</h2>

<p>Though I imagine these kind of untargeted scans are long-term processes
continually running, I decided to check and see what the timing looked like
anyway.  Neither the day of week analysis nor the hour of day analysis look
like there’s any significant variance.</p>

<p><img src="https://systemoverlord.com/img/gopot/days_of_week.png" alt="Day of Week">
<img src="https://systemoverlord.com/img/gopot/hours.png" alt="Hour of Day"></p>

<p>Looking at the number of login requests over the time period where I’ve been
running the honeypots shows the traffic to be intermittent.  While I didn’t
expect the number to be constant, the variance is much higher than I expected.
I imagine a larger sample size and more nodes would probably make the results
more even.</p>

<p><img src="https://systemoverlord.com/img/gopot/dates.png" alt="Day of Study"></p>

<h2 id="analysis-of-sources">Analysis of Sources</h2>

<p>So where are all of these requests coming from?  I want to start by noting that
<em>none</em> of my analysis is an attempt to attribute the actors making the requests
– that’s just not possible with this kind of data.  There’s two ways to look at
the source of requests – in terms of the network, and in terms of the (assumed)
geography.  My analysis relied on the IP to ASN and IP to Country data provided
by <a href="https://iptoasn.com/">iptoasn.com</a>.</p>

<p>Looking at the country-level data, networks from China lead the pack by a long
shot (62% of all login attempts), followed by the US.</p>

<p><img src="https://systemoverlord.com/img/gopot/countries.png" alt="Countries"></p>

<table>
  <thead>
    <tr>
      <th>Country</th>
      <th>Count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CN</td>
      <td>577789</td>
    </tr>
    <tr>
      <td>US</td>
      <td>87589</td>
    </tr>
    <tr>
      <td>TW</td>
      <td>48645</td>
    </tr>
    <tr>
      <td>FR</td>
      <td>39072</td>
    </tr>
    <tr>
      <td>RU</td>
      <td>30929</td>
    </tr>
    <tr>
      <td>NL</td>
      <td>29920</td>
    </tr>
    <tr>
      <td>JP</td>
      <td>28033</td>
    </tr>
    <tr>
      <td>DE</td>
      <td>15408</td>
    </tr>
    <tr>
      <td>IN</td>
      <td>13921</td>
    </tr>
    <tr>
      <td>LT</td>
      <td>6623</td>
    </tr>
  </tbody>
</table>

<p>Again, I’m not claiming that these countries mean anything other than location
of the autonomous system (AS) that originates the requests.  I also did not do
individual IP geolocation, so the results should be taken with a small grain of
salt.</p>

<p>So what networks are sourcing this traffic?  I have the <a href="https://systemoverlord.com/static/attachments/gopot/asns.csv">full AS counts and
data</a>, but the top networks are:</p>

<table>
  <thead>
    <tr>
      <th>AS Name</th>
      <th>Country</th>
      <th>ASN</th>
      <th>Count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CHINANET-BACKBONE No.31,Jin-rong Street</td>
      <td>CN</td>
      <td>4134</td>
      <td>202024</td>
    </tr>
    <tr>
      <td>CHINANET-JS-AS-AP AS Number for CHINANET jiangsu province backbone</td>
      <td>CN</td>
      <td>23650</td>
      <td>186274</td>
    </tr>
    <tr>
      <td>CHINA169-BACKBONE CNCGROUP China169 Backbone</td>
      <td>CN</td>
      <td>4837</td>
      <td>122192</td>
    </tr>
    <tr>
      <td>HINET Data Communication Business Group</td>
      <td>TW</td>
      <td>3462</td>
      <td>48492</td>
    </tr>
    <tr>
      <td>OVH</td>
      <td>FR</td>
      <td>16276</td>
      <td>30865</td>
    </tr>
    <tr>
      <td>VECTANT ARTERIA Networks Corporation</td>
      <td>JP</td>
      <td>2519</td>
      <td>27481</td>
    </tr>
    <tr>
      <td>DIGITALOCEAN-ASN - DigitalOcean, LLC</td>
      <td>US</td>
      <td>14061</td>
      <td>26965</td>
    </tr>
    <tr>
      <td>MICROSOFT-CORP-MSN-AS-BLOCK - Microsoft Corporation</td>
      <td>US</td>
      <td>8075</td>
      <td>20370</td>
    </tr>
    <tr>
      <td>RMINJINERING</td>
      <td>RU</td>
      <td>49877</td>
      <td>16710</td>
    </tr>
    <tr>
      <td>AS38994</td>
      <td>NL</td>
      <td>38994</td>
      <td>14482</td>
    </tr>
    <tr>
      <td>XMGBNET Golden-Bridge Netcom communication Co.,LTD.</td>
      <td>CN</td>
      <td>45058</td>
      <td>12418</td>
    </tr>
    <tr>
      <td>CNNIC-ALIBABA-CN-NET-AP Hangzhou Alibaba Advertising Co.,Ltd.</td>
      <td>CN</td>
      <td>37963</td>
      <td>12045</td>
    </tr>
    <tr>
      <td>CNNIC-TENCENT-NET-AP Shenzhen Tencent Computer Systems Company Limited</td>
      <td>CN</td>
      <td>45090</td>
      <td>10804</td>
    </tr>
    <tr>
      <td>CNIX-AP China Networks Inter-Exchange</td>
      <td>CN</td>
      <td>4847</td>
      <td>10000</td>
    </tr>
    <tr>
      <td>PONYNET - FranTech Solutions</td>
      <td>US</td>
      <td>53667</td>
      <td>9317</td>
    </tr>
    <tr>
      <td>ITTI</td>
      <td>US</td>
      <td>44685</td>
      <td>7960</td>
    </tr>
    <tr>
      <td>CHINA169-BJ China Unicom Beijing Province Network</td>
      <td>CN</td>
      <td>4808</td>
      <td>7835</td>
    </tr>
    <tr>
      <td>AS12876</td>
      <td>FR</td>
      <td>12876</td>
      <td>7262</td>
    </tr>
    <tr>
      <td>AS209605</td>
      <td>LT</td>
      <td>209605</td>
      <td>6586</td>
    </tr>
    <tr>
      <td>CONTABO</td>
      <td>DE</td>
      <td>51167</td>
      <td>6261</td>
    </tr>
  </tbody>
</table>

<p><img src="https://systemoverlord.com/img/gopot/asns.png" alt="AS Graph"></p>

<p>Chinanet is no surprise given the high ratio of China in general.  OVH is a
low-cost host known to have liberal AUP, so is popular for both malicious and
research purposes.  DigitalOcean and Microsoft, of course, are popular cloud
providers.  Surprisingly, AWS only sourced about 600 connections, unless they
have a large number of IPs on a non-Amazon ASN.</p>

<p>Overall, traffic came from 27,448 unique IPv4 addresses.  Of those, more than 11
thousand sent only a single request.  At the other end of the spectrum, the top
IP source sent 64,969 login requests.</p>

<p>Most hosts sent relatively few requests, the large numbers are outliers:</p>

<p><img src="https://systemoverlord.com/img/gopot/ipcnts.png" alt="IP Count Graph"></p>

<p>Surely, by now a thought has crossed your mind: how many of these requests are
coming from Tor?  Surely the Tor network is a wretched hive of scum and villany,
and the source of much malicious traffic, right?</p>

<p><img src="https://systemoverlord.com/img/gopot/tor.png" alt="Tor Graph"></p>

<p>Not at all.  Only 219 of the unique source IPs were identified as Tor exit
nodes, representing only 0.8% of the sources.  On a per-request basis, even a
smaller percentage of requests is seen from Tor exit nodes.</p>

<h2 id="client-software">Client Software</h2>

<p>Remember – this is self-reported by the client application, and just like I can
spoof the server version string, so can clients.  But I still thought it would
be interesting to take a brief look at those.</p>

<table>
  <thead>
    <tr>
      <th>client</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>SSH-2.0-PuTTY</code></td>
      <td>309797</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-PUTTY</code></td>
      <td>182465</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-libssh2_1.4.3</code></td>
      <td>135502</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-Go</code></td>
      <td>125254</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-libssh-0.6.3</code></td>
      <td>62117</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-libssh2_1.7.0</code></td>
      <td>23799</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-libssh2_1.9.0</code></td>
      <td>21627</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-OpenSSH_7.3</code></td>
      <td>9954</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-OpenSSH_7.4p1</code></td>
      <td>8949</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-libssh2_1.8.0</code></td>
      <td>5284</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-JSCH-0.1.45</code></td>
      <td>3469</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-PuTTY_Release_0.70</code></td>
      <td>2080</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-PuTTY_Release_0.63</code></td>
      <td>1813</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-OpenSSH_5.3</code></td>
      <td>1212</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-paramiko_1.8.1</code></td>
      <td>1140</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-PuTTY_Release_0.62</code></td>
      <td>1130</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-OpenSSH_4.3</code></td>
      <td>795</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-PuTTY_Release_0.66</code></td>
      <td>694</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-OpenSSH_7.9p1 Raspbian-10+deb10u2</code></td>
      <td>690</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-libssh_0.11</code></td>
      <td>660</td>
    </tr>
  </tbody>
</table>

<p>You know, I didn’t expect that.  <a href="https://www.putty.org/">PuTTY</a> as the top
client strings.  (Also not sure what to make of the case difference.)  I wonder
if people are building the PuTTY SSH library into a tool for scanning or
wrapping the binary in some kind of script.</p>

<p>Go, paramiko, and libssh are less surprising, as they’re libraries designed for
integration.  It’s hard to know if the OpenSSH requests are linked into a
scanning tool or just wrapped versions of the SSH client.  At some point in the
future, I might dive more into this and trying to figure out which software uses
which libraries (at least for the publicly-known tools).</p>

<h2 id="summary">Summary</h2>

<p>I was hoping to find something earth-shattering in this research.  Instead, I
found things that were much as expected – common usernames and passwords,
widespread scanning, large numbers of requests.  One thing’s for sure though:
connect it to the internet and someone’s going to pwn it.</p>

  </div>
  

</div></div>]]>
            </description>
            <link>https://systemoverlord.com/2020/09/04/lessons-learned-from-ssh-credential-honeypots.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399463</guid>
            <pubDate>Mon, 07 Sep 2020 14:00:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitLive 6.0 – Code Together in Real Time]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399461">thread link</a>) | @SuDa2103
<br/>
September 7, 2020 | https://blog.git.live/gitlive-6.0-Code-together-in-real-time | <a href="https://web.archive.org/web/*/https://blog.git.live/gitlive-6.0-Code-together-in-real-time">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

        
        <!-- .site-header -->
        

        <div id="content">
    <main id="main">
        <article>
            <!-- .post-header -->
            
            <p><img src="https://blog.git.live/assets/images/posts/2020/collabv3.gif" alt="GitLive 6.0: Code together in real-time"></p>
            
            <div>
                <p>GitLive 6.0 releases real-time editing to the JetBrains Marketplace after it has been battle-tested by our community of beta users. It has by far been one of the most anticipated features allowing you to open a teammate’s file and start editing it exactly as you would in a Google Doc independently of the IDE you are using. Furthermore, GitLive 6.0 is adding <strong>Azure DevOps cloud</strong> to our family of supported repository hosting services. A full blog post dedicated to each of these major updates will be released shortly. Additional new features of this release include:</p>

<h4 id="privacy-settings">Privacy Settings</h4>
<p>We had a few queries of people wanting more control over what data is shared with their teammates. Our previous ‘incognito’ mode was the first step in that direction by allowing users to hide their current file changes and what they’re working on.</p>

<p><img src="https://blog.git.live/assets/images/posts/2020/gitlive-privacy-settings.png" alt="Privacy Settings GitLive"></p>

<p>Our new privacy settings go a few steps further in that regard by giving users more granular control over what info users want to continuously share or prefer to share only when needed, for instance when discussing a piece of unpushed code in a user’s local working copy.</p>

<table>
    <thead>
        <tr>
        <th>Feature</th>
        <th>Functionality</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Offline Mode</td>
            <td>
                When enabled you will appear as offline
            </td>
        </tr>
        <tr>
            <td>Hide activity graph</td>
            <td>
                When enabled your activity graph will not appear for you or your team
            </td>
        </tr>
        <tr>
            <td>Hide my working copy changes</td>
            <td>
                When enabled your local file changes will not appear for you or your team
            </td>
        </tr>
    </tbody>
</table>

<h4 id="inline-diff-view">Inline Diff View</h4>
<p>In JetBrains IDEs clicking a teammate’s file will now open a diff view inline. The diff view updates as your teammate is making changes to the file.</p>

<p><img src="https://blog.git.live/assets/images/posts/2020/gitlive-diff-view.png" alt="Life Diff View in JetBrains"></p>

<h4 id="switching-between-repository-hosting-service-accounts">Switching between repository hosting service accounts</h4>

<p>In JetBrains IDEs you can now easily manage which repository hosting accounts are associated with your GitLive user. Use the “+” and “-“ icons under the GitLive tab within the <em>Preferences</em> window to add and remove repository hosting service accounts you are signed in with.</p>

<p><img src="https://blog.git.live/assets/images/posts/2020/GitLive-accounts.jpg" alt="Account Settings in JetBrains"></p>

<h4 id="teammates-list-sorted-by-online-status">Teammates list sorted by online status</h4>
<p>Finally, your teammate’s names in the Team View are now sorted by online status. This makes it more convenient for large teams to locate their active teammates and collaborate.</p>

<p><img src="https://blog.git.live/assets/images/posts/2020/Sorted-online-status.png" alt="Sorted online status"></p>

<p><strong>NOTE:</strong> As this is a major version update make sure your whole team upgrades, all team members need to use the same major version of the plugin otherwise you may find some features that do not work correctly.</p>

            </div>
            
            <!--<div class="author-box">-->
                <!--<div class="author-avatar"><img src="/assets/images/" alt="'s Picture"-->
                        <!--class="avatar"></div>-->
                <!--<div class="author-details">-->
                    <!--<h2 class="author-title">About </h2>-->
                    <!--<p class="author-description"></p>-->
                <!--</div>-->
            <!--</div>-->
            



        </article>
        
        <section>
    <div>
        <h2>Subscribe to GitLive</h2>
        <p>Get the latest news from GitLive delivered straight to your inbox</p>
        <!-- Begin MailChimp Signup Form -->
        
        <!--End mc_embed_signup-->
    </div><!-- .inner -->
</section><!-- .widget -->
        
        <section>
            <h2>Read Next</h2>
            
            <article>
                
                
                <a href="https://blog.git.live/teamhub-becomes-gitlive">
                    <img src="https://blog.git.live/assets/images/posts/2020/GitLive-Logo-Rect-Black-Widev-less-width-whitespace.png" alt="TeamHub becomes GitLive">
                </a>
                
            </article>
            
            
        </section><!-- .read-next -->
    </main><!-- .site-main -->
</div><!-- .site-content -->

        

        

        <!-- .site-footer -->
    </div></div>]]>
            </description>
            <link>https://blog.git.live/gitlive-6.0-Code-together-in-real-time</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399461</guid>
            <pubDate>Mon, 07 Sep 2020 14:00:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React-konva – 2d canvas components for React]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24399448">thread link</a>) | @lavrton
<br/>
September 7, 2020 | https://konvajs.org/docs/react/Intro.html | <a href="https://web.archive.org/web/*/https://konvajs.org/docs/react/Intro.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://konvajs.org/docs/react/Intro.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399448</guid>
            <pubDate>Mon, 07 Sep 2020 13:57:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing Interplanetary Trajectories Resilient to Missed Thrust Events Usin ETF]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399346">thread link</a>) | @gereshes
<br/>
September 7, 2020 | https://gereshes.com/2020/09/07/designing-trajectories-resilient-to-missed-thrust-events-using-expected-thrust-fraction-asc-2020/ | <a href="https://web.archive.org/web/*/https://gereshes.com/2020/09/07/designing-trajectories-resilient-to-missed-thrust-events-using-expected-thrust-fraction-asc-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p><span>Note: This post is adapted from my&nbsp;conference</span> <a href="https://www.researchgate.net/publication/343658815_Designing_Trajectories_Resilient_to_Missed_Thrust_Events_Using_Expected_Thrust_Fraction" target="_blank" rel="noopener noreferrer">paper</a>, <span>which was presented at the Astrodynamics Specialists Conference in Summer 2020. You can read the full paper</span> <a href="https://www.researchgate.net/publication/343658815_Designing_Trajectories_Resilient_to_Missed_Thrust_Events_Using_Expected_Thrust_Fraction" target="_blank" rel="noopener noreferrer">here.</a></p>
<h3><span>Abstract – Designing Trajectories Resilient to Missed Thrust Events Using Expected Thrust Fraction</span></h3>
<p><span>With the adoption of efficient low-thrust propulsion methods, the probability of a</span> <a href="https://gereshes.com/2019/09/02/missed-thrust-events-in-deep-space-trajectories/" target="_blank" rel="noopener noreferrer">missed thrust event</a>&nbsp;<span>occurring has become a significant concern for short and long-duration missions. If the missed thrust events take place during a critical portion of the trajectory, the mission can be compromised. Therefore, it is essential to develop trajectories that are resilient to missed thrust events. This paper investigates the use of expected thrust fraction, which embeds the stochastic nature of missed thrust events into a deterministic optimal control problem. The performance of trajectories designed using expected thrust fraction is compared with traditionally designed trajectories to measure changes in resiliency to missed thrust events. In this investigation, trajectories designed using expected thrust fraction arrive with a median lateness half that of traditionally designed trajectories. Using expected thrust fraction can help astrodynamicists mitigate risks posed by the use of low-thrust propulsion.</span></p>
<p><img loading="lazy" src="https://i1.wp.com/gereshes.com/wp-content/uploads/2020/07/Earth_Return_Orbiter_pillars.jpg?resize=1024%2C576&amp;ssl=1" alt="" width="1024" height="576" srcset="https://i1.wp.com/gereshes.com/wp-content/uploads/2020/07/Earth_Return_Orbiter_pillars.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/gereshes.com/wp-content/uploads/2020/07/Earth_Return_Orbiter_pillars.jpg?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/gereshes.com/wp-content/uploads/2020/07/Earth_Return_Orbiter_pillars.jpg?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/gereshes.com/wp-content/uploads/2020/07/Earth_Return_Orbiter_pillars.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/gereshes.com/wp-content/uploads/2020/07/Earth_Return_Orbiter_pillars.jpg?w=1921&amp;ssl=1 1921w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></p>
<h3><span>Key Takeaways</span></h3>
<p><span>The full paper is online&nbsp;</span><a href="https://www.researchgate.net/publication/343658815_Designing_Trajectories_Resilient_to_Missed_Thrust_Events_Using_Expected_Thrust_Fraction" target="_blank" rel="noopener noreferrer">here</a>, <span>but here are, in my opinion, the most interesting aspects</span></p>
<ul>
<li><span>The stochastic nature of missed thrust events can be embedded into a&nbsp; time-varying duty cycle</span></li>
<li><span>It makes trajectories more resilient to&nbsp; missed thrust events</span></li>
<li><span>The risk of a mission and mass delivered can be traded between</span></li>
</ul>
<h3><span>Presentation</span></h3>
<p><span>Due to COVID-19, this conference was held virtually, and I have uploaded a video of my presentation below.</span></p>
<p><span><iframe width="1170" height="659" src="https://www.youtube.com/embed/GqvoaGvDrdE?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<h3>Want More Gereshes?</h3>
<p>If you want to receive new Gereshes blog post directly to your email when they come out, you can sign up for that&nbsp;<a href="https://tinyletter.com/gereshes">here!</a></p>
<p>Don’t want another email? That’s ok, Gereshes also has a&nbsp;<a href="https://twitter.com/gereshes" target="_blank" rel="noreferrer noopener">twitter account</a>&nbsp;and&nbsp;<a href="https://www.reddit.com/r/gereshes" target="_blank" rel="noreferrer noopener">subreddit!</a></p>

					</div></div>]]>
            </description>
            <link>https://gereshes.com/2020/09/07/designing-trajectories-resilient-to-missed-thrust-events-using-expected-thrust-fraction-asc-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399346</guid>
            <pubDate>Mon, 07 Sep 2020 13:39:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moonlander: A next-generation ergonomic keyboard]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399196">thread link</a>) | @magnetised
<br/>
September 7, 2020 | https://www.zsa.io/moonlander/ | <a href="https://web.archive.org/web/*/https://www.zsa.io/moonlander/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><strong>Ergonomic:</strong> Type at shoulder width, reassign keys, tilt and tent it.</p><p><strong>Mechanical:</strong> For the most enjoyable typing experience.</p><p><strong>Dynamic:</strong> Adjust the angle of the whole keyboard, or just the thumb cluster.</p><p><strong>Portable:</strong> Folds into a compact package. Carrying case included.</p><p><strong>Gamer-friendly:</strong> Plug in just the left side to get your game on.</p><p><strong>Built to last:</strong> Backed by a solid two-year warranty.<!-- --> <br>No fine print.</p></div></div></div></div>]]>
            </description>
            <link>https://www.zsa.io/moonlander/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399196</guid>
            <pubDate>Mon, 07 Sep 2020 13:12:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Gamify Team Work]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24399139">thread link</a>) | @mindhash
<br/>
September 7, 2020 | https://amols.blog/engineering/dont-gamify-team-work | <a href="https://web.archive.org/web/*/https://amols.blog/engineering/dont-gamify-team-work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote>
<p>“Competition is for the Losers - Peter Thiel”</p>
</blockquote>
<p>Almost a decade ago, I learnt an important lesson about adverse effect of gamification on team work. We did hit our goal before the deadline but in the hindsight it wasn’t the best outcome in terms of team dynamics. </p>
<p>I was asked to lead an upgrade project. We had 800 issues to fix in ~4 weeks time. Although most of the issues were minor, we had to look through and test each of them.  </p>
<p>Most work items took a few hours but some took a little longer than a day. I decided to create a shared pool, from which each team member will pick the next item after he/she is done with the current at hand. I kept a shared dashboard that showed total issues resolved and no of tasks solved by each member.  </p>
<p>After a couple days, I was surprised to notice a few members converted this process into a battleground.  They were keeping scores.  For a moment, I thought this is going well and we should stick to it. But then, as I reviewed the work, I started noticing the mistakes.  </p>
<p>The reason was clear, the team members were scoring based on just the completion of work and in that hurry the quality started to fall apart. </p>
<blockquote>
<p>Moral of the story - a shared metric and progress helped the team to get energised but keeping score of each members didn’t. </p>
</blockquote>
<p>The ill effects of competition are not just limited to workplace but they can be seen at our schools too. </p>
<h4 id="groupism"><a href="#groupism" aria-label="groupism permalink"></a>Groupism</h4>
<p>At a summer camp, a newly appointed sports teacher thought it will be a good idea to split students in red (ruby) and blue(emerald) teams. Each team would compete in multiple games, challenges through out the summer.  </p>
<p>The team assignments in a way mutated the identities of the kids. They started associated themselves as rubysts or emeralds. </p>
<p>Half way through the summer, the teacher started noticing increasing hatred among two groups as they competed as rivals.  This wasn’t the result she was expecting. The idea was rather to make students better team players and respect each other. </p>
<p>A few days went by and an unexpected event, a broken water pipe, gave her with an idea to break the tension.  The pipe delivered water to camp needed to be fixed and this impacted everybody at the camp. Both the groups had to come together to solve the issue.</p>
<blockquote>
<p>A common goal brought students to team up and work together. </p>
</blockquote>
<p>Taking a cue from this, the teacher started placing hurdles that required the two teams to work together. For example - teams could only go to a movie if both teams had enough cash to do so. In such instances, teams even started pitching in for other.  </p>
<p>In a few days, the teams started being more friendly to each other and respecting too. Some rubysts even traveled in emerald buses and vice versa.</p>
<p>The key idea here is, presence of a perceived common goal brings people together.</p>
<h4 id="creating-teams-and-department"><a href="#creating-teams-and-department" aria-label="creating teams and department permalink"></a>Creating Teams and Department</h4>
<p>I once worked with startup that grew from 10 to tripple digits in a matter of months. During this time, I have seen teams forming up. The ‘Us vs them’ chorus growing at the same time. </p>
<p>This typically happens when your go with common tactics of creating departments by nature of work (e.g. sales, marketing, product, etc). </p>
<p>But integration of teams is much more important. One way to achieve that is by sharing a metric. </p>
<p>That’s why a lot of companies are moving towards squads (mix of engineers, design, QA) that share a common goal (e.g. product delivery). I think this is a good direction to head atleast for product-led companies. </p>
<p>When I was defining the team structure at <a href="http://xcelerator.ninja/" target="_blank" rel="noopener noreferrer">xceler</a>, I learnt to put product focused squads instead of technology based split (e.g. backend/API, android, front end). The entire team had a single goal of getting that product in the market.   </p>
<p>This structure however doesn’t account much for building capability or domain expertise. That’s why focused groups for learning initiatives might be necessary. </p>
<blockquote>
<p>To summarize, I think teams should be built around a shared metric that enables a common goal.</p>
</blockquote>
<h4 id="special-badges-dont-help-anyone"><a href="#special-badges-dont-help-anyone" aria-label="special badges dont help anyone permalink"></a>Special badges don’t help anyone</h4>
<p>A common strategy in many companies is to assign badges or titles such as Performer of the Month. The only thing these awards achieve is create a sense competition among the team members.</p>
<p>I also received a few of these in my early years and I don’t think it ever motivated me more than I was.  </p>
<p>Your high performers are (usually) already motivated, get better appraisals, then why add more badges of burden on the rest? </p>
<h4 id="towards-a-cohesive-unit-not-a-competitive-one"><a href="#towards-a-cohesive-unit-not-a-competitive-one" aria-label="towards a cohesive unit not a competitive one permalink"></a>Towards a cohesive unit, not a competitive One</h4>
<p>When working with a team, I think paying attention to these two leads to better team work than not. </p>
<ul>
<li>Identify if your people or reward strategy is not creating competitition inward</li>
<li>If you must compete, then go outward (i.e. outside products, success metrics)</li>
</ul>
<p><em>Photo credit: <a href="https://amols.blog/engineering/%22https://unsplash.com/@anniespratt?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText%22">Annie Spratt</a> on <a href="https://amols.blog/engineering/%22https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText%22">Unsplash</a></em></p>
<p><em>References: Summer camp story from <a href="https://www.amazon.in/Influence-Psychology-Persuasion-Business-Essentials-ebook/dp/B002BD2UUC" target="_blank" rel="noopener noreferrer">Influence</a></em></p></div></div>]]>
            </description>
            <link>https://amols.blog/engineering/dont-gamify-team-work</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399139</guid>
            <pubDate>Mon, 07 Sep 2020 13:02:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tooltips in Tooltips]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399125">thread link</a>) | @knowingathing
<br/>
September 7, 2020 | https://philip.design/blog/tooltips-in-tooltips/ | <a href="https://web.archive.org/web/*/https://philip.design/blog/tooltips-in-tooltips/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <div>
            <p>With the recent release of <a target="_blank" href="https://store.steampowered.com/app/1158310/Crusader_Kings_III/">Crusader Kings 3</a> by Paradox Interactive, a new UI paradigm in the game stopped me in my tracks. There are a lot of lessons that web designers can learn from video game user interface design and while they aren’t always transferrable, they are worth exploring. In this case it’s the idea of having <i>tooltips within tooltips.</i></p>

            <p><img src="https://philip.design/blog/tooltips-in-tooltips/tooltips.png"></p><figcaption>Tooltips within tooltips! Image taken from <a target="_blank" href="https://www.crusaderkings.com/news/dev-diary-16-tutorials-and-tooltips-and-encyclopedias-oh-my">this dev diary</a></figcaption>

            

            <p>Tooltips have become a standard component in user interface design. The majority of web UI frameworks include some form of tooltip, with Bootstrap having <i>two</i> types (Tooltips and Popovers). Wikipedia uses tooltips when hovering over links:</p>

            <p><img src="https://philip.design/blog/tooltips-in-tooltips/droplet2.png"></p><figcaption>Image taken from this <a target="_blank" href="https://en.wikipedia.org/wiki/Respiratory_droplet">Wikipedia article</a></figcaption>

            <br>

            <h2>What about nested tooltips... on the web?</h2>
            <h3>Hover over "small droplets" to begin (sorry mobile users)</h3>
            <br>
            
            <div><p>The virus is spread primarily via
                </p><p>small droplets
                    <span>
                        <img src="https://philip.design/blog/tooltips-in-tooltips/droplet.png">
                        <p>A respiratory droplet is a small aqueous droplet produced by exhalation, consisting of

                            <span>saliva

                                <span>

                                    <img src="https://philip.design/blog/tooltips-in-tooltips/saliva.jpg">

                                    <span><b>Saliva</b> (commonly referred to as <b>spit</b>) is an extracellular fluid produced and secreted by salivary glands in the mouth. In
                                        <span>humans,

                                            <span>

                                                <span>

                                                    <img src="https://philip.design/blog/tooltips-in-tooltips/humans.jpg">
                                                    <span><b>Humans</b> (Homo sapiens) are highly intelligent primates that have become the dominant species on Earth. They are the only extant members of the subtribe Hominina and—together with chimpanzees, gorillas, and orangutans—are part of the family Hominidae (the great apes, or hominids).</span>
                                                    
                                                </span>                                                
                                                
                                            </span>
                                        </span>

                                        saliva is 99.5⁠% water plus electrolytes, mucus, white blood cells, epithelial cells (from which DNA can be extracted), enzymes (such as amylase and lipase), antimicrobial agents such as secretory IgA, and lysozymes.</span>
                                    
                                    
                                </span>
                            </span>

                            or mucus and other matter derived from

                            <span>respiratory tract

                                <span>

                                    <span>The <b>respiratory tract</b> is the subdivision of the respiratory system involved with the process of respiration in mammals. The respiratory tract is lined with respiratory mucosa or respiratory epithelium.</span>
                                    
                                    <img src="https://philip.design/blog/tooltips-in-tooltips/tract.svg">
                                    
                                </span>
                            </span>
                            
                            surfaces. Droplet sizes range from &lt;5 µm to 1000 µm. Large droplets fall to the ground or another surface before drying, but smaller ones fall slowly and dry so quickly...
                    
                        </p>
                        
                </span></p><p>
                from coughing, sneezing, and talking. The droplets are usually not airborne, however those standing in close proximity may inhale them and become infected. People may also become infected by touching a contaminated surface and then touching their face. The transmission may also occur through aerosols that can stay suspended in the air for longer periods of time in enclosed spaces. It is most contagious during the first three days after the onset of symptoms, although spread is possible before symptoms appear, and from people who are asymptomatic.
            </p></div>
            <figcaption>Images and content taken from <a target="_blank" href="https://en.wikipedia.org/">Wikipedia</a></figcaption>

            

            <p>Did you find it intuitive? Could you easily traverse up and down the tooltip chain? Note: this is a HTML/CSS example that I quickly put together so it’s rough around the edges.</p>

            <p>I found it suprisingly intuitive and easy to use. When you hover to reveal the first tooltip, you keep your cursor nice and still. After that, you locate a piece of information you want to learn more about and you hover over that. It might overlap the first tooltip, but that’s fine. You’ve chosen to seek more information.</p>

            <p>Another reason I like this idea, is that it matches how I think. When learning something new, there might be a supporting concept or idea I don't fully grasp. A nested tooltip is a great solution.</p>

            <p>In the context of a complex grand strategy game like CK3, having explanatory text is necessary. The designers and developers at Paradox elegantly solved this by implementing tooltips within tooltips. Kudos to them.</p>

            <h3>Potential issues</h3>
            <ul>
                <li><b>Accessibility.</b> Well anything is possible with Javascript right? You could tab through the tooltips to get them working.</li>
                <li><b>User experience.</b> It can be frustrating to move your cursor 1 pixel outside of the bounds of the element which removes the tooltip.</li>
                <li><b>How deep do you go?</b> The designer should use discretion. An infinitely deep tooltip chain doesn't make sense. There might be some sweet number here like, 2 or 3 nested tooltips.</li>
                <li><b>Touch?</b> I'm not sure how mobile works. You could just treat them as tappable elements.</li>
            </ul>

            <p>I guess the question is: could the web embrace nested tooltips?</p>

            <h4>Leave a comment :)</h4>
            <br>
            
        </div>
    </div></div>]]>
            </description>
            <link>https://philip.design/blog/tooltips-in-tooltips/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399125</guid>
            <pubDate>Mon, 07 Sep 2020 12:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This Week in Java]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399095">thread link</a>) | @olegchir
<br/>
September 7, 2020 | https://darkest.land/2020/09/07/this-week-in-java-1/ | <a href="https://web.archive.org/web/*/https://darkest.land/2020/09/07/this-week-in-java-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    	    
    
<ul><li>OpenJDK finished the migration <a href="https://github.com/openjdk/jdk">to the GitHub</a>.</li><li><a href="https://spring.io/blog/2020/09/02/hello-azure-spring-cloud">Azure Spring Cloud</a>&nbsp;is out. It’s a platform for deploying and managing Spring Boot and Spring Cloud-powered services and software built on Microsoft Azure. It is jointly built, operated, and supported by Microsoft and VMware.</li><li><a href="https://www.eclipse.org/eclipse/news/4.17/jdt.php?v=rc1">Eclipse IDE 4.17 Release Candidate 1</a>&nbsp;is out. It introduces some new features, including support for&nbsp;<a href="https://openjdk.java.net/jeps/358">JEP 358: Helpful NullPointerExceptions</a>.</li><li>GitHub&nbsp;<a href="https://github.blog/2020-07-08-introducing-the-github-availability-report/">released a new report</a>&nbsp;about the latest incidents and availability problems.</li><li>On July 10, 2020, JetBrains hosted a Technology Day for Java. Presentations and videos for them are now&nbsp;<a href="https://pages.jetbrains.com/technology-day-java-2020">available here</a>.</li><li>A new <a href="https://github.com/linux-china/mybatis-r2dbc">R2DBC adapter for MyBatis</a> is out. A lot of Chinese in the README 😛</li><li><a href="https://www.eclipse.org/ditto/2020-08-31-release-announcement-120.html">Eclipse Ditto</a>&nbsp;1.2.0 is out. Eclipse Ditto is an open-source framework for creating and managing digital twins in the IoT. The new release is focused on “At least once” (QoS 1) processing, injecting timestamps and metadata, HTTP auth of push connections with client certificates.</li><li>Big Data Tools&nbsp;<a href="https://blog.jetbrains.com/idea/2020/09/big-data-tools-eap-10/">update is out</a>: SSH tunnels, filters and limits for Spark Monitoring apps tab, user-defined modules, and a ton of fixes and improvements.</li><li><a href="https://spring.io/blog/2020/09/03/spring-tools-4-7-2-released">Spring Tools 4.7.2</a>&nbsp;has been released. This release introduces an entirely new wizard in Eclipse to add Spring Boot starter modules to existing projects and an early experimental version of Spring Boot OCI image building support combined with Docker.</li><li><a href="https://www.dirigible.io/release/2020/09/02/news_new_release_5_2.html">Eclipse Dirigible 5.2 is out</a>. A new release brings us OData generation from the Entity Data Model and expanded OData support overall. Dirigible is a Cloud Development Platform that provides its development tools and a runtime environment.</li><li>A new open source Kubernetes&nbsp;<a href="https://filippobuletto.github.io/kubectl-java-test/">kubectl plugin</a>&nbsp;has been released. It is written in Java and ran using jbang.</li><li>A new cool&nbsp;<a href="https://www.youtube.com/watch?v=TYENQucbOOY">demo project</a>&nbsp;that demonstrates a wave effect by generating irregular contours connected using smooth QuadCurve Bezier paths. The waves animate by adjusting the control points of the contour itself.</li><li>Another cool&nbsp;<a href="https://www.youtube.com/watch?v=0vUUTWhIsIU">demo project</a>. It’s a Special Effect demonstrated in JavaFX for shrouding a standard GUI with a colorized shadow (making it opaque to the viewer) and then adding a “spotlight”, which dynamically interacts with the underlying GUI Nodes via line of sight connections.</li><li>A new exciting command-line utility is out. It can automatically add missing import statements in a Java file. Check it&nbsp;<a href="https://github.com/nicolascouvrat/javaimports">on Github</a>&nbsp;or read an announcement&nbsp;<a href="https://www.reddit.com/r/java/comments/ijleh5/ive_created_a_cli_utility_to_automatically_add/">on Reddit</a>.</li></ul>







<ul><li>Chaos Probe is out: a new stability analysis tool for deep learning models built using JavaFX. You can check a demo&nbsp;<a href="https://www.youtube.com/watch?v=Pab2fLwxI_g">on YouTube</a>. It is an application written entirely in Java and JavaFX, 14 which provides an interactive visualization of deep learning models (Keras) designed for image classification.</li><li>Google’s deep-learning model called&nbsp;<a href="https://arxiv.org/abs/2007.14062">BigBird</a>&nbsp;allows Transformer neural networks to process sequences up to 8x longer than previously possible. It may increase performance on several NLP tasks, including question-answering and document summarization.</li></ul>







<ul><li>I found a Reddit&nbsp;<a href="https://www.reddit.com/r/java/comments/ij5qek/an_openjdk_14_docker_image_thats_33_slimmer_than/">thread</a>&nbsp;dedicated to finding the slimmest JDK docker image.</li><li>A new&nbsp;<a href="https://www.reddit.com/r/java/comments/ii939b/i_created_a_sample_http_server_using_jetty_with/">thread on Reddit</a>&nbsp;about the small experimental HTTP server that uses Project Loom.</li><li>The same Redditor opened two random questions on how to use Java on&nbsp;<a href="https://www.reddit.com/r/java/comments/iku9yl/running_java_on_gpus/">GPUs</a>&nbsp;and&nbsp;<a href="https://www.reddit.com/r/java/comments/ikucup/running_java_on_fpgas/">FPGAs</a>.</li></ul>







<ul><li><a href="https://snyk.io/">Snyk</a>&nbsp;has&nbsp;<a href="https://snyk.io/blog/snyks-developer-first-prioritization-capabilities/">released</a>&nbsp;new tools for prioritizing security vulnerabilities. You can accelerate triaging with features like “Priority Score”, “Exploit Maturity”, and so on.</li><li><a href="https://aws.amazon.com/blogs/opensource/building-resilient-services-at-prime-video-with-chaos-engineering/">AWSSSMChaosRunner</a>&nbsp;is out. It’s a chaos engineering library by AWS. It will allow us to execute commands on a specific set of EC2 instances remotely. All the library sources are open, but this doesn’t make much sense because you still must use it against proprietary technologies.</li><li>Google&nbsp;<a href="https://cloud.google.com/blog/products/data-analytics/multi-language-sdks-for-building-cloud-pipelines">announced</a>&nbsp;a new service-oriented architecture Runner v2 to the&nbsp;<a href="https://cloud.google.com/dataflow">Dataflow</a>&nbsp;– their GCP service for executing Apache Beam pipelines.</li><li>Amazon AWS announces&nbsp;<a href="https://aws.amazon.com/blogs/aws/aws-announces-aws-contact-center-intelligence-solutions/">AWS Contact Center Intelligence solutions</a>. New&nbsp;<a href="https://aws.amazon.com/machine-learning/contact-center-intelligence/">Contact Center Intelligence (CCI)</a>&nbsp;solutions will provide the power of AI for contact centers. You can use Amazon Kendra, Amazon Translate, Amazon Transcribe, and partner services of companies like Accenture, Acqueon, Slalom, and Vonage.</li></ul>







<ul><li>A new episode of Josh Long’s&nbsp;<a href="https://spring.io/blog/2020/09/04/a-bootiful-podcast-springone-2020-josh-s-book-reactive-spring-and-microsoft-java-architect-and-fellow-java-champion-jonathan-giles">“A Bootiful Podcast.”</a>&nbsp;We will discuss SpringOne 2020, Josh’s book “Reactive Spring,” with Microsoft Java Architect and fellow Java Champion Jonathan Giles.</li><li><a href="https://adambien.blog/roller/abien/entry/unit_tests_considered_harmful_an">“Unit Tests Considered Harmful.”</a>&nbsp;It’s a new Adam Bien’s podcast episode on Airhacks.</li><li>A new&nbsp;<a href="https://soundcloud.com/infoq-channel/yan-cui-on-serverless-orchestration-choreography-distributed-tracking-cold-starts-and-more">podcast by Yan Cui</a>&nbsp;on Serverless Orchestration &amp; Choreography, Distributed Tracking, Cold Starts, and more.</li><li>A&nbsp;<a href="https://www.youtube.com/watch?v=cceRz3LToIo">video tutorial</a>&nbsp;on how to get started with native Java Applications using NetBeans IDE, GraalVM and Gluon.</li></ul>







<ul><li>A new episode of Josh Long’s&nbsp;<a href="https://spring.io/blog/2020/09/02/this-week-in-spring-springone-2020-edition-september-1st-2020">“This Week in Spring.”</a></li><li>A new episode of&nbsp;<a href="https://blog.jetbrains.com/idea/2020/09/java-annotated-monthly-september-2020/">Java Annotated Monthly</a>&nbsp;by Trisha Gee.</li><li><a href="https://chrzaszcz.dev/2020/08/kafka-testing/">“How to test the application’s integration with Kafka and Testcontainers”</a> by Łukasz Chrząszcz.</li><li>Vlad Mihalcea wrote&nbsp;<a href="https://vladmihalcea.com/encrypt-decrypt-json-jpa/">a new tutorial</a>&nbsp;on how to encrypt and decrypt JSON properties with JPA.</li><li>A&nbsp;<a href="https://blog.rajanpanchal.net/write-your-first-aws-lambda-in-java">short tutorial</a>&nbsp;on how to write your first AWS Lambda in Java.</li><li>This&nbsp;<a href="https://blog.jetbrains.com/idea/2020/09/everyday-refactorings-in-intellij-idea/">blog post</a>&nbsp;reveals a bunch of neat everyday refactorings for IntelliJ IDEA.</li><li>Java Architecture for XML Binding (JAXB) API was deprecated in Java 9 and removed from Java SE 11. What should we do now? Check out&nbsp;<a href="https://adambien.blog/roller/abien/entry/from_pojo_to_xml_and">a small example</a>&nbsp;on Adam Bien’s website.</li><li>Michael Scharhag’s&nbsp;<a href="https://www.javacodegeeks.com/2020/08/ocr-in-java-with-tess4j.html">“OCR in Java with Tess4J”</a>. You will write a simple app to turn a JPEG file into text. Tess4J is a Java JNA wrapper for Tesseract OCR API. Tesseract is a famous optical character recognition engine; 94% of its code is in C++.</li><li>Michael Scherlag’s&nbsp;<a href="https://www.javacodegeeks.com/2020/08/extending-junit-5.html">“Extending JUnit 5”</a>. You will write a custom extension and use it within the @ExtendWith annotation.</li><li><a href="https://blog.frankel.ch/github-actions-maven-releases/">A quick tutorial</a>&nbsp;on how to build Maven projects with Github Actions.</li><li>A new official Vaadin&nbsp;<a href="https://vaadin.com/learn/tutorials/hazelcast">tutorial</a>&nbsp;on how to use it with Hazelcast.</li><li><a href="https://www.java67.com/2012/08/5-thread-interview-questions-answers-in.html">Top 12 Java Thread, Concurrency and Multithreading Interview Questions For experienced Programmers</a>. These questions are pretty basic, but still quite interesting for anyone who never tried to write a complex concurrent app.</li></ul>

    
            
    
    		    
</div></div>]]>
            </description>
            <link>https://darkest.land/2020/09/07/this-week-in-java-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399095</guid>
            <pubDate>Mon, 07 Sep 2020 12:55:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's New in OAuth 2.1?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398999">thread link</a>) | @animationwill
<br/>
September 7, 2020 | https://fusionauth.io/blog/2020/04/15/whats-new-in-oauth-2-1 | <a href="https://web.archive.org/web/*/https://fusionauth.io/blog/2020/04/15/whats-new-in-oauth-2-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>Hey look! OAuth is getting spiffed up a bit. The original OAuth 2.0 specification was released in October 2012 as <a href="https://tools.ietf.org/html/rfc6749">RFC 6749</a>. It replaced OAuth 1.0, released in April 2010. There have been some extensions over the years. A new OAuth specification has been proposed and is currently under discussion. As of this blog post’s writing, the specification was most recently updated on March 8, 2020. If approved, <a href="https://tools.ietf.org/html/draft-parecki-oauth-v2-1-01">OAuth 2.1</a> will obsolete certain parts of Oauth 2.0 and mandate additional security best practices. The rest of the OAuth 2.0 specification will be retained.</p>

<!--more-->

<p>This post assumes you are a developer or have similar technical experience. It also assumes you are familiar with OAuth and the terms used in the various RFCs. If you’d like an introduction to OAuth and why you’d consider using it, <a href="https://en.wikipedia.org/wiki/OAuth">Wikipedia is a good place to start</a>. This post discusses proposed changes to OAuth that might affect you if you are using OAuth in your application or if you implement the OAuth specification.</p>

<h2 id="why-oauth-21">Why OAuth 2.1?</h2>

<p>It’s been a long time since OAuth 2.0 was released. A consolidation point release was in order. As outlined in a <a href="https://aaronparecki.com/2019/12/12/21/its-time-for-oauth-2-dot-1">blog post</a> by Aaron Parecki, one of the authors of the OAuth 2.1 draft specification:</p>

<blockquote>
  <p>My main goal with OAuth 2.1 is to capture the current best practices in OAuth 2.0 as well as its well-established extensions under a single name. That also means specifically that this effort will not define any new behavior itself, it is just to capture behavior defined in other specs. It also won’t include anything considered experimental or still in progress.</p>
</blockquote>

<p>So, this is not a scrape and rebuild of OAuth 2.0. Instead, OAuth 2.1 consolidates the changes and tweaks to OAuth 2.0 that have been made over the past eight years, with a focus on better default security. It establishes the best practices and will serve as a reference document. Here’s a suggested description pulled from the <a href="https://mailarchive.ietf.org/arch/msg/oauth/Ne4Q9erPP7SpC5051sSy6XnLDv0/">ongoing mailing list discussion</a>: “By design, [OAuth 2.1] does not introduce any new features to what already exists in the OAuth 2.0 specifications being replaced.” Many of the new draft specification details are drawn from the <a href="https://tools.ietf.org/html/draft-ietf-oauth-security-topics-14">OAuth 2.0 Security Best Current Practices</a> document. However, in the name of security best practices, some of the more problematic grants will be removed.</p>

<p>At the end of the day, the goal is to have a single document detailing how to best implement and use OAuth, as both a client and an implementor. No longer will developers have to hunt across multiple RFCs and standards documents to understand how a specified behavior should be implemented or used.</p>

<h2 id="i-use-oauth-in-my-application-what-does-oauth-21-mean-to-me">I use OAuth in my application, what does OAuth 2.1 mean to me?</h2>

<p>Don’t panic.</p>

<p>As mentioned above, the discussion process around this specification is ongoing. A draft RFC was posted to the IETF mailing list in mid-March. As of the time of writing, the revision and discussion are still actively occurring.</p>

<p>You may ask, when will it be available? The short answer is “no one knows”.</p>

<p>The long answer is “truly, no one knows. It does seem like we’re early in the process, though.”</p>

<p>Even after OAuth 2.1 is released, it will likely be some time before it is widely implemented. Omitted grants may be supported with warnings forever. The exact changes to the specification are still up in the air, the release of the RFC is even further in the future and when it is released, you can continue to use an OAuth 2.0 server if that serves your needs.</p>

<p>That said, when this is released the biggest impact on people who use OAuth for authentication or authorization in their applications will be planning on how to handle the removed grants: the Implicit grant or Resource Owner Password Credentials grant.</p>

<h2 id="what-is-changing">What is changing?</h2>

<p>The draft RFC has a <a href="https://tools.ietf.org/html/draft-parecki-oauth-v2-1-01#section-12">section</a> outlining the major changes between OAuth 2.0 and OAuth 2.1. There may be other changes not captured there but the goal is to document all formal changes there. There are six such changes:</p>

<blockquote>
  <p>The authorization code grant is extended with the functionality from PKCE (<a href="https://tools.ietf.org/html/rfc7636">RFC7636</a>) such that the only method of using the authorization code grant according to this specification requires the addition of the PKCE mechanism</p>
</blockquote>

<blockquote>
  <p>Redirect URIs must be compared using exact string matching as per Section 4.1.3 of <a href="https://tools.ietf.org/html/draft-ietf-oauth-security-topics-14">OAuth 2.0 Security Best Current Practices</a></p>
</blockquote>

<blockquote>
  <p>The Implicit grant (“response_type=token”) is omitted from this specification as per Section 2.1.2 of <a href="https://tools.ietf.org/html/draft-ietf-oauth-security-topics-14">OAuth 2.0 Security Best Current Practices</a></p>
</blockquote>

<blockquote>
  <p>The Resource Owner Password Credentials grant is omitted from this specification as per Section 2.4 of <a href="https://tools.ietf.org/html/draft-ietf-oauth-security-topics-14">OAuth 2.0 Security Best Current Practices</a></p>
</blockquote>

<blockquote>
  <p>Bearer token usage omits the use of bearer tokens in the query string of URIs as per Section 4.3.2 of <a href="https://tools.ietf.org/html/draft-ietf-oauth-security-topics-14">OAuth 2.0 Security Best Current Practices</a></p>
</blockquote>

<blockquote>
  <p>Refresh tokens must either be sender-constrained or one-time use as per Section 4.12.2 of <a href="https://tools.ietf.org/html/draft-ietf-oauth-security-topics-14">OAuth 2.0 Security Best Current Practices</a></p>
</blockquote>

<p>Whew, that’s a lot of jargon. We’ll examine each of these in turn. But before we do, let’s define a few terms that will be used in the rest of this post.</p>

<ul>
  <li>A <code>client</code> is a piece of code that the user is interacting with; browsers, native apps or single-page applications are all clients.</li>
  <li>An <code>OAuth server</code> implements OAuth specifications and has or can obtain information about which resources are available to clients–in the RFCs this is called an Authorization Server, but this is also known as an Identity Provider. Most users call it “the place I log in”.</li>
  <li>An <code>application server</code> doesn’t have any authentication functionality but knows how to delegate to an OAuth server. It has a client id which allows the OAuth server to identify it.</li>
</ul>

<h3 id="the-authorization-code-grant-and-pkce">The Authorization Code grant and PKCE</h3>

<blockquote>
  <p>The authorization code grant is extended with the functionality from PKCE (<a href="https://tools.ietf.org/html/rfc7636">RFC7636</a>) such that the only method of using the authorization code grant according to this specification requires the addition of the PKCE mechanism</p>
</blockquote>

<p>Wow, that’s a mouthful. Let’s break that down. The Authorization Code grant is one of the most common OAuth grants and is the most secure. If flow charts are your jam, here’s <a href="https://fusionauth.io/learn/expert-advice/authentication/webapp/oauth-authorization-code-grant-sessions">a post explaining the Authorization Code grant</a>.</p>

<p>The <a href="https://tools.ietf.org/html/rfc7636">Proof Key for Code Exchange (PKCE) RFC</a> was published in 2015 and extends the Authorization Code grant to protect from an attack if part of the authorization flow happens over a non TLS connection. For example, between components of a native application. This attack could also happen if TLS has a vulnerability or if router firmware has been compromised and is spoofing DNS or downgrading from TLS to HTTP. PKCE requires an additional one-time code to be sent to the OAuth server. This is used to validate the request has not been intercepted or modified.</p>

<p>The OAuth 2.1 draft specification requires that the PKCE challenge must be used with every Authorization Code grant, protecting against the authorization code being hijacked by an attacker.</p>

<h3 id="redirect-uris-must-be-compared-using-exact-string-matching">Redirect URIs must be compared using exact string matching</h3>

<blockquote>
  <p>Redirect URIs must be compared using exact string matching as per Section 4.1.3 of <a href="https://tools.ietf.org/html/draft-ietf-oauth-security-topics-14">OAuth 2.0 Security Best Current Practices</a></p>
</blockquote>

<p>Some OAuth grants, notably the Authorization Code grant, use a redirect URI to determine where to send the client after success. For example, here’s a FusionAuth screen where the allowed redirect URIs are configured (it is the “Authorized redirect URLs” setting):</p>

<p><img src="https://fusionauth.io/assets/img/blogs/whats-new-in-oauth-2-1/admin-application-configuration.png" alt="Application configuration"></p>

<p>In this case, the only allowed value is <code>http://localhost:3000/oauth-callback</code> but you can configure multiple values. The client specifies which one of these the user who is signing in should be redirected to.</p>

<p>Now, it would sure be convenient to support wildcards in this redirect URI list. At FusionAuth, we hear this request from folks who want to simplify their development or CI environments. Every time a new server is spun up, the redirect URI configuration must be updated to include the new URI.</p>

<p>For example, if a CI system builds an application for every feature branch, it might have the hostname <code>dans-sample-application-1551.herokuapp.com</code>, if the feature branch was a fix for bug #1551. If I wanted to login using the Authorization Code grant, I’d have to update the redirect URI settings for my OAuth server to include that specific redirect URI: <code>https://dans-sample-application-1551.herokuapp.com/oauth-callback</code>.</p>

<p>And then when the next feature branch build happened, say for bug #1552, I’d have to add <code>https://dans-sample-application-1552.herokuapp.com/oauth-callback</code> and so on. Obviously, it’d be easier to set the redirect URI to a wildcard value like <code>https://dans-sample-application-*.herokuapp.com/oauth-callback</code>; in an ideal world, any URL matching that pattern would be acceptable to the OAuth server. Of course, if you are using FusionAuth, you can <a href="https://fusionauth.io/docs/v1/tech/apis/applications#update-an-application">update your application configuration as part of the CI build process</a> as an alternative.</p>

<p>An additional use case for a wild card redirect URI is when the redirect URI needs dynamic parameters useful to the final destination page, like <code>trackingparam=123&amp;specialoffer=abc</code>. These may be appended to the redirect URL before the OAuth process began. A URL with dynamic parameters won’t match any of the configured redirect URIs, and so the redirect fails.</p>

<p>However, allowing such wildcard matching for the redirect URI is a security risk. If the redirect URI matching is flexible, an attacker could redirect a user to an open redirect server controlled by them, and then on to a malicious destination; OWASP further discusses the <a href="https://cheatsheetseries.owasp.org/cheatsheets/Unvalidated_Redirects_and_Forwards_Cheat_Sheet.html#dangerous-url-redirects">perils of such open redirect servers</a>. While this would require compromising the request in some fashion, using exact matching for redirect URIs eliminates this risk because the redirect URI is always a known value.</p>

<h3 id="the-implicit-grant-is-removed">The Implicit grant is removed</h3>

<blockquote>
  <p>The Implicit grant (“response_type=token”) is omitted from this specification as per Section 2.1.2 of <a href="https://tools.ietf.org/html/draft-ietf-oauth-security-topics-14">OAuth 2.0 Security Best Current Practices</a></p>
</blockquote>

<p>The Implicit grant is inherently insecure when used in a single-page application (SPA). If you use this grant, your access token is exposed. You’ll get an access token that is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/blog/2020/04/15/whats-new-in-oauth-2-1">https://fusionauth.io/blog/2020/04/15/whats-new-in-oauth-2-1</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/blog/2020/04/15/whats-new-in-oauth-2-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398999</guid>
            <pubDate>Mon, 07 Sep 2020 12:36:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Successful maiden flight for the TU Delft Flying-V]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398978">thread link</a>) | @jcfrei
<br/>
September 7, 2020 | https://www.tudelft.nl/en/2020/tu-delft/successful-maiden-flight-for-the-tu-delft-flying-v/ | <a href="https://web.archive.org/web/*/https://www.tudelft.nl/en/2020/tu-delft/successful-maiden-flight-for-the-tu-delft-flying-v/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    
                        <p><strong>This summer, a team of researchers, engineers and a drone pilot of TU Delft travelled to an airbase in Germany for the first real test flight of the scaled flight model of the energy-efficient aircraft design called the Flying-V. The project was announced last year together with KLM. After a period of extensive wind tunnel testing and a series of ground tests in the Netherlands, it was time to perform the first flight and obtain an impression of the flight characteristics. The aircraft had a very successful maiden flight.</strong></p><p>Project leader Dr Roelof Vos and his team of researchers and engineers took the 22.5 kg and 3 m wide scale model of the Flying-V for flight tests to a well-guarded airbase in Germany, where they could work together with a team from Airbus. The pilot’s task was to take-off, fly a number of test manoeuvres and approaches until the batteries were nearly empty and land. And he succeeded. Vos: “One of our worries was that the aircraft might have some difficulty lifting-off, since previous calculations had shown that ‘rotation’ could be an issue. The team optimized the scaled flight model to prevent the issue but the proof of the pudding is in the eating. You need to fly to know for sure.” Rotation on take-off was performed easily and occurred at a speed of 80 km/h. The plane’s thrust was good and flight speeds and angles were as predicted.</p><p>But testing new technology is never straightforward. The team had a challenging week in which they had to change the centre of gravity of the aircraft and fix the antenna to improve telemetry. The flight has now also confirmed that the current design still shows too much ‘Dutch roll’, causing a slightly rough landing. A next step for the team is to use the data collected during the flight for an aerodynamic (software) model of the aircraft. This will make it possible to programme it in a flight simulator to be used in future research , while further improving the flight characteristics. The team will also prepare the scale model for future flight tests.&nbsp;</p><div id="c651315">

	
		
		
		
			
	<div>
		
		<p>
			<iframe src="//www.youtube-nocookie.com/embed/XHFcLfSfJWQ?autohide=1&amp;controls=2&amp;enablejsapi=1&amp;origin=www.tudelft.nl&amp;theme=light&amp;modestbranding=1&amp;fs=0&amp;showinfo=0" allowfullscreen="" width="560" height="315" frameborder="0"></iframe>
		</p>
		
	</div>

		
	











</div><div id="c650988"><p>The Flying-V is a design for a highly energy-efficient long-distance aeroplane. The aircraft’s design integrates the passenger cabin, the cargo hold and the fuel tanks in the wings, creating a spectacular V-shape. Computer calculations have predicted that the aircraft’s improved aerodynamic shape and reduced weight will reduce fuel consumption by 20% compared to today’s most advanced aircraft. KLM has been a partner in the project since 2019. Also due to their support, the project team has been able to build this scale model. It was first presented at the 100th anniversary of KLM in October 2019. Various business partners are now involved in the project, including Airbus. Airbus is also an explicit supporter for the first flight. The partners are working together on a research plan to fine-tune the concept. Next step: providing the Flying-V with sustainable propulsion, taking into account that the design seems highly suitable to carry liquid hydrogen instead of kerosene. </p></div><div id="c650998"><p><em>Webcast</em>: On 1 September Dr. Roelof Vos and Prof. Henri Werij showed and explained what happened during the test week. Pieter Elbers, the CEO of KLM and Daniel Reckzeh, Senior Manager R&amp;T in Airbus&nbsp; commented. The recording of the webcast can be viewed here: <a href="https://live.dutchwebinar.com/tudelftwebcastflyingv" target="_blank">https://live.dutchwebinar.com/tudelftwebcastflyingv</a><br><em><br>Website</em>: Detailed information about the flight tests, including videos and photos, will be made available on <a href="https://www.tudelft.nl/en/ae/flying-v/" target="_blank">https://www.tudelft.nl/en/ae/flying-v/</a>&nbsp;on Tuesday 1 September.</p></div>
                    
                </div></div>]]>
            </description>
            <link>https://www.tudelft.nl/en/2020/tu-delft/successful-maiden-flight-for-the-tu-delft-flying-v/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398978</guid>
            <pubDate>Mon, 07 Sep 2020 12:32:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Biggest l10n and Internationalization issues developers face and how to fix them]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398914">thread link</a>) | @emilsw
<br/>
September 7, 2020 | https://learn.lokalise.com/localization-issues-webinar/ | <a href="https://web.archive.org/web/*/https://learn.lokalise.com/localization-issues-webinar/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="lp-pom-text-25"><p dir="ltr"><span>If you’re working on translating your product or digital asset into multiple languages then there’s no doubt that as a developer you’ll be faced with some l10n challenges.&nbsp;</span></p><p dir="ltr"><span>Luckily we’re here to show you how you can make this process as seamless as possible whilst tackling a number of the most common issues.&nbsp;</span></p><p dir="ltr"><span>Join this webinar and learn how to effortlessly speed up your localization workflow.&nbsp;</span></p></div><p><span><span><span><strong>You'll learn how to</strong></span></span></span></p><div id="lp-pom-text-35"><ol><li dir="ltr"><p dir="ltr"><span>Find and merge duplicate keys (used on different platforms like Android and iOS)</span></p></li><li dir="ltr"><p dir="ltr"><span>Exchange translations between TMS and Github/Bitbucket</span></p></li><li dir="ltr"><p dir="ltr"><span>Stop translators from altering placeholders</span></p></li><li dir="ltr"><p dir="ltr"><span>Avoid doing manual and repetitive tasks (such as uploading and downloading new translations)</span></p></li><li dir="ltr"><p dir="ltr"><span>Provide better context for translators</span></p></li><li dir="ltr"><p dir="ltr"><span>Properly download and separate translations by files</span></p></li><li dir="ltr"><p dir="ltr"><span>Avoid common UI translation bugs</span></p></li></ol></div><p><span><span><span>Ilya is a head of content at Lokalise, an IT tutor and author, web developer, and ex-Microsoft/Cisco specialist. His primary programming languages are Ruby, JavaScript, Python, and Elixir. He enjoys coding, teaching people and learning new things. In his free time he writes educational posts, participates in OpenSource projects, goes in for sports and plays music.</span></span></span></p><p><span><span><span>Speaker</span></span></span><br><span><span><span><strong>Ilya Bodrov-Krukowski</strong></span></span></span></p><div id="lp-pom-image-49"><p><img alt="" loading="lazy" data-src-desktop-1x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/9db7d1f7-illya_102d02d02d02b000001028.png" data-src-desktop-2x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/9db7d1f7-illya_104q04q04q04m000002028.png" data-src-desktop-3x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/9db7d1f7-illya_107307307306x000003028.png" data-src-mobile-1x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/9db7d1f7-illya_102d02d02d02b000001028.png" data-src-mobile-2x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/9db7d1f7-illya_104q04q04q04m000002028.png" data-src-mobile-3x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/9db7d1f7-illya_107307307306x000003028.png" src="https://d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/9db7d1f7-illya_107307307306x000003028.png"></p></div><div id="lp-pom-box-51"><div id="lp-pom-text-52"><p><span><span><span><strong>Register and join us live</strong></span></span></span></p></div><div id="lp-pom-text-53"><p><span><span><span>Enter your information below&nbsp;</span></span></span></p></div></div><div id="lp-pom-image-97"><p><img alt="" loading="lazy" data-src-desktop-1x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/3f48aaa7-lokalise-logo-black_103u00t000000000000028.png" data-src-desktop-2x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/3f48aaa7-lokalise-logo-black_107o01m000000000000028.png" data-src-desktop-3x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/3f48aaa7-lokalise-logo-black_10bi02f000000000000028.png" data-src-mobile-1x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/3f48aaa7-lokalise-logo-black_103u00t000000000000028.png" data-src-mobile-2x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/3f48aaa7-lokalise-logo-black_107o01m000000000000028.png" data-src-mobile-3x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/3f48aaa7-lokalise-logo-black_10bi02f000000000000028.png" src="https://d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/3f48aaa7-lokalise-logo-black_10bi02f000000000000028.png"></p></div><p><span><span><span><strong><strong><span data-preserver-spaces="true"><strong><span data-preserver-spaces="true">The 9 biggest localization (l10n &amp; I18n) issues developers face (and how to solve them)</span></strong></span></strong></strong></span></span></span></p><div id="lp-pom-image-113"><p><img alt="" loading="lazy" data-src-desktop-1x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/aa99f659-ill2_106z04a000000000000028.png" data-src-desktop-2x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/aa99f659-ill2_10dy08k000000000000028.png" data-src-desktop-3x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/aa99f659-ill2_1000000000000000000028.png" src="https://d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/aa99f659-ill2_1000000000000000000028.png"></p></div><p dir="ltr">Thursday, September 10th, 5PM CET &amp; 11AM EST</p><p dir="ltr">40 minutes</p><p id="lp-pom-text-118"><h2><span>The preferred localization software of 1500+ leading global companies</span></h2></p><div id="lp-pom-image-120"><p><img alt="" loading="lazy" data-src-desktop-1x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/9638ae3b-calendar-01-01-01_100s00s000000000000028.png" data-src-desktop-2x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/9638ae3b-calendar-01-01-01_101k01k000000000000028.png" data-src-desktop-3x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/9638ae3b-calendar-01-01-01_102c02c000000000000028.png" data-src-mobile-1x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/9638ae3b-calendar-01-01-01_100s00s000000000000028.png" data-src-mobile-2x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/9638ae3b-calendar-01-01-01_101k01k000000000000028.png" data-src-mobile-3x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/9638ae3b-calendar-01-01-01_102c02c000000000000028.png" src="https://d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/9638ae3b-calendar-01-01-01_102c02c000000000000028.png"></p></div><div id="lp-pom-image-121"><p><img alt="" loading="lazy" data-src-desktop-1x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/869faa37-clock-01-01_100u00u000000000000028.png" data-src-desktop-2x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/869faa37-clock-01-01_101o01o000000000000028.png" data-src-desktop-3x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/869faa37-clock-01-01_102i02i000000000000028.png" data-src-mobile-1x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/869faa37-clock-01-01_100u00u000000000000028.png" data-src-mobile-2x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/869faa37-clock-01-01_101o01o000000000000028.png" data-src-mobile-3x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/869faa37-clock-01-01_102i02i000000000000028.png" src="https://d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/869faa37-clock-01-01_102i02i000000000000028.png"></p></div><p><span><strong>WEBINAR</strong></span></p><div id="lp-pom-image-137"><p><img alt="" loading="lazy" data-src-desktop-1x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/e3f1d0bd-logotypes-no-more-smoking_10by024000000000000028.png" data-src-desktop-2x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/e3f1d0bd-logotypes-no-more-smoking_10nw048000000000000028.png" data-src-desktop-3x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/e3f1d0bd-logotypes-no-more-smoking_10zu06c000000000000028.png" data-src-mobile-1x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/e3f1d0bd-logotypes-no-more-smoking_108w01l000000000000028.png" data-src-mobile-2x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/e3f1d0bd-logotypes-no-more-smoking_10hs036000000000000028.png" data-src-mobile-3x="//d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/e3f1d0bd-logotypes-no-more-smoking_10qo04r000000000000028.png" src="https://d9hhrg4mnvzow.cloudfront.net/learn.lokalise.com/localization-issues-webinar/e3f1d0bd-logotypes-no-more-smoking_10qo04r000000000000028.png"></p></div><p><span><span><span><strong><strong><span data-preserver-spaces="true"><strong><span data-preserver-spaces="true">The 9 biggest localization (<span><span><span><strong><strong><span data-preserver-spaces="true"><strong><span data-preserver-spaces="true">l10n &amp; I18n</span></strong></span></strong></strong></span></span></span>) issues developers face (and how to solve them).</span></strong></span></strong></strong></span></span></span></p><p><span><strong>WEBINAR</strong></span></p></div></div>]]>
            </description>
            <link>https://learn.lokalise.com/localization-issues-webinar/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398914</guid>
            <pubDate>Mon, 07 Sep 2020 12:20:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wordpress, Pimcore or Gatsby? Helping you choose CMS for your company website]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398857">thread link</a>) | @kurzor
<br/>
September 7, 2020 | https://www.kurzor.net/blog/wordpress-pimcore-or-gatsby | <a href="https://web.archive.org/web/*/https://www.kurzor.net/blog/wordpress-pimcore-or-gatsby">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                 <p>Back in 2013, I published <strong>Why you should not use Drupal or Wordpress for your company website</strong> (Czech version only, <a href="https://www.kurzor.net/blog/18-ne-drupalu-a-wordpressu-na-firemni-web" target="_blank">available in the archive</a>). The article has gained popularity amongst our local visitors. Many changes happened in website development since its publication, therefore it's a good idea to revisit the article.</p>
<p>To make sure that we understand the topic, let me explain the commonly used shortcut. CMS means Content Management System and it is a solution that:</p>
<ul>
<li>
<p>will allow you to create, edit and organize content on your website (most often online, via some administrative interface),</p>
</li>
<li>
<p>composes the website itself from the content you provided.</p>
</li>
</ul>
<p>The world has changed a lot since 2013 and as such has had the web ecosystems. This led me to revisit the topic, taking the perspective of a company manager whose task it is to create a new website for his company.</p>
<p>Let's start with some questions.</p>
<h2>What should you ask before choosing</h2>
<p><strong>How much money should I invest in the website?</strong></p>
<p>Money. That factor is the ultimate and decisive argument when thinking about any development. You can't have a top-level website if you can't afford it. So you should start by writing down a possible budget.</p>
<p>What I learned is that by far many people think website costs are only about the technical part - preparing and powering it up. But this is hazardous. The golden rule of the best value for the money should be:</p>
<blockquote>
<p>Choose the minimum viable CMS solution and invest the rest of your money into promotion and content.</p>
</blockquote>
<p>This is the most important part. It does not matter how technically good your website is if nobody can't find it. It's critical to make sure you have enough visitors to start with, and that they don't leave because your website content sucks. Always select a viable goal such as the number of conversions / purchases and do everything in your power to achieve this goal.</p>
<p>The rest of this article should help you choose your minimally viable solution from what is available today. For that to succeed, start by writing down some points:</p>
<p><strong>What functionality do I require?</strong></p>
<p>Do you have any specific tasks in mind for the website apart from presenting just content like text, images and videos?</p>
<p>Should it contain purchasing options, and into what depth? Are you selling one product with 4 options or 400 products? Would you need to handle inventory, accounting and other features of e-commerce as well?</p>
<p>Is your website supposed to be connected to some other systems of yours or a third-party provider?</p>
<p>Do you have some interactive parts for your visitors, such as quizzes, games, seminars, anything unusual?</p>
<p>And for each of the points you come up with, you should ask:</p>
<blockquote>
<p>What is the motivation for this?
How important is it for me?
Is there any other way to do it other than including it on the website?</p>
</blockquote>
<p>The reason is that any of these parts might require additional development. Or worse, it might need a more complex CMS. Both ways, if it's not thought out well before the start, your costs might skyrocket.</p>
<p><strong>What is my expected traffic?</strong></p>
<p>Another important point. Do you expect to start small, with just a few unique visits daily, or do you immediately foresee to be attracting thousands of visitors?</p>
<p>People often expect their website to handle any amount of traffic at any given time, but that is, in fact, a complex technical issue. Choosing a bad CMS and hosting combination with a very large visitor influx might bring your whole website down very quickly, and your reputation is damaged from the start. Performance, meaning how quickly your site loads and renders content, is the key here.</p>
<p><strong>How quickly do I need it?</strong></p>
<p>This is also an important factor. It translates into a simple law:</p>
<blockquote>
<p>The quality of a product is tightly related to the time required to develop it.</p>
</blockquote>
<p>The more time you can invest before you launch the website, the more options are there to choose from. And of course, nobody is working longer hours for less money, so...</p>
<blockquote>
<p>Time equals money.</p>
</blockquote>
<p>This looks very dull and obvious, but it actually leads to a very important decision you need to ask at the start of your website development cycle:</p>
<p><strong>Custom design or ready-to-use template?</strong></p>
<p>Do you know the difference and benefits? Once you have agreed on the time &amp; cost you should take your time to consider them and make your decision.</p>
<p><strong>Ready-to-use templates</strong>  or <strong>themes</strong>  are properties of some CMS to lower the initial cost a lot. Requiring typically just a small purchase and some time spent on populating the content, it has its merits for some scenarios. You cannot depend on them too heavily, though.</p>
<p>One disadvantage is that modification of themes is possible only to some extent. Demo sites usually show all of the features and if you need something outside of this realm, you might need expensive and complicated developer intrusions.</p>
<p>There will also be performance issues. Themes try to accommodate as many options as possible and that often leads to bloated designs with poor page load speeds.</p>
<p>And lastly, forget about any uniqueness. Thousands of websites might reuse the same theme as you do. And the best selling themes are the most generic ones, to appease the largest crowd.</p>
<figure>
        <img src="https://www.kurzor.net/var/assets/template_images/blog/wordpress-pimcore-or-gatsby/themes-themeforest.jpg" alt="Themes Themeforest" title="Themes Themeforest">
        <figcaption><i> <em>Figure 1.: Try</em> <a href="https://themeforest.net/category/wordpress?sort=sales" target="_blank"><em>Themeforest</em></a> <em>to get some idea what themes look like. Around 12k themes for Wordpress, costs averaging around $50.</em> </i></figcaption>
    </figure>
<p><strong>Custom design</strong>  is always the more expensive option. It usually has two steps: <em>Graphics design</em>, where your website layout is designed by a professional, and <em>coding phase</em>, which is the conversion of the design into the CMS of choice. And that also requires a professional, the one titled <em>front-end developer</em>  (sometimes <em>web coder</em>).</p>
<p>The main disadvantage is thus cost and time. Advantages, on the other hand, are serious to make this option considerable:</p>
<ul>
<li>
<p>It is possible to design whatever you want, meaning some unique parts of your site can be accommodated.</p>
</li>
<li>
<p>With a good front-end developer you are able to obtain unmatched results in site performance, cross-browser and cross-device compatibility.</p>
</li>
<li>
<p>Provided you have a good choice of the designer, your website will be more appealing and uniquely branded to fit your visual identity.</p>
</li>
</ul>
<p>With questions asked and answers written down, let's dive deep into the selection that is on the market today.</p>
<h2>First option: Classic Open-Source CMS</h2>
<p>First, we will explore CMS that can be downloaded and installed on your web server. Let's call them "classic". There are a few notes that you should be aware of.</p>
<p>At first, you need some hosting with an appropriate web server to set up your site. This is different for the various systems. Currently, it is possible to find optimized hosting plans for every major CMS. That usually trades higher cost for additional benefits, such as faster setup time, better CMS performance and fewer security issues.</p>
<p>Secondly, this type of CMS usually requires some developer or specialist to set up the website as you require. More peculiar systems will – in general – demand more skilled labour.</p>
<p>Thirdly, all these systems offer an administration interface directly via the website you will be creating. Which makes editorial work simple, but can be a security problem if not treated professionally.</p>
<h3><em>Important Note: Open-Source or Proprietary?</em></h3>
<p>Originally in 2013, I leaned towards a tailor-made CMS solution, pointing to our own 3OS system as a good candidate for the company website. Today, after gaining additional knowledge and experience, my stance is very different and I prefer Open-source systems.</p>
<p>You might ask, why? Is it about the cost of the license?</p>
<p>Actually, no. The argument is simple: Open-source CMS have matured, the selection is huge and the advantages of using them seriously outweigh the commercial/custom/proprietary bunch:</p>
<ul>
<li>their real-world usage is different orders of magnitude higher,</li>
<li>this results in the large development community and frequent updates,</li>
<li>they also have a whole ecosystem of ready-to-use themes and various plugins,</li>
<li>they are popular amongst developers, hence the risk of vendor lock-in is lower.</li>
</ul>
<p>That is also what happened to us since 2013: although the 3OS system we developed at Kurzor was a good choice for clients considering cost, quality and ease of use, it was simply unsustainable to continue its further development and keep the pace with other evolving Open-source solutions. So we now prefer Open-source CMS solutions for new projects, most usual choices being Wordpress, Pimcore or Gatsby.</p>
<p>That explained, let's move further and inspect the market as of today.</p>
<p>There is one system which we cannot afford to not list in there. Guess which one.</p>
<h3>Wordpress: The big name in the game</h3>
<p>Any serious conversation about CMS for a company website must start with Wordpress. Its coverage is by far the largest and there is nothing that can be done about it in the near future.</p>
<p>Wordpress is a great example of a matured system. It is reliable and has many great features you can directly use, such as an excellent visual-based editor, an understandable system for posts and articles, media management and many more.</p>
<figure>
        <img src="https://www.kurzor.net/var/assets/template_images/blog/wordpress-pimcore-or-gatsby/gutenberg-editor.jpg" alt="Gutenberg Editor" title="Gutenberg Editor">
        <figcaption><i> <em>Figure 2.: Wordpress core editor for content is called Gutenberg and while it looks simple, its possibilities are quite rich. You can</em> <a href="https://testgutenberg.com/" target="_blank"><em>test it yourself on a demo page</em></a><em>.</em> </i></figcaption>
    </figure>
<p>While perfectly suitable for sites with all degrees of complexity, there are some specifics of using Wordpress as your CMS of choice.</p>
<p>First of all, Wordpress is <strong>primarily a "blogging" solution</strong>. It might need the help of a few plugins to enhance it to expected levels of a typical company website. Some of them require a commercial license, making it harder to perform upgrades in the long run.</p>
<ul>
<li>
<p>For example, you need an external plugin like to handle multilingual content <a href="https://wpml.org/" target="_blank">the excellent WPML</a>,</p>
</li>
<li>
<p>or you want the power of a tool like <a href="https://www.advancedcustomfields.com/" target="_blank">Advanced Custom Fields</a> to define content entities and their relations.</p>
</li>
</ul>
<p>With Wordpress, you can do <strong>both design options</strong>, with ready-to-use themes being in the large and affordable spectrum, and custom design having no …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.kurzor.net/blog/wordpress-pimcore-or-gatsby">https://www.kurzor.net/blog/wordpress-pimcore-or-gatsby</a></em></p>]]>
            </description>
            <link>https://www.kurzor.net/blog/wordpress-pimcore-or-gatsby</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398857</guid>
            <pubDate>Mon, 07 Sep 2020 12:11:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From SIMD to AST Extraction]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398789">thread link</a>) | @ibobev
<br/>
September 7, 2020 | https://pdimov.github.io/blog/2020/09/05/from-simd-to-ast-extraction/ | <a href="https://web.archive.org/web/*/https://pdimov.github.io/blog/2020/09/05/from-simd-to-ast-extraction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>05 Sep 2020</span></p><p>Suppose we have the functions</p>

<div><div><pre><code>float f( float x )
{
    return x * 2.0f + 1.0f;
}

float g( float x, float y )
{
    return f( x ) * 0.3f + f( y ) * 0.7f;
}
</code></pre></div></div>

<p>and we need to apply <code>g</code> to the two arrays <code>x</code> and <code>y</code>,
storing the result in the array <code>z</code>:</p>

<div><div><pre><code>void h( float const * x, float const * y, float * z, std::size_t n )
{
    for( std::size_t i = 0; i &lt; n; ++i )
    {
        z[ i ] = g( x[ i ], y[ i ] );
    }
}
</code></pre></div></div>

<p>Nowadays, all major compilers
<a href="https://godbolt.org/z/q148se">automatically vectorize</a>
this code and generate SIMD instructions for it – at most,
we need to pass <a href="https://godbolt.org/z/c71vo5">-O3</a> instead
of <a href="https://godbolt.org/z/63hqG4">-O2</a> to GCC. But let’s
suppose, for the sake of discussion, that it’s 2008, the
compilers don’t autovectorize, and we still want to employ SIMD.</p>

<p>One elegant technique that allows us to keep our functions
mostly unchanged is to convert them to templates:</p>

<div><div><pre><code>template&lt;class T&gt; T f( T x )
{
    return x * 2.0f + 1.0f;
}

template&lt;class T&gt; T g( T x, T y )
{
    return f( x ) * 0.3f + f( y ) * 0.7f;
}
</code></pre></div></div>

<p>This still lets us call them with <code>float</code> as before, but
it also enables us calling them with a
<a href="https://gcc.gnu.org/onlinedocs/gcc/Vector-Extensions.html">SIMD pack of four floats</a>:</p>

<div><div><pre><code>using m128 = __attribute__(( vector_size( 4*sizeof(float) ) )) float;
</code></pre></div></div>

<p>so that we can now rewrite <code>h</code> to
<a href="https://godbolt.org/z/Y8xqd9">work at four elements at a time</a>:</p>

<div><div><pre><code>void h( float const * x, float const * y, float * z, std::size_t n )
{
    std::size_t i = 0;

    for( ; i + 3 &lt; n; i += 4 )
    {
        m128 xi;
        std::memcpy( &amp;xi, x + i, sizeof( m128 ) );

        m128 yi;
        std::memcpy( &amp;yi, y + i, sizeof( m128 ) );

        m128 zi = g( xi, yi );

        std::memcpy( z + i, &amp;zi, sizeof( m128 ) );
    }

    for( ; i &lt; n; ++i )
    {
        z[ i ] = g( x[ i ], y[ i ] );
    }
}
</code></pre></div></div>

<p>OK, but what’s the point of all this in 2020?</p>

<p>Well, it turns out that templatizing our functions enables more
than vectorization. We can pass other things to them. In particular,
we can define a type that instead of doing calculations when operators
such as <code>+</code> and <code>*</code> are applied to it, builds an abstract syntax tree
instead.</p>

<p>This means that when we call <code>g</code> with this type, instead of the value
<code>g(x)</code> at some point <code>x</code>, we can get a symbolic representation of the body
of <code>g</code>.</p>

<p>To illustrate that, I will define a simple type <code>Q</code> that for reasons of
brevity will build a string representation of the function body, instead
of a proper syntax tree:</p>

<div><div><pre><code>struct Q
{
    std::string s_;

    Q( std::string const &amp; s ): s_( s ) {}
    Q( float x ): s_( std::to_string( x ) ) {}
};

Q operator+( Q const&amp; q1, Q const&amp; q2 )
{
    return { "(" + q1.s_ + " + " + q2.s_ + ")" };
}

Q operator*( Q const&amp; q1, Q const&amp; q2 )
{
    return { "(" + q1.s_ + " * " + q2.s_ + ")" };
}

std::ostream&amp; operator&lt;&lt;( std::ostream&amp; os, Q const&amp; q )
{
    return os &lt;&lt; q.s_;
}
</code></pre></div></div>

<p>Now, when I pass this type to our function <code>g</code>:</p>

<div><div><pre><code>    std::cout &lt;&lt; g( Q{"x"}, Q{"y"} ) &lt;&lt; std::endl;
</code></pre></div></div>

<p>I <a href="https://godbolt.org/z/jonEWT">get</a></p>

<div><div><pre><code>((((x * 2.000000) + 1.000000) * 0.300000) + (((y * 2.000000) + 1.000000) * 0.700000))
</code></pre></div></div>

<p>which is exactly what <code>g</code> does.</p>

</div>

<!--

<div class="related">
  <h2>Related posts</h2>
  <ul class="related-posts">
    
    
      <li>
        <h3>
          <a href="/blog/2020/09/07/named-parameters-in-c20/">
            Named Parameters in C++20
            <small>07 Sep 2020</small>
          </a>
        </h3>
      </li>
    
    
    
      <li>
        <h3>
          <a href="/blog/2020/09/06/why-use-the-boost-license/">
            Why You Should Use the Boost Software License
            <small>06 Sep 2020</small>
          </a>
        </h3>
      </li>
    
    
    
      <li>
        <h3>
          <a href="/blog/2020/07/24/compilers-do-static-analysis/">
            Compilers Do Static Analysis, They Just Don't Tell You
            <small>24 Jul 2020</small>
          </a>
        </h3>
      </li>
    
    
  </ul>
</div>

-->

      </div></div>]]>
            </description>
            <link>https://pdimov.github.io/blog/2020/09/05/from-simd-to-ast-extraction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398789</guid>
            <pubDate>Mon, 07 Sep 2020 11:58:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Future of Staffing and Consulting: AI-Powered and Integrated]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398774">thread link</a>) | @suhailameen46
<br/>
September 7, 2020 | https://oorwin.com/ebooks/future-of-staffing-and-consulting-ai-powered-and-integrated.html | <a href="https://web.archive.org/web/*/https://oorwin.com/ebooks/future-of-staffing-and-consulting-ai-powered-and-integrated.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>This e-book examines the current staffing and consulting industry landscape and explores the technologies staffing companies need to meet their strategic goals.</p>
<p>The e-book also shows how staffing companies can stay ahead of the curve by:</p>
<ul>
<li>Winning more deals while retaining existing customers</li>
<li>Recruiting quality candidates fast</li>
<li>Reducing hiring bottlenecks</li>
<li>Automating low-value, manual tasks</li>
<li>Leveraging AI and ML for accuracy and efficiency</li>
<li>Ensuring legal compliance across geographies</li>
<li>Delivering cloud-ready, remote-first solutions</li>
<li>Enhancing customer and employee experience</li>
</ul>
			</div></div>]]>
            </description>
            <link>https://oorwin.com/ebooks/future-of-staffing-and-consulting-ai-powered-and-integrated.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398774</guid>
            <pubDate>Mon, 07 Sep 2020 11:54:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Named Parameters in C++20]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 75 (<a href="https://news.ycombinator.com/item?id=24398756">thread link</a>) | @ibobev
<br/>
September 7, 2020 | https://pdimov.github.io/blog/2020/09/07/named-parameters-in-c20/ | <a href="https://web.archive.org/web/*/https://pdimov.github.io/blog/2020/09/07/named-parameters-in-c20/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>07 Sep 2020</span></p><p>A programming language supports <em>named parameters</em> when one
can call a function supplying the parameters by name, as in
the following hypothetical example (using C++ syntax):</p>

<div><div><pre><code>void f( int x, int y );

int main()
{
    f( x = 1, y = 2 );
}
</code></pre></div></div>

<p>C++ is obviously not such a language and there have been
numerous proposals to rectify this omission, unfortunately none
of them successful. The latest attempt is Axel Naumann’s paper
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0671r2.html">Self-explanatory Function Arguments</a>,
which tries to attack the problem from another angle by just
allowing normal function calls to be tagged with the parameter
name, as in</p>



<p>enabling compilers to issue helpful warnings when a name doesn’t
match, but not allowing one to omit, or reorder, arguments.</p>

<p>Even in this limited form, named parameters would still be immensely
useful, but this is not what this post is about. What this post is
about is that we can already achieve something very close to named
parameters in C++20, by using a C99 feature called <em>designated
initializers</em>.</p>

<p>Designated initializers allow one to initialize structures by
member name, as in the following example:</p>

<div><div><pre><code>struct A
{
    int x;
    int y;
};

A a1 = { .x = 1, .y = 2 };
A a2 = { .x = 3 }; // a2.y == 0
A a3 = { .y = 4 }; // a3.x == 0
A a4 = { .y = 5, .x = 6 }; // valid C, invalid C++ (reorder)
</code></pre></div></div>

<p>C++ introduces a restriction C doesn’t have: the initializers
must follow the declaration order, similarly to how class member
initalizers are executed in member declaration order. But in
exchange, it allows us to supply default values:</p>

<div><div><pre><code>struct A
{
    int x = 0;
    int y = 0;
};

A a3 = { .y = 4 }; // a3.x == 0, no warning
</code></pre></div></div>

<p>You can already see where this is going. Instead of</p>



<p>we declare</p>



<p>and then call it like this:</p>

<div><div><pre><code>int main()
{
    f({ .x = 1, .y = 2 });
}
</code></pre></div></div>

<p>This works under <a href="https://godbolt.org/z/YfWj3W">GCC</a> and
<a href="https://godbolt.org/z/vbnz4T">Clang</a> even without <code>-std=c++20</code> because
they support designated initializers in earlier language modes as
an extension, and it works under <a href="https://godbolt.org/z/bKozaW">MSVC</a>
with <code>-std:c++latest</code>.</p>

<p>For a more realistic example, consider this snippet, taken from real
code, that sets a 10 second
<a href="https://www.boost.org/doc/libs/1_74_0/libs/beast/doc/html/beast/using_websocket/timeouts.html">timeout</a>
on a <a href="https://boost.org/libs/beast">Boost.Beast</a> websocket:</p>

<div><div><pre><code>#include &lt;boost/beast/websocket/stream.hpp&gt;
#include &lt;boost/beast/core/tcp_stream.hpp&gt;
#include &lt;chrono&gt;

void f1(boost::beast::websocket::stream&lt;boost::beast::tcp_stream&gt;&amp; ws)
{
    auto opt = boost::beast::websocket::stream_base::timeout();

    opt.keep_alive_pings = true;
    opt.idle_timeout = std::chrono::seconds(10);

    ws.set_option(opt);
}
</code></pre></div></div>

<p>Here’s how we can reformulate it by using the above idiom and <code>&lt;chrono&gt;</code>
literals:</p>

<div><div><pre><code>#include &lt;boost/beast/websocket/stream.hpp&gt;
#include &lt;boost/beast/core/tcp_stream.hpp&gt;
#include &lt;chrono&gt;

using namespace std::chrono_literals;

void f2(boost::beast::websocket::stream&lt;boost::beast::tcp_stream&gt;&amp; ws)
{
    ws.set_option({ .idle_timeout = 10s, .keep_alive_pings = true });
}
</code></pre></div></div>

<p>Apart from the slightly awkward <code>({ ... })</code> syntax and the need to observe
the right parameter order, that’s not that far from the ideal; and it’s
considerably better than <code>f1</code>.</p>

<p>This also works for constructors. Consider this hypothetical <code>vector</code> class
that is like <code>std::vector</code>, except with its various constructor overloads
replaced with one taking named parameters:</p>

<div><div><pre><code>template&lt;class T, class A = std::allocator&lt;T&gt;&gt; class vector
{
private:

    struct params
    {
        std::size_t size = 0;
        T element{};
        std::size_t capacity = 0;
        A allocator{};
    };

public:

    explicit vector( params p );
};
</code></pre></div></div>

<p>This is <a href="https://godbolt.org/z/x17fdY">how it’s used</a>:</p>

<div><div><pre><code>auto f()
{
    vector&lt;int&gt; v{{ .size = 4, .element = 11, .capacity = 64 }};
    return v;
}
</code></pre></div></div>

<p>Again, apart from the odd <code>{{ ... }}</code> syntax, not that bad.</p>


</div>

<!--

<div class="related">
  <h2>Related posts</h2>
  <ul class="related-posts">
    
    
      <li>
        <h3>
          <a href="/blog/2020/09/06/why-use-the-boost-license/">
            Why You Should Use the Boost Software License
            <small>06 Sep 2020</small>
          </a>
        </h3>
      </li>
    
    
    
      <li>
        <h3>
          <a href="/blog/2020/09/05/from-simd-to-ast-extraction/">
            From SIMD to AST Extraction
            <small>05 Sep 2020</small>
          </a>
        </h3>
      </li>
    
    
    
      <li>
        <h3>
          <a href="/blog/2020/07/24/compilers-do-static-analysis/">
            Compilers Do Static Analysis, They Just Don't Tell You
            <small>24 Jul 2020</small>
          </a>
        </h3>
      </li>
    
    
  </ul>
</div>

-->

      </div></div>]]>
            </description>
            <link>https://pdimov.github.io/blog/2020/09/07/named-parameters-in-c20/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398756</guid>
            <pubDate>Mon, 07 Sep 2020 11:51:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Composer for Easy WordPress Deployments]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398718">thread link</a>) | @patelpankaj
<br/>
September 7, 2020 | https://time2hack.com/composer-wordpress-deployment/ | <a href="https://web.archive.org/web/*/https://time2hack.com/composer-wordpress-deployment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<p>There are many ways to manage a WordPress application. Fortunately, it is possible to use Composer with WordPress.</p><p>In this article, we will show how to <strong>use Composer with WordPress</strong>, so that you can easily <strong>maintain</strong> it, <strong>manage</strong> it and <strong>deploy</strong> it in different server environments.</p><p>That means that you will be able to <strong>install WordPress core, themes, plugins</strong> etc. as well as update and delete them when needed via Composer.</p><p>To achieve this, we will use the following tools:</p><ul><li><a href="https://getcomposer.org/">Composer</a> - for managing packages</li><li><a href="https://wpackagist.org/">WPackagist</a> - repository for WordPress plugins and themes</li><li><a href="https://laravel.com/docs/master/envoy">Laravel Envoy</a> - for writing easy deployment scripts</li></ul><hr><h2 id="using-composer-with-wordpress">Using Composer with WordPress</h2><p>Our first goal is to <strong>download the WordPress core, the plugins and themes as versioned Composer dependencies</strong>.</p><p>So in order to <strong>use Composer with WordPress</strong>, we will first install Composer and then create a <code>composer.json</code> file in the root directory of our project:</p><pre><code>{
    "repositories":[
        {
            "type":"composer",
            "url":"https://wpackagist.org"
        }
    ]
}
</code></pre><p>Since Composer uses <a href="https://packagist.org/">Packagist</a> by default as a package repository, we will need to tell Composer that we will need <a>WPackagist</a> instead.</p><p>Now we would be able to <strong>install public WordPress plugins and themes as Composer dependencies</strong>, for example like this:</p><pre><code>{
    "require": {
        "wpackagist-plugin/akismet":"^4.1",
        "wpackagist-theme/twentytwenty":"*"
    }
}
</code></pre><p>Next, let's <strong>install the WordPress core via Composer</strong>. We will be using <a href="https://github.com/johnpbloch/wordpress">John P Bloch's mirror of WordPress Core</a> to achieve that:</p><pre><code>{
	"require": {
	        "johnpbloch/wordpress": "&gt;=5.4"
	},
	"extra": {
	        "installer-paths": {
	            "wp-content/plugins/{$name}/": [
	                "type:wordpress-plugin"
	            ],
	            "wp-content/themes/{$name}/": [
	                "type:wordpress-theme"
	            ]
	        },
	        "wordpress-install-dir": "wordpress"
	},
	"repositories": [
	        {
	            "type": "composer",
	            "url": "https://wpackagist.org"
	        }
	]
}       
</code></pre><p>In the <code>require</code> section, we added the dependency. Next, in the <code>extra</code> section, we told <strong>Composer where to look for themes and plugins</strong>. Lastly, we defined the WordPress installation directory to be <code>wordpress</code>.</p><p>Now we can run the following command:</p><pre><code>composer install --prefer-dist
</code></pre><p>Composer will now install WordPress within the <code>wordpress</code> directory in the root of our project.</p><p>To be able to <strong>fully manage WordPress with Composer</strong>, we need to use a different directory for <code>wp-content</code> instead of the default one, <code>wordpress/wp-content</code>.</p><p>Let's create a new directory in the project's root, called <code>wp-content</code>.</p><p>Let's go ahead and create the standard <code>wp-config.php</code> file and then add the following code:</p><pre><code>$domain = 'mydomain.test';

define('WP_SITEURL', "{$domain}/wordpress");
define('WP_HOME',"http:{$domain}");

$httpHost =  isset($_SERVER['HTTP_HOST']) ? $_SERVER['HTTP_HOST'] : $domain;

define( 'WP_CONTENT_DIR', dirname( __FILE__ ) . '/wp-content' );
define( 'WP_CONTENT_URL', 'http://' . $httpHost . '/wp-content' );

/** Absolute path to the WordPress directory. */
if ( !defined('ABSPATH') ) {
    define('ABSPATH', dirname(__FILE__) . '/wordpress');
}

/** Sets up WordPress vars and included files. */
require_once(ABSPATH . 'wp-settings.php');
</code></pre><p>Next, let's create an <code>index.php</code> file within our project's root directory:</p><pre><code>&lt;?php 
define('WP_USE_THEMES', true);
require( dirname( __FILE__ ) . '/wordpress/wp-blog-header.php' );
</code></pre><p>Since the <code>wp-config.php</code> file contains sensitive data, we will not commit it to our repository by creating a <code>.gitignore</code> file:</p><pre><code>/wp-config.php
/wordpress/
/wp-content/
/vendor/
</code></pre><p>The <code>wordpress</code>, <code>wp-content</code> and <code>vendor</code> directories also need to be ignored, so we will add them to the <code>.gitignore</code> file as well.</p><p>Now we end up with a very simple project structure:</p><pre><code>/
├── composer.json
├── composer.lock
├── wp-config.php
├── wp-content/
├── wordpress/
├── vendor/
└── .gitignore</code></pre><hr><h3 id="using-composer-to-install-wordpress-plugins-and-themes-from-private-repositories">Using composer to install WordPress plugins and themes from private repositories</h3><p>You may want to install plugins or themes that are hosted in <strong>private repositories</strong> on <strong>Github, Bitbucket</strong> or somewhere else, but not on WPackagist.<br>That is possible, but there are two things you need to do:</p><ol><li>provide your credentials in an <code>auth.json</code> file</li><li>within the <code>composer.json</code>, in the <code>repositories</code> section, you need to tell Composer where to look for the repository:</li></ol><pre><code>{
  "type": "vcs",
  "url": "https://bitbucket.org/your-company/your-theme.git"
}
</code></pre><hr><h2 id="using-envoy-to-deploy-wordpress-with-composer">Using Envoy to deploy WordPress with Composer</h2><p>Now that we have our WordPress project set up with Composer, let's see how to deploy it.</p><p>As we mentioned previously, we will be using <a href="https://laravel.com/docs/master/envoy">Laravel Envoy</a> to <strong>write a deployment script for WordPress</strong>.</p><p>The reason why we are using Envoy is because of simplicity. You can also decide to use a different tool like <a href="https://deployer.org/">Deployer</a>.</p><p>Let's go ahead and download Envoy.</p><p>With the deployment script, we can <strong>deploy our WordPress application to different servers</strong>: development, staging and production.</p><p>Because the project structure is so lightweight, now it will be easy to write the deployment steps.</p><p>Here is what our <strong>deployment script for WordPress</strong> will look do:</p><ol><li>Create a new release with a timestamp in a <code>releases</code> directory on your server</li><li>Clone the repository</li><li>Install all the dependencies</li><li>Copy <code>wp-config</code>, <code>.htaccess</code> and other files specific to the server environment (e.g production)</li><li>Create a symlink of the <code>uploads</code> directory to the new release</li><li>Create a symlink of the new release to the domain's document root directory on the server</li><li>Clean up old releases from the server.</li></ol><p>First, let's go to our server and set up a directory called <code>current</code> as the domain document root directory on the server.</p><p>If you are not familiar that, you can follow a <a href="https://www.digitalocean.com/community/tutorials/how-to-move-an-apache-web-root-to-a-new-location-on-ubuntu-16-04">tutorial</a> on how to do it.</p><p>You can create the following directory structure on your server: <code>~/sites/yoursite</code></p><p>Now, let's install Envoy with the following command:</p><pre><code>composer global require laravel/envoy
</code></pre><p>Next, let's write the <strong>deployment script for WP</strong>. Let's create a new file in our project root directory called <code>Envoy.blade.php</code>.</p><p>In Envoy, we will use the following directives: <code>@servers</code>, <code>@setup</code>, <code>@task</code> and <code>@story</code>. It's very straightforward, here is what they mean:</p><ul><li><code>@servers</code> - this is where you define all your servers with their corresponding IPs.</li><li><code>@setup</code> - section where you can define variables or configurations.</li><li><code>@task</code> - a single action that should be executed on the specified server.</li><li><code>@story</code> - a sequence of tasks that need to be executed on the specified server.</li></ul><p>The way Envoy works is, it will ssh to the specified servers and execute the defined script, by following the directives.</p><p>Inside the directives you can use PHP to define which UNIX commands need to be executed on the servers.</p><p>The first step will be to define multiple server environments:</p><pre><code>@servers(['local' =&gt; '127.0.0.1', 'staging' =&gt; 'w.x.y.z' 'production' =&gt; ['a.b.c.d']])
</code></pre><p>Next, let's define some variables for our setup steps. These are the things we can configure, depending on our needs.</p><p>In our case, we will assume we have a private repository on Bitbucket for the project.</p><p>The deployment script will clone the master branch and set up the releases directory structure, as discussed above.</p><pre><code>@setup

    // the repository to clone
    $repo = '<a href="https://time2hack.com/cdn-cgi/l/email-protection" data-cfemail="e88f819ca88a819c8a9d8b838d9cc6879a8f">[email&nbsp;protected]</a>:your-company/your-wp-composer-project.git';

    // the branch to clone
    $branch = 'master';

    // set up timezones
    date_default_timezone_set('Europe/Berlin');
    
    // we want the releases to be timestamps to ensure uniqueness
    $date = date('YmdHis');

    // the application directory on your server
    $appDir = '~/sites/yoursite';

    // this is where the releases will be stored
    $buildsDir = $appDir . '/releases';

    // this is where the deployment will be
    $deploymentDir = $buildsDir . '/' . $date;

    // and this is the document root directory
    $serve = $appDir . '/current';
    
@endsetup</code></pre><p>Next, let's create a task to actually create the directory for the new release:</p><pre><code>@task('dir')
    echo "Preparing new deployment directory..."
    
    cd {{ $buildsDir }}
    mkdir {{ $date }}
    
    echo "Preparing new deployment directory complete."
@endtask
</code></pre><p>As you can see, it's using Blade syntax for the UNIX commands, with the variables we defined in <code>@setup</code>.</p><p>The following task will clone the repository and the specified branch:</p><pre><code>@task('git')
    echo "Cloning repository..."
    
    cd {{ $deploymentDir }}
    git clone --depth 1 -b {{ $branch }} "{{ $repo }}" {{ $deploymentDir }}

    echo "Cloning repository complete."
@endtask
</code></pre><p>Of course, you will need to make sure your server can access the git repository.</p><p>The next task, will install the dependencies and copy the <code>wp-config.php</code> file:</p><pre><code>@task('install')
    echo "Installing dependencies...";

    composer install --prefer-dist
    cp ../../wp-config.php ./wp-config.php
    
    echo "Installing dependencies complete."
@endtask
</code></pre><p>The next task will create the symlinks to the new release and to the <code>uploads</code> directory:</p><pre><code>@task('live')
    echo "Creating symlinks for the live version..."
    
    cd {{ $deploymentDir }}
    ln -nfs {{ $deploymentDir }} {{ $serve }}
    ln -nfs {{ $appDir }}/uploads {{ $serve }}/wp-content/
    
    echo "Creating symlinks completed."
@endtask
</code></pre><p>The last task will perform a cleanup and delete old releases:</p><pre><code>@task('deployment_cleanup')
    echo "Cleaning up old deployments..."
	
    cd {{ $buildsDir }}
    ls -t | tail -n +4 | xargs rm -rf
    
	echo "Cleaned up old deployments."
@endtask
</code></pre><p>We can configure the number of old releases we want to keep on the server. In our case it is 4.</p><p>Now let's write a <code>@story</code> directive where we can group the tasks we just wrote:</p><pre><code>@story('deploy-staging', ['on' =&gt; 'staging'])
    dir
    git
    install
    live
    deployment_cleanup
@endstory
</code></pre><pre><code>@story('deploy-production', ['on' =&gt; 'production'])
    dir
    git
    install
    live
    deployment_cleanup
@endstory
</code></pre><p>As you can see, we used the names of the tasks inside the <code>@story</code> to define the order of execution.</p><p>Finally, we would be able to run the following <strong>commands to deploy our WordPress to the server</strong>:</p><pre><code>envoy run deploy-staging
</code></pre><p>and</p><pre><code>en…</code></pre></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://time2hack.com/composer-wordpress-deployment/">https://time2hack.com/composer-wordpress-deployment/</a></em></p>]]>
            </description>
            <link>https://time2hack.com/composer-wordpress-deployment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398718</guid>
            <pubDate>Mon, 07 Sep 2020 11:43:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Word macro executes PowerShell and download Emotet trojan – Malware Analysis]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398714">thread link</a>) | @anuraggawande
<br/>
September 7, 2020 | http://malwr-analysis.com/2020/09/07/word-document-malware-analysis/ | <a href="https://web.archive.org/web/*/http://malwr-analysis.com/2020/09/07/word-document-malware-analysis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-899">
	<!-- .entry-header -->

	<div>
		
<p>MD5: CA15F9F45971EA442943084547761994 </p>



<p>File: Microsoft word document</p>



<p>Word Document Screenshot:</p>



<div><figure><img data-attachment-id="907" data-permalink="https://malwr-analysis.com/blg23_05092020_03/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_03.png" data-orig-size="1920,570" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg23_05092020_03" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_03.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_03.png?w=900" src="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_03.png?w=1024" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_03.png?w=1024 1024w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_03.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_03.png?w=300 300w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_03.png?w=768 768w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_03.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>File Properties: </p>



<div><figure><img data-attachment-id="904" data-permalink="https://malwr-analysis.com/blg23_05092020_01/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_01.png" data-orig-size="436,338" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg23_05092020_01" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_01.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_01.png?w=436" src="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_01.png?w=300" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_01.png?w=300 300w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_01.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_01.png 436w" sizes="(max-width: 300px) 100vw, 300px"></figure></div>



<p>I used OLEVBA.py to extract the VBA code but it was giving error. I used <a rel="noreferrer noopener" href="https://blog.didierstevens.com/programs/oledump-py/" target="_blank">oledump.py</a> tools to analyze the file.</p>



<p>  Using oledum.py. I ran the below command to get the complete document streams. </p>



<pre>&gt;&gt;oledump.py &lt;filename&gt;</pre>



<div><figure><img data-attachment-id="912" data-permalink="https://malwr-analysis.com/blg23_05092020_04/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_04.png" data-orig-size="470,424" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg23_05092020_04" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_04.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_04.png?w=470" src="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_04.png?w=470" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_04.png 470w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_04.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_04.png?w=300 300w" sizes="(max-width: 470px) 100vw, 470px"></figure></div>



<p>You can see M at Number 18 and 19 which is the VBA macro as explained by the author of this python script <a rel="noreferrer noopener" href="https://blog.didierstevens.com/programs/oledump-py/" target="_blank">Didier Stevens</a> M denotes VBA macros. </p>



<p>So the next command I am running</p>



<pre>&gt;&gt;oledump.py -s 18 &lt;filename&gt;</pre>



<p>In below screenshot, it can be seen, the module <strong>Lev1daeyfvl</strong> calling <strong>S_gil0c35zh248.Mei497ecvshp </strong>on Document_Open()</p>



<div><figure><img data-attachment-id="917" data-permalink="https://malwr-analysis.com/blg23_05092020_05-1/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_05-1.png" data-orig-size="617,261" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg23_05092020_05-1" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_05-1.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_05-1.png?w=617" src="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_05-1.png?w=617" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_05-1.png 617w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_05-1.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_05-1.png?w=300 300w" sizes="(max-width: 617px) 100vw, 617px"></figure></div>



<p>After looking into more, I found <strong>S_gil0c35zh248.Mei497ecvshp</strong> which is being called on opening document is an user form. (refer below screenshot)</p>



<div><figure><img data-attachment-id="921" data-permalink="https://malwr-analysis.com/blg23_05092020_02-1/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_02-1.png" data-orig-size="549,305" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg23_05092020_02-1" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_02-1.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_02-1.png?w=549" src="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_02-1.png?w=549" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_02-1.png 549w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_02-1.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_02-1.png?w=300 300w" sizes="(max-width: 549px) 100vw, 549px"><figcaption><sub><strong>S_gil0c35zh248.Mei497ecvshp</strong> is user form</sub></figcaption></figure></div>



<p>I opened word document, and navigate to VBA developer tool (Alt + F11). I saw the VBA code will execute on form execution.  </p>



<div><figure><img data-attachment-id="926" data-permalink="https://malwr-analysis.com/blg23_05092020_06-1/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_06-1.png" data-orig-size="1067,825" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg23_05092020_06-1" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_06-1.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_06-1.png?w=900" src="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_06-1.png?w=1024" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_06-1.png?w=1024 1024w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_06-1.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_06-1.png?w=300 300w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_06-1.png?w=768 768w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_06-1.png 1067w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>Next I debug the code and analyse the behavior.</p>



<p>The PowerShell script is executed by the WMI process by executing VBA code on document open. </p>



<div><figure><img data-attachment-id="931" data-permalink="https://malwr-analysis.com/blg23_05092020_07/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_07.png" data-orig-size="1601,819" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg23_05092020_07" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_07.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_07.png?w=900" src="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_07.png?w=1024" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_07.png?w=1024 1024w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_07.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_07.png?w=300 300w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_07.png?w=768 768w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_07.png 1601w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>I have extracted the PowerShell script which is encoded in base64. by adding a code to copy PowerShell script in text file. Below is the code to extract the PowerShell script. </p>



<div><figure><img data-attachment-id="933" data-permalink="https://malwr-analysis.com/blg23_05092020_11/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_11.png" data-orig-size="584,155" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg23_05092020_11" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_11.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_11.png?w=584" src="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_11.png?w=584" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_11.png 584w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_11.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_11.png?w=300 300w" sizes="(max-width: 584px) 100vw, 584px"><figcaption><sub>M2lujl629fpjn has PowerShell script</sub></figcaption></figure></div>



<div><figure><img data-attachment-id="929" data-permalink="https://malwr-analysis.com/blg23_05092020_10/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_10.png" data-orig-size="1406,455" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg23_05092020_10" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_10.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_10.png?w=900" src="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_10.png?w=1024" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_10.png?w=1024 1024w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_10.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_10.png?w=300 300w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_10.png?w=768 768w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_10.png 1406w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><sub>Encoded PowerShell Script  base64</sub></figcaption></figure></div>



<p>I have decoded the PowerShell script and got the code below. </p>



<p> To decode PowerShell script, I used below PowerShell script.  </p>



<pre><code>$path_to_b64_string_file= Get-Content -Path "C:\output\output.txt"
[System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String($path_to_b64_string_file))
New-Item "C:\output\decoded_b64.txt"
Set-Content -Path "C:\output\decoded_b64.txt" $decoded_b64_string
Write-Host "Decoded Base64 successfully"</code></pre>



<div><figure><img data-attachment-id="935" data-permalink="https://malwr-analysis.com/blg23_05092020_12/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_12.png" data-orig-size="1201,408" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg23_05092020_12" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_12.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_12.png?w=900" src="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_12.png?w=1024" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_12.png?w=1024 1024w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_12.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_12.png?w=300 300w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_12.png?w=768 768w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_12.png 1201w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><sub>Decoded PowerShell script</sub></figcaption></figure></div>



<p>I debugged the decoded PowerShell script, during the debugging, I found, it creates a folder at location and file it is going to write will be <strong>Ws1uczsw.exe</strong></p>



<pre>C:\Users\IEUser\AppData\Local\Temp\Word\2019\<strong>Ws1uczsw.exe</strong></pre>



<p>and there are multiple remote URL’s it tried to download the malicious file. </p>



<div><figure><img data-attachment-id="941" data-permalink="https://malwr-analysis.com/blg23_05092020_14/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_14.png" data-orig-size="740,221" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg23_05092020_14" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_14.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_14.png?w=740" src="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_14.png?w=740" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_14.png 740w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_14.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_14.png?w=300 300w" sizes="(max-width: 740px) 100vw, 740px"></figure></div>



<p>All URLs are active. </p>



<figure><table><tbody><tr><td>URL</td><td>VT Score</td></tr><tr><td><a href="http://rickthewelder%5B.%5Dcom/dtbkup20110205/i/" rel="nofollow">http://rickthewelder%5B.%5Dcom/dtbkup20110205/i/</a></td><td><a href="https://www.virustotal.com/gui/url/260eb051249a9f80624ce275953be1316bb1ae3d281ca4914f30ed6f9bc15573/detection" target="_blank" rel="noreferrer noopener"><span>8/79</span></a></td></tr><tr><td><a href="http://stiecgps%5B.%5Dcom%5B.%5D" rel="nofollow">http://stiecgps%5B.%5Dcom%5B.%5D</a> br/cgi-bin/7/</td><td><a href="https://www.virustotal.com/gui/url/4e45e4e106f749479e5a62d3b345c0c40e32e09763b48a7f4e1587a059439fd5/detection" target="_blank" rel="noreferrer noopener"><span>0/79</span></a></td></tr><tr><td><a href="http://tfbauru%5B.%5D" rel="nofollow">http://tfbauru%5B.%5D</a> com[.] br/cgi-bin/Lhe/</td><td><a href="https://www.virustotal.com/gui/url/2eba38015d28cb5a9c55a5f46c4eb5b55afb01ea2ce9d34953dce7b0284da3a1/detection" target="_blank" rel="noreferrer noopener"><span>14/79</span></a></td></tr><tr><td><a href="https://paulburkphotography%5B.%5D" rel="nofollow">https://paulburkphotography%5B.%5D</a> com/_new_images/F/</td><td><a href="https://www.virustotal.com/gui/url/5a0dd4fa9d876af7c517517ec57c55a7380102018c09753c13f55fff528adde2/detection" target="_blank" rel="noreferrer noopener"><span>9/79</span></a></td></tr><tr><td><a href="http://theeldestgeek%5B.%5D" rel="nofollow">http://theeldestgeek%5B.%5D</a> com/error/F5</td><td><a href="https://www.virustotal.com/gui/url/1b49d1443c62c307abe5c2feefdd0bd81d9e7d0ed5178dce3e433ccb5bb95f44/detection" target="_blank" rel="noreferrer noopener"><span>5/79</span></a></td></tr><tr><td><a href="http://uniquewv%5B.%5D" rel="nofollow">http://uniquewv%5B.%5D</a> com/cgi-bin/OVJ9qY/</td><td><a href="https://www.virustotal.com/gui/url/a674ca94937375243216193e48dbbf0983d709a2f211fc6981fdede72dcd3e71/detection" target="_blank" rel="noreferrer noopener"><span>12/79</span></a></td></tr><tr><td><a href="http://tuls%5B.%5D" rel="nofollow">http://tuls%5B.%5D</a> pl/cgi-bin/7a9</td><td><a href="https://www.virustotal.com/gui/url/12b57c3d0f24782c5380977b025affe968cc69ff13bc1af07487f3d999985e32/detection" target="_blank" rel="noreferrer noopener"><span>9/79</span></a></td></tr></tbody></table></figure>



<p>When I executed the PowerShell script, it downloaded <strong>Ww1uczsw.exe</strong> </p>



<div><figure><img data-attachment-id="947" data-permalink="https://malwr-analysis.com/blg23_05092020_16/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_16.png" data-orig-size="469,201" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg23_05092020_16" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_16.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_16.png?w=469" src="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_16.png?w=469" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_16.png 469w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_16.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/09/blg23_05092020_16.png?w=300 300w" sizes="(max-width: 469px) 100vw, 469px"></figure></div>



<p><strong>Downloaded file details: </strong></p>



<p>MD5: A4513379DAD5233AFA402CC56A8B9222</p>



<p>File Type:  Win32 Exe</p>



<p>PEid Packer: Microsoft Visual C++ v7.0</p>



<p>Family: Emotet Trojan</p>



<p><strong>Summary:</strong></p>



<ul><li>Word document has VBA macros which executes on document open.</li><li>PowerShell is encoded in base64 and executes to download Emotet Trojan executable. </li><li>Multiple sources/URLs have been used in code to download the malware on the system.</li></ul>



<p><a href="https://app.any.run/tasks/3eb564c8-2ed4-4552-94e5-7304604addb4/" target="_blank" rel="noreferrer noopener">Download Sample Link</a></p>



<p><strong>References:</strong></p>



<ul><li><a href="https://blog.didierstevens.com/">Didier Stevens</a> Tools and blogs</li><li><a rel="noreferrer noopener" href="https://blog.didierstevens.com/programs/oledump-py/" target="_blank">oledump.py</a></li></ul>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>http://malwr-analysis.com/2020/09/07/word-document-malware-analysis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398714</guid>
            <pubDate>Mon, 07 Sep 2020 11:42:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Colorizing SVG Icons with CSS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398685">thread link</a>) | @jansan
<br/>
September 7, 2020 | https://www.iconfu.com/docs/css_colorizable_svgs/examples | <a href="https://web.archive.org/web/*/https://www.iconfu.com/docs/css_colorizable_svgs/examples">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
    <div>
      
      <div id="ifu-css-colorizable-svgs-examples">
  <div>
    <div>
      <h2>Coloring Individual Icons</h2>
      <p>When displaying the same colorizable SVG multiple times, each time a different set of colors can be applied with CSS. Below, the same "hipster" SVG is displayed four times, with different colors for skin, hair, glasses and shirt. The shading is done automatically by the SVG.</p>
      <p>Each of the icons has a unique id, so a CSS id selector can be used to apply the specific colors for each icon.</p>
    </div>
    


  </div>

  <div>
    <div>
      <h2>Coloring Groups of Icons</h2>
      <p>Groups of icons can share the same color scheme, and a group of icons can be displayed multiple times with different color schemes. Below, both company info cards show the same set of colorizable SVGs. A CSS color scheme to match the
        corporate identity is applied on each side.</p>
      <p>For coloring groups of icons a CSS class selector is used. This way each icon with class <code>green-company</code> has a different color scheme than
        an icon with class <code>blue-company</code></p>
    </div>
    


  </div>

  <div>
    <div>
      <h2>Dynamic Color Changing</h2>
      <p>Colors can be changed dynamically while the icons are displayed. Click on the toggle button below to switch between light and dark mode. The color scheme of the icons will change depending on the selected mode.</p>
      <p>The gradient on the icons is defined by three color values. If the switch is toggled, the class <code>dark-mode</code> is set to the documents's body.
        This will activate a "dark-mode" CSS rule which overrides the default color with a dark mode color.</p>
    </div>
    


  </div>

  <div>
    <div>
      <h2>Mouse Interaction and Dynamic Color Changing</h2>
      <p>In this example we use a button state for changing icon colors. Move the mouse over the icons and press and click on them to trigger the color changes.</p>
      <p>The SVG is placed on a button, so we can use the buttons's pseudo class selectors (<code>:hover</code>, <code>:active</code>, and <code>:disabled</code>) to specify different colors.</p>
    </div>
    


  </div>

  <div>
    <div>
      <h2>Text Color as Icon Color</h2>
      <p>When exporting icons as CSS styleable SVGs, you can optionally set the icons' main color as the "free color". For this color the value of current CSS text color will be used.</p>
      <p>Clicking on a color swatch below will set the <code>color</code> attribute of the icons array to the background color of the color swatch. The icons will inherit the color and change accordingly.</p>
    </div>
    


  </div>
</div>
    </div>

    </div></div>]]>
            </description>
            <link>https://www.iconfu.com/docs/css_colorizable_svgs/examples</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398685</guid>
            <pubDate>Mon, 07 Sep 2020 11:37:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic Differentiation of the Black-Scholes Model]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398656">thread link</a>) | @zzbn00
<br/>
September 7, 2020 | http://www.bnikolic.co.uk/blog/quant/python/jax/2020/09/07/jaxgreeks.html | <a href="https://web.archive.org/web/*/http://www.bnikolic.co.uk/blog/quant/python/jax/2020/09/07/jaxgreeks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I’ve written already a little about automatic differentiation with Jax
to compute <a href="http://www.bnikolic.co.uk/python/2020/01/28/jax-hessian.html">the Hessian</a> and to
run Conway’s <a href="http://www.bnikolic.co.uk/python/jax/2020/04/19/game-of-life-jax.html">game of life accelerators</a> (GPUs).</p>

<p>While computing the Jacobian and Hessian matrices is often used in as
in intermediate step optimisation algorithms, they are occasionally
practically useful in their own right. One such example is the
Black-Scholes model where the Jacobian of the present value of a
derivative (the “Greeks”) is used to hedge against market
movements. Here is a little illustration of computing the Greeks very
easily using Jax.</p>

<p>I’m also using Sam Schoenholz’s
<a href="https://twitter.com/sschoenholz/status/1297933277735469057">jax2tex</a>
(code at
<a href="https://github.com/google-research/google-research/tree/master/jax2tex">https://github.com/google-research/google-research/tree/master/jax2tex</a>
) to display the results in symbolic form.</p>



<p>The starting point is the analytic Black-Scholes model <a href="#black1973pricing">(Black &amp; Scholes, 1973)</a>. I’ve expressed it in terms of the Black 1976
formula <a href="#black1976pricing">(Black, 1976)</a>.</p>

<div><div><pre><code><span>import</span> <span>jax.scipy</span>
<span>from</span> <span>jax.scipy</span> <span>import</span> <span>special</span> <span>as</span> <span>Sfn</span>
<span>from</span> <span>jax</span> <span>import</span> <span>numpy</span>

<span>def</span> <span>Phi</span><span>(</span><span>z</span><span>):</span>
    <span>return</span> <span>(</span><span>1</span><span>+</span> <span>Sfn</span><span>.</span><span>erf</span><span>(</span><span>z</span><span>/</span><span>jax</span><span>.</span><span>numpy</span><span>.</span><span>sqrt</span><span>(</span><span>2.</span><span>)))</span><span>/</span><span>2</span>

<span>def</span> <span>Black76</span><span>(</span><span>cp</span><span>,</span> <span>F</span><span>,</span> <span>K</span><span>,</span> <span>r</span><span>,</span> <span>sigma</span><span>,</span> <span>T</span><span>):</span>
    <span>d1</span><span>=</span><span>(</span><span>numpy</span><span>.</span><span>log</span><span>(</span><span>F</span><span>/</span><span>K</span><span>)</span> <span>+</span> <span>(</span><span>sigma</span><span>**</span><span>2</span><span>)</span><span>/</span><span>2</span><span>*</span><span>T</span><span>)</span><span>/</span> <span>(</span><span>sigma</span><span>*</span><span>numpy</span><span>.</span><span>sqrt</span><span>(</span><span>T</span><span>))</span>
    <span>d2</span><span>=</span><span>d1</span><span>-</span><span>sigma</span><span>*</span><span>numpy</span><span>.</span><span>sqrt</span><span>(</span><span>T</span><span>)</span>
    <span>if</span> <span>cp</span><span>==</span><span>"C"</span><span>:</span>
        <span>return</span> <span>numpy</span><span>.</span><span>exp</span><span>(</span><span>-</span><span>r</span><span>*</span><span>T</span><span>)</span><span>*</span><span>(</span><span>F</span><span>*</span><span>Phi</span><span>(</span><span>d1</span><span>)</span> <span>-</span> <span>K</span><span>*</span><span>Phi</span><span>(</span><span>d2</span><span>))</span>
    <span>else</span><span>:</span>
        <span>return</span> <span>numpy</span><span>.</span><span>exp</span><span>(</span><span>-</span><span>r</span><span>*</span><span>T</span><span>)</span><span>*</span><span>(</span><span>K</span><span>*</span><span>Phi</span><span>(</span><span>-</span><span>d2</span><span>)</span> <span>-</span> <span>F</span><span>*</span><span>Phi</span><span>(</span><span>-</span><span>d1</span><span>))</span>

<span>def</span> <span>BlackScholes</span><span>(</span><span>cp</span><span>,</span> <span>S</span><span>,</span> <span>K</span><span>,</span> <span>r</span><span>,</span> <span>sigma</span><span>,</span> <span>T</span><span>):</span>
    <span>F</span><span>=</span><span>numpy</span><span>.</span><span>exp</span><span>(</span><span>r</span><span>*</span><span>T</span><span>)</span><span>*</span><span>S</span>
    <span>return</span> <span>Black76</span><span>(</span><span>cp</span><span>,</span> <span>F</span><span>,</span> <span>K</span><span>,</span> <span>r</span><span>,</span> <span>sigma</span><span>,</span> <span>T</span><span>)</span>

</code></pre></div></div>

<p>Note the call/put switch is the first parameter so that the call and
put versions are easily generated by partial application:</p>

<div><div><pre><code><span>from</span> <span>functools</span> <span>import</span> <span>partial</span>

<span>def</span> <span>mkCallPut</span><span>(</span><span>f</span><span>):</span>
    <span>c</span><span>=</span><span>partial</span><span>(</span><span>f</span><span>,</span> <span>"C"</span><span>)</span>
    <span>c</span><span>.</span><span>__name__</span><span>=</span><span>f</span><span>.</span><span>__name__</span><span>+</span><span>"Call"</span>
    <span>p</span><span>=</span><span>partial</span><span>(</span><span>f</span><span>,</span> <span>"P"</span><span>)</span>
    <span>p</span><span>.</span><span>__name__</span><span>=</span><span>f</span><span>.</span><span>__name__</span><span>+</span><span>"Putt"</span>
    <span>return</span> <span>c</span><span>,</span><span>p</span>

<span>BlackScholesCall</span><span>,</span> <span>BlackScholesPut</span><span>=</span><span>mkCallPut</span><span>(</span><span>BlackScholes</span><span>)</span>

</code></pre></div></div>

<p>The model can now be directly evaluated:</p>

<div><div><pre><code><span>BlackScholesCall</span><span>(</span> <span>100</span><span>,</span> <span>100</span><span>,</span> <span>0.01</span><span>,</span> <span>0.05</span><span>,</span> <span>1</span><span>)</span>
</code></pre></div></div>
<p>returns a value of around 2.52.</p>

<p>With a bit of extension of jax2tex we can also print the symbolic
version of the model:</p>

<div><div><pre><code>
<span>jax2tex</span><span>.</span><span>op2tex</span><span>[</span><span>jax</span><span>.</span><span>lax</span><span>.</span><span>erf_p</span><span>]</span> <span>=</span> <span>lambda</span> <span>x</span><span>:</span> <span>f</span><span>"</span><span>\\</span><span>mathrm{ {Erf}}</span><span>\\</span><span>left[{x}</span><span>\\</span><span>right]"</span>
<span>jax2tex</span><span>.</span><span>op2ind</span><span>[</span><span>jax</span><span>.</span><span>lax</span><span>.</span><span>erf_p</span><span>]</span> <span>=</span> <span>jax2tex</span><span>.</span><span>noop2ind</span>

<span>jax2tex</span><span>.</span><span>jax2tex</span><span>(</span><span>BlackScholesCall</span><span>,</span> <span>100</span><span>,</span> <span>100</span><span>,</span> <span>0.01</span><span>,</span> <span>0.05</span><span>,</span> <span>1</span><span>)</span>

</code></pre></div></div>

<p>We get the following:</p>





<p>With Jax’s automatic differentiation using the <code>grad</code> function we
can obtain the greeks trivially:</p>

<div><div><pre><code><span>Delta</span><span>,</span> <span>Rho</span><span>,</span> <span>Vega</span><span>,</span> <span>mTheta</span> <span>=</span> <span>[</span><span>grad</span><span>(</span><span>BlackScholesCall</span><span>,</span> <span>argnums</span><span>=</span><span>x</span><span>)</span> <span>for</span> <span>x</span> <span>in</span> <span>[</span><span>0</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>]</span> <span>]</span>
</code></pre></div></div>
<p>(NB. Theta is negative of the conventional form hence the “m” prefix).
For example we can evaluate delta simply as:</p>

<div><div><pre><code><span>Delta</span><span>(</span> <span>100.</span><span>,</span> <span>100.</span><span>,</span> <span>0.01</span><span>,</span> <span>0.05</span><span>,</span> <span>1.</span><span>)</span>
</code></pre></div></div>

<p>Very easy and much reduced possibility for user-introduced errors!</p>

<p>It is possible to also display the symbolic form of the Greeks. It
should be noted these are computed using the reverse-mode
differentiation and will not necessarily have the simplest analytic
form, but can still be useful for spotting potential issues:</p>









<p>Automatic differentiation much reduces the coding (and analysis)
requirement when derivatives are needed. This is true both when they
are used for optimisation but also in their own right. Jax makes
automatic differentiation as easy as a single function call on a
Numpy-like function.</p>

<p>The other major advantage of Jax is  acceleration – more on that in a
forthcoming post!</p>



<ol><li><span id="black1973pricing">Black, F., &amp; Scholes, M. (1973). The pricing of options and corporate liabilities. <i>Journal of Political Economy</i>, <i>81</i>(3), 637–654.</span></li>
<li><span id="black1976pricing">Black, F. (1976). The pricing of commodity contracts. <i>Journal of Financial Economics</i>, <i>3</i>(1-2), 167–179.</span></li></ol>

  </div>


  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>http://www.bnikolic.co.uk/blog/quant/python/jax/2020/09/07/jaxgreeks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398656</guid>
            <pubDate>Mon, 07 Sep 2020 11:30:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Think Real Hard]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24398649">thread link</a>) | @codesuki
<br/>
September 7, 2020 | https://www.benkuhn.net/thinkrealhard/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/thinkrealhard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Famous physicist Murray Gell-Mann is supposed to have <a href="http://wiki.c2.com/?FeynmanAlgorithm" target="_blank">suggested</a> that Richard Feynman solved problems with the following cutting edge technique:</p><blockquote><ol><li>Write down the problem.</li><li>Think real hard.</li><li>Write down the solution.</li></ol></blockquote><p>Usually when people quote this, it’s to make a joke about how smart Feynman was. (If I tried this, I wouldn’t come up with quantum electrodynamics! I must not be able to think hard enough.) That’s one reading, but I prefer a different one.</p><p>When I started programming professionally, I was really excited about figuring out how to become a better programmer. (I still am!) So I asked a lot of people, “how can I become a better programmer?” But nobody gave me very satisfactory answers. They would tell me to play around with obscure programming languages, or study algorithms, or read papers, or do a bunch of other stuff that felt tangential and didn’t really move the needle.</p><p>In retrospect, I wish those people had just told me “think real hard.” I was looking for an easy way out—One Weird Trick to Programming Better—but programming is too hard for that.</p><p>That’s my preferred reading of the Feynman Algorithm: there is no one weird trick.</p><p>On the other hand, I <em>have</em> gotten a ton better at programming in the last four years. Not through any specific piece of advice, or any weird trick. Rather, it’s come by constantly trying to learn small new things, make small tool improvements, make my models a little deeper, work a little faster, come up with slightly better ideas. By, literally, thinking real hard, for a long, long time. The Feynman Algorithm works!</p><p>(That’s not to say good advice is impossible. I’m sure if <a href="http://www.informatika.bg/jeffdean" target="_blank">Jeff Dean</a> watched me go through my programming day, he would have tons of great tactical tips that would help me a lot. But even that depends on Jeff Dean being able to know which of his 10,000 tactical tips would be most useful to me. And the real difference between us isn’t the tactical tips, it’s the underlying models that generate the tips in the first place. Those seem to be nearly impossible to communicate.)</p><p>A lot of the things people ask for advice on fall into this category. “How can I be happier?” “How can I be more productive?” “How can I have a bigger impact on the world?” Sure, there are basic life hacks like sleeping well or getting exercise. But 99% of the “secret”—the thing that separates me from Gell-Mann, or Jeff Dean—is tacit knowledge. It often can’t be articulated any better than “think real hard.” But, believe it or not, thinking real hard, for real long, <em>does</em> work.</p></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/thinkrealhard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398649</guid>
            <pubDate>Mon, 07 Sep 2020 11:30:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On All That Fuckery]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24398645">thread link</a>) | @MarcScott
<br/>
September 7, 2020 | https://www.katfukui.com/on-all-that-fuckery | <a href="https://web.archive.org/web/*/https://www.katfukui.com/on-all-that-fuckery">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><undefined><span role="img" aria-label="warning">⚠️</span> </undefined><em>CW: racist, sexist, transphobic, hateful language and online abuse</em></p><p><span>
      <a href="https://www.katfukui.com/static/78121b0fe29ffe99a14ba6f375152534/b54cd/screenshot-fuckery.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="&quot;you faggots are just giving her the material for her next talk on sexism/hate threats and all that fuckery.&quot;" title="&quot;you faggots are just giving her the material for her next talk on sexism/hate threats and all that fuckery.&quot;" src="https://www.katfukui.com/static/78121b0fe29ffe99a14ba6f375152534/e5715/screenshot-fuckery.png" srcset="https://www.katfukui.com/static/78121b0fe29ffe99a14ba6f375152534/8514f/screenshot-fuckery.png 192w,https://www.katfukui.com/static/78121b0fe29ffe99a14ba6f375152534/804b2/screenshot-fuckery.png 384w,https://www.katfukui.com/static/78121b0fe29ffe99a14ba6f375152534/e5715/screenshot-fuckery.png 768w,https://www.katfukui.com/static/78121b0fe29ffe99a14ba6f375152534/4ad3a/screenshot-fuckery.png 1152w,https://www.katfukui.com/static/78121b0fe29ffe99a14ba6f375152534/71c1d/screenshot-fuckery.png 1536w,https://www.katfukui.com/static/78121b0fe29ffe99a14ba6f375152534/b54cd/screenshot-fuckery.png 1662w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>From July 14 to August 17, 2020 (at time of publish), I experienced targeted harassment on GitHub—the company I'm employed at—via coordination happening on several "technology" 4chan threads about me. I wanted to share this story publicly to reiterate the bullshit marginalized folks in tech have to go through in order to be successful, visible, and just <em>exist</em>.</p><p>So as the dude in the screenshot says, I have plenty of material to write a post on <em>all that fuckery</em>.</p><p><span role="img" aria-label="wavy dash">〰️</span></p><p>The first round of trolling occurred in issues and PRs on <a href="https://github.com/katmeister/tokyo-2019">one of my repositories</a> that documents the food I ate with my friends on our spring Tokyo 2019 trip. It was only slightly concerning at first, until I realized that 40+ people were posting, commenting, and emoji reacting.</p><p><span>
      <a href="https://www.katfukui.com/static/b4fa0c9a46ca93a988fba3001fb34071/917ef/gh-screenshots.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="screenshots from GitHub" title="screenshots from GitHub" src="https://www.katfukui.com/static/b4fa0c9a46ca93a988fba3001fb34071/e5715/gh-screenshots.png" srcset="https://www.katfukui.com/static/b4fa0c9a46ca93a988fba3001fb34071/8514f/gh-screenshots.png 192w,https://www.katfukui.com/static/b4fa0c9a46ca93a988fba3001fb34071/804b2/gh-screenshots.png 384w,https://www.katfukui.com/static/b4fa0c9a46ca93a988fba3001fb34071/e5715/gh-screenshots.png 768w,https://www.katfukui.com/static/b4fa0c9a46ca93a988fba3001fb34071/4ad3a/gh-screenshots.png 1152w,https://www.katfukui.com/static/b4fa0c9a46ca93a988fba3001fb34071/71c1d/gh-screenshots.png 1536w,https://www.katfukui.com/static/b4fa0c9a46ca93a988fba3001fb34071/917ef/gh-screenshots.png 2095w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p><undefined>Here are a few examples. The most irritating ones used tech jargon ("fixing bloat") to mask their pathetic actions. As a bystander, you might not realize until viewing the proposed changes... and seeing all content deleted. This is also the most irritating because there is no obviously hateful or violent content, and can be written off as "just a joke." <span role="img" aria-label="face with rolling eyes">🙄</span></undefined></p><p>This is a specific type of trolling I was experiencing, called "dogpiling":</p><blockquote><p>Dogpiling: When a group of trolls works together to overwhelm a target through a barrage of disingenuous questions, threats, slurs, insults, and other tactics meant to shame, silence, discredit, or drive a target offline. — <a href="https://onlineharassmentfieldmanual.pen.org/defining-online-harassment-a-glossary-of-terms/">PEN America</a></p></blockquote><p>This is not a new tactic used to silence, but it was the first time I've personally experienced it. Good thing I designed a lot of our moderation tools and have talked about the <a href="https://youtu.be/5CSQYMOWOtQ?t=580">taxonomy of online abuse</a> before, and recognized this type of harassment quickly. I was able to get help from amazing coworkers, <a href="https://twitter.com/cheshire137">Sarah Vessels</a> and <a href="https://twitter.com/deniseyu21">Denise Yu</a>, to query my repo's referral data. The traffic was coming from 4chan... two 4chan threads totaling nearly 500 disturbing comments.</p><p>Seeing this shit was absolutely surreal. The GitHub content was annoying, but this made me feel sick. I still remember the feeling of being so overwhelmed and just sobbing at my desk. Reading disgusting, racist, sexist comments about me. Seeing screenshots of my face plastered across the threads. Understanding the exact moment where the dogpiling was coordinated. Realizing this was likely to keep happening (and it did).</p><p>And what still really creeps me out is that these people felt so emboldened to troll an EMPLOYEE using their actual GitHub accounts with legitimate work and contributions. <u>These harassers are everyday software engineers.</u></p><p>I'm not famous and I don't have a very large platform, so why me?</p><p>Upon reading the threads, there were some pretty clear reasons why this happened to me. I'll dig deeply into each one. <em>HUGE shoutout to my kat-ops counterpart <a href="https://twitter.com/pifafu">Kathy Zheng</a> for helping me compile screenshots!</em></p><h2>I'm a woman.</h2><p><undefined>Well, this was the most obvious reason. Women disproportionately experience online harassment, and very much so for sexual harassment. I included a few snippets but won't spend too much time on this one because it was some boring, basic bitch shit that we've all seen before <span role="img" aria-label="">🤷🏻‍♀️</span></undefined></p><p><span>
      <a href="https://www.katfukui.com/static/8c70cf424f0092c01e2bab74df31a7a1/4f046/screenshots-incels.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="sexist comments" title="sexist comments" src="https://www.katfukui.com/static/8c70cf424f0092c01e2bab74df31a7a1/e5715/screenshots-incels.png" srcset="https://www.katfukui.com/static/8c70cf424f0092c01e2bab74df31a7a1/8514f/screenshots-incels.png 192w,https://www.katfukui.com/static/8c70cf424f0092c01e2bab74df31a7a1/804b2/screenshots-incels.png 384w,https://www.katfukui.com/static/8c70cf424f0092c01e2bab74df31a7a1/e5715/screenshots-incels.png 768w,https://www.katfukui.com/static/8c70cf424f0092c01e2bab74df31a7a1/4ad3a/screenshots-incels.png 1152w,https://www.katfukui.com/static/8c70cf424f0092c01e2bab74df31a7a1/71c1d/screenshots-incels.png 1536w,https://www.katfukui.com/static/8c70cf424f0092c01e2bab74df31a7a1/4f046/screenshots-incels.png 3311w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><h2>I'm an Asian woman.</h2><p>I mean, I shouldn't have been surprised at this one, but here we are. I have a lot of privilege as an Asian American, but was quickly reminded how easy I can be reduced to stereotypes and slurs. And that the gross fetishization of Asian women still makes me a target:</p><p><span>
      <a href="https://www.katfukui.com/static/fb87155ab684bb443d4d7e156d69f4fe/91945/screenshots-asian-slurs.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="asian slurs" title="asian slurs" src="https://www.katfukui.com/static/fb87155ab684bb443d4d7e156d69f4fe/e5715/screenshots-asian-slurs.png" srcset="https://www.katfukui.com/static/fb87155ab684bb443d4d7e156d69f4fe/8514f/screenshots-asian-slurs.png 192w,https://www.katfukui.com/static/fb87155ab684bb443d4d7e156d69f4fe/804b2/screenshots-asian-slurs.png 384w,https://www.katfukui.com/static/fb87155ab684bb443d4d7e156d69f4fe/e5715/screenshots-asian-slurs.png 768w,https://www.katfukui.com/static/fb87155ab684bb443d4d7e156d69f4fe/4ad3a/screenshots-asian-slurs.png 1152w,https://www.katfukui.com/static/fb87155ab684bb443d4d7e156d69f4fe/71c1d/screenshots-asian-slurs.png 1536w,https://www.katfukui.com/static/fb87155ab684bb443d4d7e156d69f4fe/91945/screenshots-asian-slurs.png 2944w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>There was one in particular I wanted to highlight:</p><p><span>
      <a href="https://www.katfukui.com/static/b7462864208b987ab4889dcf7a278076/07a9c/screenshots-asian-slurs2.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="So half-human?" title="So half-human?" src="https://www.katfukui.com/static/b7462864208b987ab4889dcf7a278076/e5715/screenshots-asian-slurs2.png" srcset="https://www.katfukui.com/static/b7462864208b987ab4889dcf7a278076/8514f/screenshots-asian-slurs2.png 192w,https://www.katfukui.com/static/b7462864208b987ab4889dcf7a278076/804b2/screenshots-asian-slurs2.png 384w,https://www.katfukui.com/static/b7462864208b987ab4889dcf7a278076/e5715/screenshots-asian-slurs2.png 768w,https://www.katfukui.com/static/b7462864208b987ab4889dcf7a278076/4ad3a/screenshots-asian-slurs2.png 1152w,https://www.katfukui.com/static/b7462864208b987ab4889dcf7a278076/07a9c/screenshots-asian-slurs2.png 1440w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>This one in particular stood out to me because it's a very specific type of harassment I've received my whole life, usually from East Asians. This piece of trash is stating that I'm subhuman because of my Vietnamese heritage. Tbh, this hits harder than boring 'ol "chink." The colorism here makes me think this was an Asian dude. And speaking of which:  </p><p><span>
      <a href="https://www.katfukui.com/static/3eee0f75ebc7aeae694e1262392cf0a7/71c1d/screenshots-mrasian.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="asian slurs" title="asian slurs" src="https://www.katfukui.com/static/3eee0f75ebc7aeae694e1262392cf0a7/e5715/screenshots-mrasian.png" srcset="https://www.katfukui.com/static/3eee0f75ebc7aeae694e1262392cf0a7/8514f/screenshots-mrasian.png 192w,https://www.katfukui.com/static/3eee0f75ebc7aeae694e1262392cf0a7/804b2/screenshots-mrasian.png 384w,https://www.katfukui.com/static/3eee0f75ebc7aeae694e1262392cf0a7/e5715/screenshots-mrasian.png 768w,https://www.katfukui.com/static/3eee0f75ebc7aeae694e1262392cf0a7/4ad3a/screenshots-mrasian.png 1152w,https://www.katfukui.com/static/3eee0f75ebc7aeae694e1262392cf0a7/71c1d/screenshots-mrasian.png 1536w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>I also received an email from what appears to be an MRAsian... It's sadly not uncommon to see Asian men upholding white supremacy and targeting Asian women for living our damn lives.</p><h2>I have a "radical" profile README.</h2><p>My GitHub <a href="http://github.com/katmeister">profile README</a> includes my pronouns, support for #BlackLivesMatter, my values, and social links. The amount of transphobic and anti-Black racist comments because of this was sickening. Attacking allyship is yet another tactic to silence and isolate us.</p><p><span>
      <a href="https://www.katfukui.com/static/a7ab50905868d6c10c38a7153e01cfbe/16bd1/screenshots-readme.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="attacks on my GitHub personal README" title="attacks on my GitHub personal README" src="https://www.katfukui.com/static/a7ab50905868d6c10c38a7153e01cfbe/e5715/screenshots-readme.png" srcset="https://www.katfukui.com/static/a7ab50905868d6c10c38a7153e01cfbe/8514f/screenshots-readme.png 192w,https://www.katfukui.com/static/a7ab50905868d6c10c38a7153e01cfbe/804b2/screenshots-readme.png 384w,https://www.katfukui.com/static/a7ab50905868d6c10c38a7153e01cfbe/e5715/screenshots-readme.png 768w,https://www.katfukui.com/static/a7ab50905868d6c10c38a7153e01cfbe/4ad3a/screenshots-readme.png 1152w,https://www.katfukui.com/static/a7ab50905868d6c10c38a7153e01cfbe/71c1d/screenshots-readme.png 1536w,https://www.katfukui.com/static/a7ab50905868d6c10c38a7153e01cfbe/16bd1/screenshots-readme.png 2922w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><h2>I'm not a "real developer"</h2><p>Yikes, there were a <em>lot</em><undefined> of comments about this. The dismissal of my skills and claiming I can only write Markdown is an intentional tactic to tear down my value and diminish my success. Very funny, as I've been writing code to production since 2016, despite not being a skilled developer. <span role="img" aria-label="">🤷🏻‍♀️</span></undefined></p><p><span>
      <a href="https://www.katfukui.com/static/4aaf585e0e3766626332768d1b1cd811/60708/screenshots-not-developer.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="not a real developer" title="not a real developer" src="https://www.katfukui.com/static/4aaf585e0e3766626332768d1b1cd811/e5715/screenshots-not-developer.png" srcset="https://www.katfukui.com/static/4aaf585e0e3766626332768d1b1cd811/8514f/screenshots-not-developer.png 192w,https://www.katfukui.com/static/4aaf585e0e3766626332768d1b1cd811/804b2/screenshots-not-developer.png 384w,https://www.katfukui.com/static/4aaf585e0e3766626332768d1b1cd811/e5715/screenshots-not-developer.png 768w,https://www.katfukui.com/static/4aaf585e0e3766626332768d1b1cd811/4ad3a/screenshots-not-developer.png 1152w,https://www.katfukui.com/static/4aaf585e0e3766626332768d1b1cd811/71c1d/screenshots-not-developer.png 1536w,https://www.katfukui.com/static/4aaf585e0e3766626332768d1b1cd811/60708/screenshots-not-developer.png 2872w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>Also, I think this comment deserves a blockquote:</p><blockquote><p>women unironically think that's all there is to development - forking, pushing some spelling changes, etc</p><p>they literally have no concept of how involved any of it is</p><p>isn't it hilarious that these useless parasites are consuming at least 50% of employer resources? all the while shitting on actually productive geeks for political brownie points?   </p></blockquote><p><undefined>Just... let that one sit. <span role="img" aria-label="nauseated face">🤢</span></undefined></p><h2>I'm ruining GitHub as an employee...</h2><p>There's a recurring narrative that I'm just a diversity hire who is ruining the coding sanctity of GitHub. I don't deserve to work at this company because I do nothing, while the engineers in this thread sit in their "1 room apartments." Damn, it's not my fault you aren't talented or successful. It also appears some watched my talks—thanks for the views.</p><p><span>
      <a href="https://www.katfukui.com/static/23790c8be2d72cba09953ecb50c03cfc/40493/screenshots-ruining-gh.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="I'm ruining GitHub as an employee" title="I'm ruining GitHub as an employee" src="https://www.katfukui.com/static/23790c8be2d72cba09953ecb50c03cfc/e5715/screenshots-ruining-gh.png" srcset="https://www.katfukui.com/static/23790c8be2d72cba09953ecb50c03cfc/8514f/screenshots-ruining-gh.png 192w,https://www.katfukui.com/static/23790c8be2d72cba09953ecb50c03cfc/804b2/screenshots-ruining-gh.png 384w,https://www.katfukui.com/static/23790c8be2d72cba09953ecb50c03cfc/e5715/screenshots-ruining-gh.png 768w,https://www.katfukui.com/static/23790c8be2d72cba09953ecb50c03cfc/4ad3a/screenshots-ruining-gh.png 1152w,https://www.katfukui.com/static/23790c8be2d72cba09953ecb50c03cfc/71c1d/screenshots-ruining-gh.png 1536w,https://www.katfukui.com/static/23790c8be2d72cba09953ecb50c03cfc/40493/screenshots-ruining-gh.png 2955w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>I'd like to point out that the idea of avoiding "diversity hires" as to not lower the bar of quality is still a prevalent sentiment within tech. Again, these are not just nameless 4chan trolls—they're people in our industry.</p><h2>... and should be punished.</h2><p>Yeah, these are gross. Apparently I should get fired and deserve the harassment because I'm an attention seeking whore on a programming platform! The platform I work on and create more value to developers than you ever will in your life!!</p><p><span>
      <a href="https://www.katfukui.com/static/e7904e47d6c1e3ff58827b2096c64f78/50e7d/screenshots-ugh.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="I should get no sympathy for abuse, should be fired, should kill myself" title="I should get no sympathy for abuse, should be fired, should kill myself" src="https://www.katfukui.com/static/e7904e47d6c1e3ff58827b2096c64f78/e5715/screenshots-ugh.png" srcset="https://www.katfukui.com/static/e7904e47d6c1e3ff58827b2096c64f78/8514f/screenshots-ugh.png 192w,https://www.katfukui.com/static/e7904e47d6c1e3ff58827b2096c64f78/804b2/screenshots-ugh.png 384w,https://www.katfukui.com/static/e7904e47d6c1e3ff58827b2096c64f78/e5715/screenshots-ugh.png 768w,https://www.katfukui.com/static/e7904e47d6c1e3ff58827b2096c64f78/4ad3a/screenshots-ugh.png 1152w,https://www.katfukui.com/static/e7904e47d6c1e3ff58827b2096c64f78/71c1d/screenshots-ugh.png 1536w,https://www.katfukui.com/static/e7904e47d6c1e3ff58827b2096c64f78/50e7d/screenshots-ugh.png 1738w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>That wasn't every screenshot from the threads, but is a good summary. The sheer volume of comments was definitely one of the more overwhelming aspects of this fuckery. Thanks for reading along this far.</p><h2>So if it wasn't clear:</h2><p><undefined>I was targeted by racist techies because of my background and visibility in order to be silenced and driven out of this industry. <span role="img" aria-label="middle finger">🖕</span></undefined></p><p>It was particularly cruel to harass me on the platform I work on everyday, where I design for open source communities. I couldn't focus at work and ended up taking two weeks off. This experience has really impacted the way I view tech and my place in it—but I'll save that for another post. </p><p>I've already accepted that this won't be my last brush with online harassment, so long as I'm still a visible Asian woman in tech. And this is going to continue happening to me and less privileged tech workers for just existing and being successful. All we can do is protect and support each other, because it's not our job to fix this problem.</p><p>It's your move next, tech. Here are my suggestions, you can have them for free:  </p><h2>To the most privileged tech leaders:</h2><p>When these events happen to your employees, are you investing actual money to support them? Are you monitoring content, encouraging time off, creating company policies, and covering their therapy? In lucky cases like mine, where the bulk of harassment may happen on the platform the victim works on, are you actively fixing pain points your employee experienced? Make sure you have a policy and detailed playbook, and definitely don't expect your marginalized employees to fix these problems for you. Don't wait until an incident arises—<strong>it's always an "edge case" until someone's personal safety is threatened.</strong></p><p>By not having intentional protections for the most vulnerable in place, you're preventing employees from being productive at work (because they're dealing with bullshit!). And you're absolutely driving away diverse talent from joining your company. It's actually fucking up your business. Access and representation in tech isn't a pipeline or qualification problem. <strong>It's a white supremacy problem.</strong></p><blockquote><p>And what still really creeps me out is that these people felt so emboldened to troll an EMPLOYEE using their actual GitHub accounts with legitimate work and contributions. <u>These harassers are everyday software engineers.</u></p></blockquote><p>Lastly, I want to circle back to this point about users with legitimate coding work harassing me. It's easy to dismiss these trolls as incel 4channers that we shun and don't associate with. Lol no. These are your people. They work at your companies and write your code. They are harassing or doxxing your other employees. This toxic behavior is still very much a part of your tech culture, and you keep rewarding it.</p><p>Fix. This. Shit.</p></article></div>]]>
            </description>
            <link>https://www.katfukui.com/on-all-that-fuckery</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398645</guid>
            <pubDate>Mon, 07 Sep 2020 11:29:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Steps to Develop Global State for React with Hooks Without Context]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398532">thread link</a>) | @mehdios
<br/>
September 7, 2020 | https://blog.asayer.io/steps-to-develop-global-state-for-react-with-hooks-without-context | <a href="https://web.archive.org/web/*/https://blog.asayer.io/steps-to-develop-global-state-for-react-with-hooks-without-context">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><h2 id="introduction">Introduction</h2><p>Developing with React hooks is fun for me. I have been developing several libraries. The very first library was a library for global state. It’s naively called “react-hooks-global-state” which turns out to be too long to read.</p><p>The initial version of the library was published in Oct 2018. Time has passed since then, I learned a lot, and now v1.0.0 of the library is published (<a href="https://github.com/dai-shi/react-hooks-global-state" target="_blank" rel="noreferrer">react-hooks-global-state</a>).</p><p>This post shows simplified versions of the code step by step. It would help understand what this library is aiming at, while the real code is a bit complex in TypeScript.</p><h2 id="step-1-global-variable">Step 1: Global variable</h2><div><pre><p><span>1</span><span>let</span><span> globalState </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  count</span><span>:</span><span> </span><span>0</span><span>,</span><span></span></p><p><span>3</span><span>  text</span><span>:</span><span> </span><span>'hello'</span><span>,</span><span></span></p><p><span>4</span><span></span><span>}</span><span>;</span></p></pre></div><p>Let’s have a global variable like the above. We assume this structure throughout this post. One would create a React hook to read this global variable.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>useGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>return</span><span> globalState</span><span>;</span><span></span></p><p><span>3</span><span></span><span>}</span><span>;</span></p></pre></div><p>This is not actually a React hook because it doesn’t depend on any React primitive hooks.</p><p>Now, this is not what we usually want, because it doesn’t re-render when the global variable changes.</p><h2 id="step-2-re-render-on-updates">Step 2: Re-render on updates</h2><p>We need to use React <code>useState</code> hook to make it reactive.</p><div><pre><p><span>1</span><span>const</span><span> listeners </span><span>=</span><span> </span><span>new</span><span> </span><span>Set</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>const</span><span> </span><span>useGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>  </span><span>const</span><span> </span><span>[</span><span>state</span><span>,</span><span> setState</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>globalState</span><span>)</span><span>;</span><span></span></p><p><span>5</span><span>  </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>6</span><span>    </span><span>const</span><span> </span><span>listener</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>7</span><span>      </span><span>setState</span><span>(</span><span>globalState</span><span>)</span><span>;</span><span></span></p><p><span>8</span><span>    </span><span>}</span><span>;</span><span></span></p><p><span>9</span><span>    listeners</span><span>.</span><span>add</span><span>(</span><span>listener</span><span>)</span><span>;</span><span></span></p><p><span>10</span><span>    </span><span>listener</span><span>(</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>11</span><span>    </span><span>return</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> listeners</span><span>.</span><span>delete</span><span>(</span><span>listener</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>12</span><span>  </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>13</span><span>  </span><span>return</span><span> state</span><span>;</span><span></span></p><p><span>14</span><span></span><span>}</span><span>;</span></p></pre></div><p>This allows to update React state from outside. If you update the global variable, you need to notify listeners. Let’s create a function for updating.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>setGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>nextGlobalState</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  globalState </span><span>=</span><span> nextGlobalState</span><span>;</span><span></span></p><p><span>3</span><span>  listeners</span><span>.</span><span>forEach</span><span>(</span><span>listener</span><span> </span><span>=&gt;</span><span> </span><span>listener</span><span>(</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span></span><span>}</span><span>;</span></p></pre></div><p>With this, we can change <code>useGlobalState</code> to return a tuple like <code>useState</code>.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>useGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>const</span><span> </span><span>[</span><span>state</span><span>,</span><span> setState</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>globalState</span><span>)</span><span>;</span><span></span></p><p><span>3</span><span>  </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>    </span><span></span></p><p><span>5</span><span>  </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>6</span><span>  </span><span>return</span><span> </span><span>[</span><span>state</span><span>,</span><span> setGlobalState</span><span>]</span><span>;</span><span></span></p><p><span>7</span><span></span><span>}</span><span>;</span></p></pre></div><h2 id="step-3-container">Step 3: Container</h2><p>Usually, the global variable is in a file scope. Let’s put it in a function scope to narrow down the scope a bit and make it more reusable.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>createContainer</span><span> </span><span>=</span><span> </span><span>(</span><span>initialState</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>let</span><span> globalState </span><span>=</span><span> initialState</span><span>;</span><span></span></p><p><span>3</span><span>  </span><span>const</span><span> listeners </span><span>=</span><span> </span><span>new</span><span> </span><span>Set</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span></span></p><p><span>5</span><span>  </span><span>const</span><span> </span><span>setGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>nextGlobalState</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>6</span><span>    globalState </span><span>=</span><span> nextGlobalState</span><span>;</span><span></span></p><p><span>7</span><span>    listeners</span><span>.</span><span>forEach</span><span>(</span><span>listener</span><span> </span><span>=&gt;</span><span> </span><span>listener</span><span>(</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>8</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>9</span><span></span></p><p><span>10</span><span>  </span><span>const</span><span> </span><span>useGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>11</span><span>    </span><span>const</span><span> </span><span>[</span><span>state</span><span>,</span><span> setState</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>globalState</span><span>)</span><span>;</span><span></span></p><p><span>12</span><span>    </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>      </span><span>const</span><span> </span><span>listener</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>14</span><span>        </span><span>setState</span><span>(</span><span>globalState</span><span>)</span><span>;</span><span></span></p><p><span>15</span><span>      </span><span>}</span><span>;</span><span></span></p><p><span>16</span><span>      listeners</span><span>.</span><span>add</span><span>(</span><span>listener</span><span>)</span><span>;</span><span></span></p><p><span>17</span><span>      </span><span>listener</span><span>(</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>18</span><span>      </span><span>return</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> listeners</span><span>.</span><span>delete</span><span>(</span><span>listener</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>19</span><span>    </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>20</span><span>    </span><span>return</span><span> </span><span>[</span><span>state</span><span>,</span><span> setGlobalState</span><span>]</span><span>;</span><span></span></p><p><span>21</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>22</span><span></span></p><p><span>23</span><span>  </span><span>return</span><span> </span><span>{</span><span></span></p><p><span>24</span><span>    setGlobalState</span><span>,</span><span></span></p><p><span>25</span><span>    useGlobalState</span><span>,</span><span></span></p><p><span>26</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>27</span><span></span><span>}</span><span>;</span></p></pre></div><p>We don’t go in detail about TypeScript in this post, but this form allows to annotate types of <code>useGlobalState</code> by inferring types of <code>initialState</code>.</p><h2 id="step-4-scoped-access">Step 4: Scoped access</h2><p>Although we can create multiple containers, usually we put several items in a global state.</p><p>Typical global state libraries have some functionality to scope only a part of the state. For example, React Redux uses selector interface to get a derived value from a global state.</p><p>We take a simpler approach here, which is to use a string key of a global state. In our example, it’s like <code>count</code> and <code>text</code>.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>createContainer</span><span> </span><span>=</span><span> </span><span>(</span><span>initialState</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>let</span><span> globalState </span><span>=</span><span> initialState</span><span>;</span><span></span></p><p><span>3</span><span>  </span><span>const</span><span> listeners </span><span>=</span><span> </span><span>Object</span><span>.</span><span>fromEntries</span><span>(</span><span>Object</span><span>.</span><span>keys</span><span>(</span><span>initialState</span><span>)</span><span>.</span><span>map</span><span>(</span><span>key</span><span> </span><span>=&gt;</span><span> </span><span>[</span><span>key</span><span>,</span><span> </span><span>new</span><span> </span><span>Set</span><span>(</span><span>)</span><span>]</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span></span></p><p><span>5</span><span>  </span><span>const</span><span> </span><span>setGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>key</span><span>,</span><span> nextValue</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>6</span><span>    globalState </span><span>=</span><span> </span><span>{</span><span> </span><span>...</span><span>globalState</span><span>,</span><span> </span><span>[</span><span>key</span><span>]</span><span>:</span><span> nextValue </span><span>}</span><span>;</span><span></span></p><p><span>7</span><span>    listeners</span><span>[</span><span>key</span><span>]</span><span>.</span><span>forEach</span><span>(</span><span>listener</span><span> </span><span>=&gt;</span><span> </span><span>listener</span><span>(</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>8</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>9</span><span></span></p><p><span>10</span><span>  </span><span>const</span><span> </span><span>useGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>key</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>11</span><span>    </span><span>const</span><span> </span><span>[</span><span>state</span><span>,</span><span> setState</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>globalState</span><span>[</span><span>key</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>12</span><span>    </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>      </span><span>const</span><span> </span><span>listener</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>14</span><span>        </span><span>setState</span><span>(</span><span>globalState</span><span>[</span><span>key</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>15</span><span>      </span><span>}</span><span>;</span><span></span></p><p><span>16</span><span>      listeners</span><span>[</span><span>key</span><span>]</span><span>.</span><span>add</span><span>(</span><span>listener</span><span>)</span><span>;</span><span></span></p><p><span>17</span><span>      </span><span>listener</span><span>(</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>18</span><span>      </span><span>return</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> listeners</span><span>[</span><span>key</span><span>]</span><span>.</span><span>delete</span><span>(</span><span>listener</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>19</span><span>    </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>20</span><span>    </span><span>return</span><span> </span><span>[</span><span>state</span><span>,</span><span> </span><span>(</span><span>nextValue</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>setGlobalState</span><span>(</span><span>key</span><span>,</span><span> nextValue</span><span>)</span><span>]</span><span>;</span><span></span></p><p><span>21</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>22</span><span></span></p><p><span>23</span><span>  </span><span>return</span><span> </span><span>{</span><span></span></p><p><span>24</span><span>    setGlobalState</span><span>,</span><span></span></p><p><span>25</span><span>    useGlobalState</span><span>,</span><span></span></p><p><span>26</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>27</span><span></span><span>}</span><span>;</span></p></pre></div><p>We omit the use of useCallback in this code for simplicity, but it’s generally recommended for a library.</p><h2 id="step-5-functional-updates">Step 5: Functional Updates</h2><p>React <code>useState</code> allows <a href="https://reactjs.org/docs/hooks-reference.html#functional-updates" target="_blank" rel="noreferrer">functional updates</a>. Let’s implement this feature.</p><div><pre><p><span>1</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span>  </span><span>const</span><span> </span><span>setGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>key</span><span>,</span><span> nextValue</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>    </span><span>if</span><span> </span><span>(</span><span>typeof</span><span> nextValue </span><span>===</span><span> </span><span>'function'</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>5</span><span>      globalState </span><span>=</span><span> </span><span>{</span><span> </span><span>...</span><span>globalState</span><span>,</span><span> </span><span>[</span><span>key</span><span>]</span><span>:</span><span> </span><span>nextValue</span><span>(</span><span>globalState</span><span>[</span><span>key</span><span>]</span><span>)</span><span> </span><span>}</span><span>;</span><span></span></p><p><span>6</span><span>    </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span></span></p><p><span>7</span><span>      globalState </span><span>=</span><span> </span><span>{</span><span> </span><span>...</span><span>globalState</span><span>,</span><span> </span><span>[</span><span>key</span><span>]</span><span>:</span><span> nextValue </span><span>}</span><span>;</span><span></span></p><p><span>8</span><span>    </span><span>}</span><span></span></p><p><span>9</span><span>    listeners</span><span>[</span><span>key</span><span>]</span><span>.</span><span>forEach</span><span>(</span><span>listener</span><span> </span><span>=&gt;</span><span> </span><span>listener</span><span>(</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>10</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>11</span><span></span></p><p><span>12</span><span>  </span></p></pre></div><h2 id="step-6-reducer">Step 6: Reducer</h2><p>Those who are familiar with Redux may prefer reducer interface. React hook useReducer also has basically the same interface.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>createContainer</span><span> </span><span>=</span><span> </span><span>(</span><span>reducer</span><span>,</span><span> initialState</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>let</span><span> globalState </span><span>=</span><span> initialState</span><span>;</span><span></span></p><p><span>3</span><span>  </span><span>const</span><span> listeners </span><span>=</span><span> </span><span>Object</span><span>.</span><span>fromEntries</span><span>(</span><span>Object</span><span>.</span><span>keys</span><span>(</span><span>initialState</span><span>)</span><span>.</span><span>map</span><span>(</span><span>key</span><span> </span><span>=&gt;</span><span> </span><span>[</span><span>key</span><span>,</span><span> </span><span>new</span><span> </span><span>Set</span><span>(</span><span>)</span><span>]</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span></span></p><p><span>5</span><span>  </span><span>const</span><span> </span><span>dispatch</span><span> </span><span>=</span><span> </span><span>(</span><span>action</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>6</span><span>    </span><span>const</span><span> prevState </span><span>=</span><span> globalState</span><span>;</span><span></span></p><p><span>7</span><span>    globalState </span><span>=</span><span> </span><span>reducer</span><span>(</span><span>globalState</span><span>,</span><span> action</span><span>)</span><span>;</span><span></span></p><p><span>8</span><span>    </span><span>Object</span><span>.</span><span>keys</span><span>(</span><span>(</span><span>key</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>9</span><span>      </span><span>if</span><span> </span><span>(</span><span>prevState</span><span>[</span><span>key</span><span>]</span><span> </span><span>!==</span><span> globalState</span><span>[</span><span>key</span><span>]</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>10</span><span>        listeners</span><span>[</span><span>key</span><span>]</span><span>.</span><span>forEach</span><span>(</span><span>listener</span><span> </span><span>=&gt;</span><span> </span><span>listener</span><span>(</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>11</span><span>      </span><span>}</span><span></span></p><p><span>12</span><span>    </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>13</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>14</span><span></span></p><p><span>15</span><span>  </span><span></span></p><p><span>16</span><span></span></p><p><span>17</span><span>  </span><span>return</span><span> </span><span>{</span><span></span></p><p><span>18</span><span>    useGlobalState</span><span>,</span><span></span></p><p><span>19</span><span>    dispatch</span><span>,</span><span></span></p><p><span>20</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>21</span><span></span><span>}</span><span>;</span></p></pre></div><h2 id="step-6-concurrent-mode">Step 6: Concurrent Mode</h2><p>In order to get benefits from Concurrent Mode, we need to use React state instead of an external variable. The current solution to it is to link a React state to our global state.</p><p>The implementation is very tricky, but in essence we create a hook to create a state and link it.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>useGlobalStateProvider</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>    </span><span>const</span><span> </span><span>[</span><span>state</span><span>,</span><span> dispatch</span><span>]</span><span> </span><span>=</span><span> </span><span>useReducer</span><span>(</span><span>patchedReducer</span><span>,</span><span> globalState</span><span>)</span><span>;</span><span></span></p><p><span>3</span><span>    </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>      linkedDispatch </span><span>=</span><span> dispatch</span><span>;</span><span></span></p><p><span>5</span><span>      </span><span></span></p><p><span>6</span><span>    </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>7</span><span>    </span><span>const</span><span> prevState </span><span>=</span><span> </span><span>useRef</span><span>(</span><span>state</span><span>)</span><span>;</span><span></span></p><p><span>8</span><span>    </span><span>Object</span><span>.</span><span>keys</span><span>(</span><span>(</span><span>key</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>9</span><span>      </span><span>if</span><span> </span><span>(</span><span>prevState</span><span>.</span><span>current</span><span>[</span><span>key</span><span>]</span><span> </span><span>!==</span><span> state</span><span>[</span><span>key</span><span>]</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>10</span><span>        </span><span></span></p><p><span>11</span><span>        listeners</span><span>[</span><span>key</span><span>]</span><span>.</span><span>forEach</span><span>(</span><span>listener</span><span> </span><span>=&gt;</span><span> </span><span>listener</span><span>(</span><span>state</span><span>[</span><span>key</span><span>]</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>12</span><span>      </span><span>}</span><span></span></p><p><span>13</span><span>    </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>14</span><span>    prevState</span><span>.</span><span>current</span><span> </span><span>=</span><span> state</span><span>;</span><span></span></p><p><span>15</span><span>    </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>16</span><span>      globalState </span><span>=</span><span> state</span><span>;</span><span></span></p><p><span>17</span><span>    </span><span>}</span><span>,</span><span> </span><span>[</span><span>state</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>18</span><span>  </span><span>}</span><span>;</span></p></pre></div><p>The <code>patchedReducer</code> is required to allow <code>setGlobalState</code> to update global state. The <code>useGlobalStateProvider</code> hook should be used in a stable component such as an app root component.</p><p>Note that this is not a well-known technique, and there might be some limitations. For instance, invoking listeners in render is not actually recommended.</p><p>To support Concurrent Mode in a proper way, we would need core support. Currently, <code>useMutableSource</code> hook is proposed in <a href="https://github.com/reactjs/rfcs/pull/147" target="_blank" rel="noreferrer">this RFC</a>.</p><h2 id="closing-notes">Closing notes</h2><p>This is mostly how <a href="https://github.com/dai-shi/react-hooks-global-state" target="_blank" rel="noreferrer">react-hooks-global-state</a> is implemented. The real code in the library is a bit more complex in TypeScript, contains <code>getGlobalState</code> for reading global state from outside, and has limited support for Redux middleware and DevTools.</p><p>Finally, I have developed some other libraries around global state and React context, as listed below.</p><ul><li><a href="https://github.com/dai-shi/reactive-react-redux" target="_blank" rel="noreferrer">https://github.com/dai-shi/reactive-react-redux</a></li><li><a href="https://github.com/dai-shi/react-tracked" target="_blank" rel="noreferrer">https://github.com/dai-shi/react-tracked</a></li><li><a href="https://github.com/dai-shi/use-context-selector" target="_blank" rel="noreferrer">https://github.com/dai-shi/use-context-selector</a></li></ul><h2 id="frontend-monitoring">Frontend Monitoring</h2><p><a href="https://asayer.io/" target="_blank" rel="noreferrer">Asayer</a> is a frontend monitoring tool that replays everything your users do and shows how your web app behaves for every issue. It lets you reproduce issues, aggregate JS errors and monitor your web app’s performance. </p><p>Happy debugging, for modern frontend teams - <a href="https://asayer.io/register.html" target="_blank" rel="noreferrer">Start monitoring your web app for free</a>.</p></div></article></div>]]>
            </description>
            <link>https://blog.asayer.io/steps-to-develop-global-state-for-react-with-hooks-without-context</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398532</guid>
            <pubDate>Mon, 07 Sep 2020 11:06:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Computer vision model to identify the Australian Aboriginal Flag [follow up]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24398504">thread link</a>) | @thomasfromcdnjs
<br/>
September 7, 2020 | https://ajaxdavis.com/post/An-Open-Source-Computer-vision-model-to-identify-the-Australian-Aboriginal-Flag-Tutorial/ | <a href="https://web.archive.org/web/*/https://ajaxdavis.com/post/An-Open-Source-Computer-vision-model-to-identify-the-Australian-Aboriginal-Flag-Tutorial/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<blockquote>
<p>This project was based on a <a href="https://news.ycombinator.com/item?id=24187794">Hacker News discussion</a>, thank you for all your input!</p>
</blockquote>
<p>I've been recently paying attention to the <a href="https://clothingthegap.com.au/pages/free-the-flag">#freetheflag</a> debate, in short;</p>
<blockquote>
<p>The Aboriginal flag <a href="https://www.legislation.gov.au/Details/F2008L00209">of Australia</a> is widely used by indigenous Australians as a symbol of their heritage. Though, the flag is actually copyrighted by an <a href="https://aiatsis.gov.au/explore/articles/aboriginal-flag#:~:text=Flag%20copyright,the%20author%20of%20the%20flag.&amp;text=The%20copyright%20license%20for%20the,to%20Carroll%20and%20Richardson%20Flags.">indigenous individual</a> who has exclusive control of the licensing rightfully. This has become a debate because a lot of Aboriginals believe they should have a right to print or copy the Aboriginal flag as they would like.</p>
</blockquote>
<p>(Just a quick shout out to my mob, the <a href="https://en.wikipedia.org/wiki/Kuku_Yalanji">Kuku Yalanji</a> people of Far North Queensland)</p>
<p>Over the years I've been trying to learn machine learning but never got anywhere because I couldn't think of a use case. I recently read a cool post from <a href="https://clothingthegap.com.au/pages/aboriginal-flag-timeline">Clothing The Gap</a> which gives an overview of the current copyright debate. They had an image that contains the "Aboriginal flag" done by a European artist several years earlier and how this could maybe be used to invalidate copyright as the design was perhaps already in existence. This gave me the idea to think about if there were perhaps other artworks throughout history that may have contained the flag design.</p>
<p>My main idea was that if I could use machine learning to train a computer vision model to find Aboriginal flags. I could then run it over historical archives of images/paintings to see if I can find any other places the Aboriginal flag seemingly appeared throughout history. Such that in a court case one might overturn the copyright by simply saying they were printing an "Indonesian symbol from the 14th century" (just a potential example)</p>
<p><img src="https://i.imgur.com/nJwFE7K.jpg" alt="asdas"></p>
<p>If you look at the top left of the image, you will see an Aboriginal flag in this painting. I considered my model training a success once it could find the flag in this sample</p>
<p>It does actually work and as you can see in the above image, the model is able to draw a bounding box around the "flag".</p>
<p>I've only scanned 100,000 historical images so far and yet to find any pre-existing artworks that contain the flag. I still have a couple of million images to get through and hope to add a couple million more.</p>
<p>But here is a gallery of false positives, images that the model thought were aboriginal flags but not quite... (if you look at the images for long enough you can see why maybe the model thought it was an aboriginal flag)</p>
<p><a href="https://imgur.com/a/Q22VnGK">Results</a></p>
<p>I've also saved some of the resulting data in a <a href="https://airtable.com/shrHq7PG7CF7axGB4">table</a> for anyone who wants to take a closer look.</p>
<p>I will keep working on the project to improve the results, and all of the code is open-source and free to use.</p>
<p>The rest of this post is for people who would like to run the code themselves and learn how to train an object recognition model from scratch. It is less than 20 lines of code in total and I've made everything as simple as possible with all resources available in the repo.</p>
<p>If anyone would like to help me train a better model then please <a href="https://ajaxdavis.com/cdn-cgi/l/email-protection#f185999e9c9082909d86889f9590879882b1969c90989ddf929e9c">reach out</a>!</p>
<h2>Technical</h2>
<p>I had no prior experience in computer vision, so I had no idea how I might train a model to do this. I managed to do it in a week, it is super easy for anyone with a bit of programming knowledge. The CV community is big and beautiful and I managed to get my idea working with PyTorch in a night. (I spent a few nights on Tensorflow and didn't get very far)</p>
<p>This tutorial is self-contained and can be found in the <a href="https://github.com/australia/aboriginal-flag-cv-model">repo</a>.</p>
<p>Again, the tutorial contains very little code thanks to a few open-source projects it depends on.</p>
<p>I also had a problem with the complexity of the language in the CV community so I'm going to purposely oversimplify things here.</p>
<p>This is super easy and you could likely have it working in under an hour. (Then add ML to your <a href="https://jsonresume.org/">resume</a>)</p>
<p>We are going to split the tutorial into three steps;</p>
<ol>
<li><strong>Classification</strong> - We need to manually draw boxes around the objects we are looking for in some sample images. The machine learning will use this human-curated data to train itself.</li>
<li><strong>Training</strong> - Once we have a classified data-set of images, we can use <a href="https://pytorch.org/">PyTorch</a> to train a reusable model.</li>
<li><strong>Identification</strong> - Now that we have a model, we want to see if it can correctly find the desired object in a given sample image</li>
</ol>
<p>Let's do it!</p>
<h2>Getting Started</h2>
<pre><code>

git <span>clone</span> https://github.com/australia/aboriginal-flag-cv-model
<span>cd</span> aboriginal-flag-cv-model
pip3 install -r requirements.txt
</code></pre>
<h3>Classification</h3>
<p>For the purposes of this tutorial, we are just going to train a model to find Aboriginal flags. But after you've finished this, you should be able to train a model to detect any object you would like. (Simple things, not hard things like if a person is <em>sad</em>).</p>
<p>So the initial classification is a human step, but it's kinda fun to do and will help you understand what the model can detect.</p>
<p>We start with an <code>images</code> folder which is in the <a href="https://github.com/australia/aboriginal-flag-cv-model">repo</a>.</p>
<pre><code>/images
  1.jpg
  2.jpg
</code></pre>
<p>Essentially we have to use our monkey minds to draw bounding boxes around images that contain the desired object we are looking for.</p>
<p>And generate an associated XML file for each file that describes those bounding boxes.</p>
<p>After we are finished our directory should look like</p>
<pre><code>/images
  1.jpg
  1.xml
  2.jpg
  2.xml
</code></pre>
<p>The easiest program to do this in (and a kind of nostalgic UI) is called <code>labelImg</code></p>
<p><a href="https://github.com/tzutalin/labelImg">https://github.com/tzutalin/labelImg</a></p>
<p>You will have to figure out how to install and run it yourself.</p>
<p>Once open, point it at the <code>images</code> folder from the <a href="https://github.com/australia/aboriginal-flag-cv-model">repo</a>, once you figure out how to use the program, you will start drawing boxes and saving the XML to the <code>images</code> directory. And by the end of it, it should look like the directory structure above.</p>
<p><img src="https://i.imgur.com/yWL5vcb.jpg" alt="labelImg screenshot"></p>
<p>The XML contains a label that you will be able to define when drawing bounding boxes. The model will require you later to use the same label in the training, for this example you should just use the label <code>aboriginal_flag</code>.</p>
<p><img src="https://i.imgur.com/xc7RMDR.jpg" alt="labelImg screenshot"></p>
<p>The way you draw your boxes does change the outcome of the model, for the Aboriginal flag I tended to;</p>
<ul>
<li>Leave a bit of outer space around the shape of the flag</li>
<li>Choose images at all angles and depths</li>
<li>Didn't worry if a limb or object was in front of the flag</li>
<li>Chose real flags, paintings of flags, full-scale images of the flag</li>
<li>A mixture of single or multiple instances of the object</li>
</ul>
<p>Once you have your images and associated XML files generated, you are ready to start training.</p>
<blockquote>
<p>If you get too lazy to classify the 40 images in the <a href="https://github.com/australia/aboriginal-flag-cv-model">repo</a>, just copy the files in <code>images_classified</code> into <code>images</code>. I do recommend classifying them manually your self to see how small nuances might influence the learning model. Choosing images of different shapes, colors, angles, sizes, depth and so on will make your model more robust.</p>
</blockquote>
<h3>Training</h3>
<p>So next we want to generate a model, and PyTorch/Detecto makes this easy by letting us generate one file to store all of our learned data  in e.g. <code>model.pth</code></p>
<p>We point PyTorch/Detecto at our classified data set and it should spit out a <code>model.pth</code> which we will use later to find our object (flag) in samples.</p>
<p>What really makes this whole tutorial so easy is the fact we will be using a python library called <a href="https://github.com/alankbi/detecto">Detecto</a> written by <a href="https://github.com/alankbi/">Alan Bi</a> (thanks man, beautiful job)</p>
<p>The entire code to go from the <code>dataset</code>(folder of images and XML) to a<code>reusable object recognition model</code> is below.</p>
<p>WARNING: You might need a decent computer to even run 3 epochs let alone 6 so if you just want to get a copy of a decently trained model, just download my <a href="https://drive.google.com/file/d/1WrL1lV85njUwLR_pYaDD7fh1TV0lFKEN/view?usp=sharing">pre-trained model.pth</a></p>
<pre><code>



<span>from</span> detecto <span>import</span> core
<span>from</span> detecto.core <span>import</span> Model



dataset = core.Dataset(<span>'images_classified/'</span>)


model = Model([<span>'aboriginal_flag'</span>])








model.fit(dataset, epochs=<span>3</span>, verbose=<span>True</span>)





model.save(<span>'model.pth'</span>)





</code></pre>
<p>To run it from within the <a href="https://github.com/australia/aboriginal-flag-cv-model">repo</a>;</p>
<pre><code>python3 train.py // Should output a file called model.pth
</code></pre>
<blockquote>
<p>The PTH file type is primarily associated with PyTorch. PTH is a data file for Machine Learning with PyTorch. PyTorch is an open source machine learning library based on the Torch library. It is primarily developed by Facebooks artificial intelligence research group.</p>
</blockquote>
<p>(If the above code didn't run for you, please make an <a href="https://github.com/australia/aboriginal-flag-cv-model/issues">issue</a>.</p>
<p>Now onto the fun part, let's see if our generated model can find what we are looking for!</p>
<h3>Identification</h3>
<p>So now we should have a <code>model.pth</code> and a <code>samples/sample.jpg</code> in the <a href="https://github.com/australia/aboriginal-flag-cv-model">repo</a>, let's run it to see if our model is smart enough to find the object.</p>
<p>Finding the objects coordinates in the picture is easy, but we also want to draw a box around the coordinates which requires just a bit more code.</p>
<p>To run it from the repo</p>
<pre><code>python3 findFlag.py
</code></pre>
<p>The code for that file is below, I've commented in how it works.</p>
<pre><code>

<span>from</span> detecto.core <span>import</span> Model
<span>import</span> cv2 



model = Model.load(<span>'model.pth'</span>, [<span>'aboriginal_flag'</span>])



image = cv2.imread(<span>"samples/sample.jpg"</span>)






labels, boxes, scores = model.predict(image)







print(labels, boxes, scores)




<span>for</span> idx, s <span>in</span> enumerate(scores):
    <span>if</span> s &gt; <span>0.3</span>: 
        rect = boxes[idx]
        start_point = (rect[<span>0</span>].int(), rect[<span>1</span>].int())
        end_point = (rect[<span>2</span>].int(), rect[<span>3</span>].int())
        cv2.rectangle(image, start_point, end_point, (<span>0</span>, <span>0</span>, <span>255</span>), <span>2</span>)

cv2.imshow(<span>"Image"</span> + str(idx), image)

cv2.waitKey(<span>0</span>)

</code></pre>
<p>If you are having a good day, an image should have appeared on your screen. And if you are having a lucky day, then the Python script should have also drawn a rectangle over the image.</p>
<p>That is all there is really, you obviously can just take the outputted prediction data (boxes and scores) and save it to where ever you would like e.g. a database.</p>
<p>If something didn't work feel free to complain in the tutorial repo <a href="https://github.com/australia/aboriginal-flag-cv-model/issues">issues</a>.</p>
<h3>Conclusion</h3>
<p>I do hope it worked, those steps above worked for me. I drew an Aboriginal flag on paper and took selfies at many angles and the model picked it up. (I manually classified 150 images instead of 40 though) (and if I call recall correctly, around 10 epochs)</p>
<p><img src="https://i.imgur.com/Xcg422N.png" alt="ajax davis"></p>
<p>This tutorial is meant to be a complete noob guide (written by a noob), how I've described things, and the way they are in computer vision - are two different things.</p>
<p>This task has allowed me to introduce myself to the computer vision sector and I'm sure I will learn more over …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ajaxdavis.com/post/An-Open-Source-Computer-vision-model-to-identify-the-Australian-Aboriginal-Flag-Tutorial/">https://ajaxdavis.com/post/An-Open-Source-Computer-vision-model-to-identify-the-Australian-Aboriginal-Flag-Tutorial/</a></em></p>]]>
            </description>
            <link>https://ajaxdavis.com/post/An-Open-Source-Computer-vision-model-to-identify-the-Australian-Aboriginal-Flag-Tutorial/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398504</guid>
            <pubDate>Mon, 07 Sep 2020 10:59:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Vector Spaces to Periodic Functions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398493">thread link</a>) | @susam
<br/>
September 7, 2020 | https://susam.in/blog/from-vector-spaces-to-periodic-functions/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/from-vector-spaces-to-periodic-functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 30 Jan 2019</p>
<h2 id="vector-spaces"><a href="#vector-spaces">Vector Spaces</a></h2>
<p>
A fascinating result that appears in linear algebra is the fact that the
set of real numbers \( \mathbb{R} \) is a vector space over the set of
rational numbers \( \mathbb{Q}. \) This may appear surprising at first
but it is easy to show that it is indeed so by checking that all eight
axioms of vector spaces hold good:
</p>

<ol>
  <li>
    <p>
      Commutativity of vector addition:<br>
      \( x + y = y + x \) for all \( x, y \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Associativity of vector addition:<br>
      \( x + (y + z) = (x + y) + z \) for all \( x, y, z \in \mathbb{R}.
      \)
    </p>
  </li>
  <li>
    <p>
      Existence of additive identity vector:<br>
      We have \( 0 \in \mathbb{R} \) such that \( x + 0 = x \) for all
      \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Existence of additive inverse vectors:<br>
      There exists \( -x \in \mathbb{R} \) for all \( x \in \mathbb{R}.
      \)
    </p>
  </li>
  <li>
    <p>
      Associativity of scalar multiplication:<br>
      \( a(bx) = (ab)x \) for all \( a, b \in \mathbb{Q} \) and for all
      \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Distributivity of scalar multiplication over vector addition:<br>
      \( a(x + y) = ax + by \) for all \( a \in \mathbb{Q} \) and for
      all \( x, y \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Distributivity of scalar multiplication over scalar addition:<br>
      \( (a + b)x = ax + bx \) for all \( a, b \in \mathbb{Q} \) and for
      all \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Existence of scalar multiplicative identity:<br>
      We have \( 1 \in \mathbb{Q} \) such that \( 1 \cdot x = x \) for
      all \( x \in \mathbb{R}. \)
    </p>
  </li>
</ol>
<p>
  This shows that the set of real numbers \( \mathbb{R} \) forms a
  vector space over the field of rational numbers \( \mathbb{Q}. \)
  Another quick way to arrive at this fact is to observe that \(
  \mathbb{Q} \subseteq \mathbb{R}, \) that is, \( \mathbb{Q} \) is a
  subfield of \( \mathbb{R}. \) Any field is a vector space over any of
  its subfields, so \( \mathbb{R} \) must be a vector space over \(
  \mathbb{Q}. \)
</p>


<h2 id="problem"><a href="#problem">Problem</a></h2>

<p>
Here is an interesting problem related to vector spaces that I came
across recently:
</p>

<div>
<p>
Define two periodic functions \( f \) and \( g \) from \( \mathbb{R} \)
to \( \mathbb{R} \) such that their sum \( f + g \) is the identity
function. The axiom of choice is allowed.
</p>
<p>
A function \( f \) is periodic if there exists \( p \gt 0 \) such that
\( f(x + p) = f(x) \) for all \( x \) in the domain.
</p>
</div>

<p>
<em>
If you want to think about this problem, this is a good time to pause
and think about it. There are spoilers ahead.
</em>
</p>


<h2 id="solution"><a href="#solution">Solution</a></h2>

<p>
The axiom of choice is equivalent to the statement that every vector
space has a basis. Since the set of real numbers \( \mathbb{R} \) is a
vector space over the set of rational numbers \( \mathbb{Q}, \) there
must be a basis \( \mathcal{H} \subseteq \mathbb{R} \) such that every
real number \( x \) can be written uniquely as a finite linear
combination of elements of \( \mathcal{H} \) with rational coefficients,
that is,
\[
  x = \sum_{a \in \mathcal{H}} x_a a
\]
where each \( x_a \in \mathbb{Q} \) and \( \{ a \in \mathcal{H} \mid x_a
\ne 0 \} \) is finite. The set \( \mathcal{H} \) is also known as the
Hamel basis.
</p>

<p>
We know that \( b_a = 0 \) for distinct \( a, b \in \mathcal{H} \)
because \( a \) and \( b \) are basis vectors.
</p>

<p>
In the above expansion of \( x, \) each \( x_a \) is a rational number
that appears as the coefficient of the basis vector \( a. \) Therefore
\( (x + y)_{a} = x_a + y_a \) for all \( x, y \in \mathbb{R}. \) Thus \(
(x + b)_{a} = x_a + b_a = x_a + 0 = x_a. \) This shows that a function
\( f(x) = x_a \) is a periodic function with period \( b \) for any \( b
\in \mathcal{H} \setminus \{a\}. \)
</p>

<p>
Let us define two functions:
\begin{align*}
  f(x) &amp; = \sum_{a \in \mathcal{H} \setminus \{ b \}} x_a a,
  &amp;
  g(x) &amp; = x_b b.
\end{align*}
where \( b \in \mathcal{H} \) and \( x \in \mathbb{R}. \) Let us
choose \( c \in \mathcal{H} \) such that \( c \ne b. \) Then \( f(x) \)
is a periodic function with period \( b \) and \( g(x) \) is a periodic
function with period \( c. \) Further,
\[
  f(x) + g(x)
  = \left( \sum_{a \in \mathcal{H} \setminus \{ b \}} x_a a \right) + x_b b
  = \sum_{a \in \mathcal{H}} x_a a
  = x.
\]
Thus \( f(x) \) and \( g(x) \) are two periodic functions such that
their sum is the identity function.
</p>


<h2 id="references"><a href="#references">References</a></h2>
<ul>
  <li>
    <a href="https://mathworld.wolfram.com/VectorSpace.html">Vector
    Space</a> (by Eric W. Weisstein)
  </li>
  <li>
    <a href="https://web.archive.org/web/20141026224511/https://drexel28.wordpress.com/2010/10/22/the-dimension-of-r-over-q/">The
    Dimension of R over Q</a> (by Alex Youcis)
  </li>
  <li>
    <a href="https://mathblag.wordpress.com/2013/09/01/sums-of-periodic-functions/">Sums
  of Periodic Functions</a> (by David Radcliffe)
  </li>
</ul>



</div></div>]]>
            </description>
            <link>https://susam.in/blog/from-vector-spaces-to-periodic-functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398493</guid>
            <pubDate>Mon, 07 Sep 2020 10:58:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi 3B+ Hackable Linux Handheld]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 90 (<a href="https://news.ycombinator.com/item?id=24398485">thread link</a>) | @mmerlin
<br/>
September 7, 2020 | http://yarh.io/yarh-io-mki.html | <a href="https://web.archive.org/web/*/http://yarh.io/yarh-io-mki.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <section id="top-section">
        <div id="top-section-top">
            <nav>
                
            </nav>
            <p id="heading">
                
                <h2>Raspberry Pi 3B+ Hackable Linux Handheld<br></h2>
            </p>
        </div>
    </section>
    <section id="yarh-io-mki">
        <div>
            <div>
                <div>
                    <p><a href="http://yarh.io/assets/img/yarh-white-hand-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-white-hand-large-t-001.png"></a></p>
                    <div>
                        <p>YARH.IO is a fully hackable and custamizable Raspberry Pi based handheld, running Raspberry Pi OS and supporting all other Operating Systems available for Raspberry Pi.</p>
                        <p>The dream of a hackable&nbsp;Linux powered handheld has been around for many years, and many attempts have been made to create a working device. While some of the devices have reached the market, none of them withstood the test
                            of real world user experience.<br></p>
                        <p>YARH.IO project has taken on the challenge of building a fully functioning device by combining the best of Raspberry Pi design and 3D printing technology.&nbsp;<br></p>
                        <p>This project takes hackability to the next level by ensuring that every single component needed to build YARH.IO can be easily sourced, with no custom PCBs and just a bit of wire soldering required.&nbsp;</p>
                    </div>
                </div>
                <div>
                    <div>
                        <p>YARH.IO handheld and its unique modular design with exposed interfaces offers unprecedented connectivity with unlimited platforms and devices.<br></p>
                        <p>This model is powered by&nbsp;Raspberry Pi 3B+ and&nbsp;has the best ratio of functionality and computing power requirements for a mobile device. When it comes to the battery powered devices, the overall power consumption and longer
                            battery are more important then the extra processing power or memory.</p>
                        <p>For this model, the width of the main module is based on the keyboard dimensions for improved handling. The 5" Resistive Touch Screen 800x480 HDMI TFT LCD Display&nbsp;is a good option for YARH.IO as it&nbsp;will allow you to perform
                            all of the usual tasks with ease.&nbsp;<br></p>
                    </div>
                    <p><a href="http://yarh.io/assets/img/yarh-red-right-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-red-right-large-t-001.png"></a></p>
                </div>
                <div>
                    <p><a href="http://yarh.io/assets/img/yarh-white-left-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-white-left-large-t-001.png"></a></p>
                    <div>
                        <p>Fosmon Portable Lightweight Mini Wireless Bluetooth Keyboard Controller has been selected as the best option for YARH.IO's multifunctional design. If you are using Vim, tmux, and Emacs everyday, the available modifier keys will
                            help you get the most out of the device.</p>
                        <p>In addition to the keyboard, YARH.IO's pointing device will allow you to effortlessly browse the internet and engage with other applications with graphical interface.&nbsp;&nbsp;<br></p>
                        <p>A single removable rechargeable battery will allow you to quickly replace an empty battery with a fully charged one. A high capacity Fenix ARB-L21-5000 5000mAh Li-ion Rechargeable Battery was chosen as the best option as it fits
                            the main module perfectly. For the charger/5v power supply the internals of a Fenix ARE-D1 Smart Charger were used.</p>
                    </div>
                </div>
                <div>
                    <div>
                        <p>The RTC is a must have for a handheld device that is not continuously connected to the internet. YARH.IO includes a DS3231 High Precision RTC Clock Module.</p>
                        <p>Raspberry Pi GPIO connectors have been made available on the bottom sides of the main module and extension module for connecting all of your Raspberry Pi add-on boards.</p>
                        
                    </div>
                    <p><a href="http://yarh.io/assets/img/yarh-black-top-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-black-top-large-t-001.png"></a></p>
                </div>
                <div>
                    <p><a href="http://yarh.io/assets/img/yarh-black-back-open-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-black-back-open-large-t-001.png"></a></p>
                    <div>
                        <p>YARH.IO features modular design, where the main module includes Raspberry Pi board, screen, power supply, battery, and RTC and GPIO connector with cables.&nbsp;</p>
                        <p>The main module can be used as a fully functioning handheld computer&nbsp;with the touch screen and onscreen keyboard available for the performance of your basic tasks.</p>
                        <p>One shared USB connector is available on the bottom of the main module, allows connecting USB devices like&nbsp;hard drives or Cellular/WiFi adaptors and mounted inside the extension module.</p>
                        <p>Raspberry Pi GPIO connector is also available on the bottom of the main module, allowing for different add-on modules,&nbsp;<br>including Lora radios, RFID readers/writers, and IR transivers, to&nbsp;be mounted inside the extension
                            module. This configuration works extremely well with Pi-DAC+, creating a great handheld audio player.</p>
                    </div>
                </div>
                <div>
                    <p><a href="http://yarh.io/assets/img/yarh-black-keyboard-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-black-keyboard-large-t-001.png"></a></p>
                    <div>
                        <p>No 'click' assembly here. This is a fully hackable device with stainless steel socket cap screw used&nbsp;throughout to allow for multiple assembly and disassembly cycles.&nbsp;The Military/Industrial aesthetic can be felt throughout
                            the YARH.IO project design.&nbsp;<br></p>
                        <p>The sturdy housing parts are 3D printed using PLA, ABS, and ASA plastic.&nbsp;<br></p>
                        
                    </div>
                </div>
                <div>
                    <p><a href="http://yarh.io/assets/img/yarh-black-back-keyboard-open-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-black-back-keyboard-open-large-t-001.png"></a></p>
                    <p>The list of parts used for the YARH.IO project can be purchased from Amazon and other online stores.</p>
                </div>
                <div>
                    
                    <p><a href="http://yarh.io/assets/img/yarh-black-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-black-large-t-001.png"></a></p>
                </div>
                <div>
                    <p><a href="http://yarh.io/assets/img/yarh-white-front-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-white-front-large-t-001.png"></a></p>
                    <div>
                        <p>YARH.IO MKI Project at a Glance.&nbsp;</p>
                        <p>The outcome of this YARH.IO model is a successful handheld device with the potential to connect an unlimited range of extension devices and modules. It is a ruggedly designed and fully hackable device that can be 3D printed and
                            assembled in the field.<br></p>
                        <p>As an experimental model YARH.IO's future development will continue to increase usability and functionality of the device. One of the areas of improvement is the adaptation of IPS type screen for wider viewing angles.&nbsp;<br></p>
                        <p>Other future development will focus on adding new compartment modules to accommodate additional I/O, storage and communication devices.&nbsp;<br></p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <section id="yarh-io-mki-gallery">
        
    </section>
    <section id="yarh-io-mki-downloads">
        
    </section>
    <section id="footer">
        <div>
            <div>
                <div>
                    <div>
                        <p>© 2019-2020 YARH.IO | info@yarh.io</p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    
    
    
    


</div>]]>
            </description>
            <link>http://yarh.io/yarh-io-mki.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398485</guid>
            <pubDate>Mon, 07 Sep 2020 10:56:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to hold successful meetings (in academia)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398193">thread link</a>) | @cbock90
<br/>
September 7, 2020 | https://christian.bock.ml/posts/academic_meetings/ | <a href="https://web.archive.org/web/*/https://christian.bock.ml/posts/academic_meetings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<p>I recently read <a href="https://en.wikipedia.org/wiki/Eric_Schmidt">Eric Schmidt’s</a> and <a href="https://en.wikipedia.org/wiki/Jonathan_Rosenberg_(technologist)">Jonathan Rosenberg’s</a> book about <a href="https://www.goodreads.com/book/show/23158207-how-google-works">How Google Works</a>. While most content does not necessarily translate to academia, I think their list of rules for successful meetings does.
In this post, I will reiterate the list and comment on their applicability in academia. In general, all rules are also valid for non-academic meetings, but since I haven’t worked in industry for quite a while, I feel more comfortable taking the academic (PhD student) point of view. As you will see, I believe it’s the PhD student’s/junior researcher’s responsibility to make a meeting successful, and therefore, I want to stress that my/our meeting culture is by no means perfect, and I myself sometimes struggle to adhere to these rules.</p>

<p>Even though decision making is more and more outsourced to *your favorite communication platform* messages, in-person meetings (even virtual ones) are a much better tool to meet on an equal footing and reach mutual decisions. A proper meeting culture is therefore indispensable.</p>

<p><strong>*rage on*</strong><br>
My main concern with instant messengers is that we frequently begin to write in a tone in which we would not talk in-person, or worse: our communication partner “hears” a destructive tone in our messages that was not intended to be there. We all know this, yet we are quick in dismissing doubts about the language we chose; after all, only the content counts. I can assure you that it is impossible to read only the content; we will always question the motifs behind a message, which can be a problem if they are not clearly communicated. Humans love to “read between the lines”.
<br><strong>*rage off*</strong></p>

<p>Don’t get me wrong, I think Slack et al. are great tools that increase efficiency, but when it comes to important or potentially sensitive topics, meetings should be preferred, and the following rules might help to make them more successful<sup><a href="#fn_order">1</a></sup>:</p>

<h5 id="span-id-rule-1-rule-1-have-an-agenda-span"><span id="rule_1">Rule 1: Have an agenda</span></h5>

<p>The first rule is actually not part of E&amp;J’s list; it is a no-brainer to have an agenda in industry. In academia, this is not always the case (e.g., ad-hoc meetings to “discuss an idea”). Even if it is just 3 bullet points in your head, <strong>know the meeting’s objective</strong> and communicate it to the attendees. Objectives are critical to keep the meeting on track and determine whether the meeting was successful. Sometimes the goal of a meeting is just to update others. For such meetings, I like to have two main threads: 1) I did this, and these are the results, and 2) This is where I got stuck, and need help with. I think the objective of an “update meeting” is never <em>only</em> to update others but always to also get help with the challenges you’re facing.</p>

<h5 id="span-id-rule-2-rule-2-meetings-should-have-a-single-decision-maker-owner-span"><span id="rule_2">Rule 2: Meetings should have a single decision-maker/owner </span></h5>

<p>Eric and Jonathan argue that there should be one person whose butt is on the line for making a decision, typically a person of high seniority. This is very tricky in academia, as sometimes the more senior person is not the one whose butt is on the line. Imagine you’re a PhD student, and you meet with your PI. While your PI comes up with 10 new ideas on improving your paper, which is 90% finished, it is <strong>your</strong> missed opportunity if you fail to include the 10 new aspects in time. In this case, the decision-maker should be the PhD student. Naturally, a decision should be reached together, and there are plenty of situations in which it makes sense to adhere to a “top-down” decision. However, <a href="#rule_5">Rule 5</a> underlines my reasoning.</p>

<h5 id="rule-3-if-you-attend-a-meeting-attend-the-meeting">Rule 3: If you attend a meeting, attend the meeting</h5>

<p>Close your laptop<sup><a href="#fn_laptop">2</a></sup>. Be attentive. Otherwise, don’t be there at all. If you have the feeling you are not needed, then the decision-maker should not have invited you.  If you have the urge to be on the phone or laptop, ask yourself: “Is my time really better spent doing task X, or am I doing someone a disservice by not properly attending this meeting?”. If you are the instigator of the meeting and have the feeling that people are not attentive, tell them. Also, ask them why they are not attentive (do this offline). You might also rethink your decision of whom to include next time.</p>

<h5 id="rule-4-meetings-are-not-like-government-agencies-they-should-be-easy-to-kill">Rule 4: Meetings are not like government agencies – they should be easy to kill</h5>

<p>This is a very important one: If the meeting’s purpose can’t be achieved, the decision-maker has to ask the hard question: Does it make sense to continue the meeting? This is true for recurring meetings (e.g., in 1-on-1s, we can ask: is it beneficial to continue the weekly schedule, or would a bi-weekly meeting be enough, or does this format not work at all?) and ongoing meetings (e.g., is everyone present we need to reach a decision?)</p>

<h5 id="span-id-rule-5-rule-5-the-decision-maker-should-be-hands-on-span"><span id="rule_5">Rule 5: The decision-maker should be hands on</span></h5>

<p>More often than not, the PhD student is the one who does the dirty work. She is the one who thinks and ruminates about one specific problem for hours and days. She comes up with ideas, trashes them, gets frustrated, and tries again. This is why she should “[…] call the meeting, ensure the content is good, set the objectives, determine the participants, and <strong>share the agenda</strong> (if possible)” to quote E&amp;J. Unfortunately, the last point is rare in academia; see <a href="#rule_1">Rule 1</a>.</p>

<h5 id="rule-6-even-if-a-meeting-is-not-a-decision-making-meeting-it-should-have-a-clear-owner">Rule 6: Even if a meeting is not a decision-making meeting it should have a clear owner</h5>

<p>In academia, the majority of our meetings are to update or brainstorm. I argue that in both scenarios, the PhD student should be the owner who takes care that there is a clear agenda, and all participants were able to prepare for the meeting. Ideally, the objectives of the meeting are shared a couple hours before the meeting takes place.</p>

<h5 id="span-id-rule-7-rule-7-meetings-should-be-manageable-in-size-span"><span id="rule_7">Rule 7: Meetings should be manageable in size</span></h5>

<p>E&amp;J recommend not more than eight people and ten at a stretch, and <strong>everyone</strong> should give their input. In big collaborations, this can be hard and makes the following even more important: Have proper communication channels for people who should know the meeting results but were not crucial to reaching a decision.</p>

<h5 id="rule-8-attendance-at-meetings-is-not-a-badge-of-importance">Rule 8: Attendance at meetings is not a badge of importance</h5>

<p>If you are not needed, don’t participate. Unfortunately, this is easier said than done since, often, politics still play a significant role in academia. Some scholars think it is essential to “show presence” even though their involvement in the project is negligible. I am convinced that you can spend your time more productively than by participating in meetings for projects you’re not actively involved in. Technically, <a href="#rule_7">Rule 7</a> should take care of this issue.</p>

<h5 id="rule-9-timekeeping-matters">Rule 9: Timekeeping matters</h5>

<p>A problem I observed a lot in meetings, is that they get into “overtime” <em>before</em> the core problems were solved. This is because scholars love to discuss details, and every itsy bitsy issue needs to be completely solved before we can continue. However, we should not only start our meetings on time but also end them with a proper summary of the findings. Of course, this requires to have a reasonable agenda and maybe even a time assignment for each topic. I would also recommend having a <strong>“rabbit hole watcher”</strong> who drags us out of the rabbit holes that our attention to detail digs for us.</p>

<p>In summary, there are a lot of crucial factors that determine the success of a meeting. If I had to pick a single rule, I’d go for <a href="#rule_2"> Rule 2</a>. If the owner of the meeting is genuinely interested in a positive outcome, she will naturally think about the majority of the other rules herself, and importantly will set objectives which make the success measurable.</p>

<p><span id="fn_order">1. Eric and Jonathan did not order their rules, I tried to order them by importance based on my (limited) experience.</span> <br>
<span id="fn_laptop">2. Unless you need it for note taking.</span></p>

      </div></div>]]>
            </description>
            <link>https://christian.bock.ml/posts/academic_meetings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398193</guid>
            <pubDate>Mon, 07 Sep 2020 09:57:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Many Ways to Start an Xserver]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24398154">thread link</a>) | @gbrown_
<br/>
September 7, 2020 | https://nixers.net/Thread-How-Many-Ways-To-Start-An-Xserver | <a href="https://web.archive.org/web/*/https://nixers.net/Thread-How-Many-Ways-To-Start-An-Xserver">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://nixers.net/Thread-How-Many-Ways-To-Start-An-Xserver</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398154</guid>
            <pubDate>Mon, 07 Sep 2020 09:49:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microcentury]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398092">thread link</a>) | @susam
<br/>
September 7, 2020 | https://susam.in/blog/microcentury/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/microcentury/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 17 Jul 2020</p>
<h2 id="optimal-lecture-time"><a href="#optimal-lecture-time">Optimal Lecture Time</a></h2>

<p>
I recently found this interesting paragraph from an article titled <a href="https://www.ams.org/notices/199701/comm-rota.pdf">Ten Lessons I
Wish I Had Been Taught</a> that is based on a talk presented by
Gian-Carlo Rota in Apr 1996:
</p>

<blockquote>
Running overtime is the one unforgivable error a lecturer can make.
After fifty minutes (one microcentury as von Neumann used to say)
everybody's attention will turn elsewhere even if we are trying to prove
the Riemann hypothesis. One minute overtime can destroy the best of
lectures.
</blockquote>

<p>
That's fine advice. In fact, the whole article is full of good advice
like this. Although it was written primarily for mathematicians, a lot
of what is said in the article applies quite well to professionals in
other fields too.
</p>

<p>
The excerpt I have quoted above got me thinking about exactly how long a
microcentury is. It couldn't be exactly 50 minutes, could it?
</p>


<h2 id="wiktionary-on-microcentury"><a href="#wiktionary-on-microcentury">Wiktionary on Microcentury</a></h2>
<p>
The English Wiktionary entry for <a href="https://en.wiktionary.org/wiki/microcentury">microcentury</a>
(as of <a href="https://en.wiktionary.org/w/index.php?title=microcentury&amp;oldid=59316064">revision
59316064</a> on 7 May 2020) mentions:
</p>

<blockquote>
A time period of a millionth of a century, equal to 52 minutes and 34 seconds.
</blockquote>

<blockquote>
Not a standard unit of measurement, and used mostly humorously to denote
the maximum length of a lecture.
</blockquote>

<p>
This looks incorrect to me. This is based on the oversimplified
assumption that a century contains 36500 days, that is, it assumes that
a century is a span of 100 years where each year has exactly 365 days.
If a century were to have exactly 36500 days, then indeed it would have
3 153 600 000 seconds and one millionth of it would be
3153.6 seconds which is equivalent to 52 minutes 33.6 seconds. This
looks consistent with the Wiktionary entry. However, an actual century
on the calendar does not have exactly 36500 days. Some years are leap
years, so the actual number of days in a century is more than that.
</p>


<h2 id="assumptions"><a href="#assumptions">Assumptions</a></h2>
<p>
Let us find out how long a microcentury is as accurately as possible. We
will count the leap years. We will ignore leap seconds because they are
irregularly spaced and unpredictable. We will also ignore the following
gap between 2 Sep 1752 and 14 Sep 1752 when the British Empire switched
from the Julian calendar to the Gregorian calendar:
</p><pre><samp>$ <kbd>cal 9 1752</kbd>
   September 1752
Su Mo Tu We Th Fr Sa
       1  2 14 15 16
17 18 19 20 21 22 23
24 25 26 27 28 29 30</samp>
</pre>

<p>
The above output can be obtained by running the <code>cal</code> command
as shown above on a Unix or Linux system. Ignoring this gap is
equivalent to assuming that we are working with the Gregorian calender
since the year 1 AD.
</p>

<p>
We will call a year that is a multiple of 100 to be a <em>centurial
year</em>. Further, we will not debate whether a centurial year begins a
new century or ends one, that is, we don't care whether the current
century runs from 2001 to 2100 or if it runs from 2000 to 2099. The
computation presented in the next section works equally well for any
span of 100 years.
</p>


<h2 id="computation"><a href="#computation">Computation</a></h2>
<p>
Any span of 100 years contains exactly one centurial year, that is, a
year that is a multiple of 100. A centurial year is a leap year <em>if
and only if</em> it is also a multiple of 400. Apart from the centurial
year, a century contains 24 occurrences of years that are multiples of 4
and these are all leap years. From these facts, we can conclude that a
span of 100 years contains:
</p>

<ul>
  <li>
    Exactly 25 leap years if the centurial year within the span is a
    multiple of 400.
  </li>
  <li>
    Exactly 24 leap years, otherwise.
  </li>
</ul>

<p>
Therefore a century has either 36524 days or 36525 days. In other words,
a century has either 3 155 673 600 seconds or
3 155 760 000 seconds. Here is a
quick demonstration of this with a simple Python program:
</p>

<pre><code>#!/usr/bin/env python3

import datetime

for year in range(1, 2400, 100):
    delta = datetime.date(year + 100, 1, 1) - datetime.date(year, 1, 1)
    print('{:04}-{:04}: {} d = {} s'
          .format(year, year + 100, delta.days, delta.total_seconds()))</code>
</pre>

<p>
Here is the output of this program:
</p>

<pre><samp>0001-0101: 36524 d = 3155673600.0 s
0101-0201: 36524 d = 3155673600.0 s
0201-0301: 36524 d = 3155673600.0 s
0301-0401: 36525 d = 3155760000.0 s
0401-0501: 36524 d = 3155673600.0 s
0501-0601: 36524 d = 3155673600.0 s
0601-0701: 36524 d = 3155673600.0 s
0701-0801: 36525 d = 3155760000.0 s
0801-0901: 36524 d = 3155673600.0 s
0901-1001: 36524 d = 3155673600.0 s
1001-1101: 36524 d = 3155673600.0 s
1101-1201: 36525 d = 3155760000.0 s
1201-1301: 36524 d = 3155673600.0 s
1301-1401: 36524 d = 3155673600.0 s
1401-1501: 36524 d = 3155673600.0 s
1501-1601: 36525 d = 3155760000.0 s
1601-1701: 36524 d = 3155673600.0 s
1701-1801: 36524 d = 3155673600.0 s
1801-1901: 36524 d = 3155673600.0 s
1901-2001: 36525 d = 3155760000.0 s
2001-2101: 36524 d = 3155673600.0 s
2101-2201: 36524 d = 3155673600.0 s
2201-2301: 36524 d = 3155673600.0 s
2301-2401: 36525 d = 3155760000.0 s</samp>
</pre>

<p>
Thus one millionth of a century has 3155.6736 or 3155.7600 seconds, that
is 52 minutes 35.6736 seconds or 52 minutes 35.7600 seconds.
</p>


<h2 id="Conclusion"><a href="#conclusion">Conclusion</a></h2>

<p>
If we round off the number of seconds in a microcentury to one decimal
place, we can say that a microcentury has 52 minutes 35.7 seconds.
</p>



</div></div>]]>
            </description>
            <link>https://susam.in/blog/microcentury/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398092</guid>
            <pubDate>Mon, 07 Sep 2020 09:38:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Transclude for Networked Writing]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398014">thread link</a>) | @Frodo478
<br/>
September 7, 2020 | http://subpixel.space/entries/open-transclude/ | <a href="https://web.archive.org/web/*/http://subpixel.space/entries/open-transclude/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>tl;dr: If you follow this blog you’ve seen me experiment with iframe-based citations; this post is about open-sourcing that tooling. <a href="#tutorial-start" target="_self">Skip</a> to demo, implementation tutorial, and GitHub link.</p>

<hr>

<p>Knowledge tooling is happily becoming a hot topic again. With this trend is coming revived interest in <a href="https://en.wikipedia.org/wiki/Project_Xanadu">Xanadu</a>, bi-directional hyperlinking, knowledge databases, visualizing knowledge graphs, and so on. At this moment, I see most of the emphasis being put on tooling for the research side, with Notion, Workflowy, and the new and hyped Roam Research leading the way.</p>

<p><img src="http://subpixel.space/uploads/xanadu-shot.png" alt="Screenshot of the OpenXanadu prototpye"></p>

<p>Where I see less focus is the <em>writing</em> part of the knowledge production process, where older apps like Scrivener are still the thing to beat. And almost nobody at all is working on the reader’s experience. As a blogger who largely caters to a wide audience, I’m especially interested in these areas.</p>

<p>Written information is largely still presented as a single document, and writing tools are geared toward the production of long pages. But before I say what’s wrong with this, let me sing the praises of documents for a moment.</p>

<p>People often get carried away when they discover the original vision of hypertext, which involves a network of documents, portions of which are “transcluded” (included via hypertext) into one another. The implication is that readers could follow any reference and see the source material—and granted, this would be transformative. However, there’s a limit to the effectiveness of the knowledge network as a reading experience. “Hypertext books,” online books which are made up of an abundance of interlinked HTML pages, are mostly unpopular. The failure of this experiment is, in my opinion, very revealing.</p>

<p><img src="http://subpixel.space/uploads/sprawlingplaces-shot.jpg" alt="Screenshot of tinderbox map of hypertext book Sprawling Places by David Kolb">
<span>Tinderbox map of a portion of David Kolb’s hypertext book Sprawling Places</span></p>

<p>Knowledge is not an accumulation of facts, nor is it even a set of facts and their relations. Facts are only rendered meaningful within narratives, and the single-page document is a format very conducive to narrative structure. The hypertext books that have gained popularity (I’m thinking here of <a href="http://meaningness.com/">Meaningness.com</a>) have largely conformed to this in two ways: 1) there is an intended reading order, and 2) the longer essays within the project do most of the heavy lifting in terms of imparting the author’s perspective to readers.</p>

<p>On the other hand, the notion of the “document” that is intrinsic to web development today is overdetermined by the legacy of print media. The web document is a static, <em>finished</em> artifact that does not bring in dynamic data. This is strange because it lives on a medium that is alive, networked, and dynamic, a medium which we increasingly understand more as a <em>space</em> than a thing.</p>

<p>For example, consider how silly it is to include MLA-style citations at the bottom of a text when we have the vast capabilities of linked documents on the web. Why should the reader have to read every citation or trust that an author is not taking a citation out of context, when hyperlinks are available?</p>

<p>This all suggests that a compromise must be struck between the coherence of a text and the new opportunities for knowledge work afforded by the fundamental capabilities of the medium: the internet’s connectivity, the screen’s frame rate.</p>

<hr>

<p>My own blogging is one context in which I’ve seen this tension play out, and have been working to explore ways of making my texts richer. A lot of the ideas I talk about in various pieces of writing are connected to one another. When I publish an essay, I’m not done with it. The ideas live on and get renewed, reused, and recycled in later works. Some sentences contain definitions that are core to my mental models, and there are whole paragraphs that might be useful out of context. I’m building my knowledge network in mind maps and behind various SaaS APIs, but how can I publicly show my thinking to be part a cohesive worldview?</p>

<p>Normally people solve this by simply block quoting themselves, but this is a waste of an opportunity. The indented block quote is a print medium invention <a href="https://en.wikipedia.org/wiki/Block_quotation#Origins">almost as old as typesetting</a>. The block quote is <em>plaintext</em>, it is not actually linked to the original text or its context.</p>

<p>I’ve been experimenting with one idea for a solution, and if you’ve read the last couple blog posts you’ll have seen it there. My stab at an answer is an iframe which shows the quote within its original context and gives a hint at its surroundings. Effectively, it’s a transclusion within my own blog. I’m currently satisfied with what I have as a v1, and am interested to see if others find it useful, so I’m open sourcing it here and including a tutorial.</p>



<p>Open Transclude is a UX pattern, a spec for networked writing within your own blog. Here’s how it looks:</p>



<!-- <script src="/portal.js"></script> -->



<p>What you are looking at is an scroll-locked iframe that links to a quote I picked out of my blog post “Notes on Comparative Psychology.” You can use Open Transclude anywhere you can drop an <code>&lt;a&gt;</code> tag on your own site.</p>

<p>Open Transclude:</p>
<ul>
  <li>Works anywhere on your own domain</li>
  <li>Compatible with most static site generators / templating engines</li>
  <li>12 lines of HTML, 80 lines of SCSS, 22 lines of JS (4.5 kb total)</li>
  <li>Has 0 dependencies&nbsp;— this is native web technology</li>
</ul>

<p>Open Transclude is extremely simple, and the heaviest part of the code is the CSS, which you can simplify at your whim. That’s why I am referring to it as a UX pattern. This is not a protocol. The code is really a commodity. What’s interesting about it is the idea and the design, and this is just one viable implementation! Feel free to adapt it however you like.</p>

<p>The principal improvement over a block quotation is <em>sense of context</em>.</p>

<p>Over on GitHub you’ll find the <a href="https://github.com/tobyshorin/Open-Transclude/">reference implementation for Jekyll</a>. Below is a tutorial for implementing it yourself, by way of also explaining some of the technical design decisions.</p>

<hr>

<h2 id="implementation-recipe">Implementation Recipe</h2>

<p>Here’s what you need to do to get Open Transclude up and running.</p>

<ol>
  <li>Create an anchor tag in the blog post where you want to cite yourself.</li>
  <li>Create the HTML for the reusable transclusion component.</li>
  <li>Call the portal into any document and passing it Jekyll variables.</li>
  <li>A small piece of Javascript which populates your transclusion into the document.</li>
  <li>Create the SCSS file with the component’s styles.</li>
</ol>

<h3 id="1-create-the-anchor-tag-where-you-want-to-cite-yourself">1. <strong>Create the anchor tag where you want to cite yourself</strong></h3>

<p>To quote yourself, you’ll need to create an <code>&lt;a&gt;</code> anchor tag in the markdown file for the post you want to quote. If you wish to highlight a specific piece of text, instead create a <code>&lt;span&gt;&lt;/span&gt;</code> around the section you want to quote. Note that this can <em>only be on your own website</em>—it doesn’t work cross domain.</p>

<p>Here’s what it looks like for the example iframe above.</p>

<figure><pre><code data-lang="markdown">It will, for one thing, become newly conscious of itself, and, to the degree that it is, <span>**it will tend to undermine its own experiential integrity**</span>" (emphasis mine).

<span>&lt;span</span> <span>name=</span><span>"mainstream-magic"</span><span>&gt;</span>Ironically, psychology remains one of the closest things we have to a mainstream magic or a mystical art today. Not only is it plainly the direct descendent of medieval magic, as I learned when I read Ioan Coulianou's <span>*Eros and Magic in the Renaissance*</span> earlier this year. <span>**It is a theory of the self that is phenomenologically accurate, objectively wrong, and is based on magical thinking even as it deconstructs itself**</span>.<span>&lt;/span&gt;</span> Some magical thinking processes that happen in psychotherapy, such as <span>[</span><span>transference to the psychologist</span><span>](</span><span>https://en.wikipedia.org/wiki/Transference#Transference_and_countertransference_during_psychotherapy</span><span>)</span>, are even intended to stay unmentioned to the patient in order to be utilized most effectively by the therapist!</code></pre></figure>

<h3 id="2-create-your-iframe-component">2. Create your iframe component</h3>

<p>This is most useful as a standardized component which can be used across the site, so we are going to take advantage of Jekyll’s templating features. Jekyll and other static site generators like Kirby and Zola support HTML “partials” or “includes” so that you can create reusable components.</p>

<p>In your <code>/_scss</code> or <code>/_sass</code> folder make a new file, <code>portal.scss</code>. I called it “portal” because it’s shorter than “transclusion” and less prone to spelling errors.</p>

<p>Here’s our component:</p>

<figure><pre><code data-lang="html"><span>&lt;div</span> <span>class=</span><span>"portal-container"</span><span>&gt;</span>
    <span>&lt;div</span> <span>class=</span><span>"portal-head"</span><span>&gt;</span>
        <span>&lt;div</span> <span>class=</span><span>"portal-backlink"</span> <span>&gt;</span>
            <span>&lt;div</span> <span>class=</span><span>"portal-title"</span><span>&gt;</span>From <span>&lt;span</span> <span>class=</span><span>"portal-text-title"</span><span>&gt;</span>{{ include.title }}<span>&lt;/span&gt;&lt;/div&gt;</span>
            <span>&lt;a</span> <span>href=</span><span>"{{ include.link }}"</span> <span>class=</span><span>"portal-arrow"</span><span>&gt;</span>Go to text <span>&lt;span</span> <span>class=</span><span>"right-arrow"</span><span>&gt;</span>→<span>&lt;/span&gt;&lt;/a&gt;</span>
        <span>&lt;/div&gt;</span>
    <span>&lt;/div&gt;</span>
    <span>&lt;div</span> <span>id=</span><span>"portal-parent-{{include.anchor}}"</span> <span>class=</span><span>"portal-parent"</span><span>&gt;</span>
        <span>&lt;div</span> <span>class=</span><span>"portal-parent-fader-top"</span><span>&gt;&lt;/div&gt;</span>
        <span>&lt;div</span> <span>class=</span><span>"portal-parent-fader-bottom"</span><span>&gt;&lt;/div&gt;</span>        
        <span>&lt;!-- We'll use Javascript to populate the iframe right here --&gt;</span>
    <span>&lt;/div&gt;</span>    
<span>&lt;/div&gt;</span></code></pre></figure>

<p>You’ll notice immediately that the iframe isn’t there yet. Like I mentioned above, we’re going to be populating it with Javascript.</p>

<p>You’ll also see that in various places we’re using <code>{{ include.___}}</code>. A cool thing about Jekyll includes its that it’s possible to define variables and pass them to our include, so we can create reusable components across our site. Dave Rupert has a <a href="https://daverupert.com/2017/07/jekyll-includes-are-cool/">nice blog post about this</a> called if you want to see more advanced examples!</p>

<h3 id="3-calling-the-component">3. Calling the component</h3>

<p>Anytime you want to pull this component into a blog post, all you have to do is <code>include</code> it in the markdown of another blog post, like this:</p>

<figure><pre><code data-lang="html">  {% include portal.html title="Notes On Comparative Psychology" link="/entries/notes-on-comparative-psychology/#mainstream-magic" anchor="emotional-deficit" %} </code></pre></figure>

<p>When you include it, you’ll need to pass in those three variables - title, link, and anchor, that fill in the includes above. If you’re following along now and making a build in Jekyll, you’ll see an empty, unstyled component with the link. So good so far!</p>

<h3 id="4-populating-with-javascript">4. Populating with Javascript</h3>

<p>This is a good time to address why we need Javascript. Web developers reading this are probably asking why we don’t simply put the full <code>/link#with-anchor</code> into the iframe src and be done with it. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://subpixel.space/entries/open-transclude/">http://subpixel.space/entries/open-transclude/</a></em></p>]]>
            </description>
            <link>http://subpixel.space/entries/open-transclude/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398014</guid>
            <pubDate>Mon, 07 Sep 2020 09:23:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Threat modelling case study: bicycles]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 98 (<a href="https://news.ycombinator.com/item?id=24397852">thread link</a>) | @calpaterson
<br/>
September 7, 2020 | http://calpaterson.com/bicycle-threat-model.html | <a href="https://web.archive.org/web/*/http://calpaterson.com/bicycle-threat-model.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <p>August 2020</p>
        <p id="article-description">How to avoid buying your bike again every 6-12
        months and tips for how to apply the same reasoning to other things, like
        computers</p>
        <hr>
        <figure>
            <img src="http://calpaterson.com/assets/solitary-wheel.jpeg" alt="a solitary wheel left behind after the rest of the bike was nicked">
            <figcaption>
                Rucksack Rupert strikes again
            </figcaption>
        </figure>
        <p>Some very commonly repeated advice on preventing someone from nicking your
        bike:</p>
        <blockquote>
            <p>Buy a good [~10% of bicycle value] lock, ideally one with a high
            "SoldSecure" rating and lock your bicycle somewhere inside the rear
            triangle and the rear wheel.</p>
        </blockquote>
        <p>I've seen this advice repeated in cycling magazines, in quality newspapers,
        sometimes even by the police and of course on internet forums.</p>
        <p>The above would imply that if you own a £400 bicycle (<a href="https://www.statista.com/statistics/395884/bicycle-average-prices-in-the-european-union-eu-by-country/">a
        typical price in the UK</a>) you'd buy a £40 lock and put it in the right
        place.</p>
        <p>However, it is a cold fact that a cordless angle grinder can defeat any
        bicycle lock, no matter how expensive (<a href="https://www.youtube.com/watch?v=pywN558dJaU&amp;t=198">see this video for a
        demonstration</a>). You can buy a used cordless angle grinder on eBay for less
        than £100. Even U-locks - traditionally thought to be the strongest type of
        lock - are opened in seconds with a sub-£100 angle grinder.</p>
        <p>There is other advice floating around of doubtful value, for example:</p>
        <blockquote>
            <p>Add your bicycle to a national register</p>
        </blockquote>
        <p>But cases where BikeRadar manage to reunite bicycles with their owners seem
        to be the exception rather than the rule. Probably this is because, as with
        cars, the first thing you do with a stolen bicycle is take it across a border
        to somewhere different.</p>
        <blockquote>
            <p>Lock your bicycle inside a secure building or place, away from sight</p>
        </blockquote>
        <p>This prevents opportunistic theft but if this space is shared with others
        (apartment blocks and offices) it in fact serves to increase the economies of
        scale for prepared thieves who break into your storage area late at night with
        a van. It's not uncommon for office bicycle stores (with many fancy, expensive
        bikes inside) to be emptied out completely overnight by professional
        thieves.</p>
        <h2>A threat model, by user persona</h2>
        <p>I think the advice above is poor because it doesn't come from a systematic
        consideration of the problem <em>from the point of view of thieves</em>.</p>
        <p>To come up with better advice requires a threat model, which is a piece of
        jargon for taking a holistic view of the danger posed by attackers. I think one
        of the simplest and most straightforward ways to do threat modelling is by
        <em>user persona</em>, whereby you consider each kind of attacker in turn,
        making some reasonable assumptions about their level of motivation and
        methods.</p>
        <p>As far as bicycle theft is concerned there are three basic types of
        thief.</p>
        <h3>"No-tools Nigel", the rank opportunist</h3>
        <p>Nigel has just his two hands and is simply looking for a ride home or maybe
        something he can sell to a friend for some quick cash.</p>
        <p>Nigel will steal any unlocked bicycle.</p>
        <p>Nigel is also able to take any bicycle parts that can be removed without
        tools. That means any quick-release wheels or thumbscrew saddles. In an urban
        area your parked bicycle may be passed by a Nigel as often as a few times an
        hour so anything that is not bolted down won't last very long.</p>
        <h3>"Rucksack Rupert", the thief with a few hand tools</h3>
        <p>Rupert has a small pair of shears; 4, 5 and 6mm Allen keys and a 15mm
        spanner for wheel nuts.</p>
        <p>Rupert will make his way through cable locks with his shears. If there is a
        valuable part that can be removed with hand tools he will take it. He is
        particularly keen on premium saddles and name brand wheels.</p>
        <h3>"Powertool Percy", the professional with a complete set of tools</h3>
        <p>Percy has a small collection of electric and air tools including an angle
        grinder as well as bolt-cutters and an air-jack. He has access to <a href="https://en.wikipedia.org/wiki/Fence_(criminal)">criminal fences</a> which he
        can use to sell stolen bicycles quickly. Percy often arrives in his van and
        this allows him to steal multiple bikes at once.</p>
        <p>No bicycle is safe from Percy. No lock can hold against his angle grinder.
        Often he finds if he's wearing a hi-vis jacket he can even get away with using
        his power tools in broad daylight. He's willing to chance that if the bicycle
        seems valuable enough.</p>
        <h2>Coming up with better advice based on Nigel, Rupert and Percy</h2>
        <p>In order to keep your bicycle safe you need to take steps against all three
        levels of imaginary thieves.</p>
        <p>"No-tools Nigel" will be warded off simply by:</p>
        <ul>
            <li>Locking your bicycle whenever you leave it - even if just for a
            minute</li>
            <li>Ensuring you leave nothing on your bicycle that can be removed without
            tools
                <ul>
                    <li>replace quick-release wheel skewers with bolts</li>
                    <li>take your lights with you when you park in public</li>
                    <li>make sure your saddle is not on a thumbscrew</li>
                </ul>
            </li>
        </ul>
        <p>"Rucksack Rupert" will be deterred by:</p>
        <ul>
            <li>Not using a cable lock!</li>
            <li>Making sure that nothing good can be removed from your bicycle with
            hand tools
                <ul>
                    <li>Lock both wheels <em>and the frame</em> to the bike stand -
                    don't rely on bolts</li>
                </ul>
            </li>
        </ul>
        <p>"Powertool Percy" will be kept at bay by:</p>
        <ul>
            <li>Nothing, save ensuring that your bicycle doesn't look valuable enough
            to be worth his time
                <ul>
                    <li>this probably means keeping its value down below a few hundred
                    pounds</li>
                </ul>
            </li>
        </ul>
        <h2>The virtue of the "bicycle shaped object"</h2>
        <p>Valuable bicycles (&gt;£1000) have an extremely short half-life in urban
        areas. The sad truth is that the Percys of the world are common enough and
        resourceful enough that a bicycle worth over a thousand pounds isn't really
        safe anywhere in a large town. <strong>This includes most e-bikes.</strong> You
        might notice that cycle couriers who have e-bikes tend to eat lunch while
        looking directly at their locked e-bike, so that it never goes out of their
        sight. Few people in other lines of work can do the same.</p>
        <p>If the tyres are inflated, my own commuter bicycle is probably worth £30 to
        the right buyer. My bicycle is so low-end that cycling snobs refer to it as a
        mere "bicycle shaped object". Rather selfishly I am glad that such snobs exist
        as having a lot of more valuable bicycles around provides me with good ambient
        security. No thief is going to bother cutting my locks when there is a
        Campagnolo on the next rack.</p>
        <p>One father I know had his primary-school-age daughter "decorate" his
        commuting bicycle with girly stickers and pink glitter. If anyone examines his
        bicycle closely he looks like a complete loon but I think his motivation is
        right: it's going to be much less appealing to steal when it's covered in Miffy
        stickers.</p>
        <h3>Insurance - not usually worth it</h3>
        <p>What about bicycle insurance? It's fairly expensive here in the UK, usually
        10-15% of the bicycle's value annually and insurers typically only pay out when
        the whole bicycle is taken (so if if your front wheel is nicked, you're on your
        own) and when you can demonstrate that it was locked to their standards. Often
        these standards require that it is locked up indoors which means you're
        chancing it whenever you park away from your home or office.</p>
        <h2>Lists of "best practices" vs having your own threat model</h2>
        <p>The same thing goes for securing your bicycle as for securing other things:
        pat, concrete pieces of security advice are something to treat with a bit of
        doubt.</p>
        <p>In bicycles the common mantra is "spend 10% on a lock" but in computing the
        mantras are slogans such as "use a strong password", "back up your important
        data" or "use encryption" but these can all be just as vapid.</p>
        <p>"Strong passwords!" as a slogan fails to address the fact that the average
        internet user has hundreds of logins for various sites (my own password manager
        has over 700 sites recorded). The majority of internet users decide on a single
        "strong password" and then use it everywhere. They are only a single bad
        sysadmin or javascript injection away from losing access to every account on
        every website they have.</p>
        <p>Backing up your important data is only an aid to your security if the backup
        is stored as securely as the original. Much user data is stolen or exposed
        through poorly secured backups on shared fileservers. A huge number of people
        have passport and utility bill scans in their Dropbox - again, behind the same
        email and password they use everywhere. Companies can be surprisingly sloppy
        with backups too: often dumped into cloud storage somewhere once before the Big
        Migration and never removed.</p>
        <p>Encryption is troublesome as it can give undue confidence that can backfire
        spectacularly: a quarter of a million American diplomatic cables were
        inadvertantly published in unredacted form when a Guardian journalist <a href="https://en.wikipedia.org/wiki/WikiLeaks:_Inside_Julian_Assange%27s_War_on_Secrecy">
        included the password for an widely-distributed encrypted file in his book</a>.
        Apparently he thought the file's password was somehow temporary. It wasn't.</p>
        <p>Instead of following such "best practices" it's much more intellectually
        robust to <strong>come up with your own threat model</strong> - then you can
        decide your own concrete steps instead of just following the security steps of
        others which might be inapplicable or even wrong.</p>
        <h2>Some hints on coming up with your own …</h2></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://calpaterson.com/bicycle-threat-model.html">http://calpaterson.com/bicycle-threat-model.html</a></em></p>]]>
            </description>
            <link>http://calpaterson.com/bicycle-threat-model.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397852</guid>
            <pubDate>Mon, 07 Sep 2020 08:58:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data analysis made easy: Text2Code for Jupyter notebook]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24397670">thread link</a>) | @dsr12
<br/>
September 7, 2020 | https://madewithml.com/projects/2283/data-analysis-made-easy-text2code-for-jupyter-notebook/ | <a href="https://web.archive.org/web/*/https://madewithml.com/projects/2283/data-analysis-made-easy-text2code-for-jupyter-notebook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

          <!-- Links -->
          <div>

            <!-- Details -->
            
              <!-- <h5>Details</h5> -->
              <div>
                <div>
                  <div>
                    
                      <p><img src="https://github.com/deepklarity/jupyter-text2code/blob/master/mopp-demo.gif?raw=true" alt=""></p>

<p>A ready-to-install jupyter extension which converts english queries into relevant code. Built as a proof of concept for the problem we personally face of <strong>forgetting less-used syntaxes of pandas and plotly libraries</strong> which is often used in Exploratory Data Analysis. This tool allows us to query in a generic language without having to remember the syntax.</p>

<p>Inspired by cool GPT-3 demos and not having the access to the API, here is an attempt by us to build a Text2Code extension using publicly available libraries. The approach isn't generative, but relies on identifying &amp; matching from a set of predefined <em>intents</em> and generating the relevant code by extracting relevant entities and inserting them in a template. Adding new intents and extending the functionality is easy once the pipeline is in place. </p>

<p>Technologies used:</p>

<ul>
<li>Universal Sentence Encoder</li>
<li>Spacy</li>
<li>Faiss</li>
<li>Jupyter extension</li>
</ul>

                    
                  </div>
                </div>
              </div>
            

            <!-- Comments -->
            
            
            <p><i></i>Don't forget to tag
              
              <a href="https://madewithml.com/@dk-crazydiv/" target="_blank">@dk-crazydiv</a>
              
              ,
              
              
              <a href="https://madewithml.com/@deepak-deepklarity/" target="_blank">@deepak-deepklarity</a>
              
               in
              your comment, otherwise they may not be notified.
            </p>
            

          </div>

        </div></div>]]>
            </description>
            <link>https://madewithml.com/projects/2283/data-analysis-made-easy-text2code-for-jupyter-notebook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397670</guid>
            <pubDate>Mon, 07 Sep 2020 08:32:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaffolding a complete React app with GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24397628">thread link</a>) | @jensneuse
<br/>
September 7, 2020 | https://wundergraph.com/blog/2020/09/06/scaffolding_react_app_with_graphql | <a href="https://web.archive.org/web/*/https://wundergraph.com/blog/2020/09/06/scaffolding_react_app_with_graphql">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Let us imagine that by writing a handful of GraphQL queries, it would be possible to build a fully functional React
application. For a TODO app, we could allow users to login, post, retrieve, update and complete tasks. In this post, I'll explain how WunderGraph could be leveraged to achieve such a thing, and what the implications are.</p><h2>What is WunderGraph?</h2><p>Before we dig in, let's have a quick overview of what WunderGraph is in order to fully understand the scenario.</p><p>WunderGraph is a GraphQL Engine that compiles Queries on the server, exposes them as persisted operations and then
generates smart clients to help you to consume them.</p><p>While GraphQL doesn't lose its dynamic character, this approach makes using GraphQL a lot safer and more performant.
Additionally, because Queries &amp; Mutations are persisted on the server by default, you are now uniquely able to use
directives in Operations.</p><p>A few example queries to illustrate:</p><div><div><div tabindex="0"><div><p><span>query</span><span> AllTasks</span><span>(</span><span>$email</span><span>:</span><span> String</span><span>!</span><span> </span><span>@fromClaim</span><span>(</span><span>name</span><span>:</span><span> </span><span>"email"</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  queryTask</span><span>(</span><span>filter</span><span>:</span><span> </span><span>{</span><span>email</span><span>:</span><span> </span><span>{</span><span>eq</span><span>:</span><span> </span><span>$email</span><span>}</span><span>}</span><span>)</span><span>{</span><span></span></p><p><span>    id</span></p><p><span>    title</span></p><p><span>    completed</span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><div><div><div tabindex="0"><div><p><span>mutation</span><span> AddTask</span><span>(</span><span>$title</span><span>:</span><span> String</span><span>!</span><span>,</span><span> </span><span>$email</span><span>:</span><span> String</span><span>!</span><span> </span><span>@fromClaim</span><span>(</span><span>name</span><span>:</span><span> </span><span>"email"</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  addTask</span><span>(</span><span>input</span><span>:</span><span> </span><span>[</span><span>{</span><span>title</span><span>:</span><span> </span><span>$title</span><span>,</span><span> </span><span>completed</span><span>:</span><span> </span><span>false</span><span>,</span><span> </span><span>email</span><span>:</span><span> </span><span>$email</span><span> </span><span>}</span><span>]</span><span>)</span><span>{</span><span></span></p><p><span>    task </span><span>{</span><span></span></p><p><span>      id</span></p><p><span>      title</span></p><p><span>      completed</span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><div><div><div tabindex="0"><div><p><span>mutation</span><span> SetTaskCompleted</span><span>(</span><span>$id</span><span>:</span><span> ID</span><span>!</span><span>,</span><span> </span><span>$completed</span><span>:</span><span> Boolean</span><span>!</span><span> </span><span>$email</span><span>:</span><span> String</span><span>!</span><span> </span><span>@fromClaim</span><span>(</span><span>name</span><span>:</span><span> </span><span>"email"</span><span>)</span><span>)</span><span>{</span><span></span></p><p><span>  updateTask</span><span>(</span><span>input</span><span>:</span><span> </span><span>{</span><span>filter</span><span>:</span><span> </span><span>{</span><span>id</span><span>:</span><span> </span><span>[</span><span>$id</span><span>]</span><span>,</span><span> </span><span>email</span><span>:</span><span> </span><span>{</span><span>eq</span><span>:</span><span> </span><span>$email</span><span>}</span><span>}</span><span> </span><span>set</span><span>:</span><span> </span><span>{</span><span>completed</span><span>:</span><span> </span><span>$completed</span><span>}</span><span> </span><span>}</span><span>)</span><span>{</span><span></span></p><p><span>    task </span><span>{</span><span></span></p><p><span>      id</span></p><p><span>      title</span></p><p><span>      completed</span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>Above, we have 3 operations:</p><p>AllTasks - Lists all tasks for a user by their email address
AddTask - To add a task for a user
SetTaskCompleted - To mark a task as complete</p><p>The above three Operations are quite standard with one slight exception, They contain a custom directive:
<code>@fromClaim(name: "email")</code>. This directive ensures that the variable <code>$email</code>, is always obtained from a JWT claim
<code>email</code>.</p><p>If you're not yet familiar with the concepts of WunderGraph, this is absolutely safe because only the server
(WunderGraph console) can define and persist an Operation.</p><p>This means that a user needs to be logged-in to interact with these queries &amp; only the logged in user can create, list
or update their own tasks.</p><p>Next, we use wundergen (our code generator) to generate an OpenID client that is preconfigured with our backend, all
type definitions for the GraphQL schema as well as React hooks for each Operation.</p><p>This process is pretty much straight forward as we just take all the configuration and run it through a template. We can
now just consume the TODO API as if it were just another function call.</p><h2>Why can't we scaffold the entire site?</h2><p>Well, at the moment this is just a concept, so I want to hear your feedback first before implementing it. Let's have a
look at some ideas on how we might implement this. As I said before we will only be writing GraphQL Operations so
let's revisit them:</p><div><div><div tabindex="0"><div><p><span>query</span><span> AllTasks</span><span>(</span><span>$email</span><span>:</span><span> String</span><span>!</span><span> </span><span>@fromClaim</span><span>(</span><span>name</span><span>:</span><span> </span><span>"email"</span><span>)</span><span>)</span><span></span></p><p><span>    </span><span>@ui</span><span>(</span><span>page</span><span>:</span><span> </span><span>"/tasks"</span><span>,</span><span> </span><span>component</span><span>:</span><span> </span><span>TABLE</span><span>)</span><span></span></p><p><span></span><span>{</span><span></span></p><p><span>  queryTask</span><span>(</span><span>filter</span><span>:</span><span> </span><span>{</span><span>email</span><span>:</span><span> </span><span>{</span><span>eq</span><span>:</span><span> </span><span>$email</span><span>}</span><span>}</span><span>)</span><span>{</span><span></span></p><p><span>    </span><span>...</span><span> </span><span>@ui</span><span>(</span><span>linkTo</span><span>:</span><span> </span><span>"/tasks/:id"</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>        id </span><span>@ui</span><span>(</span><span>columnName</span><span>:</span><span> </span><span>"ID"</span><span>)</span><span></span></p><p><span>        title </span><span>@ui</span><span>(</span><span>columnName</span><span>:</span><span> </span><span>"Title"</span><span>)</span><span></span></p><p><span>        completed </span><span>@ui</span><span>(</span><span>columnName</span><span>:</span><span> </span><span>"Completed"</span><span>)</span><span></span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>The <code>AllTasks</code> Query will generate a table component on the <code>/tasks</code> route.
Columns will have headers and each column will link to a task detail <code>/tasks/:id</code> page.</p><div><div><div tabindex="0"><div><p><span>mutation</span><span> AddTask</span><span>(</span><span></span></p><p><span>    </span><span>$title</span><span>:</span><span> String</span><span>!</span><span> </span><span>@ui</span><span>(</span><span>formType</span><span>:</span><span> </span><span>TEXT</span><span>,</span><span> </span><span>formName</span><span>:</span><span> </span><span>"Title"</span><span>)</span><span>,</span><span></span></p><p><span>    </span><span>$email</span><span>:</span><span> String</span><span>!</span><span> </span><span>@fromClaim</span><span>(</span><span>name</span><span>:</span><span> </span><span>"email"</span><span>)</span><span></span></p><p><span></span><span>)</span><span></span></p><p><span>    </span><span>@ui</span><span>(</span><span>page</span><span>:</span><span> </span><span>"/tasks/new"</span><span>,</span><span> </span><span>component</span><span>:</span><span> </span><span>FORM</span><span>)</span><span></span></p><p><span></span><span>{</span><span></span></p><p><span>  addTask</span><span>(</span><span>input</span><span>:</span><span> </span><span>[</span><span>{</span><span>title</span><span>:</span><span> </span><span>$title</span><span>,</span><span> </span><span>completed</span><span>:</span><span> </span><span>false</span><span>,</span><span> </span><span>email</span><span>:</span><span> </span><span>$email</span><span> </span><span>}</span><span>]</span><span>)</span><span>{</span><span></span></p><p><span>    task </span><span>{</span><span></span></p><p><span>      id</span></p><p><span>      title</span></p><p><span>      completed</span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>The <code>AddTask</code> Mutation will generate a form on the <code>/tasks/new</code> route.
The variable <code>$title</code> will be filled from the form.</p><div><div><div tabindex="0"><div><p><span>mutation</span><span> SetTaskCompleted</span><span>(</span><span></span></p><p><span>    </span><span>$id</span><span>:</span><span> ID</span><span>!</span><span>,</span><span></span></p><p><span>    </span><span>$completed</span><span>:</span><span> Boolean</span><span>!</span><span> </span><span>@ui</span><span>(</span><span>formType</span><span>:</span><span> </span><span>SWITCH</span><span>,</span><span> </span><span>formName</span><span>:</span><span> </span><span>"Completed"</span><span>)</span><span>,</span><span></span></p><p><span>    </span><span>$email</span><span>:</span><span> String</span><span>!</span><span> </span><span>@fromClaim</span><span>(</span><span>name</span><span>:</span><span> </span><span>"email"</span><span>)</span><span></span></p><p><span></span><span>)</span><span></span></p><p><span>    </span><span>@ui</span><span>(</span><span>page</span><span>:</span><span> </span><span>"/tasks/:id"</span><span>,</span><span> </span><span>component</span><span>:</span><span> </span><span>FLAT_VIEW</span><span>)</span><span></span></p><p><span></span><span>{</span><span></span></p><p><span>  updateTask</span><span>(</span><span>input</span><span>:</span><span> </span><span>{</span><span>filter</span><span>:</span><span> </span><span>{</span><span>id</span><span>:</span><span> </span><span>[</span><span>$id</span><span>]</span><span>,</span><span> </span><span>email</span><span>:</span><span> </span><span>{</span><span>eq</span><span>:</span><span> </span><span>$email</span><span>}</span><span>}</span><span> </span><span>set</span><span>:</span><span> </span><span>{</span><span>completed</span><span>:</span><span> </span><span>$completed</span><span>}</span><span> </span><span>}</span><span>)</span><span>{</span><span></span></p><p><span>    task </span><span>{</span><span></span></p><p><span>      id</span></p><p><span>      title</span></p><p><span>      completed</span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>The <code>SetTaskCompleted</code> Mutation will render a switch on the <code>/tasks/:id</code> page to update the task state.</p><h3>Let's discuss the pros and cons</h3><p>First, it's valid GraphQL syntax. Operations might get complex quite fast though.</p><p>We're definitely limited in what we could achieve with this. However, there will be use cases where customization is
not as important as the cost of development.</p><p>WunderGraph allows you to connect any possible datasource (at least that's the vision) so if you wanted to build
Dashboards or Admin panels, or even a simple contact page on top of your existing APIs this could be a very
convenient way to achieve it without code.</p><p>There might be quite a compelling use-case for rapid prototyping. Consider the flow: Deploy a CRUD GraphQL backend,
write a bunch of Operations and your app is ready to deploy. How much faster could it be? You could then customize
the scaffolded views &amp; forms as you saw fit.</p><p>Maybe the idea to directly introduce navigation between pages is a step too far. Maybe we could just generate
Components based on the Operations and let the user define Navigation manually?</p><p>But then, how would you go about customizing the pre-generated components without breaking when re-generating the code
after a change to the Operations?</p><p>Would multiple templates be useful so that users could choose between Material-UI or Bootstrap etc... Would that make
sense?</p><h3>What do you think?</h3><p>Finally, I think this is not yet ready for implementation. I need your feedback to see if this approach is useful for
you. Do you have ideas on how you could use this? Is there anything missing to make it work for you?</p><p>Please meet us on <a href="https://discord.gg/Jjmc8TC" target="_blank" rel="noopener noreferrer">discord</a>, <a href="https://github.com/wundergraph/community/issues/1" target="_blank" rel="noopener noreferrer">GitHub</a>
or in the comments and share your opinion so we can make the right decisions.</p></section></div>]]>
            </description>
            <link>https://wundergraph.com/blog/2020/09/06/scaffolding_react_app_with_graphql</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397628</guid>
            <pubDate>Mon, 07 Sep 2020 08:24:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Configuring WordPress as a Headless CMS with Next.js]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24397585">thread link</a>) | @kendalmintcode
<br/>
September 7, 2020 | https://robkendal.co.uk/blog/configuring-wordpress-as-a-headless-cms-with-next.js | <a href="https://web.archive.org/web/*/https://robkendal.co.uk/blog/configuring-wordpress-as-a-headless-cms-with-next.js">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/469bfa00bd6320832992e9fc5c2ed4a061f868ff/64a71/img/next-js-with-wordpress-part-1-blog-post.png" alt="Blog article on configuring WordPress as a headless CMS with Next.js"></p>
<p>Welcome to the first in a series of articles on getting started with Next.js. In this very first starting point, we'll be looking at creating a brand new Next.js project using the very helpful <code>create-next-app</code> tool.</p>
<p>From there, we'll be setting up WordPress as a headless CMS to manage our blog posts' content for us.</p>
<p>As we move through future articles in the series, we'll be covering a lot of moving parts to round out the entire process, including:</p>
<ul>
<li>Starting a blog using Next.js,</li>
<li>Using WordPress as a headless CMS with Next.js,</li>
<li>Creating an RSS feed for our static Next.js blog</li>
<li>Bundling, building and deploying our Next.js static blog with Netlify</li>
</ul>
<p>For this very article, however, we're just going to start with the basics of getting Next.js and our headless WordPress instance setup and ready to go.</p>
<p>So let's get to it!</p>
<h2>Why Next.js</h2>
<p><a href="https://nextjs.org/" title="Next.js from Vercel">Next.js</a> (made by a company called <a href="https://vercel.com/" title="Vercel static website hosting">Vercel</a> — formally Zeit) is a React-based framework for producing static-generated websites. It fills in some of the blanks of using React in its vanilla form, such as dynamic page routing, and it also allows developers a bevvy of choices of where to get their data from to power their static websites.</p>
<h3>Isn't it just like Gatsby</h3>
<p>It's very comparable to <a href="https://nextjs.org/" title="Next.js from Vercel">Gatsby</a> (which I also love) in many ways. Indeed Next.js and Gatsby share the same end goal: to connect data with a static-generator engine to produce a static website.</p>
<p>Personally, I prefer Next.js the more I use it. Whilst Gatsby offers a more mature eco-system with its plugins and community, Next.js offers a much less complex setup and often requires fewer plugins to achieve the same thing.</p>
<p>I'd recommend trying both and seeing which you prefer.</p>
<h2>Why use WordPress as a headless CMS</h2>
<p>WordPress is an often maligned platform, but it does power something close to 35% of the entire web. It's a hugely popular content management platform and most people have come across it, if not directly used it at some point during their time.</p>
<p>However, it does have a reputation for being quite clunky at times and it takes some work to produce a performant website on the front end.</p>
<p>One of the best reasons to consider WordPress as a headless CMS is that it solves the largest problem facing static-generated websites: editing content!</p>
<p>Sure, for most developers (me included) this isn't so much of a burden. For example, I use <a href="https://forestry.io/" title="Forestry.io markdown CMS">Forestry.io</a> as a markdown editor/CMS to edit the markdown files that power this very site directly in my GitHub repo.</p>
<p>Other developers may choose to just edit HTML directly, and that's fine and dandy.</p>
<p>But what about 'normal' users, marketers, content editors, <em>non-developers</em>?! Editing markdown or HTML files is a bit beyond their needs or, perhaps, their skillsets.</p>
<p>By using WordPress as a headless CMS with Next.js, it's win win win. Website visitors get performant, accessible websites. Developers get a great developer experience and aren't hampered by the very opinionated and clunky PHP development required for WordPress. And content producers and site owners still get to use their favourite content management tool, WordPress, to handle the editing process!</p>
<p><a href="https://twitter.com/kendalmintcode"><img src="https://d33wubrfki0l68.cloudfront.net/299aa0eb90b8aa416e6c8dc6b7bf85e6c7f1d561/b0f6e/img/twitter_cta.png" alt="Follow me on Twitter @kendalmintcode"></a></p>
<h2>Step 1, getting WordPress ready for Next.js</h2>
<p>Installing and getting a WordPress instance going is beyond the scope of this article and there are many places to help get you started with that.</p>
<p>If you're looking for a recommendation then check out <a href="https://aws.amazon.com/lightsail/" title="Amazon Lightsail hosting">Amazon's Lightsail</a>, or the AWS platform in general as there are often free tiers available, especially whilst you're just getting started.</p>
<p>What we're bothered about here is adding some necessary bits and pieces to a WordPress website to turn it into a headless CMS for Next.js to access.</p>
<p>So, assuming you already have a WordPress instance set up, let's move on.</p>
<p><img src="https://d33wubrfki0l68.cloudfront.net/e8f504d6e8834e2f39467d5d570671a22ab328f0/15fa3/img/nextjs-demo-robkendal.jpg" alt="Demo WordPress website from Rob Kendal"></p>
<p>(PS - if you want to use my demo site, which I'm using in this article, then you can check it out here - <a href="http://demo.robkendal.co.uk/" title="Demo WordPress website for linking to Next.js">http://demo.robkendal.co.uk/</a></p>
<h3>Installing WPGraphQL (and plugins)</h3>
<p>Out of the box you can use the WordPress REST API to fetch data and so on, but we're going to be using GraphQL to do the heavy lifting.</p>
<p>This does mean we have to install a few plugins, however, before we can start accessing our data via Next.js.</p>
<p>So, we'll be heading over to <a href="https://www.wpgraphql.com/" title="WPGraphQL plugin">https://www.wpgraphql.com/</a> and we'll want to install the following plugins:</p>
<ul>
<li><a href="https://github.com/wp-graphql/wp-graphql/releases" title="WPGraphQL plugin">WPGraphQL main plugin</a></li>
<li><a href="https://github.com/wp-graphql/wp-graphql-acf" title="WPGraphQL for ACF plugin">WPGraphQL for ACF</a> (advanced custom fields)</li>
<li><a href="https://github.com/wp-graphql/wp-graphiql" title="WPGraphiQL plugin">WPGraphiQL</a> - a visual query builder/explorer for GraphQL</li>
</ul>
<p><strong>Note:</strong> <em>with the WPGraphQL stuff, you'll have to visit those links, download the Source Code (zip) as zip files and upload them to WordPress manually via the Admin Menu &gt; Plugins &gt; Add New &gt; Upload dialog.</em></p>
<p><img src="https://d33wubrfki0l68.cloudfront.net/20fccd08ff42eab3a803c36749a5dd5476913b33/abf82/img/nextjs-article-wpgraphql.jpg" alt="WPGraphQL releases plugin download page"></p>
<p>The reason for favouring GraphQL is that it's faster than the REST API and GraphQL gives us the power and flexibility to return only the data we need. Using the WPGraphiQL plugins also allows us to both build our queries directly inside of our WordPress instance before moving them into Next.js</p>
<blockquote>
<p>This is hugely important as we can see the output of the queries, testing and tweaking them as we go, <em>before</em> we have to blindly add them to our local dev instance.</p>
</blockquote>
<p>We'll also need once last plugin, <a href="https://www.advancedcustomfields.com/" title="WordPress Advanced Custom Fields (ACF) plugin">Advanced Custom Fields</a> (ACF). This will allow us to add extra fields to our posts or pages to extend their content capabilities.</p>
<h3>Adding custom fields to posts</h3>
<p>Next, and this part is optional if you don't want/need custom fields on your posts, we'll set up a few custom fields using ACF and make sure they're enabled for WPGraphQL, <strong>otherwise they won't show up</strong>.</p>
<p>Head over to your WordPress admin console and then to Custom Fields &gt; Field Groups and make a new one, calling it whatever you like.</p>
<p>For my site, I called the Field Group 'Extra Post Info'. Then, I added three fields:</p>
<ol>
<li>Author Excerpt - a text area field</li>
<li>Preview Image - a simple image selection field</li>
<li>Thumbnail Image - as above</li>
</ol>
<p><img src="https://d33wubrfki0l68.cloudfront.net/2e1688bc8fe3a58371879f35d13803da2b0b4138/fc5ae/img/nextjs-article-acf-setup.jpg" alt="WordPress ACF fields setup"></p>
<p>You can add whatever fields you wish and name them to suit your needs.</p>
<p>From here, scroll all the way to the bottom of this page and enable the WPGraphQL settings as follows:</p>
<ol>
<li>Make sure <code>Show in GraphQL</code> is set to 'Yes'</li>
<li>For <code>GraphQL Field Name</code> set this to a meaningful and descriptive name for your extra fields. This will be the name we use to reference the extra fields in GraphQL. Here, I named mine <code>extraPostInfo</code></li>
</ol>
<p><img src="https://d33wubrfki0l68.cloudfront.net/cb9f2bf0cdbde1947b3f8fb306f0372b14404522/b0110/img/nextja-article-ac-graphql-settins.jpg" alt="WPGraphQL settings to enable custom fields to show up"></p>
<p>And that's that. One final thing is to populate a few dummy posts in the Posts section of the admin menu. Just create a handful of new posts and add in whatever content you wish (I find Lorem Ipsum works just fine here).</p>
<h3>Viewing our Posts in GraphQL</h3>
<p>Having installed all the necessary WPGraphQL posts, added some extra fields, and made sure those were added to the GraphQL schema, with some dummy Post content in place, we can go check out the Posts data via the WPGraphiQL explorer.</p>
<p>Head over to the GraphiQL menu item in your WordPress admin console.</p>
<p>Now for the real magic! GraphiQL is a visual query builder that lets you simply expand and toggle data fields on the left hand side, build a query in the middle using those data fields, and execute that query to see what data is returned.</p>
<p>Very powerful stuff, I'm sure you'll agree. Now, the in's and out's of GraphQL language and the GraphiQL tool are entire articles and courses in themselves, but you can find out more from the <a href="https://graphql.org/" title="Official GraphQL website and documentation">official GraphQL website</a>.</p>
<p>For our purposes, you can see below that I've expanded various paths on the tree menu, starting with <code>posts</code> and this has automatically built me a query in the centre editor panel. When I pressed the big play button, the query is executed and the results shown in the rightmost panel.</p>
<p><img src="https://d33wubrfki0l68.cloudfront.net/d7b87cf1fd0717aa70ffdf2ac855c7351e9db3be/6a9ed/img/nextjs-article-graphiql-query.png" alt="GraphiQL query data builder"></p>
<p>The query built looks like this:</p>
<pre><code>    query MyQuery {
      posts {
        edges {
          node {
            id
            date
            title
            slug
            featuredImage {
              node {
                mediaItemUrl
              }
            }
            extraPostInfo {
              authorExcerpt
            }
          }
        }
      }
    }
</code></pre>
<p>And this query returns something along the lines of this data:</p>
<pre><code>{
  "data": {
    "posts": {
      "edges": [
        {
          "node": {
            "id": "cG9zdDoyOA==",
            "date": "2020-07-09T07:18:42",
            "title": "A third post with an interesting name",
            "slug": "a-third-post-with-an-interesting-name",
            "featuredImage": null,
            "extraPostInfo": {
              "authorExcerpt": "I'm a thing. I usually try to keep my sadness pent up inside where it can fester quietly as a mental illness. Leela, are you alright? You got wanged on the head. Okay, I like a challenge. Robot 1-X, save my friends! And Zoidberg!"
            }
          }
        },
        {
          "node": {
            "id": "cG9zdDoyNQ==",
            "date": "2020-07-09T07:17:19",
            "title": "Another awesome post with a really long title",
            "slug": "another-awesome-post-with-a-really-long-title",
            "featuredImage": null,
            "extraPostInfo": {
              "authorExcerpt": "It's okay, Bender. I like cooking too. Why would I want to know that? Fry, we have a crate to deliver. You guys aren't Santa! You're not even robots. How dare you lie in front of Jesus? My fellow Earthicans, as I have explained in my book 'Earth in the Balance'', and the much more popular ''Harry Potter and the Balance of Earth', we need to defend our planet against pollution. Also dark wizards."
            }
          }
        },
        ...others
      ]
    }
  }
}
</code></pre>
<p>And with that, we have our WordPress instance set up as a headless CMS with the Posts data all ready to go in a nice, neat GraphQL query.</p>
<h2>Step 2, creating a Next.js project</h2>
<p>The final step in the project setup process to use WordPress as a headless CMS using Next.js is the most important part: Next.js!</p>
<p>As it happens, <a href="https://nextjs.org/learn/basics/create-nextjs-app/setup" title="Next.js Create Next App tool documentation">Next.js has a project create tool</a> called <code>create-next-app</code> which will create us a bootstrapped Next.js app with the barebones of configuration ready to go.</p>
<p>Much like React's own <code>create-react-app</code> tool, the <code>create-next-app</code> tool is run from the command line and creates a directory with all the necessary project files in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://robkendal.co.uk/blog/configuring-wordpress-as-a-headless-cms-with-next.js">https://robkendal.co.uk/blog/configuring-wordpress-as-a-headless-cms-with-next.js</a></em></p>]]>
            </description>
            <link>https://robkendal.co.uk/blog/configuring-wordpress-as-a-headless-cms-with-next.js</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397585</guid>
            <pubDate>Mon, 07 Sep 2020 08:15:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Post-Open Source]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24397552">thread link</a>) | @luu
<br/>
September 7, 2020 | https://www.boringcactus.com/2020/08/13/post-open-source.html | <a href="https://web.archive.org/web/*/https://www.boringcactus.com/2020/08/13/post-open-source.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <p>i’m writing this like a day after <a href="https://www.fastcompany.com/90539632/mozilla-vows-mdn-isnt-going-anywhere-as-layoffs-cause-panic-among-developers">big mozilla layoffs</a> that included a lot of people working on cool and important shit.
the consensus i’m seeing is that it reflects mozilla’s search for profit over impact, mismanagement, and disproportionate executive compensation.
this is taking place in a larger trend of corporatization of open source over the past several years, an ongoing open source sustainability crisis, and of course COVID-19, the all-consuming crisis that makes all our other crises worse.
all of this was summed up most concisely by <a href="https://twitter.com/zkat__/status/1293626135142477825">Kat Marchán</a>:</p>

<blockquote>
  <p>Imo, open source as a community endeavor is falling apart right before our eyes, and being replaced by open source as Big Corp entrenchment strategy.</p>

  <p>I mean it’s been happening for a while, but seeing Mozilla sinking like this is just driving the point home for me.</p>

  <p>FOSS is dead</p>
</blockquote>

<p>how did we get here?
where even are we?
what happens next?</p>

<p>i am incredibly unqualified to answer any of this - i didn’t show up until right around the peak of SourceForge, i wasn’t there for most of this - but i’m not gonna let that stop me.</p>

<h2 id="names">names</h2>

<p>to start this funeral service for FOSS, we have to unpack the term itself.
“free and open source software” as a term already contains multitudes.
on one hand, “free software”, an explicitly political movement with a decidedly anti-charismatic leader.
on the other hand, “open source software”, defanged and corporate-friendly by design.
the free software people (correctly) criticize “open source” as milquetoast centrism.
the open source people (correctly) criticize “free software” as stubborn idealism fighting tooth and nail to reject the real world as it actually exists.
they have as much in common as leftists and liberals (but they’re more prepared to work together), and although their short-term goals were similar enough that it made sense to lump them together (hence the cooperation), now that the movement is dead i think there’s more to gain from considering them separately.
most software licenses that i’m going to bring up technically qualify as both, but they’re popular with one or the other, so i’ll refer to “free software licenses” and “open source licenses” as licenses that are more directly tied to those movements, even though any given license likely meets both definitions.</p>

<p>i’d say free software died a while ago, and open source went horribly right.</p>

<h2 id="freedom">freedom</h2>

<p>the free software movement, for all its faults, has always known <a href="https://www.gnu.org/philosophy/free-sw.html.en">what it’s about</a>:</p>

<blockquote>
  <ol>
    <li>The freedom to run the program for any purpose.</li>
    <li>The freedom to study how the program works, and change it to make it do what you wish.</li>
    <li>The freedom to redistribute and make copies so you can help your neighbour.</li>
    <li>The freedom to improve the program, and release your improvements (and modified versions in general) to the public, so that the whole community benefits.</li>
  </ol>
</blockquote>

<p>it’s concise, it’s understandable, and it’s… kinda useless.
this point was <a href="https://lu.is/blog/2016/03/23/free-as-in-my-libreplanet-2016-talk/">raised better by actual lawyer Luis Villa</a> (Karl Marx slander notwithstanding), but those freedoms don’t actually mean shit to the average end user.
only programmers care if they have access to the source code, and most people aren’t programmers.
and i <em>am</em> a programmer, and i don’t give a shit.
the freedom to not think about my operating system and just get work done overrules all of those for me, so i use windows.
like, yeah, those things are all in principle nice to have, and between two otherwise equally good programs i’d take the free one.
but they’re really fuckin specific things, and even if i have the freedom to do them i’m not likely to have the ability or desire to do them, so there’s no good reason for me as a user to use software that’s worse in other ways because it gives me freedoms i don’t need.</p>

<p>the free software movement is explicitly political, but its politics suck.
it’s a movement by and for ideological diehards but the ideology is extremely esoteric.
theirs was a losing battle from day one.
so what was it that actually killed them?
i think in a very real way it was the GPLv3.</p>

<h2 id="losing">losing</h2>

<p>the flagship projects of the free software movement are probably Linux and the GNU pile of tools.
the Linux kernel being released under a free software license doesn’t directly create more free software, though, since even things that tie closely to the kernel aren’t obligated to also be free software, and of course user-level applications can have whatever license they want.
and also most of the people using Linux right now are using it by accident, distributed as ChromeOS or Android, neither of which is free software.
so Linux is a win for the free software movement but a useless one.</p>

<p>the GNU userland tools are, for the most part, even more underwhelming.
it may be technically more accurate to call it GNU/Linux, but the only time i remember my linux userland tools are GNU or free software at all is when there’s <a href="https://twitter.com/boring_cactus/status/1166408436386430976">some weird inconsistency between a GNU tool and its BSD equivalent</a>, and that’s not exactly ideal.
gcc had, as far as i can tell, been basically <em>the</em> C compiler for a while, if you weren’t stuck with MSVC or something worse.
the free software movement were stubborn ideologues with weird priorities, but they still had one big technical advantage.
then the GPLv3 happened.</p>

<p>the GPLv2 was pretty popular at the time, but there were a couple notable loopholes some big corporations had been taking advantage of, which the free software people wanted to close.
a whole bunch of people thought the GPLv2 was fine the way it was, though - closing the loopholes as aggressively as the GPLv3 did cut off some justifiable security measures, and some people said that it could do more harm than good.
the linux kernel, along with a lot more stuff, declared it was sticking with the GPLv2 and not moving to the GPLv3.
when your movement says “here is the new version of The Right Way To Do Things” and several of your largest adherents say “nah fuck you we’re going with the old version” that is not a good sign.
around the same time, free software organizations were starting to successfully sue companies who were using free software but not complying with the license.
so big companies, like Apple, saw new restrictions coming in at the same time as more aggressive enforcement, and said “well shit, we want to base our software on these handy convenient tools like GCC but we can’t use GPLv3 software while keeping our hardware and software as locked together as we’d like.”
so they started pouring money into a new C compiler, LLVM, that was instead open source.</p>

<p>and LLVM became at least as good as GCC, and a less risky decision for big companies, and easier to use to build new languages.
so the free software movement’s last technical advantage was gone.
its social advantages also kinda went up in flames with the GPLv3, too: the software that was the foundation for the GPL enforcement lawsuits stuck with the GPLv2.
the discourse over that decision was so nasty that the lead maintainer (Rob Landley; he’ll come up later) started an identical project which he wound up relicensing under an open source license because the lawsuits had completely backfired: instead of complying with the terms of the GPL, companies were just avoiding GPL software.</p>

<p>the free software movement, in the end, burned itself out, by fighting for a tiny crumb of success and then turning around and lighting that success on fire.
the death of free software tells us that we can’t use a license to trick corporations into sharing our values: they want to profit, and if good software has a license that puts a limit on how much they can do that, they’ll put more resources into writing their own alternative than they would spend complying with the license in the first place.</p>

<h2 id="openness">openness</h2>

<p>the open source movement manages to share the same short term goals as the free software movement but be bad in almost entirely disjoint ways.
the <a href="https://opensource.org/about">mission of the Open Source Initiative</a> says</p>

<blockquote>
  <p>Open source enables a development method for software that harnesses the power of distributed peer review and transparency of process.
The promise of open source is higher quality, better reliability, greater flexibility, lower cost, and an end to predatory vendor lock-in.</p>
</blockquote>

<p>this is so profoundly different from the free software definition that it’s almost comical.
where free software says “we value freedom, which we define in these ways,” open source says “your code will get better.”
the free software movement was prepared to start fights with corporations that used their work but didn’t play by their rules.
the open source movement was invented to be a friendly, apolitical, pro-corporate alternative to the free software movement.</p>

<p>the contrast between “use free software because it preserves your freedom” and “use open source software because it’s better” is profound and honestly a little disappointing to revisit this explicitly.
free software preserves freedoms i don’t need or care about as a user, but it does at least do that.
open source software is frequently not in fact better than closed source alternatives, and “use open source software because on rare occasions it manages to be almost as good” is an even more underwhelming sales pitch than anything free software can give.</p>

<p>where free software is misguided and quixotic, open source is spineless and centrist.
and as tends to happen with spineless centrism, it has eaten the world.</p>

<h2 id="winning">winning</h2>

<p>if there’s anything corporations love more than rewriting software so it lets them make all the money they can dream of, it’s letting other people do that work for them.
it took a while to take off, because the conservative approach of “keep things closed source” was pretty solidly entrenched in a lot of places, but now even the once conservative holdouts have accepted the gospel of centrism.
corporations have little to nothing to lose by publishing existing source code, and can gain all sorts of unpaid volunteer labor.
if they start a new internal project, important enough that they’re …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.boringcactus.com/2020/08/13/post-open-source.html">https://www.boringcactus.com/2020/08/13/post-open-source.html</a></em></p>]]>
            </description>
            <link>https://www.boringcactus.com/2020/08/13/post-open-source.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397552</guid>
            <pubDate>Mon, 07 Sep 2020 08:06:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SEO Doesn't Matter Anymore]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24397541">thread link</a>) | @puggo
<br/>
September 7, 2020 | https://hawaiigentech.com/post/no-more-seo/ | <a href="https://web.archive.org/web/*/https://hawaiigentech.com/post/no-more-seo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><img src="https://hawaiigentech.com/post/no-more-seo/seo-joke.png" alt="Seo is a Joke"></p>
<hr>
<h2 id="seo-search-engine-optimization-is-the-art-of-enticing-machines-so-as-to-entice-people">SEO (Search Engine Optimization): is the art of enticing machines so as to entice people.</h2>
<p><em>But it’s no longer needed.</em></p>
<p>Granted, the usual stuff applies: Fast page load, responsiveness for mobile devices, spelling and grammer…still apply.</p>
<p><em><strong>But gone are the days</strong></em> of the subtler forms of SEO, where you cared about keyword density, backlinks, and similar things.</p>
<hr>
<h2 id="the-algorithms-and-ai-are-more-advanced-now">The Algorithms and AI Are More Advanced Now</h2>
<p>The algorithms are practically sentient…</p>
<p><img src="https://hawaiigentech.com/post/no-more-seo/webcrawler.jpg" alt="The Algorithms Are Practically Sentient"></p>
<p>At this time, it is now better for you to write content like a human, with personality, and natural.</p>
<p>If you know a subject well, Google especially can sense that. If you are faking, google can sense that too.</p>
<p>Bing search engine likely has comparable talents. Other <em>search engines don’t even matter anymore</em>, as they (such as Duckduckgo and Yahoo) actually source their results from Bing.</p>
<p>Whereas domain authority was previously calculated by backlinks and social network cues, the algos can now sense from your writing alone, along with a multitude of other cues…if you are who you say you are.</p>
<p>On this subject, here is some light reading for you… <a href="https://web.archive.org/web/20200831214216/https://static.googleusercontent.com/media/guidelines.raterhub.com/en//searchqualityevaluatorguidelines.pdf">https://web.archive.org/web/20200831214216/https://static.googleusercontent.com/media/guidelines.raterhub.com/en//searchqualityevaluatorguidelines.pdf</a> (E-A-T)</p>
<hr>
<h3 id="backlinks-hardly-matter">Backlinks… Hardly Matter</h3>
<p>Before, in SEO, you had the burden of building backlinks. Backlinks helped search engines understand the context of your site and it’s possible popularity and authority.</p>
<p>This, too, could be farmed artificially.</p>
<p>It doesn’t matter now.</p>
<hr>
<h3 id="keyword-density-dont-need-it">Keyword Density? Don't Need It</h3>
<p>If I were to speak, talk, express myself to you in a awkward, silly, repetitive, redundant manner, you might not like, appreciate, understand me very well.</p>
<p>If I spoke to you with no less than 1000 words, you might be annoyed. You would, most likely, be very, annoyed, angered, frustrated, sad.</p>
<p>You get it? The Algorithms practically have emotions now. They don’t want to hear you talk like that either.</p>
<p>They don’t like SEO tricks.</p>
<p>Don’t use them.</p>
<hr>

<p>Unless you really are a popular person, don’t bother. Sure, social network traffic is great. But artificial popularity on a social network (ie, an army of admiring sock puppets talking about you… doesn’t help anymore). Search engines know who’s real and who’s not (mostly).</p>
<hr>
<h2 id="finally-you-can-be-you">Finally, You Can Be You</h2>
<p>Now that search engines are smarter, you are officially relieved of the burden of SEO. You can be your best you, and you will now thrive for it.</p>
<p>The fakers…they will sink in results. Why? Because nobody likes a cheat, fraud, fake, keyword stuffer, SEO “Expert”.</p>
<hr>
<h3 id="ohjust-one-more-thing">Oh…Just One More Thing</h3>
<p>Don’t ever pay an “SEO Expert” again. He’s not applicable anymore.</p>

    </div></div>]]>
            </description>
            <link>https://hawaiigentech.com/post/no-more-seo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397541</guid>
            <pubDate>Mon, 07 Sep 2020 08:04:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pragmatic MVU with React and TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24397443">thread link</a>) | @asp_net
<br/>
September 7, 2020 | https://thomasbandt.com/model-view-update-with-react-and-typescript | <a href="https://web.archive.org/web/*/https://thomasbandt.com/model-view-update-with-react-and-typescript">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
    
    <p>With the introduction of hooks, React got some compelling new instruments – including useReducer, which can be used to implement Model-View-Update within a React component.</p>
    
    <p>While probably intended to "hook up" developers experienced in working with Redux, <a href="https://reactjs.org/docs/hooks-reference.html#usereducer">useReducer</a> at the same time opens the door for implementing The Elm Architecture, aka Model-View-Update (MVU) quickly and pragmatically.</p>
<h2>The Core Idea</h2>
<p>If you don't know what MVU is and want to learn more first, check out my article on <a href="https://thomasbandt.com/model-view-update">how it works</a>. If you are impatient, I can offer you a shortcut:</p>
<p><img src="https://thomasbandt.com/upload/mvu.png" alt="MVU"></p>
<p>From my perspective, the whole thing's essential idea is to make changes to the state explicit and easy to reason about. That is achieved through:</p>
<ol>
<li>Data is flowing uni-directionally.</li>
<li>Having a view that is a function of the state (model).</li>
<li>Having an update function that is the only place where state changes.</li>
<li>Communicating through messages.</li>
</ol>
<p>It is fair to argue that 1. and 2. are already core principles of React itself. However, <code>useReducer</code> adds 3. and 4. to the game.</p>
<h2>A Practical Example</h2>
<p>Without further ado, let's go through it based on a little example, a login form.</p>
<h3>What Are The Requirements?</h3>
<ol>
<li>There are a user name and a password field, and a submit button.</li>
<li>The button must only be enabled when the user name and password are provided.</li>
<li>When the button is clicked, some work shall be done (e.g., validation/network request).</li>
</ol>
<h3>The State</h3>
<pre><code>interface State {
  userName: string;
  password: string;
  isValid: boolean;
}

const initialState: State = {
  userName: "",
  password: "",
  isValid: false,
};
</code></pre>
<p>That's as unspectacular as necessary, as the core information we are working with is defined at a central place. So whenever you want to access the user name or password, you don't need to go to the form itself.</p>
<h3>The Messages</h3>
<pre><code>type UserNameChangedMsg = {
  type: "UserNameChangedMsg";
  userName: string;
};

type PasswordChangedMsg = {
  type: "PasswordChangedMsg";
  password: string;
};

type Msg = UserNameChangedMsg | PasswordChangedMsg;
</code></pre>
<p>While the definition of messages is not as lean as in other languages (in F#, this would have been a three-liner), TypeScript, fortunately, supports <a href="https://mariusschulz.com/articles/tagged-union-types-in-typescript">Tagged Union Types</a>, which do the job.</p>
<h3>The View</h3>
<pre><code>export default function () {
  const [state, dispatch] = useReducer(update, initialState);

  return (
    &lt;div&gt;
      &lt;input
        type="text"
        placeholder="User name"
        defaultValue={state.userName}
        onChange={(e) =&gt;
          dispatch({ type: "UserNameChangedMsg", userName: e.target.value })
        }
      /&gt;
      &lt;input
        type="password"
        placeholder="Password"
        defaultValue={state.password}
        onChange={(e) =&gt;
          dispatch({ type: "PasswordChangedMsg", password: e.target.value })
        }
      /&gt;
      &lt;button disabled={!state.isValid} onClick={() =&gt; signIn(state)}&gt;
        Sign in
      &lt;/button&gt;
    &lt;/div&gt;
  );
}
</code></pre>
<p>Now things are getting more interesting. Let's go through it:</p>
<pre><code>const [state, dispatch] = useReducer(update, initialState);
</code></pre>
<p>There it is, our <code>useReducer</code> hook. Calling it returns two things: The current <code>state</code> and a <code>dispatch</code> function.</p>
<p>The <code>state</code> can be used to render the view depending on its properties. For example, as required, the sign-in button is only enabled when <code>state.isValid</code> is set to <code>true</code>.</p>
<p>The <code>dispatch</code> function is used to "fire" messages: Whenever the user changes the user name or the password, the corresponding message is being dispatched. Note that it contains the element's value as its payload, for example, in the case of the password:</p>
<pre><code>onChange={(e) =&gt;
  dispatch({ type: "PasswordChangedMsg", password: e.target.value })
}
</code></pre>
<p>Now, two questions come up: What happens when a message is being dispatched? And how does <code>state.isValid</code> ever become true?</p>
<h3>The Update Function</h3>
<pre><code>function validate(state: State): boolean {
  return state.userName.length &gt; 0 &amp;&amp; state.password.length &gt; 0;
}

function update(state: State, msg: Msg) {
  switch (msg.type) {
    case "UserNameChangedMsg": {
      const newState = { ...state, userName: msg.userName };
      return { ...newState, isValid: validate(newState) };
    }
    case "PasswordChangedMsg": {
      const newState = { ...state, password: msg.password };
      return { ...newState, isValid: validate(newState) };
    }
  }
  return assertUnreachable(msg);
}
</code></pre>
<p>Here it is, the U of MVU, our <code>update</code> function. Its signature is defined by the <code>useReducer</code> hook: It accepts the latest known state and a message it is supposed to process.</p>
<p>Based on some magic of the TypeScript compiler, it is possible to switch through the messages based on the discriminant property type, which all of them provide.</p>
<p>Depending on the message type, we now know what should be changed, <code>userName</code> or <code>password</code>, and so we do. We also set the <code>isValid</code> property, which becomes only true when both the user name and the password contain at least one character.</p>
<p>Side note: The whole thing is exhaustive, which is achieved by the little helper function <code>assertUnreachable()</code>:</p>
<pre><code>function assertUnreachable(x: never): never {
  throw new Error("Didn't expect to get here");
}
</code></pre>
<p>Whenever our tagged union <code>Msg</code> gets a new case, the compiler will notice, and the build will fail â€“ until we add that case to the switch.</p>
<h3>Commands?</h3>
<p>If you already know about MVU, you might have noticed that there are no commands yet. And there won't be any â€“ the <code>useReducer</code> hook doesn't know about the concept of commands. That's why I call it a pragmatic approach.</p>
<p>But that's not the end of the world as it is possible to work around it for most cases. For example, when our sign-in button is enabled and gets clicked, we call another function and pass the current state:</p>
<pre><code>function signIn(state: State) {
  // Do something here ...
}
</code></pre>
<p>We could validate the credentials, make network requests, or do whatever we like. And if the result would be a change of our state, we could pass the dispatch function and dispatch a message from within here.</p>
<h2>Conclusion</h2>
<p>The example may seem relatively trivial, even too insignificant to use that MVU approach. But if you chose to go down that route, it will come with all the benefits listed above â€“ even for such a relatively simple component.</p>
<p>And once you follow the pattern in more and more components of your application, you will notice that behavior reasoning will become much more straightforward.</p>
<p>PS: See <a href="https://gist.github.com/aspnetde/93bf9cbbac76b7c36b59015ec47cabdf">here</a> for the complete code of the component.</p>

    
</article>




        </div></div>]]>
            </description>
            <link>https://thomasbandt.com/model-view-update-with-react-and-typescript</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397443</guid>
            <pubDate>Mon, 07 Sep 2020 07:45:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Create a Bad Name for Your Startup]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24397428">thread link</a>) | @johannesippen
<br/>
September 7, 2020 | https://toolbox.humandeluxe.com/bad-business-name/ | <a href="https://web.archive.org/web/*/https://toolbox.humandeluxe.com/bad-business-name/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  



  <p><img src="https://d33wubrfki0l68.cloudfront.net/014b39cd15c61584a080d634e68a0861129d628b/1a9e4/uploads/bad-names.jpg" alt=""></p>

<p>In our <a href="https://toolbox.humandeluxe.com/good-business-name/">last article</a> of the Business Naming series, you learned that good company names will make you SMILE – and which successful brands apply these criterias. Now, just applying the five SMILE-criterias to a name is not enough: A good name does not only make you smile, it will also not be a head-SCRATCHer.</p>

<p>So, in this article, you will learn what makes a bad company name – so you can avoid these pitfalls with your own brand. There are 7 deal-breaking points to be aware of, following the handy acronym SCRATCH:</p>

<p><strong>Spelling-challenged</strong>: A name isn’t spelled how it sounds like. in the 2000s, a lot of Tech startups did that to secure domains and look unique. The issue: Just from hearing the name, you couldn’t replicate and spell it correctly, which causes trouble when remembering the the brand. In name brainstorming meetings, this is usually the first idea: “Let’s take a word and spell it differently” – please don’t do that. Famous brands that you know (and probably misspelled at first) include Flickr, Lyft or Houzz. Pro tipp: Ask Siri if she knows your company and see how she spells it.</p>

<p><strong>Copycat</strong> – Remember your last beach vacation? The sun, the smell of fresh coconuts and the beach salesman offering the finest garments from Calvin Kline, Guggi, Dolce &amp; Banana. If your brand name is too close to your competition’s, you will end up not only getting sued by them, but perceived as unoriginal and lame. That’s also true if you think of opening a Burger Queen’s or a Jamie and the Juice.</p>

<p><strong>Restrictive</strong> – You know who has a hard time selling anything else but seafood? Bubba Gump Shrimp Company. If your name is very precise on only one aspect of your business, it will lock you in and limit future growth.</p>

<p><strong>Annoying</strong> – Your brand name should not be indecipherable, forced or cutesy – any kind of leaving out letters, play on words or puns will rather hurt your brand perception than help it.</p>

<p><strong>Tame</strong> – Do you know what “Simple” does? Or “Life”? Or “Tune”? All of these are real brand names, they are short, positive, and totally tame. Avoid names that don’t dare or are not specific enough</p>

<p><strong>Curse of Knowledge</strong> – When you are using subculture references or language for your skate shop or surf school, your audience might really enjoy the insider joke. This curse of knowledge however excludes everyone else, and your brand from growing outside the core demographic.</p>

<p><strong>Hard-to-pronounce</strong> – Again, your name doesn’t need to have any artsy qualities. While something like Cartier or Hermès might work in the luxury sector, their pronunciation does exclude the rest of us. If your name is not obvious or you rely on accents or punctuation, try to find a simpler name.</p>

<p>For good brand names, try to avoid any of these head scratchers. To audit your own brand name, try out the <a href="https://docs.google.com/spreadsheets/d/14FR3b-ZmeO32uI_sqLRQTACCnEdwZP8Qgi549R9kmFI/edit#gid=0">Human Deluxe SMILE &amp; SCRATCH Matrix</a> on Google Sheets – it’s free, of course!</p>

</div></div>]]>
            </description>
            <link>https://toolbox.humandeluxe.com/bad-business-name/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397428</guid>
            <pubDate>Mon, 07 Sep 2020 07:41:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things I Learned to Become a Senior Software Engineer]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 116 (<a href="https://news.ycombinator.com/item?id=24397269">thread link</a>) | @janvdberg
<br/>
September 7, 2020 | https://neilkakkar.com/things-I-learned-to-become-a-senior-software-engineer.html | <a href="https://web.archive.org/web/*/https://neilkakkar.com/things-I-learned-to-become-a-senior-software-engineer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In 2018, I started working at Bloomberg. Things have changed a lot since. I’m not the most junior member in the company anymore and I’ve mentored quite a few new engineers, which has been amazing. It helped me observe how others differ from me, absorb their best practices, and figure out things I’ve unconsciously been doing pretty well.</p>

<p>Yearly work reviews are a good way to condense these lessons I’ve learned.  They’re valuable for pattern matching, too. Only when I zoom out do certain patterns become visible. I can then <a href="https://neilkakkar.com/the-human-log.html">start tracking these patterns consciously</a>.</p>

<p>The broad theme for this year is zooming out and challenging the boundaries. It’s also about zooming in, and adding nuance to the sections from last year. It’s more fun if you’ve <a href="https://neilkakkar.com/year-in-review-2019.html">read last year’s review first</a>: You can then diff my growth.<sup id="fnref:2"><a href="#fn:2">1</a></sup></p>

<p>It all began with a question: How do I grow further?</p>





<nav>

  <h4>Table of Contents</h4>

<ul id="markdown-toc">
  <li><a href="#growing-using-different-ladders-of-abstraction" id="markdown-toc-growing-using-different-ladders-of-abstraction">Growing using different ladders of abstraction</a></li>
  <li><a href="#learning-what-people-around-me-are-doing" id="markdown-toc-learning-what-people-around-me-are-doing">Learning what people around me are doing</a></li>
  <li>
<a href="#learning-good-habits-of-mind" id="markdown-toc-learning-good-habits-of-mind">Learning good habits of mind</a>    <ul>
      <li><a href="#thinking-well" id="markdown-toc-thinking-well">Thinking Well</a></li>
      <li><a href="#strategies-for-making-day-to-day-more-effective" id="markdown-toc-strategies-for-making-day-to-day-more-effective">Strategies for making day-to-day more effective</a></li>
    </ul>
  </li>
  <li><a href="#acquiring-new-tools-for-thought--mental-models" id="markdown-toc-acquiring-new-tools-for-thought--mental-models">Acquiring new tools for thought &amp; mental models</a></li>
  <li><a href="#protect-your-slack" id="markdown-toc-protect-your-slack">Protect your slack</a></li>
  <li><a href="#ask-questions" id="markdown-toc-ask-questions">Ask Questions</a></li>
  <li><a href="#noticing-confusion" id="markdown-toc-noticing-confusion">Noticing Confusion</a></li>
  <li><a href="#force-multipliers" id="markdown-toc-force-multipliers">Force multipliers</a></li>
  <li><a href="#on-ownership" id="markdown-toc-on-ownership">On Ownership</a></li>
  <li><a href="#embrace-fear" id="markdown-toc-embrace-fear">Embrace fear</a></li>
  <li>
<a href="#adding-nuance" id="markdown-toc-adding-nuance">Adding nuance</a>    <ul>
      <li><a href="#writing-code" id="markdown-toc-writing-code">Writing Code</a></li>
      <li><a href="#testing" id="markdown-toc-testing">Testing</a></li>
      <li>
<a href="#design" id="markdown-toc-design">Design</a>        <ul>
          <li><a href="#gathering-requirements" id="markdown-toc-gathering-requirements">Gathering Requirements</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#some-hacks-that-have-worked-very-well-for-me" id="markdown-toc-some-hacks-that-have-worked-very-well-for-me">Some hacks that have worked very well for me</a></li>
  <li><a href="#super-powers" id="markdown-toc-super-powers">Super powers</a></li>
  <li>
<a href="#some-gotchas-with-growing" id="markdown-toc-some-gotchas-with-growing">Some gotchas with growing</a>    <ul>
      <li><a href="#sometimes-i-feel-i-need-to-know-the-answer-to-everything" id="markdown-toc-sometimes-i-feel-i-need-to-know-the-answer-to-everything">Sometimes, I feel I need to know the answer to everything</a></li>
      <li><a href="#sometimes-i-lose-my-cool" id="markdown-toc-sometimes-i-lose-my-cool">Sometimes, I lose my cool</a></li>
      <li><a href="#neophilia" id="markdown-toc-neophilia">Neophilia</a></li>
    </ul>
  </li>
  <li><a href="#questions" id="markdown-toc-questions">Questions</a></li>
</ul>

</nav>

<!-- works only once jQuery is loaded -->


<h2 id="growing-using-different-ladders-of-abstraction">Growing using different ladders of abstraction</h2>

<p>Entering my second year, I had all the basics in place. I had picked all the low hanging fruit, and my rate of growth slowed down. Not good. The big question in my mind was “How do I grow further?”</p>

<p>There was only so much I could do to improve my coding skills. Most blogs epousing techniques to write cleaner code, repeating yourself, not repeating yourself, etc. are micro-optimisations. Almost none of them would make me instantly impactful.<sup id="fnref:3"><a href="#fn:3">2</a></sup></p>

<p>However, I did figure out something insightful. I’m working inside the software development lifecycle, but this lifecycle is part of a bigger lifecycle: the product and infrastructure development lifecycle. I decided to go broader instead of deeper. Surprisingly, the breadth provided more depth to what I knew.</p>

<p>I zoomed out in 3 broad directions: learning what people around me are doing, learning good habits of mind, and acquiring new tools for thought.</p>

<h2 id="learning-what-people-around-me-are-doing">Learning what people around me are doing</h2>

<p>Since we’re not in a closed system, it makes sense to better understand the job of the product managers, the sales people, and the analysts. In the end it’s a business making money through products. The goal isn’t to write code, it’s to be a profitable business.<sup id="fnref:15"><a href="#fn:15">3</a></sup></p>

<p>Most big companies aren’t doing just one thing, which means there are different paths to making money in the same company. Everyone is on at least one path - if they weren’t, they wouldn’t be here.<sup id="fnref:1"><a href="#fn:1">4</a></sup> Tracking these paths, and the path I’m on was pretty valuable. It helped me see how I matter, and what levers I can pull to become more effective. Sometimes, it’s about making the sales jobs easier, so they can make more sales. Other times, it’s about building a new feature for clients. And some other times, it’s about improving a feature that keeps breaking.</p>

<p>Product managers are the best source for this. They know how the business makes money, who are the clients, and what do clients need.</p>

<p>Over the year, I setup quite a few meetings with everyone on my path. A second benefit this gave me was the context of other’s jobs. It helped me communicate better. Framing things in the right way is powerful.</p>

<p>For example, one conversation helped me appreciate why Sarah in Sales wants a bulk update tool. Some companies have lots of employees, and  updating them one by one is a pain. The code I write would literally ease Sarah’s pain.</p>

<!-- More recently, I got a chance to sit in on a few product scoping meetings between teams. This gave me a lot more appreciation for the job my PM and TLs do. Communication is surprisingly hard, and aligning different teams takes skill. -->

<!-- Force multiplier in team vs force multiplier in the entire chain. -->

<h2 id="learning-good-habits-of-mind">Learning good habits of mind</h2>

<p>Software engineering entails thinking well and making the right decisions. Programming is implementing those decisions.</p>

<p>A habit of mind is something your brain does regularly. This could be thinking of X whenever you see Y happen, or applying thinking tool X to problem Y. In short, habits of mind facilitate better thinking.</p>

<p>I suspected if I learn the general skill, I should be able to apply it better to software engineering.</p>

<h3 id="thinking-well">Thinking Well</h3>

<p>Software engineering is an excellent field to practice thinking well in. The feedback loops are shorter, and gauging correctness doesn’t take too long.</p>

<p>I dived into cognitive science studies. It’s a permanent skill that’s worth exploring - a force multiplier for whatever I end up doing, and pays dividends throughout my life. One output was <a href="https://neilkakkar.com/Bayes-Theorem-Framework-for-Critical-Thinking.html">a framework for critical thinking</a>. It’s compounding, <a href="https://neilkakkar.com/year-in-review-2019.html#compounding-is-powerful-building-intuition-for-compounding-even-more-so">and compounding is powerful</a>.</p>

<p>There’s lots of good things that came out of this, which I’ll talk about in a bit. They deserve their own section.</p>

<h3 id="strategies-for-making-day-to-day-more-effective">Strategies for making day-to-day more effective</h3>

<p>The other side of the coin is habits that allow you to think well. It starts with noticing little irritations during the day, inefficiencies in meetings, and then figuring out strategies to avoid them. These strategic improvements are underrated.</p>

<p>You decide what to do, and then let it run on automatic, freeing up the brain to think of more fun stuff. Of course, that’s what a habit is, too.</p>

<p>Some good habits I’ve noticed:</p>

<ul>
  <li>Never leave a meeting without making the decision / having a next action</li>
  <li>Decide who is going to get it done. Things without an owner rarely get done.</li>
  <li>Document design decisions made during a project</li>
</ul>

<p>This pattern became visible during the review, so I’m keen to pay attention and collect more strategies next year. Having an excellent scrum master who holds me accountable has helped me get better at following these strategies.</p>



<p>New tools for thought are related to thinking well, but more specific to software engineering. Tools for thought help me think better about specific engineering problems.</p>

<p>I’ve adopted a just-in-time approach to this. I look for new tools only when I get stuck on something, or when I find out my abstractions and design decisions aren’t working well.</p>

<p>For example, I was recently struggling with a domain with lots of complex business logic. Edge cases were the norm, and we wanted to design a system that handles this cleanly. That’s when I read about <a href="https://amzn.to/2FdCYUQ" target="_blank" rel="noopener">Domain Driven Design</a><sup id="fnref:25"><a href="#fn:25">5</a></sup>. I could instantly put it to practice and make a big difference. Subsequently, I grasped these concepts better. I acquired a new mental model of how to create enterprise software.</p>

<p>The second way I keep learning and acquiring new mental models is via reading what surfaces on Hacker News. They are interesting ideas, some of which I’ve put to practice, but this is a lot less effective than the technique above. The only reason I still do this is to <a href="https://neilkakkar.com/rationality.html#map-and-the-territory">map the territory</a> - it keeps me aware of techniques that exist, so when I face a problem, I know there’s a method that might help.</p>

<p>The final way I acquire better mental models is by learning new diverse languages. The diversity bit is important. Learning yet another dialect of lisp has a lot less benefit than say, learning C++03, a functional programming language, a dynamic typed language, and a lisp. Today, <a href="https://www.hillelwayne.com/post/j-notation/" target="_blank" rel="noopener">J seems interesting</a>, and one I might consider learning. It’s a thinking model I haven’t used before.</p>

<p>I’ve gotten lots of value from doing this. Each language has its own vocabulary and grammar, and <a href="https://neilkakkar.com/vocabulary-mental-model.html">vocabulary is a meta-mental model</a>. It’s a new lens to look at how to do things.</p>

<p>When memory management is in your control, you understand how pointers and allocators work. When Python then abstracts this away, you appreciate the complexity reduction. When maps and filters in a functional language show up, you appreciate how Python’s for loops can be improved. Indeed, that’s what list comprehensions are. And then you notice how some things are easier with object oriented programming. There’s no one magic tool that fits everything well. And then you understand that despite this, you don’t have to switch tools. You can adapt best practices from one into another to solve your problems: like writing functional javascript. It’s the principles that matter more than their expression.</p>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/divider.jpg" alt="">
    
    
    
</figure>

<p>Broadly, that’s all I did this year. What follow are insights that sprang forth thanks to zooming out.</p>

<h2 id="protect-your-slack">Protect your slack</h2>

<p>When I say slack, I don’t mean the company, but the adjective.</p>

<p>One thing that gives me high output and productivity gains is to “slow down”. Want to get more done? Slow down.</p>

<p>Caveats apply, but here’s what I mean:</p>

<p>I’ve noticed people rush to solve problems. It can be something they’ve done before, or something we have a template for. It feels pretty good to smash through things. I’ve done that before, too! However, there’s very specific cases where this makes sense.<sup id="fnref:11"><a href="#fn:11">6</a></sup></p>

<p>Whenever I’m working on something new, I take the time to learn things about the system I’m working on, and things closely related to it. If it’s too massive, I optimise for learning as much as I can. Every time I revisit the system, I aim to learn more.</p>

<p>When <a href="https://www.lesswrong.com/posts/yLLkWMDbC9ZNKbjDG/slack" target="_blank" rel="noopener">there is slack</a>, you get a chance to experiment, learn, and think things through. This means you get enough time to get things done.</p>

<p>When there is no slack, deadlines are tight, and all your focus goes into getting shit done.</p>

<p>Protecting your slack means not letting deadlines wrap tight around you. Usually, this is as simple (or hard) as communicating.<sup id="fnref:16"><a href="#fn:16">7</a></sup></p>

<p>Slack might have a negative connotation with “slackers”, but protecting slack is a super power. It’s a long term investment into building yourself up at the cost of short term efficiency.</p>

<p>When I’m quickly dishing out stories, I also have a much harder time fixing bugs. I don’t take the time to create proper mental models of the system, which means my assumptions don’t match the code, and this mismatch is where most bugs lie.</p>

<p>I protect my slack, so I can take the time out to prioritise …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neilkakkar.com/things-I-learned-to-become-a-senior-software-engineer.html">https://neilkakkar.com/things-I-learned-to-become-a-senior-software-engineer.html</a></em></p>]]>
            </description>
            <link>https://neilkakkar.com/things-I-learned-to-become-a-senior-software-engineer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397269</guid>
            <pubDate>Mon, 07 Sep 2020 07:11:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Causality in Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24397129">thread link</a>) | @cbock90
<br/>
September 6, 2020 | https://christian.bock.ml/posts/mlss_causality/ | <a href="https://web.archive.org/web/*/https://christian.bock.ml/posts/mlss_causality/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<p>I try to consolidate my MLSS 2020 notes in small blog posts and hope you might also find them interesting. I don’t try to cover the complete lectures but rather pick some pieces that I find important when working or doing research in ML. I anticipate this series of blog posts will range from extremely superficial to excessively detailed for some readers.</p>

<p>I will start with Bernhard Schölkopf’s <a href="https://www.youtube.com/watch?v=btmJtThWmhA">lecture</a> on Causality (the second part by Stefan Bauer can be found <a href="https://www.youtube.com/watch?v=9DJWJpn0DmU">here</a>) and draw some connections to Moritz Hardt’s presentations (<a href="https://www.youtube.com/watch?v=Igq_S_7IfOU">1</a> and <a href="https://www.youtube.com/watch?v=9oNVFQ9llPc">2</a>) on fairness. I also recommend taking a look at Bernhard’s very accessible <a href="https://arxiv.org/pdf/1911.10500.pdf">monograph</a>.</p>

<h3 id="independence-of-events-and-random-variables">Independence of Events and Random Variables</h3>

<p>Before we start, we define some basic notions. The first one is the statistical <strong>independence of events</strong>. Let’s consider the events “rainy day” $R$ and “choosing Cini Minis as breakfast cereal” $C$ together with their respective probabilities $Pr(\cdot)$. If rain does not influence your cereal choice, and you can’t change the weather by eating Cini Minis, we say the events are <em>independent</em>, and the following equality holds:
$$
Pr(R \cap C) = Pr(R) \cdot Pr(C).
$$
Similarly, we can define the <strong>independence of continuous random variables</strong> $X$ and $Y$. We write
$$
X \mathrel{\unicode{x2AEB}} Y
$$
for independent variables if for their probability density functions $f_X(x)$ and $f_Y(y)$ it holds that
$$
f_{X,Y}(x,y) = f_X(x)f_Y(y)
$$
for all $x$ and $y$.</p>

<p>For the next concept, we introduce a third random variable $Z$ on which we can condition $X$ and $Y$. If $X$ and $Y$ and <strong>conditionally independent</strong> given $Z$, we write
$$
(X \mathrel{\unicode{x2AEB}} Y) | Z,
$$
and for the joint probability density conditioned on $Z$, it holds that $f_{XY|Z}(x,y|z)=f_X(x|z)f_Y(y|z)$ for all $x$,$y$, and
$z$ such that $f_Z(z)&gt;0$. This simply translates to the fact that</p>

<blockquote>
<p>if I know $Z$, knowing $X$ does not tell me anything additional about $Y$.</p>
</blockquote>

<p>Why is this relevant for causality? The notion of whether or not two random variables are dependent or independent is essential to understand the underlying phenomena that govern this relationship. For example, if we consider the classic example of observing increased stork activity ($X$) and increased birth rate ($Y$), $X$ and $Y$ can depend on each other in two ways:</p>

<ol>
<li>$X \rightarrow Y$: storks bring babies, or</li>
<li>$Y \rightarrow X$: babies attract storks.</li>
</ol>

<p>If we believe that both causal relationships are nonsensical, there must be a third factor that influences both observations simultaneously, $X$ and $Y$ have a <strong>common cause</strong> $Z$:</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3. $X \leftarrow Z \rightarrow Y$.</p>

<p>The fact that there is an underlying mechanism ($Z$) that explains the observed dependence is also known as the <strong>common cause principle</strong> [<a href="#reichenbach_1956">1</a>]. Importantly, we cannot determine which of the three relationships is the “truth” given observational data alone.</p>

<h3 id="structural-causal-model">Structural Causal Model</h3>

<p>One approach to model such relationships/dependencies is <strong>structural causal models (SCM)</strong> [<a href="#pearl_2009">2</a>], realized as directed acyclic graph (DAG) as shown below. <em>Directed</em> because we have arrows in one direction, rather than “simple” edges. <em>Acyclic</em> because there are no self-references. Vertices are <em>observables</em> (see <a href="#ontol_insta">further down</a> for an analysis of the meaning of vertices with respect to fairness in AI), and arrows represent <em>direct causation</em>.
</p><p><img src="https://christian.bock.ml/SCM.png" alt="drawing" width="50%">
</p>

<p><span><i>Figure 1:</i> Example of a structural causal model with noise variable $U$.</span>
</p>

<p>In the above graph, we say that an observable $X$, modeled as a random variable, is a function<sup><a href="#fn_func">1</a></sup> of its parents $PA$ and exogenic or noise variables $U$:
$$
X_j = f_j(PA_j, U_j), \qquad (j=1, \dots, n).
$$</p>

<p>Importantly, all noise variables $U$ are stochastic and <strong>jointly independent</strong>, which leads to the insight that the functional viewpoint $f_j(PA_j, U_j)$ can represent the general conditional distribution $p(X_j|PA_j)$. If the $U$s were not independent, there has to be another mechanism (which we called $Z$ in the stork example) that causes their dependence, and hence we’d have to add it in the diagram. But since this is not the case, the graph contains all potential factors, and we call it <strong>causally sufficient</strong>.</p>

<p>The functional representation of a node can expressed purely by the noise factors by recursively substituting the parent equations:
$$
X_j = f_j(PA_j, U_j) = f_j(f_k(PA_k, U_k), U_j) = f_j(f_k(f_l(PA_l, U_j), U_k), U_j) = \dots = g_j(U_1, \dots, U_n)
$$
Each $X_j$ is therefore a random variable and we get a joint distribution of $p(X_1, \dots, X_n)$ which we call the <em>observational distribution</em>.</p>

<h4 id="disentangled-factorization-graphical-causal-inference">Disentangled Factorization &amp; Graphical Causal Inference</h4>

<p>If a structural causal model (e.g., a graph $G$ as shown in Figure 1) exists, there exists a factorization of the observational distribution:
$$
p(X_1, \dots, X_n) = \prod_ip(X_i, PA_i).
$$
We call each $p(X_i, PA_i)$ a <em>causal conditional</em> or <em>causal Markov kernel</em>. Note that only conditionals that are exclusively conditioned on their parents are <em>causal</em>; they are statistically independent of non-descendants given the parents (this is the <strong>local causal Markov condition</strong>). We call this factorization <strong>disentangled/causal</strong> if 1. knowing a mechanism $p(X_i,PA_i)$ does not yield any information about another mechanism $p(X_j,PA_j)$ for $i \neq j$, and 2. changing one $p(X_i,PA_i)$ does not change $p(X_j,PA_j)$ for $i \neq j$.</p>

<p>Changing $X_j$, for example by setting it to a constant $X_j=const$, is also called <strong>intervention</strong>. Interventions are key operators in Pearl’s <a href="https://plato.stanford.edu/entries/causal-models/do-calculus.html">do-calculus</a>, which I will not address here, but this blog post should help you understand the concept.</p>

<p><strong>Graphical Causal Inference</strong>
They key question is now: How can we recover the graph $G$ of an SCM from the observational distribution $p$ (a.k.a the data)? The answer sounds quite simple: We perform conditional independence testing by tracking how the noise information “spreads through the data”. To make a statement about the existence of a causal graph $G$ when we only see data, we have to assume that seeing data is enough to actually make a statement about $G$. This sounds tautological but is called <strong>faithfulness</strong> and can be formalized by writing</p>

<p>$$
(X \mathrel{\unicode{x2AEB}} Y | Z)_p \Rightarrow (X \mathrel{\unicode{x2AEB}} Y | Z)_G.
$$
This means that from <em>observed</em> conditional independence, we can <em>deduce</em> the causal relationship of these variables. This, however, is hard to justify for finite data, and we need to make assumptions on the function classes $f_{\bullet}$ (see chapter 6 of <a href="https://arxiv.org/pdf/1911.10500.pdf">Causality for Machine Learning</a> for details).</p>

<p>That’s all I wanted to say about this topic. As I said, it is by no means exhaustive, but hopefully provides the lingo that helps to understand some of the basic concepts of causality.</p>

<h3 id="span-id-ontol-insta-parallel-to-fairness-in-ai-ontological-instability-of-causal-vertices-observables-span"><span id="ontol_insta"> Parallel to Fairness in AI: Ontological instability of causal vertices/observables </span></h3>

<p><a href="https://scholar.google.com/citations?user=adnTgaAAAAAJ&amp;hl=en&amp;oi=ao">Moritz Hardt</a> argued that we have to ask the fundamental question of what a node in a causal graph actually references. What is the ontological entity? He motivated this line of thought by considering the situation in which the job application of a person dressed like a hipster was rejected. There are now two positions we can take:</p>

<ol>
<li>He was rejected because he is a hipster (being a hipster caused the rejection), and</li>
<li>He was rejected because he did not meet the dress code (his clothing caused the rejection).</li>
</ol>

<p>In the first position, there is a <strong>mediator</strong> that conveyed that this person is a hipster (e.g., his clothes), which influenced the decision (left graph in Fig. 2). The second view stresses that being assigned the “hipster” label can be influenced by <strong>confounders</strong> such as clothing (right graph in Fig. 2).</p>

<p><img src="https://christian.bock.ml/hipster_SCM.png" alt="drawing" width="50%">
</p>

<p><span><i>Figure 2:</i> Two possible causal graphs generated by two ontological views.</span>
</p>

<p>The problem that clothing can be seen as either a mediator or a confounder, depending on the ontology that fits your world view best, is pointed out by <a href="https://scholar.google.com/citations?user=bAipNH8AAAAJ&amp;hl=en&amp;oi=ao">Judea Pearl</a> himself:</p>

<blockquote>
<p>As you surely know by now, mistaking a mediator for a confounder is one of the deadliest sins in causal inference and may lead to the most outrageous error. The latter invites adjustment; the former forbids it. [<a href="#pearl_2018">4</a>]</p>
</blockquote>

<p>So the bigger question is: why can “hipster” even be a node in the first place? What does it reference, and what are its “settings”?
In a more serious, but analogous situation (“she was rejected because of her religion”) we can take the same two views: Education acts as mediator for religion, and both influence the decision, or education is a confounder that determines religion (see <a href="https://www.cs.purdue.edu/homes/eb/r30.pdf">Fairness in Decision-Making - The Causal Explanation Formula</a>). According to Hardt, these competing models are manifestations of the suppressed question of what the “religion” node references in the first place. A similar problem arises from putting “race” in a causal model: <a href="https://www.oxfordscholarship.com/view/10.1093/oso/9780190610173.001.0001/oso-9780190610173#:~:text=is%20no%20...-,What%20is%20race%3F,the%20biological%20and%20social%20sciences.">What is race?</a></p>

<h4 id="references">References</h4>

<ol>
<li><span id="reichenbach_1956">H. Reichenbach. 1956. <em>The direction of time</em>. University of California Press, Berkeley, CA.</span></li>
<li><span id="pearl_2009">J. Pearl. 2009. <em>Causality: Models, Reasoning, and Inference</em>. Cambridge University Press, New York, NY.</span></li>
<li><span id="lauritzen_1996">L. Lauritzen. 2009. <em>Graphical models</em>. Oxford University Press, New York, NY.</span></li>
<li><span id="pearl_2018">J. Pearl, and D. Mackenzie. <em>The book of why: the new science of cause and effect.</em> Basic Books, 2018.</span></li>
</ol>

<p><span id="#fn_func">1. Note, that $f$ does not refer to the probability density function as introduced in the beginning. It can be any function.</span></p>

      </div></div>]]>
            </description>
            <link>https://christian.bock.ml/posts/mlss_causality/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397129</guid>
            <pubDate>Mon, 07 Sep 2020 06:44:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Managing Managers: Forming the Unicorn]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24397126">thread link</a>) | @jstanier
<br/>
September 6, 2020 | https://www.theengineeringmanager.com/managing-managers/forming-the-unicorn/ | <a href="https://web.archive.org/web/*/https://www.theengineeringmanager.com/managing-managers/forming-the-unicorn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="primary" role="main">
		
<article id="post-1423">

			<!-- end .entry-header -->

		<div>
		
		<div>
			
<p>What’s the best way to level managers up that are reporting to you? It’s by understanding their output and working with them to improve it through a continual virtuous cycle.&nbsp;</p>



<p>This idea isn’t new or novel: Andy Grove wrote the equation below in <a href="https://www.amazon.com/High-Output-Management-Andrew-Grove/dp/0679762884">High Output Management</a> way back in 1983 when he was CEO of Intel:</p>



<blockquote><p><em>A manager’s output = the output of their team + the output of the organization under their influence</em></p></blockquote>



<p>I’ve referred to this many times in the past, because it’s the equivalent of <em>e=mc²</em> for managers. Simple, elegant, yet quite groundbreaking. However, previous references in my articles have used the equation within the context of a manager figuring out how best to spend their time and effort with their ICs and peers to maximize their output. However, if you’re managing managers you’re going to have to think about this equation a little differently because of the managerial role that your direct reports have.</p>



<p>Very few managers are ever the complete article (a <em>unicorn</em>). That includes you and I. This is because being a manager involves a great number of different skills, from the technical to the interpersonal, and no one person is maximally perfect at all of them. That’s entirely normal, and as their manager, your responsibility is to help them <em>fill in all of the gaps</em> by working with them to identify their competency level at all of these different skills, then have them seek out opportunities to <em>delegate</em>, <em>collaborate</em> and <em>educate</em> themselves in order to begin their transformation into that mythical unicorn.</p>



<h2>Delegation, collaboration, and education</h2>



<p>These three core activities are what you should expect all of your managers to continually work on, and you can neatly bucket their activities into each of them.</p>



<ul><li><strong>Delegation</strong> is the bread and butter of having their team get their work done. We’ve written about <a href="http://theengineeringmanager.com/management-101/delegation/">delegation in detail previously</a>. This fits into the <em>output of their team</em> part of the management equation.</li><li><strong>Collaboration</strong> is working with their peers in order to maximize the effectiveness of their team’s work, ensuring that efforts are aligned, opportunities are identified, and that work isn’t duplicated. This is the <em>output of the organization that they influence</em> part of the equation.</li><li><strong>Education</strong> involves both self-directed learning (<em>pull</em>) and learning through your coaching relationship with them (<em>push</em>). Improvements here amplify the output in the previous two areas.</li></ul>



<h2>An example: the CTO</h2>



<p>Let’s frame this by thinking about a CTO of a large technology company. They are accountable for running the Engineering department, reporting to the CEO. They have a number of VPs reporting to them running the various divisions of Engineering. Their peers are the other C-level staff, such as the Chief Marketing Officer (CMO), Chief Product Officer (CPO) and Chief Revenue Officer (CRO) who are accountable for the other departments of the company respectively.</p>



<p>We mentioned above that when managing managers you should be working with them to ensure good delegation, collaboration and education. Let’s think about how the CEO could be working on these areas with the CTO.</p>



<ul><li><strong>Delegation</strong>: It’s likely that the CEO won’t have too much input on the exact technology choices being used to build the product, however they’ll have a vested interest in how they’ve decided to structure their divisions and teams so that the technology strategy is being delegated – and therefore implemented – effectively through their VPs. The CEO will also want to ensure that the CTO is able to delegate all of the <a href="https://www.theengineeringmanager.com/managing-managers/vp-director-what/">operational</a> work to their layer below so that the CTO has time to work on the current and future <a href="https://www.theengineeringmanager.com/managing-managers/vp-director-what/">strategy</a> of the department, rather than needing to get swept into the details of making the trains run on time.</li><li><strong>Collaboration</strong>: An effective Engineering department is nothing without collaboration with the other departments in the company. The CEO will be wanting to ensure that the CTO is regularly collaborating with the CRO in order to understand what current and prospective customers are thinking about the product, to ensure that a close bond exists between the CPO and the product strategy so they can plan and execute it together, and that the go-to-market strategy lead by the CMO properly shines a light on all of the innovation being delivered by Engineering.</li><li><strong>Education</strong>: A tenured CEO will be an experienced leader, so can coach the CTO on leadership skills so they can become better at the two activities above (<em>push</em>). They can help them think through problems, discuss the company strategy, and point them at areas in which they can improve their impact as a leader. Additionally, the CTO will want to invest time in themselves to increase their own skills (<em>pull</em>) by requesting specific coaching support from the CEO or an external coach, by keeping up to date on the latest developments in the industry and by watching talks, by building their network and reading books, and also by occasionally diving deep into high priority or challenging projects within the department to assist in their execution. This in turn allows them to delegate and collaborate better, continuing a virtuous cycle of increasing their output.</li></ul>



<h2>Mapping out a manager’s skills</h2>



<p>So let’s think about how you can apply this technique.</p>



<p>Getting the conversation underway with your managers can take the form of a coaching session that you can run with them individually.&nbsp;</p>



<p>Firstly, you can run through the Andy Grove managerial output equation and show how delegation affects the output of their team, and how collaboration affects the output of those that they influence.</p>



<p>Together you can focus on both their delegation and collaboration in turn and explore how this currently manifests in their work, where it works well, and where it can be improved. Then, once you’ve done that, you can focus on the areas where it can be improved to see how they can do so either via push (i.e. you coach them or get involved yourself) or via pull (i.e. they invest in self-directed learning and initiatives to get there).</p>



<p>You can then form this into a plan to increase their output as a manager as per the equation. If you want it to be more formal, then perhaps try a <a href="https://www.amazon.com/First-90-Days-Strategies-Expanded/dp/1422188612">30-60-90</a>. This can be a coaching topic that you both revisit regularly in order to measure progress and to identify further areas that you can assist them with.</p>



<p>Simple!</p>



<h2>Helping them form their Voltron</h2>



<p>There are parallels with the concept of filling in gaps with an excellent article by Lara Hogan on forming a <a href="https://larahogan.me/blog/manager-voltron/">Manager Voltron</a>. The premise in that article is that if you aren’t getting the support that you need from your own manager, then you can take the problem into your own hands and build a diverse crew around you that enables you to fill the gaps in your own skill set. For example, if you’re not getting the feedback that you need, you can build a network of others in the business that you trust that can give you it without needing to wait, or depend on, your manager.</p>



<p>This too is something that you help your direct report form. For all of the education they can receive via push, it doesn’t necessarily have to come from <em>you</em>. Instead, you can help them <a href="https://www.theengineeringmanager.com/growth/your-network-inside-the-business/">build their network</a> in order to surround them with a crew that can be their very own Voltron, allowing them to get the best of both worlds: a manager that is deeply invested in their success, and also a peer network that challenges and elevates them.</p>



<p>So remember: <em>delegation</em>, <em>collaboration</em> and <em>education</em>. You’re responsible for making it happen. And the effects can be transformational.</p>
					</div><!-- end .entry-content -->

			</div><!-- end .entry-wrap -->

</article><!-- end .post-1423 -->
	<!-- #comments .comments-area -->
	</div></div>]]>
            </description>
            <link>https://www.theengineeringmanager.com/managing-managers/forming-the-unicorn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397126</guid>
            <pubDate>Mon, 07 Sep 2020 06:43:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Automatically Generate a Helpful Changelog from Your Git Commit Messages]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24397020">thread link</a>) | @mokkapps
<br/>
September 6, 2020 | https://www.mokkapps.de/blog/how-to-automatically-generate-a-helpful-changelog-from-your-git-commit-messages/ | <a href="https://web.archive.org/web/*/https://www.mokkapps.de/blog/how-to-automatically-generate-a-helpful-changelog-from-your-git-commit-messages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Creating a changelog is a usual task if a new software version is going to be released. It contains all the changes
which were made since the last release and is helpful to remember what has changed in the code and to be able to
inform the users of our code. </p>
<p>In many projects, creating the changelog is a manual process that is often undesired, error-prone, and time-consuming.
This article describes some tools that can help to automate the changelog creation based on the Git history.</p>
<p>Let’s start with some basics.</p>
<h2>Semantic Versioning</h2>
<p><a href="https://semver.org/" target="_blank" rel="noopener noreferrer">Semantic Versioning (SemVer)</a> is a de facto standard for code versioning. It specifies that a
version number always contains these three parts: </p>
<p><span>
      <a href="https://www.mokkapps.de/static/eb7fe21308b3a0ddf4fb139fd6757869/39f45/semver.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="SemVer" title="SemVer" src="https://d33wubrfki0l68.cloudfront.net/1ffe581e39b3f08db3f410c3c749b17e0c04f7c3/9cbae/static/eb7fe21308b3a0ddf4fb139fd6757869/1e043/semver.png" srcset="https://d33wubrfki0l68.cloudfront.net/0a8ca566a0809dbd3fdaa5920dd4e534b6c037b3/c6b4a/static/eb7fe21308b3a0ddf4fb139fd6757869/991de/semver.png 173w,
https://d33wubrfki0l68.cloudfront.net/1dec6f445968719a44e0d0b58e4a4ec8b08e7de7/37941/static/eb7fe21308b3a0ddf4fb139fd6757869/e4d6b/semver.png 345w,
https://d33wubrfki0l68.cloudfront.net/1ffe581e39b3f08db3f410c3c749b17e0c04f7c3/9cbae/static/eb7fe21308b3a0ddf4fb139fd6757869/1e043/semver.png 690w,
https://d33wubrfki0l68.cloudfront.net/3fd03bfd989f0137531fc20676e92d450e9fc159/cbf0c/static/eb7fe21308b3a0ddf4fb139fd6757869/e3189/semver.png 1035w,
https://d33wubrfki0l68.cloudfront.net/cc378835e34d85efb0d9630dd1650e33301ad307/d28cd/static/eb7fe21308b3a0ddf4fb139fd6757869/b1001/semver.png 1380w,
https://d33wubrfki0l68.cloudfront.net/419c8fac58a2f4dc8623d5bdda8a747b3f2803b8/9a223/static/eb7fe21308b3a0ddf4fb139fd6757869/39f45/semver.png 2184w" sizes="(max-width: 690px) 100vw, 690px" loading="lazy">
  </a>
    </span></p>
<ul>
<li><strong>MAJOR</strong>: is incremented when you add breaking changes, e.g. an incompatible API change </li>
<li><strong>MINOR</strong>: is incremented when you add backward compatible functionality</li>
<li><strong>PATCH</strong>: is incremented when you add backward compatible bug fixes</li>
</ul>
<h2>Conventional Commits</h2>
<blockquote>
<p>The Conventional Commits specification proposes introducing a standardized lightweight convention on top of commit messages.
This convention dovetails with SemVer, asking software developers to describe in commit messages, features, fixes, and breaking changes that they make.</p>
</blockquote>
<p>Developers tend to write commit messages that <a href="http://whatthecommit.com/" target="_blank" rel="noopener noreferrer">serve no purpose</a>. Usually, the message does not
describe where changes were made, what was changed, and what was the motivation for making the changes. </p>
<p>So I recommend to write commit messages using the <a href="https://www.conventionalcommits.org/en/v1.0.0-beta.2/" target="_blank" rel="noopener noreferrer">Conventional Commits specification</a>:</p>
<div data-language="text"><pre><code>&lt;type&gt;[optional scope]: &lt;description&gt;

[optional body]

[optional footer]</code></pre></div>
<p>An example of such a message: </p>
<div data-language="text"><pre><code>fix: ABC-123: Caught Promise exception

We did not catch the promise exception thrown by the API call
and therefore we could not show the error message to the user</code></pre></div>
<p>The commit type <code>&lt;type&gt;</code> can take one of these value:</p>
<ul>
<li><code>fix:</code> a commit of this type patches a bug in your codebase and correlates with the patch version in semantic versioning</li>
<li><code>feat:</code> a commit of this type introduces a new feature to the codebase and correlates with a minor version in semantic versioning</li>
<li><code>BREAKING CHANGE:</code> a commit that has the text <code>BREAKING CHANGE:</code> at the beginning of its optional body or footer section
introduces a breaking API change and correlates with a major version in semantic versioning. A breaking change can be part of
commits of any type. e.g., a <code>fix:</code>, <code>feat:</code> &amp; <code>chore:</code> types would all be valid, in addition to any other type.</li>
</ul>
<p>Other types like <code>chore:</code>, <code>docs:</code>, <code>style:</code>, <code>refactor:</code>, <code>perf:</code>, <code>test:</code> are recommended by the
<a href="https://github.com/angular/angular/blob/22b96b9/CONTRIBUTING.md#-commit-message-guidelines" target="_blank" rel="noopener noreferrer">Angular convention</a>. These
types have no implicit effect on semantic versioning and are not part of the conventional commit specification.</p>
<p>I also recommend reading <a href="https://www.freecodecamp.org/news/writing-good-commit-messages-a-practical-guide/" target="_blank" rel="noopener noreferrer">How to Write Good Commit Messages: A Practical Git Guide</a>.</p>
<h2>Auto-Generate Changelog</h2>
<p>Now we can start to automate the changelog creation.</p>
<ol>
<li>Follow the <a href="https://conventionalcommits.org/" target="_blank" rel="noopener noreferrer">Conventional Commits Specification</a> in your repository. We will use <a href="https://github.com/conventional-changelog/commitlint/tree/master/%40commitlint/config-conventional" target="_blank" rel="noopener noreferrer">@commitlint/config-conventional</a> to enforce this via <a href="https://git-scm.com/docs/githooks" target="_blank" rel="noopener noreferrer">Git hooks</a>.</li>
<li>Use <a href="https://github.com/conventional-changelog/standard-version" target="_blank" rel="noopener noreferrer">standard-version</a>, a utility for versioning using SemVer and changelog generation powered by <a href="https://www.conventionalcommits.org/" target="_blank" rel="noopener noreferrer">Conventional Commits</a>.</li>
</ol>
<p>I will demonstrate the usage based on this <a href="https://github.com/Mokkapps/changelog-generator-demo" target="_blank" rel="noopener noreferrer">demo project</a> which
was initialized running <code>npm init</code> and <code>git init</code>.</p>
<p>The next step is to install <a href="https://github.com/typicode/husky" target="_blank" rel="noopener noreferrer">husky</a>, which sets up your <a href="https://git-scm.com/docs/githooks" target="_blank" rel="noopener noreferrer">Git hooks</a>:</p>

<p>Then install <a href="https://github.com/conventional-changelog/commitlint" target="_blank" rel="noopener noreferrer">commitlint</a> with a config, which will be used to lint your commit message:</p>
<div data-language="text"><pre><code>npm install @commitlint/{cli,config-conventional}</code></pre></div>
<p>As we are using <code>config-conventional</code> we are automatically following the <a href="https://github.com/angular/angular/blob/22b96b9/CONTRIBUTING.md#-commit-message-guidelines" target="_blank" rel="noopener noreferrer">Angular commit convention</a>.</p>
<p>Now we need to tell Husky to run <code>commitlint</code> during the Git commit hook. We can add it to the <code>package.json</code> </p>
<div data-language="json"><pre><code>  <span>"dependencies"</span><span>:</span> <span>{</span>
    <span>"@commitlint/cli"</span><span>:</span> <span>"latest"</span><span>,</span>
    <span>"@commitlint/config-conventional"</span><span>:</span> <span>"latest"</span><span>,</span>
    <span>"husky"</span><span>:</span> <span>"latest"</span>
  <span>}</span><span>,</span>
  <span>"husky"</span><span>:</span> <span>{</span>
    <span>"hooks"</span><span>:</span> <span>{</span>
      <span>"commit-msg"</span><span>:</span> <span>"commitlint -E HUSKY_GIT_PARAMS"</span>
    <span>}</span>
  <span>}</span></code></pre></div>
<p>alternatively to a <code>.huskyrc</code> file: </p>
<div data-language="text"><pre><code>{
  "hooks": {
    "commit-msg": "commitlint -E HUSKY_GIT_PARAMS"
  }
}</code></pre></div>
<p>Finally, we create a <code>.commitlintrc.json</code> file which extends the rules from <a href="https://github.com/conventional-changelog/commitlint/tree/master/%40commitlint/config-conventional" target="_blank" rel="noopener noreferrer">config-conventional</a>:</p>
<div data-language="json"><pre><code><span>{</span>
  <span>"extends"</span><span>:</span> <span>[</span><span>"@commitlint/config-conventional"</span><span>]</span>
<span>}</span></code></pre></div>
<p>Running <code>git commit</code> with an invalid message will now cause an error:</p>
<div data-language="text"><pre><code>▶ git commit -m "this commit message is invalid"
husky &gt; commit-msg (node v14.8.0)
⧗   input: this commit message is invalid
✖   subject may not be empty [subject-empty]
✖   type may not be empty [type-empty]

✖   found 2 problems, 0 warnings
ⓘ   Get help: https://github.com/conventional-changelog/commitlint/#what-is-commitlint

husky &gt; commit-msg hook failed (add --no-verify to bypass)</code></pre></div>
<p>and valid commits will work: </p>
<div data-language="text"><pre><code>▶ git commit -m "feat: initial feature commit"
[master (root-commit) a87f2ea] feat: initial feature commit
 5 files changed, 1228 insertions(+)
 create mode 100644 .commitlintrc.json
 create mode 100644 .gitignore
 create mode 100644 index.js
 create mode 100644 package-lock.json
 create mode 100644 package.json</code></pre></div>
<p>Now we are safe and can guarantee that only valid commit messages are in our repository. </p>
<h2>Generate Changelog</h2>
<p>Finally, we can create our changelog from our Git history. First step is to install <a href="https://github.com/conventional-changelog/standard-version" target="_blank" rel="noopener noreferrer">standard-version</a>:</p>
<div data-language="text"><pre><code>npm i --save-dev standard-version</code></pre></div>
<p>Now we can create some npm scripts in our <code>package.json</code>: </p>
<div data-language="json"><pre><code>  <span>"scripts"</span><span>:</span> <span>{</span>
    <span>"release"</span><span>:</span> <span>"standard-version"</span><span>,</span>
    <span>"release:minor"</span><span>:</span> <span>"standard-version --release-as minor"</span><span>,</span>
    <span>"release:patch"</span><span>:</span> <span>"standard-version --release-as patch"</span><span>,</span>
    <span>"release:major"</span><span>:</span> <span>"standard-version --release-as major"</span>
  <span>}</span><span>,</span></code></pre></div>
<p>The changelog generation can be configured via a <code>.versionrc.json</code> file or placing a <code>standard-version</code> stanza in your <code>package.json</code>.</p>
<p>In our demo we use a <code>.versionrc.json</code> file based on the <a href="https://github.com/conventional-changelog/conventional-changelog-config-spec/blob/master/versions/2.1.0/README.md" target="_blank" rel="noopener noreferrer">Conventional Changelog Configuration Spec</a>: </p>
<div data-language="json"><pre><code><span>{</span>
    <span>"types"</span><span>:</span> <span>[</span>
      <span>{</span><span>"type"</span><span>:</span> <span>"feat"</span><span>,</span> <span>"section"</span><span>:</span> <span>"Features"</span><span>}</span><span>,</span>
      <span>{</span><span>"type"</span><span>:</span> <span>"fix"</span><span>,</span> <span>"section"</span><span>:</span> <span>"Bug Fixes"</span><span>}</span><span>,</span>
      <span>{</span><span>"type"</span><span>:</span> <span>"chore"</span><span>,</span> <span>"hidden"</span><span>:</span> <span>true</span><span>}</span><span>,</span>
      <span>{</span><span>"type"</span><span>:</span> <span>"docs"</span><span>,</span> <span>"hidden"</span><span>:</span> <span>true</span><span>}</span><span>,</span>
      <span>{</span><span>"type"</span><span>:</span> <span>"style"</span><span>,</span> <span>"hidden"</span><span>:</span> <span>true</span><span>}</span><span>,</span>
      <span>{</span><span>"type"</span><span>:</span> <span>"refactor"</span><span>,</span> <span>"hidden"</span><span>:</span> <span>true</span><span>}</span><span>,</span>
      <span>{</span><span>"type"</span><span>:</span> <span>"perf"</span><span>,</span> <span>"hidden"</span><span>:</span> <span>true</span><span>}</span><span>,</span>
      <span>{</span><span>"type"</span><span>:</span> <span>"test"</span><span>,</span> <span>"hidden"</span><span>:</span> <span>true</span><span>}</span>
    <span>]</span><span>,</span>
    <span>"commitUrlFormat"</span><span>:</span> <span>"https://github.com/mokkapps/changelog-generator-demo/commits/{{hash}}"</span><span>,</span>
    <span>"compareUrlFormat"</span><span>:</span> <span>"https://github.com/mokkapps/changelog-generator-demo/compare/{{previousTag}}...{{currentTag}}"</span>
  <span>}</span>
  </code></pre></div>
<p>An array of <code>type</code> objects represents the explicitly supported commit message types, and whether they should show up in the generated changelog file.
<code>commitUrlFormat</code> is an URL representing a specific commit at a hash and <code>compareUrlFormat</code> is an URL representing the comparison between two git shas.</p>
<p>The first release can be created by running <code>npm run release -- --first-release</code> in the terminal:</p>
<div data-language="text"><pre><code>▶ npm run release -- --first-release

&gt; changelog-generator-demo@0.0.0 release /Users/mhoffman/workspace/changelog-generator-demo
&gt; standard-version "--first-release"

✖ skip version bump on first release
✔ created CHANGELOG.md
✔ outputting changes to CHANGELOG.md
✔ committing CHANGELOG.md
✔ tagging release v0.0.0
ℹ Run `git push --follow-tags origin master` to publish</code></pre></div>
<p>An exemplary <code>CHANGELOG.md</code> could look similar to this one:</p>
<p><span>
      <a href="https://www.mokkapps.de/static/43682732cd75b06795c875eccd0aae1a/bf286/changelog.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="CHANGELOG First Release" title="CHANGELOG First Release" src="https://d33wubrfki0l68.cloudfront.net/bea34094ace0fe0506ebd1a8dd1030717c9e1848/cf194/static/43682732cd75b06795c875eccd0aae1a/1e043/changelog.png" srcset="https://d33wubrfki0l68.cloudfront.net/389e32b7e47f4e0a1f974daacf94391c47d60355/5679f/static/43682732cd75b06795c875eccd0aae1a/991de/changelog.png 173w,
https://d33wubrfki0l68.cloudfront.net/37c00073ac29fec58ddea15fae045aa383505084/bdf9d/static/43682732cd75b06795c875eccd0aae1a/e4d6b/changelog.png 345w,
https://d33wubrfki0l68.cloudfront.net/bea34094ace0fe0506ebd1a8dd1030717c9e1848/cf194/static/43682732cd75b06795c875eccd0aae1a/1e043/changelog.png 690w,
https://d33wubrfki0l68.cloudfront.net/217de77e2c63ed754d1a927ae64358b60b78dff8/d5695/static/43682732cd75b06795c875eccd0aae1a/e3189/changelog.png 1035w,
https://d33wubrfki0l68.cloudfront.net/abc69d24631dca030e29dd6c2be5898d8a5ae881/1af65/static/43682732cd75b06795c875eccd0aae1a/b1001/changelog.png 1380w,
https://d33wubrfki0l68.cloudfront.net/d0a4d480c9a46148625d3d3f22b40871b202b1c3/a841f/static/43682732cd75b06795c875eccd0aae1a/bf286/changelog.png 1688w" sizes="(max-width: 690px) 100vw, 690px" loading="lazy">
  </a>
    </span></p>
<p>What I like is that the changelog is divided by the type of commit, it contains links to the specific commits and link to
the diff of the version.</p>
<p>Of course, you can always edit the auto-generated changelog to make it more readable though. The generated changelog Markdown
text can be pasted into GitHub releases so that it shows up next to each release tag. There are a lot more options in
the tools to customize linting commits or the changelog generation.</p>
<h2>Conclusion</h2>
<p>For lazy developers like me, an automatic changelog generation is a nice tool that saves me a lot of time. Additionally,
we have better commit messages in our code repository as they follow an established specification. </p>
<p>It needs some time to get used to the commit convention. You could encounter some discussions in your team as all
code contributors need to follow the convention. The Git hook solution should catch the wrong messages as early as possible
but you could also add a guard in your CI/CD pipeline. </p>
<p>In my opinion, it is worth the effort to introduce the Git commit convention and the changelog generation in projects.
We as developers do not need to invest much time &amp; brain capacity for the changelog generation and have a helpful
document where we can look up what has changed between our software releases. Additionally, we can easily share this
with the users of our software so that they also see what they can expect from each new release.</p></div></div>]]>
            </description>
            <link>https://www.mokkapps.de/blog/how-to-automatically-generate-a-helpful-changelog-from-your-git-commit-messages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397020</guid>
            <pubDate>Mon, 07 Sep 2020 06:16:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tech Debt is an unfortunate abstraction, let's not use it]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24396959">thread link</a>) | @liveweird
<br/>
September 6, 2020 | https://no-kill-switch.ghost.io/tech-debt-is-an-unfortunate-abstraction/ | <a href="https://web.archive.org/web/*/https://no-kill-switch.ghost.io/tech-debt-is-an-unfortunate-abstraction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-post-id="5f554d9876722a003999c80f">
	

	<section>
		<p><em>Disclaimer: this blog post was triggered/inspired by an article you can find <a href="https://thehftguy.com/2020/08/26/technical-debt-doesnt-exist/">here</a>. I strongly encourage you to get familiar with it - whatever I put below is built on it as a foundation, so all the kudos go to <strong>The HFT Guy</strong>.</em></p><hr><p>Mental models are extremely powerful thought constructs. They do guide &amp; simplify our reasoning, but they also prime us. Bias us. And when treated as axioms, dangerously narrow down our thinking horizons.</p><p>All of the above applies to the popular concept of <strong>"technical debt" (TD)</strong>. I won't cover its meaning and history (there are tons of online materials on those) - instead, I'd like to focus on why the concept of TD is far less useful than we tend to think and actually quite harmful for our daily work.</p><p>Why so? Mainly because:</p><ol><li>there's no code w/o technical debt - TD is <strong>a "local" maintainability factor</strong> (a multiplier - that can span from very low to extremely high values) for a particular piece of a system; hence it's not separable from good (/healthy) code; consider it an inevitable "property" of any code</li><li>mentally dividing work between "fixing/fighting TD" and "developing features" usually leads to: never doing anything about TD and just going short-cuts all the time (<em>"I'll just do it the quick'n'dirty style, we'll need to refactor all that anyway ... some day"</em>)</li><li>we tend to brand as TD <strong>everything "we don't like at the moment"</strong> (a code written by someone else, a code that uses a library we find passé atm, etc.) - which leads to several types of immature &amp; unprofessional practices and massive wastes ("lava flow" effect, stacking unnecessary abstractions, etc.)</li><li>for the reasons stated above, TD is highly subjective and prone to individual judgment, hence nearly impossible to reliably quantify &amp; measure (regardless of whether you estimate the cost of its reduction or its actual impact on the development process); but it looks like <strong>a great candidate for a universal excuse</strong> (and it's frequently used that way)</li><li>it conveniently puts engineers in "we VS the debt" mode by giving the common enemy (that won't speak up) - some ephemeral "entity" you can stand in opposition to; this detail is important: no-one ever openly admits to the ownership over the TD, it just pops up out of the thin air and hinders the work of poor engineers ...</li></ol><p>Nevertheless, peeling TD out of its name won't make all its negative consequences disappear, right? Naming it explicitly at least makes discussing it (among engineers) easier &amp; (hopefully) more conclusive.</p><p>But maybe there's a better way to tame it? E.g. by ...</p><ul><li>... treating it as something inevitable (as there's no and there'll never be perfect, debt-less code)</li><li>... containing it within component/element/unit boundaries</li><li>... and coming up with a way to "reset" it (once in a while) within those local boundaries?</li></ul><p>I've already written (over four years ago) about some particular concept that can help with that - <a href="https://no-kill-switch.ghost.io/wiping-the-tech-debt-out-with-immutable-code/"><strong>the immutable code</strong></a>. It may sound weird at first glance, but apparently many companies adopt a similar standpoint:</p><ul><li>they create software with the EXPIRY date (on the level of module/component/piece) and re-create it every few years (because business/scale conditions do change anyway) - as a normal business-as-usual activity</li><li>they optimize not for "perfect architectures" but for future re-writes on the level of module/component/piece (e.g. by enforcing explicit contracts - so after a single component replacement, the whole system doesn't collapse like a house of cards)</li></ul><p>That's (creating with a re-write in mind) actually something I've already covered in <a href="https://no-kill-switch.ghost.io/are-the-software-product-companies-doomed-to-collapse/"><strong>the different post in the past</strong></a>, so feel free to reach there for more details.</p><p>Great! But what if my system wasn't written in a re-write-friendly way? What if there are no explicit contracts, dependencies are out of control, the only units of abstractions are the language's syntactic constructs (a flat list, w/o hierarchy or varying perspectives) and it's not possible to map certain capabilities/duties?</p><p>HA! And now we've reached a conclusion I was looking for - the main pre-requisite to build a future-proof solution with a TAMEABLE technical debt is ... <strong>by doing a deliberate design</strong>. It can be done up-front or in an evolutionary way - the mode doesn't matter that much. The truly crucial elements are:</p><ul><li>capability-driven composition (driven by purpose, function) with explicit boundaries and dependencies</li><li>the ubiquitous language used everywhere</li><li>wide (expressive) but shallow (w/o internal details) contracts treated as a binding promise to all the consumers</li></ul><p>That's also why so many attempts to reduce technical debt by purely technical refactoring (e.g. splitting big classes, harmonizing conventions, simplifying the flow in complicated procedures) are a pure waste w/o any noticeable positive long-term effect.</p>
	</section>

	
</article></div>]]>
            </description>
            <link>https://no-kill-switch.ghost.io/tech-debt-is-an-unfortunate-abstraction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24396959</guid>
            <pubDate>Mon, 07 Sep 2020 06:02:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Workflow for Publishing Articles]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24396916">thread link</a>) | @amitmerchant
<br/>
September 6, 2020 | https://www.amitmerchant.com/my-workflow-for-publishing-articles/ | <a href="https://web.archive.org/web/*/https://www.amitmerchant.com/my-workflow-for-publishing-articles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>After writing &amp; publishing articles for about two years (consistently), Iâ€™ve sort of created a system when it comes to publishing an article. From ideation to hitting the publish button.</p>

<p>Of course, this system is ever-evolving and over the years, Iâ€™ve tried to tweak it to suit my needs. And today, I think it has reached to a point where I can share it with you and allow you to peek into this very â€œsystemâ€�.</p>

<h2 id="ideation">Ideation</h2>

<p>A couple of years ago, when I started this blog, I was used to writing casually and back then i.e. I was only used to post articles whenever I feel like. But from the previous two years, things have changed. Iâ€™ve started to take it more seriously and started publishing articles quite frequently. Almost daily (of course, with a few exceptions).</p>

<p>You might be asking how Iâ€™ve started writing so much? And where do I get ideas from?</p>

<p>The answer to all these questions is <strong><em>â€œFrom teaching things to myselfâ€�</em></strong>. In a nutshell, whenever Iâ€™m in a situation where I donâ€™t get certain concepts correctly, I would first try to understand the topic thoroughly. And when things get clear for me, I would try to depict the concept in my words. In a way that can make me understand whenever I look upon it next time.</p>

<p>That means I primarily write articles for myself only. And if anyone gets benefitted from my articles, it would be an added bonus!</p>

<h2 id="writing-the-article">Writing the Article</h2>

<p>Next, for writing articles, Iâ€™m using <a href="https://code.visualstudio.com/">VS Code</a> because articles are written in <a href="https://daringfireball.net/projects/markdown/">Markdown</a> and nothing is better than the VS Codeâ€™s built-in support for Markdown in my opinion. To get started with a brand new article, all I need to do is whip up a blank Markdown file and pour my heart out in it. Itâ€™s as simple as that.</p>

<p>To make this even better, I use a VS Code extension called <a href="https://marketplace.visualstudio.com/items?itemName=yzhang.markdown-all-in-one">Markdown All in One</a> which add some essential things such as keyboard shortcuts, table of contents, auto preview, and more when it comes to Markdown. It saves tonnes of time fiddling around some Markdown quirks.</p>

<h2 id="fixing-the-article">Fixing the Article</h2>

<p>Once the article has been written, I head to <a href="https://www.grammarly.com/">grammarly.com</a> and paste in my entire article to check for spelling and grammatical mistakes. And once it detects those errors, it can fix those in a cinch.</p>

<p>On top of this, it also suggests alternative words and removal of unnecessary words which can make the entire reading experience a pleasant one.</p>

<blockquote>
  <p>Back then, I was not very concerned regarding making my articles grammar-correct. But over time, I realised itâ€™s important from the perspective of a reader because Iâ€™m also an avid reader myself. And so the grammar correction step entered into my workflow.</p>
</blockquote>



<p>Now is the time to create a nice social banner for the article. It looks something like so on Twitter.</p>

<p><img src="https://www.amitmerchant.com/images/social-banner-demo.png" alt=""></p>

<p>A lot of content creators ignore this but in my opinion, it is a really important thing if youâ€™re posting your articles across different social media platforms. It can make your article stand out because images can grab usersâ€™ attention more quickly than the text.</p>

<p>I use a service called <a href="https://crello.com/">Crello</a> where I create social banners every time I write a new article. The banner contains nothing but the title of the article but alas! in big and attention-grabbing fonts. Itâ€™s all handmade.</p>

<h2 id="publishing-the-article">Publishing the Article</h2>

<p>At this moment, everything is in the place and the article is ready to be published. For publishing the article, all it takes is a simple <code>git push</code> in my case as Iâ€™ve hosted my blog on GitHub Pages and it triggers the new build on every Git push.</p>

<p>Once the code is pushed, it would take 30-45 seconds to make the article live on the holy internet!</p>

<p>And that completes my entire workflow from <em>ideation</em> to <em>publishing an article</em>. Iâ€™ve been following this workflow from the past two years and it has suited me very well and Iâ€™m hoping the continue it for some more time!</p>

    </div></div>]]>
            </description>
            <link>https://www.amitmerchant.com/my-workflow-for-publishing-articles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24396916</guid>
            <pubDate>Mon, 07 Sep 2020 05:49:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL: From Idea to Database]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24396635">thread link</a>) | @parsd
<br/>
September 6, 2020 | https://blog.rustprooflabs.com/2018/06/pg-series-toc | <a href="https://web.archive.org/web/*/https://blog.rustprooflabs.com/2018/06/pg-series-toc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>By Ryan Lambert -- Published June 19, 2018</p><p><em><strong>PostgreSQL</strong>: From Idea to Database</em> is a series of blog posts written to teach practical database design.
This series focuses on practical examples of working with Postgres
to illustrate the why and how of operation.</p>
<blockquote>
<p>Note:  This series is an evolving and improving collection of blog posts.
I regularly update this page as content is published and maintained.</p>
</blockquote>
<h2>Table of contents</h2>
<p>The following listing includes links to the pages that are already
published along with placeholders for planned future topics.
Future topics (e.g. titles without links) are likely to change in title, exact content and scope.</p>
<!--endteaser-->

<h3>General Postgres topics</h3>
<ul>
<li><a href="https://blog.rustprooflabs.com/2018/06/pg-series-intro">Introduction to <em><strong>PostgreSQL</strong>:  From Idea to Database</em></a> series (2018)</li>
<li><a href="https://blog.rustprooflabs.com/2018/07/pg-crash-course">PostgreSQL Crash Course</a> (2018)</li>
<li><a href="https://blog.rustprooflabs.com/2018/09/pg-define-design-repeat">Define, Design, Repeat</a> (2018)</li>
<li><a href="https://blog.rustprooflabs.com/2018/09/pg-data-dictionary">Build your Data Dictionary in PostgreSQL</a> (2018)</li>
<li><del><a href="https://blog.rustprooflabs.com/2018/11/pg-data-dictionary-pgdd">Enhance your PostgreSQL Data Dictionary</a></del> (2018)</li>
<li><a href="https://blog.rustprooflabs.com/2019/11/pgdd-now-postgresql-extension">PostgreSQL Data Dictionary Extension</a> (2019)</li>
<li><a href="https://blog.rustprooflabs.com/2016/08/psql-vs-mysql">PostgreSQL vs. MySQL: Why we use PostgreSQL</a> (2016)</li>
<li><a href="https://blog.rustprooflabs.com/2018/01/db-anti-pattern">Database Anti-patterns: Performance Killers</a> (2018)</li>
<li><a href="https://blog.rustprooflabs.com/2019/07/postgresql-automate-ansible-sqitch">Deploying PostgreSQL using Ansible and Sqitch</a> (2019)</li>
<li><a href="https://blog.rustprooflabs.com/2020/07/postgres-storing-large-text">Large Text in PostgreSQL: Performance and Storage</a> (2020)</li>
<li>Database lifecycle</li>
<li>Backup and Restore</li>
<li>Databases and change over time</li>
<li>PostgreSQL, JSON and PiWS</li>
<li>PostgreSQL Functions - Data as an API</li>
</ul>
<h3>Advanced Postgres topics</h3>
<h4>Performance</h4>
<ul>
<li><a href="https://blog.rustprooflabs.com/2018/02/pg10_parallel_queries">PostgreSQL 10 Parallel Queries and Performance</a> (2018)</li>
<li><a href="https://blog.rustprooflabs.com/2016/07/psql-unlogged-table">Testing PostgreSQL Unlogged Tables for Performance</a> (2016)</li>
<li><a href="https://blog.rustprooflabs.com/2019/04/postgrseql-pgbench-raspberry-pi">PostgreSQL performance on Raspberry Pi</a> (2019)</li>
<li><a href="https://blog.rustprooflabs.com/2019/04/postgrseql-pgbench-raspberry-pi-pt2">PostgreSQL performance on Raspberry Pi, Reporting edition</a> (2019)</li>
<li><a href="https://blog.rustprooflabs.com/2019/08/postgresql-pgbench-raspberry-pi-4-initial">PostgreSQL on Raspberry Pi 4: Initial Testing</a> (2019)</li>
<li><a href="https://blog.rustprooflabs.com/2017/12/psql-load-test">PostgreSQL Load Testing</a> (2017)</li>
<li><a href="https://blog.rustprooflabs.com/2020/08/postgres-integer-index-performance">PostgreSQL: Integers, on-disk order, and performance</a> (2020)</li>
<li><a href="https://blog.rustprooflabs.com/2020/09/postgres-beta3-btree-dedup">PostgreSQL 13 B-Tree Deduplication</a> (2020)</li>
</ul>
<h4>Spatial data (PostGIS)</h4>
<ul>
<li><a href="https://blog.rustprooflabs.com/2019/08/postgis-qgis-create-layers">Create vector layers using QGIS and PostGIS</a>(2019)</li>
<li><a href="https://blog.rustprooflabs.com/2018/07/postgis-tame-your-data">PostGIS:  Tame your spatial data (Part 1)</a> (2018)</li>
<li><a href="https://blog.rustprooflabs.com/2018/07/postgis-tame-your-data-2">PostGIS:  Tame your spatial data (Part 2)</a> (2018)</li>
<li><del><a href="https://blog.rustprooflabs.com/2019/01/postgis-osm-load">Load OpenStreetMap data to PostGIS</a></del> (2019)</li>
<li><a href="https://blog.rustprooflabs.com/2020/01/postgis-osm-load-2020">Updated for 2020: Load OpenStreetMap data to PostGIS</a> (2020)</li>
<li><a href="https://blog.rustprooflabs.com/2019/10/osm2pgsql-scaling">Scaling osm2pgsql: Process and costs</a> (2019)</li>
<li><a href="https://blog.rustprooflabs.com/2019/01/osm2pgsql-raspberry-pi">osm2pgsql on a Raspberry Pi</a> (2019)</li>
<li><a href="https://blog.rustprooflabs.com/2019/01/postgis-pgosm">PgOSM:  Transform OpenStreetMap data in PostGIS</a> (2019)</li>
<li><a href="https://blog.rustprooflabs.com/2019/02/postgis-pgosm-transformations-explained">PgOSM Transformations explained</a> (2019)</li>
<li><a href="https://blog.rustprooflabs.com/2019/05/pg-fixed-xml-pg_dump">FIXED!</a> --&gt;  <a href="https://blog.rustprooflabs.com/2018/08/postgresql-xml-pg_dump-gotcha">Gotcha restoring XML data from pg_dump</a> (2019, 2018)</li>
</ul>
<h4>PostGIS Recorded Session</h4>
<ul>
<li><a href="https://blog.rustprooflabs.com/2020/01/webinar-intro-postgis-openstreetmap">Intro to PostGIS and OpenStreetMap (1/6)</a> (Recorded December 2019)</li>
<li><a href="https://blog.rustprooflabs.com/2020/01/webinar-load-postgis-with-osm2pgsql">Load PostGIS with osm2pgsql (2/6)</a> (Recorded January 2020)</li>
<li><a href="https://blog.rustprooflabs.com/2020/02/webinar-postgis-osm-tools-and-queries">Exploring OpenStreetMap from PostGIS: Tools and Queries (3/6)</a> (Recorded January 2020)</li>
<li><a href="https://blog.rustprooflabs.com/2020/02/webinar-postgis-query-performance">PostGIS Queries and Performance (4/6)</a> (Recorded February 2020)</li>
<li><a href="https://blog.rustprooflabs.com/2020/02/webinar-postgres12-postgis3-whats-new">Postgres 12 and PostGIS 3 (5/6)</a> (Recorded February 2020)</li>
<li><a href="https://blog.rustprooflabs.com/2020/02/webinar-postgis-openstreetmap-advanced">PostGIS Advanced Features (6/6)</a> (Recorded March 2020)</li>
</ul>
<h4>Administration and Security</h4>
<ul>
<li><a href="https://blog.rustprooflabs.com/2019/12/exploring-pgconfig-comparison-tool">Exploring PgConfig comparison tool</a> (2019)</li>
<li><a href="https://blog.rustprooflabs.com/2019/07/postgresql-postgis-install-from-source-raspberry-pi">Installing PostgreSQL and PostGIS from source</a> (2019)</li>
<li><a href="https://blog.rustprooflabs.com/2019/09/prepare-for-postgres12-config-changes">Prepare for Postgres 12:  Configuration Changes</a> (2019)</li>
<li>CIS Benchmarks</li>
</ul>
<h2>Get in touch</h2>
<p>If you have questions or comments please <a href="https://www.rustprooflabs.com/contact">Contact us</a>.</p><p>By Ryan Lambert <br> Published June 19, 2018 <br> Last Updated September 06, 2020</p>
                </div></div>]]>
            </description>
            <link>https://blog.rustprooflabs.com/2018/06/pg-series-toc</link>
            <guid isPermaLink="false">hacker-news-small-sites-24396635</guid>
            <pubDate>Mon, 07 Sep 2020 04:29:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Never Lose a Part Again, with the Ultimate Component Storage System]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24396611">thread link</a>) | @kevinqqsam
<br/>
September 6, 2020 | https://www.hackster.io/news/never-lose-a-part-again-with-the-ultimate-component-storage-system-00987cde6744 | <a href="https://web.archive.org/web/*/https://www.hackster.io/news/never-lose-a-part-again-with-the-ultimate-component-storage-system-00987cde6744">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><p><span>The creator of </span><a href="https://www.instructables.com/id/The-Ultimate-Component-Storage-System/" rel="nofollow">this project</a><span>, APTechnologies, came up with the idea for the storage cabinet by observing that he would run into trouble when organizing his component library. Rather than having to go across the workshop to get each part, he wanted a way to consolidate everything into one place for easy finding. The system works by first having the user search for a part on an adjacent screen, and then the associated bin will light up if the component is found in the system.</span></p><h3 id="toc-designing-the-cabinet-0"><a href="#toc-designing-the-cabinet-0"><i></i></a><span>Designing the Cabinet</span></h3><p>The storage solution is comprised of a 35 x 12 grid of drawers, which gives ample space for parts. The drawers are laid out according to the spacing between the LEDs in the strip (30 LEDs/meter). They are meant to be printed individually and then slotted in, plus they come in several different sizes.</p><h3 id="toc-fabrication-1"><a href="#toc-fabrication-1"><i></i></a><span>Fabrication</span></h3><p>Each drawer was 3D-printed on a Prusa Mk2S with PLA filament at a .2mm layer height. In order to minimize filament consumption, wall thicknesses are kept very thin, but even with this savings, 5kg of filament was required to fabricate the parts. There is also a small articulating arm that juts out from the side for the HDMI display.</p><h3 id="toc-software-2"><a href="#toc-software-2"><i></i></a><span>Software</span></h3><p>The primary way to interact with the system is through the terminal, which runs a Python 3 script. It begins by checking the text file for data integrity, where it then gets parsed and loaded into an object. Data is stored in CSV-style fashion, with the ID being the first column, the associated LEDs in the second, and finally the quantity in the third column. All subsequent values are optional and simply loaded by the user when the parts is located. A regex is used to parse the user's request, including searching for a component, changing its quantity, adding a new part, and removing a component.</p><h3 id="toc-electronics-3"><a href="#toc-electronics-3"><i></i></a><span>Electronics</span></h3><p>According to the project's creator, the choice for hardware components was quite straightforward. He used a Raspberry Pi 4 Model B in conjunction with a generic HDMI monitor to show the command line interface. For power delivery, he opted for a simple 5V adapter to power both the Raspberry Pi 4 and NeoPixel strip. Since the Pi outputs 3.3v signals from its GPIO pins, a level-shifter is needed, in this case a 74AHCT125. There is an option to use an Arduino Uno via UART if the NeoPixel strip is too unreliable, since the Arduino Uno can supply stricter timings.</p><h3 id="toc-usage-4"><a href="#toc-usage-4"><i></i></a><span>Usage</span></h3><p><span>To add a new part, the command </span><code>PI&lt;ledn&gt;:PI&lt;ledn+k&gt;, &lt;quantity&gt;[, optional parameters]:add</code><span> is sent, which adds a new component to the library. Other commands such as ID&lt;id number&gt; (search for part by ID) and ID&lt;id number&gt;:rm (remove part with that ID) exist to manage added components in the library.</span></p><h3 id="toc-possible-additions-5"><a href="#toc-possible-additions-5"><i></i></a><span>Possible Additions</span></h3><p>Although the system works well for one place and a small collection of components, it tends to scale poorly when there's a large library or multiple users want to interact with it. One way to solve this issue is to replace the single text file with a relational database such as MySQL, where parts can be stored and indexed in a single table, and other data can be referenced. This gives a very powerful interface for the software to easily search, add, and modify parts without having to read and rewrite the text file constantly.</p></div></section><section></section><div><div><a href="https://www.hackster.io/gatoninja236"></a><div><p><span><a href="https://www.hackster.io/gatoninja236">Arduino “having11” Guy</a><span></span></span></p><p>18 year-old IoT and embedded systems enthusiast. Also an interned at Hackster.io and love working on projects and sharing knowledge.</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.hackster.io/news/never-lose-a-part-again-with-the-ultimate-component-storage-system-00987cde6744</link>
            <guid isPermaLink="false">hacker-news-small-sites-24396611</guid>
            <pubDate>Mon, 07 Sep 2020 04:21:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. Blacklisting China's Chipmaker SMIC (Asia AI News)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24396448">thread link</a>) | @asiaainews
<br/>
September 6, 2020 | http://newsletter.asiaainews.com/issues/u-s-mulls-blacklisting-smic-biofourmis-raises-100m-via-softbank-others-275601 | <a href="https://web.archive.org/web/*/http://newsletter.asiaainews.com/issues/u-s-mulls-blacklisting-smic-biofourmis-raises-100m-via-softbank-others-275601">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://newsletter.asiaainews.com/issues/u-s-mulls-blacklisting-smic-biofourmis-raises-100m-via-softbank-others-275601</link>
            <guid isPermaLink="false">hacker-news-small-sites-24396448</guid>
            <pubDate>Mon, 07 Sep 2020 03:42:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The corporate / academic / public AI value gap]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24396354">thread link</a>) | @bpodgursky
<br/>
September 6, 2020 | https://bpodgursky.com/2020/09/07/the-corporate-academic-public-ai-value-gap/ | <a href="https://web.archive.org/web/*/https://bpodgursky.com/2020/09/07/the-corporate-academic-public-ai-value-gap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>There is a huge gap between the benefits of Artificial Intelligence the public is being sold, the benefits of AI which are being marketed to corporate adopters, and the actual motivations of AI researchers.</p>



<ul><li>Tech providers pitch AI as a driver of innovation (self-driving cars) and global good (mitigating global warming).&nbsp; But the B2B case-studies pitched to corporate clients more often pitch AI solutions as <em>better automation, </em>mostly enabling cost-reduction (specifically, reducing human-in-the-loop labor).</li><li>While many AI researchers are motivated by genuine interest in improving the human condition, other motivations diverge — a desire to push the bounds of what we <em>can </em>do, a genuine belief in transhumanism (the desire for AI to replace, or transform into something entirely unrecognizable, humanity), or simply because AI pays bigly.</li></ul>



<p>These drivers — replacing human employment, and perhaps humans themselves — are, to put it mildly — not visions the public has bought into.</p>



<p>But these internal motivations are drowned out by the marketing AI pitch by which AI is sold to the public: “AI will solve [hunger/the environment/war/global warming]”.&nbsp; This leaves the people not “in the know” about AI progress — 99% of the population — not even <em>thinking </em>to use democracy to direct AI research towards a world the (average) person actually wants to live in.</p>



<p>This is not particularly fair.</p>



<p><strong>Marketed AI vs Profitable AI</strong></p>



<p>To the public, the tech giants selling AI solutions (Google, Microsoft, and Apple) pitch visions of AI <em>for good</em>.&nbsp;&nbsp;</p>



<p>The public face of these advertising campaigns is usually brand advertising, perhaps pitching consumers on a software ecosystem (Android, iOS), but rarely selling any specific product.&nbsp; This makes it easy to sell the public a <em>vision </em>of the future in HDR, backed by inspirational hipster soundtracks.</p>



<p>You all know what I’m talking about — you’ve seen them on TV and in movie theaters — but the imagery is so<em> honed, </em>so <em>heroic, </em>that we should look at the pictures anyway.</p>



<p>Google’s AI will do revolutionary things, like fix farming, improve birthday parties, and help us not walk off cliffs:&nbsp;</p>



<figure><img src="https://lh4.googleusercontent.com/jId-kNaiaBP0HNR6FjXXaS3HPKHoVr_tLUjEjjGS5sZ23IF1718IWzLeD719RSqO2Aj6vx3oDgeedE_Yjg5xcdNzl2IC71KP79uS0gUjyHSMEkLI1VALL8iqmwdhWXxTdGN7Qm2j" alt=""></figure>



<p>Microsoft’s AI is safe.&nbsp; You can tell because this man is looking <a href="https://www.microsoft.com/en-us/ai?activetab=pivot1%3aprimaryr5">very thoughtfully</a> into the distance:</p>



<figure><img src="https://lh5.googleusercontent.com/JKMsdtPMVmd5PHVOAgCleWpG4WctVm-3rGxiM70Tg0HsmDgdxYysjqjGR_zn0I8SEs-lLQxpOyKqxFI_RioIuGDGUFMillFX4T7IxZPI6jHpNiQ10YWpCoodiWli-Z8IxlRVFxq4" alt=""></figure>



<p>But if that is not enough to convince you, here is a bird:</p>



<figure><img src="https://lh5.googleusercontent.com/_NtL_Yy86NCoL4J_2kOpzAObYf9KTQ2D0i98JV4PnuAAE-yCqqAOXv7NGB_BSL8KJ-zBLGuiuqI5-fqmFkXLDVIONHPvvUWY6XWzjKC6D0LRaIVXjixdCWaidceDERUBRz-OyjP0" alt=""></figure>



<p>Microsoft goes into detail on their “AI for Good” page.&nbsp; The testimonials highlight the power of AI as applied to:</p>



<ul><li>Environmental sustainability (image recognition of land use, wildlife tracking, maximizing farm yields)</li><li>Healthcare (dredging through data to find diseases)</li><li>Accessibility (machine translation, text to speech)</li><li>Humanitarian action and Cultural Heritage preservation</li></ul>



<p>Even the Chinese search engine Baidu, not exactly known for their humanitarian work, <a href="https://internetofbusiness.com/baidu-becomes-first-chinese-firm-to-join-us-safe-a-i-consortium/">has joined</a> the OpenAI “safe AI” consortium, which is nominally dedicated to developing and selling only <em>safe </em>AI.</p>



<p>The theme among all these public “good AI” initiatives — the sales pitch to the public — is:</p>



<blockquote><p>“We’re developing advanced AI, but we’re partnering with NGOs, hospitals, and more, to make this AI work <em>for </em>people, not against them.&nbsp; Look at all the good we can do!”</p></blockquote>



<p>This isn’t fake.&nbsp; Microsoft <em>is </em>working with nonprofits, NGOs, and more, to deploy for-the-people AI.&nbsp; But these applications don’t get us closer to the <em>real </em>question:</p>



<p>“What solutions are <em>normal</em> companies <em>actually deploying </em>with AI-as-a-service cloud technology?”</p>



<p>We can peek behind the curtain at Amazon.&nbsp; Amazon’s AWS has been for the last decade synonymous with “the cloud”, and still has a full 50% market share.&nbsp; The bleeding edge of AWS are plug-and-play machine learning and AI tools: Amazon Forecast (machine learning), Amazon Polly (text to speech), Amazon Rekognition (video object recognition), Amazon Comprehend (natural language processing), and more.</p>



<p>And Amazon, alone and refreshingly among tech giants, <a href="https://www.computerworld.com/article/3463071/aws-is-ethical-about-ai-but-we-just-don-t-talk-about-it-say-apac-execs.html">doesn’t even pretend</a> to care why their customers use AI:</p>



<blockquote><p>“We certainly don’t want to do evil; everything we’ve released to customers to innovate [helps] to lift the bar on what’s actually happening in the industry. It’s really up to the individual organisation how they use that tech”</p></blockquote>



<p>Amazon sells AI to C-suites, and we know what the hooks are, because the marketing pitches are online.&nbsp; AWS <a href="https://aws.amazon.com/machine-learning/customers/?customer-references-cards.sort-by=item.additionalFields.publishedDate&amp;customer-references-cards.sort-order=desc&amp;awsf.customer-references-category=category%23ai-ml&amp;awsm.page-customer-references-cards=2">publishes case studies</a> about how their plug-and-play AI and ML solutions are used by customers.&nbsp;</p>



<p>We can look at a typical example <a href="https://aws.amazon.com/solutions/case-studies/dxc/?did=cr_card&amp;trk=cr_card">here</a>, outlining how DXC used AWS’s ML and AI toolkits to improve customer service call center interactions.&nbsp; Fair warning:&nbsp; the full read is catastrophically boring — which is to be expected when AI used not to expand the horizon of what is possible… but instead used to excise human labor from work which is already being done:</p>



<blockquote><p>“DXC has also reduced the lead time to edit and change call flow messaging on its IVR system. With its previous technology, it took two months to make changes to IVR scripts because DXC had to retain a professional voice-over actor and employ a specialized engineer to upload any change. With Amazon Polly, it only takes hours”</p></blockquote>



<blockquote><p>Using Amazon Connect, DXC has been able to automate password resets, so the number of calls that get transferred to an agent has dropped by 30–60 percent.</p></blockquote>



<blockquote><p>DXC anticipates an internal cost reduction of 30–40 percent as a result of implementing Amazon Connect, thanks to increased automation and improved productivity on each call.</p></blockquote>



<p>In total, what did DXC do with its deployed AI solution?&nbsp; AI is being used to:</p>



<ul><li>Replace a voice-over actor</li><li>Eliminate an operations engineer</li><li>Eliminate customer service agents</li></ul>



<p>There’s nothing evil in streamlining operations.&nbsp; But because of the split messaging being used to <em>sell </em>AI research to the public vs to industry — on one hand, visions of environmental sustainability and medical breakthroughs, and on the other hand, the mundane breakthrough of applying a scalpel to a call center’s staffing — the public has little insight (other than nagging discomfort) into automation end-game.&nbsp;&nbsp;</p>



<p>The complete lack of (organized) public anger or federal AI policy — or even an <em>attempt </em>at a policy — speaks to the success of this doublespeak.</p>



<p><strong>Research motivations</strong></p>



<p>So why are actual engineers and researchers <em>building </em>AI solutions?</p>



<p>I could dredge forums and form theories, but I decided to just <a href="https://www.reddit.com/r/artificial/comments/gz5so7/why_are_you_personally_working_on_ai/">ask on reddit</a>, in a quick and completely unscientific test.&nbsp; Feel free to read all the responses — I’ve tried to aggregate them here and distill them into the four main themes.&nbsp; Weighted by upvotes, here’s the summary:</p>



<figure><img src="https://lh4.googleusercontent.com/DvF1XOwrQOuSnpwX0z5y1YLq3keBLTdqSQqyOKj1FrdmNANo2gVWZXWjHnp282aio1EzBBfWMYNPfof4MKZDdeJoQKe18Znbw0jI-iI2QxmmeVkF-MTWGGOsnF1xAaSlMUCtiilV" alt=""></figure>



<p>Preface: none of these are radical new revelations.&nbsp; They match, in degrees, what you’d find with a more exhaustive dragnet of public statements, blogs, or after liquoring up the academic research mainstream.</p>



<p>Walking down the list:</p>



<p><strong>1. Improving the human condition</strong></p>



<p>A plurality goal is to better the human condition, which is promising.&nbsp; An archetypal response is a vision of a future without work (or at least, without universal work):</p>



<blockquote><p>“I believe the fundamental problem of the human race is that pretty much everyone has to work for us to survive.</p><p>So I want to work on fixing that.”</p></blockquote>



<p>It’s not a vision without controversy — it’s an open question whether people can really live fulfilled lives in a world where they <em>aren’t</em> <em>really needed —</em> but at minimum it’s a vision many could get behind, and is at root predicated in a goal of human dignity.</p>



<p><strong>2. It pays</strong></p>



<p>Close behind are crude economics.&nbsp; Top comment:</p>



<blockquote><p> “Dat money”</p></blockquote>



<p>I don’t intend to sound negative — capitalism is the lever which moves the world, and in capitalism, money follows value.&nbsp; But as shown by AWS, value can come from either revolutionary invention (delivering novel value), or cost excision (delivering <em>cheaper </em>value).</p>



<p>Either direction pays the bills (and engineers), and few megacorp engineers care to peek behind the curtain at which specific aspect of the AI product delivered to clients pays the bills.</p>



<p><strong>3. Transhumanism</strong></p>



<p>Here’s where the interests of true believers in AI diverge from the mainstream.&nbsp; Top comment:</p>



<blockquote><p>“I don’t really care about modern ML solutions, I am only concerned with AGI. Once we understand the mechanisms behind our own intelligence, we move to the next phase in our species’ evolution. It’s the next paradigm shift. Working on anything else wouldn’t be worth it since the amount of value it brings is so vast.”</p></blockquote>



<p>“I’m in it for the money” is just realism.&nbsp; “A world without work” and “making cheddar” are motivations which appeal to the mainstream, and is at least comprehensible (if frustrating) to those whose jobs are on the line.&nbsp;&nbsp;</p>



<p><a href="https://en.wikipedia.org/wiki/Transhumanism">Transhumanism</a> is different.&nbsp; There’s a prevalent (although possibly not majority) philosophy among many AI researchers, practitioners, and enthusiasts, that the goal of developing strong (human-level) AI is not a tool <em>for </em>humans, but an end unto itself.&nbsp; The goal is the creation of a grander intelligence beyond our own:</p>



<blockquote><p>“Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an ‘intelligence explosion,’ and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make.”</p></blockquote>



<p>Or, step-by-step:</p>



<ul><li>Humans create AI 1.0 with IQ human + 1</li><li>AI 1.0 creates AI 2.0, which is slightly smarter</li><li>AI 2.0 creates AI 3.0, which is WAY smarter</li><li>AI 3.0 creates AI 4.0, which is incomprehensibly smarter</li></ul>



<p>And whatever comes next… we can’t predict.</p>



<p>This is not a complete summary of transhumanism.&nbsp; There’s a spectrum of goals, and widespread desire for AI which can integrate <em>with</em> humans — think, nanobots in the brain, neural augmentation, or wholesale digital brain uploads.&nbsp; But either way — whether the goal is to retrofit or replace …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bpodgursky.com/2020/09/07/the-corporate-academic-public-ai-value-gap/">https://bpodgursky.com/2020/09/07/the-corporate-academic-public-ai-value-gap/</a></em></p>]]>
            </description>
            <link>https://bpodgursky.com/2020/09/07/the-corporate-academic-public-ai-value-gap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24396354</guid>
            <pubDate>Mon, 07 Sep 2020 03:20:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Investing in a Tax Efficient Manner]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24396276">thread link</a>) | @yacc79
<br/>
September 6, 2020 | https://www.dollartrak.com/what-is-tax-efficient-investing/ | <a href="https://web.archive.org/web/*/https://www.dollartrak.com/what-is-tax-efficient-investing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
					<div>
			<div>
		
				<div id="primary">
		<main id="main" role="main">
			
<article id="post-1028">
	<div>
		<!--post thumbnal options-->
		 
			<div>
				<a href="https://www.dollartrak.com/what-is-tax-efficient-investing/">
				 
            <p><img width="2560" height="1629" src="https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/wealth-over-time-scaled.jpg?fit=2560%2C1629&amp;ssl=1" data-src="https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/wealth-over-time-scaled.jpg?fit=2560%2C1629&amp;ssl=1" alt="wealth over time bar graph" loading="lazy" data-srcset="https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/wealth-over-time-scaled.jpg?w=2560&amp;ssl=1 2560w, https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/wealth-over-time-scaled.jpg?resize=300%2C191&amp;ssl=1 300w, https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/wealth-over-time-scaled.jpg?resize=1024%2C652&amp;ssl=1 1024w, https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/wealth-over-time-scaled.jpg?resize=768%2C489&amp;ssl=1 768w, https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/wealth-over-time-scaled.jpg?resize=1536%2C977&amp;ssl=1 1536w, https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/wealth-over-time-scaled.jpg?resize=2048%2C1303&amp;ssl=1 2048w, https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/wealth-over-time-scaled.jpg?w=1280&amp;ssl=1 1280w, https://i2.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/wealth-over-time-scaled.jpg?w=1920&amp;ssl=1 1920w" data-sizes="(max-width: 2560px) 100vw, 2560px">            </p><!-- .post-thumbnail -->

        				</a>
			</div><!-- .post-thumb-->
		
		<div>
			
			
			<!-- .entry-header -->

			<div>
				
<p>Tax efficient investing means carefully choosing certain investments and determining which accounts to hold them in to reduce to reduce your overall tax bill.  Saving money on taxes allows you to make larger investments and keep more of the returns.  In the long run, due to the power of compounding, this can have a dramatic impact on your overall <a href="https://www.dollartrak.com/net-worth-explained/">net worth</a>.  </p>



<p>When investing, there are things that you can control and things that you cannot control.  One area where you do have control over is your taxes.  One way the wealthy became that way was by <a href="https://www.cnbc.com/2019/02/21/here-are-5-ways-the-super-rich-manage-to-pay-lower-taxes.html" target="_blank" rel="noreferrer noopener">taking advantage of tax laws</a>.    </p>



<p>The impact of tax laws can vary widely based on your unique situation, so it is best to meet with a qualified accountant to help you establish a plan as soon as possible.</p>



<h4>Key Takeaways</h4>



<ul><li><strong>You should take advantage of opportunities to reduce your tax liability</strong> <strong>to maximize your eventual <a href="https://www.dollartrak.com/net-worth-explained/" target="_blank" rel="noreferrer noopener">net worth</a></strong></li><li><strong>Certain types of investments are more tax efficient than others</strong></li><li><strong>Certain types of investment holding accounts are more tax efficient than others</strong></li><li><strong>You should always hold your least tax efficient investments in your more tax efficient accounts</strong></li></ul>



<h2>Certain Investments are More Tax Efficient Than Others</h2>



<figure><img loading="lazy" src="https://i0.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/taxes.jpg?resize=456%2C303&amp;ssl=1" data-src="https://i0.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/taxes.jpg?resize=456%2C303&amp;ssl=1" alt="taxes" width="456" height="303" data-srcset="https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/taxes-scaled.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/taxes-scaled.jpg?resize=300%2C200&amp;ssl=1 300w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/taxes-scaled.jpg?resize=768%2C512&amp;ssl=1 768w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/taxes-scaled.jpg?resize=1536%2C1024&amp;ssl=1 1536w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/taxes-scaled.jpg?resize=2048%2C1365&amp;ssl=1 2048w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/taxes-scaled.jpg?w=1280&amp;ssl=1 1280w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/taxes-scaled.jpg?w=1920&amp;ssl=1 1920w" data-sizes="(max-width: 456px) 100vw, 456px" data-recalc-dims="1"></figure>



<p>Which investments you hold and how you hold them can have a tremendous impact on your long term returns.  The power of compounding can turn small differences now into large differences when you are older.  There are essentially two concepts to keep in mind here, and they are somewhat related.</p>



<ol><li>Some <em>investments</em> are more tax efficient than others</li><li>Some <em>accounts</em> are more tax friendly than others</li></ol>



<p>Your goal should be to hold your least efficient investments in your most tax efficient accounts.  As an example, you can do short term trading inside of a Roth IRA and totally avoid short term capital gains tax!</p>



<h2>What Makes an Investment Tax Efficient?</h2>



<p>Now that you know that some investments are more tax efficient than others let us look at what makes an investment tax efficient.  Investments that generate capital gains and dividends during the year will be generating a tax liability for you in addition to the income.  The more income that the investment generates the higher the tax liability.  </p>



<p>Alternatively, growth investments will not generate any income until you sell them.  This can allow you flexibility for when to earn the income, thus giving you control over when you pay the tax and how much tax you end up paying.  How long you hold an investment matters.  In general, if you hold an investment for over a year you get a reduced tax bill when you sell it.</p>



<p>Let’s take a closer look at how investments generate income and as a result income tax.</p>



<h3>How Do Investments Generate Tax Liability</h3>



<p>Investments can generate taxable income in several ways.  In general, if you sell an investment for more than you paid for it this is called a capital gain.  You will need to pay tax on the capital gain. Also, any cash flows generated from the investment while you own it are taxable income.</p>



<h4>Types of Investment Income</h4>



<ol><li><strong>Capital Gains </strong>– A capital gain is income you generate when you sell an investment for more than you paid for it.  It is defined as <em>sale price – purchase price = capital gain</em>.  Real estate and certain other assets can be more difficult calculate because deprecation of the original purchase price is allowed.  Investments held for more than 1 year before being sold are taxed as long-term gains and have a top federal rate of 23.8% (versus 40.8% for short-term).   This means you should always hold investments you intend to sell within a year in a tax advantaged account.</li><li><strong>Dividends, Interest and Rent</strong> – These are cash payments that are made you for owning the asset.  Stocks can pay dividends, bonds can pay interest, and real estate can pay you rent.  Dividends that are paid on a stock are taxed at the same rate that the capital gains would be on that stock.  This means that for the first year, you would be responsible for short term rate on the dividends.</li></ol>



<p>This is an important concept for stocks.  Growth stocks pay very little dividends but have a high appreciation rate. Dividend stocks have a more stable rate of appreciation but pay frequent dividends.  This means dividend stocks are more appropriately held in tax advantaged accounts and growth stocks that you intend to hold for more than a year can be held in a taxable account.</p>



<h3>Examples of Investments</h3>



<figure><table><thead><tr><th>Investment</th><th>Tax Efficiency</th></tr></thead><tbody><tr><td>Growth Stocks</td><td>High</td></tr><tr><td>Dividend Stocks</td><td>Low</td></tr><tr><td>Bonds</td><td>Low</td></tr><tr><td>Index ETFs</td><td>High</td></tr><tr><td>REITs</td><td>Low</td></tr><tr><td>Actively Managed Mutual Funds</td><td>Low</td></tr><tr><td>Municipal Bonds</td><td>High</td></tr><tr><td>Securities Held Short Term(&lt; 1 year)</td><td>Low</td></tr><tr><td>Crypto</td><td>High</td></tr><tr><td></td><td></td></tr></tbody></table><figcaption>Examples of Investments</figcaption></figure>



<h2>What are Tax Efficient Accounts?</h2>



<figure><img loading="lazy" width="640" height="384" src="https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/uncle-sam.png?resize=640%2C384&amp;ssl=1" data-src="https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/uncle-sam.png?resize=640%2C384&amp;ssl=1" alt="Uncle Sam" data-srcset="https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/uncle-sam.png?w=750&amp;ssl=1 750w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/07/uncle-sam.png?resize=300%2C180&amp;ssl=1 300w" data-sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"><figcaption>Uncle Sam wants you to pay your taxes</figcaption></figure>



<p>Uncle Sam gives you multiple options to hold investments in accounts where you won’t generate any tax liability at all.   The most commons ones are IRAs, 401Ks, Health Savings Accounts and Roth IRAs.  <a href="https://www.dollartrak.com/top-9-tax-advantaged-accounts/">Here</a> is a complete list of the tax advantaged accounts available to you.  </p>



<p>Only use a taxable account once you have maxed out your other areas of savings.  Only highly efficient investments should be held in a taxable account.  You will have to pay tax on your gains and dividends here, so you should hold your most efficient investments here.</p>



<h3>Should I Hold Tax Inefficient Investments at All?</h3>



<p>You only have so much money to invest and you should be concerned with the <a href="https://www.dollartrak.com/what-is-opportunity-cost/">opportunity cost</a> of your investment choices.  This may make you wonder why you would even invest in a tax inefficient choice to begin with.  </p>



<p>You should not rule out tax inefficient investments, you should just be careful where you hold them.  Many tax inefficient investments can have a good risk adjusted return provided you can mitigate the tax liability inherent with holding them.  Ultimately this will help you with diversification of your investments.  </p>



<h3>Take Advantage of as Many Tax Strategies as Possible</h3>



<p>A rational person should seek to pay the least amount of tax and generate the highest returns on their investments.  You should take advantage of every available way of avoiding taxes that you can.  The implications in any single tax year may not be dramatic, but over the course of your lifetime the power of compounding can turn that reduced tax bill into a fortune.</p>



<h2>Conclusion</h2>



<p>Tax efficiency should not be your primary concern when choosing an investment, but it should be considered.  Don’t eliminate an investment from consideration just because it has a low tax efficiency, but do hold it in a tax efficient account.  Pay attention to the period of time you expect to hold an investment.  Short term capital gains tax can be avoided completely if you hold the stock in a Roth IRA for example.</p>



<p>Ultimately reducing your tax burden will allow you to keep more money invested and due to the power of compounding it can have a dramatic impact on your long term returns.</p>

			</div><!-- .entry-content -->
			
		</div>
	</div>
</article><!-- #post-## -->					
					

						</main><!-- #main -->
	</div><!-- #primary -->
<!-- #secondary -->

    		</div><!-- #row -->
		</div><!-- #container -->
	</div></div>]]>
            </description>
            <link>https://www.dollartrak.com/what-is-tax-efficient-investing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24396276</guid>
            <pubDate>Mon, 07 Sep 2020 03:00:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[David Graeber on harmful jobs, odious debt, and fascists who mind global warming]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24396247">thread link</a>) | @kunfuu
<br/>
September 6, 2020 | https://www.disenz.net/en/david-graeber-on-harmful-jobs-odious-debt-and-fascists-who-believe-in-global-warming/ | <a href="https://web.archive.org/web/*/https://www.disenz.net/en/david-graeber-on-harmful-jobs-odious-debt-and-fascists-who-believe-in-global-warming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>It was a warm spring evening in London and David Graeber, an anthropology professor at the LSE, was sitting on a rooftop. Our conversation was transmitted through the Internet because of the global travel ban due to the coronavirus pandemic. However, we did not only talk about the new virus and its consequences for society, politics, and the economy. We took the rare opportunity to discuss most of his published works – from the <em>Fragments of Anarchist Anthropology</em> and <em>Debt</em> to <em>Utopia of Rule</em>s, and his most recent book <em>The Bullshit Jobs</em>. All of which have become even more relevant during the corona-crisis.</p>



<p>Professor Graeber presents himself as an anthropologist and anarchist. However, he will not be happy if you refer to him as an “anarchist anthropologist” because there is no such discipline, which he explained during the conversation. The professor is also an activist. He joined many social movements and protests in the last few decades and is often credited as the author of the unofficial slogan from the Occupy Wall Street movement: We are the 99 percent. But he insists that the slogan – as well as everything else in the movement – was a collective effort.</p>



<p>How can democratic governments use this health crisis to enforce authoritarian measures on their citizens? Why don’t the health and care workers strike, during the pandemic, for higher wages? What would happen if we closed Wall Street for a few months? Why do we only see flying cars as special effects in science fiction movies? How can anarchistic principles bring order into chaos during the crisis? Why do we not want to depend on the Chinese and US armies to save our planet?</p>



<p>And finally – how can a drunken rant become a best-selling book?</p>



<figure><img src="https://www.disenz.net/wp-content/uploads/2020/05/DG-in-office-IMG_2027.JPG-1-2-768x1024.jpeg" alt="" width="561" height="748" srcset="https://www.disenz.net/wp-content/uploads/2020/05/DG-in-office-IMG_2027.JPG-1-2-768x1024.jpeg 768w, https://www.disenz.net/wp-content/uploads/2020/05/DG-in-office-IMG_2027.JPG-1-2-225x300.jpeg 225w, https://www.disenz.net/wp-content/uploads/2020/05/DG-in-office-IMG_2027.JPG-1-2-rotated.jpeg 864w" sizes="(max-width: 561px) 100vw, 561px"><figcaption>David Graeber in his office</figcaption></figure>



<p><strong>Everybody seems to be speaking the same language during the coronavirus pandemic – from progressive and conservative governments to ISIS and the anarchists: stay at home, wash your hands, avoid other people … And people have been listening to the officials without much protest. They stayed at home and accepted the new rules. We have not seen anything like this for a long while. What has happened?</strong></p>



<p>Well, there are just not all that many people who are quite crazy enough to ignore medical advice during a pandemic.</p>



<p>It brings to mind the 19<sup>th</sup> century French political thinker Henry Saint-Simon—who might have been the first person to come up with the notion of withering away of the state. He argued that if the state was refounded on scientific basis, eventually it would not need to rely on coercion, and therefore, it wouldn’t even be a state in the contemporary sense of having a monopoly of violence.</p>



<p><strong>Why?</strong></p>



<p>For the same reason, he said, that doctor doesn’t have to threaten to beat you up to convince you to the medicine they prescribe. You know the doctor knows something you don’t know, and you assume the doctor is acting in your best interest. Saint-Simon argued once the state was rationally founded on scientific principles, citizens would act in the same way, and coercive enforcement would become unnecessary. Maybe they’d be a few nutty people who refuse to take their medicine but not enough to make much difference.</p>



<p>Obviously this was all very optimistic and naive—that’s why Marx dismissed people like Saint Simon as “utopian socialists”. But there are certain branches of the government that still claim to operate on such basis. And one could make the argument that they’re not by their nature part of government at all.</p>



<p>During the student movement in the UK in 2010 we talked about this a lot, we were mostly anarchists, but we believed in a public health system, and a public university system. Was this hypocritical? None of us felt it was, but we talked a lot about why. Perhaps the problem is that states don’t allow the existence of public institutions – that is, ones which are both universal and non-profit-oriented – that they don’t control. That doesn’t mean those institutions are somehow of the same nature as the army, or prison system, which are entirely creatures of the state.</p>



<blockquote><p>The idea that knowledge is always a form of power is very flattering to academics, who have a great deal of one and very little of the other, so it’s hardly surprising they like it so much.</p></blockquote>



<p><strong>Yes and of course Foucault would say the authority that does not need a violent force to enforce itself is the scariest kind of all.</strong></p>



<p>He would. Though I think Foucault is often misinterpreted in this regard, to assume that any truth discourse is a form of power, and every form of power is violent and objectionable in itself. True, he sometimes sounds as if that’s what he’s saying. But if specifically challenged, he’d always say, no, no, obviously not.</p>



<p>The idea that knowledge is always a form of power is very flattering to academics, who have a great deal of one and very little of the other, so it’s hardly surprising they like it so much. Foucault himself had his own immediate concerns – he was diagnosed as a homosexual in his youth, and wanted to understand how it came about that his most intimate desires could be considered a disease.</p>



<p>He effectively dedicated his life to trying to understand that. But many on the academic left forget that, such diagnoses were not just abstractions, they ultimately relied on force of law, on the threat of physical violence, even if the doctor isn’t personally carrying a gun. A kind of vulgar Foucauldianismn has encouraged us to overlook how much the threat of force really does still lurk behind most of the institutions he describes.</p>



<p>The Panopticon was a prison after all. Normally if you think someone might be staring at you at any moment, you just go someplace else. Actually things have gotten rather worse in that respect since Foucault’s time. There didn’t used to be actual armed guards in schools and hospitals; now in many places there are.</p>



<p><strong>Many governments all over the world are using public health to enforce measures that could not have been imaginable in democratic societies only a few months ago. In Slovenia, for example, individuals are fined when they try to protest against the government actions. Not for protesting, of course. That would be undemocratic. But for violating the law on infectious diseases. So the only groups of people that are allowed move freely are the police, the army, and the politicians.</strong></p>



<p>That does not surprise me. You can learn a lot of things about your state by comparing how they treat a political assembly, and any other kind.</p>



<p><strong>In what way?</strong></p>



<p>In liberal democracies, the entire justification for a country’s legal structure is, typically, some kind of ideal of human freedom and liberty. The American bill of rights begins with the freedom of speech, freedom of press, and freedom of assembly. In practice, the assembly of people that gather in order to protest – which is the very essence of what is supposed to be American – is considered <em>less</em> legitimate than an assembly of people who want to sell you something.</p>



<p>You point this out to most middle-class Americans, they seem incredulous. Poor ones not so much, they don’t assume the rules are fair. Anyway: they’ll say “but of course you have the right to assemble, you just need a permit, what’s wrong with that?” So you have to say “all right, if you have to ask police permission to print something, that’s called not having freedom of the press. If you have to ask police permission to say something..” And they’ll say, “but that’s different! There are traffic issues. You can’t just gather. It gets in the way of people walking down the street” Which is funny, because I don’t remember anywhere in the constitution it says anything about the right to unimpeded traffic flow.</p>



<p>We learned that lesson during the Occupy movement. It was startling, after they evicted our camp, how many middle class Americans just shrugged their shoulders when they went on to rip up the Bill of Rights, the very thing they teach their children to be so proud of…</p>



<blockquote><p>The Anonymous movement has shown that you can have meaningful and impactful protests online. And people all across the world are inventing new ways to protest from their home.</p></blockquote>



<p><strong>You were trying to occupy a public space?</strong></p>



<p>Any space. After they evicted us from Zuccotti Park, we tried to reestablish a new camp because… well, it was crucial that everyone knew where we were. That was what was so effective about the original occupation: anyone in the city who felt they wanted to get involved knew where they could go and plug in instantly.</p>



<p>At first we thought we could relocate to a huge lot near Wall Street that belong to the Episcopalian Church, they agreed, but huge pressure was place on the Church hierarchy and eventually they reversed themselves. We had a march led by several bishops trying to occupy anyway; the cops beat us up, and the media refused to show any footage of the priests but only anyone in masks to make us look violent and scary.</p>



<p>Then we occupied a park that was open all night and they changed the rules of the park. We then got a legal ruling from a judge that we could sleep on the sidewalk as long as we do not take more than half of it. So the city just passed an order that Lower Manhattan was an emergency zone where legal decisions do not apply. So we decided to occupy the stairs of the building where the Bill of Rights was actually signed, which is right near Wall Street incidentally, but wasn’t under city jurisdiction. We were immediately were surrounded by SWAT teams and after two days they found a way to force us from there.</p>



<p>We tried everything to set up a legal alternative. But the state completely simply shredded the very legal principles that they teach children are what makes them proud to be Americans, and the media didn’t even cover it.</p>



<p><strong>But what can you occupy when you are not allowed to even leave your own apartment?</strong></p>



<p>There are always things you can do. The Anonymous movement has shown that you …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.disenz.net/en/david-graeber-on-harmful-jobs-odious-debt-and-fascists-who-believe-in-global-warming/">https://www.disenz.net/en/david-graeber-on-harmful-jobs-odious-debt-and-fascists-who-believe-in-global-warming/</a></em></p>]]>
            </description>
            <link>https://www.disenz.net/en/david-graeber-on-harmful-jobs-odious-debt-and-fascists-who-believe-in-global-warming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24396247</guid>
            <pubDate>Mon, 07 Sep 2020 02:52:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Distilling Inductive Biases]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24395986">thread link</a>) | @hardmaru
<br/>
September 6, 2020 | https://samiraabnar.github.io/articles/2020-05/indist | <a href="https://web.archive.org/web/*/https://samiraabnar.github.io/articles/2020-05/indist">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p><a href="https://en.wikipedia.org/wiki/No_free_lunch_in_search_and_optimization">No free lunch theorem</a> states that for any learning algorithm, any improvement on performance over one class of problems is balanced out by a decrease in the performance over another class <a href="#wolpert1997no">(Wolpert &amp; Macready, 1997)</a>. In other words, <strong>there is no “one size fits all” learning algorithm</strong>.</p>

<p>We can see this in practice in the deep learning world. Among the various neural network architectures, each of them are better or worse for solving different tasks based on their inductive biases. For example, consider the image classification problem. CNNs are the de facto choice for processing images and in general data with grid-like topology. Sparse connectivity and parameter sharing in CNNs make them an effective and statistically efficient architecture.</p>

<p>The convolution operation in combination with max pooling makes CNNs approximately invariant to translation.
When a module is translation invariant, it means that if we apply translation transformation on the input image, i.e., change the position of the objects in the input, the output of the module won’t change. In mathematical terms if  is translation invariant, then , where  is a translation function.
A module could also be translation equivariant, which means that any translation in the input will be reflected in the output. In mathematical terms, if  is translation equivariant, then .
The convolution operation is translation equivariant, and applying a pooling operation on top of it results in translation invariance!</p>

<!-- _includes/image.html -->
<div>
    
        <p><img src="https://samiraabnar.github.io/img/indist_images/translation_invariance.gif" alt="Translation Invariance"></p><p>Translation invariance</p>
    
</div>

<p>Translation invariance of CNNs improves their generalization and makes them data efficient compared to fully connected networks. For example, if, during training, a CNN has only seen pictures of cats where the cat is located at the centre of the image, it can correctly classify cats at test time independent of their position in the image.  In the lack of this inductive bias, the model needs to see examples of cats at different positions to be able to correctly classify them at test time.
On the other hand, this translation invariance can hurt the performance of CNNs in cases where the position of the objects in the image matters. This is known as the Picasso effect, where you have all the pieces of an object but not in the right context (One of the motivations behind <a href="http://samiraabnar.github.io/articles/2019-03/capsule">CapsNets</a> is to address this drawback).</p>

<!-- _includes/image.html -->
<div>
    
        <p><img src="https://samiraabnar.github.io/img/indist_images/Pablo-Picasso-Spanish-Cubist-Oil-Canvas-Portrait.jpg" alt="Oil on canvas. Featuring a cubist portrait."></p><p>Oil on canvas, featuring a cubist portrait, attributed to Pablo Picasso (1881-1973, Spanish)</p>
    
</div>

<p>Another example of such tradeoffs are recurrent neural networks (RNNs) in contrast to Transformers. It has been shown that the recurrent inductive bias of RNNs helps them capture hierarchical structures in sequences (<a href="https://samiraabnar.github.io/articles/2020-05/recurrence">Take a look at my other blog post about the recurrecnt inductive bias</a>). But this recurrence and the fact that RNNs’ access to previous tokens is limited to their memory makes it harder for them to deal with long term dependencies.
Besides, RNNs can be rather slow because they have to process data sequentially, i.e, they are not parallelizable. On the other hand, Transformers have direct access to all input tokens and they are very expressive when it comes to representing longer context sizes. Also, they can process the input sequence in parallel, hence they can be remarkably faster than LSTMs. However, Transformers struggle to generalize on tasks that require capturing hierarchical structures when training data is limited.</p>

<p>It might not be possible to have one model that can single handedly achieve the desired generalization behaviour on a wide range of tasks, but would it be possible to benefit from the inductive biases of different models during training to have one best model at inference?</p>

<p>Fortunately, it seems to be possible to do this to some extent!
In this post, I discuss our paper, <a href="https://arxiv.org/abs/2006.00555">“Transferring Inductive Biases through Knowledge Distillation”</a>, where we show that it is possible to transfer the effect of inductive bias through knowledge distillation and this can be a step toward achieving the goal of combining the strengths of multiple models in one place.</p>

<h4 id="what-is-inductive-bias">What is Inductive bias?</h4>
<p>Inductive biases are the characteristics of learning algorithms that influence their generalization behaviour, independent of data. They are one of the main driving forces to push learning algorithms toward particular solutions <a href="#mitchell1980need">(Mitchell, 1980)</a>.
In the absence of strong inductive biases, a model can be equally attracted to several local minima on the loss surface; and the converged solution can be arbitrarily affected by random variations, for instance, the initial state or the order of training examples <a href="#sutskever2013importance">(Sutskever et al., 2013; McCoy et al., 2020; Dodge et al., 2020)</a>.</p>

<p>In figure below, we see a schematic example of the paths that different instances of two models with different levels of inductive biases follow on a fitness landscape.<sup id="fnref:3be40dd2"><a href="#fn:3be40dd2">1</a></sup></p>

<!-- _includes/image.html -->
<div>
    
        <p><img src="https://samiraabnar.github.io/img/indist_images/inductive_bias_distilation_example_1.png" alt="Oil on canvas. Featuring a cubist portrait."></p><p>A drawing of how inductive biases can affect models' preferences to converge to different local minima. The inductive biases are shown by colored regions (green and yellow) which indicates regions that models prefer to explore.</p>
    
</div>

<p>There are two types of inductive biases: <strong>restricted hypothesis space bias</strong> and <strong>preference bias</strong>. Restricted hypothesis space bias determines the expressively of a model, while preference bias weighs the solutions within the hypothesis space <a href="#Craven1996ExtractingCM">(Craven, 1996)</a>.</p>

<p>From another point of view, as formulated by <a href="#seuncurve">(Seung et al., 1991)</a> we can study models from two aspects:</p>
<ol>
  <li>Whether a solution is realisable for the model, i.e., there is at least one set of weights that leads to the optimal solution.</li>
  <li>Whether a solution is learnable for the model, i.e., it is possible for the model to learn that solution within a reasonable amount of time and computations.</li>
</ol>

<p>In many cases in deep learning, we are dealing with models that have enough expressive power to solve our problems, however, they have different preference biases. Meaning the desired solutions are realisable for all of them, but depending on the task at hand it is more easier for some of them to learn the solutions compared to the others.</p>

<!-- So,once we have the desired solution, we might be able to guid the other models toward that  solution. -->

<h4 id="having-the-right-inductive-bias-matters">Having the Right Inductive Bias Matters</h4>
<p>To understand the effect of inductive biases of a model, we need to take a look at its generalization behaviour.</p>

<p>Let’s walk through the example of LSTMs and Transformers.
When we train these models on language modelling, i.e., predicting the next word in a sequence, they both achieve more or less similar perplexities.
But how can we know which one is learning a more generlizable solution? One way to check the generalizability of language models is to test how well they have learned the syntactic rules of the language and the hierarchical structures of the sentences.
The task of subject-verb agreement is designed for this purpose, i.e., to assess the ability of models to caputre hierchical structure in the language.
In this task, the goal for the model is to predict the number of a masked verb in a given sentence. To do this, the model needs to correctly recognize the subject of the verb in the sentence and the main difficulty is when the verb does not follow the subject immediately and there are one or more agreement attractors<sup id="fnref:f53f52f4"><a href="#fn:f53f52f4">2</a></sup> between the subject and the verb. In the figure below, we see an example for this task.</p>

<!-- _includes/image.html -->
<div>
    
        <p><img src="https://samiraabnar.github.io/img/indist_images/sv_example.png" alt=""></p><p>An example from the subject-verb agreement task</p>
    
</div>

<p>Comparing different instances of LSTMs and Transformers, with different perplexities, we observe that LSTMs have a higher tendency toward solutions that achieve better accuracy on the <a href="https://github.com/TalLinzen/rnn_agreement">subject verb agreement task</a>. We can see that, LSTMs with worse perplexities achieve better accuracies than Transformers with better perplexities.</p>

<!-- _includes/image.html -->
<div>
    
        <p><img src="https://samiraabnar.github.io/img/indist_images/Screenshot%202020-05-22%20at%2021.13.43.png" alt=""></p><p>Accuracy on verb number prediction vs perplexity</p>
    
</div>

<p>Now, let’s go back to the CNN example and see how the inductive bias of CNNs works in practice.
We can view CNNs as MLPs with an inﬁnitely strong prior over their weights, which says that the weights for one hidden unit must be identical to the weights of its neighbor but shifted in space, also that the weights must be zero, except for in the small, spatially contiguous receptive ﬁeld assigned to that hidden unit <a href="#Goodfellow-et-al-2016">(Goodfellow et al., 2016)</a>.
Hence, to measure the effectiveness of the CNNs inductive biases we can compare them to MLPs.
Here you can see the results of training CNNs and MLPs on the MNIST dataset and evaluating them on the translated and scaled version of MNIST from the <a href="https://github.com/google-research/mnist-c">MNIST-C</a> dataset.</p>

<!-- _includes/image.html -->
<div>
    
        <p><img src="https://samiraabnar.github.io/img/indist_images/Screenshot%202020-05-25%20at%2012.16.21.png" alt=""></p><p>Accuracy and Expected Calibration Error (mean$\pm$std over multiple trials) of CNNs and MLPs trained on MNIST and evaluated on MNIST, MNIST-Scaled and MNIST-Translated</p>
    
</div>

<p>As expected, even though the accuracies of MLPs and CNNs are only slightly different on the original MNIST test set, CNNs can generalize much better to the out of distribution test sets that include translated and scaled MNIST examples.</p>

<h4 id="knowledge-distillation-to-the-rescue">Knowledge Distillation to the Rescue</h4>
<p>There are different ways to inject inductive biases into learning algorithms, for instance, through architectural choices, the objective function, curriculum  strategy, or the optimisation regime.
Here, we exploit the power of Knowledge Distillation (KD) to transfer the effect of inductive biases between neural networks.</p>

<!-- _includes/image.html -->
<div>
    
        <p><img src="https://samiraabnar.github.io/img/indist_images/inductive_bias_distilation_example_2.png" alt="Oil on canvas. Featuring a cubist portrait."></p><p>A drawing of how inductive biases can be transferred through distillation. The inductive biases are shown by colored regions (green and yellow) which indicates regions that models prefer to explore.</p>
    
</div>

<p>KD refers to the process of transferring knowledge from a teacher model to a student model, where the logits from the teacher are used to train the student. It is best known as an effective method for model compression <a href="#hinton2015distilling">(Hinton et al., 2015)</a> which allows taking advantage of the huge number of parameters during training, without losing the efficiency of a smaller model during inference.
When we have a teacher that performs very well on a given task, using it to train another model can lead to an improved performance in the student …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samiraabnar.github.io/articles/2020-05/indist">https://samiraabnar.github.io/articles/2020-05/indist</a></em></p>]]>
            </description>
            <link>https://samiraabnar.github.io/articles/2020-05/indist</link>
            <guid isPermaLink="false">hacker-news-small-sites-24395986</guid>
            <pubDate>Mon, 07 Sep 2020 01:31:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing Azure Functions on Azure DevOps – part 1: setup]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24395947">thread link</a>) | @davideguida
<br/>
September 6, 2020 | https://www.davideguida.com/testing-azure-functions-on-azure-devops-part-1-setup/ | <a href="https://web.archive.org/web/*/https://www.davideguida.com/testing-azure-functions-on-azure-devops-part-1-setup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p>Hi All! Today we’re going to talk a bit about testing strategies for Azure Functions. We’ll see how setup our test framework and in another article, we’ll see how to create a build pipeline on Azure DevOps.</p>



<p>As part of my daily job, I’m spending a lot of time working with Azure and Azure Functions. These days I’m also working a lot with <a href="https://www.davideguida.com/how-to-use-azure-durable-entities-to-see-whos-the-strongest-avenger/" target="_blank" rel="noreferrer noopener">Durable Entities</a>, which open the door to even more scenarios. Anyways, no matter what’s the technology behind, one of the best ways to ensure that our software is reliable is to add automatic tests. And these tests <strong>have to be part of the build pipeline</strong>.</p>



<p>Now, based on my researches so far, we can’t create a Functions Host directly as <a rel="noreferrer noopener" href="https://www.davideguida.com/testing-boundaries-web-api/" target="_blank">we could do</a> for a “regular” WebAPI. What we can do instead is make use of the <a rel="noreferrer noopener" href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-run-local?WT.mc_id=DOP-MVP-5003878" target="_blank">Azure Function Core Tools</a> and manually (aka via code) spin up the host in an XUnit Fixture.</p>



<p>This has the only drawback that when running the tests locally we won’t be able to debug the Function code. However, keep in mind the goal here: we want to test the boundaries of our services by probing the various <a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings?WT.mc_id=DOP-MVP-5003878" target="_blank" rel="noreferrer noopener">Function Triggers</a>. </p>



<h4>And this is a form of <em><a href="https://academic.microsoft.com/topic/24169984/publication/search?q=Black-box%20testing&amp;qe=And(Composite(F.FId%253D24169984)%252CTy%253D%270%27)&amp;f=&amp;orderBy=0" target="_blank" rel="noreferrer noopener">Black Box Testing</a></em><strong>:</strong> we’re not supposed to know what’s inside the box, only how to operate it.</h4>



<p>If we need to debug, we can always run the Function project directly from VS and check the behaviour via Postman (if it’s a REST endpoint). Just sayin’.</p>



<p>Moreover, as stated before, we will be executing those tests in our build pipeline, so debugging is not our primary interest.</p>



<p>Anyways, let’s just into the code! The first thing to do, assuming we already have an <strong>Azure Functions</strong> project, is to create the Test project, add a reference to XUnit and create a <a href="https://xunit.net/docs/shared-context" target="_blank" rel="noreferrer noopener">Fixture</a>:</p>



<pre data-enlighter-language="csharp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">public class AzureFunctionsFixture : IDisposable
{
	private readonly Process _funcHostProcess;	

	public readonly HttpClient Client;

	public AzureFunctionsFixture()
	{		
		var port = /*get this from config*/
		var dotnetExePath = /*get this from config*/
		var functionHostPath = /*get this from config*/		
		var functionAppFolder = /*get this from config*/

		_funcHostProcess = new Process
		{
			StartInfo =
			{
				FileName = dotnetExePath,
				Arguments = $"\"{functionHostPath}\" start -p {port}",
				WorkingDirectory = functionAppFolder
			}
		};
		var success = _funcHostProcess.Start();
		if (!success || _funcHostProcess.HasExited)
			throw new InvalidOperationException("Could not start Azure Functions host.");

		this.Client = new HttpClient();
		this.Client.BaseAddress = new Uri($"http://localhost:{port}");
	}
}</pre>



<p>As you can see, in the cTor we’re reading few values from the configuration:</p>



<ul><li>the path to <em>dotnet.exe</em></li><li>the path to <em>func.dll</em> from the <strong>Azure Functions Core Tools</strong></li><li>the path to our Azure Functions DLL</li><li>the port we want to use to expose the host </li></ul>



<p>The <em>Process</em> class will be basically running something like:</p>



<pre><em>dotnet "%APPDATA%\npm\node_modules\azure-functions-core-tools\bin\func.dll" start -p 7071</em> </pre>



<p>from the <em>bin\Debug</em> (or <em>Release</em>) directory of our Azure Functions project.</p>



<p>We’re also creating and publicly exposing an <em>HttpClient</em>: our tests will be using it to “talk” with the Functions Host. To keep things simple, I’m assuming that we’re using only HTTP Triggers. </p>



<p>As some of you might have noticed, the Fixture class is also implementing <em>IDisposable</em>, to properly dispose of the <em>Process </em>and of the <em>HttpClient</em>:</p>



<pre data-enlighter-language="csharp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">public void Dispose()
{
	this.Client?.Dispose();

	if (null != _funcHostProcess)
	{
		if (!_funcHostProcess.HasExited)
			_funcHostProcess.Kill();

		_funcHostProcess.Dispose();
	}
}</pre>



<p>The next thing to do is to create our test class as usual. Now, it’s quite likely that we might want to split our tests into multiple classes. </p>



<h4>In this case, we have to make sure to not spin up more than one Functions Host. </h4>



<p>Luckily, XUnit comes to the rescue with <em><a href="https://xunit.net/docs/shared-context#collection-fixture" target="_blank" rel="noreferrer noopener">Collection Fixtures</a></em>. All we have to do is to create an empty class and mark it with the <em>CollectionDefinition</em> attribute:</p>



<pre data-enlighter-language="csharp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">[CollectionDefinition(nameof(AzureFunctionsTestsCollection ))]
public class AzureFunctionsTestsCollection : ICollectionFixture { }</pre>



<p>Now we can decorate our test classes with all the necessary attributes and inject the <em>Fixture</em>:</p>



<pre data-enlighter-language="csharp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">[Collection(nameof(AzureFunctionsTestsCollection))]
[Category("Contract")]
[Trait("Category", "Contract")]
public class TriggerWorkflowTests
{
	private readonly AzureFunctionsFixture _fixture;

	public TriggerWorkflowTests(AzureFunctionsFixture fixture)
	{
		_fixture = fixture;
	}

	[Fact]
	public async Task FooFunc_should_do_something_and_not_fail_miserably()
	{
		var response = await _fixture.Client.GetAsync("api/foo");
		response.IsSuccessStatusCode.Should().BeTrue();
	}
}</pre>



<p>That’s all for today! Next time we’ll push our Azure Functions to the repository and make sure the build pipeline runs fine. Ciao!</p>

			</div></div>]]>
            </description>
            <link>https://www.davideguida.com/testing-azure-functions-on-azure-devops-part-1-setup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24395947</guid>
            <pubDate>Mon, 07 Sep 2020 01:21:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My thoughts about editors in 2020]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24395863">thread link</a>) | @todsacerdoti
<br/>
September 6, 2020 | https://phaazon.net/blog/editors-in-2020 | <a href="https://web.archive.org/web/*/https://phaazon.net/blog/editors-in-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><h2><em>editor, vim, neovim, atom, vs-code, emacs, intellij-idea</em></h2><h2>2020-09-07 00:03:00 UTC, by Dimitri Sabadie — <a href="https://phaazon.net/blog/feed">feed</a></h2><hr><div><p>I have been trying a lot of editors lately. When I say “trying”, I really meant I spent some time configuring and using those editors. The ones I spent time using are:</p>
<ul>
<li><a href="https://neovim.io/">neovim</a>, my main, daily editor I use for pretty much almost all projects I work on.</li>
<li><a href="https://www.jetbrains.com/idea">IntelliJ IDEA</a>, that I currently use at work to hack on Java codebases.</li>
<li><a href="https://code.visualstudio.com/">VS Code</a>, that I have been trying mainly in Rust, TOML and Markdown.</li>
<li><a href="https://www.gnu.org/software/emacs">emacs</a>, that I highly hacked around to play on my Haskell and Rust codebases (and YAML / Markdown / TOML too).</li>
<li><a href="https://github.com/hlissner/doom-emacs">DOOM Emacs</a>, that I tried when I saw a colleague in a previous company I worked in (I was impressed by the “united” feeling of the UI and by how everything looked so slick). So I gave it a try.</li>
<li><a href="https://atom.io/">atom</a>, <a href="https://github.com/">GitHub</a>’s take on editors. Same thing, mostly Rust, Haskell, etc.</li>
<li>A bunch of others that I won’t talk about because I quickly stopped using.</li>
</ul>
<p>The goal of this article is to create a temporal “snapshot” of my views on editors and what I think about the current situation. I have been using vim and especially neovim for more than a decade. I need to explain about my current workflow and what I cherish in editing before talking about each editors. Expect a point of view from a neovimer which is looking around at lots of editors.</p>
<blockquote>
<p>This is only a personal workflow / point of view that works well <em>for me right now</em>. It doesn’t mean it will for you and it doesn’t mean a different workflow would be worse.</p>
</blockquote>
<!-- vim-markdown-toc GFM -->
<ul>
<li><a href="#what-i-think-powerful-editing-should-be">What I think powerful editing should be</a>
<ul>
<li><a href="#keyboard-layout">Keyboard layout</a></li>
<li><a href="#modal-editors">Modal editors</a></li>
<li><a href="#how-i-like-to-move-around">How I like to move around</a></li>
<li><a href="#all-the-other-modal-candies">All the other modal candies</a></li>
</ul></li>
<li><a href="#the-editors">The editors</a>
<ul>
<li><a href="#neovim">neovim</a>
<ul>
<li><a href="#my-neovim-setup">My neovim setup</a></li>
<li><a href="#what-i-like-about-neovim">What I like about neovim</a></li>
<li><a href="#what-i-dislike-about-neovim">What I dislike about neovim</a></li>
</ul></li>
<li><a href="#intellij-idea">IntelliJ IDEA</a>
<ul>
<li><a href="#what-i-like-about-intellij-idea">What I like about IntelliJ IDEA</a></li>
<li><a href="#what-i-dislike-about-intellij-idea">What I dislike about IntelliJ IDEA</a></li>
</ul></li>
<li><a href="#vs-code">VS Code</a>
<ul>
<li><a href="#what-i-like-about-vs-code">What I like about VS Code</a></li>
<li><a href="#what-i-dislike-about-vs-code">What I dislike about VS Code</a></li>
</ul></li>
<li><a href="#emacs-and-doom-emacs">emacs and DOOM emacs</a>
<ul>
<li><a href="#what-i-like-about-emacs--doom-emacs">What I like about emacs / DOOM emacs</a></li>
<li><a href="#what-i-dislike-about-emacs--doom-emacs">What I dislike about emacs / DOOM Emacs</a></li>
</ul></li>
<li><a href="#atom">atom</a>
<ul>
<li><a href="#what-i-like-about-atom">What I like about atom</a></li>
<li><a href="#what-i-dislike-about-atom">What I dislike about atom</a></li>
</ul></li>
</ul></li>
<li><a href="#wrap-it-up">Wrap it up</a></li>
</ul>
<!-- vim-markdown-toc -->

<h2 id="keyboard-layout">Keyboard layout</h2>
<p>I am French and I’m using a keyboard layout that is made to type very quickly in French and to code. With hindsight, since I type more often in English than in French, maybe I should have picked another keyboard layout, but the coding experience in my keyboard layout is really great, so I stick around.</p>
<p>The keyboard layout is <strong>bépo</strong>. I learned bépo the “recommended” way — i.e.&nbsp;you have to practice <em>typing</em> (« dactylographie » in French). It means that I use all my fingers to type on a keyboard, and that each key on the keyboard is assigned <em>a single finger</em> that will press it. That helps a lot with muscle memory and to reduce wrist pain (my wrists barely move when I type on a keyboard), among other things. The typing speed is a side-effect of being accurate and having good comfort (if you are curious, I’m pretty fast but there are faster people — I type at around 120 to 130 words per minute). Because I think the speed doesn’t matter when programming, I think the most important part to remember here is the comfort: the wrists don’t move and my fingers fly around the keyboard, whatever the speed.</p>
<h2 id="modal-editors">Modal editors</h2>
<p>I think a modal editor is superior, for various reasons. The first one is that I truly <strong>hate</strong> having to use a <em>mouse</em> for something that can be done without having to move around hundred of pixels with your cursor and clicking on buttons. For instance, running an application, on my current machines, is simply typing <code>alt d</code>, the name of the program (I typically use completion, so I never type fully the name of the program) and hit enter. All this without moving my hands from the keyboard. And I do that for programs like <code>firefox</code>, <code>kdenlive</code>, etc. but for terminal applications, I simply type and complete them in my terminal, which I open simply with <code>alt return</code>.</p>
<p>So, using a mouse to move around a cursor in an editor feels like completely suboptimal to me, especially because we write code (i.e.&nbsp;we type on a keyboard) most of the time, so moving around with the mouse implies several back and forth movements between the keyboard and the mouse. Maybe you don’t care and it’s cool to you, but to me, this is truly <em>horror land</em>. I feel <em>very</em> uncomfortable when doing this.</p>
<p>Also, <em>modern editors</em> that are not modal typically make people move by using the arrows keys, which are either far on your keyboard, or — like my keyboard, a 60% home made one — not in direct access and then require a function key to enable them.</p>
<p>So that’s the first reason why I like modal editors. They make a smarter use of your keyboard for simple yet recurrent features, like moving around — e.g.&nbsp;<code>h j k l</code>. The second reason why I like them is because of the facts they have a completely new mode for non-modal editor (i.e.&nbsp;the <em>normal</em> mode), you have a whole keyboard / lots of keys to bind actions to and do lots of things people usually do with the mouse. Being able to split an editor into several buffers, move around the buffers, go at the beginning of the paragraph, search and replace, register actions into macros and replay them, etc. All this without even moving the wrists. The learning curve is steep if you’re used to the mouse, but once you’ve passed the mental barrier, really, and this is a personal opinion, but I truly think that using the mouse again after that feels like handicap to me.</p>
<h2 id="how-i-like-to-move-around">How I like to move around</h2>
<p>When I look at people coding, I see several kind of programmers:</p>
<ul>
<li>The ones who move with the arrows or with <code>h j k l</code> in modal editors. You can spot them very easily at how the cursor moves in a document. It typically implies keeping a key pressed until the cursor reach a given row, then pressing another key until the cursor reach a given column and then adjust if they went passed the location they had in mind.</li>
<li>People using the mouse, by clicking at the place they want to put the cursor at.</li>
<li>People using <em>relative numbers</em>. That’s an enhancement of the first group: they typically use relative numbers to know which lines they want to jump to very quickly, so that they don’t have to press the up / down keys for ages until reaching the line they want to. Instead, they look at the number on the lines, press that number, and the direction, and bam, they are on the lines. They then use typical motions from vim like <code>$</code> (go to end of line), <code>f</code> (go to the first occurrence of the next character typed after <code>f</code>, like <code>f(</code> will make your cursor go to the next <code>(</code>), <code>%</code> (go to the matching delimiter) or <code>w</code> (go to the beginning of the next word) / <code>b</code> (go to the beginning of the previous word), etc. to move faster on the same line (it works across lines too).</li>
</ul>
<p>I think that represents 99,9% of what I see people do. Obviously, you will get that I don’t belong to the second set of people… but I don’t really belong to any, actually. How I move is, I guess, convoluted for most people and I know some people won’t understand how it can feel. I use <code>h j k l</code> and all the motions from vim described in the third group (and even more; I full lecture of four hours would be required to explain all of them :D), but it all depends on the <em>distance</em> I need to travel. If my cursor is on a word and I want to move to the beginning of a word located very closely to my cursor on the same line, I’ll simply type <code>www</code> if it’s three words apart (or <code>3w</code> if I’m feeling funny). If the distance is higher, I use a tool called [EasyMotion].</p>
<p>Easymotion really is a wonderful tool. The idea is that it has several modes, depending on the kind of move you want to perform:</p>
<ul>
<li><em>By lines</em>: this mode allows you to jump to any line in the current (or all open) buffers.</li>
<li><em>By words</em>: tihs mode allows you to jump to any “word” in the current (or all open) buffers.</li>
<li><em>By characters</em>: when the <em>word</em> mode doesn’t help with jumping to a special operator or character (because it’s not recognized as a word), this mode allows you to jump to any character in the current or (or all open) buffers.</li>
<li>It has other modes but I have never really found useful cases for them.</li>
</ul>
<p>The way I typically do it is by mapping the three modes to <code>&lt;leader&gt;l</code>, <code>&lt;leader&gt;w&gt;</code> and <code>&lt;leader&gt;c</code> (in my case, <code>&lt;leader&gt;</code> is the <em>space</em> key).</p>
<p>Typing <code>SPC l</code> in my current buffer results in this:</p>
<figure>
<img src="https://phaazon.net/media/uploads/easymotion_lines.png" alt=""><figcaption>EasyMotion lines</figcaption>
</figure>
<p>Typing any highlighted character will make my cursor jump to it. The same applies for words, with <code>SPC w</code>:</p>
<figure>
<img src="https://phaazon.net/media/uploads/easymotion_words.png" alt=""><figcaption>EasyMotion words</figcaption>
</figure>
<p>For the <em>character</em> mode, after pressing <code>SPC c</code>, I have to press another character (the one I want to jump to). Let’s say we want to jump to a <code>#</code> (which is not part of words): <code>SPC c #</code>:</p>
<figure>
<img src="https://phaazon.net/media/uploads/easymotion_chars.png" alt=""><figcaption>EasyMotion characters</figcaption>
</figure>
<p>This way of moving is not intuitive at first, but once you get used to it… it’s a <em>must have</em>.</p>
<h2 id="all-the-other-modal-candies">All the other modal candies</h2>
<p>Among all the things that I like about modal editing, here is a non-exhaustive list of features I expect to have around my fingers:</p>
<ul>
<li><code>C-i</code> and <code>C-o</code>: those allows me to jump to something / a file / a place in a buffer and then go back to where I was right before with <code>C-o</code> (read it like <em>out</em>) or go back again with <code>C-i</code> (read it like <em>in</em>).</li>
<li>Macros and registers: those allow me to yank content into different registers (like clipboards) by assigning a single key to paste their content. For instance, I can put a few lines in my <code>t</code> register with <code>"tyi(</code> (“put in the <code>t</code> register the <code>y</code>ank <code>i</code>nside matching <code>(</code>), and paste that content later with <code>"tp</code>. Macros allow more powerful editing control by assigning a key to set of actions with the <code>q</code> keyword (<code>qa</code> will register all the next keystrokes and actions into the <code>a</code> macro). Then simply replay the macro with <code>@a</code>, for instance.</li>
<li>Obviously, all the basic vim motions, like <code>d</code> to delete, <code>y</code> to yank, <code>c</code> to change, <code>t</code> to go to the character right before the one you search, <code>%</code> to go to the other delimiter, etc. And more complex text manipulation, such as “Let’s change what’s inside this function parameter list, delimited by <code>(</code>”: <code>ci(</code>.</li>
</ul>
<p>It would take too much time to list everything, but the main idea is: I need the modal features when editing code.</p>

<p>So let’s talk about the list of editors I mentioned in the preface. The idea is to give <em>my own opinion</em> on those …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://phaazon.net/blog/editors-in-2020">https://phaazon.net/blog/editors-in-2020</a></em></p>]]>
            </description>
            <link>https://phaazon.net/blog/editors-in-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24395863</guid>
            <pubDate>Mon, 07 Sep 2020 00:50:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL B-Tree index deduplication]]>
            </title>
            <description>
<![CDATA[
Score 183 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24395825">thread link</a>) | @petergeoghegan
<br/>
September 6, 2020 | https://blog.rustprooflabs.com/2020/09/postgres-beta3-btree-dedup | <a href="https://web.archive.org/web/*/https://blog.rustprooflabs.com/2020/09/postgres-beta3-btree-dedup">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>By Ryan Lambert -- Published September 06, 2020</p><p>PostgreSQL 13 development is coming along nicely, Postgres 13 Beta3 was
<a href="https://www.postgresql.org/about/news/2060/">released on 8/13/2020</a>.
The Postgres Beta 1 and 2 releases were released in May and June 2020.
One of the features that has my interest in Postgres 13 is the B-Tree deduplication effort.  B-Tree indexes are the default indexing method
in Postgres, and are likely the most-used indexes in production 
environments.
Any improvements to this part of the database are likely to have wide-reaching benefits.
Removing duplication from indexes keeps their physical size smaller,
reduces I/O overhead, and should help keep <code>SELECT</code> queries fast!</p>
<!--endteaser-->

<blockquote>
<p>This post is part of the series <a href="https://blog.rustprooflabs.com/2018/06/pg-series-toc"><em>PostgreSQL:  From Idea to Database</em></a>.</p>
</blockquote>
<p>There is a good summary of the what and how of this improvement
in <a href="https://www.cybertec-postgresql.com/en/b-tree-index-deduplication/">Laurenz Albe's post</a> from early in June 2020, presumably using
Pg13 Beta1.  <a href="https://www.highgo.ca/2020/07/06/features-in-pg13-deduplication-in-b-tree-indexes/">Hamid Akhtar's post in July</a>
covered this feature using Pg13 Beta2 and a different approach including
a look at the performance using <code>EXPLAIN</code>.
This post takes yet another look at this improvement using Pg13 Beta3.
I intend to see how well this improvement pans out on a data set I use in production.  For that task my go-to is
<a href="https://www.openstreetmap.org/">OpenStreetMap</a> data loaded to Postgres/PostGIS <a href="https://blog.rustprooflabs.com/2020/01/postgis-osm-load-2020">using osm2pgsql</a>.</p>
<h2>Install Postgres 13 Beta 3</h2>
<p>The first step is to install the two versions of Postgres (12 and 13beta3) 
on a single Ubuntu 18 host.  In the past when I have tested pre-production
releases I have built Postgres from source instead of using <code>apt</code>.
This time around I decided to use <code>apt install</code>, so am including the
basic process for that.</p>
<p>The advised way to install PostgreSQL is from the pgdg (PostgreSQL Global Development Group) repositories,
see <a href="https://wiki.postgresql.org/wiki/Apt">the Postgres wiki</a> for more.
To enable the beta versions, the line needed in <code>/etc/apt/sources.list.d/pgdg.list</code> is:</p>
<pre><code>deb http://apt.postgresql.org/pub/repos/apt/bionic-pgdg main 13
</code></pre>
<p>With that in place, update the sources and install Postgres and PostGIS.</p>
<pre><code>sudo apt update
# Postgres 12
sudo apt install postgresql-12 postgresql-12-postgis-3
# Postgres 13 (Currently Beta)
sudo apt install postgresql-13 postgresql-13-postgis-3
</code></pre>
<p>On Ubuntu, installing multiple versions will create multiple instances running on different ports. The test server I'm using to write this post
currently has three versions of Postgres installed, only two are currently running. Postgres 12 was installed first so "won" the default port of 5432.  Postgres 11 was installed second and was assigned 5433, and Pg13 beta 3 was installed last and was assigned port 5434.  The <code>pg_lsclusters</code> is avaiable on Debian/Ubuntu hosts as part of the wrapper around <code>pg_ctl</code>.</p>
<pre><code>sudo -u postgres pg_lsclusters
Ver Cluster Port Status Owner    Data directory              Log file
11  main    5433 down   postgres /var/lib/postgresql/11/main /var/log/postgresql/postgresql-11-main.log
12  main    5432 online postgres /var/lib/postgresql/12/main /var/log/postgresql/postgresql-12-main.log
13  main    5434 online postgres /var/lib/postgresql/13/main /var/log/postgresql/postgresql-13-main.log
</code></pre>
<blockquote>
<p>This post does not use Postgres 11 beyond this example.</p>
</blockquote>
<p>When working with multiple versions installed it is helpful to verify
versions match what you expect them to be.
First, the port 5432 for Postgres 12 version.</p>
<pre><code>psql -d pgosm -p 5432 -c "select version();"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”�
â”‚                                   version                                    â”‚
â•žâ•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•¡
â”‚ PostgreSQL 12.4 (Ubuntu 12.4-1.pgdg18.04+1) on x86_64-pc-linux-gnu, compiledâ€¦â”‚
â”‚â€¦ by gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0, 64-bit                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>Now, port 5434 for Postgres 13 version.</p>
<pre><code>psql -d pgosm -p 5434 -c "select version();"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”�
â”‚                                   version                                    â”‚
â•žâ•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•¡
â”‚ PostgreSQL 13beta3 (Ubuntu 13~beta3-1.pgdg18.04+1) on x86_64-pc-linux-gnu, câ€¦â”‚
â”‚â€¦ompiled by gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0, 64-bit                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h2>Create Indexes</h2>
<p>Both versions of Postgres were loaded with the same Colorado OpenStreetMap
data loaded <a href="https://blog.rustprooflabs.com/2020/01/postgis-osm-load-2020">using osm2pgsql</a>.
The osm2pgsql does not create any B-Tree indexes on its own, only the GIST
indexes on geometries.
For this post, we examine B-Tree index sizes created on four columns:
<code>osm_id</code>, <code>highway</code>, <code>waterway</code>, and <code>natural</code>.
Looking at the stats on the <code>public.planet_osm_line</code> table I can make 
a couple guesses where we will and will not see gains based on <code>n_distinct</code>.
I can guess we will not see major gains in the
<code>osm_id</code>, there is only a small amount of duplication in those values.
The other three columns (<code>highway</code>, <code>natural</code> and <code>waterway</code>) have a small number of distinct values
and varying amounts of <code>NULL</code> values.  These three columns would all
be candidates for partial indexes to avoid indexing the <code>NULL</code> values,
thus reducing the size of the created index.
I have hopes to see the benefits in Postgres 13 on these columns, possibly
making the use of partial indexes less frequent.</p>
<pre><code> SELECT attname, n_distinct, null_frac
    FROM pg_catalog.pg_stats
    WHERE tablename = 'planet_osm_line'
        AND attname IN ('osm_id', 'highway', 'waterway', 'natural')
;

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”�
â”‚ attname  â”‚ n_distinct â”‚ null_frac  â”‚
â•žâ•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•ªâ•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•ªâ•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•¡
â”‚ osm_id   â”‚  -0.833553 â”‚          0 â”‚
â”‚ highway  â”‚         26 â”‚ 0.41616666 â”‚
â”‚ natural  â”‚          4 â”‚      0.994 â”‚
â”‚ waterway â”‚          9 â”‚     0.6663 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>Index on <code>osm_id</code></h3>
<p>First up is the <code>osm_id</code> column, a nearly unique set of positive and 
negative values.  The index to create in both versions:</p>
<pre><code>CREATE INDEX ix_osm_line_osm_id ON public.planet_osm_line (osm_id);
</code></pre>
<p>The following query is used throughout to report out index sizes.
The query itself will not be repeated, as only the filter would change.</p>
<pre><code>SELECT ai.schemaname AS s_name, ai.relname AS t_name,
        ai.indexrelname AS index_name,
        pg_size_pretty(pg_relation_size(quote_ident(ai.schemaname)::text || '.' || quote_ident(ai.indexrelname)::text)) AS index_size,
        pg_relation_size(quote_ident(ai.schemaname)::text || '.' || quote_ident(ai.indexrelname)::text) AS index_size_bytes
    FROM pg_catalog.pg_stat_all_indexes ai
    WHERE ai.indexrelname LIKE 'ix_osm_line%'
    ORDER BY index_name
;
</code></pre>
<p>Due to the low number of duplicates, it is no surprise that the
show only a tiny reduction in the size.  The reduction
would not be detectable from only the <code>index_size</code> column (in MB), the
<code>index_size_bytes</code> shows the slight reduction in size (29,515,776 bytes vs. 29,384,704 bytes).</p>
<p>Pg 12.</p>
<pre><code>â”Œâ”€[ RECORD 1 ]â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”�
â”‚ s_name           â”‚ public             â”‚
â”‚ t_name           â”‚ planet_osm_line    â”‚
â”‚ index_name       â”‚ ix_osm_line_osm_id â”‚
â”‚ index_size       â”‚ 28 MB              â”‚
â”‚ index_size_bytes â”‚ 29515776           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>Pg 13.</p>
<pre><code>â”Œâ”€[ RECORD 1 ]â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”�
â”‚ s_name           â”‚ public             â”‚
â”‚ t_name           â”‚ planet_osm_line    â”‚
â”‚ index_name       â”‚ ix_osm_line_osm_id â”‚
â”‚ index_size       â”‚ 28 MB              â”‚
â”‚ index_size_bytes â”‚ 29384704           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>Index on <code>highway</code></h3>
<p>The <code>highway</code> data in the <code>planet_osm_line</code> data is a good example of when
a
<a href="https://www.postgresql.org/docs/current/indexes-partial.html">partial index</a>
might typically be a good idea to minimize index size.  My hunch (and hope)
is that the de-duplication will make a partial index here a moot point by reducing the size required to index a large number of <code>NULL</code> values.</p>
<p>Create two indexes, one partial covering the non-<code>NULL</code> values and one full
index on the entire table.</p>
<pre><code>CREATE INDEX ix_osm_line_highway_partial 
    ON public.planet_osm_line (highway)
    WHERE highway IS NOT NULL;
CREATE INDEX ix_osm_line_highway_full
    ON public.planet_osm_line (highway);
</code></pre>
<p>The two indexes in Postgres 12, notice the partial index cuts out about 1/3 of the size from the full index.</p>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”…</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.rustprooflabs.com/2020/09/postgres-beta3-btree-dedup">https://blog.rustprooflabs.com/2020/09/postgres-beta3-btree-dedup</a></em></p>]]>
            </description>
            <link>https://blog.rustprooflabs.com/2020/09/postgres-beta3-btree-dedup</link>
            <guid isPermaLink="false">hacker-news-small-sites-24395825</guid>
            <pubDate>Mon, 07 Sep 2020 00:39:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a startup from zero first goal $1: Day 11]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24395786">thread link</a>) | @branzzel
<br/>
September 6, 2020 | https://www.twitch.tv/branzzel | <a href="https://web.archive.org/web/*/https://www.twitch.tv/branzzel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/branzzel</link>
            <guid isPermaLink="false">hacker-news-small-sites-24395786</guid>
            <pubDate>Mon, 07 Sep 2020 00:31:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Play “The Endov Society” Built with Epic Online Services and Godot]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24395776">thread link</a>) | @follower
<br/>
September 6, 2020 | https://rancidbacon.itch.io/the-endov-society | <a href="https://web.archive.org/web/*/https://rancidbacon.itch.io/the-endov-society">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>THIS IS NOT A TECH DEMO.</h3>
<h3>THIS IS THE ENDOV SOCIETY.</h3>

<h3>will you survive the dystopian total surveillance future...</h3>
<h4>...and will you contribute to it in order to survive?</h4>
<p><strong>I did.</strong><br></p>
<p>Download an Extreme Early Access edition of "The Endov Society" the online interactive video game software provided for entertainment purposes like no other...<br></p>
<p>Join/find/create lobbies with up to 32 members! <strong>Unlock achievements!</strong> Change outfits! <strong>Get surveilled!</strong> Become more or less suspicious! <strong>Get promoted!</strong></p>
<p>Also features an episodic story that will have <em>you</em> asking "Is this a demonstration?".</p>
<p>Available for:</p>
<ul><li>Linux </li><li>Mac (10.13+; runs under WINE on older versions)</li><li>Windows</li></ul>
<p><em>Note: This is an online only, multiplayer game. Online features are implemented via Epic Online Services. No Epic or other account required.</em><br></p></div></div>]]>
            </description>
            <link>https://rancidbacon.itch.io/the-endov-society</link>
            <guid isPermaLink="false">hacker-news-small-sites-24395776</guid>
            <pubDate>Mon, 07 Sep 2020 00:29:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to implement Relay node in GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24395732">thread link</a>) | @albertgao
<br/>
September 6, 2020 | https://www.albertgao.xyz/2020/09/07/how-to-implement-relay-node-in-graphql/ | <a href="https://web.archive.org/web/*/https://www.albertgao.xyz/2020/09/07/how-to-implement-relay-node-in-graphql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">

      
        <p>Relay is a great GraphQL client side library made by Facebook. It has a <code>Node</code> query which allows you to have a universal endpoint for querying all your endpoints in your GraphQL. Let’s check how we do that, we will use <a href="https://nexusjs.org/" target="_blank" rel="noopener"><code>Nexus</code></a>, you can use the other GraphQL, but I found <code>Nexus</code> made me really productive.</p>
<p>You can use <code>toGlobalID()</code> and <code>fromGlobalID</code> from <code>graphql-relay</code> package. Then you can stop reading here. But I will use an easier way, which you can adopt for your green field project.</p>
<h2 id="1-Rationale"><a href="#1-Rationale" title="1. Rationale"></a>1. Rationale</h2><p>The benefit of having the <code>node()</code> query on your GraphQL root, is:</p>
<ul>
<li>not only Relay can do the refetch via this <code>node()</code>,</li>
<li>but also you can use this node to query any entity that implements this interface.<ul>
<li>So instead of having separate query for <code>user()</code>, <code>company()</code> and <code>task()</code></li>
<li>you can have this single <code>node()</code> query for getting <code>user</code>, <code>company</code> and <code>task</code> entities, if they all implement the <code>node interfaceType</code>.</li>
</ul>
</li>
</ul>
<h2 id="2-For-the-global-unique-ID"><a href="#2-For-the-global-unique-ID" title="2. For the global unique ID"></a>2. For the global unique ID</h2><p>Firstly, you need to adopt a convention for your id, which is:</p>
<blockquote>
<p>The id of an entity is combined by entity name and the real id.</p>
</blockquote>
<p>For example:</p>
<ul>
<li>If you have a <code>user</code>, the id should be <code>user_cyasjkajkas</code>.</li>
<li>If you have a <code>task</code>, the id should be <code>task_asjksakjas-12jh12hj-sakjasjksw</code>.</li>
</ul>
<p>Not only you can identify the entity of the object, but also you paved the way for the next step, which is easily identity the incoming query in the GraphQL endpoint without any additional saving in your database.</p>
<p>And via doing this, you remove that unnecessary step for wrapping the id.</p>
<blockquote>
<p>The ID you have now for each record is already global unique, think about it. :)</p>
</blockquote>
<h2 id="3-Define-the-ID-mapper-function"><a href="#3-Define-the-ID-mapper-function" title="3. Define the ID mapper function"></a>3. Define the ID mapper function</h2><p>This is for checking the pattern of the id.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></pre></td><td><pre><span><span>const</span> isId = {</span><br><span>  task: <span>(<span>entity: { id: string }</span>) =&gt;</span> entity.id.startsWith(IdPrefix.task),</span><br><span>  user: <span>(<span>entity: { id: string }</span>) =&gt;</span> entity.id.startsWith(IdPrefix.user),</span><br><span>};</span><br></pre></td></tr></tbody></table></figure>

<h2 id="4-Define-the-Node-type"><a href="#4-Define-the-Node-type" title="4. Define the Node type"></a>4. Define the <code>Node</code> type</h2><p>We need to return the proper GraphQL <code>type</code>, from the <code>id</code>. So the <code>Task</code> and <code>User</code> that we are returning here, should be already defined in your codebase. <code>Nexus</code> can auto-find them, follow the convention if you use the other framework.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br></pre></td><td><pre><span><span>const</span> Node = schema.interfaceType({</span><br><span>  name: <span>"Node"</span>,</span><br><span>  definition(t) {</span><br><span>    t.id(<span>"id"</span>);</span><br><span>    t.resolveType(<span>(<span>entity</span>) =&gt;</span> {</span><br><span>      <span>if</span> (isId.task(entity)) {</span><br><span>        <span>return</span> <span>"Task"</span>;</span><br><span>      } <span>else</span> <span>if</span> (isId.user(entity)) {</span><br><span>        <span>return</span> <span>"User"</span>;</span><br><span>      }</span><br><span></span><br><span>      <span>return</span> <span>null</span>;</span><br><span>    });</span><br><span>  },</span><br><span>});</span><br></pre></td></tr></tbody></table></figure>

<h2 id="4-Define-the-node-query-for-that-type"><a href="#4-Define-the-node-query-for-that-type" title="4. Define the node query for that type"></a>4. Define the <code>node</code> query for that type</h2><p>You are doing the same thing, use the id pattern to retrieve the entity. It will then being used as the backing type for the underneath object type, for example, the result of <code>ctx.db.task.findOne({ where: { id } })</code> is a single task, and it will be used by your GraphQL type <code>Task</code> as the backing type.</p>
<p>And how does the framework now, that we want to resolve <code>Task</code> here, well, you already done that in the previous step.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></pre></td><td><pre><span>schema.extendType({</span><br><span>  type: <span>"Query"</span>,</span><br><span>  definition(t) {</span><br><span>    t.field(<span>"node"</span>, {</span><br><span>      type: Node,</span><br><span>      args: { <span>id</span>: schema.idArg({ <span>required</span>: <span>true</span> }) },</span><br><span>      resolve: <span>(<span>_, args, ctx</span>) =&gt;</span> {</span><br><span>        <span>if</span> (isId.task(args)) {</span><br><span>          <span>return</span> ctx.db.task.findOne({ <span>where</span>: { id } });</span><br><span>        } <span>else</span> <span>if</span> (isId.user(args)) {</span><br><span>          <span>return</span> ctx.db.user.findOne({ <span>where</span>: { id } });</span><br><span>        }</span><br><span></span><br><span>        <span>return</span> <span>null</span>;</span><br><span>      },</span><br><span>    });</span><br><span>  },</span><br><span>});</span><br></pre></td></tr></tbody></table></figure>

<p>BTW, what is that beautiful <code>ctx.db.task.findOne({ where: { id } })</code>? It’s <a href="https://www.prisma.io/" target="_blank" rel="noopener"><code>Prisma</code></a>, and modern database access for Typescript and Node.js, auto generate all the types and very friendly to use.</p>
<h2 id="5-Now-You-get-the-GraphQL-schema"><a href="#5-Now-You-get-the-GraphQL-schema" title="5. Now You get the GraphQL schema"></a>5. Now You get the GraphQL schema</h2><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br></pre></td><td><pre><span>type Query {</span><br><span>  node(id: ID!): Node</span><br><span>}</span><br></pre></td></tr></tbody></table></figure>

<h2 id="6-The-end"><a href="#6-The-end" title="6. The end"></a>6. The end</h2><p>Hope it helps. Of course, you can argue that the <code>if-else</code> here can be a more functional approach like using <code>cond()</code> from <code>rambda</code>, but I will leave that to you.</p>

    </div></div>]]>
            </description>
            <link>https://www.albertgao.xyz/2020/09/07/how-to-implement-relay-node-in-graphql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24395732</guid>
            <pubDate>Mon, 07 Sep 2020 00:16:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Computational Thinking]]>
            </title>
            <description>
<![CDATA[
Score 315 | Comments 32 (<a href="https://news.ycombinator.com/item?id=24395700">thread link</a>) | @guiambros
<br/>
September 6, 2020 | https://mitmath.github.io/18S191/Fall20/ | <a href="https://web.archive.org/web/*/https://mitmath.github.io/18S191/Fall20/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<!-- Content appended here -->
<div>
<p>Welcome to the new course <strong>MIT 18.S191</strong>, the debut edition, <strong>Fall 2020</strong>!</p>
<p> This is an introductory course on Computational Thinking. We use the <a href="http://www.julialang.org/">Julia programming language</a> to approach real-world problems in varied areas applying data analysis and computational and mathematical modeling.  In this class you will learn computer science, software, algorithms, applications, and mathematics as an integrated whole.</p>
<p>Topics include:</p>
<ul>
<li><p>Image analysis</p>
</li>
<li><p>Particle dynamics and ray tracing</p>
</li>
<li><p>Epidemic propagation</p>
</li>
<li><p>Climate modeling</p>
</li>
</ul>
<h2 id="professors"><a href="#professors">Professors</a></h2>
<p><a href="http://math.mit.edu/~edelman">Alan Edelman</a>, <a href="http://sistemas.fciencias.unam.mx/~dsanders/">David P. Sanders</a>, <a href="https://www.3blue1brown.com/about">Grant Sanderson</a>, &amp; <a href="https://eapsweb.mit.edu/people/jars">James Schloss</a></p>
<h2 id="introduction_video"><a href="#introduction_video">Introduction video</a></h2>
<iframe id="course-intro" width="800" height="474" src="https://www.youtube.com/embed/vxjRWtWoD_w" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<h2 id="logistics"><a href="#logistics">Logistics</a></h2>
<p>Course materials will be published on the accompanying website: <a href="https://mitmath.github.io/18S191/Fall20/">https://mitmath.github.io/18S191/Fall20/</a></p>
<p>TR 2:30–3:30pm EST, online (Go to the lecture page on this site to stream it.)</p>
<ul>
<li><p>Tuesdays: Prerecorded videos, released on YouTube and played live on this site.</p>
</li>
<li><p>Thursdays: Live sessions (same YouTube link 2:30–3) and MIT-only discussion (3-3:30); link to follow</p>
</li>
</ul>
<p>Start date: September 1, 2020</p>
<p>Office hours TBD.</p>
<h3 id="discussion_forum_and_homework_submission"><a href="#discussion_forum_and_homework_submission">Discussion forum and homework submission</a></h3>
<ul>
<li><p><a href="https://discord.gg/Z5qnVf8">Discord</a>: discussion (we encourage you to hang out here during class!)</p>
</li>
<li><p><a href="https://piazza.com/class/kd33x1xnfyq3b1">Piazza</a>: (MIT only) allows for anonymity to other students, discussion</p>
</li>
<li><p><a href="https://canvas.mit.edu/courses/5637">Canvas</a>: (MIT only) homework submission. If you're a non-MIT student, please find a partner to cross-grade homeworks via Discord.</p>
</li>
</ul>
<h3 id="evaluation"><a href="#evaluation">Evaluation</a></h3>
<ul>
<li><p>12 weekly problem sets with equal weight; your lowest score will be dropped. </p>
</li>
<li><p>Released on Thursdays and due before the following Thursday's class. (No problem set during Thanskgiving week.)</p>
</li>
<li><p>No exams</p>
</li>
</ul>
<p>Problem sets consist of code. MIT students enrolled in the course must submit homeworks via Canvas. If you are not a student then we encourage you to join the Discord and find a cross-grading partner.</p>
<div>
  <p>
    Last modified: September 09, 2020. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
  </p>
</div>
</div><!-- CONTENT ENDS HERE -->

    </div></div>]]>
            </description>
            <link>https://mitmath.github.io/18S191/Fall20/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24395700</guid>
            <pubDate>Mon, 07 Sep 2020 00:08:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elixir Is Erlang, not Ruby]]>
            </title>
            <description>
<![CDATA[
Score 401 | Comments 282 (<a href="https://news.ycombinator.com/item?id=24395695">thread link</a>) | @stanislavb
<br/>
September 6, 2020 | https://preslav.me/2020/09/06/elixir-is-not-ruby-elixir-is-erlang/ | <a href="https://web.archive.org/web/*/https://preslav.me/2020/09/06/elixir-is-not-ruby-elixir-is-erlang/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>Try to remember the first time you heard about this fascinating language called <a href="https://elixir-lang.org/">Elixir</a>. Chances are, you had by the time been developing software using Ruby. If that's the case, Elixir seems to have appeared out of nowhere until suddenly, it became the solution for all your previous problems. It is fast, clean, scales extremely well. It was <strong>almost</strong> like the Ruby you've always wanted to have, but never got.</p><p>I say <strong>almost</strong>, because as much as you want it to be, <strong>Elixir is not Ruby</strong>. The familiar syntax has definitely helped the language win the hearts of the broader developer community. Yet, under the hood, <strong>Elixir is all about Erlang.</strong> The <a href="https://elixir-lang.org/">Erlang</a> that everyone tells stories about, as if it were some mythical creature, but no one dares to touch.</p><figure><img src="https://preslav.me/content/images/2020/09/book-cover.png" alt="" width="500" height="700"><figcaption>Elixir for Non-Ruby Programmers</figcaption></figure><p>Why am I saying all of this? First, because I would love to see greater adoption of Elixir outside Ruby/Rails community. It was among that group of people where the idea first sparked, and I fully respect the fact. Nevertheless, I would love to see it growing out. As someone who discovered Elixir after years of doing Java, &nbsp;.NET and more recently, Go, I can say that there is enough goodness in it for everyone. Moreover, bringing people with different backgrounds (both technical and non-technical) will lead to an explosion of new ideas. Having more diverse minds will help us better understand and make use of the elephant in the room-Erlang.</p><p>This brings me to my second point. Erlang is not obscure at all, once you give it enough attention. It is actually oddly satisfying, once you start reading code written in it. I have had my few a-ha moments, when I figured the original inspiration for most constructs in Elixir. The point is, we shouldn't fear Erlang, but try to understand it. This applies both to when things go well, as well as when they go south.</p><p>My biggest hope of all is that by understanding Erlang well enough, the Elixir community will start looking for new uses for it. Uses that go beyond being a scalable replacement for Rails apps. More daring and more ambitious uses, where Erlang's resilience model can prove to be critical for the success of the mission. I'd love to see it used in transportation, space, as well as the domain that started it all- telecommunications.</p><blockquote>“Shoot for the moon. Even if you miss it you will land among the stars.”<br><strong>Les Brown</strong></blockquote>
                <section>
                  
                  <ul>
                      <li>
                        <a href="https://preslav.me/tag/elixir/" title="Elixir">Elixir</a>
                      </li>
                      <li>
                        <a href="https://preslav.me/tag/programming/" title="Programming">Programming</a>
                      </li>
                      <li>
                        <a href="https://preslav.me/tag/ruby/" title="Ruby">Ruby</a>
                      </li>
                      <li>
                        <a href="https://preslav.me/tag/erlang/" title="Erlang">Erlang</a>
                      </li>
                      <li>
                        <a href="https://preslav.me/tag/2-cents/" title="2 Cents">2 Cents</a>
                      </li>
                  </ul>
                </section>
            </div></div>]]>
            </description>
            <link>https://preslav.me/2020/09/06/elixir-is-not-ruby-elixir-is-erlang/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24395695</guid>
            <pubDate>Mon, 07 Sep 2020 00:07:39 GMT</pubDate>
        </item>
    </channel>
</rss>
