<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 25 Jan 2021 17:33:24 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 25 Jan 2021 17:33:24 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Stop Naming Adages After People and Calling Them Laws]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25890434">thread link</a>) | @taylorlunt
<br/>
January 24, 2021 | https://taylor.gl/blog/11/ | <a href="https://web.archive.org/web/*/https://taylor.gl/blog/11/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<span>
  Reading time: 15 minutes.

  Written in 2021.
</span>



<p>Without leaving the letter <em>M</em>: <a href="https://taylor.gl/blog/11/#moore-s-law"><strong>Moore’s Law</strong></a>, <a href="https://taylor.gl/blog/11/#murphy-s-law"><strong>Murphy’s Law</strong></a>, <a href="https://taylor.gl/blog/11/#metcalfe-s-law"><strong>Metcalfe’s Law</strong></a>, <a href="https://taylor.gl/blog/11/#mooers-law"><strong>Mooers’s Law</strong></a>. I’m not saying an adage should never, ever be named after a person. I’ll admit, <a href="https://taylor.gl/blog/11/#moore-s-law"><strong>Moore’s Law</strong></a> and <a href="https://taylor.gl/blog/11/#murphy-s-law"><strong>Murphy’s Law</strong></a> have a certain catchiness to them. But the trend of taking a maxim and calling it Person’s Law has resulted in dozens and dozens of these things being produced, and it makes my head spin. Soon every fact or aphorism will be Somebody’s Law. Not only have such adage laws become a cliché, but, as I have found when researching this article, many of the laws are either not named after the person who came up with the idea (ignorance), or are named by the author after themselves (egotism). They are also called “laws” when they aren’t really laws to lend the ideas more credence than they deserve, or at least more memetic value. It’s hard for me not to take on a negative tone in this article after being exposed to such egotism and ignorance. Apologies in advance.</p>
<p>Newton earned his laws. So did Asimov. But now any lazy aphorism can lend your name immortality if you push for it hard enough. Let me give it a go:</p>
<h3 id="taylor-s-law"><a href="#taylor-s-law" aria-label="Anchor link for: taylor-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Taylor’s Law:</h3>
<blockquote>
<p>If an adage is named after a person and called a law, there is a 50% chance the law is named after the wrong person, and if not, there is a 50% chance it was named by the author after themselves.</p>
</blockquote>
<p>Tell your friends. Ironically, I have basically stolen <strong>Stigler’s Law</strong> here (see <a href="https://taylor.gl/blog/11/#stigler-s-law">below</a>). Oh well, nothing is new under the sun.</p>
<p>Here are some popular adage laws. There are so many of them, but I bet you’ve heard of at least half. Special thanks to <a href="https://en.wikipedia.org/wiki/List_of_eponymous_laws">Wikipedia’s list of eponymous laws</a>.:</p>
<h3 id="amara-s-law"><a href="#amara-s-law" aria-label="Anchor link for: amara-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Amara’s Law:</h3>
<blockquote>
<p>People overestimate the impact of a given technology initially, then underestimate it. Basically, when the hype bubble bursts, people are disappointed. After that, things return to a reasonable baseline. <em>Named after Roy Amara, the futurist who created the idea.</em></p>
</blockquote>
<h3 id="andy-and-bill-s-law"><a href="#andy-and-bill-s-law" aria-label="Anchor link for: andy-and-bill-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Andy and Bill’s Law:</h3>
<blockquote>
<p>An increase in hardware computing power will be met with an increase in software demand. Very similar to <a href="https://taylor.gl/blog/11/#wirth-s-law">Wirth’s law</a>. <em>Named after Andy Grove, Intel’s former CEO, and Bill Gates, Microsoft’s former CEO. Based on an old joke that, “what Andy gives, Bill takes away.”</em></p>
</blockquote>
<h3 id="atwood-s-law"><a href="#atwood-s-law" aria-label="Anchor link for: atwood-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Atwood’s Law:</h3>
<blockquote>
<p>All software that can be written in JavaScript, will eventually be written in JavaScript. <em>Created by Jeff Atwood, of the <a href="https://blog.codinghorror.com/">Coding Horror</a> blog. Named by himself after himself.</em></p>
</blockquote>
<h3 id="benford-s-law"><a href="#benford-s-law" aria-label="Anchor link for: benford-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Benford’s Law:</h3>
<blockquote>
<p>In real-world data sets, the leading digit is much more likely to be a ’1’ than any other digit: the chance is about 30% <em>Named after Frank Benford, who originally called it the Law of Anomalous Numbers, though it was mentioned first by Simon Newcomb decades prior.</em>. </p>
</blockquote>
<h3 id="benford-s-law-of-controversy"><a href="#benford-s-law-of-controversy" aria-label="Anchor link for: benford-s-law-of-controversy"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Benford’s Law of Controversy:</h3>
<blockquote>
<p>“Passion is inversely proportional to the amount of real information available.” <em>Stated by Gregory Benford the sci-fi author, not to be confused with Frank Benford, the physicist and engineer who lends their name to the first Benford’s Law.</em> Because we have two “Benford’s laws”, maybe we should stick to Frank Benford’s original name for his law: the Law of Anomalous Numbers.</p>
</blockquote>
<h3 id="betteridge-s-law"><a href="#betteridge-s-law" aria-label="Anchor link for: betteridge-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Betteridge’s Law:</h3>
<blockquote>
<p>Headlines which end in a question mark can be answered by the word “no”. (This really only makes sense for yes-or-no question headlines.) Studies have tried to disprove this law by showing that articles which have yes-or-no headlines are more likely to be answered in the body of the article “yes” than “no”, but these studies are clearly missing the point of the law. <em>Named after the tech journalist Ian Betteridge, who did not create the principle, though he claimed he did. Also referred to earlier as “Davis’ law”, with no reference to who Davis is.</em></p>
</blockquote>
<h3 id="brandolini-s-law"><a href="#brandolini-s-law" aria-label="Anchor link for: brandolini-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Brandolini’s Law:</h3>
<blockquote>
<p>The energy needed to refute bullshit is an order of magnitude larger than the energy needed to produce it. <em>Originally called the Bullshit Asymmetry Principle by Alberto Brandolini on Twitter, though the idea has been around since before Twitter was even a thing.</em></p>
</blockquote>
<h3 id="brooks-law"><a href="#brooks-law" aria-label="Anchor link for: brooks-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Brooks’ Law:</h3>
<blockquote>
<p>“Adding manpower to a late software project makes it later” because it takes time for new members of a team to become productive, and because tasks are not infinitely divisible and adding people creates communication and collaboration overhead. <em>Created by Fred Brooks, author of the Mythical Man-Month, and named after himself.</em></p>
</blockquote>
<h3 id="campbell-s-law"><a href="#campbell-s-law" aria-label="Anchor link for: campbell-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Campbell’s Law:</h3>
<blockquote>
<p>Quantitative social metrics often corrupt the process they are intended to measure because people will try to game the metric. <em>Created by the social scientist Donald T. Campbell. Although this law is often worded differently than <a href="https://taylor.gl/blog/11/#goodhart-s-law">Goodhart’s law</a>, as described by Campbell it is basically indistinguishable from Goodhart’s law, which was stated before Campbell’s law.</em></p>
</blockquote>
<h3 id="cheop-s-law"><a href="#cheop-s-law" aria-label="Anchor link for: cheop-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Cheop’s Law:</h3>
<blockquote>
<p>Nothing is ever built on schedule or within budget. A patently false child of <a href="https://taylor.gl/blog/11/#hofstadter-s-law">Hofstadter’s law</a> and <a href="https://taylor.gl/blog/11/#murphy-s-law">Murphy’s law</a>. <em>This one is named after an ancient Egyptian pharaoh, but was created by Robert A. Heinlein in one of his novels.</em></p>
</blockquote>
<h3 id="chesterton-s-fence"><a href="#chesterton-s-fence" aria-label="Anchor link for: chesterton-s-fence"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Chesterton’s Fence:</h3>
<blockquote>
<p>If you don’t know why something is a certain way, leave it alone until you do. If you see a fence or other barrier across a road, some people will immediately try to remove it, but they may be ignorant of the reason for the fence and so could be making a mistake. <em>Named after Gilbert Keith Chesterton who stated it in one of his books. The allegory is clever and original, but the underlying idea is not and is essentially a restating of, “if it ain’t broke, don’t fix it.” or of the Precautionary principle, etc. It’s not technically an adage law, but I included it because I like it.</em></p>
</blockquote>
<h3 id="claasen-s-law"><a href="#claasen-s-law" aria-label="Anchor link for: claasen-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Claasen’s Law:</h3>
<blockquote>
<p>Usefulness increases with the logarithm of technology. Combined with <a href="https://taylor.gl/blog/11/#moore-s-law">Moore’s law</a>, this gives technology a linear rate of improvement in terms of usefulness. <em>Named after the originator of the idea, Theo A. C. M. Claasen, the former CTO of Philips Semiconductors.</em> </p>
</blockquote>
<h3 id="clarke-s-three-laws"><a href="#clarke-s-three-laws" aria-label="Anchor link for: clarke-s-three-laws"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Clarke’s Three Laws:</h3>
<blockquote>
<p>Ooh, three laws by one person</p>
<ol>
<li>When a famous, elderly scientist claims something is possible, they are almost certainly right. But when they claim something is impossible, they are almost certainly wrong.</li>
<li>The only way to know the limit of what’s possible is to cross that limit and find out what’s impossible.</li>
<li>“Any sufficiently advanced technology is indistinguishable from magic.”</li>
</ol>
</blockquote>
<blockquote>
<p><em>By the sci-fi author Arthur C. Clarke. The third one is the most famous, though also the least original, as very similar things have been said before by other authors, including Isaac Asimov: “An uninformed public tends to confuse scholarship with magicianry.”</em></p>
</blockquote>
<h3 id="conway-s-law"><a href="#conway-s-law" aria-label="Anchor link for: conway-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Conway’s Law:</h3>
<blockquote>
<p>Any system has a structure which reflects the communication structure of the organization which produced it.
<em>By Melvin Conway, a computer programmer, not to be confused with John Conway of Conway’s Game of Life. Named by Fred Brooks of Brooks’ Law.</em></p>
</blockquote>
<h3 id="cunningham-s-law"><a href="#cunningham-s-law" aria-label="Anchor link for: cunningham-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Cunningham’s Law:</h3>
<blockquote>
<p>The best way to get the right answer on the Internet isn’t to request it, but to post the wrong answer. <em>Named after the programmer Ward Cunningham, inventor of the concept of the wiki. Named by Steven McGeady, former Intel exec, though Cunningham denies actually having created the idea.</em></p>
</blockquote>
<h3 id="dilbert-principle"><a href="#dilbert-principle" aria-label="Anchor link for: dilbert-principle"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Dilbert Principle:</h3>
<blockquote>
<p>Incompetent workers are systematically moved to management, because that’s where they can do the least damage. <em>Created by Scott Adams, and named after his comic strip, Dilbert.</em></p>
</blockquote>
<h3 id="doctorow-s-law"><a href="#doctorow-s-law" aria-label="Anchor link for: doctorow-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Doctorow’s Law:</h3>
<blockquote>
<p>“Anytime someone puts a lock on something you own, against your wishes, and doesn't give you the key, they're not doing it for your benefit.” <em>Named after its author, Cory Doctorow, a blogger and journalist (see <a href="https://taylor.gl/blog/11/craphound.com">craphound.com</a>.</em></p>
</blockquote>
<h3 id="eroom-s-law"><a href="#eroom-s-law" aria-label="Anchor link for: eroom-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Eroom’s Law:</h3>
<blockquote>
<p>The idea that drug discovery is becoming slower and more expensive. <em>Named creatively ’Eroom’ as a pun on <a href="https://taylor.gl/blog/11/#moore-s-law">Moore’s law</a>, as it describes an opposite effect.</em></p>
</blockquote>
<h3 id="gall-s-law"><a href="#gall-s-law" aria-label="Anchor link for: gall-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Gall’s Law:</h3>
<blockquote>
<p>“A complex system that works is invariably found to have evolved from a simple system that worked. A complex system designed from scratch never works and cannot be patched up to make it work.” <em>By the author John Gall.</em> </p>
</blockquote>
<h3 id="gell-mann-amnesia-effect"><a href="#gell-mann-amnesia-effect" aria-label="Anchor link for: gell-mann-amnesia-effect"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Gell-Mann Amnesia Effect:</h3>
<blockquote>
<p>If you think the news is accurate in areas outside your field of expertise, you must have forgotten how inaccurate the news is about things you’re knowledgeable about. <em>Created by filmmaker Michael Crichton and named after the famous physicist Murray Gell-Mann in a bid to lend the idea credence.</em></p>
</blockquote>
<h3 id="godwin-s-law"><a href="#godwin-s-law" aria-label="Anchor link for: godwin-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Godwin’s Law:</h3>
<blockquote>
<p>“As an online discussions grows longer, the probability of a comparison involving Nazis or Hitler approaches one.” Addendum: If you’re the one who brought up Hitler or the Nazis, you lose whatever debate is occuring. <em>Created by Mike Godwin, and named by him after himself. May be considered a description of reductio ad Hitlerum, which was described earlier.</em></p>
</blockquote>
<h3 id="goodhart-s-law"><a href="#goodhart-s-law" aria-label="Anchor link for: goodhart-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Goodhart’s Law:</h3>
<blockquote>
<p>“When a measure becomes a target, it ceases to be a good measure.” <em>The idea was formulated by economist Charles Goodhart, though the succinct and generalized wording people are more familiar with was written by anthropologist Marilyn Strathern.</em></p>
</blockquote>
<h3 id="greenspun-s-tenth-rule"><a href="#greenspun-s-tenth-rule" aria-label="Anchor link for: greenspun-s-tenth-rule"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Greenspun’s Tenth Rule:</h3>
<blockquote>
<p>“Any sufficiently complicated C or Fortran program contains an ad hoc, informally specified, bug-ridden, slow implementation of half of Common Lisp.” <em>Coined by Philip Greenspun and named after himself. It was not even part of a list of rules, and was simply called the “tenth rule” for added memorability. There is no ninth rule.</em></p>
</blockquote>
<h3 id="grosch-s-law"><a href="#grosch-s-law" aria-label="Anchor link for: grosch-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Grosch’s Law:</h3>
<blockquote>
<p>The economic value of computation increases with the square root of the increase in computing speed. <em>Named by Grosch after himself, though the idea predates his statement of it.</em></p>
</blockquote>
<h3 id="hofstadter-s-law"><a href="#hofstadter-s-law" aria-label="Anchor link for: hofstadter-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Hofstadter’s Law:</h3>
<blockquote>
<p>“It always takes longer than you expect, even when you take into account Hofstadter’s law.” <em>A self-referential law appropriately coined by Douglas Hofstadter, author of Gödel, Escher, Bach. He named it after himself, which I find to be somehow appropriate.</em></p>
</blockquote>
<h3 id="humphrey-s-law"><a href="#humphrey-s-law" aria-label="Anchor link for: humphrey-s-law"><img src="https://taylor.gl/link.svg" alt="chain link icon"></a>
Humphrey’s Law:</h3>
<blockquote>
<p>Paying attention to an automatic task can disrupt it. <em>Named for psychologist George Humphrey. Also called, the centipede effect, in my opinion a more fitting name, after a poem referred to by Humphrey when he …</em></p></blockquote></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://taylor.gl/blog/11/">https://taylor.gl/blog/11/</a></em></p>]]>
            </description>
            <link>https://taylor.gl/blog/11/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25890434</guid>
            <pubDate>Sun, 24 Jan 2021 08:46:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 is spread by aerosols: an evidence review]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25890346">thread link</a>) | @simonebrunozzi
<br/>
January 24, 2021 | https://first10em.com/covid-19-is-spread-by-aerosols-an-evidence-review/ | <a href="https://web.archive.org/web/*/https://first10em.com/covid-19-is-spread-by-aerosols-an-evidence-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-52248">
      <div>
    <section>
            <div>
        
<p>In early April, <a href="https://first10em.com/aerosols-droplets-and-airborne-spread/">I wrote a long post covering all the science I could find about aerosols and droplets</a>. The basic summary was that this is an area of medicine with lots of misconceptions, poor assumptions, and incomplete science. There was good evidence that previous coronaviruses were spread by aerosols. There was good evidence that influenza is spread by aerosols. Overall, it seemed very likely that SARS-CoV-2 or COVID-19 was being spread by aerosols, but the science was pretty weak. There is still a lot we don’t know, but as I update the evidence 6 months later, it is pretty clear that aerosols play an important, and unfortunately still widely ignored, role in the transmission of COVID-19.&nbsp;</p>



<h2><strong>Dispelling some misconceptions</strong></h2>



<p>There are still many who argue strongly against the role of aerosols in transmission of COVID-19. In general, I think these arguments clash with science and have significant logical inconsistencies. Before getting to the evidence that COVID-19 is spread by aerosols, let’s dispel a few widely held misconceptions.</p>



<h3>COVID-19 has a low Ro</h3>



<p>One main argument against aerosol spread points to the Ro, with the assumption that airborne diseases will always spread easily, and therefore have a high Ro. The argument is often framed as, “this disease doesn’t look like measles, and therefore cannot possibly be airborne.” This is bad logic, as infectivity and mechanism of transmission are separate concepts. Some pathogens require higher numbers to reliably cause infections, which will result in a lower Ro no matter how the infection is transmitted. “While many airborne infections are highly contagious, this is not, strictly speaking, part of the definition.” (Tellier 2019)</p>



<p>The logic here is clearly faulty. The argument being used has the basic format: “X is a Y. Z is not like X. Therefore Z cannot be a Y.” This is somewhat like saying “a horse is a mammal, therefore that dog cannot be a mammal because they don’t look the same.”&nbsp;</p>



<p>This logic is especially problematic in the context of aerosol spread because there are other diseases with good evidence of aerosol spread, such as influenza, that look nothing like measles, but a lot like COVID-19. In fact, the prototypical airborne pathogen is tuberculosis, and tuberculosis has an Ro between 1-3 (exactly like COVID-19). (Ma 2018)&nbsp;</p>



<p>Furthermore, the statement that ‘COVID looks nothing like measles’ is probably untrue. On average, disease transmission is low, but if you look at <a href="#superspreaders">super-spreaders</a>, COVID-19 starts to look a lot like measles.&nbsp;</p>



<p>Therefore, the arguments based on Ro are both illogical and inconsistent with science. If anything, the Ro of COVID-19 looks exactly like other known airborne diseases (such as tuberculosis), and so this would be an argument in favour of airborne spread.</p>



<h3>Most transmission is short distance</h3>



<p>The equally fallacious corollary to the Ro argument is that “if COVID-19 is transmitted through aerosols, we should see a lot of infections occurring over long distances”. Although it is true that aerosols will disperse much further than droplets, it is faulty logic to define the <em>mode</em> of transmission by the <em>distance</em> of transmission. The concentration of infectious particles falls dramatically with distance, even when those infectious particles are carried by aerosols. They are spread out through 3 dimensional space, and therefore decrease exponentially with distance. Although aerosols <em>can </em>transmit disease over long distances, they are much more likely to transmit disease over a short distance. (Chen 2020)</p>



<p>This illogical step is so ingrained in the infectious diseases literature that most studies just assume droplet spread if there was close contact. This illogical assumption undermines a great deal of the existing infectious disease literature.&nbsp;</p>



<p>As an interesting historical analogy, for decades it was thought that tuberculosis was transmitted through droplets and fomites, because it occurred most often after close contact. We now know that tuberculosis <em>can only be transmitted through aerosols. </em>(Jimenez 2020)</p>



<p>The existing science refutes the assumption that close contact suggests droplet spread. At the typical conversational distance of about 1 meter, exposure to aerosols is about 2000 times greater than exposure to droplets. (Chen 2020)</p>



<p>The bottom line is that short range disease transmission is definitely consistent with aerosol transmission, and distance cannot be used to define mode of transmission. </p>



<figure><img data-attachment-id="52260" data-permalink="https://first10em.com/covid-19-is-spread-by-aerosols-an-evidence-review/wei-2016-shortrage-aerosols/" data-orig-file="https://i0.wp.com/first10em.com/wp-content/uploads/2020/11/Wei-2016-Shortrage-Aerosols.jpg?fit=1108%2C586&amp;ssl=1" data-orig-size="1108,586" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;Justin Morgenstern&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1606425125&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Wei-2016-Shortrage-Aerosols" data-image-description="" data-medium-file="https://i0.wp.com/first10em.com/wp-content/uploads/2020/11/Wei-2016-Shortrage-Aerosols.jpg?fit=350%2C185&amp;ssl=1" data-large-file="https://i0.wp.com/first10em.com/wp-content/uploads/2020/11/Wei-2016-Shortrage-Aerosols.jpg?fit=1108%2C586&amp;ssl=1" loading="lazy" width="1108" height="586" src="https://i0.wp.com/first10em.com/wp-content/uploads/2020/11/Wei-2016-Shortrage-Aerosols.jpg?resize=1108%2C586&amp;ssl=1" alt="" srcset="https://i0.wp.com/first10em.com/wp-content/uploads/2020/11/Wei-2016-Shortrage-Aerosols.jpg?w=1108&amp;ssl=1 1108w, https://i0.wp.com/first10em.com/wp-content/uploads/2020/11/Wei-2016-Shortrage-Aerosols.jpg?resize=350%2C185&amp;ssl=1 350w, https://i0.wp.com/first10em.com/wp-content/uploads/2020/11/Wei-2016-Shortrage-Aerosols.jpg?resize=270%2C143&amp;ssl=1 270w, https://i0.wp.com/first10em.com/wp-content/uploads/2020/11/Wei-2016-Shortrage-Aerosols.jpg?resize=768%2C406&amp;ssl=1 768w, https://i0.wp.com/first10em.com/wp-content/uploads/2020/11/Wei-2016-Shortrage-Aerosols.jpg?resize=570%2C301&amp;ssl=1 570w" sizes="(max-width: 1108px) 100vw, 1108px" data-recalc-dims="1"><figcaption>From Wei 2016. Short range infection by aerosols is frequently ignored in discussion about disease transmission, biasing the available science.&nbsp;</figcaption></figure>



<figure><img src="https://lh3.googleusercontent.com/L5-2vvhXzO_aDuKAGFwUDx_AxmkSd38kpa6yoxpUFaZZClsGgK6MXNAkSF51B2EJw6Yt3CN4cvg22edQQ7_IrNotc9UB-diCwotWjds5t5A0KTXYRGN96WFJrkOk2vk9f5x42zvK" alt=""><figcaption>From Nielson 2020. Transmission by both aerosols and droplets is highest when close to the patient. Although aerosol transmission can occur at a distance, the vast majority will occur at close range.</figcaption></figure>



<p>So why don’t we see a lot of long range transmission of COVID-19? The primary explanation is simple dilution. The further you are from a patient, the more dilute aerosols become. Risk of aerosol transmission drops off dramatically with increasing distance.&nbsp;</p>



<p>The importance of dilution of aerosols is evident in everyday life. You can smell cigarette smoke when you are standing 8 meters away from a smoker, but it is nothing like the obnoxious fumes present if you were standing right next to them. Similarly, cigarette smoke is much worse indoors than out. Imagine each smoke molecule as a virus. You are obviously at much higher risk 1 meter away than you are at 8 meters. (But that doesn’t make smoke a droplet.)</p>



<p>Dilution doesn’t prevent exposure to the virus, but it makes it less probable. With dilution of aerosols, the primary driver of infection is the intrinsic infectivity of the pathogen. If infection occurs after exposure to only a few viral particles, we should expect to see more long range transmission despite the dilution. If larger exposures are required, we will see fewer infections. This is the primary difference between measles and COVID-19.</p>



<p>One final note about long range transmission: we really don’t know how common it is in COVID-19. Identification of long range transmission is incredibly difficult unless there are a very small number of cases. With a small outbreak of measles cases, it is easier to determine exactly where individuals were, and identify airborne transmission. For the vast majority of COVID-19 cases, we do not know how the individual became ill, and so could easily be overlooking long range transmission (especially when the possibility of aerosol transmission is dismissed out of hand in some circles). In fact, there seems to be pretty good evidence of long range transmission in many of the <a href="#superspreader">super-spreader events discussed below</a>.&nbsp;</p>



<h3>Our current approach is working</h3>



<p>Another argument occasionally used to dismiss aerosols as a mode of transmission is that our current PPE approach seems to be working in hospitals. First, <a href="https://first10em.com/we-are-not-doing-enough-to-protect-healthcare-workers-from-covid-19/">I would point out that healthcare workers are contracting COVID-19 at a rate that is far higher than the general population</a>, so this argument is pretty weak. Furthermore, as will be explored further below, there are many other factors that significantly dilute aerosols in most hospitals, like excellent ventilation, good distancing, and masking of both patients and providers. Although not quite as good as N95s, well fitting surgical masks will still filter out as much as 80% of infectious aerosols. (Makison Booth 2013) Combined with the low infectivity of SARS-CoV-2, these factors keep us relatively safe even when we stubbornly ignore the science that suggests aerosols are very important in the transmission of COVID-19.&nbsp;</p>



<h3>Particle size</h3>



<p>Many of the arguments against the aerosol spread of COVID-19 rely on incorrect assumptions about particle size. <a href="https://first10em.com/aerosols-droplets-and-airborne-spread/">I went into this at length in the first post</a>, so won’t repeat myself here. The basic summary is that particles of sizes that many articles refer to as droplets actually remain airborne for prolonged periods, and are therefore better classified as aerosols for the purposes of transmission. Just be careful when reading articles, because many don’t define these terms. When I use the term aerosol here, I am referring to any droplet that remains suspended in the air for longer that a few seconds, whatever the size, because that is the feature that matters for infection control. </p>



<h3>The lack of definitive proof</h3>



<p>Some of the arguments against aerosol transmission simply assume droplet transmission and demand “definitive proof” for aerosol transmission. I won’t attempt a treatise on the philosophy of science here, but that is an unreasonable bar.</p>



<p>One version of this argument states that viable SARS-CoV-2 has never been isolated from the air, and therefore we cannot definitively prove airborne transmission. This demand is unreasonable. Measles and tuberculosis are both known to be airborne, and no one has been able to isolate viable pathogens for either from the air. (Jimenez 2020) Furthermore, this is probably an outdated argument, as multiple studies actually have identified viable SARS-CoV-2 in the air. (Lednicky 2020; Santarpia 2020a)&nbsp;</p>



<p>The specifics of whether or not viable virus has been cultured from air samples is irrelevant. The point is that unfair standards are being used when comparing aerosols and droplets. There is no definitive proof that SARS-CoV-2 spreads through large droplets. (Jimenez 2020) It is crazy to require such stringent proof of aerosol transmission, while simultaneously just assuming droplet transmission is occurring. The same standards must be required for both claims. We are unlikely to have ‘definitive proof’ of either claim. Our decisions must be made based on the preponderance of the evidence.&nbsp;</p>



<h2><strong>There is good evidence that COVID-19 spreads through aerosols</strong></h2>



<p>Although there is no “smoking gun”, the evidence that COVID-19 spreads through aerosols is relatively strong. Below I outline the …</p></div></section></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://first10em.com/covid-19-is-spread-by-aerosols-an-evidence-review/">https://first10em.com/covid-19-is-spread-by-aerosols-an-evidence-review/</a></em></p>]]>
            </description>
            <link>https://first10em.com/covid-19-is-spread-by-aerosols-an-evidence-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25890346</guid>
            <pubDate>Sun, 24 Jan 2021 08:22:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jeff Bezos and Amazon do not want their workers voting by mail on unionization]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25889838">thread link</a>) | @jimmy2020
<br/>
January 23, 2021 | https://www.outkick.com/jeff-bezos-amazon-mail-in-votes/ | <a href="https://web.archive.org/web/*/https://www.outkick.com/jeff-bezos-amazon-mail-in-votes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		

		
		<div itemprop="articleBody">
			



<p>Jeff Bezos — a strong Democratic supporter — and Amazon are aiming to postpone a unionization vote at one of its warehouses in Alabama, the <em>Wall Street Journal</em> <a href="https://www.wsj.com/articles/amazon-seeks-to-postpone-alabama-unionization-vote-11611339250?mod=e2tw" target="_blank" rel="noopener noreferrer">reports</a>. Interestingly, Amazon has requested that the National Labor Relations Board reconsider allowing mail-in voting, claiming that the mail-in voting process has “serious and systemic flaws.”</p>
<p>Got that? Bezos and Amazon are doing all they can to prevent any shady activity when workers cast their ballots for unionization, and they are particularly concerned about the integrity of mail-in ballots.</p>
<p>You are likely trying to figure out how that adds up, right? The <em>Washington Post</em>, owned by Bezos, called any claims of mail-in voter fraud by Donald Trump and his supporters dangerous and inexcusable. Amazon even banned Parler from its servers, in part to ensure no one could claim voter fraud occurred from mail-in ballots back in November.</p>
<p>But stop trying to make it make sense. It is not supposed to add up.</p>
<p>In this case, mail-in voting is disadvantageous for Bezos and his e-commerce behemoth. Therefore, they now consider mail-in voting seriously flawed.</p>
<p>An Amazon spokesperson <a href="https://www.cnn.com/2021/01/22/tech/amazon-nlrb-union-election/index.html" target="_blank" rel="noopener noreferrer">tells</a> CNN the company is seeking a “valid, fair and successful election” and suggests that only in-person voting can ensure that. Hmm, interesting perspective.</p>
<p>Amazon has, thus far, fended off unions in the United States. If a majority of ballots vote in favor of unionization, hourly Amazon workers would send an L right up to Bezos’ office.</p>
<p>Bamazonunion.com explains that a union at Amazon would “give us the right to collectively bargain over our working conditions including items such as safety standards, training, breaks, pay, benefits, and other important issues that would make our workplace better.”</p>
<p>The NLRB says, “A mail ballot election will enfranchise employees who cannot enter the voting location for health reasons or due to positive COVID tests.” Fearing an unfavorable outcome, however, Amazon now insists that current COVID outbreaks aren’t dangerous enough to warrant this NLRB decision.</p>
<p>Amazon says that Lisa Henderson, NLRB’s Acting Regional Director “reached the remarkable conclusion that any level of infection or potential infection among employees counts as an ‘outbreak.'” <em>O</em><em>nly</em> 218 people employees, 2.88%, at its Bessemer facility tested positive during the 14-day period ending on January 7, which Amazon does not consider an “outbreak” apparently. This is quite the change of perspective. Imagine the coverage from the <em>Washington Post</em> if similar questions had been asked before November.</p>
<p>Mail-in voting has never been about the health of Americans or ensuring that each voice counts. As always, our country’s most powerful figures in both Washington and Silicon Valley base their opinions solely on the outcomes that increase their own power, finances, and flexibility.</p>
<p>Hypocritical, but sadly, all too predictable.</p>
		</div>
	</div></div>]]>
            </description>
            <link>https://www.outkick.com/jeff-bezos-amazon-mail-in-votes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25889838</guid>
            <pubDate>Sun, 24 Jan 2021 06:30:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Plotting Graphs from CSV Files in F# Using XPlot]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25889232">thread link</a>) | @todsacerdoti
<br/>
January 23, 2021 | https://markjames.dev/2021-01-23-plotting-csv-files-fsharp/ | <a href="https://web.archive.org/web/*/https://markjames.dev/2021-01-23-plotting-csv-files-fsharp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>Data visualization is an important tool, and there’s been many cases where I’ve found myself wanting to visualize data from a CSV file. As I’ve <a href="https://markjames.dev/2021-01-04-why-learning-fsharp-2021/">been learning F#</a> in the New Year, I thought that plotting a chart would be a great exercise to help sharpen my F# skills. This is especially true as once I finish porting <a href="https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/">the iRacing SDK</a> to F#, the next step will be to record my lap times and visualize the telemetry data. Fortunately, charts can be created fairly easily in F# by using the <a href="https://github.com/fslaborg/XPlot">XPlot</a> library in conjunction with Plotly.</p>

<p>For the purposes of this exercise, I’ll be using the <a href="https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks?select=data_by_year.csv">Spotify Dataset</a> from Kaggle, specifically the data by year file. From this file, we’ll be looking to plot the danceability of music over time. According to the Kaggle definition, danceability is “The relative measurement of the track being danceable (ranging from 0 to 1)”, but I’m unsure what the exact criteria for danceability is (maybe tempo and loudness combined with some other variable?). The end result should produce an HTML file which you can then embed on a website:</p>


    
        <meta charset="UTF-8">
        
    
    
        
        
    




<p>After creating a new F# console project in Visual Studio, the first step was to load the CSV file so that we can feed the data to XPlot. This can be done using the CSV type provider in the <a href="https://fsprojects.github.io/FSharp.Data/">F# Data library</a>.</p>

<p>Next, I created a new module called CSVRead inside a new file called CSVRead.fs. Inside the module, I place the first few lines of code:</p>

<div><div><pre><code><span>open</span> <span>FSharp</span><span>.</span><span>Data</span>

<span>[&lt;</span><span>Literal</span><span>&gt;]</span>
<span>let</span> <span>filePath</span> <span>=</span> <span>"""C:</span><span>\</span><span>Path</span><span>\</span><span>To</span><span>\</span><span>data_by_year.csv"""</span>

<span>type</span>  <span>rawCSV</span> <span>=</span> <span>CsvProvider</span><span>&lt;</span><span>filePath</span><span>,</span> <span>HasHeaders</span> <span>=</span> <span>true</span><span>&gt;</span>
</code></pre></div></div>

<p>In the above code, we bind our filepath to an identifier and then create a new type which contains the CSVProvider plus our filepath. We also include HasHeaders = true as our CSV file contains column headers.</p>

<p>One thing to note is that in F# we use [&lt;Literal&gt;] the same way we would const in C# or other languages. I’m using a literal here due to a blessing and curse of type providers in F#. On one hand, they’re amazing, because you get compile-time types for your data! But, that also means the data must be available at compile time. You can usually work around this by either:</p>
<ul>
  <li>Including representative data inside your project’s git repo, so you can build the provider based on sample data and then parse any conforming input data</li>
  <li>Using a string literal in source code to define sample data and use that for the provider (which is what I’ve done here).</li>
</ul>

<p>Now that we have our type provider setup, the next step is to create a function which loads our CSV file by using the GetSample() function from our type provider:</p>

<div><div><pre><code><span>let</span> <span>loadCSVFile</span> <span>()</span> <span>=</span>
    <span>try</span>
        <span>let</span> <span>cSVFile</span> <span>=</span> <span>rawCSV</span><span>.</span><span>GetSample</span><span>()</span>
        <span>let</span> <span>cSVFile</span> <span>=</span> <span>Some</span><span>(</span><span>cSVFile</span><span>)</span>
        <span>cSVFile</span>
    <span>with</span> <span>_</span> <span>-&gt;</span> <span>None</span>
</code></pre></div></div>

<p>This function’s signature is unit -&gt; Some cSVFile. Note that we’re using an option here since the CSV file may not load (for more information on using options for error handling, see <a href="https://markjames.dev/2021-01-14-handling-errors-fsharp-with-option-types/">this post</a>).</p>



<p>Now that we have a way to load our CSV file in place, the next step is to use XPlot to chart our data with Plotly, a handy charting library with an HTML frontend. To do so, I created a new file called Graphing.fs which would contain our graphing module and associated functions.</p>

<p>With our Graphing module created, the first step was to create a graphData function which would map our chosen rows to a scatter plot. My solution ended up looking like this:</p>

<div><div><pre><code><span>let</span> <span>graphData</span> <span>(</span><span>rawCSV</span><span>:</span> <span>rawCSV</span><span>)</span> <span>=</span>
    <span>Scatter</span><span>(</span>
       <span>x</span> <span>=</span> <span>[</span><span>for</span> <span>row</span> <span>in</span> <span>rawCSV</span><span>.</span><span>Rows</span> <span>-&gt;</span> <span>row</span><span>.</span><span>Year</span><span>],</span>
       <span>y</span> <span>=</span> <span>[</span><span>for</span> <span>row</span> <span>in</span> <span>rawCSV</span><span>.</span><span>Rows</span> <span>-&gt;</span> <span>row</span><span>.</span><span>Danceability</span><span>],</span>
        <span>mode</span> <span>=</span> <span>"lines+markers"</span>
    <span>)</span>
</code></pre></div></div>

<p>This function takes in our rawCSV type and returns a Scatter object, which is produced by iterating over the Year and Danceability rows of the CSV file.</p>

<p>One important thing to remember, is that in F#, the order of your files matter. In my Graphing module, I had been getting the error: <em>FS0039: The namespace or module ‘CSVRead’ is not defined</em> which confused me as I was referencing was my own module inside Graphing.fs. It turns out however, that I had forgotten to put CSVRead.fs above Graphing.fs inside Visual Studio, but once I did the error cleared up right away.</p>

<p>Although I’m not used to having the order of source files matter, it makes quite a lot of sense in terms of readability as the same principles apply to functions within the files. My experience with this style so far has made it easier to understand programs as I’m not constantly jumping from file to file and looking in different areas while trying to mentally keep track of function side effects.</p>

<p>The next step is to create a function which takes our scatter plot as input and then sets up the actual plot in Plotly:</p>

<div><div><pre><code><span>let</span> <span>createPlot</span> <span>(</span><span>data</span><span>:</span> <span>Scatter</span><span>)</span> <span>=</span>
    <span>data</span>
    <span>|&gt;</span> <span>Chart</span><span>.</span><span>Plot</span>
    <span>|&gt;</span> <span>Chart</span><span>.</span><span>WithOptions</span>
        <span>(</span><span>Options</span><span>(</span><span>title</span> <span>=</span> <span>"Music Danceability Over the Ages"</span><span>))</span>
    <span>|&gt;</span> <span>Chart</span><span>.</span><span>WithXTitle</span><span>(</span><span>"Year"</span><span>)</span>
    <span>|&gt;</span> <span>Chart</span><span>.</span><span>WithYTitle</span><span>(</span><span>"Danceability"</span><span>)</span>
    <span>|&gt;</span> <span>Chart</span><span>.</span><span>WithWidth</span> <span>700</span>
    <span>|&gt;</span> <span>Chart</span><span>.</span><span>WithHeight</span> <span>500</span>
    <span>|&gt;</span> <span>Chart</span><span>.</span><span>Show</span> 
</code></pre></div></div>
<p>The above code is fairy straightforward, setting up a pipeline which creates a chart to plot and then fills it with the relevant information. I must say that I’m becoming a big fan of F# pipe-forward operator as I find this style of coding to look clean and elegant while being easy to reason about.</p>



<p>With our CSV and graphing modules now in place, the final step was to chain our functions together in our Program.fs EntryPoint:</p>

<div><div><pre><code><span>open</span> <span>CSVRead</span>
<span>open</span> <span>Graphing</span>

<span>[&lt;</span><span>EntryPoint</span><span>&gt;]</span>
<span>let</span> <span>main</span> <span>argv</span> <span>=</span>
    <span>loadCSVFile</span><span>()</span>
    <span>|&gt;</span> <span>Option</span><span>.</span><span>map</span> <span>graphData</span>
    <span>|&gt;</span> <span>Option</span><span>.</span><span>map</span> <span>createPlot</span> 
    <span>|&gt;</span> <span>ignore</span>
    <span>0</span>
</code></pre></div></div>

<p>Here, we’re loading our CSV file and then chaining functions together to graph the data and create the plot. Note the use of Option.map here as loadCSVFile() is returning an option. In addition, we’re ignoring the return value since Plotly is being loaded and displayed in the browser and we don’t need any return value.</p>



<p>As you can see, plotting a chart from a CSV file is fairly straightforward in F#. I find F#’s pipe operator and lack of visual clutter makes it very succinct and easy to understand. Although this example creates a connect scatterplot, Plotly has a wide variety of chart types that you can create, and I highly recommend taking a look and playing around to see what you can do!</p>

      </article></div>]]>
            </description>
            <link>https://markjames.dev/2021-01-23-plotting-csv-files-fsharp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25889232</guid>
            <pubDate>Sun, 24 Jan 2021 04:25:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visual Sentence Composer for Japanese]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25888468">thread link</a>) | @sova
<br/>
January 23, 2021 | https://japanesecomplete.com/visual-composer | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/visual-composer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-wrapper">

			<!-- Header -->
				

			<!-- Features -->
				<section id="features">
					<div>
						<div>
							<div>

								<!-- Feature #1 -->
									<section>
										<a href="#"><img alt="Koi swimming" src="https://jpc0.b-cdn.net/img/daruma-dolls.jpg"></a>
										
										<h2>Start Generating Real Japanese, Visually!</h2>
										<p>
											Sign up today to be notified when we release our Point-and-Click interface for composing Japanese visually.</p>
										<p>Japanese Grammar is quite different from English Grammar, and now we take the stress and anxiety out of learning the language and generating authentic Japanese with our Visual Sentence Builder.  You can rest assured that what you generate is following Japanese grammar rules, although nailing the meaning you want is still up to you.</p>
										<p> Create some posts in Japanese and share them with your friends!</p>
										<p>This is yet another tool we are developing to help people learn to think in Japanese.  And best of all, the Visual Sentence Composer is free!  Although, subscribers will get extra bells and whistles to play with.</p>
										
										<p>Sign up today to be notified when the Visual Sentence Composer is ready.  Coming soon to a screen-device near you.</p>
										
										
									</section>

							</div>
						</div><!--endrow-->
					</div><!--endcontainer>-->
					<div>
						<div>
							<div>

								<!-- Feature #2 -->
									<section>
										<a href="#"><img alt="Build Japanese Sentences Visually with the Japanese Complete Sentence Composer." src="https://jpc0.b-cdn.net/img/mf-composer-004.png"></a>
										<h2>Four Simple Steps to Generating Real Japanese</h2>
										<p>
											We take the guess work out of grammar by providing a clean interface that limits the acceptable next input based on Japanese grammatical rules.
										</p>
										<p>Just follow the four easy steps and you're making real Japanese.  Choose a noun, then choose the correct corresponding particle, repeat steps one and two until you have all the <em>who, what, when, where, and hows</em> of your sentence, and finally select the correct verb for the sentence.  すごい！ [sugoi!]  Brilliant!</p>
										<p>We plan to offer translations of your creations inline so you can verify that you are <strong>meaning what you say and saying what you mean.</strong></p>
									</section>

							</div>
						</div><!--endrow-->
					</div><!--endcontainer>-->
					<div>
						<div>
							<div>

								<!-- Feature #3 -->
									<section>
										<a href="#"><img alt="In four easy steps, write real Japanese that obeys Japanese grammar rules!" src="https://jpc0.b-cdn.net/img/mf-composer-002.png"></a>
										<h2>Point, Click, Post, Share!</h2>
										<p>Part of learning a language to mastery is being able to generate fresh thoughts and ideas on your own.  With our visual sentence composer you'll be able to create fresh statements and share them with your friends.</p>
										<p>Other users on the platform will be able to see your posts and give you encouragement with a "like" or a "re-wag" (similar to a "retweet" in Twitterland.) </p>
										<p>People will be able to see your unique statements made from real Japanese, and we plan to offer inline translations of the posts so others can follow along in English and so that you can be sure your statement means what you want it to mean.</p>
									</section>

							</div>
						</div><!--endrow-->
					</div><!--endcontainer>-->
				</section>
				<!--boxes-->
				




				<section id="content2">
					<div>
						<div>
							<div>


								<!-- Feature #4 -->
									<section>
										
										<a href="#"><img alt="Sacred Mountain Fuji as framed by cherry blossoms." src="https://jpc0.b-cdn.net/img/fujicherry.jpg"></a>
										<h2>Master Japanese with Ease</h2>
										<p>
											Japanese, just like any other skill, takes practice to master.  Start your immersion experience in a fun and social way -- by creating real Japanese and sharing it with others, so you can encourage one another on your path to mastery!</p>
										<p>There are many ways to get exposed to Japanese via media, music, shows, and immersion, but relatively few ways to practice language generation in a way that makes sure you won't habituate to making the same mistakes over and over again.  We are changing this with our Visual Sentence Composer.  <a href="#signup">Sign up today to be notified when it's available for free!</a></p>
									</section>

							</div>

						</div>
					</div>
				</section>
			<!-- -->
			<!-- Features -->
			

	


			<!-- Footer -->
				

			<!-- Copyright -->
				<p>
					© Japanese Complete 2019, 2020, 2021. All rights reserved.
				</p>

		</div></div>]]>
            </description>
            <link>https://japanesecomplete.com/visual-composer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25888468</guid>
            <pubDate>Sun, 24 Jan 2021 02:32:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pip has dropped support for Python 2]]>
            </title>
            <description>
<![CDATA[
Score 431 | Comments 305 (<a href="https://news.ycombinator.com/item?id=25888249">thread link</a>) | @groodt
<br/>
January 23, 2021 | https://pip.pypa.io/en/stable/news/#id1 | <a href="https://web.archive.org/web/*/https://pip.pypa.io/en/stable/news/#id1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<li><p><strong>PROCESS</strong> Version numbers are now simply <code><span>X.Y</span></code> where the leading <code><span>1</span></code>
has been dropped.</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> Dropped support for Python 3.1.</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> Removed the bundle support which was deprecated in
1.4. (#1806)</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> File lists generated by <cite>pip show -f</cite> are now
rooted at the location reported by show, rather than one (unstated)
directory lower. (#1933)</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> The ability to install files over the FTP protocol
was accidentally lost in pip 1.5 and it has now been decided to not restore
that ability.</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> PEP 440 is now fully implemented, this means that
in some cases versions will sort differently or version specifiers will be
interpreted differently than previously. The common cases should all function
similarly to before.</p></li>
<li><p><strong>DEPRECATION</strong> <code><span>pip</span> <span>install</span> <span>--download-cache</span></code> and
<code><span>pip</span> <span>wheel</span> <span>--download-cache</span></code> command line flags have been deprecated and
the functionality removed. Since pip now automatically configures and uses
it’s internal HTTP cache which supplants the <code><span>--download-cache</span></code> the
existing options have been made non functional but will still be accepted
until their removal in pip v8.0. For more information please see
<a href="https://pip.pypa.io/en/stable/reference/pip_install.html#caching">https://pip.pypa.io/en/stable/reference/pip_install.html#caching</a></p></li>
<li><p><strong>DEPRECATION</strong> <code><span>pip</span> <span>install</span> <span>--build</span></code> and <code><span>pip</span> <span>install</span> <span>--no-clean</span></code> are now
<em>NOT</em> deprecated.  This reverses the deprecation that occurred in v1.5.3.
(#906)</p></li>
<li><p><strong>DEPRECATION</strong> Implicitly accessing URLs which point to an origin which is
not a secure origin, instead requiring an opt-in for each host using the new
<code><span>--trusted-host</span></code> flag (<code><span>pip</span> <span>install</span> <span>--trusted-host</span> <span>example.com</span> <span>foo</span></code>).</p></li>
<li><p>Allow the new <code><span>--trusted-host</span></code> flag to also disable TLS verification for
a particular hostname.</p></li>
<li><p>Added a <code><span>--user</span></code> flag to <code><span>pip</span> <span>freeze</span></code> and <code><span>pip</span> <span>list</span></code> to check the
user site directory only.</p></li>
<li><p>Silence byte compile errors when installation succeed. (#1873)</p></li>
<li><p>Added a virtualenv-specific configuration file. (#1364)</p></li>
<li><p>Added site-wide configuration files. (1978)</p></li>
<li><p>Added an automatic check to warn if there is an updated version of pip
available. (#2049)</p></li>
<li><p><cite>wsgiref</cite> and <cite>argparse</cite> (for &gt;py26) are now excluded from <cite>pip list</cite> and
<cite>pip freeze</cite>. (#1606, #1369)</p></li>
<li><p>Add <code><span>--client-cert</span></code> option for SSL client certificates. (#1424)</p></li>
<li><p><cite>pip show --files</cite> was broken for wheel installs. (#1635, #1484)</p></li>
<li><p>install_lib should take precedence when reading distutils config.
(#1642, #1641)</p></li>
<li><p>Send <cite>Accept-Encoding: identity</cite> when downloading files in an attempt to
convince some servers who double compress the downloaded file to stop doing
so. (#1688)</p></li>
<li><p>Stop breaking when given pip commands in uppercase (#1559, #1725)</p></li>
<li><p>pip no longer adds duplicate logging consumers, so it won’t create duplicate
output when being called multiple times. (#1618, #1723)</p></li>
<li><p><cite>pip wheel</cite> now returns an error code if any wheels fail to build. (#1769)</p></li>
<li><p><cite>pip wheel</cite> wasn’t building wheels for dependencies of editable requirements.
(#1775)</p></li>
<li><p>Allow the use of <code><span>--no-use-wheel</span></code> within a requirements file. (#1859)</p></li>
<li><p>Attempt to locate system TLS certificates to use instead of the included
CA Bundle if possible. (#1680, #1866)</p></li>
<li><p>Allow use of Zip64 extension in Wheels and other zip files. (#1319, #1868)</p></li>
<li><p>Properly handle an index or --find-links target which has a &lt;base&gt; without a
href attribute. (#1101, #1869)</p></li>
<li><p>Properly handle extras when a project is installed via Wheel. (#1885, #1896)</p></li>
<li><p>Added support to respect proxies in <code><span>pip</span> <span>search</span></code>.
(#1180, #932, #1104, #1902)</p></li>
<li><p><cite>pip install --download</cite> works with vcs links. (#798, #1060, #1926)</p></li>
<li><p>Disabled warning about insecure index host when using localhost. Based off of
Guy Rozendorn’s work in #1718. (#1456, #1967)</p></li>
<li><p>Allow the use of OS standard user configuration files instead of ones simply
based around <code><span>$HOME</span></code>. (#2021)</p></li>
<li><p>When installing directly from wheel paths or urls, previous versions were not
uninstalled. (#1825, #804, #1838)</p></li>
<li><p>Detect the location of the <code><span>.egg-info</span></code> directory by looking for any file
located inside of it instead of relying on the record file listing a
directory. (#2075, #2076)</p></li>
<li><p>Use a randomized and secure default build directory when possible.
(#1964, #1935, #676, #2122, CVE-2014-8991)</p></li>
<li><p>Support environment markers in requirements.txt files. (#1433, #2134)</p></li>
<li><p>Automatically retry failed HTTP requests by default. (#1444, #2147)</p></li>
<li><p>Handle HTML Encoding better using a method that is more similar to how
browsers handle it. (#1100, #1874)</p></li>
<li><p>Reduce the verbosity of the pip command by default. (#2175, #2177, #2178)</p></li>
<li><p>Fixed <a href="https://github.com/pypa/pip/issues/2031">#2031</a> - Respect sys.executable on OSX when installing from
Wheels.</p></li>
<li><p>Display the entire URL of the file that is being downloaded when downloading
from a non PyPI repository. (#2183)</p></li>
<li><p>Support setuptools style environment markers in a source distribution. (#2153)</p></li>
</div></div>]]>
            </description>
            <link>https://pip.pypa.io/en/stable/news/#id1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25888249</guid>
            <pubDate>Sun, 24 Jan 2021 02:01:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Dark-heya – Disposable chat platform]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25887799">thread link</a>) | @altilunium
<br/>
January 23, 2021 | https://altilunium.github.io/blog/darkHeya.html | <a href="https://web.archive.org/web/*/https://altilunium.github.io/blog/darkHeya.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://altilunium.github.io/blog/darkHeya.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25887799</guid>
            <pubDate>Sun, 24 Jan 2021 01:09:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning Userland DRM]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25887546">thread link</a>) | @felipetavares
<br/>
January 23, 2021 | https://felipetavares.com/post/learning-userland-drm-part-i/ | <a href="https://web.archive.org/web/*/https://felipetavares.com/post/learning-userland-drm-part-i/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>DRM is the bridge between the Linux kernel and actual software running atop
Linux, for most operations which involve a graphics card. For example, X11 and
Wayland actually send drawing commands to the graphics card using DRM.</p>
<p>In this post I’ll be talking about how to write software which communicates with
the graphics card directly, completely bypassing X. Do mind that I am also
learning while I write, so some information might be inaccurate and also I’m
jumping through unnecessary hoops, from the perspective of just getting things
done.</p>
<p>I’ll be using C++.</p>

<p>The kernel DRM API is file based, which means you can open a file representing
the graphics card (usually <code>/dev/dri/card0</code>) and use that file to send actual
commands to the card, using the <code>ioctl()</code> syscall with the opened file
representing the card.</p>
<p>Fortunately, there is also a library conveniently named <a href="https://gitlab.freedesktop.org/mesa/drm/">libdrm</a> that
simplifies all that. Keep in mind that all that it does is what we mentioned
above: opening a file and sending commands through <code>ioctl()</code> syscalls.</p>
<p>In C++ a simple program that interacts with the video card through DRM might
look like this at the top level:</p>
<div><pre><code data-lang="cpp"><span>#include</span> <span>&lt;cassert&gt;</span><span>
</span><span>#include</span> <span>&lt;unistd.h&gt;</span><span>
</span><span>#include</span> <span>&lt;fcntl.h&gt;</span><span>
</span><span></span>
<span>// The file which represents the card
</span><span></span><span>static</span> <span>const</span> <span>char</span> gpu_dev[] <span>=</span> <span>"/dev/dri/card0"</span>;

<span>int</span> <span>open_gpu</span>() {
  <span>return</span> open(gpu_dev, O_RDWR);
}

<span>int</span> <span>close_gpu</span>(<span>int</span> gpu) {
  <span>return</span> close(gpu);
}

<span>int</span> <span>main</span>(<span>int</span> arg_count, <span>char</span><span>**</span> arg_vector) {
  <span>const</span> <span>int</span> gpu <span>=</span> open_gpu();
  assert(gpu <span>&gt;=</span> <span>0</span>);

  <span>// some ioctl() magic here...
</span><span></span>
  assert(close_gpu(gpu) <span>&gt;=</span> <span>0</span>);

  <span>return</span> <span>0</span>;
}
</code></pre></div><p>And as a sanity check we can try to run it in a Linux machine:</p>
<pre><code>❯ clang++ drm-part-1.cpp -o drm-part-1
❯ ./drm-part-1
❯
</code></pre>
<p>Surely enough, it runs! But it doesn’t do anything yet. It needs that <code>ioctl()</code>
magic, but at least no assertions failed and we know we can open the video card
file now!</p>
<p>Lets include another library which has some very handy <em>structs</em> and also
definitions of parameters for <code>ioctl()</code>: <code>libdrm/drm.h</code>. While we are at it,
lets also include <code>sys/ioctl.h</code> and <code>iostream</code> for syscalls and printing.</p>
<div><pre><code data-lang="cpp"><span>#include</span> <span>&lt;libdrm/drm.h&gt;</span><span>
</span><span>#include</span> <span>&lt;sys/ioctl.h&gt;</span><span>
</span><span>#include</span> <span>&lt;iostream&gt;</span><span>
</span></code></pre></div>
<p>The first interaction that we are going to have with the card is not going to be
with the card itself but just with the driver (bummer, I know). Lets try to
retrieve the driver version using a <code>ioctl()</code> call.</p>
<p>There is a definition for a <em>struct</em> which holds exactly this data in
<code>libdrm/drm.h</code>, <code>drm_version_t</code>:</p>
<div><pre><code data-lang="cpp"><span>struct</span> <span>drm_version</span> {
	<span>int</span> version_major;	  <span>/**&lt; Major version */</span>
	<span>int</span> version_minor;	  <span>/**&lt; Minor version */</span>
	<span>int</span> version_patchlevel;	  <span>/**&lt; Patch level */</span>
	__kernel_size_t name_len;	  <span>/**&lt; Length of name buffer */</span>
	<span>char</span> <span>*</span>name;	  <span>/**&lt; Name of driver */</span>
	__kernel_size_t date_len;	  <span>/**&lt; Length of date buffer */</span>
	<span>char</span> <span>*</span>date;	  <span>/**&lt; User-space buffer to hold date */</span>
	__kernel_size_t desc_len;	  <span>/**&lt; Length of desc buffer */</span>
	<span>char</span> <span>*</span>desc;	  <span>/**&lt; User-space buffer to hold desc */</span>
};
</code></pre></div><p>To get the version from the driver we need to do three things:</p>
<ol>
<li>Initialize a <code>drm_version_t</code>, notice there are some <em>char *</em> fields for which
we need to allocate memory.</li>
<li>Call <code>ioctl()</code> with the appropriate parameters and a pointer to our
<code>drm_version_t</code>.</li>
<li>Print out the information we get and free everything.</li>
</ol>
<p>Seems easy enough right? Lets do it!</p>
<div><pre><code data-lang="cpp">drm_version_t <span>create_version</span>() {
  drm_version_t version;

  version.name <span>=</span> <span>new</span> <span>char</span>[<span>256</span>];
  version.date <span>=</span> <span>new</span> <span>char</span>[<span>256</span>];
  version.desc <span>=</span> <span>new</span> <span>char</span>[<span>256</span>];

  <span>return</span> version;
}
</code></pre></div><p>And:</p>
<div><pre><code data-lang="cpp"><span>void</span> <span>delete_version</span>(<span>const</span> drm_version_t <span>&amp;</span>version) {
  <span>delete</span> version.name;
  <span>delete</span> version.date;
  <span>delete</span> version.desc;
}
</code></pre></div><p>To print it out:</p>
<div><pre><code data-lang="cpp"><span>void</span> <span>print_version</span>(<span>const</span> drm_version_t <span>&amp;</span>version) {
  std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>string(version.name, version.name_len) <span>&lt;&lt;</span> std<span>::</span>endl
            <span>&lt;&lt;</span> std<span>::</span>string(version.desc, version.desc_len) <span>&lt;&lt;</span> std<span>::</span>endl
            <span>&lt;&lt;</span> version.version_major <span>&lt;&lt;</span> <span>"."</span>
            <span>&lt;&lt;</span> version.version_minor <span>&lt;&lt;</span> <span>"."</span>
            <span>&lt;&lt;</span> version.version_patchlevel <span>&lt;&lt;</span> std<span>::</span>endl;
}
</code></pre></div><p>And finally, we can call all that in our <code>main()</code>, notice the <code>ioctl()</code> call
using the <code>DRM_IOCTL_VERSION</code> value, which is defined in <code>libdrm</code> so we don’t
have to worry about the specific values passed:</p>
<div><pre><code data-lang="cpp"><span>int</span> <span>main</span>(<span>int</span> arg_count, <span>char</span><span>**</span> arg_vector) {
  <span>const</span> <span>int</span> gpu <span>=</span> open_gpu();
  assert(gpu <span>&gt;=</span> <span>0</span>);

  drm_version_t version <span>=</span> create_version();
  assert(ioctl(gpu, DRM_IOCTL_VERSION, <span>&amp;</span>version) <span>==</span> <span>0</span>);
  print_version(version);
  delete_version(version);

  assert(close_gpu(gpu) <span>&gt;=</span> <span>0</span>);

  <span>return</span> <span>0</span>;
}
</code></pre></div><p>After a little compiling, behold the power!</p>
<pre><code>❯ ./drm-part-1
i915
Intel Graphics
1.6.0
</code></pre>
<p>We are <em>talking</em> to the DRM driver of my Intel graphics card! No X11 involved,
this runs even directly in the <em>tty</em>!</p>
<p>Keep in mind that <em>libdrm</em> does a lot more than just provide the definitions and
we do not need to be calling <code>ioctl()</code> directly, but for the purposes of
learning I found important know exactly how the syscalls are made to the
graphics driver.</p>
<p><a href="https://felipetavares.com/src/drm/drm-part-1.cpp">drm-part-1.cpp</a></p>

    </article></div>]]>
            </description>
            <link>https://felipetavares.com/post/learning-userland-drm-part-i/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25887546</guid>
            <pubDate>Sun, 24 Jan 2021 00:30:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software engineering topics I changed my mind on]]>
            </title>
            <description>
<![CDATA[
Score 565 | Comments 397 (<a href="https://news.ycombinator.com/item?id=25887373">thread link</a>) | @goostavos
<br/>
January 23, 2021 | https://chriskiehl.com/article/thoughts-after-6-years | <a href="https://web.archive.org/web/*/https://chriskiehl.com/article/thoughts-after-6-years">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><article><p><img alt="image" src="https://s3.amazonaws.com/awsblogstore/articles/162da1cd/5cfd8e9f-image-1440px.jpeg" srcset="https://s3.amazonaws.com/awsblogstore/articles/162da1cd/5cfd8e9f-image-1440px.jpeg 1440w, https://s3.amazonaws.com/awsblogstore/articles/162da1cd/5cfd8e9f-image-1200px.jpeg 1200w, https://s3.amazonaws.com/awsblogstore/articles/162da1cd/5cfd8e9f-image-960px.jpeg 960w, https://s3.amazonaws.com/awsblogstore/articles/162da1cd/5cfd8e9f-image-720px.jpeg 720w, https://s3.amazonaws.com/awsblogstore/articles/162da1cd/5cfd8e9f-image-480px.jpeg 480w, https://s3.amazonaws.com/awsblogstore/articles/162da1cd/5cfd8e9f-image-240px.jpeg 240w"></p><p><sup>Published: 2021-01-23</sup></p><h2>Things I've changed my mind on:</h2><p>Things I now believe, which past me would've squabbled with:</p><ul><li>Typed languages are better when you're working on a team of people with various experience levels</li><li>Standups are actually useful for keeping an eye on the newbies.</li><li>Sprint retrospectives have their place so long as they're for actual course correction (i.e. "holy shit, <i>that</i> went poorly!") and not some god awful&nbsp; 'agile' / 'scum master' driven waste of everyone's time</li><li>Software architecture probably matters more than anything else. A shitty implementation of a good abstraction causes no net harm to the code base. A bad abstraction or missing layer causes everything to rot. &nbsp;</li><li>Java isn't that terrible of a language.</li><li>Clever code isn't usually good code. Clarity trumps all other concerns.</li><li>Bad code can be written in any paradigm</li><li>So called "best practices" are contextual and not broadly applicable. Blindly following them makes you an idiot</li><li>Designing scalable systems when you don't need to makes you a <i>bad engineer</i>.</li><li>Static analysis is useful</li><li>DRY is about avoiding a specific problem, not an end goal unto itself.</li><li>In general, RDBMS &gt; NoSql</li><li>Functional programming is another tool, not a panacea.</li></ul><h2>Opinions I've picked up along the way</h2><ul><li>YAGNI, SOLID, DRY. In that order.</li><li>Pencil and paper are the best programming tools and vastly under used</li><li>Trading purity in exchange for practicality is usually a good call</li><li>Adding more technology is rarely a good call</li><li>Talking directly to the customer always reveals more about the problem, in less time, and with higher accuracy</li><li>The word "scalable" has a mystical and stupefying power over the mind of the software engineer. Its mere utterance can whip them into a depraved frenzy. Grim actions have been justified using this word</li><li>Despite being called "engineers," most decision are pure cargo-cult with no backing analysis, data, or numbers</li><li>90% – <i>maybe</i> 93% – of project managers, could probably disappear tomorrow to either no effect or a net gain in efficiency.</li><li>After performing over 100 interviews: interviewing is thoroughly broken. I also have no idea how to actually make it better.</li></ul><h2>Old opinions unchanged:</h2><ul><li>People who stress over code style, linting rules, or other minutia are insane weirdos</li><li>Code coverage has absolutely nothing to do with code quality</li><li>Monoliths are pretty good in most circumstances</li><li>TDD purists are just <i>the worst</i>. Their frail little minds can't process the existence of different workflows.</li></ul><p>&nbsp; We'll see which of these have flipped or changed at year 10.</p></article></div></div></div></div>]]>
            </description>
            <link>https://chriskiehl.com/article/thoughts-after-6-years</link>
            <guid isPermaLink="false">hacker-news-small-sites-25887373</guid>
            <pubDate>Sun, 24 Jan 2021 00:02:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automation to run VMs based on vanilla Cloud Images on Firecracker]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25887152">thread link</a>) | @ahachete
<br/>
January 23, 2021 | https://ongres.com/blog/automation-to-run-vms-based-on-vanilla-cloud-images-on-firecracker/ | <a href="https://web.archive.org/web/*/https://ongres.com/blog/automation-to-run-vms-based-on-vanilla-cloud-images-on-firecracker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<main>

        	

	        <section id="post">
	            <p><span>Post</span>
	            </p>

	            <div data-aos="fade-right" data-aos-mirror="false">
	            	
	            	

                    <p> ·
                        <span>Dec 14, 2020</span> ·
                        <span>10 min read</span>
                    </p>

                    

                    

                    <div>
                        
                        <div>
  
  <p><span>Álvaro Hernández</span>
  <span>Founder and CEO</span>
</p></div>
                        
                    </div>
	            </div>

	            <div data-aos="fade-left" data-aos-delay="200" data-aos-mirror="false">
                    
                        <p><img src="https://ongres.com/img/blog/automation_firecracker-cover.jpg" alt="Automation to run VMs based on vanilla Cloud Images on Firecracker"></p>
<p>This blog post is a part of a series of posts devoted to <strong>Firecracker automation</strong>. Currently it consists of the
following posts:</p>
<ul>
<li>Part I (current)</li>
<li>Part II:
<a href="https://ongres.com/blog/63-node-eks-cluster-running-on-a-single-instance-with-firecracker">63-Node EKS Cluster running on a Single Instance with Firecracker</a></li>
</ul>
<h3 id="why-some-firecracker-automation-would-be-helpful">Why some Firecracker automation would be helpful</h3>
<p><a href="https://firecracker-microvm.github.io/">Firecracker</a> is a lightweight <em>VMM</em> (Virtual Machine Monitor), a VM
“controller” layered on top of KVM, created an open sourced by AWS. The virtual machine runs as a process in your
host OS, and is designed for simplicity and security. This post is not about Firecracker itself, but if you are
not familiar with it I recommend diving deeper.</p>
<p>Because of its simplicity, it only supports virtualizing Linux, and starting a VM requires handing to Firecracker a root
filesystem image and the kernel in uncompressed format. When using Firecracker you often times find yourself using the
sample Linux kernel and root filesystem images on Firecracker’s GitHub
“<a href="https://github.com/firecracker-microvm/firecracker/blob/master/docs/getting-started.md">getting started</a>”, or building
your own.</p>
<p>Firecracker is started as a process per VM, typically listening on a file-based socket for HTTP requests to its API for
configuration and VM lifecycle operations. Passing all the required configuration becomes a bit tedious and is a great
candidate for scripting.</p>
<p>Besides, <strong>it would be ideal to run vanilla cloud images, as produced by the different distros, on Firecracker</strong>. This
is possible and was enabled when
<a href="https://github.com/firecracker-microvm/firecracker/pull/1246">initrd support was added</a>. Still, you need to download
the cloud image and modify it to potentially add SSH keys, change the default user’s password, configure the network,
etc.</p>
<p>At the end of the day, both <strong>configuring and starting Firecracker, and preparing the cloud images to connect and use
them, requires a fair amount of effort. The main goal of this post is to show some automation for these tasks, and offer
a simple way to run cloud images, as provided</strong>. Key to this automation will be the use of
<a href="https://cloudinit.readthedocs.io/">cloud-init</a>, a pervasive initialization software that is included in most cloud
images, allowing to configure the image on first boot, based on provided metadata.</p>
<h3 id="the-architecture">The architecture</h3>
<p>The created automation should be good to launch multiple VMs. Multiple Firecracker processes will be then needed (one
for each VM), and one socket file for each too (for Firecracker’s API to listen to our commands and launch the VMs). Then,
we will need one “disk” for each VM. A disk for a Firecracker VM is just a file on the host OS containing the root
filesystem. So it will suffice to download the cloud image, make some minor scripted adjustments to it (more on this
later) and then use it as a template –basically, copy the root filesystem to the file that the VM will effectively use.</p>
<p>What about networking? Firecracker allows you to specify a tap device to be passed to the VM. These tap devices will
then have one endpoint on the VM and another one on the host, allowing the network traffic to flow. In order for the host
OS to communicate with the VMs, and the VMs to communicate among each other, a Linux bridge will be used, where all the
host endpoints of the tap devices will be connected. The bridge will have its own IP on the same network (enabling host
processes to reach the network on the VMs), and then will be MASQUERADEd via <code>iptables</code> to allow the VMs to reach the
Internet.</p>
<p>Additionally, a second tap device will be added to the VMs. It will not be connected anywhere on the host or be given
any IP address on the host. This tap device will also have the special Firecracker property <code>allow_mmds_requests</code>, which
enables communications from the guest VM to the HTTP metadata endpoint to access Firecracker’s
<a href="https://github.com/firecracker-microvm/firecracker/blob/master/docs/mmds/mmds-user-guide.md">metadata service</a> (MMDS).
This metadata service is what will be used to provide the necessary information for the VM to configure itself on first
boot. The MMDS could have been enabled just on the main tap interface; but both for performance and security reasons,
it is better to have a separate tap device just to access MMDS.</p>
<p>This is how the complete architecture looks like:</p>
<p><img src="https://ongres.com/img/blog/automation_firecracker-architecture.jpg" alt="Firecracker automation: architecture"></p>
<h3 id="cloud-init">cloud-init</h3>
<p>Key to all the process is <code>cloud-init</code>. It is installed by default on most cloud images, and runs on first boot,
configuring the VM. <code>cloud-init</code> supports several methods (“sources”) from where to feed the necessary metadata on how
to configure the instance. Here I will be using one called
<a href="https://cloudinit.readthedocs.io/en/latest/topics/datasources/nocloud.html"><code>nocloud-net</code></a>, which is specific for
on-prem environments. It supports fetching all the metadata from an HTTP endpoint, which is a perfect match for
Firecracker’s MMDS service. It will suffice then to write the cloud-init necessary metadata from the host to
Firecracker’s MMDS service via its API, and the guest VM will connect to the URL provided as the seed for <code>nocloud-net</code>
cloud-init datasource, and fetch it. Configuring <code>nocloud-net</code> can be easily achieved by passing to Firecracker’s boot
source configuration the following additional Linux kernel command line argument:</p>
<pre><code>ds=nocloud-net;s=http://169.254.169.254/latest/
</code></pre><p>(see
<a href="https://gitlab.com/ongresinc/blog-posts-src/-/blob/master/202012-firecracker_cloud_image_automation/conf/firecracker/boot-source.json">conf/firecracker/boot-source.json</a>).
Here <code>169.254.169.254</code> is the address where by default the MMDS service is accessible from the guest (can be changed via
Firecracker’s API if desired) and <code>/latest</code> is part of cloud-init’s API when accessing metadata (more precisely, it’s
a versioning field).</p>
<p>But how do we connect to the metadata IP service? We should firstly configure the network, in particular the tap device
that would be configured for MMDS access. Fortunately, we can also pass a network configuration via a kernel command line
argument (<code>network-config</code>), from where it will be read by cloud-init. It must be a
<a href="https://cloudinit.readthedocs.io/en/latest/topics/network-config-format-v2.html#network-config-v2">Networking Config Version 2</a>
YAML file, base64 encoded (can also be gzip’ed before encoding –used here). The applied configuration will be
derived from the file
<a href="https://gitlab.com/ongresinc/blog-posts-src/-/blob/master/202012-firecracker_cloud_image_automation/conf/cloud-init/network_config.yaml">conf/cloud-init/network_config.yaml</a>.</p>
<p>Upon boot, cloud-init will then read the kernel command-line arguments explained, and will configure <code>eth0</code> inside the
VM, the device that is allowed to communicate with the MMDS API, with an IP able to access the MMDS range; and <code>eth1</code>
with an IP in the range of the internal network of the VMs. Remember that <code>eth0</code>’s host tap endpoint is not connected
anywhere, while <code>eth1</code>s host tap endpoint is connected to the bridge (and NAT-ed). Note that because of this, the IP
address of the <code>eth0</code> device can be made the same on all VMs.</p>
<p>Once the network is configured, it will follow the <code>nocloud-net</code> datasource configuration, and connect to the HTTP
endpoint, accesible from <code>eth0</code>. According to cloud-init, it will need to fetch two files from the metadata service:</p>
<ul>
<li>
<p><a href="https://gitlab.com/ongresinc/blog-posts-src/-/blob/master/202012-firecracker_cloud_image_automation/conf/cloud-init/meta-data.yaml">meta-data</a>.
It serves to perform instance configuration. Here only will be used to set the instance id and configure the hostname.</p>
</li>
<li>
<p><a href="https://gitlab.com/ongresinc/blog-posts-src/-/blob/master/202012-firecracker_cloud_image_automation/conf/cloud-init/user-data.yaml">user-data</a>.
Probably known to many (as you can pass this on most cloud environments), is used to perform package installation, user
configuration and many other actions on instance’s first boot. Here, it is used as a
<a href="https://cloudinit.readthedocs.io/en/latest/topics/examples.html">cloud-config</a> script, one of the several possible
options to initialize the instance provided by cloud-init. In particular, it is used to create the <code>fc</code> user, add it to
password-less sudo, and set the SSH authorized key to an SSH pubkey, part of a key-pair previously generated on the host.</p>
</li>
</ul>
<p>Thanks to this process, once the VM is booted, it will have its network configured and will be accessible from the host
(thanks to the IP assigned to the bridge) via password-less SSH and with sudo permissions. <strong>Just like your regular EC2
instace!</strong></p>
<h3 id="automation-steps">Automation steps</h3>
<p>All the automation has been written on a series of –a bit <em>hackish</em>– shell scripts. They are only intended for
demonstration purposes, and definitely have a lot of room for improvement. All the source code is
<a href="https://gitlab.com/ongresinc/blog-posts-src/-/tree/master/202012-firecracker_cloud_image_automation">publicly available</a>.</p>
<p>To use the automation, please review first the <code>README.md</code> file and see if you want to modify any values in <code>variables</code>.
Note that this will only run on a bare metal Linux system or a Linux VM with support for nested KVM virtualization.
Follow the next steps:</p>
<ol>
<li>Download Firecracker and set permissions for your user to access the <code>/dev/kvm</code> special device. See
<a href="https://github.com/firecracker-microvm/firecracker/blob/master/docs/getting-started.md">Getting Started with Firecracker</a>
for more information.</li>
</ol>
<pre><code>sudo setfacl -m u:${USER}:rw /dev/kvm
[ $(stat -c "%G" /dev/kvm) = kvm ] &amp;&amp; sudo usermod -aG kvm ${USER}
</code></pre><ol>
<li>
<p><a href="https://gitlab.com/ongresinc/blog-posts-src/-/blob/master/202012-firecracker_cloud_image_automation/01-setup_host.sh">01-setup_host.sh</a>.
This script creates the host bridge where all VMs will be connected and creates the <code>iptables</code>
rules to NAT outgoing traffic from the VMs to Internet. Modify the <code>$EGRESS_IFACE</code> variable if the device would not be
correctly detected.</p>
</li>
<li>
<p><a href="https://gitlab.com/ongresinc/blog-posts-src/-/blob/master/202012-firecracker_cloud_image_automation/02-gen_keypair.sh">02-gen_keypair.sh</a>.
Generates the SSH keypair. The private key will be kept on the host to SSH the VMs. The public
key will be inserted into the <code>authorized_keys</code> of the <code>fc</code> user in all VMs. Note that the more modern and
secure <a href="https://medium.com/risan/upgrade-your-ssh-key-to-ed25519-c6e8d60d3c54">EdDSA</a> keys have been used.</p>
</li>
<li>
<p><a href="https://gitlab.com/ongresinc/blog-posts-src/-/blob/master/202012-firecracker_cloud_image_automation/03-download_generate_image.sh">03-download_generate_image.sh</a>.
All the user configuration will be performed via cloud-init. However, because of how Firecracker works, cloud image as
downloaded cannot be used directly. First of all, Firecracker doesn’t use a disk image with partitions, but just the root filesystem.
Also, the kernel and initrd need to be provided separately (as Firecracker doesn’t support system emulation for
bootloaders). Finally, the kernel image cannot be compressed. This script just downloads a <code>.tar.xz</code>-ed cloud image,
copies it into an <code>ext4</code> filesystem backed by a file, downloads the initrd and kernel, and uncompresses the kernel.</p>
</li>
<li>
<p><a href="https://gitlab.com/ongresinc/blog-posts-src/-/blob/master/202012-firecracker_cloud_image_automation/04-launch_vms.sh">04-launch_vms.sh</a>.
The main script, that launches N virtual machines. It launches one Firecracker process per VM, proceeds to configure the
VM and the metadata via Firecracker’s HTTP API, and finally boots into it. Note that several requests are needed to configure
all the …</p></li></ol></div></section></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ongres.com/blog/automation-to-run-vms-based-on-vanilla-cloud-images-on-firecracker/">https://ongres.com/blog/automation-to-run-vms-based-on-vanilla-cloud-images-on-firecracker/</a></em></p>]]>
            </description>
            <link>https://ongres.com/blog/automation-to-run-vms-based-on-vanilla-cloud-images-on-firecracker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25887152</guid>
            <pubDate>Sat, 23 Jan 2021 23:33:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quebec researchers say they have found an effective drug to fight Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25886836">thread link</a>) | @longdefeat
<br/>
January 23, 2021 | https://montreal.ctvnews.ca/mobile/quebec-researchers-say-they-have-found-an-effective-drug-to-fight-covid-19-1.5279310 | <a href="https://web.archive.org/web/*/https://montreal.ctvnews.ca/mobile/quebec-researchers-say-they-have-found-an-effective-drug-to-fight-covid-19-1.5279310">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>MONTREAL -- 
	A team of researchers from the Montreal Heart Institute believe they have found an effective weapon against COVID-19: colchicine, an oral tablet already known and used for other diseases.</p>
<p>
	For Dr. Jean-Claude Tardif, who led the study, this is a "major scientific discovery," he said. Colchicine is the first "effective oral drug to treat out-of-hospital patients."</p>
<p>
	"To be able to offer this, from Quebec, and for the planet, we are very happy," said Tardif.</p>
<p>
	<a href="https://www.colcorona.net/" target="_blank">The ColCorona study</a> involved 4,159 patients whose diagnosis of COVID-19 had been confirmed by a nasopharyngeal test (PCR).</p>

<p>
	Analysis of the study found that colchicine resulted in reductions in hospitalizations by 25 per cent, the need for mechanical ventilation by 50 per cent, and deaths by 44 per cent.</p>
<p>
	"This is the first hope for patients who have COVID, who are worried and who hope that they will not have complications," said Tardif. Previously, "there were no tablets that could be taken by mouth and reduce the risks."</p>
<p>
	Tardif said he believes that prescribing the drug could help reduce congestion in hospitals quickly and reduce health-care costs in Quebec and elsewhere.</p>
<p>
	"Our study showed the effectiveness of treatment using colchicine to prevent the phenomenon of the major inflammatory storm and reduce complications related to COVID-19," he said.</p>
<p>
	As colchicine is a well-understood drug, it could be used very quickly to treat people with COVID-19, the researcher says.</p>
<p>
	"Colchicine is old as it is -- we've been treating gout with it for hundreds of years -- so it's available in pharmacies," Tardif said, speaking in French.</p>
<p>
	"So any doctor, tomorrow, who reads this can definitely decide to prescribe if he wants."</p>
<p>
	On Friday evening, Quebec Premier Francois Legault called the study "big news" on social networks.</p>
<p>
	In the spring, Legault said the Colcorona study was one of the largest studies in the world researching ways to fight the virus.</p>
<p>
	The randomized, double-blind, placebo-controlled study was deployed in Canada, the United States, Europe, South America and South Africa.</p>
<p>
	"It was a double-blind study, meaning neither the patient, nor the team that ran the study, including me, knew whether the patient was taking the placebo or the drug," explained Tardif.</p>
<p>
	"There was just one group, independent from us, which was aware."</p>
<p>
	He said the team is "very proud of the work accomplished -- it is a clinically convincing result," adding that he assembled a spectacular team from all over Quebec including microbiologists, intensive care specialists, statisticians, computer scientists and epidemiologists.</p>
<p>
	The Centre de Coordination des Essais Cliniques de Montréal (MHICC) of the Montreal Heart Institute coordinated the study.</p>
<p>
	<em>This report by The Canadian Press was first published Jan. 23, 2021.</em></p>
                                              </div></div>]]>
            </description>
            <link>https://montreal.ctvnews.ca/mobile/quebec-researchers-say-they-have-found-an-effective-drug-to-fight-covid-19-1.5279310</link>
            <guid isPermaLink="false">hacker-news-small-sites-25886836</guid>
            <pubDate>Sat, 23 Jan 2021 22:43:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Who should you expect to spend your life with?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25886695">thread link</a>) | @apsec112
<br/>
January 23, 2021 | https://worldspiritsockpuppet.com/2021/01/23/who-spend-time-with.html | <a href="https://web.archive.org/web/*/https://worldspiritsockpuppet.com/2021/01/23/who-spend-time-with.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Striking things about the figure below, which I got from <a href="https://ourworldindata.org/time-use">Our World in Data</a>, on time use:</p>
<ul>
  <li>People spend increasing time alone over their whole lives, with the exception of roughly their twenties. This surprises me a bit because it seems like people like spending time with other people, and I would expect them to increasingly succeed at it with experience and time to acquire partners and families and friends.</li>
  <li>From 31 to 45, people spend more time with children<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> on average than they spend with any other category of person, including for instance partners and colleagues.</li>
  <li>You might think all this children time would be substituting for some partner time, but as the children time swoops downward by three quarters, partner time stays about the same.</li>
  <li>People are at a relationship-time-steady-state between about thirty and sixty. I imagine that many people start relationships in that time, so does that mean that they also stop them at about the same rate, or gradually reduce time with their partners at a rate matching others’ forming of new relationships? Are people radically less likely to start relationships after about thirty?</li>
  <li>People spend broadly decreasing time with every group except their partner over time, from some early peak for each trend—in the teenage years for friends and family, and in the 20s and 30s for colleagues and children. I wonder how many people just like being alone and with their partners more than most other options, and steadily optimize for that, once they have been sociable enough to find a partner in their early years.</li>
  <li>Coworker time peaks at age 25-30 and goes slowly downward before the retirement descent. Is that from people dropping out of the workforce? Earning themselves a nice private office? Some difference between junior and senior roles?</li>
  <li>People spend fairly consistent time with their friends after a decline from 18 to 40. Retirement doesn’t increase it. Spending three hours a day fewer with children doesn’t increase it. I guess those things go to solitude.</li>
</ul>



<p>In other news, <a href="https://ourworldindata.org/">Our World In Data</a> seems awesome.</p>



  </div>
  
  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://worldspiritsockpuppet.com/2021/01/23/who-spend-time-with.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25886695</guid>
            <pubDate>Sat, 23 Jan 2021 22:22:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Experience as an Undergraduate AI Researcher]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25886582">thread link</a>) | @GoodD0ctor
<br/>
January 23, 2021 | https://beehired.io/articles/my-experience-as-an-ai-researcher | <a href="https://web.archive.org/web/*/https://beehired.io/articles/my-experience-as-an-ai-researcher">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>If there is one thing that I have taken away from my 3 years studying CS at college, it’s that learning is not exclusively reserved for the lecture halls. In fact, I would argue that I have learned more by myself in my bedroom in the past 10 months than I have in the first 2 years of university.</p><p>There are several factors that went into this, but I want to focus on my experience doing research for both the computational brain lab and machine learning (ML) lab at my college. Before that, here’s a little background.</p><p>I breezed past the typical undergraduate CS courses and to be honest, I can’t say that I learned much more than I had for free online or that I could have in far less time for free online (do you see the pattern here?).</p><p>Learning what IEEE-754 floating point representation is was great and all, but something else caught my eye the winter of my sophomore year, ML. I started going through Andew Ng’s famous CS229 on coursera and was introduced to a whole new world with these interesting concepts. I quickly became obsessed. But at the same time, I stumbled upon the world of entrepreneurship and listened to countless founder stories of successful startups. My university classes became secondary to what I was teaching myself online and what I was consuming via podcasts and founder interviews on YouTube.</p><p>Now for those of you who are being swayed to skip out on university because of what I’ve said until now, please don’t take that as the main message. I am blessed to be able to attend a university and get this experience, and I will forever be grateful and remember these years of my life. What I do want to say though is that you will find much more fulfilment by proactively challenging yourself to find things which will satisfy your intellectual and/or creative desires beyond the lecture hall.</p><p>With my new found interest in ML, I scoured my university’s computer science website for things that an undergraduate student could do for more exposure to AI and ML. I came across the term research, which was obviously a term that I was familiar with but I did not know that the world of AI research was so vast, with its history going back as far as 1955. There were so many professors who were working on incredible things, so I hastily read a few of each of their publications and cold emailed close to 10 professors, each with a genuine interest in their work and desire to join their lab. 9 of them ghosted me, but 1 professor emailed me back saying that he wanted to meet the following day.</p><p>I had finally found an outlet where I could work on some more interesting things related to AI. Turns out, I had gotten far too ahead of myself. I was assigned to work on an interface for a robot head, which I happily worked on but quickly found to not be the kind of work I was looking for. Then covid-19 hit like a truck and all students and professors were sent home, and here we are now.</p><p>Covid didn’t stop my research group, and of course classes were still in session. I apologize for potentially sounding insensitive, but to be honest Covid brought a turning point in terms of research for me. I constantly started bugging a PhD student in my lab about what I could learn and work on during this time working remotely. After several back and forth emails, he offered a chance for me to work on an actual AI project to work towards a second author publication with him and one other lab mate.</p><p>Working on this publication quickly took all time away from me, and I loved it <i>at first</i>. The intellectual challenges that I faced in having to learn so many things on the fly fundamentally changed the way that I learn and I will forever be grateful that I learned how to learn during my time working on this project. Working with two other PhD students, we successfully submitted our project to a conference called CoRL and the work was accepted. Great! But I faced several realizations about the world of AI research, at least in academia.</p><p>I realized that research in AI was really cool and intellectually challenging, but I also realized that it took a very large amount of time away from both me and the PhD students in the lab. Deep down inside, I knew that I always wanted to start my own company, and I missed listening to and studying how other founders started their startups. I was passionate about building, but research had taken the time that I once spent listening to CEO interviews and podcasts away, not to mention time I once spent learning how to build software products. But the prestige and challenging nature of research and PhD students was compelling to me and it seemed like an easy route to respect from friends and family.</p><p>Amidst this internal conflict, I reached out to the ML lab at my college because it would be great to have another publication and potential recommendation letter for applying to PhD programs later on. I joined the ML lab November 2020 and worked on some very interesting things in probabilistic generative models and representation learning. The work that the lab was interested in was exactly what I had wanted to work on when I first fell in love with ML and AI. However, every day that went by reading a few papers a day, preparing for presentations on some of these papers, and going deeper still into the rabbit hole of ML research, my desire for making products and working on being an entrepreneur screamed louder and louder.</p><p>I took time to carefully reflect on what my desires were, and I found that all I desired was to live a life of continual learning and working on interesting problems. Research was a means by which I was gaining this for sure, but my opinion on research started to become exactly like what my opinion on classical lecture learning was; it was slow and I found that I could do things faster on my own. <i>Lightbulb</i> I realized that the bureaucracy of academic learning and research put ceilings over the potential that I believe I have. Only a month and a half later I contacted the&nbsp; professor of the ML lab that I wanted to work on my entrepreneurial dreams and that I could not commit to contributing to the lab any longer.</p><p>And here I am now, writing this blog to share my experiences with the people of the internet. Some of you may be wondering, do I regret giving up my chances of going to a prestigious PhD program and gaining the “elite” status of being an AI researcher at a top university lab? To be honest, I don’t have an answer for that explicitly, but I do know that the past month where I’ve been preparing to launch a startup with my cofounder and closest friend has been just as challenging and just as fulfilling, if not more, as my experience working with the computational brain lab and ML lab. The ceiling I once felt from university and research is nowhere to be seen, because the path to entrepreneurship is impossible to foresee. Everyone’s story of launching a successful startup is different, thus I live everyday in mystery just trying to get closer to my goal of working on challenging problems to help people live easier and happier lives. The path to being a researcher is quite established and oftentimes a rinse and repeat cycle. You do research in your undergraduate years and make strong relationships with your professors in hopes of getting strong recommendation letters for PhD programs, then you hopefully join a top 10 lab in the world and do research for 5-6 years before either doing a postdoc at a university or joining an industry lab. Then you work for the next few decades until you become a tenured professor at a nice university while still doing research and guiding younger researchers to push out publications for your lab. This sounds great for sure, but living in uncertainty sounds even greater to me. Even if I don’t gain a single ounce of respect or prestige that I could have from continuing to be a researcher, I will have no regrets because in the time that I live I know that I will be working on creating products and services to make the lives of people just like me easier. There is no ceiling to entrepreneurship. You control what your path is, and I’ve just started going along my path after taking a few detours.</p><p>I am by no means telling people to quit their dreams of pursuing research in AI, rather I am sharing the reason why I both joined and quit research in the field as an undergraduate student.</p></div></div></div>]]>
            </description>
            <link>https://beehired.io/articles/my-experience-as-an-ai-researcher</link>
            <guid isPermaLink="false">hacker-news-small-sites-25886582</guid>
            <pubDate>Sat, 23 Jan 2021 22:05:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Station M1 – my fastest ARM SBC]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25886580">thread link</a>) | @todsacerdoti
<br/>
January 23, 2021 | https://www.thanassis.space/stationm1.html | <a href="https://web.archive.org/web/*/https://www.thanassis.space/stationm1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="Page">
        
        <div id="MainContent">
            <p><a href="https://www.reddit.com/r/programming/submit" onclick="window.location = window.location.protocol + '//www.reddit.com/r/programming/submit?url=' + encodeURIComponent(window.location); return false"> <img src="https://www.thanassis.space/spreddit7.gif" alt="submit to programming reddit"> </a></p><p><em>(January 2021)</em></p>

<div>
<p><b>TL; DR: Another year, another SBC!</b>
This time, it's a 4-core RK3328, with Gigabit Ethernet and USB3.
My fastest ARM-based computer yet!</p><p>

Let's install 
<a target="_blank" href="https://www.armbian.com/">Armbian</a>
on it, and put it through performance tests.</p></div>

<h2>The hardware</h2>

<p>I received the Station M1 a few days ago - courtesy of
<a target="_blank" href="https://www.stationpc.com/">Firefly</a>.</p>

<div>
<p><img src="https://www.thanassis.space/stationm1.jpg" alt="Credit-card sized, inside a metal enclosure"></p><p>
<em>Credit-card sized, inside a metal enclosure</em>
</p></div>

<p><span color="red"><b>Inside:</b></span></p>

<ul>
<li><strong>RK3328</strong> Quad-core A53 64bit CPU, at 1.5GHz</li>
<li>2GB or 4GB of <strong>DDR3 RAM</strong>. My board is the 2GB model, costing 65$ at the time I am writing this.</li>
<li>8/16/32/64/128GB <strong>EMMC</strong> for storage; my board came with 16GB. Note: you can also use Micro-SD cards.</li>
<li>802.11 b/g/n <strong>Wifi</strong> (2.4GHz) + bluetooth 4.2. Antenna is included inside the enclosure.</li>
<li>26 pin <strong>GPIO</strong> header - assuming you open the enclosure.</li>
</ul>

<p><span color="red"><b>Front:</b></span></p>

<ul>
<li>One <strong>USB3</strong> and one USB2 type-A ports.</li>
<li><strong>Infrared receiver</strong> - the SBC also comes with a remote control</li>
<li><strong>Micro-SD</strong> card slot</li>
<li><strong>Power button</strong>; a sorely missed feature in many other SBCs <em>(forcing
people like me to do <a href="https://www.thanassis.space/remotepower.html" target="_blank">crazy</a> things)</em>.</li>
</ul>

<p><span color="red"><b>Back:</b></span></p>

<ul>
<li><strong>USB-C</strong> for power (5V)</li>
<li>1x <strong>HDMI2.0</strong>, supporting up to 4K@60Hz</li>
<li>RJ45 10/100/1000 (i.e. <strong>Gigabit Ethernet</strong>)</li>
<li>3.5mm <strong>audio jack</strong></li>
<li>All this in <strong>credit-card size!</strong> See picture with 2 Euro coin for size comparison.</li>
</ul>

<p>The SBC came with a power adapter, so I plugged it in, connected a Full-HD 
monitor to the HDMI port, and...</p>

<div>
<p><img src="https://www.thanassis.space/stationm1-welcome.jpg" alt="Default setup screen"></p><p>
<em>Default setup screen</em>
</p></div>

<p>After 5 minutes of configuration setup, I ended up with a fully operational
Android 10 set-top box experience; with the provided remote control allowing
easy control of the pre-installed Kodi.</p>

<p>But if you want to see an Android review of this SBC, you are on the wrong 
site :-)<br>
I have far more fun <a href="https://www.thanassis.space/android.html" target="_blank">hacking Android</a>
than I ever have using it.</p>

<p>So, to quote a <a target="_blank" href="https://www.youtube.com/user/EEVblog">famous electronics Youtuber</a>:</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;<em>"Don't turn it on! <strong>Take it apart!</strong>"</em></p>

<p>...and I'll add: <em>"...and then install a fully open-source OS, compiled from scratch"</em>.</p>

<p>Keep reading :-)</p>

<h2>Disassembly</h2>

<p>There are 4 screws holding the enclosure firmly in place. After removing them,
the insides of the SBC are easily accessible:</p>

<div>
<p><img src="https://www.thanassis.space/stationm1-disassembly.jpg" alt="Disassembled"></p><p>
<em>Disassembled.</em>
</p></div>

<p>As you can see, the Wi-Fi antenna is already pre-installed; the two chips 
giving my SBC 2GB of RAM are easily identifiable; and on the top, the
GPIO pins that make SBCs what they are - perfect toys for makers :-)</p>

<p>In case you are wondering, yes, that's a battery slot for an RTC.
I always use NTP, of course - but this is a nice perk for usage scenarios
where the SBC is not connected to the web.</p>

<p>In the case of the Station M1, the 3 pins shown in the picture below
form a 3.3V serial port, that speaks at 1500000 baud - in classic 8-N-1.
Any USB2TTL dongle that works with 3.3V levels will do nicely:</p>

<div>
<p><img src="https://www.thanassis.space/stationm1-serial.jpg" alt="Serial port"></p><p>
<em>Serial port</em>
</p></div>

<h2>The issue of SW - Armbian</h2>

<p>At a high level, there are basically two options with most ARM SBCs <em>(including this one)</em>.</p>

<ul>
<li>Either you trust the makers of the board with the custom
distributions they build (including Android ones).<br></li>
<li>Or you trust <a target="_blank" href="https://www.armbian.com/">Armbian</a>.</li>
</ul>

<p>I am firmly in the second camp. I don't know where the makers of the Station M1
stand on the subject, but as a rule, SBC builders rarely - if ever - update
their custom distros. I can't abide by that.</p>

<p><a target="_blank" href="https://docs.armbian.com/Developer-Guide_Using-Vagrant/">
I therefore prefer building the entire, flashable Armbian distribution for my targets myself - from source</a>.
There is no better way to trust my SBCs, than knowing that I built their OS myself;
and that I can go as deep as I want and debug everything using the source code...
From the deepest dungeon at kernel level, all the way to the top-level bash scripts. </p>

<p>Then again, I do this sort of thing <a href="https://www.thanassis.space/cv.pdf">for a living</a>. Your mileage may vary.</p>

<p>If you do decide to build from sources, the board is marked in the Armbian
<a href="https://github.com/armbian/build/blob/master/config/boards/station-m1.csc">repo</a>
as CSC - so you need to enable the CSC option during the build, and then
choose "Station M1". Other than that, everything just worked;
building went just as smoothly as any other flashable Armbian image I've compiled:</p>

<div>
<pre><tt><span>$ git clone https</span><span>:</span><span>//github</span><span>.</span><span>com/armbian/build</span><span>/</span>
<span>$ cd build</span>
<span>$ sudo </span><span>.</span><span>/compile</span><span>.</span><span>sh</span>
</tt></pre>
</div>

<p>Since it takes some time to do this build, I performed it from an Ubuntu-Focal
Droplet that I created in my Digital Ocean account. At a cost of 3 cents per hour
and a total build time of approximately 3h, I paid 10 cents to have fully traceable
SW for my SBC.</p>

<p>Not bad :-)</p>

<p>Another option you have is to trust completely the Armbian developers - and simply
download the <a target="_blank" href="https://www.armbian.com/station-m1/">pre-built image</a>.</p>

<p>In either case, you then "flash" the image in any micro SD card.
In my case, I executed something like this:</p>

<pre><code># ls -l *img
-rw-r--r-- 1 root root 1816133632 Jan 20 20:06
    Armbian_21.02.0-trunk_Station-m1_bullseye_current_5.10.9.img

# dd if=Armbian_21.02.0-trunk_Station-m1_bullseye_current_5.10.9.img
    bs=1M oflag=sync iflag=fullblock status=progress of=/dev/sdc
</code></pre>

<p>When running this command, my Micro-SD card was inside a USB adapter plugged-in and visible under /dev/sdc.
Make sure you use the appropriate target here, <strong>otherwise you will wipe out your own machine's
data!</strong> The output of <code>dmesg</code> is your friend - look at it <em>(as well as the output
of <code>lsblk</code>)</em> to see the name of the device for your SD writer.</p>

<p>The <code>sync</code> output flag of <code>dd</code> caused a significant improvement in reliability with
my SD writer. You may or may not need this option - but if you don't use it,
make sure you actually invoke <code>sync</code> after <code>dd</code> is complete. And you will definitely
benefit from a big block size (<code>bs=1M</code>) and a nice and simple progress report
while the writing takes place (<code>status=progress</code>). </p>

<p>Most importantly: don't you dare remove the <code>fullblock</code> iflag. Trust me on
this - you need it.</p>

<h2>Booting Armbian</h2>

<p>After that, I plugged the Micro-SD card in the Station M1, and booted - in a 
normal, Armbian boot. I didn't use my USB-to-TTL adapter this time; the HDMI
cable offered a far easier way to interact with the boot process - and a
keyboard plugged in the USB2 port allowed me to easily work with the system.</p>

<p>I then connected the SBC directly to my router (over the Gigabit Ethernet
port), setup SSH, rebooted, and SSH-ed into the machine from my laptop.</p>

<p>Since I hate the speed and reliability aspects of Micro-SD cards, I then
proceeded to migrate into an external USB3 drive. I can probably migrate into
the EMMC, but I chose not to - I prefer to keep it in its pristine
("Android-y") state, for easy re-use when COVID allows me to visit people
again. A credit-card sized, portable set-top box is always nice :-)</p>

<p>To migrate to the external drive, I copied everything in the root fs into a
freshly formatted 5GB ext partition. The rest of the drive was formatted as
a LUKS-encrypted drive, which will take advantage of the crypto instructions
in this SBCs ARM cores.</p>

<p>I then modified two files in the SD-card filesystem to make the system boot
from the USB drive instead:</p>

<ul>
<li>The <code>/boot/armbianEnv.txt</code> needs to know where the root fs lives:</li>
</ul>

<div>
<pre><tt>
<span>verbosity</span><span>=</span><span>1</span>
<span>bootlogo</span><span>=</span><span>false</span>
<span>overlay_prefix</span><span>=</span><span>rockchip</span>
<span>fdtfile</span><span>=</span><span>rockchip/rk</span><span>3328</span><span>-roc-pc</span><span>.</span><span>dtb</span>
<span>rootdev</span><span>=</span><span>UUID</span><span>=........</span><span>-</span><span>....</span><span>-</span><span>....</span><span>-</span><span>....</span><span>-</span><span>............</span>
</tt></pre>
</div>

<p>The device UUID is easily obtainable via <code>blkid -c /dev/null</code>.</p>

<ul>
<li>The <code>/etc/fstab</code> should also point to the proper root.
So the proper UUID needs to appear there:</li>
</ul>

<div>
<pre><tt>
<span>UUID</span><span>=...</span><span> </span><span>/</span><span> ext4 defaults</span><span>...</span>
</tt></pre>
</div>

<p>That's it - the SBC now works from reliable, fast storage.</p>

<h2>How fast is it, with USB3 storage?</h2>

<p>Well, don't take my word for it - let's watch it in action:</p>

<center>
<a href="https://asciinema.org/a/386483" target="_blank"><img src="https://asciinema.org/a/386483.svg"></a>
</center>

<p>What you can see in this <em>asciinema</em> video:</p>

<ul>
<li><p>This (110MB+ per second) is the same speed I have seen with this mechanical
external USB3 drive on any of my computers (including PCs). No slowdowns in
the Station M1.</p></li>
<li><p>Did you notice the temperature of 37C? This is my coolest SBC yet...
The metal enclosure and the thermal pad it uses to attach on the SoC perform
their work admirably.</p></li>
</ul>

<h2>Benchmarking CPU performance</h2>

<p>OK, but what if we stress the machine? Let's benchmark the device with my <a href="https://www.thanassis.space/renderer.html">renderer</a>.</p>

<pre><code># apt install libsdl1.2-dev
...
# wget -q -O - https://github.com/ttsiodras/renderer/archive/v2.3b.tar.gz \
    | tar zxvf -
# cd renderer-2.3b
# ./configure
# make -j4
...
# make bench
</code></pre>

<p>My renderer uses all available cores, and stresses the memory and the FPU a lot <a href="#renderer">[1]</a>.
You can see results from all kinds of machines running it via the <a href="https://openbenchmarking.org/test/pts/ttsiod-renderer#metrics">Phoronix</a>
test suite.</p>

<p>For completeness, I include the results from all my ARM SBCs - so you can compare
for yourself.</p>

<ul>
<li><strong>Raspberry PI2</strong>: it reached 58C - and scored 17fps...</li>
</ul>

<div>
<pre><tt><span>Average value</span><span>:</span><span> </span><span>17.306140</span>
<span>Std deviation</span><span>:</span><span> </span><span>0.199651</span>
<span>       Median</span><span>:</span><span> </span><span>17.401600</span>
<span>          Min</span><span>:</span><span> </span><span>17.064300</span>
<span>          Max</span><span>:</span><span> </span><span>17.479500</span>
</tt></pre>
</div>

<ul>
<li><strong>Orange PI Zero</strong>: It scored 21 frames per second and its temperature rose above 80C.
That forced me to <a target="_blank" href="https://www.thanassis.space/thebeast.html#thebeast">install a fan to keep it cool</a>...</li>
</ul>

<div>
<pre><tt><span>Average value</span><span>:</span><span> </span><span>21.027340</span>
<span>Std deviation</span><span>:</span><span> </span><span>0.037930</span>
<span>       Median</span><span>:</span><span> </span><span>21.017200</span>
<span>          Min</span><span>:</span><span> </span><span>20.979300</span>
<span>          Max</span><span>:</span><span> </span><span>21.082800</span>
</tt></pre>
</div>

<ul>
<li><strong>ROCK PI S</strong> scored 28fps, with a temperature that reached 76C:</li>
</ul>

<div>
<pre><tt><span>Average value</span><span>:</span><span> </span><span>28.139440</span>
<span>Std deviation</span><span>:</span><span> </span><span>0.084740</span>
<span>       Median</span><span>:</span><span> </span><span>28.153200</span>
<span>          Min</span><span>:</span><span> </span><span>28.003400</span>
<span>          Max</span><span>:</span><span> </span><span>28.227900</span>
</tt></pre>
</div>

<ul>
<li><strong>Station M1</strong>: Let's watch the newcomer live:</li>
</ul>

<center>
<a href="https://asciinema.org/a/386492" target="_blank"><img src="https://asciinema.org/a/386492.svg"></a>
</center>

<p>The Station M1 scored 32.7 fps. It never exceeded 1.3GHz while doing so,
  which makes me think there's more potential here - the Armbian defaults
  can probably be bumped up. Not that I need more horsepower <em>(it offers
  more than what I need)</em> but it's still nice to know there's room to grow.</p>

<p>Also, very importantly - notice that even though we stressed the machine to
  an extreme - all cores fully utilised <em>(see second run with <code>top</code> in the
  first <code>tmux</code> pane for confirmation)</em> the temperature <strong>never went above 53C</strong>.</p>

<p>The enclosure barely felt warm during the test; nothing even remotely concerning.
  From a thermal perspective, amongst all my ARM SBCs, this is the one I trust the most.</p>

<h2>Network</h2>

<p>Is it truly a Gigabit device?</p>

<p>Well, the best way to confirm it, is to use another <a href="https://www.thanassis.space/atomicpi.html">machine</a>
on the same Gigabit network, to send/receive data and benchmark via <code>iperf3</code>.</p>

<p>Again, let's see it done live:</p>

<center>
<a href="https://asciinema.org/a/386494" target="_blank"><img src="https://asciinema.org/a/386494.svg"></a>
</center>

<p>That looks like Gigabit to me :-)</p>

<h2>Power consumption</h2>

<p>OK - so we know this is a more than fast enough SBC, with fast USB3
storage and Gigabit networking. But how does it fare in terms of
power consumption?</p>

<p>I revert the configuration to a …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thanassis.space/stationm1.html">https://www.thanassis.space/stationm1.html</a></em></p>]]>
            </description>
            <link>https://www.thanassis.space/stationm1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25886580</guid>
            <pubDate>Sat, 23 Jan 2021 22:04:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mikrokosmos a λ-Calculus Interpreter]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25886133">thread link</a>) | @haskellandchill
<br/>
January 23, 2021 | https://mroman42.github.io/mikrokosmos/ | <a href="https://web.archive.org/web/*/https://mroman42.github.io/mikrokosmos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org15ba408">Try Mikrokosmos!</a></li>
<li><a href="#org4af199c">About</a></li>
</ul>
</div>
</div>

<p><img src="https://mroman42.github.io/mikrokosmos/icon.svg.png" alt="icon.svg.png">
</p>

<p>
<b>Mikrokosmos</b> is an untyped and simply typed λ-calculus
interpreter, borrowing its name from the series of progressive piano
études <i><a href="https://www.youtube.com/watch?v=VEsMk3DAzWM">Mikrokosmos</a></i> written by <i>Bela Bartok</i>. It aims to provide
students with a tool to learn and understand the <a href="https://en.wikipedia.org/wiki/Lambda_calculus#Informal_description">λ-calculus</a>.
</p>

<div id="outline-container-org15ba408">
<h2 id="org15ba408">Try Mikrokosmos!</h2>
<div id="text-org15ba408">
<p>
You can try Mikrokosmos in your browser. Press the <b>evaluate</b>
button below!
</p>



<p>
A more detailed tutorial and a user's guide are available.
</p>

<ul>
<li><a href="https://mroman42.github.io/mikrokosmos/tutorial.html">Mikrokosmos: a tutorial</a>.</li>
<li><a href="https://mroman42.github.io/mikrokosmos/userguide.html">Mikrokosmos: user's guide</a>.</li>
</ul>
</div>
</div>

<div id="outline-container-org4af199c">
<h2 id="org4af199c">About</h2>
<div id="text-org4af199c">
<p>
Mikrokosmos has been developed by <a href="https://mroman42.github.io/blog/about/">Mario Román</a> as part of a bachelor
thesis. It is free software licensed under GPL-3. You can follow the
development on the relevant GitHub repositories
</p>

<ul>
<li><a href="https://github.com/mroman42/mikrokosmos">Mikrokosmos</a>, main repository. Console interpreter.</li>
<li><a href="https://github.com/mroman42/jupyter-mikrokosmos">Mikrokosmos-Jupyter</a>, a Jupyter kernel for the interpreter.</li>
<li><a href="https://github.com/mroman42/mikrokosmos-tutorials">Mikrokosmos-tutorials</a>, a set of tutorials written for Jupyter.</li>
<li><a href="https://github.com/mroman42/mikrokosmos-lib">Mikrokosmos-libs</a>, standard libraries for the interpreter.</li>
<li><a href="https://github.com/mroman42/mikrokosmos-js">Mikrokosmos-JS</a>, call Mikrokosmos from JS.</li>
</ul>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://mroman42.github.io/mikrokosmos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25886133</guid>
            <pubDate>Sat, 23 Jan 2021 21:11:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Filmulator – a streamlined, open-source raw photo editor]]>
            </title>
            <description>
<![CDATA[
Score 210 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25885760">thread link</a>) | @CarVac
<br/>
January 23, 2021 | https://filmulator.org/v0-11-0/ | <a href="https://web.archive.org/web/*/https://filmulator.org/v0-11-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
  
  <p><span>2021-01-23</span></p><p>Now announcing Filmulator version 0.11.0!</p>
<h2 id="filmulate">Filmulate</h2>
<ul>
<li>Filmulator now properly handles cameras where whitepoint varies according to the set ISO. To benefit from this, go to the Settings tab and tell Filmulator to download the latest camera constants.</li>
<li>The auto CA correction now loads properly for manual lenses on selecting an image.</li>
<li>Reduce Memory Usage now works correctly when quick preview is on.</li>
</ul>
<h2 id="import">Import</h2>
<ul>
<li>The file selection for import no longer needs the text box cleared in between uses.</li>
<li>Files that match the name filters but cannot be processed (weird DNGs especially) are now properly ignored when importing.</li>
</ul>
<h2 id="organize">Organize</h2>
<ul>
<li>The Organize view now defaults to the current day upon opening.</li>
<li>When on the Organize tab, pressing left/right switches the currently selected day, and holding shift will let you select multiple days.</li>
</ul>
<h2 id="queue">Queue</h2>
<ul>
<li>Double-clicking on an image in the queue now brings you directly to the Filmulate tab if you weren't already there.</li>
<li>When an image is right-clicked, the rating shortcuts apply to that image instead of the image currently open for editing.</li>
</ul>
<h2 id="general">General</h2>
<ul>
<li>ARM AArch64 builds are now possible, but no premade builds are available at this time.</li>
<li>The version number can now be seen at the bottom right corner of the Settings tab.</li>
</ul>
<p>Builds are available for Linux and Windows, but still no MacOS builds are available at this time. Please get in touch if you can help set up CI for MacOS builds.</p>
<p>Downloads:</p>
<ul>
<li><a href="https://github.com/CarVac/filmulator-gui/releases/download/v0.11.0/Filmulator_v0.11.0.AppImage">Filmulator v0.11.0 Linux AppImage</a></li>
<li><a href="https://github.com/CarVac/filmulator-gui/releases/download/v0.11.0/Filmulator_v0.11.0.exe">Filmulator v0.11.0 Windows Installer</a></li>
</ul>
<p>You can discuss the release <a href="https://discuss.pixls.us/t/filmulator-v0-11-0-released/22944">here on our official forum</a> or <a href="https://www.reddit.com/r/Filmulator/">on our subreddit</a>.</p>

</div>


        </div></div>]]>
            </description>
            <link>https://filmulator.org/v0-11-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25885760</guid>
            <pubDate>Sat, 23 Jan 2021 20:30:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Restoring metabolism of myeloid cells reverses cognitive decline]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25885721">thread link</a>) | @JPLeRouzic
<br/>
January 23, 2021 | https://padiracinnovation.org/News/2021/01/restoring-metabolism-of-myeloid-cells-reverses-cognitive-decline | <a href="https://web.archive.org/web/*/https://padiracinnovation.org/News/2021/01/restoring-metabolism-of-myeloid-cells-reverses-cognitive-decline">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">                                   
                    <p>A <a href="https://www.nature.com/articles/s41586-020-03160-0">new study</a> published Jan. 21 in Nature by Katrin Andreasson and Paras Minhas, suggests that cognitive aging is not irrevocable, but can be reversed by reprogramming glucose metabolism in myeloid cells.</p>

<p>Biologists have long hypothesized that reducing inflammation may slow down the aging process and delay the onset of age-associated diseases, such as heart disease, Alzheimer's disease, cancer and the frailty that concerns each of us during our aging.
Yet, the question of exactly what causes these inflammatory reactions of the immune system had not found a definitive answer.</p>

<p><strong>Diseases concerned</strong></p>

<p>A long-standing observation in epidemiological studies of aging populations has been that NSAIDs, which inhibit the production of cyclooxygenase-1 (COX-1) and COX-2 and prostaglandin (PG), prevent the development of the disease. Alzheimer's.</p>

<p>Model ALS mice and patients with sporadic ALS have increased levels of prostaglandin E2 (PGE2). In addition, levels of microsomal proteins PGE synthase-1 and cyclooxygenase-2, which catalyze PGE2 biosynthesis, are <a href="https://pubmed.ncbi.nlm.nih.gov/27140190/">dramatically increased in the spinal cord mice model of ALS </a>.</p>

<p>Preclinical studies suggest that prostaglandin E2 (PGE2) is an essential inflammatory mediator of brain damage via the activation of four G protein coupled receptors, namely EP1-EP4.</p>

<p>Transient inhibition of the EP2 receptor by antagonists permeable to the blood-brain barrier shows marked anti-inflammatory and neuroprotective effects in several rodent models of epilepsy, without, however, having a noticeable effect on seizures per se.</p>

<p>In the brain, microglia lose the ability to remove misfolded proteins associated with neurodegeneration.</p>

<p><strong>Prostaglandin and myeloid cells</strong></p>

<p>Prostaglandins are one of the main mediators of inflammation which play an important role in improving neuroinflammatory and neurodegenerative processes. Myeloid cells are the main source of PGE2, a hormone belonging to the prostaglandin family. Prostaglandins are a group of physiologically active lipid compounds derived from arachidonic acid.</p>

<p>Arachidonic acid is one of the most abundant fatty acids in the brain (10% of its fatty acid content). Among other things, it helps protect the brain from oxidative stress by activating the gamma receptor activated by peroxisome proliferators.</p>

<p>One type of receiver for PGE2 is EP2. This receptor is found on immune cells and is particularly abundant on myeloid cells. It initiates inflammatory activity inside cells after receiving PGE2.</p>

<p><strong>Myeloid and macrophages</strong></p>

<p>Myeloid cells are distinguished from lymphocytes.
Monocytes, a type of myeloid cell, and their macrophages and dendritic cell descendants perform three main functions in the immune system. These are phagocytosis, antigen presentation and cytokine production.</p>

<p>Macrophages engulf and digest cell debris, foreign substances, microbes, cancer cells, and anything that does not have the type of proteins specific to healthy cells in the body on its surface.
The first author of the study, Paras Minhas, initially isolated monocytes from blood donated by healthy people under the age of 35 or over 65. Scientists also looked at macrophages from young mice compared to old mice.</p>

<p>During aging, functional changes are due to macrophages. Microglia residing in the brains of aged mice increase their soma volume but reduce the length of their processes, limiting their ability to interact and support neuron survival.</p>

<p>Macrophages can undergo "training" after re-exposure to a stimulus.
Recent studies have described that the induced immunity in young mice leads to an increase in myeloid lineage cells and can occur in myeloid precursors in the bone marrow.
As we age, a similar shift towards a myeloid cell line occurs, and the aging microenvironment may also have a ripple effect.</p>

<p><strong>Effects of a significant increase in PGE2 levels</strong></p>

<p>The authors observed that older macrophages from mice and humans not only produced significantly more PGE2 than in younger subjects, but also had a much higher number of EP2 on their surface. Andreasson and his colleagues also confirmed significant increases significant levels of PGE2 in the blood and brain of old mice.
The researchers found that in aging macrophages and microglia, PGE2 signaling through its EP2 receptor promotes the sequestration of glucose into glycogen, reducing glucose flow and mitochondrial respiration.</p>

<p>The dramatically increased PGE2-EP2 binding in elderly myeloid cells alters energy production in these myeloid cells by inducing them to store glucose, rather than fueling energy production in the cell.
Cells store glucose by converting this energy source into long chains of glucose called glycogen (the animal equivalent of starch).</p>

<p>This build-up creates a state of chronic exhaustion (stress) in the cells, which leads them to express inflammatory signals.
Not only have aging macrophage cells found it difficult to burn glucose, they also don't use other sources of energy for respiration. Young macrophage cells were better able to utilize lactate and pyruvate.</p>

<p><strong>An apparent rejuvenation?</strong></p>

<p>The authors deleted EP2 in transgenic mice, which halved the amounts of receptors. Macrophages from 20 month old EP2-deficient mice maintained normal cellular respiration and glycolysis. In control animals of the same age, macrophage function deteriorated with age.
Cells from control animals secreted pro-inflammatory factors, were poorly phagocytosed, and had fewer and poorly formed mitochondria. Macrophages deficient in EP2, on the other hand, had none of these problems, behaving like those of young mice.</p>

<p>Scientists gave mice one or both of two experimental drugs known to interfere with PGE2-EP2 binding in animals for a month. They also incubated cultured mouse and human macrophages with these substances. In doing so, the old myeloid cells metabolized glucose just like the young myeloid cells, reversing the inflammatory character of the old cells.</p>

<p>More strikingly, the drugs reversed the cognitive decline associated with the age of mice. Indeed, the old mice who received them performed recall and spatial navigation tests as well as the young adult mice. Blocking peripheral myeloid EP2 signaling is therefore sufficient to restore cognition in aged mice.</p>

<p>The blood-brain barrier EP2 inhibitor C52 improved glycogen synthesis, improved glycolytic response and TCA cycling of myeloid cells (microglia and peripheral macrophages), and improved cognitive performance.</p>

<p>Surprisingly, mice reaped these cognitive benefits even when treated with an EP2 inhibitor (PF-04418948) that does not cross the blood-brain barrier.</p>

<p><strong>Towards drugs?</strong></p>

<p>Since activation of the EP2 receptor has been identified as a common culprit in several neurological conditions associated with inflammation, such as stroke and neurodegenerative disease, selective small molecule antagonists targeting EP2 are being developed. to suppress PGE2-mediated neuroinflammation.</p>

<p>Several companies manufacture selective EP2 antagonists, but none are approved for human use. Pfizer's PF-04418948 was tested for safety in a Phase 1 study in 2010, but the company has discontinued clinical development.</p>

<p>However, targeting EP2 could be complicated. The receptor is known to regulate blood flow and blood pressure, and has been shown to protect the brain during stroke.</p>
                </div></div>]]>
            </description>
            <link>https://padiracinnovation.org/News/2021/01/restoring-metabolism-of-myeloid-cells-reverses-cognitive-decline</link>
            <guid isPermaLink="false">hacker-news-small-sites-25885721</guid>
            <pubDate>Sat, 23 Jan 2021 20:26:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2 times 3 can sometimes equal 7 with Android's Neural Network API]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25885524">thread link</a>) | @aga_ml
<br/>
January 23, 2021 | http://alexanderganderson.github.io/engineering/2021/01/23/integer_indeterminism.html | <a href="https://web.archive.org/web/*/http://alexanderganderson.github.io/engineering/2021/01/23/integer_indeterminism.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="http://alexanderganderson.github.io/static/img/indeterminism.png" alt="two_times_three"></p>

<p>Two times three equals six or at least that’s what I naively expected.</p>

<p>It is well-known that floating point matrix multiplication can result in a variety of <a href="https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9911-determinism-in-deep-learning.pdf">surprises</a>.
But did you know that quantized neural networks are not deterministic as well?
A quantized neural network uses integers to
multiply weights and activations in a neural network.
Thus, the naive logic goes, two and three represented and multiplied as integers should always give the exact same result,
namely six.</p>

<p>However, according to the <a href="https://source.android.com/devices/neural-networks#validation">Android NNAPI Driver Validation</a> documentation, a
driver is valid if multiplication of quantized tensors is within plus or minus
one bit.</p>



<p>The non-determinism of quantized multiplication is a result of optimizing for
the most common neural network deployment use cases.  Neural networks used for
classification and detection generally work well with small amounts of
non-determinism due to the nature of the mathematical operations involved in
<a href="https://openreview.net/forum?id=B1IDRdeCW">neural networks</a>. Furthermore, such networks often benefit from training with
some noise (e.g. batch normalization). Likewise, the input to many neural
networks comes from a camera that generates inherently variable images.</p>

<p>The main challenge associated with neural network deployment on the phone
is creating models that are sufficiently fast, power friendly, and small on
disk. Quantizing a neural network helps one improve in all of these categories.
Quantized weights take up less space on disk, take less energy to transfer, and
can be moved more quickly between different levels of memory.</p>

<p>The last issue at play is that it is much cheaper (both in terms of computing
cost and engineering effort) to quantize a pre-trained model than to train an
existing model from scratch. Consequently, the method developed in this
<a href="https://arxiv.org/abs/1712.05877">Integer Inference</a> paper
targets quantizing existing models. The key idea is that a floating point
value can be approximated as a scale times a quantized value minus a zero
point. (Also take a look at the <a href="https://www.tensorflow.org/lite/performance/quantization_spec">Tensorflow Quantization Spec</a>).
The scale and zero point can be chosen relatively easily by, for
instance, looking at the
range of the weights and activations when evaluating the model on a number of
representative inputs.</p>

<p>The loss in predictive performance due to quantization in many practical use cases is
small and this abstraction is widely implemented and baked into hardware,
for instance, by Qualcomm’ <a href="https://developer.qualcomm.com/docs/snpe/quantized_models.html">Snapdragon Neural Processing Engine SDK</a>.
[Strictly speaking, the drivers for this hardware could be
changed to ensure determinism, but that may result in a significant loss in
speed at inference time.]
The SNPE was developed and subsequently, Android sought to simplify the process
of deploying neural networks given the wide variety of available
accelerators. The restrictions on the driver tests were relaxed after pushback from
chip manufacturers whose hardware and drivers did not produce deterministic
quantized math.</p>

<p>Unfortunately, the NN API off by at most 1 (or 3 for a larger network) leaves a
lot of room for funny business that can change the results by small amounts.
The hardware and driver vendors want to produce fast times and low energy
usage numbers on
various neural network benchmarks and are less concerned about reproducibility.
This can lead to unexpected changes in neural network outputs.
For instance, the zero point or scale of the
weights might be changed for some reason by the hardware, and the quantized
values are then recomputed. Another thing that can happen is that the range might
be slightly shifted to make zero exactly representable (see Case 3: Inputs are
both negative and positive in the <a href="https://developer.qualcomm.com/docs/snpe/quantized_models.html">Snapdragon Neural Processing Engine SDK</a>).
Likewise, as the off by one error bound is on a per layer basis, larger
networks generate accumulating error. Practically speaking, the error bound is
increased to three for mobilenet in the NN API driver validation tests. Other
networks could produce larger errors.</p>



<p>The lack of determinism for quantized neural networks touches on the broader
issue of cross platform reproducibility and performance optimization for neural networks.
As the neural networks get deployed more and more widely, these issues will grow in importance.</p>

<p>The first major issue is that if you want to deploy a neural network across
many platforms, you don’t have any guarantees that you are going to get the
same results.
Even if you manage to assemble a large team to test your networks on many
different platforms, the problem isn’t solved.
<em>The lack of determinism means that even if you test your network
on every platform, a driver update may unexpectedly change your results</em>.
This creates an ongoing engineering cost beyond the initial fixed cost of
validating the deployment on existing hardware.</p>

<p>The next major issue is that some application areas have more stringent
standards in terms of reproducibility and auditability. Suppose that a neural
network is used in a self-driving car that gets in an accident. For auditing
purposes, it is important to be able to replay the decisions made by the car’s
control system exactly. In the best case, this requires a significant
engineering effort to keep track of all of the driver versions and internal
testing to verify reproducibility for any deployment.</p>

<p>The final issue is that while classification and detection are not particularly
sensitive to small changes in output, the lack of determinism makes it more
challenging to deploy neural network models which are deeper or more sensitive to
changes.  For instance, imagine a language model that is unrolled over many
iterations to parse or generate a sentence. In that case, accumulating errors
could cause unexpected results.</p>



<p>In the past couple years, there has been an explosion of experimentation in
neural network deployment from software frameworks to hardware
accelerators.  As the field matures, questions about best practices will slowly
be answered. The ability to <em>train once, deploy anywhere</em> will become easier
and easier. In the particular case of determinism, the most reasonable next
step is to have a driver test that ensures determinism and publish a list of
vendors that implement a deterministic API.</p>

<p>The question of determinism is only one small part of the puzzle of being able
to deploy anywhere. Another subtle but important issue is that different
operations will run faster on different hardware. Even if a network can deploy
anywhere in a reproducible manner, an even more fundamental issue is whether
or not a network will be fast and power efficient on any platform. Indeed, while there
has been a great amount of progress in the field of neural network
deployment, there is much to be done to make the ecosystem easier to use and
more mature.</p>

<p>If you are interested in learning more about issues surrounding neural network
deployment or how to be a better machine learning engineer,
connect with me on <a href="https://www.linkedin.com/in/alexanderganderson/">LinkedIn</a> to see my future <a href="http://alexanderganderson.github.io/blog">blog</a> posts!  If you think that I
can help you grow professionally, check out my <a href="http://alexanderganderson.github.io/coaching">coaching</a> page.</p>

<!-- [zero exactly representable] -->

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>http://alexanderganderson.github.io/engineering/2021/01/23/integer_indeterminism.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25885524</guid>
            <pubDate>Sat, 23 Jan 2021 19:58:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WhatsApp facing up to €50M privacy fine]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25885492">thread link</a>) | @JumpCrisscross
<br/>
January 23, 2021 | https://www.politico.eu/article/whatsapp-privacy-fine-data-protection-europe-50-million/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/whatsapp-privacy-fine-data-protection-europe-50-million/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									<p>Facebook-owned messaging app WhatsApp could be fined up to €50 million over violations of the European Union's data protection rules, according to three people with direct knowledge of the procedure who spoke with POLITICO.</p>
<p>The preliminary penalty — the figure is now under consultation with the bloc's other data protection agencies — would be one of the largest-ever fines under the EU's General Data Protection Regulation, a set of privacy rules that came into force in 2018. </p>
<p>As part of Ireland's draft findings, the internet messenger may face a fine of between €30 million and €50 million for not living up to transparency requirements under Europe's privacy regime. Whatsapp could also be required to change how it handles its users' data, as the case relates to how the messenger may have failed to properly inform its EU users about how it would share their data with Facebook.</p>

<p>France's privacy authority <a href="https://www.cnil.fr/en/cnils-restricted-committee-imposes-financial-penalty-50-million-euros-against-google-llc" target="_blank">has fined</a> Google €50 million for separate privacy violations, while Ireland's Data Protection Commission, which has regulatory authority over Facebook, recently <a href="https://www.politico.eu/article/irish-data-regulator-fines-twitter-e450000/">issued</a> a €450,000 penalty against Twitter. That represented its first levy against any Silicon Valley company, many of which fall under Dublin's jurisdiction because these firms are legally domiciled in Ireland, mostly for tax reasons.</p>
<p>The multi-million euro draft WhatsApp fine is an initial proposal from Dublin, and has been opened up to other European data protection agencies for their feedback. A final decision on how big the fine should be — and what other remedies WhatsApp should agree to — is not expected until later in the year.</p>
<p>A spokesman for Ireland's Data Protection Commissioner declined to comment. A spokesman for WhatsApp said the company was awaiting the final privacy decision.</p>
<p>In November, Facebook&nbsp;<a href="https://www.politico.eu/?p=1521035">earmarked €77.5 million&nbsp;for a likely privacy fine against its messaging service WhatsApp,&nbsp;</a>which, unlike Instagram, is a separate legal entity in Ireland and therefore has its own set of financial records. The Irish data protection agency is conducting a separate investigation into whether WhatsApp can legally share its users' data with Facebook's other digital services, among other privacy-related concerns.</p>
<p>The draft penalty against WhatsApp, which Ireland <a href="https://www.politico.eu/?p=1577539">submitted</a> to other EU agencies for review just before Christmas, comes as the messenger faces a global backlash over planned updates to its terms and conditions. Those include&nbsp;clarifying to its billions of users how their data is shared more widely with Facebook's other services.</p>
<p>Those changes will not affect WhatsApp European operations, but people across the bloc and elsewhere still have flocked to rivals like Signal because of privacy fears. On January 15, the messenger <a href="https://blog.whatsapp.com/giving-more-time-for-our-recent-update" target="_blank">said</a> it was delaying the upcoming privacy changes, in part because of the confusion generated by the proposed overhaul.</p>

<p>Johannes Caspar, Hamburg's privacy regulator who filed objections to a previous Irish decision against Twitter, told POLITICO earlier this week that he<a href="https://www.politico.eu/?p=1579886"> had not ruled out </a>doing the same in the WhatsApp case. </p>
<p>"WhatsApp has an enormous amount of users," he said. "It must be clear that the consent mechanism they use must be lawful and that consent is informed and freely given by the users."</p>
								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/whatsapp-privacy-fine-data-protection-europe-50-million/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25885492</guid>
            <pubDate>Sat, 23 Jan 2021 19:54:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quite the ReMarkable Device]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25885456">thread link</a>) | @figbert
<br/>
January 23, 2021 | https://figbert.com/posts/remarkable-tablet/ | <a href="https://web.archive.org/web/*/https://figbert.com/posts/remarkable-tablet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Lately, there’s been renewed interest in clean, simple technology
built to help us focus. Protocols like <a rel="noopener nofollow noreferrer" target="_blank" href="https://gemini.circumlunar.space/">Gemini</a> strip away
the chaos of the web. Hardware hackers fit screens in
<a rel="noopener nofollow noreferrer" target="_blank" href="https://onezero.medium.com/smarter-mirrors-and-how-theyre-made-327997b9eff7">mirrors</a> and build beautiful minimalist displays to
<a rel="noopener nofollow noreferrer" target="_blank" href="https://onezero.medium.com/the-morning-paper-revisited-35b407822494">read the news</a>, display data neatly in a <a rel="noopener nofollow noreferrer" target="_blank" href="https://onezero.medium.com/meet-accent-352cfa95813a">picture
frame</a>, or provide a <a rel="noopener nofollow noreferrer" target="_blank" href="https://healeycodes.com/hacking-together-an-e-ink-dashboard/">daily summary</a>. Hidden amongst
these many awesome projects is the <a rel="noopener nofollow noreferrer" target="_blank" href="https://remarkable.com/">reMarkable 2</a>.</p>
<p>I’ve been using the reMarkable for the past month or so and it is a
seriously solid device. I use it mainly to take notes, at which it
excels. The e-ink display is the best I have ever seen, barely ever
refreshing the entire screen and almost entirely without the temporary
artifacts that plague similar devices. The pencil is comfortable to
use – slightly fuzzy – and, interestingly, entirely passive: it never
needs to charge. Given that it’s meant to replace your paper, it
shouldn’t be too surprising that the tablet’s also incredibly thin.</p>
<h2 id="cornellnotes"><a href="#cornellnotes" aria-label="Anchor link for: cornellnotes">##
</a>
cornellNotes</h2>
<p>In one of my classes, I’m required to take Cornell notes. On what may
be a related note, it’s a terrible class. Regardless, I need to get an
A and so notes I shall take. The reMarkable comes with a built-in
Cornell notes template. It’s slightly different than the format I’m
used to, but it fits the bill well enough.</p>
<p>It’s hard to describe the experience of using the device. I would
say that it feels shockingly natural. Using it to take notes feels
like writing on a clipboard with none of the usual annoyances – the
paper sliding, having finite pages; and all the benefits of a digital
device – sending files via email, OCR, a select-and-drag tool, etc.
It’s convenient, feels nice, and performs well. Most importantly, it
makes me <em>excited</em> to use it every time I turn it on.</p>
<h2 id="worksheet"><a href="#worksheet" aria-label="Anchor link for: worksheet">##
</a>
workSheet</h2>
<p>In another class, the instructor distributes worksheets every once in
a while to complete during class. Now that we’re in distance learning
due to COVID, these are <code>pdf</code>s – perfect for use with the reMarkable.</p>
<p>I download them onto my laptop, upload them through the app, and
voila. Look Mom, no scratch paper! I can write directly on the
worksheet. I’ve only started doing it this week, and it’s amazing.
Sure, there are programs on the computer that allow you to write
on a <code>pdf</code>, but doing math with a trackpad sounds like torture. With
the reMarkable, it’s enjoyable.</p>
<p>That’s the device’s biggest impact. I used to hate writing by hand.
I would beg my teachers to let me type assignments so I didn’t have
to use a pencil – what am I, a caveman? Now, my paper has superpowers.</p>
<h2 id="notkindle"><a href="#notkindle" aria-label="Anchor link for: notkindle">##
</a>
notKindle</h2>
<p>It’s also a suprisingly good reading device, with native support for
<code>epub</code>s and <code>pdf</code>s. It doesn’t have a backlight, but to be fair
neither do actual books so I’m not too bothered. The default font size
is quite large, and the UI is really minimal which makes for peaceful,
undistracted reading. I own two Kindles already, but I’ve taken to
using the reMarkable instead for a number of reasons:</p>
<ol>
<li>There’s no ads or tracking. On Kindle there’s an ad on the bottom
of the homescreen, which expands to the whole screen when you turn it
off – plus it sends every move you make to live forever with Big Papa
Bezos. Not so with the reMarkable.</li>
<li>The screen on the reMarkable is physically larger. Though sometimes
the compact size of my Kindle comes in handy, like when traveling,
having a nice big display is definitely an advantage. My Kindle is
closer to a large phone, and the reMarkable is definitely a tablet.</li>
<li>The reMarkable is a fairly open device. The Kindle, on the other
hand, is locked down and dripping with DRM (fairly easy to break but
still an encumberance).</li>
</ol>
<p>The developers have also made a browser extension for Chromium-based
browsers called <a rel="noopener nofollow noreferrer" target="_blank" href="https://chrome.google.com/webstore/detail/read-on-remarkable/bfhkfdnddlhfippjbflipboognpdpoeh">Read on reMarkable</a>, which I would love to see
the insides of but is unfortunately closed-source. Basically, it takes
any webpage, turns it into an <code>epub</code>, and sends it off to your device.
I love it and use it near constantly: whenever I run into anything on
HN that is either really long, or I just want to save for later, I
hit a button and it sends it to the tablet. Again, just incredibly
convenient.</p>
<h2 id="jailbreak"><a href="#jailbreak" aria-label="Anchor link for: jailbreak">##
</a>
jailBreak</h2>
<p>This section is titled “jailbreak,” which is actually a bit of
misnomer because the reMarkable runs Linux and you can <code>ssh</code> into it
with ease. It’s also not too fitting because I’m not just going to
talk about modifying the device, but also about official accessories.
My device came with a <a rel="noopener nofollow noreferrer" target="_blank" href="https://remarkable.com/store/remarkable-2/folios">Book Folio</a> and <a rel="noopener nofollow noreferrer" target="_blank" href="https://remarkable.com/store/remarkable-2/markers">Marker</a> in the
box, which is pretty good value. I did find out while writing this
that they offer a “Marker Plus” that comes with a built-in eraser. It
is, unfortunately, out of stock currently but I plan on buying it once
it returns in “January 2021,” so supposedly sometime in the next week
or so.</p>
<p>Ok now time for the jailbreak-y stuff. There’s an active community on
Freenode, an unofficial <a rel="noopener nofollow noreferrer" target="_blank" href="https://remarkablewiki.com/">wiki</a>, and an <a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/reHackable/awesome-reMarkable">Awesome list</a>.
All of these are really great resources for cool stuff you can do with
your device, and I’m planning to begin experimenting with them in the
coming weeks. My first goal is to get <a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/koreader/koreader">KOReader</a> running so I
can sync my extensive Calibre library to the device. I’m going to
avoid adding any <a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/reHackable/awesome-reMarkable#games">games</a> so as not to add additional complexity
to a device that aims to remove distractions, and proceed slowly so I
don’t brick my fancy new toy. Stick around to see how that goes.</p>
<h2 id="ps"><a href="#ps" aria-label="Anchor link for: ps">##
</a>
pS</h2>
<p>The recently published fairly viral <a rel="noopener nofollow noreferrer" target="_blank" href="https://surma.dev/things/ditherpunk/index.html">Ditherpunk article</a>
by <a rel="noopener nofollow noreferrer" target="_blank" href="https://surma.dev/">Surma</a> gives a really interesting overview of image
dithering. After reading the article, I noticed that the reMarkable
itself uses dithering to “fade off” your writing and make it look
like pencil. Neat.</p>
<p>Also, comparing the reMarkable to the Kindle makes me want to
jailbreak that too – I’ll find some time to look into that soon.</p>
</div></div>]]>
            </description>
            <link>https://figbert.com/posts/remarkable-tablet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25885456</guid>
            <pubDate>Sat, 23 Jan 2021 19:50:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DrScheme in Space]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25885430">thread link</a>) | @azhenley
<br/>
January 23, 2021 | https://parentheticallyspeaking.org/articles/drscheme-in-space/ | <a href="https://web.archive.org/web/*/https://parentheticallyspeaking.org/articles/drscheme-in-space/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>This was initially written for my regular column in the
Brown Computer Science departmental magazine, <span>conduit!</span>,
for the
<a href="https://cs.brown.edu/about/conduit/conduit_v12n2.pdf">Fall 2003
issue</a>. I think it’s far too much fun to leave hidden in such an obscure place.
The prose is unchanged since then (so some of the classification information
may well be incorrect); only the marginal notes are new.</span></p><p>The sender’s name was in all-upper-case, and the subject
line read, “Not exactly...”.</p><p>Spam.</p><p>But I’m glad I opened it anyway. “This is not exactly your
normal query...”, the message
body began. It was from an upstanding citizen at the NASA
Johnson Space Center, asking
for... the Export Control Classification Number (ECCN) for
DrScheme<span><span><span>Now <a href="https://www.drracket.org/">DrRacket</a>.</span></span></span>, a Scheme programming environment I
helped develop.</p><p>The what for what?!?</p><p>It transpires that a tasteful astronaut (name withheld to protect the innocent) had loaded
DrScheme on his laptop for use during his free
time in space.<span><span><span>Turns out he was working through <span><a href="https://htdp.org/">How to Design Programs</a></span>.</span></span></span>
He was (a) going to be on the International Space Station (ISS) and (b) launching a
hard drive image from Russia. The ISS is a multinational enterprise and Russia is, well, another
country, so the act of sending software in both instances involves an export. Both, consequently,
need an ECCN. (I wonder if there is some tacit assumption here that outer space, or at least the ISS,
is a foreign land. I wonder if there isn’t some
group squirreled away trying to determine the
equivalent of nautical limits in space.)</p><p>The US government does a remarkably good job
of publishing documents on the Web; anyone
who’s had to deal with the IRS or the lucky few
who’ve had to contend with the INS will grudgingly admit this. These are sometimes no more
than OCR-scanned copies, but the scanning yields
enough clarity that Google can find the documents. I can’t begin to imagine what this process
must have been like ten years ago. (Probably a lot
simpler: I’d have written off for an official document, then returned to my regularly scheduled
work.)</p><p>Anyway, accessing prose is not the same as understanding it. The second paragraph of the first document I read began “The CCL is contained in
Supplement No. 1 to part 774 of the EAR.”</p><p>It was going to be that kind of day.</p><p>I have some layman’s thoughts about such prose.
It doesn’t look like natural language at all. I conjecture it’s because natural language is rife with
anaphoric references. Letting context and a rich
language of reference “do the talking” leads to
higher communication bandwidth, but it’s hell on
disjointed documents.... But this is beginning to
read like one of Eugene’s<span><span><span>That would be natural-language processing maestro
<a href="https://en.wikipedia.org/wiki/Eugene_Charniak">Eugene Charniak</a>, who had a regular column in <span>conduit!</span> that was
the inspiration for mine.</span></span></span> articles, so I should stop
this digression now.</p><p>The ECCN system is quite simple once you get
the hang of it. Numerous artifacts, from nuclear to
software, are given codes such as 14D993. These
codes determine the range of permitted distribution and the licensing demands on those who wish
to acquire them. Everything else is assigned the
default code EAR99, sometimes designated NLR
(No License Required). So it’s simply a matter of
reading enough documentation, slotting your
product, and finding a code. This is a bit like saying that feeding your pet octopus is simply a matter of pulling aside the arms, placing the food in
the middle, then retracting your limb. Easily done,
but you may lose an organ or two getting the hang
of it.</p><p>Reading these documents was not without its rewards. I discovered, for instance, that EAR 740.13
(d) (3) (ii) (A) differs from EAR 774 Supplement
No. 2 (2) (a), though they describe the same thing.
The former document is dated later, yet leaves out
a key provision included in the latter, the recognition that software may be sold electronically! Better still, I found that ECCN category 14D993
specifically restricts the export of “program”
proof and validation “software” using mathematical and analytical techniques and designed or
modified for “programs” having more than
500,000 “source code” instructions. Beware, all
you verification researchers—don’t get too ambitious!</p><p>Having done my research, I determined that we
fall under License Exception TSU (Technology
and Software — Unrestricted), though it all gets a
bit sketchy here because our software is not specifically sold. (The concept of free software
doesn’t seem to be in the ECCN vocabulary.
Cheap political crack omitted here.) This didn’t
necessarily mean we were EAR99, and EAR99 is
an ECCN, whereas TSU isn’t, and NASA had
asked for an ECCN. Mustering great courage, I
called the encouragingly named Outeach and Educational Services Division of the US Commerce
Department. After only a few minutes, I was connected to a gruff counselor.</p><p>“Can I help you?”</p><p>“Ah, yes, I was hoping to get a quick clarification
on an ECCN classification.”</p><p>(gruffer still) “Yes?”</p><p>(deep breath) “If I find that my product falls under
License Exception TSU under part 774 of the
EAR, can I assume it has the ECCN of EAR99?”</p><p>I believe I did this without inhaling.</p><p>These are the moments that test the mettle of great
men. Like Major Major’s father, my counselor
was made of stern stuff. He paused for just a moment, just long enough to
accord respect to someone he clearly perceived to be a fellow numbers-and-policy wonk. And then, in a voice rich in
cameraderie, he said, “You know, I’ve been trying
to determine that for five years myself!”</p><p>Being excepted from a license was not the same as
not requiring a license? In the logic of the US government, did the Law of the Excluded Middle not
apply? What was the difference between the two?</p><p>Syria.</p><p>No, seriously. The difference really is Syria. TSU
permits export to Syria, but EAR99 does not.</p><p>My counselor told me this with glee. Apparently I
had hit on one of his favorite trivia questions, because, now really warming to the topic, he informed me that he had asked this very question of
many of his colleagues. Some had incorrectly
identified the two; others, quicker on the draw,
had said that they were indeed different but had
recommended the use of ECCN 4D994. As everyone knows — shucks, by this point even I knew —
this was a contemptible response, because 4D994
permits the export of only specific software products. And so on.</p><p>Anyway, this story has a happy ending. We appear
to meet EAR99. NASA Johnson has acknowledged receipt of our ECCN. I’ve been in touch
with the fine astronaut. DrScheme will soon be
happily beta-v-cs-reducing expressions in outer
space.</p><p>Where has your programming language been today?</p></div></div></div>]]>
            </description>
            <link>https://parentheticallyspeaking.org/articles/drscheme-in-space/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25885430</guid>
            <pubDate>Sat, 23 Jan 2021 19:47:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Fast, turnkey static web site recipe (Terraform and Jekyll and AWS)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25885413">thread link</a>) | @happythenewsad
<br/>
January 23, 2021 | https://peterkong.com/2020/12/16/the-new-static-web-stack-made-easy-terraform.html | <a href="https://web.archive.org/web/*/https://peterkong.com/2020/12/16/the-new-static-web-stack-made-easy-terraform.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
  
  <p><time datetime="2020-12-16T00:00:00-07:00" itemprop="datePublished">16 Dec 2020</time><span> • </span>
      
        </p>

  <h2 id="tldr">TL;DR</h2>
<p>Terraform is great; I provide a Terraform recipe that’s easy to get started with, along with some things I learned along the way.</p>

<h2 id="intended-audience">Intended Audience</h2>
<p>Software developers who are interested in trying out Terraform to manage cloud infrastructure.</p>

<h2 id="motivation">Motivation</h2>
<p>Until recently, my old web property languished on a past end-of-life Rails Heroku stack. It was slow to build and served over plain HTTP. Time for an upgrade.</p>

<p>I taught myself Terraform (and Jekyll) by migrating to this new stack. I’m convinced it’s an ideal configuration for modern static sites: S3-backed CloudFront offers blazing fast page loads, SSL/TLS configuration is one-and-done, and your cloud architecture is expressed in code, so you never need click through tedious AWS interfaces trying to remember how you configured a firewall setting or bucket rule. And you have complete control over every part of your stack.</p>

<p>I’ve captured my learnings in two public repos: <a href="https://github.com/happythenewsad/terraform-static-site">terraform-static-site</a> and <a href="https://github.com/happythenewsad/jekyll_pkcom">jekyll-pkcom</a></p>

<p>Feel free to start there. The rest of this post will cover some more detailed thoughts and observations on working with Terraform. Code snippets reference <a href="https://github.com/happythenewsad/terraform-static-site">terraform-static-site</a>.</p>

<h2 id="terraforms-tactical-merits">Terraform’s tactical merits</h2>
<p>Terraform expresses cloud infrastructure (i.e. servers, load balancers, datastores, permissions) in code. This is super great because non-trivial cloud configurations become complex very quickly.</p>

<p>Cloud providers (e.g. AWS, Azure) provide browser UIs out of the box for managing infrastructure. These can be helpful when starting out, but quickly become cumbersome.</p>

<p>Here are a few scenarios that illustrate problems I have encountered with cloud infrastructure management before Terraform:</p>

<ul>
  <li>
    <p>A teammate changes a firewall rule, cutting communication between a load balancer and a server. Identifying the root cause takes minutes rather than seconds, because infrastructure configurations are not versioned in a central place. After identifying the bad firewall rule, uncertainty lingers - have other misconfigurations occurred which may also be impacting production?</p>
  </li>
  <li>
    <p>You want to set up a new CDN distribution that reads from various S3 buckets. To do this, you need to copy and paste a list of S3 bucket names into an AWS web form to tell the new CDN distribution where to read from.</p>
  </li>
</ul>

<p>Terraform solves issues like these by deploying your cloud infrastucture from a versioned template files. Terraform deployments are idempotent, so existing architecture is preserved if it reflects what’s in your Terraform specification.</p>

<h2 id="notes-and-learnings">Notes and learnings</h2>

<p>The official Terraform <a href="https://www.terraform.io/docs/configuration/index.html">documentation</a> is indispensable and generally quite good, but it can be overwhelming when starting out.</p>

<p>I found it helpful to start with a minimal working Terraform configuration (say, a single <code>.tf</code> file that deploys a bare EC2 instance), and extend iteratively.</p>

<p>Let’s look at <a href="https://github.com/happythenewsad/terraform-static-site">terraform-static-site</a>: it has a single Terraform directory, <code>s3</code>, with just 3 files inside. Yep, that’s all you need. Like Git, Terraform only cares about the directory you tell it to care about. If you run <code>cd s3 &amp;&amp; terraform init .</code>, Terraform will start managing artifacts within <code>s3/</code>, and only <code>s3/</code>. Terraform can manage multiple directories through Terraform modules, but those are out of the scope of this minimal example.</p>

<p><code>s3.tf</code>:</p>

<div><div><pre><code>terraform {
	...
} 
provider "aws" {
	...
}

resource "aws_s3_bucket" "pkcom" {
	...
}

resource "aws_cloudfront_distribution" "pkcomCFDistro"{
	...
}
</code></pre></div></div>

<p>There’s some boilerplate, specifying AWS as our cloud provider, then just two resources: an S3 bucket and a CloudFront distribution. Sadly, Terraform <a href="https://github.com/hashicorp/terraform/issues/571">does not currently support</a> dynamic names, so you’ll have to change “pkcom” and “pkcomCFDistro” to something relevant to you.</p>

<p>That’s it: get used to resource blocks; they’re Terraform’s bread and butter. Resources are tied to a specific cloud provider, so if you’re not using AWS, you’ll need to use Azure resource blocks, for example, which will have configuration options that differ from AWS.</p>

<p>You could populate <code>s3.tf</code> with hard-coded variables, like S3 bucket names, but it’s best to think of your main <code>.tf</code> file as a template, and store variables separately. Let’s check out <code>variables.tf</code>:</p>

<div><div><pre><code>variable "region" {
  default = "us-west-2"
}

variable "property" {
}

variable "bucketName" {
}
...
</code></pre></div></div>

<p>This is how you declare variables in Terraform. I’ve abstracted the <em>values</em> of the variables into <code>terraform.tfvars</code>. This is a way to keep secret values out of version control, but it’s not required.</p>

<p>When you run <code>terraform apply</code>, the Terraform CLI will automatically inject variables into your template file(s).</p>

<p>That’s it! Once you’ve populated <code>terraform.tfvars</code> with your specific values, you can deploy with <code>terraform apply</code>.</p>

<h3 id="http-or-https">http or https?</h3>

<p>It’s easy to misconfigure the connection between S3 and and CloudFront. After trial and error I found that it’s best to have CloudFront fetch S3 objects over http, but accept only https requests:</p>

<div><div><pre><code>origin_protocol_policy = "http-only"
...
viewer_protocol_policy = "redirect-to-https"
</code></pre></div></div>

<p>Some recipes will specify</p>

<div><div><pre><code>origin_protocol_policy = "match-viewer"`
</code></pre></div></div>

<p>which causes CloudFront to raise HTTP 504 errors in my experience. In general, it’s handy to enable an S3 logging bucket when debugging S3 &lt;-&gt; CloudFront issues.</p>

<h3 id="custom-domain--cert">custom domain / cert</h3>
<p><a href="https://github.com/happythenewsad/terraform-static-site">terraform-static-site</a> is configured to use a custom domain, so your web property can be accessed via a normal domain instead of xyz.cloudfront.net. Doing this in AWS requires a custom SSL/TLS cert. You need out-of-band approval for a cert. Log into the <a href="https://console.aws.amazon.com/acm">AWS Certificate Manager</a> to create one, then add its ARN in <code>terraform.tvars</code>. If you prefer to host domains outside of AWS’s Route53 service like I do, you’ll also need to follow <a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/CNAMEs.html">this CNAMEing procedure</a>. Verifying ownership of your domain is easy, but manual and out-of-band. It took about 10 minutes for AWS to recognize ownership for my domain after I updated CNAME records through my 3rd party DNS service.</p>

<h3 id="503-gotcha">503 gotcha</h3>
<p>If you’re getting 503’s from CloudFront, it may be because you need a <code>custom_origin_config</code> within your <code>aws_cloudfront_distribution</code> resource block. Luckily, <a href="https://github.com/happythenewsad/terraform-static-site">terraform-static-site</a>’s configuration should work out of the box.</p>

<p>And if you have any feedback or suggestions, please add an issue or open a PR on the <a href="https://github.com/happythenewsad/terraform-static-site">Github repo!</a></p>

<p>* Terraform supports most cloud providers; this post uses AWS.</p>


  
</article>






      </div></div>]]>
            </description>
            <link>https://peterkong.com/2020/12/16/the-new-static-web-stack-made-easy-terraform.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25885413</guid>
            <pubDate>Sat, 23 Jan 2021 19:45:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hush: Noiseless Browsing for Safari]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25885409">thread link</a>) | @robenkleene
<br/>
January 23, 2021 | https://oblador.github.io/hush/ | <a href="https://web.archive.org/web/*/https://oblador.github.io/hush/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      

      <h2>Noiseless Browsing</h2>
      <h3>by <a href="https://oblador.se/">Joel Arvidsson</a></h3>
      <p>Block nags to accept cookies and privacy  invasive tracking in Safari on Mac, iPhone and iPad.</p>

      <figure>
        <blockquote cite="https://daringfireball.net/linked/2021/01/23/hush">
          <p>“I’d recommend Hush to anyone who uses Safari”</p>
        </blockquote>
        <figcaption>— John Gruber, <cite><a href="https://daringfireball.net/linked/2021/01/23/hush">Daring Fireball</a></cite></figcaption>
      </figure>

      

      

    </div>
    <div>
      <div>
        
        
        
        
        
        

        
        
        
        
        
        <div>
          <p>
              This website is using cookies, read more in our <a href="#">privacy policy</a> that is too long and complicated for most to comprehend.
            </p>
        </div>
        <div>
          <div>
            <h3>We care about your privacy</h3>
            <p>
              Not really though. That's why we made the process of opting out really difficult because we know nobody would opt in otherwise.
            </p>
            
          </div>
        </div>
        <div>
          <div>
            <p>
              www.everywebsite.ever wants to annoy even after you leave by sending push notifications.
            </p>
            
          </div>
        </div>
        <div>
          <div>
            <h3>Sign up for our newsletter</h3>
            <p>
              You seem like the type that what to have spam sent to you on a regular basis, so we'll make sure to sell your address on to others.
            </p>
            
          </div>
        </div>
      </div>
    </div>
  </div>

  <div>
    <div>
      <svg width="193" height="150" xmlns="http://www.w3.org/2000/svg"><g fill="#000" fill-rule="nonzero"><path d="M147.995 79.92c-16.872.05-31.309 12.127-34.338 28.725a57.364 57.364 0 00-33.75 0c-3.278-17.949-19.804-30.36-37.955-28.507C23.8 81.993 10.126 97.49 10.545 115.731c.42 18.24 14.792 33.093 33.01 34.111 18.216 1.018 34.154-12.14 36.604-30.22a46.977 46.977 0 0133.35 0c2.554 18.508 19.222 31.73 37.826 30.004 18.604-1.725 32.556-17.787 31.662-36.45-.894-18.662-16.318-33.316-35.002-33.256zM45.463 139.283c-13.37.023-24.275-10.703-24.474-24.07-.2-13.368 10.38-24.414 23.744-24.79 13.364-.376 24.549 10.058 25.101 23.416a5.152 5.152 0 00-.147 3.995c-1.516 12.233-11.898 21.426-24.224 21.449zm102.532 0c-12.326-.023-22.708-9.216-24.224-21.449a5.152 5.152 0 00-.147-3.995c.563-13.34 11.739-23.753 25.085-23.374 13.347.38 23.913 11.41 23.718 24.761-.196 13.35-11.08 24.068-24.432 24.057zM187.507 51.133h-15.35l-9.694-34.717C159.876 7.164 151.213.203 142.297.203H51.16c-8.916 0-17.58 6.96-20.166 16.213l-9.694 34.717H5.951a5.257 5.257 0 100 10.514h181.556a5.257 5.257 0 000-10.514zm-155.271 0l8.895-31.9c1.283-4.626 5.888-8.516 10.03-8.516h91.136c4.205 0 8.747 3.89 10.03 8.517l8.895 31.9H32.236z"></path></g></svg>
      <h2>Private</h2>
      <p>Unlike some blockers, Hush has absolutely no access to your browser habits or passwords. Nor does it track behavior or collect crash reports - <strong>nothing leaves your device</strong>.</p>
    </div>
    <div>
      <svg width="146" height="146" xmlns="http://www.w3.org/2000/svg"><g fill="#000" fill-rule="nonzero"><path d="M78.619 68.804h-1.227v-22.85h1.227c5.06 0 9.507 3.374 10.887 8.435.614 2.3 3.068 3.68 5.368 3.067 2.3-.613 3.68-3.067 3.067-5.367-2.3-8.741-10.275-14.722-19.322-14.722h-1.227V25.099c0-2.454-1.994-4.294-4.294-4.294-2.454 0-4.294 1.993-4.294 4.294v12.268h-1.227a19.955 19.955 0 00-14.108 5.827c-3.834 3.834-5.828 8.741-5.828 14.109 0 11.04 9.048 20.089 20.09 20.089h1.226v22.696h-1.226c-5.061 0-9.508-3.374-10.888-8.128-.46-1.993-2.147-3.527-4.294-3.527-2.454 0-4.294 1.994-4.294 4.294 0 .46 0 .767.153 1.227 2.454 8.74 10.275 14.722 19.323 14.722h1.226v12.268c0 2.453 1.994 4.294 4.294 4.294 2.454 0 4.294-1.994 4.294-4.294v-12.268h1.227c11.041 0 20.089-9.048 20.089-20.09a19.955 19.955 0 00-5.827-14.108c-3.988-3.68-9.048-5.674-14.415-5.674zm-11.042 0A11.322 11.322 0 0156.23 57.456c0-3.067 1.227-5.98 3.22-7.974 2.147-2.147 5.061-3.374 7.975-3.374h1.227v22.696h-1.074zm11.042 31.437h-1.227v-22.85h1.227c3.067 0 5.827 1.228 7.974 3.374 2.147 2.147 3.22 4.908 3.22 7.975.154 6.287-4.907 11.501-11.194 11.501z"></path><path d="M73.098.256C32.92.256.256 32.92.256 73.098S32.92 145.94 73.098 145.94s72.842-32.664 72.842-72.842S113.276.256 73.098.256zM8.997 73.098c0-16.102 5.98-30.824 15.948-42.172l10.888 10.888c.92.92 1.994 1.227 3.067 1.227 1.074 0 2.147-.46 3.067-1.227a4.35 4.35 0 000-6.134L31.08 24.792C42.427 14.977 57.15 8.843 73.251 8.843c35.425 0 64.101 28.83 64.101 64.101 0 16.102-5.98 30.824-15.948 42.172l-10.888-10.888a4.35 4.35 0 00-6.134 0 4.35 4.35 0 000 6.134l10.888 10.888C103.922 131.065 89.2 137.2 73.098 137.2c-35.425 0-64.101-28.677-64.101-64.101z"></path></g></svg>
      <h2>Free</h2>
      <p>Everything is <strong>free of charge</strong>. Forever. No in-app purchases, no nonsense. However, <a href="https://github.com/sponsors/oblador">any help</a> towards covering the yearly Apple Developer fee is greatly appreciated.</p>
    </div>
    <div>
      <svg width="188" height="150" xmlns="http://www.w3.org/2000/svg"><g fill="#000" fill-rule="nonzero"><path d="M176.072 100.93H73.012c-3.96 0-3.96 8.788 0 8.788h103.06c3.96-.003 3.96-8.787 0-8.787zM184.192 75.903H88.895c-3.803 0-3.803 8.452 0 8.452h95.297c3.8 0 3.8-8.452 0-8.452zM165.075 51.132H62.01c-3.958 0-3.958 8.784 0 8.784h103.064c3.957.005 3.957-8.784 0-8.784z"></path><path d="M64.837 149.26c-21.32 0-38.667-17.346-38.667-38.666 0-1.216.125-2.293.283-3.272C11.083 102.03.39 87.409.39 70.759c0-21.324 17.346-38.669 38.669-38.669 1.23 0 2.46.055 3.684.173C45.58 13.84 61.218.162 80.654.162c18.29 0 34.224 12.988 37.881 30.88a4.987 4.987 0 01-3.882 5.879c-2.688.543-5.336-1.187-5.884-3.887-2.712-13.278-14.539-22.91-28.122-22.91-15.93 0-28.408 12.382-28.408 28.19a4.981 4.981 0 01-6.831 4.63l-.982-.393a28.959 28.959 0 00-5.37-.503c-15.83 0-28.705 12.875-28.705 28.709 0 13.687 9.727 25.53 23.132 28.166a4.996 4.996 0 013.444 2.554 5.005 5.005 0 01.177 4.291l-.423.991c-.055.297-.115.59-.17.879-.216 1.12-.388 2.006-.388 2.953 0 15.83 12.875 28.705 28.704 28.705 11.69 0 22.117-6.98 26.567-17.794a4.977 4.977 0 016.499-2.715 4.979 4.979 0 012.712 6.501c-5.977 14.568-20.02 23.972-35.768 23.972z"></path></g></svg>
      <h2>Fast</h2>
      <p>The app is primarily a host of rules that <strong>integrates with Safari in a native, lightweight way</strong>, making the blocking efficient and fast.</p>
    </div>
  </div>

  <div>
    <div>
      <svg width="122" height="100" xmlns="http://www.w3.org/2000/svg"><g fill="#000" fill-rule="nonzero"><path d="M74.723 22.124a19.298 19.298 0 00-13.827 5.822 19.332 19.332 0 10-22.124 30.959v1.936c0 12.218 9.905 22.124 22.124 22.124S83.02 73.059 83.02 60.84v-1.936a19.317 19.317 0 00-8.297-36.781zm4.605 32.33a2.767 2.767 0 00-1.84 2.606v3.78c0 9.165-7.428 16.594-16.592 16.594-9.164 0-16.593-7.43-16.593-16.593V57.06c0-1.17-.737-2.214-1.839-2.606a13.796 13.796 0 1116.128-20.596 2.87 2.87 0 004.608 0 13.806 13.806 0 1116.128 20.596z"></path><path d="M47.069 35.951a5.531 5.531 0 105.53 5.531 5.538 5.538 0 00-5.53-5.53zM74.723 35.951a5.531 5.531 0 105.531 5.531 5.538 5.538 0 00-5.53-5.53zM68.785 61.019a2.756 2.756 0 00-3.563 1.612 4.57 4.57 0 01-4.42 2.65 4.302 4.302 0 01-4.21-2.596 2.767 2.767 0 00-5.219 1.842 9.766 9.766 0 009.37 6.285h.124a9.924 9.924 0 009.53-6.23 2.763 2.763 0 00-1.612-3.563z"></path><path d="M121.737 24.89c-.013-10.687-8.673-19.346-19.359-19.359a19.004 19.004 0 00-11.956 4.238c-17.539-13.033-41.548-13.025-59.078.02a19.127 19.127 0 00-11.93-4.258 19.308 19.308 0 00-7.715 37.029 49.78 49.78 0 1098.394 0 19.275 19.275 0 0011.644-17.67zm-116.15 0c.008-7.634 6.194-13.82 13.827-13.828 2.708.003 5.355.809 7.605 2.316a49.671 49.671 0 00-14.18 23.607A13.751 13.751 0 015.586 24.89zm55.309 69.137c-24.437 0-44.248-19.81-44.248-44.248S36.458 5.53 60.896 5.53c24.437 0 44.248 19.81 44.248 44.248a44.248 44.248 0 01-44.248 44.248zm48.057-57.042a49.673 49.673 0 00-14.205-23.63 13.649 13.649 0 017.63-2.293 13.785 13.785 0 016.575 25.923z"></path></g></svg>
      <h2>Simple</h2>
      <p>It's as easy as downloading the app and enabling it in <em>Safari</em> settings ⭢ <em>Content Blockers</em>. No configuration or maintenance needed.</p>
    </div>
    
    <div>
      <svg width="112" height="100" xmlns="http://www.w3.org/2000/svg"><path d="M102.662 70.352l-.01-.012c.164-.557.333-1.111.477-1.682 6.157-24.48-8.87-53.42-34.3-68.658 11.143 15.075 16.07 33.333 11.693 49.3a41.435 41.435 0 01-1.379 4.12 34.13 34.13 0 00-2.225-1.312S51.622 36.523 24.205 8.958c-.72-.725 14.62 21.876 32.028 40.228C48.032 44.593 25.174 28 10.705 14.784c1.777 2.958 3.892 5.807 6.216 8.55 12.084 15.29 27.842 34.158 46.722 48.646-13.265 8.1-32.009 8.73-50.67.008A76.581 76.581 0 010 64.266c7.9 12.608 20.066 23.487 34.874 29.837 17.66 7.573 35.22 7.06 48.3.124l-.011.015c.06-.037.135-.078.197-.117a41.45 41.45 0 001.592-.891c6.284-3.255 18.696-6.557 25.358 6.378 1.632 3.166 5.099-13.61-7.648-29.26zm-3.877 3.158c3.732 4.581 6.133 9.543 7.327 14.356-2.492-1.427-5.255-2.256-8.217-2.498a23.001 23.001 0 00-2.552-.063l3.43-5.009-14.824 7.86c-.437.204-.87.417-1.297.638l-.13.067-.125.075c-.396.235-.83.477-1.4.783l-.131.07-.02.013-.015.008c-12.072 6.4-28.134 6.495-43.986-.302a71.82 71.82 0 01-15.23-8.915c16.18 4.73 32.232 3.227 44.634-4.346l6.22-3.798-5.782-4.436c-7.946-6.098-15.355-12.888-22.948-20.914 3.998 2.762 7.489 5.015 10.051 6.45l28.74 16.095-20.69-21.812a271.722 271.722 0 007.898 5.553c1.256.849 2.37 1.584 3.332 2.203.588.379 1 .638 1.226.777l.104.065.108.059a29.62 29.62 0 011.895 1.114l5.156 3.378L83.8 55.24a46.296 46.296 0 001.543-4.616c2.69-9.81 2.246-20.484-.937-30.947 12.115 14.279 17.771 32.265 13.873 47.762-.077.307-.154.575-.34 1.202l-.001.005-.083.282-.726 2.462 1.578 2.025.027.032.05.064z" fill="#000" fill-rule="nonzero"></path></svg>
      <h2>Modern</h2>
      <p>Hush is written in Apple's latest programming paradigm Swift UI and has native support for M1 processors.</p>
    </div>
    <div>
      <svg width="102" height="102" xmlns="http://www.w3.org/2000/svg"><g fill="#000" fill-rule="nonzero"><path d="M73.419 25.497L60.84 37.638V30.92a1.994 1.994 0 10-3.989 0v11.968c0 1.101.892 1.995 1.995 1.995H70.13a1.994 1.994 0 100-3.99h-6.922l12.98-12.528a1.992 1.992 0 10-2.769-2.868zM42.888 56.851H31.604a1.994 1.994 0 100 3.99h6.47L25.52 73.392a1.992 1.992 0 001.41 3.405 1.99 1.99 0 001.41-.585l12.553-12.552v7.153a1.994 1.994 0 103.989 0V58.846a1.994 1.994 0 00-1.995-1.995zM63.66 60.84h6.47a1.993 1.993 0 001.994-1.994 1.993 1.993 0 00-1.994-1.995H58.846a1.993 1.993 0 00-1.995 1.995v11.968c0 1.103.892 1.995 1.995 1.995a1.993 1.993 0 001.994-1.995V63.66l12.553 12.552a1.99 1.99 0 002.82 0c.78-.78.78-2.04 0-2.82L63.661 60.84zM42.888 28.926a1.995 1.995 0 00-1.994 1.994v7.153L28.34 25.521c-.78-.78-2.04-.78-2.82 0-.78.78-.78 2.04 0 2.82l12.552 12.553h-6.469a1.995 1.995 0 000 3.989h11.284a1.995 1.995 0 001.995-1.995V30.92a1.995 1.995 0 00-1.995-1.994z"></path><path d="M50.867 1C23.37 1 1 23.37 1 50.867c0 27.497 22.37 49.867 49.867 49.867 27.497 0 49.867-22.37 49.867-49.867C100.734 23.37 78.364 1 50.867 1zm0 95.745c-25.297 0-45.878-20.58-45.878-45.878C4.99 25.57 25.57 4.989 50.867 4.989c25.299 0 45.878 20.581 45.878 45.878 0 25.299-20.58 45.878-45.878 45.878z" stroke="#000"></path></g></svg>
      <h2>Tiny</h2>
      <p>The app download clocks in at less than half a megabyte.</p>
    </div>
  </div>
  
</div></div>]]>
            </description>
            <link>https://oblador.github.io/hush/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25885409</guid>
            <pubDate>Sat, 23 Jan 2021 19:44:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Evaluate “Expert” Scientific Opinions?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25885389">thread link</a>) | @yesperhaps88
<br/>
January 23, 2021 | https://demystifyingscience.com/blog/viral-evolution | <a href="https://web.archive.org/web/*/https://demystifyingscience.com/blog/viral-evolution">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-c850fbf271b4b442b8bf"><div><p>This week, we stumbled across&nbsp;<a href="https://youtu.be/TEb33U0hHxM" target="_blank">a video</a>&nbsp;that outlines a paradigm shift in the way that humans see viruses in the context of germ theory. The traditional explanation of disease is that it’s caused by microbial colonization of a healthy body. The immune system, then, is there to mount a defense against that pathogen. Since their discovery in the early 20th century, viruses have been included in this milieu as just another type of autonomous pathogen.</p><p>More recently, however, both the human microbiome and the human virome have been recognized as foundational elements of our biology. The “-ome” title is given in order to denote a network of interrelated viruses or microorganisms that are associated with the human body. In the case of the&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4919837/" target="_blank">virome</a>, this includes the viruses that target members of the gut microbiota (our intestinal bacteria). Viruses, however, unlike bacteria, archaea, and fungi are not organisms - rather,&nbsp;<a href="https://pubmed.ncbi.nlm.nih.gov/26970895/" target="_blank">they are a process</a>. During the viral process, target-specific, nucleotide-containing vesicles, virions, are secreted by one individual and can be taken up by another.&nbsp;</p><p>The paradigm shift, that the viral program represents a wider communication network between organisms, has seen some press - but like all such shifts, is slow to be accepted. There are even tantalizing clues that viruses may have an evolutionary role that extends beyond mere pathology.&nbsp;</p><p>In this video, Dr. Zach Bush points to this changing pathogenic narrative with enthusiastic certainty... and then adds some other less established assertions. The conversation that follows takes aim at some of these tendentious assertions. More importantly, we demystify Dr. Bush’s presentation, showing both the merits of his theory as well as his use of some rather common epistemological vices.  Let us know your thoughts on social or in the comment section…</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1599965975832_14859"><div><p><strong>AB:&nbsp;</strong>We don’t really make it to the core of the presentation of the video until the very end - that the pathology of COVID-19 is due to the fact that humans live in a particularly toxic environment. This is maybe the strongest piece of his whole argument since there’s ample literature that suggests air pollution plays an important role in the lethality of COVID - as do pre-occurring conditions. [<a href="https://www.sciencedirect.com/science/article/pii/S004896972032221X" target="_blank">1</a>][<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7345938/" target="_blank">2</a>][<a href="https://www.medrxiv.org/content/medrxiv/early/2020/04/27/2020.04.05.20054502.full.pdf" target="_blank">3</a>]</p><p><strong>MD:</strong>&nbsp;Yes, it seems like Dr. Bush is setting out to explain how COVID or pandemics in general are a natural response to a toxic environment. He sees viruses as a whole-species software update. If you get the update, your body will adapt. If you are unable to handle the update, your body self-destructs through widespread inflammatory disease. He presents this “update” notion as a matter of fact, but it’s quite hypothetical since we aren’t aware of any selective advantage of getting infected. It is an interesting theory but his conversion of hypothesis to fact sets off alarms.</p><p><strong>AB:&nbsp;</strong>This sort of certainty is a common feature of scientific presentations - both fringe and mainstream, that leave me uneasy about the reliability of the presenter’s claims. For me, it shifts their presentation into one of belief. Ideally, when someone makes a presentation they’re doing so from the standpoint of possibility, rather than certainty, since the entire enterprise of science is one of “maybe.”&nbsp;</p><p><strong>MD:</strong>&nbsp;For me, the most valuable scholars are the ones that will not make a claim without scaling the uncertainty, either qualitatively or quantitatively.&nbsp;</p><p><strong>AB:&nbsp;</strong>And we see some of those issues here pretty early. He makes the claim that 50% of the human genome is viral, which is, at best, a 5X exaggeration. Then there are some non-specific claims about the fact that viral expression is induced by stress, which has only been shown in the case of herpes simplex, not across the board. Then there’s the nebulous presentation about these pools of pig feces where there’s a lot of “stress” that causes the viruses to jump into the human population.&nbsp;</p><p>None of them would be deal-breakers if presented in an inductive lens. Say, “We know that stress causes flare-ups of the herpes virus, so..” or “a significant amount of the human genome is composed of viral DNA…” It makes it much harder for me to pay attention to the actual content of the presentation since I’m so busy searching PubMed for confirmation of the claims.&nbsp;</p><p><strong>MD:</strong>&nbsp;Right. And I feel like these are very common problems amongst both science popularizers and scientists themselves. They want so badly for their theory to be taken seriously that they’re willing to compromise their presentation’s accuracy. We see this all the time from institutional authorities as well.&nbsp;</p><p>But underneath all the exaggerations and hypotheses converted to “facts,” we have a cool idea; one that’s rapidly gaining mainstream traction. Scientists are starting to realize that viruses aren’t jumping or doing anything active like an organism: they’re a targeted message system. Recall that a virus itself is a process; the physical objects secreted are called “virions” and they are not alive in the canonical sense.</p><p><strong>AB:&nbsp;</strong>The question of viral “aliveness” has come up over and over again in our research on COVID and viruses, in general, these last few months. In order to be a living organism, you’d expect viruses to reproduce independently - but no, they can only do so by forcing a host cell to create them - lending credence to the idea that they’re little more than software.</p><p>That’s probably the biggest gem in this presentation - that viruses are a software program. But I’m not totally sure about the fact that they’re more damaging in the modern-day because we live in some kind of “toxic” world. After all, virions make up the majority of the nucleic acid content in the world. That there weren’t always some that could cause harm to humans just doesn’t scan for me.&nbsp;</p><p><strong>MD:</strong>&nbsp;I’m fairly sure that our industrial world is pumping out toxins on a level that our ancestors never imagined in their worst nightmares, but the link to viral expression or infection-mediated resilience, while interesting, is far from a settled matter. And this is why it’s so important to be transparent when presenting a new idea in science. If you want your idea to be taken seriously, you can’t oversell its merits. At best you can oversell its&nbsp;<em>potential&nbsp;</em>merits.</p><p>When you present a new mechanism in science, also called a theory, you have to be absolutely clear in the set up: here is what&nbsp;<em>is</em>&nbsp;known and apparent, and here is what could hypothetically, if shown to be true, provide for my explanation.</p><p>Honestly, if a presenter does not follow that simple method, it makes a lot of work for readers like us, trying to pluck the gold from the slag. And quite frankly, most scientists won’t have the patience for this at some point, which means that a lot of potentially brilliant leaps get relegated to the back pages.</p><p><strong>AB:&nbsp;&nbsp;</strong>It’s definitely not as sexy, to talk about possibility rather than certainty, or to avoid tendentious claims - those are basically the fritos of the intellectual world. But I think that there’s a lot to be said about the ideas that are produced by the “fringe” actually being useful for all of science. They’re analogous to the potentially pathological software updates that Dr. Bush suggests viruses act like!</p><p>I’d love to see a wider acceptance among audience members for what makes a good presentation - rather than allowing ourselves to be bowled over by big numbers and even bigger claims, I want to see a world where people clamor for a more reasonable, measured approach.&nbsp;</p><p>I have a feeling it would go a long way towards reconciling the fringe with the mainstream.&nbsp;</p></div></div></div>]]>
            </description>
            <link>https://demystifyingscience.com/blog/viral-evolution</link>
            <guid isPermaLink="false">hacker-news-small-sites-25885389</guid>
            <pubDate>Sat, 23 Jan 2021 19:43:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I bought 200 Raspberry Pi Model B’s and I’m going to fix them]]>
            </title>
            <description>
<![CDATA[
Score 387 | Comments 128 (<a href="https://news.ycombinator.com/item?id=25885348">thread link</a>) | @stedaniels
<br/>
January 23, 2021 | https://blog.jmdawson.co.uk/i-bought-200-raspberry-pi-model-bs-and-im-going-to-fix-them-part-1/ | <a href="https://web.archive.org/web/*/https://blog.jmdawson.co.uk/i-bought-200-raspberry-pi-model-bs-and-im-going-to-fix-them-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3571">

	

	<div>
		
<h2>Introduction</h2>



<p>I’m sure some of my followers have seen my recent social media posts regarding the 200+ Raspberry Pi Model B’s I purchased on ebay – if you have not then follow my <a href="https://twitter.com/jmdawson_blog" target="_blank" rel="noreferrer noopener">twitter</a> for sneak peaks and updates!</p>



<div><p>I purchased the job lot of Pi’s for just £61 although there was a catch – they were listed as broken and I believe they are customer returns. They are all Model B’s with with either 256MB or 512MB of RAM and are in various conditions. </p><p>The first step in repairing these is to diagnose the issues, I created some tooling to assist with this which I will cover now.</p></div>



<h2>Pi Diagnostics</h2>



<p>So how do you go around diagnosing 200+ faulty Raspberry Pi’s? Regardless of how clever I get around this its not going to be a fast process but I needed a plan. </p>



<div><p>I will be categorising the Pi’s into two categories those that boot and those that are or appear dead. The “Dead” Pi’s will be revisited at a later date but lets take a look at how I’ve gone about testing the ones that boot up. </p><p>Using a cheap 3.5″ TFT Pi display and a hacky bash script I have created a diagnostic tool that will test the following: </p></div>



<ul><li>USB Ports</li><li>Ethernet</li><li>Display Output</li></ul>



<p>This also gives me an opportunity to test the GPIO to an extent as the display uses the I2C, VCC and GND pins and also gives me a chance to assess the physical condition of the device. </p>



<figure><img data-attachment-id="3573" data-permalink="https://blog.jmdawson.co.uk/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59/" data-orig-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?fit=1920%2C2560&amp;ssl=1" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 8 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1611403391&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.066666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59" data-image-description="" data-medium-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?fit=750%2C1000&amp;ssl=1" loading="lazy" width="1920" height="2560" src="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" data-src="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?fit=750%2C1000&amp;ssl=1" alt="" data-srcset="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?w=1500&amp;ssl=1 1500w" data-sizes="(max-width: 750px) 100vw, 750px" data-old-src="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?fit=750%2C1000&amp;ssl=1" data-lazy-srcset="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?w=1500&amp;ssl=1 1500w" data-lazy-src="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/63309619129__9379d143-f95e-4cd3-9144-77a3d23c7f59-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>So far I am around half way through the diagnostics and 59 of the Pi’s boot and work with minor damage such as snapped SD card slots or physically damaged USB ports.</p>



<p>10 of the Pi’s are fully working although their is no Ethernet – These will not be fixed as such although the Ethernet chip and port will be removed transforming the device into a Model A. </p>



<div><p>A further 4 devices are fully working although the HDMI port doesn’t work, all 4 of these look to have damaged traces on the PCB around the HDMI circuitry – I will not be fixing these although I can make them safe to run headless. </p><p>A further 40 Pi’s are dead although some of them are likely just broken power delivery circuits which should be easy fixes – I will revisit these in the near future. </p><p>Here are the remaining devices that need to be diagnosed: </p></div>



<figure><img data-attachment-id="3575" data-permalink="https://blog.jmdawson.co.uk/img_1456/" data-orig-file="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?fit=1920%2C2560&amp;ssl=1" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 8 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1611407783&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.11111111111111&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1456" data-image-description="" data-medium-file="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?fit=750%2C1000&amp;ssl=1" loading="lazy" width="1920" height="2560" src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" data-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?fit=750%2C1000&amp;ssl=1" alt="" data-srcset="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?w=1500&amp;ssl=1 1500w" data-sizes="(max-width: 750px) 100vw, 750px" data-old-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?fit=750%2C1000&amp;ssl=1" data-lazy-srcset="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?w=1500&amp;ssl=1 1500w" data-lazy-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1456-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<div><p>Over the next few days I will diagnose the remaining devices and add a follow up post that will have a total count of Pi’s in the box and a count of the ones that I believe are repairable. </p></div>



<h2>Repairing the Pi’s</h2>



<p>Although I haven’t finished diagnosing the Pi’s I couldn’t help but repair a few of the easier fixes, lets look at a few repairs I carried out this morning.</p>



<h3>Bent GPIO pins</h3>



<figure><img data-attachment-id="3577" data-permalink="https://blog.jmdawson.co.uk/img_1432/" data-orig-file="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?fit=1920%2C2560&amp;ssl=1" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 8 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1611314976&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;64&quot;,&quot;shutter_speed&quot;:&quot;0.066666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1432" data-image-description="" data-medium-file="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?fit=750%2C1000&amp;ssl=1" loading="lazy" width="1920" height="2560" src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" data-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?fit=750%2C1000&amp;ssl=1" alt="" data-srcset="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?w=1500&amp;ssl=1 1500w" data-sizes="(max-width: 750px) 100vw, 750px" data-old-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?fit=750%2C1000&amp;ssl=1" data-lazy-srcset="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?w=1500&amp;ssl=1 1500w" data-lazy-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1432-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Bent GPIO Pins on one of the damaged Pi’s’</figcaption></figure>



<p>How the hell does this happen?! one of the Pi’s had the GPIO pins swashed flat. I could have replaced the header but as no pins were snapped I carefully straightened them a metal ruler. <br></p>



<figure><img data-attachment-id="3578" data-permalink="https://blog.jmdawson.co.uk/img_1434/" data-orig-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?fit=1920%2C2560&amp;ssl=1" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 8 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1611315440&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;64&quot;,&quot;shutter_speed&quot;:&quot;0.066666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1434" data-image-description="" data-medium-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?fit=750%2C1000&amp;ssl=1" loading="lazy" width="1920" height="2560" src="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" data-src="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?fit=750%2C1000&amp;ssl=1" alt="" data-srcset="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?w=1500&amp;ssl=1 1500w" data-sizes="(max-width: 750px) 100vw, 750px" data-old-src="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?fit=750%2C1000&amp;ssl=1" data-lazy-srcset="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?w=1500&amp;ssl=1 1500w" data-lazy-src="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1434-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Whilst they didn’t come out perfect it is once again a fully working device.</p>



<h3>Broken USB Ports</h3>



<figure><img data-attachment-id="3582" data-permalink="https://blog.jmdawson.co.uk/img_1438/" data-orig-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?fit=1920%2C2560&amp;ssl=1" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 8 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1611331791&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.25&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1438" data-image-description="" data-medium-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?fit=750%2C1000&amp;ssl=1" loading="lazy" width="1920" height="2560" src="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" data-src="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?fit=750%2C1000&amp;ssl=1" alt="" data-srcset="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?w=1500&amp;ssl=1 1500w" data-sizes="(max-width: 750px) 100vw, 750px" data-old-src="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?fit=750%2C1000&amp;ssl=1" data-lazy-srcset="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?w=1500&amp;ssl=1 1500w" data-lazy-src="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1438-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Ok broken is an understatement! This poor Pi has had the ports ripped right off it, fortunately there is plenty dead Pi’s that will not be fixable so rather than buying parts I salvaged the USB ports from a dead Pi. </p>



<figure><img data-attachment-id="3568" data-permalink="https://blog.jmdawson.co.uk/img_1441/" data-orig-file="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?fit=1920%2C2560&amp;ssl=1" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 8 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1611333172&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.2&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1441" data-image-description="" data-medium-file="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?fit=750%2C1000&amp;ssl=1" loading="lazy" width="1920" height="2560" src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" data-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?fit=750%2C1000&amp;ssl=1" alt="" data-srcset="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?w=1500&amp;ssl=1 1500w" data-sizes="(max-width: 750px) 100vw, 750px" data-old-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?fit=750%2C1000&amp;ssl=1" data-lazy-srcset="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?w=1500&amp;ssl=1 1500w" data-lazy-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1441-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>I then carefully unsoldered the remains of the broken port:</p>



<figure><img data-attachment-id="3579" data-permalink="https://blog.jmdawson.co.uk/img_1440-2/" data-orig-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1440-1-scaled.jpg?fit=1920%2C2560&amp;ssl=1" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 8 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1611332424&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.066666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1440" data-image-description="" data-medium-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1440-1-scaled.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1440-1-scaled.jpg?fit=750%2C1000&amp;ssl=1" loading="lazy" width="1920" height="2560" src="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1440-1-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" data-src="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1440-1-scaled.jpg?fit=750%2C1000&amp;ssl=1" alt="" data-srcset="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1440-1-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1440-1-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1440-1-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1440-1-scaled.jpg?w=1500&amp;ssl=1 1500w" data-sizes="(max-width: 750px) 100vw, 750px" data-old-src="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1440-1-scaled.jpg?fit=750%2C1000&amp;ssl=1" data-lazy-srcset="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1440-1-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1440-1-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1440-1-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1440-1-scaled.jpg?w=1500&amp;ssl=1 1500w" data-lazy-src="https://i1.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1440-1-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Added the salvaged port along with plenty of no-clean flux and soldered it on:</p>



<figure><img data-attachment-id="3581" data-permalink="https://blog.jmdawson.co.uk/img_1444/" data-orig-file="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1444-scaled.jpg?fit=1920%2C2560&amp;ssl=1" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 8 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1611333515&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.25&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1444" data-image-description="" data-medium-file="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1444-scaled.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1444-scaled.jpg?fit=750%2C1000&amp;ssl=1" loading="lazy" width="1920" height="2560" src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1444-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" data-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1444-scaled.jpg?fit=750%2C1000&amp;ssl=1" alt="" data-srcset="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1444-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1444-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1444-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1444-scaled.jpg?w=1500&amp;ssl=1 1500w" data-sizes="(max-width: 750px) 100vw, 750px" data-old-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1444-scaled.jpg?fit=750%2C1000&amp;ssl=1" data-lazy-srcset="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1444-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1444-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1444-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1444-scaled.jpg?w=1500&amp;ssl=1 1500w" data-lazy-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1444-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>There we have it, another Pi saved from the scrap pile! </p>



<p>I know people are excited to see the board level repairs but I can assure that they are coming, there are just a lot of devices to go through and I want to get the easy fixes out of the way first. <br></p>



<div><p>I fixed several with broken USB ports and added them to the box of working Pi’s. I will be covering SD card slot repairs when my AliExpress parts arrive but for now this is all on the repairs. </p><p>Here is a final photo showing the so-far working devices: </p></div>



<figure><img data-attachment-id="3576" data-permalink="https://blog.jmdawson.co.uk/img_1455/" data-orig-file="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?fit=1920%2C2560&amp;ssl=1" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 8 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1611407779&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.090909090909091&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1455" data-image-description="" data-medium-file="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?fit=750%2C1000&amp;ssl=1" loading="lazy" width="1920" height="2560" src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" data-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?fit=750%2C1000&amp;ssl=1" alt="" data-srcset="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?w=1500&amp;ssl=1 1500w" data-sizes="(max-width: 750px) 100vw, 750px" data-old-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?fit=750%2C1000&amp;ssl=1" data-lazy-srcset="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?resize=1600%2C2133&amp;ssl=1 1600w, https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?w=1500&amp;ssl=1 1500w" data-lazy-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/img_1455-scaled.jpg?fit=750%2C1000&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<h2>What am I going to do with 200 Raspberry Pi’s?!</h2>



<p>I’m sorry to disappoint but I won’t be building a cluster or decorating my walls with them! In fact I don’t have a project planned for these instead they will be sold on starting at £4 for a “Model A” and up to £9 for a fully boxed un-repaired Model B. I’m not doing this to make a quick buck I’m doing it for the blog content and the experience and to hopefully provide you guys with some very cheap Raspberry Pi’s for your projects!</p>



<p>I had a lot of suggestions to send the Pi’s to a developing Country for students to learn IT on and whilst I really like that idea the logistics of it and finding someone trustworthy enough to hand them out aren’t straight forward. Then there is the issue or 200 Pi’s requiring SD cards, Keyboards, Mice and Displays A board alone just isn’t enough here and its just not simple or easy for me to do. Instead I will be donating the proceeds of the sales to the Raspberry Pi Foundation and they can decide what to do with the Money! </p>



<p>I will post an update tomorrow with the results of the diagnostics and a link where you can purchase the repaired devices – UK only though I’m afraid unless you are willing to cover the shipping. </p>



<p>Let me know what you think of this mammoth task in a comment below and please consider following this blog for updates. </p>



<p>Edit: 24/01/21<br>Part 2 is now out <a href="https://blog.jmdawson.co.uk/i-bought-200-raspberry-pi-model-bs-and-im-going-to-fix-them-part-2/">here</a>.</p>



<p>Part 3 is now out <a href="https://blog.jmdawson.co.uk/i-bought-200-raspberry-pi-model-bs-and-im-going-to-fix-them-part-3/">here</a></p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://blog.jmdawson.co.uk/i-bought-200-raspberry-pi-model-bs-and-im-going-to-fix-them-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25885348</guid>
            <pubDate>Sat, 23 Jan 2021 19:36:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Golang – Detecting Resource Leaks with Baseline Tests]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25885254">thread link</a>) | @dm03514
<br/>
January 23, 2021 | https://on-systems.tech/106-go-detecting-resource-leaks-with-baseline-tests/ | <a href="https://web.archive.org/web/*/https://on-systems.tech/106-go-detecting-resource-leaks-with-baseline-tests/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Cleaning up resources is one fo the most difficult things in Go. If careful attention isn’t paid to files,
network connections, or goroutines then a special type of memory leaked, called a resource leak, can occur.
One of the most effective way to identify resource leaks I’ve found are “baseline” tests. These tests establish
a healthy baseline. Next some work is simulated. The final step is to verify that the baseline was returned to,
once the work has completed.</p><p>Baseline tests are a reactionary way to detect resource leaks. This means that a resource leak must <em>already</em> be
present in code. Contrast this with a proactive detection mechanism such as a static analysis. In static analysis
a check may be performed to ensure that every <a href="https://golang.org/pkg/io/#Closer"><code>io.Closer</code></a>, has <code>Close()</code> called
on it within the function scope the resource was opened. Another strategy to manage resource leaks is a strict adherence to convention. i.e.
ensure that every goroutine that’s started has a way to finish, or <code>defer</code>ing <code>Close()</code> right after a resource is
successfully opened.</p><p>A baseline tests involves starting your application and then generating some short-lived test load.
Below shows an example of a baseline test.</p><p><span>
      <span></span>
  <img alt="baseline_heap_objects" title="baseline_heap_objects" src="https://on-systems.tech/static/d13e832dfad97b040e0f45e97d960323/b1001/baseline_heap_objects.png" srcset="https://on-systems.tech/static/d13e832dfad97b040e0f45e97d960323/e4d6b/baseline_heap_objects.png 345w,https://on-systems.tech/static/d13e832dfad97b040e0f45e97d960323/1e043/baseline_heap_objects.png 690w,https://on-systems.tech/static/d13e832dfad97b040e0f45e97d960323/b1001/baseline_heap_objects.png 1380w,https://on-systems.tech/static/d13e832dfad97b040e0f45e97d960323/a6d66/baseline_heap_objects.png 2070w,https://on-systems.tech/static/d13e832dfad97b040e0f45e97d960323/53948/baseline_heap_objects.png 2720w" sizes="(max-width: 1380px) 100vw, 1380px" loading="lazy">
    </span></p><p>The graph shows the # of objects allocated by go. The flat sections of the graph display the “baseline”. The
spikes indicate load is being applied.</p><p>After the program is initialized it is a flat steady line. Then some load is applied to the program. Afterwards
the runtime returns to the initial flat line. When resources leak the # of objects will increase after each
application of load, and the flat “baseline” sections will slowly grow.</p><p>The next graph shows a base line tests affect on the # of goroutines. During steady state 11 goroutines are
running. </p><p><span>
      <span></span>
  <img alt="baseline_go_routines" title="baseline_go_routines" src="https://on-systems.tech/static/179864feba9ab80a5db07a66e58f3c2f/b1001/baseline_go_routines.png" srcset="https://on-systems.tech/static/179864feba9ab80a5db07a66e58f3c2f/e4d6b/baseline_go_routines.png 345w,https://on-systems.tech/static/179864feba9ab80a5db07a66e58f3c2f/1e043/baseline_go_routines.png 690w,https://on-systems.tech/static/179864feba9ab80a5db07a66e58f3c2f/b1001/baseline_go_routines.png 1380w,https://on-systems.tech/static/179864feba9ab80a5db07a66e58f3c2f/a6d66/baseline_go_routines.png 2070w,https://on-systems.tech/static/179864feba9ab80a5db07a66e58f3c2f/4f2ef/baseline_go_routines.png 2714w" sizes="(max-width: 1380px) 100vw, 1380px" loading="lazy">
    </span></p><p>If the # of go routines or the # of objects allocated never return after stopping load, it’s a good indicator
of a resource leak. Once a resource leak is detected its important to dig into the root cause. Go provides a tool
called <a href="https://golang.org/pkg/net/http/pprof/">pprof</a> which helps in <a href="https://medium.com/dm03514-tech-blog/sre-debugging-simple-memory-leaks-in-go-e0a9e6d63d4d">detecting resources leaks</a>.</p><p>Baseline tests are a really simple and easy way to detect resource leaks. Unfortunately, they only detect after
a resource leak is already present in code, so they should be combined with static analysis and resource management
conventions for the best coverage. Go makes it particularly easy to inspect the runtime and expose the # of
allocated objects and goroutines through the <a href="https://golang.org/pkg/runtime/#ReadMemStats"><code>runtime</code></a> package.</p><p>References:</p><ul><li><a href="https://medium.com/dm03514-tech-blog/sre-debugging-simple-memory-leaks-in-go-e0a9e6d63d4d">https://medium.com/dm03514-tech-blog/sre-debugging-simple-memory-leaks-in-go-e0a9e6d63d4d</a></li><li><a href="https://www.freecodecamp.org/news/how-i-investigated-memory-leaks-in-go-using-pprof-on-a-large-codebase-4bec4325e192/">https://www.freecodecamp.org/news/how-i-investigated-memory-leaks-in-go-using-pprof-on-a-large-codebase-4bec4325e192/</a></li><li><a href="https://golang.org/pkg/net/http/pprof/">https://golang.org/pkg/net/http/pprof/</a></li></ul></section></div>]]>
            </description>
            <link>https://on-systems.tech/106-go-detecting-resource-leaks-with-baseline-tests/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25885254</guid>
            <pubDate>Sat, 23 Jan 2021 19:23:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Three Strikes Rule for Blogging]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25885243">thread link</a>) | @craigkerstiens
<br/>
January 23, 2021 | https://www.swyx.io/three-strikes/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/three-strikes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Here's how to stop being so darn precious about your blogging: <strong>The third time you use an idea in a conversation, you have to blog about it.</strong></p>
<p>
  <img src="https://dev-to-uploads.s3.amazonaws.com/i/dgn7cqkm5385vom48amy.png" alt="Visualized three strikes rule">
</p>
<section>
  <h2 id="why"><a href="#why">Why</a></h2>
  <p>People often wonder what to blog about. You can get really fancy with Google keyword research and content calendars and the like. It's too complicated for me, and often leads to the kind of impersonal, SEO-driven blogposts that are slowly ruining the web.</p>
  <p>We need a simple, authentic heuristic to decide. Let's think about the upper and lower bounds:</p>
  <ul>
    <li>It's possible to blog too much — nobody wants you to broadcast every waking thought.</li>
    <li>But it's more likely that we are just <em>not blogging enough</em>.</li>
  </ul>
  <p>What's obvious to you is often not obvious to others. How often do you speak with someone and casually mention something that is new to them?</p>
  <p>Pretty often.</p>
  <p>
    <img src="https://imgs.xkcd.com/comics/ten_thousand.png" alt="xkcd 1053">
  </p>
  <p>It's natural to want to hold off publishing our insights and discoveries until the magical right time when it all clicks together in one beautiful, perfect essay that springs forth fully formed from our foreheads, making us famous and showing the world how smart we are.</p>
  <p>We want it so much we end up <strong>never writing it</strong>.</p>
  <p>This is how the world misses out on so much of our unique voices, taste, and perspectives.</p>
  <p>The Three Strikes Rule is designed as both a filter (for passing thoughts) and a prompt (for you to write more).</p>
  <p><strong>To stop being so precious</strong> about your blog.</p>
  <p><strong>To share ideas</strong> more openly and freely with your readers.</p>
  <p><strong>To <a href="https://www.swyx.io/create_luck/">Create Luck</a></strong>.</p>
  <p><strong>To create one reference</strong> for that bunch of links you always end up searching for when you write or answer questions.</p>
  <p>And, quite honestly, <strong>to write shorter blogposts</strong>. Nobody has time to read the 3,000 word preamble to your magnum opus. It's a blog, not a physical book — you can return over time to expand it if it's worth it (like <a href="https://www.swyx.io/LIP">this</a> or <a href="https://www.swyx.io/how-to-name-things/">this</a>).</p>
  <blockquote>
    <p>Sidenote: Some people call these "blogs that grow over time" a <a href="https://joelhooks.com/digital-garden">digital garden</a>. The mental masturbation crowd prefer <a href="https://writingcooperative.com/zettelkasten-how-one-german-scholar-was-so-freakishly-productive-997e4e0ca125">Zettelkasten</a> because it sounds foreign. It doesn't matter what you call it, it matters that you do it and grow it.</p>
  </blockquote>
</section>
<section>
  <h2 id="how"><a href="#how">How</a></h2>
  <p>Let's say we accept that "the 3rd time we reference an idea in a conversation, we have to blog about it". What does that really mean?</p>
  <p>I take an expansive view of what "ideas" and "conversations" means.</p>
  <ul>
    <li><strong>Ideas</strong> includes great talks, good books, useful concepts, obscure names, handy definitions, copied-and-pasted code snippets, historical facts, surprising charts, and even blogposts by other people. (Yes, you can blog about other blogs. <a href="https://css-tricks.com/the-power-of-lampshading/">Like this</a>. Why not?) Sometimes the idea will be your own, most times it will be your takes on others'.</li>
    <li><strong>Conversations</strong> include in-person, on Zoom, on Twitter, wherever you communicate and exchange ideas.</li>
  </ul>
  <p><strong>The first time</strong> you refer to an idea, you probably just learned about it. It might be a fad; you may never find the idea useful again. Let it go.</p>
  <p><strong>The second time</strong> you refer to the idea, you should be taking note. Ideas are things we find useful in our day-to-day conversations, and there's probably a good amount of our readers who would too. But it might <em>still</em> fade away, so we hold off on it. It still needs to <strong>prove its usefulness</strong>.</p>
  <p>By <strong>the third time</strong> you refer to an idea, it's no longer a coincidence. It's a pattern. You're increasingly likely to refer to it again in future. It's marinated in your head for a bit, and you've likely gained some experience explaining it to others. It's also not so old that it may have lost relevance. It's time to write it down <a href="https://www.hanselman.com/blog/do-they-deserve-the-gift-of-your-keystrokes">to save keystrokes</a>.</p>
  <p>Do I <em>literally</em> write everything down after the 3rd time? No, sometimes the "three strikes" becomes the "five strikes" or the "ten strikes" rule, mostly out of laziness. But I know I <em>should</em>. With this rule, I find that I blog more and people still get value out of the core idea.</p>
  <blockquote>
    <p>In case you were wondering... yes the "reference counter" on the Three Strikes rule itself got up to about 8 or 9 before I wrote this post. 🙈</p>
  </blockquote>
</section>
<section>
  <h2 id="delivery"><a href="#delivery">Delivery</a></h2>
  <p>Following this rule will dramatically increase the volume of your output. There's then the question of how to deliver these high frequency things. There are a few methods:</p>
  <ul>
    <li>Tweet it out</li>
    <li>Dump them in a github repo (<a href="https://github.com/jbranchaud/til">like this</a>)</li>
    <li>Split your blog from "only having essays" mode to having both "essays" and "notes". Publish separate RSS feeds for them.</li>
    <li>Buffer them up for a "grab bag post" like <a href="https://marginalrevolution.com/marginalrevolution/2021/01/what-ive-been-reading-183.html">Tyler Cowen</a></li>
  </ul>
  <p>Personally, I am exploring doing this with a <a href="http://swyx.transistor.fm/">daily podcast</a>. See what works for you.</p>
  <p>If you're worried that people will think you're too noisy, you probably shouldn't.</p>
  <blockquote>
    <p>"You’ll worry less about what people think about you when you realize how seldom they do." - David Foster Wallace, <em>Infinite Jest</em></p>
  </blockquote>
  <p><strong>I'd love for you to share great ideas more freely.</strong> Great ideas deserve to be shared, and your readers will appreciate it.</p>
</section>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/three-strikes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25885243</guid>
            <pubDate>Sat, 23 Jan 2021 19:22:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why am I wasting time on EndBASIC?]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25884859">thread link</a>) | @todsacerdoti
<br/>
January 23, 2021 | https://jmmv.dev/2021/01/why-endbasic.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2021/01/why-endbasic.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article><p>If you have been following this blog or my social profiles for the last year, you are probably aware that <a href="https://jmmv.dev/tags/endbasic">I have been working on something called EndBASIC</a>. You also probably know that this is a retro-looking BASIC interpreter written in Rust that <a href="https://endbasic.jmmv.dev/">happens to run on the web</a>. And if you know those two things, you are probably wondering, like some of my friends do: why am I <em>wasting</em> time developing such a useless project? <strong>Because.</strong></p>
<p>No, seriously, because. It is obvious that the EndBASIC language and environment will not gain massive traction, and I do not have any interest in inventing a perfect new language (because, let’s face it, we already have one and it’s called Rust 😉).</p>
<p>So, then, why do I spend any of my scarce free time on this project? If you must know:</p>
<ul>
<li>
<p><strong>It’s a fun thing to do.</strong> Just like some people enjoy watching TV shows, playing video games, or crafting wood, I enjoy programming. It feels like a game. And EndBASIC <em>itself</em> could be seen as a game at this point.</p>
</li>
<li>
<p><strong>It’s a form of art.</strong> Developing a personal project is a different experience than developing a work project. I can spend all the time in the world polishing the same turd over and over again, playing with different ideas until things look best.</p>
<p>If you have ever considered that programming may be art, then this kind of side project is where you crank your craft up a notch. As just one example, working on EndBASIC’s tests made me come up with the idea of <a href="https://jmmv.dev/2020/12/builder-pattern-for-tests.html">using the builder pattern for tests</a> and it seemed to have been well-received.</p>
</li>
<li>
<p><strong>It’s a learning experience.</strong> In writing EndBASIC, I’m playing with Rust. I strongly believe that Rust is one of the languages of the future and it’s the language that makes me say “aha, I agree” at every corner I turn. Yet, I haven’t mastered it. Working on Rust projects lets me learn a bunch of stuff about the language that will be helpful in future endeavors. And it’s not only about Rust per se: <a href="https://jmmv.dev/2020/04/rust-into-trait.html">learning the idioms</a> used in this language can <a href="https://jmmv.dev/2018/06/rust-review-protect-the-data.html">help write better code</a> in any other.</p>
<p>Another example is that I also got to learn about WASM, targeting the browser from a “native” app and making it work on various different devices. This led me down the path of async programming and how to interact with Javascript in that context—which was <a href="https://jmmv.dev/2020/05/bridging-the-web-gap-endbasic.html">a painful but eventually-gratifying obstacle</a> to overcome.</p>
<p>And yet another example is that I also got to set up continuous <em>deployment</em>, first via Travis CI and then via the new GitHub Actions coolness. This, in turn, gave me ammo to write up more <a href="https://jmmv.dev/2021/01/github-actions-code-health.html">interesting</a> <a href="https://jmmv.dev/2021/01/do-not-submit.html">stuff</a> in this blog.</p>
</li>
<li>
<p><strong>Copying an “old technology” is irrelevant.</strong> Yes, BASIC is not the language of the future (although… VB.NET users may disagree with you because it supports, I don’t know, thousands of businesses?). But that doesn’t matter. Only 5,000 lines of the codebase (about 30% of the total) are devoted to parsing the language, and most of those lines are unit tests anyway. If I wanted to change the language per se to offer a more “modern” experience with things like first-order functions, objects, etc. it’d be <em>trivial</em> to do so.</p>
<p>To be clear, I have no interest in building my own language as mentioned in the opening, but having worked on the <em>building blocks</em> of a real language is enlightening, and having those building blocks around will surely come in handy in the future.</p>
</li>
</ul>
<p>So what happened to the <a href="https://jmmv.dev/2020/04/hello-endbasic.html">original goal</a> of teaching programming to my kids via this project? Well… uhh… let’s say I’ve gotten distracted having fun by myself rather than actually getting them in front of this. I should get back to that goal after all the recent improvements to make the environment more usable and seeing if they care at all.</p>
<p>But yes. For the most part, EndBASIC is a crazy/useless language. Although… ~50 other people currently disagree with the thought of this being useless if <a href="https://github.com/jmmv/endbasic/">GitHub stars</a> mean anything at all 😉 If you are one of those ~50, thank you! And if you are not, join me in the craze?</p>
<p><strong>Edit (Jan 24th): If you are here from the recent bump in Hacker News, hello! I have <a href="https://jmmv.dev/2021/01/endbasic-0.5.html">just published the 0.5.0 release</a> which might answer some of the questions you have.</strong></p>
</article>
            </div>
          </div><div>
            <div>
              <p><b>Want more posts like this one? Take a moment to subscribe!</b></p>
            </div>
            <div>
              
              <p>
                  <a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;screen_name=jmmv">
                    <img src="https://jmmv.dev/images/badges/Twitter_logo_blue_32.png" alt="Follow @jmmv on Twitter">
                  </a>
                </p>
              <p><a href="https://jmmv.dev/feed.xml"><img src="https://jmmv.dev/images/badges/feed-icon-28x28.png" alt="RSS feed"></a></p>
            </div>
          </div><div>
            <div>
              <p><b>Enjoyed this article? Spread the word or join the ongoing discussion!</b></p>
            </div>
            
          </div></div>]]>
            </description>
            <link>https://jmmv.dev/2021/01/why-endbasic.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25884859</guid>
            <pubDate>Sat, 23 Jan 2021 18:31:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing Raft's Leader Election in Rust]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25884781">thread link</a>) | @laurocaetano
<br/>
January 23, 2021 | http://laurocaetano.com/programming/2021/01/23/raft-leader-election-rust/ | <a href="https://web.archive.org/web/*/http://laurocaetano.com/programming/2021/01/23/raft-leader-election-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>Consensus algorithms is a topic that always caught my attention: it is complex and hard and needs a precise and safe solution. In other words: We have a couple of machines forming a cluster, and they operate on identical copies of the same data and can continue operating even in the scenario of some servers being down. This approach is used to solve a bunch of problems in distributed systems.</p>

<p>To give a bit of background of where we currently stand, we have to talk about <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>. Over the past decade or more, Paxos was almost synonymous with consensus, as it is the protocol taught in most computer science courses, and most implementations of consensus make use of it. The only problem is that Paxos is really difficult to understand, thus making it very hard to be implemented correctly. With that, Diego Ongaro and John Ousterhout <a href="https://raft.github.io/raft.pdf">designed Raft</a>, with the most important goal of making it understandable.</p>

<p>Given that Raft focuses so much on understandability, it breaks down the consensus into three relatively independent subproblems (quoting the Raft paper):</p>

<ul>
  <li>Leader election: a new leader must be chosen when an existing leader fails.</li>
  <li>Log replication: the leader must accept log entries from clients and replicate them across the cluster, forcing the other logs to agree with their own</li>
  <li>Safety: if any server has applied a given log entry to its state machine, then no other server may apply a different command for the same log index.</li>
</ul>

<p>In this blog post, I will cover only the Leader election. The other two topics I will cover in the future in other blog posts!</p>

<h3 id="the-basics-of-raft-and-leader-election">The basics of Raft and leader election</h3>

<p>A Raft cluster is composed of several servers and five is a typical number, therefore allowing the system to have two failures. A server in this cluster is in one of three possible states:</p>

<ul>
  <li>Leader: Handles all client requests.</li>
  <li>Followers: are passive, and only respond to requests from leaders.</li>
  <li>Candidate: a state used to elect a new leader.</li>
</ul>

<p>Raft divides time into terms of arbitrary length, and they are numbered with consecutive integers. Each one of these terms starts with an election, where one or more candidates attempt to become the leader of the cluster. When a candidate wins the election, it serves as the leader for the rest of the term. To explain this process a bit better, we can illustrate these transitions.</p>

<p><img src="http://laurocaetano.com/images/raft-states-2.png" alt="raft-states"></p>

<p>Raft uses a heartbeat mechanism to trigger elections. When a server joins the cluster, they begin as followers, and they remain in this state as long as they receive valid heartbeats from the current leader. The leaders send periodic heartbeats to all followers in order to notify them of the existence of it and maintain its authority. When a follower does not receive a heartbeat over a period of time, named in Raft “election timeout”, then it proceeds to start a new election.</p>

<p>A new election follows these steps:</p>

<ol>
  <li>Changing the state from follower to candidate</li>
  <li>Increase the current term by 1</li>
  <li>Votes for itself</li>
  <li>Requests votes from all servers in the cluster</li>
  <li>If the server gets the majority of the votes, it assumes the role of leader</li>
  <li>Starts sending heartbeats to all followers, including the new term</li>
</ol>

<p>This is a very simplistic and short explanation for the leader election process, and for more details do not hesitate in <a href="https://raft.github.io/raft.pdf">reading the paper</a>! It’s a very pleasant read.</p>

<h3 id="implementation-in-rust">Implementation in Rust</h3>

<p><a href="https://www.rust-lang.org/">Rust</a> is a programming language designed for performance, safety, and safe concurrency. It is strongly typed, compiled, has no garbage collector, and has no runtime (a.k.a a very minimal runtime).</p>

<p>I got interested in Rust at the end of 2020, by reading a couple of blog posts. With that trigger, I decided to read <a href="https://doc.rust-lang.org/book/title-page.html">The Rust Programming Language</a> book and started to code very small projects. Only that very small projects do not tell you much about the language in the real world. So I decided to implement something that is more related to what I work on on my daily basis: dealing with distributed systems.</p>

<p>Note: if you are not familiar with the language, you can quickly check <a href="https://stevedonovan.github.io/rust-gentle-intro/">the Gentle intro to Rust</a>.</p>

<h4 id="the-implementation">The implementation</h4>

<p>I decided to use the most simple and basic constructs of the language. This means no big runtimes, libs that do most of the job and etc. So I ended up using only threads for concurrency, and TCP for the RPCs.</p>

<h5 id="reproducing-the-states-and-types-in-the-code">Reproducing the states and types in the code</h5>

<p>My initial approach was to find out which types were the most important ones, and reproduced them in the code.</p>

<div><div><pre><code><span>// Examples of types.</span>
<span>enum</span> <span>State</span> <span>{</span>
  <span>FOLLOWER</span><span>,</span>
  <span>LEADER</span><span>,</span>
  <span>CANDIDATE</span><span>,</span>
<span>}</span>

<span>enum</span> <span>LogEntry</span> <span>{</span>
    <span>Heartbeat</span> <span>{</span> <span>term</span><span>:</span> <span>u64</span><span>,</span> <span>peer_id</span><span>:</span> <span>String</span> <span>},</span>
<span>}</span>

<span>struct</span> <span>Server</span> <span>{</span>
    <span>id</span><span>:</span> <span>String</span><span>,</span>
    <span>address</span><span>:</span> <span>SocketAddrV4</span><span>,</span>
    <span>state</span><span>:</span> <span>State</span><span>,</span>
    <span>term</span><span>:</span> <span>u64</span><span>,</span>
    <span>log_entries</span><span>:</span> <span>Vec</span><span>&lt;</span><span>LogEntry</span><span>&gt;</span><span>,</span>
    <span>voted_for</span><span>:</span> <span>Option</span><span>&lt;</span><span>Peer</span><span>&gt;</span><span>,</span>
    <span>next_timeout</span><span>:</span> <span>Option</span><span>&lt;</span><span>Instant</span><span>&gt;</span><span>,</span>
    <span>config</span><span>:</span> <span>ServerConfig</span><span>,</span>
    <span>current_leader</span><span>:</span> <span>Option</span><span>&lt;</span><span>Leader</span><span>&gt;</span><span>,</span>
    <span>number_of_peers</span><span>:</span> <span>usize</span><span>,</span>
<span>}</span>

<span>// Visit the file "types.rs" in the repo to see the all type definition.</span>
</code></pre></div></div>

<p>And once my types were defined, I started to implement the state transitions step by step.</p>

<h5 id="a-server-starts-as-follower">A server starts as follower</h5>

<p>In order to reproduce this behavior, I implemented a <code>new</code> method inside <code>Server</code>, to ensure that all servers are started with this state.</p>

<div><div><pre><code><span>impl</span> <span>Server</span> <span>{</span>
    <span>pub</span> <span>fn</span> <span>new</span><span>(</span>
        <span>config</span><span>:</span> <span>ServerConfig</span><span>,</span>
        <span>number_of_peers</span><span>:</span> <span>usize</span><span>,</span>
        <span>address</span><span>:</span> <span>SocketAddrV4</span><span>,</span>
        <span>id</span><span>:</span> <span>String</span><span>,</span>
    <span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
        <span>Server</span> <span>{</span>
            <span>id</span><span>:</span> <span>id</span><span>,</span>
            <span>state</span><span>:</span> <span>State</span><span>::</span><span>FOLLOWER</span><span>,</span>
            <span>term</span><span>:</span> <span>0</span><span>,</span>
            <span>log_entries</span><span>:</span> <span>Vec</span><span>::</span><span>new</span><span>(),</span>
            <span>voted_for</span><span>:</span> <span>None</span><span>,</span>
            <span>next_timeout</span><span>:</span> <span>None</span><span>,</span>
            <span>config</span><span>:</span> <span>config</span><span>,</span>
            <span>current_leader</span><span>:</span> <span>None</span><span>,</span>
            <span>number_of_peers</span><span>:</span> <span>number_of_peers</span><span>,</span>
            <span>address</span><span>:</span> <span>address</span><span>,</span>
        <span>}</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Now we have a server that starts as follower! Let’s go and implement the rest of the state transitions.</p>

<h5 id="starting-an-election-when-a-timeout-occurs">Starting an election when a timeout occurs</h5>

<p>As mentioned before, a server in Raft times out when it does not receive a heartbeat from a leader in a predetermined amount of time. Each server has a randomized timeout setting, to ensure that servers time out at different times.</p>

<p>To implement that, I decided to do the following:</p>

<div><div><pre><code><span>// The final implementation is not exactly like this,</span>
<span>// but the idea is the same.</span>
<span>thread</span><span>::</span><span>spawn</span><span>(||</span> <span>{</span>
    <span>loop</span> <span>{</span>
        <span>if</span> <span>server</span><span>.has_timed_out</span><span>()</span> <span>{</span>
            <span>new_election</span><span>(</span><span>&amp;</span><span>server</span><span>);</span>
        <span>}</span>
    <span>}</span>
<span>});</span>
</code></pre></div></div>
<p>So we have a thread that runs an infinite loop, always checking for the server’s timeout. Whenever it occurs, a new election is triggered.</p>

<p>The election process, in the happy path, occurs as follow:</p>

<div><div><pre><code><span>// 1. Changing the state from follower to candidate</span>
<span>server</span><span>.state</span> <span>=</span> <span>State</span><span>::</span><span>CANDIDATE</span><span>;</span>

<span>// 2. Increase the current term by one</span>
<span>server</span><span>.term</span> <span>=</span> <span>server</span><span>.term</span> <span>+</span> <span>1</span><span>;</span>
<span>server</span><span>.refresh_timeout</span><span>();</span>

<span>// 3. Vote for itself</span>
<span>server</span><span>.voted_for</span> <span>=</span> <span>Some</span><span>(</span><span>Peer</span> <span>{</span>
    <span>id</span><span>:</span> <span>server</span><span>.id</span><span>.to_string</span><span>(),</span>
    <span>address</span><span>:</span> <span>server</span><span>.address</span><span>,</span>
<span>});</span>

<span>// 4. Prepare vote requests and make the RPC request</span>
<span>let</span> <span>request_vote_rpc</span> <span>=</span> <span>Some</span><span>(</span><span>VoteRequest</span> <span>{</span>
    <span>term</span><span>:</span> <span>new_term</span><span>,</span>
    <span>candidate_id</span><span>:</span> <span>id</span><span>,</span>
<span>})</span>

<span>let</span> <span>rpc_response</span> <span>=</span> <span>rpc_client</span><span>.request_vote</span><span>(</span><span>request_vote_rpc</span><span>);</span>

<span>// 5. if the server gets the majority of votes, becomes leader</span>
<span>if</span> <span>has_won_the_election</span><span>(</span><span>&amp;</span><span>server</span><span>,</span> <span>rpc_response</span><span>)</span> <span>{</span>

    <span>// 6. sends heartbeats to all followers</span>
    <span>let</span> <span>log_entry</span> <span>=</span> <span>LogEntry</span><span>::</span><span>Heartbeat</span> <span>{</span>
        <span>term</span><span>:</span> <span>server</span><span>.term</span><span>,</span>
        <span>peer_id</span><span>:</span> <span>server</span><span>.id</span><span>.to_string</span><span>(),</span>
    <span>};</span>

    <span>rpc_client</span><span>.broadcast_log_entry</span><span>(</span><span>log_entry</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<h5 id="election-timeout-and-discovering-another-leader">Election timeout and discovering another leader</h5>

<p>In case a timeout occurs or the server does not get the majority of the votes, it will start the election once again, increasing the term once more. In Raft, it is totally fine to have terms without a leader.</p>

<p>Another interesting case can occur during the election process: another server in the cluster is elected, and starts sending heartbeats. When this occurs, our server changes back the state from <code>CANDIDATE</code> to <code>FOLLOWER</code>, and set the terms to the current leader’s term.</p>

<div><div><pre><code><span>// Example of how a server behaves when receiving heartbeats</span>
<span>// It becomes a follower if the received heartbeat has a higher</span>
<span>// term than itself.</span>

<span>if</span> <span>term</span> <span>&gt;</span> <span>server</span><span>.term</span> <span>{</span>
    <span>info!</span><span>(</span>
        <span>"Server {} becoming follower. The new leader is: {}"</span><span>,</span>
        <span>server</span><span>.id</span><span>,</span> <span>peer_id</span>
    <span>);</span>

    <span>server</span><span>.term</span> <span>=</span> <span>term</span><span>;</span>
    <span>server</span><span>.state</span> <span>=</span> <span>State</span><span>::</span><span>FOLLOWER</span><span>;</span>
    <span>server</span><span>.voted_for</span> <span>=</span> <span>None</span><span>;</span>
    <span>server</span><span>.current_leader</span> <span>=</span> <span>Some</span><span>(</span><span>Leader</span> <span>{</span>
        <span>id</span><span>:</span> <span>peer_id</span><span>.to_string</span><span>(),</span>
        <span>term</span><span>:</span> <span>term</span><span>,</span>
    <span>})</span>
<span>}</span>
</code></pre></div></div>

<p>With that, we have covered all the steps for the state transitions in Raft’s leader election algorithm!</p>

<h5 id="more-info-about-the-full-implementation">More info about the full implementation</h5>

<p>The core logic for the leader election is implemented in the <code>raft::core</code> package, where functions to handle log entries (heartbeats), elections, and timeouts are placed. Please visit the <a href="https://github.com/laurocaetano/rsraft/blob/fda7e677627577e452fef5858d58bce3ed8d74f6/src/raft/core.rs">full implementation</a> for a more detailed look into the code.</p>

<p><em>Important notes</em></p>

<p>RPCs are done through TCP connections. Each server starts up with a TPC listener, and create client connections to all other servers in the cluster.</p>

<p>The implementation is not making usage of persistent storage, so all operations are done in memory. For this reason, the <code>Server</code> instance is shared across many functions, by making usage of Rust’s <code>Arc</code> and <code>Mutex</code> combination. It took me a while to understand the concepts, but once you get the basics, it turns out very simple!</p>

<p>There is a <a href="https://github.com/laurocaetano/rsraft/blob/fda7e677627577e452fef5858d58bce3ed8d74f6/src/raft/demo.rs">demo</a>, which runs and demonstrates the process of electing a leader in a new cluster. By running it, we get the following output:</p>

<div><div><pre><code>22:46:10 [INFO] Starting server at: 127.0.0.1:3300...
22:46:10 [INFO] Starting server at: 127.0.0.1:3301...
22:46:10 [INFO] Starting server at: 127.0.0.1:3302...
22:46:11 [INFO] The server server_1, has a timeout of 3 seconds.
22:46:11 [INFO] The server server_3, has a timeout of 6 seconds.
22:46:11 [INFO] The server server_2, has a timeout of 5 seconds.
22:46:14 [INFO] Server server_1 has timed out.
22:46:14 [INFO] Server server_1, with term 1, started the election process.
22:46:14 [INFO] Server server_1 has won the election! The new term is: 1
22:46:14 [INFO] Server server_3 with term 0, received heartbeat …</code></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://laurocaetano.com/programming/2021/01/23/raft-leader-election-rust/">http://laurocaetano.com/programming/2021/01/23/raft-leader-election-rust/</a></em></p>]]>
            </description>
            <link>http://laurocaetano.com/programming/2021/01/23/raft-leader-election-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25884781</guid>
            <pubDate>Sat, 23 Jan 2021 18:23:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgREST on Fargate]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25884447">thread link</a>) | @mooreds
<br/>
January 23, 2021 | https://www.nedmcclain.com/postgrest-rest-api-on-aws-fargate/ | <a href="https://web.archive.org/web/*/https://www.nedmcclain.com/postgrest-rest-api-on-aws-fargate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.nedmcclain.com/content/images/size/w300/2021/01/moab.jpg 300w,
                            https://www.nedmcclain.com/content/images/size/w600/2021/01/moab.jpg 600w,
                            https://www.nedmcclain.com/content/images/size/w1000/2021/01/moab.jpg 1000w,
                            https://www.nedmcclain.com/content/images/size/w2000/2021/01/moab.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.nedmcclain.com/content/images/size/w2000/2021/01/moab.jpg" alt="PostgREST on Fargate">
            </figure>

            <section>
                <div>
                    <p>Launching an MVP is the only way to get real user feedback on your startup. Rather than build out a custom backend, <a href="https://postgrest.org/">PostgREST</a> exposes your Postgres DB tables as a REST API. <strong>Put those first months of engineering focus into the frontend and unique business logic - save the custom backend for when you need to scale.</strong></p><blockquote>Using PostgREST is an alternative to manual CRUD programming. Custom API servers suffer problems. Writing business logic often duplicates, ignores or hobbles database structure. Object-relational mapping is a leaky abstraction leading to slow imperative code. The PostgREST philosophy establishes a single declarative source of truth: the data itself. - <a href="https://postgrest.org/">https://postgrest.org/</a></blockquote><p><a href="https://aws.amazon.com/fargate/">AWS Fargate</a> is an ideal compute platform for PostgREST. Being serverless, it is very efficient in terms of cost and operations. Yet Fargate containers are relatively long-lived compared to AWS Lambda - this allows PostgREST's caching mechanisms to remain effective.</p><h2 id="prerequisites">Prerequisites</h2><ul><li>You'll need an AWS account and its associated access/secret keys.</li><li>Install the AWS CLI [<a href="https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html">directions here</a>], and configure your AWS keys [<a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html#cli-configure-quickstart-config">directions here</a>].</li><li>The <a href="https://github.com/awslabs/fargatecli">Fargate CLI</a> is the easiest way to deploy a container on AWS. You'll want to install it [<a href="https://github.com/awslabs/fargatecli/releases">download here</a>].</li><li>A Postgres database. Your Fargate task(s) will need network access to this database. If you are using RDS, be sure to specify subnets and security groups for your load balancer and tasks (see below) so they get deployed in the same VPC as your database.</li></ul><h2 id="ship-it">Ship it</h2><h3 id="1-setup-a-test-db-api-role-and-table-in-postgres-">1. Setup a test DB, API, role, and table in Postgres:</h3><p>Connect to Postgres, then create a database for this exercise:</p><pre><code>postgres=&gt; create database startup;
CREATE DATABASE
postgres=&gt; \c startup;
psql ...
You are now connected to database "startup" as user "root".
startup=&gt;</code></pre><p>PostgREST uses a "naked schema" to identify which DB tables should be exposed in the API. We can create one, and add a sample table:</p><pre><code>startup=&gt; create schema api;
CREATE SCHEMA

startup=&gt; create table api.trees (id serial primary key, name text not null, species text not null);
CREATE TABLE

startup=&gt; insert into api.trees (name, species) values ('Banyan', 'Ficus benghalensis'), ('Quaking Aspen', 'Populus tremula'), ('American Elm', 'Ulmus americana'), ('Red Maple', 'Acer rubrum');
INSERT 0 4</code></pre><p>Finally, we need to set up two roles. The first controls anonymous access with Postgres' standard grants and (optionally) row-level security. PostgREST uses the <code>authenticator</code> role to connect to the database. Once connected, PostgREST assumes the <code>web_anon</code> role. <em>Please pick a better password than 'secret1'.</em></p><pre><code>create role web_anon nologin;

grant usage on schema api to web_anon;
grant select on api.trees to web_anon;

create role authenticator noinherit login password 'secret1';
grant web_anon to authenticator;</code></pre><p>This structure ensures you are not using the <code>root</code> user for PostgREST connections and makes it easy to add <a href="https://postgrest.org/en/v7.0.0/tutorials/tut1.html">JWT-authenticated roles</a> in the future.</p><p>A more detailed PostgREST setup tutorial is available here: <a href="https://postgrest.org/en/v7.0.0/tutorials/tut0.html">https://postgrest.org/en/v7.0.0/tutorials/tut0.html</a></p><h3 id="2-deploy-an-application-load-balancer-to-route-traffic-to-your-fargate-task-s-">2. Deploy an Application Load Balancer to route traffic to your Fargate task(s):</h3><pre><code>fargate lb create postgrest --port HTTP:80
 ℹ️  Created load balancer postgrest</code></pre><p>Let's break down this command:</p><ul><li><code>fargate lb create postgrest</code>: create an ALB named <code>postgrest</code>.</li><li><code>--port HTTP:80</code>: the load balancer will accept internet requests on port 80.</li><li>If you've deleted your default VPC, or wish to use a different VPC, be sure to specify the appropriate subnets (this flag can be used multiple times):<br><code>--subnet-id subnet-0ae7XXX</code></li><li>You can also optionally specify multiple security groups with the <code>--security-group-id sg-02ddXXX</code> flag. </li></ul><h3 id="3-deploy-a-postgrest-task-">3. Deploy a PostgREST task:</h3><p>This command will deploy the PostgREST image to a Fargate task. It automatically creates a new ECS cluster and a default IAM role for task execution.</p><pre><code>fargate service create postgrest \
  --lb postgrest --port HTTP:3000 \
  --image 'registry.hub.docker.com/postgrest/postgrest' \
  --num 1 \
  --env PGRST_DB_URI='postgres://authenticator:secret1@HOST/startup' \
  --env PGRST_DB_SCHEMA='api' \
  --env PGRST_DB_ANON_ROLE='web_anon'
  ℹ️ Created service postgrest</code></pre><p>A quick review of the flags we used:</p><ul><li><code>fargate service create postgrest</code>: create a <code>postgrest</code> Fargate service in a new ECS cluster.</li><li><code>--lb postgrest --port HTTP:3000</code>: connect this service to your load balancer.</li><li><code>--image 'registry.hub.docker.com/postgrest/postgrest'</code>: deploy the <code>postgrest</code> image from dockerhub.</li><li><code>--env PGRST_DB_URI='postgres://authenticator:secret1@HOST/startup'</code>: set <a href="https://www.postgresql.org/docs/9.2/libpq-connect.html#LIBPQ-CONNSTRING">URI</a> for access to your database. Note this is the username/password/db you setup in step 1.</li><li><code>--env PGRST_DB_SCHEMA='api'</code>: name the API you created in step 1.</li><li><code>--env PGRST_DB_ANON_ROLE='web_anon'</code>: name the role you created in step 1.</li></ul><h3 id="4-test-troubleshoot">4. Test/Troubleshoot</h3><p>If things go as planned, you'll be able to find your load balancer hostname with:</p><pre><code>$ fargate lb list | grep postgrest
postgrest	Application	Active	
postgrest-132447124.us-east-1.elb.amazonaws.com	HTTP:80</code></pre><p>Now, you can query your new API:</p><pre><code>curl postgrest-132447124.us-east-1.elb.amazonaws.com/trees
[{"id":1,"name":"Banyan","species":"Ficus benghalensis"},
 {"id":2,"name":"Quaking Aspen","species":"Populus tremula"},
 {"id":3,"name":"American Elm","species":"Ulmus americana"},
 {"id":4,"name":"Red Maple","species":"Acer rubrum"}]</code></pre><h2 id="cost">Cost</h2><p>AWS's "free tier" doesn't include Fargate, so here’s the bottom line: it will cost you $2.83 to run PostgREST on a Fargate &nbsp;for one month, while easily serving 500 requests/second. This is with the smallest single instance available - there is tons of room to scale both vertically and horizontally with this architecture.</p><p><strong>Caution:</strong> the load balancer costs are more significant (~$16+/mo), but they are included in the "free tier" and can be shared between many Fargate (and Lambda/EC2) services.</p><h2 id="next-steps">Next Steps</h2><ul><li>Looking for more than a read-only API? You can enable authenticated access to read and write private information in your database. PostgREST supports JWT authentication, which maps to Postgres roles you configure. You can even enable row-level security. <a href="https://postgrest.org/en/v7.0.0/tutorials/tut1.html">Tutorial is here</a>, with <a href="https://postgrest.org/en/v7.0.0/auth.html">further details here</a>.</li><li>Please enable TLS (SSL) on your load balancer, and require encrypted connections to PostgREST. We don't want your credentials leaking!</li><li>In production, you might use an infrastructure-as-code tool like Terraform or CDK to deploy your Fargate tasks. These tools offer more control and customization than the Fargate CLI.</li><li>Want more content like this? Follow me on Twitter at <a href="https://twitter.com/nedmcclain">@nedmcclain</a>. Struggling to get PostgREST deployed on Fargate? DM me!</li></ul><h2 id="thanks-nalin-">Thanks Nalin!</h2><p>Hat tip to my dear friend <a href="https://twitter.com/nalin">@nalin</a>, for encouraging me to write this post!</p><figure><img src="https://www.nedmcclain.com/content/images/2021/01/postgrest_tweet-1.png" alt="" srcset="https://www.nedmcclain.com/content/images/2021/01/postgrest_tweet-1.png 600w"></figure><p><em>Cover photo by <a href="https://unsplash.com/@kevinbree?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Kevin Bree</a> on <a href="https://unsplash.com/s/photos/arch?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.nedmcclain.com/postgrest-rest-api-on-aws-fargate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25884447</guid>
            <pubDate>Sat, 23 Jan 2021 17:47:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emails a browser extension developer gets from scammers]]>
            </title>
            <description>
<![CDATA[
Score 151 | Comments 66 (<a href="https://news.ycombinator.com/item?id=25884338">thread link</a>) | @ajayyy
<br/>
January 23, 2021 | https://sponsor.ajay.app/emails/ | <a href="https://web.archive.org/web/*/https://sponsor.ajay.app/emails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>I've been seeing a lot of stories about extensions getting taken over by unknown developers and becoming malware. Sadly, with how many permissions many  extensions have, it can do a lot of damage. I decided to compile a list of these sketchy emails I have received, to show the kinds of offers that exist.</p><p>To be clear I <strong>will never</strong> do anything of this sort, but make sure any extensions you install are from trusted developers and have as few permissions as possible. Most of these scams wouldn't even work with SponsorBlock due to lack of permissions (it only has access to youtube.com), but they spam email all developers anyway.</p><h2>From partners@infatica.io (A proxy service (botnet?)):</h2><p><a href="https://infatica.io/sdk-monetization/?utm_campaign=1+SDK+N+-+Accept+All">Their explanation page</a> <a href="https://archive.vn/Oax8a">(Archive)</a></p><p>Here's the <a href="https://pastebin.com/MXVMmwAx">code</a> for their sdk. In the email they told me it was "open", so that should mean it is meant to be public.</p><p><img src="https://user-images.githubusercontent.com/12688112/105428261-04d7f180-5c1d-11eb-9d97-9f9be56eecef.png" alt="scam"><img src="https://user-images.githubusercontent.com/12688112/105428173-d0643580-5c1c-11eb-8d41-a8214efa2725.png" alt="scam"><img src="https://user-images.githubusercontent.com/12688112/105427987-68155400-5c1c-11eb-8837-cf6574dfea85.png" alt="scam"><img src="https://user-images.githubusercontent.com/12688112/105427949-52079380-5c1c-11eb-956b-6e9a74d6567a.png" alt="scam"></p><h2>From extensionmetric.com</h2><p>The site disapeared exactly one month after their email, almost like they weren't planning on paying anything after all... Here's the <a href="https://pastebin.com/dUXNDfNs">code</a> for their sdk. This one is FAR worse than infatica. There are some calls to getAllResponseHeaders, which could mean stealing logged in accounts.</p><p><img src="https://user-images.githubusercontent.com/12688112/105615170-8b670d00-5d9c-11eb-8f4d-9b9fe0c4a6e9.png" alt="scam"><img src="https://user-images.githubusercontent.com/12688112/105615192-bb161500-5d9c-11eb-8185-2ff28ac67a1b.png" alt="scam"></p><h2>From datos.live:</h2><p><img src="https://user-images.githubusercontent.com/12688112/105609313-6d86b180-5d76-11eb-8eb5-540e2ca76391.png" alt="scam"></p><h2>From admedia.com:</h2><p><img src="https://user-images.githubusercontent.com/12688112/105428058-8d09c700-5c1c-11eb-861a-30af42eb7bfe.png" alt="scam"></p><h2>From invokevision.com/invoke.vision:</h2><p><img src="https://user-images.githubusercontent.com/12688112/105428076-998e1f80-5c1c-11eb-8fce-d1f457bdd133.png" alt="scam"></p><h2>From admitad.com:</h2><p><img src="https://user-images.githubusercontent.com/12688112/105428131-b62a5780-5c1c-11eb-9c7a-dde5c23b8bc1.png" alt="scam"></p><h2>From monetisationsolutions@gmail.com:</h2><p><img src="https://user-images.githubusercontent.com/12688112/105428492-7dd74900-5c1d-11eb-842f-552131926ad5.png" alt="scam"></p><h2>From sponsoredsearchsolutions@gmail.com:</h2><p><img src="https://user-images.githubusercontent.com/12688112/105428629-be36c700-5c1d-11eb-8408-88bce74574a8.png" alt="scam"></p></div></div></div>]]>
            </description>
            <link>https://sponsor.ajay.app/emails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25884338</guid>
            <pubDate>Sat, 23 Jan 2021 17:37:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi 4 Kubernetes Cluster with x86 Support]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25884318">thread link</a>) | @patelajay285
<br/>
January 23, 2021 | https://ajayp.app/posts/2020/06/raspberry-pi-4-kubernetes-cluster-with-x86-support/ | <a href="https://web.archive.org/web/*/https://ajayp.app/posts/2020/06/raspberry-pi-4-kubernetes-cluster-with-x86-support/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The new Raspberry Pi 4 Model B can perform extremely well in an on-premise server cluster as a replacement for cloud services like AWS. The usual drawback is the lack of x86 support given the Linux ARM package ecosystem is still nascent. I’ve <a href="#running-x86-on-raspberry-pi">hacked in x86 capabilities</a> resembling Apple’s <a href="https://www.theverge.com/21304182/apple-arm-mac-rosetta-2-emulation-app-converter-explainer">Rosetta 2</a>.</p><h2 id="specs">Specs</h2><figure><img src="https://media.ajayp.app/posts/2020/06/cluster.gif" loading="lazy" alt="Raspberry Pi 4 Cluster" title="Raspberry Pi 4 Cluster" width="300"><figcaption><span>Raspberry Pi 4 Cluster</span>
4 Raspberry Pi 4’s, a network switch, a USB power supply, and a power strip</figcaption></figure><p>I’ve replaced using AWS for smaller projects and development using this 16 core, 20GB RAM, 512GB of storage cluster.</p><p>The setup of the instances in the cluster are:</p><ul><li><strong>main:</strong> <a href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/?variant=raspberry-pi-4-model-b-8gb">Raspberry Pi 4 - Quad Core - 8GB RAM</a>, 256GB SD<ul><li>Kubernetes master</li><li>Kubernetes node</li><li>s3fs mount</li><li>GitLab CI Runner</li><li>Jump server for VPN and Traefik reverse proxy</li></ul></li><li><strong>s1:</strong> <a href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/?variant=raspberry-pi-4-model-b-4gb">Raspberry Pi 4 - Quad Core - 4GB RAM</a>, 64GB SD<ul><li>Kubernetes node</li><li>s3fs mount</li></ul></li><li><strong>s2:</strong> <a href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/?variant=raspberry-pi-4-model-b-4gb">Raspberry Pi 4 - Quad Core - 4GB RAM</a>, 64GB SD<ul><li>Kubernetes node</li><li>s3fs mount</li></ul></li><li><strong>w1:</strong> <a href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/?variant=raspberry-pi-4-model-b-4gb">Raspberry Pi 4 - Quad Core - 4GB RAM</a>, 128GB SD<ul><li>Kubernetes node</li><li>s3fs mount</li></ul></li></ul><p>The <strong>main</strong> instance serves as the jump server and is the <a href="#networking">only box exposed</a> to the external internet. The rest proxy through <strong>main</strong>. It has the highest RAM and largest storage since it needs to run multiple GitLab CI build jobs, perform proxying to the other instances, and run a VPN so I can access the local network from anywhere. It also acts a Kubernetes node, but typically doesn’t host anything unless the others are full.</p><p>The <strong>s1</strong> and <strong>s2</strong> instances are meant for hosting applications via Kubernetes.</p><p>The <strong>w1</strong> instance can be used for hosting applications via Kubernetes. But, it is more of a general purpose box to SSH into for ad-hoc Linux work, use as a <a href="https://www.docker.com/blog/how-to-deploy-on-remote-docker-hosts-with-docker-compose/#:~:text=A%20remote%20Docker%20host%20is,remote%20host%20in%20several%20ways.">remote Docker host</a>, and run long-running jobs or fan-spinning jobs I don’t want to run on my MacBook Pro.</p><h2 id="hardware">Hardware</h2><h3 id="storage">Storage</h3><p>For storage I am using <a href="https://www.amazon.com/SanDisk-256GB-Extreme-UHS-I-SDSDXXY-256G-GN4IN/dp/B07H9VX76D/ref=sr_1_2?crid=GZY4QWXOYYJR&amp;dchild=1&amp;keywords=sandisk+sdxc+card&amp;qid=1610551297&amp;sprefix=sandisk+sd+cards%2Caps%2C160&amp;sr=8-2">SDXC flash memory cards</a> instead of an external hard drive to keep it portable and fast. SDXC cards, however, can be prone to failure on heavy read/write workloads. I haven’t had too much of a problem with this though, using reputable cards from a manufacturer like SanDisk lowers the odds of a card failure. Any vital data is placed in or backed up to <a href="#system--storage">the s3fs mount</a> regularly.</p><h3 id="network-switch">Network Switch</h3><p>At the bottom, I am using a <a href="https://www.amazon.com/NETGEAR-8-Port-Gigabit-Ethernet-Unmanaged/dp/B07PFYM5MZ/ref=sr_1_3?crid=3L02KVPMAQV8S&amp;dchild=1&amp;keywords=netgear+network+switch&amp;qid=1610513653&amp;sprefix=netgear+network%2Caps%2C170&amp;sr=8-3">NETGEAR Ethernet network switch</a> so I can plug in the cluster into a router using a single connection and that connection can be split 4 ways to each instance. While I always leave the instances plugged into the switch, I usually don’t connect the switch to a router as the instances <a href="#networking">can also connect over WiFi</a> and those speeds are tolerable most of the time.</p><h3 id="cable-management-and-power">Cable Management and Power</h3><p>In order to keep the build clean, short cables are used to connect the network cables to the network switch and the USB power cables to the reliable <a href="https://www.amazon.com/Anker-10-Port-Charger-PowerPort-iPhone/dp/B00YRYS4T4/ref=sr_1_13?crid=1KU57ZAEHMG8T&amp;dchild=1&amp;keywords=anker+usb+power+supply&amp;qid=1610513955&amp;sprefix=anker+usb+c+power%2Caps%2C187&amp;sr=8-13">Anker USB power supply</a>. Any longer cables are wound, zip-tied, and hidden in the back.</p><p>Since both the network switch and the USB power supply have an AC adapter, I attached a <a href="https://www.amazon.com/JSVER-Portable-Desktop-Charging-Station/dp/B074KBN8FY/ref=sr_1_11?dchild=1&amp;keywords=mini+power+strip&amp;qid=1610514053&amp;sr=8-11">mini power strip</a> at the top that they both plug into, so there is only one external power cable coming out of the otherwise self-contained cluster that needs to be plugged into the wall.</p><h2 id="system--storage">System &amp; Storage</h2><p>The system runs <a href="https://ubuntu.com/download/raspberry-pi">Ubuntu Server Edition for Raspberry Pi</a>. I have flashing scripts that can flash SDXC cards with the operating system and custom initialization scripts for each instance. The initialization scripts handle numerous things including:</p><ul><li>Installing and running instance specific applications (<a href="https://microk8s.io/">Kubernetes via microk8s</a>, <a href="https://docs.gitlab.com/runner/install/index.html">GitLab CI Runner</a>, <a href="https://doc.traefik.io/traefik/v2.0/getting-started/install-traefik/">Traefik</a>, <a href="https://github.com/hwdsl2/docker-ipsec-vpn-server">VPN server</a>, etc.) and polls for updates to the initialization scripts using a cron so I can modify the software stack without re-flashing.</li><li>Mounting an S3 bucket via <a href="https://github.com/s3fs-fuse/s3fs-fuse">s3fs</a> for remote storage and shared storage between the cluster instances.</li><li>The entire operating system is commited to a Git repository at the root <code>/</code>. This saves a checkpoint of the server’s file system before anything else is installed. Then, with a script containing some simple <code>git</code> commands I can blow everything away if I need to restore and start an instance over from scratch without having to pop out the SDXC card and re-flash. This can be tricky since <code>git</code> isn’t made for volatile use cases like this, but it has worked suprisingly well with a proper <code>.gitignore</code> file.</li></ul><h2 id="networking">Networking</h2><p>The initialization scripts automatically connect to WiFi so an Ethernet connection is not required, but can be used.</p><p>The <strong>main</strong> instance is exposed to the external network. The router port forwards specific ports to the <strong>main</strong> instance and other instances are proxied to <strong>main</strong> via Kubernetes and then Traefik exposes Kubernetes services and the VPN server to the external internet on <strong>main</strong>. The <strong>main</strong> instance updates a Route53 DNS record with its public IP address every few minutes as a method of <a href="https://en.wikipedia.org/wiki/Dynamic_DNS">dynamic DNS</a>.</p><p>Traefik and/or Kubernetes with <a href="https://cert-manager.io/docs/installation/kubernetes/">cert-manager</a> automatically issues TLS certificates for applications using <a href="https://letsencrypt.org/">Let’s Encrypt</a>.</p><p>Finally, instances can be accessed at hostnames like <code>main.local</code> or <code>s1.local</code> on the local network for SSH access automatically because the instances will publish themselves via the <a href="https://wiki.archlinux.org/index.php/avahi">Avahi daemon</a> using the <a href="https://en.wikipedia.org/wiki/Bonjour_(software)">Bonjour/Zeroconf protocol</a>.</p><h2 id="running-x86-on-raspberry-pi">Running x86 on Raspberry Pi</h2><p>The biggest downside to running on Raspberry Pi right now is the fact that it runs on ARM. That means many GitLab CI builds will fail since the Docker images might only be available for x86. There’s reason to believe this might change since Apple’s new chips are ARM-based and that will surely push adoption forward.</p><p>For now, however, I implemented a solution similar to Apple’s <a href="https://www.theverge.com/21304182/apple-arm-mac-rosetta-2-emulation-app-converter-explainer">Rosetta 2</a> for running x86 applications on ARM. I use <a href="https://wiki.debian.org/QemuUserEmulation">QEMU’s user emulation</a> along with the <a href="https://en.wikipedia.org/wiki/Binfmt_misc"><code>binfmt_misc</code></a> capability of the Linux kernel to transparently run x86 executables on the instances. This can also be done to <a href="https://github.com/multiarch/qemu-user-static">enable running and building x86 Docker images</a>.</p><p>However, just doing this, doesn’t seamlessly work as dynamically linked binaries need to be able to access x86 shared libraries not ARM ones. In order to solve this, I download a x86 version of the same Ubuntu Server image and place the files in a directory <code>/x86_root/</code>. Then, I use <code>chroot</code> to run the x86 version of <code>/x86_root/bin/bash</code> against <code>/x86_root/</code>. The result is a nice working x86 shell on your ARM-based Raspberry Pi!</p><p>I go one step further and wrap running the shell with <code>chroot</code> into an executable script. I create a new SSH user <code>ajay-x86@</code> that allows me to SSH and drop directly into an x86 shell instead of the native ARM shell I would get if SSH into <code>ajay@</code>.</p><p>The whole solution is elegant, simple, and has worked extremely well in my usage.</p><h2 id="casing-and-cooling">Casing and Cooling</h2><p>The Pi boards are cased for protection along with a fan to prevent throttling of the CPU. The fan usually keeps it below $50^{\circ}$ celsius on idle and $70^{\circ}$ celsius at peak.</p><p>All of the different boxes are attached together using <a href="https://www.amazon.com/gp/product/B07JHQJHP4/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">ceramic magnets</a> (which are glued to the surfaces with a <a href="https://www.amazon.com/gp/product/B00KPYB05A/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">cyanoacrylate glue</a>). This allows them to be disassembled and quickly snapped back together for easy portable transport in a smaller container.</p><figure><img src="https://media.ajayp.app/posts/2020/06/magnets.gif" loading="lazy" alt="Magnetic Connectors" title="Magnetic Connectors" width="200"><figcaption>Yeah, <a target="_blank" href="https://youtu.be/J0IqVC8mTwk?t=149">magnets</a>.</figcaption></figure><h2 id="cost">Cost</h2><p>All in all, the system cost around ~$600. The equivalent instances on AWS would cost around (without accounting for bandwidth / storage costs):</p><p>$$ 1 \space\text{8GB instance} * $0.05\space/\space\text{hour} * 24 * 30 * 12 $$
$$ +\space 3 \space\text{4GB instances} * $0.04\space/\space\text{hour} * 24 * 30 * 12 $$
$$ = $1,468.80\space/\space\text{year} $$</p><p>Yes, you could likely optimize this cost a little bit using RIs or a different host, but as a rough calculation, it works out to be much more affordable (especially over multiple years) and you get to avoid the suprise bills of AWS services.</p><p>But, you should still probably only use this for development or individual use cases, even though it can be served to the internet.</p><h2 id="size">Size</h2><p>Finally, for a sense of scale, the server is actually not that large and can be tucked away pretty easily especially since it can connect via WiFi.</p><figure><img src="https://media.ajayp.app/posts/2020/06/server_scale.jpg" loading="lazy" width="300"></figure></div></div>]]>
            </description>
            <link>https://ajayp.app/posts/2020/06/raspberry-pi-4-kubernetes-cluster-with-x86-support/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25884318</guid>
            <pubDate>Sat, 23 Jan 2021 17:36:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Have you ever tried blocking WhatsApp from your router?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25884289">thread link</a>) | @rukshn
<br/>
January 23, 2021 | https://ruky.me/2021/01/23/have-you-ever-tried-blocking-whatsapp-you-probably-cant/ | <a href="https://web.archive.org/web/*/https://ruky.me/2021/01/23/have-you-ever-tried-blocking-whatsapp-you-probably-cant/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>In a previous post I wrote that I live in a part of the world that <a href="https://ruky.me/2020/12/28/sri-lanka-need-unlimited-internet-connections/" data-type="post" data-id="107">does not provide unlimited internet</a>.</p>
<p>This means data is valuable, and if I run out of data, I have to pay a premium amount to activate a data add-on which can be quite expensive. There is one router at our apartment, and we all share the data among ourselves, and we hope that we are all using in a fair manner without over spending on streaming, or downloads, in an unfair way. </p>
<p>The easiest way for anyone to do is use the nighttime data for their streaming and downloads, and leave to peak day time data for office and other important work. (Yes if you are reading this from USA, we have peak and off peak time data for home broadband)</p>
<p>A detailed usage report provided by my ISP suggested to me that there is a WhatsApp addict in my apartment, who is spending large amount of data for WhatsApp video calls.</p>
<p>Since I’m the person who is paying the internet bill, and I need data for more important work than making WhatsApp video calls, I wanted a way to stop people from spending my data in unnecessarily ways, and use their own mobile data if they have to make WhatsApp or any other video calls.</p>
<p>Since I can’t go and ask from each and every individual whether they are spending too much time on WhatsApp video calls, I decided to block all WhatsApp communications at the router level.</p>
<p>Initially I thought this would be a walk in the park, just log in to my router dashboard, and block the WhatsApp URL, IP addresses and ports. Just a two minute job.</p>
<p>But this lead me to rabbit hole that too more than several hours, and made me yield without finding a solution.</p>
<h2>Google search</h2>
<p>A search on Google shows that people have been asking for a way to block WhatsApp, going back to several years.</p>
<p>The first approach which I found in a StackOverflow answer was to block the domain <strong><em>c.whatsapp.net </em></strong> according to the answer, this is the domain which handshakes at initiation of the app. And according to the poster, if we can block this domain, we would be able to block initiation a connection to WhatsApp server, and therefore successfully block WhatsApp.</p>
<p>I flagged the domain and tested, but to it did not prove to successfully block WhatsApp.</p>
<p>So I decided to search even further, another <a href="https://security.stackexchange.com/questions/203475/how-to-block-whatsapp-traffic-in-tp-link-router" target="_blank" rel="noreferrer noopener">answer also posted on StackOverflow</a> told me to block some ports, with TCP and UDP connections. These included TCP ports 5222, 5223, 5228 and 3478.</p>
<p>I painstakingly blocked all upstream and downstream TCP and UDP connections from my router, hoping it would block WhatsApp. But that did not also proved to be effective.</p>
<h2>Trying to find an IP addresses</h2>
<p>There has to be a way to block WhatsApp right? So why can’t I find an IP address or list of IP addresses, that I can block from my router, and finally block WhatsApp for good?</p>
<p>There was one IP address range that I found in the same SO answer, 31.13.64.0/18.</p>
<p>So I decided to block the IP addresses, and tested to see if it works, but unfortunately that also did not seem to work.</p>
<p>So I did further digging, and came to the GitHub post, which showed a comprehensive list of domains and IP addresses, that according to the poster, should be able to successfully block WhatsApp, or most of the connections to WhatsApp.</p>
<p><a href="https://github.com/ukanth/afwall/wiki/HOWTO-blocking-WhatsApp">https://github.com/ukanth/afwall/wiki/HOWTO-blocking-WhatsApp</a></p>
<p>There it seems WhatsApp has multiple domains from c.whatsapp.net to c20.whatsapp.com and e.whatsapp.net to e20.whatsapp.com.</p>
<p>Also multiple IP ranges, and ports, but even though I tried all of them, none seemed to work. Why can’t I block a simple app from accessing though my router?</p>
<p>I guess they may have changed their domains, or added more domains and IP addresses by now, since WhatsApp has grown in popularity since most of these answers were posted on different forums.</p>
<h2>WhatsApp will tell you their IPs, only if you pay</h2>
<p>It seems like WhatsApp shares there IP addresses only to network operators and if you pay them to do it. </p>
<blockquote><p>WhatsApp is currently providing special pricing campaign service for Mobile operators, the IP pool is only available for those operators. Please note that we have migrated the latest IP pools of WhatsApp to Facebook Mobile Partner Portal and the IP pool update process has been fully automated.</p><cite><a href="https://www.whatsapp.com/cidr.txt" target="_blank" rel="noreferrer noopener">https://www.whatsapp.com/cidr.txt</a></cite></blockquote>
<p>So there is no way for me to know what are the IP addresses and ports that I should block in order to prevent WhatsApp from using my network, without randomly blocking ports and IPs and breaking my access to internet.</p>
<p>It seems almost all the posts I found on the internet, the people who originally asked the question also did not find a clear way to block WhatsApp. So I guess it’s not just me.</p>
<p>So how would you block WhatsApp if you faced with a similar situation? If you want your employees to stop using WhatsApp or other IM service during their working hours?</p>
<p>I’m left with no other option but to change my router password, so no one else can access internet via my router and my internet connection.</p>
</div></div>]]>
            </description>
            <link>https://ruky.me/2021/01/23/have-you-ever-tried-blocking-whatsapp-you-probably-cant/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25884289</guid>
            <pubDate>Sat, 23 Jan 2021 17:34:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[German Greens go nuclear over call to renew NATO vows]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25884233">thread link</a>) | @Tomte
<br/>
January 23, 2021 | https://www.politico.eu/article/german-greens-go-nuclear-over-call-to-renew-nato-vows/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/german-greens-go-nuclear-over-call-to-renew-nato-vows/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									
							<div id="amazon-polly-audio-table">
				<p>Press play to listen to this article</p>
				
		</div>


<p>BERLIN — A call for Berlin to renew its commitment to NATO’s nuclear defense in a gesture of solidarity with the United States has prompted a heated backlash among Germany’s Greens, the party seen as the likely kingmaker in the country’s next government.&nbsp;</p>



<p>A high-profile group of German and American academics and strategic advisers delivered the NATO call in a more than 8,000-word&nbsp;<a href="https://anewagreement.org/en/" target="_blank">paper</a>&nbsp;titled “More Ambition, Please!,” urging Berlin to seize the moment presented by the change in administration in Washington.</p>



<p>“The erosion of transatlantic relations is a strategic crisis for Germany,” the signatories argue in a prelude to specific policy recommendations for transatlantic cooperation on everything from climate change to trade. “Without this alliance, a stable and united Europe cannot be sustained, and neither can the international order be renewed.”</p>



<p>While such conclusions may sound self-evident to American ears, they are not universally shared in Germany, especially when it comes to the country’s role in NATO and in ensuring Europe’s nuclear defense.&nbsp;</p>



<p>Those questions remain particularly contentious in the Green party, which, despite moderating its stances on many policy fronts in recent years, never abandoned its pacifist, antiwar roots. Support for the transatlantic declaration by moderate forces in the party triggered a fierce reaction by leading members of the Greens’ left wing, underscoring the difficulty that lies ahead for the Biden administration as it seeks to repair and renew America’s strategic bonds in Europe following the divisive Trump years.&nbsp;</p>



<p>“I’m very irritated,”&nbsp;Agnieszka Brugger,&nbsp;deputy leader of the Greens’ parliamentary group,&nbsp;<a href="https://www.sueddeutsche.de/politik/gruene-heinrich-boell-stiftung-verteidigungspolitik-1.5182258" target="_blank">told</a>&nbsp;the daily Süddeutsche Zeitung. She said she was especially annoyed that the paper was supported by Ellen Ueberschär, the co-head of the Heinrich Böll Stiftung, the Greens’ de facto in-house think tank (Ueberschär not only signed the controversial paper, she co-wrote an&nbsp;<a href="https://www.tagesspiegel.de/politik/transatlantisch-traut-euch-wir-brauchen-eine-neue-uebereinkunft/26827522.html" target="_blank">op-ed</a>&nbsp;in Berlin’s Tagesspiegel encouraging others to embrace the initiative as well.).&nbsp;&nbsp;</p>



<p>The paper’s signatories – a group that includes the likes of James D. Bindenagel, a retired American ambassador who spent much of his career in Germany, and Boris Ruge, a German ambassador currently serving as deputy head of the&nbsp;<a href="https://securityconference.org/en/" target="_blank">Munich Security Conference</a>&nbsp;— acknowledge the corrosive effect Donald Trump had on the alliance, while also highlighting “German neglect and failures” on defense spending and in pursuing the controversial&nbsp;<a href="https://www.politico.eu/article/angela-merkel-joe-biden-nord-stream-2/">Nord Stream 2</a>&nbsp;pipeline project with Russia.&nbsp;&nbsp;</p>



<p>The group ascribes a central role to Germany in Europe’s broader effort to keep the U.S. engaged in the region, saying that in order to meet that responsibility, Germany should accelerate its push to increase defense spending to ensure “a deployable military.” Critics say Germany’s military, known as the Bundeswehr, has been plagued for years by underfunding and chronic mismanagement.&nbsp;</p>



<p>“A deployable military gives weight to diplomacy, adds an indispensable contribution to transatlantic credibility, strengthens the deterrence capability of NATO, and consequently defends the freedom of German citizens,” the paper argues.&nbsp;</p>



<p>A key aspect of Germany’s mission should be to remain engaged in NATO’s “nuclear-sharing arrangements,” a reference to Germany’s longstanding commitment to deliver U.S. atomic bombs in the event of an attack. To maintain that role, Berlin needs to replace the country’s aging fleet of combat aircraft equipped to carry out the role.&nbsp;</p>



<p>“The U.S. nuclear shield is essential to all non-nuclear NATO countries in Europe,” the paper says.&nbsp;“It should exist for as long as nuclear weapons exist and the nuclear threat looms.”&nbsp;</p>



<p>But many on Germany’s left, including factions in both the Green party and the Social Democrats, oppose the move and want the U.S. to remove the nuclear warheads it has stationed in Germany.&nbsp;&nbsp;&nbsp;</p>



<p>While Greens have enshrined the goal of a nuclear-free Europe into their party platform, some in the party see the weapons as a necessary evil for as long as Europe remains threatened by Russia.&nbsp;</p>



<p>That pragmatic approach to security has helped broaden the party’s appeal to centrist voters in recent years and is one reason why many political observers believe it is likely to enter a coalition with the center-right Christian Democrats, Germany’s dominant political force, after national elections in the fall. The Greens are currently polling at about 20 percent, more than double their showing in the last election in 2017.&nbsp;</p>



<p>Despite the party’s newfound mainstream appeal, the friction over Germany’s continued role in guaranteeing NATO’s nuclear deterrent suggests that Green acceptance of existing norms is far from settled.</p>



<p>Many in the party believe Germany should abandon NATO’s spending target, which calls on members to strive towards investing 2 percent of their GDP on defense. Brugger, in her Süddeutsche interview, called the focus on military spending “false and dangerous.”&nbsp;</p>



<p>Some Greens also want Germany to sign the United Nations’&nbsp;<a href="https://www.un.org/disarmament/wmd/nuclear/tpnw/" target="_blank">nuclear ban treaty</a>, which goes into effect on Friday.&nbsp;</p>



<p>Among them is Jürgen Trittin, a veteran Green MP and former minister. He&nbsp;<a href="https://twitter.com/JTrittin/status/1352367821003628547" target="_blank">tweeted</a>&nbsp;that he could only “slap his forehead” over Ueberschär’s support for the initiative to renew the transatlantic alliance.&nbsp;</p>



<p>While the Greens’ moderate and more ideological wings have a long history of locking horns on policy issues, the military question is particularly explosive because opposition to all things nuclear lies at the core of the party’s identity.</p>



<p>Even so, the party has a history of breaking with orthodoxy, most notably by&nbsp;<a href="http://ghdi.ghi-dc.org/sub_document.cfm?document_id=3723" target="_blank">supporting</a>&nbsp;NATO’s 1999&nbsp;military intervention in Kosovo. If the Greens are to join the conservatives in forming a government after the September election, the consensus-driven party may have no choice but to redraw its red lines once again.&nbsp;&nbsp;&nbsp;</p>
								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/german-greens-go-nuclear-over-call-to-renew-nato-vows/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25884233</guid>
            <pubDate>Sat, 23 Jan 2021 17:28:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VisualAge for Java 1.0 – Let the Future Begin (1997)]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25884159">thread link</a>) | @rufus_foreman
<br/>
January 23, 2021 | https://www.tug.ca/articles/Volume13/V13N1/V13N1_Jenkins_VisualAge-for-Java.html | <a href="https://web.archive.org/web/*/https://www.tug.ca/articles/Volume13/V13N1/V13N1_Jenkins_VisualAge-for-Java.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

	<img src="https://www.tug.ca/articles/graphics/TUGLOGO_red.gif" alt=" Logo: TUG ">
	<span size="5" color="teal"><b>TORONTO USERS GROUP <i>for Midrange Systems</i></b></span><b><br>
	<span size="5" color="black">TUG </span></b>
	<span size="5" color="maroon"><b><i>e</i></b></span>
	<span size="5" color="black">-server magazine</span><h3>
September 1997: Volume 13, Number 1
	</h3><hr>



	<p>
<img src="https://www.tug.ca/articles/graphics/Verdana_I.gif">
n a recent interview, Bill Zeitler, IBM's General Manager for the AS/400 Division, was asked a very blunt question: What are you betting the AS/400 business on today?  His answer, in all of two words, was "Network Computing".  In the next breath, he explained that he wasn't just talking about connectivity, but about conducting business electronically, over the Internet, and largely by virtue of a superior Java environment.

</p><p>
It's remarkable to think that IBM is basing so much of its future on, of all things, a programming language, and on a programming language that not only didn't exist a few years ago, but also was developed by an IBM competitor, Sun Microsystems.  What on earth could a new programming language offer to merit such attention?  Some new killer op-code?  A revolutionary new way to program a do-loop?

<img src="https://www.tug.ca/articles/Volume13/V13N1/V13N1_Jenkins_Fig-1.jpg" alt="Figure 1. ">

</p><p>
The answer is that there is not much in the Java language itself to write home about - it is a slightly simplified and streamlined version of C++, with some features that make it suitable for running applications over a network - the Internet, for an obvious example.  However, Java does have the revolutionary attribute of being hardware platform and operating system independent: "Write Once, Run Anywhere" is the battle cry of the Java faithful, and when you think about it, it certainly would change the industry landscape if hardware platforms and their respective operating systems became the handmaidens of applications, not vice versa.  Put a Java applet on your Web page, and it can be used, unchanged, by a Windows user in Buenos Aires, a Mac bigot in Australia, a Unix nut in Sweden, and an OS/2 diehard in Singapore (and all this with no royalties accruing to Microsoft!)

</p><p>
Thus, Java has the potential, at least, to break the hold that the hardware and operating system monoliths have on the computer world, and could make hardware and software tycoons like Steve Jobs and Bill Gates as obsolete in the 21st century as railway barons have become in the 20th.  From IBM's point of view, if business application software were uncoupled from hardware platforms and operating systems, then computer systems could be sold on their own merits - robustness, security, manageability, etc. - and IBM no doubt feels that with the AS/400 they can compete quite well on that playing field.

</p><p>
Computer industry geopolitics aside, Java has become the Next Big Thing in the computer field - and if you're not constantly eager to get in on the Next Big Thing (even before you've fully mastered the Previous Three Big Things), then why the heck did you choose this industry to work in!

<img src="https://www.tug.ca/articles/Volume13/V13N1/V13N1_Jenkins_Fig-2.jpg" alt="Figure 2. ">

</p><p>
Since Java was introduced by Sun Microsystems, the Java Development Kit (JDK) has been available to be downloaded free over the Internet.  The JDK (now at version 1.1) includes a Java compiler, an applet viewer, and standard class libraries.  However, it is strictly command line based.  If you want to design the graphical interface of your application on-screen, as well as take advantage of the other benefits of graphical integrated development environments, you have to open your wallet a bit and look at something like Borland's JBuilder, Microsoft's Visual J++, or Symantec's Visual Café.  Or, as of July 25, IBM's Visual Age for Java.

</p><p>
The latest in IBM's Visual Age series of development environments had been available in a beta test version for several months, but recently Version 1.0 was officially released.  It's available in two flavours: the Professional Edition, and the pricier Enterprise Edition, which adds support for team development, as well as "Enterprise Access Builders" - tools for developing components to connect a Java client to various database platforms.  Within the Visual Age for Java environment you can create both applications and "applets" - Java programs that can be embedded in an HTML document and run by Web browsers which implement the JVM (Java Virtual Machine).  (Note that Visual Age for Java includes its own JVM as well as an applet viewer, so you can view and test your programs locally).  VA for Java also has a version control capability, and a debugger is included.

</p><p>
The Professional Edition is priced to compete with its counterparts mentioned above - that is, in the 100 - 200 dollar range per license.  However, if even that amount is a deterrent to you, the neophyte dabbler in Java, you may be interested to know that you can download a free copy of the Entry Edition - which contains all the functionality of the Professional Edition, minus only the documentation and online help, and limited to the creation of 100 classes.  In the remainder of this article, I'll show how you can download and install the Entry Edition of Visual Age for Java, and have a quick look at some of its features.

</p><p>
First, you'll have to consider the prerequisites, which are pretty significant, particularly for RAM.  You'll need Windows 95 or Windows NT 4.0 or OS/2 Warp V4, an SVGA display, and, IBM says, 32MB of RAM (with 48MB recommended), at least 45MB of free disk space for the software (with an additional 30MB free disk space for swapping), and lastly, an unzip program.

</p><p>
If you're still standing, here's where you can find the Entry Edition on the Internet: <a href="http://www.software.ibm.com/ad/vajava" target="_blank"> www.software.ibm.com/ad/vajava</a>.  (Before downloading it, you should uninstall any Beta versions of the product from your system).  The Windows version of the download file (wenty100.ZIP) is a single .ZIP file almost 22MB in size - so you'll finally be able to wallpaper that bathroom while it's downloading.  Download it into a temporary directory, then unzip it.  One of the unzipped files is a setup.exe file, which can be invoked to complete the installation.  There is also an install.txt file with further installation and troubleshooting information.
After a successful installation, you'll have an "IBM Visual Age for Java" icon on your desktop to invoke the program.  It will bring up the Workbench window seen in Figure 1.  It will also bring up the "Quick Start" window seen in Figure 2 (which also can be brought up at any time from the Window… Quick Start… menu option).  If you select to create a new applet, as shown, you will be taken to a Smart Guide window (comparable to a Windows 95 "wizard"), which prompts you for applet name, project, and package, and whether you want to design the applet visually, or write source code for it.  If you select the former, the Visual Composition Editor is invoked (Figure 3).

<img src="https://www.tug.ca/articles/Volume13/V13N1/V13N1_Jenkins_Fig-3.jpg" alt="Figure 3. ">

</p><p>
The Visual Composition Editor allows you to create a graphical interface, with all the usual components - buttons, lists, menus, entry fields, etc., which it calls (in yet another of those coffee metaphors which are already becoming tiresome) "beans".  These are selectable from the left hand side of the window.  Beyond just laying out an application window, basic application logic can be constructed by making connections between components in the window (marked out with the dashed line), or with non-visual components outside the window.  In the example shown, the Remove button has been connected to the list, to indicate that clicking Remove should delete the highlighted item from the list.  The source code for this event logic is then generated automatically.
With Version 1.0, "beans" for all the standard Java Class Libraries are available.  In future, more sophisticated - and AS/400-specific - components will accessible, allowing, for example, access to files and fields in DB2/400, analogous to using externally described files in RPG/400.

</p><p>
Regardless of how many pre-built components, or "beans", are available, there will always be a requirement for new classes in any custom application.  VA for Java of course enables the creation of such classes in the old fashioned way - typing source code - with Smart Guides that prompt you and provide some of the fundamental class definition code.  And even if you are programming the old fashioned way, the VA for Java environment makes life easier by making instantly accessible the definitions of all the classes on the system and their methods, organized by their respective packages, whether standard Java classes or your own previously created classes (see again Figure 1).  If, like me, you've tried to learn and program Java from one of the many books available today, you may have been frustrated by not having access to such comprehensive documentation of the numerous standard Java classes.

</p><div><p>
What I've given above is just a quick overview of IBM's Java development environment - and admittedly not much reference is made to where the AS/400 comes into all this.  The AS/400, as of V3R7, does not currently natively support Java applications - a coming release of OS/400 will rectify that.  And as of the time of writing this article, much of the AS/400-specific Java development capability is still under construction.  In future articles, I hope to explore more AS/400-related capabilities of Java as they become available.  In the meantime, the latest scoop from IBM is of course available on the Internet, at www.software.ibm.com/ad/vajava.   
 



	<span>T</span>
	<span>&lt;</span>
	<span>G</span></p></div><hr>

	</div>]]>
            </description>
            <link>https://www.tug.ca/articles/Volume13/V13N1/V13N1_Jenkins_VisualAge-for-Java.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25884159</guid>
            <pubDate>Sat, 23 Jan 2021 17:20:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MySQL Charset/Collate]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25884094">thread link</a>) | @chenster
<br/>
January 23, 2021 | http://mysql.rjweb.org/doc.php/charcoll | <a href="https://web.archive.org/web/*/http://mysql.rjweb.org/doc.php/charcoll">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<i>Brought to you by Rick James</i><br>
<h2><a name="caveat">CAVEAT</a></h2><a name="caveat">
<br>
This one of my pages is not well maintained.  This is a jumble of poorly-organized information; some info is quite useful, some is not.  I keep it around only because there of the few good nuggets buried in it.
</a><a name="the_problems_being_addressed"><h2>The problems being addressed</h2>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;Your web page the wrong characters coming out where accented letters should be.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;You are upgrading from MySQL 4.0, where characters were simply bytes.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;You are trying to wrap your head around how MySQL handles CHARSET / COLLATION.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;You upgraded, and now you are getting garbage.
<p>

Please read most of this document.  I know it is long (after all, I wrote it!)
But you really need to understand a lot of the pieces in it, in order
to solve your problem.
</p><p>

The tips in this document apply to MySQL, MariaDB, and Percona.
Version differences are called out where relevant.
</p></a><a name="basic_concepts"><h2>Basic Concepts</h2>
<br>
"Character" and "byte" are different!
You must understand this before continuing.
A "byte" is an a-bit thing; it is the unit of space in computers (today).
A "character" is composed of one or more bytes, and represents what we think
of when reading.
<p>

A byte can represent only 256 different values.
There are over 11,000 Korean characters and over 40,000 Chinese characters --
no way to squeeze such a character into a single byte.
</p><p>

Charset vs collation.  These are different things!
'Charset' ('character set'; 'encoding') refers to the bits used to represent 'characters'.
'Collation' refers to how those bits could be compare for inequality (WHERE)
and sorting (ORDER BY).  GROUP BY and FOREIGN KEY CONSTRAINTS can also involve collation.
And it even can involve deciding whether two different bit strings compare 'equal'.
</p></a><a name="history"><h2>History</h2>
<br>
1950's -- A character was (sometimes) represented in only 5 bits, on "paper tape"; no lowercase; had to "shift" to switch between letters and digits.
<br>
1960's -- A character was 6 bits; no lower case.  "Punched cards" were used.
<br>
1970's -- 7-bit ASCII becomes common -- that limits you to English.
And the 8-bit "byte" was invented and was coming into common usage (re: IBM 360).
<br>
1980's -- Beginning to see 8-bit encodings.  Especially since 7-bit ASCII
was wasting a bit of the omni-present "byte".
This can handle Western European accented letters.
<br>
1990's -- The computer world realizes that there are other people in
the world and embarks on Unicode and UTF8.  ("UTF" = "Unicode Transformation Format")
<p>

Meanwhile, MySQL is born,
but has enough problems without worrying about character sets.
Through version 4.0, a CHAR is just a byte.
You can put any kind of bytes, representing anything, into a VARCHAR.
Thus, begins the need for this discussion.
</p><p>

MySQL 4.1 introduced the concept of "character set" and "collation".
If you had legacy data or legacy code, you probably did not notice
that you were messing things up when you upgraded.
Or you started with 4.1 (or later) and "latin1 / latin1_swedish_ci"
and failed to notice that you were asking for trouble.
</p><p>

Today, it's pretty safe to simply lay down the law and say
"Use utf8 for all text."
If you have version 5.5.3 or later,
"Use utf8mb4 for all text."
</p><p>

Sure, there are other character sets,
and they are useful if you have a narrow focus.
But, you may as well use utf8mb4.
</p></a><a href="https://docs.python.org/2/howto/unicode.html">Another take on the History</a><a name="best_practice"><h2>Best Practice</h2>
<br>
Best practice is to go completely utf8mb4.
I will focus on utf8 and utf8mb4, but if you choose to do otherwise, keep reading;
most of this discussion can still be adapted to the charset of your choice.
<p>

For collation, probably the best 'overall' collation is utf8mb4_0900_ai_ci (if available) or utf8mb4_unicode_520_ci.
<i>0900</i> refers to UCA 9.0.  xxx_unicode_520_ci collations are based on UCA 5.2.0 weight keys: https://www.unicode.org/Public/UCA/5.2.0/allkeys.txt.
Unnumbered Collations are based on the older UCA 4.0.0.
</p><p>

A web page (if that is what you have) should begin with
</p><tt>&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;</tt>
<p>

Establish the characterset for talking to the MySQL server:
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;</p><tt>init_connect = 'SET NAMES utf8'</tt>  in my.cnf
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;<tt>SET NAMES utf8</tt> -- done immediately after connecting
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;<tt>SET GLOBAL VARIABLE character_set_...</tt> SET NAMES does the three you need.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;In some cases in your my.cnf (my.ini) file, add this under [mysql] or [client]: <tt>default-character-set = utf8</tt>
<p>

For PHP:
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;(deprecated; DO NOT USE mysql_* !) mysql interface: </p><tt>mysql_set_charset('utf8');</tt> (assuming PHP 5.2.3 &amp; MySQL 5.0.7)  Note: "mysql_" interface is deprecated.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;mysqli interface: <tt>mysqli_set_charset('utf8') function</tt>.  See </a><a href="https://secure.php.net/manual/en/mysqli.set-charset.php">mysqli_set_charset</a>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;PDO interface: set the charset attribute of the PDO dsn or via SET NAMES utf8mb4.
<a href="https://php.net/manual/en/ref.pdo-mysql.connection.php">PDO manual</a><p>

For Java (JDBC):
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;</p><tt>?useUnicode=yes&amp;characterEncoding=UTF-8</tt> in the getConnection() call.
<br>
For Hikari (perhaps):
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;<tt>spring.jpa.properties.hibernate.connection.characterEncoding=utf-8</tt>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;<tt>spring.jpa.properties.hibernate.connection.CharSet=utf-8</tt>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;<tt>spring.jpa.properties.hibernate.connection.useUnicode=true</tt>
<br>
(or maybe it is =yes and =utf8)
<p>

add
</p><pre>spring:
  datasource:
     connectionInitSql: "SET NAMES 'utf8mb4'"
</pre>
in the application.yml.  connectionInitSql is used by HikariCP when it open the connection.
<p>

<a href="https://stackoverflow.com/questions/31096653/jsp-writing-utf8-to-mysql-wont-work">For Java/JSP</a><br>
<a href="https://stackoverflow.com/a/45305951/1766831">Something about 'filters'</a></p><p>

SET NAMES can be invoked by your language just like
other non-SELECT commands: mysqli_query(), do(), execute(), etc.
</p><p>

I digress here for a note about GRANTs.
'root', and any other user from </p><tt>GRANT ALL ON *.*</tt>,
because it has "SUPER" privilege, will skip the <tt>init_connect</tt>,
so that technique is not 'perfect'.
<p>

<a href="https://dev.mysql.com/doc/refman/5.7/en/charset-connection.html">SET NAMES</a></p><p>

Declare most CHAR/TEXT columns in all tables as CHARSET utf8.
Some exceptions: columns with hex (MD5, GUID), ...
These should be BINARY or CHAR charset ASCII.
</p><p>

Collation?
</p><p>

For true text, utf8_unicode_ci is best.  It handles the complex
rules of "combining chararacters", etc.
It handles essentially all languages simultaneously, but compromises on ordering.
</p><p>

utf8_general_ci is the default for utf8, so you may accidently
get this.  It is a little faster than utf8_unicode_ci and
works ok for many situations.
</p><p>

utf8_bin says to just compare the bytes.
CHAR/TEXT utf8 with utf8_bin validates (on INSERT) that the bytes comprise valid
utf8 bytes, but does not do anything useful for comparisions other than
exact (no case folding, etc) equality.
BINARY/BLOB should be usually be used instead CHAR+utf8;
this stores the bytes without any checking.
</p><p>

Alas, MySQL's collations think of case folding and accent-stripping as equivalent.
That is, there is no utf8 collation for case folding, but keeping accents distinct.
Do </p><tt>SHOW COLLATION LIKE '%cs';</tt> to see the few collations that work that way.
<p>

This document is evolving.  It started with just 'utf8', but the 'standard' is becoming 'utf8mb4'.
The document is inconsistent as to which it specifies.
If you are running MySQL before 5.5.3, you have only 'utf8'.
If you need Emoji or Chinese, then you need 'utf8mb4'.
</p><a name="conversions_and_common_errors"><h2>Conversions and Common Errors</h2>
<br>
This is a summary of how things work, and what is likely to go wrong.
<p>

There are 3 dimensions to character set problems:
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;How the client's bytes are encoded when INSERTing, and what encoding you want when SELECTing;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;What SET NAMES you use (or what the default is);
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;The CHARACTER SET on the column definition.
</p><p>

All is well if the SET NAMES agrees with the encoding of the bytes in the Client.
The column's CHARACTER SET need not agree with SET NAMES; if they differ, a conversion will be performed for you.
If your characters exist in both encodings, the conversion will be transparent.
If a source character does not exist in the target encoding
(example: when converting a Chinese character from utf8mb4 to latin1), a "?" is usually put in its place.
</p><p>

The main thing that can go wrong is that SET NAMES can disagree with the Client's bytes.
Let's walk an acute-e (é) through the INSERT and SELECT.  First, note the encodings for é:
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;Hex for latin1's 1-byte encoding: E9
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;Hex for utf8's 2-byte encoding: C3A9
<br>
(BTW, this and some other encodings are enumerated below.)
</p><p>

Case 1: SET NAMES latin1 (the default) is in effect and your application is thinking in utf8.
It INSERTs é encoded as utf8 (hex C3A9):
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;C3A9 will become two latin1 characters: 'Ã©' "on the wire".  (C3 represents Ã in latin1, etc)
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;If the CHARACTER SET for the column is latin1, then those 2 characters (2 bytes) are inserted.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;If the CHARACTER SET for the column is utf8, then they are converted to utf8: Ã ⇒ C383 and © ⇒ C289; you insert 4 latin1 characters (4 bytes: C383C289) into the table.
<br>
Continuing the case, let's do a SELECT:
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;For utf8 column, the C383C289 is converted to latin1 Ã© (C3A9) for sending across the wire to the client.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;For latin1 column, no conversion is performed, so, again, C389 goes across the wire.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;The client receives the two bytes C389, thinking it is Ã© (because of SET NAMES).  However, the rest of your application is thinking 'utf8', it sees it as é.
<br>
C383C289 is an example of what I call "double encoding" because of the
two 'wrong' conversions from latin1 to utf8.
The resulting SELECT (at least for European text) looks exactly like what you INSERTed.
However, comparisions (WHERE x&gt;y) and sorting (ORDER BY) and, in a few cases, equality (x=y) will not work as expected.
</p><p>

Now, let's flip the situation:
Case 2: SET NAMES utf8, but you are inserting é encoded as latin1 (E9):
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;SET NAMES is falsely asserting that E9 is a valid utf8 encoding of something, which it is not.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;The INSERT finishes (with a WARNING that you probably ignored), but the string is truncated before the é.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;The CHARACTER SET of the column does not matter since the string is truncated.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;⚈&nbsp;&nbsp;A SELECT will get only the truncated string.
</p><p>

Case 3: One application INSERTs and another SELECTs, but they are using different SET NAMES.
All sorts of messes can occur.
</p><p>

Case 4: You have an old latin1 table (possibly dating back to …</p></a></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://mysql.rjweb.org/doc.php/charcoll">http://mysql.rjweb.org/doc.php/charcoll</a></em></p>]]>
            </description>
            <link>http://mysql.rjweb.org/doc.php/charcoll</link>
            <guid isPermaLink="false">hacker-news-small-sites-25884094</guid>
            <pubDate>Sat, 23 Jan 2021 17:15:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simulation is easy, probability is hard]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25884023">thread link</a>) | @magni121
<br/>
January 23, 2021 | https://magnusross.github.io/posts/mc/ | <a href="https://web.archive.org/web/*/https://magnusross.github.io/posts/mc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>There are many interesting things that can be learned about probabilistic modelling from the world of trading and finance, where, perhaps due to the direct connection to very large sums of money,  attitudes to problems are generally very different to those of the typical statistician or ML practitioner. Two books I have enjoyed recently in the area are <em>The Education of a Speculator</em> by Victor Niederhoffer and <em>Fooled by Randomness</em> by Nassim Nicholas Taleb. The books are similar in many ways, both contain plenty of interesting insights into thinking probabilistically, as well as a number of cautionary tales of modelling gone wrong<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. In <em>Fooled by Randomness</em>, Taleb talks a lot about the power of simulation for probabilistic models, and how modern computers, using what he calls his “Monte Carlo Engine”, allow us to get answers from complex models that previously would have been impossible, or at least very time consuming, to solve analytically. This was fresh in my mind when I read the following passage from chapter 8 of <em>The Education of a Speculator</em> about the well known gambler’s ruin problem:</p>
<blockquote>
<p>A speculator with initial capital $C$ plays a game with a casino: he wins $£1$ each play with probability $P$ or loses $ £1$ with probability $Q=1-P$, the speculator stays in the game until his capital reaches $A$ or depreciates to $0$. It can be shown that in such a game, the speculators probability of ruin is, $$ \frac{(Q/P)^A-(Q/P)^C}{(Q/P)^A-1}$$</p>
</blockquote>
<p>This is a very good example a problem which can be solved easily with the “Monte Carlo Engine”, or simulation in plainer language, but is actually quite difficult to solve analytically. In this post we’re going to derive the formula for the probability of ruin above analytically, and calculate the probability using simulation and hopefully along the way we’ll get a feel for the advantages and disadvantages of both methods<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p>
<h2 id="simulation">Simulation<a href="#simulation" arialabel="Anchor">⌗</a> </h2>
<p>The idea behind simulation is really simple, to work out the probability that our gambler will be ruined, all we need to do is run a bunch of games in our imaginary casino, and work out the proportion of games in which the gambler loses, this then becomes our answer for the probability of ruin. We can think of each of these games as a sort of parallel universe, each is possible and distinct from the next, and taken as a whole they represent every possible situation our gambler could go through. Now you might be thinking, hang on, are there not an extremely large number (an infinite number even) of possible games? Could the gambler not keep on playing indefinitely if the correct combination of wins and losses arise such that the balance never goes higher than $A$, or lower than $0$? How are we going to simulate all of the games? The answer is that we aren’t, because this would take an infinitely long time, and so unfortunately we will never get the answer for the probability exactly correct, but we will be able to get pretty close in quite a short time. When we simulate things randomly, games that are more probable, and so contribute more to our final answer, are likely to occur even in a small number of simulations. Improbable games, such as very long games, are unlikely to occur in our simulation, this isn’t a problem though  because they naturally don’t contribute much to the final answer, so the error associated with not including them in our proportion will be small.</p>
<p>So how do we actually do the simulating? We just need to have some code that can produce randomly 1 (representing the gambler winning a play) with probability $P$ or 0 (representing the gambler losing a play) with
probability $Q$. Then we add or subtract $£1$ from the gamblers balance accordingly, we keep doing this until the balance reaches $A$, in which case we note down a win for the gambler, or $0$, where we note down a loss. All we have to do then to calculate the probability is tally up all the games the gambler lost, and then divide by the total number of games we simulated to get our estimate. The following Python code will do this for us:</p>
<div><pre><code data-lang="python"><span>from</span> scipy.stats <span>import</span> bernoulli

<span>def</span> <span>simulate_game</span>(P, C, A):    
    
    balance <span>=</span> C <span># set balance to initial capital</span>
    <span>while</span> <span>0.</span> <span>&lt;</span> balance <span>&lt;</span> A:
        <span># 1 is win, 0 is loss</span>
        outcome <span>=</span> bernoulli<span>.</span>rvs(P) 
        <span># transform to £ won or lost </span>
        balance <span>+=</span> <span>2.</span><span>*</span>outcome <span>-</span> <span>1.</span> 

    <span>if</span> balance <span>&lt;=</span> <span>0.</span>:
        <span># bankrupt, note down a loss</span>
        <span>return</span> <span>0</span>
    <span>else</span>:
        <span># balance greater than A, note down a win</span>
        <span>return</span> <span>1</span>
    
<span>def</span> <span>simulated_probability</span>(P, C, A, N<span>=</span><span>500</span>):
    wins <span>=</span> <span>0</span>
    <span># run N games</span>
    <span>for</span> i <span>in</span> range(N):
        <span># tally up the wins</span>
        wins <span>+=</span> simulate_game(P, C, A) 
    
    <span># p(loss) = 1 - p(win)</span>
    <span>return</span> <span>1</span> <span>-</span> wins<span>/</span>N 

<span>print</span>(f<span>"Probabilty of ruin: {simulated_probability(0.6, 5, 10)}"</span>)
</code></pre></div><p>Note the Bernoulli function here just produces a 1 with probability $P$, and a zero with probability $Q=1-P$ like we needed. It really is that simple! Before we look at the properties of the answers our code gives, let’s solve the problem analytically as well.</p>
<h2 id="analytical-solution">Analytical Solution<a href="#analytical-solution" arialabel="Anchor">⌗</a> </h2>
<p><em>(This section is going to be a bit more maths heavy, so if that’s not your thing then feel free to skim/skip.)</em></p>
<p>Like a lot of problems in probability, at first glance it doesn’t look too bad. Unfortunately it’s kind of hard to know where to start because of the limitless number of different games that are possible. To get going we need to use a bit of a trick<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. Let’s say the probability of winning the game when we start with capital $i$ is $P_i$ (taking $i$ to be an integer). The two possibilities for the first play of the game are:</p>
<ol>
<li>The gambler wins the first play with probability $p$ and ends up with capital $i+1$, the probability of going on to win the game from this position is then $P_{i+1}$.</li>
<li>The gambler loses the first play with probability $q=1-p$, and ends up with capital $i-1$, the probability of going on to win the game from this position is then $P_{i-1}$.</li>
</ol>
<p>We can then write $P_i$ in terms of these possible outcomes for the first play, as</p>
<p>$$ P_i = p \times P_{i+1} + q \times P_{i-1}. \tag{1}$$</p>
<p>We also know that $P_0=0$, if we have no money we have certainly lost, and $P_A=1$, if we reach capital $A$ we have certainly won. Equation 1 is called a difference equation, and it is like a discrete version of a differential equation. To solve it, we use use $p + q = 1$ to rewrite as follows,
$$(p+q)P_i =pP_{i+1} + q P_{i-1}$$
$$ \implies pP_{i+1}-pP_i=qP_{i}-qP_{i-1}$$
$$ \implies P_{i+1}-P_i=\frac{q}{p}(P_{i}-P_{i-1}) \tag{2}$$</p>
<p>Next write equation 2 as,<br>
$$ P_{j+1}-P_j = \frac{q}{p}(P_{j}-P_{j-1}) = \Big(\frac{q}{p}\Big)^2(P_{j-1}-P_{j-2}) = \dots= \Big(\frac{q}{p}\Big)^{j-1}(P_{1}-P_{0})=\Big(\frac{q}{p}\Big)^{j-1}P_{1}$$</p>
<p>for $j=1, \dots, A$, using $P_0=0$ for the final step. Next we want to use this to find a general formula for $P_i$, we are allowed to write
$$ P_i = P_i - P_0 = (P_i - P_{i-1}) + (P_{i-1} - P_{i-2}) + \dots + (P_{1} - P_{0}) $$</p>
<p>because for example the $+P_{i-1}$ cancels with the $-P_{i-1}$ and so contributes nothing overall. Subbing in equation 2 to each of the terms in brackets we get,
$$ P_i = P_1 \sum^{i-1}_{j=0}\Big(\frac{q}{p}\Big)^{j-1}$$</p>
<p>using the standard result for a finite sum of a geometric series, we get</p>
<p>$$P_i = P_1 \frac{(q/p)^i -1}{(q/p) -1}$$</p>
<p>as long as $p\neq q$. If $p=q=1/2$ then we simply get  $P_i=P_1\sum^{i-1}_{j=0}(1)=iP_1$. Now we need to get rid of the $P_1$ which we can do by using $P_A=1$. In the case $p\neq q$ we have,</p>
<p>$$ P_A = 1 = P_1 \frac{(q/p)^A -1}{(q/p) -1}$$</p>
<p>so,
$$ P_1 =  \frac{(q/p) -1}{(q/p)^A -1}$$</p>
<p>which means
$$ P_i =  \frac{(q/p) -1}{(q/p)^A -1}\frac{(q/p)^i -1}{(q/p) -1} =\frac{(q/p)^i -1}{(q/p)^A -1}.$$</p>
<p>In the case $p=q=1/2$ we have $P_A=1=A P_1 \implies P_1 = 1/A$ so $P_i = i/A$. We now have an expression for the probability of a win so to covert our answer into the probability of ruin we just subtract it from 1 to get,</p>
<p>$$ P_i = 1 - \frac{(q/p)^i -1}{(q/p)^A -1} = \frac{(q/p)^A - (q/p)^i}{(q/p)^A -1} \text{ and } P_i = 1 - \frac{i}{A} = \frac{A-i}{A} \tag{4}$$</p>
<p>in cases $p\neq q$ and $p=q=1/2$ respectively. We’ve finally made it, equation 4 is the same as the answer from <em>Education of a Speculator</em>!</p>
<h2 id="comparison">Comparison<a href="#comparison" arialabel="Anchor">⌗</a> </h2>
<p>OK so now we have methods to calculate the probability of ruin both using simulation and analytically, let’s see how they compare. Below are plots of the probability of winning the game against the probability of winning a play $P$, for starting capital $C=£8$ and $C=£1$, using 500 simulated games. We can see that there is very good agreement between the two methods.</p>

  <figure>
    <img src="https://magnusross.github.io/ruin_main.png" alt="How likely is ruin?">
    
      <figcaption>Plot of probability of ruin against probability of winning single play, for different $C$'s</figcaption>
    
  </figure>


<p>We can get a better idea about the error introduced by using the simulated method from the following plot of error against number of simulated games, with error bars computed from 5 repeats. The gradient of the graph is about 0.5 and since the axis are log scale this corresponds to the relationship $E\propto\sqrt N$, where $E$ is error and $N$ is number of games. This is consistent with the standard result for the error of a Monte Carlo estimator.</p>

  <figure>
    <img src="https://magnusross.github.io/ruin_errs.png" alt="Error from simulation.">
    
      <figcaption>Plot of error introduced by simulation methods against  number of simulated games.</figcaption>
    
  </figure>


<h2 id="conclusions">Conclusions<a href="#conclusions" arialabel="Anchor">⌗</a> </h2>
<p>I think the most important thing to consider when comparing the two solutions before we even think about errors, computation time etc, is simplicity. The code for the simulations took me less than 5 minutes to write. I spent about an hour trying to come up with an analytical solution with no luck, I then looked up the solution, and it took me quite a while longer to get my head round it. Even simple problems in probability can end up being analytically intractable, meaning no closed form solution can ever be found, let alone by me. For this reason Taleb is right to emphasize the power of the Monte Carlo engine, I hope this post has gone some way to illustrates it practical application.</p>
<p>Thanks for reading!</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote"></li></ol></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://magnusross.github.io/posts/mc/">https://magnusross.github.io/posts/mc/</a></em></p>]]>
            </description>
            <link>https://magnusross.github.io/posts/mc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25884023</guid>
            <pubDate>Sat, 23 Jan 2021 17:09:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comp Sci readings based on Halt and Catch Fire series]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25883965">thread link</a>) | @tusharchoudhary
<br/>
January 23, 2021 | https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/ | <a href="https://web.archive.org/web/*/https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="about">
      

<p>This site features a curriculum developed around the television series, <a href="https://www.google.com/search?channel=fs&amp;client=ubuntu&amp;q=halt+and+catch+fire">Halt and Catch Fire</a> (2014-2017), a fictional narrative about people working in tech during the 1980s-1990s.</p>

<p>The intent is for this website to be used by self-forming small groups that want to create a “watching club” (like a book club) and discuss aspects of technology history that are featured in this series.</p>

<p>There are 15 classes, for a “semester-long” course:<br>
~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/01.html">#01</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/02.html">#02</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/03.html">#03</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/04.html">#04</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/05.html">#05</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/06.html">#06</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/07.html">#07</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/08.html">#08</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/09.html">#09</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/10.html">#10</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/11.html">#11</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/12.html">#12</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/13.html">#13</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/14.html">#14</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/15.html">#15</a> ~</p>

<p><strong>Prefer a <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/HaltAndCatchFireSyllabus.pdf">PDF</a>?</strong></p>

<p>Brief guide to class layout:</p>
<ul>
  <li><strong>Apéritifs</strong> Casual viewing presented before gathering. This is entertainment; not required viewing.</li>
  <li><strong>RFC as koan</strong> A Request for Comments from the Internet Engineering Task Force, for reflecting on.</li>
  <li><strong>Emulation as koan</strong> An emulated computer in the browser, also for reflection.</li>
  <li><strong>Themes</strong> Recommendations for topics to be discussed.</li>
  <li><strong>Prompts</strong> Questions to inspire conversation when gathering.</li>
  <li><strong>Readings</strong> Related material for deeper thinking on the class topic.</li>
  <li><strong>Description</strong> Brief summary of what’s going on in the episodes and how it relates to tech history at large / the weekly topic.</li>
  <li><strong>Episode summaries</strong> A link to summaries of the episodes that should be watched prior to meeting as a group. Watching each episode is not required; if time doesn’t allow, refer to the summaries. Content warnings are provided for relevant episodes. If there are specific concerns, this can determine which episodes should be skipped or anticipated before viewing.</li>
</ul>

<p><br>
Curriculum and website designed by <a href="https://ashleyblewer.com/">Ashley Blewer</a>.<br>
see also ↠ <a href="https://github.com/ablwr/halt-and-catch-fire-syllabus">source code &amp; site metadata</a></p>

<p><img src="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/assets/img/construction.gif" alt="under construction"></p>

    	</div></div>]]>
            </description>
            <link>https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25883965</guid>
            <pubDate>Sat, 23 Jan 2021 17:05:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TRS-80: a TRS-80 running a custom Associated Press ROM]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25883853">thread link</a>) | @Aloha
<br/>
January 23, 2021 | https://wayne.lorentz.me/This_TRS-80/ | <a href="https://web.archive.org/web/*/https://wayne.lorentz.me/This_TRS-80/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		
		<section>
			<blockquote>
				<p>
					February 2019 â€” I created this document from a collection of memories of a particular time in my life.  It is accurate to the best of my memory, but that does not mean it is complete.  Still, I think itâ€™s worth making public because there is almost no similar information on the intarwebs.
				</p>
				<p>
					If youâ€™re here to read about the TRS-80 Model 100 computer, you will have to slog through a lot of background information and personal anecdotes.  I didnâ€™t write this for clicks, or popularity, or recognition.  I wrote it for my own edification.  And I wrote the text of it on a TRS-80 Model 100.
				</p>
			</blockquote>
		</section>
		<section>
			<h2>
				Introduction
			</h2>
			<p>
				There are many TRS-80â€™s in the world. But this one is mine.
			</p>
			<figure>
				<a href="https://wayne.lorentz.me/This_TRS-80/images/2000/TRS-80_Model_100-001.jpeg"><img src="https://wayne.lorentz.me/This_TRS-80/images/1000/TRS-80_Model_100-001.jpeg" alt="My TRS-80 Model 100 computer on a table at Starbucks, as I wrote this story."></a>
				<figcaption>My TRS-80 Model 100 computer on a table at Starbucks, as I wrote this story.</figcaption>
			</figure>
			<p>
				The TRS-80 Model 100 is claimed by some to be the worldâ€™s first portable computer.  Whether that is true or not is hard to say.  Ninety percent of online journalism these days is nothing more than wannabe reporters summarizing other peopleâ€™s assumptions from web sites that know how to game a search engine.  But looking at old magazines of its era, the Model 100 was at least the first portable computer that wasnâ€™t a glorified calculator, or a suitcase so hefty that you could chock a tire with it to keep a Greyhound bus from rolling away.
			</p>
			<p>
				This document exists to show that the urban legend about TRS-80's being the devices that ushered journalism into the modern age is true. The Model 100 was a workhorse for a number of journalists, including a cadre of  roving correspondents for the Associated Press.  And also for me: a cub reporter for a radio station in a medium-sized, unremarkable city.
			</p>
		</section>
		<section>
			<h2>
				Background
			</h2>
			<p>
				This was a city not unlike dozens of other river towns across the United States.  For me, it wasnâ€™t my first experience as a broadcast journalist, but it was my first full-time, all-on-my-own job hundreds of miles from home.  More importantly, it was my first job with a computer.
			</p>
			<p>
				The conventional wisdom is that the computer revolution came all at once, and from the top down; with big businesses investing in hardware and software to make their employees more productive.  But it was a two-pronged offense.
			</p>
			<p>
				While desktop computers were commonplace in large companies in large office towers in large cities, it took decades for computers to become everyday objects in 90% of America.
			</p>
			<p>
				The second prong came from that 90%.
			</p>
			<p>
				Across the country, computers were becoming regular fixtures in ordinary households.  Commodore 64â€™s, TI99/4Aâ€™s, Apple ][â€™s and the like opened up a new world of possibilities for Joe and Jane Lunchbucket, and their children.  Online services like CompuServe, QLink, The Source, and Delphi connected people to information and each other in ways that previous generations could only imagine.
			</p>
			<p>
				It was also unimaginable to many of the people running the companies for which these people worked.
			</p>
			<p>
				Even as late as the turn of the millennium, it was commonplace for someone to have a computer and online connection at home that was faster and better than what was available in their workplace.  Complaints about this upside-down situation put pressure on small and mid-sized companies to land computers on every desk.  Firms like Dell, Gateway 2000 and eMachines were happy to churn out millions of low-quality â€œbusiness" computers to fill this technology gap.
			</p>
			<p>
				This story starts during the early portion of that gap.
			</p>
		</section>
		<section>
			<h2>
				Work before computers
			</h2>
			<p>
				I had a computer at home.  It was home-built, which wasnâ€™t unusual for the time.  But at work, it was all typewriters and pencils.  So many pencils.  I often wondered if it would make sense for all the reporters to put their pencils in a big communal bucket and have the interns sharpen them at the beginning of each work day.
			</p>
			<p>
				In addition to pencils, the primary tools of the reporterâ€™s trade were reporter notepads.  These are special spiral-bound pads of lined paper that are unusually narrow and unusually long.  They are the perfect size for stuffing into the inside pocket of a suit jacket or the outside pocket of a trench coat.  Each big story got its own pad, and youâ€™d build up a library of pads as an archive you could reference.
			</p>
			<p>
				Reporter pads were more than utilitarian.  They helped define the local journalism hierarchy.  Interns and reporters for alternative rags carried steno pads.  Real journalists had real reporter notepads from real journalism supply companies.
			</p>
			<p>
				But there was another level in the notepad caste system.  If you were lucky enough to be in the presence of a network correspondent, or someone working for one of the broadsheet institutions, you might be lucky enough to catch a glimpse of their special reporter notepads.  These looked like the regular notepads that plebs like myself used.  But their companies were so professional, and so focused on making sure their people had everything they needed to do a good job that the notepads had the company logos stamped on the cover.  It was like bird watching for news nerds.  A big black CBS eye here. An academic maroon AP logo there.  A corporate blue UPI logo could be spied if you were very lucky.
			</p>
			<p>
				Just as important as paper were the pencils a reporter carried.  Pens were right out.  If a pen dries up, explodes in your pocket, or otherwise refuses to cooperate, youâ€™re screwed.  A pencilâ€™s point might break, but you could pop into any random office building and ask the first secretary you came across to use her sharpener.  Plus, you always carried a fistful of spares.  In the worst case scenario, you could use a random sharp implement to expose enough lead to scratch with.  We all envisioned a story that was so important weâ€™d have to gnaw the wood off the end of a pencil just to make sure we didnâ€™t miss that career-making quote.
			</p>
			<figure>
				<a href="https://wayne.lorentz.me/This_TRS-80/images/2000/TRS-80_Model_100-008.jpeg"><img src="https://wayne.lorentz.me/This_TRS-80/images/1000/TRS-80_Model_100-008.jpeg" alt="Teletype paper from 1983"></a>
				<figcaption>Teletype paper was never meant to last more than a few hours or days.  This is from 1983.</figcaption>
			</figure>
			<p>
				In the radio newsroom, an intermittent tide of information came in on an Associated Press teletype machine.  It was something that looked like it belonged on the deck of a battleship spewing hot lead at airborne foes.  Two or three times a day someone would search through the ribbon of paper it spit onto the floor, rip each story from the spool, and file the stories into wire baskets labeled â€œLocal,â€� â€œState,â€� and â€œNational.â€�  There was also a â€œSaveâ€� bin way off to the side where people could collect copies of important news alerts and bulletins for posterity or their own personal collections.  International news went into the trash bins.  Thatâ€™s what we had the national network for.
			</p>
			<p>
				Thatâ€™s not to say that we didnâ€™t know what was going on.  At that level, all reporters are experts on national issues and foreign affairs.  Just ask them.  It was a game of one-upmanship that we all played to feed the fantasy that we might get a call from the network to join the big leagues in New York or D.C.  Which almost never happened.  No matter how much you contributed, you were more likely to squeeze into one of the few desirable slots at Voice of America than to be remembered by the network editors at Black Rock for more than six seconds after your voice left their air.
			</p>
			<p>
				But while we had pencils and we had paper and we had teletype machines, what we didnâ€™t have were computers.
			</p>
			<p>
				In school the boys didnâ€™t learn how to type.  That was for girls.  But since I had a computer at home, I knew my way around a keyboard.  You couldnâ€™t get a journalism degree without being able to bang out 40 words per minute on an IBM Selectric.  My scores were consistently above 80.  My J-school professors thought I was cheating.
			</p>
			<p>
				When I started my career, my home base was an AM/FM combo in the center of a small market.  Since I wasnâ€™t a full-time employee, I was free to work elsewhere.  And I did.  I would do a day at this station to fill in for someone who was sick, or a week at that station so someone could go on vacation.  At the time, it was very unusual for a local radio station to not have news at least once an hour.  Automation existed, but the spinning wheels of carts stopped when it was time for news.
			</p>
			<p>
				Doing news after school and on weekends helped pay for college.  To make that happen I got myself on the fill-in sheets of half the radio stations within 200 miles of where I lived.  Doing so allowed me to list more than a dozen commercial stations on my resume at a point in my career when my peers were lucky to get a DJ shift at a carrier current college station.
			</p>
			<p>
				I was bouncing between so many stations that one day I did, regrettably, announce that â€œKOJ news time is 7:05â€� on a station that wasnâ€™t KOJ.  The good people at K-104 never asked me back, which was a shame.  It was the first place I ever considered working full-time.  The facilities at K-104 were terrible.  But that was because management invested money in the employees instead of the physical plant, and everyone was paid far above what the competition paid.  The result was that everyone worked hard, and we were all handsomely rewarded.  But after my on-air mistake, I decided it was time to find one job, and stick to it.
			</p>
			<p>
				When it came time for a career change, I did what all radio people did: I consulted the help wanted listings in a strange industry newsletter that came in every day by fax.  Some station managers would tear the want ads off the end of the transmissions.  It was a very effective way to keep people from jumping ship in an era when information was still easy to control.  But if you were on the morning shift, you came in six hours before sales and management. That gave you an …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wayne.lorentz.me/This_TRS-80/">https://wayne.lorentz.me/This_TRS-80/</a></em></p>]]>
            </description>
            <link>https://wayne.lorentz.me/This_TRS-80/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25883853</guid>
            <pubDate>Sat, 23 Jan 2021 16:57:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Replicating GPT-2 at Home]]>
            </title>
            <description>
<![CDATA[
Score 229 | Comments 43 (<a href="https://news.ycombinator.com/item?id=25883791">thread link</a>) | @bkkaggle
<br/>
January 23, 2021 | https://bkkaggle.github.io/blog/algpt2/2020/07/17/ALGPT2-part-2.html | <a href="https://web.archive.org/web/*/https://bkkaggle.github.io/blog/algpt2/2020/07/17/ALGPT2-part-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <ul>
<li><a href="#tldr">TL;DR</a></li>
<li><a href="#the-idea">The Idea</a></li>
<li><a href="#background">Background</a></li>
<li><a href="#gpt-2-and-albert">GPT-2 and ALBERT</a>
<ul>
<li><a href="#factorized-embedding">Factorized embedding</a></li>
<li><a href="#layer-wise-parameter-sharing">Layer-wise parameter sharing</a></li>
<li><a href="#sentence-order-prediction-auxillary-loss">Sentence-order-prediction auxillary loss</a></li>
<li><a href="#removing-dropout">Removing dropout</a></li>
</ul>
</li>
<li><a href="#setup">Setup</a>
<ul>
<li><a href="#openwebtext">OpenWebText</a></li>
<li><a href="#tokenization">Tokenization</a></li>
<li><a href="#tfrecords">TFRecords</a></li>
<li><a href="#coding-it-up">Coding it up</a></li>
</ul>
</li>
<li><a href="#replicating-gpt-2">Replicating GPT-2</a>
<ul>
<li><a href="#replicating-gpt-2-1">Replicating GPT-2</a></li>
<li><a href="#adamw-vs-adafactor">AdamW vs Adafactor</a></li>
<li><a href="#learning-rates">Learning rates</a></li>
</ul>
</li>
<li><a href="#pretraining-algpt-2">Pretraining ALGPT-2</a>
<ul>
<li><a href="#implementing-parameter-sharing">Implementing parameter sharing</a></li>
<li><a href="#implementing-a-factorized-embedding">Implementing a factorized embedding</a></li>
<li><a href="#effect-of-layer-wise-parameter-sharing">Effect of layer-wise parameter sharing</a></li>
<li><a href="#effect-of-removing-dropout">Effect of removing dropout</a></li>
<li><a href="#effect-of-factorized-embeddings">Effect of factorized embeddings</a></li>
<li><a href="#effect-of-model-size">Effect of model size</a></li>
</ul>
</li>
<li><a href="#conclusion-and-next-steps">Conclusion and next steps</a></li>
</ul><hr>

<blockquote>
  <p><a href="https://bkkaggle.github.io/blog/algpt2/2020/06/22/ALGPT2-part-1">Part 1: Best Practices for Finetuning Large Transformer Language models</a></p>

  <p>Part 2: How I (almost) replicated OpenAI’s GPT-2 (124M version)</p>
</blockquote>

<hr>



<hr>

<p>A few months ago I started working on a research project trying to pretrain my own, more efficient language model from scratch. I got access to a 128-core TPUv3 pod from the Tensorflow Reseach Cloud and used it to pretrain a $124$M parameter GPT-2 model to a perplexity pretty close to OpenAI’s results (my pretrained model was trained for about $1/8$th of the number of iterations that OpenAI trained their model for and got $21$ ppl on OpenWebText compared to $17$ ppl for OpenAI’s model), and then pretrained an ALBERT-style GPT-2 (that I’m calling ALGPT2) language model with a factorized input embedding and layer-wise parameter sharing that would reduce the number of paramters in the model from $124$M to around $12$M.</p>

<p>Unfortunately, ALGPT-2 doesn’t perform as well as GPT-2 (ALGPT-2 gets $31$ ppl on OpenWebText compared to $21$ ppl for my pretrained GPT-2 model), but I’m writing this series of blog posts to go through everything I’ve learned over the last few months.</p>

<hr>



<hr>

<p>The main thing that I wanted to do from this sort-of “research project” that I was working on by myself this spring was to develop and train a more efficient version of the $124$M parameter version of <a href="https://openai.com/blog/better-language-models/">GPT-2</a>. I wanted to pretrain the $1.5$B parameter version of GPT-2 but since I only got access to the TPU pod for a week, I had to choose a model that would train in time. A $100$k iteration training run takes about $20$ hours to run which gave me plenty of time to run multiple experiments. In contrast, following OpenAI’s training procedure exactly and training for the full $800$k iterations would take up almost an entire week and use up most of my quota.</p>

<p>I was able to almost replicate the $124$M parameter version of GPT-2 by pretraining it to a perplexity pretty close to OpenAI’s results (my pretrained model used was trained for about $1/8$th of the number of iterations that OpenAI trained their model for and got $21$ perplexity (ppl) on the standard OpenWebText dataset compared to $17$ ppl for OpenAI’s model),</p>

<p>My idea of making a more efficient transformer didn’t really work out since my pretrained transformer ended up being about $20$ppl worse than an equivalent GPT-2 model, but I wanted to writeup what I learned over the two or three months that I was working on this anyway.</p>

<hr>



<hr>

<p>A little bit about myself: I’m an incoming software engineering student at the University of Waterloo and this post is supposed to be a writeup of a NLP research project that I was working on from around March to May of 2020 (right in the middle of the first Covid-19 lockdown of 2020, I’m currently writing this on July 15, 2020 while waiting for my Pix2PixHD model to train for a few hundred epochs on colab for a new project that I’m working on).</p>

<p>I was pretty lucky that I started learning NLP right before transformers exploded in popularity, I remember when <a href="https://arxiv.org/abs/1301.3781">word2vec</a> and LSTMs were SOTA on a lot of NLP tasks, and it has been really interesting to see how much the field of NLP has changed in just a few years, going from when LSTMs with only a a handful of layers and somewhere on the order of $512$ units were considered to be large networks and computationally expensive to train, to training LSTMs with <a href="https://arxiv.org/abs/1409.0473">attention</a> layers on top, to the original <a href="https://arxiv.org/abs/1706.03762">transformer encoder/decoder networks</a>, to <a href="https://arxiv.org/abs/1801.06146">ULMFIT</a> and <a href="https://arxiv.org/abs/1802.05365">ELMO</a>, then <a href="https://arxiv.org/abs/1810.04805">BERT</a>, <a href="https://arxiv.org/abs/1907.11692">RoBERTa</a>, <a href="https://openai.com/blog/better-language-models/">GPT-2</a>, and <a href="https://arxiv.org/abs/1910.10683">T5</a>, to just a few months ago with the explosion of new, more efficient replacements for self-attention like the <a href="https://openai.com/blog/sparse-transformer/">Sparse Transformer</a>, the <a href="https://arxiv.org/abs/2001.04451">Reformer</a>, and <a href="https://arxiv.org/abs/2005.00743">Synthesizers</a>, and now <a href="https://arxiv.org/abs/2005.14165">GPT-3</a>, which IMO has the potential to really change the whole field of NLP.</p>

<p>Just a few years ago we trained shallow recurrent networks on datasets, then pretrained large transformer language models on large datasets and finetuned on task-specific datasets. Now the whole idea of just training a gigantic language model on a huge dataset, then conditioning the model in a form of few-shot learning by prepending a few examples of a certain task to an input feels like it can really make NLP models a lot more accessible and easier to productionize as well as making human-chatbot interactions a lot more realistic than they are today.</p>

<p>I’ve rambled on for long enough, lets get to the main topic of this post.</p>

<hr>



<hr>

<p><a href="https://openai.com/blog/better-language-models/">GPT-2</a> is a transformer decoder.</p>

<p>The embedding layer at the root of the model maps a one-hot vector of a given token’s index (all the GPT-2 models use a vocabulary size of $50257$) to a $768$ dimensional vector (all GPT-2 numbers in this blog post will be for the $124$m parameter version of GPT-2).</p>

<p>The embedding matrix is followed by a stack of self-attention and feed-forward layers that each output a $768$ dimensional vector (keeping the number of outputs for each layer constant), which makes up the main part of the transformer.</p>

<p>The stack of self-attention layers is then followed by an output embedding (the weights of the input and output embeddings are tied to make training easier) that maps the $768$ dimensional vector that is the output of the last layer of the transformer to the same $50257$ dimensional vector that represents the probability of each token in the vocabulary being the next token in the sequence.</p>

<p>Take a look at <a href="http://jalammar.github.io/illustrated-gpt2/">The Illustrated GPT-2</a> for a more in-depth look into GPT-2.</p>

<p><a href="https://arxiv.org/abs/1909.11942">ALBERT</a> (A Lite BERT) is a paper that takes a look at <a href="https://arxiv.org/abs/1810.04805">BERT</a> and identifies some ways in which to make it more efficient and reduce the number of parameters in the model in four major ways: a factorized embedding, layer-wise parameter sharing, a sentence-order-prediction auxillary loss, and removing dropout.</p>

<hr>

<h3 id="factorized-embedding">
Factorized embedding</h3>

<hr>

<p>GPT-2’s embedding has a lot of parameters. It’s really just a matrix of dimensions $50257 \times 768$. That means that the input embedding alone uses up almost $50257 \times 768 = \space \sim 38,000,000$ parameters which is a pretty big chunk of the $128$M total parameters in the model.</p>

<p>The ALBERT authors propose a factorized embedding with an intermediate embedding size of $128$: one embedding of size $50257 \times 128$ and another embedding of size $128 \times 768$. By breaking up the large embedding matrix into two smaller matrices, the total number of parameters used in the embedding goes from about $38$M to about $6$M.</p>

<p>$50257 \times 128 = \sim 6,000,000$</p>

<p>$128 \times 768 = \sim 100,000$</p>

<p>The authors try different intermediate embedding sizes and settle on $128$ as a good tradeoff betweeen parameters and performance.</p>

<hr>

<h3 id="layer-wise-parameter-sharing">
Layer-wise parameter sharing</h3>

<hr>

<p>In a normal transformer model, the transformer layers are created something like this:</p>

<div><div><pre><code><span>class</span> <span>BERT</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>n_layers</span><span>):</span>
        <span>super</span><span>().</span><span>__init__</span><span>()</span>
        <span>//</span> <span>...</span>
        <span>self</span><span>.</span><span>blocks</span> <span>=</span> <span>nn</span><span>.</span><span>ModuleList</span><span>([</span><span>Block</span><span>()</span> <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>n_layers</span><span>)])</span>
        <span>//</span> <span>...</span>
    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>):</span>
        <span>//</span> <span>...</span>
        <span>for</span> <span>block</span> <span>in</span> <span>self</span><span>.</span><span>blocks</span><span>:</span>
            <span>x</span> <span>=</span> <span>block</span><span>(</span><span>x</span><span>)</span>
        <span>//</span> <span>...</span>
</code></pre></div></div>

<p>ALBERT shares all parameters across the transformer layers something like this:</p>

<div><div><pre><code><span>class</span> <span>ALBERT</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>n_layers</span><span>):</span>
        <span>super</span><span>().</span><span>__init__</span><span>()</span>
        <span>//</span> <span>...</span>

        <span>self</span><span>.</span><span>n_layers</span> <span>=</span> <span>n_layers</span>
        <span>self</span><span>.</span><span>block</span> <span>=</span> <span>Block</span><span>()</span>
        <span>//</span> <span>...</span>
    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>):</span>
        <span>//</span> <span>...</span>
        <span>for</span> <span>_</span> <span>in</span> <span>self</span><span>.</span><span>n_layers</span><span>:</span>
            <span>x</span> <span>=</span> <span>block</span><span>(</span><span>x</span><span>)</span>
        <span>//</span> <span>...</span>
</code></pre></div></div>

<p>By only defining one transformer block and looping around it <code>n_layers</code> times, ALBERT saves the GPU memory that would be used to store the parameters for all the layers.</p>

<p>Since we normally use $32$ bit floats to store parameters on the GPU, storing the $1.5$B parameter GPT-2 on the GPU will use up about $6$GB of the GPU’s memory — that’s a pretty big chunk of the $16$GB of memory that’s on a normal V100 GPU already being used up before taking into account the memory needed to store the model’s activations as well as any momentum parameters needed by the optimizer. In contrast, if you share parameters across all transformer layers in the $1.5$B parameter GPT-2, the resulting model will only have about $37$M parameters, the parameter-sharing version would only use up around $148$MB of GPU memory.</p>

<p>The authors try applying parameter sharing to BERT and see that it reduces performance but makes it easier to train larger and larger models.</p>

<blockquote>
  <p>In a machine learning framework like JAX, which by default unrolls and inlines loops when it’s compiling your code with XLA, the size of the unrolled and inlined loop would make the computation graph really large and take a long time to compile. This is why you’re recommended to use somehting like <a href="https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.scan.html"><code>lax.scan()</code></a> in these situations.</p>
</blockquote>

<hr>

<h3 id="sentence-order-prediction-auxillary-loss">
Sentence-order-prediction auxillary loss</h3>

<p>The ALBERT authors add an auxillary loss to help training. Since language modelling is usually done autoregressively, I didn’t use this for my custom model.</p>

<hr>

<h3 id="removing-dropout">
Removing dropout</h3>

<p>The ALBERT authors remove all dropout from BERT and see that it significantly improves performance.</p>

<hr>

<p>That’s pretty much what my idea was: Take GPT-2, add a factorized embedding, share parameters across all transformer layers, remove dropout (I actually missed the part about ALBERT removing dropout until I was pretty far into my work, but I did run one or two runs without dropout to see how that works), and pretrain on a large dataset for a few hundred thousand iterations.</p>

<p>There’s no way that I could pretrain something like GPT-2 by myself, so I applied to the <a href="https://www.tensorflow.org/tfrc">Tensorflow Research Cloud</a> (TFRC).</p>

<blockquote>
  <p>The TFRC …</p></blockquote></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bkkaggle.github.io/blog/algpt2/2020/07/17/ALGPT2-part-2.html">https://bkkaggle.github.io/blog/algpt2/2020/07/17/ALGPT2-part-2.html</a></em></p>]]>
            </description>
            <link>https://bkkaggle.github.io/blog/algpt2/2020/07/17/ALGPT2-part-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25883791</guid>
            <pubDate>Sat, 23 Jan 2021 16:52:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Simple Garbage Collector in C]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25883686">thread link</a>) | @signa11
<br/>
January 23, 2021 | https://maplant.com/gc.html#org0333c0b | <a href="https://web.archive.org/web/*/https://maplant.com/gc.html#org0333c0b">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-2">
<p>
To begin, we need to write a memory allocator, or as we will be calling it,
a malloc function. The simplest malloc implementations maintain a linked-list of
free blocks of memory that can be partitioned and given out as needed. When a
user requests a chunk of memory, a block of the right size is removed from the
free list and returned. If no blocks of the right size exist, either a block of
a larger size is partitioned into smaller blocks or more memory is requested
from the kernel. Freeing a chunk of memory simply adds it back to the free list.
</p>

<p>
Each chunk of memory in the free list begins with a header describing the
block. Our header will contain two fields, one indicating the size of the chunk
and the second pointing to the next free block of memory:
</p>

<div>
<pre><span>typedef</span> <span>struct</span> <span>header</span> {
    <span>unsigned</span> <span>int</span>    <span>size</span>;
    <span>struct</span> <span>header</span>   *<span>next</span>;
} <span>header_t</span>;
</pre>
</div>

<p>
Using headers that are embedded in the memory we allocate is really the only
sensible way of doing this, but it has the added benefit of automatically
word-aligning the chunks, which is important.
</p>

<p>
Because we will need to keep track of the blocks of memory currently in use
as well as the blocks that are not, we will have a used list in addition to a
free list. Items will be added to the used list when they are removed from the
free list, and vice-versa.
</p>

<p>
We are almost ready to complete the first step and write our malloc
implementation. Before we do that, we first need to understand how to request
memory from the kernel.
</p>

<p>
Dynamically allocated memory resides in the so-called heap, a section memory
between the stack and the BSS (uninitialized data segment - all your global
variables that have the default value of zero). The heap starts at a low address
bordering the BSS and ends at the program break, which resides somewhere between
the BSS and the stack. Attempting to access any memory between the stack and the
break will cause an access violation (unless you access within the amount the
stack can be extended by, but that's a whole separate conversation). In order to
obtain more memory from the kernel, we simply extend the break, thus allowing us
to access more memory. To do this, we call the Unix sbrk system call, which
extends the break by its argument and returns the address of the previous break
on success, thus giving the program more memory. On failure, sbrk returns -1
casted to a void pointer, which is a terrible convention that no one likes.
</p>

<p>
We can use this knowledge to create two functions: <code>morecore</code> and
<code>add_to_free_list</code>. In the case that we are out of blocks in the free list, we 
will call <code>morecore</code> to request more memory. Since requesting the kernel for more
memory is expensive, we will do it in page-size chunks. Knowing what a page is
is not important right now, but a terse explanation is that it is the smallest
unit of virtual memory that can be mapped to any particular location in physical
memory. We will use the function <code>add_to_free_list</code> to do exactly what it sounds
like.
</p>

<div>
<pre><span>static</span> <span>header_t</span> <span>base</span>;           <span>/* </span><span>Zero sized block to get us started. </span><span>*/</span>
<span>static</span> <span>header_t</span> *<span>freep</span> = &amp;base; <span>/* </span><span>Points to first free block of memory. </span><span>*/</span>
<span>static</span> <span>header_t</span> *<span>usedp</span>;         <span>/* </span><span>Points to first used block of memory. </span><span>*/</span>

<span>/*</span>
<span> * Scan the free list and look for a place to put the block. Basically, we're </span>
<span> * looking for any block that the to-be-freed block might have been partitioned from.</span>
<span> </span><span>*/</span>
<span>static</span> <span>void</span>
<span>add_to_free_list</span>(<span>header_t</span> *<span>bp</span>)
{
    <span>header_t</span> *<span>p</span>;

    <span>for</span> (p = freep; <span>!</span>(bp &gt; p &amp;&amp; bp &lt; p-&gt;next); p = p-&gt;next)
        <span>if</span> (p &gt;= p-&gt;next &amp;&amp; (bp &gt; p || bp &lt; p-&gt;next))
            <span>break</span>;

    <span>if</span> (bp + bp-&gt;size == p-&gt;next) {
        bp-&gt;size += p-&gt;next-&gt;size;
        bp-&gt;next = p-&gt;next-&gt;next;
    } <span>else</span>
        bp-&gt;next = p-&gt;next;

    <span>if</span> (p + p-&gt;size == bp) {
        p-&gt;size += bp-&gt;size;
        p-&gt;next = bp-&gt;next;
    } <span>else</span>
        p-&gt;next = bp;

    freep = p;
}

<span>#define</span> <span>MIN_ALLOC_SIZE</span> 4096 <span>/* </span><span>We allocate blocks in page sized chunks. </span><span>*/</span>

<span>/*</span>
<span> * Request more memory from the kernel.</span>
<span> </span><span>*/</span>
<span>static</span> <span>header_t</span> *
<span>morecore</span>(<span>size_t</span> <span>num_units</span>)
{
    <span>void</span> *<span>vp</span>;
    <span>header_t</span> *<span>up</span>;

    <span>if</span> (num_units &gt; MIN_ALLOC_SIZE)
        num_units = MIN_ALLOC_SIZE / <span>sizeof</span>(header_t);

    <span>if</span> ((vp = sbrk(<span>num_units</span> * <span>sizeof</span>(header_t))) == (<span>void</span> *) -1)
        <span>return</span> <span>NULL</span>;

    up = (<span>header_t</span> *) vp;
    up-&gt;size = num_units;
    add_to_free_list (up);
    <span>return</span> freep;
}
</pre>
</div>

<p>
Now that we have our two helper functions, writing our malloc function is
pretty straight forward. We simply scan the free list and use the first block
that is at least as big as the chunk we're trying to find. Because we use the 
first block we find instead of trying to find a "better" block, this algorithm
is known as first fit.
</p>

<p>
A quick note to clarify: the size field in the header struct is measured in
header-sized blocks, and not bytes.
</p>

<div>
<pre><span>/*</span>
<span> * Find a chunk from the free list and put it in the used list.</span>
<span> </span><span>*/</span>
<span>void</span> *
<span>GC_malloc</span>(<span>size_t</span> <span>alloc_size</span>)
{
    <span>size_t</span> <span>num_units</span>;
    <span>header_t</span> *<span>p</span>, *<span>prevp</span>;

    num_units = (alloc_size + <span>sizeof</span>(header_t) - 1) / <span>sizeof</span>(header_t) + 1;  
    prevp = freep;

    <span>for</span> (p = prevp-&gt;next;; prevp = p, p = p-&gt;next) {
        <span>if</span> (p-&gt;size &gt;= num_units) { <span>/* </span><span>Big enough. </span><span>*/</span>
            <span>if</span> (p-&gt;size == num_units) <span>/* </span><span>Exact size. </span><span>*/</span>
                prevp-&gt;next = p-&gt;next;
            <span>else</span> {
                p-&gt;size -= num_units;
                p += p-&gt;size;
                p-&gt;size = num_units;
            }

            freep = prevp;

            <span>/* </span><span>Add to p to the used list. </span><span>*/</span>
            <span>if</span> (usedp == <span>NULL</span>)  
                usedp = p-&gt;next = p;
            <span>else</span> {
                p-&gt;next = usedp-&gt;next;
                usedp-&gt;next = p;
            }

            <span>return</span> (<span>void</span> *) (p + 1);
        }
        <span>if</span> (p == freep) { <span>/* </span><span>Not enough memory. </span><span>*/</span>
            p = morecore(num_units);
            <span>if</span> (p == <span>NULL</span>) <span>/* </span><span>Request for more memory failed. </span><span>*/</span>
                <span>return</span> <span>NULL</span>;
        }
    }
}
</pre>
</div>

<p>
Although this code isn't going to win any awards for low fragmentation, it'll
work. And if it works, that means we can finally get to the fun part - the
garbage collection!
</p>
</div></div>]]>
            </description>
            <link>https://maplant.com/gc.html#org0333c0b</link>
            <guid isPermaLink="false">hacker-news-small-sites-25883686</guid>
            <pubDate>Sat, 23 Jan 2021 16:44:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Clojure by Example: Cljfx]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25883645">thread link</a>) | @wellpast
<br/>
January 23, 2021 | https://blog.matthewdmiller.net/learn-clojure-by-example-javafx-gui-with-cljfx | <a href="https://web.archive.org/web/*/https://blog.matthewdmiller.net/learn-clojure-by-example-javafx-gui-with-cljfx">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>Clojure is a dialect of Lisp that runs on the JVM. JavaFX is a modern GUI
toolkit for the JVM. You could use JavaFX directly with Clojure's Java interop,
but Cljfx provides a declarative and functional wrapper for JavaFX. Instead of
building yet another calculator, we're going to use Cljfx to build a GUI for
generating a tone.</p>
<p><img src="https://raw.githubusercontent.com/goober99/lisp-gui-examples/master/screenshots/cljfx.png" alt="Screenshot"></p>
<p>You'll need Clojure installed. We also need a way to pull the Cljfx dependency
into our app. It seems <a target="_blank" href="https://clojure.org/guides/deps_and_cli">deps.edn</a>
would be the easiest way to accomplish this for a short tutorial example such
as this, but I develop on Debian and found that the new <a target="_blank" href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=891141">command line
tools</a> for Clojure
that enable this haven't made it into Debian yet. I could install Clojure from
the Clojure website, but the point of this tutorial is to be easy to follow by
someone not familiar with Clojure. It's a lot easier to direct a person to <code>apt
install clojure</code> (or whatever package manager your preferred distro uses). This
tutorial is a living document maintained on GitHub along with the example code.
Whenever the Clojure command line tools become available on Debian, it's
possible I'll revisit this tutorial and update it.</p>
<p>The Clojure build tool Leiningen is capable of managing dependencies (and a
whole lot more). There is also a build tool for Clojure called Boot. I found
more plentiful tutorials and beginner resources for Leiningen, plus Leiningen
is available as a Debian package, so for this tutorial, Leiningen it is.
Install Clojure and Leiningen from your distro's repo. Debian also has an
OpenJFX package, but Leiningen was able to pull OpenJFX in as a dependency of
Cljfx. The version pulled in by Leiningen is probably more up to date than
whatever might be sitting in your distro's repos.</p>
<p>After that, we need to create a Leiningen project directory. This can be
accomplished with <code>lein new app bleep</code>, but that created a directory full of
subdirectories and files that were unnecessary for a short little example like
this. I created the directory structure (<code>mkdir -p cljfx/src/bleep</code>) and
created <code>cljfx/project.clj</code> and <code>cljfx/src/bleep/core.clj</code> with the minimum
needed to create a window with Cljfx.</p>
<p><code>project.clj</code></p>
<pre><code>(defproject bleep "0.1.0-SNAPSHOT"
  :dependencies [[org.clojure/clojure "1.10.0"]
                 [cljfx "1.7.12"]
                 [com.jsyn/jsyn "20170815"]]
  :main bleep.core)
</code></pre>
<p><code>core.clj</code></p>
<pre><code>(ns bleep.core
  (:gen-class)
  (:require [cljfx.api :as fx])
  (:import [javafx.application Platform]
           [com.jsyn JSyn]
           [com.jsyn.unitgen LineOut SineOscillator]))

(defn hello-world [&amp; args]
  {:fx/type :label
   :text "Hello, World!"})

(defn root [&amp; args]
  {:fx/type :stage
   :showing true
   :title "Bleep"
   :scene {:fx/type :scene
           :root {:fx/type :v-box
                  :padding 25
                  :spacing 40
                  :children [{:fx/type hello-world}]}}})

(def renderer
  (fx/create-renderer))

(defn -main [&amp; args]
  (Platform/setImplicitExit true)
  (renderer {:fx/type root}))
</code></pre>
<p>The project file (<code>project.clj</code>) is the file that tells Leiningen about your
project (such as its dependencies). Typically with Leiningen, your code will
live in the <code>src</code> subdirectory in a subdirectory that matches the top-level
namespace of your project. All this can be changed with your <code>project.clj</code>, but
we'll be sticking to convention for this example. In this subdirectory is
<code>core.clj</code>.</p>
<p>Begin the file with a namespace declaration. The namespace should have a
<code>(:gen-class)</code> declaration in the <code>ns</code> form at the top for Leiningen. Since
we'll be using Cljfx to create our GUI, we need to <code>require</code> it. We'll mostly
be using JavaFX via Cljfx, but you can also access JavaFX classes directly.
Let's <code>import</code> (a way to get Java code into Clojure) the JavaFX Platform class.
We'll also import the Java JSyn library for use later in generating the tone.</p>
<p>Leiningen needs a <code>-main</code> function (note the leading dash is part of the
function name). This is the function that will get called when you run your app
with Leiningen or when you compile it to a standalone JAR. We use the
<code>setImplicitExit</code> method from the JavaFX Platform class to make sure the JavaFX
runtime shuts down when the window is closed.</p>
<p>Cljfx is declarative instead of imperative or object oriented like many GUI
libraries. You describe the layout with a map of key-value pairs instead of
creating controls with methods or functions. The <code>:fx/type</code> key has a value of
a kebab-cased keyword derived from a JavaFX class name. The other keys of the
map are the kebab-cased properties of that class. You can refer to the <a target="_blank" href="https://openjfx.io/">JavaFX
documentation</a> for a list of classes and their properties.
JavaFX is well documented and has a large number of controls available.</p>
<p>JavaFX defines the user interface by means of a stage and a scene. The stage is
the top-level JavaFX container (the window). The scene is the container for all
content. To add a JavaFX class to the map, you convert the class name to
kebab-case. For example, JavaFX has a <code>VBox</code> pane used to lay out controls
vertically. This would be written <code>:v-box</code> in the Cljfx map. The <code>VBox</code> class
has a <code>padding</code> property. We can set this to 25 by adding a <code>:padding</code> key to
the map with a value of 25.</p>
<p>Cljfx provides a renderer function created with <code>fx/create-renderer</code> that you
pass the map describing your user interface to. You can call <code>renderer</code>
multiple times to dynamically change the GUI. Now let's replace the Hello World
label with a slider:</p>
<pre><code>(defn frequency-slider [{:keys [frequency]}]
  {:fx/type :slider
   :min 20
   :max 20000
   :value frequency})
</code></pre>
<p>Instead of placing the definition of your entire UI into one big map, you can
compose the UI from reusable functions. This also makes your code more
readable, because you don't have a deeply nested map. These functions can be
used just like any other JavaFX class. The <code>:fx/type</code> key is the function name,
and the other keys of the map are the arguments to the function. We can add the
<code>frequency-slider</code> we created above to the <code>:children</code> vector of the <code>:v-box</code>
in the <code>root</code> map like this:</p>
<pre><code>[{:fx/type frequency-slider
  :frequency 440}]
</code></pre>
<p>The range of frequencies audible by humans is typically between 20 Hz and 20
KHz (we lose the ability to hear some of those higher frequencies as we age).
The <a target="_blank" href="https://en.wikipedia.org/wiki/A440_(pitch_standard">musical note A above middle
C</a>) is 440 Hz. Since A4
serves as a general tuning standard, it seems like a sensible default, but if
you run the above with <code>lein run</code>, this is what you'll see:</p>
<p><img src="https://raw.githubusercontent.com/goober99/lisp-gui-examples/master/screenshots/cljfx-linearslider.png" alt="Slider"></p>
<p>The scale of 20 to 20,000 is so large that 440 doesn't appear to move the
slider at all. Ideally, 440 would fall about the middle of the slider. To
achieve this, let's use a logarithmic scale.</p>
<p>I found a <a target="_blank" href="https://stackoverflow.com/questions/846221/logarithmic-slider/846249#846249">Stack Overflow
answer</a>
on how to map a slider to a logarithmic scale. The code given in the answer is
JavaScript, but it was easy enough to port to Clojure.</p>
<pre><code>; Scale used by slider
(def min-position 0)
(def max-position 2000)
; Range of frequencies
(def min-frequency 20)
(def max-frequency 20000)

; Logarithmic scale for frequency (so middle A [440] falls about in the middle)
; Adapted from https://stackoverflow.com/questions/846221/logarithmic-slider

(def min-freq (Math/log min-frequency))
(def max-freq (Math/log max-frequency))
(def frequency-scale (/ (- max-freq min-freq) (- max-position min-position)))
; Convert slider position to frequency
(defn position-&gt;frequency [position]
  (int (Math/round (Math/exp (+ min-freq (* frequency-scale (- position min-position)))))))
; Convert frequency to slider position
(defn frequency-&gt;position [freq]
  (int (Math/round (/ (- (Math/log freq) min-freq) (+ frequency-scale min-position)))))
</code></pre>
<p>I added some global parameters to the top of the script. I came up with the
range of 0-2,000 by trial and error. It seemed to strike the best balance
between each step of the slider making a noticeable change to the frequency
while still allowing the user to narrow in on a specific frequency with just
the slider.</p>
<p>Then we create two functions: one that takes the position on the slider and
returns the frequency (<code>position-&gt;frequency</code>) and another that takes a
frequency and returns the position on the slider (<code>frequency-position</code>). Now
let's set the initial position of our slider with the <code>frequency-&gt;position</code>
function:</p>
<pre><code>(defn frequency-slider [{:keys [frequency]}]
  {:fx/type :slider
   :min min-position
   :max max-position
   :value (frequency-&gt;position frequency)})
</code></pre>
<p>Underneath the slider is a text field showing the current frequency.</p>
<pre><code>(defn frequency-controls [{:keys [frequency]}]
  {:fx/type :h-box
   :alignment :center
   :spacing 20
   :children [{:fx/type :h-box
               :alignment :center
               :spacing 5
               :children [{:fx/type :text-field
                           :text (str frequency)}
                          {:fx/type :label
                           :text "Hz"}]}]})
</code></pre>
<p>Add this to the <code>:children</code> vector of the <code>:v-box</code> in the <code>root</code> map:</p>
<pre><code>[{:fx/type frequency-slider
  :frequency frequency}
 {:fx/type frequency-controls
  :frequency frequency}]
</code></pre>
<p>At this point, we are starting to have a nice looking interface, but it doesn't
do anything. If you slide the slider, nothing happens. If your experience is
mostly with object-oriented GUI libraries, the way Cljfx does things will be a
little unfamiliar. If you've used the JavaScript library React, it employs a
similar model. Global state is stored in an atom. When you update that atom,
all the relevant controls are updated accordingly.</p>
<pre><code>; Cljfx global state
(def *state
  (atom {:frequency 440}))
</code></pre>
<p>Add middleware to the <code>renderer</code> that maps incoming data from the global state
atom to the component description to be rendered:</p>
<pre><code>(def renderer
  (fx/create-renderer
    :middleware (fx/wrap-map-desc assoc :fx/type root)))
</code></pre>
<p>Then modify <code>-main</code> to use <code>fx/mount-renderer</code> instead of calling <code>renderer</code>
directly. This will watch the global state atom for changes and rerender the
GUI accordingly.</p>
<pre><code>(defn -main [&amp; args]
  (Platform/setImplicitExit true)
  (fx/mount-renderer *state renderer))
</code></pre>
<p>In most of the other examples, I would now write a function for each control
that updates the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.matthewdmiller.net/learn-clojure-by-example-javafx-gui-with-cljfx">https://blog.matthewdmiller.net/learn-clojure-by-example-javafx-gui-with-cljfx</a></em></p>]]>
            </description>
            <link>https://blog.matthewdmiller.net/learn-clojure-by-example-javafx-gui-with-cljfx</link>
            <guid isPermaLink="false">hacker-news-small-sites-25883645</guid>
            <pubDate>Sat, 23 Jan 2021 16:41:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Tracking with Todoist]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25883439">thread link</a>) | @awaxman11
<br/>
January 23, 2021 | https://blog.awaxman.com/time-tracking-with-todoist | <a href="https://web.archive.org/web/*/https://blog.awaxman.com/time-tracking-with-todoist">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="ArticleBody"><div><h2 id="context">Context</h2><p>Yesterday afternoon Karri Saarinen <a href="https://twitter.com/karrisaarinen/status/1352685228242784256" target="_blank" rel="noreferrer">asked</a> if anyone had a good system for tracking how they spend their time. </p><p><span>
      <span></span>
  <picture>
        <source srcset="https://blog.awaxman.com/static/28ce0e4f82abf104f4ae068792bb4f42/8ac9c/tweet.webp 2310w" sizes="(max-width: 2310px) 100vw, 2310px" type="image/webp">
        <source srcset="https://blog.awaxman.com/static/28ce0e4f82abf104f4ae068792bb4f42/5ecf7/tweet.png 2310w" sizes="(max-width: 2310px) 100vw, 2310px" type="image/png">
        <img tabindex="0" src="https://blog.awaxman.com/static/28ce0e4f82abf104f4ae068792bb4f42/5ecf7/tweet.png" alt="Anyone have a good time tracking workflow?" title="Anyone have a good time tracking workflow?" loading="lazy">
      </picture>
    </span></p><p>After looking through ~50 replies, it looked like there was an opportunity. Half of the suggestions were automated solutions like RescueTime or Toggl. While these are low effort, they make it hard to add stuff post hoc and/or keep track of non-digital activities. They also aren’t as customizable as people want. While there were fully customized solutions like Rahul’s <a href="https://blog.superhuman.com/the-most-effective-way-to-track-your-time" target="_blank" rel="noreferrer">The Most Effective Way to Track Your Time</a>, these often require a lot of manual effort to get the data into a useful format. Karri posted some screenshots of a concept where he could quickly add activities and also tag them as energy draining or energy gaining. </p><p><span>
      <span></span>
  <picture>
        <source srcset="https://blog.awaxman.com/static/42501863200c3500102063e98bad398b/9fd9e/example.webp 742w" sizes="(max-width: 742px) 100vw, 742px" type="image/webp">
        <source srcset="https://blog.awaxman.com/static/42501863200c3500102063e98bad398b/28ca2/example.png 742w" sizes="(max-width: 742px) 100vw, 742px" type="image/png">
        <img tabindex="0" src="https://blog.awaxman.com/static/42501863200c3500102063e98bad398b/28ca2/example.png" alt="Example Workflow" title="Example Workflow" loading="lazy">
      </picture>
    </span></p><p>I was inspired by the idea so spent my Fri night trying to see if I could cook up my own workflow. My goals were to make it:</p><ol><li>Easy to add tasks</li><li>Highly customizable </li><li>Use existing tools</li></ol><h2 id="the-workflow">The Workflow</h2><p>After playing around with TaskPaper files, Day One, and Alfred, I ended up deciding to use Todoist. Their API seemed easy to use, and I also like how you can quickly add items via a global shortcut and quickly add tags using keyboard shortcuts.</p><p>To add a task, you simply trigger Todoist’s global shorcut and type in your activity. You can then add tags like how many minutes you spent doing the task, whether it was an energy @gain or @drain, and any other tags you think may be helpful later on.</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://blog.awaxman.com/static/2998806474cc3315063f5eddb7fc73aa/1b4bb/todoist-add.webp 1960w" sizes="(max-width: 1960px) 100vw, 1960px" type="image/webp">
        <source srcset="https://blog.awaxman.com/static/2998806474cc3315063f5eddb7fc73aa/20fa6/todoist-add.png 1960w" sizes="(max-width: 1960px) 100vw, 1960px" type="image/png">
        <img tabindex="0" src="https://blog.awaxman.com/static/2998806474cc3315063f5eddb7fc73aa/20fa6/todoist-add.png" alt="Adding a task with Todoist" title="Adding a task with Todoist" loading="lazy">
      </picture>
    </span></p><p>For the purposes of this workflow, I decided to leave the tasks in the Inbox. This reduces the need to add a Project to each item. However, if you are a regular Todoist user you will likely want to use a specific Project so that you can use your Inbox for non-time tracking items. You could either do this via a keyboard shortcut when you add activities or by manually moving all tasks to a specific project in batches. Here’s my example Inbox:</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://blog.awaxman.com/static/de47bdc95d6d2baefc6c946b0ae53510/05b1a/todoist-inbox.webp 2324w" sizes="(max-width: 2324px) 100vw, 2324px" type="image/webp">
        <source srcset="https://blog.awaxman.com/static/de47bdc95d6d2baefc6c946b0ae53510/4e898/todoist-inbox.png 2324w" sizes="(max-width: 2324px) 100vw, 2324px" type="image/png">
        <img tabindex="0" src="https://blog.awaxman.com/static/de47bdc95d6d2baefc6c946b0ae53510/4e898/todoist-inbox.png" alt="Todoist inbox" title="Todoist inbox" loading="lazy">
      </picture>
    </span></p><p>Now that the items are in Todoist, I created a script to export them into a specific CSV format that will make it easy to upload and analyze in Google Sheets. Once the script is run, you can upload the CSV file in a Google Sheet via “File &gt; Import &gt; Upload”. Here’s an example of what this could look like:</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://blog.awaxman.com/static/56aee1f33662dc570fd8ab0a62c4b661/a3bc4/data-in-sheets.webp 2500w,https://blog.awaxman.com/static/56aee1f33662dc570fd8ab0a62c4b661/2f319/data-in-sheets.webp 2638w" sizes="(max-width: 2638px) 100vw, 2638px" type="image/webp">
        <source srcset="https://blog.awaxman.com/static/56aee1f33662dc570fd8ab0a62c4b661/082ed/data-in-sheets.png 2500w,https://blog.awaxman.com/static/56aee1f33662dc570fd8ab0a62c4b661/9a9ef/data-in-sheets.png 2638w" sizes="(max-width: 2638px) 100vw, 2638px" type="image/png">
        <img tabindex="0" src="https://blog.awaxman.com/static/56aee1f33662dc570fd8ab0a62c4b661/9a9ef/data-in-sheets.png" alt="Data in sheets" title="Data in sheets" loading="lazy">
      </picture>
    </span></p><p>With the data in Sheets, you can slice, dice, and display the data to your heart’s desire using pivot tables, charts, and whatever other Sheets trickery you know. Here’s an example of a pivot table that shows an example of time spent by activity over the past week. Pivot tables make it easy to quickly change the time horizon via a dropdown menu. You can check out a demo of the workflow in action <a href="https://www.loom.com/share/66aed12aa5f14cbdadb75754ef513b55" target="_blank" rel="noreferrer">here</a>.</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://blog.awaxman.com/static/d8e2d473316f6452569c2612f102adfe/a3bc4/graph.webp 2500w,https://blog.awaxman.com/static/d8e2d473316f6452569c2612f102adfe/47fe0/graph.webp 3174w" sizes="(max-width: 3174px) 100vw, 3174px" type="image/webp">
        <source srcset="https://blog.awaxman.com/static/d8e2d473316f6452569c2612f102adfe/082ed/graph.png 2500w,https://blog.awaxman.com/static/d8e2d473316f6452569c2612f102adfe/c83ba/graph.png 3174w" sizes="(max-width: 3174px) 100vw, 3174px" type="image/png">
        <img tabindex="0" src="https://blog.awaxman.com/static/d8e2d473316f6452569c2612f102adfe/c83ba/graph.png" alt="Data graph example" title="Data graph example" loading="lazy">
      </picture>
    </span></p><h2 id="summary">Summary</h2><p>It was a lot of fun bringing this idea to life. There is no better feeling (especially as a bad developer) than bringing to life something that was just an idea a couple hours ago. While there are probably better solutions out there, I think this solution strikes a good balance of being easy to use and highly customizable, a combination that seems rare based on all the replies. If you’d like to try it out you can find the script and more specific setup instructions on <a href="https://github.com/awaxman11/todoist-time-tracker" target="_blank" rel="noreferrer">GitHub</a>.</p></div></article></div>]]>
            </description>
            <link>https://blog.awaxman.com/time-tracking-with-todoist</link>
            <guid isPermaLink="false">hacker-news-small-sites-25883439</guid>
            <pubDate>Sat, 23 Jan 2021 16:25:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Immutable zOS data with immudb – lightweight on big iron]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25883326">thread link</a>) | @vchain-dz
<br/>
January 23, 2021 | https://www.codenotary.com/blog/lightweight-on-big-iron | <a href="https://web.archive.org/web/*/https://www.codenotary.com/blog/lightweight-on-big-iron">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div>
<p><img src="https://www.codenotary.com/images/blog/mascotfree.png" width="350"></p><p>A huge percentage of the world’s most valuable data is processed on IBM mainframes. Mainframes are designed with reliability and security in mind since day one. Many libraries on mainframes should only be changed through a trusted pipeline. Tampering central and highly critical programs on a mainframe infrastructure of an organization would be a strike at the heart. Attacks like <a href="https://www.codenotary.com/blog/solarwinds-sunburst/" rel="nofollow noopener noreferrer" target="_blank">Sunburst</a> showed that cyber-criminals act opportunistic and are able to create huge damage by tampering software. Hackers won't stop at system frontiers but instead, look for a weak spot. Sometimes even mainframes get in their focus although known for being a highly secured platform. One example for that has been the <a href="https://badcyber.com/a-history-of-a-hacking/" rel="nofollow noopener noreferrer" target="_blank">Logica-Nordea mainframe hack</a>. Next to cyber-security threats orchestrated by state-funded hacker organizations is the possibility of a malicious insider attack by actors like employees. Although this scenario is not very common the consequences would be equally devastating.</p>
<p><a href="https://www.codenotary.com/technologies/immudb/" rel="nofollow noopener noreferrer" target="_blank">Immudb</a> is an open-source, lightweight, high-speed immutable database with built-in cryptographic proof and verification. It can run on almost every architecture and you can track changes in sensitive data in your transactional databases and then record those changes permanently in a tamperproof immudb database. This allows you to keep an indelible history of sensitive data, for example, debit/credit card transactions or datasets and it's members. Traditional DB transactions and logs are hard to scale and are mutable. So there is no way to know for sure if your data has been compromised. As such, immudb provides unparalleled insights retroactively of changes to your sensitive data, even if your perimeter has been compromised. immudb guarantees immutability by using cryptographic data structures internally.</p>
<h2 id="immudb-architecture-on-ibm-z">Immudb architecture on IBM Z</h2>
<p><img src="https://www.codenotary.com/images/blog/immudb-mainframe.jpg" width="450">
Immudb is lightweight and at the same time delivering unprecedented performance. Every Hardware-Architecture that is supported by golang will be able to run immudb. S390X is the Architecture of IBM Z and it is fully supported. The immudb server should run in a different and protected environment. LPAR on IBM Z is EAL5 certified therefore offering a high level of protection. Of course, immudb is also able to run next to a mainframe on distributed systems.
</p><p>We propose running immudb on Linux on Z on a different LPAR communicating with z/OS over in-memory HiperSockets reducing overhead and latency. <a href="https://github.com/codenotary/immugw" rel="nofollow noopener noreferrer" target="_blank">Immugw</a> is a middleware that provides a REST-API for immudb. The API can be consumed by z/OS through various programming languages and scripts. Take a look at rocket software's <a href="https://www.rocketsoftware.com/zos-open-source" rel="nofollow noopener noreferrer" target="_blank">open source tools for z/OS</a> to expand your scope with tools like <a href="https://www.rocketsoftware.com/platforms/ibm-z/curl-for-zos" rel="nofollow noopener noreferrer" target="_blank">cURL</a>. </p>
<p>Immudb and immugw can be deployed on Linux on Z without a hassle. Git clone the repositories and install golang. Switch to the repositories directory and type: make all. Start up ./immudb and ./immugw. Done.</p>
<h2 id="application-design">Application design</h2>
<p>It is recommended to use IBM Z's extensive crypto-hardware support (for example for hash functions) like <a href="https://www.ibm.com/support/knowledgecenter/SSYKE2_8.0.0/com.ibm.java.zsecurity.api.80.doc/com.ibm.crypto.hdwrCCA/com/ibm/crypto/hdwrCCA/provider/IBMJCECCA.html#IBMJCECCA--" rel="nofollow noopener noreferrer" target="_blank">IBMJCECCA</a>. One challenge of running highly critical systems is to ensure that no one tampered production software. Let’s start with an basic example, a developer pushed code into a protected library. Now he wants to notarize that member using immudb. He can do so by using a batch job that has the following steps:</p>
<ul>
<li>Step 1: pull the original signing program or script and verify it</li>
<li>Step 2: generate checksum of his source code and set it in immudb</li>
</ul>
<p>Now a build-job would look almost the same. First, the source will be verified. With immudb it is also possible to look up the history. An object with an unclear history wouldn't be able to get into production. The program can then be build from the trusted source and the resulting load module has to be notarized. </p>
<h3 id="example">Example</h3>
<p>In this blog we are showing how to communicate with immudb/immugw by using java. Java is a good candidate because it works in every environment even in DB2 as a stored procedure. It is possible to backup data of DB2 tables on change. More about that later.</p>
<p>Our Java programm can be run as step in JCL Jobs (for example: build jobs or jobs that are altering). The target dataset can be set as variable in JCL and passed to the java program.</p>
<div><pre><code>//JAVAJVM  EXEC PGM=JVMLDM&amp;VERSION,REGION=&amp;REGSIZE,
//   PARM='&amp;DATASET'
//STEPLIB  DD DSN=&amp;LIBRARY,DISP=SHR  
//SYSPRINT DD SYSOUT=*                   &lt;System stdout
//SYSOUT   DD SYSOUT=*                  &lt;System stderr 
//STDOUT   DD SYSOUT=*                  &lt;Java System.out 
//STDERR   DD SYSOUT=*                  &lt;Java System.err 
//CEEDUMP  DD SYSOUT=*
//ABNLIGNR DD DUMMY
//*
//*The following DDs can/should be present in the calling JCL
//*
//*STDIN   DD                       &lt;OPTIONAL - Java System.in
//*STDENV  DD                         &lt;REQUIRED - JVM Environment script
//*MAINARGS DD                          &lt;Preferred method to supply args
// PEND
</code></pre></div>
<p>The code snippet below is showing a clean way of doing HTTP-API calls with only using HttpURLConnection. That way you will not face missing dependencies in different runtime locations. The function postRequest needs to be provided with the URL of immugw and a JSON-string. The JSON-string will be converted to bytes and posted. The response is being returned.</p>
<div><pre><code><span>import</span> <span>java<span>.</span>io<span>.</span></span><span>BufferedReader</span><span>;</span>
<span>import</span> <span>java<span>.</span>io<span>.</span></span><span>IOException</span><span>;</span>
<span>import</span> <span>java<span>.</span>io<span>.</span></span><span>InputStreamReader</span><span>;</span>
<span>import</span> <span>java<span>.</span>io<span>.</span></span><span>OutputStreamWriter</span><span>;</span>
<span>import</span> <span>java<span>.</span>io<span>.</span></span><span>OutputStream</span><span>;</span>
<span>import</span> <span>java<span>.</span>net<span>.</span></span><span>HttpURLConnection</span><span>;</span>
<span>import</span> <span>java<span>.</span>security<span>.</span></span><span>Provider</span><span>;</span>
<span>import</span> <span>java<span>.</span>net<span>.</span></span>URL<span>;</span>


<span>public</span> <span>class</span> <span>Main</span> <span>{</span>
    
    <span>public</span> <span>static</span> <span>String</span> <span>postRequest</span><span>(</span><span>String</span> urlStr<span>,</span> <span>String</span> jsonBodyStr<span>,</span> <span>String</span> authorization<span>)</span> <span>throws</span> <span>IOException</span> <span>{</span>
        <span>URL</span> url <span>=</span> <span>new</span> <span>URL</span><span>(</span>urlStr<span>)</span><span>;</span>
        <span>HttpURLConnection</span> httpURLConnection <span>=</span> <span>(</span><span>HttpURLConnection</span><span>)</span> url<span>.</span><span>openConnection</span><span>(</span><span>)</span><span>;</span>
        httpURLConnection<span>.</span><span>setDoOutput</span><span>(</span><span>true</span><span>)</span><span>;</span>
        httpURLConnection<span>.</span><span>setRequestMethod</span><span>(</span><span>"POST"</span><span>)</span><span>;</span>
        httpURLConnection<span>.</span><span>setRequestProperty</span><span>(</span><span>"Content-Type"</span><span>,</span> <span>"application/json"</span><span>)</span><span>;</span>
        <span>if</span> <span>(</span>authorization <span>!=</span> <span>""</span><span>)</span><span>{</span>
            httpURLConnection<span>.</span><span>setRequestProperty</span><span>(</span><span>"Authorization"</span><span>,</span> authorization<span>)</span><span>;</span>
        <span>}</span>
        <span>try</span> <span>(</span><span>OutputStream</span> outputStream <span>=</span> httpURLConnection<span>.</span><span>getOutputStream</span><span>(</span><span>)</span><span>)</span> <span>{</span>
            outputStream<span>.</span><span>write</span><span>(</span>jsonBodyStr<span>.</span><span>getBytes</span><span>(</span><span>)</span><span>)</span><span>;</span>
            outputStream<span>.</span><span>flush</span><span>(</span><span>)</span><span>;</span>
        <span>}</span>
        <span>if</span> <span>(</span>httpURLConnection<span>.</span><span>getResponseCode</span><span>(</span><span>)</span> <span>==</span> <span>HttpURLConnection</span><span>.</span>HTTP_OK<span>)</span> <span>{</span>
            <span>try</span> <span>(</span><span>BufferedReader</span> bufferedReader <span>=</span> <span>new</span> <span>BufferedReader</span><span>(</span><span>new</span> <span>InputStreamReader</span><span>(</span>httpURLConnection<span>.</span><span>getInputStream</span><span>(</span><span>)</span><span>)</span><span>)</span><span>)</span> <span>{</span>
                <span>String</span> line<span>;</span>
                <span>while</span> <span>(</span><span>(</span>line <span>=</span> bufferedReader<span>.</span><span>readLine</span><span>(</span><span>)</span><span>)</span> <span>!=</span> <span>null</span><span>)</span> <span>{</span>
                    <span>return</span> line<span>;</span>
                <span>}</span>
                <span>}</span>
            <span>}</span>
        <span>return</span> <span>"Error code: "</span><span>+</span><span>Integer</span><span>.</span><span>toString</span><span>(</span>httpURLConnection<span>.</span><span>getResponseCode</span><span>(</span><span>)</span><span>)</span><span>;</span>
        <span>}</span>
</code></pre></div>
<p>The first request will be the login request. The Api returns a token that will be used as authorization string later on.</p>
<div><pre><code>        <span>String</span> <span>URLString</span> <span>=</span> <span>"http://LINUXONZ:3323/v1/immurestproxy/login"</span><span>;</span>
        
        <span>String</span> jsonInputString <span>=</span> <span>"{\"user\": \"aW1tdWRi\", \"password\": \"aW1tdWRi\"}"</span><span>;</span>
        <span>String</span> response <span>=</span> <span>postRequest</span><span>(</span><span>URLString</span><span>,</span>jsonInputString<span>,</span><span>""</span><span>)</span><span>;</span>
        <span>System</span><span>.</span>out<span>.</span><span>println</span><span>(</span>response<span>)</span><span>;</span>
</code></pre></div>
<p>Read in the file for creating the checksum. Use JZOS (com.ibm.jzos) and a hash-function of your favor. Set the dataset name and its hash value in immudb. Look into our <a href="https://www.codenotary.com/blog/ultimate-connectivity-for-immudb-with-immugw" rel="nofollow noopener noreferrer" target="_blank">immugw</a> blog to read more about using the immugw api.</p>
<div><pre><code>         <span>String</span> ddname <span>=</span> <span>ZFile</span><span>.</span><span>allocDummyDDName</span><span>(</span><span>)</span><span>;</span>
         <span>String</span> cmd <span>=</span> <span>"alloc fi("</span><span>+</span>ddname<span>+</span><span>") da(HLQ.MYDATA) reuse shr msg(2)"</span><span>;</span>
         <span>ZFile</span><span>.</span><span>bpxwdyn</span><span>(</span>cmd<span>)</span><span>;</span>
         <span>RecordReader</span> reader <span>=</span> <span>null</span><span>;</span>
         <span>try</span> <span>{</span>
           reader <span>=</span> <span>RecordReader</span><span>.</span><span>newReaderForDD</span><span>(</span>ddname<span>)</span><span>;</span>
           <span>byte</span><span>[</span><span>]</span> recordBuf <span>=</span> <span>new</span> <span>byte</span><span>[</span>reader<span>.</span><span>getLrecl</span><span>(</span><span>)</span><span>]</span><span>;</span>
           <span>while</span> <span>(</span><span>(</span>bytesRead <span>=</span> reader<span>.</span><span>read</span><span>(</span>recordBuf<span>)</span><span>)</span> <span>&gt;=</span> <span>0</span><span>)</span> <span>{</span>
             <span>.</span><span>.</span><span>.</span>
           <span>}</span>
</code></pre></div>
<h3 id="getting-checksums-of-datasets-on-change">Getting checksums of datasets on change</h3>
<p>With z/OS it is possible to detect changes of datasets. There are two ways of doing that. Either write a started task and listen to the <a href="https://www.ibm.com/support/knowledgecenter/SSLTBW_2.3.0/com.ibm.zos.v2r3.ieac100/ieac1-smf-inmem.htm" rel="nofollow noopener noreferrer" target="_blank">SMF realtime api</a> (SMF15) or monitor a module that gets loaded by CLOSE via CSVEXIT. Intercepting the CLOSE SVC is a delicate job but possible. Then use the name of the changed dataset create a hash and set it in immudb. That way you can track changes of datasets immutably and tamperproof.</p>
<h3 id="overcoming-ebcdic-and-ascii-conversion-challenges">Overcoming EBCDIC and ASCII conversion challenges</h3>
<p>Objects will change their checksum when they are converted from EBCDIC to ASCII and the other way around. Many code signing solutions will lose track of the object. Immudb is capable of storing JSON-Objects as value. Metadata can be added to an object referencing at the ASCII/EBCDIC checksum of the object. </p>
<div><pre><code><span>{</span>
  <span>"ascii.checksum"</span> <span>:</span> <span>"d7e4d83a94d161837aa4038cbaf9708b2bb2d91675a20493a982ce4b17d8012e"</span>
  <span>"ebcdic.checksum"</span><span>:</span> <span>"cffeab52f4f186936e3697bf1c69a6ec72d298ff94e0b40d603f453285707e2e"</span>
<span>}</span>
</code></pre></div>
<h2 id="immutability-for-db2">Immutability for DB2</h2>
<p>A possible cyber-attack could focus on databases. Cybercriminals could gain access to databases by using SQL injections. They then use their access levels to encrypt whatever they get their hands on. Immudb can keep up with the fastest databases and back up their data. Read more about that in our <a href="https://www.codenotary.com/blog/immutability-vs-ransomware" rel="nofollow noopener noreferrer" target="_blank">randomware</a> blog.</p>
<p>Triggers in DB2 will notify about changes of tables. Set an <a href="https://www.ibm.com/support/knowledgecenter/SSEPEK_12.0.0/sqlref/src/tpc/db2z_sql_altertriggeradvanced.html" rel="nofollow noopener noreferrer" target="_blank">alter trigger</a> and execute a stored procedure to store the new data of the table in immudb. Push the java code to DB2 and create the stored procedure. After that, it is callable by SQL. When the trigger is called, set the parameters and call javaproc. Use the OUT STATUS variable to report the HTTP-Code.</p>
<div><pre><code>CREATE PROCEDURE JAVAPROC (IN TABLE CHAR(99),
                           IN COLUMN CHAR(99),
                           IN KEY(99),
                           OUT STATUS INTEGER)
   NOT DETERMINISTIC
   LANGUAGE Java
   PARAMETER STYLE JAVA
   EXTERNAL NAME 'DS_20180823161823:com.userid.JAVAPROC.x_JAVAPROC'
   COLLID NULLID
   WLM ENVIRONMENT D121WLM_JAVA
</code></pre></div>
<p>Call the stored procedure with SQL:</p>
<div><pre><code>CALL IMMUDB.JAVAPROC(:TABLE,     
                     :COLUMN,   
                     :KEY,  
                     :OUT)     </code></pre></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.codenotary.com/blog/lightweight-on-big-iron">https://www.codenotary.com/blog/lightweight-on-big-iron</a></em></p>]]>
            </description>
            <link>https://www.codenotary.com/blog/lightweight-on-big-iron</link>
            <guid isPermaLink="false">hacker-news-small-sites-25883326</guid>
            <pubDate>Sat, 23 Jan 2021 16:15:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making a simple, better weather and traffic conditions map for Spain's roads]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25883265">thread link</a>) | @manugarri
<br/>
January 23, 2021 | http://blog.manugarri.com/making-a-simple-better-road-conditions-map-for-spain/ | <a href="https://web.archive.org/web/*/http://blog.manugarri.com/making-a-simple-better-road-conditions-map-for-spain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<h2 id="tldr">TL;DR</h2>

<p>I made a map displaying weather and traffic road conditions for Spain that is easier to use, nicer and faster than the official Spanish Government map. <br>
As usual (<a href="http://blog.manugarri.com/where-the-f-can-i-park/">1</a>, <a href="http://blog.manugarri.com/the-sorry-state-of-transparency-in-spain-where-is-my-certificate/">2</a>), I keep being disappointed with the Spanish Government Open Data policies.</p>

<p>You can check out the map <a href="http://dgt.manugarri.com/">here</a>. I also shared the required code on <a href="https://github.com/manugarri/dgt_map">Github</a>.</p>

<h2 id="anintroductionandabitofranting">An introduction, and a bit of ranting.</h2>

<p>It was January 2021, and I was spending the holidays with my family in my awesome hometown of <a href="http://blog.manugarri.com/plotting-100k-tweets-from-my-home-town/">Murcia, Spain</a>.</p>

<p>For you future travelers, this year was the COVID pandemic year, so things were a bit weird and traveling wasnt as easy as you whipersnappers are used to. Me and my family (two kids at the moment of writing this) would be driving back from Murcia to Lisbon, Portugal where I reside.</p>

<p>Additionally, this year saw record breaking snowstorms in Spain thanks to (<a href="https://www.bbc.com/news/world-europe-55612955">Storm Filomena</a>).</p>

<p>These two reasons meant that going back home to Lisbon from my hometown required planning, since there was a real risk of getting stuck in the car with 2 crying babies (omg Im shivering just thinking about it).</p>

<p>So a couple days before the travel day, I checked online to see any information on the roads.</p>

<p>The best resource I could find (<strong>and if there is a better resource, the fact that it cant be easily found defeats its purpose</strong>) was the official Spain Traffic Authority (DGT, <em>Direccion General de Trafico</em>) Map. You can check it <a href="http://infocar.dgt.es/etraffic/">here</a></p>

<p>Here is a screenshot of how the map looks like: <br>
<img src="https://i.imgur.com/wAbVIe9.png" alt="ugh"></p>

<p>There are a few things that trigger me when I see this map:</p>

<ul>
<li><em>Slow</em>, this map seems to be an embedded map from an internal GIS system or something, plus it has a ton of features that makes it pretty slow.</li>
<li><em>Confusing</em> no legend regarding event types</li>
<li><em>Overall Ugliness</em>, you can tell icons just jam up next to each other, and they are mostly gray, with a tiny hint of color indicating the road circulation level.</li>
</ul>

<p>But the worst thing of all, <em>there is no navigation search!</em>.  This means the official traffic map forces you to know the actual code of the road you are planning to drive on in order to see if there are any weather events affecting the road's state. <strong>Im not a truck driver! I don't know these names!</strong></p>

<p>What I needed at that uncertain time was to be able <strong>to find out if driving from point A to Point B would go through any road that was blocked for any reason</strong>. The only way to do so with the official map was to search in google maps for driving directions and then check the DGT map for any road event.</p>

<h2 id="buildingabettermap">Building a better map</h2>

<p>Here is my version (<a href="http://dgt.manugarri.com/">link</a>)</p>

<p><img src="https://i.imgur.com/2uMnyqi.png" alt="tadaa!"></p>

<p>You may notice a few differences between my map and DGT map:</p>

<ul>
<li><em>fast</em>, my map consist of a simple map, so the only loading consists of the map tiles themselves</li>
<li><em>easy to read</em> , my map has an actual legend that indicates what each icon means. This is Dataviz 101</li>
<li><em>pretty</em>, this is more of a personal opinion, but using brighter colors for the event icons makes the map more appealing, and visual appeal increases user engagement. </li>
</ul>

<p>And most important of all, <strong>you can get see the road conditions for the trip you are planning!</strong>. Just type the origin and destination and click the button, and the map will plot the route.</p>

<p><img src="https://i.imgur.com/PHk7NjD.png" alt="it aint hard"></p>

<h2 id="applicationdetails">Application Details</h2>

<p>You can see the code powering the map on <a href="https://github.com/manugarri/dgt_map">Github</a>.</p>

<p>My initial idea was to implement the map as a 100% frontend solution, since that would keep the site from exploding if it becomes too popular,  but due to <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS">CORS</a> limitations I had to implement a simple backend to fetch the DGT road condition events.</p>

<p>The backend app is a <a href="https://fastapi.tiangolo.com/">FastAPI</a> web application in charge of rendering the index page, fetching the road condition events, and geocoding the navigation search terms. It is the first time I use FastAPI, and its super easy to use and faster than other similar microframeworks (like Flask)</p>

<p>The map itself is a simple Leaflet map with overlaid events, when the user loads the map, an HTTP GET request fetches the official DGT road conditions data from <a href="http://infocar.dgt.es/etraffic/BuscarElementos?latNS=44&amp;longNS=5&amp;latSW=27&amp;longSW=-19&amp;zoom=6&amp;accion=getElementos&amp;Camaras=true&amp;SensoresTrafico=true&amp;SensoresMeteorologico=true&amp;Paneles=true&amp;Radares=true&amp;IncidenciasRETENCION=true&amp;IncidenciasOBRAS=false&amp;IncidenciasMETEOROLOGICA=true&amp;IncidenciasPUERTOS=true&amp;IncidenciasOTROS=true&amp;IncidenciasEVENTOS=true&amp;IncidenciasRESTRICCIONES=true&amp;niveles=true&amp;caracter=acontecimiento">this url</a> , the same one the official map uses (you can check using the developer network tools on your browser). </p>

<p>I used <a href="https://www.python-httpx.org/">httpx</a> to perform the GET request, for no reason besides testing it, its supposed to be the next Requests.</p>

<p>Leaflet provides basic icons out of the box, but since I wanted to display a few different event types, I used erikflower's awesome <a href="https://erikflowers.github.io/weather-icons/">Weather icons</a>. These icons not only are beautiful (particularly compared to DGT's <a href="http://infocar.dgt.es/etraffic/img/iconosIncitar/">ugly ones</a>), but also render very fast since they are not bitmaps.</p>

<p>I found it a bit complicated how to add custom icons, but <a href="http://blog.manugarri.com/making-a-simple-better-road-conditions-map-for-spain/(https://www.geoapify.com/create-custom-map-marker-icon)">this doc</a> explains it nicely.</p>

<p>Finally, I used <a href="https://openrouteservice.org/">OpenRouteService</a> as a geocoding package to translate the Navigation search terms into geocoordinates. It doesnt work as well as Google Maps, but its open source and Google Maps has turned a bit evil in recent times. OpenRouteService has a nice <a href="https://openrouteservice-py.readthedocs.io/">python package</a>.</p>

<h2 id="notes">Notes</h2>

<ol>
<li>Leaflet keeps getting better and better!, now its super easy to add custom tile providers. there are even a ton of tile providers now thanks to the awesome <a href="https://github.com/leaflet-extras/leaflet-providers">leaflet-providers</a> project. For example, here is how the map looks like with a different tile provider (Stadia)</li>
</ol>

<p><img src="https://i.imgur.com/lLif5Ff.png" alt="stadia"></p>

<ol>
<li>Again and again, I come up with a nice frontend project idea that I have to implement with a backend just because of <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS">CORS</a>. There should be a way to disable CORS for well spirited applications. Maybe prompting the user to disable CORS for a site?</li>
</ol>
			</section></div>]]>
            </description>
            <link>http://blog.manugarri.com/making-a-simple-better-road-conditions-map-for-spain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25883265</guid>
            <pubDate>Sat, 23 Jan 2021 16:10:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chickenization]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25883032">thread link</a>) | @jzelinskie
<br/>
January 23, 2021 | https://pluralistic.net/2020/10/02/chickenized-by-arise/#arise | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/10/02/chickenized-by-arise/#arise">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1445">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
chickenization, arise, mlm, disney, intuit, airbnb, comcast, carnival, class war, guillotine watch, dan hillier, gift guide, art, engravings, collage, public domain, apple, china, app stores, drm, ios, mobile, human rights, rss

Summary:
Call center workers pay for the privilege; Dan Hillier's Six Women/Six Men; Apple kills RSS readers in China

URL:
https://pluralistic.net/2020/10/02/chickenized-by-arise/

Title:
Pluralistic: 02 Oct 2020 chickenized-by-arise

Bullet:
🎃

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: JWZ (https://www.jwz.org/blog/).

--><br>
<a href="https://pluralistic.net/2020/10/02/chickenized-by-arise/"><img src="https://i1.wp.com/craphound.com/images/02Oct2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/02Oct2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/10/02/chickenized-by-arise/#arise">Call center workers pay for the privilege</a>: Propublica breaks open the massive, secretive abuser Arise, fronted by Disney, Airbnb, Intuit, Comcast, Carnival and more.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/10/02/chickenized-by-arise/#hillier">Dan Hillier's Six Women/Six Men</a>: New "box sets" from the spooky, brilliant collagist.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/10/02/chickenized-by-arise/#rss-ccp-rip">Apple kills RSS readers in China</a>: Chekhov's Law for DRM strikes again.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/10/02/chickenized-by-arise/#retro">This day in history</a>: 2015, 2019
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/10/02/chickenized-by-arise/#bragsheet">Colophon</a>: Recent publications, upcoming appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="arise"></a><br>
<img src="https://i1.wp.com/craphound.com/images/main-qimg-153bc76c2b6706d6949ef31d64eda375.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/main-qimg-153bc76c2b6706d6949ef31d64eda375.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>If you only learn one technical term from labor economics, make it "chickenization" – Christopher Leonard's term for the way that the Big Three poultry processors have structured the chicken-farming industry (I learned it from Zephyr Teachout).</p>
<p><a href="https://pluralistic.net/2020/07/29/break-em-up/#break-em-up">https://pluralistic.net/2020/07/29/break-em-up/#break-em-up</a></p>
<p>Here's chickenization: you're a chicken farmer. There is only one company that can buy your birds, thanks to market concentration. They tell you how to design and maintain your coop. They sell you the chicks. They tell you which feed to use, how much and when.</p>
<p>They tell you when the lights go on and when they go off. They tell you how which vet to use, and which medicines they can use. They bind you to secrecy through nondisclosure and strip you of the right to sue through arbitration.</p>
<p>They experiment on you. Your barn is filled with sensors that they monitor, and they tell you to vary feed, lighting, medicine and other variables to see if your birds get bigger. They are the only buyer in your region, so they know how each farmer's birds are thriving.</p>
<p>But if the "independent" farmers ever tried to compare notes, they'd be violating their nondisclosure agreements and could be sued. Farmers who complain to regulators are barred from the market.</p>
<p>Once your birds are grown, you bring them to the processor, who exploits their information asymmetry to figure out how to pay you JUST ENOUGH to go back to things, but not enough to get ahead. Since chickenization, poultry farmers have faced a wave of suicides.</p>
<p>Once you know about chickenization, you see it everywhere: crop farmers are chickenized by seed companies, and Uber drivers are chickenized by their apps.</p>
<p>The contours of chickenization are impossible to miss: it's a shifting of all the risk from the employer's side of the balance sheet to the workers', using the fiction of independent contractorship, the data-gathering capabilities of digital work, and monopolies.</p>
<p>Today, I learned about the worst chickenization scheme I've ever encountered: a giant, global company that has chickenized a vast workforce, but maintains total secrecy, even as it services massive blue-chip companies from Airbnb to Disney.</p>
<p>That company is Arise, and Propublica and Planet Money just blew the roof off its ghastly charnel house of a chicken farm by, as Ken Armstrong, Justin Elliott and Ariana Tobin reported out leaks, arbitration reports, and whistleblower accounts.</p>
<p><a href="https://www.propublica.org/article/meet-the-customer-service-reps-for-disney-and-airbnb-who-have-to-pay-to-talk-to-you#1001065">https://www.propublica.org/article/meet-the-customer-service-reps-for-disney-and-airbnb-who-have-to-pay-to-talk-to-you#1001065</a></p>
<p>Here's chickenization, Arise style: the company is a outsource phone support system. Workers have to pay to work for Arise (they're "independent contractors"): buy a dedicated PC, internet connection and other equipment.</p>
<p>They have to do weeks of unpaid "training" just to get started, and then they have to pay more to get specific training for every one of Arise's giant corporate clients, from AT&amp;T to Carnival Cruises to Comcast to Disney to Airbnb to Intuit to Barnes and Noble to Ebay.</p>
<p>After passing random, invasive, in-home inspections, after shelling out thousands of dollars and doing weeks – if not months – of unpaid training, they are finally eligible to sign up for shifts.</p>
<p>These shifts come in 30 minute slices, widely spaced, and turning them down gets you blacklisted. It's impossible to hold down another job while you're an Arise chicken-farmer.</p>
<p>But you don't get paid for 30-minute shifts. You just get paid for the time that you're talking to customers.</p>
<p>The whole time you talk to a customer, an algorithm is ready to penalize you: i.e., if it takes too long to deal with queries, or if there're too many pauses.</p>
<p>Meanwhile, the client's outsource managers randomly (or not-randomly) listen in on your calls, and they can penalize you too.</p>
<p>The main penalty is being "deskilled" – barred from working for that client, after paying (in cash and time) to get trained to be their phone rep.</p>
<p>Workers are barred from hanging up on abusive customers. Women report high levels of sexual harassment, which they have to patiently endure, because they risk getting fired if they hang up on their abusers.</p>
<p>And all workers are expected to tolerate unlimited abuse from callers. 64% of Arise's workers are people of color. 89% of them are women. Arise's recruiting ads target Black women in particular.</p>
<p>There <em>is</em> a way to get ahead in Arise: recruit other workers. Because, in addition to everything else, it's a pyramid scheme, and the business is riddled with people who've been previously convicted of wire fraud.</p>
<p>Nearly every person in the Arise structure is chickenized:. The following jobs are all performed by "independent contractors":</p>
<ul>
<li>Client Support Professionals</li>
<li>Quality Assurance Performance Facilitators</li>
<li>Chat Performance Facilitators</li>
<li>Escalation Performance Facilitators</li>
</ul>
<p>Not only do you have to pay to work for Arise – you have to pay (a "contract termination fee") to stop working for them.</p>
<p>Arise binds workers to arbitration, meaning they can't sue. The right of workers to join class actions in spite of arbitration waivers went to the Supreme Court in '18, where the illegitimate justice Neal Gorsuch wrote the majority opinion, ruling against workers.</p>
<p>Arise honors Juneteenth with a day off for all employees. But all those Black women it has chickenized are independent businesses and are still expected to show up for work.</p>
<p>Arise's founder is Richard Cherry, a Canadian "serial entrepreneur" who started off writing scammy get-rich-quick and lose-weight-quick books before moving to Florida and getting heavily involved with the Home Shopping Network.</p>
<p>Today, the company is a division of a giant private equity fund, Warburg Pincus.</p>
<hr>
<p><a name="hillier"></a><br>
<img src="https://i1.wp.com/craphound.com/images/Box-sets-gold-5_d7bd7b23-de34-4634-abb0-fbedbe140be6_2000x.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/Box-sets-gold-5_d7bd7b23-de34-4634-abb0-fbedbe140be6_2000x.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>One of my all-time favorite artists is London's Dan Hillier, who has made a career out of finding public domain engravings, scanning and cleaning them up, and then making spooky, haunting, grotesque and infinitely lovely collages out of them.</p>
<p>Hillier has just launched two new projects: "Six Women" and "Six Men," a pair of "box sets" of  previously released and sold out work in fresh editions as giclee prints augmented by handpainted, very fine 24K gold leaf, sold as framed sets.</p>
<p><img src="https://i2.wp.com/craphound.com/images/hilliersixwomen.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/hilliersixwomen.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><br>
<img src="https://i0.wp.com/craphound.com/images/hilliersixmen.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/hilliersixmen.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>The sets are limited editions, framed in antique-black finish beech by Dylan Shipton Frames, and the prints float in behind anti-UV glass. You can see them in person at Hillier's (distanced/ventimated) Walthamstow gallery or buy them online:</p>
<p><a href="https://danhillier.com/collections/gold-leaf-specials">https://danhillier.com/collections/gold-leaf-specials</a></p>
<hr>
<p><a name="rss-ccp-rip"></a><br>
<img src="https://i1.wp.com/craphound.com/images/apple-china.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/apple-china.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Chekhov exhorted writers not to put a gun onstage unless a character is going to fire it. But this advice has a corollary for audiences: "If there's a pistol on the mantelpiece in Act I, it'll go off by Act III."</p>
<p>If only Apple had paid attention.</p>
<p>Apple wasn't the first company to use DRM to prevent users from installing software on devices without its approval (game consoles did this for years), but it WAS the first company to popularize the model for general purpose devices.</p>
<p>Ten years ago, I predicted that once Apple gave itself the power to decide which software you were allowed to use, governments would start ordering it to prevent you from using software they didn't like.</p>
<p><a href="https://boingboing.net/2010/04/02/why-i-wont-buy-an-ipad-and-thi.html">https://boingboing.net/2010/04/02/why-i-wont-buy-an-ipad-and-thi.html</a></p>
<p>Three years ago, Apple kicked aa working VPNs out of the Chinese App Store, to so that the Chinese state – which was in the midst of rounding up <em>one million</em> Uyghurs and putting them in concentration camps – could spy on its population more effectively</p>
<p><a href="https://www.ft.com/content/ad42e536-cf36-11e7-b781-794ce08b24dc">https://www.ft.com/content/ad42e536-cf36-11e7-b781-794ce08b24dc</a></p>
<p>Now, Apple's purged its Chinese App Store of RSS readers, which allow Apple customers in China to evade state censorship and surveillance, which have been used in lethal ways, including targeting dissidents for organ-harvesting.</p>
<p><a href="https://techcrunch.com/2020/09/30/apple-removes-two-rss-feed-readers-from-china-app-store/">https://techcrunch.com/2020/09/30/apple-removes-two-rss-feed-readers-from-china-app-store/</a></p>
<p>This is a really stark example of the failure of the "feudal security" model we have evolved as states have both failed to create protections for users (e.g. a US federal privacy law with a private right of action) and to prevent monopolization of tech.</p>
<p>Deprived of the legal tools to defend ourselves with, we are forced to seek protection from feudal seigneurs (e.g. tech companies) and hope that their business interests align with our human rights interests.</p>
<p>So you can use Chrome, which is about to start blocking third-party cookies, meaning that other people can't track you – but Google can. Google doesn't want to protect your privacy – it wants to get a piece of the action.</p>
<p>Google will use this power to incidentally protect your privacy by blocking some of the worst online surveillance, but if you're worried about Google itself (or one of its trusted parties) abusing your data, Chrome won't help you.</p>
<p>Likewise, Apple makes a big (and deserved) deal out of its privacy orientation, but that privacy is in service to a marketing message: "Apple is the pro-privacy alternative." Apple cares about selling devices, and privacy is a means to that end.</p>
<p>Apple's decision to both manufacture and sell devices in China, combined with its power to choose which apps you can use, all but guaranteed that it would be deputized to aid in mass roundups for concentration camps and organ harvesting.</p>
<p>Meanwhile, the policies that Apple relies on to prevent companies creating third-party app stores – policies like DMCA 1201, the copyright law that bans breaking Apple DRM – are defended by an infinite warchest funded by all …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2020/10/02/chickenized-by-arise/#arise">https://pluralistic.net/2020/10/02/chickenized-by-arise/#arise</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2020/10/02/chickenized-by-arise/#arise</link>
            <guid isPermaLink="false">hacker-news-small-sites-25883032</guid>
            <pubDate>Sat, 23 Jan 2021 15:48:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoiding the One Step Back]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25882914">thread link</a>) | @meatandcheese
<br/>
January 23, 2021 | https://staysaasy.com/management/2021/01/21/Step-Back.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2021/01/21/Step-Back.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Teams, especially at growth companies, often have a pattern of taking two steps forward and one step back. Let’s explore how teams often unknowingly slip after growing and let’s explore ways to prevent that from happening. Only forward steps!</p>

<h2 id="this-happens-a-lot---the-setup">This Happens A Lot - The Setup</h2>

<p>Let’s talk about my favorite pretend team, The Acme Widget Builders. It’s a cross-functional team with a product manager, an engineering manager, and a number of engineers. The team is operating very well and is growing with the company. Eventually the Original Product Manager has to hire another PM to manage the team, so the Original Product Manager can manage a larger group of teams.</p>

<p>About 6 months later the team starts to suffer a string of quality issues. Nobody really knows why this is happening, but it’s frustrating. The team starts to focus much more heavily on QA and gets back on the righteous path over time. However, a concern remains - what happened?</p>

<h2 id="this-happens-a-lot---the-diagnosis">This Happens A Lot - The Diagnosis</h2>

<p>After doing some soul searching about what the heck happened, you realize that the Original Product Owner was a Widget Whiz. They knew every single thing about the Acme Widgets, and, in fact, they were catching a lot of bugs when reviewing features-to-be-launched at the UAT phase. Herein lies the issue.</p>

<p>It’s not really the PMs primary job to catch bugs in the UAT phase. Actually, when the Original Product Owner transferred the team responsibility to the new PM, the Original Product Owner never mentioned the QA they were doing in UAT. As a result, the team lost a critical QA resource and never thought about how to counteract that reality.</p>

<h2 id="implicit-responsibilities">Implicit Responsibilities</h2>

<p>When team’s grow, explicit responsibilities are often transferred deftly and quickly as new team members join. However, implicit or unstated responsibilities often fall by the wayside. It’s not part of the official checklist, it might not even be part of the job, but the reality remains - if you’re filling a gap and leave without finding a replacement, that gap is going to show up as soon as you leave.</p>

<p>Furthermore, you might have an explicit responsibility that you do way better than expected. Handing off that responsibility to someone who is not going to fully fill your shoes (even if at first), is another form of creating implicit gaps on the team.</p>

<h2 id="the-fix">The Fix</h2>

<p>When you transition a team that you were previously a leader in, take stock of the things you were doing that weren’t part of the official role. Consider things that you are disproportionately owning for the team. It can be anything: meeting running, architecture, QA, recruiting.</p>

<p>Then, find ways to do some of the following:</p>
<ul>
  <li>Let people know the gaps will exist. Announce the diagnosis.</li>
  <li>Find ways to personally ensure continuity and resource the gap.</li>
</ul>



    

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2021/01/21/Step-Back.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25882914</guid>
            <pubDate>Sat, 23 Jan 2021 15:33:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rollerball Pens of 2021]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 121 (<a href="https://news.ycombinator.com/item?id=25882702">thread link</a>) | @thomas
<br/>
January 23, 2021 | https://unsharpen.com/best-rollerball-pen/ | <a href="https://web.archive.org/web/*/https://unsharpen.com/best-rollerball-pen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><small>Unsharpen may earn a commission when you buy through links on our site.</small></p><div>

                                
                                <p>If you are in search of a great rollerball you have a lot of work ahead of you. There are many brands of rollerball pens and many styles of rollerball inks, as well as many sizes and colors.</p>
<p>We’ve done the testing and done the research to fine the best rollerball pens and rollerball refills available today.</p>

<h2><span id="What_Is_A_Rollerball_Pen">What Is A Rollerball Pen?</span></h2>
<p>As we noted in our <a href="https://unsharpen.com/ballpoint-vs-rollerball/">rollerball vs. ballpoint guide</a>, a rollerball is a pen that uses water-based ink where a ballpoint pen uses oil-based ink. Rollerballs use smaller writing tips — usually 0.5 mm or 0.7 mm — because their ink spreads out on the paper and forms lines that are wider than the tip of the pen. Most rollerballs use dye for color but some are pigments so they are water-resistant and semi-permanent.</p>
<p>Japanese pen maker Ohto is created with developing the first rollerball, then known as the “water-based ballpoint ink pen” in 1964.</p>
<figure id="attachment_7469" aria-describedby="caption-attachment-7469"><a href="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Unsharpen-Rollerball-Scan-scaled.jpg"><img loading="lazy" src="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Unsharpen-Rollerball-Scan-450x303.jpg" alt="Unsharpen Rollerball Scan" width="450" height="303" srcset="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Unsharpen-Rollerball-Scan-450x303.jpg 450w, https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Unsharpen-Rollerball-Scan-1024x690.jpg 1024w, https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Unsharpen-Rollerball-Scan-768x517.jpg 768w, https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Unsharpen-Rollerball-Scan-1536x1035.jpg 1536w" sizes="(max-width: 450px) 100vw, 450px"></a><figcaption id="caption-attachment-7469">Unsharpen Rollerball Pen Testing Sample Scan</figcaption></figure><h2><span id="Testing_Rollerball_Pens">Testing Rollerball Pens</span></h2>
<p>In order to create this guide in a repeatable, methodical manner, we purchased a large number of rollerball pens and refills and use each across a number of different paper types. The favorite pens and refills were isolated and then used further, both for testing and real-world writing. The below rollerball pens — our top picks — are the ones we considered to be the finest rollerballs sold today.</p>
<p>Please note, that while the initial testing list included many rollerball pens, the list was not exhaustive and where are always pens and refills that will be missing in any test like this. Please contact us if you see anything notable missing.</p>
<p>Where possible all sizes of a rollerball were tested and both blue and black were testing. When options were limited the focus was on blue and 1.0 mm, which is where a rollerball can really differentiate itself from the competition.</p>
<p>Please note that gel pens were not part of this test. Gel pens have become their own category and will receive their own buying guide! <a href="https://unsharpen.com/rollerball-pen-fountain-pen-ink/">Refillable rollerball pens</a> are eligible for this list.</p>
<h2><span id="Best_Mainstream_Rollerball_Pens">Best Mainstream Rollerball Pens</span></h2>
<p>If you find yourself walking through the aisles of an office superstore and you want a great rollerball, what should you get? Or if you want a 12-pack of excellent, not-too-expensive rollerballs, what’s the best pick? These are the pens in this list.</p>
<h3><span id="Uni-ball_Vision_Elite">Uni-ball Vision Elite</span></h3>
<p>The <a href="https://unsharpen.com/pen/uni-ball-vision-elite/">Uni-ball Vision Elite</a>&nbsp;has lone been a top pick among choosy rollerball fans as well as dedicated fountain pen users who want something for day-to-day writing. This pen is smooth, a bit watery in its ink, and uses Uni-ball’s Super Ink, which is chemical-, water-, and fade-resistant, plus is acid-free and of archival quality.</p>
<p>This pen is affordable, easy to find, quite smooth, and is reliable. The downsides are that its design is somewhat dated at this point, and it’s not really refillable <a href="https://amzn.to/3hrqYhu" target="_blank" rel="nofollow noopener noreferrer">(the refills are almost full pens themselves</a>). This is the essence of a great everyday rollerball.</p>
<p><a href="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Uni-ball_Vision_Elite.jpg"><img loading="lazy" src="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Uni-ball_Vision_Elite-450x51.jpg" alt="" width="450" height="51" srcset="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Uni-ball_Vision_Elite-450x51.jpg 450w, https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Uni-ball_Vision_Elite-1024x117.jpg 1024w, https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Uni-ball_Vision_Elite-768x87.jpg 768w, https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Uni-ball_Vision_Elite.jpg 1476w" sizes="(max-width: 450px) 100vw, 450px"></a></p>
<h3><span id="Uni-ball_Air">Uni-ball Air</span></h3>
<p>The <a href="https://unsharpen.com/pen/uni-ball-air/">Uni-ball Air</a>&nbsp;is a unique, high-tech take of the everyday rollerball. It also uses Uni-ball’s everything-resistant Super Ink and it’s similarly not refillable, but it has Uni’s “Cushion Tip” writing end which is smooth and forgiving, making the pen a great choice for almost all writing scenarios.</p>
<p>The pen isn’t refillable and has an entirely plastic body (including the clip), but it’s still a great everyday rollerball because it’s fun to use, easy to find, and a great writer overall.</p>
<h2><span id="Best_Rollerball_Pens">Best Rollerball Pens</span></h2>
<p>If you are in the market for a great rollerball pen and are willing to upgrade past a disposable pen, here are the top picks of 2021.</p>
<p><a href="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/zoom_505-e1608993432315.jpg"><img loading="lazy" src="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/zoom_505-e1608993432315-450x44.jpg" alt="" width="450" height="44" srcset="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/zoom_505-e1608993432315-450x44.jpg 450w, https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/zoom_505-e1608993432315-768x75.jpg 768w, https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/zoom_505-e1608993432315.jpg 1000w" sizes="(max-width: 450px) 100vw, 450px"></a></p>
<h3><span id="Tombow_Zoom_505">Tombow Zoom 505</span></h3>
<p>The Tombow Zoom 505 combines an affordable metal body with a pigmented refill that is permanent and surprisingly fun to use, even though Tombow is not typically known for their rollerballs. The build quality of this pen’s body is excellent for the price which is surprising right around $20.</p>
<p>The Tombow Zoom 505 also benefits from being sold as a set of instruments. So if you like the rollerball, you can also buy the 505 in a mechanical pencil and a fountain pen. The downsides of this rollerball are that it has a proprietary refill, the older models of which tend to leak, but it’s still a great writer.</p>
<h3><span id="Lamy_Vista">Lamy Vista</span></h3>
<p>The Lamy Vista (the clear version of the Lamy Safari) uses Lamy’s <a href="https://unsharpen.com/refill/lamy-m63/">M63 rollerball refill</a>. This means the pen is a combination of a good rollerball refill and a great pen body. The good news is that the refill is easy to swap out if you want to use a standard European rollerball refill, like a Waterman or even a Pilot G2 gel refill. This is just an all-round great pen that is ideal for everyday use and will last you for years of writing.l</p>
<p><a href="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Pilot-Rollerballs.jpg"><img loading="lazy" src="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Pilot-Rollerballs-450x226.jpg" alt="" width="450" height="226" srcset="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Pilot-Rollerballs-450x226.jpg 450w, https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Pilot-Rollerballs-768x386.jpg 768w, https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Pilot-Rollerballs-1024x515.jpg 1024w" sizes="(max-width: 450px) 100vw, 450px"></a></p>
<h3><span id="Pilot_Hi-Tecpoint_V7">Pilot Hi-Tecpoint V7</span></h3>
<p>The <a href="https://unsharpen.com/pilot-precise-and-hi-tecpoint-pen-guide/">Hi-Tecpoint V7</a> is a refillable rollerball pen that uses fountain pen-like cartridges and a liquid rollerball ink. The pen is great looking, with a flat paint job, and handsome aesthetics. The pen is like a better version of the Pilot Precise V7 — which is much more common in the US — because the Hi-Tecpoint looks better and is refillable using a cartridge.</p>
<p>Then pen is also sold in a very wet 1.0 mm and a smooth but precise 0.5 mm version, called the <a href="https://unsharpen.com/pen/pilot-v10-grip-hi-tecpoint/">V10</a> and V5 respectively.</p>
<p><a href="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/stabilo-bionic-worker.png"><img loading="lazy" src="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/stabilo-bionic-worker-450x46.png" alt="" width="450" height="46" srcset="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/stabilo-bionic-worker-450x46.png 450w, https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/stabilo-bionic-worker.png 680w" sizes="(max-width: 450px) 100vw, 450px"></a></p>
<h3><span id="Stabilo_Worker">Stabilo Worker+</span></h3>
<p>While it’s not as popular as the rest of the pens on this list, the Stabilo Worker+ is an excellent roller, as is its refillable counterpart, the <a href="https://unsharpen.com/pen/stabilo-bionic/">Bionic</a>. These pens have confusing conventions, where the 0.5 mm Medium version writes more like a 1.0 mm, but they are both exceptionally smooth and comfortable pens.</p>
<p>The Worker+ is known for its bold orange body and comfortable rubber coating, but then pen is also available in black, grey, and now other colors if you want something more muted.</p>
<p>This is super smooth rollerball that deserves more attention.</p>



                            </div></div>]]>
            </description>
            <link>https://unsharpen.com/best-rollerball-pen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25882702</guid>
            <pubDate>Sat, 23 Jan 2021 15:04:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FBI agents track cell phones that pinged near the Capitol]]>
            </title>
            <description>
<![CDATA[
Score 318 | Comments 443 (<a href="https://news.ycombinator.com/item?id=25882688">thread link</a>) | @danso
<br/>
January 23, 2021 | https://www.wusa9.com/article/features/producers-picks/fbi-tracks-cell-phones-that-were-near-capitol-insurrection-and-riot/65-ca268165-a5c5-46a4-8b88-943a8517343a | <a href="https://web.archive.org/web/*/https://www.wusa9.com/article/features/producers-picks/fbi-tracks-cell-phones-that-were-near-capitol-insurrection-and-riot/65-ca268165-a5c5-46a4-8b88-943a8517343a">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A DC woman said an FBI agent contacted her and said investigators were reaching out to the owner of every phone that touched a cell tower near the riot.</p><div>
                            <p>WASHINGTON — If you were anywhere near the Capitol on Jan. 6, you may be getting a knock on your door from the FBI.</p>
                    <p>A D.C. woman said an agent visited her neighbor and called her, telling them investigators were tracking people whose cell phones connected to wi-fi or pinged cell phone towers near the Capitol during the riots.</p>
                        
                    <p>"They don't call first, they just come to your house," Bree Stevens, a legal investigator who lives near Capitol Hill, said.&nbsp;</p>
                    <p>Stevens said an FBI agent told her they were reaching out to every single person whose cell phone put them near the Capitol during the riots.</p>
                    <p>She was out for a walk with a friend and his two young daughters on the afternoon of Jan. 6, but they were diverted by bomb scares until they ended up right next to the insurrection. Adults and kids were cordoned off and unable to get back to their apartments for four hours.</p>
                    <p>"You don't want to be anywhere where they're going to go!" she said on a video she shot while police officers in riot gear quick-stepped toward the Capitol.&nbsp;</p>
                                <div>
        <div data-module="video" data-stream="https://video.tegna-media.com/assets/WUSA/videos/187d0b2f-3e6e-4754-8f6a-fa7174d479fd/187d0b2f-3e6e-4754-8f6a-fa7174d479fd.m3u8" data-float="false" data-thumbnail="https://media.wusa9.com/assets/WUSA/images/05e27a77-8b56-418d-aede-fe82b97100b1/05e27a77-8b56-418d-aede-fe82b97100b1_1920x1080.jpg" data-title="More than 85 people charged in the US Capitol riots" data-description="Authorities say additional complaints have been submitted and investigations are ongoing." data-site="65" data-id="187d0b2f-3e6e-4754-8f6a-fa7174d479fd" data-dfpposition="" data-mute="false" data-autoplay="false" data-link="https://www.wusa9.com/video/news/more-than-85-people-charged-in-the-us-capitol-riots/65-187d0b2f-3e6e-4754-8f6a-fa7174d479fd" data-origin="clipping" data-section="news" data-subsection="" data-subcategory="" data-topic="" data-subtopic="" data-captions="" data-related-playlist-id="tSIkxFyA" data-related-media-id="9qoUuTLb" data-use-trending="true" data-is-watch-player="false" data-is-live-now="false" data-ugc-preroll-disabled="true" data-duration="129" data-disable-preroll-at-duration="0">
            <div>
                <div>
                    <div>
                        <div>
                            <p><img data-asset-fallback="default" src="https://media.wusa9.com/assets/WUSA/images/05e27a77-8b56-418d-aede-fe82b97100b1/05e27a77-8b56-418d-aede-fe82b97100b1_1920x1080.jpg"></p>
                            
                        </div>
                        
                    </div>
                </div>
            </div>
                            
        </div>
                                </div>
                    <p><br>Monday night, an investigator knocked on the door of her friend's apartment, who was "in house clothes" at the time.&nbsp;</p>
                    <p>"His little girl had just painted his toenails, that was a little bit embarrassing," Stevens said.&nbsp;</p>
                    <p>Stevens was out of town, so the agent called her on the phone number that the FBI had tracked.&nbsp;</p>
                    <p>"Extremely creepy, because he explained that they have everyone’s phone number from pinging off the cell phone towers, and they know basically exactly where you were, within the vicinity of the Capitol," Stevens said. "And they can actually pinpoint on Google Maps exactly where you were standing. Like, he knew where I was standing on the sidewalk, like specifically, based on my cell phone ping."&nbsp;</p>
                    <p>Stevens said the agent told her she wasn't a suspect, but said he wanted pictures of things she might have seen.</p>
                    <p>Some civil rights advocates are concerned about the FBI's surveillance power.</p>
                    <p>When contacted, the FBI declined to discuss its investigative methods.&nbsp;</p>
                                

                    
                    
    </div></div>]]>
            </description>
            <link>https://www.wusa9.com/article/features/producers-picks/fbi-tracks-cell-phones-that-were-near-capitol-insurrection-and-riot/65-ca268165-a5c5-46a4-8b88-943a8517343a</link>
            <guid isPermaLink="false">hacker-news-small-sites-25882688</guid>
            <pubDate>Sat, 23 Jan 2021 15:02:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Rust in WebAssembly in a Pool of Concurrent Web Workers in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25882677">thread link</a>) | @kiyanwang
<br/>
January 23, 2021 | https://alesgenova.github.io/concurrent-wasm-workers/ | <a href="https://web.archive.org/web/*/https://alesgenova.github.io/concurrent-wasm-workers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://alesgenova.github.io/images/2021-1-16-concurrent-wasm-workers/diagram.png" alt="_config.yml"></p>

<blockquote>

  <p>Your scientists were so preoccupied with whether or not they could, that they didn’t stop to think whether they should.</p>

  <p>- Ian Malcolm</p>

</blockquote>

<p>I would like to share a little experiment I did for no other reason than to show I could.</p>

<p>In this proof of concept application, the main application starts a pool of web workers that it later uses to offload a series of heavy tasks.</p>

<p>The task in question is to to render a single frame of a simple 3D scene using ray-tracing (path-tracing). The computationally intensive rendering is performed by a <code>rust</code> library compiled to WebAssembly.</p>

<p>These are the tools I used:</p>
<ul>
  <li><strong><code>post-me</code></strong> to communicate with the workers using a <code>Promise</code> API: <a href="https://alesgenova.github.io/introducing-post-me/">Blog</a> - <a href="https://github.com/alesgenova/post-me">Github</a></li>
  <li>My own toy ray tracing engine I implemented in rust a couple of years ago: <a href="https://github.com/alesgenova/ray-tracer">Github</a></li>
  <li><strong><code>wasm-bindgen</code></strong> to compile rust to wasm and create js bindings: <a href="https://github.com/rustwasm/wasm-bindgen">Github</a></li>
  <li>Small in-house task queue to dispatch tasks to workers when available.</li>
  <li><code>react</code> for the scheleton of the app.</li>
</ul>

<p>If you would like to run this madness, an instance of this application is deployed <a href="https://alesgenova.github.io/ray-tracer-app/">here</a>.</p>

<p><a href="https://alesgenova.github.io/ray-tracer-app/"><img src="https://alesgenova.github.io/images/2021-1-16-concurrent-wasm-workers/ray_tracer.gif" alt="_config.yml"></a></p>

<p>If you would like to see the details of the implementation, you can find the source code of the app on <a href="https://github.com/alesgenova/ray-tracer-app">Github</a></p>

<h2 id="bonus">Bonus</h2>

<p>Using a similar approach, I also created an app that can detect the pitch of sounds being captured by the device’s microphone.</p>

<p><a href="https://alesgenova.github.io/pitch-detection-app/">Try it out </a></p>

<p><a href="https://alesgenova.github.io/pitch-detection-app/"><img src="https://alesgenova.github.io/images/2021-1-16-concurrent-wasm-workers/pitch_detection.gif" alt="_config.yml"></a></p>

<ul>
  <li>Source code: <a href="https://github.com/alesgenova/pitch-detection-app">Github</a></li>
  <li>Pitch detection library: <a href="https://github.com/alesgenova/pitch-detection">Github</a></li>
</ul>

  </div></div>]]>
            </description>
            <link>https://alesgenova.github.io/concurrent-wasm-workers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25882677</guid>
            <pubDate>Sat, 23 Jan 2021 15:01:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teleguard: Swiss Made Safe Messaging]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 76 (<a href="https://news.ycombinator.com/item?id=25882319">thread link</a>) | @0x10c0fe11ce
<br/>
January 23, 2021 | https://teleguard.com/en/ | <a href="https://web.archive.org/web/*/https://teleguard.com/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        


<section id="screenshots">
    <div>
        
        <h2>get in touch with the swiss feeling of modern messaging</h2>

        

        
    </div>
</section>

<section id="benefits">
    <p>
        
        <h2>designed to be the most private messenger over the world</h2>
    </p>
    <div>
        <div>
            <div>
                <svg><use xlink:href="/images/icons.svg#teleguard-swiss-outline"></use></svg>
                <p>Practical, modern messenger with full functionality for iOS and Android</p>
            </div>
            <div>
                <svg><use xlink:href="/images/icons.svg#shield-account-outline"></use></svg>
                <p>Independent company under Swiss data protection law and GDPR-compliant</p>
            </div>
            <div>
                <svg><use xlink:href="/images/icons.svg#lock-check-outline"></use></svg>
                <p>Complex encryption system for all transmitted data</p>
            </div>
            <div>
                <svg><use xlink:href="/images/icons.svg#image-filter-hdr"></use></svg>
                <p>All Servers in the data centers in Switzerland</p>
            </div>
            <div>
                <svg><use xlink:href="/images/icons.svg#cube-outline"></use></svg>
                <p>No storage of user data on the servers</p>
            </div>
            <div>
                <svg><use xlink:href="/images/icons.svg#guy-fawkes-mask"></use></svg>
                <p>No connection to a telephone number and no collection of user identification data</p>
            </div>
        </div>
    </div>
    <div>
        <p>
            download teleguard for free:            
        </p>
        <p><a href="https://apps.apple.com/us/app/teleguard/id1505636751" target="_blank">
                <img alt="ios app" src="https://teleguard.com/images/app-ios-en.png">
            </a>
            <a href="https://play.google.com/store/apps/details?id=ch.swisscows.messenger.teleguardapp" target="_blank">
                <img alt="android app" src="https://teleguard.com/images/app-android-en.png">
            </a>
        </p>
    </div>
</section>

<section id="faq">
    <div>
        
        <h2>get information from the very first hands</h2>
        <div><p><em>01.</em>What is TeleGuard?</p>


<p><em>02.</em>Why is TeleGuard better than other messengers?</p>


<p><em>03.</em>How do I do a TeleGuard update?</p>


<p><em>04.</em>What is a TeleGuard ID?</p>


<p><em>05.</em>How do I add friends?</p>


<p><em>06.</em>Will there be a web / desktop version?</p>


<p><em>07.</em>Edit profile</p>


<p><em>08.</em>Which operating systems are supported?</p>


<p><em>09.</em>Will there be a TeleGuard business solution?</p>


<p><em>10.</em>How do I delete my account?</p>


<p><em>11.</em>How is my privacy secured?</p>


<p><em>12.</em>How do I login / logout?</p>


</div>
    </div>
</section>

<section id="contacts">
    <div>
        

<h2>Please share your thoughts and ideas with us.</h2>

<p><b>Do you have a question, comment or suggestion?</b><br>
        For more information, please fill out the contact form. Please note that there are mandatory fields.</p>


    </div>
</section>



        
    </div></div>]]>
            </description>
            <link>https://teleguard.com/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25882319</guid>
            <pubDate>Sat, 23 Jan 2021 14:10:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Irma: Open-source, attribute based credentials]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25881954">thread link</a>) | @jeroenhd
<br/>
January 23, 2021 | https://irma.app/docs/what-is-irma/ | <a href="https://web.archive.org/web/*/https://irma.app/docs/what-is-irma/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p><span><p>IRMA is a set of free and open source software projects implementing the Idemix attribute-based credential scheme, allowing users to safely and securely authenticate themselves as privacy-preserving as the situation permits. Users receive digitally signed attributes from trusted issuer, storing them in their IRMA app, after which the user can selectively disclose attributes to others. Schematically:</p>
<p><img src="https://irma.app/docs/assets/issuance.png" alt="issuance-flow">
  <img src="https://irma.app/docs/assets/disclosure.png" alt="disclosure-flow">
</p>
<p>Using the issuer's digital signature over the attributes the verifier can verify that the attributes were given to the user in the past, and that they have not been modified since.</p>
<h2>IRMA session flow</h2>
<p>A typical IRMA session is depicted schematically below.</p>
<p><img src="https://irma.app/docs/assets/irmaflow.png" alt="IRMA session flow"></p>
<p>Software components:</p>
<ul>
<li><em>Requestor backend and frontend</em>: Generally the requestor runs a website with a (JavaScript) frontend in the user's browser, and a backend server. During an IRMA session the frontend displays the IRMA QR that the <a href="https://irma.app/docs/irma-app">IRMA app</a> scans. All frontend tasks depicted in the diagram are supported by <a href="https://irma.app/docs/irma-frontend"><code>irma-frontend</code></a>.</li>
<li><a href="#irma-servers"><em>IRMA server</em></a>: Handles IRMA protocol with the IRMA app for the requestor.</li>
<li><a href="https://irma.app/docs/irma-app"><em>IRMA mobile app</em></a>: <a href="https://play.google.com/store/apps/details?id=org.irmacard.cardemu">Android</a>, <a href="https://itunes.apple.com/nl/app/irma-authentication/id1294092994">iOS</a>.</li>
</ul>
<p>Explanation of the steps:</p>
<ol>
<li>Usually the session starts by the user performing some action on the website (e.g. clicking on "Log in with IRMA").</li>
<li>The requestor sends its <a href="https://irma.app/docs/session-requests">session request</a> (containing the attributes to be disclosed or issued, or message to be signed) to the <a href="#irma-servers">IRMA server</a>. Depending on its configuration, the IRMA server accepts the session request only if the session request is authentic (e.g. a validly signed <a href="https://irma.app/docs/session-requests#jwts-signed-session-requests">session request JWT</a>) from an authorized requestor.</li>
<li>The IRMA server accepts the request and assigns a session token (a random string) to it. It returns the contents of the QR code that the frontend must display: the URL to itself and the session token.</li>
<li>The frontend (<a href="https://irma.app/docs/irma-frontend"><code>irma-frontend</code></a>) receives and displays the QR code, which is scanned by the IRMA app.</li>
<li>The IRMA app requests the session request from step 1, receiving the attributes to be disclosed or issued, or message to be signed.</li>
<li>The IRMA server returns the session request.</li>
<li>The IRMA app displays the attributes to be disclosed or issued, or message to be signed, and asks the user if she wants to proceed.</li>
<li>The user accepts.</li>
<li>The IRMA server performs the IRMA protocol with the IRMA app, issuing new attributes to the user, or receiving and verifying attributes from the user's IRMA app, or receiving and verifying an attribute-based signature made by the user's app.</li>
<li>The session status (<code>DONE</code>, <code>CANCELLED</code>, <code>TIMEOUT</code>), along with disclosed and verified attributes or signature depending on the session type, are returned to the requestor.</li>
</ol>
<p>Additional notes:</p>
<ul>
<li>Which of these tasks are performed by the requestor's backend and which by its frontend differs case by case:
<ul>
<li>Often the session request is sent to the IRMA server by the requestor's backend, after which the IRMA server's reply in step 2 is forwarded to the frontend which renders it as a QR code. Step 1 can however also be done by <code>irma-frontend</code>, in which case <code>irma-frontend</code> automatically picks up the IRMA server's reply in step 2 and renders the QR code.</li>
<li>Similarly, <code>irma-frontend</code> can be instructed to fetch the session result in step 10, but this can also be done in the backend. In the latter, <code>irma-frontend</code> can fetch a custom result at your backend, if desired.</li>
</ul></li>
<li>The IRMA server could be deployed on the same machine as the requestor's backend, but it need not be; possibly it is not even controlled by the requestor. Generally, steps 2/3 and 10 are done with REST HTTP calls to the IRMA server, but in case the <a href="https://irma.app/docs/irma-server-lib"><code>irmaserver</code></a> library is used, these steps are function calls. Alternatively, you could use one of the packages in <a href="https://irma.app/docs/irma-backend"><code>irma-backend-packages</code></a> to do these steps with function calls in other programming languages.</li>
</ul>
<h2>Session types</h2>
<p>In an IRMA session, the <a href="https://irma.app/docs/irma-app">IRMA mobile app</a> performs one of the following three <em>session types</em> with an <a href="#irma-servers"><em>IRMA server</em></a>:</p>
<ul>
<li><em>Disclosure sessions</em>: Upon receiving a list of requested attributes from the IRMA server, the app discloses the required attributes to the IRMA server if the app user agrees, after which they are verified by the IRMA server.</li>
<li><em>Attribute-based signature sessions</em>: Similar to disclosure sessions, but the attributes are attached to a message digitally signed into an <a href="https://irma.app/docs/overview#attribute-based-signatures"><em>attribute-based signature</em></a>. The attribute-based signature can be verified at any later time, ensuring that the signed message is intact, and that the IRMA attributes attached to it were valid at the time of creation of the attribute-based signature.</li>
<li><em>Issuance sessions</em>: the IRMA app receives a new set of IRMA attributes including valid issuer signatures from the IRMA server, to use in later disclosure or attribute-based signature sessions. (Possibly the user is asked to disclose some attributes as well, within the same IRMA session, before receiving the new attributes. This is called a <em>combined issuance-disclosure session</em>.)</li>
</ul>
<p>This process is depicted schematically and explained in more detail in the <a href="https://irma.app/docs/what-is-irma#irma-session-flow">IRMA session flow</a> chapter. For the user, after scanning the QR in his/her IRMA app a disclosure session generally looks like the following. (Attribute-based signature sessions and issuance sessions are identical in terms of their flow (scan qr, provide permission, success screen); only the graphical interface is different.)</p>
<p><img src="https://irma.app/docs/assets/disclose-permission.png" alt="disclose-permission">
  <img src="https://irma.app/docs/assets/disclose-done.png" alt="disclosure-done">
</p>
<h2>IRMA servers</h2>
<p>Various existing software components documented on this website can perform the role of the IRMA server.
Apart from exposing an API that is used by the <a href="https://irma.app/docs/irma-app">IRMA app</a> during IRMA sessions, each of these components also offer an API with which IRMA sessions can be started and monitored, for use by the <a href="https://irma.app/docs/overview#participants"><em>requestor</em></a>: the party wishing to issue attributes to or verify attributes from an IRMA app. The IRMA server handles the IRMA session with the IRMA app for the requestor.</p>
<p>Currently the following IRMA servers exist:</p>
<ul>
<li>The <code>irma server</code> command of the <a href="https://irma.app/docs/irma-cli"><code>irma</code></a> binary: a standalone daemon exposing its requestor API as HTTP endpoints. <a href="https://irma.app/docs/irma-server">Documentation</a>; <a href="https://irma.app/docs/api-irma-server">API reference</a>.</li>
<li>The <code>irmaserver</code> Go library, exposing a HTTP server that handles IRMA sessions with the IRMA app, and Go functions for starting and managing IRMA sessions. <a href="https://irma.app/docs/irma-server-library">Documentation</a>; <a href="https://godoc.org/github.com/privacybydesign/irmago/server/irmaserver">API reference</a>.</li>
<li>The now deprecated <a href="https://github.com/privacybydesign/irma_api_server"><code>irma_api_server</code></a>.</li>
</ul>
<h2>About this documentation</h2>
<p>IRMA uses JSON to pass messages within IRMA sessions. The majority of IRMA is <a href="https://github.com/privacybydesign/irmago">written in Go</a>, and the JSON messages generally correspond to specific Go structs. For example, the <a href="https://irma.app/docs/api-irma-server#get-session-token-result"><code>GET /session/{token}/result</code></a> endpoint of the <a href="https://irma.app/docs/irma-server"><code>irma server</code></a> outputs instances of the <a href="https://godoc.org/github.com/privacybydesign/irmago/server#SessionResult"><code>server.SessionResult</code></a>.  In such cases, a link to the corresponding Go struct will be included. This can tell you what fields you can use or expect. (Note that some structs have custom (un)marshalers. See also the <a href="https://blog.golang.org/json-and-go">Go documentation</a> on JSON and Go.)</p>
</span></p></article></div></div>]]>
            </description>
            <link>https://irma.app/docs/what-is-irma/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25881954</guid>
            <pubDate>Sat, 23 Jan 2021 13:13:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The 8 Essential Features for a Sample Management LIMS in a Covid-19 Testing Lab]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25881912">thread link</a>) | @jradhughes
<br/>
January 23, 2021 | https://thirdwaveanalytics.com/blog/8-essential-features-sample-management-lims-in-a-covid-19-testing-lab/ | <a href="https://web.archive.org/web/*/https://thirdwaveanalytics.com/blog/8-essential-features-sample-management-lims-in-a-covid-19-testing-lab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div> <p><span><span> </span><time datetime="2020-12-19T01:43:33+00:00">December 19, 2020</time></span> </p><p>During the current pandemic, the ability to rapidly acquire, test, and report samples for the novel coronavirus has been essential for labs’ survival. Every COVID-19 testing lab demands a <a href="https://thirdwaveanalytics.com/">Laboratory Information Management System</a> (LIMS) to coordinate the huge influx of samples. For any lab to quickly test and report samples, their sample management software must have certain features to facilitate rapid testing. (Read: <a href="https://thirdwaveanalytics.com/blog/what-does-a-lims-do/">What is a LIMS?</a>)</p><p>These eight features of a sample management LIMS ensure your lab can easily and quickly handle a large number of COVID-19 samples.</p><h2>Essential LIMS Feature #1: Highly Secure, Cloud-based, Accessible Anywhere on Any Device</h2><p>A variety of people will need to access your laboratory’s sample management software: physicians and nurses, laboratory testing personnel, management, and directors. The ideal solution is a cloud-based system they can all access on any internet-connected device.</p><p>A cloud-based LIMS can also be highly secure, able to manage any form of Protected Health Information (PHI). In fact, a large number of cloud-based systems currently store and process PHI every day, approved by and compliant with all pertinent regulatory agencies. To ensure PHI security, the LIMS system should absolutely require two-factor authentication (2FA) for anyone that accesses PHI.</p><h2>Essential LIMS Feature #2: An Interface for Physicians to Order Tests and Review Results</h2><p>Here’s a nightmare for testing labs: The lab knows about a sample only when it shows up at their lab (known as “bluebird” samples, as they appear “out of the blue”). You can’t properly staff a lab if you do not know the number of samples that require testing on any given day. When each sample arrives with a paper test request form, laboratory technicians must enter all sample information from that paper form.</p><p>The process is extremely cumbersome and error-prone. Reading paper test request forms is a common challenge due to poor handwriting, poor quality printing, or damage during delivery. Many samples suffer significant testing delays from errors caused by lab staff forced to enter data directly from test request forms.</p><h3>Improving the sample testing order process</h3><p>There’s a far more accurate, efficient process. A sample test is ordered prior to the physician or healthcare provider shipping the sample. This advance order occurs through a special interface in the LIMS, such as a portal specifically for physicians or healthcare providers. With this process, the laboratory gains efficiencies by knowing the number of samples that will require testing on any given day. Lab staff need only to verify that the information on the test request form is consistent with the information entered into the LIMS.</p><p>Finally, if the LIMS is a cloud-based system (see feature #1), any physician or provider can easily order a test from any healthcare facility or sample acquisition location, such as various drive-through sample collection tents.</p><h2>Essential LIMS Feature #3: Batched Sample Processing, Including Liquid Handlers</h2><p>Some available technologies make it extremely easy to test a single COVID-19 sample (such as single sample-single-use PCR amplification systems). But these systems are expensive for a single sample, and can generally only test a few samples per hour.</p><p>Any lab serious about performing COVID-19 testing can test hundreds of thousands of samples a day. To meet this throughput, the laboratory must have a sample management system that can process 96-well or 384-well plates that are full of samples.</p><p>The ability to simultaneously process 96 to 384 samples can require significant computation resources. <a href="https://thirdwaveanalytics.com/covid19/">A COVID-19 testing LIMS</a> must be able to handle this volume and process the appropriate controls concurrent with each sample.</p><p>Each lab may choose to batch samples differently or use different controls. Therefore, the LIMS must have the flexibility to be configured to the needs of each individual testing lab. This includes processing data files from different liquid handlers or qPCR instruments. Data files from each liquid handler program will likely be formatted differently, adding to the complexity the LIMS must be able to manage.</p><h2>Essential LIMS Feature #4: Automated Data Analysis and Result Generation</h2><p>Each testing lab generates raw sample data from different instruments. Each file has its own unique format and sample naming conventions. The LIMS must absolutely be able to properly harvest this data. Ensuring that all data is accurately associated with its correct sample can be a tricky process, especially since most COVID-19 tests generate multiple data points for each tested sample (e.g. CT values for the three SARS-CoV-2 genes, and a CT for a spiked internal control).</p><p>After all testing data is appropriately associated with each sample, the LIMS should instantaneously analyze the sample and generate a result. The data auto-analysis can be exceptionally complicated. The LIMS must first assess all controls that are run with samples. Then the LIMS assesses the sample itself. Finally,&nbsp;it reviews the possible re-testing data if a sample is run multiple times (see feature #8 below). While some testing workflows use vendor software for raw data analysis, all values from analysis must still be accurately imported into the LIMS, and all re-testing values analyzed.</p><h2>Essential LIMS Feature #5: Result Review and Automated Report Generation and Delivery</h2><p>After a the LIMS generates a sample result, a laboratory director (or other appropriate staff) must review the data. Considering the limited time these lab personnel usually have each day, it is paramount that they can review results for each sample easily.</p><p>They should be able to conduct the review of all negative samples in batch. Once the sample data are reviewed and approved, the LIMS should automatically generate a report. To prevent errors and save time, lab staff should never have to create a manual report, under any circumstances. The LIMS should always generate each sample report, even for amended reports.</p><p>All positive samples will likely require critical calls to the physician, healthcare provider, and/or patient. The LIMS must be able to easily and quickly document each critical call. If the LIMS also provides contact information for each individual sample — the contact may be different for each positive sample — that can be extremely helpful.</p><p>Finally, the LIMS should automatically deliver each report to the proper physician or healthcare provider. This delivery can take many forms, including a secure email or electronic fax, or by posting to the portal.</p><h2>Essential LIMS Feature #6: Queue-based Sample Tracking</h2><p>Any serious COVID-19 testing lab will process hundreds or thousands of samples in a single day. For those labs, <a href="https://thirdwaveanalytics.com/sample-tracking/">sample tracking</a> can feel like a massive traffic jam. Lab staff must act as traffic cop while also taking responsibility for testing samples. Sample sheets, such as an Excel document, are commonly out-of-date and full of inaccuracies. This leads to poor turnaround time for sample testing and potentially “lost” samples during the testing process.</p><p>A good LIMS provides an easy solution: the ability to track all samples in a queue-based manner. Queue-based sample tracking places every sample onto a list, based on that sample’s current status. As each sample is processed, the LIMS should automatically update its status, and push the sample to the next queue.</p><p>This queue-based system is perfect for high-throughput sample testing. No sample leaves a list until its status is updated — you can never lose or accidentally forget any sample. Every sample remains on the queue until it is tested.</p><h2>Essential LIMS Feature #7: Re-testing of Invalid or Inconclusive Samples</h2><p>All testing labs understand that samples frequently fail and require re-testing. Unfortunately, sample re-testing can be a messy process. Do you create a new sample record for the re-test or overwrite the first sample’s data? Do you have to put a new barcode on the sample to re-test it? Can the data auto-analysis manage re-test results?</p><p>A LIMS must address these re-testing problems in a COVID-19 sample testing environment. It is usually not acceptable to simply overwrite initial failed sample data, so the LIMS must generate a new sample record for re-testing.&nbsp; Each re-test record must be appropriately updated during the re-testing process, making sure the original sample record isn’t accidentally updated. The data auto-analysis must be able to accurately calculate a final patient result, accounting for all sample testing results.</p><p>Finally, few labs will run re-test samples in a separate batch. The LIMS must be able to process both original sample tests and sample re-tests <strong>at the same time</strong>.</p><h2>Essential LIMS Feature #8: The Ability to Report to Public Health Departments</h2><p>There is one final task after your COVID-19 lab completes all sample testing and reports all results. The lab must report each result to the appropriate Department of Public Health (DPH). Each DPH requires different information on the sample, within different timeframes.</p><p>To help the lab facilitate these challenging demands, the LIMS should export all recent results in a format that can be directly provided to the appropriate DPH. Even better, the LIMS might directly integrate with the DPH system. When integrated, the LIMS can automatically send the data in the requested timeframe and format (such as HL7 formatting).</p><h2>Summary: Essential Features for a COVID-19 Lab’s Sample Management Software</h2><p>Evaluating a LIMS to manage samples in a COVID-19 testing lab can be tricky. You’ll find plenty of potential features in a LIMS that may not deliver value. Consider the key features listed here as essential. Without them, you’ll be stuck with an inefficient, error-prone sample management system&nbsp;— and frustrated users spending an excessive amount of time managing sample data.</p><p><strong>Which LIMS features are essential for your lab? Here’s a quick checklist.</strong><br> 1. A cloud-based system anyone can access, on any device, from …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thirdwaveanalytics.com/blog/8-essential-features-sample-management-lims-in-a-covid-19-testing-lab/">https://thirdwaveanalytics.com/blog/8-essential-features-sample-management-lims-in-a-covid-19-testing-lab/</a></em></p>]]>
            </description>
            <link>https://thirdwaveanalytics.com/blog/8-essential-features-sample-management-lims-in-a-covid-19-testing-lab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25881912</guid>
            <pubDate>Sat, 23 Jan 2021 13:06:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[But how, exactly, do databases use mmap?]]>
            </title>
            <description>
<![CDATA[
Score 195 | Comments 106 (<a href="https://news.ycombinator.com/item?id=25881911">thread link</a>) | @brunoac
<br/>
January 23, 2021 | https://brunocalza.me/but-how-exactly-databases-use-mmap/ | <a href="https://web.archive.org/web/*/https://brunocalza.me/but-how-exactly-databases-use-mmap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>In a previous post <a href="https://brunocalza.me/discovering-and-exploring-mmap-using-go/">Discovering and exploring mmap using Go</a>, we talked about how databases have a major problem to solve, which is: <strong>how to deal with data stored in disk that is bigger than the available memory</strong>. We talked about how many databases solve this problem using <strong>memory-mapped files</strong> and explored <strong>mmap</strong> capabilities.</p><p>Knowing that databases use <strong>memory-mapped files </strong>to solve the problem was not enough for me. It solved part of the mystery but a question remained: <strong>how, exactly, databases use <em>mmap</em> to read and write data from disk?</strong></p><!--kg-card-begin: markdown--><p>I decided to dig through a database source code to answer that question. There are plenty of databases that use mmap. Some of them decided to not use anymore. Some examples: <a href="https://www.sqlite.org/index.html">SQLite</a> has an option of accessing disk content directly using memory-mapped I/O<sup>[1]</sup>, it seems <a href="https://github.com/google/leveldb">LevelDB</a> used to use but it changed it<sup>[2]</sup>, <a href="https://lucene.apache.org/">Lucene</a> has an option with <em>MMapDirectory</em><sup>[3]</sup>, <a href="https://lmdb.readthedocs.io/">LMDB</a> uses mmap<sup>[4]</sup>, a simple key/value in-memory database from Counchbase called <a href="https://github.com/couchbase/moss">moss</a> uses mmap for durability of in-memory data<sup>[5]</sup> and <a href="https://www.mongodb.com/">MongoDB</a> removed <strong>mmap</strong> storage engine for <em>WiredTiger</em><sup>[6]</sup>.</p>
<!--kg-card-end: markdown--><p>I chose <a href="https://github.com/boltdb/bolt">bolt</a>, a simple <strong>key/value store</strong> implemented in <strong>Go</strong> by <a href="https://twitter.com/benbjohnson">Ben Johnson</a> inspired by the <strong>LMDB</strong> project, for this endeavor. Mostly because of source code simplicity and my familiarity with Go language. I know a simple key/value store might not be the most complete source code for learning all the details of reading/writing data to disk, but as I have found out, it was more than enough to get a grasp of it. </p><p>The original bolt repository is no longer maintained. A fork of <strong>bolt</strong> called <strong>bbolt</strong> is maintained and used by <a href="https://github.com/etcd-io/bbolt">etcd</a>. If you are not familiar with <strong>bolt</strong>, I recommend the articles <a href="https://npf.io/2014/07/intro-to-boltdb-painless-performant-persistence/">Intro to BoltDB: Painless Performant Persistence</a> and <a href="https://www.progville.com/go/bolt-embedded-db-golang/">Bolt — an embedded key/value database for Go </a>.</p><h2 id="the-start">The start</h2><p>I download the code to my machine and opened it in my editor. I thought a good place to start digging was to find out where the database was initialized and look for any references of <strong>mmap</strong> there. Like most embedded databases, <strong>bolt </strong>has an <a href="https://github.com/boltdb/bolt/blob/fd01fc79c553a8e99d512a07e8e0c63d4a3ccfc5/db.go#L150">Open</a> method for opening the database or creating a new one if it does not exist. Inside it, I found a reference to a private <strong>mmap</strong> function. That's a good start. </p><pre><code>// Memory map the data file.
if err := db.mmap(options.InitialMmapSize); err != nil {
    _ = db.close()
    return nil, err
}</code></pre><h2 id="how-much-memory-should-i-allocate">How much memory should I allocate?</h2><p>The private <a href="https://brunocalza.me/p/b43be99e-c260-446b-a1b1-40261aaffcf3/func%20(db%20*DB)%20mmap(minsz%20int)%20error%20%7B">mmap</a> is responsible for opening the memory-mapped file. In order to do this, it needs to figure out how much memory it is going to allocate. This task is accomplished by another method called <a href="https://github.com/boltdb/bolt/blob/fd01fc79c553a8e99d512a07e8e0c63d4a3ccfc5/db.go#L308">mmapSize</a>. Given the size of the database, this method figures out how many bytes of memory should be allocated.</p><p>It starts by doubling the size from <strong>32KB</strong> to <strong>1GB</strong>. But if the database is larger than <strong>1GB</strong>, it grows <strong>1GB</strong> at a time.</p><pre><code>// Double the size from 32KB until 1GB.
for i := uint(15); i &lt;= 30; i++ {
	if size &lt;= 1&lt;&lt;i {
		return 1 &lt;&lt; i, nil
	}
}

...

// If larger than 1GB then grow by 1GB at a time.
sz := int64(size)
if remainder := sz % int64(maxMmapStep); remainder &gt; 0 {
	sz += int64(maxMmapStep) - remainder
}</code></pre><p>It is all fine by now. That's how <strong>bolt</strong> figured out how much to allocate. But there is a piece of the puzzle now that will be very important when we talk about database storage layout. After figuring out how much to allocate, it needs to ensure that the allocated size is a multiple of the <strong>page size</strong>. If you are not familiar with database storage and don't know what a <strong>page</strong> is, don't worry, we'll be back to this.</p><pre><code>// Ensure that the mmap size is a multiple of the page size.
// This should always be true since we're incrementing in MBs.
pageSize := int64(db.pageSize)
if (sz % pageSize) != 0 {
	sz = ((sz / pageSize) + 1) * pageSize
}</code></pre><p>Shouldn't it check if we are allocating more than we have available? That's the last piece of the <a href="https://github.com/boltdb/bolt/blob/fd01fc79c553a8e99d512a07e8e0c63d4a3ccfc5/db.go#L308">mmapSize</a> method.</p><pre><code>// If we've exceeded the max size then only grow up to the max size.
if sz &gt; maxMapSize {
	sz = maxMapSize
}</code></pre><!--kg-card-begin: markdown--><p>The <a href="https://github.com/boltdb/bolt/blob/fd01fc79c553a8e99d512a07e8e0c63d4a3ccfc5/bolt_amd64.go#L4">maxMapSize</a> constant is set to <code>0xFFFFFFFFFFFF</code> on <strong>AMD64</strong> architectures.</p>
<!--kg-card-end: markdown--><blockquote>The <strong>AMD64</strong> architecture defines a 64-bit virtual address format, of which the low-order 48 bits are used in current implementations. This allows up to 256 TiB (2<sup>48</sup> bytes) of virtual address space. - <a href="https://en.wikipedia.org/wiki/X86-64">x86-64 Wiki</a></blockquote><p>This is the limit of the <strong>bolt</strong> database file.</p><h2 id="calling-the-system-call">Calling the system call</h2><p>Now that <strong>bolt</strong> knows how much it should allocate, it calls the system call <a href="https://brunocalza.me/p/b43be99e-c260-446b-a1b1-40261aaffcf3/func%20mmap(db%20*DB,%20sz%20int)%20error%20%7B">mmap</a>. Here is the full code for <em>Unix</em>-like environments:</p><pre><code>// mmap memory maps a DB's data file.
func mmap(db *DB, sz int) error {
	// Map the data file to memory.
	b, err := syscall.Mmap(int(db.file.Fd()), 0, sz, syscall.PROT_READ, syscall.MAP_SHARED|db.MmapFlags)
	if err != nil {
		return err
	}

	// Advise the kernel that the mmap is accessed randomly.
	if err := madvise(b, syscall.MADV_RANDOM); err != nil {
		return fmt.Errorf("madvise: %s", err)
	}

	// Save the original byte slice and convert to a byte array pointer.
	db.dataref = b
	db.data = (*[maxMapSize]byte)(unsafe.Pointer(&amp;b[0]))
	db.datasz = sz
	return nil
}</code></pre><!--kg-card-begin: markdown--><p>It is a pretty straightforward code. I have some observations to make about <code>syscall.PROT_READ</code>, but I'll leave for the next session. It is nice to see the call to madvise there, although I don't know its benefits. I would love to know the importance of that call, if it improves performance or if another flag could be set to get different behavior from OS for different use cases.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>The mapped memory is set to the variables <code>db.dataref</code> and <code>db.data</code>.</p>
<!--kg-card-end: markdown--><pre><code>db.dataref = b
db.data = (*[maxMapSize]byte)(unsafe.Pointer(&amp;b[0]))
</code></pre><!--kg-card-begin: markdown--><p>I would like to know about the importance of keeping track of both variables. I could not grasp what is going on in the conversion to <code>db.data</code>. But anyway, what we have to keep in mind is that is through these variables that <strong>bolt</strong> will read data from disk.</p>
<!--kg-card-end: markdown--><h2 id="what-about-writes">What about writes?</h2><!--kg-card-begin: markdown--><p>While skimming through the source code, I looked for evidence of how <strong>mmap</strong> was used for both reads and writes. I dug both <a href="https://github.com/boltdb/bolt/blob/fd01fc79c553a8e99d512a07e8e0c63d4a3ccfc5/bucket.go#L266">Get</a> and <a href="https://github.com/boltdb/bolt/blob/fd01fc79c553a8e99d512a07e8e0c63d4a3ccfc5/bucket.go#L285">Put</a> method. I could not find any place where the references to <code>db.dataref</code> or <code>db.data</code> were being updated. I discovered that the writes to disk happen when <a href="https://github.com/boltdb/bolt/blob/fd01fc79c553a8e99d512a07e8e0c63d4a3ccfc5/tx.go#L144">Commit</a> is called to a transaction. But there I could only find calls to <a href="https://golang.org/pkg/os/#File.WriteAt">WriteAt</a>. So I gave up my search of trying to understand how <strong>mmap</strong> was used for writes.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>Then, suddenly, while looking back to the call of <strong>mmap</strong>, I noticed the  <code>syscall.PROT_READ</code> flag that I have not noticed the first time I looked at the code. So <strong>mmap</strong>, is only used for reads in <strong>bolt</strong>. Another place that indicates this is in the definition of <a href="https://github.com/boltdb/bolt/blob/fd01fc79c553a8e99d512a07e8e0c63d4a3ccfc5/db.go#L100">DB struct</a>:</p>
<!--kg-card-end: markdown--><pre><code>dataref  []byte   // mmap'ed readonly, write throws SEGV
data     *[maxMapSize]byte</code></pre><p>That made perfect sense to me. Since flushes to disk are very hard to control when using <strong>mmap</strong>, it is probably the safest approach. How <strong>bolt</strong> does writing is a topic of another post. </p><h2 id="how-the-database-file-is-structured">How the database file is structured?</h2><p>We know how and when<strong> bolt </strong>allocates memory and that <strong>mmap</strong> is not used for writes. But how, exactly, <strong>bolt</strong> can find the value of a key? To understand that, we have to understand how typically databases structure their files. I am not going to do deep here. Mostly because I don't understand enough to go deep. Just going to try to give a glimpse of what is going on. </p><p>A file is just an array of bytes. We have to apply some reasoning to this array of bytes to work with it effectively. Databases structure their files in disk into blocks (chunks of bytes) called <strong>pages</strong>. <strong>bolt </strong>is no different. The database file can be seen as</p><figure><img src="https://brunocalza.me/content/images/2021/01/image--17-.png" alt=""></figure><!--kg-card-begin: markdown--><p>Each page has a <strong>fixed length of bytes</strong>, typically the same size as the OS page (usually <code>4096 bytes</code>). Here is the <a href="https://github.com/boltdb/bolt/blob/fd01fc79c553a8e99d512a07e8e0c63d4a3ccfc5/db.go#L40">part</a> of <strong>bolt</strong> that sets the <code>pageSize</code>.</p>
<!--kg-card-end: markdown--><pre><code>// default page size for db is set to the OS page size.
var defaultPageSize = os.Getpagesize()
</code></pre><p>Every database has its own page layout. The page layout of <strong>bolt</strong> is defined at <a href="https://github.com/boltdb/bolt/blob/fd01fc79c553a8e99d512a07e8e0c63d4a3ccfc5/page.go#L28">page.go</a> as</p><pre><code>const (
	branchPageFlag   = 0x01
	leafPageFlag     = 0x02
	metaPageFlag     = 0x04
	freelistPageFlag = 0x10
)

const (
	bucketLeafFlag = 0x01
)

type pgid uint64

type page struct {
	id       pgid
	flags    uint16
	count    uint16
	overflow uint32
	ptr      uintptr
}
</code></pre><!--kg-card-begin: markdown--><ul>
<li><code>id</code>: it is the page identifier used to index the page. Given a page id, I can locate it in the disk through <strong>mmap</strong>, since the disk file is just a list of continuous fixed length pages;</li>
<li><code>flags</code>: it tells the page type. There are four types of page: <code>meta</code>, <code>freeList</code>, <code>leaf</code> and <code>branch</code>;</li>
<li><code>count</code>: indicates the number of elements stored in the page;</li>
<li><code>overflow</code>: represents the number of subsequent pages;</li>
<li><code>ptr</code>: indicates the end of page header and start of page data. This is where the keys and values are going to be stored.</li>
</ul>
<!--kg-card-end: markdown--><p>A visual representation of a page:</p><figure><img src="https://brunocalza.me/content/images/2021/01/image--16-.png" alt=""><figcaption>Layout of a page</figcaption></figure><p>With this in mind, we can look at the code that retrieves a <a href="https://github.com/boltdb/bolt/blob/fd01fc79c553a8e99d512a07e8e0c63d4a3ccfc5/db.go#L792">page</a> given its id.</p><pre><code>// page retrieves a page reference from the mmap based on the current page size.
func (db *DB) page(id pgid) *page {
	pos := id * pgid(db.pageSize)
	return (*page)(unsafe.Pointer(&amp;db.data[pos]))
}</code></pre><h2 id="how-to-perform-an-efficient-search">How to perform an efficient search?</h2><!--kg-card-begin: markdown--><p>We know how the database file is structured in disk and we know how to retrieve a page from disk. But how a <code>bucket.Get([]byte("key"))</code> search works? We are not going to go into too much detail here. I hope the abstraction I created will be enough to get a clue about what is going on.</p>
<!--kg-card-end: markdown--><p><strong>What if the pages themselves, in the data part, contained references to other pages? And what if these references build up to form a B+Tree?</strong></p><p>That is exactly what <strong>bolt</strong> does. Thinking of the page as a node of a <strong>B+Tree</strong>. In a <strong>B+Tree</strong> we have internal nodes and leaves. That's the reason for the `flags` attribute, to indicate what kind of node that page is.</p><figure><img src="https://brunocalza.me/content/images/2021/01/image--18-.png" alt=""><figcaption>Abstract representation of a B+Tree in <strong>bolt</strong></figcaption></figure><p>So to perform the search of a key, you start at the root node a do a B+Tree traversal on mmapped disk pages. Therefore, <strong>bolt</strong> is a memory-mapped B+Tree file. The more memory you have, the more it will behave like a memory key/value store.</p><p>There are many more details about this process. Most of it I don't understand myself. So let's just keep it simple at this abstract level. </p><h2 id="resizing-mmap">Resizing mmap</h2><!--kg-card-begin: markdown--><p>When I started looking …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://brunocalza.me/but-how-exactly-databases-use-mmap/">https://brunocalza.me/but-how-exactly-databases-use-mmap/</a></em></p>]]>
            </description>
            <link>https://brunocalza.me/but-how-exactly-databases-use-mmap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25881911</guid>
            <pubDate>Sat, 23 Jan 2021 13:06:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Serendipity, seeing bridges where others see gaps, taking actions to create luck]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25881742">thread link</a>) | @boraoztunc
<br/>
January 23, 2021 | https://psyche.co/guides/how-to-open-up-to-serendipity-and-create-your-own-luck | <a href="https://web.archive.org/web/*/https://psyche.co/guides/how-to-open-up-to-serendipity-and-create-your-own-luck">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>Human beings find comfort in certainty. We form governments, make calendars, and create organisations; and we structure our activities, strategies and plans around these constructs. These routines give us the satisfaction of knowing that, by having a plan, thereâ€™s a means of it coming to fruition.</p>
<p>But thereâ€™s another force, constantly at play in life, that often makes the greatest difference to our futures: the â€˜unexpectedâ€™ or the â€˜unforeseenâ€™. If you think about it, you already look out for the unexpected every day, but perhaps only as a defence mechanism. For example, whenever you use a pedestrian crossing on a busy road, you look out for the unexpected driver who might race through the red light. That â€˜alertnessâ€™ to, or awareness of, the unexpected is at the centre of understanding the science of (smart) luck and exploiting it to your benefit.</p>
<p>In my research into what makes individuals and organisations fit for the future, one insight has come up again and again: many of the worldâ€™s leading minds have developed a capacity, often unconscious, to turn the unexpected into positive outcomes. Developing this â€˜serendipity mindsetâ€™, as I <a href="https://theserendipitymindset.com/" rel="nofollow noreferrer noopener">call</a> it, is both a philosophy of life and a capability that you can shape and nurture in yourself. (Note, while this approach has been <a href="https://ssir.org/books/excerpts/entry/cultivating_serendipity" rel="nofollow noreferrer noopener">successful</a> across many settings, it does need to go hand in hand with tackling the structural inequality related to factors such as race, gender and income.)</p>
<p>You might think of serendipity as passive luck that just happens to you, when actually itâ€™s an active process of spotting and connecting the dots. It is about seeing bridges where others see gaps, and then taking initiative and action(s) to create smart luck. Serendipity is a guiding force in great scientific discoveries but itâ€™s also present in our everyday lives, in the smallest of moments as well as the greatest life-changing events. Itâ€™s how we often â€˜unexpectedlyâ€™ find love, a co-founder, a new job, or a business partner â€“ and itâ€™s how inventions such as Post-it Notes, X-rays, penicillin, microwaves and many other innovations came about.</p>
<p>My research suggests that serendipity has three core characteristics. It starts with a serendipity <em>trigger</em> â€“ the moment when you encounter something unusual or unexpected. Next, you need to <em>connect the dots</em> â€“ that is, observe the trigger and link it to something seemingly unrelated, thus realising the potential value within the chance event (sometimes referred to as a Eureka moment). Finally, <em>sagacity and tenacity</em> are required to follow through and create an unexpected positive outcome. While a particular chance encounter is an event, serendipity is a multifaceted process, as the figure below shows (note that the trigger and connecting the dots often happen at the same time).</p>
</div><div><figure data-align="center"><img src="https://d2e1bqvws99ptg.cloudfront.net/user_image_upload/1434/new-inset-graphic-.jpg" alt="" title=""><figcaption>Figure supplied by the author.</figcaption></figure></div><div>
<p>To be lucky, itâ€™s often essential to be open and alert to the unexpected. Consider an entertaining experiment that the British psychologist Richard Wiseman carried out for a BBC TV show some time ago, which involved just two people: one who saw himself as â€˜luckyâ€™, and one who identified herself as â€˜unluckyâ€™. The researchers asked both participants to take separate trips to a coffee shop outside which theyâ€™d placed a Â£5 note on the pavement. Inside, someone posing as a successful businessman sat at the table by the counter. The â€˜lucky personâ€™ approached, spotted the money and picked it up. Inside, he ordered a coffee, sat next to the businessman and struck up a conversation with him. The self-described â€˜unluckyâ€™ person, on the other hand, failed to notice the money or talk to the businessman. Later, the researchers asked both participants how their day had been. The â€˜luckyâ€™ person reported having had a great day â€“ heâ€™d found money in the street, and made a new friend (who might lead him to additional opportunities). Meanwhile, the â€˜unluckyâ€™ person described her day as uneventful. So, although both participants had the same chances, only one was able to â€˜seeâ€™ them.</p>
<p>Such an experiment â€“ while lighthearted â€“ shows that your mindset, and how you think about possibility in your life, can affect your ability to be alert when opportunity occurs. In fact, the terms â€˜unexpectedâ€™, â€˜extraordinaryâ€™ and â€˜unlikelyâ€™ are misleading because accidents or coincidences happen all the time. But we must be able to see the opportunity in the moment.</p>
<p>Although being alert to the unexpected is vital for creating smart luck, there is another key factor: preparation. This is partly about removing the barriers to serendipity, both mental (your mindset) and physical (the spaces you live and interact in), such as: overloaded schedules; senseless meetings; and the inefficiencies throughout your day that rob you of time, curiosity and a sense of joy. You can prepare by strengthening your mental readiness to connect with opportunity, and creating an environment that enables the use of your skills and available resources to act on the moment. An unprepared mind often discards unusual encounters, thereby missing the opportunities for smart luck. But this is a learned behaviour. Preparation is about developing the capacity to accelerate and harness the positive coincidences that show up in life. In this Guide, I will show you the basics of how to do this.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p><strong>Recognise and challenge your biases</strong></p>
<p>Our habits of thought and preconceptions about the world can make it difficult to spot or harness serendipity. They shape our behaviour and how we interact with the world. There are three major biases that will require the most attention to overcome if weâ€™re to effectively cultivate serendipity: underestimating the unexpected; hindsight bias; and functional fixedness.</p>
<p><em><strong>Underestimating the unexpected.</strong></em> Itâ€™s natural to underestimate the unexpected, but when you do, you tune out opportunities to create smart luck. Yes, itâ€™s unlikely that, on the day of your big presentation, Zoom crashes. Itâ€™s unlikely that the person who was supposed to evaluate your presentation gets sick. Itâ€™s unlikely that you spill coffee over your laptop right before the presentation. But add up all these unlikely events, and it becomes relatively likely that something unexpected might happen. Experienced presenters will often have a joke for when things go wrong â€“ knowing that, often, they do â€“ which tends to bring the audience over to their side as they appear to be quick on their feet and comfortable sharing their humanness. The same logic applies to all the good things that can happen throughout the day. Only once we accept that the unexpected happens all the time do we start â€˜seeingâ€™ it (like the â€˜luckyâ€™ person who spotted the money planted on the street in the experiment above) â€“ and begin to view it as a potential benefit or opportunity rather than a threat.</p>
<p><em><strong>Hindsight bias.</strong></em> When we construct stories of past events, we often act as if there was a linear trajectory, even though reality most probably followed a squiggly path. This can lead us to perceive events as having been more predictable than they were (known as â€˜hindsight biasâ€™), and to construct narratives that conveniently explain everything, ignoring the role of chance. This post-rationalisation speaks to our human need to find familiarity in the unknown, and to control anomalies. However, if you continually airbrush the many unexpected events out of your (hi)stories, youâ€™ll miss the importance of the unpredictable parts and therefore fail to recognise â€“ let alone legitimise â€“ the critical role that serendipity will play in your future.</p>
<p><em><strong>Functional fixedness.</strong></em> Whenever we use a tool in everyday life, weâ€™re so accustomed to its usual specific function that weâ€™re often unable to see its usefulness in other contexts â€“ a bias known as â€˜functional fixednessâ€™. Similarly, <a href="https://philpapers.org/rec/ADAFFA-2" rel="nofollow noreferrer noopener">research</a> has shown that individuals who are familiar with specific problem-solving strategies are unlikely to devise simpler ones, even if and when it could be appropriate. In other words, we tend to do many things out of habit â€“ weâ€™ll often persist with â€˜the hard wayâ€™ simply because itâ€™s the way we already know. Having the mental agility to improvise, to see how a tool could be used in a new way, is essential to building your serendipity mindset. Think of fictional characters, such as Lara Croft or James Bond, and how â€“ thanks to their quick-wittedness â€“ they manage to turn any ordinary object into a deadly weapon. While this is a Hollywood clichÃ©, weâ€™re nonetheless impressed by these characters because we recognise their talent and resourcefulness â€¦ and perhaps how unlikely we might have been to think of that solution when faced with their predicament. Your own creativity will thrive when you abandon the physical and mental tools with which youâ€™re most familiar, and find new ways to work or think.</p>
<p><strong>Cultivate your serendipity mindset</strong></p>
<p>As well as challenging your innate biases and making a conscious effort to think beyond your usual models or fixed ways of thinking, there are many more practical steps you can take to help develop or strengthen your serendipity muscle. Here are four. Together, theyâ€™ll help you identify the clutter in your life, clean it up and create space for serendipity; forge more connections; and see opportunity in crisis.</p>
<p><em><strong>Get in the habit of journalling</strong></em><strong>.</strong> If you are new to <a href="https://psyche.co/guides/to-start-to-heal-from-trauma-in-your-life-write-about-it" rel="noopener">journalling</a>, donâ€™t overthink it. Set a timer for two minutes, then list out in two columns the parts of your day that led to positive outcomes and the parts of the day that did not. As you break down your day into these segments, examine the parts that worked really well for you, and the ones that were inefficient, stressful or unfulfilling. You might begin to notice some patterns that stand out, for good or bad. Journalling and reflection is a way to begin decluttering your life, to explore the areas that take you out of being present, and …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/how-to-open-up-to-serendipity-and-create-your-own-luck">https://psyche.co/guides/how-to-open-up-to-serendipity-and-create-your-own-luck</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/how-to-open-up-to-serendipity-and-create-your-own-luck</link>
            <guid isPermaLink="false">hacker-news-small-sites-25881742</guid>
            <pubDate>Sat, 23 Jan 2021 12:27:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Italy orders TikTok to stop using children’s data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25881721">thread link</a>) | @gr2zr4
<br/>
January 23, 2021 | https://www.politico.eu/article/italy-orders-tiktok-to-stop-using-childrens-data/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/italy-orders-tiktok-to-stop-using-childrens-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									<p>The Italian data protection authority on Friday ordered video sharing platform TikTok to immediately stop collecting and using data of users whose ages it doesn't know "with certainty." </p>
<p>The order comes after a 10-year-old girl in the Sicilian city of Palermo <a href="https://www.ansa.it/english/news/general_news/2021/01/21/girl-10-brain-dead-after-taking-tiktok-blackout-challenge_4fd482a0-e3f3-47ed-b8ab-29e7a81dc33a.html" target="_blank">died from asphyxiation after participating in a so-called blackout challenge on the social network.</a> Users must be 13-years-old or older to set up an account, according to the company's policies.</p>
<p>"The authority has decided to intervene as a matter of urgency following the terrible story of the 10-year-old girl from Palermo," <a href="https://www.garanteprivacy.it/home/docweb/-/docweb-display/docweb/9524224" target="_blank">the authority, called Garante, said in a statement Friday</a>.</p>

<p>Ordinarily privacy enforcement against TikTok would be led by the Irish Data Protection Commission (DPC), since the platform is legally established in Dublin. But Garante said it is invoking an emergency procedure that allows it to act directly against the company. It said it had notified the Irish authority of the restrictions, which will initially be in place until February 15.</p>
<p>A spokesperson for the Irish DPC declined to comment on Garante's order, but confirmed that the DPC has been TikTok's lead authority under EU rules since mid-December.</p>
<p>The action comes while Garante was already investigating TikTok, <a href="https://www.politico.eu/?p=1558838">having initiated a formal procedure against the app in December.</a> TikTok did not respond to a request for comment. </p>
								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/italy-orders-tiktok-to-stop-using-childrens-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25881721</guid>
            <pubDate>Sat, 23 Jan 2021 12:23:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Never Ever Use NixOS]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25881654">thread link</a>) | @nudpiedo
<br/>
January 23, 2021 | https://hands-on.cloud/why-you-should-never-ever-use-nixos/ | <a href="https://web.archive.org/web/*/https://hands-on.cloud/why-you-should-never-ever-use-nixos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <div>
        <div>
            <div>
                <div>
                    
                    























<picture>
    
        <source data-srcset="https://hands-on.cloud/why-you-should-never-ever-use-nixos/Why-you-should-never-every-use-NixOS.webp" type="image/webp">
    
    <img sizes="(min-width: 35em) 1024px, 100vw" data-srcset="
    
        /why-you-should-never-ever-use-nixos/Why-you-should-never-every-use-NixOS_hu872c30b063e8d97ef97ff92b31b67f9a_114164_500x0_resize_box_2.png 500w
    
    
        , /why-you-should-never-ever-use-nixos/Why-you-should-never-every-use-NixOS_hu872c30b063e8d97ef97ff92b31b67f9a_114164_800x0_resize_box_2.png 800w
    
    
        , /why-you-should-never-ever-use-nixos/Why-you-should-never-every-use-NixOS_hu872c30b063e8d97ef97ff92b31b67f9a_114164_1024x0_resize_box_2.png 1024w
    
    " data-src="/why-you-should-never-ever-use-nixos/Why-you-should-never-every-use-NixOS.png" alt="Why you should never ever use NixOS" srcset="
    
        https://hands-on.cloud/why-you-should-never-ever-use-nixos/Why-you-should-never-every-use-NixOS_hu872c30b063e8d97ef97ff92b31b67f9a_114164_500x0_resize_box_2.png 500w
    
    
        , https://hands-on.cloud/why-you-should-never-ever-use-nixos/Why-you-should-never-every-use-NixOS_hu872c30b063e8d97ef97ff92b31b67f9a_114164_800x0_resize_box_2.png 800w
    
    
        , https://hands-on.cloud/why-you-should-never-ever-use-nixos/Why-you-should-never-every-use-NixOS_hu872c30b063e8d97ef97ff92b31b67f9a_114164_1024x0_resize_box_2.png 1024w
    
    " src="https://hands-on.cloud/why-you-should-never-ever-use-nixos/Why-you-should-never-every-use-NixOS.png">
</picture>

                    <p>Table Of Contents</p>
                    <nav id="TableOfContents">
  <ul>
    <li><a href="#why-you-may-want-to-use-nixos">Why you may want to use NixOS.</a>
      <ul>
        <li><a href="#determinism">Determinism.</a></li>
      </ul>
    </li>
    <li><a href="#why-you-should-never-ever-use-nixos">Why you should never ever use NixOS.</a>
      <ul>
        <li><a href="#small-community">Small community.</a></li>
        <li><a href="#documentation">Documentation.</a></li>
        <li><a href="#configuration-management">Configuration management.</a></li>
        <li><a href="#kernel-upgrade">Kernel upgrade.</a></li>
        <li><a href="#cloud-support">Cloud support.</a></li>
        <li><a href="#cache">Cache.</a></li>
        <li><a href="#security">Security.</a></li>
        <li><a href="#windows-support">Windows support.</a></li>
        <li><a href="#system-requirements">System requirements.</a></li>
        <li><a href="#once-invested">Once invested.</a></li>
        <li><a href="#what-to-do-next">What to do next.</a></li>
        <li><a href="#docker-is-the-best-alternative">Docker is the best alternative.</a></li>
        <li><a href="#additional-reading">Additional reading.</a></li>
      </ul>
    </li>
  </ul>
</nav>
                    
                    <p><audio controls="">
        <source src="https://hands-on.cloud/why-you-should-never-ever-use-nixos/index.mp3" type="audio/mpeg">
        <p>Your browser doesn't support HTML5 audio. Here is
            a <a href="https://hands-on.cloud/why-you-should-never-ever-use-nixos/index.mp3">link to the audio</a> instead.</p>
    </audio>
</p>
                    <p>I’ll start my article from the biggest myth about NixOS. And soon you’ll know why.</p>
<blockquote>
<p>DevOps-friendly. Declarative specs and safe upgrades make NixOS a great system for DevOps use. NixOps, the NixOS cloud deployment tool, allows you to provision and manage networks of NixOS machines in environments like Amazon EC2 and VirtualBox. (c) <a href="https://nixos.org/">NixOS.org</a></p>
</blockquote>
<p>I will continuously update this article each time I’ll face a new weird and challenging task that makes your life much harder if you’re using NixOS instead of traditional Linux distributions.</p>
<p>Well, I’m a lucky guy… I have no choice right now and have to spend most of my working time on NixOS automation. To this moment of time I have more than 10 years experience of using different Linux distributions and more than 6 months of NixOS experience. And most of my experience with NixOS is bad experience.</p>
<h2 id="why-you-may-want-to-use-nixos">Why you may want to use NixOS.</h2>
<p>I’ll try to write something here. Hope, I’ll be able to…</p>
<h3 id="determinism">Determinism.</h3>
<p>It is declared and provided to you by the system design, that you’ll get the same version of any software package from the derivation. Lie!</p>
<p>All it’s determinism is about that it deterministically gives you a lot of issues, which you need to overcome manually without any support.</p>
<p>You may install Nix tools on Linux and OS X, for example. But it is not always building the same derivation results on Linux and NixOS itself. So, it is not OS agnostic. There’re a lot of examples of such behavior, for example, <code>fetchgit</code> and <code>fetchFromGitHub</code> functions:</p>
<ul>
<li><a href="https://github.com/NixOS/nixpkgs/issues/28324">fetchgit/fetchFromGitHub fail to fetch submodules from “git@server:repo” URLs</a>.</li>
<li><a href="https://github.com/NixOS/cabal2nix/issues/260">Use <code>fetchFromGitHub</code> instead of <code>fetchgit</code> when the source is a GitHub clone URL</a>.</li>
<li><a href="https://github.com/NixOS/nixpkgs/pull/27327">fetchgit -&gt; fetchFromGitHub where possible</a>.</li>
<li><a href="https://github.com/NixOS/nix/issues/1880">How to manually replicate/reproduce/obtain the sha256 hash specified in Nix with fetchgit or fetchFromGitHub?</a>.</li>
</ul>
<p>Meanwhile in the official manual to the current and latest <a href="https://nixos.org/nixpkgs/manual/#version-18-09-1373-50fb6820759">version-18-09-1373-50fb6820759</a> they are still using <code>fetchgit</code>.</p>
<h2 id="why-you-should-never-ever-use-nixos">Why you should never ever use NixOS.</h2>
<p>Here I’m gonna collect all my daily pain in a single place, which I hope will help people not to make somebody’s else mistakes. This is my personal view on the problem space and it can not be affiliated with the company or project where I’m working right now.</p>

<p>Sure, there are a lot of enthusiasts who are playing with NixOS by installing it on their workstations of VMs, but in comparison with Ubuntu, CentOS, Debian or RedHat:</p>
<!-- raw HTML omitted -->
<p>That means you will not be able:</p>
<ul>
<li>To get fast or enterprise support.</li>
<li>To to hire people to manage it.</li>
</ul>
<h3 id="documentation">Documentation.</h3>
<p>Official documentation is awful. Or it is just absent. NixOS is older than Docker. They are solving the same task, but NixOS is way less popular. Try to think why.</p>
<p>NIX CONFIGURATION LANGUAGE
It is functional language which name is also Nix and it is a core of this system configuration. If you’re coming from OOP world it will be very difficult to understand that “language”. You must go to swallow <a href="https://nixos.org/nixos/nix-pills/">Nix pills</a> to even try to understand something about it.</p>
<p>SOFTWARE MANAGEMENT
“Derivation” is a way of describing software distribution in NixOS. Each derivation represents software, plugin or a library. Common syntax of describing it looks like this (nginx derivation example):</p>
<div><pre><code data-lang="nix">{ stdenv<span>,</span> fetchurl<span>,</span> openssl<span>,</span> zlib<span>,</span> pcre<span>,</span> libxml2<span>,</span> libxslt
<span>,</span> gd<span>,</span> geoip
<span>,</span> withDebug <span>?</span> <span>false</span>
<span>,</span> withStream <span>?</span> <span>true</span>
<span>,</span> withMail <span>?</span> <span>false</span>
<span>,</span> modules <span>?</span> []
<span>,</span> version<span>,</span> sha256<span>,</span> <span>...</span>
}:

<span>with</span> stdenv<span>.</span>lib;

stdenv<span>.</span>mkDerivation {
  name <span>=</span> <span>"nginx-</span><span>${</span>version<span>}</span><span>"</span>;

  src <span>=</span> fetchurl {
    url <span>=</span> <span>"https://nginx.org/download/nginx-</span><span>${</span>version<span>}</span><span>.tar.gz"</span>;
    <span>inherit</span> sha256;
  };

  buildInputs <span>=</span> [ openssl zlib pcre libxml2 libxslt gd geoip ]
    <span>++</span> concatMap (mod: mod<span>.</span>inputs or []) modules;

  configureFlags <span>=</span> [
    <span>"--with-http_ssl_module"</span>
    <span>"--with-http_v2_module"</span>
    <span>"--with-http_realip_module"</span>
    <span>"--with-http_addition_module"</span>
    <span>"--with-http_xslt_module"</span>
    <span>"--with-http_geoip_module"</span>
    <span>"--with-http_sub_module"</span>
    <span>"--with-http_dav_module"</span>
    <span>"--with-http_flv_module"</span>
    <span>"--with-http_mp4_module"</span>
    <span>"--with-http_gunzip_module"</span>
    <span>"--with-http_gzip_static_module"</span>
    <span>"--with-http_auth_request_module"</span>
    <span>"--with-http_random_index_module"</span>
    <span>"--with-http_secure_link_module"</span>
    <span>"--with-http_degradation_module"</span>
    <span>"--with-http_stub_status_module"</span>
    <span>"--with-threads"</span>
    <span>"--with-pcre-jit"</span>
    <span># Install destination problems</span>
    <span># "--with-http_perl_module"</span>
  ] <span>++</span> optional withDebug [
    <span>"--with-debug"</span>
  ] <span>++</span> optional withStream [
    <span>"--with-stream"</span>
    <span>"--with-stream_geoip_module"</span>
    <span>"--with-stream_realip_module"</span>
    <span>"--with-stream_ssl_module"</span>
    <span>"--with-stream_ssl_preread_module"</span>
  ] <span>++</span> optional withMail [
    <span>"--with-mail"</span>
    <span>"--with-mail_ssl_module"</span>
  ]
    <span>++</span> optional (gd <span>!=</span> <span>null</span>) <span>"--with-http_image_filter_module"</span>
    <span>++</span> optional (<span>with</span> stdenv<span>.</span>hostPlatform; isLinux <span>||</span> isFreeBSD) <span>"--with-file-aio"</span>
    <span>++</span> map (mod: <span>"--add-module=</span><span>${</span>mod<span>.</span>src<span>}</span><span>"</span>) modules;

  NIX_CFLAGS_COMPILE <span>=</span> [ <span>"-I</span><span>${</span>libxml2<span>.</span>dev<span>}</span><span>/include/libxml2"</span> ] <span>++</span> optional stdenv<span>.</span>isDarwin <span>"-Wno-error=deprecated-declarations"</span>;

  preConfigure <span>=</span> (concatMapStringsSep <span>"</span><span>\n</span><span>"</span> (mod: mod<span>.</span>preConfigure or <span>""</span>) modules);

  hardeningEnable <span>=</span> optional (<span>!</span>stdenv<span>.</span>isDarwin) <span>"pie"</span>;

  enableParallelBuilding <span>=</span> <span>true</span>;

  postInstall <span>=</span> <span>''
</span><span>    mv $out/sbin $out/bin
</span><span>  ''</span>;

  meta <span>=</span> {
    description <span>=</span> <span>"A reverse proxy and lightweight webserver"</span>;
    homepage    <span>=</span> <span>http://nginx.org</span>;
    license     <span>=</span> licenses<span>.</span>bsd2;
    platforms   <span>=</span> platforms<span>.</span>all;
    maintainers <span>=</span> <span>with</span> maintainers; [ thoughtpolice raskin fpletz ];
  };
}
</code></pre></div><p>Interesting, isn’t it?</p>
<p>If yes, get ready, you’ll not be able to live in the system without writing something like that. <a href="https://github.com/NixOS/nixpkgs">Nix Packages GitHub repository</a> will be your second home, where you’ll be looking for examples of Nix expressions, configuration approaches and other examples.</p>
<h3 id="configuration-management">Configuration management.</h3>
<p>System state and configuration described in a special file <code>configuration.nix</code>. It’s like an entry point to endless amount of functions and dependencies for your OS.</p>
<p>Want to customize something in the OS, be ready, you’ll need to write your custom <code>systemd</code> service to do that. Aaand, yes, service configuration file also need to be declared using Nix expression language.</p>
<p>All standard system configuration files like <code>/etc/fstab</code>, for example are generated by a weird code and read only.</p>
<p>Forget about Chef, Puppet or Ansible! Only Nix expressions! Only hardcore!</p>
<h3 id="kernel-upgrade">Kernel upgrade.</h3>
<p>It is not possible just to upgrade the kernel from “ver1” to “ver2”. New kernel will bring whole set of system packages and their dependencies with it. Do not know if it is safe. Will test it soon.</p>
<h3 id="cloud-support">Cloud support.</h3>
<p>Nix is not ready for a cloud. At all. I’m always facing the following situations on NixOS 18.03:</p>
<ul>
<li>OS is not booting from the AMI.</li>
<li>OS is not supporting newest AWS instance types (like m5.*, for example).</li>
<li>NixOS 18.03 is not always able to resize your hard drive when it’s boot.</li>
<li>Do not even try to use it in Auto Scaling group and passing configuration.nix content through user-data. You may easily get to the loop, when instance start building something new from the derivations during it’s boot process, 100% CPU utilizations will require AutoScaling Group to launch additional instances that also will build something, all the instances are unhealthy and Auto Scaling group will start terminating the first instance in a loop. Your service will never start.</li>
</ul>
<h3 id="cache">Cache.</h3>
<p>To speedup software installation in NixOS the community provides you with Nix Binary Cache, where they put everything they’ve built successfully. Every version of every derivation.</p>
<p>Problems start happening when you spinning up your personal cache, which is used, for example to store your proprietary build artifacts. You always need to keep eye on the community channel version you’re using as a base for your builds. And yes, your own cache size will also grow very fast!</p>
<p>Some very talented developers start using Nix binary cache to cache everything’s possible. For example NPM or Yarn packages. Good luck!</p>
<h3 id="security">Security.</h3>
<p>People are thinking, that NixOS deterministic approach of dealing with software is very secure. Maybe yes, it is really not possible to hijack the build results once the derivation bin build. But… You always need to pay for it…</p>
<p>During the upgrade from 18.03 to 18.09 Nix community decided to change Docker tools they’ve been use to calculate derivations checksums where you were dealing with Docker images.</p>
<p>As a result we rewrote all Docker based derivation declarations and more over to rebuild them all. It was really painful and unmanaged migration.</p>
<h3 id="windows-support">Windows support.</h3>
<p>Just forget about it.</p>
<h3 id="system-requirements">System requirements.</h3>
<p>It requires a lot of CPU power to build it’s stuff and really a lot of space to store its multiple versions. Much more, than you need in traditional Linux distros.</p>
<h3 id="once-invested">Once invested.</h3>
<ul>
<li>Try to change a technology stack as soon as possible.</li>
<li>Do not listen anybody.</li>
<li>Do not reinvent the wheel.</li>
<li>Just waste it.</li>
</ul>
<p>And, God, do not try to run Nix in Docker! It’s really, not, REALLY bad idea!</p>
<h3 id="what-to-do-next">What to do next.</h3>
<p>Run away! Not, seriously! Run. From. It. Away.</p>
<p>When you try to summarize all your thoughts around the topic you want to cover in a post, you’re starting from simple Google search. One of results to my “nixos pros and cons” query: <a href="https://alternative.me/nixos">NixOS alternatives</a>. Kinda joke, but really, think twice when you’re making decision to invest your time or money in it. And I would also think …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hands-on.cloud/why-you-should-never-ever-use-nixos/">https://hands-on.cloud/why-you-should-never-ever-use-nixos/</a></em></p>]]>
            </description>
            <link>https://hands-on.cloud/why-you-should-never-ever-use-nixos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25881654</guid>
            <pubDate>Sat, 23 Jan 2021 12:05:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Category Theory Illustrated – Monoids]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25881628">thread link</a>) | @tutfbhuf
<br/>
January 23, 2021 | https://boris-marinov.github.io/category-theory-illustrated/03_monoid/ | <a href="https://web.archive.org/web/*/https://boris-marinov.github.io/category-theory-illustrated/03_monoid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <!--<h1>Monoids</h1> -->
        

<p>Since we are done with categories, letâ€™s look at some other structures that are also interesting - monoids. Like categories, monoids/groups are also abstract systems consisting of objects and rules for manipulating these objects.</p>



<p>Monoids are simpler than categories. A monoid is defined by a collection (set) of elements and an operation that allows us to combine two element and produce a third one of the same kind.</p>

<p>Letâ€™s take our familiar colourful balls.</p>

<p><img src="https://boris-marinov.github.io/category-theory-illustrated/03_monoid/balls.svg" alt="Balls"></p>

<p>In this case a monoid would be a rule (operation) for â€œcombiningâ€� two balls into one.</p>

<p>An example of such rule would be blending the colors of the balls, as if we are mixing paint.</p>

<p><img src="https://boris-marinov.github.io/category-theory-illustrated/03_monoid/balls_rule.svg" alt="A rule for combining balls"></p>

<p>You can probably think of other ways to define such a rule. This will help you realize that there can be many ways to create a monoid from a given set of items. The monoid is not the set itself, it is the set <em>together with the rule</em>.</p>

<h2 id="associativity">Associativity</h2>

<p>The monoid rule should, like functional composition, be â€œassociativeâ€� i.e. applying it on the same number of elements in a different order should make no difference.</p>

<p><img src="https://boris-marinov.github.io/category-theory-illustrated/03_monoid/balls_associativity.svg" alt="Associativity in the color mixing operation"></p>

<p>When a rule is associative, this means we can use all kinds of algebraic operations to any sequence of terms (or in other words to apply equation reasoning), like for example we can replace any element with a set of elements from which it is composed of, or add a term that is present at both sides of an equation and retaining the equality of the existing terms.</p>

<p><img src="https://boris-marinov.github.io/category-theory-illustrated/03_monoid/balls_arithmetic.svg" alt="Associativity in the color mixing operation"></p>

<h2 id="the-identity-element">The identity element</h2>

<p>Actually, not any (associative) rule for combining elements makes the balls form a monoid (it makes them form a â€œsemigroupâ€�, which is also a thing, but thatâ€™s a separate topic). In order to be a monoid, a set must feature what is called an â€œidentity elementâ€� of a given rule (or a <em>zero</em> element, if you prefer) - one that, when combined with any other element gives back that same element not the identity but the other one. Or simply <strong>x â€¢ i = x and i â€¢ x = x for any x</strong>. In the case of our color-mixing monoid the identity element is the white  ball (or perhaps a transparent one, if we have one).</p>

<p><img src="https://boris-marinov.github.io/category-theory-illustrated/03_monoid/balls_identity.svg" alt="The identity element of the color-mixing monoid"></p>

<p>As you probably remember from the last chapter, functional composition is also associative and it also contains an identity element, so you might start suspecting that it forms a monoid in some way. And it is really the case with one little caveat.</p>

<p>To keep the suspense alive, letâ€™s see some simpler monoids before we dwelve into that:</p>



<h2 id="monoids-from-numbers">Monoids from numbers</h2>

<p>Mathematics is not all about numbers, however numbers do tend to pop up in most of its areas and monoids are no exception. The set of natural numbers <em>N</em> form a monoid when combined with the all too familiar operation of addition (or to use the official terminology <em>N</em> <em>form</em> a monoid <em>under</em> addition).</p>

<p><img src="https://boris-marinov.github.io/category-theory-illustrated/03_monoid/numbers_addition.svg" alt="The monoid of numbers under addition"></p>

<p>(if you see a <strong>1 + 1 = 2</strong> in your textbook you know you are working on math foundations (or you are in kindergarten)).</p>

<p>The natural numbers also form a monoid under multiplication as well:</p>

<p><img src="https://boris-marinov.github.io/category-theory-illustrated/03_monoid/numbers_multiplication.svg" alt="The monoid of numbers under multiplication"></p>

<p><strong>Task:</strong> Which are the identity elements of those monoids?</p>

<p><strong>Task:</strong> Go through other mathematical operations and figure out why donâ€™t they are not monoidal.</p>

<h2 id="monoids-from-boolean-algebra">Monoids from boolean algebra</h2>

<p>Thinking about other operations that we covered (operation being a function which takes a pair of element of a given type and returns one element of the same type), we may remember the boolean operations <strong>AND</strong> and <strong>OR</strong>. which operate on the set, consisting of just two values <strong>{ True, False }</strong>. Those operations form monoids too. Proving that they do is easy enough by just enumerating all cases.</p>

<p>We can prove that <strong>AND</strong> is associative by expanding the formula <strong>(A AND B) AND C = A AND (B AND C)</strong> in all possible ways:</p>

<p><strong>(TRUE AND FALSE) AND TRUE = TRUE AND (FALSE AND TRUE)</strong></p>

<p><strong>(TRUE AND FALSE) AND FALSE = TRUE AND (FALSE AND FALSE)</strong></p>

<p><strong>(FALSE AND FALSE) AND TRUE = FALSE AND (FALSE AND TRUE)</strong></p>

<p>â€¦</p>

<p>And we can prove that <strong>TRUE</strong> is the identity element by expanding the other formulas that state that for all elements <strong>A</strong> <strong>I AND A = A</strong></p>

<p><strong>FALSE AND TRUE = FALSE</strong></p>

<p><strong>TRUE AND TRUE = TRUE</strong></p>

<p>â€¦and then do the same for <strong>A AND I = A</strong>.</p>

<h2 id="intuitions">Intuitions</h2>

<p>In order to form the correct intuition about monoids, try to avoid thinking of the elements in the set as objects, but instead think of them as <em>actions</em>. For example, when thinking about numbers donâ€™t think of them as <em>quantities</em> (as in two apples, two oranges etc.), but as <em>operations</em>, (e.g. as the action of adding one to a given quantity). In other words, donâ€™t think of the element by itself, but only think of it together with the operation (in this case addition).</p>

<p>This touches a programming concept which is very popular in category-theory inspired languages - currying - that is based on the idea that a function that accepts two arguments together with one of those arguments already supplied can be viewed as a function which takes one argument. e.g. the function <code>add(number, number)</code> together with the element <code>2</code> is equivalent to the <code>addTwo(number)</code> function.</p>

<p>In general, we use monoids and related structures as a way to model how a set of (associative) actions that are performed on a given object (or objects) alter itâ€™s state. We can do that, provided that the objectâ€™s state is determined solemnly by the actions that are performed on it, this allows us to leave the object out of the equation and concentrate on how the actions are combined. And as per usual in the actions (and objects) can be anything, from mixing colors in paint, or adding a quantities to a given set of things etc.</p>



<p>Monoid operations obey two laws - they are associative and there is an identity element. In some cases we come across operations that also obey other laws that are also interesting. Imposing more (or less) rules to the way in which actions are combinded results in the definition of other monoid-like structures.</p>

<h2 id="commutative-abelian-monoids">Commutative (abelian) monoids</h2>

<p>Looking at the monoid laws and the examples we gave so far, we observe that all of them obey one more rule (law) which we didnâ€™t specify - the order in which the operations are applied is irrelevant to the end result.</p>

<p><img src="https://boris-marinov.github.io/category-theory-illustrated/03_monoid/monoid_commutative.svg" alt="Commutative monoid operation"></p>

<p>Such operations (ones for which combining a given set of objects yields the same result no matter which one is first and which one is second) are called <em>commutative</em> operations. Monoids with operations that are commutative are called <em>commutative monoids</em>.</p>

<p>As we said, addition is commutative as well - it does not matter whether if I have given you 1 apple and then 2 more, or if I have given you 2 first and then 1 more.</p>

<p><img src="https://boris-marinov.github.io/category-theory-illustrated/03_monoid/addition_commutative.svg" alt="Commutative monoid operation"></p>

<p>All monoids that we examined so far are also <em>commutative</em>, but we will see some non-commutative ones later.</p>

<h2 id="groups">Groups</h2>

<p>A group is a monoid in which each element has what is called an â€œinverseâ€� element where the element and its inverse cancel each other out when applied one after the other, in other words , <strong>forall x, there must exist xâ€™ such that x â€¢ xâ€™ = i</strong> ( where <strong>i</strong> is the identity element).</p>

<p>If we view <em>monoids</em> as a means of modelling the effect of applying a set of (associative) actions, we use <em>groups</em> to model the effects of actions are also <em>reversible</em>.</p>

<p>An nice example of a group can be found in the realm of numbers (really, numbers are a nice example of almost all laws) - it is the set of integers under addition, where the inverse of each number is its opposite number (positive numbersâ€™ inverse are negatives and vice versa). The above formula, then, becomes <strong>x + (-x) = 0</strong></p>

<p>The study of groups is a field that is much bigger than the theory of monoids (and perhaps bigger than category theory itself).</p>

<p>And it all started with the what are now called the â€œsymmetry groupsâ€� which we will look into in more detail.</p>

<h2 id="summary">Summary</h2>

<p>The algebraic structures that we saw can be summarized based on the laws that define them in this table.</p>

<table>
  <thead>
    <tr>
      <th>Â&nbsp;</th>
      <th>Semigroups</th>
      <th>Monoids</th>
      <th>Groups</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Associativity</td>
      <td>X</td>
      <td>X</td>
      <td>X</td>
    </tr>
    <tr>
      <td>Identity</td>
      <td>Â&nbsp;</td>
      <td>X</td>
      <td>X</td>
    </tr>
    <tr>
      <td>Invertability</td>
      <td>Â&nbsp;</td>
      <td>Â&nbsp;</td>
      <td>X</td>
    </tr>
  </tbody>
</table>



<p>An interesting kinds of groups/monoids are the groups of <em>symmetries</em> of geometric figures. Given some geometric figure, a symmetry is an action after which the figure is not displaced (e.g. it can fit into the same mold that it fit before the action was applied).</p>

<p>We wonâ€™t use the balls this time, as they have just one position just one action - the identity action (which is itâ€™s own reverse by the way). So letâ€™s take this triangle (which for our purposes, is the same as any other triangle).</p>

<p><img src="https://boris-marinov.github.io/category-theory-illustrated/03_monoid/symmetry_group.svg" alt="A triangle"></p>

<h2 id="groups-of-rotations">Groups of rotations</h2>

<p>Letâ€™s first review the group of ways in which we can rotate our triangle i.e. its <em>rotation group</em>. A geometric figure can be rotated without displacement in positions equal to the number of its sides, so for our triangle there are 3 positions.</p>

<p><img src="https://boris-marinov.github.io/category-theory-illustrated/03_monoid/symmetry_rotation.svg" alt="The group of rotations in a triangle"></p>

<p>Connecting the dots (or the triangles in this case) shows us that there are just two possible actions that get us from any state to any other one - a <em>120-degree rotation</em> (i.e. flipping the triangle one time) and a <em>240-degree rotation</em> (i.e. flipping it two times (or equivalently, flipping it once, but in the opposite direction)). Adding the identity action of 0-degree rotation makes up for 3 actions in total.</p>

<p><img src="https://boris-marinov.github.io/category-theory-illustrated/03_monoid/symmetry_rotation_actions.svg" alt="The group of rotations in a triangle"></p>

<h2 id="cyclic-groupsmonoids">Cyclic groups/monoids</h2>

<p>Ennumerating all the rotations of a more complex geometrical figure looks quite messy at first.</p>

<p><img src="https://boris-marinov.github.io/category-theory-illustrated/03_monoid/symmetry_rotation_square.svg" alt="The group of rotations in a more complex figure"></p>

<p>But itâ€™s much simpler to grasp if we notice the following: although our group has many actions, and there are more still for figures with more sides (if I am not mistaken, the number of actions is equal to the number of the sides), all of those actions can be reduced to the repetitive application of just the simplest action, (the 120-degree rotation for triangles and the 30-degree rotation for octagons). Letâ€™s make up a symbol for this rotation.</p>

<p><img src="https://boris-marinov.github.io/category-theory-illustrated/03_monoid/symmetry_rotation_cyclic.svg" alt="The group of rotations in a triangle"></p>

<p>Groups and monoids that have this â€œmainâ€� action (called a â€œgeneratorâ€�) which when applied enough times can get you to any state that which is <em>cyclic groups</em>. All rotation groups are cyclic groups. Another example of a cyclic groups is, yes, the integers under addition. Here we can use <strong>+1</strong> or <strong>-1</strong> as generators.</p>

<p><img src="https://boris-marinov.github.io/category-theory-illustrated/03_monoid/numbers_cyclic.svg" alt="The group of numbers under addition"></p>

<p>Wait, how can this be a cyclic group when there are no cycles? This is because the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boris-marinov.github.io/category-theory-illustrated/03_monoid/">https://boris-marinov.github.io/category-theory-illustrated/03_monoid/</a></em></p>]]>
            </description>
            <link>https://boris-marinov.github.io/category-theory-illustrated/03_monoid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25881628</guid>
            <pubDate>Sat, 23 Jan 2021 11:59:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi 400 running Swift microservices]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25881565">thread link</a>) | @vi4m
<br/>
January 23, 2021 | https://www.marcinkliks.pl/programming/2021/01/19/swift-services-with-mongo-on-raspberry-pi-400/ | <a href="https://web.archive.org/web/*/https://www.marcinkliks.pl/programming/2021/01/19/swift-services-with-mongo-on-raspberry-pi-400/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
     
    <p><img width="180" src="">
    </p>
    
  <p><img src="https://www.marcinkliks.pl/uploads/574678AA-1A52-4634-84F5-95595B09BCF8.jpeg" alt="574678AA-1A52-4634-84F5-95595B09BCF8.jpeg"></p>

<p>Raspberry Pi 400 has sufficient power to run full-featured microservices written in Swift. Running Swift (together with MongoDB) on such a small gadget is serious fun!</p>

<p>I’ve tested this setup on Raspberry PI 400 which has a quad core processor, 4 GB of RAM and a speedy USB 3.0 SSD, however the instructions below are not limited only to this device. <br>
Even though base configuration was not overclocked, I’ve managed to run simple <a href="http://vapor.codes/">Vapor-based microservice</a>, and achieve over 10 000 req/sec on this little piece of silicon!</p>

<p><img src="https://www.marcinkliks.pl/uploads/pi-10k-24fa0e.png" width="800"></p>

<h2 id="installing-swift-on-rasperry-pi">Installing Swift on Rasperry PI</h2>

<p>If you want to use the latest Vapor 4, you need to upgrade Raspberry PI OS to 64 bits. Otherwise, this step may be skipped.</p>

<p>Ideal setup, as of 01/2020 is:</p>

<ul>
  <li>Swift 5.3.1</li>
  <li>MongoDB 4.9.0</li>
  <li>Nginx</li>
</ul>

<p>For IDE we will use:</p>

<ul>
  <li>Visual Studio Code 1.52.1 (latest current version)</li>
  <li>sourcekit-lsp trunk (revision:6eb17c9a7bc00bec83d57d2399ba9f5ab14d3bcc )</li>
</ul>

<h2 id="upgrading-to-rasperry-pi-os-64-bit">Upgrading to Rasperry PI OS 64 bit</h2>

<p>Swift ARM builds are available here: <a href="https://packagecloud.io/swift-arm/release">https://packagecloud.io/swift-arm/release</a>. 
Unfortunatelly, the latest version for Rasperry PI OS (default distribution) is 5.1.3 and it’s not usable with the latest Vapor 4 version. We need to upgrade the operating system to 64 bits.</p>

<ol>
  <li>Install the beta version of Rasperry PI OS 64 bit <a href="https://www.raspberrypi.org/forums/viewtopic.php?p=1668160">here</a> if you need the latest Swift.</li>
  <li>Install swift package from packagecloud.io <code>https://packagecloud.io/swift-arm/release/packages/debian/buster/swiftlang_5.3.1-3-debian-buster_arm64.deb</code> with <code>dpkg -i</code></li>
  <li>Swift REPL is not usable at the moment, but it’s not a big deal so don’t worry.</li>
  <li>Swap file. Swift needs a lot of memory during the compilation, so let’s find a spare SSD drive, and create some fast swap files, at least 5 GB.
    <div><div><pre><code>swapoff <span>-a</span>
<span>dd </span><span>if</span><span>=</span>/dev/zero <span>of</span><span>=</span>/media/[yourssd]/swap <span>ibs</span><span>=</span>1M <span>obs</span><span>=</span>1M <span>count</span><span>=</span>5000
mkswap /media/[yourssd]/swap
swapon /media/[yourssd]/swap
</code></pre></div>    </div>
  </li>
  <li>That’s it. Test if your code compiles. Vapor 4 should run just fine!
    <div><div><pre><code>swift package init <span>--type</span> executable
swift build
</code></pre></div>    </div>
  </li>
</ol>

<h2 id="ide-on-raspberry-pi-with-visual-studio-code-lsp-and-swift">IDE on Raspberry PI with Visual Studio Code, LSP and Swift</h2>

<ol>
  <li>Install ARM64 DEB package from Visual Studio Code <a href="https://code.visualstudio.com/download">https://code.visualstudio.com/download</a></li>
  <li>You need this package: <code>https://github.com/apple/sourcekit-lsp</code> to use the Auto-Completion functionality in Visual Studio Code, because version 5.3.1 is unusably slow. The new version is 10 times more performant. We will compile it from sources using this documentation <a href="https://github.com/apple/sourcekit-lsp/blob/main/Documentation/Development.md">here</a>. 
This will work for arm64:</li>
</ol>

<div><div><pre><code>swift build -c release -Xcxx -I/usr/lib/swift -Xcxx -I/usr/lib/swift/Block
cp .build/aarch64-unknown-linux-gnu/release/sourcekit-lsp /usr/local/bin/sourcekit-lsp

apt-get install npm
cd Editors/vscode
npm run createDevPackage
code --install-extension ./out/sourcekit-lsp-vscode-dev.vsix
</code></pre></div></div>
<p>After installation, every feature should work well, including: autocompletion, fix-its, documentation, go to definition.
If not, it’s probably because of the internal card speed - see below how to improve the performance by a factor of 10.</p>

<h2 id="optimization">Optimization</h2>

<p>SD cards tend to be slow. I recommend to either boot from an SSD entirely, or boot from an SD card, but in this case move the essential data to faster drive. It makes a huge difference during development.</p>

<p><strong>Directories to move to external faster drive:</strong></p>
<div><div><pre><code>~/.config/Code <span>(</span><span>for </span>Visual Studio Code<span>)</span>
~/.cache  <span>(</span><span>for </span>various developmnt tasks<span>)</span>
/tmp <span>(</span>e.g. lsp cache<span>)</span>
</code></pre></div></div>

<p>You can tune your system for maximum performance:</p>
<div><div><pre><code>fs.inotify.max_user_watches=524288
cd /sys/devices/system/cpu
echo performance &gt; cpu0/cpufreq/scaling_governor 
echo performance &gt; cpu1/cpufreq/scaling_governor 
echo performance &gt; cpu2/cpufreq/scaling_governor 
echo performance &gt; cpu3/cpufreq/scaling_governor 
echo performance &gt; cpu4/cpufreq/scaling_governor 
</code></pre></div></div>

<h2 id="mongodb-on-raspberry-pi">MongoDB on Raspberry PI</h2>

<p>Ok, this is an optional step. Chances are, your microservice needs a database, such as MongoDB. Yes, it works just fine, but you need to compile it from sources.</p>

<p>You need at least 20 GB of free space for compilation. Compilation will take at least 5-10 hours.</p>

<p>We will compile as usual using <code>https://github.com/mongodb/mongo/blob/master/docs/building.md</code>, but have to provide additional flag since there are problems with crc32 because of missing instructions. <a href="https://jira.mongodb.org/browse/SERVER-30893">More information here</a></p>

<p>Using flag <code>--use-hardware-crc32=off</code> will compile it fine. Full script should look similar to this:</p>

<div><div><pre><code>git clone https://github.com/mongodb/mongo.git

python3 <span>-m</span> vevn virtualenv
<span>source </span>virtualenv/bin/activate

python3 buildscripts/scons.py install-mongod <span>--disable-warnings-as-errors</span> <span>--use-hardware-crc32</span><span>=</span>off

</code></pre></div></div>

<p>Congratulations, after 5-10 hours, you will get the 4,2 GB binary file called <code>mongodb</code>. It’s time to strip it to just ~40 MB with the instructions below:</p>

<div><div><pre><code>root@raspberrypi:/media/pi/rpi/mongo# <span>ls </span>build/install/bin/mongod
build/install/bin/mongod

root@raspberrypi:/media/pi/rpi/mongo# strip build/install/bin/mongod
root@raspberrypi:/media/pi/rpi/mongo# <span>cp </span>build/install/bin/mongod /usr/local/bin
</code></pre></div></div>

<p>Now it’s time to prepare a storage space for a database and logs. Use your external drive and mount it somewhere. E.g. create <code>mongo-data</code> and <code>mongo-logs</code> directories, and use the following configuration files as examples.
I used the simplest configuration possible. I recommend changing the default user <code>pi</code>, for security reasons.</p>

<div><div><pre><code>root@raspberrypi:/media/pi/rpi/mongo# <span>cat</span> /etc/systemd/system/mongodb.service 
</code></pre></div></div>

<div><div><pre><code><span>[Unit]</span>
<span>Description</span><span>=</span><span>MongoDB Database Server</span>
<span>Documentation</span><span>=</span><span>https://docs.mongodb.org/manual</span>
<span>After</span><span>=</span><span>network-online.target</span>
<span>Wants</span><span>=</span><span>network-online.target</span>

<span>[Service]</span>
<span>User</span><span>=</span><span>pi</span>
<span>Group</span><span>=</span><span>adm</span>
<span>#EnvironmentFile=-/etc/default/mongod
</span><span>ExecStart</span><span>=</span><span>/usr/local/bin/mongod --config /etc/mongod.conf</span>
<span>PIDFile</span><span>=</span><span>/var/run/mongodb/mongod.pid</span>
<span># file size
</span><span>LimitFSIZE</span><span>=</span><span>infinity</span>
<span># cpu time
</span><span>LimitCPU</span><span>=</span><span>infinity</span>
<span># virtual memory size
</span><span>LimitAS</span><span>=</span><span>infinity</span>
<span># open files
</span><span>LimitNOFILE</span><span>=</span><span>64000</span>
<span># processes/threads
</span><span>LimitNPROC</span><span>=</span><span>64000</span>
<span># locked memory
</span><span>LimitMEMLOCK</span><span>=</span><span>infinity</span>
<span># total threads (user+kernel)
</span><span>TasksMax</span><span>=</span><span>infinity</span>
<span>TasksAccounting</span><span>=</span><span>false</span>

<span># Recommended limits for mongod as specified in
# https://docs.mongodb.com/manual/reference/ulimit/#recommended-ulimit-settings
</span>
<span>[Install]</span>
<span>WantedBy</span><span>=</span><span>multi-user.target</span>
</code></pre></div></div>

<p>And this is the counterpart <code>/etc/mongod.conf</code> file.</p>

<div><div><pre><code><span># mongod.conf
</span>
<span># for documentation of all options, see:
#   http://docs.mongodb.org/manual/reference/configuration-options/
</span>
<span># Where and how to store data.
</span><span>storage:</span>
  <span>dbPath:</span> <span>/media/</span><span>[yourssd]</span><span>/mongo-data</span>
  <span>journal:</span>
    <span>enabled:</span> <span>true</span>
<span>#  engine:
#  wiredTiger:
</span>
<span># where to write logging data.
</span><span>systemLog:</span>
  <span>destination:</span> <span>file</span>
  <span>logAppend:</span> <span>true</span>
  <span>path:</span> <span>/media/</span><span>[yourssd]</span><span>/mongo-logs/mongo.log</span>

<span># network interfaces
</span><span>net:</span>
  <span>port:</span> <span>27017</span>
  <span>bindIp:</span> <span>127.0.0.1</span>


<span># how the process runs
</span><span>processManagement:</span>
  <span>timeZoneInfo:</span> <span>/usr/share/zoneinfo</span>

<span>#security:
</span>
<span>#operationProfiling:
</span>
<span>#replication:
</span>
<span>#sharding:
</span>
<span>## Enterprise-Only Options:
</span>
<span>#auditLog:
</span>
<span>#snmp:
</span></code></pre></div></div>

<p>Now, it’s time to run it!</p>

<div><div><pre><code>systemctl daemon-reload
service mongodb start
</code></pre></div></div>

<p>Check your logs directory for troubleshooting with <code>journalctl -u mongodb.service</code>.</p>

<p>Congratulations!</p>

<p>I hope you will have as much fun as I did with this. Feel free to leave any comments or suggestions below. 
Thanks for trying it out!</p>

  </article></div>]]>
            </description>
            <link>https://www.marcinkliks.pl/programming/2021/01/19/swift-services-with-mongo-on-raspberry-pi-400/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25881565</guid>
            <pubDate>Sat, 23 Jan 2021 11:46:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Italy Blocks Users on TikTok After 10-Year-Old Girl Died in a Blackout Challenge]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25881460">thread link</a>) | @sodrick
<br/>
January 23, 2021 | https://relayvibes.co/italy-blocks-users-on-tiktok-after-a-10-year-old-girl-died-in-a-blackout-challenge/ | <a href="https://web.archive.org/web/*/https://relayvibes.co/italy-blocks-users-on-tiktok-after-a-10-year-old-girl-died-in-a-blackout-challenge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1450">
	
		<div>
<figure>
<img src="https://relayvibes.co/wp-content/uploads/2021/01/tiktok-678x381.jpg" alt="Italy Blocks Users On Tiktok" title="tiktok">
</figure>

<div><p><a href="https://relayvibes.co/tag/Italianauthority">Italian authority</a> has blocked certain users from accessing TikTok. Users, who can’t definitely verify their age after the tragic death of a young girl who is taking part in a “blackout challenge”, from accessing Tiktok.</p>
<p>This girl’s death was firstly reported by ANSA on Thursday when it happened.</p>
<p>From the report:</p>
<p>A Italian girl,10, was pronounced brain dead by a Palermo hospital on Thursday after she took the Blackout Challenge on TikTok.</p>
<p>Her parents have accepted to donate the organs of the girl, who tied a belt round her neck to self-asphyxiate in the challenge on Tiktok.</p>
<p>Read also: <strong><a href="https://relayvibes.co/tiktok-star-tony-lopez-sued-for-sexual-battery/">TikTok Star, Tony Lopez Sued For Sexual Battery</a></strong></p>
<p>According to <a href="https://www.theguardian.com/world/2021/jan/23/italy-blocks-tiktok-for-certain-users-after-death-of-girl-allegedly-playing-choking-game#:~:text=Italian%20prosecutors%20have%20opened%20an,could%20not%20be%20proved%20definitively." target="_blank" rel="noopener">The Guardian</a>, an investigation has been opened by Italian prosecutors , and Italy has temporarily blocked users from gaining access to the popular social platform “whose age couldn’t be verified.”</p>
<p>TikTok had reported that it has not discovered any content on its site that may have persuaded the girl to participate in the challenge, but was assisting the authorities in probing the incident.</p>
<p>A Tiktok spokesperson said: “The safety of the TikTok community is our absolute priority, for this reason we do not allow any content which encourages, promotes or glorifies behavior that could be dangerous”</p>
<p>The report shows that the Italian Data Protection Authority had blocked TikTok till February 15th immediately till regulator’s demands are met. This challenge being referred to was also reportedly called “scarfing” or “the choking game”, involving participants blocking oxygen to their brain in order to get high. The girl’s parents told La Repubblica that they are not aware of the game and only aware of their daughter going on TikTok for dances, and to watch videos.</p>

</div>

	</div><div id="text-13">			<p><img loading="lazy" src="https://relayvibes.co/wp-content/uploads/2020/08/ad-300x250-mh-magazine-3.png" alt="" width="300" height="250"></p>
		</div></article></div>]]>
            </description>
            <link>https://relayvibes.co/italy-blocks-users-on-tiktok-after-a-10-year-old-girl-died-in-a-blackout-challenge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25881460</guid>
            <pubDate>Sat, 23 Jan 2021 11:15:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Contradiction at the Heart of Stallman’s Free Software Argument]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25881273">thread link</a>) | @erwald
<br/>
January 23, 2021 | https://www.erichgrunewald.com/posts/a-contradiction-at-the-heart-of-stallman%27s-free-software-argument/ | <a href="https://web.archive.org/web/*/https://www.erichgrunewald.com/posts/a-contradiction-at-the-heart-of-stallman%27s-free-software-argument/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div id="content">
                
<blockquote>
<p>When they came to him, straightway he cast the serpent into the deep sea, where he lies about all the land; and this serpent grew so greatly that he lies in the midst of the ocean encompassing all the land, and bites upon his own tail.<sup><a href="#fn1" id="fnref1">1</a></sup></p>
<p>– Snorri Sturluson</p>
</blockquote>
<p>Let me begin with a throat clearing. I’m all for free (as in free speech) software. I have contributed, in small ways at least, to free &amp; open source projects, I admire many of its proponents &amp; contributors &amp; am increasingly trading out proprietary tools &amp; services for free ones. The <a href="https://github.com/erwald/blog">code for this website</a> is free. Nearly every other software project I have undertaken privately is also free. I think that <a href="https://www.erichgrunewald.com/posts/evolution-of-programming-language-traits/">making software free is good for innovation</a>. It’s good for programmers. It’s good for people. It’s the kind of thing that everybody can get behind.</p>
<p>But (&amp; you knew there was going to be a “but”) the philosophy that Richard Stallman presents in <em><a href="https://www.gnu.org/philosophy/shouldbefree.en.html">Why Software Should Be Free</a></em> goes too far for me. It goes so far that it bends into a circle &amp; eats its own tail, like <a href="https://en.wikipedia.org/wiki/J%C3%B6rmungandr">the world-serpent of the Norse sagas</a>. That is to say, there is a contradiction at its heart, precisely where its theory meets its praxis.</p>
<p>I will explain what I mean by that soon enough. But first I will try to summarise Stallman’s argument as clearly &amp; sympathetically as I can. The argument goes something like this:</p>
<ol>
<li>When somebody has tailored themselves a jacket, they own that jacket. They are justified in controlling it because if they were not, somebody else could do something with it which would be bad for its owner, or somebody else could steal it which, again, would be bad for its owner as it would deprive them of a jacket. The same isn’t true for software. If someone copies your program, you still have your program. If someone modifies the copy, your program is still unmodified.</li>
<li>Hence no creator is justified, when their created thing is immaterial, in controlling that thing. The two are separate from one another. The creator is entitled to credit &amp; gratitude for their work but they are not – no matter how much time, skill or effort was involved in creating it – justified in controlling its spread or use.</li>
<li>Proprietary software is like private roads. Free software is like public roads. Either we could have a world where all roads are privately built &amp; funded by tolls, such that private actors would be incentivised to build roads because they profit directly from it; or we could have a world where all roads are publicly funded &amp; freely available to whoever wishes to use them. The latter is more beneficial to society &amp; less costly for it.</li>
<li>The utility of allowing free access to a program is greater than that of restricting access to it, which in fact causes harm, e.g. by preventing others from learning about it, by preventing them from building on it, by reducing innovation or by damaging social cohesion. Therefore, each person is not only justified but even obliged to spread programs freely, no matter who created them. Because this is what will maximise utility for those who use programs. As Stallman writes:</li>
</ol>
<blockquote>
<p>Suppose that both you and your neighbor would find it useful to run a certain program. In ethical concern for your neighbor, you should feel that proper handling of the situation will enable both of you to use it. A proposal to permit only one of you to use the program, while restraining the other, is divisive; neither you nor your neighbor should find it acceptable.</p>
<p>Signing a typical software license agreement means betraying your neighbor: “I promise to deprive my neighbor of this program so that I can have a copy for myself.” People who make such choices feel internal psychological pressure to justify them, by downgrading the importance of helping one’s neighbors – thus public spirit suffers. […]</p>
<p>Many users unconsciously recognize the wrong of refusing to share, so they decide to ignore the licenses and laws, and share programs anyway. But they often feel guilty about doing so. They know that they must break the laws in order to be good neighbors, but they still consider the laws authoritative, and they conclude that being a good neighbor (which they are) is naughty or shameful.</p>
</blockquote>
<p>I think it’s important to distinguish between two senses of ownership here. The first is that of exerting control over a thing. The second is that of benefitting somehow, in a privileged way, from a thing. Stallman argues that the first is not only wrong but even incoherent in a way, since there can be no owner of software in that way. From what I can tell, Stallman is fine with a programmer benefitting from the programs they write. He writes:</p>
<blockquote>
<p>We thus have a paradox: the developer of useful software is entitled to the support of the users, but any attempt to turn this moral obligation into a requirement destroys the basis for the obligation. A developer can either deserve a reward or demand it, but not both.</p>
<p>I believe that an ethical developer faced with this paradox must act so as to deserve the reward, but should also entreat the users for voluntary donations. Eventually the users will learn to support developers without coercion, just as they have learned to support public radio and television stations.</p>
</blockquote>
<p>However, he seems to think that it’s only fine to the extent that benefitting is divorced from exerting control, viz. when the programmer benefits passively but doesn’t restrict their program in order to do so. I think this is somewhat disingenuous because recognising that the programmer is justified in benefitting passively from a program they wrote means recognising that the program they wrote is “tethered” to them in some way. It means that their having written the program gives them some rights with regard to it (specifically, the right to benefit from it). But if <em>that’s</em> true, there is reason to believe also that their having written the program gives them some rights to control it, which Stallman denies.</p>
<p>That’s not normally how we think about these things. We usually think whoever comes up with a new thing <em>is</em> justified in acting to benefit from it. Imagine a nobody approaches a Hollywood studio executive with an idea for a movie. The person is rebuffed but the studio goes on to make the movie anyway: it is a huge box office success. The person sees none of the money. Doesn’t it seem like the studio executive wronged that person? Like they used that person as a mere means to further their own ends? Under Stallman’s view there’d be nothing wrong with this; under his view, the only thing that’d be wrong is if the person had then decided to sue the studio for damages.</p>
<p>But let’s say, for the sake of argument, that Stallman can smoothen out that friction. Let’s say that the scenario with the studio executive <a href="https://www.erichgrunewald.com/posts/tolstoy-in-ryazan/">seems wrong intuitively</a> but is not wrong upon deliberation. Stallman holds that it is wrong to exert control over a program once you’ve written it. But the GNU General Public License (which I like) does exactly this. It restricts people in the way that they use the licensed program. <a href="https://www.gnu.org/licenses/gpl-3.0.html">GPL-3</a>, the latest of them, does this in a variety of ways, by requiring the user to:</p>
<ul>
<li>include information about where to find the original software,</li>
<li>include information about how the software has been modified,</li>
<li>include installation instructions,</li>
<li>retain the GPL-3 license &amp;</li>
<li>retain the original copyright.</li>
</ul>
<p>All of these are ways in which the owner, who selected the license, exerts control over the program &amp; the user, who is bound by it. In other words, GPL-3 &amp; its ancestor licenses recognise the creator’s right to a measure of control over the thing they created even after it’s out there in the world. That makes some of Stallman’s arguments, such as the example of the neighbours that I quoted earlier, sound almost incoherent.<sup><a href="#fn2" id="fnref2">2</a></sup> Thus the world-serpent bites its own tail.</p>
<p>There’s now no room for defence left on any ground outside utilitarianism. Ownership of a program is only bad to the extent that it produces bad outcomes; &amp; it is also good to the extent that it produces good outcomes. But there’s nothing inherently bad or incoherent about it. Stallman does speak of consequences &amp; cost-benefit analyses. Personally, I am neither a consequentialist nor a utilitarian. I am a Kantian, I think. I am, however, willing to consider utilitarian arguments. But in my opinion the argument from pure utilitarianism is not nearly strong enough to support the sort of conclusions that Stallman draws, such as that one is obliged to share a program with those who want it against the wishes of its creator. And I think no full account of software can be made without really considering which duties we have towards those who create it.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>Sturluson, S. &amp; Brodeur, A. G. (1916). <em>The Prose Edda</em>. <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>The example of the neighbours is a little strange in that it only seems to consider the utility of the neighbours &amp; not that of the creator of the program. I think that’s because, in Stallman’s view, there’s no such thing as an owner, so the creator has no rights over the program. This muddles things up a bit because it’s no longer a universal utilitarian argument.</p>
<p>One could argue against the example of the neighbours on consequentialist grounds. For instance, it could deprive the creator of monetary compensation, or it could create risks for them, e.g. from the neighbour’s using the program for something immoral, causing the creator to become associated with that immoral act.</p>
<p>But it would be hard to think of this reading Stallman’s presentation of the example because it magics away the programmer who wrote the program &amp; human agency generally. Hence he writes that “proper handling of the situation will enable both of you to use it” &amp; that “[a] proposal to permit only one of you to use [it] is divisive”. The acting agents here are a “proper handling” &amp; a “proposal”. <a href="#fnref2">↩︎</a></p>
</li>
</ol>
</section>

                
                    
                    
            </div>
            
        </div></div>]]>
            </description>
            <link>https://www.erichgrunewald.com/posts/a-contradiction-at-the-heart-of-stallman%27s-free-software-argument/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25881273</guid>
            <pubDate>Sat, 23 Jan 2021 10:35:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unconditional Loops Are Unconditionally]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25881142">thread link</a>) | @lukastyrychtr
<br/>
January 23, 2021 | https://brson.github.io/2021/01/17/rust-unconditional-loops | <a href="https://web.archive.org/web/*/https://brson.github.io/2021/01/17/rust-unconditional-loops">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Here’s a thing I don’t see appreciated enough about Rust: <code>loop</code>.
I know I don’t think about it all that much,
but pretty much every time I use it I feel a bit of satisfaction.</p>

<p><code>loop</code> is just an unconditional loop:
it loops forever, or until you write <code>break</code>, or <code>return</code>.</p>

<p>Most languages don’t have it.</p>

<p>Instead, loop constructs usually have some kind of termination condition,
your <code>while</code> and <code>for</code> loops.
Apparently <em><a href="https://en.wikipedia.org/wiki/Sather">Sather</a></em> has an unconditional <code>loop</code> keyword like Rust.
I only know this because a programming language historian mentioned it <a href="https://github.com/rust-lang/rust/issues/1906#issuecomment-4240501">on the bug tracker</a>.</p>

<p>Why do I love <code>loop</code>?</p>

<p>Because it frees me from thinking about how to end a loop
before I’ve even started writing it.</p>

<p>Many problems are easy to recognize as ones that require a looping solution:
I quickly realize, “I have to do something multiple times”.</p>

<p>Sometimes that loop just involves iterating over a container of things,
one at a time.
That’s easy to recognize as a <code>for thing in things { }</code> situation.
Other loops have more complex conditions though.
Often when I’m solving a looping problem,
I will know one or some of the steps I intend to do in a loop,
but will not envision the complete solution ahead of time.</p>

<p>So I just write</p>



<p>and start coding what I do know needs to happen,
and work from there.</p>

<p>For some reason this feels great.</p>

<p>Once I have solved my looping problem,
there will be a <code>break</code> or <code>return</code> somewhere in there,
or multiple <code>break</code>s and/or <code>return</code>s.
Maybe it makes sense to convert it into a <code>while</code> loop,
maybe not. But there’s not a great need
for <code>while</code> when you’ve got <code>loop</code>, <code>break</code>, and <code>return</code>.
Do readers really need to know the loop termination condition
before reading what happens in the loop?
Or, in languages with <code>do { } while (…)</code> loops,
after the very end of the loop?
I don’t know,
but writing the termination condition
naturally wherever it “wants” to live in the loop
seems reasonable to me.
One does though need to be considerate of
their readers by keeping the loop body a readable length.</p>

<p>Anecdotally, a small project I’m working on right now
contains 2 instances of <code>loop</code>, 2 of <a href="https://doc.rust-lang.org/rust-by-example/flow_control/while_let.html"><code>while let</code></a>,
and 8 of <code>for … in</code>;
no standard <code>while</code> loops.
And I think the <code>loop</code> loops read better than if I had
tried to convert them to <code>while</code> loops.</p>

<p>Here’s one example:</p>

<div><div><pre><code><span>let</span> <span>(</span><span>tx</span><span>,</span> <span>rx</span><span>)</span> <span>=</span> <span>async_channel</span><span>::</span><span>unbounded</span><span>();</span>
<span>let</span> <span>handle</span> <span>=</span> <span>thread</span><span>::</span><span>spawn</span><span>(</span><span>move</span> <span>||</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>context</span> <span>=</span> <span>FsThreadContext</span><span>::</span><span>new</span><span>();</span>
    <span>loop</span> <span>{</span>
        <span>let</span> <span>msg</span> <span>=</span> <span>block_on</span><span>(</span><span>rx</span><span>.recv</span><span>())</span><span>.expect</span><span>(</span><span>"recv"</span><span>);</span>
        <span>match</span> <span>msg</span> <span>{</span>
            <span>Message</span><span>::</span><span>Run</span><span>(</span><span>f</span><span>)</span> <span>=&gt;</span> <span>{</span>
                <span>f</span><span>(</span><span>&amp;</span><span>mut</span> <span>context</span><span>);</span>
            <span>},</span>
            <span>Message</span><span>::</span><span>Shutdown</span><span>(</span><span>rsp_tx</span><span>)</span> <span>=&gt;</span> <span>{</span>
                <span>context</span><span>.shutdown</span><span>();</span>
                <span>rsp_tx</span><span>.send</span><span>(())</span><span>.expect</span><span>(</span><span>"send"</span><span>);</span>
                <span>break</span><span>;</span>
            <span>}</span>
        <span>}</span>
    <span>}</span>
<span>});</span>
</code></pre></div></div>

<p>Here’s the other:</p>

<div><div><pre><code><span>let</span> <span>mut</span> <span>header</span> <span>=</span> <span>String</span><span>::</span><span>new</span><span>();</span>
<span>let</span> <span>mut</span> <span>line</span> <span>=</span> <span>String</span><span>::</span><span>new</span><span>();</span>

<span>loop</span> <span>{</span>
    <span>line</span><span>.truncate</span><span>(</span><span>0</span><span>);</span>
    <span>io</span><span>.read_line</span><span>(</span><span>&amp;</span><span>mut</span> <span>line</span><span>)</span><span>?</span><span>;</span>

    <span>if</span> <span>line</span><span>.is_empty</span><span>()</span> <span>{</span>
        <span>return</span> <span>Err</span><span>(</span><span>anyhow!</span><span>(</span><span>"broken frame header"</span><span>));</span>
    <span>}</span>

    <span>let</span> <span>maybe_body_marker</span> <span>=</span> <span>&amp;</span><span>line</span><span>[</span><span>..</span><span>line</span><span>.len</span><span>()</span> <span>-</span> <span>1</span><span>];</span>
    <span>if</span> <span>maybe_body_marker</span> <span>==</span> <span>FRAME_BODY_MARKER</span> <span>{</span>
        <span>break</span><span>;</span>
    <span>}</span>

    <span>header</span><span>.push_str</span><span>(</span><span>&amp;</span><span>line</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>It’s common in C-like languages to write an unconditional loop
with <code>while (true) { }</code>.</p>

<p>I’m steeped enough in Rust that I don’t know if writing <code>while (true) { }</code>
brings others the same satisfaction as I get from <code>loop { }</code>,
but I suspect not: it looks and feels just like a tiny bit of a hack.
And if I go into writing a loop by first writing <code>while …</code>
then I am immediately presented with the question,
“while <em>what</em>?”,
and sometimes I just don’t want to think about that yet.</p>

<p>Besides <em>feeling</em> good,
there is <a href="https://github.com/rust-lang/rust/issues/1906">a technical reason that Rust has <code>loop</code></a>:
it helps analyze control flow.
With it, the compiler can trivially know that any code
after the loop is unreachable.
In Rust at least this is important for type checking.
This kind of analysis <em>is done</em> in other languages,
but by my recollection they sometimes actually
special case <code>while (true) { }</code> for this purpose.</p>

<p>Here’s an example of the differences in how Rust
treats <code>loop</code> vs. <code>while true</code> <a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=010dce12fdd4c0818322717e161a2f91">on the playground</a>.
Run it and check out the warning the compiler
issues; try to alter the example as suggested in the comments.</p>

<p>Bonus Rust trivia:
did you know that <code>loop</code> is an expression,
with the same type as its <code>break</code> statements,
and the result of <code>loop</code> can be <a href="https://doc.rust-lang.org/stable/reference/expressions/loop-expr.html#break-and-loop-values">assigned to a value</a>?</p>

<p>I did not!</p>

<p>The <a href="https://github.com/rust-lang/rust/issues/1906">issue on the bug tracker</a> appears
to be the only remains of the design discussion around <code>loop</code> in Rust,
though it is insightful to the designers’ original thinking.
The <a href="https://github.com/rust-lang/meeting-minutes/blob/master/weekly-meetings/2012-03-06.md">meeting minutes</a> where it was approved
just say there was consensus to add it.</p>

<div><div><pre><code><span>loop</span> <span>{</span>
    <span>println!</span><span>(</span><span>"Unconditional loops are unconditionally awesome"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

</div></div>]]>
            </description>
            <link>https://brson.github.io/2021/01/17/rust-unconditional-loops</link>
            <guid isPermaLink="false">hacker-news-small-sites-25881142</guid>
            <pubDate>Sat, 23 Jan 2021 10:06:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi as x2go “thin” client]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25881126">thread link</a>) | @indigodaddy
<br/>
January 23, 2021 | http://www.multi-seat.com/x2go/ | <a href="https://web.archive.org/web/*/http://www.multi-seat.com/x2go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://www.multi-seat.com/x2go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25881126</guid>
            <pubDate>Sat, 23 Jan 2021 10:03:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook Disabled My Account After I Criticized Them]]>
            </title>
            <description>
<![CDATA[
Score 317 | Comments 212 (<a href="https://news.ycombinator.com/item?id=25881112">thread link</a>) | @thereare5lights
<br/>
January 23, 2021 | https://lincoln.metacannon.net/2021/01/facebook-disabled-my-account-after-i-criticized-them.html | <a href="https://web.archive.org/web/*/https://lincoln.metacannon.net/2021/01/facebook-disabled-my-account-after-i-criticized-them.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p id="Audio"><i></i> Checking for recording ...</p><div id="Content"><p><img src="https://lincoln.metacannon.net/images/posts/censored-by-facebook.jpg" alt="Facebook Disabled My Account After I Criticized Them" title="Facebook Disabled My Account After I Criticized Them"></p> <p>Facebook unfriended me. Why? So far as I can tell, it’s because I’ve been using Facebook to advocate for decentralization of social media. And apparently the algorithm didn’t like that.</p> <p>This morning, sometime between 8:54am and 9:06am Mountain, Facebook disabled my account. Just after 8:54am, I copy-pasted the content of my latest Twitter post into a new post on Facebook. At 9:06am, a friend received a Facebook notification indicating that he needed to update his trusted contacts because I was no longer available. Here’s the exact text and link that I posted to both Twitter and Facebook:</p> <blockquote> <p>“Now is the time to build, promote, and adopt decentralized social networks. The future of humanity depends on it. Ben Goertzel gets it right. Read his explanation. <a href="https://www.coindesk.com/decentralized-social-networks-next-big-blockchain-opportunity">https://www.coindesk.com/decentralized-social-networks-next-big-blockchain-opportunity</a>” (<a href="https://twitter.com/LincolnCannon/status/1352645833569669121">22 January 2021</a>)</p> </blockquote> <blockquote><p lang="en" dir="ltr">Now is the time to build, promote, and adopt decentralized social networks. The future of humanity depends on it. Ben Goertzel gets it right. Read his explanation. <a href="https://t.co/3DMsYiQdLa">https://t.co/3DMsYiQdLa</a></p>— Lincoln Cannon (@LincolnCannon) <a href="https://twitter.com/LincolnCannon/status/1352645833569669121?ref_src=twsrc%5Etfw">January 22, 2021</a></blockquote>  <p>When my friend’s notification came to my attention, I attempted to access Facebook. I was able to login. But I wasn’t able to see anything except the following message:</p> <blockquote> <p>“Your Account Has Been Disabled. For more information please visit the Help Center. Your account was disabled on Jan 22, 2021. If you think your account was disabled by mistake you can submit more information via the Help Center for up to 30 days after your account was disabled. After that, your account will be permanently disabled and you will no longer be able to request a review.”</p> </blockquote> <figure><span><img src="https://lincoln.metacannon.net/images/posts/facebook-screen-shot-2021-01-22-at-11.04.16-am.jpg" alt="Facebook Screen Shot on 22 January 2021 at 11:04am Mountain"></span><figcaption>Facebook Screen Shot on 22 January 2021 at 11:04am Mountain</figcaption></figure> <p>I clicked on a link at the end of the message. It took me to the Help Center. There I found a link to request a review. Clicking on that link took me to a form which requested my full name and photo ID.</p> <p>I filled out the form, providing my name and a JPG of my government issued ID. Then I submitted the form. In response, I received the following message:</p> <blockquote> <p>“We Cannot Review the Decision to Disable Your Account. Your Facebook account was disabled because it did not follow our Community Standards. This decision can’t be reversed.”</p> </blockquote> <figure><span><img src="https://lincoln.metacannon.net/images/posts/facebook-screen-shot-2021-01-22-at-9.26.23-am.jpg" alt="Facebook Screen Shot on 22 January 2021 at 9:26am Mountain"></span><figcaption>Facebook Screen Shot on 22 January 2021 at 9:26am Mountain</figcaption></figure> <h2 id="why-facebook-disabled-my-account">Why Facebook Disabled My Account</h2> <p>I don’t know for sure why Facebook disabled my account. I didn’t receive an explanation. There was no reference to particular Facebook Community Standards that I might have broken. There was no indication of how I might have been violating Facebook’s terms of service.</p> <p>Moreover, I have never received a warning from Facebook. And I didn’t receive a warning today. They provided no information beyond what I’ve quoted above.</p> <p>I’ve never used Facebook or any other social media to advocate violence, political or otherwise. And I’m a political centrist. In fact, during the political controversies of 2020, I repeatedly insisted on civility to such an extent that it frustrated some of my more partisan friends. So we can’t plausibly look for an explanation there.</p> <p>We could imagine a conspiracy among people who dislike my religious views. There’s plenty of <a href="https://lincoln.metacannon.net/2018/09/this-post-is-brought-to-you-by.html">strong anti-Mormon and anti-Transhumanist sentiment</a> out there. Perhaps, banding together, a group of people reported or otherwise flagged my content on Facebook as inappropriate. But this seems a bit paranoid to me.</p> <p>I don’t think the cause was the link that I shared, in itself. Quite a few other people have shared that link on Facebook. In fact, at this moment, their API indicates that <a href="https://developers.facebook.com/tools/debug/?q=https%3A%2F%2Fwww.coindesk.com%2Fdecentralized-social-networks-next-big-blockchain-opportunity">the link has received at least 88 likes, shares, and comments across Facebook</a>. And that number has been increasing throughout the day without Facebook banning others for it, to the best of my knowledge.</p> <p>So I think the cause must have been the comment itself. Or, more generally, it may have been an emerging pattern in the comments of my posts. For a long time, I have advocated replacing Facebook with <a href="https://lincoln.metacannon.net/2015/05/the-reputation-web.html">decentralized social networks</a>. And current events have motivated me to increase the frequency of that advocacy.</p> <p>Several times over the last week or two, I have promoted decentralization in posts to both Facebook and Twitter. The content and links of the original posts were identical on the two platforms. So you can see them on my Twitter account. For easy reference, here are copies of my most recent cross-posts in reverse chronological order (as ordered on Twitter and previously on Facebook):</p> <ul> <li> <p>“Congratulations to President Biden and Vice-President Harris. May your term in office be peaceful and prosperous, for the United States of America and for our world.” (<a href="https://twitter.com/LincolnCannon/status/1351953891655520258">20 January 2021</a>)</p> </li> <li> <p>“The debate between capitalism and socialism is often framed as a choice between large corporations and large government. This framing is cultivated by political and economic elites. The truth is that there’s an alternative to both. Limit both. Decentralize ALL power.” (<a href="https://twitter.com/LincolnCannon/status/1351914808753307649">20 January 2021</a>)</p> </li> <li> <p>“In a recent discussion with the Christian Transhumanist Association, I presented and answered questions about the New God Argument. Here’s a recording. <a href="https://www.youtube.com/watch?v=kCUrUnZavGk&amp;list=PL9Yc4oMKukRkMnBAkXNv9JWApl9D4Qe8j">https://www.youtube.com/watch?v=kCUrUnZavGk&amp;list=PL9Yc4oMKukRkMnBAkXNv9JWApl9D4Qe8j</a>” (<a href="https://twitter.com/LincolnCannon/status/1351384453231230976">18 January 2021</a>)</p> </li> <li> <p>“Decentralization is a practical necessity. For Christians, it’s also a theological mandate. Essential to the Gospel is a transformative discipleship, wherein we each participate in the role of Christ and become joint heirs in the glory of God. Divine creation IS decentralization.” (<a href="https://twitter.com/LincolnCannon/status/1350943723908198406">17 January 2021</a>)</p> </li> <li> <p>“If God ensures the right spirit is associated with the right body during human-mediated procreation, why wouldn’t God ensure the same for human-mediated resurrection? If you build it, they will come. If they don’t come, you didn’t build it right. Seems straightforward to me.” (<a href="https://twitter.com/LincolnCannon/status/1350259207107317760">15 January 2021</a>)</p> </li> <li> <p>“‘The long view is a thriving decentralized marketplace, fueled by personal empowerment and collaboration.’ <a href="https://www.nytimes.com/2021/01/10/technology/tim-berners-lee-privacy-internet.html">https://www.nytimes.com/2021/01/10/technology/tim-berners-lee-privacy-internet.html</a>” (<a href="https://twitter.com/LincolnCannon/status/1348662980175564802">11 January 2021</a>)</p> </li> <li> <p>“Let’s say you have enough spare cash to buy a gun, donate to a charity, or invest in some Bitcoin. What do you do and why? What does your choice say about your vision of the future? How does your choice impinge on the creation of that future?” (<a href="https://twitter.com/LincolnCannon/status/1348082874239524865">9 January 2021</a>)</p> </li> <li> <p>“Trump was banned from Facebook and Twitter. That may or may not be comparatively fair. But if it constitutes an infringement on freedom of speech then we’ve given far too much power to Facebook and Twitter. Centrally controlled freedom of speech should terrify us.” (<a href="https://twitter.com/LincolnCannon/status/1347931805370863617">9 January 2021</a>)</p> </li> </ul> <p>In addition, on 13 January 2021, I shared to Facebook some thoughts in support of a tweet from Twitter CEO Jack Dorsey. I can no longer quote the text from my Facebook post because it wasn’t a cross-post like the others. But it essentially affirmed Jack Dorsey’s interest in supporting decentralized social media, as he expressed in a recent tweet:</p> <blockquote><p lang="en" dir="ltr">We are trying to do our part by funding an initiative around an open decentralized standard for social media. Our goal is to be a client of that standard for the public conversation layer of the internet. We call it <a href="https://twitter.com/bluesky?ref_src=twsrc%5Etfw">@bluesky</a>: <a href="https://t.co/51or6OuNNv">https://t.co/51or6OuNNv</a></p>— jack (@jack) <a href="https://twitter.com/jack/status/1349510780043988992?ref_src=twsrc%5Etfw">January 14, 2021</a></blockquote> <p>As you can see, almost all of my recent social media posts have been related to decentralization. Even the ones that aren’t obviously related to decentralization are still implicitly or indirectly related to decentralization. For example, decentralization is an important aspect of the <a href="https://new-god-argument.com/compassion-argument.html">Compassion Argument of the New God Argument</a>. And a theology that would include <a href="https://lincoln.metacannon.net/2019/04/how-to-raise-dead.html">human action toward resurrection</a> as an expression of God’s work is a decentralized theology.</p> <p>A machine learning algorithm would be capable of identifying accounts that publish posts with a pattern of negative sentiment toward centralized social media. The algorithm could also assign a score to the degree of negative sentiment. And Facebook could use that score to trigger automatic deactivation of accounts that surpass a relatively high score. None of this would require direct human intervention.</p> <p>Again, I don’t know for sure why Facebook deactivated my account. But based on what I know, I think the best explanation is that Facebook now implicitly hates decentralization. I suspect that one of its algorithms is checking for accounts that encourage use of alternative social networks. And it caught my account in its automated net.</p> <p>As an aside, perhaps some Facebook managers and engineers originally intended the algorithm to catch accounts that encourage use of social networks that focus on controversial politics. That seems possible. I’ve neither advocated for nor participated in those social networks. But I can see how my posts might have some syntactical commonalities with posts that advocate for those social networks.</p> <h2 id="why-facebook-doesnt-ban-everyone">Why Facebook Doesn’t Ban Everyone</h2> <p>Aren’t other people advocating for decentralized social networks without being banned? Maybe so. But the algorithm may have identified my account as a particularly useful target. Here’s why.</p> <p>Social network theory categorizes people according to how they function in networks. Some people are influencers within groups of similar persons. Some people are followers within groups. And some people are connectors between groups.</p> <p>Connectors facilitate transmission of ideas between dissimilar groups. Transmission of ideas can be good, promoting adaptability over time and creation of new value. But transmission of ideas can also be bad insofar as they undermine the coherence and survival of the group or system. All groups and systems, even the most creative, require a balance.</p> <p>As it turns out, my social connections are unusually diverse. For example, I have many politically progressive and many politically conservative connections. I have many religious, secular, and atheist connections. And these connections include many influencers in a wide variety of geographies around the world.</p> <p>I’m a connector. I …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lincoln.metacannon.net/2021/01/facebook-disabled-my-account-after-i-criticized-them.html">https://lincoln.metacannon.net/2021/01/facebook-disabled-my-account-after-i-criticized-them.html</a></em></p>]]>
            </description>
            <link>https://lincoln.metacannon.net/2021/01/facebook-disabled-my-account-after-i-criticized-them.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25881112</guid>
            <pubDate>Sat, 23 Jan 2021 10:00:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin Core Lead Maintainer Steps Back, Encourages Decentralization]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 198 (<a href="https://news.ycombinator.com/item?id=25880727">thread link</a>) | @runeks
<br/>
January 23, 2021 | https://laanwj.github.io/2021/01/21/decentralize.html | <a href="https://web.archive.org/web/*/https://laanwj.github.io/2021/01/21/decentralize.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Recent events have made me reflect on a few things in my life I was already thinking about for a while. Also, responses on social media have made me realize that people have <em>strange</em> expectations from me, and what my role in the Bitcoin Core project is.</p>

<h2 id="growth">growth</h2>

<p>Bitcoin has grown a lot since I started contributing to it in 2011. Some arrangements that were acceptable for a small scale FOSS project are no longer so for one runing a 600 billion dollar system. Market cap is famously deceptive, but my point is not about specific numbers here.</p>

<p>One thing is clear: this is a serious project now, and we need to start taking decentralization seriously.</p>

<h2 id="moving-on">moving on</h2>

<p>I realize I am myself somewhat of a centralized bottleneck. And although I find Bitcoin an extremely interesting project and believe it’s one of the most important things happening at the moment, I also have many other interests. It’s also particularly stressful and I don’t want it, nor the bizarre spats in the social media around it, to start defining me as a person.</p>

<h2 id="spreading-out">spreading out</h2>

<p>I will start by delegating my own tasks, and decreasing my involvement. I do not intend to stop contributing to Bitcoin, or even to the Bitcoin Core project, but I would like to remove myself from the critical path and take (even more) of a background role.</p>

<p>Note that we had a nice growth in development activity, and that maintenance of the code itself has already been spread over multiple people for a while. I’m not the most active maintainer. Looking at the number of git merges</p>

<div><div><pre><code>bitcoin<span>$ </span>git log <span>--pretty</span><span>=</span><span>"format:%cn"</span> <span>--merges</span> <span>--since</span><span>=</span>2020-01-01 | <span>sort</span>| <span>uniq</span> <span>-c</span>
    313 fanquake
     51 Jonas Schnelli
    727 MarcoFalke
      7 Pieter Wuille
     65 Samuel Dobson
    363 Wladimir J. van der Laan
</code></pre></div></div>

<p>Only about 24% of the merges were done by me, last year.</p>

<h2 id="plans">plans</h2>

<p>But there’s plenty of things left to figure out, from the top of my head:</p>

<ul>
  <li>
    <p>Decentralize distribution.</p>

    <ul>
      <li>
        <p>In the short run, transfer bitcoincore.org to an organization instead of private ownership. Reduce the “bus factor”.</p>
      </li>
      <li>
        <p>I think it would be good if some other organizations set up mirrors, so there is less incentive to try to take bitcoincore.org down.</p>
      </li>
      <li>
        <p>In the long run, move away from a website for code distribution completely. No matter who owns it, a website on the clearnet can be shut down with the press of a button, and it seems that the global internet is gearing up to make censorship increasingly easy. We need a decentralized web. For us, one option would be IPFS, which is starting to catch on. For the binaries themselves there’s already the option of downloading through torrents.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Decentralize the release process, and release signing.</p>

    <ul>
      <li>
        <p>Delegate more parts of the release process. Other maintainers should be able to do a release without my involvement.</p>
      </li>
      <li>
        <p>Rename the GPG key used to sign <code>SHA256SUMS.asc</code> to “Bitcoin Core release signing key”, instead of having it in my personal title. Make some construct so that N of M (minimally) trusted gitian signers doing a succesful build automatically results in a signed distribution.</p>
      </li>
      <li>
        <p>Same for the native code signing for Windows and MacOS.</p>
      </li>
      <li>
        <p>Even better in the long run would be to split up the keys, e.g. though RSA threshold signing, so that the whole process is geographically distributed.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Decentralize the development hub.</p>

    <ul>
      <li>It’s not clear whether github can be trusted to act in our interest in the long run. Although issues and PRs are backed up through the API, having to move somewhere else could give significant interruption in development. And hopping from provider to provider would be awful—ideally the whole thing would not rely on a central server <em>at all</em>. For this I’ve been watching the <a href="https://radicle.xyz/">radicle</a> project, a P2P distributed code collaboration platform. It’s not quite there yet, but seems promising.</li>
    </ul>
  </li>
</ul>

<p>Bitcoin is quite different in some of the requirements here from other FOSS projects, so we’ll have to develop some tools as we go. We could also, definitely, use some help here.</p>

<p>Some smaller things to consider:</p>

<ul>
  <li>
    <p>Find someone else who wants to do the IRC meeting chair instead of me. Or maybe rotate it between multiple people.</p>
  </li>
  <li>
    <p>Release (and release candidate) mails to the <code>bitcoin-dev</code> and <code>bitcoin-core-dev</code> lists will no longer be necessarily signed and sent by me.</p>
  </li>
  <li>
    <p>There’s some development specific tooling hosted by me (e.g. the PR notification bots on IRC and mastodon). As they are non-critical and only little time goes into maintaining them, I’m fine with this for now.</p>
  </li>
</ul>

<p>As for decentralizing Bitcoin’s node software itself:</p>

<ul>
  <li>Carl Dong’s <code>libbitcoin_kernel</code> work. Bitcoin Core is a large monolithic project which includes the consensus code, which is much more critical than the other parts. The kernel would be an isolated part with well-defined interface, and at some point, its own review flow for changes. The difference with previous <code>libbitcoin_consensus</code> plans is that the kernel is stateful: it includes UTXO management and validation. It however does not include P2P, mempool policy, wallet, GUI, and RPC code. It could be re-used in different clients, to have more diversity in clients, but without the risks of a deviating consensus implementation.</li>
</ul>

<p>Over the course of 2021 this will be my focus with regard to Bitcoin Core.</p>

  </div></div>]]>
            </description>
            <link>https://laanwj.github.io/2021/01/21/decentralize.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25880727</guid>
            <pubDate>Sat, 23 Jan 2021 08:45:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WhatsApp facing up to €50M privacy fine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25880609">thread link</a>) | @gr2zr4
<br/>
January 23, 2021 | https://www.politico.eu/article/whatsapp-privacy-fine-data-protection-europe-50-million/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/whatsapp-privacy-fine-data-protection-europe-50-million/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									<p>Facebook-owned messaging app WhatsApp could be fined up to €50 million over violations of the European Union's data protection rules, according to three people with direct knowledge of the procedure who spoke with POLITICO.</p>
<p>The preliminary penalty — the figure is now under consultation with the bloc's other data protection agencies — would be one of the largest-ever fines under the EU's General Data Protection Regulation, a set of privacy rules that came into force in 2018. </p>
<p>As part of Ireland's draft findings, the internet messenger may face a fine of between €30 million and €50 million for not living up to transparency requirements under Europe's privacy regime. Whatsapp could also be required to change how it handles its users' data, as the case relates to how the messenger may have failed to properly inform its EU users about how it would share their data with Facebook.</p>

<p>France's privacy authority <a href="https://www.cnil.fr/en/cnils-restricted-committee-imposes-financial-penalty-50-million-euros-against-google-llc" target="_blank">has fined</a> Google €50 million for separate privacy violations, while Ireland's Data Protection Commission, which has regulatory authority over Facebook, recently <a href="https://www.politico.eu/article/irish-data-regulator-fines-twitter-e450000/">issued</a> a €450,000 penalty against Twitter. That represented its first levy against any Silicon Valley company, many of which fall under Dublin's jurisdiction because these firms are legally domiciled in Ireland, mostly for tax reasons.</p>
<p>The multi-million euro draft WhatsApp fine is an initial proposal from Dublin, and has been opened up to other European data protection agencies for their feedback. A final decision on how big the fine should be — and what other remedies WhatsApp should agree to — is not expected until later in the year.</p>
<p>A spokesman for Ireland's Data Protection Commissioner declined to comment. A spokesman for WhatsApp said the company was awaiting the final privacy decision.</p>
<p>In November, Facebook&nbsp;<a href="https://www.politico.eu/?p=1521035">earmarked €77.5 million&nbsp;for a likely privacy fine against its messaging service WhatsApp,&nbsp;</a>which, unlike Instagram, is a separate legal entity in Ireland and therefore has its own set of financial records. The Irish data protection agency is conducting a separate investigation into whether WhatsApp can legally share its users' data with Facebook's other digital services, among other privacy-related concerns.</p>
<p>The draft penalty against WhatsApp, which Ireland <a href="https://www.politico.eu/?p=1577539">submitted</a> to other EU agencies for review just before Christmas, comes as the messenger faces a global backlash over planned updates to its terms and conditions. Those include&nbsp;clarifying to its billions of users how their data is shared more widely with Facebook's other services.</p>
<p>Those changes will not affect WhatsApp European operations, but people across the bloc and elsewhere still have flocked to rivals like Signal because of privacy fears. On January 15, the messenger <a href="https://blog.whatsapp.com/giving-more-time-for-our-recent-update" target="_blank">said</a> it was delaying the upcoming privacy changes, in part because of the confusion generated by the proposed overhaul.</p>

<p>Johannes Caspar, Hamburg's privacy regulator who filed objections to a previous Irish decision against Twitter, told POLITICO earlier this week that he<a href="https://www.politico.eu/?p=1579886"> had not ruled out </a>doing the same in the WhatsApp case. </p>
<p>"WhatsApp has an enormous amount of users," he said. "It must be clear that the consent mechanism they use must be lawful and that consent is informed and freely given by the users."</p>
								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/whatsapp-privacy-fine-data-protection-europe-50-million/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25880609</guid>
            <pubDate>Sat, 23 Jan 2021 08:15:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NixOS Review: Pros and Cons]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25880112">thread link</a>) | @zdw
<br/>
January 22, 2021 | https://dataswamp.org/~solene/2021-01-22-nixos-personal-review.html | <a href="https://web.archive.org/web/*/https://dataswamp.org/~solene/2021-01-22-nixos-personal-review.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article id="20210122">
  <header>
  
    
    <p>Written by <em>Solène</em>, on 22 January 2021.<br>Tags: 
<span><a href="https://dataswamp.org/~solene/tag-nixos.html">#nixos</a></span>


<span><a href="https://dataswamp.org/~solene/tag-linux.html">#linux</a></span>

</p>
    
  </header>
  <p>Hello, in this article I would like to share my thoughts about the NixOS Linux distribution.  I've been using it daily for more than six months as my main workstation at work and on some computer at home too.  I also made modest contributions to the git repository. 
</p>
<p><a href="https://nixos.org/">NixOS official website</a></p>
<h2> Introduction</h2>
<p>NixOS is a Linux distribution built around Nix tool.  I'll try to explain quickly what Nix is but if you want more accurate explanations I recommend visiting the project website.  Nix is the package manager of the system, Nix could be used on any Linux distribution on top of the distribution package manager.  NixOS is built from top to bottom from Nix.
</p>
<p>This makes NixOS a system entirely different than what one can expect from a regular Linux/Unix system (at the exception of Guix sharing the same idea with a different implementation).  NixOS system configuration is stateless, most of the system is in read-only and most of paths you know doesn't exist.  The directory /bin/sh only contains "sh" which is a symlink.
</p>
<p>The whole system configuration: fstab, packages, users, services, crontab, firewall... is configured from a global configuration file that defines the state of the system.
</p>
<p>An example of my configuration file to enable graphical interface with Mate as a desktop and a french keyboard layout.
</p>
<pre><code>services.xserver.enable = true;
services.xserver.layout = "fr";
services.xserver.libinput.enable = true;
services.xserver.displayManager.lightdm.enable = true;
services.xserver.desktopManager.mate.enable = true;
</code></pre>
<p>I could add the following lines into the configuration to add auto login into my graphical session.
</p>
<pre><code>services.xserver.displayManager.autoLogin.enable = true;
services.xserver.displayManager.autoLogin.user = "solene";
</code></pre>
<h2> Pros</h2>
<p>There are a lot of pros.  The system is really easy to setup, installing a system (for a reinstall or replicate an installation) is very easy, you only need to get the configuration.nix file from the other/previous system.  Everything is very fast to setup, it's often only a few lines to add to the configuration.
</p>
<p>Every time the system is rebuilt from the configuration file, a new grub entry is made so at boot you can choose on which environment you want to boot.  This make upgrades or tries very easy to rollback and safe.
</p>
<p>Documentation! The NixOS documentation is very nice and is part of the code.  There is a special man page "configuration.nix" in the system that contains all variables you can define, what values to expect, what is the default and what it's doing.  You can literally search for "steam", "mediawiki" or "luks" to get information to configure your system.
</p>
<p><a href="https://nixos.org/learn.html">All the documentation</a></p>
<p>Builds are reproducible, I don't consider it a huge advantage but it's nice to have it.  This allow to challenge a package mirror by building packages locally and verifying they provide the exact same package on the mirror.
</p>
<p>It has a lot of packages.  I think the NixOS team is pretty happy to share their statistics because, if I got it right, Nixpkgs is the biggest and up to date repository alive.
</p>
<p><a href="https://search.nixos.org/packages">Search for a package</a></p>
<h2> Cons</h2>
<p>When you download a pre compiled Linux program that isn't statically built, it's a huge pain to make it work on NixOS.  The binary will expect some paths to exist at usual places but they won't exist on NixOS.  There are some tricks to get them work but it's not always easy.  If the program you want isn't in the packages, it may not be easy to use it.  Flatpak can help to get some programs if they are not in the packages though.
</p>
<p><a href="https://nixos.wiki/wiki/Packaging/Binaries">Running binaries</a></p>
<p>It takes disk space, some libraries can exist at the same time with small compilation differences.  A program can exist with different version at the same time because of previous builds still available for boot in grub, if you forget to clean them it takes a lot of memory.
</p>
<p>The whole system (especially for graphical environments) may not feel as polished as more mainstream distributions putting a lot of efforts into branding and customization.  NixOS will only install everything and you will have a quite raw environment that you will have to configure.  It's not a real cons but in comparison to other desktop oriented distributions, NixOS may not look as good out of the box.
</p>
<h2> Conclusion</h2>
<p>NixOS is an awesome piece of software.  It works very well and I never had any reliability issue with it.  Some services like xrdp are usually quite complex to setup but it worked out of the box here for me.
</p>
<p>I see it as a huge Lego© box with which you can automate the building of the super system you want, given you have the schematics of its parts.  Once you need a block you don't have in your recipes list, you will have a hard time.
</p>
<p>I really classify it into its own category, in comparison to Linux/BSD distributions and Windows, there is the NixOS / Guix category with those stateless systems for which the configuration is their code.
</p>

</article>
</div></div>]]>
            </description>
            <link>https://dataswamp.org/~solene/2021-01-22-nixos-personal-review.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25880112</guid>
            <pubDate>Sat, 23 Jan 2021 06:16:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Whiter white using Apple devices' HDR capabilities]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25879844">thread link</a>) | @thesephist
<br/>
January 22, 2021 | https://kidi.ng/wanna-see-a-whiter-white/ | <a href="https://web.archive.org/web/*/https://kidi.ng/wanna-see-a-whiter-white/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p id="tester">White.</p><div id="info">
    <p>
      Set the display brightness to less than 100%.<br>
      Turn off <a href="https://support.apple.com/en-us/HT205234">Low Power Mode on iOS.</a>
    </p>
    <p>
      The RGB color values of <i>the message</i> and <i>the background</i> are the same.<br>
      Take a screenshot then compare them in an image editor.
    </p>
    <p>
      Your experience may vary depending on browser, OS version, display, everything.<br>
      Tests so far seem to indicate this only works on <b>the Apple platforms.</b>
    </p>
    <details>
        <summary>Test Results</summary>
        <p>Works with <a href="https://support.apple.com/en-us/HT210980">HDR-capable Macs</a> and iPhones:</p>
        <ul>
          <li>Safari / Chrome / Edge, macOS Big Sur, MacBook Air (M1, 2020)</li>
          <li>Safari, macOS Big Sur, MacBook Pro (15-inch, 2018)</li>
          <li>Safari, macOS Big Sur, MacBook Pro (16-inch, 2019)</li>
          <li>Safari, macOS Big Sur, iMac (Retina 5K, 27-inch, 2020)</li>
          <li>iOS 14, iPhone X</li>
          <li>iOS 14, iPhone XS / XR</li>
          <li>iOS 14, iPhone 12 / iPhone 12 Pro</li>
          <li>iOS 14, iPad Pro 11-inch (2nd generation)</li>
        </ul>
        <p>Works with SDR Macs with Blink browsers:</p>
        <ul>
          <li>Chrome / Edge, macOS Big Sur, iMac (Retina 5K, 27-inch, Late 2015)</li>
        </ul>
        <p>Does not work with:</p>
        <ul>
          <li>Firefox (Does not support <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1539685">HDR</a>)</li>
          <li>webOS TV (Does not support <a href="http://webostv.developer.lge.com/discover/specifications/web-engine/">backdrop-filter</a>)</li>
          <li>Chrome, Google Pixel 4a</li>
          <li>Edge, Samsung Galaxy S10</li>
          <li>PlayStation 4</li>
          <li>Xbox Series X (Might crash the console)</li>
          <li>Chrome, Windows 10, LG 27UK600 / LG 34WL600</li>
        </ul>
      </details>
    
    <details>
        <summary>How does this work?</summary>
        <p>
          There are hidden HDR videos playing at the corners of this page. When a HDR-capable browser encounters one, it switches to HDR mode. For some reason, CSS backdrop-filter + brightness &gt;100% combo seems to behave like HDR—reaching beyond the user-controlled display brightness, up to the maximum HDR brightness—while the everything in between follow along. At least that's the overall idea, but I still don't know exactly why it works; especially why with those two CSS properties.
        </p>
        <p>
          Once the system switches to HDR mode, it seems to affect the whole display. That says, as long as you can trigger HDR mode by any means—simply playing an HDR video on Movist, for example—the CSS trick works on Safari / Chrome / Edge with HDR-capable / SDR devices. This indicates this bug/feature is mostly tied to <a href="https://developer.apple.com/documentation/metal/drawable_objects/displaying_hdr_content_in_a_metal_layer">the EDR system.</a>
        </p>
      </details>
    
    <p>
      Project on <a href="https://github.com/kiding/wanna-see-a-whiter-white">GitHub</a>. Short URL <code><a href="https://fff.kidi.ng/">fff.kidi.ng</a></code>.<br>
      Created by <a href="https://kidi.ng/">kiding</a>. Inspired by <a href="https://xenosium.com/">zvuc</a>. 
    </p>
  </div></div>]]>
            </description>
            <link>https://kidi.ng/wanna-see-a-whiter-white/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25879844</guid>
            <pubDate>Sat, 23 Jan 2021 05:07:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to Time Representation, Serialization and Management in Software]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25879660">thread link</a>) | @nwotnagrom
<br/>
January 22, 2021 | https://mirkocaserta.com/posts/2013/04/an-introduction-to-time-representation-serialization-and-management-in-software/ | <a href="https://web.archive.org/web/*/https://mirkocaserta.com/posts/2013/04/an-introduction-to-time-representation-serialization-and-management-in-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>Most issues in software development usually arise from poor,
inconsistent knowledge of the domain at hand. A topic apparently as
simple as time representation, serialization and management can easily
cause a number of problems both to the neophyte and to the experienced
programmer.</p>
<p>In this post, we’ll see that there’s no need to be a
<a href="http://en.wikipedia.org/wiki/Time_Lord">Time Lord</a> to grasp the
very simple few concepts needed not to incur into time management hell.</p>
<p><img src="https://mirkocaserta.com/images/posts/time.jpg" alt="Time doesn’t exist. Clocks exist."></p>
<h2 id="representation">Representation</h2>
<p>A question as simple as <em>“What time is it?"</em> assumes a number of
contextual subleties that are obvious to the human brain, but become
absolute nonsense for a computer.</p>
<p>For instance, if you were asking to me what time is it right now, I
might say: <em>“It’s 3:39”</em> and, if you were a colleague in my office,
that’d be enough information to infer that it’s 3:39pm CEST. That’s
because you would already be in possession of some bits of important
contextual information such as</p>
<ul>
<li>it’s an afternoon because we’ve already had lunch</li>
<li>we’re in Rome, therefore our timezone is Central European Time (CET)
or Central European Summer Time (CEST)</li>
<li>we’ve switched to daylight savings time a few weeks earlier, so the
current timezone must be Central European Summer Time</li>
</ul>
<p><em>3:39</em> only happens to be a convenient representation of time as long as
we’re in possession of the contextual bits.  In order to represent time
in an universal way, you should have an idea what
<a href="http://en.wikipedia.org/wiki/Coordinated_Universal_Time">UTC</a> and
<a href="http://en.wikipedia.org/wiki/Time_zone">timezones</a> are.</p>
<p>Now, suppose I have to schedule a skype chat with a fellow software
developer in the US. I could write him an email and say something along
the lines of <em>“see you on 2/3”</em>. In Italy, that would be the second day
in the month of march, but to an US person, that would be the third day
in the month of february. As you can see, how our chat is never going to
happen.</p>
<p>These are only a few examples of the kind of issues that might arise
when representing date and time information. Luckily enough, there is a
solution to the representation conundrums, namely the
<a href="http://en.wikipedia.org/wiki/ISO_8601">ISO 8601</a> standard.</p>
<p>Just to give you an example, in ISO 8601, <code>1994-11-05T08:15:30-05:00</code>
corresponds to November 5, 1994, 8:15:30 am, US Eastern Standard Time.
<code>1994-11-05T13:15:30Z</code> corresponds to the same instant (the <code>Z</code> stands
for UTC). Same instant, different representations.</p>
<p>The ISO 8601 standard also has the nice side effect of providing natural
sorting in systems that use lexicographical order (such as filesystems)
because information is organized from most to least significant, i.e.
year, month, day, hour, minute, second, fraction of a second.</p>
<p>Even if you’re only dealing with local times in your software, you
should know that, unless you also display the time zone, you can never
be sure of the time. I cannot remember how many times a developer has
asked me to <em>fix the time</em> on the server, only to discover that his
software was printing time in UTC.</p>
<p>At display time, it is okay to deal with partial representation of time
because the user experience requires so. Just make sure, when debugging,
to print out the whole set of information, including the time zone,
otherwise you can never be sure what you’re looking at is what you
actually think it is.</p>
<p>Although a given moment in time is immutable, there is an arbitrary
number of ways to express it. And we’ve not even talked about the Julian or
Indian calendars or stuff like expressing durations!</p>
<p>Let me summarize a few key points to bring home so far:</p>
<ul>
<li>get to know <a href="http://en.wikipedia.org/wiki/Time_zone">time zones</a> and
<a href="http://en.wikipedia.org/wiki/Coordinated_Universal_Time">UTC</a></li>
<li><a href="http://en.wikipedia.org/wiki/ISO_8601">ISO 8601</a> is your friend</li>
<li>always print the time zone while debugging</li>
</ul>
<p><img src="https://mirkocaserta.com/images/posts/bttf-clock.png" alt="Back to the future clock"></p>
<h2 id="serialization">Serialization</h2>
<p>Speaking of software, serialization is a process where you take an object’s
status and spell it out in such a way that it can be later entirely rebuilt,
exactly like the original, by using the spelt out (serialized) information.
Think of an xml or json file:</p>
<div><pre><code data-lang="json">{
  <span>"person"</span>: {
    <span>"name"</span>: <span>"Mirko"</span>,
    <span>"surname"</span>: <span>"Caserta"</span>,
    <span>"class"</span>: <span>"nerd"</span>
  }
}
</code></pre></div><p>This is the serialized form of a peculiar imaginary person class instance.</p>
<p>In the binary world of computers, time is usually serialized and stored
by using the <a href="http://en.wikipedia.org/wiki/Unix_time">Unix time</a>
convention. As I’m writing this, my Unix time is <code>1366191727 UTC</code>. That
is: <code>1366191727</code> seconds have passed since January 1st, 1970 at 00:00
UTC. Isn’t that a pretty clever, consistent and compact way of
representing a plethora of information, such as <code>April 17 2013 @ 11:42:07am CEST</code>?</p>
<p>Unix time is only another arbitrary representation of a given moment in time,
although a not very human readable one. But you can take that number, write it
on a piece of paper, stick it onto a carrier pigeon, and your recipient would
be able to decipher your vital message by simply turning to the Internet and
visiting a site such as <a href="http://www.unixtimestamp.com/">unixtimestamp.com</a> or
<a href="https://currentmillis.com/">currentmillis.com</a>.</p>
<p>Just like you can write that number on a piece of paper and later get
back the full instant back to life, you can store it in a file or a
row in your favorite RDBMS. Although you might want to talk to your
RDBMS using a proper driver and handing it a plain date instance; your
driver will then take care of the conversion to the underlying database
serialization format for native time instances.</p>
<p>By storing time using a native format, you get the nice time formatting,
sorting, querying, etc features of your RDBMS for free, so you might want to
think twice before storing plain Unix timestamps in, say, Oracle.</p>
<p>Just make sure you know what timezone your Unix timestamp refers to, or
you might get confused later at deserialization time.</p>
<p>ISO 8601 is also a serialization favorite. In fact, it is used in the <a href="http://www.w3.org/TR/xmlschema-2/#isoformats">XML
Schema</a> standard.  Most xml
frameworks are natively able to serialize and deserialize back and forth from
<code>xs:date</code>, <code>xs:time</code> and <code>xs:dateTime</code> to your programming language’s native
format (and viceversa). The same is true for json. Just be careful when dealing
with partial representations: for instance, if you omit the time zone, make
sure you agree beforehand on a default one with your communicating party
(usually UTC or your local time zone if you’re both in the same one).</p>
<h2 id="management">Management</h2>
<p>First of all, if you think you can write your own time management
software library, or even write a little routine that adds or subtracts
arbitrary values from the time of the day,
please allow me to show you the source code for the
<a href="http://www.docjar.com/html/api/java/util/Date.java.html">java.util.Date</a>
and
<a href="http://www.docjar.com/html/api/java/util/GregorianCalendar.java.html">java.util.GregorianCalendar</a>
classes from JDK 7, respectively weighting 1331 and 3179 lines of code.</p>
<p>Okay, these are probably not the best examples of software routines that
deal with time, I agree. That’s why Java libraries like
<a href="http://joda-time.sourceforge.net/">Joda Time</a> were written.
In fact, Joda Time has become so popular that it gave birth to
<a href="http://jcp.org/en/jsr/detail?id=310">JSR-310</a> and is
<a href="http://www.h-online.com/open/news/item/JSR-310-s-Date-and-Time-API-added-to-JDK-8-1708647.html">now</a>
<a href="http://www.infoq.com/news/2013/02/java-time-api-jdk-8">part</a> of JDK 8.</p>
<p>Use of popular, well designed and implemented time frameworks will save your
life. Seriously. Take your time to get familiar with the API of your choosing.</p>
<h2 id="further-resources">Further Resources</h2>
<p>Here are a few useful links I’ve accumulated over time:</p>
<ul>
<li><a href="https://zachholman.com/talk/utc-is-enough-for-everyone-right">UTC is enough for everyone… right?</a></li>
<li><a href="http://infiniteundo.com/post/25326999628/falsehoods-programmers-believe-about-time">Falsehoods programmers believe about time</a></li>
<li><a href="http://apiux.com/2013/03/20/5-laws-api-dates-and-times/">The 5 laws of API dates and times</a></li>
<li><a href="http://derickrethans.nl/storing-date-time-in-database.html">Storing Date/Times in Databases</a></li>
<li><a href="https://medium.com/techtofreedom/5-levels-of-handling-date-and-time-in-python-46b601e47f65">5 Levels of Handling Date and Time in Python</a></li>
<li><a href="http://youtu.be/kzprsR2SvrQ">A Short History of the Modern Calendar</a></li>
<li><a href="http://opensourcehacker.com/2013/03/28/converting-world-timezones-with-duckduckgo-and-wolfram-alpha/">Converting world timezones with DuckDuckGo and Wolfram Alpha from the browser address bar</a></li>
</ul>

            </div></div>]]>
            </description>
            <link>https://mirkocaserta.com/posts/2013/04/an-introduction-to-time-representation-serialization-and-management-in-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25879660</guid>
            <pubDate>Sat, 23 Jan 2021 04:29:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open-source is still not a business model]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25879561">thread link</a>) | @pabs3
<br/>
January 22, 2021 | https://funnelfiasco.com/blog/2021/01/22/open-source-business-model/ | <a href="https://web.archive.org/web/*/https://funnelfiasco.com/blog/2021/01/22/open-source-business-model/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>If you thought 2021 was going to be the year without big drama in the world of open source licensing, you didn’t have to wait long to be disappointed. Two stories have already sprung up in the first few weeks of the year. They’re independent, but related. Both of them remind us that open source is a <em>development</em> model, not a business model.</p>



<h2>Elasticsearch and Kibana</h2>



<p>A few years ago, it seemed like I couldn’t go to any sysadmin/DevOps conference or meetup without hearing about the “<a href="https://www.elastic.co/what-is/elk-stack">ELK stack</a>“. ELK stands for the three pieces of software involved: Elasticsearch, Logstash, and Kibana. Because it provided powerful aggregation, search, and visualization of arbitrary log files, it became very popular. This also meant that Amazon Web Services (AWS) saw value in providing an <a href="https://aws.amazon.com/elasticsearch-service/">Elasticsearch service</a>.</p>



<p>As companies moved more workloads to AWS it made sense to pay AWS for Amazon Elasticsearch Service instead of paying Elastic. This represented what you might call a revenue problem for Elastic. So they decided to follow MongoDB’s lead and <a href="https://www.elastic.co/blog/licensing-change">change their license</a> to the Server Side Public License (SSPL).</p>



<p>The SSPL is essentially a “you can’t use it, AWS” license. This makes it decidedly <a href="https://opensource.org/node/1099">not open source</a>. Insultingly, Elastic’s announcement and follow-up messaging include phrases like “doubling down on open”, implying that the SSPL is an open source license. It is not. It a source-available license. And, as open source business expert VM Brasseur writes, it <a href="https://anonymoushash.vmbrasseur.com/2021/01/14/elasticsearch-and-kibana-are-now-business-risks">creates business risk</a> for companies that use Elasticsearch and Kibana.</p>



<p>Elastic is, of course, free to use whatever license it wants for the software it develops. And it’s free to want to make money. But it’s not reasonable to get mad at companies using the software under the license you chose to use for it. Picking a license is a <a href="https://anonymoushash.vmbrasseur.com/2019/06/07/the-problem-with-amazon-and-open-source-isnt-amazon/">business decision</a>.</p>



<p>Shortly before I sat down to write this post, I saw that <a href="https://aws.amazon.com/blogs/opensource/stepping-up-for-a-truly-open-source-elasticsearch/?sc_channel=sm&amp;sc_campaign=launch_&amp;sc_publisher=TWITTER&amp;sc_country=Global&amp;sc_geo=GLOBAL&amp;sc_outcome=awareness&amp;trk=launch__TWITTER&amp;linkId=109673114">Amazon has forked Elasticsearch and Kibana</a>. They will take the last-released versions and continue to develop them as open source projects under the Apache License v2. This is entirely permissible and to be expected when a project makes a significant licensing change. So now Elastic is in danger of a sizable portion of the community moving to the fork and away from their projects. If that pans out, it may end up being more harmful than Amazon Elasticsearch Service ever was.</p>



<h2>Nmap Public Source License</h2>



<p>The second story actually started in the fall of 2020, but didn’t seem to get much notice until after the new year. The developers of <a href="https://nmap.org/">nmap</a>, the widely-used security scanner, began using a new license. Prior to the release of version 7.90, nmap was under a modified version of the GNU General Public License version 2 (GPLv2). This license had some additional “gloss”, but was generally accepted by Linux distributions to be a valid free/open source software license.</p>



<p>With version 7.90, nmap is now under the Nmap Public Source License (NPSL). <a href="https://web.archive.org/web/20201127221208/https://nmap.org/npsl/npsl-annotated.html">Version 0.92</a> of this license contained some phrasing that seemed objectionable. The Gentoo licenses team brought their concerns to the developers in a <a href="https://github.com/nmap/nmap/issues/2199">GitHub issue</a>. Some of their concerns seemed like non-issues to me (and to the lawyers at work I consulted with on this), but one part in particular stood out.</p>



<blockquote><p>Proprietary software companies wishing to use or incorporate Covered Software within their programs must contact Licensor to purchase a separate license</p></blockquote>



<p>It seemed clear that the intent was to restrict proprietary <em>software</em>, not otherwise-compliant projects from companies that produce proprietary software. Nonetheless, as it was written, it constituted a violation of the <a href="https://opensource.org/osd#fields-of-endeavor">Open Source Definition</a>, and we <a href="https://lists.fedoraproject.org/archives/list/legal@lists.fedoraproject.org/thread/GZIDC4DHXZP67LFU7P2OT2AQVDJRHZ2M/">rejected it for use in Fedora</a>.</p>



<p>To their credit, the developers took the feedback well and quickly released an <a href="https://web.archive.org/web/20210113133517/https://nmap.org/npsl/npsl-annotated.html">updated version of the license</a>. They even retroactively licensed affected releases under the updated license. Unfortunately, version 0.93 still contains some problems. In particular, the annotations still express field of endeavor restrictions.</p>



<p>While the license text is the most important part, the annotations still matter. They indicate the intent of the license and guide the interpretation by lawyers and judges. So newer versions of nmap remain unsuitable for some distributions.</p>



<h3>Licenses are not for you to be clever</h3>



<p>Like with Elastic, I’m sympathetic to the nmap developers’ position. If someone is going to use their project to make money, they’d like to get paid, too. That’s an entirely reasonable position to take. But the way they went about it isn’t right. As noted in the GitHub issue, they’re not copyright attorneys. If they were, the license would be much better.</p>



<p>It seems like the developers are fine with people free-riding profit off of nmap so long as the software used to generate the profit is also open source. In that case, why not just use a professionally-drafted and vetted license like the AGPL? The NPSL is already using the GPLv2 and adding more stuff on top of it, and it’s the more stuff on top of it that’s causing problems.</p>



<p>Trying to write your business model into a software license that purports to be open source is a losing proposition.</p>
			</div></div>]]>
            </description>
            <link>https://funnelfiasco.com/blog/2021/01/22/open-source-business-model/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25879561</guid>
            <pubDate>Sat, 23 Jan 2021 04:11:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bournegol – Algol-like C dialect that Steve Bourne used to write Bourne shell]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25879517">thread link</a>) | @segfaultbuserr
<br/>
January 22, 2021 | http://oldhome.schmorp.de/marc/bournegol.html | <a href="https://web.archive.org/web/*/http://oldhome.schmorp.de/marc/bournegol.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p><b>Last change: 2014-12-30</b></p>




While browsing, I found this except from the book <a href="http://www.amazon.com/exec/obidos/ASIN/1565922603/heinersshelldora/002-6407720-0447242">Unix Power Tools</a>:

<blockquote>
   ... To fix it, first get the source, and then change it in the obvious three places in xec.c. You will have to learn <strong>Bournegol</strong> [the ALGOL-like dialect of C that Steve Bourne used to
   write the original Bourne shell-JP ]. Another alternative is to replace /bin/sh with one of the free sh look-alikes... (CT in comp.unix.questions on Usenet, 20 February 1990)
</blockquote>

I immediately asked myself: what could Bournegol look like? Well,
it's not that easy to find the <a href="http://minnie.tuhs.org/UnixTree/V7/usr/src/cmd/sh/">original Bourne
Shell</a> sourcecode, so,
after some googling, I thought I might put an example of Bournegol on
my homepage, so other people have the chance to find about "Bournegol"
without the tedious search.<p>

(many years later I found <a href="http://www.collyer.net/who/geoff/sh.tour.ps">this
paper</a>, A Partial Tour Through
the UNIX Shell, which makes for very nice reading).

Ok, without any further ado, here is an excerpt of the file
<tt>xec.c</tt>, referenced above, supposedly from the <a href="http://minnie.tuhs.org/UnixTree/V7/usr/src/">7th Edition UNIX</a>, that gives you an
impression of bournegol:</p><pre>LOCAL INT	parent;

SYSTAB		commands;

/* ========	command execution	========*/

execute(argt, execflg, pf1, pf2)
	TREPTR		argt;
	INT		*pf1, *pf2;
{
	/* `stakbot' is preserved by this routine */
	REG TREPTR	t;
	STKPTR		sav=savstak();

	sigchk();

	IF (t=argt) ANDF execbrk==0
	THEN	REG INT		treeflgs;
		INT		oldexit, type;
		REG STRING	*com;

		treeflgs = t-&gt;tretyp; type = treeflgs&amp;COMMSK;
		oldexit=exitval; exitval=0;

		SWITCH type IN

		case TCOM:
			BEGIN
			STRING		a1;
			INT		argn, internal;
			ARGPTR		schain=gchain;
			IOPTR		io=t-&gt;treio;
			gchain=0;
			argn = getarg(t);
			com=scan(argn);
			a1=com[1]; gchain=schain;

			IF (internal=syslook(com[0],commands)) ORF argn==0
			THEN	setlist(t-&gt;comset, 0);
			FI

			IF argn ANDF (flags&amp;noexec)==0
			THEN	/* print command if execpr */
				IF flags&amp;execpr
				THEN	argn=0;	prs(execpmsg);
					WHILE com[argn]!=ENDARGS
					DO prs(com[argn++]); blank() OD
					newline();
				FI

				SWITCH internal IN

				case SYSDOT:
					IF a1
					THEN	REG INT		f;
	
						IF (f=pathopen(getpath(a1), a1)) &lt; 0
						THEN failed(a1,notfound);
						ELSE execexp(0,f);
						FI
					FI
					break;
	
				case SYSTIMES:
					{
					L_INT	t[4]; times(t);
					prt(t[2]); blank(); prt(t[3]); newline();
					}
					break;
	
				case SYSEXIT:
					exitsh(a1?stoi(a1):oldexit);
	
</pre>
[...]<br>
<pre>				case SYSTRAP:
					IF a1
					THEN	BOOL	clear;
						IF (clear=digit(*a1))==0
						THEN	++com;
						FI
						WHILE *++com
						DO INT	i;
						   IF (i=stoi(*com))&gt;=MAXTRAP ORF i&lt;MINTRAP
						   THEN	failed(*com,badtrap);
						   ELIF clear
						   THEN	clrsig(i);
						   ELSE	replace(&amp;trapcom[i],a1);
							IF *a1
							THEN	getsig(i);
							ELSE	ignsig(i);
							FI
						   FI
						OD
					ELSE	/* print out current traps */
						INT		i;
	
						FOR i=0; i&lt;MAXTRAP; i++
						DO IF trapcom[i]
						   THEN	prn(i); prs(colon); prs(trapcom[i]); newline();
						   FI
						OD
					FI
					break;
	
</pre>
[...]<br>
<pre>                                                   
		case TFORK:
			IF execflg ANDF (treeflgs&amp;(FAMP|FPOU))==0
			THEN	parent=0;
			ELSE	WHILE (parent=fork()) == -1
				DO sigchk(); alarm(10); pause() OD
			FI

			IF parent
			THEN	/* This is the parent branch of fork;    */
				/* it may or may not wait for the child. */
				IF treeflgs&amp;FPRS ANDF flags&amp;ttyflg
				THEN	prn(parent); newline();
				FI
				IF treeflgs&amp;FPCL THEN closepipe(pf1) FI
				IF (treeflgs&amp;(FAMP|FPOU))==0
				THEN	await(parent);
				ELIF (treeflgs&amp;FAMP)==0
				THEN	post(parent);
				ELSE	assnum(&amp;pcsadr, parent);
				FI

				chktrap();
				break;

</pre>
[...]<p>

(Note the <em>single</em> use of curly braces after <tt>case SYSTIMES</tt>. This
and the lowercase <tt>case</tt> let me believe this segment might have been
added at a later stage). The necesssary macro definitions to understand (if
you dare to try) the above excerpt can be found in the file <tt>mac.h</tt>:

</p><pre>/*
 *	UNIX shell
 *
 *	S. R. Bourne
 *	Bell Telephone Laboratories
 *
 */

#define LOCAL	static
#define PROC	extern
#define TYPE	typedef
#define STRUCT	TYPE struct
#define UNION	TYPE union
#define REG	register

#define IF	if(
#define THEN	){
#define ELSE	} else {
#define ELIF	} else if (
#define FI	;}

#define BEGIN	{
#define END	}
#define SWITCH	switch(
#define IN	){
#define ENDSW	}
#define FOR	for(
#define WHILE	while(
#define DO	){
#define OD	;}
#define REP	do_lbr
#define PER	}while(
#define DONE	);
#define LOOP	for(;;){
#define POOL	}


#define SKIP	;
#define DIV	/
#define REM	%
#define NEQ	^
#define ANDF	&amp;&amp;
#define ORF	||

#define TRUE	(-1)
#define FALSE	0
#define LOBYTE	0377
#define STRIP	0177
#define QUOTE	0200

#define EOF	0
#define NL	'\n'
#define SP	' '
#define LQ	'`'
#define RQ	'\''
#define MINUS	'-'
#define COLON	':'

#define MAX(a,b)	((a)&gt;(b)?(a):(b))
</pre><p>

Hope you found this interesting ;)


</p><p><img src="http://oldhome.schmorp.de/marc/images/hbar.gif" alt="=======================================================" images="" hbar.gif="" gif="" 775x16="" 775x16+0+0="" pseudoclass="" 8c="" 381=""></p>
<p>Any questions/hints/critics? Contact the <a href="mailto:pcg@goof.com">author</a> of this page!





                  

</p></div>]]>
            </description>
            <link>http://oldhome.schmorp.de/marc/bournegol.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25879517</guid>
            <pubDate>Sat, 23 Jan 2021 04:01:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bootstrapped]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25879363">thread link</a>) | @Malfunction92
<br/>
January 22, 2021 | https://postmake.io/bootstrapped | <a href="https://web.archive.org/web/*/https://postmake.io/bootstrapped">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-1698d9c8=""><h4 data-v-1698d9c8="">More tools and resources!</h4> <p data-v-1698d9c8="">Postmake is a directory of curated tools and resources for your next projects.
                        If you liked this list, check out the <strong data-v-1698d9c8=""><a href="https://postmake.io/" data-v-1698d9c8="">full directory</a></strong>
                        for more tools and resources, or join the newsletter to regularly receive more cool and helpful stuff.</p> <p data-v-1698d9c8="">Drop your email below and join
                        <span data-v-1698d9c8="">the</span>
                        founders and makers already getting our weekly newsletter.
                        <span data-v-1698d9c8="">
                            Here's <strong data-v-1698d9c8=""><a href="https://postmake.io/bits" target="_blank" rel="noopener noreferrer" data-v-1698d9c8="">an example</a></strong>
                            of what you'll receive.
                        </span></p></div></div>]]>
            </description>
            <link>https://postmake.io/bootstrapped</link>
            <guid isPermaLink="false">hacker-news-small-sites-25879363</guid>
            <pubDate>Sat, 23 Jan 2021 03:34:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Rysolv – Fix open source issues, get paid]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 99 (<a href="https://news.ycombinator.com/item?id=25879238">thread link</a>) | @themanmaran
<br/>
January 22, 2021 | https://rysolv.com/issues | <a href="https://web.archive.org/web/*/https://rysolv.com/issues">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://rysolv.com/issues</link>
            <guid isPermaLink="false">hacker-news-small-sites-25879238</guid>
            <pubDate>Sat, 23 Jan 2021 03:14:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Job Transitions in a Time of Automation and Labor Market Crises]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25879225">thread link</a>) | @nikolasjdawson
<br/>
January 22, 2021 | https://bitsandatoms.co/job-transitions-in-a-time-of-automation-and-labour-market-crises/ | <a href="https://web.archive.org/web/*/https://bitsandatoms.co/job-transitions-in-a-time-of-automation-and-labour-market-crises/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

				
					<h2><strong>Summary</strong></h2>
<ul>
<li>We’ve built a machine learning-based Job Transitions Recommender System that can accurately predict the probability of transitioning between occupations. We showcase the system for workers forced to transition between jobs.</li>
<li>The system is based on a novel data-driven method to measure the similarity between occupations based on their underlying skill profiles from real-time job ads.</li>
<li>We’ve also developed a leading indicator of Artificial Intelligence adoption in Australian industries, outlining gaps, opportunities, and trends.</li>
<li>For full technical details, please read the <a href="https://arxiv.org/abs/2011.11801">pre-print</a>.</li>
</ul>
<p>People are forced to change jobs as new technologies automate labour, production is moved abroad, and economic crises unfold. Successfully transitioning between jobs, however, requires leveraging current skills and acquiring others, which can falter if the skills gap is too large.</p>
<p>In our latest research, <a href="https://au.linkedin.com/in/marian-andrei-rizoiu-063b19b0" target="_blank" rel="noopener">Marian-Andrei Rizoiu</a>, <a href="https://au.linkedin.com/in/maryanne" target="_blank" rel="noopener">Mary-Anne Williams</a> and I developed a novel method to measure the ‘distance’ between <em>sets of skills</em> using real-time job ads data. We then use these measures to build a recommender system that accurately predicts the probability of transitioning from one occupation to every other possible occupation. Intuitively, two occupations have a high probability of successfully transitioning when their skill sets are highly similar (i.e. the distance is small). For example, an Accountant has a high probability of transitioning to become a Financial Analyst because their skill sets are similar; whereas a Speech Therapist has a low transition probability to becoming a Financial Analyst as their skill sets are very different. This isn’t to say that it’s not possible. Rather, the skills gap is large, so the probability of successfully transitioning is diminished.</p>
<h2><strong>The SKILL SPACE Method</strong></h2>
<h3>Distance between skills</h3>
<p>In order to measure the distance between occupations from their underlying skill sets, we first measure the distance between individual skills in job ads for each calendar year from 2012-2020. To achieve this bottom-up approach, we first use a method from Trade Economics, called ‘Revealed Comparative Advantage’ (RCA), to identify how important an individual skill is to a job ad (i.e. comparative advantage). Then, after some normalisation, we calculate the pairwise similarity between every skill for each year. The image below shows the skill distance embeddings for the top 500 skills by posting frequency in 2018.</p>
<p><img src="https://bitsandatoms.co/wp-content/uploads/2021/01/all_skills_inset.png" alt="" width="671" height="776"></p>
<p>Here, each marker represents an individual skill that is coloured according to one of 13 clusters of highly similar skills. As seen in the Software Development cluster (see inset), highly similar skills cluster closely together, such as ‘Python’ and ‘C++’. The skills map also provides useful insights, highlighting that specialised skills (such as ‘Software Development’ and ‘Healthcare’) tend to lay toward the edges of the embedding, whereas more general and transferable skills lay toward the middle, acting as a ‘bridge’ to specialist skills.</p>
<h3>Distance between occupations</h3>
<p>Next, we use the pairwise skill distances to measure the distance between <em>sets of skills</em>. In this example, we define sets of skills by their occupational groupings. But they can just as easily be defined by other groupings, such as companies, industries, or personalised skill sets. We calculate the distance between skill sets as the weighted average similarity between the individual skills in each set, where the weights correspond to the skill importance in their respective sets. The figure below visualises the distance between Australian occupations in 2018.</p>
<p><img src="https://bitsandatoms.co/wp-content/uploads/2021/01/ANZSCO_automation_inset.png" alt="" width="749" height="689"></p>
<p>Each occupation is represented by a marker and coloured on a scale according to their automation susceptibility, as calculated by <a href="https://www.sciencedirect.com/science/article/abs/pii/S0040162516302244" target="_blank" rel="noopener nofollow">Frey and Osborne</a> – dark blue represents low-risk probability and dark red shows high-risk probability over the coming two decades. As seen in the magnified inset, similar occupations lie close together on the map. Further, occupations in low-risk of automation tend to be characterised by non-routine, interpersonal, and/or high cognitive labour tasks; whereas occupations in high risk of automation tend to require routine, manual, and/or low cognitive labour tasks. For example, in the inset of the Figure above, a ‘Sheetmetal Trades Worker’ is deemed to be at high risk of labour automation (82% probability) due to high levels of routine and manual labour tasks required by the occupation. However, the skill set demands of a ‘Sheetmetal Trades Worker’ are highly similar to an ‘Industrial Designer’, which is considered at low risk of labour automation over the coming two decades (4% probability). Therefore, an ‘Industrial Designer’ represents a transition opportunity for a ‘Sheetmetal Trades Worker’ that leverages existing skills and protects against potential risks of technological labour automation.</p>
<h2><strong>Constructing the <em>Job Transitions Recommender System</em></strong></h2>
<p>The SKILL SPACE Method described above achieves high levels of accuracy in predicting job transitions. However, these are symmetric measures and we know that <strong>job transitions are <em>asymmetric</em></strong> – it is more difficult to transition between jobs in one direction than the other. Therefore, transitions are determined by more than the symmetric distance between skill sets; other factors, such as educational requirements and experience demands, contribute to these asymmetries.</p>
<p>We account for the asymmetries between job transitions by training a machine learning classifier model that combines the SKILL SPACE distance measures with other labour market variables from job ads data and employment statistics (see the <a href="https://arxiv.org/abs/2011.11801" target="_blank" rel="noopener nofollow">pre-print</a> for full details). Our machine learning model is trained against a dataset of ‘actual’ (i.e. real life) job transitions from an Australian longitudinal household survey. We then apply the trained model to predict the probability for every possible occupational transition in the dataset – described as the transition probability between a ‘source’ and a ‘target’ occupation. This creates the <em>Transitions Map</em>, for which a subset of 20 occupations can be seen in the figure below.</p>
<p><img src="https://bitsandatoms.co/wp-content/uploads/2021/01/R_clusterheatmap_subset_transitions.png" alt="" width="1152" height="1152" srcset="https://bitsandatoms.co/wp-content/uploads/2021/01/R_clusterheatmap_subset_transitions.png 1152w, https://bitsandatoms.co/wp-content/uploads/2021/01/R_clusterheatmap_subset_transitions-150x150.png 150w, https://bitsandatoms.co/wp-content/uploads/2021/01/R_clusterheatmap_subset_transitions-300x300.png 300w, https://bitsandatoms.co/wp-content/uploads/2021/01/R_clusterheatmap_subset_transitions-768x768.png 768w, https://bitsandatoms.co/wp-content/uploads/2021/01/R_clusterheatmap_subset_transitions-1024x1024.png 1024w" sizes="(max-width: 1152px) 100vw, 1152px"></p>
<p>The coloured heatmap shows the transition probabilities (‘source’ occupations are in columns and ‘targets’ are in rows). Dark blue represents higher transition probabilities and lighter blue shows lower probabilities, where the asymmetries between occupation pairs are clearly observed. For example, a ‘Finance Manager’ has a higher probability of transitioning to become an ‘Accounting Clerk’ than the reverse direction. Moreover, transitioning to some occupations is generally easier (for example, ‘Bar Attendants and Baristas’) than others (‘Life Scientists’). The dendrogram (the lines on the left and top of the chart) illustrates the hierarchical clusters of occupations where there is a clear divide between service-oriented professions and manual labour occupations.</p>
<p>Our model achieves high levels of performance, <strong>accurately predicting 76% of occupational transitions</strong>.</p>
<h2><strong>Recommending Jobs and Skills</strong></h2>
<p>The <em>Transitions Map</em> provides the basis for making qualified job transition recommendations.&nbsp;We call this the <em>Job Transitions Recommender System</em>. In the figure below, we make job recommendations for ‘Domestic Cleaners’ as an example – an occupation that has experienced significant declines in labour demand and employment levels during COVID-19 in Australia.</p>
<p><img src="https://bitsandatoms.co/wp-content/uploads/2021/01/transitions-example-updated.png" alt="" width="1401" height="628" srcset="https://bitsandatoms.co/wp-content/uploads/2021/01/transitions-example-updated.png 1401w, https://bitsandatoms.co/wp-content/uploads/2021/01/transitions-example-updated-300x134.png 300w, https://bitsandatoms.co/wp-content/uploads/2021/01/transitions-example-updated-768x344.png 768w, https://bitsandatoms.co/wp-content/uploads/2021/01/transitions-example-updated-1024x459.png 1024w" sizes="(max-width: 1401px) 100vw, 1401px"></p>

<p>First, we use the <em>Transitions Map</em> to recommend the occupations with the highest transition probabilities; these are the named occupations on the right side of the flow diagram, ordered in descending order of transition probability. Segment widths show the labour demand for each of the recommended occupations during the beginning of the COVID-19 period (measured by posting frequency). The segment colours represent the percentage change of posting frequency during March and April 2019 compared to the same months in 2020; dark red indicates a big decrease in job ad posts and dark blue indicates a big increase. The first six transition recommendations for ‘Domestic Cleaners’ all experienced negative demand, which is unsurprising given that ‘non-essential’ services were restricted in Australia during this period. However, the seventh recommendation, ‘Aged and Disabled Carers’, had significantly grown in demand during the beginning of the COVID-19 period and there was a high number of jobs advertised. Given that it is generally favourable to transition to high demand jobs, we selected ‘Aged and Disabled Carers’ as the target occupation for this example.</p>
<h3>Skill recommendations for target occupations</h3>
<p>We then take the <em>Job Transitions Recommender System</em> a step further by incorporating skill recommendations. Transitioning to a new occupation generally requires developing new skills under time and resource constraints. Therefore, workers must prioritise which skills to develop. We argue that a worker should invest in developing a skill when (1) the <strong>skill is important to the target occupation</strong> <em>and</em> (2) the <strong>distance to acquire the skill is large</strong> (that is, it is relatively difficult to acquire). In the case of the ‘Domestic Cleaner’ in the figure above, the top recommended skills to assist in the transition to the ‘Aged and Disabled Carer’ occupation are specialised patient care skills, such as ‘Patient Hygiene Assistance’.&nbsp;Conversely, the reasons <em>not</em> to develop a skill are when (1) the <strong>skill is not important</strong> <em>or</em> (2) the <strong>distance is small to the target occupation</strong>. The figure shows that while some ‘Aged and Disabled Carer’ jobs require ‘Business Analysis’ and ‘Finance’ skills, these skills are of low importance for the ‘Aged and Disabled Carer’ occupation, so they should not be prioritised. Similarly, skills such as ‘Ironing’ and ‘Laundry’ are required by ‘Aged and Disabled Carer’ jobs but the distance is small, so it is likely that either a ‘Domestic Cleaner’ already possesses these skills or they can easily acquire them.</p>
<h2><strong>Developing a Leading Indicator of AI Adoption</strong></h2>
<p>The SKILL SPACE method can …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bitsandatoms.co/job-transitions-in-a-time-of-automation-and-labour-market-crises/">https://bitsandatoms.co/job-transitions-in-a-time-of-automation-and-labour-market-crises/</a></em></p>]]>
            </description>
            <link>https://bitsandatoms.co/job-transitions-in-a-time-of-automation-and-labour-market-crises/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25879225</guid>
            <pubDate>Sat, 23 Jan 2021 03:13:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing Apple's M1 Matmul Performance – AMX2 vs. Neon (2020)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25879062">thread link</a>) | @gone35
<br/>
January 22, 2021 | https://nod.ai/comparing-apple-m1-with-amx2-m1-with-neon/ | <a href="https://web.archive.org/web/*/https://nod.ai/comparing-apple-m1-with-amx2-m1-with-neon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Matrix Multiply forms the foundation of Machine Learning computations. We show Apple’s M1 custom AMX2 Matrix Multiply unit can outperform ARMv8.6’s standard NEON instructions by about <strong>2X</strong>.</p>
<p>Nod’s AI Compiler team focusses on the state of art code generation, async partitioning, optimizations and scheduling to overlap communication and compute on various A.I hardware from large datacenter clusters to edge A.I silicon. The basic computation building block for all of that is the venerable Matmul. In this post we focus on the the Matmul performance on the just released Apple M1 Chip since that translates directly to how much you can squeeze out of any A.I hardware.</p>
<p>Typically silicon teams work closely with the optimization teams to create highly optimized SGEMM ( <b>S</b>ingle precision&nbsp;<b>GE</b>neral&nbsp;<b>M</b>atrix&nbsp;<b>M</b>ultiply) and DGEMM (<strong>D</strong>ouble precision <strong>GE</strong>neral <strong>M</strong>atrix <strong>M</strong>ulitply) kernels for each silicon platform. Intel’s <strong>MKL</strong> provides these kernels for the Intel chipsets and Apple’s <strong>Accelerate Framework&nbsp;</strong>provides highly optimized kernels for Apple machines (both Intel and Apple Silicon).</p>
<p>Eigen provides a reasonably easy to use high-level template library of these linear algebra algorithms while also exposing building blocks like <strong>GEBP</strong> (GeneralBlockPanelKernel) “traits” for each SoC.&nbsp; These GEBP traits effectively allow you to use Compiler Intrinsics and custom instructions to target a particular SoC while still wrapping it up in higher level C++ for ease of use. BLIS (a BLAS like library) also follows a similar paradigm where the “inner most” microkernel is highly hand optimized assembly for a particular architecture and&nbsp; forms the foundation of the higher level computations that could be written in more portable code. There is a good read on the concepts used by BLIS <a href="https://www.cs.utexas.edu/users/flame/pubs/blis2_toms_rev2.pdf">here</a>. However BLIS’s microkernel on ARM/NEON is woefully inadequate (See <a href="https://github.com/flame/blis/issues/421">this bug report</a> when building with clang). There have been other attempts to write the GEBP kernel in portable code (see <a href="http://www.cse.unsw.edu.au/~jingling/papers/cgo17.pdf">this</a>), but I think Eigen is probably the most successful with the backing of the Tensorflow and Android efforts.</p>
<p>Apple’s M1 SoC&nbsp; has received rave reviews on its performance. It includes extension to the ARM Architectural Specification to include a Matrix Co-Processor – commonly referred to as <strong>AMX (Apple Matrix Co-processor)</strong>. The version in the M1 SoC is supposedly a “Version 2” so let’s refer to it as AMX2. Supposedly the AMX2 is tightly coupled with the ARM core (has custom instructions to access it) than the <strong>ANE (Apple Neural Engine)</strong> which is a separate Neural Processing Unit on the SoC – which would behave more like an integrated GPU with higher latencies and higher throughput when compared to the inline AMX2.</p>
<p>Apple has not released the instructions to access the AMX2.&nbsp; This way there is no need to maintain backwards compatibility with compiled software. The only way you should (though not the only way you <em>can</em>) currently access AMX2 on&nbsp; M1 SoC is via the Accelerate Framework.&nbsp; ARM has just started adding support for Architecture ARMv8.7-a in <a href="https://reviews.llvm.org/search/query/OxQ0whlSn_CS/#R">LLVM</a> and specifically the support for Accelerators such as AMX <a href="https://reviews.llvm.org/D91775">here</a> . It includes the ability to add Accelerators such as the AMX but it is unclear if AMX will adhere to that specification. You can find out more about ARMv8.7-a <a href="https://youtu.be/CSUohi1XY78"><strong>here</strong></a></p>
<p>In this post we will evaluate a <strong>simple SGEMM with a size of 1000</strong> using AMX2 and Eigen’s Neon optimized version on the Apple M1.&nbsp; We have done some tests with other ARMv8 SoCs but it is not apples to apples since they were older generation parts or had different toolchain options etc.&nbsp; &nbsp;All tests were done with top of master Clang (12.0.0+) built with OpenMP support (for Eigen’s parallelism) and top of master Eigen. We run 10 iterations of the Matrix multiply as warmup (to initialize any lazy loading libraries or fill the instruction and data caches) and then run the test 20 times and average the run times.&nbsp; We have to use Eigen noalias() to make sure there are no unnecessary copies.</p>
<p>We compile the code with -O3 and validate with <em>“otool -L”</em> that we link against Accelerate when using it and just standard libs otherwise. Also “otool -tv a.out | grep fmla” should show you the NEON FMLA instructions being used as shown below:</p>
<pre><span>nodai@macbook-pro-2 pytorch % otool -tv a.out| grep fmla</span>
<span>00000001000025a8 fmla.2d v0, v2, v1<span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span>; Latency: 10</span>
<span>0000000100002700 fmla.2d v2, v4, v0<span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span>; Latency: 10</span>
<span>0000000100002704 fmla.2d v1, v5, v3<span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span>; Latency: 10</span>
<span>0000000100002a78 fmla.2d v3, v5, v1<span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span>; Latency: 10</span></pre>

<h3><strong>Results</strong></h3>
<p><strong>Apple M1 with Accelerate (AMX2)&nbsp;</strong></p>
<blockquote>
<pre><span>(nnc_venv) nodai@macbook-pro pytorch % LD_LIBRARY_PATH=/Users/nodai/lokal/lib/ ./a.out</span>
<span>Eigen is using 8 threads</span>
<span>Starting matrix multiplication test with 1000 matrices</span>
<span>Eigen avg execution time (ms) = <strong>8</strong></span></pre>
</blockquote>
<p><strong>Apple M1 with NEON (AMX2)&nbsp;</strong></p>
<blockquote>
<pre><span>(nnc_venv) nodai@macbook-pro pytorch % LD_LIBRARY_PATH=/Users/nodai/lokal/lib/ ./a.out</span>
<span>Eigen is using 8 threads</span>
<span>Starting matrix multiplication test with 1000 matrices</span>
<span>Eigen avg execution time (ms) = <strong>20</strong></span></pre>
</blockquote>
<p><strong>CPU utilization:&nbsp;</strong></p>
<p>For the test matrix size of 1000 there is negligible cpu utilization so we tried increasing the matrix size large enough to see some impact. With AMX2 the CPU utilization delta is negligible but there is likely memory pressure to DMA into the AMX2, however with NEON we can saturate the CPU cores.</p>

<p><strong>Matrix Multiplication for Various Matrix Sizes</strong></p>
<p><strong>Configuration</strong></p>
<ul>
<li>Apple Silicon M1</li>
<li>compiler: clang version 12.0.0 (/Users/nodai/llvm-project/clang e6ae623314bab3ddd983ed941bf63a6d4c63a1f4)</li>
<li>eigen3: fdf2ee62c5174441076fb64c9737d89bbe102759</li>
</ul>
<p><strong>Single Threaded FP32 Matmul NEON</strong></p>
<p><img loading="lazy" src="https://nod.ai/wp-content/uploads/2020/12/matrix_matrix.png" alt="" width="800" height="560" srcset="https://nod.ai/wp-content/uploads/2020/12/matrix_matrix.png 800w, https://nod.ai/wp-content/uploads/2020/12/matrix_matrix-300x210.png 300w, https://nod.ai/wp-content/uploads/2020/12/matrix_matrix-768x538.png 768w, https://nod.ai/wp-content/uploads/2020/12/matrix_matrix-600x420.png 600w" sizes="(max-width: 800px) 100vw, 800px"></p>

<p>But is this the best NEON optimization possible ? Based on this <a href="https://docs.google.com/spreadsheets/d/1i3GXUku9e76B7YwPnYiDx-d36ZuL85WRKEnNiIgA8rQ/edit#gid=1050198706">work</a> as part of GEMMLOWP project there should be more room. So we ran the “standalone NEON tests” on the M1. This should give us a good idea on the delta between Eigen’s GEBP and a fully hand optimized NEON kernel by ARM themselves (though for a Cortex-A57 class core).&nbsp; The results are below:</p>

<blockquote>
<pre><span>kernel,Gop/s</span>
<span>NEON_64bit_GEMM_Int425Operands_intrinsics,145.04</span>
<span>NEON_64bit_GEMM_Int7Operands_AccumEightWithin16Bits,105.541</span>
<span>NEON_64bit_GEMM_Int7Operands_AccumEightWithin16Bits_intrinsics,39.3034</span>
<span>NEON_64bit_GEMM_Int8Operands_AccumTwoWithin16Bits,81.8715</span>
<span>NEON_64bit_GEMM_Int8Operands_AccumTwoWithin16Bits_intrinsics,16.8501</span>
<span>NEON_64bit_GEMM_Uint8Operands_Uint32Accumulators,51.2957</span>
<span>NEON_64bit_GEMM_Uint8Operands_Uint32Accumulators_intrinsics,54.485</span>
<span>NEON_64bit_GEMM_Uint8Operands_Uint32Accumulators_noexpand_A57,58.1817</span>
<span>NEON_64bit_GEMM_Int32_WithScalar,69.2449</span>
<span>NEON_64bit_GEMM_Float32_WithVectorDuplicatingScalar,48.9629</span>
<span>NEON_64bit_GEMM_Float32_WithScalar,69.229</span>
<span>NEON_64bit_GEMM_Float32_WithScalar_intrinsics,32.3552</span>
<span>NEON_64bit_GEMM_Float32_WithScalar_A57,68.6708</span>
<span>NEON_64bit_GEMM_Float32_WithScalar_A55r1,53.2717</span></pre>
</blockquote>

<p>Based on the above we estimate there is another 20% or so we can squeeze out of the NEON implementation.&nbsp; An important point to consider is the overhead of using intrinsics vs full inline assembly – you still have to make a choice between portability and performance.</p>
<p><strong>Single Threaded FP32 Matmul AMX2</strong></p>
<p>After the post was initially written we found there is an environment variable <span>VECLIB_MAXIMUM_THREAD</span> that can control single threaded operation of Accelerate. Stay tuned for more controlled studies.</p>
<p><strong>Summary:</strong></p>
<p>This is a first pass performance test of using AMX2 vs NEON on the <strong>Apple M1 </strong>that<b> shows AMX2 roughly twice as fast as the NEON implementation</b>. There are probably a lot of corner cases to consider and tweaks to be done to the the NEON code especially with the varying size of L2 caches between the different cores.&nbsp; Based on the GEMMLowP work we estimate there is atleast another 20% or so left on the table with NEON. Let us know if we missed anything. Right now the system (Core clocks, core types, scheduler priorities etc) is not in a controlled environment to test it throughly but hopefully this gives us a first order approximation of what performance to expect at the fundamental building block – a Matmul, on the Apple M1.</p>
<p><strong>Future Work:</strong></p>
<p>In our next blog post we will build on a MatMul and share some numbers of the Nod Compiler’s codegen capabilities to automatically generate these GEMM kernels and other common kernels used in Machine Learning and compare the performance to native frameworks like MKL/MKL-DNN, Accelerate / MLCompute and Cudnn/cuBLAS on the GPU.</p>

<h4>Update 1 (12/30): Add first pass ruy numbers and push source code</h4>
<p>Thanks the Benoit Jacob from the Google&nbsp; who has worked on Eigen, Gemmlowp, TFlite, IREE etc we have first pass ruy numbers below on the M1. Stay tuned for more detailed comparisons and numbers.</p>
<blockquote>
<pre><span>macbook-pro-2 iree-build % THREADS=8 RUY_BENCHMARK_CUBIC=1 NOEXT=1 PATHS=f0 ./build_tools/third_party/ruy/benchmark_f32_f32_f32_f32</span>
<span>size,kNeon:Gop/s,kNeonDotprod:Gop/s</span>
<span>16,32.4,32</span>
<span>24,53.27,52.75</span>
<span>32,65.25,65.17</span>
<span>48,125.5,124</span>
<span>64,45.57,47.24</span>
<span>96,75.85,78.76</span>
<span>128,134.2,134.2</span>
<span>192,202.6,211.1</span>
<span>256,253.5,249.9</span>
<span>384,286.5,287.1</span>
<span>512,359.9,364.6</span>
<span>768,356,354</span>
<span>1024,430.4,424.6</span>
<span>1536,470.1,463.5</span>
<span>2048,470.7,469.2</span>
<span>3072,459,456.4</span>
<span>4096,454.1,454.3</span>

<span>Covered paths: kNeon, kNeonDotprod</span></pre>
</blockquote>

<p>Source code is now available at: <a href="https://github.com/powderluv/mm_benchmarks">here</a></p>
        </div></div>]]>
            </description>
            <link>https://nod.ai/comparing-apple-m1-with-amx2-m1-with-neon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25879062</guid>
            <pubDate>Sat, 23 Jan 2021 02:44:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cybersecurity Statistics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25879055">thread link</a>) | @yepgwer
<br/>
January 22, 2021 | https://justprivacy.org/cybersecurity-statistics/ | <a href="https://web.archive.org/web/*/https://justprivacy.org/cybersecurity-statistics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://justprivacy.org/cybersecurity-statistics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25879055</guid>
            <pubDate>Sat, 23 Jan 2021 02:44:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jupiter Structural Layer Cake (2013)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25878721">thread link</a>) | @FlyMoreRockets
<br/>
January 22, 2021 | https://cakecrumbs.me/2013/07/24/jupiter-structural-layer-cake/ | <a href="https://web.archive.org/web/*/https://cakecrumbs.me/2013/07/24/jupiter-structural-layer-cake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>When I posted the <a href="https://cakecrumbs.me/2013/05/24/commission-earth-structural-layer-cake/">Earth cake</a>, I did not expect it to get anywhere near the amount of attention it received. Getting featured on the Facebook pages Think Geek and I Fucking Love Science was a total highlight of my blogging life. I’m big fans of both pages so it was kind of surreal. A lot of my Zoology graduate mates are also fans of IFLS and you’d often hear conversations in the Masters office beginning with, “Did you see that post by IFLS today?” So I woke up to several of them messaging me about it and we all got super excited over it.</p>
<p>With the exposure those pages brought came a whole lot of people who wanted to know how to make it. I still get a couple of emails a week asking for a recipe. The cake was a total experiment on my part, and not one that went flawlessly. There were many imperfections within the cake and I never share recipes unless I know it’s absolutely tried and true. I’d hate to be responsible for a baking fail simply for giving a botched up recipe. But I also hate letting people down. So I decided to re-visit the concept so I could make a tutorial. That will come later in the week as I’m still editing it. But first, here’s the result of round 2.</p>
<p><a href="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake00.jpg"><img data-attachment-id="855" data-permalink="https://cakecrumbs.me/2013/07/24/jupiter-structural-layer-cake/ccjupitercake00/#main" data-orig-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake00.jpg" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS 600D&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1374606437&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;30&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.1&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Cakecrumbs’ Jupiter Structural Layer Cake" data-image-description="" data-medium-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake00.jpg?w=300" data-large-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake00.jpg?w=500" alt="Cakecrumbs' Jupiter Structural Layer Cake" src="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake00.jpg?w=640" srcset="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake00.jpg 500w, https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake00.jpg?w=150 150w, https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake00.jpg?w=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>One question I got asked a lot was if it was possible to make it a sphere. Absolutely it is. If you can make the hemisphere a sphere is easy. I didn’t want to make another Earth cake as I hate repeating bakes, so I opted to decorate it as something new. I threw around a few ideas ranging from something floral to a giant pokéball, but in the end I just wanted to make another planet.</p>

<p>Choosing a favourite planet was tough. As a kid I was fiercely passionate about two things: animals and the solar system. I ended up following the path of the former and never kept up to date with the latter, but the inner passion for astronomy has never died. Space is just <em>so freaking cool</em>. Our solar system alone is filled with so many fascinating planets, dwarf planets and all their satellites — choosing just one felt treacherous.</p>
<p><a href="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake01.jpg"><img data-attachment-id="856" data-permalink="https://cakecrumbs.me/2013/07/24/jupiter-structural-layer-cake/ccjupitercake01/#main" data-orig-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake01.jpg" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;5.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS 600D&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1374607281&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;55&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.5&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Cakecrumbs’ Jupiter Structural Layer Cake" data-image-description="" data-medium-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake01.jpg?w=300" data-large-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake01.jpg?w=500" alt="Cakecrumbs' Jupiter Structural Layer Cake" src="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake01.jpg?w=640" srcset="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake01.jpg 500w, https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake01.jpg?w=150 150w, https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake01.jpg?w=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>In the end I settled on Jupiter predominantly for one reason: its Great Red Spot. The giant anticyclonic storm has always been one of my favourite things and continues to be a subject of great fascination for me. At thrice the size of the Earth it’s bewildering to comprehend the actual magnitude of it. If I absolutely have to choose a favourite planet, it’s got to Jupiter for that storm alone. It’s also so iconic. It’s a characteristic feature almost everyone is familiar with, making it easier to create something that would be instantly recognisable.</p>
<p>The red spot is one of a number of storms you can see all over Jupiter. Some of them last hours, others last for centuries. The red spot had been around since the early 1800s, and it’s possible that it may remain as a permanent feature of the planet. It would be fascinating to see Jupiter if the storm did in fact die out, or if another large one were to appear. The smaller white storms are made up of cool clouds in the upper atmosphere, whereas the brown dots are composed of warmer clouds in the lower atmosphere.</p>
<p><a href="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake02.jpg"><img data-attachment-id="857" data-permalink="https://cakecrumbs.me/2013/07/24/jupiter-structural-layer-cake/ccjupitercake02/#main" data-orig-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake02.jpg" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS 600D&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1374607918&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;39&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.25&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Cakecrumbs’ Jupiter Structural Layer Cake" data-image-description="" data-medium-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake02.jpg?w=300" data-large-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake02.jpg?w=500" alt="Cakecrumbs' Jupiter Structural Layer Cake" src="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake02.jpg?w=640" srcset="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake02.jpg 500w, https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake02.jpg?w=150 150w, https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake02.jpg?w=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>I detailed the atmosphere of Jupiter by covering the cake with ivory marshmallow fondant, then dry brushing a combination of ivory, brown and maroon edible ink. The top ended up being a bit more saturated as I was largely experimenting with colours at that point and was throwing in a bit of yellow. I ended up sticking mostly with ivory and adding extra detail with the brown. Once all the base colours were down I started removing colour to create the storms or other distinguishing features and topping it off with highlights. The whole process took about 8 hours with teeny tiny brushes.</p>
<p><a href="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake03.jpg"><img data-attachment-id="858" data-permalink="https://cakecrumbs.me/2013/07/24/jupiter-structural-layer-cake/ccjupitercake03/#main" data-orig-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake03.jpg" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS 600D&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1374607652&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;34&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.25&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Cakecrumbs’ Jupiter Structural Layer Cake" data-image-description="" data-medium-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake03.jpg?w=300" data-large-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake03.jpg?w=500" alt="Cakecrumbs' Jupiter Structural Layer Cake" src="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake03.jpg?w=640" srcset="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake03.jpg 500w, https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake03.jpg?w=150 150w, https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake03.jpg?w=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>Here’s a 360 of the cake:</p>
<p><a href="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake05.jpg"><img loading="lazy" data-attachment-id="860" data-permalink="https://cakecrumbs.me/2013/07/24/jupiter-structural-layer-cake/ccjupitercake05/#main" data-orig-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake05.jpg" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS 600D&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1374607842&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;29&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.25&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Cakecrumbs’ Jupiter Structural Layer Cake" data-image-description="" data-medium-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake05.jpg?w=300" data-large-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake05.jpg?w=500" alt="Cakecrumbs' Jupiter Structural Layer Cake" src="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake05.jpg?w=300&amp;h=300" width="300" height="300" srcset="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake05.jpg?w=300&amp;h=300 300w, https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake05.jpg?w=150&amp;h=150 150w, https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake05.jpg 500w" sizes="(max-width: 300px) 100vw, 300px"></a> <a href="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake06.jpg"><img alt="Cakecrumbs' Jupiter Structural Layer Cake" src="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake06.jpg?w=300&amp;h=300" width="300" height="300"></a></p>
<p><a href="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake07.jpg"><img loading="lazy" data-attachment-id="862" data-permalink="https://cakecrumbs.me/2013/07/24/jupiter-structural-layer-cake/ccjupitercake07/#main" data-orig-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake07.jpg" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS 600D&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1374607842&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;29&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.25&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Cakecrumbs’ Jupiter Structural Layer Cake" data-image-description="" data-medium-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake07.jpg?w=300" data-large-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake07.jpg?w=500" alt="Cakecrumbs' Jupiter Structural Layer Cake" src="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake07.jpg?w=300&amp;h=300" width="300" height="300" srcset="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake07.jpg?w=300&amp;h=300 300w, https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake07.jpg?w=150&amp;h=150 150w, https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake07.jpg 500w" sizes="(max-width: 300px) 100vw, 300px"> </a><a href="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake04.jpg"><img alt="Cakecrumbs' Jupiter Structural Layer Cake" src="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake04.jpg?w=300&amp;h=300" width="300" height="300"></a></p>
<p>It was kind of difficult to get good reference shots of the non-red-spot sides of Jupiter, particularly to get consistent ones. They were all taken over many different years and influenced by many different weather events so there was lots of variation. But I got enough to get a rough guestimate of the more static features of Jupiter’s atmosphere. The rest I’ll just claim as artistic license.</p>
<p>Finally came time to cut the cake and see how there spheres lined up inside. It turned out better matched than I’d anticipated.</p>
<p><a href="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake08.jpg"><img data-attachment-id="863" data-permalink="https://cakecrumbs.me/2013/07/24/jupiter-structural-layer-cake/ccjupitercake08/#main" data-orig-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake08.jpg" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS 600D&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1374609123&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;24&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.6&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Cakecrumbs’ Jupiter Structural Layer Cake" data-image-description="" data-medium-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake08.jpg?w=300" data-large-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake08.jpg?w=500" alt="Cakecrumbs' Jupiter Structural Layer Cake" src="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake08.jpg?w=640" srcset="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake08.jpg 500w, https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake08.jpg?w=150 150w, https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake08.jpg?w=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>When my sister asked me what I was making and I said Jupiter, she said to me, “I didn’t even know Jupiter had layers.” It’s amazing how much we can forget after learning it in primary school. So here’s a rehashing for those of you who’ve also forgotten. Our knowledge is mostly theoretical of course, but the gas giants are thought to have a core comprised mostly of rock and ice. This is surrounded by a layer liquid metallic hydrogen, and the outer layer is composed of molecular hydrogen. *cake is totally not to scale</p>
<p><a href="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake09.jpg"><img data-attachment-id="864" data-permalink="https://cakecrumbs.me/2013/07/24/jupiter-structural-layer-cake/ccjupitercake09/#main" data-orig-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake09.jpg" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS 600D&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1374608756&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;25&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;1&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Cakecrumbs’ Jupiter Structural Layer Cake" data-image-description="" data-medium-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake09.jpg?w=300" data-large-file="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake09.jpg?w=500" alt="Cakecrumbs' Jupiter Structural Layer Cake" src="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake09.jpg?w=640" srcset="https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake09.jpg 500w, https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake09.jpg?w=150 150w, https://bakecrumbs.files.wordpress.com/2013/07/ccjupitercake09.jpg?w=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>In cake speak, this translates to a core made of mudcake, surrounded by almond butter cake, surrounded by a tinted vanilla Madeira sponge. There’s a crumb coat of vanilla buttercream underneath the fondant.</p>
<p>This run went so much better than the first, informed by the mistakes and lessons learned in the mean time. So I feel much safer sharing the process with you guys now. Stay tuned for that later this week if all goes to plan.</p>
<p><strong>ETA: Tutorial is now <a href="https://cakecrumbs.me/2013/08/01/spherical-concentric-layer-cake-tutorial/">here</a>. </strong></p>
			
			
						</div></div>]]>
            </description>
            <link>https://cakecrumbs.me/2013/07/24/jupiter-structural-layer-cake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25878721</guid>
            <pubDate>Sat, 23 Jan 2021 01:48:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Primer on How to Work with the Usenet Community (1984)]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25878578">thread link</a>) | @nkurz
<br/>
January 22, 2021 | https://www.krsaborio.net/internet/research/1984/0603.htm | <a href="https://web.archive.org/web/*/https://www.krsaborio.net/internet/research/1984/0603.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.krsaborio.net/internet/research/1984/0603.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25878578</guid>
            <pubDate>Sat, 23 Jan 2021 01:20:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Role of Discomfort in Decision Making]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25878526">thread link</a>) | @ruborcalor
<br/>
January 22, 2021 | https://colekillian.com/posts/discomfort/ | <a href="https://web.archive.org/web/*/https://colekillian.com/posts/discomfort/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<p>Discomfort, a slight physical or emotional pain, developed as an evolutionary necessity; historically, considering the unpleasantness of discomfort during decision making was for the best of the species. Berries make your stomach uneasy? Stop eating them. Prickly bush scratches your skin? Don’t let it happen again.</p>
<p>On average your body does a good job correlating discomfort with actions that are bad for your well being, but it’s important to note that your body isn’t right 100% of the time!</p>
<p>The world has changed a lot since we developed the capacity to feel discomfort. I claim that people would be better off if they were to diminish or even eliminate the role that discomfort plays in the decision making process, opting instead for considering “long term” consequences. At least personally, this mentality shift has had a huge positive impact on my day to day life.</p>

<p>There are many things that people know they should be doing try to do but can’t do with success:</p>
<ul>
<li>eating healthy</li>
<li>getting 8 hours of sleep a night</li>
<li>exercising regularly</li>
<li>taking cold showers</li>
</ul>
<p>A common reason people don’t commit to these resolutions is that they rationalize them away on the basis of the required discomfort. People don’t want to miss out on the taste of junk food, or deal with the pain of a work out. After removing discomfort, the only reason left not to do build these healthy habits would be the cost of time, but even the busiest people can carve out a little bit of time for these activities that have much higher returns than the time investment (yes even you!).</p>

<p>Since the new year I have started every morning with a 20 minute workout. My workout consists of handstand pushups, pullups, hanging leg raises, and stretching. By framing the workout as having a cost of 20 minutes and forgetting about the discomfort I will experience during the workout, I am having an easier time maintaining the habit (knock on wood). It takes just 20 minutes and leaves me feeling energized for the rest of the day.</p>
<p>After my workout I hop into a cold shower. Similarly, I dispell thoughts relating to the discomfort of the cold water, and instead phrase the cold shower as a healthy experience that will take just 5 minutes. I wake right up and feel warm as soon as I get out of the cold.</p>

<p>The previous examples were activites of relatively minor discomfort that have compounding positive effects when incorporating them into daily life. Another benefit of making them ritual is to prepare you for dire needs which may include:</p>
<ul>
<li>a necessary confrontation</li>
<li>asking someone out</li>
<li>asking for a raise</li>
<li>building moral courage</li>
<li>generally getting out of one’s comfort zone</li>
</ul>
<p>These are the types of scenarios where people often regret not stepping out of their comfort zones; by building a tolerance for discomfort you will more easily take them on.</p>
<blockquote>
<p>Keep the faculty of effort alive in you by a little gratuitous exercise every day. Do every day or two something for no other reason than that you would rather not do it, so that when the hour of dire needs draws nigh, it may find you not unnerved and untrained to stand the test - The Way To Willpower</p>
</blockquote>

<p>I hope that this mentality shift is as helpful to you as it was to me. Please leave any comments or reflections below :)</p>
</div></div>]]>
            </description>
            <link>https://colekillian.com/posts/discomfort/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25878526</guid>
            <pubDate>Sat, 23 Jan 2021 01:13:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CSRF Protection in Plug and Phoenix]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25878449">thread link</a>) | @griffinmb
<br/>
January 22, 2021 | https://gmb.is/csrf-protection-in-plug-and-phoenix.html | <a href="https://web.archive.org/web/*/https://gmb.is/csrf-protection-in-plug-and-phoenix.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   
   <p>When I encounter a new class of vulnerability or attack vector, I typically add a check for it in <a href="https://github.com/nccgroup/sobelow">Sobelow</a>. Occasionally, however, I see an opportunity for these issues to be mitigated at the library level. In these cases, I try to reach out to JosÃ© or Chris to talk through potential solutions.</p>
   <p>For example, I recently ran into the following issue:</p>
   <pre><code>&lt;%= form_for @conn, "https://third-party-site", fn f -&gt; %&gt;
  &lt;%= email_input f, :email %&gt;
  &lt;%= submit "Get notified!" %&gt;
&lt;% end %&gt;</code></pre>
   <p>A developer building SiteA added a form for a third-party service (SiteB), using Phoenixâ€™s built-in <code>form_for</code> function. Because Phoenix forms include a valid CSRF token by default, these tokens were being leaked to the third-party<sup><a href="#g939451-footnote-1-definition" name="g939451-footnote-1-return">1</a></sup>. As a consequence, SiteB could cause a user to perform unwanted actions on SiteA, such as updating their password or deleting their account.</p>
   <p>This is the problem we were aiming to fix. But before getting to our solution, I want to flesh out the problem a little bit. Letâ€™s start with an overview of Cross-Site Request Forgery (or CSRF), one of the webâ€™s most common vulnerabilities.</p>
   <h2 id="what-is-csrf">What is CSRF?</h2>
   <p>The basic idea is this: Any website can create a form pointing to any other website. They can also automatically fill out and submit these forms. Because cookies are sent with every request, a CSRF attack allows untrusted applications to cause a userâ€™s browser to submit requests and perform authenticated actions on the userâ€™s behalf. Thankfully, web libraries such as Phoenix and Plug have adopted techniques to mitigate such attacks.</p>
   <p>The most common solution to this problem, and the one taken by Phoenix, is to store a unique, random token in the userâ€™s session. This token is then fetched by the client and sent along with every request. When an application processes the request, the submitted token should match the token stored in the userâ€™s session. This way, a malicious website can only cause a user to make valid requests if they have access to a valid CSRF token.</p>
   <p>Now, this is where our initial issue comes into play. When using form generation for third-party or dynamic endpoints, valid CSRF tokens will be leaked by default, leaving users vulnerable to attack. This is something that an experienced developer will probably catch, but itâ€™s a common enough occurrence that it would be nice if the issue could be addressed.</p>
   <p>So, the core issue is simple: In some cases, valid CSRF tokens are leaked by default. And the desired outcome is clear: Donâ€™t leak valid tokens by default. But, in achieving that solution, there are a few considerations:</p>
   <ol>
    <li>Tokens leaked in this manner shouldnâ€™t be useful to an attacker.</li>
    <li>A solution shouldnâ€™t increase burden on the developer, and it shouldnâ€™t sacrifice performance.</li>
    <li>Tokens should work across domains when desired.</li></ol>
   <h2 id="what-is-the-solution">What is the solution?</h2>
   <p>Ultimately, the solution is actually pretty simple. If the token is being generated for a path, as is typical, then everything stays the same. That is, fetching the CSRF token looks something like this:</p>
   <pre><code>get_csrf_token()</code></pre>
   <p>However, if a token is fetched for a fully qualified host, it looks more like this:</p>
   <pre><code>csrf_token = get_csrf_token()
key = KeyGenerator.generate(secret, csrf_token)
host_token = MessageVerifier.sign(host, key)</code></pre>
   <p>The userâ€™s CSRF token is fetched like normal. However, instead of returning the token directly, the token is used as a â€œsaltâ€� in a key derivation function. This newly derived secret key is then used to sign a message which includes the target host.</p>
   <p>On the receiving end of things, the CSRF tokenâ€™s signature is validated. If the signature verification succeeds, then the host is validated to ensure it matches a set of allowed hosts (or the host header). If either of these checks fails, the request is rejected as fraudulent.</p>
   <p>Letâ€™s look back at the initial problem, this time using our new host tokens.</p>
   <p>A developer building SiteA adds a form for a third-party service (SiteB), using Phoenixâ€™s built-in <code>form_for</code> function. Because Phoenix forms include a CSRF token by default, these tokens will be leaked to the third-party. Fortunately, these are now the signed host tokens. If the malicious site attempts to initiate a CSRF attack, the host signed in the token (SiteB) wonâ€™t match the host being requested (SiteA). As a consequence, SiteBâ€™s attack fails.</p>
   <p>This technique has a few benefits. First, and most importantly, nothing changes in the vast majority of cases. Most forms will continue to include plain, standard CSRF tokens. But now, if CSRF tokens are leaked in the described manner, we are safe from attack. Further, unlike other potential solutions, this solution will still work seamlessly across subdomains and domains the developer controls.</p>
   <p>With this solution, we prevent usable tokens from leaking by default, require no changes from the end-developer, and still allow the same range of functionality.</p>
   <p>These changes are live on Plug 1.5.0 and phoenix_html 2.10.0!</p>
   </div></div>]]>
            </description>
            <link>https://gmb.is/csrf-protection-in-plug-and-phoenix.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25878449</guid>
            <pubDate>Sat, 23 Jan 2021 01:02:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Databricks Raising a Private Round at $27B]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25877748">thread link</a>) | @zuhayeer
<br/>
January 22, 2021 | https://www.newcomer.co/p/sources-databricks-raising-at-27 | <a href="https://web.archive.org/web/*/https://www.newcomer.co/p/sources-databricks-raising-at-27">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Databricks — a data and AI platform — is in talks to raise a private funding round that could value the company at about $27 billion.</p><p>It seems like the private deal is being done by buyside public investors, though I don’t know who is winning out, if it’s been decided, or how much they’re investing.</p><p>I’ve been hearing a lot about Databricks recently. For one, it has a similar investor story to Snowflake, and we saw the appetite on the public stock market for that company. Investors seem to want exposure to horizontal cloud computing companies outside of big tech. I’ve also been deep in the world of Andreessen Horowitz and this is an extremely important company for the portfolio. Andreessen Horowitz led Series A, D, and E rounds, according to Pitchbook. NEA led the Series B and C. </p><p>A spokesperson for Databricks declined to comment.</p><div><p>Mostly I care because it’s a huge frothy-sounding number that no one has reported so far.</p><p>Have a nice weekend. </p></div></div></div>]]>
            </description>
            <link>https://www.newcomer.co/p/sources-databricks-raising-at-27</link>
            <guid isPermaLink="false">hacker-news-small-sites-25877748</guid>
            <pubDate>Fri, 22 Jan 2021 23:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SymQEMU: Compilation-based symbolic execution for binaries]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25877317">thread link</a>) | @homarp
<br/>
January 22, 2021 | http://s3.eurecom.fr/tools/symbolic_execution/symqemu.html | <a href="https://web.archive.org/web/*/http://s3.eurecom.fr/tools/symbolic_execution/symqemu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <blockquote>
    <p>
      SymQEMU: Compilation-based symbolic execution for binaries
    </p>
    
    <em>Proceedings of the Network and Distributed System Symposium (NDSS 2021),
    San Diego, CA, USA</em>
    
    
    <p>
      Symbolic execution is a powerful technique for software analysis and bug
      detection. Compilation-based symbolic execution is a recently proposed
      flavor that has been shown to improve the performance of symbolic
      execution significantly when source code is available. We demonstrate a
      novel technique to enable compilation-based symbolic execution of binaries
      (i.e., without the need for source code). Our system, SymQEMU, builds on
      top of QEMU, modifying the intermediate representation of the target
      program before translating it to the host architecture. This enables
      SymQEMU to compile symbolic-execution capabilities into binaries and reap
      the associated performance benefits while maintaining architecture
      independence.
    </p>
    
    <p>
      We present our approach and implementation, and we show that it
      outperforms the state-of-the-art binary symbolic executors S2E and QSYM
      with statistical significance; on some benchmarks, it even achieves better
      performance than the source-based SymCC. Moreover, our tool has found a
      previously unknown vulnerability in the well-tested libarchive library,
      demonstrating its utility in testing real-world software.
    </p>
  </blockquote>

  <h2 id="intro">Introduction</h2>

  <p>
    SymQEMU is a fast symbolic execution engine for binaries. On this page, we
    provide its source code, the raw results of the experiments described in the
    paper, and instructions how you can replicate those experiments yourself.
  </p>

  <h2>Code</h2>

  <p>
    SymQEMU is available
    on <a href="https://github.com/eurecom-s3/symqemu">GitHub</a>.
  </p>

  <h2>Experiments</h2>

  <p>
    In the paper, we describe three sets of experiments: we first benchmark
    SymQEMU with Google FuzzBench, then we run it on real-world software, and
    finally we perform a benchmark comparison during concolic execution of fixed
    paths. This section describes how to replicate our experiments, and provides
    links to our results.
  </p>

  <ol>
    <li>
      <p>
        FuzzBench (see the <a href="http://s3.eurecom.fr/~seba/2020-05-24-symqemu.zip">report</a>)
      </p>

      <p>
        We will share our integration scripts shortly; they're being cleaned up
        to obtain SymQEMU and its dependencies from the new public repository.
      </p>
    </li>

    <li>
      <p>Real-world software</p>

      <p>
        For the analysis of real-world software we used the same setup as in the
        <a href="http://s3.eurecom.fr/tools/symbolic_execution/symcc.html">evaluation of SymCC</a>. The binaries for SymQEMU,
        QSYM and S2E were plain builds without any instrumentation. SymQEMU was
        run via SymCC's fuzzing helper by prefixing the target command
        with <tt>/path/to/symqemu-x86_64</tt>. For the S2E analysis, we created
        a default project, then enabled the <tt>FunctionModels</tt> plugin and
        activated the option <tt>generateOnStateFork</tt> in
        the <tt>TestCaseGenerator</tt> plugin; coverage was evaluated
        with <tt>afl-showmap</tt> at the end of the analysis, using the same
        AFL-instrumented binaries as with the hybrid fuzzers.
      </p>

      <ul>
          <li>
            OpenJPEG
            (<a href="http://www.s3.eurecom.fr/~seba/symqemu_afl_openjpeg.tar.gz">our
            results</a>), libarchive
            (<a href="http://www.s3.eurecom.fr/~seba/symqemu_afl_libarchive.tar.gz">our
            results</a>), tcpdump
            (<a href="http://www.s3.eurecom.fr/~seba/symqemu_afl_tcpdump.tar.gz">our
            results</a>): please find the details on
            our <a href="http://s3.eurecom.fr/tools/symbolic_execution/symcc.html">SymCC page</a>.
          </li>

          <li>
            <a href="https://www.rarlab.com/download.htm">WinRAR</a>
            (<a href="http://www.s3.eurecom.fr/~seba/symqemu_afl_rar.tar.gz">our
            results</a>): we downloaded version 6.00 for 64-bit Linux.
          </li>
        </ul>
      
    </li>

    <li>
      <p>
        Benchmark experiments
          (<a href="http://www.s3.eurecom.fr/~seba/symqemu_benchmark.tar.gz">our
          results</a>)
      </p>

      <p>
        After the analysis of real-world software described above, we randomly
        collected 1,000 generated test cases per open-source target. We ran
        SymQEMU, QSYM and SymCC on each of those inputs, recording the time
        spent in execution and SMT solving, respectively, as per the logging
        output from the QSYM backend.
      </p>
    </li>
  </ol>

  <h2>Acknowledgements</h2>

  <p>
    This work has been supported partly by the DAPCODS/IOTics ANR 2016 project
    (ANR-16-CE25-0015) and partly by the Defense Advanced Research
    Projects Agency (DARPA) under agreement number FA875019C0003.
  </p>

  <h2>Contact</h2>

  <p>
    Feel free to <a href="http://www.s3.eurecom.fr/~seba/">reach out</a> to us
    if anything is unclear or if you need more information.
  </p>
</div></div>]]>
            </description>
            <link>http://s3.eurecom.fr/tools/symbolic_execution/symqemu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25877317</guid>
            <pubDate>Fri, 22 Jan 2021 22:54:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big Tech Censorship]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25877309">thread link</a>) | @AugusteDupin
<br/>
January 22, 2021 | https://objectivedissent.org/2021/01/22/big-tech-censorship/ | <a href="https://web.archive.org/web/*/https://objectivedissent.org/2021/01/22/big-tech-censorship/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>What Big Tech is doing in deplatforming prominent right-wing figures, based on prodding from certain NGOs and politicians, is in fact censorship, even if Parler Chief Policy Officer <a href="https://en.wikipedia.org/wiki/Amy_Peikoff" target="_blank" rel="noreferrer noopener">Amy Peikoff</a> calls it <a rel="noreferrer noopener" href="https://dontletitgo.com/2021/01/17/section-230-the-third-party-doctrine-and-the-looming-dark-age/" target="_blank">“censorship by proxy”</a>.&nbsp; I have held this position for years.&nbsp; The question is not “Is the government doing this censoring?” The question is, “Are the people who are in effective control of our government doing this censoring using private companies as proxies because there is still a modicum of honesty in the courts when dealing with First Amendment issues that prevents the government (at least for now) from passing anti-hate-speech laws?” &nbsp;</p>



<p>If you look at the <a href="https://www.eff.org/issues/cda230/legislative-history" target="_blank" rel="noreferrer noopener">history</a> of <a href="https://www.law.cornell.edu/uscode/text/47/230" target="_blank" rel="noreferrer noopener">Section 230</a> of the <a href="https://www.congress.gov/104/bills/s314/BILLS-104s314is.pdf" target="_blank" rel="noreferrer noopener">“Communications Decency Act,”</a> what you find is that the congressional intent of the license to remove “objectionable” content while still receiving immunity was to allow, indeed encourage, web sites from removing pornography, nudity, or other prurient content, NOT allowing them to curate speech based on ideas.&nbsp; Why no one has mentioned this in all the discussions astounds me.&nbsp; Why was the “Communications <em>Decency</em> Act” ever passed?&nbsp; To allow for a free flow of information without endless porn spam. (As well as Viagra spam, vituperative name calling, or illegal activity).</p>



<p>Lawyers will tell you that the standard for incitement from <a href="https://caselaw.findlaw.com/us-supreme-court/395/444.html" target="_blank" rel="noreferrer noopener">Brandenburg v. Ohio (1969)</a> is speech that produces or is likely to produce <em>imminent</em> <em>lawless</em> action.&nbsp; The standard for imminence is quite narrow: it means “right now”, not “sometime in the future.”&nbsp; And lawless action means just that, action that is against the law.&nbsp; Advocating, for example, to <a href="https://www.rev.com/blog/transcripts/donald-trump-speech-save-america-rally-transcript-january-6">walk to the Capitol and demonstrate peacefully</a> in favor of a certain political action is neither imminent (it’s a 45-minute walk from the Washington Monument), nor illegal (since permits for the protest were obtained well in advance).&nbsp; It is certainly <em>possible</em> to use social media to plan imminent lawless action, but sifting that signal out of the broad noise of general twitfuckery is impossible for a human, and definitely impossible for a computer.&nbsp; If I sent one of my friends a Facebook message saying “Let’s you and I go attack the Capitol right now!” that might seem like an incitement to imminent lawless action, but then when the investigator discovers that I am an hour away from the Capitol and my correspondent is in another state a thousand miles away, that statement (though stupid) fails the test of imminence, and thus is not legally incitement, even if it is ill-considered.&nbsp; No computer can figure all this out.&nbsp; Thus Big Tech’s AIs are tuned to produce very few false negatives (missing threats) with the obvious consequence of producing an enormous number of false positives (claiming posts are threats that aren’t).&nbsp; <a rel="noreferrer noopener" href="https://www.therichest.com/entertainment/15-famous-ordinary-people-who-got-banned-from-social-media/" target="_blank">Examples of these false positives abound on the internet</a>.</p>



<p>Nevertheless, the real issue is not the AIs (which are admittedly tuned to be stupid), nor the algorithms used, which are destroying these companies’ usefulness and thus profitability all anyway.&nbsp; No, the people being deplatformed are not being deplatformed by AIs, but by human beings.&nbsp; And it is the decisions of the human beings that is at issue, not the stupid decisions of automated systems.&nbsp; <a rel="noreferrer noopener" href="https://theboschfawstinstore.blogspot.com/2019/09/peaceful-death-threats-2.html" target="_blank">There are hundreds of thousands of vile death threats against people every day on Twitter</a>.&nbsp; I personally know an individual who has received such death threats every day, and who himself was banned for the death threats they received, while none of the death-threat senders was banned!&nbsp; This result is not an error.&nbsp; <a rel="noreferrer noopener" href="https://nlpc.org/2020/06/01/antifas-call-to-violence-gets-free-rein-on-twitter-while-trump-is-censored/" target="_blank">Left-wing</a> or <a rel="noreferrer noopener" href="https://twitter.com/khamenei_ir" target="_blank">jihadi</a> terror groups are allowed to use Twitter and Facebook to plan terror attacks, plan riots, intimidate businesses and individuals, and threaten entire nations with annihilation with no consequence whatsoever. &nbsp;[Note that in the last year or so Al Qaeda, Hamas, and some other jihadi groups were <a rel="noreferrer noopener" href="https://www.haaretz.com/twitter-blocks-hamas-hezbollah-accounts-in-israel-under-pressure-1.6240629" target="_blank">removed from Twitter</a> after pressure from Israel, but the <a rel="noreferrer noopener" href="https://twitter.com/ikhwanweb" target="_blank">Muslim Brotherhood</a> and their US <a href="https://twitter.com/ikhwanweb" target="_blank" rel="noreferrer noopener">affiliates</a> and <a href="https://twitter.com/IlhanMN" target="_blank" rel="noreferrer noopener">agents</a> are still on social media.]</p>



<p>We tend to think of the deplatforming crisis as either an issue of free speech (akin to the <a rel="noreferrer noopener" href="https://usconstitution.net/xconst_Am1.html" target="_blank">First Amendment</a>) or <a rel="noreferrer noopener" href="http://www.linfo.org/sherman_txt.html" target="_blank">anti-trust</a> (which it is, more on that later).&nbsp; These are both true enough.&nbsp; But the real crisis is much more akin to the rest of the <a rel="noreferrer noopener" href="https://www.archives.gov/founding-docs/bill-of-rights-transcript" target="_blank">Bill of Rights</a>, rather than the First Amendment.&nbsp; Big Tech companies have the right to search (and read) your private correspondence without your permission, unlike, for example, the Post Office, which has <a rel="noreferrer noopener" href="https://www.quora.com/Can-the-post-office-see-whats-in-my-package" target="_blank">never had this power</a>, and still doesn’t today even though it is technically a “private” company now.&nbsp; People build businesses on these Big Tech platforms, and have such businesses completely taken from them without anything resembling “due process of law”.&nbsp; They are banned.&nbsp; They “appeal.”&nbsp; They receive a form letter within minutes saying their appeal is denied, and there is no one to speak to.&nbsp; The companies’ “terms of service” purport to demand arbitration, but the arbitration process is so <a rel="noreferrer noopener" href="https://www.citizen.org/wp-content/uploads/migration/concepcion-anniversary-justice-denied-report.pdf" target="_blank">skewed in favor of the corporations</a> that it is almost impossible to prevail on the basic tort of <a rel="noreferrer noopener" href="https://tremblylaw.com/tortious-interference-in-business-contracts-and-relationships/" target="_blank">tortious interference in a business relationship</a> (which these Big Tech companies violate routinely and yet are protected by “elected” California judges who are bought and paid for by these same companies).&nbsp; People are banned for t<a rel="noreferrer noopener" href="https://heavy.com/news/2018/12/patreon-sargon-of-akkad-jordan-peterson/" target="_blank">hings they said years ag</a>o, thus not giving them the chance of a “speedy trial” or recognize the legal doctrine behind statutes of limitation.&nbsp; No one is ever allowed to “confront their accusers.”&nbsp; Indeed, given that these deplatformings are almost always driven by NGOs like <a rel="noreferrer noopener" href="https://www.sumofus.org/" target="_blank">SumOfUs</a>, <a rel="noreferrer noopener" href="https://www.hopenothate.org.uk/" target="_blank">Hope Not Hate</a>, the <a rel="noreferrer noopener" href="https://www.splcenter.org/" target="_blank">SPLC</a>, or the <a rel="noreferrer noopener" href="https://www.adl.org/" target="_blank">ADL</a> [some funded to a greater of lesser extent by <a rel="noreferrer noopener" href="https://youtu.be/X9tKvasRO54" target="_blank">George Soros</a> and his <a href="http://themillenniumreport.com/2020/06/organizations-funded-by-george-soros-and-his-open-society-foundations/" target="_blank" rel="noreferrer noopener">Open Society Foundation</a>], they are never even allowed to know who their accusers were!&nbsp; They are not allowed to produce witnesses in their favor, indeed they are not allowed to have any witnesses or even a hearing!&nbsp; Finally, the “punishment” is almost always the “death penalty” for their business with no warning or “strikes” or anything, making the punishment both excessive and cruel.&nbsp; Finally, moving to the business analogue of the <a rel="noreferrer noopener" href="https://www.archives.gov/founding-docs/amendments-11-27" target="_blank">14th Amendment</a>, no one enjoys <a href="https://www.salon.com/2021/01/16/despite-parler-backlash-facebook-played-huge-role-in-fueling-capitol-riot-watchdogs-say/" target="_blank" rel="noreferrer noopener">“equal protection of the laws”</a>.&nbsp; As described earlier, and from your own personal experience you know, that it is the <em>victims</em> that are often punished rather than the violators, if the victims have a certain philosophy and the perpetrators membership in certain <a rel="noreferrer noopener" href="https://blacklivesmatter.com/" target="_blank">favored groups</a>.&nbsp; This is unequivocal. &nbsp;</p>



<p>All of the things in the previous paragraph I lump into the general category of “due process of law.”&nbsp; In these cases of censorship and deplatforming there is no due process of law–<strong><a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=LkON93drONQ" target="_blank">none whatsoever</a></strong>, and it is <em><strong>this</strong></em> lack that dooms any attempt to improve the situation by trying to enforce a commitment to freedom of speech or attempts to make their ridiculously subjective rules more objective.&nbsp; This is true even some of the more free-speech oriented sites, like the recently deplatformed Parler.&nbsp; A site could have completely provably objective rules, like “if you post the n-word, you will be banned.”&nbsp; Seems perfectly objective and straightforward, right?&nbsp; But what will that objective rule matter if it is unequally applied, if as <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=LkON93drONQ" target="_blank">Patreon proved</a>, one group can use it and another group can’t, not in the rules themselves, but in the enforcement.&nbsp; Or if your account is hacked and the hacker posted the offending words (and you can prove it), but there is no ability to have a hearing to present evidence?&nbsp; Yes, free speech is very important, and a culture of free speech (<a rel="noreferrer noopener" href="https://quoteinvestigator.com/2015/06/01/defend-say/" target="_blank">“I disapprove of what you say, but I will defend to the death your right to say it”</a>) is crucially important for a free society, and I applaud all of the new <a href="https://en.wikipedia.org/wiki/Alt-tech" data-type="URL" data-id="https://en.wikipedia.org/wiki/Alt-tech" target="_blank" rel="noreferrer noopener">alt-tech</a> sites for fighting this fight.&nbsp; But that is only 1/3 of the fight.&nbsp; The “due process of law” is the other 2/3 and no one seems to want to address it.&nbsp; Only when the Big Tech firms, like the Post Office, are subject to what is analogous to all the Bill of Rights (as Ayn Rand reminded us, all rights are integrated, and this applies to “civil” rights–process rights–as well as natural rights), we will not have freedom of speech in this country again.</p>



<p>I want to say unequivocally that I reject “regulation” as a solution to this problem.&nbsp; Regulation almost never works as intended since the regulators are immediately subject to <a rel="noreferrer noopener" href="https://www.investopedia.com/terms/r/regulatory-capture.asp" target="_blank">regulatory capture</a> and thus do the bidding of the companies they are supposed to regulate rather than protect the interests of the citizenry.&nbsp; What is needed is federal standing to sue based on breach of contract (that is, these companies do not themselves adhere to their own terms of service, or apply them arbitrarily, capriciously, or discriminatorily), tortious interference in a business relationship, false advertising, and provide the ability to federally enforce state laws that these companies violate with impunity.&nbsp; Federal courts are the appropriate jurisdiction to legally fight these companies’ deceptive business practices, since almost all of their customers live in different states.&nbsp; Similarly, given the corruption of California state courts, only in Federal court can justice be done.&nbsp; This type of case is <em>exactly</em> the original purpose of federal courts.&nbsp; Repealing <a rel="noreferrer noopener" href="https://www.law.cornell.edu/uscode/text/47/230" target="_blank">Section 230</a>, or <a rel="noreferrer noopener" href="https://www.washingtonpost.com/technology/2020/05/28/what-is-section-230/" target="_blank">modifying it</a>, or leaving it be does not address the real problem.&nbsp; Only giving a federal cause of action to consumers to force the companies to abide by their own terms of service equally to all consumers will have any effect.&nbsp; They can then, if they wish, declare themselves partisan organizations who only invite fellow partisans to join, and they can make explicit that anyone who does not agree with whatever the Democratic Party (or the New York Times, or the ADL, or Al Qaeda) is pushing that day–that hour–is not welcome and can be kicked off their platform.&nbsp; This result would be <em>much</em> better than regulation since it would legally force these companies to be <em>honest</em> in their dealings with the public.&nbsp; That’s all any of us have ever wanted.</p>



<p>Finally, the collusion …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://objectivedissent.org/2021/01/22/big-tech-censorship/">https://objectivedissent.org/2021/01/22/big-tech-censorship/</a></em></p>]]>
            </description>
            <link>https://objectivedissent.org/2021/01/22/big-tech-censorship/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25877309</guid>
            <pubDate>Fri, 22 Jan 2021 22:53:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Analog Computer Inside Prime Minister]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25877102">thread link</a>) | @homarp
<br/>
January 22, 2021 | http://www.insidegmt.com/2021/01/the-analog-computer-inside-prime-minister/ | <a href="https://web.archive.org/web/*/http://www.insidegmt.com/2021/01/the-analog-computer-inside-prime-minister/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><img loading="lazy" width="657" height="217" src="http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2.jpg" alt="" srcset="http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2.jpg 657w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2-300x99.jpg 300w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2-518x171.jpg 518w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2-82x27.jpg 82w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner2-600x198.jpg 600w" sizes="(max-width: 657px) 100vw, 657px"></figure></div>



<p><span title="G">G</span>lance at <em>Prime Minister</em>’s game board and player mats, and the first thing you’ll notice are all the numbers. The most important one is 330: the number of seats you need for a majority in the House of Commons. In this article, we’ll take a look at <em>Prime Minister</em>’s numerical side, with a focus on its measurement of public opinion.</p>



<p>At the heart of the game is an analog computer simulating the Victorian-era British political system. It tracks and links about 30 different political factors, including Parliament’s confidence in each player, each party’s popular support in eight key sectors of the electorate, current election projections, the number of government MPs and their “moderate” or “partisan” inclinations, projected votes on the government’s bills, the “uncertainty” factor in elections and Parliamentary votes, and Queen Victoria’s support for different players. By reducing these factors to numerical values and structuring their relationships, this analog computer decides who gets to lead each party, which party controls the government, and what bills the government can pass. Whoever does the best job of manipulating the factors controls the system and gets an edge in the game.</p>



<div><figure><a href="http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1.png"><img loading="lazy" width="977" height="550" src="http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1.png" alt="" srcset="http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1.png 977w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-300x169.png 300w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-768x432.png 768w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-760x428.png 760w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-518x292.png 518w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-82x46.png 82w, http://www.insidegmt.com/wp-content/uploads/2021/01/PM_1-600x338.png 600w" sizes="(max-width: 977px) 100vw, 977px"></a></figure></div>



<p>Here you can see a partial snapshot of <em>Prime Minister</em>’s game board, showing the most detailed part of its analog computer: the eight key sectors of the electorate. They include a mix of geographic, social, and ideological groups: Conservatives, Farmers, the Gentry, Ireland, Liberals, the Middle Class, Scotland, and Workers. You’ll track support for each party in each sector, moving wooden markers up and down the numerical tracks. The side with the blue rosette tracks support for the Conservative Party, and the side with the orange rosette does the same for the Liberal Party. The green circles indicate each party’s starting position in the game’s standard setup. During the game, you’ll encounter icons from bills, events, and actions that tell you when to move the markers up and down a track. By moving a marker up one step, you earn one to three popularity points, depending on the sector and your current position. The popularity points that each party earns in the different sectors are added up, and the total relative point difference between the parties determines projections for the next election.</p>



<p>The eight sectors overlap so that one voter might belong to several different sectors at once. For example, a landowner in Scotland might belong to the Conservatives, Gentry, Farmer, and Scotland sectors. The Conservative Party might win his vote by appealing to his ideological identity as a Conservative, or the Liberal Party might win his vote by appealing to his geographic Scots identity. A sector’s significance in each election varies depending on the parties’ respective strategies. If both parties neglect Farmers, then Farmers will have no significance. But if the Conservative Party maxes out its popularity among Farmers while the Liberal Party earns nothing there, the Farmers sector will weigh heavily in the next election–not only because Farmers prefer the Conservative Party, but because they have been motivated to vote according to their economic interests.</p>



<p>Different sectors have different point spreads, reflecting their importance in the Victorian-era electorate. In this era, most British subjects didn’t have the right to vote, so the point spreads aren’t simply based on population distribution. They’re based on the number of voters and each sector’s overall impact on the election results, factoring in the value of campaign contributions, endorsements, and other means of influence. This is why the Gentry sector has more points than Workers, despite being a much smaller slice of the population.</p>



<p>As the game progresses, parties will reach maximum or minimum values in some sectors. These maximums and minimums affect the game’s strategy and evoke real-life political effects. No matter how strongly Scotland prefers one party over another, Scotland’s impact is limited by the number of voters in Scotland. Once the Conservative Party has maxed out its popularity in Scotland, it can gain nothing more there; it must look for additional points in other sectors while being careful not to rock the boat in Scotland. Conversely, once the Conservative Party has bottomed out in Ireland, it has nothing more to lose there and incurs no further penalty for continuing to neglect the Irish–a circumstance which may become useful. As in real life, the parties and politicians in <em>Prime Minister </em>can’t please everyone all the time. When faced with hard choices, they favor their political patrons and write off sectors that are unimportant to them. If there’s a rail disaster in Scotland, a Conservative Prime Minister (PM) will be forced to deal with it if he wants to retain his party’s support there. But if a problem surfaces in Ireland, the same PM might choose to ignore it and focus on something else, knowing that his party can’t do any worse in Ireland.</p>



<p>In addition to tracking popular support, the sectors also track the public’s mood for partisanship, which in turn can result in “partisan” MPs who support more radical bills. The game board measures public partisanship through “red points” that are printed side-by-side next to the total points for some sectors. Not every sector produces red points. For example, the Middle Class–not known for favoring radicalism–doesn’t generate any red points. At the other end of the spectrum, the ideological sectors (Conservatives and Liberals) produce only red points. Red points are always party-specific. If a sector offers red points, it offers them to one party only. By appealing to Workers, the Liberal Party can earn up to 7 red points, reflecting the support of radical Workers who favor partisan Liberal MPs. The Conservative Party can also earn popularity points in the Workers sector, but can’t earn any red points there because Workers who support the Conservative Party prefer moderate MPs.</p>



<p>Each sector has its own flavor and strategic impact. Both parties are free to pursue popularity in any sector–the Conservative Party may pursue a limited number of points in the Liberals sector, for example–but some sectors have a natural affinity or resistance to a particular party. In pursuing popular support in the different sectors, players have to think not only about the raw number of points they earn, but also the difficulty of holding particular sectors. Scotland has the fewest points, but it’s the most stable sector. Scotland’s interests aren’t directly implicated in the hot-button political issues of the day, so there are no bills that upset the Scots. The Middle Class is equally open to both parties and offers more points than Scotland, but is somewhat harder to hold owing to its more sensitive economic and moral preferences. Players also need to think about maintaining a coherent moderate or partisan strategy. The sectors for Conservatives and Liberals are the richest in points, making them tempting targets early in the game. But appealing to voters’ partisanship results in partisan MPs who favor divisive bills that could come back to haunt you. And if your government is equally split between moderate and partisan MPs, you may have a hard time getting them to agree on legislation.</p>



<p>In standard games, <em>Prime Minister</em>’s framework supports an open-ended format in which players strive to control government, win elections, and pass bills. Different politician abilities and about 200 unique cards ensure that no two games are the same. The same framework also supports specific scenarios that simulate historical problems, like home rule for Ireland or the repeal of the Corn Laws. Automated “Clockwork” politicians can readily function within the game’s system, opening the door to solitaire play.</p>



<p>Players have a wide variety of ways to interact with the game, starting with an action point system that allows you to perform a variable number of actions per turn. Depending on your current player mat and your politician’s fixed abilities, you can campaign to increase your party’s popularity in particular sectors, debate for or against bills, flatter Her Majesty to gain her favor, or influence MPs to make them more moderate or partisan. You can also draw “supporter” cards featuring influential Victorians who perform actions on your behalf. You’ll always have many things to do and not enough action cubes to spend, forcing you to prioritize your actions while anticipating future events. The PM’s response to random events and Parliament’s enactment of important bills have consequences that ripple through the system. The players and parties are in a constant tug of war. Collecting the right supporters, unleashing them at the right moment, and coordinating your actions with other players can help you achieve a breakthrough. But the game is not all about numbers. Relationships between players also factor heavily in the game, particularly in its 3- or 4-player mode. We’ll take a look at the players’ roles and relationships in the next <em>InsideGMT</em> article for <em>Prime Minister</em>.</p>



<hr>



<div><figure><a href="https://www.gmtgames.com/p-906-prime-minister.aspx"><img loading="lazy" width="657" height="217" src="http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3.jpg" alt="" srcset="http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3.jpg 657w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3-300x99.jpg 300w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3-518x171.jpg 518w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3-82x27.jpg 82w, http://www.insidegmt.com/wp-content/uploads/2021/01/PrimeMinister_banner3-600x198.jpg 600w" sizes="(max-width: 657px) 100vw, 657px"></a></figure></div>

	</div></div>]]>
            </description>
            <link>http://www.insidegmt.com/2021/01/the-analog-computer-inside-prime-minister/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25877102</guid>
            <pubDate>Fri, 22 Jan 2021 22:29:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Unplugged 308: The One About GPU Passthrough]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25876995">thread link</a>) | @tambourine_man
<br/>
January 22, 2021 | https://linuxunplugged.com/308 | <a href="https://web.archive.org/web/*/https://linuxunplugged.com/308">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  


<header>
  <div>
    <div>
        <h5>Episode 308</h5>
      

      <div>
          
<div id="fireside-player" data-started="false" data-theme="minimal-dark" data-player-type="embed" data-player-download="https://chtbl.com/track/392D9/aphid.fireside.fm/d/1437767933/f31a453c-fa15-491f-8618-3f71f1d565e5/5f78aaf3-0565-405c-8685-a5c0e56f7843.mp3" data-player-duration="3406" data-player-share="/308" data-player-theme="minimal-dark" data-player-time="0">
  

  <div>
    <p><audio preload="none">
      <source src="https://media.fireside.fm/file/fireside-audio/podcasts/audio/f/f31a453c-fa15-491f-8618-3f71f1d565e5/episodes/5/5f78aaf3-0565-405c-8685-a5c0e56f7843/5f78aaf3-0565-405c-8685-a5c0e56f7843.mp3" type="audio/mpeg">
      Your browser does not support the audio tag.
    </audio></p>

    

    

    

    </div>

  

</div>

      </div>
      <div>
        <div>
          <p>
            <i></i>
            July 2nd, 2019
          </p>
          <p>
            <i></i>
            56 mins 46 secs
          </p>
        </div>
        
      </div>
      <div>
        
        <div>
            <h5>
              Special Guest
            </h5>
            <ul>
                <li>
                  <a title="Alex Kretzschmar" href="https://linuxunplugged.com/guests/alexktz">
                    <img src="https://assets.fireside.fm/file/fireside-images/podcasts/images/f/f31a453c-fa15-491f-8618-3f71f1d565e5/guests/7/7b468271-67fc-4c41-88a7-d883cb0c436d/avatar_small.jpg?v=1">
</a>                </li>
            </ul>
        </div>
      </div>
        <h5>Tags</h5>
        
    </div>
  </div>
</header>

<nav>
  <ul>
      <li><a href="https://linuxunplugged.com/rss"> RSS</a></li>
      <li><a href="https://itunes.apple.com/us/podcast/linux-unplugged-podcast/id687598126"><i></i> Apple Podcasts</a></li>
      <li><a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy5maXJlc2lkZS5mbS9saW51eHVucGx1Z2dlZC9yc3M="><i></i> Google Podcasts</a></li>
      <li><a href="https://playmusic.app.goo.gl/?ibi=com.google.PlayMusic&amp;isi=691797987&amp;ius=googleplaymusic&amp;apn=com.google.android.music&amp;link=https://play.google.com/music/m/I2hmp7hkpuqnu7qnbw5k46ngray?t%3DLINUX_Unplugged%26pcampaignid%3DMKT-na-all-co-pr-mu-pod-16"><i></i> Google Play</a></li>
      <li><a href="https://castbox.fm/channel/LINUX-Unplugged-id2120644?country=us"><i></i> Castbox</a></li>
      <li><a href="https://overcast.fm/itunes687598126/linux-unplugged-podcast"><i></i> Overcast</a></li>
      <li><a href="http://pca.st/itunes/687598126"><i></i> Pocket Casts</a></li>
      <li><a href="https://radiopublic.com/linux-unplugged-G2BldG"><i></i> RadioPublic</a></li>
      <li><a href="https://www.iheart.com/podcast/256-linux-unplugged-31099185/"><i></i> iHeartRadio</a></li>
      <li><a href="https://open.spotify.com/show/7bVFJvj8A2ZuYVs5lS992b"><i></i> Spotify</a></li>
      <li><a href="https://www.stitcher.com/podcast/jupiter-broadcasting/linux-unplugged"><i></i> Stitcher</a></li>
      <li><a href="https://tunein.com/podcasts/Technology-Podcasts/LINUX-Unplugged-p1136199/"><i></i> TuneIn</a></li>
      <li>
    <a href="#share_modal" data-modal=""> Share</a>
  </li>

  </ul>
</nav>


<section>
  <div>
    

    <p>Our crew walks you through their PCI Passthrough setups that let them run Windows, macOS, and distro-hop all from one Linux machine.</p>

<p>Forget multiple partitions, dual booting, and Hackintoshes; you can do it all with Linux and KVM.</p>

<p>Near-native VM performance doesn't have to be painful. You only need a few prerequisites and a little help. </p>


      <p><a target="_blank" rel="payment" href="https://jupitersignal.memberful.com/checkout?plan=52946">Support LINUX Unplugged</a></p>
      <ul>
        <li><a title="Windows VirtIO Drivers" rel="nofollow" href="https://www.linux-kvm.org/page/WindowsGuestDrivers/Download_Drivers">Windows VirtIO Drivers</a> — 64-bit versions of Windows Vista and newer require the drivers to be digitally signed.</li><li><a title="Alex's arch-vfio-ovmf scripts" rel="nofollow" href="https://github.com/IronicBadger/arch-vfio-ovmf">Alex's arch-vfio-ovmf scripts</a> — Arch Linux installation and VFIO setup scripts
</li><li><a title="Looking Glass - Quickstart Guide" rel="nofollow" href="https://looking-glass.hostfission.com/quickstart">Looking Glass - Quickstart Guide</a> — These guides are designed to help you get Looking Glass up and running on an already configured QEMU KVM Virtual Machine that has a VGA PCI Passthrough device. </li><li><a title="duncanthrax/scream" rel="nofollow" href="https://github.com/duncanthrax/scream#using-ivshmem-between-windows-guest-and-linux-host">duncanthrax/scream</a> — Scream is a virtual device driver for Windows that provides a discrete sound device. Audio played through this device is published on your local network as a PCM multicast stream.

</li><li><a title="ACS patch COPR" rel="nofollow" href="https://copr.fedorainfracloud.org/coprs/jlay/kernel-acspatch/">ACS patch COPR</a> — Fedora kernels with add-acs-overrides patch from Arch AUR</li><li><a title="ACS Override Kernel Builds" rel="nofollow" href="https://queuecumber.gitlab.io/linux-acs-override/">ACS Override Kernel Builds</a> — This page contains links to the latest kernel builds with the ACS override patch applied for PCI devices.

</li><li><a title="natalie-/fedora-acs-override" rel="nofollow" href="https://github.com/natalie-/fedora-acs-override">natalie-/fedora-acs-override</a> — Using the ACS override patch for Fedora</li><li><a title="VFIO tips and tricks: IOMMU Groups, inside and out" rel="nofollow" href="https://vfio.blogspot.com/2014/08/iommu-groups-inside-and-out.html">VFIO tips and tricks: IOMMU Groups, inside and out</a> — Sometimes VFIO users are befuddled that they aren't able to separate devices between host and guest or multiple guests due to IOMMU grouping and revert to using legacy KVM device assignment, or as is the case with may VFIO-VGA users, apply the PCIe ACS override patch to avoid the problem. &nbsp;Let's take a moment to look at what this is really doing.
</li><li><a title="&quot;Error 43: Driver failed to load&quot; on Nvidia GPUs passed to Windows VMs" rel="nofollow" href="https://wiki.archlinux.org/index.php/PCI_passthrough_via_OVMF#%22Error_43:_Driver_failed_to_load%22_on_Nvidia_GPUs_passed_to_Windows_VMs">"Error 43: Driver failed to load" on Nvidia GPUs passed to Windows VMs</a> — Since version 337.88, Nvidia drivers on Windows check if an hypervisor is running and fail if it detects one, which results in an Error 43 in the Windows device manager. Starting with QEMU 2.5.0 and libvirt 1.3.3, the vendor_id for the hypervisor can be spoofed, which is enough to fool the Nvidia drivers into loading anyway.</li><li><a title="Mac OS Adds Early Support for VirtIO, Qemu - The Passthrough POST" rel="nofollow" href="https://passthroughpo.st/mac-os-adds-early-support-for-virtio-qemu/">Mac OS Adds Early Support for VirtIO, Qemu - The Passthrough POST</a> — In a new development uncovered by Qemu developer Gerd Hoffmann, Apple has apparently added early support for VirtIO and framebuffer graphics in a later Mac OS Mojave release.
</li><li><a title="New and Improved Mac OS Tutorial, Part 1 (The Basics) - The Passthrough POST" rel="nofollow" href="https://passthroughpo.st/new-and-improved-mac-os-tutorial-part-1-the-basics/">New and Improved Mac OS Tutorial, Part 1 (The Basics) - The Passthrough POST</a> — Due to certain recent developments, It’s become clear to us that it’s necessary to update and improve our OSX VM guide. A lot’s changed since we wrote it, and rolling in those changes will make the process much more user friendly and accessible to newer VFIO users.

</li><li><a title="Mac OS VM Guide Part 2 (GPU Passthrough and Tweaks) - The Passthrough POST" rel="nofollow" href="https://passthroughpo.st/mac-os-vm-guide-part-2-gpu-passthrough-and-tweaks/">Mac OS VM Guide Part 2 (GPU Passthrough and Tweaks) - The Passthrough POST</a> — We’ve made every attempt to make this as straightforward as possible, but there’s a lot more ground to cover here than in the first part of the guide</li><li><a title="UGREEN USB 3.0 Sharing Switch Selector 4 Port 2 Computers Peripheral Switcher Adapter Hub for PC, Printer, Scanner, Mouse, Keyboard with One Button Swapping" rel="nofollow" href="https://www.amazon.com/UGREEN-Selector-Computers-Peripheral-Switcher/dp/B01N6GD9JO/ref=sr_1_3?keywords=usb+switcher&amp;qid=1561573709&amp;s=gateway&amp;sr=8-3">UGREEN USB 3.0 Sharing Switch Selector 4 Port 2 Computers Peripheral Switcher Adapter Hub for PC, Printer, Scanner, Mouse, Keyboard with One Button Swapping</a> — This USB Switch 4 Port device allows up to 2 users to share 4 USB 3.0 peripheral devices, such as printer,scanner,mouse,keyboard or usb disk etc without the need to constantly swap cables or set up complicated network sharing software. It's a great for use at home if you have multiple PCs or Macs.</li><li><a title="How to setup VFIO GPU passthrough using OVMF and KVM on Arch Linux" rel="nofollow" href="https://blog.linuxserver.io/2017/04/28/how-to-setup-vfio-gpu-passthrough-using-ovmf-and-kvm-on-arch-linux/">How to setup VFIO GPU passthrough using OVMF and KVM on Arch Linux</a> — This article will detail the steps required to passthrough your GPU to a guest VM which will in our case be a Windows 10 VM used for gaming. Yes, this is the exact same technology made popular by Linus on his LinusTechTips YouTube channel in the seven gamers, one CPU video.</li><li><a title="Chris' HDMI Monitor 1920x1080 16: 9 LCD Screen" rel="nofollow" href="https://www.amazon.com/gp/product/B0762NKY3D/">Chris' HDMI Monitor 1920x1080 16: 9 LCD Screen</a></li><li><a title="Lenovo G0A10170UL Thunderbolt 3 Graphics Dock" rel="nofollow" href="https://www.amazon.com/Lenovo-G0A10170UL-Thunderbolt-Graphics-Dock/dp/B079JFW3YT">Lenovo G0A10170UL Thunderbolt 3 Graphics Dock</a> — Amplify your ultrabook’s graphics performance with the integrated NVIDIA GeForce GTX 1050 graphics card. </li><li><a title="Mantiz Venus MZ-02 External Graphic Enclosure eGPU" rel="nofollow" href="https://www.amazon.com/gp/product/B0745H6GTX/ref=ppx_yo_dt_b_asin_title_o09_s00?ie=UTF8&amp;psc=1">Mantiz Venus MZ-02 External Graphic Enclosure eGPU</a> — Connects Full High Full Length 120" Width 2.5 PCIE Desktop Power GPU to computer WITH an Intel Certified Thunderbolt 3 port.</li><li><a title="Synergy" rel="nofollow" href="https://symless.com/synergy">Synergy</a> — Synergy is a software download that shares one mouse and one keyboard between multiple computers. Simply move your mouse between your computers effortlessly</li><li><a title="barrier: Open-source KVM software" rel="nofollow" href="https://github.com/debauchee/barrier">barrier: Open-source KVM software</a> — Barrier is KVM software forked from Symless's synergy 1.9 codebase. Synergy was a commercialized reimplementation of the original CosmoSynergy written by Chris Schoeneman.

</li><li><a title="foxlet/macOS-Simple-KVM" rel="nofollow" href="https://github.com/foxlet/macOS-Simple-KVM/">foxlet/macOS-Simple-KVM</a> — Documentation to set up a simple macOS VM in QEMU, accelerated by KVM.

</li>
      </ul>

  </div>

  
</section>


  <nav>
      <a href="https://linuxunplugged.com/307">← Previous episode</a>
      <a href="https://linuxunplugged.com/309">Next episode →</a>
  </nav>
</div></div>]]>
            </description>
            <link>https://linuxunplugged.com/308</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876995</guid>
            <pubDate>Fri, 22 Jan 2021 22:17:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Craft of Experimental Physics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25876989">thread link</a>) | @mdturnerphys
<br/>
January 22, 2021 | http://www.jameshedberg.com/writing/2015/02/01/the-craft-of-experimental-physics.html | <a href="https://web.archive.org/web/*/http://www.jameshedberg.com/writing/2015/02/01/the-craft-of-experimental-physics.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>In the basement of the Argosy Book Store, I found a collection of essays from 1933. The one that prompted the purchase of the book was entitled: The Craft of Experimental Physics, by P.M.S. Blackett. Though written more than 80 years ago, the salient points are just as relevant today. I might go so far as to say it should be required reading for both newcomers to the field, as well as for established lab rats. Aside from a few ‘old fashioned’ tendencies (gender specific pronouns being the most notable) and dated technologies mentioned (a valve is a vacuum tube), the essay should resonate with all who have spent a few years poking around the dark corners of Nature with their fingers. Here are some selected passages. (A link to the whole pdf is below)</p>

<blockquote>
  <p>For the experimental physicist is a Jack-of-All Trades, a versatile but amateur craftsman. He must blow glass and turn metal, though he could not earn his living as a glassblower nor ever be classed as a skilled mechanic; he must carpenter, photograph, wire electric circuits and be a master of gadgets of all kinds; he may find invaluable a training as an engineer and can profit always by utilising his gifts as a mathematician. In such activities will he be engaged for three-quarters of his working day. During the rest, he must be a physicist, that is, he must cultivate an intimacy with the behaviour of the physical world.</p>
</blockquote>

<p>In this opening paragraph, Blackett sums it up perfectly. My days, especially the early ones, in the lab were indeed spent with carpentry, photography (digital of course these days), soldering, and often needing to incorporate a new device (gadget) on the fly, sometime with no manual or instructions to serve as a guide. I myself never had to blow any glass, though friends of mine did, but I sure turned some metal now and then. All the meanwhile, one couldn’t lose sight of the bigger goal — to do some physics.</p>

<div>
<figure>
   <img src="http://www.jameshedberg.com/assets/img/control-station.jpg" alt="control station">
   <figcaption> A lot of gadgets all talking nicely to each other.</figcaption>
</figure>
</div>

<blockquote>
  <p>The experimental physicist must be enough of a theorist to know what experiments are worth doing and enough of a craftsman to be able to do them. He is only preeminent in being able to do both.</p>
</blockquote>

<p>This line captures another aspect well. Not only must we know how to do things, we must at least have a good inclination as to why. Like the famous quote from that dinosaur movie: “…but your scientists were so preoccupied with whether or not they could that they didn’t stop to think if they should.” Of course we weren’t battling over moral dilemmas (that much) but more so over the question of what would we achieve by measuring something. So you can measure the voltage with nanovolt precision – but will it help?</p>

<blockquote>
  <p>Certainly the way of a researcher is hard who does not in some degree delight in handy work for its own sake. However much his theoretical interest may be excited by the problem he is to investigate, he may feel a certain dismay on being assigned a room empty perhaps of all but a table, a blow-pipe and a few tools. Often two years may elapse before definite results come in sight; two years occupied with carpentering, metal work, glassblowing, and the wiring of electric circuits. Even when an apparatus is completed, an endless succession of minor difficulties and mishaps may postpone its successful use. A glass tube may crack overnight, a single hair may short circuit an electrometer, a filament may burn out, or the failing of the water supply may wreck an elaborate apparatus. But almost the worst trials to the experimenters patience are due to leaks, and a considerable portion of his time is often spent in finding them. An experimenter was once heard to complain, I have spent two days in getting the leak in my apparatus so small that it will now take me a week to find it. If the experimenter does not find pleasure in such activities, that is, if he has not in some degree the temperament of the amateur craftsman, much of his work must be a weariness.</p>
</blockquote>

<p>My first day in the lab, in 2005, I painted the floor. It was great. Part of the instrument that I was to work on lay in a coffin-like wooden box, in pieces. Other parts didn’t exists yet. There was pvc pipe to be hung, hundred of meters of wire to direct, and many other tasks that might at first glance seem not very physics related.</p>

<div>
<figure>
   <img src="http://www.jameshedberg.com/assets/img/floor.jpg" alt="the pit">
   <figcaption> The freshly painted concrete pit.</figcaption>
</figure>
</div>

<p>And of course, let’s be humble about the whole thing also:</p>

<blockquote>
  <p>Taken singly, the qualities of hand and mind required to make a good experimental physicist are not rare.</p>
</blockquote>

<p>Indeed. None of us were truly talented craftsmen. I did build a table out of an old crate, and it worked well for years, (it might even still be there) but it would hardly be worthy of a spot on a showroom floor.</p>

<div>
<figure>
   <img src="http://www.jameshedberg.com/assets/img/table.jpg" alt="table">
   <figcaption> The aforementioned table in the upper left portion of the image, along with another fantastic experimentalist.</figcaption>
</figure>
</div>

<p>Nor would most of us have gotten very far in the math olympiads. But, as is pointed out in the subsequent sentence,</p>

<blockquote>
  <p>But the combination of these abilities in one individual with the right temperament to use them to the full is rare.</p>
</blockquote>

<p>it requires more than just steady hands and a way with math to do the physics. It requires a subtle combination of patience, stubbornness, determination, and even some cowboy-esque roping to get the job done.</p>

<p>Blackett then goes on, in such a polite way, to highlight a major issue with experimental physics that persists today: working with the machine shop.</p>

<blockquote>
  <div><p>The rapidity with which an alteration to an apparatus can be carried out is a matter of primary and not of secondary importance. If a days work is required to test out an idea, it may be done; if a weeks work, it may not be done at all. </p><p> So even when professional assistance is available, many experimenters prefer to make their own apparatus, however amateurishly. It is very often so very much quicker. For if the aid of a mechanic is called in, scale drawings will have to be made, and it is often easier to construct a small piece of complicated apparatus than to make a drawing of it</p></div>
</blockquote>

<p>While my PhD was not finished in record time, it would have taken twice as long if every threaded hole had to be formally requested and accompanied by shop drawings. Sure, there were some parts of the apparatus that were well beyond my abilities in the shop, and those we handed over to the highly trained professionals (often aided by computer controlled machining capabilities). But having the ability to simply run over to a drill press and tap a 1/4-20 hole was indispensable. I couldn’t imagine having to ask every time I needed the smallest bit of machining done.</p>

<div>
<figure>
   <img src="http://www.jameshedberg.com/assets/img/measure-hookes-law.jpg" alt="hookes law measurement">
   <figcaption> Here is a measurement to see if the spring constant of a stainless steel bellows would change at very low temperatures.</figcaption>
</figure>
</div>

<p>The middle section of the essay is spent discussing three technologies that were common at the time: the scintillator, amplification (via tubes), and the cloud chamber. Scintillators are still used today to observe radiation. Of course our amplifiers are no longer based on vacuum tubes, but no lab could function without the solid state versions. The cloud chamber has little presence in today’s labs, but the evolution of that technology can be seen in today modern particle detectors.</p>

<p>The third and final section of essay makes some interesting points about how the experimental physicist might, by the very nature of his hands-on approach to the world, be in a good position to understand physics. Essentially, Blackett makes the argument that our intuition gained from a mechanistic interaction with the world might be of some advantage in trying to navigate the abstractions of modern physics. While very much the case for introductory physics topics, I’m not convinced that experience, however measured and probing it may be, with the macroscopic, human scale objects of daily life, can really be a strong source of conceptual foundation for much of what comes out of modern theoretical physics land. Perhaps occasionally, but I usually felt my rootedness in the mechanical world to be a bit of a handicap when exploring the abstract landscape of theory.</p>

<p>The separation between theorist and experimentalist will more than likely be a constant feature of the practice of natural science. There are of course exceptions to be found in the historical record, and in the current era – now and then, some people get really good at both. As is discussed in the essay, the experimentalist most likely has not the time nor the resources to become a fully functional theorist, and the theorists, in general, seem uninterested in arts and crafts. Exactly what leads one towards a particular camp is most likely a factor of both our innate circuitries as well as what filled our days during our youths. I had a neighbor who regularly deposited old stereos and other small appliances on my doorstep when I was young. I would dismantle, and occasionally re-mantle these gifts. There were numerous sets of blocks, legos, logs, and other construction elements in my hands at all time. I’m guessing those sorts of things had something to do with the paths I followed.</p>

<blockquote>
  <p>The experimental physicist is luckier; his legitimate field of activity ranges from carpentering to quantum mechanics; it is his job to make and think, and he can divide his time as he thinks fit between both these pleasurable occupations.</p>
</blockquote>

<p>Exactly.</p>

<div>
<figure>
   <img src="http://www.jameshedberg.com/assets/img/theorist.jpg" alt="hookes law measurement">
   <figcaption> Theorist at work</figcaption>
</figure>
</div>

<p>Here is a link to the <a href="http://jameshedberg.com/assets/docs/TheCraftofExperimentalPhysics-Blackett.pdf">whole pdf</a>. It really is a fantastic read and affirms much of the wonderful aspects of being involved in natural science.</p>

      </div></div>]]>
            </description>
            <link>http://www.jameshedberg.com/writing/2015/02/01/the-craft-of-experimental-physics.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876989</guid>
            <pubDate>Fri, 22 Jan 2021 22:16:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Architecture of My Life]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25876823">thread link</a>) | @drstewart
<br/>
January 22, 2021 | https://blog.nntn.nl/architecture-of-my-life-2021 | <a href="https://web.archive.org/web/*/https://blog.nntn.nl/architecture-of-my-life-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><figure><img src="https://miro.medium.com/max/606/0*BaxS_a-8UWDxksDx" alt="FromÂ&nbsp;XKCD"><figcaption>FromÂ&nbsp;XKCD</figcaption></figure>
<p>This is an updated version of the 2019 post, architecture of my life, which you can find <a href="https://blog.nntn.nl/architecture-of-my-life" target="blank">here</a>.</p>

<p>Automation is something dear to my heart. Like the figure at the top of this post, I am not sure that in the end it will have actually saved me time, but it has given me many opportunities to learn, as trying to build a resilient piece of software with a beautiful architecture, which helps me be more productive is an ever-evolving project, which will keep pushing me to learn more. I hope with this I can inspire you to automate some part of your life.</p>
<p>In this blogpost I will describe the following things:</p>
<ul><li><a href="#the-foundation"><b>The foundation</b></a>:<br>The code my automation is built upon. It will also explain the fundamental ideas behind how I think about automation.</li>
<li><a href="#actions"><b>Actions</b></a><b>:</b><br>An overview of some of the automation I have built. If you're looking for some inspiration to build something yourself, this is the place to go.</li>
<li><a href="#other-software-i-made"><b>Other software</b></a><b>:</b><br>Not everything I built can be run inside the framework I built. I also built some other cool utilities to help me in my every day life.</li></ul>

<p>The core and foundation of my automation is named Atlas. Atlas handles everything to run my automation, from connecting to services to handling errors.</p>
<h2 id="an-action">An Action</h2>
<p>At the core of Atlas is a simple idea: Actions. Anything I might ever want to automate is an action. It will act on my behalf on the online services that I use. Some actions will check for themselves if they need to run (adding a reminder for a sent email). The action can also decide how often it wants to run, from every 15 minutes to once a week. Others I only want to run when I need them to (checking the uptime of my systems). </p>
<p>Some require input to do their job correctly (adding a todo to my todo list). The most complicated actions have some state, as the input they require is more complicated. </p>
<p>To build this state I use a chatbot interface, where I give a command, the system parses my input, updates the state and performs the next step, incrementally building the state until all the necessary properties for the action to complete are in place. This flow is explained in the figure below</p>
<figure><img src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F4c8fca8e-34ca-4d28-aae0-8739d858799a%2FUntitled.png?table=block&amp;id=3589228c-eff7-48d2-96d1-453c772c5623&amp;userId=&amp;cache=v2" alt="Overview of the state"><figcaption>Overview of the state</figcaption></figure>
<p>For example, when I want to add a task to a specific task list, I first write the content of that task, which is added to the state. It replies asking which project I want it to add to with some example task lists. I reply with "Write a blog". In the "Update State" part of the flow, this title of a task list is then internally converted to the internal id of the list. This way, me and anyone else using the system do not need to know the exact internals.</p>
<h2 id="interface">Interface</h2>
<p>Atlas is always part of another project. It is wrapped in Ares, a project that connects Atlas and the Microsoft Bot Framework to make it available as a chatbot, in my case as a Telegram chatbot, where you can ask it to perform the actions. It is also run as an Azure Function, available as a <a href="https://zeus-laurentia.azurewebsites.net/api/run/help" target="blank">web-api</a>. I have used this API to build an iOS shortcut to run Actions from my phone and watch and have created a windows application such that I can run any action from my laptop. The Azure Function also runs on a timer trigger and executes every 15 minutes to execute the relevant actions. </p>

<figure><img src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff3b1e86d-a29f-42cd-a80c-2919f668ba32%2FUntitled.png?table=block&amp;id=cd513ca1-b189-4792-9c94-ea4428a84242&amp;userId=&amp;cache=v2" alt="Telegram chat interface"><figcaption>Telegram chat interface</figcaption></figure>





<h2 id="exceptions">Exceptions</h2>
<p>One of the problems of building your own automation is that things are breaking. Constantly. I am connecting to 17 online services and having 35.000+ lines of code means that it is likely something will break. Most of the errors occur within Actions, as they make the calls to external services and change (and therefore break) most often. To make sure one action does not break the entire system, the actions are run in a try-catch block. </p>
<p>Once an action crashes, automation will start running to handle the crash. Independently running actions will start to send me messages to tell me that it is broken after four failed runs, so that timeouts and other temporary problems donâ€™t bother me. It will also automatically throttle itself, postponing its next run in an exponential way, to make sure it does not break anything and I do not get spammed with messages. </p>
<p>After 10 crashes, my automation will automatically create a GitHub issue with the name of the action that crashes and the stack trace. It will even try to generate a url to line in the code in GitHub link where it believes the issue is originating.</p>
<p>The Telegram chatbot will ask the user after a single crash if it wants to make a GitHub issue, as this is deemed more important.</p>
<p>Now, you have a good overview of the basics, we can discuss the cool parts.</p>

<h2 id="spotify">Spotify</h2>
<p>I like to listen to a lot of music. Last year, I spent 98.960 minutes listening to <a href="https://spotify.com/" target="blank">Spotify</a>, one of the most  popular streaming services out there. To help me get the most out of their service, I have a lot of automation running to help me. </p>
<h3 id="sort-by-loudness">Sort by Loudness</h3>
<p>To aid you in finding new music, Spotify presents you with two auto-generated personalized playlists. AÂ&nbsp;<a href="https://support.spotify.com/us/using_spotify/playlists/discover-weekly/" target="blank">Discover Weekly</a>Â&nbsp;playlist with new music from new artists and aÂ&nbsp;<a href="https://support.spotify.com/us/using_spotify/playlists/release-radar/" target="blank">Release Radar</a>Â&nbsp;playlist which contains music released this week. Both are very nice, but have one problem, they jump from very loud energetic to peaceful piano music. This is very jarring if you are listening. To solve this, I download all songs from the playlist and get the features of the songs. <a href="https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/#audio-features-object" target="blank">These features are provided by Spotify</a> and contain things like energy, danceability, liveness and loudness. I order all songs by loudness and put them in a new playlist for me. This way I can listen to my music from very loud to very peaceful.</p>
<h3 id="personally-generated-playlists">Personally generated playlists</h3>
<p>Once you have features of songs, you can think bigger. Spotify can extract features from all of my saved music. From that you can generate playlists. However to do that, you would need to find the perfect settings to create a nice playlist. For this I created a windows application called Playlister, explained further below. Using Playlister, I have created playlists named Summer, Winter, Piano and Energy. Every week, Atlas downloads all my saved songs from Spotify and runs it through each of the finely tuned filters for my playlists and updates each with new songs Iâ€™ve added and removes songs I no longer like. So if I want to listen to music that gets me hyped, I listen to the Energy playlist, which consists of songs I like that, following my tweaks, can be considered full of energy.</p>
<h3 id="last-4-weeks">Last 4 weeks</h3>
<p>I (used to) spend a lot of time biking and travelling by train. I have a data plan, but don't want to overshoot it. This leads to the fact that I need Spotify to download a lot of music. However, I also have a lot of new music that I want to bring with me. I could download all my music, but my phone does not have enough storage for that. To solve this problem, Atlas will update a playlist every night with all of the songs I added in the last 4 weeks. I then tell Spotify to keep this playlist downloaded at all times. This leads to an almost always updated playlist with my newest songs.</p>
<h3 id="random-songs">Random Songs</h3>
<p>In the previous paragraph I explained that I canâ€™t download every songs to my phone. However, I might want to listen to a random selection of music every once in a while. Music not in one of my automatically generated playlist or in any other list. Furthermore, even if I have internet, I sometimes feel like the shuffle is not completely random. And lastly, it is also sorted by loudness and if I need to concentrate, I can start at loud and end at calm music. To solve these problems, every night Atlas takes all my saved music, picks 50 random songs and adds it to a playlist sorted by loudness, so I can always listen to some random music I like.</p>
<h3 id="full-release-radar">Full Release Radar</h3>
<p>Spotify has a feature called Release Radar, where each week, you can listen to music that came out that week from artists you follow or might find interesting. This is great and Iâ€™ve gotten a lot of new music from it, however it might miss artists that I like and if an artist released an entire album, it will only display one song in the playlist, which I can definitely understand, but I donâ€™t want. So I created an Action on Atlas, which every Friday checks all the artists I follow. If they released any new music in the last week and it puts the songs into a playlist called â€œFull release radarâ€�, so that I do have this overview.<br>As an addition, another action checks if I added music from a new artist and automatically follows them, so this list is constantly expanding.</p>
<h2 id="todoist">Todoist</h2>
<p>Task lists are must for me. I forget a lot of things and task lists enable me to keep track of all the things I need to do. To help me I use <a href="https://todoist.com/" target="blank">Todoist</a>.</p>
<h3 id="temporary-projects">Temporary Projects</h3>
<p>As some might know, every Friday, I try to clean my room. This is very nice, as during the week I donâ€™t have to think about keeping everything clean, as on Friday I will clean it anyways, nor do I have to force it in sometime during the week. Cleaning is something that I have to go through often and has a predetermined list of tasks. Although I try to do it on Friday, it might occur that it happens on another day. To be able to start with all of these tasks on the fly I have an Action which can import a template at any time. The template is written inÂ&nbsp;<a href="https://www.taskpaper.com/" target="blank">TaskPaper</a>, a simplistic way of writing down tasks, to create all projects and tasks. These configuration files are stored in my OneDrive, so I can edit, delete or add any new list at any time or any place.</p>
<h3 id="github-synchronisation">GitHub Synchronisation</h3>
<p>On <a href="https://github.com/" target="blank">GitHub</a>, I currently have 7 repositories where I have issues open that I plan on fixing one day. To keep track of this in one place, I synchronize them to Todoist, where I can see them in a separate project. This is only one way, as I neither want to create issues in Todoist, not be able to complete them. </p>
<h3 id="today-action">Today action</h3>
<p>When doing work from my task list, there are two main categories this work can be divided into: work that needs to be done today and work that you plan on doing today. The first is easily managed in Todoist by due dates. The second is managed by myself with a …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.nntn.nl/architecture-of-my-life-2021">https://blog.nntn.nl/architecture-of-my-life-2021</a></em></p>]]>
            </description>
            <link>https://blog.nntn.nl/architecture-of-my-life-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876823</guid>
            <pubDate>Fri, 22 Jan 2021 22:00:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview with Virologist Christian Drosten]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25876682">thread link</a>) | @Tomte
<br/>
January 22, 2021 | https://www.spiegel.de/international/germany/interview-with-virologist-christian-drosten-i-am-quite-apprehensive-about-what-might-otherwise-happen-in-spring-and-summer-a-f22c0495-5257-426e-bddc-c6082d6434d5 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/germany/interview-with-virologist-christian-drosten-i-am-quite-apprehensive-about-what-might-otherwise-happen-in-spring-and-summer-a-f22c0495-5257-426e-bddc-c6082d6434d5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="">


</section>
<section>
<div>
<figure data-component="Image" data-zoom-id="7d7437b1-f37f-45af-b101-2aaf3e2da486" data-settings="{&quot;id&quot;:&quot;24e27727-88e6-406c-9b86-4f907da0941b&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;7d7437b1-f37f-45af-b101-2aaf3e2da486&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/24e27727-88e6-406c-9b86-4f907da0941b_w948_r1.77_fpx66_fpy45_fd50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/24e27727-88e6-406c-9b86-4f907da0941b_w520_r1.77_fpx66_fpy45_fd50.jpg 520w, https://cdn.prod.www.spiegel.de/images/24e27727-88e6-406c-9b86-4f907da0941b_w948_r1.77_fpx66_fpy45_fd50.jpg 948w" width="948" height="536" sizes="948px" title="Christian Drosten on the grounds of Charité Universtiy Hospital in Berlin" alt="Christian Drosten on the grounds of Charité Universtiy Hospital in Berlin">
</span>
</span>
</span>

</p>
<figcaption>
<p>Christian Drosten on the grounds of Charité Universtiy Hospital in Berlin</p>
<span>
Foto: <p>Julia Steinigeweg&nbsp;/ DER SPIEGEL</p>
</span>
</figcaption>
</figure>
</div><div>
<p><strong>DER SPIEGEL:</strong> Professor Drosten, the pandemic has entered a decisive phase. The beginning of the vaccination campaign has meant light at the end of the tunnel, but now, more contagious virus variants have appeared. How dangerous is the situation in Germany at the moment?</p>


<p><strong>Drosten:</strong> I am, of course, closely monitoring the situation. Politicians are also acutely aware that we have to be careful. Early on, I admit that I had my doubts as to whether B.1.1.7, the new variant from Britain, was as much more contagious as people were claiming. But now, there is a new study from Oxford, really solid data, showing that this mutation is up to 35 percent more contagious than the wild-type virus. It is rather astonishing that the virus has boosted its infectiousness to that degree. That is, unfortunately, more dangerous than if it had become more deadly – because every new case will infect more people, and each of them will infect more people, such that the number of cases will grow exponentially.</p>

<p><strong>DER SPIEGEL:</strong> On Monday evening, you were part of the group of experts advising Chancellor Angela Merkel and the governors of Germany's 16 states. What recommendations did you make?</p>
<p><strong>Drosten:</strong> Right now, I am most concerned about the British variant, primarily because of our geographical proximity to the UK. According to the facts we currently have, B.1.1.7 has just started spreading in Germany. I think we have the singular opportunity to prevent, or at least significantly slow, the advance of this variant. With B.1.1.7, there could be a kind of threshold effect. If we are able to keep the new variant below a critical benchmark, we would at least have hope that it wouldn't spread as quickly here.</p>

<div>
<p><strong>DER SPIEGEL:</strong> Are the measures decreed on Tuesday sufficient?</p><p><strong>Drosten:</strong> In the negotiations, I think there was an effort made to find the gaps, the places where not enough has thus far been undertaken to stop the spread. It's clear that it was a struggle and that the results are a compromise. Some areas appear particularly important to me. Schools and daycare centers, for one, particularly the classes in secondary schools. England has closed such schools, with the exception of children of critical workers, and I think that is also where the most reliable data is to be found. For me, this is unequivocal, and Germany should use it as an orientation.</p>
</div>


<div>
<p><strong>DER SPIEGEL:</strong> What about the measures pertaining to working from home?</p><p><strong>Drosten:</strong> More could certainly have been done on that issue. It would have been good to take inspiration from the Irish experience in the autumn. Ireland introduced strict measures regarding working from home, and it was apparently quite effective. Doing so automatically reduces public transport occupancy. There is also a third aspect where improvements are necessary, something the British are doing: Targeted contact and support for the socially disadvantaged and groups that are difficult to reach in the pandemic. Here, the virus frequently spreads explosively, because many people live in close quarters and have jobs that don't allow them to work from home. Many perhaps don't fully understand the problem presented by confined spaces. I think there is still a lot to do here.</p><p><strong>DER SPIEGEL:</strong> You've come up with an image to illustrate our current situation in the pandemic: We are in a rickety truck that is driving down a steep mountainside ...</p><p><strong>Drosten:</strong> ... and we don't know what curves are coming up and whether the road is suddenly about to get steeper. We also don't know how far we still have to go, but we do know that we absolutely have to avoid missing a corner. In a situation like this, closing our eyes doesn't help. We have to keep going and do one thing in particular: Hit the brakes, even if they might be rusty.</p><p><strong>DER SPIEGEL:</strong> What do you mean by that?</p><p><strong>Drosten:</strong> That means, we have to lower the reproduction number R.</p><p><strong>DER SPIEGEL:</strong> The value that tells us the average number of people an infected person passes the virus to.</p><p><strong>Drosten:</strong> Precisely. Currently, that number is at 0.9. It is great that we have finally managed to push it back down below 1, so that the number of cases can begin to drop. But 0.9 isn't enough if we want to quickly loosen the brakes. With an R of 0.9, it takes about a month to reduce the number of infections by half. That is too long. We should try, through an intensification of the shutdown, to get the number down to 0.7. Then, the case numbers will drop by half in just a week, and we can get to a point where we can stop the spread of B.1.1.7 or at least give ourselves a head start.</p>
</div>

<section data-area="contentbox">

</section>
<div>
<p><strong>DER SPIEGEL:</strong> Do you think that the so-called Zero-COVID strategy, the goal of sinking the number of new infections to zero, is the right way forward?</p><p><strong>Drosten:</strong> I do think it would be possible with a significant effort. The virus, of course, would continue to flare up, just as we have seen in China and Australia. But it would absolutely be worthwhile to at least identify zero new infections as a target. Primarily because I am quite apprehensive about what might otherwise happen in the spring and summer.</p><p><strong>DER SPIEGEL:</strong> What do you mean?</p><p><strong>Drosten:</strong> Once the elderly and maybe part of the risk groups have been vaccinated, there will be immense economic, social, political and perhaps also legal pressure to end the corona measures. And then, huge numbers of people will become infected within just a short amount of time, more than we can even imagine at the moment. We won't have 20,000 or 30,000 new cases a day, but up to 100,000 in a worst-case scenario. It will, of course, be primarily younger people who are less likely than older people to have severe symptoms, but when a huge number of younger people get infected, then the intensive care units will fill up anyway and a lot of people will die. Just that it will be younger people. We can cushion this terrible scenario somewhat by pushing the numbers way down now.</p><p><strong>DER SPIEGEL:</strong> Can we be confident that case numbers will begin to drop in spring as temperatures rise?</p><p><strong>Drosten:</strong> I don't think so. The fact that we had such a relaxed summer in 2020 likely had to do with the fact that our case numbers remained below a critical threshold in the spring. But that's not the case any longer. I am afraid that it will be more like in Spain, where case numbers climbed rapidly again after the lockdown was lifted, even though it was quite hot. In South Africa, too, where it is currently summer, case numbers are at a high level. (<em>Sinks into thought, saying nothing</em>) I'm sorry, unfortunately I'm extremely tired.</p><p><strong>DER SPIEGEL:</strong> Because you were advising politicians deep into the night?</p>
</div>
<div>
<p><strong>Drosten:</strong> (<em>laughs</em>) No. Because I worked until 1 a.m. and then woke up this morning at 5:30.</p><p><strong>DER SPIEGEL:</strong> How well are you able to juggle your work with family life?</p><p><strong>Drosten:</strong> I don't really want to talk about my private life. But I do think that it's a problem many families are facing at the moment. The pandemic has found a sore spot. In countries like Germany, where people generally aren't living together with grandma and grandpa, many families find themselves in an extremely difficult situation. I hope that we can learn from this and find new solutions.</p><p><strong>DER SPIEGEL:</strong> Do you still have time for your real work, as a virologist?</p><p><strong>Drosten:</strong> Yes, of course. We are currently taking a closer look at the British variant. We hope to have initial results in a few weeks.</p><p><strong>DER SPIEGEL:</strong> Which of the new mutants do you believe is the most dangerous?</p>
</div>
<figure>
<div data-component="Image" data-zoom-id="f1cdd478-e224-4145-9d49-1bf0993325cf" data-settings="{&quot;id&quot;:&quot;901740b1-c534-4785-b6b3-16ab224c5156&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;f1cdd478-e224-4145-9d49-1bf0993325cf&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w718_r0.75_fpx49.88_fpy37.41.jpg" srcset="https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w488_r0.75_fpx49.88_fpy37.41.jpg 488w, https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w616_r0.75_fpx49.88_fpy37.41.jpg 616w, https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w718_r0.75_fpx49.88_fpy37.41.jpg 718w" width="718" height="957" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w488_r0.75_fpx49.88_fpy37.41.jpg 488w, https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w616_r0.75_fpx49.88_fpy37.41.jpg 616w, https://cdn.prod.www.spiegel.de/images/901740b1-c534-4785-b6b3-16ab224c5156_w718_r0.75_fpx49.88_fpy37.41.jpg 718w" title="Christian Drosten: &quot;I'm sorry, unfortunately I'm extremely tired.&quot;" alt="Christian Drosten: &quot;I'm sorry, unfortunately I'm extremely tired.&quot;">
</span>
</span>
</span>
</p><figcaption>
<p><strong>Christian Drosten:</strong> "I'm sorry, unfortunately I'm extremely tired."</p>
<span>
Foto: Julia Steinigeweg&nbsp;/ DER SPIEGEL
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p><strong>Drosten:</strong> In a population that still isn't immune, like here in Germany, the variant from Britain will likely find success, because it is better at spreading, it is more contagious. The South African and Brazilian variants may be able to infect people who have already had the disease, but that likely doesn't give them an advantage in a population where immunity isn't yet widespread. Which means that the virus will be distributed here and there over the course of the next year, and new variants will surely appear.</p><p><strong>DER SPIEGEL:</strong> What does that mean for the vaccines?</p><p><strong>Drosten:</strong> One of the mutations in the Brazilian and South African variants has already demonstrated a serious immune escape ...</p><p><strong>DER SPIEGEL:</strong> ... which helps the virus evade our immune defenses. Does that mean that the vaccines will be ineffective?</p><p><strong>Drosten:</strong> Antibodies are just one component of immune protection, another is T-cell immunity. That protects much more strongly against a serious progression of the illness. If the virus mutates, it doesn't have an effect on T-cell immunity. As such, I don't think that we have to fear that our vaccines will be ineffective.</p><p><strong>DER SPIEGEL:</strong> When you formulate such assessments, people across Germany are listening, and it often determines public opinion. How well are you able to live with that responsibility?</p><p><strong>Drosten:</strong> It doesn't rob me of sleep. From the very beginning, I hoped that this public role would be shared among several people. And luckily, that is happening.</p>
</div>
<section>

</section>
<div>
<p><strong>DER SPIEGEL:</strong> Last year, experts who have argued time and again against scientifically proven measures – e.g. Jonas Schmidt-Chanasit and Hendrik Streeck – likely did more damage than corona-truthers. Protecting high-risk groups must have priority, you frequently heard from their group. Yet it has long-since been clear that doing so is impossible when case numbers are high. At what point do you lose your patience?</p><p><strong>Drosten:</strong> Are you trying to get me to criticize colleagues by name? I don't think much of personal attacks.</p><p><strong>DER SPIEGEL:</strong> We are more interested in a fundamental point. Many such experts awaken the impression that only opinions are important in science, and not evidence. That undermines the credibility of researchers who take a more serious approach. How do you deal with that?</p><p><strong>Drosten:</strong> Like most …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/germany/interview-with-virologist-christian-drosten-i-am-quite-apprehensive-about-what-might-otherwise-happen-in-spring-and-summer-a-f22c0495-5257-426e-bddc-c6082d6434d5">https://www.spiegel.de/international/germany/interview-with-virologist-christian-drosten-i-am-quite-apprehensive-about-what-might-otherwise-happen-in-spring-and-summer-a-f22c0495-5257-426e-bddc-c6082d6434d5</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/germany/interview-with-virologist-christian-drosten-i-am-quite-apprehensive-about-what-might-otherwise-happen-in-spring-and-summer-a-f22c0495-5257-426e-bddc-c6082d6434d5</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876682</guid>
            <pubDate>Fri, 22 Jan 2021 21:43:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ELM-ART: an interactive and adaptive introduction to Lisp]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25876661">thread link</a>) | @andredz
<br/>
January 22, 2021 | http://art2.ph-freiburg.de/Lisp-Course | <a href="https://web.archive.org/web/*/http://art2.ph-freiburg.de/Lisp-Course">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<a name="top"></a>
<center><table>
<tbody><tr><td rowspan="3">
    <img width="112" height="103" alt="ELM" src="http://art2.ph-freiburg.de/art/elmart112x103.gif"></td>
<td nowrap=""><span size="7">Episodic Learner Model</span></td></tr><tr>
<td nowrap=""></td></tr><tr> 
<td nowrap=""><span size="6">The 
<span color="#cf0000" size="6">A</span>daptive 
<span color="#cf0000" size="6">R</span>emote 
<span color="#cf0000" size="6">T</span>utor</span></td></tr><tr>
</tr></tbody></table></center>
<hr>


<center><span color="#ff00ff"> Important! Use ASCII characters only, no language specific characters!!! </span></center>

<p>"<b>ELM-ART</b>" is an interactive and adaptive introduction to the programming language LISP. 
It can be used for <b>free</b>. You don't have to pay for using ELM-ART.</p>

<a name="hilfe"><center><b><span size="6">Hints</span></b><hr size="1"></center></a>
<a name="name"><h3>Why is registration necessary?</h3></a>
<p>Registration is necessary to identify different users and thereby be able to create personalized 
user models. Those models track interactions and solution attempts and are the bases for offering 
individual advice and guidance through the course.</p>
<p>Please note, that every user name can be used only once. You may get a "Wrong Password" message 
on first login indicating that your name has already been taken by someone else. In this case you 
have to switch to another name.</p>
<a name="pass"><h3>Passwords</h3></a>
<p>Passwords are used for safe identification of users. You can choose your password on your first 
access to ELM-ART freely. It can also be changed later.</p>
<p><b>Important note:</b> As this kind of transfer is not encrypted, you should not use any password 
allowing access to one of your computern accounts.</p>
<hr>
<small>Last update:</small> <i>January 3, 2014</i>
<br>
<i>ELM-ART is a project of   
<a href="http://www.ph-freiburg.de/psychologie/weber.html" target="NEW">Gerhard Weber</a> 
using 
<a href="http://www.cl-http.org:8001/cl-http/" target="NEW">CL-HTTP</a> 
--- [<a href="mailto:weber@ph-freiburg.de" target="_top">Email Feedback</a>]</i><small>

</small></div>]]>
            </description>
            <link>http://art2.ph-freiburg.de/Lisp-Course</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876661</guid>
            <pubDate>Fri, 22 Jan 2021 21:41:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weak Men Are Superweapons (2014)]]>
            </title>
            <description>
<![CDATA[
Score 259 | Comments 162 (<a href="https://news.ycombinator.com/item?id=25876554">thread link</a>) | @skinkestek
<br/>
January 22, 2021 | https://www.slatestarcodexabridged.com/Weak-Men-Are-Superweapons | <a href="https://web.archive.org/web/*/https://www.slatestarcodexabridged.com/Weak-Men-Are-Superweapons">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikitext">

<p><span>May 12, 2014</span>
</p>
<h3>I</h3>
<p>There was an argument on Tumblr which, like so many arguments on Tumblr, was terrible. I will rephrase it just a little to make a point.
</p>
<p>Alice said something along the lines of “I hate people who frivolously diagnose themselves with autism without knowing anything about the disorder. They should stop thinking they’re ‘so speshul’ and go see a competent doctor.”
</p>
<p>Beth answered something along the lines of “I diagnosed myself with autism, but only after a lot of careful research. I don’t have the opportunity to go see a doctor. I think what you’re saying is overly strict and hurtful to many people with autism.”
</p>
<p>Alice then proceeded to tell Beth she disagreed, in that special way only Tumblr users can. I believe the word “cunt” was used.
</p>
<p>I notice two things about the exchange.
</p>
<p>First, why did Beth take the bait? Alice said she hated people who <em>frivolously</em> self-diagnosed <em>without knowing anything about the disorder</em>. Beth clearly was not such a person. Why didn’t she just say “Yes, please continue hating these hypothetical bad people who are not me”?
</p>
<p>Second, why did <em>Alice</em> take the bait? Why didn’t she just say “I think you’ll find I wasn’t talking about you?”
</p>
<h3>II</h3>
<p>One of the cutting-edge advances in fallacy-ology has been the <a href="http://www.scientificamerican.com/article/getting-duped/" rel="nofollow">weak man</a>, a terribly-named cousin of the straw man. The straw man is a terrible argument nobody really holds, which was only invented so your side had something easy to defeat. The weak man is a terrible argument that only a few unrepresentative people hold, which was only <em>brought to prominence</em> so your side had something easy to defeat.
</p>
<p>For example, “I am a proud atheist and I don’t like religion. Think of the terrible things done by religion, like the actions of the Westboro Baptist Church. They try to disturb the funerals of heroes because they think God hates everybody. But this is horrible. Religious people can’t justify why they do things like this. That’s why I’m proud to be an atheist.”
</p>
<p>It’s not a straw man. There really is a Westboro Baptist Church, for some reason. But one still feels like the atheist is making things just a little too easy on himself.
</p>
<p>Maybe the problem is that the atheist is indirectly suggesting that Westboro Baptist Church is typical of religion? An implied falsehood?
</p>
<p>Then suppose the atheist posts on Tumblr: “I hate religious people who are rabidly certain that the world was created in seven days or that all their enemies will burn in Hell, and try to justify it through ‘faith’. You know, the sort of people who think that the Bible has all the answers and who hate anyone who tries to think for themselves.”
</p>
<p>Now there’s practically no implication that these people are typical. So that’s fine, right?
</p>
<p>On the other side of the world, a religious person is writing “I hate atheists who think morality is relative, and that this gives them the right to murder however many people stand between them and a world where no one is allowed to believe in God”.
</p>
<p>Again, not a straw man. The Soviet Union contained several million of these people. But if you’re an atheist, would you just let this pass?
</p>
<p>How about “I hate black thugs who rob people”?
</p>
<p>What are the chances a black guy reads that and says “Well, good thing I’m not a thug who robs people, he’ll probably <em>love</em> me”?
</p>
<h3>III</h3>
<p>What is the problem with statements like this?
</p>
<p>First, they are meant to re-center a category. Remember, people think in terms of categories with central and noncentral members – a sparrow is a central bird, an ostrich a noncentral one. But if you live on the Ostrich World, which is inhabited only by ostriches, emus, and cassowaries, then probably an ostrich seems like a pretty central example of ‘bird’ and the first sparrow you see will be fantastically strange.
</p>
<p>Right now most people’s central examples of religion are probably things like your local neighborhood church. If you’re American, it’s probably a bland Protestant denomination like the Episcopalians or something.
</p>
<p>The guy whose central examples of religion are Pope Francis and the Dalai Lama is probably going to have a different perception of religion than the guy whose central examples are Torquemada and Fred Phelps. If you convert someone from the first kind of person to the second kind of person, you’ve gone most of the way to making them an atheist.
</p>
<p>More important, if you convert a culture from thinking in the first type of way to thinking in the second type of way, then religious people will be unpopular and anyone trying to make a religious argument will have to spend the first five minutes of their speech explaining how they’re not Fred Phelps, honest, and no, they don’t picket any funerals. After all that time spent apologizing and defending themselves and distancing themselves from other religious people, they’re not likely to be able to make a very rousing argument for religion.
</p>
<h3>IV</h3>
<p>In <a href="https://slatestarcodex.com/2014/04/15/the-cowpox-of-doubt/" rel="nofollow">Cowpox of Doubt</a>, I mention the inoculation effect. When people see a terrible argument for an idea get defeated, they are more likely to doubt the idea later on, even if much better arguments show up.
</p>
<p>Put this in the context of people attacking the Westboro Baptist Church. You see the attacker win a big victory over “religion”, broadly defined. Now you are less likely to believe in religion when a much more convincing one comes along.
</p>
<p>I see the same thing in atheists’ odd fascination with creationism. Most of the religious people one encounters are not young-earth creationists. But these people have a dramatic hold on the atheist imagination.
</p>
<p>And I think: well, maybe if people see atheists defeating a terrible argument for religion enough, atheists don’t <em>have to</em> defeat any of the others. People have already been inoculated against religion. “Oh, yeah, that was the thing with the creationism. Doesn’t seem very smart.”
</p>
<p>If this is true, it means that all religious people, like it or not, are in the same boat. An atheist attacking creationism becomes a deadly threat for the average Christian, even if that Christian does not herself believe in creationism.
</p>
<p>Likewise, when a religious person attacks atheists who are moral relativists, or communists, or murderers, then all atheists have to band together to stop it somehow or they will have successfully poisoned people against atheism.
</p>
<h3>V</h3>
<p>This is starting to sound a lot like <a href="http://squid314.livejournal.com/329171.html" rel="nofollow">something I wrote on my old blog about superweapons</a>.
</p>
<p>I suggested imagining yourself in the shoes of a Jew in czarist Russia. The big news story is about a Jewish man who killed a Christian child. As far as you can tell the story is true. It’s just disappointing that everyone who tells it is describing it as “A Jew killed a Christian kid today”. You don’t want to make a big deal over this, because no one is saying anything objectionable like “And so all Jews are evil”. Besides you’d hate to inject identity politics into this obvious tragedy. It just sort of makes you uncomfortable.
</p>
<p>The next day you hear that the local priest is giving a sermon on how the Jews killed Christ. This statement seems historically plausible, and it’s part of the Christian religion, and no one is implying it says anything about the Jews today. You’d hate to be the guy who barges in and tries to tell the Christians what Biblical facts they can and can’t include in their sermons just because they offend you. It would make you an annoying busybody. So again you just get uncomfortable.
</p>
<p>The next day you hear people complain about the greedy Jewish bankers who are ruining the world economy. And really a disproportionate number of bankers are Jewish, and bankers really do seem to be the source of a lot of economic problems. It seems kind of pedantic to interrupt every conversation with “But also some bankers are Christian, or Muslim, and even though a disproportionate number of bankers are Jewish that doesn’t mean the Jewish bankers are disproportionately active in ruining the world economy compared to their numbers.” So again you stay uncomfortable.
</p>
<p>Then the next day you hear people complain about Israeli atrocities in Palestine (what, you thought this was past czarist Russia? This is future czarist Russia, after Putin finally gets the guts to crown himself). You understand that the Israelis really do commit some terrible acts. On the other hand, when people start talking about “Jewish atrocities” and “the need to protect Gentiles from Jewish rapacity” and “laws to stop all this horrible stuff the Jews are doing”, you just feel worried, even though you personally are not doing any horrible stuff and maybe they even have good reasons for phrasing it that way.
</p>
<p>Then the next day you get in a business dispute with your neighbor. Maybe you loaned him some money and he doesn’t feel like paying you back. He tells you you’d better just give up, admit he is in the right, and apologize to him – because if the conflict escalated everyone would take his side because he is a Christian and you are a Jew. And everyone knows that Jews victimize Christians and are basically child-murdering Christ-killing economy-ruining atrocity-committing scum.
</p>
<p>You have been boxed in by a serious of individually harmless but collectively dangerous statements. None of them individually referred to you – you weren’t murdering children or killing Christ or owning a bank. But they ended up getting you in the end anyway.
</p>
<p>Depending on how likely you think this is, this kind of forces Jews together, makes them become strange bedfellows. You might not like what the Jews in Israel are doing in Palestine. But if you think someone’s trying to build a superweapon against you, and you don’t think you can differentiate yourself from the Israelis reliably, it’s in your best interest to defend them anyway.
</p>
<h3>VI</h3>
<p>I wrote the superweapon post to address some of my worries about feminism, so it would not be surprising at all if we found this dynamic there.
</p>
<p>Feminists tend to talk about things like “Men tend to silence women and not respect their opinions” or “Men treat women like objects …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.slatestarcodexabridged.com/Weak-Men-Are-Superweapons">https://www.slatestarcodexabridged.com/Weak-Men-Are-Superweapons</a></em></p>]]>
            </description>
            <link>https://www.slatestarcodexabridged.com/Weak-Men-Are-Superweapons</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876554</guid>
            <pubDate>Fri, 22 Jan 2021 21:26:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tutorial Introduction to the Unix Text Editor by Brian W. Kernighan [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25876312">thread link</a>) | @guerrilla
<br/>
January 22, 2021 | http://www.verticalsysadmin.com/vi/a_tutorial_introduction_to_the_unix_text_editor.pdf | <a href="https://web.archive.org/web/*/http://www.verticalsysadmin.com/vi/a_tutorial_introduction_to_the_unix_text_editor.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.verticalsysadmin.com/vi/a_tutorial_introduction_to_the_unix_text_editor.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876312</guid>
            <pubDate>Fri, 22 Jan 2021 21:02:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why it's bad to have a high GDP]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25876206">thread link</a>) | @wooque
<br/>
January 22, 2021 | https://lukesmith.xyz/articles/gdp | <a href="https://web.archive.org/web/*/https://lukesmith.xyz/articles/gdp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    


    <p>by <a href="https://lukesmith.xyz/index.html">Luke Smith</a>, originally a blog post in November 2018, rewritten for this website.</p>

    <h2>To put it in other words...</h2>

<p>
The common way of looking at Gross Domestic Product (GDP) is that it's a metric of economic success: more GDP is more wealth.
Wealth is good. "Poverty" (meaning low <em>per capita</em> GDP) is bad.
Nowadays, pretty much everyone talks about "economics" like this as if this truism was scribbled on the back walls of the cosmos.
</p>

<p>
This is just looking at one side of the ledger in a kind of global double-entry accounting book.
A logically equivalent way of looking at it is that <strong>GDP is a metric of economic exchange required for survival in society as it exists</strong>.
You can say that some area "produced" $1 billion of output (sounds good), but you can just as easily say that $1 billion was required for that area to sustain itself (sounds bad).
These two are simply logically equivalent.
</p>

<h2>Living on $1 a day</h2>

<figure>
<a href="https://lukesmith.xyz/articles/pix/ivanov01.jpg">
<img alt="Hyperborea" title="(((They))) don't want you to know about this." src="https://lukesmith.xyz/articles/pix/ivanov01s.jpg">
</a>
<figcaption>Antediluvian Hyperborea. GDP: $0 per year.</figcaption>
</figure>

<p>
Let's dive into the Gestalt: when you hear that a family of eight lives on less than a dollar per day (PPP adjusted), you might wonder how they manage!
To <em>actually</em> do such a thing would require buying large bags of rice for the whole family, eat only that and live in free cardboard boxes.
</p>

<p>
The reality is that that often uttered phrase means that they use less than $1 a day in the general economy, while the rest of their livelihood is "off-the-grid" or self-sufficient.
They may grow food in a family farm, hunt for food, and most of their daily needs from cooking oils, to plates, to pottery, to soap are often made at home as well.
</p>

<p>
There is still "an economy" but often one that is barter based or <em>socialist</em> in the real pre-socialist sense of the word: mediated by direct face-to-face social tit-for-tat between neighbors and friends, none of this mediated by currency being exchanged, thus it is not part of the GDP.
</p>

<p>
If you read about some Bangladeshi village where the only product is "textiles", that doesn't mean that everyone there makes textiles all day and, without a textile company, everyone would've starved to death.
It means that the only on-paper, measurable global industry practiced there is textile manufacturing.
Other villagers might farm, hunt, even do some kind of gathering in some places.
They will produce the arts and crafts and live the way people live when you leave them alone.
If your view of the world is mediated by GDP, you're only seeing the extremely small sliver that pops into existence when people exchange something involving legal tender.
</p>

<p>
This is extremely difficult for us modern bugpeople to understand because to be a bugman in a large city is to produce absolutely nothing on one's own and buy literally everything you need from the store.
To us non-productive people, GDP means income which means survival.
But the further out of Bugmanville you go, the clearer the vacuousness of GDP becomes.
When you realize that most of human wealth is unmeasured by GDP, you realize that Whig History and Steven Pinkerism is based on shaky foundations.
</p>

<h2>Example</h2>

<p>
A minor example.
We had a large Thanksgiving feast near my uncle's house in very rural Florida.
As it got cold in the night, we had a fire in a repurposed old sugar cane cooking vat artfully standing on used symmetrical cinderblock pieces.
A bugman hipster might pay two hundred dollars or more for a similar looking "authentic" piece of equipment. Those $200 would be counted in the GDP.
A bugman hipster might have also bought or rented chairs for the event, "contributing" more to the GDP, but my uncle, as part of the local wholesome church community, simply borrowed some from the church.
Thus our event produced basically no GDP output in goods or services, despite being functionally equivalent to some similar but expensive and ergo "productive" "Friendsgiving" practiced by urbanites.
In reality <em>we</em> are richer than the bugmen hipsters who blew hundreds of dollars on a faux-folksy party.
In this case, we owned the firepit and had easy access and permission to the chairs, thus we are more economically flexible than they are.
That GDP that they produced/expended is evidence of deeper reliance on the economic system.
That GDP output is a marker of <em>fragility</em>, reliance on the conditions of the outside economy in the same way that a village of Bangladeshis who abandon their traditional way of lives to work on textiles are more fragile, despite being able to save up for iPhones.
</p>

<h2>What GDP really measures</h2>

<p>
<strong>Most of the increase in GDP across the world is simply the movement from local partially-social partially-under-the-table economies to economies mediated by taxable currency.</strong>
An economically self-sufficient village with close social relationships and a barter economy has 0 GDP.
A township of entrepreneurs and artisans you partially barter and partially use currency which they don't report has 0 GDP.
All of these people are "in poverty" and "earn less than a dollar a day".
And if you want to be truly self-sufficient, that means having a personal GDP of zero.
</p>

<p>
More than that, pretty much everywhere, GDP is a strong indicator of social upheaval.
If you think that GDP is some eternal goodness, remember that <em>everything "good" about industrialization shows up in the GDP</em>, while at the same time, <em>everything bad about it will not show up</em>.
Or, sometimes bad things are registered as positive economic growth: urbanization has caused mass-disease, and if that means a market for new medical services and pharmaceuticals, great!
The GDP just went up!
The Ganges is polluted due to the textile plant? That just means more opportunities for local entrepreneurs to sell bottled water!
The GDP just went up!
Are people being pushed out of fishing or other subsistence occupations because of it? Even better! Now they have no choice but to contribute to the GDP!
With every passing year, in fact, more and more of the GDP is produced by dealing with the problems that our higher level of GDP have caused.
</p>

<p>
At the end of the day, <strong>GDP is only a measurement of how reliant a place or country is on the global economy</strong>.
Self-sufficiency has a GDP of 0.
Wasteful consooomerism has an extremely large GDP.
</p>

<h2>Planned obsolescence</h2>

<p>
I have one of my great grandfather's early electric circular saws.
It has a bunch of gunk in it, but it still works (although I recently took it apart to replace some old screws and springs and other little parts to be careful).
They literally do not make circular saws like it; it's all metal, while even the fancy modern stuff is mostly plastic.
</p><p>
The "unfortunate" thing about it and other durable tools is that it's "bad for the economy," especially the GDP.
Since that thing has been around since maybe the 50's or 60's, that's as long as 70 years the economy has gone without the "stimulation" of us having to buy another saw.
</p>

<p>
Viewers of my technology videos: Which would be better for the world, if everyone used the material equivalent of a classic American-made IBM ThinkPad, or some Apple Laptops that are unfixable computers made of mostly batteries designed to conk out right before the new version comes out?
Regardless, the Apple Macs that cost thousands a piece are much better for the "economy."
</p>

<p>
That's what I mean.
If you have quality tools and do not need to constantly throw money at the system to buy things, fix things and otherwise waste money, you are going to be having a lower GDP.
That's just how it is.
</p>

<h2>The propagandistic role of GDP</h2>

<p>
When you don't think things through like this, GDP is supposed to appear as an objective measure of economic goodness.
You're supposed to be looking at those GDP charts and saying, "Wow, my life might be terrible, I am not free, I am subject to forces out of my control, and I and told I have to participate in mass-consumerism to survive, but these charts are the facts[!], and the facts say that things are better now, so I believe them!"
</p>

<p>
It's legitimately surprising to me how big of a boon the idea of increasing GDP is for Whig history and NPCs of many different ideologies.
People of the Left and Right will matter-of-factly tell me that a plastic based economy taking over the world is still good because the line is going up.
I've heard it as a justification for everything:
</p>


<blockquote>
    Don't like globalization?<br>
    <span>You're wrong, the GDP is going up.</span><br>

    Don't trust state-funded institutionalized science?<br>
    <span>You're wrong, the GDP is going up.</span><br>

    Don't want child drag queens?<br>
    <span>You're wrong, the GDP is going up.</span><br>

    Don't want everything to be made of plastics and other petrochemicals?<br>
    <span>You're wrong, the GDP is going up.</span><br>

    Don't want mass pornography?<br>
    <span>You're wrong, the GDP is going up.</span><br>
    Don't want free sugary drinks since infancy?<br>
    <span>You're wrong, the GDP is going up.</span><br>
</blockquote>

<p>
When you abandon the illusion of GDP, you are suddenly able to ask whether
massive technological "progress" has <em>actually</em> been good for real human
life and human pychology.
</p>

    <hr>

    



</div>]]>
            </description>
            <link>https://lukesmith.xyz/articles/gdp</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876206</guid>
            <pubDate>Fri, 22 Jan 2021 20:51:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cranelift, Part 2: Compiler Efficiency, CFGs, and a Branch Peephole Optimizer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25876199">thread link</a>) | @cfallin
<br/>
January 22, 2021 | https://cfallin.org/blog/2021/01/22/cranelift-isel-2/ | <a href="https://web.archive.org/web/*/https://cfallin.org/blog/2021/01/22/cranelift-isel-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This post is the second in a three-part series about
<a href="https://github.com/bytecodealliance/wasmtime/tree/main/cranelift">Cranelift</a>.
In the <a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">first post</a>, I
described the context around Cranelift and our project to replace its
backend code-generation infrastructure, and detailed the
instruction-selection problem and how we solve it. The remaining two
posts will be deep-dives into some interesting engineering problems.</p>

<p>In this post, I want to dive into the <em>compiler performance</em> aspect of
our work more deeply. (In the next post we’ll explore correctness.)
There are many interesting aspects of compilation speed I could talk
about, but one particularly difficult problem is the handling of
<em>control flow</em>: how do we translate structured control flow at the
Wasm level into control-flow graphs at the IR level, and finally to
branches in a linear stream of instructions at the machine-code level?</p>

<p>Doing this translation efficiently requires careful attention to the
overall pass structure, with the largest wins coming when one can
completely eliminate a category of work. We’ll see this in how we
combine several passes in a traditional lowering design (critical-edge
splitting, block ordering, redundant-block elimination, branch
relaxation, branch target resolution) into <em>inline transforms</em> that
happen during other passes (lowering of the CLIF, or Cranelift IR,
into machine-specific IR; and later, binary emission).</p>

<p>This post basically describes the
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/codegen/src/machinst/buffer.rs"><code>MachBuffer</code></a>,
a “smart machine-code buffer” that knows about branches and edits them
on-the-fly as we emit them, and the
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/codegen/src/machinst/blockorder.rs"><code>BlockLoweringOrder</code></a>,
which allows us to lower code in final basic-block order, with split
critical edges inserted implicitly, by traversing a never-materialized
implicit graph. The work was done mostly in <a href="https://github.com/bytecodealliance/wasmtime/pull/1718">Cranelift PR
#1718</a>, which
resulted in a ~10% compile-time improvement and a ~25%
compile+run-time improvement on a CPU-intensive benchmark (<code>bz2</code>).</p>

<h2 id="control-flow-graphs">Control-Flow Graphs</h2>

<p>Before we discuss any of that, we need to review control-flow graphs
(CFGs)! The CFG is a fundamental data structure used in almost all
modern compilers. In brief, it represents how execution (i.e., program
control) may flow through instructions, using graph nodes to represent
linear sequences of instructions and graph edges to represent all
possible control-flow transfers at branch instructions.</p>

<p>At the end of the instruction selection process, which we learned
about in the <a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">previous post</a>, we have a function body lowered into VCode that consists of
<a href="https://en.wikipedia.org/wiki/Basic_block"><em>basic blocks</em></a>. A basic
block is a contiguous sequence of instructions that has no outbound
branches except at the end, and has no inbound branches except at the
beginning. In other words, it is “straight-line” code: execution
always starts at the top and proceeds to the end. An example
control-flow graph (CFG) consisting of four basic blocks is shown
below:</p>

<p><img src="https://cfallin.org/assets/2020-10-08-cfg-web.svg" alt="Figure: Control-flow graph with four basic blocks in a diamond"></p>

<p>Control-flow graphs are excellent data structures for compilers to
use. By making the flow of execution explicit as graph edges, rather
than reasoning about instructions in order in memory as the processor
sees them, many analyses can be performed more easily. For example,
<a href="https://en.wikipedia.org/wiki/Data-flow_analysis">dataflow analysis</a>
problems can be solved easily because the CFG makes traversal of
possible control-flow transfers easy. Graph-based representations of
the program also allow easier <em>moving and insertion of code</em>: it is
less error-prone to manipulate an explicit graph than to reason about
implicit control-flow (e.g. fallthrough from a not-taken conditional
branch). Finally, the graph representation factors out the question of
<em>block ordering</em>, which can be important for performance; we can
address this problem separately by choosing how we serialize the graph
nodes (blocks). For these reasons, most compiler IRs, including
Cranelift’s CLIF and <code>VCode</code>, are CFG-based.</p>

<p>(Historical note: control-flow graphs were invented by the late
<a href="https://en.wikipedia.org/wiki/Frances_Allen">Frances Allen</a>, who
largely established the algorithmic foundations that modern compilers
use. Her paper <a href="https://www.clear.rice.edu/comp512/Lectures/Papers/1971-allen-catalog.pdf">A catalogue of optimizing
transformations</a><sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>
covers essentially all of the important optimizations used today and
is well worth a read.)</p>

<h2 id="cpus-and-branch-instructions">CPUs and Branch Instructions</h2>

<p>To represent a CFG’s end-of-block branches at the instruction level,
we can use <em>two-way branches</em>: these are instructions that branch
either to one basic-block target if some condition is true, or another
if the condition is false. (Basic blocks can also end in simple
unconditional single-target branches.) We wrote such a branch as <code>if
r0, L1, L2</code> above; this means that the block <code>L0</code> will be followed in
execution either by <code>L1</code> or <code>L2</code>, depending on the value in <code>r0</code>.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<h3 id="branches-with-fallthrough">Branches with Fallthrough</h3>

<p>However, CPUs rarely have such two-way branch instructions. Instead,
conditional control-flow in common ISAs is almost always provided with
a <em>conditional branch with fallthrough</em>. This is an instruction that,
if some condition is true, branches to another location; otherwise,
does nothing, and allows execution to continue sequentially. This is a
better fit for a hardware implementation for a number of reasons: it’s
easier to encode one target than two (the destination of the jump
might be quite far away for some branches, and instructions have
limited bits available), and it’s usually the case that the compiler
can place one of the successor blocks immediately afterward anyway.</p>

<p>Now, this isn’t much of a problem if we just want a working compiler;
instead of a two-way branch</p>



<p>We can write a sequence of branches</p>



<p>where <code>br_if</code> branches to <code>L1</code> or falls through to the unconditional
<code>goto</code>. But this is not so efficient in many cases. Consider what
would happen if we laid out basic blocks in the order <code>L0</code>, <code>L2</code>,
<code>L1</code>, <code>L3</code>:</p>

<div><div><pre><code>    L0:
      ...
      br_if r0, L1
      goto L2
    L2:
      ...
      goto L3
    L1:
      ...
      goto L3
    L3:
      ...
      return
</code></pre></div></div>

<p>There are two redundant unconditional branches (<code>goto</code> instructions),
each of which uselessly branches to the following instruction. We can
remove both of them with no ill effects, taking advantage instead of
<em>fallthrough</em>, or allowing execution to proceed directly from the end
of one block to the start of the next one:</p>

<div><div><pre><code>    L0:
      ...
      br_if r0, L1
      // ** Otherwise, fall through to L2 **
    L2:
      ...
      goto L3
    L1:
      ...
      // ** Always fall through to L3 **
    L3:
      ...
      return
</code></pre></div></div>

<p>This seems like an easy enough problem to solve: we just need to
recognize when a branch is redundant and remove it, right? Well, yes,
but we can do much better than that in some cases; we’ll dig into this
problem in significantly more depth below!</p>

<h3 id="machine-code-encoding-branch-offsets">Machine-code Encoding: Branch Offsets</h3>

<p>So far, we’ve written our machine instructions in a way that humans
can read, using <em>labels</em> to refer to locations in the instruction
stream. At the hardware level, however, these labels do not exist;
instead, the machine code branches contain target <em>addresses</em> (usually
encoded as relative <em>offsets</em> from the branch instruction). In other
words, we do not see <code>goto L3</code>, but rather <code>goto +32</code>.</p>

<p>This gives rise to several complications when emitting machine code
from a list of instruction <code>struct</code>s.  At the most basic level, we
have to resolve labels to offsets and then patch the branches
appropriately. This is analogous to (but at a lower level than) the
job of a <a href="https://en.wikipedia.org/wiki/Linker_(computing)">linker</a>:
we resolve symbols to concrete values after deciding placement, and
then edit the code according to <em>relocations</em> to refer to those
symbols. In other words, whenever we emit a branch, we make a note (a
relocation, or “label use” in our <code>MachBackend</code>) to go back later and
patch it with the resolved label offset.</p>

<p>The second, and more interesting, problem arises because not all
branch instructions can necessarily refer to all possible labels! As a
concrete example, on AArch64, conditional branches have a ±1 MB range,
and unconditional branches have a ±128 MB range. This arises out of
instruction-encoding considerations: particularly in
fixed-instruction-size ISAs (such as ARM, MIPS, and RISC V), less than
a full machine word of bits are available for the immediate jump
offset that is embedded in the instruction word. (The instruction
itself is always a machine-word wide, and we need some bits for the
opcode and condition code too!) On x86, we have limits for a different
reason: the variable-width encoding allows either a one-byte offset
(allowing a ±128 byte range) or four-byte offset (allowing a ±2 GB
range).</p>

<p>To make a branch to a far-off label, then, on some machines we need to
either use a different sort of branch than the default choice for the
instruction selector, or we need to use a form of <em>indirection</em>, by
targetting the original branch to <em>another branch</em>, the latter in a
special form. The former is tricky because we do not know whether a
target will be in-range until all code is lowered and placement is
computed; so we need to either optimistically or pessimistically lower
branches to the shortest or longest form (respectively) and possibly
switch later. To make matters worse, as we edit branches to use a
shorter or longer form, their length may change, moving <em>other</em>
targets into or out of range; in the most general solution, this is a
“fixpoint problem”, where we iterate until no more changes occur.</p>

<h2 id="challenges-in-lowering-cfgs-to-machine-code">Challenges in Lowering CFGs to Machine Code</h2>

<p>So far, we have a way to produce <em>correct</em> machine code. To emit the
final code for a two-target branch, we can emit a conditional-
followed by unconditional-branch machine instruction. To resolve
branch targets correctly, we can assume that any target could be
anywhere in memory, and always use the long form of a branch; then we
just need to come back in one final pass and fill in the offsets when
we know them.</p>

<p>We can do much better than this, though! Below I’ll describe four
problems and the ways that they are traditionally solved.</p>

<h3 id="problem-1-efficient-use-of-fallthroughs">Problem 1: Efficient use of Fallthroughs</h3>

<p>We described above how <em>branch fallthroughs</em> allow us to omit some
some unconditional branches once we know for sure the order that basic
blocks will appear in the final binary. In …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cfallin.org/blog/2021/01/22/cranelift-isel-2/">https://cfallin.org/blog/2021/01/22/cranelift-isel-2/</a></em></p>]]>
            </description>
            <link>https://cfallin.org/blog/2021/01/22/cranelift-isel-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876199</guid>
            <pubDate>Fri, 22 Jan 2021 20:50:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[.NET GC Internals mini-series]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 68 (<a href="https://news.ycombinator.com/item?id=25876087">thread link</a>) | @GordonS
<br/>
January 22, 2021 | https://tooslowexception.com/net-gc-internals-mini-series/ | <a href="https://web.archive.org/web/*/https://tooslowexception.com/net-gc-internals-mini-series/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-625">
	
		
	
	<div itemprop="articleBody">
				<p>I’ve decided to make a series of at least <a href="https://www.youtube.com/playlist?list=PLpUkQYy-K8Y-wYcDgDXKhfs6OT8fFQtVm" target="_blank">8 free weekly-based webinars</a> about<strong> in-depth implementation details of the .NET GC</strong> and… I’m super happy with it! Why the idea? Many <strong>my other activities are about more practical “.NET memory management”</strong>, like <a href="https://prodotnetmemory.com/" target="_blank">my book</a> or <a href="https://workshop.prodotnetmemory.com/" target="_blank">workshops/trainings/consultancy</a> I gave. But during all this practical-oriented events t<strong>here is always not enough time</strong> to explain in details how .NET GC is implemented. Obviously, I always explain some concepts and algorithms, to the level that helps in understanding the whole concept. But not with the level of details that I am satisfied.</p>
<p>Hence the idea – make a separate <strong>content that will be just as deep as I like</strong> 🙂 So, I will cover details on the level of bits, bytes and source code, not only on the level of the overall algorithm description.</p>
<p>The first episode was yesterday, feel invited to watch:</p>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/8i1Nv7wGsjk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe></p>

<p>The topics I’ve covered in the first module:</p>
<ul>
<li>the whole series roadmap</li>
<li>some fundamentals like reference counting (including more modern algorithms) and tracing GC</li>
<li>.NET GC types and its history</li>
<li>first dive into the .NET 5 runtime source code, including the first breakpoints in the famous 40 kLOC gc.cpp</li>
</ul>
<p>And the whole <a href="https://www.youtube.com/playlist?list=PLpUkQYy-K8Y-wYcDgDXKhfs6OT8fFQtVm" target="_blank">playlist is also available on YouTube</a>.</p>
<p>The topics I will cover during the whole series are as follows:</p>
<p><a href="https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02.png"><img src="https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02-1024x535.png" alt="gcwebinar02" width="720" height="376" srcset="https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02-1024x535.png 1024w, https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02-300x157.png 300w, https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02-768x401.png 768w, https://tooslowexception.com/wp-content/uploads/2021/01/gcwebinar02.png 1402w" sizes="(max-width: 720px) 100vw, 720px"></a></p>
<p>And we will see whethere it ends after eight episodes, or maybe a new interesting topics will emerge (including, from your questions).</p>
<p>Have a nice watch!</p>
							</div>
		</article></div>]]>
            </description>
            <link>https://tooslowexception.com/net-gc-internals-mini-series/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25876087</guid>
            <pubDate>Fri, 22 Jan 2021 20:39:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Touchless button that uses motion as feedback]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25875798">thread link</a>) | @giuliomagnifico
<br/>
January 22, 2021 | https://stucklab.com/kinetic-touchless | <a href="https://web.archive.org/web/*/https://stucklab.com/kinetic-touchless">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
	<div id="vbid-b71647ec-lxknncib" data-menu-name="BLOCKS_PREVIEW_BODY">
		<p>With contactless interactions on the rise in the face of COVID-19, most touchless tech tends towards a static sensor with a light or buzz to indicate an activated button, greatly diminishing the push button interaction. On the other hand, <strong>the Kinetic Touchless button uses motion as feedback. </strong><br></p><p>

When used in the context of lift buttons, Kinetic Touchless mirrors your finger movements to recreate the tactile response of pushing a button. As the finger moves towards the button to activate it, as one would a traditional lift button, the Kinetic Touchless button responds with the same motion by sinking inwards before pushing back out, directly mimicking the finger motion. This drastically shifts the image of how touchless tech can be—a tactile button that remains safely contactless.
<br></p><p>
By going beyond the expected feedback of light and sound, Kinetic Touchless provides a surprisingly delightful and yet newly familiar way to interact with contactless technology. <br></p>
	</div>
	
</div></div>]]>
            </description>
            <link>https://stucklab.com/kinetic-touchless</link>
            <guid isPermaLink="false">hacker-news-small-sites-25875798</guid>
            <pubDate>Fri, 22 Jan 2021 20:13:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Game Design Perspective: Stardew Valley (2020)]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25875395">thread link</a>) | @prismatic
<br/>
January 22, 2021 | https://www.pixelatedplaygrounds.com/sidequests/game-design-perspective-stardew-valley | <a href="https://web.archive.org/web/*/https://www.pixelatedplaygrounds.com/sidequests/game-design-perspective-stardew-valley">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5eaf246a2e269141d854b774" data-item-id="5eaf246a2e269141d854b774">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1588538734494" id="item-5eaf246a2e269141d854b774"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1590697859773_10341"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1590697897602-7LZ694GBBP4JE0P38B1I/ke17ZwdGBToddI8pDm48kHhlTY0to_qtyxq77jLiHTtZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7T-j82ScS_xjTqFYGqFrT72qZ_E0ELtHpOZiWcSG1QwIMeEVreGuQ8F95X5MZTW1Jw/Josh_3_larger.png" data-image="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1590697897602-7LZ694GBBP4JE0P38B1I/ke17ZwdGBToddI8pDm48kHhlTY0to_qtyxq77jLiHTtZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7T-j82ScS_xjTqFYGqFrT72qZ_E0ELtHpOZiWcSG1QwIMeEVreGuQ8F95X5MZTW1Jw/Josh_3_larger.png" data-image-dimensions="256x256" data-image-focal-point="0.5,0.5" alt="Josh_3_larger.png" data-load="false" data-image-id="5ed01fa93dbf3e290e8e8e1d" data-type="image" src="https://www.pixelatedplaygrounds.com/sidequests/Josh_3_larger.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1588531737133_62487"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1588536534304-3EQXGULV3LXKOIPXG9OW/ke17ZwdGBToddI8pDm48kNvT88LknE-K9M4pGNO0Iqd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UbeDbaZv1s3QfpIA4TYnL5Qao8BosUKjCVjCf8TKewJIH3bqxw7fF48mhrq5Ulr0Hg/Opening+image.png" data-image="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1588536534304-3EQXGULV3LXKOIPXG9OW/ke17ZwdGBToddI8pDm48kNvT88LknE-K9M4pGNO0Iqd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UbeDbaZv1s3QfpIA4TYnL5Qao8BosUKjCVjCf8TKewJIH3bqxw7fF48mhrq5Ulr0Hg/Opening+image.png" data-image-dimensions="1920x1080" data-image-focal-point="0.5,0.5" alt="Opening image.png" data-load="false" data-image-id="5eaf24d3f79cfb3497c2b4b6" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1588536534304-3EQXGULV3LXKOIPXG9OW/ke17ZwdGBToddI8pDm48kNvT88LknE-K9M4pGNO0Iqd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UbeDbaZv1s3QfpIA4TYnL5Qao8BosUKjCVjCf8TKewJIH3bqxw7fF48mhrq5Ulr0Hg/Opening+image.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-207925de78fae3898061"><div><p>Recently, Juliana has gotten into Stardew Valley. Hard. Since I’m a huge fan myself, I'm doing a Game Design Perspective on the game to celebrate. I'll be looking at the game mechanics and how the interlocking layers make the game tick.</p><p>In Stardew Valley, you play as a disillusioned city slicker who takes over their grandfather's broken-down farm. You clear the land so you can grow crops, a la Harvest Moon. Beyond the basics of farming, the game really shines in its variety. You can go fishing on the beach, delve into a dangerous cave in the mountains, raise livestock, interact with a town full of characters, cook up different dishes, donate buried treasure to the museum, and participate in a number of holiday festivals throughout the year. Juliana's put in maybe forty hours over the past couple weeks, which is about half the time I put in when I played. Clearly, the game has something that makes you want to come back. Let's take a look why.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1588531737133_66246"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1588536578138-IHURW79W6UFT7P1NFI16/ke17ZwdGBToddI8pDm48kNvT88LknE-K9M4pGNO0Iqd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UbeDbaZv1s3QfpIA4TYnL5Qao8BosUKjCVjCf8TKewJIH3bqxw7fF48mhrq5Ulr0Hg/fishing+mushrooms.png" data-image="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1588536578138-IHURW79W6UFT7P1NFI16/ke17ZwdGBToddI8pDm48kNvT88LknE-K9M4pGNO0Iqd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UbeDbaZv1s3QfpIA4TYnL5Qao8BosUKjCVjCf8TKewJIH3bqxw7fF48mhrq5Ulr0Hg/fishing+mushrooms.png" data-image-dimensions="1920x1080" data-image-focal-point="0.5,0.5" alt="fishing mushrooms.png" data-load="false" data-image-id="5eaf24fe2fe3b4136fb14a0a" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1588536578138-IHURW79W6UFT7P1NFI16/ke17ZwdGBToddI8pDm48kNvT88LknE-K9M4pGNO0Iqd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UbeDbaZv1s3QfpIA4TYnL5Qao8BosUKjCVjCf8TKewJIH3bqxw7fF48mhrq5Ulr0Hg/fishing+mushrooms.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1588531737133_69860"><div><p>One of the things Stardew Valley does best is variety, both in the small and in the large. Farming is the most fundamental activity in the game and it's a great example of variety "in the small". You have 44 different crops in the game (not counting fruit trees or mushrooms). Each crop has distinct and visually-appealing pixel artwork that shows the growing plant and the final product. Time passes through the four seasons, and each season has its own soundtrack, background weather effects (snowy forests or flower petals swaying in the breeze), and set of crops. As soon as the player gets used to, say, planting parsnips in the spring, summer arrives and a whole new set of crops becomes available. The player isn't able to keep going in the same routine. That's good for keeping engagement up.</p><p>More so than the sheer quantity of crops (or fish or buried treasure or...), Stardew shines in the number of activities available to you. This is the variety "in the large". There are five major skill tracks - farming, fishing, foraging, fighting, and fmining. Each one has an experience tracker and perks for being more experienced. All tracks except foraging have associated and upgradable equipment.</p><p>A day could be spent gathering wood or stone to upgrade your farm or trying to catch a rare fish in the mountain lake. It could be spent a day going deeper in the monster-infested mines or running errands for the townsfolk. You can forage for wild flowers near the river or decorate your farm. You can skip out on all your responsibilities and do nothing but play video games - just like real life! There's never enough time in a single Stardew day to do everything you want to do. That's a great way to keep players coming back - it gives that "just one more turn" feeling that leads people to play Civilization until dawn.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1588531737133_70445"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1588537010072-CDGU4SWSGBYHRWRUGUQA/ke17ZwdGBToddI8pDm48kNvT88LknE-K9M4pGNO0Iqd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UbeDbaZv1s3QfpIA4TYnL5Qao8BosUKjCVjCf8TKewJIH3bqxw7fF48mhrq5Ulr0Hg/night+market.png" data-image="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1588537010072-CDGU4SWSGBYHRWRUGUQA/ke17ZwdGBToddI8pDm48kNvT88LknE-K9M4pGNO0Iqd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UbeDbaZv1s3QfpIA4TYnL5Qao8BosUKjCVjCf8TKewJIH3bqxw7fF48mhrq5Ulr0Hg/night+market.png" data-image-dimensions="1920x1080" data-image-focal-point="0.5,0.5" alt="night market.png" data-load="false" data-image-id="5eaf26afe42f917ae7242a10" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1588537010072-CDGU4SWSGBYHRWRUGUQA/ke17ZwdGBToddI8pDm48kNvT88LknE-K9M4pGNO0Iqd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UbeDbaZv1s3QfpIA4TYnL5Qao8BosUKjCVjCf8TKewJIH3bqxw7fF48mhrq5Ulr0Hg/night+market.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1588531737133_74362"><p>Of course, it's not enough just to have a whole lot of options. Stardew keeps on chugging by having these different activities overlap with each other and support each other. Performing one activity will provide progress towards another or even unlock new goals for the player. A player could spend the day fishing, perhaps trying to catch the elusive lingcod. They might bring up some sunken treasure chests containing artifacts to donate to the museum. The player will likely catch a few common fish while going after the lingcod - these common fish could be turned into fertilizer to grow better crops. If the player is delving into the mines, they will find the stone to help build a barn. If a player is making friends with the townsfolk, they'll get new crafting recipes to increase their farm's production. Almost every activity in the game will help out another. This keeps the flow of the game smooth, as finishing one activity primes the player for the next one.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1588531737133_74818"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1588537063418-LVETKHBHJKQZTS9R91NT/ke17ZwdGBToddI8pDm48kNvT88LknE-K9M4pGNO0Iqd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USOFn4xF8vTWDNAUBm5ducQhX-V3oVjSmr829Rco4W2Uo49ZdOtO_QXox0_W7i2zEA/fishing.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1588537063418-LVETKHBHJKQZTS9R91NT/ke17ZwdGBToddI8pDm48kNvT88LknE-K9M4pGNO0Iqd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USOFn4xF8vTWDNAUBm5ducQhX-V3oVjSmr829Rco4W2Uo49ZdOtO_QXox0_W7i2zEA/fishing.jpg" data-image-dimensions="1920x1080" data-image-focal-point="0.5,0.5" alt="fishing.jpg" data-load="false" data-image-id="5eaf26e67db95f3c3b31a795" data-type="image" src="https://www.pixelatedplaygrounds.com/sidequests/fishing.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1588531737133_78634"><div><p>I find it useful to think about games in terms of nested reward cycles. A game designer needs to think about feedback, goals, and rewards happening both in repeating cycles and hierarchical layers. What should the player do in the next fifteen seconds? The next five minutes? The next thirty? Mario can provide a quick example - the player can jump on a goomba (pleasant sound effects!), finish a level (look at that flag go!), and rescue the princess (take that, Bowser!).&nbsp; A short-term cycle will happen many times during a medium-term cycle, which in turn repeats itself during the long-term cycles. In Stardew, chopping down a tree nets you wood, which you can use to build yourself a new chicken coop, which you can use to hatch a flock of egg-laying chickens, which you can use to get a mayonnaise factory going, and so on and so forth.</p><p>Stardew adds an effective twist to this idea by delaying rewards. When you first plant a parsnip seed, you won't get to harvest it until a week later. You'll have to spend time each day watering the little guy, and that anticipation makes the eventual pay-off that much sweeter. It uses the delay to good effect in other areas. For instance, when you upgrade your equipment with the town blacksmith, the upgrade doesn't happen instantly. It easily could have happened this way if the game designer wanted it to. Instead, the blacksmith keeps your tool (watering can, pickax, etc.) for a couple of days. If you don't have, say, your pickaxe, then you can't delve into the mines. This forces you to explore other aspects of the game by constraining your available options. Sometimes the game incentivizes different activities with the carrot, and sometimes it uses the stick.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1588531737133_79170"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1588537137709-LSUX0M4BJVIPG9CL48DZ/ke17ZwdGBToddI8pDm48kFTEgwhRQcX9r3XtU0e50sUUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcjVvFZn3_1TpSINbj1p15LLAjcj6UHNkQOuDz3gO52lBvccB2t33iJEaqs_Hdgp_g/bundles.png" data-image="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1588537137709-LSUX0M4BJVIPG9CL48DZ/ke17ZwdGBToddI8pDm48kFTEgwhRQcX9r3XtU0e50sUUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcjVvFZn3_1TpSINbj1p15LLAjcj6UHNkQOuDz3gO52lBvccB2t33iJEaqs_Hdgp_g/bundles.png" data-image-dimensions="1280x720" data-image-focal-point="0.5,0.5" alt="bundles.png" data-load="false" data-image-id="5eaf2730f79cfb3497c33682" data-type="image" src="https://www.pixelatedplaygrounds.com/sidequests/bundles.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1588531737133_83009"><div><p>One of my favorite bits of game design in Stardew are the Bundles. In the community center, you can help the spirits of the forest restore the community by leaving various items as offerings. These offerings are grouped together as a "bundle", and each room in the community center has a set of bundles to complete. You get smaller rewards for finishing individual bundles, like a new scarecrow or a new mayonnaise press. You get larger rewards for finishing off a room's worth of bundles, like a greenhouse that can grow crops in the winter. The Bundles provide the player with a sense of direction in a game that otherwise has few explicit long-term goals. It organizes and focuses the time spent in the game. In fact, I consider the game "beaten" once all the Bundles have been completed.</p><p>As nice as the big "Room" rewards are, the individual "bundle" rewards are worth taking a look at. In true Stardew fashion, there are a whole boatload of different craftable items. The craftables will have different effects on your farm. For example, a mayonnaise press can turn eggs into more valuable mayo, a scarecrow will prevent wild crows from eating your crops, and a beehive will produce honey if it is nearby a flower crop. If you're developing a game and you design an item, the player may or may not end up using it. They might think it won't fit their playstyle or they might not know it's even an option. Stardew gets around this issue by just giving these craftable items to the player, which encourages the player to experiment with it. If the player likes it, they will aim to craft more. If not, the player didn’t have to spend their own resources building the thing.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1588531737133_83636"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1588537365816-4SSS5USWFFFMVO3G8OGM/ke17ZwdGBToddI8pDm48kD33KhhWEodMJvcytjXFyvFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIQVUjsvMYGrjk5P5guv3Gb1aPQrnDLhtGUJ-UJkarKCw/joja.png" data-image="https://images.squarespace-cdn.com/content/v1/5bfa159385ede160a0faea5f/1588537365816-4SSS5USWFFFMVO3G8OGM/ke17ZwdGBToddI8pDm48kD33KhhWEodMJvcytjXFyvFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIQVUjsvMYGrjk5P5guv3Gb1aPQrnDLhtGUJ-UJkarKCw/joja.png" data-image-dimensions="960x540" data-image-focal-point="0.5,0.5" alt="joja.png" data-load="false" data-image-id="5eaf2815437a4e57ef510346" data-type="image" src="https://www.pixelatedplaygrounds.com/sidequests/joja.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1588531737133_87593"><div><p>Long before we started recording and publishing podcasts, Bryan and I did a Video Game Book Club on Stardew Valley. At one point, he mentioned that he wished there was a way to hire someone to milk his cows and goats and didn't have to spend time with them each morning. (Note: Update 1.3 introduced this exact item.) I found his comment hilarious. The game's ostensible narrative is that you quit your soulless job at a MegaCorporation in order to get closer to the land, but after just two years on the farm you want to hire someone to work the land for you. You've become the corporation that you tried to escape from. I waffle back and forth on whether Stardew is pro- or anti-capitalism, but in the meantime I'll be planting some parsnips.<br></p><p><em>Addendum: I’ve recently created a short Stardew-like game as part of something called the Seven Day Roguelike Challenge. It was tons of fun, although the short development time meant that I wasn’t able to hit 100% of the cool Stardew things I mentioned above. You can read about </em><a href="https://www.pixelatedplaygrounds.com/sidequests/gamesmithing-moondrop-mountain-postmortem">my experience developing the game</a><em>, or you can check the game out </em><a href="https://joshuagalecki.itch.io/moondrop-mountain">on itch.io</a></p></div></div></div></div></div>

    

    

    <section id="comments-5eaf246a2e269141d854b774">
      
  


    </section>

  </article>





  <nav>

    
      <a href="https://www.pixelatedplaygrounds.com/sidequests/gamesmithing-follow-your-prototype">
        <svg viewBox="0 0 23 48">
          <g>
            <polyline fill="none" stroke-miterlimit="10" points="21.5,1.3 2.6,23.4 21.5,45.7 "></polyline>
          </g>
        </svg><!--
        --><div>
          <p>Previous</p>
          <h4>Gamesmithing: Follow Your Prototype</h4>
          <div>
       …</div></div></a></nav></section></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pixelatedplaygrounds.com/sidequests/game-design-perspective-stardew-valley">https://www.pixelatedplaygrounds.com/sidequests/game-design-perspective-stardew-valley</a></em></p>]]>
            </description>
            <link>https://www.pixelatedplaygrounds.com/sidequests/game-design-perspective-stardew-valley</link>
            <guid isPermaLink="false">hacker-news-small-sites-25875395</guid>
            <pubDate>Fri, 22 Jan 2021 19:39:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Specs of Popular phones in Africa(NG) 2021]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25875285">thread link</a>) | @anthony_barker
<br/>
January 22, 2021 | https://naijaprice.com/best-cheapest-phones-in-nigeria-market-prices/ | <a href="https://web.archive.org/web/*/https://naijaprice.com/best-cheapest-phones-in-nigeria-market-prices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div role="main">
<div>
<article id="post-3571" itemscope="" itemtype="https://schema.org/Article">


<div>
<p><img width="640" height="497" src="https://naijaprice.com/wp-content/uploads/2018/04/Best-Cheapest-Phones-in-Nigeria-Prices.jpg" srcset="https://naijaprice.com/wp-content/uploads/2018/04/Best-Cheapest-Phones-in-Nigeria-Prices.jpg 680w, https://naijaprice.com/wp-content/uploads/2018/04/Best-Cheapest-Phones-in-Nigeria-Prices-300x233.jpg 300w" sizes="(max-width: 640px) 100vw, 640px" alt="Best Cheapest Phones in Nigeria Prices" title="Best Cheapest Phones in Nigeria Prices"></p>



<p>There are <em><strong>very good affordable phones in Nigeria</strong></em>. So today, we’ll be looking at the Best cheapest affordable phones in the Nigeria market. Cheap phones do not necessarily mean low quality. Those days, are long gone.</p>
<p>For example, some android phones in this list have <a href="https://naijaprice.com/best-2gb-ram-phones-nigeria-price-list/" target="_blank" rel="noopener">2GB RAM</a> and <a href="https://naijaprice.com/best-16gb-rom-phones-nigeria-price-list/" target="_blank" rel="noopener">16GB of internal storage</a>. In this list of best cheapest Android phones in Nigeria, I have included handsets from Infinix, Leagoo, Tecno, <a href="https://naijaprice.com/innjoo-phone-prices-in-nigeria/" target="_blank" rel="noopener">InnJoo</a> and Samsung. The smartphones have different strengths, so choose the one that best suits your needs.</p>
<p>Also check out: <a href="https://naijaprice.com/best-phones-under-30000-naira-nigeria/" target="_blank" rel="noopener">Best Phones Under 30000 Naira</a> and also <a href="https://naijaprice.com/best-phones-under-20000-naira-nigeria/" target="_blank" rel="noopener">Top Best Phones Below 20000 Naira.</a></p>
<h2><span><strong>The Following are the Best Cheapest Android Phones in Nigerian Market (2021):</strong></span></h2>

<table id="tablepress-524">
<thead>
<tr>
<th colspan="2"><h3><span id="Leagoo_KIICAA_POWER-_Android">Leagoo KIICAA POWER- Android</span></h3></th>
</tr>
</thead>
<tfoot>
<tr>
<th></th><th></th>
</tr>
</tfoot>
<tbody>
<tr>
<td colspan="2"><img src="https://naijaprice.com/wp-content/uploads/2018/03/Leagoo-KIICAA-POWER-5-0-Inch-2GB16GB-ROM-Android-7-0-Nougat-8MP-5MP-Dual-5MP-Dual-SIM-3G-Smartphone-Champagne-Gold-154x300.jpg" alt="Leagoo-KIICAA-POWER-5-0-Inch-(2GB,16GB-ROM)-Android-7-0-Nougat,-8MP-5MP-Dual-5MP,-Dual-SIM-3G-Smartphone-Champagne-Gold" width="154" height="300"><br>
<a target="_blank" rel="nofollow" href="http://c.jumia.io/?a=27313&amp;c=11&amp;p=r&amp;E=kkYNyk2M4sk%3d&amp;ckmrdr=https%3A%2F%2Fwww.jumia.com.ng%2Fmobile-phones%2F%3Fq%3Dleagoo&amp;s1=leagoo&amp;utm_source=cake&amp;utm_medium=affiliation&amp;utm_campaign=27313&amp;utm_term=leagoo">See This Jumia Price Offer</a></td>
</tr>
<tr>
<td><b>Price</b> </td><td>₦&nbsp;17,990</td>
</tr>
<tr>
<td><b>Operating System</b> </td><td>Android 7.0 Nougat</td>
</tr>
<tr>
<td><b>Screen Size</b> </td><td>5 inches</td>
</tr>
<tr>
<td><b>Display Resolution</b> </td><td>720 x 1280 pixels</td>
</tr>
<tr>
<td><b>Processor</b> </td><td>Quad Core up to 1.3GHz CPU</td>
</tr>
<tr>
<td><b>GPU</b> </td><td>Mali</td>
</tr>
<tr>
<td><b>RAM</b> </td><td>2GB</td>
</tr>
<tr>
<td><b>Storage Space</b> </td><td>16GB</td>
</tr>
<tr>
<td><b>microSD Slot</b> </td><td>32GB</td>
</tr>
<tr>
<td><b>Main Camera</b> </td><td>8 megapixels</td>
</tr>
<tr>
<td><b>Selfie Camera</b> </td><td>5 megapixels</td>
</tr>
<tr>
<td><b>Battery</b> </td><td>4000mAh</td>
</tr>
<tr>
<td><b>Connectivity</b> </td><td>3G, Wifi, Bluetooth, USB</td>
</tr>
<tr>
<td><b>Pros</b> </td><td>Price, Performance, Display</td>
</tr>
<tr>
<td><b>Cons</b> </td><td>NA</td>
</tr>
</tbody>
</table>

<table id="tablepress-488">
<thead>
<tr>
<th colspan="2"><h3><span id="Infinix_Hot_5_Lite">Infinix Hot 5 Lite</span></h3></th>
</tr>
</thead>
<tfoot>
<tr>
<th></th><th></th>
</tr>
</tfoot>
<tbody>
<tr>
<td colspan="2"><img src="https://naijaprice.com/wp-content/uploads/2018/03/Infinix-Hot-5-Lite-X559-5-5-Inch-HD-1GB-RAM-16GB-ROM-Android-7-Nougat-8MP-5MP-Dual-SIM-3G-Smartphone-Gold-233x300.jpg" alt="Infinix-Hot-5-Lite-(X559)-5-5-Inch-HD-(1GB-RAM,-16GB-ROM)-Android-7-Nougat,-8MP-+-5MP-Dual-SIM-3G-Smartphone-Gold" width="233" height="300"><br>
<a target="_blank" rel="nofollow noopener" href="http://c.jumia.io/?a=27313&amp;c=11&amp;p=r&amp;E=kkYNyk2M4sk%3d&amp;ckmrdr=https%3A%2F%2Fwww.jumia.com.ng%2Fmobile-phones%2F%3Fq%3Dinfinix&amp;s1=infinix&amp;utm_source=cake&amp;utm_medium=affiliation&amp;utm_campaign=27313&amp;utm_term=infinix">Check This Latest Price Deal</a></td>
</tr>
<tr>
<td><b>Price</b> </td><td>₦&nbsp;31,500</td>
</tr>
<tr>
<td><b>OS</b> </td><td>Android 7 Nougat</td>
</tr>
<tr>
<td><b>Screen Size</b> </td><td>5.5 inches</td>
</tr>
<tr>
<td><b>Display Resolution</b> </td><td>720 x 1280 pixels</td>
</tr>
<tr>
<td><b>Processor</b> </td><td>1.3GHz quad-core</td>
</tr>
<tr>
<td><b>GPU</b> </td><td>Mali</td>
</tr>
<tr>
<td><b>RAM</b> </td><td>1GB</td>
</tr>
<tr>
<td><b>Storage Space</b> </td><td>16GB</td>
</tr>
<tr>
<td><b>Expansion Slot</b> </td><td>32GB</td>
</tr>
<tr>
<td><b>Primary Camera</b> </td><td>8 megapixels</td>
</tr>
<tr>
<td><b>Selfie Camera</b> </td><td>5 megapixels</td>
</tr>
<tr>
<td><b>Battery</b> </td><td>4000mAh</td>
</tr>
<tr>
<td><b>Connectivity</b> </td><td>3G</td>
</tr>
<tr>
<td><b>Pros</b> </td><td>Price, Display Size, Cameras, Battery</td>
</tr>
<tr>
<td><b>Cons</b> </td><td>No 4G LTE</td>
</tr>
</tbody>
</table>

<table id="tablepress-623">
<thead>
<tr>
<th colspan="2"><h3><span id="Tecno_WX3_LTE">Tecno WX3 LTE</span></h3></th>
</tr>
</thead>
<tfoot>
<tr>
<th></th><th></th>
</tr>
</tfoot>
<tbody>
<tr>
<td colspan="2"><img src="https://naijaprice.com/wp-content/uploads/2018/03/Tecno-WX3-LTE-5-Inch-1GB-8GB-ROM-Android-7-0-Nougat-5MP-5MP-4G-Smartphone-Sky-Grey-154x300.jpg" alt="Tecno-WX3-LTE-5-Inch-(1GB,-8GB-ROM)-Android-7-0-Nougat,-5MP-5MP-4G-Smartphone-Sky-Grey Jumia Nigeria" width="154" height="300"><br>
<a target="_blank" rel="nofollow noopener" href="http://c.jumia.io/?a=27313&amp;c=11&amp;p=r&amp;E=kkYNyk2M4sk%3d&amp;ckmrdr=https%3A%2F%2Fwww.jumia.com.ng%2Fmobile-phones%2F%3Fq%3Dtecno&amp;s1=tecno&amp;utm_source=cake&amp;utm_medium=affiliation&amp;utm_campaign=27313&amp;utm_term=tecno">Check This Latest Price Deal</a></td>
</tr>
<tr>
<td><b>Price</b> </td><td>₦&nbsp;29,000</td>
</tr>
<tr>
<td><b>OS</b> </td><td>Android Nougat 7.0</td>
</tr>
<tr>
<td><b>Screen Size</b> </td><td>5.0 inches</td>
</tr>
<tr>
<td><b>Display Resolution</b> </td><td>FWVGA</td>
</tr>
<tr>
<td><b>Processor</b> </td><td>1.3GHz quad-core</td>
</tr>
<tr>
<td><b>GPU</b> </td><td>Mali</td>
</tr>
<tr>
<td><b>RAM</b> </td><td>1GB</td>
</tr>
<tr>
<td><b>Storage Space</b> </td><td>8GB</td>
</tr>
<tr>
<td><b>Expansion Slot</b> </td><td>32GB</td>
</tr>
<tr>
<td><b>Main Camera</b> </td><td>5 megapixels</td>
</tr>
<tr>
<td><b>Selfie Camera</b> </td><td>5 megapixels</td>
</tr>
<tr>
<td><b>Battery</b> </td><td>2500mAh</td>
</tr>
<tr>
<td><b>Connectivity</b> </td><td>Wifi, 4G LTE, Bluetooth, USB</td>
</tr>
<tr>
<td><b>Pros</b> </td><td>Price</td>
</tr>
<tr>
<td><b>Cons</b> </td><td>Storage Capacity</td>
</tr>
</tbody>
</table>

<table id="tablepress-619">
<thead>
<tr>
<th colspan="2"><h3><span id="Tecno_Spark_K7">Tecno Spark K7</span></h3></th>
</tr>
</thead>
<tfoot>
<tr>
<th></th><th></th>
</tr>
</tfoot>
<tbody>
<tr>
<td colspan="2"><img src="https://naijaprice.com/wp-content/uploads/2018/03/Tecno-Spark-K7-5-5-Inch-HD-1GB-16GB-ROM-13MP-5MP-Android-7-0-Nougat-Dual-SIM-3G-Smartphone-Champagne-Gold-250x300.jpg" alt="Tecno-Spark-K7-5-5-Inch-HD-(1GB,-16GB-ROM)-13MP-5MP,-Android-7-0-Nougat-Dual-SIM-3G-Smartphone-Champagne-Gold Jumia Nigeria Lagos" width="250" height="300"><br>
<a target="_blank" rel="nofollow noopener" href="http://c.jumia.io/?a=27313&amp;c=11&amp;p=r&amp;E=kkYNyk2M4sk%3d&amp;ckmrdr=https%3A%2F%2Fwww.jumia.com.ng%2Fmobile-phones%2F%3Fq%3Dtecno&amp;s1=tecno&amp;utm_source=cake&amp;utm_medium=affiliation&amp;utm_campaign=27313&amp;utm_term=tecno">See This Jumia Price Offer</a></td>
</tr>
<tr>
<td><b>Price</b> </td><td>₦&nbsp;32,800</td>
</tr>
<tr>
<td><b>OS</b> </td><td>Android 7.0 (Nougat)</td>
</tr>
<tr>
<td><b>Screen Size</b> </td><td>5.5 inches</td>
</tr>
<tr>
<td><b>Display Resolution</b> </td><td>720 x 1280 pixels</td>
</tr>
<tr>
<td><b>Processor</b> </td><td>1.3GHz quad-core</td>
</tr>
<tr>
<td><b>GPU</b> </td><td>Mali</td>
</tr>
<tr>
<td><b>RAM</b> </td><td>1GB</td>
</tr>
<tr>
<td><b>Storage Space</b> </td><td>16GB</td>
</tr>
<tr>
<td><b>Expansion Slot</b> </td><td>32GB</td>
</tr>
<tr>
<td><b>Main Camera</b> </td><td>13 megapixels</td>
</tr>
<tr>
<td><b>Selfie Camera</b> </td><td>5 megapixels</td>
</tr>
<tr>
<td><b>Battery</b> </td><td>3000mAh</td>
</tr>
<tr>
<td><b>Connectivity</b> </td><td>Wifi, Bluetooth, 3G, USB</td>
</tr>
<tr>
<td><b>Pros</b> </td><td>Battery, Performance, Display</td>
</tr>
<tr>
<td><b>Cons</b> </td><td>NA</td>
</tr>
</tbody>
</table>

<table id="tablepress-419">
<thead>
<tr>
<th colspan="2"><h3><span id="Gionee_P5_Mini">Gionee P5 Mini</span></h3></th>
</tr>
</thead>
<tfoot>
<tr>
<th></th><th></th>
</tr>
</tfoot>
<tbody>
<tr>
<td colspan="2"><img src="https://naijaprice.com/wp-content/uploads/2018/03/Gionee-P5-Mini-4-5-Inch-WVGA-1GB-8GB-ROM-Android-5-1-Lollipop-5MP-2MP-Dual-SIM-3G-Smartphone-Freebie-156x300.jpg" alt="Gionee-P5-Mini-4-5-Inch-WVGA-(1GB,-8GB-ROM)-Android-5-1-Lollipop,-5MP-+-2MP-Dual-SIM-3G-Smartphone-Freebie" width="156" height="300"><br>
<a target="_blank" rel="nofollow noopener" href="http://c.jumia.io/?a=27313&amp;c=11&amp;p=r&amp;E=kkYNyk2M4sk%3d&amp;ckmrdr=https%3A%2F%2Fwww.jumia.com.ng%2Fcatalog%2F%3Fq%3Dgionee&amp;s1=gionee&amp;utm_source=cake&amp;utm_medium=affiliation&amp;utm_campaign=27313&amp;utm_term=gionee">Check These Latest Prices</a></td>
</tr>
<tr>
<td><b>Price</b> </td><td>₦&nbsp;23,899</td>
</tr>
<tr>
<td><b>OS</b> </td><td>Android OS,v5.1 (Lollipop)</td>
</tr>
<tr>
<td><b>Screen Size</b> </td><td>4.5 inches</td>
</tr>
<tr>
<td><b>Display Resolution</b> </td><td>FWVGA&nbsp;</td>
</tr>
<tr>
<td><b>Processor</b> </td><td>1.3GHz quad-core</td>
</tr>
<tr>
<td><b>GPU</b> </td><td>Mali</td>
</tr>
<tr>
<td><b>RAM</b> </td><td>1GB</td>
</tr>
<tr>
<td><b>Storage Space</b> </td><td>8GB</td>
</tr>
<tr>
<td><b>Expansion Slot</b> </td><td>32GB</td>
</tr>
<tr>
<td><b>Primary Camera</b> </td><td>5 megapixels</td>
</tr>
<tr>
<td><b>Selfie Camera</b> </td><td>2 megapixels</td>
</tr>
<tr>
<td><b>Battery</b> </td><td>1850mAh</td>
</tr>
<tr>
<td><b>Connectivity</b> </td><td>3G, Bluetooth, Wifi</td>
</tr>
<tr>
<td><b>Pros</b> </td><td>Price, Connectivity</td>
</tr>
<tr>
<td><b>Cons</b> </td><td>Battery</td>
</tr>
</tbody>
</table>

<table id="tablepress-871">
<thead>
<tr>
<th colspan="2"><h3><span id="Motorola_Moto_C">Motorola Moto C</span></h3></th>
</tr>
</thead>
<tfoot>
<tr>
<th></th><th></th>
</tr>
</tfoot>
<tbody>
<tr>
<td colspan="2"><img src="https://naijaprice.com/wp-content/uploads/2018/04/Motorola-Moto-C-5-0-Inch-1GB-8GB-ROM-Android-7-0-Nougat-5MP-2MP-3G-155x300.jpg" alt="Motorola-Moto-C-5-0-Inch-(1GB,-8GB-ROM)-Android-7-0-Nougat,-5MP-2MP-3G Jumia Sale" width="155" height="300"><br>
<a target="_blank" rel="nofollow" href="http://c.jumia.io/?a=27313&amp;c=11&amp;p=r&amp;E=kkYNyk2M4sk%3d&amp;ckmrdr=https%3A%2F%2Fwww.jumia.com.ng%2Fsmartphones%2F%3Fq%3Dmotorola&amp;s1=motorola&amp;utm_source=cake&amp;utm_medium=affiliation&amp;utm_campaign=27313&amp;utm_term=motorola">See This Updated Jumia Price Offer</a></td>
</tr>
<tr>
<td><b>Price</b> </td><td>₦&nbsp;24,030</td>
</tr>
<tr>
<td><b>Operating System</b> </td><td>Android 7.0 Nougat</td>
</tr>
<tr>
<td><b>Screen Size</b> </td><td>5.0 inches</td>
</tr>
<tr>
<td><b>Display Resolution</b> </td><td>854 x 480 pixels</td>
</tr>
<tr>
<td><b>Processor</b> </td><td>1.3GHz quad-core</td>
</tr>
<tr>
<td><b>GPU</b> </td><td>Mali</td>
</tr>
<tr>
<td><b>RAM</b> </td><td>1GB</td>
</tr>
<tr>
<td><b>Storage Space</b> </td><td>8GB</td>
</tr>
<tr>
<td><b>microSD Slot</b> </td><td>32GB</td>
</tr>
<tr>
<td><b>Main Camera</b> </td><td>5 megapixels</td>
</tr>
<tr>
<td><b>Selfie Camera</b> </td><td>2 megapixels</td>
</tr>
<tr>
<td><b>Battery</b> </td><td>2350mAh&nbsp;</td>
</tr>
<tr>
<td><b>Connectivity</b> </td><td>3G, Wifi, Bluetooth, USB</td>
</tr>
<tr>
<td><b>Pros</b> </td><td>Price, Performance</td>
</tr>
<tr>
<td><b>Cons</b> </td><td>Camera, Battery</td>
</tr>
</tbody>
</table>

<table id="tablepress-489">
<thead>
<tr>
<th colspan="2"><h3><span id="Infinix_Hot_5_X559">Infinix Hot 5 (X559)</span></h3></th>
</tr>
</thead>
<tfoot>
<tr>
<th></th><th></th>
</tr>
</tfoot>
<tbody>
<tr>
<td colspan="2"><img src="https://naijaprice.com/wp-content/uploads/2018/03/Infinix-Hot-5-X559-5-5-Inch-HD-2GB-16GB-ROM-Android-7-Nougat-8MP-5MP-Dual-SIM-3G-Smartphone-Black-240x300.jpg" alt="Infinix-Hot-5-(X559)-5-5-Inch-HD-(2GB,-16GB-ROM)-Android-7-Nougat,-8MP-+-5MP-Dual-SIM-3G-Smartphone-Black" width="240" height="300"><br>
<a target="_blank" rel="nofollow noopener" href="http://c.jumia.io/?a=27313&amp;c=11&amp;p=r&amp;E=kkYNyk2M4sk%3d&amp;ckmrdr=https%3A%2F%2Fwww.jumia.com.ng%2Fmobile-phones%2F%3Fq%3Dinfinix&amp;s1=infinix&amp;utm_source=cake&amp;utm_medium=affiliation&amp;utm_campaign=27313&amp;utm_term=infinix">See This Jumia Price Offer</a></td>
</tr>
<tr>
<td><b>Price</b> </td><td>₦&nbsp;37,500</td>
</tr>
<tr>
<td><b>OS</b> </td><td>Android 7 Nougat</td>
</tr>
<tr>
<td><b>Screen Size</b> </td><td>5.5 inches</td>
</tr>
<tr>
<td><b>Display Resolution</b> </td><td>720 x 1280 pixels</td>
</tr>
<tr>
<td><b>Processor</b> </td><td>1.3GHz quad-core</td>
</tr>
<tr>
<td><b>GPU</b> </td><td>Mali</td>
</tr>
<tr>
<td><b>RAM</b> </td><td>2GB</td>
</tr>
<tr>
<td><b>Storage Space</b> </td><td>16GB</td>
</tr>
<tr>
<td><b>Expansion Slot</b> </td><td>64GB</td>
</tr>
<tr>
<td><b>Primary Camera</b> </td><td>13 megapixels</td>
</tr>
<tr>
<td><b>Selfie Camera</b> </td><td>5 megapixels</td>
</tr>
<tr>
<td><b>Battery</b> </td><td>4000mAh</td>
</tr>
<tr>
<td><b>Connectivity</b> </td><td>3G</td>
</tr>
<tr>
<td><b>Pros</b> </td><td>Price, Design, Cameras, Display</td>
</tr>
<tr>
<td><b>Cons</b> </td><td>No 4G LTE</td>
</tr>
</tbody>
</table>

<table id="tablepress-484">
<thead>
<tr>
<th colspan="2"><h3><span id="INFINIX_SMART_X5010">INFINIX SMART X5010</span></h3></th>
</tr>
</thead>
<tfoot>
<tr>
<th></th><th></th>
</tr>
</tfoot>
<tbody>
<tr>
<td colspan="2"><img src="https://naijaprice.com/wp-content/uploads/2018/03/INFINIX-SMART-X5010-4-233x300.jpg" alt="INFINIX-SMART-X5010-4 Nigeria Jumia Lagos" width="233" height="300"><br>
<a target="_blank" rel="nofollow noopener" href="http://c.jumia.io/?a=27313&amp;c=11&amp;p=r&amp;E=kkYNyk2M4sk%3d&amp;ckmrdr=https%3A%2F%2Fwww.jumia.com.ng%2Fmobile-phones%2F%3Fq%3Dinfinix&amp;s1=infinix&amp;utm_source=cake&amp;utm_medium=affiliation&amp;utm_campaign=27313&amp;utm_term=infinix">Check This Latest Price Deal</a></td>
</tr>
<tr>
<td><b>Price</b> </td><td>₦&nbsp;28,950</td>
</tr>
<tr>
<td><b>OS</b> </td><td>Android 6.0 Marshmallow</td>
</tr>
<tr>
<td><b>Screen Size</b> </td><td>5.0 inches</td>
</tr>
<tr>
<td><b>Display Resolution</b> </td><td>720 x 1280 pixels</td>
</tr>
<tr>
<td><b>Processor</b> </td><td>1.2Ghz Quad Core Cortex</td>
</tr>
<tr>
<td><b>GPU</b> </td><td>MALI-T720 MP3 450MHz</td>
</tr>
<tr>
<td><b>RAM</b> </td><td>1GB</td>
</tr>
<tr>
<td><b>Storage Space</b> </td><td>16GB</td>
</tr>
<tr>
<td><b>Expansion Slot</b> </td><td>64GB</td>
</tr>
<tr>
<td><b>Primary Camera</b> </td><td>8 megapixels</td>
</tr>
<tr>
<td><b>Selfie Camera</b> </td><td>2 megapixels</td>
</tr>
<tr>
<td><b>Battery</b> </td><td>30600mAh</td>
</tr>
<tr>
<td><b>Connectivity</b> </td><td>3G</td>
</tr>
<tr>
<td><b>Pros</b> </td><td>Price, Cameras, Display</td>
</tr>
<tr>
<td><b>Cons</b> </td><td>4G LTE, Cameras</td>
</tr>
</tbody>
</table>

<table id="tablepress-498">
<thead>
<tr>
<th colspan="2"><h3><span id="Innjoo_Fire_4_Plus">Innjoo Fire 4 Plus</span></h3></th>
</tr>
</thead>
<tfoot>
<tr>
<th></th><th></th>
</tr>
</tfoot>
<tbody>
<tr>
<td colspan="2"><img src="https://naijaprice.com/wp-content/uploads/2018/03/Innjoo-Fire-4-Plus-Dual-Sim-32GB-2GB-RAM-4G-LTE-154x300.jpg" alt="Innjoo-Fire-4-Plus-Dual-Sim-32GB,-2GB-RAM,-4G-LTE" width="154" height="300"><br>
<a target="_blank" rel="nofollow noopener" href="http://c.jumia.io/?a=27313&amp;c=11&amp;p=r&amp;E=kkYNyk2M4sk%3d&amp;ckmrdr=https%3A%2F%2Fwww.jumia.com.ng%2Fmobile-phones%2F%3Fq%3Dinnjoo&amp;s1=innjoo&amp;utm_source=cake&amp;utm_medium=affiliation&amp;utm_campaign=27313&amp;utm_term=innjoo">Check Out This Price Offer</a></td>
</tr>
<tr>
<td><b>Price</b> </td><td>₦&nbsp;67,900</td>
</tr>
<tr>
<td><b>OS</b> </td><td>Android 7.0 Nougat</td>
</tr>
<tr>
<td><b>Screen Size</b> </td><td>5.5 inches</td>
</tr>
<tr>
<td><b>Display Resolution</b> </td><td>1920 x 1080 pixels</td>
</tr>
<tr>
<td><b>Processor</b> </td><td>1.3GHz quad-core</td>
</tr>
<tr>
<td><b>GPU</b> </td><td>Mali</td>
</tr>
<tr>
<td><b>RAM</b> </td><td>2GB</td>
</tr>
<tr>
<td><b>Storage Space</b> </td><td>32GB</td>
</tr>
<tr>
<td><b>Expansion Slot</b> </td><td>64GB</td>
</tr>
<tr>
<td><b>Primary Camera</b> </td><td>13 megapixels</td>
</tr>
<tr>
<td><b>Selfie Camera</b> </td><td>5 megapixels</td>
</tr>
<tr>
<td><b>Battery</b> </td><td>3000mAh</td>
</tr>
<tr>
<td><b>Connectivity</b> </td><td>3G</td>
</tr>
<tr>
<td><b>Pros</b> </td><td>Design, Price, Display, Performance</td>
</tr>
<tr>
<td><b>Cons</b> </td><td>NA</td>
</tr>
</tbody>
</table>

<table id="tablepress-583">
<thead>
<tr>
<th colspan="2"><h3><span id="Samsung_Galaxy_Grand_Prime_Plus">Samsung Galaxy Grand Prime Plus</span></h3></th>
</tr>
</thead>
<tfoot>
<tr>
<th></th><th></th>
</tr>
</tfoot>
<tbody>
<tr>
<td colspan="2"><img src="https://naijaprice.com/wp-content/uploads/2018/03/Samsung-Galaxy-Grand-Prime-Plus-5-0-Inch-1-154x300.jpg" alt="Samsung-Galaxy-Grand-Prime-Plus-5-0-Inch-(1" width="154" height="300"><br>
<a target="_blank" rel="nofollow noopener" href="http://c.jumia.io/?a=27313&amp;c=11&amp;p=r&amp;E=kkYNyk2M4sk%3d&amp;ckmrdr=https%3A%2F%2Fwww.jumia.com.ng%2Fmobile-phones%2F%3Fq%3Dsamsung&amp;s1=galaxy&amp;utm_source=cake&amp;utm_medium=affiliation&amp;utm_campaign=27313&amp;utm_term=galaxy">See This Price Offer at Jumia</a></td>
</tr>
<tr>
<td><b>Price</b> </td><td>₦&nbsp;41,990</td>
</tr>
<tr>
<td><b>OS</b> </td><td>Android 6.0 Marshmallow</td>
</tr>
<tr>
<td><b>Screen Size</b> </td><td>6.0 inches</td>
</tr>
<tr>
<td><b>Display Resolution</b> </td><td>720 x 1280 pixels</td>
</tr>
<tr>
<td><b>Processor</b> </td><td>Quad-core 1.4 GHz Cortex-A53</td>
</tr>
<tr>
<td><b>GPU</b> </td><td>Mali</td>
</tr>
<tr>
<td><b>RAM</b> </td><td>1.5GB</td>
</tr>
<tr>
<td><b>Storage Space</b> </td><td>8GB</td>
</tr>
<tr>
<td><b>Expansion Slot</b> </td><td>64GB</td>
</tr>
<tr>
<td><b>Primary Camera</b> </td><td>8 megapixels</td>
</tr>
<tr>
<td><b>Selfie Camera</b> </td><td>5 megapixels</td>
</tr>
<tr>
<td><b>Battery</b> </td><td>2000mAh</td>
</tr>
<tr>
<td><b>Connectivity</b> </td><td>4G</td>
</tr>
<tr>
<td><b>Pros</b> </td><td>Display, Performance, Design</td>
</tr>
<tr>
<td><b>Cons</b> </td><td>Storage Capacity</td>
</tr>
</tbody>
</table>

<h4><span><strong>More Mobile Phones:</strong></span></h4>
<table id="tablepress-1324">
<tbody>
<tr>
<td><a href="https://naijaprice.com/alcatel-phone-prices-in-nigeria/" rel="noopener" target="_blank">Alcatel Smartphone Prices in Nigeria</a></td>
</tr>
<tr>
<td><a href="https://naijaprice.com/motorola-phone-prices-in-nigeria/" rel="noopener" target="_blank">Latest Motorola Smartphones in Nigeria</a></td>
</tr>
<tr>
<td><a href="https://naijaprice.com/vkworld-phone-prices-in-nigeria/" rel="noopener" target="_blank">VK World Phones and their Prices in Nigeria</a></td>
</tr>
<tr>
<td><a href="https://naijaprice.com/letv-phone-prices-in-nigeria/" rel="noopener" target="_blank">Le TV Phones Price List in Nigeria</a></td>
</tr>
<tr>
<td><a href="https://naijaprice.com/vernee-phone-prices-in-nigeria/" rel="noopener" target="_blank">Latest Vernee Mobile Phones in Nigeria</a></td>
</tr>
<tr>
<td><a href="https://naijaprice.com/imose-phone-prices-in-nigeria/" rel="noopener" target="_blank">I-Mose Smartphones Price List in Nigeria</a></td>
</tr>
<tr>
<td><a href="https://naijaprice.com/oeina-phone-prices-in-nigeria/" rel="noopener" target="_blank">Oiena Mobile Phone Prices</a></td>
</tr>
<tr>
<td><a href="https://naijaprice.com/elephone-mobile-prices-in-nigeria/" rel="noopener" target="_blank">Elephone Smartphones and Prices in Nigeria</a></td>
</tr>
<tr>
<td><a href="https://naijaprice.com/doogee-phone-prices-in-nigeria/" rel="noopener" target="_blank">Doogee Mobile Phones Price List in Nigeria</a></td>
</tr>
<tr>
<td><a href="https://naijaprice.com/allwin-phone-prices-in-nigeria/" rel="noopener" target="_blank">Allwin Smartphone Prices in Nigeria</a></td>
</tr>
</tbody>
</table>




</div>

</article> 
 
</div>
</div>

</div></div>]]>
            </description>
            <link>https://naijaprice.com/best-cheapest-phones-in-nigeria-market-prices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25875285</guid>
            <pubDate>Fri, 22 Jan 2021 19:30:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Analysis – Methodologies Introduction]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25875216">thread link</a>) | @rafaelgss
<br/>
January 22, 2021 | https://blog.rafaelgss.com.br/performance-methodologies | <a href="https://web.archive.org/web/*/https://blog.rafaelgss.com.br/performance-methodologies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<section>

<p>Poor performance costs the software industry millions of dollars annually in lost revenue, decreased productivity, increased development, hardware costs and damaged customer relations.</p>
<p>Most applications tend to focus on correctness over performance. The shift towards performance only occurs once it is seen as a problem.
When that happens, one rarely has time to dedicated towards improving it. This article aims to show you that <strong>there is no simple answer</strong>.
A lot of performance work should be done in early phases of development. For the rest of the article, the reader is considered having a role of Performance Engineer or “acting” as one.</p>
<p>In my experience, a strictly “agile” methodology (Idea -&gt; MVP -&gt; Feature -&gt; “Refactor”) tends to leave out proper performance engineering, since performance is not a goal but an expectation.</p>
<blockquote><p><em>Performance is a field where the more you know, the less you understand</em>.</p>
</blockquote>
<p>Regardless of the source, when a performance issue appears it should be fixed immediately. Two ways are: 1) modifying code/architecture or throwing money at additional hardware resources. The second path in some time will lead to the same problem down the line.</p>
<p>Prior starting performance analysis, you <strong>must</strong>  understand your application architecture. Any analysis requires clear boundaries and a full understanding of dependencies and third-party services.</p>
<p>A diagram of your software architecture is a great starting point.</p>
<blockquote><p>The foundation of your software should be resilient to achieve better results.</p>
</blockquote>
<h2>Monitoring</h2>
<p>Today, a big part of the market is adopting distributed systems. As we’ve come to learn, such systems adds a lot of complexity to your architecture in exchange for scalability and availability (resilience).</p>
<p>It also adds more components to your list of dependencies. Therefore, you should monitor these dependencies to have better visibility when things deviate from a happy path.</p>
<p>Each part of the architecture (or software) needs individual monitoring that helps us go back in time and answer some of these questions:</p>
<ul>
<li>When did the software start performing worse?
</li>
<li>During what timeframe are we seeing most activity?
</li>
<li>How are components behaving during these timeframes? Think: I/O latency, DNS resolution, CPU or RAM consumption
</li>
</ul>
<p>These questions will help to choose the right performance methodology to apply.</p>
<h2>Known-Unknowns</h2>
<p><img src="https://blog.rafaelgss.com.br/images/performance-analysis/diagram-known-unknowns.png" alt="Known Unknowns"></p>
<blockquote><p><em>This section is a reference to the book <a href="https://www.goodreads.com/book/show/18058001-systems-performance">System Performance</a> by the author Brendan Gregg.</em></p>
</blockquote>
<p>In performance analysis we can split information into three types:</p>
<ul>
<li>Know-Knows: These are things you know, for instance, you know that you should be checking CPU utilization <strong>and</strong> you know that the value is 10% on average.
</li>
<li>Know-Unknows: There are things that you know that you do not know. You know that an increase in API response time can be related to a third-party component, but you don’t have metrics showing it.
</li>
<li>Unknown-Unknowns: These are things you are unaware of not knowing. Confusing? For instance: you may not know that DNS resolution can become heavy I/O latency, so you are not checking them (because you didn’t know).
</li>
</ul>
<p>While creating architecture diagrams,  <em>unknowns-unknowns</em>  obviously aren’t mappable since you don’t know about them.</p>
<blockquote><p><code>unknown-unknows</code> are common. It is your job as a performance engineer to transform the <code>unknown-unknowns</code> into <code>know-unknows</code>.</p>
</blockquote>
<p>The Diagram above map <code>known-knowns</code> (Green box) and <code>known-unknows</code> (Red box)</p>
<h2>Observability Tools</h2>
<p>As previously mentioned, achieving observability in our software/architecture is fundamental to perform performance improvements. In this section, I’ll walk through a few tools that are great for this purpose.</p>
<h3>Tracing</h3>
<p>Tracing collects per-event data for analysis. Normally, tracing tools are not enabled by default since it adds CPU overhead to capture and send/store the data.</p>
<p>Logging (including system logs) can be seen as low-frequency tracing that is enabled by default.</p>
<p>Some common tools:</p>
<p><strong>system-wide</strong>:</p>
<ul>
<li><code>tcpdump</code>: network packet tracing
</li>
<li><code>perf</code>: Linux Performance Events (tracing static and dynamic probes)
</li>
</ul>
<p><strong>per-process</strong>:</p>
<ul>
<li><code>strace</code>: system call tracing
</li>
<li><code>USDT</code> (Userland Statically Defined Tracing)
</li>
<li><code>DTrace</code>: observability framework that includes a programming language and a tool.
</li>
</ul>
<p>TracePoints is a great way to observe your software in the production environment. You can use USDT (dynamic probes) or static tracepoints.
For further information check the <em>useful links</em> section.</p>
<h3>Profiling</h3>
<p>Profiling characterizes the target by collecting a set of samples of snapshots. CPU usage is a common example where samples are taken of the stack trace to characterize the code paths that are consuming CPU cycles.</p>
<p><strong>Note</strong>: For further information about Profiling CPU, I’ve made a blog post doing CPU Profiling in a Node.js application. <a href="https://blog.rafaelgss.com.br/node-cpu-profiler">Check here</a>.</p>
<p>Tools:</p>
<ul>
<li><code>perf</code>: Linux Performance Events (profiling)
</li>
<li><code>cachegrind</code>: a Valgrind sub tool, can profile hardware cache usage and be visualized using <code>kcachegrind</code>
</li>
</ul>
<blockquote><p><code>/proc</code> is a file system interface for kernel statistics, it contains directories where each directory is named after the <strong>PID</strong> of the process. These directories contain a number of files containing information and statistics about each process mapped from kernel data structures.</p>
</blockquote>
<p><img src="https://pbs.twimg.com/media/DZ3HpVXXkAEgxpc?format=jpg&amp;name=large" alt="Julia Evans - Comic /proc"> - <a href="https://twitter.com/b0rk/status/981159808832286720/photo/1">reference</a></p>
<h2>Methodologies</h2>
<p>This section will describe three of the most used methodologies (by me at least). Apply a methodology when performance issues start showing up; there is no rule about choosing the best approach.
Previous experience with your software architecture will likely be the best way to make a decision.</p>
<h3>USE</h3>
<p>Utilization, Saturation and Errors (USE) is an methodology that <strong>should be used early in performance investigation</strong>. For every resource, check the utilization, saturation, and errors:</p>
<ul>
<li><strong>Resource</strong>: server components (CPU, buses, …)
</li>
<li><strong>Utilization</strong>: for a set time interval, the percentage of time that the resource was busy servicing work. While busy, the resource may <strong>still be able to accept more work</strong>.
</li>
<li><strong>Saturation</strong>: additional work to be done, likely waiting in a queue. Jobs that cannot be dealt with instantly.
</li>
</ul>
<p><img src="https://blog.rafaelgss.com.br/images/performance-analysis/workflow-use.png" alt="Workflow with USE Methodology"></p>
<p>Its important to consider that it can be counter-intuitive; a short burst of high utilization can introduce saturation and performance issues even though the overall utilization is low over a long interval. CPU utilization <strong>can change dramatically from second to second</strong> so a 5-minute average may disguise short periods of 100% utilization and therefore lead to saturation.</p>
<p>Note: The saturation could not be easier to identify.</p>
<p>The first step is to create a list of resources:</p>
<ul>
<li><strong>CPUs:</strong> sockets, cores, hardware threads (virtual CPUs)
</li>
<li><strong>Main memory</strong>: DRAM
</li>
<li><strong>Network interfaces</strong>: Ethernet ports
</li>
<li><strong>Storage devices</strong>: disks
</li>
<li><strong>Controllers</strong>: storage, network
</li>
<li><strong>Interconnects</strong>: CPU, memory, I/O
</li>
</ul>
<blockquote><p>Virtual resources are fundamentally different than dedicated hardware. Especially as your resources are both shared and intentionally throttled. Some - if not all - cloud providers make their money by overselling and betting on idle processes.</p>
</blockquote>
<p>The USE method is most effective for resources that suffer performance degradation under high utilization or saturation, leading to bottlenecks. Fortunately, they are not common system bottlenecks, as they are typically designed to provide an excess of throughput. Unfortunately, if they are the problem, can be difficult to solve.</p>
<p>After you get the list of resources, try to create some metrics for it:</p>
<p><img src="https://blog.rafaelgss.com.br/images/performance-analysis/list-resources-use.png" alt="List of resources to create metric"></p>
<p>The process of elimination is good for us. Eliminate a possible resource bottleneck may help us to focus on another resource limiting our scope.</p>
<h3>Drill Down</h3>
<p>The process iterates through deeper layers of the software stack – even to hardware if necessary – to find the root cause of the issue. I try to to apply this methodology in every part of the software stack. It’s usually harder to do so  without having the bigger picture; but as you get more experienced you start recognizing recurring issues.</p>
<blockquote><p>Collecting and monitoring metrics is fundamental. Without it, we cannot fix the bugs the components cause.</p>
</blockquote>
<p>Such deeper analysis may involve the creation of custom tools and inspection of source code (if available). Here is where most of the drilling takes place, peeling away layers of the software stack as necessary to find the root cause.</p>
<p>Imagine an application that after a month in an production environment has begun to perform poorly.</p>
<p><strong>Five Whys</strong></p>
<ol>
<li>A database has performing poorly for some queries. Why?
</li>
<li>It’s delayed by disk I/O due to memory paging. Why?
</li>
<li>Database memory usage has grown too large. Why?
</li>
<li>The allocator is consuming more memory than expected. Why?
</li>
<li>The allocator has a memory fragmentation issue.
</li>
</ol>
<p>This is a good real sample extracted from <a href="https://www.goodreads.com/book/show/18058001-systems-performance">System Performance</a> book. There is not limit to go deep into <em>Why?</em>, but, one has to when the software is performing well.</p>
<p><img src="https://blog.rafaelgss.com.br/images/performance-analysis/5-whys.png" alt="Five why - Drill Down"></p>
<h3>Scientific Method</h3>
<p>The <em>scientific method</em> studies the <em>unknown</em> by making hypotheses and testing them. The <code>unknown</code> here can mean the <code>unknown-unknown</code> as discussed in <a href="#know-unknowns"><code>Know-Unknows</code></a> section.</p>
<p>Every <em>scientific method</em> consists:</p>
<ol>
<li>Formulation of a question?
</li>
<li>Hypothesis
</li>
<li>Prediction
</li>
<li>Testing
</li>
<li>Analysis
</li>
</ol>
<blockquote><p>For more information about how <em>scientific methods</em>, see <a href="https://en.wikipedia.org/wiki/Scientific_method">here</a></p>
</blockquote>
<p>First, define a question based on performance problem; for instance: <em>Why does my application have degraded throughput?</em>.</p>
<p>Second, build a hypothesis about what the cause of poor performance may be. <em>CPU Miss rate</em>? Write a test to prove your theory by for instance using <code>Valgrind</code>.</p>
<p>Collect results from your previous step and analyze how it behaves over time. It will give you a better idea of what components are connected and ultimately affected.</p>
<p><strong>Note:</strong> Shaping a hypothesis requires a clear understanding of your software architecture. Versioning your architectural changes can play a key role in understanding sudden changes.</p>
<p><img src="https://blog.rafaelgss.com.br/images/performance-analysis/scientific-method-steps.png" alt="Scientific Method Steps"></p>
<h2>Memory</h2>
<p>Usually, when a system boots the memory usage starts to grow as the operating system uses available memory to cache file system improving performance.
A system may report that it has only 10 MB of available memory when it actually has 10 GB of file system cache that can be reclaimed by applications immediately when …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.rafaelgss.com.br/performance-methodologies">https://blog.rafaelgss.com.br/performance-methodologies</a></em></p>]]>
            </description>
            <link>https://blog.rafaelgss.com.br/performance-methodologies</link>
            <guid isPermaLink="false">hacker-news-small-sites-25875216</guid>
            <pubDate>Fri, 22 Jan 2021 19:25:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software development: it’s got nothing to do with computers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25875204">thread link</a>) | @alexrustic
<br/>
January 22, 2021 | https://www.philipotoole.com/software-development-got-nothing-computers | <a href="https://web.archive.org/web/*/https://www.philipotoole.com/software-development-got-nothing-computers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Well, <strong>almost</strong> nothing.</p>
<p><a href="https://www.philipotoole.com/?attachment_id=4178" rel="attachment wp-att-4178"><img src="https://www.philipotoole.com/wp-content/uploads/2017/04/source-code-log-150x150.png" width="150" height="150" srcset="https://www.philipotoole.com/wp-content/uploads/2017/04/source-code-log-150x150.png 150w, https://www.philipotoole.com/wp-content/uploads/2017/04/source-code-log-300x300.png 300w, https://www.philipotoole.com/wp-content/uploads/2017/04/source-code-log.png 512w" sizes="(max-width: 150px) 100vw, 150px"></a>Obviously it’s got <strong>something</strong> to do with computers since developers spend so much of their time in front of one. But software development <strong>is actually all about people</strong>. And successful software development even more so.</p>
<p><span id="more-2576"></span><br>
Take, for example,&nbsp; <a href="http://www.stroustrup.com/hopl-almost-final.pdf" target="_blank" rel="noopener noreferrer">Stroustrup’s paper </a>on the development of <a href="http://en.cppreference.com/w/" target="_blank" rel="noopener noreferrer">C++</a> through the years. A surprisingly large fraction of the paper discusses how personalities and group behaviour drove the development of C++.&nbsp; Or Dijkstra, who wrote a famous paper titled <em><a href="https://www.cs.utexas.edu/~EWD/transcriptions/EWD01xx/EWD117.html" target="_blank" rel="noopener noreferrer">Programming Considered as a Human Activity</a></em>. But when one thinks about it, how could it be considered anything else?</p>
<h2>Bankers know this</h2>
<p>I know some bankers, and when I first socialized with them, and I was taken aback by the bravado and the backslapping. But bankers already know that <strong>banking has almost nothing to do with money</strong>. It’s got to do with relationships and ideas, and banking’s nature is mostly explained by this fact.</p>
<p>It’s the same with software development.</p>
<p>Money and software share much in common. Neither really exists in the physical world. Yet both are powerful because of the huge influence each has, the power of each to effect real change. One could summarize this as <em>the less real the final product</em>, <em>the more important to its success is the relationships between the people who build it</em>.</p>
<h2>Traps for young players</h2>
<p>It often takes many years to truly realize – to really accept – this single,&nbsp;overarching, truth about software development. Many developers resent this reality, especially when they are younger — after all, developers are often drawn to computers for the very reason that computers are not people.</p>
<p>When I first started programming professionally it was at a large telecommunications firm. I quickly discovered how much decision making was controlled by non-engineering personnel. It took a few years for me to fully understand why. It’s because the world is not driven by engineering. It may be built by engineers, which makes me so proud of our role, but it’s not driven by engineering. And there is a difference.</p>
<h2>Forget everything else</h2>
<p>Unless you’re planning to develop your project solo, forget about your ideas and the intrinsic talent of your team. Forget about it all <strong>until</strong> you realise that it will be how coherently your team works, how well they communicate with each other, the process in place that empowers them, the pride they derive from their work, how involved they feel – it is all this that will make the difference.<br>
When it comes to successful software development only the people matter.</p>
	</div></div>]]>
            </description>
            <link>https://www.philipotoole.com/software-development-got-nothing-computers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25875204</guid>
            <pubDate>Fri, 22 Jan 2021 19:24:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Find lesser known artists on Spotify with my playlist generation tool]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25875175">thread link</a>) | @l1am0
<br/>
January 22, 2021 | https://tastemaker.cc/newcomers/ | <a href="https://web.archive.org/web/*/https://tastemaker.cc/newcomers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://tastemaker.cc/newcomers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25875175</guid>
            <pubDate>Fri, 22 Jan 2021 19:22:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fundamental Mechanism of Scaling]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25875156">thread link</a>) | @ignoramous
<br/>
January 22, 2021 | https://brooker.co.za/blog/2021/01/22/cloud-scale.html | <a href="https://web.archive.org/web/*/https://brooker.co.za/blog/2021/01/22/cloud-scale.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">


<p>It's not Paxos, unfortunately.</p>


<p>A common misconception among people picking up distributed systems is that replication and consensus protocols—Paxos, Raft, and friends—are the tools used to build the largest and most scalable systems. It's obviously true that these protocols are important building blocks. They're used to build systems that offer more availability, better durability, and stronger integrity than a single machine. At the most basic level, though, they don't make systems scale.</p>

<p>Instead, the fundamental approach used to scale distributed systems is <em>avoiding</em> co-ordination. Finding ways to make progress on work that doesn't require messages to pass between machines, between clusters of machines, between datacenters and so on. The fundamental tool of cloud scaling is coordination avoidance.</p>

<p><strong>A Spectrum of Systems</strong></p>

<p>With this in mind, we can build a kind of spectrum of the amount of coordination required in different system designs:</p>

<p><em>Coordinated</em> These are the kind that use paxos, raft, chain replication or some other protocol to make a group of nodes work closely together. The amount of work done by the system generally scales with the offered work (<em>W</em>) and the number of nodes (<em>N</em>), something like O(<em>N</em> * <em>W</em>) (or, potentially, worse under some kinds of failures).</p>

<p><em>Data-dependent Coordination</em> These systems break their workload up into uncoordinated pieces (like shards), but offer ways to coordinate across shards where needed. Probably the most common type of system in this category is sharded databases, which break data up into independent pieces, but then use some kind of coordination protocol (such as two-phase commit) to offer cross-shard transactions or queries. Work done can vary between O(<em>W</em>) and O(<em>N</em> * <em>W</em>) depending on access patterns, customer behavior and so on.</p>

<p><em>Leveraged Coordination</em> These systems take a coordinated system and build a layer on top of it that can do many requests per unit of coordination. Generally, coordination is only needed to handle failures, scale up, redistribute data, or perform other similar management tasks. In the happy case, work done in these kinds of systems is O(<em>W</em>). In the bad case, where something about the work or environment forces coordination, they can change to O(<em>N</em> * <em>W</em>) (see <a href="http://brooker.co.za/blog/2019/05/01/emergent.html">Some risks of coordinating only sometimes</a> for more). Despite this risk, this is a rightfully popular pattern for building scalable systems.</p>

<p><em>Uncoordinated</em> These are the kinds of systems where work items can be handled independently, without any need for coordination. You might think of them as embarrassingly parallel, sharded, partitioned, geo-partitioned, or one of many other ways of breaking up work. Uncoordinated systems scale the best. Work is always O(<em>W</em>).</p>

<p>This is only one cut through a complex space, and some systems don't quite fit<sup><a href="#foot1">1</a></sup>.  I think it's still useful, though, because by building a hierarchy of coordination we can think clearly about the places in our systems that scale the best and worst. The closer a system is to the uncoordinated end the better it will scale, in general.</p>

<p><strong>Other useful tools</strong></p>

<p>There are many other ways to approach this question of when coordination is necessary, and how that influences scale.</p>

<p>The CAP theorem<sup><a href="#foot2">2</a></sup>, along with a rich tradition of other impossibility results<sup><a href="#foot3">3</a></sup>, places limits on the kinds of things systems can do (and, most importantly, the kinds of things they can offer to their clients) without needing coordination. If you want to get into the details there, the breakdown in Figure 2 of <a href="http://www.bailis.org/papers/hat-vldb2014.pdf">Highly Available Transactions: Virtues and Limitations</a> is pretty clear. I like it because it shows us both what is possible, and what isn't.</p>

<p>The <a href="https://arxiv.org/pdf/1901.01930.pdf">CALM theorem</a><sup><a href="#foot4">4</a></sup> is very useful, because it provides a clear logical framework for whether particular programs can be run without coordination, and something of a path for constructing programs that are coordination free. If you're going to read just one distributed systems paper this year, you could do a lot worse than <a href="https://arxiv.org/pdf/1901.01930.pdf">Keeping CALM</a>.</p>

<p><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.411">Harvest and Yield</a> is another way to approach the problem, by thinking about when systems can return partial results<sup><a href="#foot4">4</a></sup>. This is obviously a subtle topic, because the real question is when your clients and customers can accept partial results, and how confused they will be when they get them. At the extreme end, you start expecting clients to write code that can handle any subset of the full result set. Sometimes that's OK, sometimes it sends them down the same rabbit hole that CALM takes you down. Probably the hardest part for me is that partial-result systems are hard to test and operate, because there's a kind of mode switch between partial and complete results and <a href="https://aws.amazon.com/builders-library/avoiding-fallback-in-distributed-systems/">modes make life difficult</a>. There's also the minor issue that there are 2<sup>N</sup> subsets of results, and testing them all is often infeasible. In other words, this is a useful too, but it's probably best not to expose your clients to the full madness it leads to.</p>

<p>Finally, we can think about the work that each node needs to do. In a <em>coordinated</em> system, there is generally one or more nodes that do O(<em>W</em>) work. In an uncoordinated system, the ideal node does O(<em>W</em>/<em>N</em>) work, which turns into O(1) work because <em>N</em> is proportional to <em>W</em>.</p>

<p><strong>Footnotes</strong></p>

<ol>
<li><a name="foot1"></a> Like systems that coordinate heavily on writes by mostly avoid coordination on reads. <a href="https://www.usenix.org/legacy/event/usenix09/tech/full_papers/terrace/terrace.pdf">CRAQ</a> is one such system, and a paper that helped me fall in love with distributed systems. So clever, and so simple once you understand it.</li>
<li><a name="foot2"></a> Best described by <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.6951&amp;rep=rep1&amp;type=pdf">Brewer and Lynch</a>.</li>
<li><a name="foot3"></a> See, for example, Nancy Lynch's 1989 paper <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.13.5022">A Hundred Impossibility Proofs for Distributed Computing</a>. If there were a hundred of these in 1989, you can imagine how many there are now, 32 years later. Wow, 1989 was 32 years ago. Huh.</li>
<li><a name="foot4"></a> I wrote <a href="http://brooker.co.za/blog/2014/10/12/harvest-yield.html">a post</a> about it back in 2014.</li>
</ol>


</div></div>]]>
            </description>
            <link>https://brooker.co.za/blog/2021/01/22/cloud-scale.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25875156</guid>
            <pubDate>Fri, 22 Jan 2021 19:21:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The widening gyre: how to decentralize Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25875107">thread link</a>) | @ur-whale
<br/>
January 22, 2021 | https://laanwj.github.io/2021/01/21/decentralize.html | <a href="https://web.archive.org/web/*/https://laanwj.github.io/2021/01/21/decentralize.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Recent events have made me reflect on a few things in my life I was already thinking about for a while. Also, responses on social media have made me realize that people have <em>strange</em> expectations from me, and what my role in the Bitcoin Core project is.</p>

<h2 id="growth">growth</h2>

<p>Bitcoin has grown a lot since I started contributing to it in 2011. Some arrangements that were acceptable for a small scale FOSS project are no longer so for one runing a 600 billion dollar system. Market cap is famously deceptive, but my point is not about specific numbers here.</p>

<p>One thing is clear: this is a serious project now, and we need to start taking decentralization seriously.</p>

<h2 id="moving-on">moving on</h2>

<p>I realize I am myself somewhat of a centralized bottleneck. And although I find Bitcoin an extremely interesting project and believe it’s one of the most important things happening at the moment, I also have many other interests. It’s also particularly stressful and I don’t want it, nor the bizarre spats in the social media around it, to start defining me as a person.</p>

<h2 id="spreading-out">spreading out</h2>

<p>I will start by delegating my own tasks, and decreasing my involvement. I do not intend to stop contributing to Bitcoin, or even to the Bitcoin Core project, but I would like to remove myself from the critical path and take (even more) of a background role.</p>

<p>Note that we had a nice growth in development activity, and that maintenance of the code itself has already been spread over multiple people for a while. I’m not the most active maintainer. Looking at the number of git merges</p>

<div><div><pre><code>bitcoin<span>$ </span>git log <span>--pretty</span><span>=</span><span>"format:%cn"</span> <span>--merges</span> <span>--since</span><span>=</span>2020-01-01 | <span>sort</span>| <span>uniq</span> <span>-c</span>
    313 fanquake
     51 Jonas Schnelli
    727 MarcoFalke
      7 Pieter Wuille
     65 Samuel Dobson
    363 Wladimir J. van der Laan
</code></pre></div></div>

<p>Only about 24% of the merges were done by me, last year.</p>

<h2 id="plans">plans</h2>

<p>But there’s plenty of things left to figure out, from the top of my head:</p>

<ul>
  <li>
    <p>Decentralize distribution.</p>

    <ul>
      <li>
        <p>In the short run, transfer bitcoincore.org to an organization instead of private ownership. Reduce the “bus factor”.</p>
      </li>
      <li>
        <p>I think it would be good if some other organizations set up mirrors, so there is less incentive to try to take bitcoincore.org down.</p>
      </li>
      <li>
        <p>In the long run, move away from a website for code distribution completely. No matter who owns it, a website on the clearnet can be shut down with the press of a button, and it seems that the global internet is gearing up to make censorship increasingly easy. We need a decentralized web. For us, one option would be IPFS, which is starting to catch on. For the binaries themselves there’s already the option of downloading through torrents.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Decentralize the release process, and release signing.</p>

    <ul>
      <li>
        <p>Delegate more parts of the release process. Other maintainers should be able to do a release without my involvement.</p>
      </li>
      <li>
        <p>Rename the GPG key used to sign <code>SHA256SUMS.asc</code> to “Bitcoin Core release signing key”, instead of having it in my personal title. Make some construct so that N of M (minimally) trusted gitian signers doing a succesful build automatically results in a signed distribution.</p>
      </li>
      <li>
        <p>Same for the native code signing for Windows and MacOS.</p>
      </li>
      <li>
        <p>Even better in the long run would be to split up the keys, e.g. though RSA threshold signing, so that the whole process is geographically distributed.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Decentralize the development hub.</p>

    <ul>
      <li>It’s not clear whether github can be trusted to act in our interest in the long run. Although issues and PRs are backed up through the API, having to move somewhere else could give significant interruption in development. And hopping from provider to provider would be awful—ideally the whole thing would not rely on a central server <em>at all</em>. For this I’ve been watching the <a href="https://radicle.xyz/">radicle</a> project, a P2P distributed code collaboration platform. It’s not quite there yet, but seems promising.</li>
    </ul>
  </li>
</ul>

<p>Bitcoin is quite different in some of the requirements here from other FOSS projects, so we’ll have to develop some tools as we go. We could also, definitely, use some help here.</p>

<p>Some smaller things to consider:</p>

<ul>
  <li>
    <p>Find someone else who wants to do the IRC meeting chair instead of me. Or maybe rotate it between multiple people.</p>
  </li>
  <li>
    <p>Release (and release candidate) mails to the <code>bitcoin-dev</code> and <code>bitcoin-core-dev</code> lists will no longer be necessarily signed and sent by me.</p>
  </li>
  <li>
    <p>There’s some development specific tooling hosted by me (e.g. the PR notification bots on IRC and mastodon). As they are non-critical and only little time goes into maintaining them, I’m fine with this for now.</p>
  </li>
</ul>

<p>As for decentralizing Bitcoin’s node software itself:</p>

<ul>
  <li>Carl Dong’s <code>libbitcoin_kernel</code> work. Bitcoin Core is a large monolithic project which includes the consensus code, which is much more critical than the other parts. The kernel would be an isolated part with well-defined interface, and at some point, its own review flow for changes. The difference with previous <code>libbitcoin_consensus</code> plans is that the kernel is stateful: it includes UTXO management and validation. It however does not include P2P, mempool policy, wallet, GUI, and RPC code. It could be re-used in different clients, to have more diversity in clients, but without the risks of a deviating consensus implementation.</li>
</ul>

<p>Over the course of 2021 this will be my focus with regard to Bitcoin Core.</p>

  </div></div>]]>
            </description>
            <link>https://laanwj.github.io/2021/01/21/decentralize.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25875107</guid>
            <pubDate>Fri, 22 Jan 2021 19:16:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Floating Point Basics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25875101">thread link</a>) | @recursivelambda
<br/>
January 22, 2021 | https://hampuswessman.se/2021/01/floating-point-basics/ | <a href="https://web.archive.org/web/*/https://hampuswessman.se/2021/01/floating-point-basics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><p><a href="https://hampuswessman.se/categories/mathematics">Mathematics</a> |
<time datetime="2021-01-22T18:40:00Z">2021-01-22</time>.
Edited
<time datetime="2021-01-24T10:23:45Z">2021-01-24</time>.
8
min read (2011 words).</p></header><p>What are floating-point numbers? When is it a bad idea to compare them? How
precise are they? Let’s explore this.</p><p>Contents:</p><nav id="TableOfContents"><ol><li><a href="#a-floating-point-mystery">A floating-point mystery</a></li><li><a href="#what-is-a-floating-point-number">What is a floating-point number?</a></li><li><a href="#representation-errors">Representation errors</a></li><li><a href="#using-decimal-numbers-on-computers">Using decimal numbers on computers</a></li><li><a href="#rounding-and-machine-epsilon">Rounding and machine epsilon</a></li><li><a href="#common-floating-point-number-formats">Common floating-point number formats</a></li><li><a href="#conclusions">Conclusions</a></li></ol></nav><h3 id="a-floating-point-mystery">A floating-point mystery</h3><p>It’s common knowledge in programming that comparing floating-point numbers for
equality is rarely a good idea. My favourite example is:</p><p>$$1.1 \times 1.1 = 1.21\text{.}$$</p><p>This is mathematically true. However, in almost all programming languages, it
happens to be <strong>false</strong>! You can try this in Python, JavaScript, Java, Haskell,
C++, and many more languages. Most languages on most platforms will give the
same result. Some languages (such as C++) leave details unspecified so that it
can vary by platform, but almost all hardware platforms handle floating-point
numbers the same or similarly anyway.</p><p>Let’s try Python:</p><div><pre><code data-lang="python 3"><span>&gt;&gt;&gt;</span> <span>1.1</span> <span>*</span> <span>1.1</span> <span>==</span> <span>1.21</span>
<span>False</span></code></pre></div><p>Another simple example is:</p><div><pre><code data-lang="python 3"><span>&gt;&gt;&gt;</span> <span>0.1</span> <span>+</span> <span>0.2</span> <span>==</span> <span>0.3</span>
<span>False</span></code></pre></div><p>Why does this happen? It’s not a bug. Let’s dive deeper to find out.</p><h3 id="what-is-a-floating-point-number">What is a floating-point number?</h3><p>In mathematics, there are the <em>real numbers</em>. Unfortunately, the set of all real
numbers is infinite (uncountably infinite even!) and it’s therefore impossible
to represent them all on physical computers with limited memory. The same occurs
when writing down real numbers on a finite amount of paper. The typical solution
for writing (some) real numbers is to use the <a href="https://en.wikipedia.org/wiki/Decimal">decimal
system</a>.</p><p>The decimal system uses the base ten to represent numbers through digits (from 0
to 9) that are arranged after each other with an optional decimal separator for
fractions. This is well known. For example:</p><p>$$31.416 = 3 \times 10^1 + 1 \times 10^0 + 4 \times 10^{-1} + 1 \times 10^{-2} +
6 \times 10^{-3}\text{.}$$</p><p>This system has its limitations. An infinitely long decimal number is needed to
represent some rational numbers and all <a href="https://en.wikipedia.org/wiki/Irrational_number">irrational
numbers</a>. For example:</p><p>$$\frac{1}{3} = 0.333333 \dots$$</p><p>Both on paper and in computer hardware, only a finite number of digits can be
represented. Therefore, some real numbers can’t be accurately described.</p><p>Floating-point numbers are very similar to this concept and usually follow the
<a href="https://en.wikipedia.org/wiki/IEEE_754">IEEE 754</a> standard, at least partially,
nowadays. IEEE 754 defines floating-point formats using base 10, but these are
unusual. It’s more efficient to use base 2, which is what most hardware supports
natively.</p><p>Each floating-point format can only represent a finite set of real numbers
accurately. They have limited <em>precision</em> and <em>range</em>.</p><p>One way to represent floating-point numbers mathematically is:</p><p>$$s \times \beta^{e}\quad s,\beta,e \in \Z.$$</p><p>Here, $s$ is the significand (including sign), $\beta$ is the base (usually 2),
and $e$ is the exponent. This leaves some redundancy that IEEE 754 employs extra
tricks to get around and to be able to represent certain special numbers
(infinity and not-a-number / NaN). Such extensions will be ignored here.</p><p>Depending on the exact floating-point format, both $s$ and $e$ are limited to
some finite integer intervals. The IEEE 754 formats all have a fixed size, such
that the number of bits allocated for each part put fixed restrictions on how
large these intervals can be. The valid interval of $s$ determines the
precision, whereas the valid exponents determine the range.</p><p>IEEE 754 floating-point numbers are not represented exactly like this, but the
simplified representation conveys the basic concept while it avoids having to
deal with non-essential special cases.</p><h3 id="representation-errors">Representation errors</h3><p>As already seen above, some real numbers can’t be represented accurately as
finite decimal numbers. $1/3$ is one such number.</p><p>For rational numbers of the form $p/q$, where $p$ and $q$ are integers with no
common non-trivial divisor (i.e. other than $\pm 1$), the number can be accurately
represented as a finite decimal number if and only if it’s possible to write</p><p>$$m q = 10^n,$$</p><p>for some $m, n \in \Z$ (i.e. any integers). We can then rewrite the number:</p><p>$$\frac{p}{q} = \frac{m p}{m q} = m p \times 10^{-n},$$</p><p>which is easy to write as a finite decimal number. By referring to the
<a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_arithmetic">unique-prime-factorization
theorem</a>, it
can be seen that this is possible only if $q$ contains no other prime factors
than those of the base, which are 2 and 5 for base 10.</p><p>As such, $1/2$, $1/5$, and $1/800$ are all possible to write as decimal numbers
with finitely many digits. The opposite goes for $1/3$, $1/6$, $1/7$, and
similar. Irrational numbers such as $\pi$ and $\sqrt{2}$ are infinitely long in
all integer<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> bases.</p><p>For base 2, the difference is that only fractions that are powers of two (i.e.
$1/2^n$, $n \in \Z^+$) can be represented accurately without infinite digits.
Since this is not the case for $1/10$, many numbers that can be represented in
base 10 using finite digits require infinite digits to be represented in base 2.</p><p>The same reasoning applies directly to floating-point numbers. Another potential
reason that a real number can’t be represented as a floating-point number is
that it’s out of range. This is much less interesting, however, and not unique
to floating-point numbers, so it will be ignored.</p><p>Let’s decide on an example floating-point format for some examples. Assume that
$|s| \leq 999$ and $\beta = 10$. The closest floating-point number to $1/3$ is
then:</p><p>$$\frac{1}{3} \approx 333 \times 10^{-3} = 0.333.$$</p><p>By changing to $\beta = 2$, a close approximation becomes:</p><p>$$\frac{1}{3} \approx 683 \times 2^{-11} \approx 0.3335.$$</p><p>This is due to limited precision. If the valid interval of $s$ was extended, we
could get better approximations. With infinite precision (i.e. a never-ending
continuation of digits), an exact representation would be theoretically
possible.</p><p>The same happens when approximating 0.1, 0.2, 0.3, and 1.1 using binary IEEE 754
floating-point numbers. This can be seen directly in Python:</p><div><pre><code data-lang="python 3"><span>&gt;&gt;&gt;</span> <span>'</span><span>{:.20}</span><span>'</span><span>.</span><span>format</span><span>(</span><span>0.1</span><span>)</span>
<span>'0.10000000000000000555'</span></code></pre></div><h3 id="using-decimal-numbers-on-computers">Using decimal numbers on computers</h3><p>There are both base-10 floating-point numbers defined by IEEE 754 and there are
libraries in most programming languages for representing decimal numbers without
conversion to base 2.</p><p>By switching to base 10 in Python, our original problem disappears:</p><div><pre><code data-lang="python 3"><span>&gt;&gt;&gt;</span> <span>from</span> <span>decimal</span> <span>import</span> <span>Decimal</span>
<span>&gt;&gt;&gt;</span> <span>Decimal</span><span>(</span><span>'1.1'</span><span>)</span> <span>*</span> <span>Decimal</span><span>(</span><span>'1.1'</span><span>)</span> <span>==</span> <span>Decimal</span><span>(</span><span>'1.21'</span><span>)</span>
<span>True</span></code></pre></div><p>This can, of course, be convenient since decimal numbers are more intuitive to
most people. As have already been demonstrated above, the fundamental
limitations are still there, however, and decimal numbers usually bring a
considerable performance decrease with them.</p><p>Other alternatives are <em>fixed-point arithmetic</em>, where the exponent is fixed.
This used to be much faster than floating-point arithmetic on old hardware
without hardware support for floating-point arithmetic. Nowadays, floating-point
arithmetic is very fast due to built-in floating-point units in processors.</p><h3 id="rounding-and-machine-epsilon">Rounding and machine epsilon</h3><p>To approximate numbers that can’t be represented exactly, <em>rounding</em> is used.
This is used when converting decimal numbers to binary floating-point numbers,
as seen above. Rounding is also necessary when performing operations on the
floating-point numbers, i.e. <em>floating-point arithmetic</em>.</p><p>IEEE 754 requires <em>correct rounding</em> for floating-point arithmetic, which means
that the errors introduced are only cased by rounding. More precisely, this
requires that the result of an operation is the same as if it was carried out
exactly and the result was then rounded. IEEE 754 defines multiple rounding
modes and the default is the familiar <em>round to nearest</em>. IEEE 754 hardware uses
extra guard digits during computations to achieve correct rounding. This means
that we only need to analyse <em>rounding errors</em>.</p><p>The absolute size of rounding errors will vary depending on the exponent for
floating-point numbers. For error analysis, it’s therefore more useful to study
the relative error. Let $b = round(a)$ be the value after rounding the number
$a$. The relative rounding error is then:</p><p>$$\eta = \left |\frac{a-b}{a} \right |, \quad a \neq 0.$$</p><p>It’s possible to determine an upper bound of the relative error $\eta$ for each
floating-point format, which is called <em>machine epsilon</em>. This is a useful
measure of the format’s precision.</p><p><strong>Definition</strong>. Machine epsilon ($\epsilon$) for a specific format:</p><p>$$\epsilon \geq \left |\frac{a-round(a)}{a} \right |,$$</p><p>for all $a \in \mathbb{R \backslash \{0\}}$ that are within the valid range of
the floating-point format.</p><p>The relative rounding error for large out-of-range numbers is clearly close to 1
and not interesting. Note the $\geq$ here. It’s useful as long as it’s an upper
bound and relatively tight. It can be chosen as the supremum (least upper
bound), but simplicity is also important. Machine epsilons like this are
presented in the table further down for the most common IEEE 754 formats.</p><p>Unfortunately, <em>machine epsilon</em> is sometimes defined as the distance between
$1.0$ and the smallest larger number. This is about twice the (smallest) machine
epsilon according to the definition above for binary formats (so it can be
converted easily and is also an upper bound). Many programming languages and
libraries use this definition instead. Depending on the analysis performed a
constant factor of 2 might give a tight-enough bound regardless.</p><p>Once we know the machine epsilon according to the definition above, we can
calculate a bound of the absolute error when performing floating-point
arithmetic. Let $x$ and $y$ be two floating-point numbers of the same format
with machine epsilon $\epsilon$. The absolute rounding error of their product is
then:</p><p>$$|x \times y - round(x \times y)| \leq \epsilon |x \times y| \approx \epsilon
|round(x \times y)|.$$</p><p>It’s worth pointing out that the rounding error can be zero, if the number can
be exactly represented. Therefore, the lower bound of rounding errors is always
zero for all floating-point formats, since they can all represent some numbers.</p><p>There’s more to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hampuswessman.se/2021/01/floating-point-basics/">https://hampuswessman.se/2021/01/floating-point-basics/</a></em></p>]]>
            </description>
            <link>https://hampuswessman.se/2021/01/floating-point-basics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25875101</guid>
            <pubDate>Fri, 22 Jan 2021 19:16:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reviewing Trump's Presidency]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25875068">thread link</a>) | @mellosouls
<br/>
January 22, 2021 | https://www.readtangle.com/p/grading-donald-trump-presidency-promises | <a href="https://web.archive.org/web/*/https://www.readtangle.com/p/grading-donald-trump-presidency-promises">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>I’m Isaac Saul, and this is Tangle: an independent, ad-free, subscriber-supported politics newsletter that summarizes the best arguments from across the political spectrum — then “my take.” You can subscribe by <a href="https://tangle.substack.com/subscribe">clicking here</a>.</p></blockquote><p>A first look at the presidency of Donald Trump. </p><p>Encapsulating Donald Trump in a single newsletter is impossible.&nbsp;</p><p>Critics of his presidency loathe to admit it, but he was — for better or for worse — one of the most consequential presidents in American history. He was also historic: the wealthiest president ever, the first president to be impeached twice, perhaps the most “outsider” president of all time, one of the oldest presidents ever, and — by party differences in approval ratings alone — the most divisive president in modern U.S. history.</p><p>There are many things we could focus on when discussing Trump’s ascendence to the White House: why he was elected, what he was elected to do, what his election means about America, what it meant for America, how it changed the world, and why so many millions of Americans supported someone loathed by so many people who represent America’s most important institutions (hint: part of the answer is in the question).&nbsp;</p><p>We could also talk a lot about his campaign: the tactics he used to invigorate non-voters, the rallies, the Access Hollywood tape, the paying off adult actresses, the Russia investigation. But most of this is dated news now, though we reference it in the pages to come if for no other reason than to contextualize parts of his time in office.&nbsp;</p><p>Instead, today we’re going to look simply at the accomplishments and failures of Trump’s presidency — what he promised to do against what he actually did, the state he leaves the country in, and how his actions may change the future of politics and the Republican Party in particular.</p><p>For all the noise, Trump ran on a few key campaign promises: he was going to build a wall (and make Mexico pay for it), make immigration harder, bring our troops home, repeal and replace Obamacare, cut taxes, renegotiate trade deals, and appoint conservative judges. When discussing his presidency, it seems worthwhile to start with these major issues. </p><p>To address these promises, I’m going to employ a “promise meter” — on a scale of 1 to 10 — with 10 being the highest rating for a promise kept (promise was completely fulfilled), and 1 being the lowest (promise was not fulfilled in any way). I am not trying to evaluate whether these are <em>good or effective </em>policies, but instead whether Trump accomplished what he said he would.</p><p><strong>The border wall: </strong>Trump’s wall, of course, was the signature promise of his campaign. It wasn’t just about a physical barrier on the border, but a symbol that America was going to “secure the border” and keep out anyone or anything that was a threat to Americans’ safety or even an American job.</p><p>Throughout the campaign, Trump was specific about two things: he’d build about 1,000 miles of wall and he’d make Mexico pay for it. The <em>way </em>Mexico would pay for it morphed over time (from direct payments, to taxes, to tariffs), but it’s mostly irrelevant since Mexico never really paid for the wall in any way. American taxpayers have footed the entire bill.&nbsp;</p><p>All told, the Trump administration built just about 400 miles of wall along the border — but only 16 miles of it constituted a new barrier. The rest, by the Trump administration’s own admission, was reinforcing or repairing barriers or fencing that already existed, though in some places it had become so decrepit that it was as good as building a new wall.&nbsp;</p><p>Initially, whether because of the wall or family separation or Trump’s general posture toward immigrants, illegal crossings on the border dropped dramatically, reaching their lowest levels in about 50 years. But by 2019, they were back at the highest levels they had been in a decade. Then, in 2020, they dropped again precipitously — in large part, experts say, due to COVID-19.&nbsp;</p><p>In the end, the border wall manifested in places along our southwestern border and it had decidedly mixed results in preventing illegal crossings. It was not paid for by Mexico, and even if you include all the rebuilt sections as part of 1,000 miles of new border wall, it’s still only about 40% complete. Given that he had to divert funding from the military to construct the wall because he faced such serious opposition from his own party and Democrats, it’s in some ways impressive he built as much as he did. Generously, at 40% completion, it seems fair to give Trump a 4 out of 10, with a point deduction for not getting Mexico to pay for it.&nbsp;</p><p><em>Promise meter: <strong>3 out of 10.&nbsp;</strong></em></p><p><strong>Immigration: </strong>We’ve discussed this quite a bit in Tangle, but the Trump administration has been relentlessly focused on reducing legal immigration, too. The president suspended immigration from many volatile regions in the world, and some may argue followed through on a “Muslim ban” by stopping immigration from Syria, Libya and several other Muslim majority countries.</p><p>But while so much of the focus was understandably on border walls and Muslim bans, nursing babies being pulled from their mothers and children in cages on the border, a lot of people missed another side of this story. As The Washington Post put it, <a href="https://www.washingtonpost.com/opinions/2020/10/29/trump-immigration-daca-family-separation/?arc404=true&amp;itid=lk_inline_manual_27">“Trump didn’t build his wall with steel, he built it out of paper.”</a> For all the claims that the Trump administration was hectic, unfocused or inexperienced, it was remarkably good at reducing <em>legal</em> immigration. We will admit half the number of legal immigrants this fiscal year as we did in 2016, and we’ll see the lowest levels of legal immigration in America since 1987 — when the U.S. population was “about a quarter smaller, substantially younger and less in need of working-age immigrants than it is today,” according to The Washington Post.&nbsp;</p><p>Not only that, but these aren’t the kinds of executive orders that can simply be undone. Immigration experts agree that the number of new immigrants in America will be reduced for the coming years. Before Trump took office, the overall number of legal immigrants was growing while the overall number of illegal immigrants was shrinking. Since he took office, we have entered a new phase where the legal immigrations have been halved and the rate of new undocumented immigrants has, in the end, <a href="https://www.pewresearch.org/fact-tank/2020/03/02/how-border-apprehensions-ice-arrests-and-deportations-have-changed-under-trump/">basically stayed the same</a>.&nbsp;</p><p>If Trump’s supporters believe we needed to significantly reduce immigrants in the U.S., and elected Trump to act on those promises, they got what they voted for.</p><p><em>Promise meter: <strong>8 out of 10.&nbsp;</strong></em></p><p><em><strong>Bringing our troops home: </strong></em>Key to Trump’s outsider status was a pair of promises he made that many other Republicans didn’t: bringing our troops home from endless wars abroad while also beefing up the military.</p><p>Again, Trump faced serious opposition to this stated goal, even from the people working inside his administration. And while troop levels in Afghanistan are the lowest they’ve been in years, on the whole, the numbers show Trump did not really come close to accomplishing his goals. Not only did he promise to <em>reduce </em>troop levels, he at times promised to bring them to zero in various parts of the world.</p><p>When Trump entered office, we had just over 200,000 troops overseas. Today, that number is just under 200,000, according to Department of Defense data. That’s because, while Trump often had high-profile withdrawals in a place like Syria, he was frequently moving those troops to a nearby place like the Persian Gulf or deploying new troops altogether.</p><p>He deserves a lot of credit for not starting any new interventions, something unique to most presidents, but he never did fulfill this promise, despite his efforts.</p><p><em><strong>Promise meter: 3 out of 10.&nbsp;</strong></em></p><p><strong>Repeal and replace Obamacare: </strong>This one is a lot simpler. Trump came close to repealing the law in his first year in office, but the now-famous John McCain thumbs down vote on the floor of the Senate killed his effort to repeal Obamacare. When Democrats cleaned up in the midterms, any hopes of taking the law down vanished. Trump has repeatedly and unambiguously promised to come forward with a new “better and cheaper” Republican health care plan to replace Obamacare, and that also has never materialized — despite his making the promise over and over again.</p><p>On the whole, this is perhaps the greatest policy failure of his presidency.</p><p><em><strong>Promise meter: 1 out of 10.&nbsp;</strong></em></p><p><strong>Cutting taxes and regulations: </strong>This one is simple, too, albeit with a touch of nuance. Trump’s signature legislative achievement was the 2017 tax bill, which reduced taxes for most Americans (the nuance being in how many of those reductions will expire, and for whom) and ushered in a new era of lower tax rates for corporations and the wealthy.</p><p>While some have argued the tax cut was about a quarter of the size Trump promised, it was still a major overhaul that was met cheerfully by many of his supporters. The overall popularity of the bill has waned, though, and it’s now one of the least popular pieces of major legislation passed in recent memory. Which makes evaluating this promise more difficult.&nbsp;</p><p>In the end, Trump promised to cut corporate tax rates and cut taxes for middle-income Americans — and that’s what he did. Though it seems the wealthiest Americans and corporations got a far better end of the deal. He gets knocked a couple of points for falling short of the stated rates and because the bill mostly favored the wealthy, and became deeply unpopular, but he mostly did what he said he would.</p><p><em><strong>Promise meter: 8 out of 10.&nbsp;</strong></em></p><p><strong>Renegotiating trade deals: </strong>This one is hard to parse. On the surface, Trump did most of what he said he would: he renegotiated NAFTA and pulled us out of the Trans-Pacific Partnership all while taking an aggressive stance with China.</p><p>Then he signed us into the United States-Mexico-Canada Agreement (USMCA), which was basically an updated version of NAFTA. There were quite a few criticisms of the USMCA, including from me, that its changes to NAFTA were minor. But there absolutely were some big, impactful changes to hiring in pockets of the country …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.readtangle.com/p/grading-donald-trump-presidency-promises">https://www.readtangle.com/p/grading-donald-trump-presidency-promises</a></em></p>]]>
            </description>
            <link>https://www.readtangle.com/p/grading-donald-trump-presidency-promises</link>
            <guid isPermaLink="false">hacker-news-small-sites-25875068</guid>
            <pubDate>Fri, 22 Jan 2021 19:14:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Programmers who Use Spaces Instead of Tabs Make More Money]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25874869">thread link</a>) | @hongzi
<br/>
January 22, 2021 | https://insanelab.com/blog/notes/spaces-vs-tabs/ | <a href="https://web.archive.org/web/*/https://insanelab.com/blog/notes/spaces-vs-tabs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <section data-section="black">
      <img src="https://insanelab.com/wp-content/uploads/2020/10/logo-mark.svg" alt="">
    <div>
          <p><img src="https://insanelab.com/wp-content/uploads/2019/01/tabs-vs-spaces-1-scaled.jpg" alt="">
      </p>
        <div>
      <div data-aos="fade-right">
        <h4>July 27, 2018 - Notes</h4>
        <h3>Why Programmers Who Use Spaces Instead of Tabs Make More Money</h3>
                
              </div>
    </div>
  </div>
</section>

  <section data-section="black">
    <div>
      <article data-aos="fade-up">
        <p>If you are a member of the programming community, you know all too well about the age-old debate of spaces versus tabs. There are a number of programmers out there that use indentation in their code rather than tabs. This highly debated topic has <strong>divided programmers for years</strong>, but recent data shows that people on the side of using spaces may be right.</p>
<p>Recently, the team at<a href="https://www.businessinsider.com/google-silicon-valley-tabs-spaces-debate-2016-8" target="_blank" rel="nofollow noopener"> Google analyzed a billion files</a> to figure out which technique was better. Their research found that <strong>spaces were far better for a number of different reasons</strong>. Not only is this technique more visually appealing, it allows programmers to <a href="https://insanelab.com/blog/team-augmentation/cheap-software-development-costs-you-more/" target="_blank" rel="noopener">make more money</a>.</p>
<p><img src="https://insanelab.com/wp-content/uploads/2019/02/throwing-money-away.gif" alt="Spaces vs Tabs"></p>
<p>The analysis performed by the&nbsp;<a href="https://stackoverflow.blog/2017/06/15/developers-use-spaces-make-money-use-tabs/" target="_blank" rel="nofollow noopener">team at Stack Overflow</a> found that programmers who use spaces instead of tabs are making more money. David Robinson, the data scientist who performed this study found that programmers using space over tabs made an average of 9 percent more each year than their tab using counterparts.</p>
<p>Read below to find out more about the use of <strong>proper indentation in coding</strong> and how it can benefit you as a programmer.</p>
<h2>The Need For Indentation</h2>

      </article>
    </div>
  </section>
                    <section data-section="black">
    <div>
      <div data-aos="fade-up">
        <p>
          <iframe title="Tabs versus Spaces" width="1280" height="720" src="https://www.youtube.com/embed/SsoOG6ZeyUI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
        </p>
      </div>
    </div>
  </section>
                    <section data-section="black">
    <div>
      <article data-aos="fade-up">
        <p>One of the biggest reasons why most programmers use an indent style is to provide their program with structure. Generally, <strong>this indentation style is used in C programming</strong> and its many descendants. However, it can be applied to other programming languages where the use of whitespace is rendered insignificant.</p>
<p>While indentation is not required in programming languages, it is widely used by some of the best programmers on the planet. Generally, indentation provides a clarification when it comes to control flow constructs. When using things like loops or conditions, you need to clearly show where the code contained outside of these constructs are.</p>
<p><strong>Using indentation in Python</strong> allows you to avoid using braces or keywords to set sets of code apart. Most people new to the world of coding fail to realize that indentation is more for the interpreter and less about the structure of the program itself.</p>

      </article>
    </div>
  </section>
                    <section data-section="black">
  <div>
    <div>
      <p><img src="https://insanelab.com/wp-content/uploads/2018/07/tabs-vs-spaces-2.jpg" alt="" data-aos="zoom-in"></p><p>
          Credits: ZombieMann, devRant
        </p>
          </div>
  </div>
</section>
                    <section data-section="black">
    <div>
      <article data-aos="fade-up">
        <p>When done properly, the indentation will give the reader of the code a level of comfort and understanding. If a code is properly broken up, it will <strong>much easier to comprehend</strong>. By writing code that is easy to review, a programmer can make an impression on prospective employers and increase their earning potential at the same time.</p>
<p>This subject has been covered in depth by Google’s Felipe Hoffa on Medium. Felipe analyzed 400,000 GitHub repositories, 1 billion files, and 14 terabytes of code to determine why spaces might be actually better than tabs.</p>

      </article>
    </div>
  </section>
                    <section data-section="black">
  <div>
    <p><img src="https://insanelab.com/wp-content/uploads/2018/07/tabs-vs-spaces.png" alt="" data-aos="zoom-in">

          </p>
  </div>
</section>
                    <section data-section="black">
    <div>
      <article data-aos="fade-up">
        <h2><b>Other Best Practices to Follow When Writing Code</b></h2>
<p>While indentation is paramount when attempting to write readable and appealing code, there are a number of other best practices you should follow. Below are just some of the practices you need to get accustomed to using.</p>
<h3><b>Documentation and Commenting</b></h3>
<p>With the technological advancements in the world of integrated development environments, commenting on the code is more useful than ever. By following industry standards when developing these comments, you will allow other tools to utilize them in a variety of different ways.</p>
<p><strong>Read also:&nbsp;</strong><a href="https://insanelab.com/blog/resources/tips-vetting-software-development-agency/" target="_blank" rel="noopener"><em>10 Essential Tips for Vetting a Software Development Agency</em></a></p>
<h3><b>Focus on Architecture First</b></h3>
<p>While meeting deadlines is one of the things you will have to focus on to become a great programmer, you need to avoid skipping vital steps. The first thing you need to do before writing any code is to think about the architecture of the program you are working on. Failing to do this can lead to big problems in the long run.</p>
<p>Knowing what your code will be used for and what programs it will be working with is vital. With this information, you can write code that is both effective and bug-free.</p>
<h3><b>Keep It Simple</b></h3>
<p>Writing code that is <strong>overly-complex</strong> can cause major problems when it comes to the functionality of a program. By focusing on writing simple code, you can make it much easier to avoid bugs. Your code should get right to the point rather than using a ton of abstractions. Getting in the habit of writing simple code can benefit you greatly as you try to rise to the top of your industry.</p>
<h3>Code Reviews May Be a Bad Idea</h3>
<p>While there are situations where code reviews can be beneficial, there are times when it can just be a headache. The only way to properly utilize this tool is by working with a developer that understands your codes and can monitor the updates it needs. The main goal of a code review is to maintain the quality of the programming being done, <strong>not to teach new developers</strong>. When this is used as a learning tool, it will typically backfire in spectacular fashion.</p>
<h2><b>Coding Mistakes to Avoid At All Costs</b></h2>
<p>Errors made during the coding process can lead to an application or software program being unstable. It is your job as a programmer to learn more about common coding errors so you can avoid them. If you are interested in learning about common Java performance errors, be sure to&nbsp;<a href="https://www.appoptics.com/monitor/java-performance" target="_blank" rel="nofollow noopener">read more</a> here. Below are just some of the errors you need to steer clear of during the app coding process.</p>
<h3><b>The Reusing Old Code Trap</b></h3>
<p>One of the biggest mistakes you need to avoid when developing a new program is reusing old code. While your client may request this to save time and money, you need to do all you can to talk them out of it. Unless the code in question was specifically designed to be reused, <strong>you will end up basically rewriting it anyway</strong>. This is why starting with a fresh batch of coding is a must when trying to have success.</p>
<h3><b>Failing to Test at Ever Phase of Development</b></h3>
<p>As a programmer, your main goal should be providing your clients with the bug-free code they need. The only way to ensure the code you have written is correct is by testing it at every phase of development. Getting in too big of a hurry will lead to big mistakes and may cause app crashes in the future.</p>
<p>While utilizing the power of space and indentation in your code will take some practice, it will be worth the effort. Finding a more experienced programmer to mentor you on this practice is a great idea that will help you progress at a rapid pace.</p>
<p><img src="https://insanelab.com/wp-content/uploads/2019/02/xinsanelab-clutch.png" alt="Insanelab clutch software development agency"></p>

      </article>
    </div>
  </section>
      
  

  

      <img src="https://insanelab.com/wp-content/uploads/2020/10/logo-mark.svg" alt="">
  </div></div>]]>
            </description>
            <link>https://insanelab.com/blog/notes/spaces-vs-tabs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874869</guid>
            <pubDate>Fri, 22 Jan 2021 19:00:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple plans new MacBook Air with Magsafe, MacBook Pro with SD Card Slot]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25874703">thread link</a>) | @fudgy
<br/>
January 22, 2021 | https://www.bloomberg.com./news/articles/2021-01-22/apple-aapl-plans-new-macbook-air-with-magsafe-macbook-pro-with-sd-card-slot | <a href="https://web.archive.org/web/*/https://www.bloomberg.com./news/articles/2021-01-22/apple-aapl-plans-new-macbook-air-with-magsafe-macbook-pro-with-sd-card-slot">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <section>
            <h3>Why did this happen?</h3>
            <p>Please make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our <a href="https://www.bloomberg.com./notices/tos">Terms of Service</a> and <a href="https://www.bloomberg.com./notices/tos">Cookie Policy</a>.</p>
        </section>
        <section>
            <h3>Need Help?</h3>
            <p>For inquiries related to this message please <a href="https://www.bloomberg.com./feedback">contact our support team</a> and provide the reference ID below.</p>
            <p>Block reference ID: </p>
        </section>
    </section></div>]]>
            </description>
            <link>https://www.bloomberg.com./news/articles/2021-01-22/apple-aapl-plans-new-macbook-air-with-magsafe-macbook-pro-with-sd-card-slot</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874703</guid>
            <pubDate>Fri, 22 Jan 2021 18:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating Embedded Microcontrollers [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25874440">thread link</a>) | @Koshkin
<br/>
January 22, 2021 | https://abdullahyildiz.github.io/files/Creating_Embedded_Microcontrollers.pdf | <a href="https://web.archive.org/web/*/https://abdullahyildiz.github.io/files/Creating_Embedded_Microcontrollers.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://abdullahyildiz.github.io/files/Creating_Embedded_Microcontrollers.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874440</guid>
            <pubDate>Fri, 22 Jan 2021 18:23:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wanna See a Whiter White?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25874433">thread link</a>) | @derekdahmer
<br/>
January 22, 2021 | https://kidi.ng/wanna-see-a-whiter-white/ | <a href="https://web.archive.org/web/*/https://kidi.ng/wanna-see-a-whiter-white/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p id="tester">White.</p><div id="info">
    <p>
      Set the display brightness to less than 100%.<br>
      Turn off <a href="https://support.apple.com/en-us/HT205234">Low Power Mode on iOS.</a>
    </p>
    <p>
      The RGB color values of <i>the message</i> and <i>the background</i> are the same.<br>
      Take a screenshot then compare them in an image editor.
    </p>
    <p>
      Your experience may vary depending on browser, OS version, display, everything.<br>
      Tests so far seem to indicate this only works on <b>the Apple platforms.</b>
    </p>
    <details>
        <summary>Test Results</summary>
        <p>Works with <a href="https://support.apple.com/en-us/HT210980">HDR-capable Macs</a> and iPhones:</p>
        <ul>
          <li>Safari / Chrome / Edge, macOS Big Sur, MacBook Air (M1, 2020)</li>
          <li>Safari, macOS Big Sur, MacBook Pro (15-inch, 2018)</li>
          <li>Safari, macOS Big Sur, MacBook Pro (16-inch, 2019)</li>
          <li>Safari, macOS Big Sur, iMac (Retina 5K, 27-inch, 2020)</li>
          <li>iOS 14, iPhone X</li>
          <li>iOS 14, iPhone XS / XR</li>
          <li>iOS 14, iPhone 12 / iPhone 12 Pro</li>
          <li>iOS 14, iPad Pro 11-inch (2nd generation)</li>
        </ul>
        <p>Works with SDR Macs with Blink browsers:</p>
        <ul>
          <li>Chrome / Edge, macOS Big Sur, iMac (Retina 5K, 27-inch, Late 2015)</li>
        </ul>
        <p>Does not work with:</p>
        <ul>
          <li>Firefox (Does not support <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1539685">HDR</a>)</li>
          <li>webOS TV (Does not support <a href="http://webostv.developer.lge.com/discover/specifications/web-engine/">backdrop-filter</a>)</li>
          <li>Chrome, Google Pixel 4a</li>
          <li>Edge, Samsung Galaxy S10</li>
          <li>PlayStation 4</li>
          <li>Xbox Series X (Might crash the console)</li>
          <li>Chrome, Windows 10, LG 27UK600 / LG 34WL600</li>
        </ul>
      </details>
    
    <details>
        <summary>How does this work?</summary>
        <p>
          There are hidden HDR videos playing at the corners of this page. When a HDR-capable browser encounters one, it switches to HDR mode. For some reason, CSS backdrop-filter + brightness &gt;100% combo seems to behave like HDR—reaching beyond the user-controlled display brightness, up to the maximum HDR brightness—while the everything in between follow along. At least that's the overall idea, but I still don't know exactly why it works; especially why with those two CSS properties.
        </p>
        <p>
          Once the system switches to HDR mode, it seems to affect the whole display. That says, as long as you can trigger HDR mode by any means—simply playing an HDR video on Movist, for example—the CSS trick works on Safari / Chrome / Edge with HDR-capable / SDR devices. This indicates this bug/feature is mostly tied to <a href="https://developer.apple.com/documentation/metal/drawable_objects/displaying_hdr_content_in_a_metal_layer">the EDR system.</a>
        </p>
      </details>
    
    <p>
      Project on <a href="https://github.com/kiding/wanna-see-a-whiter-white">GitHub</a>. Short URL <code><a href="https://fff.kidi.ng/">fff.kidi.ng</a></code>.<br>
      Created by <a href="https://kidi.ng/">kiding</a>. Inspired by <a href="https://xenosium.com/">zvuc</a>. 
    </p>
  </div></div>]]>
            </description>
            <link>https://kidi.ng/wanna-see-a-whiter-white/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874433</guid>
            <pubDate>Fri, 22 Jan 2021 18:22:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avalonia 0.10.0 Release – A cross platform XAML framework for .NET]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25874397">thread link</a>) | @wiso
<br/>
January 22, 2021 | http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release | <a href="https://web.archive.org/web/*/http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <dl>
        <dt>Published</dt>
        <dd>2020-12-29</dd>

        <dt>Author</dt>
        <dd>Steven Kirk</dd>

        <dt>Category</dt>
          <dd>Release</dd>
    </dl>
    <p>We are pleased to announce that <a href="https://github.com/AvaloniaUI/Avalonia">Avalonia</a> 0.10.0 has been
released.</p>
<p>0.10 is a huge update, it has been extensively tested and brings some great new features and improvements.</p>
<h2 id="fluent-theme">Fluent Theme</h2>
<p>The most noticable change for Avalonia 0.10 is a beautiful new Fluent theme. Now your Avalonia applications will look better than ever:</p>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/fluent-control-gallery-light.png" alt="Xaml Control Gallery">
<img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/fluent-control-gallery-dark.png" alt="Xaml Control Gallery">
<a href="https://github.com/AvaloniaUI/xamlcontrolsgallery">Xaml Control Gallery</a></p>
<p>The fluent theme is available in light and dark modes, and will be used by the 0.10 templates by default. It can be enabled in existing applications by including the following in your <code>App.axaml</code>:</p>
<pre><code>&lt;Application.Styles&gt;
  &lt;FluentTheme Mode="Light"/&gt;
&lt;/Application.Styles&gt;
</code></pre>
<p>Where <code>Mode</code> can be <code>Light</code> or <code>Dark</code>.</p>
<h2 id="new-controls">New Controls</h2>
<p>Along with the fluent theme, several new controls have been added:</p>
<h3 id="datepickertimepicker">DatePicker/TimePicker</h3>
<p>The <code>DatePicker</code> and <code>TimePicker</code> controls give you a standardized way to let users pick a localized date or time value value using touch, mouse, or keyboard input.</p>
<pre><code>&lt;DatePicker Header="Date of birth"/&gt;
</code></pre>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/datepicker.png" alt="Xaml Control Gallery"></p>
<h3 id="toggleswitch">ToggleSwitch</h3>
<p><code>ToggleSwitch</code> is a control that can be toggled between 2 states.</p>
<pre><code>&lt;ToggleSwitch OffContent="Power Off" OnContent="Power On"/&gt;
</code></pre>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/toggleswitch.png" alt="Xaml Control Gallery"></p>
<h3 id="label">Label</h3>
<p>The <code>Label</code> control allows a text label with a shortcut key to be assocated with a control such as a <code>TextBox</code> such that pressing Alt plus the shortcut key will focus the associated control:</p>
<pre><code>&lt;StackPanel&gt;
  &lt;!-- Pressing Alt+N will focus nameTextBox --&gt;
  &lt;Label Target="nameTextBox"&gt;_Name&lt;/Label&gt;
  &lt;TextBox Name="nameTextBox"&gt;
&lt;/StackPanel&gt;
</code></pre>
<p>The shortcut key is designated by prepending an underscore to the desired character in the <code>Label</code> content, <code>N</code> in this example.</p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4904">https://github.com/AvaloniaUI/Avalonia/pull/4904</a></li>
</ul>
<h2 id="compiled-bindings">Compiled Bindings</h2>
<p>Avalonia 0.10 includes experimental support for compiled bindings. When using compiled bindings, binding paths are verified at compile time and do not use reflection at runtime.</p>
<p>To enable compiled bindings, add an <code>x:DataType</code> attribute to your root control and use the <code>{CompiledBinding}</code> markup extension or set <code>x:CompileBindings="True"</code>.</p>
<pre><code>&lt;Window xmlns="https://github.com/avaloniaui"
        xmlns:x='http://schemas.microsoft.com/winfx/2006/xaml'
        x:Class="AvaloniaApplication"
        xmlns:vm="using:AvaloniaApplication.ViewModels" 
        x:DataType="vm:MainWindowViewModel"&gt;
  &lt;!-- The existence of the MyValue property will be checked at compile-time --&gt;
  &lt;TextBox Text="{CompiledBinding MyValue}"/&gt;
&lt;/Window&gt;
</code></pre>
<p><a href="http://avaloniaui.net/docs/advanced/compiled-bindings">Documentation</a></p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/2734">https://github.com/AvaloniaUI/Avalonia/pull/2734</a></li>
</ul>
<h2 id="unicode-support">Unicode Support</h2>
<p>Avalonia's <code>TextBlock</code> now correctly supports unicode characters.</p>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/unicode.png" alt="Unicode Support"></p>
<p>Full Unicode support for <code>TextBox</code> will be incoming in the near future.</p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/3438">https://github.com/AvaloniaUI/Avalonia/pull/3438</a></li>
</ul>
<h2 id="box-shadows">Box Shadows</h2>
<p>Box shadows can now be applied to <code>Border</code> controls:</p>
<pre><code>&lt;Border BoxShadow="4 4 4 gray"
        Background="Silver"
        Margin="20"
        Padding="10"&gt;
  &lt;TextBlock&gt;Box Shadow&lt;/TextBlock&gt;
&lt;/Border&gt;
</code></pre>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/box-shadow.png" alt="Box Shadows"></p>
<p><a href="http://avaloniaui.net/docs/controls/border#box-shadows">Documentation</a></p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/3871">https://github.com/AvaloniaUI/Avalonia/pull/3871</a></li>
</ul>

<p>DevTools has been completely revamped for the 0.10 release.</p>
<p><img src="http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release/devtools.png" alt="DevTools"></p>
<p>The new features include:</p>
<ul>
<li>A built-in console using roslyn scripting which allows running arbitrary code</li>
<li>Editing of property values</li>
<li>Improved display and grouping of control properties</li>
<li>Filtering control properties using a string or regular expression</li>
<li>A visualization of a control's layout properties such as width, height, margins and padding:</li>
<li>Toggle an FPS overlay and dirty rect visualization for the window from DevTools from the "Options" menu</li>
</ul>
<p><a href="http://avaloniaui.net/docs/quickstart/devtools">Documentation</a></p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/3462">https://github.com/AvaloniaUI/Avalonia/pull/3462</a></li>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4523">https://github.com/AvaloniaUI/Avalonia/pull/4523</a></li>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4529">https://github.com/AvaloniaUI/Avalonia/pull/4529</a></li>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4609">https://github.com/AvaloniaUI/Avalonia/pull/4609</a></li>
</ul>
<h2 id="typed-property-change-notifications">Typed Property Change Notifications</h2>
<p>The <code>OnPropertyChanged</code> method and <code>AvaloniaProperty&lt;T&gt;.Changed</code> observable APIs have been changed to use a typed <code>AvaloniaPropertyChangedEventArgs&lt;T&gt;</code> class to prevent boxing. Note that this is a <a href="https://github.com/AvaloniaUI/Avalonia/wiki/Breaking-Changes">breaking change</a>.</p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/3255">https://github.com/AvaloniaUI/Avalonia/pull/3255</a></li>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4648">https://github.com/AvaloniaUI/Avalonia/pull/4648</a></li>
</ul>
<h2 id="selectionmodel">SelectionModel</h2>
<p>Selection on <code>SelectingItemsControl</code>-derived controls such as <code>ListBox</code> and <code>ComboBox</code> now implement their selection tracking via a <code>SelectionModel</code> which gives the following improvements:</p>
<ul>
<li>Selection ranges are now stored as a range of indexes, so selecting all items in a large list of for example 100,000 elements is now stored simply as a range of <code>0-99999</code>. Previously each selected item was added to a list, inflating memory usage</li>
<li>Selection now handles duplicate items</li>
<li>The selection model can be bound to a view model allowing fine control of the selected items at the view model layer</li>
</ul>
<p><a href="http://avaloniaui.net/docs/controls/listbox#selection">Documentation</a></p>
<p>Related PRs:</p>
<ul>
<li><a href="https://github.com/AvaloniaUI/Avalonia/pull/4533">https://github.com/AvaloniaUI/Avalonia/pull/4533</a></li>
</ul>
<h2 id="breaking-changes">Breaking Changes</h2>
<p>See <a href="https://github.com/AvaloniaUI/Avalonia/wiki/Breaking-Changes">our wiki</a> for a list of breaking changes in this release.</p>
<h2 id="getting-started">Getting started</h2>
<p>Follow instructions <a href="http://avaloniaui.net/docs/quickstart">here</a>.</p>
<h2 id="support-and-contributing">Support and Contributing</h2>
<p>The best way to support Avalonia is to get involved, implement a feature, fix a bug or help test. See <a href="http://avaloniaui.net/contributing">contributing</a> for information on how to get started.</p>
<p>For commercial users, AvaloniaUI OÜ provides support packages and custom development services. Contact us at team@avaloniaui.net for more information.</p>
<p>Otherwise you can sponsor Avalonia financially via <a href="https://opencollective.com/Avalonia#sponsor">OpenCollective</a>.</p>
<p>We hope you enjoy developing with Avalonia - please let us know what you are building!</p>
<p><a href="https://github.com/grokys">grokys</a></p>

  </article></div>]]>
            </description>
            <link>http://avaloniaui.net/blog/2020-12-29-avalonia-0.10.0-release</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874397</guid>
            <pubDate>Fri, 22 Jan 2021 18:19:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How hard should I push myself?]]>
            </title>
            <description>
<![CDATA[
Score 308 | Comments 190 (<a href="https://news.ycombinator.com/item?id=25874374">thread link</a>) | @dshipper
<br/>
January 22, 2021 | https://superorganizers.every.to/p/how-hard-should-i-push-myself | <a href="https://web.archive.org/web/*/https://superorganizers.every.to/p/how-hard-should-i-push-myself">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3d2ebce7-e447-49bf-a6b4-f78c21198041_1400x934.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3d2ebce7-e447-49bf-a6b4-f78c21198041_1400x934.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/3d2ebce7-e447-49bf-a6b4-f78c21198041_1400x934.jpeg&quot;,&quot;height&quot;:934,&quot;width&quot;:1400,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:181814,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>How hard should I push myself?</p><p>It’s a question I ask myself a lot, and I bet you do too. On the one hand I really want to push myself. I’m ambitious, I want to leave it all out on the field—some of my peak work moments have come from times when I’ve pushed myself to a place where I didn’t think I could go. We all have more ability to adapt to stress and pressure than we think we do.</p><p>On the other hand, I want to be kind to myself. I wonder how much the drive to push myself is really just a drive to make up for something that I feel is missing or inadequate—and whether pushing myself will actually fill the hole. I also sometimes wonder whether letting myself off the hook is just laziness masquerading as self-care. It’s hard to tell.</p><p>But importantly, I wonder whether pushing myself might, in fact, kill me. Constant pressure creates chronic stress, and there’s all sorts of scientific studies that show that chronic stress is really bad for you. It makes you more susceptible to heart disease, it makes it harder to recover from illnesses, it can affect your sleep, and it can even affect your working memory.</p><p>There’s also all sorts of literature (and conversations on Twitter) that says that stress is actually good for you.&nbsp;</p><p>What gives? How much stress is good, and how much is bad?&nbsp;</p><p>I think that in order to understand the question we posed at the top—how much we should be pushing ourselves—we have to better understand stress. We need to understand what the stress of pushing ourselves does to our bodies, how much we can take of it, and how we can, hopefully, learn to cope with it better.</p><p>That’s what <a href="https://us.macmillan.com/books/9780805073690">Why Zebra's Don't Get Ulcers</a> by Robert M. Sapolsky is about. Robert's a stress researcher, and as far as I can tell he's one of the good ones. He's the kind of intellectual who's smart, but also smart enough to know what he doesn't know. He's written a book, but he doesn't come across as trying to sell it to you—he's kind of like your zany self-aware smart-as-hell uncle who happens to study the stress responses of baboons for a living.</p><p>In the book Dr. Sapolsky harnesses his own research, as well as a wide array of animal and human studies to figure out the answer to a fairly simple question: how does stress work, and why do humans get stress-related diseases?&nbsp;</p><p>It’s an interesting question—you can understand why a human body might react poorly to not being fed enough. But why would psychological stress have dangerous consequences? The basic gist is this:&nbsp;</p><p>The stress response is built to get us out of danger. If you're an animal in the Serengeti and you're being chased by a lion you really, really want to have a stress response. Being stressed means you’re preparing your muscles to move—a lot. Your heart rate rises and pushes blood to your extremities. Glucose is released into your bloodstream to help run your muscles as fast as possible.&nbsp;</p><p>The stress response pushes certain parts of your body into high gear—but it also turns certain parts of your body off. For example, when you’re stressed digestion is inhibited. What’s the point of wasting energy on digesting food for later when you might not even survive for 10 more minutes? Reproduction is also inhibited. Same reason.&nbsp;</p><p>This is all well and good in the wild—you don't need to reproduce if a lion is eating your face off. But humans, and some more intelligent animals, have evolved the stress response from an unqualified Good Thing into...well, something that might kill you.</p><p>What’s different about our stress response? Well, we have the ability to <em>anticipate</em> danger. Other animals have this ability too: it’s a good thing to get stressed seeing the lion all the way across the savannah, instead of only when it mauls your intestines out. But humans have evolved this anticipation ability to extend far beyond other animals. We anticipate bad things months, years, or even decades out. And when we do this, the very same stress response gets turned on—even though there is no immediate danger, and there is no immediate way to avoid it.&nbsp;</p><p>Suddenly, you aren’t just activating the stress response for a few minutes when you’re running for your life. Instead, it’s activated all the time—chronically. And this is where the problems start.&nbsp;</p><p>Remember we mentioned earlier that the stress response amps some parts of your body into high gear, and turns off others? If you’re doing that chronically, you start to have problems. Suddenly, your digestive system isn’t just inhibited for a few minutes while you’re escaping danger. It’s chronically inhibited. The same thing happens with your immune system—chronic stress tamps it down, and makes it harder for you to fight off diseases. Stress is bad for your heart too—if you’re pumping blood as if you need to run from something all the time, you’re going to get high blood pressure.&nbsp;</p><p>In these cases, according to Sapolsky, “the stress response can become more dangerous than the stressor itself, especially when the stress is purely psychological.”</p><p>To be clear, stress doesn’t actually make you sick. But it does leave you more vulnerable to disease and illnesses than you otherwise would be—and those <em>can</em> make you very sick.</p><h3><strong>So is stress bad?</strong></h3><p>Stress isn’t good or bad. It’s a tool. In small doses it’s good, but too much of a good thing becomes a bad thing pretty quickly.</p><p>When your stress response is working properly it makes you run faster, your memory gets better, you’re able to focus better. But when your stress response is over-activated, or chronically activated—you get ulcers and heart disease. It’s bad!&nbsp;</p><p>A good analogy is exercise. Too little exercise and you open yourself up to a whole host of diseases, both physical and psychological. Too much, and you can actually kill yourself.&nbsp;</p><h3><strong>What do we do about it?</strong></h3><p>The answer to the question we posed at the top, then, is that it’s great to push yourself—but you should be paying attention to the signs that tell you that you need a break. And it’s to give yourself plenty of ways to manage stress while you’re going through it, so that it doesn’t affect you as badly as it could.</p><p>This is the really interesting nugget: stress isn’t mathematical. Expose the same person to the same stressor and they will have different stress responses based on their coping strategies. Which means if you want to live a life where you’re pushing yourself, it’s best to develop a variety of coping strategies to help you manage it.&nbsp;</p><p>Here’s what Sapolsky recommends:</p><h4><strong>Increase your sense of control</strong>.&nbsp;</h4><p>If you put a human in a room where loud noises are going off, you’ll activate their stress response. If you give the human a button to reduce the volume of the loud noises they’ll be less stressed—regardless of whether they even use the button.&nbsp;</p><p>What that means is, just knowing you have the <em>option</em> to reduce stress is enough to make something less stressful—even if you’re not actually controlling the stressors at all.&nbsp;</p><p>It’s why the first few sessions of therapy are often so powerful for patients. You’ve finally found a way to manage how you’re feeling, even though you probably haven’t changed too much about your life.</p><p>When you’re facing mild to moderate stressors, ask yourself, <em>How can I increase my sense of control in this situation?</em> You might find there are simple answers that will make you feel a lot better.</p><h4><strong>Increase your sense of predictability.</strong></h4><p>Rats that are exposed to repeated electric shocks are more likely to get ulcers. But if you ring a bell before you administer the shock—making the shock more predictable—the rats are less likely to get ulcers. If you make the stressor predictable, you only have to get stressed right before it happens. That means you’re not stressed the rest of the time, and therefore the stress response doesn’t wreak as much havoc on your body.</p><p>Making the stressors in your life more predictable can have a similar effect. When you see CEOs that keep their calendars clear and never do phone calls—you’re seeing the benefit of predictability in action.</p><p>Of course, we can’t make our lives totally predictable (and in fact that wouldn’t be desirable.) But the more you can expose yourself to stressors in a predictable way the better off you’ll be. For example, maybe only doomscroll on Twitter once a week. Or only check email a couple of times a day.</p><h4><strong>Create outlets for frustration.</strong></h4><p>When rats that are exposed to repeated stressors are given a piece of wood to gnaw on, they are far less likely to develop ulcers. Outlets for frustration are another important coping mechanism for stress.&nbsp;&nbsp;</p><p>There are many unproductive outlets—for example, taking things out on your partner or a co-worker. But there are also many productive ones, like exercise or journaling. Making a list of outlets and making sure to return to them again and again can reduce the havoc that chronic stress can wreak on your body.</p><h4><strong>Increase social support.</strong></h4><p>Social support is the last coping strategy on the list, and it’s perhaps my favorite one.</p><p>If you give a primate a stressor in the lab, you’ll find elevated markers of stress in its behavior and in its blood. But give the primate a stressor when it’s surrounded by friends—its stress markers will be lower, even for the same level of stressor.</p><p>The same thing happens in humans. For example, in one study parents of children who have been killed in war were no more likely to get disease or die—except if they were already widowed or divorced.</p><p>Creating a vibrant sense of social support can put an unmanageable stressor into perspective and help keep it under control. Without social support, even small things can set us off in ways that are unproductive and unhealthy.</p><h2><strong>What did you think of this article?</strong></h2><p><a href="https://docs.google.com/forms/d/e/1FAIpQLSeMqlgyA7pSRFgxvzNkEFFqsPIvmkxtZ81IiGD0LQzYFL5-AA/viewform?usp=pp_url&amp;entry.1276325438=Amazing">Amazing</a>&nbsp;-&nbsp;&nbsp;<a href="https://docs.google.com/forms/d/e/1FAIpQLSeMqlgyA7pSRFgxvzNkEFFqsPIvmkxtZ81IiGD0LQzYFL5-AA/viewform?usp=pp_url&amp;entry.1276325438=Good">Good</a>&nbsp;-&nbsp;&nbsp;<a href="https://docs.google.com/forms/d/e/1FAIpQLSeMqlgyA7pSRFgxvzNkEFFqsPIvmkxtZ81IiGD0LQzYFL5-AA/viewform?usp=pp_url&amp;entry.1276325438=Meh">Meh</a>&nbsp;-&nbsp;&nbsp;<a href="https://docs.google.com/forms/d/e/1FAIpQLSeMqlgyA7pSRFgxvzNkEFFqsPIvmkxtZ81IiGD0LQzYFL5-AA/viewform?usp=pp_url&amp;entry.1276325438=Bad">Bad</a></p></div></div>]]>
            </description>
            <link>https://superorganizers.every.to/p/how-hard-should-i-push-myself</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874374</guid>
            <pubDate>Fri, 22 Jan 2021 18:16:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Address and POI Matching Without Writing Code]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25874219">thread link</a>) | @kpaddie10
<br/>
January 22, 2021 | https://www.placekey.io/blog/introducing-placekey-for-google-sheets-and-placekey-for-excel | <a href="https://web.archive.org/web/*/https://www.placekey.io/blog/introducing-placekey-for-google-sheets-and-placekey-for-excel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Read more about the announcement in </em><a href="https://www.directionsmag.com/pressrelease/10385"><em>Directions Magazine</em></a><em>.</em></p><p>Imagine you’re a retail brand trying to determine which of your stores performs best on a revenue-per-visit basis (RPV), compared to others. How would you solve this problem?</p><p>Analyses like these are interesting, because they require multiple disparate datasets to be brought together in order to tell a story. In this example, you’d be analyzing transaction data to calculate revenue per store over a certain time period, along with foot-traffic data. Maybe you’d even compare it against other variables like store age, square footage, and more. You would want to use data from different sources— store transaction data from <a href="https://www.affinity.solutions/">Affinity Solutions</a>, and foot traffic data from <a href="https://www.safegraph.com/?utm_source=referral&amp;utm_medium=pkblog&amp;utm_campaign=nocode">SafeGraph</a>.<br></p><p>The tough thing about this approach is that you need all these datasets to talk to each other. Problems like these are why data scientists spend up to <a href="https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/?sh=578166c86f63">80% of their time</a> doing <em>data preparation, </em>rather than driving insights. This situation is especially problematic when you’re working with location data, since many addresses don’t have standardization. A Target at 2626 E Stone Dr in one dataset might be listed as 2626 E Stone Dr Ste 90 in another, even though they’re the same store. A dataset indexed on the first address wouldn’t match the second.<br></p><p><a href="https://www.placekey.io/?utm_source=referral&amp;utm_medium=pkblog&amp;utm_campaign=nocode">Placekey</a> was designed to solve address and POI matching problems like these. It works like this: an address or place name is inputted, and Placekey generates a unique, authoritative identifier that can be used for address and POI matching, deduplication, normalization, entity resolution, and more.&nbsp;<br></p><p>This week, Placekey officially announced the launch of its no-code solutions for <a href="https://workspace.google.com/marketplace/app/address_matching_by_placekey/611255445050">Google Sheets</a> and <a href="https://appsource.microsoft.com/en-us/product/office/WA200002522?tab=Overview">Excel</a>. What this means is that thorny address and POI matching problems can now be solved without writing a single line of code.</p><p>We’ll look at how <a href="https://www.affinity.solutions/">Affinity Solutions</a>, a leading provider for consumer purchase and intent behavior is using Placekeys appended to their data sets to make it easier to combine with other data sets and drive insights. For more context, you can check Nitin Duggal, Affinity’s Chief Product Officer discussing Placekey here:</p><figure id="w-node-4a727786a108-be1d9f6e"><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/-WjKy-CK3Hs"></iframe></p></figure><p>This blog post will walk you through a practical example of a Placekey use case: where one is merging purchase intelligence information from Affinity, and places data from <a href="https://www.safegraph.com/?utm_source=referral&amp;utm_medium=pkblog&amp;utm_campaign=nocode">SafeGraph</a>— all without code.<strong>‍</strong></p><p><strong>The Data: Affinity and SafeGraph</strong><br></p><p>Since<strong> </strong><a href="https://www.affinity.solutions/">Affinity</a> is the leading provider of purchase data intelligence, their dataset covers granular transactions, down to the individual store level. Here’s a sample of data about US-based Target stores:</p><figure id="w-node-95555a0afff4-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0c41866be87357905e46_pasted%20image%200%20(11).png" loading="lazy" alt=""></p></figure><p>On the foot traffic data side, <a href="https://www.safegraph.com/">SafeGraph</a> aggregates anonymized location data from numerous applications, and generates information like number of visits, bucketed dwell times, and more. Here’s a sample of SafeGraph data for one US-based Target location:</p><figure id="w-node-3e414f5208fa-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0c667e793011bcda6851_pasted%20image%200%20(12).png" loading="lazy" alt=""></p></figure><p><strong>The Problem: Merging Location-based Datasets is Really Hard</strong><br></p><p>While we want to merge these datasets together in order to leverage Affinity’s spend data and SafeGraph’s mobility information for each store, addresses weren’t invented in a time of machine-tooled standardization. Arbitrary format convention differences in point-of-interest or POI naming s make the task of joining location-based datasets together super hard. For example, in these two data sets above, the respective address formats differ considerably.</p><figure id="w-node-8d54ce993e7f-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0c93e6ddc261570af0fe_pasted%20image%200%20(13).png" loading="lazy" alt=""></p></figure><p>To unlock the insights that come from bringing multiple datasets together, we need a way to cleanly merge address and POI data.<br></p><p><strong>The Solution: Meet Placekey</strong><br><a href="https://www.placekey.io/?utm_source=referral&amp;utm_medium=pkblog&amp;utm_campaign=nocode">Placekey</a> is a universal standard identifier for a physical location, and it was created to solve problems like these. Placekey does the tough job of address and POI resolution, standardization, validation, and geolocation behind the scenes, producing instead a simple identifier that uniquely identifies a place. Here, the two different street names resolve to the same Placekey, which can then be used to merge the data together.</p><figure id="w-node-79f19d4e95e1-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0cb2e832196767475950_pasted%20image%200%20(14).png" loading="lazy" alt=""></p></figure><p>Now, using Placekey as a join key to merge these two datasets produces the below dataset:</p><figure id="w-node-3ed6da2d5ebb-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0cfc02432de21342ed01_pasted%20image%200%20(15).png" loading="lazy" alt=""></p></figure><p>Now, from these columns, it is possible to directly compute dollars spent per visit - an analysis which relies on data from both Affinity and SafeGraph, and gives a more holistic view of revenue-per-visitor (RPV) at a granular level. We can also leverage the store age column to produce the below plot of store age vs. conversion.</p><figure id="w-node-3a095848eb16-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0ce987306118ee90cfe4_imageLikeEmbed.png" loading="lazy" alt=""></p></figure><p><br><strong>Demo: Merging Affinity and SafeGraph Data Using the Placekey No-Code Integrations for Excel and Google Sheets&nbsp;</strong><br></p><p>To conduct a similar analysis, you can append Placekeys to your dataset using Excel or Google Sheets. Here’s how you do it:<br></p><ul role="list"><li>After loading your data into Excel (or Google Sheets), open the Placekey extension, and click “Generate Placekeys”.</li><li>Enter your API key (note: this is not always required). If you don’t yet have one, sign up for free <a href="https://dev.placekey.io/default/register">here</a> in a few seconds.</li><li>Open the first dataset you’re working with. Map the headers in the data (i.e. brand, street, city, state, and zip) to the relevant API field values, and when you’re done, click “Generate Placekeys”</li></ul><figure id="w-node-45eaf86adc10-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0d7e55c3ac3341efb1c6_VJBq9jKrNxtRHhc_dBrUqPHLKjztah9WMIxAKLLJKxCzyCIEIhQm5LvmZYwPrXRIsq_MLA7NJchOMwVhSwl8vUpaNxFJBrOxTbki76wURGGyfjCV6NfuNGEk5S4m31dfrESv74j6.png" alt=""></p></figure><ul role="list"><li>After a few seconds, the Placekeys are appended to the data in a new column.</li></ul><figure id="w-node-d874ebb5fd9a-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0d6face7fd52ffb5a1e3_pasted%20image%200%20(16).png" loading="lazy" alt=""></p></figure><ul role="list"><li>Repeat the same process on the data you would like to join. Here, the SafeGraph data already has a Placekey column, making it super easy to join in without any pre-processing.&nbsp;</li><li>Use a standard Google Sheets or Excel VLOOKUP function to merge the rows of the two datasets. Here, we highlight two relevant columns — spend data from Affinity and visits data from SafeGraph, plus a simulated value for the age of the store.</li></ul><figure id="w-node-5e078560ae0b-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0d9612125f094b91615c_Bc_WWUQZg_xDdeCxE0-BuRAvglnxSooLagXQ6tvIJiIFbhT0TGcSmuyYWsPkuPQF-EJsWQVST-f-PD-YDRDvVH-QD-fJWJszu1CPnJqsTxLDbnWBdySZp4PLsSFS4S61o8GIuSOh.png" alt=""></p></figure><ul role="list"><li>From these columns, you can directly compute a measure of dollars spent per visit. As mentioned above, the store age column can also be leveraged to produce the below plot:</li></ul><figure id="w-node-3f488d7fa48d-be1d9f6e"><p><img src="https://assets.website-files.com/5f277eb85e5f02d500828d71/600b0dbc9d4c6158f07d5675_lbjMhl9cq1fxzd2OtRktHYaaOsyJbWRYUwmnngag3NQ7srwf4QPJ0FK52MIzq0-50ADb51SKn3xgA3tR6Y0sCrAhSq_S6k_zVH7fm3vgAcwcvoe3mKrgpFO2gLjtUQhYzNQX8F-P.png" alt=""></p></figure><p>This example demonstrates how any best-in-class transaction dataset can be joined to third-party data sources by leveraging Placekey to match addresses and POIs. Placekey opens the door for analyses such as this and many more to be performed by expanding the interoperability of different data solutions.</p><p>‍</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.placekey.io/blog/introducing-placekey-for-google-sheets-and-placekey-for-excel</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874219</guid>
            <pubDate>Fri, 22 Jan 2021 18:02:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons learned in my first year being CTO]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25874094">thread link</a>) | @feross
<br/>
January 22, 2021 | https://shekhargulati.com/2021/01/03/being-chief-technology-officer-lessons-learned-in-my-first-year/ | <a href="https://web.archive.org/web/*/https://shekhargulati.com/2021/01/03/being-chief-technology-officer-lessons-learned-in-my-first-year/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6462">
	<!-- .entry-header -->

	
	
	<div>
		<br>
<blockquote><p>Happy New Year!</p><p>2020 was a difficult year for most of us, as we fought with COVID-19 and came to terms with the remote way of working. It was a year when we had a lot more time in our hands as all of us were locked in our houses with almost no travel. The things that we took for granted were taken from us and there was a constant fear of losing the loved ones.&nbsp;</p><p>I hope in 2021 we regain our freedom to live freely. But, this time with a sense of responsibility and awareness.&nbsp;</p></blockquote>



<p>It is now little over a year since I became Chief Technology Officer (CTO) in my current organization. And, I thought it will be a good time to do a quick retrospective on the lessons learned in my first year as CTO. The journey has been tough but deeply rewarding for me. There were occasions when I thought the leadership role was not for me and I should go back to being an individual contributor. But, with support from my organization and learning (books, blogs, observation), I have started to enjoy the role and its challenges.</p>



<p>Before I talk about the lessons I learned, let’s look at my software engineering journey.&nbsp;&nbsp;</p>



<h2>My software engineering journey</h2>



<ul><li>2005-2008: Software Engineer</li><li>2008-2012: Senior Software Engineer</li><li>2013-2014: Principal Technology Evangelist</li><li>2014-2019: Principal Engineer/Architect (during this period, I was in the role of Director, but I was neck-deep in writing code, building systems, and technology consulting)</li><li>2020-present: Chief Technology Officer (my first leadership/management role)</li></ul>



<p>Yes, this is my first leadership and management role. The leap from an individual contributor to a CTO was as much nerve-wracking as it was ambitious in terms of responsibilities.</p>



<p>Of course, along with this opportunity came its share of pros and cons. Nonetheless, I took the plunge and went through this transition without any preconceived notion.&nbsp;&nbsp;</p>



<h2>Defining the CTO role</h2>



<p>When I was told that I will be the next CTO, I immediately looked for a playbook that would describe and provide best practices and guide me on the rules of becoming a good, successful CTO. I wanted to be ready for the role and study the entire CTO literature available on the web. Guess what? There was no such playbook.&nbsp;</p>



<p>At the end of the day, it is always about learning on the job and not making the same mistake twice.&nbsp;</p>



<p>The first thing that I read was what people usually define the role of Chief Technology Officer as. Apparently, it is one of the most confusing C-level roles, and each CTO plays a bit differently. The best description of this role that I found was in an <a href="https://www.linkedin.com/pulse/five-flavors-being-cto-matt-tucker/">essay</a> by Matt Tucker. According to Matt, to better understand the role, you should break into five flavors.</p>



<figure><a href="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png"><img data-attachment-id="6464" data-permalink="https://shekhargulati.com/screenshot-2021-01-03-at-9-09-34-pm/" data-orig-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png" data-orig-size="1248,704" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2021-01-03-at-9.09.34-pm" data-image-description="" data-medium-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=300" data-large-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=840" src="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=1024" alt="" srcset="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=1024 1024w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=150 150w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=300 300w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png?w=768 768w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.34-pm.png 1248w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></a><figcaption>CTO Framework by Matt Tucker</figcaption></figure>



<p>I think the above framework gives a good mental model on how to think about the role of a CTO. Mostly, they come with a combination of two or more aforementioned flavors.&nbsp;</p>



<p>Let me share what my role, as a Chief Technology Officer, looks like. In my view, the framework (above) shared by Matt Tucker is from a product organization’s perspective. I am a CTO of an IT services organization, where this role gets diluted, fragmented and challenging because of the following additional factors:</p>



<ul><li>People are an important asset in any organization, but for an IT service organization, growth is directly proportional to the number of people. If you want to remain a niche service provider, then the story could be different.&nbsp;</li><li>You have to make modern technology accessible to large enterprises that are not ready for the change. In the last 5 years or so, there is a push towards digital transformation in most organizations. In my experience, organizations are now more open toward trying new technologies (React, Golang, Flutter, Cloud, Kubernetes) and architecture styles (Microservices, Event-driven, Serverless), more than ever before. This is a great news, but very few organizations understand the complexity introduced by these modern technology stacks. They are not doing the groundwork required to become the next Google in their domain. You can read my post <a href="https://medium.com/xebia-engineering/11-reasons-why-you-are-going-to-fail-with-microservices-29b93876268b"><em>11 Reasons Why You Are Going To Fail With Microservices</em></a>&nbsp;</li><li>There are not many good software engineers in the market with real experience in these modern technologies. Good software engineers are expensive and their financial and work aspirations are more aligned with product organizations. For an IT service organization, it is not possible to pay at the scale of product organizations.&nbsp;</li></ul>



<p>There is not much written about/by the CTOs of IT service organizations. It is not clear who should be your role model, so I will take Matt’s framework and define it for myself.</p>



<p>Here, you will see Matt’s framework modified by virtue of the flavors comprising my role. I have given a rough estimate on the time I had spent on each activity in the last year.&nbsp;</p>







<figure><a href="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png"><img data-attachment-id="6466" data-permalink="https://shekhargulati.com/screenshot-2021-01-03-at-9-09-48-pm/" data-orig-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png" data-orig-size="1240,1166" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2021-01-03-at-9.09.48-pm" data-image-description="" data-medium-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=300" data-large-file="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=840" src="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=1024" alt="" srcset="https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=1024 1024w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=150 150w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=300 300w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png?w=768 768w, https://whyjava.files.wordpress.com/2021/01/screenshot-2021-01-03-at-9.09.48-pm.png 1240w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></a><figcaption>Modified CTO Framework</figcaption></figure>



<p>As you can see in the above table, I am everywhere. Luckily for me, I had less overhead in context switching. The main reason was I made sure that I never get involved in more than 2 tasks at a time.&nbsp;</p>



<p>In my first year as the CTO, I have built some level of delegation hierarchy. Hopefully, in the second year, I will be more focussed on a few of these flavors.</p>



<h2>Lessons learned in the first year</h2>



<p>So far, I have shared about my journey and the CTO role definition. Next, let me walk you through the lessons that I have learned in the first year as CTO.</p>



<h3>Lesson #0: You have to believe in yourself and ask for the role</h3>



<p>Most software engineers dream of becoming a CTO one day. This is how some of us define a successful engineering career. Someone will not make you the CTO just because you are the most capable software engineer/architect in your organization. You really need to have the hunger.&nbsp;</p>



<p>It took me close to 2-3 years before I was sure in my mind that I am ready to become a CTO. One of the reasons I thought I was not ready for a leadership role was Peter Principle.&nbsp;</p>



<blockquote><p>The Peter Principle is an observation that the tendency in most organizational hierarchies, such as that of a corporation, is for every employee to rise in the hierarchy through promotion until they reach a level of respective incompetence.</p></blockquote>



<p>I always took pride in being a competent software engineer/architect. The fear of becoming incompetent one day made me stick to the hands-on individual contributor role.</p>



<p>One thing that I realized was if I am not going to do the role, someone else will. Since, I knew the organization long enough and I have figured out my engineering leadership style, so why not give it a try. The most difficult part for me was asking for the role. The sad part is if you don’t ask people, they don’t give you what you deserve.&nbsp;</p>



<blockquote><p>Now, I’ve actually always found something to be very true, which is that most people don’t get those experiences because they never ask. I’ve never found anybody who didn’t want to help me when I’ve asked them for help – Steve Jobs [1]</p></blockquote>



<h3>Lesson #1: Schedule time for yourself</h3>



<p>A couple of weeks back, a colleague asked me how you are able to do deep work when you have to attend so many meetings. I discovered that people will add you to a meeting as soon as they find a free meeting slot in your calendar. I struggled with this for the first half of 2020.&nbsp; I was in meetings most of the day. Most of the thinking work that I did during this period was either after office hours or on weekends.&nbsp;</p>



<p>I changed my way of working in the second half after realizing that I can also schedule time&nbsp; with myself. Now, everyday I schedule a couple of hours to half a day with myself and do one deep work task. This way I am able to manage between maker schedule and manager schedule [2].</p>



<p>Another way, I avoid becoming a slave to my calendar, is by ensuring with the organizer whether my presence in the meeting is critical. At other times, I decline meetings when someone from my team is already attending.&nbsp;</p>



<h3>Lesson #2: Getting things done without doing them</h3>



<p>This is the challenge that most individual contributors face when they take up managerial/leadership roles. You know you can do the task better and faster. Thereby, you prefer to do the task yourself. This does not scale and you quickly become the bottleneck. And I bet you already know the answer.&nbsp;</p>



<p>The best way to scale yourself is through delegation. There are two parts in the delegation: what to delegate and which delegation level to apply.</p>



<p><strong>What to delegate</strong></p>



<p>In <em>How to Decide Which Tasks to Delegate </em>[3], Jenny Blake categorizes tasks into 6 categories which she calls 6 Ts.</p>



<ul><li><strong>Tiny</strong>: Tasks that are so small they seem inconsequential to tackle but they add up.</li><li><strong>Tedious</strong>: Tasks that are relatively simple probably are not&nbsp; the best use of your time.</li><li><strong>Time-consuming</strong>: Tasks that, although they may be important and even somewhat complex, are time-consuming and do not require you to do the initial 80% of research.</li><li><strong>Teachable</strong>: Tasks that, although complicated-seeming at first and possibly comprising several smaller subtasks, can be translated into a system and passed along, with you still providing quality checks and final approval.</li><li><strong>Terrible At</strong>: Tasks that not only do not fall into your strengths, but an area where you feel unequipped.</li><li><strong>Time sensitive</strong>: Tasks that are time-sensitive but compete with other priorities; there isn’t enough time to do them all at once, so you delegate an important and time-sensitive task so that it can be done in parallel to your other project-based deadlines.</li></ul>



<p>Tasks like organizing internal tech talks, operating internal infra, code reviews, junior engineer hiring I have delegated to others in my team.&nbsp;</p>



<p>Once you know which tasks to delegate, you have to use a delegation level that gets the best job done. I learnt about 7 levels of delegation at Management 30 website [4].</p>



<ol><li><strong>Tell</strong>: I will tell them&nbsp;</li><li><strong>Sell</strong>: I will try and sell it to them&nbsp;</li><li><strong>Consult</strong>: I will consult and then decide&nbsp;</li><li><strong>Agree</strong>: We will agree together&nbsp;</li><li><strong>Advise</strong>: I will advise but they decide&nbsp;</li><li><strong>I…</strong></li></ol></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shekhargulati.com/2021/01/03/being-chief-technology-officer-lessons-learned-in-my-first-year/">https://shekhargulati.com/2021/01/03/being-chief-technology-officer-lessons-learned-in-my-first-year/</a></em></p>]]>
            </description>
            <link>https://shekhargulati.com/2021/01/03/being-chief-technology-officer-lessons-learned-in-my-first-year/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874094</guid>
            <pubDate>Fri, 22 Jan 2021 17:49:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Setting up Matrix Synapse on a delegated subdomain]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25874010">thread link</a>) | @pngmangi
<br/>
January 22, 2021 | https://ansonvandoren.com/posts/matrix-server-digital-ocean/ | <a href="https://web.archive.org/web/*/https://ansonvandoren.com/posts/matrix-server-digital-ocean/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<h2 id="why-do-i-want-to-do-this">Why do I want to do this?</h2>
<p>That's a good question. I think the honest answer is because I had some spare time this week and I wanted to learn
something new. Part of me also says that after having left at least 5 different primary messaging platforms
over the last 20 years due to them either being killed off (looking at you, Google), or becoming irrelevant (ICQ anyone?),
or becoming too creepy (WhatsApp, WeChat), it might be worth investing in a chat platform that's under (mostly) my own
control.</p>
<p>I've seen bits and pieces about Matrix over the last couple of years, but never really investigated it much. I knew
that it was open source and self-hosted, but what I didn't know until yesterday is that it also has quite a few
<a href="https://matrix.org/bridges/">bridges</a> to connect to the chat apps I still do use. Most of my day-to-day chatting
right now is via Telegram, which has been working out pretty well for the last two years, but I'm not convinced
how much longer a Russian tech billionaire is going to want to keep self-funding the project, especially after
the TON ICO <a href="https://www.sec.gov/news/press-release/2019-212">was halted by the SEC</a>.</p>
<p>Anyway, if nothing else I'd learn a bit about the Matrix community, keep current on some sysadmin skills, and
build a little more feeling of ownership in the parts of the internet that I use on a daily basis. If I found
a lot of value in Matrix after it was up and running, maybe I'd try to get some of my normal contacts to add/switch,
or if not than I should be able to set up some bridging and still talk via my usual platforms, but with my own
copy of the chats on my private server, and the knowledge that I'd marginally improved my online privacy.</p>
<p>Before going too much further, I read the <a href="https://matrix.org/docs/guides/getting-involved">How can I get involved?</a>
page on the Matrix website, and spent a bit of time testing out the <a href="https://matrix.org/docs/projects/client/element">Element client</a>
in both the web and the desktop (Windows) app forms. Satisfied that it all seemed usable enough that I could
get used to it for a daily driver, I started investigating what it takes to self-host a
<a href="https://matrix.org/docs/guides/installing-synapse">Synapse server</a>.</p>
<h2 id="domain-name-setup-on-namecheap">Domain name setup on Namecheap</h2>
<p>First thing I need is a domain name to point at my new chat server. I already own several domain names (OK, domain collecting
is actually something of a bad habit of mine), but since the domain name of the server is reflected in one's Matrix
ID, I wanted to stick with <code>ansonvandoren.com</code>, to mirror both this website, and my email addresses. To complicate this just a bit,
I didn't want to use the same VPS that hosts my blog, and I also wanted Synapse to actually listen on a subdomain,
(e.g., <code>matrix.ansonvandoren.com</code>) instead of the domain name itself. Neither of these criteria makes the setup unmanageable,
but each adds a bit of complexity that I'll describe below.</p>
<p>My domain name is registered through <a href="https://namecheap.pxf.io/mDrKy">NameCheap</a>, which has been an absolute pleasure to work
with over the last few years. Since the nameservers for <code>ansonvandoren.com</code> already point towards DigitalOcean, I don't
need to make any changes there. <em>(Note: I may gain a small commission from Namecheap if you use the link above. You will
not be charged anything extra for using it. Thanks!)</em></p>
<p>If you're starting out from scratch and do need to point a Namecheap domain at a Digital Ocean droplet, you'll want the
“Custom DNS” setting, and the nameservers shown below:</p>
<p><img src="https://ansonvandoren.com/images/namecheap-nameservers.png" alt="Nameserver setup for Namecheap and DigitalOcean"></p>
<h2 id="droplet-creation-on-digital-ocean">Droplet creation on Digital Ocean</h2>
<p>I've been using Digital Ocean for hosting for years now and love their services. The price is right for the hobby
projects I usually take on, and the setup and maintenance is easy. If you're interested, here's a
<a href="https://m.do.co/c/4b40cdbde86d">referral link</a> you can use to sign up. <em>I'll get a small commission if you
sign up and keep using them, but it doesn't cost you anything</em>.</p>
<p>Based on the <a href="https://github.com/matrix-org/synapse/blob/master/INSTALL.md">Synapse installation guide</a>, the minimum
system requirements are 1GB of RAM. As you'll see later, it's fairly easy to limit the memory used even further if you
don't have many users on your homeserver. I chose an Ubuntu 20.04, Basic/Shared CPU $5/mo droplet with 1GB RAM, 1 (shared) CPU,
25GB storage, and 1000GB/mo bandwidth. Since I live in California, I chose a San Francisco datacenter. I selected IPv6 and Monitoring
options, and re-used my existing SSH keys from previous droplets. I chose a hostname of <code>matrix</code> and some relevant tags,
assigned it to my personal project, and enabled backups.</p>
<p>It takes a few moments to spin up. Before connecting the first time, I set up a subdomain record through DigitalOcean
(under the Networking menu) that points <code>matrix.ansonvandoren.com</code> to the newly created droplet. I did this for both an
A record and an AAA record (IPv4 and IPv6).</p>
<p><img src="https://ansonvandoren.com/images/digitalocean-dns.png" alt="DNS setup on Digital Ocean"></p>
<p>Since I chose to use a SSH key to login, I didn't need the Access Console at all, and
instead just connected from a terminal session using:</p>
<div><pre><code data-lang="sh">$ ssh root@matrix.ansonvandoren.com
</code></pre></div><p>It takes some time for the new DNS records to propagate, so if you get an error message like this, then try
using the IP address instead, or just wait an hour or so.</p>
<div><pre><code data-lang="sh">ssh: Could not resolve hostname matrix.ansonvandoren.com: No address associated with hostname
</code></pre></div><h2 id="initial-droplet-setup">Initial droplet setup</h2>
<p>Following the <a href="https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04">Initial Server Setup with Ubuntu 20.04</a>
documentation from Digital Ocean, I created a new non-root user, generated a memorable and secure password using
<a href="https://correcthorsebatterystaple.net/">Correct Horse Battery Staple</a>, and saved the new credentials in <a href="https://1password.com/">1Password</a>.</p>
<p>I finished out the guide by:</p>
<ul>
<li>Copying the SSH authorized_keys over to the new user</li>
<li>Making the new user a superuser</li>
<li>Setting up <code>ufw</code> firewall rules (allowing <code>OpenSSH</code>, <code>http</code>, <code>https</code>)</li>
<li>Updating Linux packages</li>
</ul>
<h2 id="installing-synapse">Installing Synapse</h2>
<p>I followed <a href="https://github.com/matrix-org/synapse/blob/master/INSTALL.md">these instructions</a> from the Matrix
Github page, installing the prebuilt packages for Ubuntu:</p>
<div><pre><code data-lang="sh">$ sudo apt install -y lsb-release wget apt-transport-https
$ sudo wget -O /usr/share/keyrings/matrix-org-archive-keyring.gpg https://packages.matrix.org/debian/matrix-org-archive-keyring.gpg
$ <span>echo</span> <span>"</span><span>deb [signed-by=/usr/share/keyrings/matrix-org-archive-keyring.gpg] https://packages.matrix.org/debian/ </span><span>$(</span>lsb_release -cs<span>)</span><span> main</span><span>"</span> |
    sudo tee /etc/apt/sources.list.d/matrix-org.list
$ sudo apt update
$ sudo apt install matrix-synapse-py3
</code></pre></div><p>During the installation, when prompted for the Synapse server name, I used <code>ansonvandoren.com</code> even though the Synapse
server is actually pointed to by <code>matrix.ansonvandoren.com</code> since I intend to set up delegation later. Your
needs may be different, so you may want to read the <a href="https://github.com/matrix-org/synapse/blob/master/docs/delegate.md">delegation docs</a>
to help you decide. By choosing <code>ansonvandoren.com</code> as the server name and then delegating it, I can keep logical
servers with different names to improve organization and security, but still keep my Matrix ID as something
like <code>@anson:ansonvandoren.com</code> instead of <code>@anson:matrix.ansonvandoren.com</code>.</p>
<h2 id="installing-postgresql-for-synapse">Installing PostgreSQL for Synapse</h2>
<p>This isn't required, and probably not actually needed since I don't plan to host a lot of users, but it seemed
easier to do it now rather than try to do it down the road. There is a migration path from SQLite to PostgreSQL, but it looks
a little error-prone, and also, according to the official docs:</p>
<blockquote>
<p>Almost all installations should opt to use PostgreSQL</p>
</blockquote>
<p>Installation instructions are <a href="https://github.com/matrix-org/synapse/blob/master/docs/postgres.md">linked</a> from the main
Synapse install page, but those assume you already have Postgres installed, which I did not on the new droplet. There is
a pretty good <a href="https://www.digitalocean.com/community/tutorials/how-to-install-postgresql-on-ubuntu-20-04-quickstart">tutorial</a>
on Digital Ocean for setting up Postgres that I referenced to get started.</p>
<p>Install PostgreSQL:</p>
<div><pre><code data-lang="sh">$ sudo apt install postgresql postgresql-contrib
</code></pre></div><p>Switch to the newly created <code>postgres</code> user:</p>
<p>Create a <code>synapse_user</code> Postgres role:</p>
<div><pre><code data-lang="sh">$ createuser --pwprompt synapse_user
</code></pre></div><p>Enter a new password (and don't forget to store it in 1Password).</p>
<p>Create the Synapse database by first starting <code>psql</code></p>
<div><pre><code data-lang="sh">$ psql
psql (12.5 (Ubuntu 12.5-0ubuntu0.20.04.1))
Type <span>"help"</span> <span>for</span> help.
</code></pre></div><p>then from the Postgres prompt, create the database:</p>
<div><pre><code data-lang="postgres">postgres=# <span>CREATE</span> <span>DATABASE</span> synapse
             <span>ENCODING</span> <span></span><span>'</span><span>UTF8</span><span>'</span>
             <span>LC_COLLATE</span>=<span></span><span>'</span><span>C</span><span>'</span>
             <span>LC_CTYPE</span>=<span></span><span>'</span><span>C</span><span>'</span>
             <span>template</span>=template0
             <span>OWNER</span> synapse_user;
</code></pre></div><p>Exit the Postgres prompt by typing <code>\q</code>, and then exit back into the normal user login.</p>
<p>To set Synapse to use Postgres instead of the default SQLite, edit the config file:</p>
<div><pre><code data-lang="sh">$ sudo vim /etc/matrix-synapse/homeserver.yaml
</code></pre></div><p>Search for the <code>database</code> section, and comment out the <code>sqlite3</code> section, and uncomment the <code>psycopg2</code> part.
Mine looks like this:</p>
<div><pre><code data-lang="yaml">database:
  name: psycopg2
  args:
    user: synapse_user
    password: secretpassword
    database: synapse
    host: localhost
    cp_min: <span>5</span>
    cp_max: <span>10</span>
</code></pre></div><p>Obviously, change <code>secretpassword</code> to whatever your <code>synapse_user</code> password is (created a few steps above).</p>
<h2 id="configuring-reverse-proxy-for-synapse">Configuring reverse proxy for Synapse</h2>
<p>Again, the Matrix team has a reasonable set of instructions <a href="https://github.com/matrix-org/synapse/blob/master/docs/reverse_proxy.md">here</a>.
I chose to use Caddy for a reverse proxy, mostly because I already use Nginx for other projects, and wanted some different
experience. I followed the basic Caddy 2 installation instructions <a href="https://caddyserver.com/docs/install#debian-ubuntu-raspbian">from here</a>.</p>
<div><pre><code data-lang="sh">$ sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https
$ curl -1sLf <span>'https://dl.cloudsmith.io/public/caddy/stable/cfg/gpg/gpg.155B6D79CA56EA34.key'</span> | sudo apt-key add -
$ curl -1sLf <span>'https://dl.cloudsmith.io/public/caddy/stable/cfg/setup/config.deb.txt?distro=debian&amp;version=any-version'</span> | sudo tee -a /etc/apt/sources.list.d/caddy-stable.list
$ sudo apt update
$ sudo apt install caddy
</code></pre></div><p>There is a default Caddyfile in <code>/etc/caddy/Caddyfile</code> that I edited to look like below:</p>
<pre><code data-lang="caddy">matrix.ansonvandoren.com {
  # enable logging
  log

  reverse_proxy /_matrix/* http://localhost:8008
  reverse_proxy /_synapse/client/* http://localhost:8008
}
</code></pre><p><strong>From that folder</strong>, reload caddy with</p>
<p>Then wait for LetsEncrypt to generate the certs. Make sure that <code>http</code> and <code>https</code> are enabled via <code>ufw</code>.</p>
<h2 id="delegating-access-to-a-subdomain">Delegating access to a subdomain</h2>
<p>Since the Synapse server is hosted on a different box and a subdomain (not just <code>ansonvandoren.com</code>),
I needed to delegate access. The easiest way seems to be with a <code>.well-known</code> directive, so I followed the
basic instructions <a href="https://github.com/matrix-org/synapse/blob/master/docs/delegate.md">here</a>. Sort of.</p>
<p>Actually I needed quite a bit from <a href="https://git.finallycoffee.eu/jdreichmann/matrix-docker-ansible-deploy_dev/src/commit/c1a9549d54538cf35076f2a6a19e13004a483a06/docs/configuring-well-known.md">this document</a> as well.</p>
<p>On my regular <code>ansonvandoren.com</code> host, in the same Nginx server block that holds information
for this website, I added …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ansonvandoren.com/posts/matrix-server-digital-ocean/">https://ansonvandoren.com/posts/matrix-server-digital-ocean/</a></em></p>]]>
            </description>
            <link>https://ansonvandoren.com/posts/matrix-server-digital-ocean/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25874010</guid>
            <pubDate>Fri, 22 Jan 2021 17:42:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twitter Bluesky Is a Business Strategy]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25873965">thread link</a>) | @WClayFerguson
<br/>
January 22, 2021 | https://quanta.wiki/u/WClayFerguson/twitter-bluesky | <a href="https://web.archive.org/web/*/https://quanta.wiki/u/WClayFerguson/twitter-bluesky">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://quanta.wiki/u/WClayFerguson/twitter-bluesky</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873965</guid>
            <pubDate>Fri, 22 Jan 2021 17:39:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Marketing can make the world a better place]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25873957">thread link</a>) | @jnoog
<br/>
January 22, 2021 | https://boundlesshumanblog.com/marketing-makes-the-world-a-better-place-cory-ames-grow-ensemble/ | <a href="https://web.archive.org/web/*/https://boundlesshumanblog.com/marketing-makes-the-world-a-better-place-cory-ames-grow-ensemble/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-24">
	<!-- .entry-header -->

	<div>
		
<figure><img loading="lazy" width="640" height="853" src="https://i2.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble-768x1024.jpeg?resize=640%2C853&amp;ssl=1" alt="Cory Ames CEO of Grow Ensemble wearing yellow beanie and jacket" srcset="https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?resize=1152%2C1536&amp;ssl=1 1152w, https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?resize=1536%2C2048&amp;ssl=1 1536w, https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/boundlesshumanblog.com/wp-content/uploads/2020/10/Cory-Ames-CEO-of-Grow-Ensemble.jpeg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></figure>



<p id="block-feb40dbc-4d12-4f90-8338-808d52cca5e4">Fun fact: Cory dropped out of university and began working at a multi-million-dollar marketing agency. He quickly climbed up the ranks from Assistant Project Manager to CEO within 18 months.</p>



<p id="block-feb40dbc-4d12-4f90-8338-808d52cca5e4">Though I would never suggest anyone to take ditching school lightly, sometimes it can work out for the best.</p>



<p id="block-027cc4d0-39a6-4811-bd23-a17f9f80fc84">Cory first reached out to me to update some content for his podcast and I jumped on board immediately because I loved its mission. I’ve been following Grow Ensemble, his marketing agency and consultancy for purpose-driven companies, ever since.</p>



<p id="block-5cc1b2af-3eaa-4447-a2c5-12a330b7f149">He and his team have helped hundreds of social enterprises, lead by similarly passionate entrepreneurs, grow. Indeed, profit and purpose can exist in perfect harmony.</p>



<p id="block-54e98d7e-fa85-4e32-b039-774c6f11faa2">So whatever they tell you about sleazy marketers trying to sell you snake oil, it’s not always true.</p>



<p id="block-662133ef-7438-427f-af40-6b036ea3e6e8">His background makes him the perfect first guest on Boundless Human so I didn’t hesitate to ask him for an interview. But enough from me, I’ll give Cory the stage now.</p>



<blockquote><p><em>In our most ambitious frame of mind, we want Grow Ensemble to inspire a cultural transformation—one where we begin to think more communally, rather than hyper-individually.&nbsp;&nbsp;</em></p><p>Cory Ames</p></blockquote>



<h2><strong>1. Where does the desire to do good come from? What inspires you in this regard?</strong></h2>



<p>First, I know I am insanely privileged. There has been little in my life that I’ve wanted to do that I haven’t been able to. And really, that’s all a product of luck. I was lucky enough to be born into a middle-class/upper-middle-class family, have extremely supportive parents, and be a skin color (white) that’s preferential to receiving “opportunities” in America.&nbsp;</p>



<p>I didn’t do anything to <em>deserve </em>this; I didn’t earn this in any way, it was all by chance. And so, I feel obligated to use my privilege to ideally make the world a (truly) better place for those who aren’t as lucky.&nbsp;</p>



<p>Second, I’m really not sure what could be a better or more meaningful use of my own skills and capacities than to work towards reducing the unnecessary suffering of others and leaving the world a more just, equitable, and habitable place for all of us, not just some of us. If we have skills, if we have resources, and if we have time, it should be spent thinking about and working towards making others better off, no?&nbsp;</p>



<h2><strong>2. You dropped out of university to pursue digital marketing and went on to become the CEO of a multi-million dollar marketing agency in just 18 months. You clearly like to “colour outside the lines”. Do you embody this ethos in other aspects of your life?</strong></h2>



<p>Definitely. And honestly, I feel that the quality of mine might cause me some distress. I can often be so committed to doing things the exact way I want to, at the time I want to, where I want to. I can shy away from or procrastinate on maybe more mundane, repetitive, but still <em>very important </em>things. Sometimes the things that I <em>have </em>to do, but don’t <em>want </em>to fall to the wayside.&nbsp;</p>



<h2><strong>3. Imagine an ideal future and the ultimate impact you want to make with Grow Ensemble. What would that look like?</strong></h2>



<p>We started Grow Ensemble because we wanted to create a community around ‘bettering the world.’ Research shows that we are more lonely and depressed than we ever have been. We hope that Grow Ensemble can be a vehicle for inspiring others to do good in their day-to-day lives with a like-minded, like-valued community.&nbsp;</p>



<p>In our most ambitious frame of mind, we want Grow Ensemble to inspire a cultural transformation—one where we begin to think more communally, rather than hyper-individually.&nbsp;&nbsp;</p>



<h2><strong>4. What’s your favourite book / podcast / song / etc. (choose one) and why?</strong></h2>



<p>Player Piano, by Kurt Vonnegut—I’m eternally grateful to my partner, Annie, for this recommendation.&nbsp;</p>



<p>To quote Vonnegut himself, “This book is not a book about what is, but a book about what could be.” He published Player Piano in 1952. Vonnegut’s predictions about “what could be,” were eerie.&nbsp;&nbsp;</p>



<p>The book is set in a completely ‘automated’ American society. Through automation and technology, every single one of our conveniences has been met. This book had me questioning our obsession with “progress” and technological innovation.&nbsp;</p>



<p>Is progress for progress’ sake really what’s best for us both individually and collectively? What are we ‘optimizing’ for?&nbsp;</p>



<p>As we watch automation wipe out hundreds of thousands of livelihoods and we create another widget to make it easier to do something insignificant like brushing our teeth, or finding a new T.V. show, I can’t help but wonder, is all the “advancement” in fact improving our lives?&nbsp;</p>



<h2><strong>5. ‎What’s the bravest thing you’ve ever done?</strong></h2>



<p>This is interesting. I don’t consider myself to be particularly courageous and boiling that down to one single moment doesn’t really seem to fit with how I think of myself. I’m very reflective and analytical. I think through potential life choices and actions I can take rather exhaustively.&nbsp;</p>



<p>And then, when the event comes, it feels almost “normal,” or exactly what I should be doing.&nbsp;</p>



<p>Leaving university early didn’t feel all particularly courageous at the time, because I felt extremely certain of what I wanted to do. If anything, the bravest things I’ve done revolve around moving or travel.&nbsp;</p>



<p>Of anything, I’d say those experiences have taken me the most out of my comfort zone and maybe have rewarded me the most.&nbsp;</p>



<p>While I’ve spent some significant time traveling/living within different countries, most meaningful may have been my move from Washington state to Texas. This felt like a ‘starting fresh’ of sorts, making new friends, finding new routines, and spending significant time away from my family.&nbsp;</p>



<p>And now, I’m so endlessly grateful I made the move as the universe certainly “rewarded me” with meeting my now partner who I plan to spend the rest of my life with.&nbsp;</p>



<p><em>If you want to learn more about Cory and his mission, check out his <a href="https://coryames.com/">personal website</a>, <a href="https://growensemble.com/">Grow Ensemble</a> and <a href="https://growensemble.com/podcast/">the Social Entrepreneurship and Innovation Podcast</a>.</em></p>












	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://boundlesshumanblog.com/marketing-makes-the-world-a-better-place-cory-ames-grow-ensemble/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873957</guid>
            <pubDate>Fri, 22 Jan 2021 17:39:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A curriculum developed around the television series, Halt and Catch Fire]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25873949">thread link</a>) | @_pius
<br/>
January 22, 2021 | https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/ | <a href="https://web.archive.org/web/*/https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="about">
      

<p>This site features a curriculum developed around the television series, <a href="https://www.google.com/search?channel=fs&amp;client=ubuntu&amp;q=halt+and+catch+fire">Halt and Catch Fire</a> (2014-2017), a fictional narrative about people working in tech during the 1980s-1990s.</p>

<p>The intent is for this website to be used by self-forming small groups that want to create a “watching club” (like a book club) and discuss aspects of technology history that are featured in this series.</p>

<p>There are 15 classes, for a “semester-long” course:<br>
~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/01.html">#01</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/02.html">#02</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/03.html">#03</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/04.html">#04</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/05.html">#05</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/06.html">#06</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/07.html">#07</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/08.html">#08</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/09.html">#09</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/10.html">#10</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/11.html">#11</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/12.html">#12</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/13.html">#13</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/14.html">#14</a> ~ <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/classes/15.html">#15</a> ~</p>

<p><strong>Prefer a <a href="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/HaltAndCatchFireSyllabus.pdf">PDF</a>?</strong></p>

<p>Brief guide to class layout:</p>
<ul>
  <li><strong>Apéritifs</strong> Casual viewing presented before gathering. This is entertainment; not required viewing.</li>
  <li><strong>RFC as koan</strong> A Request for Comments from the Internet Engineering Task Force, for reflecting on.</li>
  <li><strong>Emulation as koan</strong> An emulated computer in the browser, also for reflection.</li>
  <li><strong>Themes</strong> Recommendations for topics to be discussed.</li>
  <li><strong>Prompts</strong> Questions to inspire conversation when gathering.</li>
  <li><strong>Readings</strong> Related material for deeper thinking on the class topic.</li>
  <li><strong>Description</strong> Brief summary of what’s going on in the episodes and how it relates to tech history at large / the weekly topic.</li>
  <li><strong>Episode summaries</strong> A link to summaries of the episodes that should be watched prior to meeting as a group. Watching each episode is not required; if time doesn’t allow, refer to the summaries. Content warnings are provided for relevant episodes. If there are specific concerns, this can determine which episodes should be skipped or anticipated before viewing.</li>
</ul>

<p><br>
Curriculum and website designed by <a href="https://ashleyblewer.com/">Ashley Blewer</a>.<br>
see also ↠ <a href="https://github.com/ablwr/halt-and-catch-fire-syllabus">source code &amp; site metadata</a></p>

<p><img src="https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/assets/img/construction.gif" alt="under construction"></p>

    	</div></div>]]>
            </description>
            <link>https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873949</guid>
            <pubDate>Fri, 22 Jan 2021 17:38:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof of Reserves and Why It Matters]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25873947">thread link</a>) | @Bluestein
<br/>
January 22, 2021 | https://www.quadrigainitiative.com/proofofreserves.php | <a href="https://web.archive.org/web/*/https://www.quadrigainitiative.com/proofofreserves.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<p>In case you missed them, so far this year we've seen 3 large scale exchange events:</p>
<ul>
<li>QuadrigaCX</li>
<li>EZ-BTC</li>
<li>Cryptopia</li></ul>

<p>Each one represents massive losses for those involved - hundreds and thousands of affected lives. These are real people and families at the other ends, with hopes and dreams, who worked hard for their money.</p>

<p>In the case of QuadrigaCX, it took the freezing of the bank accounts, the death/disappearance of the CEO, and concerted legal action to even realize it was insolvent.</p>

<p>Exchanges can easily continue to operate for years with whatever level of reserves they like. Nothing prevents exchange owners from spending cryptocurrency stored by users, or failing to disclose if reserves are breached. Third party audits are riddled with holes like:</p>
<ul>

<li>How can they know the client list they're given is legitimate and fully inclusive?</li>

<li>How can you know the funds weren't borrowed for the audit purposes?</li>

<li>How old is the report? How can you trust the auditor?</li></ul>

<p>On top of that - most exchange platforms still don't even bother to audit. Despite the warnings about storing funds on exchanges, people still do. And remember that many affected users weren't storing funds on Quadriga - they simply got stuck with no way to withdraw.</p>

<p>Proof of Reserves asks exchanges to:</p>
<ul>

<li>Publish the wallet public keys so people can see that funds are fully backed. (A satoshi test can prove ownership of those wallets.)</li>

<li>Publish a hash tree to let each customer validate that their balance is included in the total.</li></ul>

<p>What it doesn't prevent:</p>

<ul>

<li>Same as presently, if funds are not secured in proper multi-sig wallets or multiple exchange operators are corrupt, the funds could still be taken, up to what's stored. However, this would be immediately known to everyone instead of revealed whenever admins felt like it (or never).</li>

<li>The balances of customers who never check the hash tree could be excluded by a dishonest exchange, which wouldn't be noticed until one of those customers decided to check.</li>

<li>A dishonest exchange could still dispute the balance of a customer or arbitrarily prevent withdrawals. In this case, the customer and exchange would have to sort that out.</li>

<li>A dishonest exchange could pretend to own wallets it doesn't. A satoshi test would help with this, where the exchange operators send a small amount at a specified time.</li>

<li>While it makes things safer, it's still not a good idea to store funds on the exchange.</li></ul>

<p>What it does prevent:</p>

<ul>

<li>The exchange owner can't spend funds of active customers, and still claim to hold them.<ul>

<li>ie QuadrigaCX, EZ-BTC</li></ul></li>

<li>The exchange owner can't conceal if funds are hacked or stolen. It becomes known immediately.<ul>

<li>ie Mt. Gox, Cryptopia, Bitgrail</li></ul></li>

<li>Anyone can see if the exchange is solvent before trading.<ul>

<li>ie Anyone with "bad timing" using an insolvent exchange.</li></ul></li></ul>

<p><a href="https://web.archive.org/web/20170114112433/https://iwilcox.me.uk/2014/proving-bitcoin-reserves">Check this link for more details on Proof of Reserves, including the full hash tree algorithm.</a></p>

<p>Despite the relative simplicity of publishing wallet keys, the vast selection of exchanges we have in Canada, and the many millions of dollars stored, not a single exchange has done so. The hash tree algorithm has existed since 2014. It's presently on one exchange (last audited in 2014).</p>

<p><a href="https://www.quadrigainitiative.com/txquick.php">This is why we are so pleased to work with an exchange partner committed to transparency, who will be implementing a full proof of reserves.</a></p>

<p>It's time to do something about this!</p>

<!--<form action="emailonly.php" method="post">
<input type="hidden" name="r" value="">
<table width="100%">
<tbody><tr><td colspan="3"><h3>Join the Fight for Proof of Reserves</h3></td></tr>
<tr><td>First&nbsp;Name:</td><td><input type="text" name="first" value=""></td><td>Enter your first name. (Used in email contact.)</td></tr>
<tr><td>Email:</td><td><input type="text" name="email" value=""></td><td>Enter an email address which will work to receive a launch announcement in a few months.</td></tr>
<tr><td colspan="3" style="text-align:center"><input type="checkbox" value="1" name="confirm" id="confirm"><label for="confirm"> I accept the <a href="terms.php">Terms of Use</a> and <a href="privacy.php">Privacy Policy</a>.</label></td></tr>
<tr><td colspan="3"><input type="submit" value="Email-Only Signup" style="width:100%;font-size: 1.17em;"></td></tr></tbody></table>
</form>-->

</div><p>Your use of this site/service accepts the <a href="https://www.quadrigainitiative.com/terms.php">Terms of Use</a> and <a href="https://www.quadrigainitiative.com/privacy.php">Privacy Policy</a>. This site is not associated with Ernst &amp; Young, Miller Thompson, or the Official Committee of Affected User. For questions or enquiries, email <a href="mailto:info@quadrigainitiative.com">info@quadrigainitiative.com</a>.</p></div>]]>
            </description>
            <link>https://www.quadrigainitiative.com/proofofreserves.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873947</guid>
            <pubDate>Fri, 22 Jan 2021 17:38:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting the Apple M1 GPU, Part II]]>
            </title>
            <description>
<![CDATA[
Score 564 | Comments 185 (<a href="https://news.ycombinator.com/item?id=25873887">thread link</a>) | @dddddaviddddd
<br/>
January 22, 2021 | https://rosenzweig.io/blog/asahi-gpu-part-2.html | <a href="https://web.archive.org/web/*/https://rosenzweig.io/blog/asahi-gpu-part-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<header><p>22 Jan 2021</p></header><p>Less than a month ago, I began <a href="https://rosenzweig.io/blog/asahi-gpu-part-1.html">investigating the Apple M1 GPU</a> in hopes of developing a free and open-source driver. This week, I’ve reached a second milestone: drawing a triangle with my own open-source code. The vertex and fragment shaders are handwritten in machine code, and I interface with the hardware via the IOKit kernel driver in an identical fashion to the system’s Metal userspace driver.</p>
<figure>
<img src="https://rosenzweig.io/M1HelloTriangle.png" alt=""><figcaption>A triangle rendered on the M1 with open-source code</figcaption>
</figure>
<p>The bulk of the new code is responsible for constructing the various command buffers and descriptors resident in shared memory, used to control the GPU’s behaviour. Any state accessible from Metal corresponds to bits in these buffers, so understanding them will be the next major task. So far, I have focused less on the content and more on the connections between them. In particular, the structures contain pointers to one another, sometimes nested multiple layers deep. The bring-up process for the project’s triangle provides a bird’s eye view of how all these disparate pieces in memory fit together.</p>
<p>As an example, the application-provided vertex data are in their own buffers. An internal table in yet another buffer points each of these vertex buffers. That internal table is passed directly as input to the vertex shader, specified in another buffer. That description of the vertex shader, including the address of the code in executable memory, is pointed to by another buffer, itself referenced from the main command buffer, which is referenced by a handle in the IOKit call to submit a command buffer. Whew!</p>
<p>In other words, the demo code is not yet intended to demonstrate an understanding of the fine-grained details of the command buffers, but rather to demonstrate there is “nothing missing”. Since GPU virtual addresses change from run to run, the demo validates that all of the pointers required are identified and can be relocated freely in memory using our own (trivial) allocator. As there is a bit of “magic” around memory and command buffer allocation on macOS, having this code working at an early stage gives peace of mind going forward.</p>
<p>I employed a piecemeal bring-up process. Since my IOKit wrapper exists in the same address space as the Metal application, the wrapper may modify command buffers just before submission to the GPU. As an early “hello world”, I identified the encoding of the render target’s clear colour in memory, and demonstrated that I could modify the colour as I pleased. Similarly, while learning about the instruction set to bring up the disassembler, I replaced shaders with handwritten equivalents and confirmed I could execute code on the GPU, provided I wrote out the machine code. But it’s not necessary to stop at these “leaf nodes” of the system; after modifying the shader code, I tried uploading shader code to a different part of the executable buffer while modifying the command buffer’s pointer to the code to compensate. After that, I could try uploading the commands for the shader myself. Iterating in this fashion, I could build up every structure needed while testing each in isolation.</p>
<p>Despite curveballs, this procedure worked out far better than the alternative of jumping straight to constructing buffers, perhaps via a “replay”. I had used that alternate technique to bring-up Mali a few years back, but it comes with the substantial drawback of fiendishly difficult debugging. If there is a single typo in five hundred lines of magic numbers, there would be no feedback, except an error from the GPU. However, by working one bit at a time, errors could be pinpointed and fixed immediately, providing a faster turn around time and a more pleasant bring-up experience.</p>
<p>But curveballs there were! My momentary elation at modifying the clear colours disappeared when I attempted to allocate a buffer for the colours. Despite encoding the same bits as before, the GPU would fail to clear correctly. Wondering if there was something wrong with the way I modified the pointer, I tried placing the colour in an unused part of memory that was already created by the Metal driver – that worked. The contents were the same, the way I modified the pointers was the same, but somehow the GPU didn’t like my memory allocation. I wondered if there was something wrong with the way I allocated memory, but the arguments I used to invoke the memory allocation IOKit call were bit-identical to those used by Metal, as confirmed by <code>wrap</code>. My last-ditch effort was checking if GPU memory had to be mapped explicitly via some side channel, like the <code>mmap</code> system call. IOKit does feature a device-independent memory map call, but no amount of fortified tracing found any evidence of side-channel system call mappings.</p>
<p>Trouble was brewing. Feeling delirious after so much time chasing an “impossible” bug, I wondered if there wasn’t something “magic” in the system call… but rather in the GPU memory itself. It was a silly theory since it produces a serious chicken-and-egg problem if true: if a GPU allocation has to be blessed by another GPU allocation, who blesses the first allocation?</p>
<p>But feeling silly and perhaps desperate, I pressed forward to test the theory by inserting a memory allocation call <em>in the middle</em> of the application flow, such that every subsequent allocation would be at a different address. Dumping GPU memory before and after this change and checking for differences revealed my first horror: an auxiliary buffer in GPU memory tracked all of the required allocations. In particular, I noticed values in this buffer increasing by one at a predictable offset (every <code>0x40</code> bytes), suggesting that the buffer contained an array of handles to allocations. Indeed, these values corresponded exactly to handles returned from the kernel on GPU memory allocation calls.</p>
<p>Putting aside the obvious problems with this theory, I tested it anyway, modifying this table to include an extra entry at the end with the handle of my new allocation, and modifying the header data structure to bump the number of entries by one. Still no dice. Discouraging as it was, that did not sink the theory entirely. In fact, I noticed something peculiar about the entries: contrary to what I thought, not <em>all</em> of them corresponded to valid handles. No, all but the <em>last</em> entry were valid. The handles from the kernel are 1-indexed, yet in each memory dump, the final handle was always <code>0</code>, nonexistent. Perhaps this acts as a sentinel value, analogous to NULL-terminated strings in C. That explanation begs the question of why? If the header already contains a count of entries, a sentinel value is redundant.</p>
<p>I pressed on. Instead of adding on an extra entry with my handle, I copied the last entry <code>n</code> to the extra entry <code>n + 1</code> and overwrote the (now second to last) entry <code>n</code> with the new handle.</p>
<p>Suddenly my clear colour showed up.</p>
<p>Is the mystery solved? I got the code working, so in some sense, the answer must be yes. But this is hardly a satisfying explanation; at every step, the unlikely solution only raises more questions. The chicken-and-egg problem is the easiest to resolve: this mapping table, along with the root command buffer, is allocated via a special IOKit selector independent from the general buffer allocation, and the handle to the mapping table is passed along with the submit command buffer selector. Further, the idea of passing required handles with command buffer submission is not unheard of; a similar mechanism is used on mainline Linux drivers. Nevertheless, the rationale for using 64-byte table entries in shared memory, as opposed to a simple CPU-side array, remains totally elusive.</p>
<p>Putting memory allocation woes behind me, the road ahead was not without bumps (and potholes), but with patience, I iterated until I had constructed the entirety of GPU memory myself in parallel to Metal, relying on the proprietary userspace only to initialize the device. Finally, all that remained was a leap of faith to kick off the IOKit handshake myself, and I had my first triangle.</p>
<p>These changes amount to around 1700 lines of code since the last blog post, available on <a href="https://github.com/AsahiLinux/gpu">GitHub</a>. I’ve pieced together a simple demo animating a triangle with the GPU on-screen. The window system integration is effectively nonexistent at this point: XQuartz is required and detiling the (64x64 Morton-order interleaved) framebuffer occurs in software with naive scalar code. Nevertheless, the M1’s CPU is more than fast enough to cope.</p>
<p>Now that each part of the userspace driver is bootstrapped, going forward we can iterate on the instruction set and the command buffers in isolation. We can tease apart the little details and bit-by-bit transform the code from hundreds of inexplicable magic constants to a real driver. Onwards!</p>
<p><a href="https://rosenzweig.io/">Back to home</a></p>
</div>]]>
            </description>
            <link>https://rosenzweig.io/blog/asahi-gpu-part-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873887</guid>
            <pubDate>Fri, 22 Jan 2021 17:34:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on Making Small Games]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25873837">thread link</a>) | @adnzzzzZ
<br/>
January 22, 2021 | https://a327ex.github.io/blog/small-games | <a href="https://web.archive.org/web/*/https://a327ex.github.io/blog/small-games">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><small><i>published on: 2021-01-22</i></small><br><small><i>last updated on: 2021-01-22</i></small></p></div></div><!--
title: Thoughts on making small games
date: 2021-01-22
update: 2021-01-22
-->

<p>I notice more people talking about making small games. As I'm currently also focused on this goal I thought it would be good to write something about it.</p>
<p>I personally think that indiedevs currently focused on this have a few misconceptions about the problem and aren't thinking about it clearly enough, and in this post I'll go over that argument.</p>
<h2 id="the-meaning-of-small">The meaning of small</h2>
<p>The first thing to notice is that the word <em>small</em>, when used in the context of making games, is conflating multiple meanings into one word. The first meaning is related to how long or how many people it took to make the game. The second meaning is related to how long it takes players to go through the game.</p>
<p>When indie developers use this word to describe their games, they're generally referring to both meanings at the same time, or to one of them in an interchangeable way with the other.</p>
<p>For instance, <a href="https://www.youtube.com/watch?v=wb22xeh_VqM" target="_blank">this great talk</a> (watch it in its entirety, I highly recommend it) goes over techniques for making games every month. However, it implicitly assumes that because this development duration is small, the games also will be fairly small for the players. This is illustrated in the first point where one month games are referred to as concept games rather than real games.</p>
<p><iframe width="100%" height="100%" src="https://www.youtube.com/embed/wb22xeh_VqM?rel=0&amp;modestbranding=1&amp;feature=oembed" allowfullscreen="" scrolling="no" allow="encrypted-media; accelerometer; clipboard-write; gyroscope; picture-in-picture"></iframe></p>
<p>Another example of a similar assumption being made is in <a href="https://howtomarketagame.com/2021/01/18/can-you-make-a-living-from-small-games-on-steam/" target="_blank">this article</a>, which goes over a game made in 4 months. Similarly, it is implicitly assumed that because the game was made in a short timeframe, the game would also necessarily be fairly small from the perspective of the players - as far as I can tell it can be finished in about 1 or 2 hours - and there's not a single point made by the author in relation to that.</p>
<p>In both of these cases you see the same error being implicitly made, which is that both meanings of the word small are the same thing, and this logically leads to the idea that if you make a game in a short timespan it must be the case that the game will not last a very long amount of time to the player. These are just two examples, and they're simply illustrative because this error is made by pretty much every indiedev talking about making small games.</p>
<h2 id="the-game-scope-chart">The game scope chart</h2>
<p>To further illustrate the point, you could look at this problem as a chart with four quadrants. On the horizontal axis we'll have one meaning of the word, on the vertical axis we'll have another. For clarity's sake, we'll refer to the meaning that pertains to development as small/big and to the other as short/long.</p>
<p><img src="https://i.imgur.com/mG5qz09.png"></p>
<p>We generally don't care about the top two quadrants of the chart. Those are related to games that have big development times or teams, and that's not what people are referring to when they talk about small games. We're then left with the bottom two quadrants, and here we have a spectrum that goes from small short games to small long games.</p>
<p>Most indie devs inherently assume that because a game is small, it has to be short. I reject this notion entirely. I think the quadrant of small long games is fairly unexplored, at least in the context of small games discussions, and it's useful to think about if this is a valid quadrant at all.</p>
<h2 id="my-experience-with-bytepath">My experience with BYTEPATH</h2>
<p>The only game I've released so far is <a href="https://store.steampowered.com/app/760330/BYTEPATH/" target="_blank">BYTEPATH</a>, and it falls under what I would consider a small long game.</p>
<p>It's small because it was made in about 4 months by me alone, and it also has a fairly small scope. By the nature of its gameplay it's essentially a single screen game with lots of upgrades, like one of those old flash games.</p>
<p>And it's long because it feels like a long game. Despite the game being small and made in just 4 months, it has a skill tree with about 900 nodes, it has 10 different characters, I don't even remember how many different classes but probably around 40, essentially, it's what I also like to call a <em>spacious</em> game.</p>
<p>You ever listen to a song or an album for hundreds of hours? I'm currently doing this for <a href="https://eirthankyouscientist.bandcamp.com/album/terraformer" target="_blank">Thank You Scientist's Terraformer</a> and it's crazy how despite listening to it for so long I still find new things in each song that I didn't notice before. This album is a spacious album. It can be thought of as this large space, and as you listen to it, you're exploring it, mapping the environment, finding new walls, rooms, objects, that you didn't know were there before.</p>
<p>Games can also be like this, and long games are generally like this. BYTEPATH certainly is because it was made to be so, as the goal of the game is finding new builds to play, to the point where the main gameplay itself is kind of irrelevant.</p>
<p>And because of this I think BYTEPATH did way better than I expected it to do. It's also important to note that despite me calling spacious games long games, they don't necessarily have to be played by most people for a very long time. Here's what BYTEPATH's hour distribution looks like:</p>
<p><img src="https://i.imgur.com/Fqmq6hW.png"></p>
<p>This is definitely not impressive but it's also not too bad. And I know for a fact there's at least one guy (I saw him in the game's reviews) who played it for over 100 hours. When games feel spacious they have the possibility of keeping people playing for a fairly long time, which increases the chances that the game will do well.</p>
<h2 id="small-long-games">Small long games</h2>
<p>The most important point here is that small long/spacious games <em>DO NOT</em> need to take a long time to be made. If I were to make a game like BYTEPATH again I'm fairly confident I could do it in 2 months, and it would be a significantly better game too, simply because it's actually not that hard. (I'm 100% not some kind of disciplined productivity God or anything)</p>
<p>When developers focus on making small games, this implicit notion that the games also have to be short is pretty wrong. You can make small long games, and because of the way the market works, those kinds of games will tend to do better than short games. I'm not the first person to notice this:</p>
<p><iframe width="100%" height="100%" src="https://www.youtube.com/embed/sIqz5xmQKnc?rel=0&amp;modestbranding=1&amp;feature=oembed" allowfullscreen="" scrolling="no" allow="encrypted-media; accelerometer; clipboard-write; gyroscope; picture-in-picture"></iframe></p><br>
<h2 id="marketing">Marketing</h2>
<p>Another issue that happens often is that because developers are making small games that they feel are sort of worthless, they don't really do a good, serious job at marketing them. For instance, the example game from <a href="https://howtomarketagame.com/2021/01/18/can-you-make-a-living-from-small-games-on-steam/" target="_blank">this article</a> was marketed on Twitter only.</p>
<p>Anyone who has released a game knows that Twitter is notoriously poor at driving sales, and that sites like reddit are much better. Would it really have cost these developers that much time to make a few posts about their games on reddit? No. And I know for a fact that a game of such visual quality would have done very well on multiple subreddits.</p>
<p>So a lot of the conclusions people reach about their efforts with smaller games, and the conclusion the author reaches in that article as well are pretty pessimist and in my view mistaken. I think that most devs making smaller games would benefit tremendously from taking making their games somewhat more spacious and from thinking more clearly about how they're going to market it.</p>
<h2 id="the-right-development-duration">The right development duration</h2>
<p>Another thing to consider is what's the right timeframe for making a small game. One of the videos above focuses on 1 month per game, and both my previous game and the game from the article above took 4 months. I think the right duration is between 1 and 2 months.</p>
<p>The reasons for this are fairly simple. If you're making a 1 month game you probably want something with a scope such that it can be finished in 2-3 days, and then you spend the rest of the month polishing it in various ways. This keeps your game fairly focused and it's a good strategy if you want to drastically increase your chances of actually finishing and release the game.</p>
<p>If you're making a 2 month game this affords you a little more time such that you can actually start adding some meat to it and make it more spacious. But I personally think that it's too easy to start getting lost in scope-creep if you give yourself much more time than 2 months, so that would be my limit. Currently that's what I'm aiming for with the game I'm making and I already overscoped myself slightly (meaning I should have chosen an even smaller game), so I think it really pays to keep this duration limited like this unless you're already more experienced and know you can avoid making these kinds of mistakes.</p>
<p>What also matters is how much money you can expect to make off of these games. BYTEPATH for instance made about $10k over its lifetime, and if I were to release a game like BYTEPATH every 2 months and they all did half as well as it did, then that would be considered "making a living from small games on Steam". But that's largely because I live in Brazil and that amount of money here (even accounting for cuts and taxes) every 2 months would be a pretty comfortable salary. If you're in more expensive countries then perhaps that isn't such a good strategy, so this timeframe consideration really depends on your personal situation as well.</p>
<h2 id="luck">Luck</h2>
<p>To finalize this fairly rambly article, one of the reasons people cite for making small games is to hedge their bets. The argument goes that if they make lots of games, chances are that one of those games will succeed wildly and cover for the costs of the other failures. More specifically <a href="https://www.gamasutra.com/blogs/DanielCook/20150415/241145/Minimum_Sustainable_Success.php" target="_blank">this article</a> said that using this famous graph:</p>
<p><img src="https://i.imgur.com/FNg1WW8.png"></p>
<p>I similarly reject this notion. In my opinion you shouldn't make small games for any reason having to do with what that article says. When you're approaching things from this economic portfolio theory approach you're mirrorring the biases of our society around the notion of luck and chance and it more likely than not will sap your motivation to work on things without you even realizing it.</p>
<p>Additionally, for a single indie developer like me, I don't think it's actually that hard to get a game to sell, say 5000 copies. And if you can do that consistently you can definitely make a living off it. Maybe I'm arrogant and I don't know what I'm talking about. I probably am, after all I've only released one game. But I'd rather be arrogant like that than view things from this lottery/luck oriented approach that so many people seem to fall prey to these days.</p>
<p>This …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://a327ex.github.io/blog/small-games">https://a327ex.github.io/blog/small-games</a></em></p>]]>
            </description>
            <link>https://a327ex.github.io/blog/small-games</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873837</guid>
            <pubDate>Fri, 22 Jan 2021 17:29:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Swyg – Job candidates interview other candidates]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25873795">thread link</a>) | @jawns
<br/>
January 22, 2021 | https://swyg.com/candidates/ | <a href="https://web.archive.org/web/*/https://swyg.com/candidates/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section id="why-swyg"><div><h2>Why Swyg?</h2><p><strong>A better candidate experience.</strong></p><p>The traditional job application process can be frustrating. A slow and opaque hiring process is a big turn-off for job applicants. By letting candidates interview other candidates, Swyg gives all participants a meaningful and significant voice in the interviewing process.</p></div></section><section id="download-our-case-studies"><header><h2>Download our case studies</h2><strong>Don't just take our word for it. See how Swyg is helping companies just like yours!</strong></header><div><ul><li><img src="data:image/svg+xml;base64,PHN2ZyBpZD0ibW1jLWxvZ28iIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHZpZXdCb3g9IjAgMCAxODAgNDUuNTk0Ij4KICA8dGl0bGU+bW1jLWxvZ288L3RpdGxlPgogIDxnIGZpbGw9Im5vbmUiIGZpbGwtcnVsZT0iZXZlbm9kZCI+CiAgICA8cGF0aCBmaWxsPSIjMmEwMzJmIiBkPSJNIDk5LjE0NCAzMy40NDYgViAwLjY4NiBIIDkxLjc4IEwgNjguNTEgMzMuNDMxIFYgMC42ODYgaCAtNy4yMjMgTCAzOC4wNzMgMzMuNDQ3IFYgMC42ODYgaCAtNy40NTcgTCAwLjE1NyA0NC42MjUgTCAwIDQ0Ljg1IGggNy41NTEgTCAzMi4wMTIgOC43NTggViA0NC44NSBoIDUuMTA2IGwgMjUuMzMgLTM1Ljk1MSBWIDQ0Ljg1IGggNS4xNjMgTCA5My4wODIgOC44NjIgViA0NC44NSBoIDUuMTA3IGwgMjUuMzMgLTM1Ljk1MSBWIDQ0Ljg1IGggNi4wNjEgViAwLjY4NiBoIC03LjIyMiBsIC0yMy4yMTQgMzIuNzYgTSAxNzMuMjM4IDMxLjkyNCBsIC0wLjI3NCAwLjM2NCBjIC0zLjcxMSA0LjkzIC04LjcxNCA3LjY0NSAtMTQuMDg3IDcuNjQ1IGEgMTYuOTExIDE2LjkxMSAwIDAgMSAtMTEuODM3IC01LjE1IGEgMTcuMTQ1IDE3LjE0NSAwIDAgMSAtNS4xIC0xMS45IGMgMCAtOS4xNzQgNy44ODcgLTE3LjIyMiAxNi44NzkgLTE3LjIyMiBhIDE2LjkzMiAxNi45MzIgMCAwIDEgMTMuOTQ0IDcuMzE4IGwgMC4yNzEgMC40MDYgaCA2LjY4NSBsIC0wLjYyOCAtMS4zMSBDIDE3NS42ODUgNC45NjYgMTY3LjM3MSAwIDE1OC44NzcgMCBhIDIyLjY2OSAyMi42NjkgMCAwIDAgLTIzIDIyLjgyNiBhIDIyLjQzNyAyMi40MzcgMCAwIDAgNi44MiAxNi4xOTQgYSAyMy4xMTEgMjMuMTExIDAgMCAwIDE2LjIzNSA2LjU3NCBhIDIyLjU0MyAyMi41NDMgMCAwIDAgMTEuNjg3IC0zLjI4NiBhIDI0LjQ3OSAyNC40NzkgMCAwIDAgOC42MiAtOS4wMjUgbCAwLjc1OSAtMS4zNTkgaCAtNi43NjIiPgogICAgPC9wYXRoPgogIDwvZz4KPC9zdmc+Cg==" alt="MMC Logo"><div><p>MMC created a more inclusive hiring process focussed on a great candidate experience. With the help of Swyg, they hired an amazing analyst.</p><p><a href="https://swyg.com/static/documents/swyg-mmc-case-study.pdf" target="_blank">Download</a></p></div></li><li><img src="data:image/svg+xml;base64,<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 800 200">
  <g
     id="g1"
     transform="translate(1336.5435,-1736.3561)">
    <rect
       width="2546.1001"
       height="2546.1001"
       style="opacity:1;fill:#000000;fill-opacity:0"
       id="rect1827"
       x="0"
       y="0" />
    <rect
       x="-2248.1226"
       y="385.36295"
       transform="rotate(-45)"
       class="st1"
       width="161.39235"
       height="477.01822"
       id="rect1829-6"
       style="opacity:1;fill:#f2669f;fill-opacity:1;stroke-width:0.288665" />
    <rect
       x="-2207.5862"
       y="385.36624"
       transform="rotate(-45)"
       class="st2"
       width="40.182102"
       height="477.01822"
       id="rect1831-7"
       style="opacity:1;fill:#ff7bac;fill-opacity:1;stroke-width:0.288665" />
    <rect
       x="-2126.7148"
       y="385.35849"
       transform="rotate(-45)"
       class="st2"
       width="40.008911"
       height="477.01822"
       id="rect1833-5"
       style="opacity:1;fill:#ff7bac;fill-opacity:1;stroke-width:0.288665" />
    <polygon
       class="st3"
       points="1372.2,975.6 1173.9,975.6 1173.9,1173.9 975.6,1173.9 975.6,1372.2 1173.9,1372.2 1173.9,1570.5 1372.2,1570.5 1372.2,1372.2 1570.5,1372.2 1570.5,1173.9 1372.2,1173.9 "
       id="polygon1835-3"
       style="opacity:1;fill:#f7f739;fill-opacity:1"
       transform="matrix(0.28866733,0,0,0.28866733,-1598.785,1466.2181)" />
  </g>
  <g
     id="g3"
     style="fill:#1b1464;fill-opacity:1"
     transform="matrix(5.1205009,0,0,5.1205009,-1277.7821,-617.62999)">
    <path
       style="fill:#1b1464;fill-opacity:1;stroke-width:0.055372"
       d="m 305.69374,147.00913 -0.58141,0.0232 -0.31485,-0.05 -0.31485,-0.05 -0.34961,-0.0895 -0.34962,-0.0895 -0.40775,-0.19488 -0.40775,-0.19489 -0.39793,-0.39633 -0.39792,-0.39634 -0.20169,-0.38966 -0.20169,-0.38967 -0.13943,-0.48113 -0.13943,-0.48113 -0.0612,-0.70731 -0.0611,-0.7073 0.0174,-3.07315 0.0174,-3.07315 0.12782,-0.25949 0.12782,-0.2595 0.22532,-0.20356 0.22532,-0.20356 0.25595,-0.11807 0.25595,-0.11807 0.49835,-2.1e-4 0.49835,-2.1e-4 0.35028,0.18992 0.35029,0.18992 0.18658,0.21798 0.18659,0.21799 0.0861,0.25258 0.0861,0.25258 10e-4,2.71721 0.001,2.71721 0.078,0.36789 0.078,0.36789 0.11255,0.22062 0.11255,0.22061 0.24819,0.21847 0.24819,0.21846 0.32719,0.0991 0.32719,0.0991 0.63128,-0.0225 0.63127,-0.0225 0.32402,-0.16165 0.32402,-0.16164 0.21401,-0.24313 0.21401,-0.24314 0.11352,-0.30338 0.11351,-0.30339 0.0535,-0.50765 0.0535,-0.50765 10e-4,-2.47158 0.001,-2.47157 0.15506,-0.29681 0.15505,-0.2968 0.26556,-0.20072 0.26557,-0.20071 0.32381,-0.098 0.32381,-0.098 0.35945,0.0288 0.35946,0.0289 0.26098,0.12633 0.26097,0.12634 0.18768,0.16478 0.18767,0.16478 0.15016,0.25542 0.15016,0.25542 v 4.78968 4.78968 l -0.15189,0.25837 -0.15188,0.25837 -0.23444,0.20067 -0.23444,0.20068 -0.38074,0.11564 -0.38074,0.11565 -0.34377,-0.0276 -0.34376,-0.0276 -0.2486,-0.10997 -0.2486,-0.10996 -0.21361,-0.18755 -0.2136,-0.18755 -0.12912,-0.27727 -0.12911,-0.27726 -7.4e-4,-0.2907 -7.4e-4,-0.2907 h -0.0428 -0.0428 l -0.10704,0.19877 -0.10704,0.19876 -0.42819,0.40281 -0.42819,0.40281 -0.46021,0.22713 -0.46022,0.22714 -0.35992,0.0864 -0.35991,0.0865 -0.58141,0.0232 z m 31.94965,-3.7e-4 -0.80289,0.0193 -0.1938,-0.0245 -0.19381,-0.0245 -0.44297,-0.0875 -0.44298,-0.0875 -0.3876,-0.13902 -0.38761,-0.13901 -0.33223,-0.16678 -0.33223,-0.16678 -0.32542,-0.22074 -0.32543,-0.22076 -0.41516,-0.39436 -0.41517,-0.39437 -0.2427,-0.34012 -0.24271,-0.34013 -0.27321,-0.57375 -0.27321,-0.57376 -0.11389,-0.44297 -0.1139,-0.44298 -0.0537,-0.41529 -0.0537,-0.41529 -10e-4,-0.49835 -0.001,-0.49835 0.0851,-0.52451 0.0851,-0.52452 0.16719,-0.49903 0.16719,-0.49904 0.22433,-0.40638 0.22433,-0.40638 0.31968,-0.40228 0.31967,-0.40227 0.3248,-0.28533 0.32481,-0.28533 0.41529,-0.25808 0.41529,-0.25807 0.34672,-0.15564 0.34673,-0.15563 0.37311,-0.11574 0.37311,-0.11574 0.52603,-0.0798 0.52604,-0.0798 0.47211,-3.7e-4 0.47212,-3.7e-4 0.45876,0.0575 0.45875,0.0575 0.57976,0.18991 0.57975,0.18991 0.37202,0.20371 0.37203,0.20371 0.40301,0.30344 0.40302,0.30345 0.3362,0.36669 0.33619,0.3667 0.27019,0.43881 0.27019,0.43881 0.16298,0.39177 0.16297,0.39177 0.11153,0.42621 0.11152,0.42621 0.0653,0.56173 0.0653,0.56172 -0.025,0.30176 -0.025,0.30176 -0.10958,0.14677 -0.10958,0.14677 -0.20917,0.16932 -0.20917,0.16933 -3.94015,0.0277 -3.94015,0.0277 0.018,0.13843 0.018,0.13843 0.12517,0.27686 0.12517,0.27686 0.27038,0.26599 0.27037,0.266 0.38931,0.19038 0.38931,0.19037 0.40506,0.0835 0.40507,0.0835 h 0.48456 0.48456 l 0.3229,-0.0597 0.32291,-0.0597 0.31002,-0.1371 0.31002,-0.13711 0.25119,-0.16119 0.2512,-0.16119 0.35183,-0.0901 0.35183,-0.0901 0.25306,0.0379 0.25307,0.0379 0.23606,0.11097 0.23607,0.11096 0.2008,0.22227 0.20081,0.22227 0.0715,0.17384 0.0715,0.17385 0.0384,0.23329 0.0384,0.23329 -0.0861,0.29627 -0.0861,0.29628 -0.16442,0.22697 -0.16441,0.22697 -0.24181,0.16637 -0.24181,0.16637 -0.43965,0.22041 -0.43965,0.2204 -0.44998,0.14102 -0.44997,0.14103 -0.49135,0.0894 -0.49135,0.0894 -0.80289,0.0193 z m -0.35206,-7.05811 h 2.52131 l -0.037,-0.23533 -0.037,-0.23533 -0.15544,-0.33907 -0.15544,-0.33906 -0.20921,-0.23157 -0.2092,-0.23156 -0.24195,-0.14179 -0.24194,-0.14179 -0.33518,-0.10432 -0.33519,-0.10432 h -0.43531 -0.43532 l -0.29343,0.0617 -0.29343,0.0617 -0.30454,0.14253 -0.30455,0.14253 -0.2851,0.28489 -0.28511,0.28489 -0.13785,0.27223 -0.13786,0.27223 -0.0863,0.2907 -0.0863,0.29071 z m 11.70332,7.07822 -0.30454,-0.007 -0.16612,-0.0197 -0.16611,-0.0197 -0.33223,-0.0579 -0.33224,-0.0579 -0.35991,-0.11484 -0.35992,-0.11481 -0.47067,-0.24171 -0.47066,-0.24171 -0.41276,-0.31903 -0.41277,-0.31903 -0.3166,-0.37697 -0.3166,-0.37696 -0.22583,-0.38012 -0.22582,-0.38013 -0.16544,-0.41314 -0.16543,-0.41315 -0.11145,-0.46308 -0.11146,-0.46308 -0.0606,-0.65523 -0.0606,-0.65524 0.0607,-0.62185 0.0607,-0.62186 0.11726,-0.46371 0.11726,-0.46371 0.1567,-0.38505 0.1567,-0.38505 0.26585,-0.44513 0.26586,-0.44512 0.47066,-0.48212 0.47067,-0.48212 0.41231,-0.2651 0.41231,-0.26509 0.41972,-0.17702 0.41973,-0.17702 0.4692,-0.12057 0.46921,-0.12059 0.58141,-0.0318 0.58141,-0.0318 0.45073,0.0857 0.45075,0.0857 0.37846,0.15141 0.37846,0.15141 0.27824,0.16334 0.27823,0.16334 0.29716,0.25296 0.29717,0.25296 0.20947,0.26501 0.20948,0.26501 0.0592,-0.33627 0.0592,-0.33626 0.14136,-0.24121 0.14136,-0.24122 0.17873,-0.13398 0.17872,-0.13398 0.24917,-0.13052 0.24918,-0.13051 0.49835,-1.1e-4 0.49835,-1.1e-4 0.27685,0.12704 0.27687,0.12704 0.21426,0.20491 0.21427,0.20491 0.13126,0.27686 0.13128,0.27687 7.4e-4,4.64482 7.4e-4,4.64482 -0.0664,0.22171 -0.0664,0.22169 -0.2647,0.28962 -0.26469,0.28962 -0.29182,0.12602 -0.29181,0.12602 -0.36636,0.0266 -0.36635,0.0266 -0.2787,-0.0926 -0.2787,-0.0926 -0.25161,-0.16665 -0.2516,-0.16666 -0.16579,-0.2503 -0.16579,-0.2503 -0.0274,-0.14801 -0.0274,-0.148 -0.0342,-0.2091 -0.0342,-0.2091 -0.21003,0.26447 -0.21003,0.26447 -0.24683,0.22631 -0.24682,0.2263 -0.38479,0.22732 -0.38479,0.22731 -0.42323,0.14102 -0.42324,0.14102 -0.37966,0.0549 -0.37966,0.0549 -0.30454,-0.007 z m 0.77521,-3.09558 0.52604,0.002 0.35992,-0.12742 0.35991,-0.1274 0.23405,-0.14817 0.23405,-0.14817 0.29799,-0.30278 0.29797,-0.30278 0.2004,-0.38135 0.20039,-0.38135 0.0835,-0.35421 0.0835,-0.35421 -1.6e-4,-0.24917 -1.7e-4,-0.24918 -0.0817,-0.3876 -0.0817,-0.38761 -0.17451,-0.35534 -0.17451,-0.35535 -0.39341,-0.39694 -0.39341,-0.39695 -0.3118,-0.15077 -0.31179,-0.15078 -0.2973,-0.0791 -0.29729,-0.0791 -0.36112,-7.4e-4 -0.36112,-7.4e-4 -0.3705,0.10274 -0.37051,0.10274 -0.31304,0.18796 -0.31304,0.18797 -0.24504,0.27686 -0.24505,0.27686 -0.16261,0.33223 -0.16261,0.33223 -0.0843,0.33002 -0.0842,0.33003 7.4e-4,0.47287 7.4e-4,0.47287 0.0817,0.34665 0.0817,0.34664 0.17192,0.34058 0.17193,0.34058 0.28463,0.30095 0.28463,0.30096 0.23875,0.13991 0.23874,0.13992 0.31575,0.10095 0.31575,0.10096 0.52603,0.002 z m 11.96036,3.09977 -0.74752,-0.005 -0.3876,-0.071 -0.38761,-0.071 -0.39658,-0.1187 -0.39659,-0.11869 -0.32325,-0.14274 -0.32325,-0.14275 -0.36951,-0.24539 -0.3695,-0.24539 -0.27836,-0.30456 -0.27835,-0.30457 -0.18149,-0.36864 -0.18148,-0.36864 -0.0215,-0.38035 -0.0215,-0.38034 0.0949,-0.24845 0.0949,-0.24846 0.13174,-0.15656 0.13173,-0.15656 0.28888,-0.12427 0.28887,-0.12427 0.34563,0.002 0.34563,0.002 0.24877,0.11005 0.24877,0.11004 0.45647,0.42688 0.45647,0.42689 0.38528,0.18465 0.38528,0.18464 0.31093,0.0645 0.31093,0.0645 0.53213,-0.0256 0.53213,-0.0256 0.2633,-0.12746 0.2633,-0.12746 0.0779,-0.18636 0.0779,-0.18636 -0.0329,-0.15181 -0.0329,-0.15181 -0.0629,-0.12917 -0.0629,-0.12918 -0.22352,-0.12902 -0.22352,-0.12902 -1.24587,-0.44132 -1.24587,-0.44132 -0.48335,-0.22386 -0.48336,-0.22385 -0.42096,-0.29101 -0.42096,-0.29101 -0.26752,-0.30015 -0.26751,-0.30015 -0.16642,-0.34043 -0.16641,-0.34044 -0.066,-0.3407 -0.066,-0.3407 0.0201,-0.63128 0.0201,-0.63128 0.21074,-0.4264 0.21073,-0.4264 0.31135,-0.33629 0.31134,-0.33629 0.34498,-0.24617 0.34498,-0.24617 0.40644,-0.18509 0.40645,-0.1851 0.44873,-0.11869 0.44874,-0.1187 0.5663,-0.054 0.56629,-0.054 0.53398,0.0554 0.53397,0.0554 0.46527,0.1105 0.46526,0.11049 0.44978,0.21297 0.44979,0.21298 0.32413,0.24292 0.32413,0.24293 0.27064,0.36021 0.27064,0.36021 0.0897,0.26807 0.0897,0.26807 -0.0225,0.3528 -0.0225,0.35281 -0.16646,0.2097 -0.16645,0.20971 -0.27403,0.13728 -0.27403,0.13728 -0.36913,0.021 -0.36914,0.021 -0.28732,-0.0954 -0.28731,-0.0954 -0.36793,-0.25205 -0.36794,-0.25205 -0.3506,-0.16419 -0.3506,-0.16419 -0.4281,-0.003 -0.42811,-0.003 -0.2636,0.0738 -0.2636,0.0738 -0.16203,0.16203 -0.16204,0.16204 v 0.20976 0.20976 l 0.11598,0.14745 0.11598,0.14744 0.22823,0.11643 0.22824,0.11644 1.28115,0.43096 1.28116,0.43096 0.40955,0.20505 0.40956,0.20504 0.3401,0.24125 0.34011,0.24125 0.30398,0.33591 0.30398,0.33591 0.16774,0.31617 0.16774,0.31617 0.0974,0.33224 0.0974,0.33223 -10e-4,0.52603 -10e-4,0.52604 -0.1231,0.35992 -0.1231,0.35991 -0.13349,0.23002 -0.13348,0.23001 -0.28732,0.31437 -0.28732,0.31437 -0.30871,0.20941 -0.30871,0.2094 -0.33318,0.16798 -0.33318,0.16798 -0.48949,0.1493 -0.48949,0.14931 -0.47857,0.0777 -0.47858,0.0777 -0.74752,-0.005 z m 24.83435,-0.0272 -0.7752,0.0217 -0.22149,-0.0241 -0.22149,-0.0241 -0.4636,-0.0844 -0.46359,-0.0844 -0.4416,-0.16116 -0.44161,-0.16117 -0.42372,-0.22836 -0.42374,-0.22836 -0.41027,-0.31341 -0.41027,-0.31342 -0.31236,-0.36234 -0.31236,-0.36235 -0.2568,-0.41286 -0.2568,-0.41286 -0.17254,-0.43201 -0.17254,-0.43201 -0.10779,-0.42146 -0.10779,-0.42146 -0.0498,-0.66926 -0.0498,-0.66926 0.0491,-0.5235 0.0491,-0.52349 0.11107,-0.42851 0.11107,-0.4285 0.11484,-0.29387 0.11484,-0.29387 0.19113,-0.34977 0.19114,-0.34978 0.22016,-0.29802 0.22016,-0.29803 0.29105,-0.29353 0.29104,-0.29352 0.30454,-0.23134 0.30455,-0.23133 0.47925,-0.25491 0.47926,-0.25491 0.47644,-0.16104 0.47644,-0.16105 0.59472,-0.0933 0.59472,-0.0933 0.66447,0.0276 0.66446,0.0276 0.52543,0.12548 0.52542,0.12548 0.38225,0.15555 0.38223,0.15556 0.44152,0.26585 0.44151,0.26586 0.35957,0.31649 0.35956,0.31649 0.32262,0.40335 0.32262,0.40335 0.22151,0.41529 0.22149,0.41529 0.16701,0.49859 0.167,0.49859 0.085,0.48752 0.085,0.48752 0.009,0.48978 0.009,0.48977 -0.11002,0.21296 -0.11001,0.21296 -0.23515,0.16612 -0.23514,0.16611 -3.92667,0.0149 -3.92667,0.0149 7.4e-4,0.1235 7.4e-4,0.1235 0.1325,0.28459 0.13252,0.28459 0.2021,0.2237 0.20211,0.22371 0.27426,0.176 0.27428,0.176 0.4288,0.13866 0.4288,0.13867 0.64287,0.0288 0.64287,0.0288 0.4092,-0.0911 0.40919,-0.0911 0.35992,-0.1933 0.35992,-0.19331 0.30454,-0.14933 0.30455,-0.14933 0.38761,7.4e-4 0.3876,7.4e-4 0.25412,0.11405 0.25413,0.11405 0.20172,0.20173 0.20173,0.20172 0.0971,0.17908 0.0971,0.17909 v 0.44297 0.44298 l -0.12317,0.23221 -0.12316,0.23221 -0.1902,0.18472 -0.19019,0.18471 -0.43041,0.24626 -0.43041,0.24627 -0.52883,0.18566 -0.52883,0.18567 -0.52604,0.1069 -0.52603,0.1069 -0.77521,0.0217 z m -0.45481,-7.05516 h 2.52144 l -0.0779,-0.33397 -0.0779,-0.33398 -0.11855,-0.23359 -0.11854,-0.23358 -0.1357,-0.16226 -0.13569,-0.16227 -0.2305,-0.18441 -0.2305,-0.18442 -0.43199,-0.13782 -0.43199,-0.13783 h -0.45619 -0.45617 l -0.32588,0.0849 -0.32588,0.0849 -0.26776,0.14573 -0.26776,0.14573 -0.27895,0.29496 -0.27895,0.29494 -0.1621,0.34655 -0.1621,0.34654 -0.036,0.17997 -0.0359,0.17995 z m 11.91682,7.05861 -0.55372,0.0225 -0.34337,-0.0485 -0.34337,-0.0485 -0.42653,-0.11968 -0.42654,-0.11969 -0.40744,-0.18568 -0.40745,-0.18568 -0.41877,-0.28949 -0.41878,-0.28951 -0.42495,-0.4546 -0.42496,-0.45461 -0.25602,-0.43538 -0.25601,-0.43538 -0.17117,-0.44298 -0.17118,-0.44298 -0.082,-0.33223 -0.082,-0.33223 -0.0655,-0.49835 -0.0655,-0.49835 0.0315,-0.77521 0.0315,-0.77521 0.0903,-0.4095 0.0903,-0.40951 0.16499,-0.456 0.165,-0.45599 0.26017,-0.44916 0.26017,-0.44916 0.32852,-0.39153 0.32852,-0.39153 0.44034,-0.33181 0.44033,-0.3318 0.36628,-0.18377 0.36627,-0.18377 0.40625,-0.14593 0.40625,-0.14593 0.50739,-0.0823 0.50738,-0.0823 0.4153,7.5e-4 0.41528,7.4e-4 0.38035,0.0806 0.38035,0.0806 0.3118,0.11579 0.3118,0.11579 0.30455,0.17038 0.30455,0.17038 0.30454,0.23943 0.30455,0.23943 0.24917,0.31351 0.24918,0.31352 0.0277,-3.45393 0.0277,-3.45393 0.12184,-0.22772 0.12183,-0.22772 0.27048,-0.24294 0.27048,-0.24294 0.28779,-0.10311 0.28781,-0.10311 0.35905,0.002 0.35906,0.002 0.28921,0.0961 0.28922,0.0961 0.30845,0.30952 0.30844,0.30952 0.0797,0.27686 0.0797,0.27686 v 7.80745 7.80746 l -0.14872,0.28184 -0.14871,0.28185 -0.20839,0.18297 -0.20839,0.18296 -0.25199,0.11632 -0.25198,0.11631 h -0.49835 -0.49835 l -0.25199,-0.11631 -0.25198,-0.11632 -0.20695,-0.1817 -0.20695,-0.1817 -0.13742,-0.23449 -0.13742,-0.23449 -0.0404,-0.31824 -0.0404,-0.31824 -0.25413,0.32745 -0.25412,0.32746 -0.35497,0.26897 -0.35497,0.26897 -0.44298,0.20676 -0.44297,0.20676 -0.35992,0.0913 -0.35992,0.0913 -0.55372,0.0226 z m 0.56505,-3.07738 0.50967,0.006 0.35849,-0.13012 0.35849,-0.13013 0.28013,-0.17976 0.28013,-0.17976 0.27401,-0.2998 0.274,-0.29982 0.19326,-0.3863 0.19327,-0.38631 0.0663,-0.31909 0.0663,-0.31908 -0.0285,-0.47066 -0.0285,-0.47067 -0.13551,-0.36802 -0.13551,-0.36802 -0.26142,-0.36635 -0.26143,-0.36635 -0.2874,-0.21469 -0.28741,-0.2147 -0.27687,-0.13764 -0.27686,-0.13765 -0.29342,-0.0623 -0.29343,-0.0623 h -0.34556 -0.34556 l -0.32588,0.0849 -0.32588,0.0849 -0.26648,0.14504 -0.26647,0.14504 -0.3258,0.33928 -0.3258,0.33929 -0.13937,0.27522 -0.13938,0.27522 -0.0886,0.29861 -0.0886,0.29861 -0.0354,0.42477 -0.0354,0.42477 0.0945,0.46712 0.0945,0.46712 0.20145,0.38361 0.20145,0.38361 0.28152,0.28835 0.28152,0.28835 0.34345,0.17337 0.34346,0.17338 0.20741,0.0489 0.20742,0.0489 z m -82.70944,2.97943 -0.41529,0.0204 -0.3127,-0.13202 -0.3127,-0.13201 -0.14741,-0.11595 -0.14741,-0.11595 -0.10843,-0.13785 -0.10843,-0.13785 -0.10855,-0.23919 -0.10856,-0.23921 -7.4e-4,-4.67893 -7.4e-4,-4.67894 0.1292,-0.27686 0.1292,-0.27686 0.23724,-0.21388 0.23725,-0.21389 0.25595,-0.11781 0.25595,-0.1178 0.47066,-7.4e-4 0.47066,-7.4e-4 0.30934,0.14506 0.30933,0.14506 0.20189,0.20189 0.20189,0.20189 0.0937,0.17908 0.0937,0.17908 0.0319,0.3592 0.0319,0.3592 0.18633,-0.29091 0.18632,-0.29092 0.3565,-0.32666 0.3565,-0.32667 0.43799,-0.22787 0.43799,-0.22786 0.43117,-0.11298 0.43117,-0.11297 0.66446,0.002 0.66447,0.002 0.43167,0.11148 0.43168,0.11148 0.35265,0.16831 0.35266,0.1683 0.33427,0.25128 0.33428,0.25128 0.26022,0.34339 0.26023,0.3434 0.19046,0.40871 0.19046,0.4087 0.14566,0.53262 0.14566,0.53262 0.0181,3.56073 0.0181,3.56074 -0.13346,0.29151 -0.13346,0.29152 -0.25149,0.20608 -0.2515,0.20608 -0.32369,0.11431 -0.32369,0.11432 -0.3876,-0.0246 -0.3876,-0.0246 -0.25596,-0.11349 -0.25595,-0.11348 -0.23724,-0.21389 -0.23724,-0.21388 -0.1292,-0.27686 -0.1292,-0.27686 -0.003,-2.63017 -0.003,-2.63017 -0.0746,-0.41808 -0.0746,-0.41808 -0.14001,-0.27629 -0.14002,-0.2763 -0.25824,-0.23804 -0.25824,-0.23804 -0.25891,-0.11862 -0.2589,-0.1186 -0.60909,1.1e-4 -0.60909,1.1e-4 -0.30894,0.12388 -0.30894,0.12388 -0.22756,0.19479 -0.22757,0.19479 -0.142,0.29024 -0.142,0.29024 -0.0819,0.38664 -0.0819,0.38664 -10e-4,2.7162 -0.001,2.7162 -0.14279,0.28652 -0.14278,0.28653 -0.21273,0.16849 -0.21274,0.16849 -0.26741,0.11897 -0.26743,0.11896 -0.41528,0.0204 z m 12.68019,-7.4e-4 -0.41529,0.0209 -0.3105,-0.13112 -0.3105,-0.13111 -0.16886,-0.12024 -0.16885,-0.12024 -0.17025,-0.25703 -0.17025,-0.25702 -0.0426,-0.19969 -0.0425,-0.19969 v -7.752 -7.75208 l 0.15449,-0.3146 0.1545,-0.3146 0.20289,-0.17815 0.2029,-0.17814 0.29265,-0.13398 0.29264,-0.13398 0.40203,-0.001 0.40204,-10e-4 0.32895,0.1236 0.32896,0.12359 0.25704,0.25703 0.25703,0.25703 0.0923,0.27093 0.0923,0.27094 v 7.77732 7.77732 l -0.0664,0.2217 -0.0664,0.2217 -0.2647,0.28962 -0.26469,0.28962 -0.29182,0.12687 -0.29182,0.12687 -0.41529,0.0209 z m 41.05835,-0.003 -0.3876,0.0189 -0.22149,-0.0734 -0.22148,-0.0734 -0.17277,-0.0901 -0.17275,-0.0901 -0.25271,-0.28107 -0.25272,-0.28108 -0.0729,-0.20573 -0.0729,-0.20573 v -7.77954 -7.77977 l 0.0738,-0.20844 0.0738,-0.20843 0.20738,-0.26223 0.20739,-0.26223 0.2755,-0.14979 0.27551,-0.14979 0.31581,-0.0495 0.31581,-0.0495 0.28604,0.0452 0.28605,0.0452 0.29357,0.14363 0.29358,0.14363 0.19647,0.22954 0.19648,0.22954 0.0818,0.27548 0.0818,0.27549 0.002,3.43685 0.002,3.43686 0.20005,-0.37506 0.20005,-0.37507 0.32558,-0.30142 0.32557,-0.30143 0.51099,-0.24943 0.51101,-0.24944 0.42679,-0.0846 0.4268,-0.0846 0.43146,3.7e-4 0.43148,3.7e-4 0.35991,0.0568 0.35992,0.0568 0.35992,0.11669 0.35992,0.1167 0.35991,0.18229 0.35993,0.18229 0.29676,0.24684 0.29676,0.24684 0.24419,0.29677 0.24419,0.29676 0.24617,0.49835 0.24615,0.49835 0.13594,0.52885 0.13592,0.52886 0.0629,0.5509 0.0629,0.55089 -0.0169,2.96241 -0.0169,2.9624 -0.0979,0.17908 -0.0979,0.17908 -0.20189,0.20189 -0.20188,0.20189 -0.30934,0.14477 -0.30933,0.14477 -0.47067,2.1e-4 -0.47066,2.1e-4 -0.30934,-0.14507 -0.30933,-0.14506 -0.19501,-0.19502 -0.19502,-0.19501 -0.11859,-0.24497 -0.11858,-0.24496 -7.4e-4,-2.46042 -7.4e-4,-2.46041 -0.0534,-0.46472 -0.0534,-0.46472 -0.16346,-0.34929 -0.16346,-0.34929 -0.25632,-0.25632 -0.25632,-0.25633 -0.29827,-0.13655 -0.29828,-0.13655 -0.34705,-0.0559 -0.34704,-0.0559 -0.38995,0.0648 -0.38994,0.0647 -0.29909,0.14522 -0.29909,0.14521 -0.2446,0.23772 -0.2446,0.23772 -0.13419,0.29312 -0.13419,0.29311 -0.0558,0.29421 -0.0558,0.29421 v 2.63003 2.63003 l -0.0664,0.2217 -0.0664,0.2217 -0.2647,0.28962 -0.26469,0.28962 -0.29182,0.12646 -0.29181,0.12646 -0.38761,0.0189 z"
       id="path1191-6" />
  </g>
</svg>
" alt="Unleashed Logo"><div><p>Swyg helped unleashed hire an amazing people partner. By using our platform they were able to conduct 75 interviews over 3 days.</p><p><a href="https://swyg.com/static/documents/swyg-unleashed-case-study.pdf" target="_blank">Download</a></p></div></li></ul></div></section><section id="swyg-benefits-for-candidates"><header><h2>Swyg benefits for candidates</h2></header><div><ul><li><strong>More human.</strong><p>You’re more than a CV. That’s why Swyg gives every candidate the opportunity to show their best side to a real human.</p></li><li><strong>Collaborative.</strong><p>In the Swyg process, every participant is on an equal footing, everyone gets a voice. This makes the process more collaborative than traditional interviews.</p></li><li><strong>Everyone gets feedback.</strong><p>No more black-hole job applications. We give every candidate feedback. Moreover, seeing your peers in the interview process is a great way to get better at interviewing.</p></li><li><strong>Fairness.</strong><p>Candidates should not be judged based on whether they happen to get along well with the interviewer. Our AI ensures the process is fair for everyone.</p></li></ul></div></section><section id="the-candidate-journey"><div><p><h2><span>The<!-- --> </span><span>Candidate<!-- --> </span><span>Journey<!-- --> </span></h2></p><div><ol><li><strong>Apply</strong><p>Candidates apply on hiring company careers page.</p></li><li><strong>On-boarding</strong><p>Candidates receive an invitation from Swyg and we’ll explain how our process works.</p></li><li><strong>Peer to Peer interviews</strong><p>Candidates participate in multiple interviews over 1-hour.</p></li><li><strong>Feedback</strong><p>All participants receive feedback from Swyg. The hiring company decides next steps.</p></li></ol></div></div></section></div></div>]]>
            </description>
            <link>https://swyg.com/candidates/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873795</guid>
            <pubDate>Fri, 22 Jan 2021 17:26:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Source Licensing for Supervillains]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25873701">thread link</a>) | @markmossberg
<br/>
January 22, 2021 | https://offlinemark.com/2021/01/22/open-source-licensing-for-supervillains/ | <a href="https://web.archive.org/web/*/https://offlinemark.com/2021/01/22/open-source-licensing-for-supervillains/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>This post covers my research into open source software licensing and my analysis of real-world open source projects that profit off of open source code via proprietary licenses.</p>



<p>Keep reading and you’ll learn:</p>



<ul><li>What the difference between a restrictive and permissive license is</li><li>What dual licensing is and how you can use it make money off of open source code</li><li>What CLAs are and the <strong>specific clause</strong> your CLA needs for use with dual licensing</li><li>Examples of companies that implement dual licensing and how they do it</li></ul>



<p>And of course: I am not a lawyer and none of this is legal advice.</p>



<hr>



<p><strong>Let’s talk evil</strong>. And by evil, I mean money.</p>



<p>Here’s a hypothetical scenario. Let’s say you write some code and would like to open source it. But, if someone uses it to make money, you want a cut. Nefarious, right?</p>



<p>This kind of thinking tends to be taboo in open source. In open source, you typically choose a license for your software and it is either restrictive (copyleft) (e.g. GPL) or permissive (e.g. MIT). Restrictive licenses require parties that redistribute the code — modified or unmodified — use the same license and release source. Permissive licenses do not have these conditions. They allow distributing under any license and not releasing source.</p>



<p><strong>In either case, people are allowed to profit off of your work, without restriction</strong>. This is explicitly permitted in most open source licenses:</p>



<p>GPL:</p>



<blockquote><p>d) Convey the object code by offering access from a designated place (gratis <strong>or for a charge</strong>)</p><cite>https://opensource.org/licenses/GPL-3.0</cite></blockquote>



<p>MIT:</p>



<blockquote><p><em>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, <strong>and/or sell copies of the Software</strong>, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</em></p><cite>https://opensource.org/licenses/MIT</cite></blockquote>



<p>Indeed, the general definition of open source from the Open Source Initiative (the organization that officially approves licenses as ‘open source’) <strong>explicitly protects the ability to sell open source software</strong>.</p>



<blockquote><p>1. Free Redistribution The license <strong>shall not restrict any party from selling</strong> or giving away the software as a component of an aggregate software distribution containing programs from several different sources. The license shall not require a royalty or other fee for such sale.</p><cite><br><a href="https://opensource.org/osd-annotated">https://opensource.org/osd-annotated</a></cite></blockquote>



<p>A license that restricts use of the software in commercial settings would not be considered open source, even if the code was freely available and you accepted contributions.</p>



<p>Is this it? <strong>If we open source our code, are we doomed to lose any chance of capturing profits generated by it?&nbsp;</strong></p>



<p>No, there is a solution: dual licensing. It is possible to license a codebase under multiple licenses, offer users a choice, and effectively force them to pay for a commercial license.</p>



<h2>Dual licensing for profit… and profit</h2>



<p>We can dual license our project under two licenses and offer users a choice. Let’s say we choose the GPL (a restrictive, copyleft license) and a non-open-source, commercial license of our own.</p>



<ul><li>The restrictive license is meant for casual users, hobbyists, and other members of the open source community. They’ll need to release source but they probably won’t mind.</li><li>The commercial license is meant for the companies that want to sell our code. That’s where we’ll include our terms about getting paid and make our money.</li></ul>



<p><strong>The critical assumption is that companies using our code commercially will not want to release their source</strong>. Their source means both their modifications to our code and their proprietary application that links to our code. This will prevent them from using the copyleft license and their only other option (barring walking away) will be to begrudgingly contact us for a commercial license.</p>



<p>However, if they are somehow ok with releasing source, then we’ve been foiled. If they have <em>somehow</em> found a business model that allows them to both sell our software <em>and</em> comply with the GPL (release their code), there’s nothing we can do. But the idea is that this is rare.</p>



<h3>Abuse of the GPL</h3>



<p>To be clear, this technique is abuse of the GPL. The GPL and copyleft philosophy are foremost about freedom of source and the reality that the GPL is unusable for businesses just happens to be an unfortunate side effect. But for us supervillains who may or may not care about free software, this makes it the perfect tool. C’est la vie.</p>



<h3>Subtle pitfalls with CLAs (Contributor License Agreements)</h3>



<p>We’re not done yet. In order to dual license, we need full copyright ownership over the codebase. This is because we need to relicense the codebase under our commercial license, which gets tricky if we want to <s>exploit free labor</s> accept contributions.</p>



<p>By default, the copyright on an open source contribution stays with the contributor. This means we lose copyright ownership over the full codebase and can no longer relicense it in its entirety. To maintain full ownership, we need permission from each contributor.</p>



<p>We’ll institute a new system. Now, before anyone can contribute, they need to sign an agreement that either:</p>



<ol><li>Transfers their copyright to us entirely.</li><li>Explicitly gives us permission to relicense their contributions (which remain under their copyright) under an arbitrary license.</li></ol>



<p>The latter agreement is called a CLA (Contributor <em>License</em> Agreement). The former is a CTA (Copyright <em>Transfer</em> Agreement).</p>



<p>So where do you get a CLA? You can use a popular one like the Apache or Harmony CLAs but be careful, not all of them are appropriate for dual licensing.</p>



<p>The Apache CLA (<a href="https://www.apache.org/licenses/icla.pdf">pdf</a>) should not be used for dual licensing because it does <strong>not</strong> specify a relicensing clause.</p>



<blockquote><p>Subject to the terms and conditions of this Agreement, You hereby grant to the Foundation and to recipients of software distributed by the Foundation a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare derivative works of, publicly display, publicly perform, <strong>sublicense</strong>, and distribute Your Contributions and such derivative works.</p></blockquote>



<p>It does mention the ability to “sublicense” but this does not mean “relicense”. From what I could find, “sublicensing” is akin to “forwarding” existing license terms. Sublicensing permission does not allow for loosening existing license restrictions. (sources: <a href="https://flylib.com/books/en/4.467.1.50/1/">1</a> <a href="https://opensource.stackexchange.com/questions/2644/does-the-mit-licenses-right-to-sublicense-allow-me-to-change-the-license-of-s">2</a> <a href="https://softwareengineering.stackexchange.com/questions/189633/what-sublicense-actually-means">3</a>)<span id="easy-footnote-1-897"></span><span><a href="#easy-footnote-bottom-1-897" title="&amp;#8220;Note that the license terms for a sublicense must be consistent with ”not necessarily the same as ”the original license terms. A sublicensor cannot sublicense more rights than have been granted by the original author&amp;#8221; (Rosen, 166) &amp;#8220;Open Source Licensing: Software Freedom and Intellectual Property Law&amp;#8221; "><sup>1</sup></a></span></p>



<p>Here’s an example. Let’s say we have a project on Github which is dual licensed between GPL and a commercial license, and uses the Apache CLA.</p>



<p>Contributions by default become GPL due to the Github <a href="https://docs.github.com/articles/github-terms-of-service#6-contributions-under-repository-license">terms of service</a>. The Apache CLA gives the project owner the right to sublicense contributions. Since sublicensing does not permit loosening restrictions, when the project owner relicenses the codebase in a commercial license, that commercial license cannot remove the GPL restriction that requires source to be released. Therefore, the Apache CLA doesn’t give project owners enough permission to implement a dual licensing scheme.</p>



<p>Unlike the Apache CLA, the <a href="http://harmonyagreements.org/docs/ha-cla-i-v1.pdf">Harmony CLA</a>, specifically with Outbound Option #5 chosen, will work. This is what <a href="https://ubuntu.com/legal/contributors">Ubuntu</a> <a href="https://ubuntu.com/legal/contributors/agreement">uses</a>. The Outbound License section specifies to what extent the contribution can be relicensed. Option 5 is the most permissive, allowing relicensing.</p>



<blockquote><p>(Option Five) Based on the grant of rights in Sections 2.1 and 2.2, if We include Your Contribution in a Material, <strong>We may license the Contribution under any license, including copyleft, permissive, commercial, or proprietary licenses</strong>. As a condition on the exercise of this right, We agree to also license the Contribution under the terms of the license or licenses which We are using for the Material on the Submission Date.</p></blockquote>



<p>So the quick answer is to <strong>use the Harmony CLA with Outbound License option #5 for dual licensing.</strong></p>



<h3>Time to make some money!</h3>



<p>We’re finished. We have a clever scheme which lets us solve the paradox of being both an “open source” project while also restricting the ability of users to sell our code without giving us a cut 😈.</p>



<p>The only cost is that we have to enforce a heavyweight CTA/CLA. But most people just click through so this might be ok. Time to make some money!</p>



<h2>Case Studies</h2>



<p>MongoDB, Elasticsearch, Qt, and JUCE are “real life” projects that employ this scheme. Let’s look into how they implement dual licensing.<span id="easy-footnote-2-897"></span><span><a href="#easy-footnote-bottom-2-897" title="A few others that I didn&amp;#8217;t research deeply are <a href=&quot;https://www.cockroachlabs.com/docs/stable/licensing-faqs.html&quot;>CockroachDB</a> and <a href=&quot;https://redislabs.com/legal/licenses/&quot;>Redis</a>."><sup>2</sup></a></span></p>



<h3>MongoDB</h3>



<p>The MongoDB database is <a href="https://www.mongodb.com/community/licensing">dual licensed</a> under a custom copyleft license, the Server Side Public License (SSPL), and commercial licenses. This is done to is to <a href="https://www.mongodb.com/licensing/server-side-public-license/faq">prevent cloud providers</a> from freely profiting from running MongoDB as a service, especially without contributing back changes.</p>



<figure><img loading="lazy" width="625" height="146" src="https://i2.wp.com/offlinemark.com/wp-content/uploads/2020/11/image.png?resize=625%2C146&amp;ssl=1" alt="" srcset="https://i2.wp.com/offlinemark.com/wp-content/uploads/2020/11/image.png?resize=1024%2C240&amp;ssl=1 1024w, https://i2.wp.com/offlinemark.com/wp-content/uploads/2020/11/image.png?resize=300%2C70&amp;ssl=1 300w, https://i2.wp.com/offlinemark.com/wp-content/uploads/2020/11/image.png?resize=768%2C180&amp;ssl=1 768w, https://i2.wp.com/offlinemark.com/wp-content/uploads/2020/11/image.png?resize=1536%2C359&amp;ssl=1 1536w, https://i2.wp.com/offlinemark.com/wp-content/uploads/2020/11/image.png?resize=624%2C146&amp;ssl=1 624w, https://i2.wp.com/offlinemark.com/wp-content/uploads/2020/11/image.png?w=1770&amp;ssl=1 1770w, https://i2.wp.com/offlinemark.com/wp-content/uploads/2020/11/image.png?w=1250&amp;ssl=1 1250w" sizes="(max-width: 625px) 100vw, 625px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/offlinemark.com/wp-content/uploads/2020/11/image.png?resize=1024%2C240&amp;ssl=1 1024w, https://i2.wp.com/offlinemark.com/wp-content/uploads/2020/11/image.png?resize=300%2C70&amp;ssl=1 300w, https://i2.wp.com/offlinemark.com/wp-content/uploads/2020/11/image.png?resize=768%2C180&amp;ssl=1 768w, https://i2.wp.com/offlinemark.com/wp-content/uploads/2020/11/image.png?resize=1536%2C359&amp;ssl=1 1536w, https://i2.wp.com/offlinemark.com/wp-content/uploads/2020/11/image.png?resize=624%2C146&amp;ssl=1 624w, https://i2.wp.com/offlinemark.com/wp-content/uploads/2020/11/image.png?w=1770&amp;ssl=1 1770w, https://i2.wp.com/offlinemark.com/wp-content/uploads/2020/11/image.png?w=1250&amp;ssl=1 1250w" data-lazy-src="https://i2.wp.com/offlinemark.com/wp-content/uploads/2020/11/image.png?resize=625%2C146&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>The <a href="https://www.mongodb.com/licensing/server-side-public-license">SSPL</a> is a <a href="https://webassets.mongodb.com/_com_assets/legal/SSPL-compared-to-AGPL.pdf">near-verbatim copy</a> of the <strong><a href="https://www.gnu.org/licenses/agpl-3.0.en.html">AGPL</a></strong> variant of the GPL.</p>



<p>Let’s start from the top.</p>



<ul><li>The GPL requires you to release source when you <em>distribute</em> (“convey”) the code (i.e. ship it to a user in source or binary form). Interaction with running code via the network does <em>not</em> count as distribution. (GPL Section 0, Paragraph 7)<span id="easy-footnote-3-897"></span><span><a href="#easy-footnote-bottom-3-897" title="&amp;#8220;To “convey” a work means any kind of propagation that enables other parties to make or receive copies. Mere interaction with a user through a computer network, with no transfer of a copy, is not conveying.&amp;#8221;"><sup>3</sup></a></span></li><li>The AGPL does not change the source-release requirement nor does it change the definition of distribution (common misconception). It simply adds a special case (AGPL Section 13, “Remote Network Interaction”) that additionally requires source release<strong> if a <em>modified</em> version of the program is used over a network.</strong> (AGPL Section 13, Paragraph 1)<span id="easy-footnote-4-897"></span><span><a href="#easy-footnote-bottom-4-897" title="Notwithstanding any other provision of this License, if you modify the Program, your modified version must prominently offer all users interacting with it remotely through a computer network (if your version supports such interaction) an opportunity to receive the Corresponding Source of your version by providing access to the Corresponding Source from a network server at no charge, through some standard or customary means of facilitating copying of software."><sup>4</sup></a></span> Offering an unmodified version is allowed without source release. This subtlety points to the original goal behind the AGPL: to ensure modifications are always released (AGPL Preamble). This goal is consistent with the overall philosophy of the FSF and notably not a goal of being anti-commercial-use.</li><li>The SSPL expands Section 13 of the AGPL to require source release for <strong>unmodified</strong> versions of the program that are specifically made “…available to third parties as a …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://offlinemark.com/2021/01/22/open-source-licensing-for-supervillains/">https://offlinemark.com/2021/01/22/open-source-licensing-for-supervillains/</a></em></p>]]>
            </description>
            <link>https://offlinemark.com/2021/01/22/open-source-licensing-for-supervillains/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873701</guid>
            <pubDate>Fri, 22 Jan 2021 17:20:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ClickHouse Is Apache 2.0]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25873409">thread link</a>) | @hodgesrm
<br/>
January 22, 2021 | https://altinity.com/blog/clickhouse-is-apache-2-0 | <a href="https://web.archive.org/web/*/https://altinity.com/blog/clickhouse-is-apache-2-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	

	<p>Open source licenses are in the news again. Elastic recently <a href="https://www.elastic.co/blog/licensing-change" target="_blank" rel="noreferrer noopener">changed the licensing for ElasticSearch and Kibana</a> from Apache 2.0 to a choice of <a href="https://www.mongodb.com/licensing/server-side-public-license" target="_blank" rel="noreferrer noopener">Server Side Public License</a> (SSPL) or the non-open source Elastic license. Like most open source licensing changes, this one prompted a lot of discussion. Examples <a href="https://news.ycombinator.com/item?id=25776657" target="_blank" rel="noreferrer noopener">here</a> and <a href="https://news.ycombinator.com/item?id=25833781" target="_blank" rel="noreferrer noopener">here</a> include some of the more printable comments.&nbsp;</p><p>But we’re not here to discuss Elastic’s business model or their choice of license(s).&nbsp; We’re here to discuss ClickHouse licensing and Altinity’s view of it. Here’s the executive summary.&nbsp;</p><p><strong>ClickHouse is Apache 2.0.&nbsp; Altinity is committed to ensuring it stays that way.&nbsp;</strong></p><p>Our contributions to ClickHouse are<a href="https://en.wikipedia.org/wiki/Apache_License" target="_blank" rel="noreferrer noopener"> Apache 2.0</a>. Our ecosystem projects like the ClickHouse Kubernetes operator are likewise Apache 2.0. We believe the Apache 2.0 license is best for our users. It’s also the best way to make ClickHouse the most popular SQL data warehouse on the planet. There are several reasons for our outlook.&nbsp;</p><p>The most important feature of Apache 2.0 is that it allows use for any purpose, which is the first of the <a href="https://www.gnu.org/philosophy/free-sw.en.html" target="_blank" rel="noreferrer noopener">four essential freedoms</a> of open source software. Such freedom is important for all applications, regardless of whether they run on-prem or as cloud services. Apache 2.0 opens the door to imaginative new services as well as creative paths to develop them. Installed&nbsp;applications morph into online services. Services that hide data behind APIs morph into open data. This freedom is key to enabling innovative new ways to incorporate analytics into applications, which in turn unlocks new business opportunities.&nbsp;</p><p>Apache 2.0 is also a great license for contributors.&nbsp; It has been around since 2004, which is a long time in open source. Corporate legal departments understand it and can easily approve contributions from employees. Individual contributors understand the freedom Apache 2.0 confers to publish their work and use it freely in future. It’s a win-win: companies are motivated to make investment decisions in open source projects, and contributors are motivated to implement them.&nbsp;</p><p>Apache 2.0 licensing opens a path to increasing ClickHouse capabilities and worldwide use. More important, it is enabling a flood of innovation in analytic applications. In a crowded market with many database products besides ClickHouse, that’s a critical competitive advantage.&nbsp;</p><p><h2 id="h-apache-2-0-creates-a-level-playing-field">Apache 2.0 creates a level playing field</h2>
</p><p>Since the ClickHouse Apache 2.0 license places no restriction on business use, we can expect many competing services that leverage ClickHouse in one way or another.&nbsp; This includes hosted ClickHouse and value-added analytic services built on top of ClickHouse capabilities. It also extends to add-ons for countless existing services ranging from web analytics to network flow log management to financial asset valuation and everything in between.</p><p>The competition will be distressing for unprepared vendors, but it’s great for users. Competing services mean that users have alternatives. It also means that innovation is not random but focused on things that users care about: SQL features, performance, security, cost-efficiency, and time to market.&nbsp;</p><p>The same vendors that offer ClickHouse managed services have contributed popular features to ClickHouse like <a href="https://altinity.com/blog/clickhouse-and-s3-compatible-object-storage" target="_blank" rel="noreferrer noopener">S3 storage integration</a>, <a href="https://clickhouse.tech/docs/en/operations/access-rights/#role-management" target="_blank" rel="noreferrer noopener">Role-based Access Control</a>, <a href="https://clickhouse.tech/docs/en/sql-reference/statements/select/with/" target="_blank" rel="noreferrer noopener">Common Table Expressions</a>, and many more. ClickHouse is experiencing the same <a href="https://en.wikipedia.org/wiki/Coopetition" target="_blank" rel="noreferrer noopener">co-opetition</a> feedback effect that helped fuel the success of Linux, Kubernetes, PostgreSQL, and other open source projects.&nbsp;</p><p><h2 id="h-restrictive-licenses-like-sspl-are-antithetical-to-user-interests">Restrictive licenses like SSPL are antithetical to user interests</h2>
</p><p>The Server Side Public License is an attempt to set back the clock on open source software development. It rules out new SaaS offerings based on projects whose value&nbsp;</p><div><blockquote>
<p>…entirely or primarily derives from the value of the Program or modified version, or offering a service that accomplishes for users the primary purpose of the Program or modified version.&nbsp; (SSPL Section 13).&nbsp;</p>
</blockquote>
</div><p>The goal of the SSPL and similar licenses is nothing short of setting up monopoly providers of SaaS offerings. It has ambiguous terms–creating uncertainty for potential competitors–and onerous viral requirements. Services that fall under Section 13 must release all source code required to run the entire SaaS offering. That includes everything from the service management plane down to deployment and backup scripts. SSPL is <a href="https://www.gnu.org/licenses/copyleft.en.html" target="_blank" rel="noreferrer noopener">copyleft</a> with fangs.&nbsp;</p><p>This obviously affects vendors trying to set up competing services to the copyright holders of SSPL projects. But the effect on the market is far wider.&nbsp; Analytics are pervasive in modern applications and SaaS is the primary way that software is now distributed. The SSPL potentially harms any user building an application who just wants a managed offering to take care of running it. We believe that’s an unacceptable limitation.&nbsp;</p><p><h2 id="h-but-wait-what-about-amazon">But wait, what about Amazon?</h2>
</p><p>Many vendors have justified <a href="https://techcrunch.com/2018/10/16/mongodb-switches-up-its-open-source-license/" target="_blank" rel="noreferrer noopener">open source relicensing as a necessary defense</a> against “strip mining” from public clouds. Aren’t we afraid of this ourselves? If so, it’s a bit late. There are already multiple cloud services for ClickHouse, including our own offering, <a href="https://altinity.com/cloud-database/" target="_blank" rel="noreferrer noopener">Altinity.Cloud</a>. There’s also <a href="https://cloud.yandex.com/services/managed-clickhouse" target="_blank" rel="noreferrer noopener">Yandex.Cloud</a> and at least three services in China. New entrants need to compete by adding additional value, <a href="https://siliconangle.com/2020/07/08/suse-acquires-rancher-labs-reported-600m-chases-1b-revenue-goal/" target="_blank" rel="noreferrer noopener">just as Rancher did</a> in the Apache 2.0-licensed Kubernetes market.&nbsp;&nbsp;</p><p>Our goal at Altinity is to help customers bring high-value analytic applications to market quickly and operate them cost-effectively. We focus on development efficiency, data privacy, world-class support, and operations. We do so on all platforms, both public cloud and on-prem. Anybody who has worked on such services knows there’s opportunity here to build many valuable companies, not just one.&nbsp;</p><p>Other paths are possible. Vendors may fork ClickHouse and try to add licenses that create a proprietary fortress. If so, we would point to some friendly advice from a famous competitive analyst of the Italian Renaissance:&nbsp;</p><div><blockquote>
<p><em>So the best fortress that exists is to avoid being hated by the people. If you have fortresses and the people hate you, they will not save you</em>.</p>
<p><cite><em>Niccolo Machiavelli, The Prince</em></cite></p></blockquote>
</div><p>We don’t want to build new fortresses to protect ourselves against our users. We want to tear them down. Apache 2.0 is the key to enabling a new generation of analytic applications based on ClickHouse. Altinity is all in.&nbsp;</p><p>P.S., If you are worried about ElasticSearch and Kibana switching licenses, this might be a nice time to look at alternatives. ClickHouse can store log data remarkably well. More on that in future articles.&nbsp;</p>
	


					</div></div>]]>
            </description>
            <link>https://altinity.com/blog/clickhouse-is-apache-2-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873409</guid>
            <pubDate>Fri, 22 Jan 2021 16:58:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EU Parliament condemns China deal over HK crackdown]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25873389">thread link</a>) | @riffraff
<br/>
January 22, 2021 | https://news.rthk.hk/rthk/en/component/k2/1571688-20210122.htm?spTabChangeable=0 | <a href="https://web.archive.org/web/*/https://news.rthk.hk/rthk/en/component/k2/1571688-20210122.htm?spTabChangeable=0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
			The EU has lost credibility on human rights by sealing an investment deal with China, a resolution in the European Parliament warned on Thursday.</p><p>

MEPs meeting by videolink in Brussels overwhelmingly passed the resolution which broadly condemned the crackdown on Hong Kong activists by the central government in China.</p><p>

The resolution also called for "targeted sanctions" against Chinese and Hong Kong officials held responsible for the police action.</p><p>

The opinion of EU lawmakers is important as they will need to approve the German-backed investment deal that was agreed in principle last month after years of talks.</p><p>

Given the Hong Kong crackdown, doubts about the accord have quickly emerged, with ratification by MEPs very much uncertain, though the vote is not expected until the end of the year at the earliest.</p><p>

The resolution said that MEPs "regret" that the EU-China investment talks were not seized "as a leverage tool aimed at preserving Hong Kong's high degree of autonomy, as well as its basic rights and freedoms".</p><p>

"By rushing to reach this agreement while not taking concrete action against ongoing, grave human right violations, for example in Hong Kong, Xinjiang province and Tibet, the EU risks undermining its credibility as a global human rights actor," it said.</p><p>

China is accused of grave human rights abuses against the Uighur minority in Xinjiang.</p><p>

The resolution said parliament will "carefully scrutinise" the deal and will take the human rights situation in China into account when it votes on the deal.</p><p>

The EU commission, which began negotiating the deal in 2014, said it helps rectify the long-standing imbalance in the way Brussels and Beijing treat investors and the access they allow them.</p><p>

It also says that China agreed through the deal - known as the Comprehensive Agreement on Investment (CAI) - to work harder towards approving International Labour Organisation (ILO) conventions on forced labour. (AFP)		</p></div></div>]]>
            </description>
            <link>https://news.rthk.hk/rthk/en/component/k2/1571688-20210122.htm?spTabChangeable=0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873389</guid>
            <pubDate>Fri, 22 Jan 2021 16:57:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The strange economics of open-source software (2015)]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25873194">thread link</a>) | @alexrustic
<br/>
January 22, 2021 | https://www.philipotoole.com/the-strange-economics-of-open-source-software/ | <a href="https://web.archive.org/web/*/https://www.philipotoole.com/the-strange-economics-of-open-source-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><a href="https://www.maynardkeynes.org/" target="_blank" rel="noopener noreferrer"><img title="John Maynard Keynes" src="https://www.philipotoole.com/wp-content/uploads/2015/09/keynes-150x150.png" alt="John Maynard Keynes" width="150" height="150"></a>I always use the names of economists for my machines’ <a href="http://tools.ietf.org/html/rfc1034" target="_blank" rel="noopener noreferrer">hostnames</a>. <a href="http://www.econlib.org/library/Enc/bios/Keynes.html" target="_blank" rel="noopener noreferrer"><em>keynes</em></a>, <a href="http://www.nobelprize.org/nobel_prizes/economic-sciences/laureates/1976/friedman-bio.html" target="_blank" rel="noopener noreferrer"><em>friedman</em></a>, <a href="https://en.wikipedia.org/wiki/Karl_Marx" target="_blank" rel="noopener noreferrer"><em>marx</em></a>, <em><a href="https://fraser.stlouisfed.org/docs/meltzer/fisdeb33.pdf" target="_blank" rel="noopener noreferrer">fisher</a>, </em><em><a href="http://www.britannica.com/biography/David-Ricardo" target="_blank" rel="noopener noreferrer">ricardo</a></em>.</p>
<p>So every so often the strange economics of open-source software hits me.</p>
<p><span id="more-2749"></span><br>
Today it is almost taken for granted that the source code for most software is freely available. This is a profound and remarkable change, given how different it was only 15 years ago. From a certain point of view our industry is “giving away” its product, and yet the industry <a href="http://www.nytimes.com/2015/09/20/opinion/is-big-tech-too-powerful-ask-google.html?_r=0" target="_blank" rel="noopener noreferrer">is richer and more powerful than ever</a>.&nbsp; So where is the value? What are the implications?</p>
<h2>Where has all the closed-source software gone?</h2>
<p>Of course, it’s not <strong>gone</strong>. It’s there at the banks, within embedded devices, and companies such as <a href="https://www.microsoft.com/" target="_blank" rel="noopener noreferrer">Microsoft</a> and <a href="https://www.oracle.com/" target="_blank" rel="noopener noreferrer">Oracle</a> remain among the most powerful companies in the world, but almost all the innovation — and most importantly most of the excitement —&nbsp; is happening within open-source.</p>
<p>Within our industry it is becoming apparent that services — <a href="http://searchcloudcomputing.techtarget.com/definition/Software-as-a-Service" target="_blank" rel="noopener noreferrer">SaaS</a>&nbsp; and companies such as <a href="https://www.airbnb.com/" target="_blank" rel="noopener noreferrer">Airbnb </a>— are the future.&nbsp; And in fact, it sometimes seems to be that the only way to write really valuable closed-source software nowadays is within the context of a service. Behind all the <a href="https://en.wikipedia.org/wiki/Representational_state_transfer" target="_blank" rel="noopener noreferrer">REST</a> endpoints, the&nbsp; <a href="https://aws.amazon.com/elasticloadbalancing/" target="_blank" rel="noopener noreferrer">AWS ELBs</a>, and the<a href="http://www.haproxy.org/" target="_blank" rel="noopener noreferrer"> HAProxy systems</a>, sits some of most closely-guarded software in the world.</p>
<h2>The ever-increasing dominance of open-source</h2>
<p>The increasing dominance of open-source software seems particularly true with respect to infrastructure software.&nbsp; While security software has often been open-source through necessity — no-one would trust it otherwise — infrastructure is becoming the dominant category of open-source. Look at databases — <a href="https://dev.mysql.com/doc/internals/en/guided-tour.html" target="_blank" rel="noopener noreferrer">MySQL</a>, <a href="https://www.mongodb.org/" target="_blank" rel="noopener noreferrer">MongoDB</a>, <a href="https://www.rethinkdb.com/" target="_blank" rel="noopener noreferrer">RethinkDB</a>, <a href="https://github.com/apache/couchdb" target="_blank" rel="noopener noreferrer">CouchDB</a>, <a href="https://influxdb.com/" target="_blank" rel="noopener noreferrer">InfluxDB</a> (of which I am part of the <a href="https://github.com/influxdata/influxdb/graphs/contributors" target="_blank" rel="noopener noreferrer">development team</a>), or <a href="http://www.cockroachlabs.com/" target="_blank" rel="noopener noreferrer">cockroachdb</a>. Is there anyone today that would even consider developing a new closed-source database? Or take search technology — <a href="https://github.com/elastic/elasticsearch" target="_blank" rel="noopener noreferrer">elasticsearch</a>, <a href="http://lucene.apache.org/solr/" target="_blank" rel="noopener noreferrer">Solr</a>, and <a href="http://www.blevesearch.com/" target="_blank" rel="noopener noreferrer">bleve</a> — all open-source. And <a href="https://www.linux.com/" target="_blank" rel="noopener noreferrer">Linux</a> is so obvious, it is almost pointless to mention it.<br>
If you want to create a closed-source infrastructure solution, you better have an enormously compelling story, or be delivering it as part of a bigger package such as a software appliance.</p>
<h2>So where is the value?</h2>
<p>Compared to when I first <a href="https://en.wikipedia.org/wiki/Nortel" target="_blank" rel="noopener noreferrer">started programming,</a> that some of the most valuable companies in software now give away their product is astounding, when you actually think about it. So where is the real value within a such a company, when its product is free? It’s where it’s always been — just more so.</p>
<p>The real value is within the development team and its ideas, that the team behind the software are, and remain, innovative, execute well, and produce quality software. And that they remain so is key — so that it does not matter that what they produce is freely available.&nbsp; It is of little benefit to a competitor that the source is freely available, when the team behind the project is probably six months ahead — and often more — conceptually in terms of design, development and process.</p>
<h2>The economics of recruitment</h2>
<p>And the implications go far beyond how software is developed.<br>
It is generally accepted these days within <a href="https://en.wikipedia.org/wiki/Silicon_Valley">The Valley</a> that large, older, firms find it particularly hard to hire. The excitement, and latitude for creativity, within a start-up has always appealed, and even more so now with the outstanding <a href="http://www.bloomberg.com/news/articles/2014-10-28/facebook-s-22-billion-whatsapp-deal-buys-10-million-in-sales" target="_blank" rel="noopener noreferrer">commercial success of some</a>.</p>
<p>But a second-order effect is also prevalent — many developers baulk at the idea that their work may never be seen by their peers in the open-source community, and therefore may never help them progress in their careers. And it is at larger, older firms, that the least amount of open-source software is written — what <a href="http://paulgraham.com/index.html" target="_blank" rel="noopener noreferrer">Paul Graham</a> calls <a href="http://paulgraham.com/ideas.html" target="_blank" rel="noopener noreferrer">downwind jobs</a>.</p>
<p>But Services remain part of the future — because while the code that Service software developers write may not be visible, the functionality is visible to the world and with the advent of cloud-computing, the power accruing to these developers is significant and growing. Services can hire, unlike the traditional firms.</p>
<h2>Possibilities for our grandchildren</h2>
<p>The rise of open-source has been a remarkable development in the history of economics and production. I often wonder what <a href="http://www.econ.yale.edu/smith/econ116a/keynes1.pdf" target="_blank" rel="noopener noreferrer">Keynes</a>, Marx, and even Ricardo, would think of it all.</p>
	</div></div>]]>
            </description>
            <link>https://www.philipotoole.com/the-strange-economics-of-open-source-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873194</guid>
            <pubDate>Fri, 22 Jan 2021 16:40:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon A10 algorithm update targets Walmart and Target on Google]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25873107">thread link</a>) | @ilamont
<br/>
January 22, 2021 | https://www.modernretail.co/platforms/why-amazons-algorithm-update-takes-direct-aim-at-walmart-and-target/ | <a href="https://web.archive.org/web/*/https://www.modernretail.co/platforms/why-amazons-algorithm-update-takes-direct-aim-at-walmart-and-target/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    <div>

      

      
      <p>Amazon’s recent algorithm tweak signals the growing competition the e-commerce giant faces.</p>
<p>In the fall, Amazon rolled out its latest update to its product ranking algorithm, dubbed “A10.” The new rendition of the algorithm looked largely familiar: when considering how to rank and recommend products, Amazon, as before, <a href="https://feedvisor.com/resources/industry-news/amazon-a10-algorithm-what-you-need-to-know/">put a lot of weight</a> on sales history, conversion rate and seller history. But while the underlying variables stayed the same, the company played around with how much it weights each variable. In particular, Amazon’s new algorithm now prioritizes products that receive a significant share of its traffic from off of Amazon — meaning from blogs, Instagram, <a href="https://www.modernretail.co/platforms/how-linktree-and-linkin-bio-became-the-new-digital-storefront/">Linktree</a> and so on.</p>
<div id="piano-cta">
<p>That change might sound subtle, but it reflects the growing competition within the e-commerce market. As Target — and in particular Walmart — increasingly build up their e-commerce offerings, Amazon is trying to cling to its positioning in search engine results. Walmart and Target still represent only a fraction of the e-commerce market compared to Amazon, but both companies saw their digital sales <a href="https://www.clevelandresearch.com/ecommerce-share-target-digital-up-275-walmart-com-and-online-grocery-growth/">more than double</a> from the start of 2020 to the end, and that pace doesn’t seem to be letting up.&nbsp;When customers type “leopard print bedding” into Google, Amazon wants to ensure that an Amazon product — not a Walmart product — comes up first. Pushing its own sellers to prioritize referral traffic is one way to do that.</p>

<p>“When [customers] do Google searches for products, less and less Amazon products are showing up on the first page of results,” said Tanner Rankin, an Amazon consultant. “With Walmart very aggressively competing with them,” he went on, what Amazon needs to do is “ensure that they are not only top of mind but top of search everywhere.”</p>
<p>Both Amazon and Walmart depend heavily on search. About 26.8% of Amazon’s traffic comes from search engines,&nbsp;<a href="https://www.similarweb.com/website/amazon.com?competitors=walmart.com">according to</a> the analytics tracker SimilarWeb, while close to half — 43.8% — of Walmart’s web traffic comes from search. Boosting those numbers is a simple matter of boosting external links. Because most major search engines give significant weight to the number of referral links that drive people to a given page, one way for Amazon to ensure that its products rank highly in search results is to help those products get a lot of external traffic.</p>
<p>Mehmood Hanif, an Amazon seller who specializes in baby products and men’s fashion, said that he and other sellers are taking notice of the changes. Sellers are always paying attention to Amazon’s algorithm shifts, even small ones. “You should be smart enough to understand these signals as soon as possible and make the changes in your campaigns accordingly,” he said, adding that those who don’t take the changes seriously can see swift losses: “You will see many people in different Facebook groups who were doing business for years on Amazon and all of a sudden they collapse,” he said.</p>
<p>Hanif said he hasn’t encountered any issues with the new update — he is increasingly prioritize his work with influencers, most of whom are on Instagram, but he said the new weight Amazon is giving to outside traffic seems relatively minor so far.</p>
<p>Still, the algorithm update seems to be part of a larger effort by Amazon. Shortly before the algorithm change, Amazon rolled out <a href="https://www.junglescout.com/blog/amazon-attribution-guide/">Amazon Attribution</a>, a tool that helps third-party sellers track the amount of off-Amazon traffic going to their listings. The company has also actively recruited more social media stars to join the <a href="https://www.modernretail.co/platforms/how-amazon-live-is-growing-its-micro-influencer-program/">Amazon Influencer Program</a>, which integrates with most social platforms (minus, for now, TikTok) and gives influencers commissions between 1% and 10% on sales that they refer.</p>

<p>Rankin said that influencers will only continue to grow in importance over time. That’s because so much product discovery is moving to social channels like Instagram and TikTok — especially as Google <a href="https://www.modernretail.co/platforms/retailers-are-rethinking-their-google-search-strategies/">de-prioritizes</a> traffic to traditional product recommendation sites like Wirecutter. Getting its sellers to focus on social referrals is a win-win for Amazon: it means both that more people will discover Amazon products through new channels and that Google will rank those Amazon’s product listings over similar ones from Walmart.</p>
<p>When it comes to affiliate marketing, “Amazon is the king because they have just a head start,” said Rankin. “Back in 1996, they were the first to really lean into this.” Walmart does have an affiliate program of its own, though it is a drop in the bucket compared to what Amazon has built. About 6.6% of Amazon’s traffic comes from referrals, according to SimilarWeb, whereas just 2.8% of Walmart’s does. Walmart even <a href="https://www.marketingdive.com/news/report-walmart-suspends-affiliate-program-with-magiclinks-rakuten/575436/">suspended</a> some of its affiliate partners last April.</p>
<p>“That’s changing because Walmart and also Target have been able to identify the fact that [so much] of Amazon’s traffic comes from affiliates,” said Rankin.</p>
</div>
      

    </div>
  </div></div>]]>
            </description>
            <link>https://www.modernretail.co/platforms/why-amazons-algorithm-update-takes-direct-aim-at-walmart-and-target/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873107</guid>
            <pubDate>Fri, 22 Jan 2021 16:32:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin White Paper [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25873083">thread link</a>) | @arunagarwal
<br/>
January 22, 2021 | https://bitcoinwhitepaper.digital/bitcoin.pdf | <a href="https://web.archive.org/web/*/https://bitcoinwhitepaper.digital/bitcoin.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://bitcoinwhitepaper.digital/bitcoin.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873083</guid>
            <pubDate>Fri, 22 Jan 2021 16:30:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mustard Watches]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25873058">thread link</a>) | @blewboarwastake
<br/>
January 22, 2021 | http://girard.perso.math.cnrs.fr/mustard/article.html | <a href="https://web.archive.org/web/*/http://girard.perso.math.cnrs.fr/mustard/article.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><b>MUSTARD WATCHES</b></p><p>
  
  Y.-J. Ringard 
  <br>
  Reconstituted by Pierre Barthélémy and Éric Lozingot
</p></div></div>]]>
            </description>
            <link>http://girard.perso.math.cnrs.fr/mustard/article.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25873058</guid>
            <pubDate>Fri, 22 Jan 2021 16:28:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Inflation is here – it’s just not evenly distributed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25872853">thread link</a>) | @prostoalex
<br/>
January 22, 2021 | https://www.evergreencap.com/post/inflation-is-here | <a href="https://web.archive.org/web/*/https://www.evergreencap.com/post/inflation-is-here">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>Inflation is here – it’s just not evenly distributed. <br></p><p>In other words, inflation means different things to different people. </p><p>The Fed says there is <strong>no</strong> inflation. That’s fine if you’re the government and want to keep social security increases low. But what if you live in an expensive city and noticed your healthcare, education and housing costs are soaring? &nbsp;</p><figure id="w-node-cfddddb12522-da44fa1d"><p><img src="https://uploads-ssl.webflow.com/5f3331735ee664994ed7ccd4/6009b1848ac2704852312174_Screen%20Shot%202021-01-21%20at%208.39.03%20AM.png" loading="lazy" alt=""></p><figcaption>‍<em>Source: FRED, Census, HUD</em></figcaption></figure><p>And what about financial assets? While investments don't factor into the CPI inflation calculation, the vast majority of assets are clearly ‘inflated’. This is – in part – a function of the Fed’s aggressive money creation. </p><figure id="w-node-43df9735ae11-da44fa1d"><p><img src="https://uploads-ssl.webflow.com/5f3331735ee664994ed7ccd4/6009b1b6f58bdf0ad67671e5_Screen%20Shot%202021-01-21%20at%208.39.11%20AM.png" loading="lazy" alt=""></p><figcaption>‍<em>Source: Federal Reserve </em></figcaption></figure><p>Yet, all this stimulus hasn’t resulted in CPI inflation. What gives? Well, the velocity of money today is glacial. As it turns out, it’s a lot easier to save money when everything’s closed. But what happens after more helicopter cash, vaccinations and the floodgates of commerce re-open? <br></p><p>President Biden is <a href="https://www.wsj.com/articles/biden-to-propose-1-9-trillion-covid-19-package-11610661977?mod=article_inline">proposing another round</a> of stimulus ($1.9 Trillion), which includes:</p><ul role="list"><li>Increased unemployment benefits through September</li><li>A doubling of the Federal minimum wage to $15 / hour </li><li>Another direct $1,400 check to every American</li></ul><p>Extreme times call for extreme actions. However, we would not be surprised if even more rounds of checks and quantitative easing are forthcoming. How many trillions can we create from thin air without long term consequences? </p><p>It appears we’re going to find out. <br></p><figure id="w-node-88cf478094de-da44fa1d"><p><img src="https://uploads-ssl.webflow.com/5f3331735ee664994ed7ccd4/6009b2aae5ac178004ec59be_Picture1.png" loading="lazy" alt=""></p></figure><h3><strong>Free Money Is A Slippery Slope </strong></h3><p>More concerning is the moral hazard the Fed created by printing and buying everything is sight (including corporate bonds for the first time in history). Passing large tax increases might prove difficult over the short-term. Most Americans now realize the government can just add zeros to its balance sheet to pay bills. Don’t get too excited, taxes are still likely to go a bit higher. We simply assume politicians will have a hard time turning off the cash spicket. <br></p><p>This is not to say we suspect inflation to run rampant. There are deflationary counterbalances. Technology advances and offshoring labor are deflationary. The question is: will deflationary trends be enough to dampen unprecedented money printing? <br></p><p>Your guess is as good as ours. <br></p><p>Evergreen doesn’t rely on macro predictions. &nbsp;We’ll leave that to the economists, who are so numerous that if you stacked them end to end into outer space…that wouldn’t be a bad thing. <br></p><p>We do think deeply about risk and probabilities though. Consequently, we believe the risk of meaningful inflation this decade hasn’t been this high since the 1970s. &nbsp;</p><h3><strong>Your Personal Inflation Rate</strong><br></h3><p>Perhaps a better way to think about inflation is through your own personal spending lens.<br></p><p>Take a mental inventory of your major expenses. If your unique basket of products, services, necessities and future assets (investments you’d like to make) are skyrocketing in price, then today’s zero CPI rate isn’t your reality. <br></p><p>In that case, it makes sense to prepare for the possible degradation of your cash holdings. Or as hedge fund manager Ray Dalio said more succinctly: “Cash is trash”. <br></p><p>Given the circumstances, investor portfolios should overweight hard assets. While commodities have worked as inflation hedges, we prefer cash-flowing real estate with pricing power. As CPI increases, so does net operating income stemming from rent increases. This is true both of private and public real estate (REITs). </p><figure id="w-node-7b3cd314b5bb-da44fa1d"><p><img src="https://uploads-ssl.webflow.com/5f3331735ee664994ed7ccd4/6009b27a5a32193a88838cfb_Picture2.png" loading="lazy" alt=""></p><figcaption><em>Data source: Nuveen and Real estate net operating income is from the NFI-ODCE and U.S. Inflation is provided by Moody’s Analytics, 2019.</em><br></figcaption></figure><p>Real estate and REITs provide natural protection against inflation. Rents and values tend to increase with consumer prices. This supports REIT dividend growth and provides a reliable stream of income during inflationary periods. REITs also have attractive, fixed rate debt. Inflation is a boon to borrowers as you get to pay the lender back with “cheaper” cash. <br></p><p>America had a four-decade run of disinflation since 1980. Given the circumstances, the risk of broadly higher inflation is – while not a given – on the table. The Fed wants above average CPI numbers to inflate away our unsustainable debt. <br></p><p>Don’t fight the Fed, plan accordingly. &nbsp;</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.evergreencap.com/post/inflation-is-here</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872853</guid>
            <pubDate>Fri, 22 Jan 2021 16:08:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The State of Design in 2021]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25872788">thread link</a>) | @superbaconman
<br/>
January 22, 2021 | https://www.abstract.design/state-of-design?ref=webdesignernews.com | <a href="https://web.archive.org/web/*/https://www.abstract.design/state-of-design?ref=webdesignernews.com">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div id="hero"><section id="sod-hero" data-w-id="3428c477-cd5b-8757-b8ee-7d552b20ac49"><div><p><img src="https://assets-global.website-files.com/5ff3926f03b3ba26b7d639cb/5ff3926f03b3ba5d0dd63a08_State-of-design.gif" loading="eager" alt=""></p></div></section></div><nav></nav><section><div data-w-id="d90b714a-c794-53b3-9f06-d5df62022110"><div><div><div><p>It wasn’t that long ago when good product design meant something that simply looked cool. <span>But how cool something looks doesn’t really matter as much anymore.</span></p></div></div></div></div></section><section data-w-id="48aa8b56-4d23-8efc-35a6-48a4781a7444"><div><div><div><p>Design today is no longer just about the output — the artifact, the cool thing. </p><p>Design must deliver on business outcomes. </p><p>Recently we’ve surveyed over 1,000 designers and asked them how they work, what they value, and what kinds of challenges they’re facing. Here’s what we found:</p></div></div><div data-w-id="48aa8b56-4d23-8efc-35a6-48a4781a7450"><div><div><div href="#section-1"><div><div><p><img src="https://assets-global.website-files.com/5ff3926f03b3ba26b7d639cb/5ffc9a62fc57c282c7d7964f_ill-sod-card1.svg" loading="lazy" alt=""></p></div><div><p>Design teams are <span>bigger and more complex</span> than ever</p><p><strong>3 out of 4 designers</strong> said they planned to add anywhere from 1-5 new designers to their team this year.</p></div></div></div><div href="#section-2"><div><div><p><img src="https://assets-global.website-files.com/5ff3926f03b3ba26b7d639cb/5ffc9cc48d96d924099b59a8_ill-sod-card2.svg" loading="lazy" alt=""></p></div><div><p>We need better ways to <span>measure impact</span> </p><p><strong>1 out of 2 designers</strong> reported that their organization expects them to measure and report their teams’ outcomes.</p></div></div></div><div href="#section-3"><div><div><p><img src="https://assets-global.website-files.com/5ff3926f03b3ba26b7d639cb/5ffc9cd24ba5e042d27f05ba_ill-sod-card3.svg" loading="lazy" alt=""></p></div><div><p>The shift from <span>outputs to outcomes</span></p><p><strong>1 out of 2 designers</strong> said the ability to quantify impact would make design more valuable to business strategy.</p></div></div></div><div href="#section-4"><div><div><p><img src="https://assets-global.website-files.com/5ff3926f03b3ba26b7d639cb/5ffc9cde2ba63990e0324101_ill-sod-card4.svg" loading="lazy" alt=""></p></div><div><p>Today’s <span>biggest challenges</span></p><p><strong>The pain points of design collaboration</strong><strong> </strong>are sharing and tracking tasks, wrangling feedback, and visibility into the work.</p></div></div></div><div href="#section-5"><div><div><p><img src="https://assets-global.website-files.com/5ff3926f03b3ba26b7d639cb/5ffc9cee18b6b44d5b547ba2_ill-sod-card5.svg" loading="lazy" alt=""></p></div><div><p>What’s the <span>next big thing</span> for design?</p><p>Communicating the <strong>value of time spent through measurement and reporting</strong> is key to an overwhelming majority of designers.</p></div></div></div></div><div><p><img src="https://assets-global.website-files.com/5ff3926f03b3ba26b7d639cb/600776ff0f55e0b2ca06da7a_ill-sod-drag.svg" loading="lazy" alt=""></p></div></div></div></div></section><div><div data-w-id="d9f935a6-3640-ac44-c656-e41a1dfc0480"><p><img src="https://assets-global.website-files.com/5ff3926f03b3ba26b7d639cb/5ff73bf69df5f1225a5ea3db_ill-sod-hero-1.svg" loading="lazy" alt="Design teams"></p><div><p><h2><span>1.</span> Design teams are <span>bigger and more complex</span> than ever.</h2></p></div></div></div><section><div data-w-id="a87b9f81-68a7-8b4d-cf3c-9d0d58d779f2"><div><div><p>As the nature and definition of design have changed, so, too, have design teams. Not only are they growing in size — [text-highlight]<a href="https://clicktotweet.com/eIN8h" target="_blank">3 out of 4 designers said they plan to add up to 5 new people to their team this year</a>[text-highlight] — they’re also increasing in complexity.</p></div><div><div><div><div><div><p><strong>Expect to add 1-5 designers to their team this year</strong></p></div><div><p><strong>See integrating workflows with stakeholders as critical to success</strong></p></div><div><p><strong>Say integrating with tools used by other teams is important</strong></p></div><div><p><strong>Plan to develop more technical skills in the future</strong></p></div></div></div></div></div><div><p>Andy Vitale, VP of Product Design and Content at Quicken Loans, says organizations have been slow to catch up to this complexity. </p><p>“Early in my career, people would ask, ‘What kind of designer are you? What do you design?’ As the industry matured, designers went from being generalists to specialists. That specialization drove what we now consider UX Design. Then, as our focus shifted from web pages and screens to digital projects, Silicon Valley began to call these more [text-pseudolink-ee-t]T-shaped[text-pseudolink-ee-t] designers with multiple specialities, Product Designers — and it caught on.” </p><p>The problem, Vitale adds, was that organizations didn’t understand the nuances between different disciplines. </p><p>“Even at my previous company, we had six core competencies within our UX design team,” he says. “There was information architecture, content strategy, interaction design, visual design, front-end development, and design research. All of these fell under the umbrella of product design, and having to communicate these competencies to other teams became just as important as their output.”</p></div><div><div data-w-id="b55b8a9c-f1cc-8e95-430c-39f642398fd7"><blockquote>Our responsibility as design leaders is to move beyond thinking about our role as a core discipline, and <span>evolve into being strategic partners.”</span></blockquote></div></div><div><p>Today, perhaps more than ever, being a good design leader means working effectively with stakeholders from other teams. Harrison Wheeler, Product Design Manager at LinkedIn says, “Having a seat at the table is table stakes. Our responsibility as design leaders is to move beyond thinking about our role as a core discipline and evolve into being strategic partners. This means thinking about the impact, value, and consequences of our decisions on the business, and our users."</p><p>[text-highlight]<a href="https://clicktotweet.com/S2Ug5">One out of two designers said that integrating their workflow with these stakeholders was “critical” to their team’s success</a>[text-highlight]. Another 1 out of 2 said this lack of inter-departmental integration was among their organizations’ most significant challenges.</p><p>And with more collaboration comes a need for more skills. You’re less likely to find team members who are only designers now. More than 60% of designers reported having development experience, and 42% said they plan to develop more technical skills in the future. </p></div></div></div></section><div><div data-w-id="07a82425-c219-527e-957e-5a32907aa761"><p><img src="https://assets-global.website-files.com/5ff3926f03b3ba26b7d639cb/5ffcf7c45f8fe9e8cf5bf2af_sod-hero-2.svg" loading="lazy" alt="Measuring impact"></p><div><p><h2><span>2.</span> We need better ways to <span>measure impact</span></h2></p></div></div></div><section><div data-w-id="0bf3cf5c-6b32-a78f-8044-a4f282db13ff"><div><p>According to design leaders, [text-highlight]<a href="https://clicktotweet.com/7aSto">57% reported that their organization expects them to measure and report their team's outcomes.</a>[text-highlight] Additionally, 58% of design leaders said the ability to measure and quantify the impact of their team’s work would make design more valuable at the organizational level, and 63% of design leaders said that measuring and reporting results is “very important” to communicating the value of time spent.</p><div><div><div><div><div><p><strong>Must measure and report team outcomes to their organization</strong></p></div><div><p><strong>Know that measuring and quantifying impact would boost design's value</strong></p></div><div><p><strong>Agree that measuring and reporting help capture the value of time spent</strong></p></div><div><p><strong>Say that DesignOps tools are lacking most in reporting and analytics</strong></p></div></div></div></div></div><div><p>It’s clear that [text-pseudolink-ee-ruler]measuring[text-pseudolink-ee-ruler] and reporting on the impact of design is important, and even necessary. What’s a little less clear is <em>how</em> teams can achieve this. When asked how they measured and reported outcomes and impact, there were as many different answers as there were designers. Overall, it seems that design teams do try to capture both data-based and qualitative feedback. But marrying these together to tell a compelling story is tricky, resulting in many answers like this:</p><p><em>“Analytics are collected, but customer reactions determine whether projects are considered successful or not. The analytics always show that updated and redesigned processes have improved but if customer feedback isn't positive, it doesn't matter.”</em></p><p><em>“Reporting is a combination of user data, how many new users started using the product, and user interviews.”</em></p><p><em>“[It’s not done] easily. I use a mix of quant-based data to show good design choices are being made, and qual data from user testing to show impact and desire. I'm trying to measure the DesignOps and workflow side as well, but that's a larger challenge.”</em></p><p>So it makes sense that [text-highlight]<a href="https://clicktotweet.com/d1JKR">2 out of 3 designers said that the design operations tools they use are lacking most in reporting and analytics.</a>[text-highlight] The [text-pseudolink-ee-apple]appetite[text-pseudolink-ee-apple] is there, but the functionality is not. Instead, leaders have to find their own ways to determine success. </p></div></div></div></section><div><div data-w-id="50ad2204-a75b-df1f-a472-b5fe34e57005"><p><img src="https://assets-global.website-files.com/5ff3926f03b3ba26b7d639cb/5ff73bf57ce5bcc6a87ade8e_ill-sod-hero-3.svg" loading="lazy" alt="The shift"></p><div><p><h2><span>3.</span> The shift from <span>outputs to outcomes</span></h2></p></div></div></div><section><div data-w-id="af975bae-8c77-2f77-a0d8-71d654d0f7b6"><div><div><p>Sarah McIlwain, our Director of Product Design, says that in the early days of UX and digital design, there was a notion of “design” being the final layer of product development after the strategy had already been established.</p><p>“You’d give it to the designers at the end, and they’d make it look nice,” she says. “But as it matured — as research matured — the perspective shifted from ‘What can we make and ship?’ to ‘What is the impact that we want to have on a customer?’”</p></div><div><div data-w-id="d48f5c3c-60a7-888a-86ce-b2e37332ea56"><blockquote>Design decisions need to ladder up to the things that are important: strategy, company goals, revenue targets. <span>It can’t just be about making cool sh*t anymore.”</span></blockquote><p>—Chi Thorsen, Brand Design Manager at Thumbtack</p></div></div><div><p>Good design means something different now. “For our work to survive and evolve, it has to be plugged into the larger picture,” says Chi Thorsen, Brand Design Manager at Thumbtack. </p><p>[text-highlight]<a href="https://clicktotweet.com/4d3Bw">“Design decisions need to ladder up to the things that are important: strategy, company goals, revenue targets. It can’t just be about making cool sh*t anymore.”</a>[text-highlight]</p><p>“Any designer who's uncomfortable being held accountable for their design choices — whether that's fiscally or performance-wise — should be comfortable giving up their ability to own design decisions,” says Melissa Cullens, former CXO of Ellevest and founder and CEO of Charette. “You have to be willing to see it all the way through. If your performance rubric is not tied to the outcome, and somebody else’s is, then you have to ask yourself, ‘What are we actually asking designers to do?’”</p><p>The potential value that good design can bring to a business has increasingly become a topic of conversation. In other words, the [text-pseudolink-ee-road]road[text-pseudolink-ee-road] to connecting design and outcomes is long, and not all teams are there yet — but the potential to get there is on the horizon.</p></div><div><div data-w-id="c92f63db-b6e4-234b-c064-81410e3c2e39"><blockquote>Any designer who’s not comfortable being held accountable for their design choices <span>should be comfortable giving up their ability to own design decisions.”</span></blockquote><p>—Melissa Cullens, Founder and CEO of Charette</p></div></div><p>“As designers, we know that design can drive business strategy, we have seen all of the supporting research,” says Vitale. “We have to realize that design isn't seen as the center of the corporate universe, especially in large enterprises. So we have to build relationships and find partners that we can collaborate with. When we show how design can improve outcomes, that’s how we become seen as strategic partners.”</p></div></div></section><div><div data-w-id="c10e4cb2-3d60-e036-5f8e-3989a965311d"><p><img src="https://assets-global.website-files.com/5ff3926f03b3ba26b7d639cb/5ff73bf5ab3047839b71c6d1_ill-sod-hero-4.svg" loading="lazy" alt="Today's challenges"></p><div><p><h2><span>4.</span> Today’s biggest challenges: <span>collaboration, people, and data</span></h2></p></div></div></div><section><div data-w-id="fc068336-97d5-34d8-2b9f-6e9f79dd49ab"><div><p>If organizations want to connect design to business outcomes, they must enable collaboration and focus on streamlining communication. When we asked designers what the <strong>most critical aspects of collaborating with other designers</strong> were, they listed the following:</p><div><div><div><div><div><p><strong>Rank sharing and managing design work high among pain points</strong></p></div><div><p><strong>Say that managing feedback and conversations is overwhelming</strong></p></div><div><p><strong>Report that bringing visibility to their team’s work is challenging</strong></p></div></div></div></div></div><p>Each of these priorities points to a separate challenge within the design process, so let’s look at each individually.</p><div><h3><span>Challenge #1:</span><br>Too much “work around the work”</h3><div><p>There are more design tools than ever, but that doesn’t necessarily add up to greater productivity. A majority of our respondents said they used some combination of tools and platforms to complete their work. Collaborating across a glut of tools requires constant coordination and multitasking to get through the day-to-day work. Abstract CEO Kelly Watkins says this cuts down on the amount of time that designers spend on actual design work.</p><p>“The high-effort, low-impact tasks that designers must do to make forward progress is so time …</p></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.abstract.design/state-of-design?ref=webdesignernews.com">https://www.abstract.design/state-of-design?ref=webdesignernews.com</a></em></p>]]>
            </description>
            <link>https://www.abstract.design/state-of-design?ref=webdesignernews.com</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872788</guid>
            <pubDate>Fri, 22 Jan 2021 16:01:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A new era for Blazor development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25872745">thread link</a>) | @pjmlp
<br/>
January 22, 2021 | https://www.radzen.com/blog/a-new-era-for-blazor-development/ | <a href="https://web.archive.org/web/*/https://www.radzen.com/blog/a-new-era-for-blazor-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
              <p>Last week I tweeted a short video previewing a prototype we have been busy with.</p>

<blockquote><p lang="en" dir="ltr">Hey <a href="https://twitter.com/aspnet?ref_src=twsrc%5Etfw">@aspnet</a> <a href="https://twitter.com/hashtag/Blazor?src=hash&amp;ref_src=twsrc%5Etfw">#Blazor</a> devs can you guess what this might be? <a href="https://t.co/1H8knERWTy">https://t.co/1H8knERWTy</a></p>— Atanas Korchev (@korchev) <a href="https://twitter.com/korchev/status/1346565271520206852?ref_src=twsrc%5Etfw">January 5, 2021</a></blockquote>


<p>Long story short - we decided to double down on our Blazor investment and build an even more powerful IDE! It is dubbed “Radzen 3” and here is why it is important to you as a Blazor developer.</p>

<h2 id="wysiwyg-design-time-experience">WYSIWYG design time experience</h2>

<p>Radzen 3 will allow you to visually develop your existing Blazor applications. Just open your Visual Studio solution and get up to work. Here is what the Radzen 3 prototype can do with the default Blazor server template created by running <code>dotnet new blazorserverside</code>.</p>

<video autoplay="" muted="" loop="" playsinline="">
  <source src="https://www.radzen.com/assets/radzen-v3-86154e687c9718b8d59d193432c9346bcbe0266a004059a3fc750655d710d51c.mp4" type="video/mp4">
</video>



<p>Radzen will list all Blazor components used by your project (including any third party ones) and
allow you to visually set their properties. We aim for supporting the most popular open source and commercial libraries.
And of course top-notch Radzen.Blazor integration.</p>

<p>Here is the Radzen.Blazor sample application.</p>

<p><img alt="Radzen.Blazor sample application in Radzen 3" src="https://www.radzen.com/assets/radzen-samples-fb3ac5a7fe4fdc2a80443438b5eee266070bd5fac7aadbd282c883d94f1a0e02.png"></p>

<p>Here is the sample application of another Blazor component vendor.</p>

<p><img alt="Other verndor's sample application in Radzen 3" src="https://www.radzen.com/assets/other-vendor-02ce2acbdd38db1217f5bbae66ea2635dc7000df1cca6c03f5c9a8fafebaf64d.png"></p>

<h2 id="powerful-scaffolding-capabilities">Powerful scaffolding capabilities</h2>

<p>Radzen 3 will allow you to</p>

<ul>
  <li>Generate CRUD and Security pages (Identity Server, Azure AD etc.).</li>
  <li>Scaffold data services and OData controllers.</li>
  <li>Add custom code generation templates to bring in your own architecture and or data access framework.</li>
</ul>

<h2 id="how-is-this-different-than-the-current-version-of-radzen">How is this different than the current version of Radzen</h2>

<p>The list is probably longer but here are the top entries:</p>

<ol>
  <li>Open <strong>any</strong> Blazor application (server or WebAssembly).</li>
  <li>Radzen 3 does not rely on a <code>meta</code> directory and JSON files. It works with <code>.razor</code> and <code>.cs</code> files directly.</li>
  <li>The code generation ignore list is no longer needed because Radzen 3 scaffolds code only once.</li>
  <li>If you need to make a quick code edit you can now do it directly in Radzen.</li>
</ol>

<h2 id="where-is-the-download-link">Where is the download link</h2>

<p>We don’t have a public build to share with you yet! There are quite a lot of things to implement before releasing
the first CTP release.</p>

<p>Meanwhile you can come by our forum and tell us what you think. Or send an email to info@radzen.com.</p>

<p>Stay healthy!</p>

            </div></div>]]>
            </description>
            <link>https://www.radzen.com/blog/a-new-era-for-blazor-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872745</guid>
            <pubDate>Fri, 22 Jan 2021 15:58:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Define New Intrinsics in SBCL (2014)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25872734">thread link</a>) | @Tomte
<br/>
January 22, 2021 | https://www.pvk.ca/Blog/2014/08/16/how-to-define-new-intrinsics-in-sbcl/ | <a href="https://web.archive.org/web/*/https://www.pvk.ca/Blog/2014/08/16/how-to-define-new-intrinsics-in-sbcl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This
<a href="https://stackoverflow.com/questions/25078285/replacing-a-32-bit-loop-count-variable-with-64-bit-introduces-crazy-performance">Stack Overflow</a>
post points out an obscure and undocumented weakness in Intel’s
implementation of the POPCNT instruction: although the population
count (number of bits equal to 1) is only a function of the source
argument, hardware schedules it as though it also depended on the
destination. GCC, clang and MSVC all fail to take this issue into
account.</p>
<p>Until a new patched version of my favourite C compiler is released,
there aren’t many tasteful workarounds for this performance bug. I’d
have to switch to inline asm, and either force the compiler to
allocate the same register to the input and the result, or force
different registers and clear the spurious dependency with a xor.
Ideally, I wouldn’t impose any additional constraint on the register
allocator and only insert a xor if the destination and source
registers don’t match.</p>
<p>SBCL easily supports this use case, without having to re-release or
even recompile the implementation: VOPs (virtual operations) execute
arbitrary CL code during code generation and they can be defined at
runtime.</p>
<p>The first step is to make sure that SBCL’s assembler knows how to emit
popcnt: the assembler can also be extended at runtime, but that’s more
hairy and a topic for another post. Instruction encodings are defined
in <code>src/compiler/$ARCH/insts.lisp</code>, and a quick grep reveals
<code>(define-instruction popcnt (segment dst src) ...)</code>: the x86-64
backend learned about popcnt in May 2013 (thanks to Douglas Katzman).</p>
<p>We define VOPs via <code>define-vop</code>, a macro that exposes many options.
Most of the time, it’s easiest to look at a pre-existing definition
for an operation that’s similar to the one we want to add. Popcount
looks like integer negation: it has a single (machine integer)
argument and returns another integer. Integer negation is defined in
<code>src/compiler/$ARCH/arith.lisp</code>:</p>
<div><notextile><figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
<span>10</span>
<span>11</span>
<span>12</span>
<span>13</span>
<span>14</span>
<span>15</span>
<span>16</span>
<span>17</span>
<span>18</span>
<span>19</span>
<span>20</span>
<span>21</span>
<span>22</span>
<span>23</span>
<span>24</span>
<span>25</span>
<span>26</span>
<span>27</span>
<span>28</span>
<span>29</span>
<span>30</span>
<span>31</span>
<span>32</span>
<span>33</span>
<span>34</span>
<span>35</span>
<span>36</span>
<span>37</span>
<span>38</span>
<span>39</span>
<span>40</span>
</pre></td><td><pre><code><span>;;;; unary operations
</span><span>
</span><span>(define-vop (fast-safe-arith-op)
</span><span>  (:policy :fast-safe)
</span><span>  (:effects)
</span><span>  (:affected))
</span><span>
</span><span>(define-vop (fixnum-unop fast-safe-arith-op)
</span><span>  (:args (x :scs (any-reg) :target res))
</span><span>  (:results (res :scs (any-reg)))
</span><span>  (:note "inline fixnum arithmetic")
</span><span>  (:arg-types tagged-num)
</span><span>  (:result-types tagged-num))
</span><span>
</span><span>(define-vop (signed-unop fast-safe-arith-op)
</span><span>  (:args (x :scs (signed-reg) :target res))
</span><span>  (:results (res :scs (signed-reg)))
</span><span>  (:note "inline (signed-byte 64) arithmetic")
</span><span>  (:arg-types signed-num)
</span><span>  (:result-types signed-num))
</span><span>
</span><span>(define-vop (fast-negate/fixnum fixnum-unop)
</span><span>  (:translate %negate)
</span><span>  (:generator 1
</span><span>    (move res x)
</span><span>    (inst neg res)))
</span><span>
</span><span>(define-vop (fast-negate/signed signed-unop)
</span><span>  (:translate %negate)
</span><span>  (:generator 2
</span><span>    (move res x)
</span><span>    (inst neg res)))
</span><span>
</span><span>(define-vop (fast-negate/unsigned signed-unop)
</span><span>  (:args (x :scs (unsigned-reg) :target res))
</span><span>  (:arg-types unsigned-num)
</span><span>  (:translate %negate)
</span><span>  (:generator 3
</span><span>    (move res x)
</span><span>    (inst neg res)))</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>The code snippet above includes a bit of boilerplate to factor out
commonalities via inheritance. The first definition introduces
<code>fast-safe-arith-op</code>, VOPs that apply in both high speed and high
safety settings (the rest is copy/pasted noise from earlier ports that
sport a scheduler); the second one extends <code>fast-safe-arith-op</code> to
define <code>fixnum-unop</code>, a base definition for single-argument operations
on fixnums, while the third one is the same, but for machine integers.
The last three definitions fill in the blanks so the compiler can
compile <code>%negate</code> of fixnum, signed and unsigned integers. The
<code>(:translate %negate)</code> bit means that these VOPs can be emitted
instead of calls to <code>%negate</code>. The integer after <code>:generator</code> defines
the “cost” of each variant; the compiler will choose the (applicable)
variant with the least cost and execute the code sequence that follows
to convert a call to <code>%negate</code> into machine code.</p>
<p>This kind of implementation inheritance is fine for an SBCL backend,
where we define many VOPs and expect developers to understand the
system. I doubt it’s a didactic win. Let’s do something simpler for
<code>popcnt</code>. In the interest of simplicity, I’ll also completely
disregard powerful details in <code>define-vop</code> that are rarely relevant
when defining intrinsics that map directly to machine instructions.</p>
<p>First, we need to tell the compiler that we’re about to do special
things to a function named <code>popcnt</code> (and to blow away any pre-existing
information if the <code>defknown</code> form is re-evaluated).</p>
<div><notextile><figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
</pre></td><td><pre><code><span>(defpackage "POPCNT"
</span><span>  (:use "CL")
</span><span>  (:export "POPCNT"))
</span><span>
</span><span>(in-package "POPCNT")
</span><span>
</span><span>(sb-c:defknown popcnt ((unsigned-byte 64)) (integer 0 64)
</span><span>    (sb-c:foldable sb-c:flushable sb-c:movable)
</span><span>  :overwrite-fndb-silently t)</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>This says that <code>popcnt</code> accepts a 64-bit unsigned integer and returns
an integer between 0 and 64 (inclusively), and that the function can
be constant-folded, flushed (eliminated as dead code) and moved around
(it’s pure).</p>
<p>Now, to define a VOP that implements <code>popcnt</code>:</p>
<div><notextile><figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
<span>10</span>
<span>11</span>
<span>12</span>
<span>13</span>
</pre></td><td><pre><code><span>(in-package "SB-VM")
</span><span>
</span><span>(define-vop (popcnt:popcnt)
</span><span>  (:policy :fast-safe)
</span><span>  (:translate popcnt:popcnt)
</span><span>  (:args (x :scs (unsigned-reg) :target r))
</span><span>  (:arg-types unsigned-num)
</span><span>  (:results (r :scs (unsigned-reg)))
</span><span>  (:result-types unsigned-num)
</span><span>  (:generator 3
</span><span>    (unless (location= r x) ; only break the spurious dep. chain
</span><span>      (inst xor r r))       ; if r isn't the same register as x.
</span><span>    (inst popcnt r x)))</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>We define a new VOP named <code>popcnt:popcnt</code> (the name is arbitrary, as
long as it doesn’t collide with another VOP) that is applicable at all
optimization policies (both high speed and high debug level), and that
implements <code>popcnt:popcnt</code>. Its first and only argument, <code>x</code>, is an
<code>unsigned-num</code>, an unsigned machine integer, that can only be stored
in a register. Moreover, if possible, we’d like <code>x</code> to be allocated
the same register as the result, <code>r</code>. There’s only one result (<code>r</code>)
and it’s an unsigned machine integer in a register, just like <code>x</code>.
The generator, of cost 3 (a common default for arithmetic operations),
breaks any dependency chain in <code>r</code> if necessary, and stores the
population count of <code>x</code> in <code>r</code>.</p>
<p>At first sight, the <code>defknown</code> form seems to conflict with the VOP.
We declare that the return value of <code>popcnt</code> is a small integer,
clearly a fixnum, and then define a VOP that returns a machine
integer. The subtlety is that <code>defknown</code> is concerned with IR1, the
higher level intermediate representation, which works on CL types
(i.e, types as sets) and abstract values. VOPs, on the other hand,
are defined for the lower level IR2, where types describe concrete
representations (like C). It is perfectly meaningful to say that a
small integer will be represented as an untagged machine integer.</p>
<p>The next step isn’t strictly necessary, but helps people who like
their REPL. The compiler knows how to compile calls to <code>popcnt</code>, so
we can define <code>popcnt</code>… as a call to <code>popcnt</code>. Our new function is
now a first-class value that can be called from interpreted code and
passed to higher-order functions, like the compiler’s constant-folding
pass.</p>
<div><notextile><figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
</pre></td><td><pre><code><span>(in-package "POPCNT")
</span><span>
</span><span>(defun popcnt (x)
</span><span>  (popcnt x))</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<pre><code>CL-USER&gt; (disassemble 'popcnt:popcnt)
; disassembly for POPCNT:POPCNT
; Size: 25 bytes
; 07FCDB6E:       4831D2           XOR RDX, RDX               ; no-arg-parsing entry point
;       71:       F3480FB8D1       POPCNT RDX,RCX
;       76:       48D1E2           SHL RDX, 1
;       79:       488BE5           MOV RSP, RBP
;       7C:       F8               CLC
;       7D:       5D               POP RBP
;       7E:       C3               RET
[ error trap noise ]
CL-USER&gt; (popcnt:popcnt 42)
3
</code></pre>
<p>The disassembly shows that we get the code that we expect, including
the dependency-breaking workaround, and the smoke test passes.
There’s one interesting detail: we only defined a VOP that returns a
machine integer. However, <code>popcnt</code> returns a tagged value (a fixnum),
and does so with an efficient shift. IR2 takes care of inserting any
coercion needed between VOPs (e.g., between <code>popcnt</code> and the VOP used to
return boxed values from functions), and the IR1 <code>defknown</code> guarantees
that the result of <code>popcnt</code>, despite being <em>represented</em> in an
unsigned machine integer, is small enough for a fixnum.</p>
<p>Let’s see what happens when we feed arithmetic into <code>popcnt</code>, e.g.:</p>
<pre><code>CL-USER&gt; (disassemble (lambda (x y)
                        (declare (type (unsigned-byte 32) x y))
                        (popcnt:popcnt (+ x y))))
; disassembly for (LAMBDA (X Y))
; Size: 55 bytes
; 0752BD59:       4801FA           ADD RDX, RDI               ; no-arg-parsing entry point
;       5C:       48D1FA           SAR RDX, 1
;       5F:       F3480FB8D2       POPCNT RDX,RDX
;       64:       48D1E2           SHL RDX, 1
;       67:       488BE5           MOV RSP, RBP
;       6A:       F8               CLC
;       6B:       5D               POP RBP
;       6C:       C3               RET
</code></pre>
<p>After adding two fixnums, an automatic coercion unboxes the resulting
fixnum into a machine integer which is then passed to <code>popcnt</code>
(note the lack of dependency-breaking <code>xor</code> now that the source and
destination are the same register).</p>
<p>That’s pretty good code, but we can do better: fixnums are tagged with
0, so we can simply pass fixnums to <code>popcnt</code> without untagging.</p>
<p>This is where the cost parameter to <code>:generator</code> comes in: we can
define another VOP for <code>popcnt</code> of fixnums and bias the compiler to
prefer the fixnum VOP.</p>
<div><notextile><figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
<span>10</span>
<span>11</span>
<span>12</span>
<span>13</span>
</pre></td><td><pre><code><span>(in-package "SB-VM")
</span><span>
</span><span>(define-vop (popcnt/fx)
</span><span>  (:policy :fast-safe)
</span><span>  (:translate popcnt:popcnt)
</span><span>  (:args (x :scs (any-reg) :target r))
</span><span>  (:arg-types positive-fixnum)
</span><span>  (:results (r :scs (unsigned-reg)))
</span><span>  (:result-types unsigned-num)
</span><span>  (:generator 2 ; 2 is lower than 3, so popcnt/fx is preferable to popcnt
</span><span>    (unless (location= r x)
</span><span>      (inst xor r r))
</span><span>    (inst popcnt r x)))</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<pre><code>CL-USER&gt; (disassemble (lambda (x y)
                        (declare (type (unsigned-byte 32) x y))
                        (popcnt:popcnt (+ x y))))
; disassembly for (LAMBDA (X Y))
; Size: 47 bytes
; 07BEABE9:       4801FA           ADD RDX, …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pvk.ca/Blog/2014/08/16/how-to-define-new-intrinsics-in-sbcl/">https://www.pvk.ca/Blog/2014/08/16/how-to-define-new-intrinsics-in-sbcl/</a></em></p>]]>
            </description>
            <link>https://www.pvk.ca/Blog/2014/08/16/how-to-define-new-intrinsics-in-sbcl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872734</guid>
            <pubDate>Fri, 22 Jan 2021 15:57:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CBMC: A Bounded Model Checker for C and C++]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25872654">thread link</a>) | @felixr
<br/>
January 22, 2021 | https://www.cprover.org/cbmc/ | <a href="https://web.archive.org/web/*/https://www.cprover.org/cbmc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrap">
<div id="main">




<p><img src="https://www.cprover.org/cbmc/images/cmu.gif" width="154" height="23" alt="CMU"></p>



<p><img src="https://www.cprover.org/cbmc/images/cbmc-about-cbmc.png" alt="About CBMC"></p><hr size="1" noshade="">

<p> <img src="https://www.cprover.org/cbmc/images/circuit-narrow.jpg" width="133" height="190" alt="chip"> <code>CBMC</code> is a Bounded
Model Checker for C and C++ programs.  It supports C89, C99, most of C11 and
most compiler extensions provided by gcc and Visual Studio. A variant
of CBMC that analyses Java bytecode is available as <a href="https://www.cprover.org/jbmc" target="_top"><code>JBMC</code></a>.
</p>

<p>CBMC verifies memory safety (which includes array
bounds checks and checks for the safe use of pointers), checks for
ex­cep­tions, checks for various variants of undefined behavior, and
user-specified as­ser­tions.  Furthermore, it can check C and C++
for consistency with other languages, such as Verilog.  The verification is
performed by unwinding the loops in the program and passing the
re­sul­ting equation to a decision procedure.</p>

<p>
<code>CBMC</code> is available for most flavours of Linux (pre-packaged on
Debian, Ubuntu and Fedora), Solaris 11, Windows and MacOS X. 
You should also read the
<a target="_top" href="https://www.cprover.org/cbmc/LICENSE">CBMC license</a>.
For questions about <code>CBMC</code>, contact <a target="_top" href="http://www.kroening.com/">Daniel Kroening</a>.
</p>

<p>
CBMC comes with a built-in solver for bit-vector formulas that
is based on MiniSat. As an alternative, CBMC has featured support for external SMT solvers
since version 3.3.  The solvers we recommend are (in no particular order)
<a target="_top" href="http://fmv.jku.at/boolector/">Boolector</a>,
<a target="_top" href="http://mathsat.fbk.eu/download.html">MathSAT</a>,
<a target="_top" href="http://yices.csl.sri.com/">Yices 2</a> and
<a target="_top" href="https://github.com/Z3Prover/z3/wiki">Z3</a>.
Note that these solvers need to be
installed separately and have different licensing conditions. 
</p>



<p><img src="https://www.cprover.org/cbmc/images/cbmc-news.png" alt="CBMC News"></p><hr size="1" noshade="">

<p>NEW: <a target="_top" href="https://www.cprover.org/eclipse-plugin/">Eclipse Plugin</a> redesigned!
</p>

<p>NEW: Version 5.11 released.</p>

<p>
There is a <a target="_top" href="http://groups.google.co.uk/group/cprover">Google
Group</a> for annoucements related to CBMC.</p>

<!-- 
<p><font face="arial,helvetica">
NEW: We are hiring <a target=_top 
href="http://www.comlab.ox.ac.uk/news/42-full.html">PhD students</a> and 
<a target=_top href="http://www.comlab.ox.ac.uk/news/51-full.html">Postdocs</a>
at Oxford University.</font></p>
-->
        


<!--
<img src="images/cbmc-screenshots.png" alt="CBMC Screenshots"><hr size=1 noshade>
<table><tr>
<td><a href="images/screenshot1.png"><img src="images/screenshot1-small.png" alt="screenshot"></a></td>
<td><a href="images/screenshot2.png"><img src="images/screenshot2-small.png" alt="screenshot"></a></td>
</tr></table>
<p>Click to enlarge.</p>

<p>&nbsp;</p>
-->

<p><img src="https://www.cprover.org/cbmc/images/cbmc-documentation.png" alt="CBMC Documentation"></p><hr size="1" noshade="">
<ul>
<li><p>
The <a target="_top" href="http://www.cprover.org/cprover-manual/">CPROVER Manual</a>
contains a tutorial from a user's point of view and
describes what properties are checked.</p>
</li>

<li><p>
A set of slides on CBMC: <a target="_top" href="https://www.cprover.org/cbmc/doc/cbmc-slides.pdf">PDF</a>,
<a target="_top" href="https://www.cprover.org/cbmc/doc/cbmc-slides-2x3.pdf">2x3 handouts</a>.<br>
The sources are available <a target="_top" href="https://github.com/diffblue/cbmc/tree/master/doc/slides/cbmc-latex-beamer">here</a>.</p>
</li>

<li>The primary reference for CBMC is
    <a target="_top" href="http://www-2.cs.cmu.edu/~svc/papers/view-publications-ckl2004.html">A
    Tool for Checking ANSI-C Programs</a> (ca.&nbsp;1300 citations).</li>

</ul>

<p>We also have a <a target="_top" href="https://www.cprover.org/cbmc/applications/">list of
interesting applications of CBMC</a>.</p>



<p><img src="https://www.cprover.org/cbmc/images/cbmc-download.png" alt="CBMC Download"></p><hr size="1" noshade="">

<div>

<p>We are releasing binaries for x86 Linux, Windows,
and MacOS.</p>

<div>
<table>
<tbody><tr>
<th>
Windows
</th>
<td>
    <p><u>Command Line</u></p>
    <p>
    Download <a target="_top" href="https://www.cprover.org/cbmc/download/cbmc-5-10-win.zip">cbmc-5-10-win.zip</a>,
    and then unzip the archive. This is a 64-bit binary,
    and you'll need a corresponding version of Windows.
    You will furthermore need to run CBMC
    from the <i>Visual Studio Command Prompt</i>.
    We recommend you install the free
    <a target="_top" href="http://www.visualstudio.com/en-us/products/visual-studio-community-vs">
    Visual Studio Community</a>.
    </p>

    <p>
    <a target="_top" href="http://www.cprover.org/visual-studio/">CPROVER Visual Studio plugin</a></p>

</td>
</tr>

<tr>
<th>
Linux
</th>
<td>

<p>If you have a recent Debian or Ubuntu
distribution, then install the package cbmc with
<code>apt-get install cbmc</code></p>

<p>On Fedora 18 or newer, do
<code>yum install cbmc</code>

</p><p>On an OpenBSD machine, do
<code>ports install cbmc</code>
</p>

<p>
Otherwise, download one of the following binaries:<br>
64-bit Linux/x64: <a target="_top" href="https://www.cprover.org/cbmc/download/cbmc-5-11-linux-64.tgz">cbmc-5-11-linux-64.tgz</a><br>
Do <code>tar xfz cbmc-5-11-linux-64.tgz</code> before running.
</p>

<!--
<p>
CBMC for Debian/i386: <a target=_top
href="download/cbmc_4.5_i386.deb">cbmc_4.5_i386.deb</a><br>
CBMC for Debian/AMD64: <a target=_top
href="download/cbmc_4.5_amd64.deb">cbmc_4.5_amd64.deb</a><br>
Install with <code>dpgk -i <i>filename</i></code>
</p>
-->

</td>
</tr>

<tr>
<th>
MacOS
</th>
<td>
<p>
CBMC for MacOS (Intel 64 binary): <a target="_top" href="https://www.cprover.org/cbmc/download/cbmc-5-11.pkg">cbmc-5-11.pkg</a><br>
OS X 10.9 or higher is required.
The binary is installed in /usr/bin. You need to have the
Command Line Tools for Xcode, which can be downloaded
<a target="_top" href="https://developer.apple.com/downloads/index.action?=command%20line%20tools">here</a>.
</p>
</td>
</tr>

<tr>
<th>
Source Code
</th>
<td>
<p>
Source code is available
<a target="_top" href="https://github.com/diffblue/cbmc/archive/cbmc-5.11.tar.gz">here</a>.
</p>
</td>
</tr>

</tbody></table>
</div>


<p><a target="_top" href="https://www.cprover.org/eclipse-plugin/">Installation instructions</a> for
    the Eclipse Plugin</p>

</div>

<p>If you need a Model Checker for
Verilog or SMV files, consider <a target="_top" href="http://www.cprover.org/ebmc/">EBMC</a>. For Java, use
<a target="_top" href="https://www.cprover.org/jbmc">JBMC</a>.</p>

<p><span size="-1">
This research was sponsored by the Semiconductor Research
Corporation (SRC) under contract no. 99-TJ-684, the National Science
Foundation (NSF) under grant no. CCR-9803774, the Office of Naval Research
(ONR), the Naval Research Laboratory (NRL) under contract
no. N00014-01-1-0796, and by the Defense Advanced Research Projects Agency,
and the Army Research Office (ARO) under contract no. DAAD19-01-1-0485, and
the General Motors Collaborative Research Lab at CMU. The views and
conclusions contained in this document are those of the author and should
not be interpreted as representing the official policies, either expressed
or implied, of SRC, NSF, ONR, NRL, DOD, ARO, or the U.S. government.
</span></p>

</div>
</div></div>]]>
            </description>
            <link>https://www.cprover.org/cbmc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872654</guid>
            <pubDate>Fri, 22 Jan 2021 15:49:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All About Identity Providers: The ABCs of IDPs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25872585">thread link</a>) | @sbauch
<br/>
January 22, 2021 | https://ossoapp.com/blog/all-about-idps/ | <a href="https://web.archive.org/web/*/https://ossoapp.com/blog/all-about-idps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><img alt="IDP" src="https://d33wubrfki0l68.cloudfront.net/2e3bb3dac11a682694ccdbae58843d5023524bb1/88d05/img/idps.jpg"><h3>The ABCs of IDPs<a href="#the-abcs-of-idps" title="Direct link to heading">#</a></h3><p>Identity Providers (IDPs) are a category of software applications responsible for <strong>managing employee access</strong> to the various third party applications (AKA Service Providers) that modern enterprise companies rely on.</p><h3>Why companies use Identity Providers<a href="#why-companies-use-identity-providers" title="Direct link to heading">#</a></h3><p>On average, companies with fewer than 1,000 employees rely on <a href="https://www.mcafee.com/blogs/enterprise/cloud-security/every-company-is-a-software-company-today" target="_blank" rel="noopener noreferrer">22 separate applications to run their business</a>. As a result, for each application an employee has access to, the employee will need to be onboarded with the proper privileges, a username and password created, and eventually offboarded upon their departure. Each point in this process gives rise to security risks.</p><p>An Identity Provider enables companies to take control of this process and ensure the correct employee is receiving the proper access levels to applications necessary for them to do their job. Additionally, Identity Providers provide employees Single Sign-On (SSO) access to applications so they don’t have to remember multiple passwords or reuse the same passwords across many applications. Upon departure, an administrator of the Identity Provider can disable access to all applications for the exiting employee at the same time.</p><h3>How Identity Providers work<a href="#how-identity-providers-work" title="Direct link to heading">#</a></h3><p>An Identity Provider is basically just a list of employee names and their job titles. A Service Provider can be anything from a chat app for internal communication where every employee requires access, to more specialized applications like that of payroll management where only a few employees are granted access.</p><p><strong>An employee attempting to login to an application used for their work typically has one of two methods to do so via IDP:</strong></p><h4>1. Identity Provider-initiated<a href="#1-identity-provider-initiated" title="Direct link to heading">#</a></h4><p>Logging into an application through an Identity Provider-initiated workflow relies on the employee to log in to their Identity Provider Portal; this is often the only username and password employees will need. From the portal, they select the application they’d like to access, and will then be redirected via a new browser window to their desired Service Provider. The Service Provider will get a message from the Identity Provider saying that the person logging in has been authenticated and is in fact who they say they are. The Service Provider sees this and grants the employee access.</p><h4>2. Service Provider-initiated<a href="#2-service-provider-initiated" title="Direct link to heading">#</a></h4><p>Signing into applications via the IDP can sometimes feel inconvenient to employees. As a result, Service Provider-initiated login is a more popular alternative. This method allows employees to login via the Service Provider’s website, just like they would normally if their employer didn’t require the use of an Identity Provider. With this method, when the employee enters their email into the Service Provider’s website, the SP will send an authentication request to the IDP associated with the employee’s email address. If the employee is already logged into their employer’s IDP, and has access to the SP making the request, the IDP will return a message to the SP letting them know the employee’s identity has been authenticated, thereby granting them access. If the employee isn’t logged into their IDP, a separate screen will prompt the employee to log in to the IDP in order for them to be authenticated and gain access to the SP.</p><h3>Challenges of Integrating Identity Providers<a href="#challenges-of-integrating-identity-providers" title="Direct link to heading">#</a></h3><p>Although each Identity Provider relies on SAML as a common means to enable SSO across Service Providers, they each have a slightly different workflow for onboarding a new Service Provider. As a result, Service Providers have to familiarize themselves with the workflow of each Identity Provider they support.</p><p>This isn’t too much of an issue when they’re supporting one or two Identity Providers, but as companies grow and mature they continue to acquire enterprise customers, and eventually they’ll be asked to support yet another new Identity Provider. Soon enough, one or two IDPs turns into five or ten, each with their own unique workflow that needs to be learned and supported.</p><h3>Benefits of supporting Identity Providers within your Service<a href="#benefits-of-supporting-identity-providers-within-your-service" title="Direct link to heading">#</a></h3><p>As B2B SaaS companies begin to sell upmarket into the enterprise space, certain security features are considered table stakes and are viewed as a prerequisite to even begin a sales conversation. SAML SSO falls into this category of features and is often viewed as a bare minimum requirement to begin selling into enterprise companies.</p><p>Additionally, when a Service Provider supports an Identity Provider they are given the opportunity to be a part of that Identity Provider’s Marketplace. This is where enterprise companies can search for software solutions that already connect to their chosen IDP.</p><p>Don’t let prospective customers disqualify themselves from your solution. Since SAML SSO is so often considered to be a prerequisite, when shopping for software many prospects will eliminate vendors based on this requirement when creating a shortlist. It is in your best interest, as a Service Provider, to support as many Identity Providers as possible to ensure this is not an objection for future prospects.</p><h3>Which Identity Providers you should support first<a href="#which-identity-providers-you-should-support-first" title="Direct link to heading">#</a></h3><p>Since balancing resources when determining your feature roadmap is a constant concern, you’ll need to prioritize the Identity Provider with the greatest reach. <a href="https://www.okta.com/" target="_blank" rel="noopener noreferrer">Okta</a> and Microsoft’s <a href="https://azure.microsoft.com/en-us/services/active-directory/" target="_blank" rel="noopener noreferrer">Azure Active Directory</a> are the industry leaders, but still require scoping, coding, testing, documenting, and training in order to produce a working prototype.</p><h3>The easy way to enable IDP logins<a href="#the-easy-way-to-enable-idp-logins" title="Direct link to heading">#</a></h3><p>Given the challenges of supporting multiple IDPs, it won’t surprise you that we recommend giving <a href="https://ossoapp.com/blog/1-0-0-release-candidate">Osso</a> a try. We’ve built a one-stop solution to connect your Service to a number of Identity Providers (and we’re constantly adding more), in addition to providing an intuitive dashboard to help manage and onboard your enterprise customers. Each Identity Provider has been outfitted with customized <a href="https://ossoapp.com/docs/user-guide/onboarding-customers">documentation</a> so that your Customer Success and Sales teams can take the lead on seamlessly onboarding your next enterprise customer to their preferred Identity Provider. </p><p>We’re excited to help businesses of all sizes support SAML, so if that sounds appealing please check out our <a href="https://ossoapp.com/pricing">plans</a> to find an option that fits your needs.</p></section></div>]]>
            </description>
            <link>https://ossoapp.com/blog/all-about-idps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872585</guid>
            <pubDate>Fri, 22 Jan 2021 15:43:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: An Interactive Virtual Keyboard to Visualize Collections of Shortcuts]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25872549">thread link</a>) | @tkainrad
<br/>
January 22, 2021 | https://tkainrad.dev/posts/visualize-collections-of-keyboard-shortcuts/ | <a href="https://web.archive.org/web/*/https://tkainrad.dev/posts/visualize-collections-of-keyboard-shortcuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contentdiv">

<p>An important part of <a href="https://keycombiner.com/">KeyCombiner</a> is displaying collections of keyboard shortcuts. Therefore, I have invested a lot of time to design searching and filtering features that help to browse even large collections.</p>
<p>Unfortunately, these feature are not sufficient when you want to understand a collection of hundreds of shortcuts at a glance. I have been thinking about this problem since I started working on KeyCombiner almost precisely one year ago. Today, I am happy to announce that KeyCombiner offers a solution:<br>
The Shortcut Collection Visualizer</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/visual-keyboard-short-blog-bg.gif" alt="Collection Visualizer for XCode, one of very few applications that use all 4 modifier keys at the same time."> <figcaption>
<p>Collection Visualizer for <a href="https://keycombiner.com/collections/xcode/">XCode</a>, one of very few applications that use all 4 modifier keys at the same time.</p>
</figcaption>
</figure>
<p>It is heavily inspired by Waldo Bronchart’s open-source <a href="https://github.com/waldobronchart/ShortcutMapper">Application Shortcut Mapper</a>. However, it is a new VueJS-based implementation, adding several additional features that work together with the rest of KeyCombiner. Most importantly, it can efficiently process KeyCombiner’s collection tables and hence works for any shortcut collection on KeyCombiner, <a href="https://keycombiner.com/collecting/collections/public/search/?description=dialog&amp;keys=&amp;mac_keys=&amp;submit=Search">even search results</a>.</p>
<p>If you want to play around with it right away, go to any public KeyCombiner collection, e.g. for <a href="https://keycombiner.com/collections/vscode/">VSCode</a>, <a href="https://keycombiner.com/collections/intellij-idea/winlinux/">IntelliJ IDEA</a>, <a href="https://keycombiner.com/collections/xcode/">XCode</a>, <a href="https://keycombiner.com/collections/chrome/winlinux/">Chrome</a> or one of <a href="https://keycombiner.com/collections/">the other 60+ public collections</a>. If you want to fully undestand its potential, please read on.</p>

<h2 id="overview">Overview</h2>
<p>The virtual keyboard packs a lot of data into a relatively small space. Each button of the keyboard consists of the following elements:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/visual-keyboard-description.png" alt="Elements on each key of the virtual keyboard."> <figcaption>
<p>Elements on each key of the virtual keyboard.</p>
</figcaption>
</figure>
<h2 id="grouping-by-modifier-combination">Grouping by Modifier Combination</h2>
<p>A proper keyboard shortcut consists of 0 or more modifier keys and exactly one non-modifier key. There are 4 modifier keys:</p>
<ol>
<li><kbd>Ctrl</kbd></li>
<li><kbd>Shift</kbd></li>
<li><kbd>Alt</kbd></li>
<li><kbd>Cmd</kbd> (macOS) / <kbd>Super</kbd> (Windows and Linux)</li>
</ol>
<p>This order of modifiers is not random. KeyCombiner <em>always</em> shows keyboard shortcuts with precisely this order. <a href="https://twitter.com/ThomasKainrad/status/1340769935971282946">There are good reasons for this</a>.</p>
<p>This means that we have four boolean variables, resulting in $2^4$ possible modifier combinations. For each of these 16 states, the Collection Visualizer uses a different background color, or background gradient if there are multiple active modifiers.</p>
<p>To toggle modifiers, click on the virtual buttons with your mouse, or press the respective modifier key on on your physical keyboard. The entire virtual keyboard will then update according to the active combination of modifiers.</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/all-modifier-states.gif" alt="It is very rare that a key has a shortcut for every modifier combination. However, it can happen, especially when combining shortcuts of multiple applications in personal collections. (Please don&amp;rsquo;t tell me I forgot one of the 16 modifier combinations - it took me way too long to create this animation.)"> <figcaption>
<p>It is very rare that a key has a shortcut for every modifier combination. However, it can happen, especially when combining shortcuts of multiple applications in personal collections. <br> (Please don’t tell me I forgot one of the 16 modifier combinations - it took me way too long to create this animation.)</p>
</figcaption>
</figure>
<h2 id="filter-collection-table">Filter Collection Table</h2>
<p>One of my favorite things about KeyCombiner’s shortcut collections is that I can filter them by context, category, or modifier combination with a single click using the panes on the side.</p>
<p>The collection visualizer expands on this concept. If you click on any non-modifier key, the collection table will show all shortcuts that use this particular key. To show all shortcuts containing the key <kbd>F</kbd> click on the F button on the virtual keyboard.</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/filter-by-key-press.gif" alt="Filtering the collection table for all shortcuts that contain the F key."> <figcaption>
<p>Filtering the collection table for all shortcuts that contain the <kbd>F</kbd> key.</p>
</figcaption>
</figure>
<h2 id="real-time-updates-on-changes">Real-time updates on changes</h2>
<p>Building personal collections of keyboard shortcuts and text snippets is the foundational concept behind KeyCombiner. You can then practice these collections with its interactive trainer, relying on spaced repetition techniques and advanced statistics to guide your learning progress. You can also use <a href="https://keycombiner.com/desktop/">KeyCombiner Desktop</a> to instantly look up all combinations in your collections without leaving your current context.</p>
<p>Oh wait, I am getting side-tracked. I meant to say that the collection visualizer updates immediately whenever you make a change to one of your collections. A change could be adding new shortcuts, editing existing entries, or re(moving) entries. This works in the blink of an eye, even if you remove hundreds of combinations at once.</p>
<h2 id="additional-features">Additional Features</h2>
<p>I am getting the sense that this post will be too long for the average person’s interest in keyboard shortcuts. So, I will list some additional features in shorter form:</p>
<ul>
<li>There are three levels of opacity:
<ol>
<li>Keys without any mapped combinations</li>
<li>Keys with mapped shortcuts, but none that use the current modifiers</li>
<li>Keys that have a combination with the currently activated modifiers</li>
</ol>
</li>
</ul>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/opacity.png" alt="Different levels of opacity carry information."> <figcaption>
<p>Different levels of opacity carry information.</p>
</figcaption>
</figure>
<ul>
<li>If, for any modifier combination, there are two or more shortcuts bound to a key, the number of combinations in the top right of the button is marked red.</li>
<li>If there are two or more combinations on a key for the current modifier state, the shortcut description for this key says <em>Conflict</em>.</li>
<li>There is a small text below the virtual keyboard saying how many shortcuts are mapped onto the virtual keyboard, and how many combinations had to be skipped. (See <a href="#current-limitations">Current Limitations</a>)</li>
<li>The keyboard must be in focus if you want to activate modifiers by pressing the respective buttons on your physical keyboard. This is so that you can still use <kbd>Ctrl</kbd> and <kbd>Shift</kbd> for table selection operations without affecting the visualizer. Buttons below the virtual keyboard allow toggling the focus.</li>
</ul>

<h2 id="quickly-grasp-a-set-of-shortcuts">Quickly Grasp a Set of Shortcuts</h2>
<p>Perhaps the most obvious use case is exploring a collection of shortcuts. The visual keyboard helps immensely in this process. Within seconds, you can get a feeling of which modifiers are used by a specific application and whether it uses Vim-like home row navigation or something else entirely.</p>
<p>The different layers of opacity aid this use case. Without activating any modifiers, you can already understand where the most shortcuts are located. This is supported further by the combination count in each virtual keyboard button’s top right.
Filtering the collection table by clicking on a specific key lets you see all shortcuts for that key and understand how they are related.</p>
<h2 id="see-conflicts-and-free-combinations">See Conflicts and Free Combinations</h2>
<p>At the moment, this is my favorite use case, as I have used it plenty of times already with great success.</p>
<p>I recently <a href="https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">learned all VSCode shortcuts</a> with KeyCombiner’s interactive trainer. However, since then, I have started to experiment with <a href="https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">Foam</a> and picked up some other extensions. All of these come with their own set of commands. So, I frequently have to find an available key combination for a new command I want to use efficiently. VSCode itself is not much help with that. It tells you <em>after</em> setting a combination that it is already taken:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/vscode-binding-exists.png" alt="Different levels of opacity carry information."> <figcaption>
<p>Different levels of opacity carry information.</p>
</figcaption>
</figure>
<p>I guess it’s better than nothing, but trying multiple combinations and manually checking what other combination is already using that binding and whether you might be able to remove that other binding is not much fun.
The collection visualizer made it trivial to see that there are actually plenty of free combinations in VSCode, only <kbd>Ctrl</kbd> and <kbd>Shift</kbd> are quite busy by default. Things start happening if you mix in <kbd>Alt</kbd>:</p>
<figure>
<img src="https://tkainrad.dev/images/keycombiner/collection-visualizer/vscode-free-combinations.png" alt="All modifier combinations with Alt are wide open for your own assignments in VSCode."> <figcaption>
<p>All modifier combinations with <kbd>Alt</kbd> are wide open for your own assignments in VSCode.</p>
</figcaption>
</figure>
<p>You can then go one step further and find free combinations that are easy to type. For me, these are combinations that I can type with just my left hand. If the non-modifier key is on the home row, that’s another big plus. In any case, a convenient shortcut should have a maximum of two modifiers.</p>
<h2 id="design-a-coherent-set-of-shortcuts">Design a Coherent Set of Shortcuts</h2>
<p>The collection visualizer helps design a coherent set of shortcuts, either for yourself or for an application you are developing.</p>
<p>Unfortunately, many application designers do not think very hard about keyboard shortcuts. Often, you end up with a set that is neither intuitive nor easy to type. Heck, even <a href="https://keycombiner.com/collections/keycombiner/">KeyCombiner’s own shortcuts</a> are all over the place with sequences and different modifier combinations. Given that I work more or less alone on the project and try to be very efficient with my time, I didn’t think about these bindings enough. The collection visualizer makes this painfully obvious, and I will soon come up with new shortcuts. However, it will be very hard not to annoy users who have already memorized these shortcuts.
So, I recommend that you be smarter than me and start to design a coherent set of shortcuts for your application right away. The collection visualizer is here to help you with that.</p>
<p>If you are not an application designer, you might still want to design a coherent set of key bindings for your personal use. Without any tools to assist you, this is a suprisingly hard taks, especially when you try to find a coherent set for or <em>multiple</em> applications. You have to keep in mind which commands are available in these different apps, what the defaults are, and how to resolve these constraints into a set that works everywhere.
The collection visualizer, along with KeyCombiner’s other collection management features, can help you get there.</p>

<p>Above, I have written that a proper keyboard shortcut consists of 0 or more modifier keys and exactly one non-modifier key. However, KeyCombiner also allows sequences, such as the <em>Go To</em> shortcuts used by Gmail. I have been thinking a lot about how to visualize those on a virtual keyboard, but have not found a good solution yet.</p>
<p>Furthermore, KeyCombiner collections can also hold short text snippets, such as commands and programming language syntax. Many people use these snippets with the <a href="https://tkainrad.dev/posts/app-to-show-shortcuts-of-current-application-windows-linux-macos">Desktop Apps' instant lookup</a>. It turns your collections into an instant, context-aware, searchable cheatsheet. However, I struggle to find a way to visualize them on a keyboard.</p>

<p>In its first days, the collection visualizer has already helped me plenty of times. I improved my VSCode bindings, realized that KeyCombiner’s own default bindings are not intuitive, and found better ways to reuse my VSCode bindings in PyCharm and Eclipse.
I’d be thrilled to hear about your experiences in the comments below or via <a href="https://tkainrad.dev/cdn-cgi/l/email-protection#0a7e6265676b794a7e616b6364786b6e246e6f7c">mail</a>.</p>
<p>I will write about the collection visualizer’s implementation in a future blog post. Spoiler: Vue and (S)CSS do the heavy lifting.</p>
<br>
</div></div>]]>
            </description>
            <link>https://tkainrad.dev/posts/visualize-collections-of-keyboard-shortcuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872549</guid>
            <pubDate>Fri, 22 Jan 2021 15:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pidgin – A Universal Chat Client]]>
            </title>
            <description>
<![CDATA[
Score 670 | Comments 445 (<a href="https://news.ycombinator.com/item?id=25872525">thread link</a>) | @smusamashah
<br/>
January 22, 2021 | https://www.pidgin.im/plugins | <a href="https://web.archive.org/web/*/https://www.pidgin.im/plugins">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <tr data-type="Protocol">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/awslabs/pidgin-chime/">Amazon Chime</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Online meeting and video conferencing
                            </td>
                            <td>
                                Amazon Web Services - Labs
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/nmbook/pidgin-libbnet/">Battle.net Classic</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Blizzard’s gaming network: notably for StarCraft, Diablo II, and WarCraft III
                            </td>
                            <td>
                                nmbook
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                <img src="https://github.com/EionRobb/purple-battlenet/raw/master/battlenet48.png" alt="Battle.net v2 logo">
                            </td>
                            <td>
                                <a href="https://github.com/EionRobb/purple-battlenet#readme">Battle.net v2</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Blizzard’s gaming network for WoW, Overwatch and others
                            </td>
                            <td>
                                EionRobb
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                <img src="https://github.com/jrfoell/campfire-libpurple/raw/master/campfire48.png" alt="Campfire logo">
                            </td>
                            <td>
                                <a href="https://github.com/jrfoell/campfire-libpurple/">Campfire</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Protocol plugin for Basecamp’s Campfire IM
                            </td>
                            <td>
                                jrfoell
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/ccpp/deltachat-purple/">Deltachat</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                IM over email
                            </td>
                            <td>
                                ccpp
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/EionRobb/purple-discord/#readme">Discord</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Text chat for gamers
                            </td>
                            <td>
                                EionRobb
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/samuelkarp/purple-docker/">Docker</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Send stdin commands to Docker containers
                            </td>
                            <td>
                                samuelkarp
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/fchat-pidgin/fchat-pidgin#readme">F-List</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                F-List roleplaying community
                            </td>
                            <td>
                                fchat-pidgin
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/dequis/purple-facebook/wiki/">Facebook</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Facebook chat
                            </td>
                            <td>
                                dequis
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                <img src="https://github.com/EionRobb/purple-gammu/raw/master/icons/48/gammu.png" alt="Gammu logo">
                            </td>
                            <td>
                                <a href="https://github.com/EionRobb/purple-gammu/#readme">Gammu</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Send SMS through your feature phone via usb/serial/bluetooth/irda
                            </td>
                            <td>
                                EionRobb
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://notabug.org/alyssa/groupme-purple/">GroupMe</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                GroupMe group messaging
                            </td>
                            <td>
                                Alyssa Rosenzweig
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                <img src="https://user-images.githubusercontent.com/1063865/87138135-18131780-c2f2-11ea-9579-3dfbb7d858fb.png" alt="Hangouts logo">
                            </td>
                            <td>
                                <a href="https://github.com/EionRobb/purple-hangouts#readme">Hangouts</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Alternative plugin for Google Hangouts
                            </td>
                            <td>
                                EionRobb
                            </td>
                        </tr>
                        <tr data-type="Protocol">
                            <td>
                                <img src="https://github.com/theli-ua/honpurple/raw/master/data/pixmaps/pidgin/emblems/16/hon_ingame.png" alt="Heroes of Newerth logo">
                            </td>
                            <td>
                                <a href="https://github.com/theli-ua/honpurple/">Heroes of Newerth</a>
                            </td>
                            <td>
                                <span aria-label="Community">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
                            <td>
                                Online video game
                            </td>
                            <td>
                                theli-ua
                            </td>
                        </tr>
                        <tr data-type="Protocol" istrusted="true">
                            <td>
                                &nbsp;
                            </td>
                            <td>
                                <a href="https://github.com/EionRobb/icyque/">ICQ WIM (IcyQue)</a>
                            </td>
                            <td>
                                <span aria-label="Trusted">
                                    <i></i>
                                </span>
                            </td>
                            <td>
                                Protocol
                            </td>
              …</tr></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pidgin.im/plugins">https://www.pidgin.im/plugins</a></em></p>]]>
            </description>
            <link>https://www.pidgin.im/plugins</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872525</guid>
            <pubDate>Fri, 22 Jan 2021 15:37:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cost of Pushing Code]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25872409">thread link</a>) | @dlevine
<br/>
January 22, 2021 | https://blog.config.ly/post/640426840224399361/the-cost-of-pushing-code | <a href="https://web.archive.org/web/*/https://blog.config.ly/post/640426840224399361/the-cost-of-pushing-code">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When you begin building a new product, pushing code to production is mostly effortless. For a server or web application, you just push the code to the main branch and run a deploy script. In some cases it is possible to set up a “Git push” deploy (e.g. Heroku), which automatically deploys whenever a branch is pushed. This workflow makes it super easy to keep everything in code, including your configuration and all of your product copy. However, as your product and company grow, it becomes harder and harder to push new code. This post will go over the major reasons why pushing code becomes painful, and discusses alternatives that may reduce some of this pain.<b><br></b></p><h2>Time and Effort</h2><p>The first pain point is that it takes time and effort to deploy code. A lot of companies don’t do continuous or even daily deployment, and code changes often go out between a day and 2 weeks after they are committed. This introduces a significant amount of lag, and prevents you from moving quickly when something minor needs to change. It might be possible to override the process and push a hotfix to production, but there is a time and effort cost to this as well.</p><p>Once you get the green light to deploy, there is still a significant amount of work to actually get the code out. Even though the push process may appear simple on the surface, most companies have pipelines that build the code and run at least some unit and integration tests. Every time you want to deploy something new, you need to wait for these tests to run, and if anything breaks (potentially from an unrelated commit that someone else pushed to the main branch), you need to track down the problem before you can deploy. This adds mental overhead, and can discourage you from even trying to make a change in the first place.</p><p>Furthermore, a lot of companies have both production and staging environments. Before you can deploy to production, you must deploy and verify your changes on staging. These environments can be total lifesavers when used appropriately, but unfortunately they do add time and cost to deploying code.</p><p>Finally, it bears mentioning that every code change requires engineering time. Engineering time is expensive, and engineers don’t respond well to distractions. Even a 1-line copy change may cost you and hour of engineering time that could be spent on other higher-value activities.</p><h2>Unexpected Consequences</h2><p>The second major pain point is that pushing code can have unexpected consequences. Even something as simple as changing a string in text can have wide-ranging consequences if that string is used in numerous places. Another example would be a configuration change. If someone makes a simple config change that invalidates a piece of JSON or even just changes its format, the entire application could fail to start. There have been plenty of times in my career where a seemingly innocuous change took down a whole app. While defensive programming practices can reduce the effect of an erroneous configuration, these sorts of things are frankly unavoidable.</p><p>Even the fear of breaking things can make it more difficult to change code. Every developer has some level of fear that he will accidentally push a bad commit and then get fired (or publicly humiliated) over it, and this leads most engineers to become somewhat risk averse. Accordingly, there have been many times where I didn’t deploy a “simple” change immediately because I was afraid that it might cause something bad to happen. In the best case, this type of fear will delay these changes until the next morning or to spend hours monitoring metrics to verify that nothing is broken. In the worst case, it could cause people to decide “not to bother” in the first place.</p><h2>Gatekeepers</h2><p>The third pain point is that there are often numerous gatekeepers who must be placated when pushing code. First of all, only engineers can make code changes. This means that if all of your product copy is stored in code, and a product manager or marketer wants to change that copy, then they must enlist the help of an engineer before they can make the change. Likewise with configuration changes that are stored in code. If someone on the customer support team wants to override some limit that is hardcoded, then the only solution is to have an engineer push code.&nbsp;</p><p>Then there are further gatekeepers, including the code reviewer and potentially devops (if they are the ones who run the deploy). Every code change will have to go through each gatekeeper, and even if the review is a formality, it is possible for a change to get stuck indefinitely due to a missed email or competing priorities.</p><p>Another gatekeeper for mobile applications is the app stores. Google and Apple review every app submission to their platform, and while the review process has sped up significantly in recent years, updates often still take 24 to 48 hours to review, and Apple occasionally rejects small updates for unrelated reasons. The result is that it often isn’t possible to “quickly” push a change when someone finds a typo, and it has the potential to become a long and drawn out process.</p><h2>The Solution</h2><p>So the solution doesn’t involve changing the code push process, which is there for good reason. As code deployment becomes painful, you will want to pull anything that isn’t code from your code base, and put it into systems that you can quickly update. Configurations and copy can be moved into alternative systems, and pulled by the server or client whenever needed. For example, you could put them in an S3 bucket or any other key/value store. While this takes a little while to set up, It frees you from the tyranny of pushing code whenever you need to make a small change. Over the long term, this sort of system will save you far more time and money than it costs. Finally, I would be remiss if I didn’t mention <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fconfig.ly&amp;t=MDYwMTRmMTNhZjM1ZjI1ZTI3ZmJkMDQxNzY4ZmUzMTA5OTgzZGFiYyxjdVVLTFVmWQ%3D%3D&amp;b=t%3AF5pXwssAHFhqj3a83p5BQg&amp;p=https%3A%2F%2Fblog.config.ly%2Fpost%2F640426840224399361%2Fthe-cost-of-pushing-code&amp;m=1&amp;ts=1611596042">Config.ly</a>, which makes it super simple to edit all kinds of string and JSON data, and then to fetch them in real-time from your server or directly from your mobile applications.<br></p></div></div>]]>
            </description>
            <link>https://blog.config.ly/post/640426840224399361/the-cost-of-pushing-code</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872409</guid>
            <pubDate>Fri, 22 Jan 2021 15:25:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our data SaaS integrates with Git]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25872405">thread link</a>) | @xoelop
<br/>
January 22, 2021 | https://blog.tinybird.co/2021/01/22/tech-product-design-how-we-integrate-with-git/ | <a href="https://web.archive.org/web/*/https://blog.tinybird.co/2021/01/22/tech-product-design-how-we-integrate-with-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting">  <div id="post-content" itemprop="articleBody"> <p>During the last years all the development lifecycle has revolved around the version control system. You want continuous integration and testing, healthy release workflows, automatic security checks, linters, links to tickets, alerts… you use a tool or a service that runs that for you when something happens in your repo, like a commit, a pull request or a merge.</p> <p>The thing is: developers are privileged, they work with source code, which is a line based text format and that’s what most of the SCMs know to work with. I don’t actually know how other industries work without tools like that.</p> <p>When designing Tinybird one of the things we had in mind was: analytics data projects are code and code should be in a repo, like other parts of the aplicacion. And that’s why we decided to expose any resource as a simple text based format and a way to serialize/deserialize to and from our service.</p> <p>Most SaaS products don’t allow you to mirror your project/metadata to a repo and that makes it impossible to use the good practices I mentioned in the first paragraph.</p> <h2 id="the-design">The design</h2> <p>Our data model is simple, we just have two kinds of resources: datasources and data transformation pipes, they store and process data respectively. You can access both resources using a regular API that returns JSON but JSON is not the best format to edit and in general, be processed by a human. So we decided to also serialize them as a regular text file.</p> <p>After some tests, we finally went with the simplest possible design for that and not tie the design to an existing format. We wanted to maximize how easy it is to write one of those files in a code editor. We expose the same resources as JSON as I said if you want to automate anything, so you don’t need to write a parser for those files. Machines and people need different interfaces.</p> <p>We chose a file format like a Dockerfile, easy to parse, easy to write and organize, that allows to resolve merge conflicts without much hassle and that most developers more or less know how to deal with.</p> <p>To be clear, we are not so clever to think about all those things before we start: we went through several data analytics projects and after some iterations we found a format that was handy.</p> <p>So for example, you define a datasource like</p> <div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
</pre></td><td><pre><span>#</span> <span>test</span><span>.</span><span>datasource</span>
<span>VERSION</span> <span>0</span>
<span>SCHEMA</span> <span>&gt;</span>
	<span>timestamp</span> <span>DateTime</span><span>,</span>
 	<span>user_id</span> <span>Int32</span>

<span>SORTING_KEY</span> <span>timestamp</span>
</pre></td></tr></tbody></table></code></pre></div></div> <p>And you push to our platform with our CLI tool made specifically to work with those files.</p> <div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>$ </span>tb push test.datasource
</pre></td></tr></tbody></table></code></pre></div></div> <p>That’s it, you can do that with every single resource in a project so you can still use your favorite version control system on any provider of your choice and use the code editor you use every single day.</p> <p>Of course you can pull files as well</p>  <h2 id="the-benefits">The benefits</h2> <p>Being able to serialize the project as text files and store them in github allows us to do different things with our data pipelines:</p> <ul> <li>Run data tests</li> <li>Test the API endpoints you can expose with a pipe (this means exposing the result of a SQL as an API)</li> <li>Push to production new data workflows</li> <li>Replicate the same project to several environments (local/dev/staging/pro)</li> <li>Use all the available tools: merge requests, github actions, gitlab CI/CD system…</li> </ul> <p>We just want to introduce those concepts, we will write a lot more about these things in future blog posts, you can subscribe to receive updates.</p> </div>  </article>  </div> </div></div>]]>
            </description>
            <link>https://blog.tinybird.co/2021/01/22/tech-product-design-how-we-integrate-with-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872405</guid>
            <pubDate>Fri, 22 Jan 2021 15:25:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Telegram Has a Nazi Problem]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25872063">thread link</a>) | @RealDeinonychus
<br/>
January 22, 2021 | https://restofworld.org/2021/terror-on-telegram/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/terror-on-telegram/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p><span>O</span>n March 15, 2019, an Australian man killed 51 people in a horrific attack on two mosques in Christchurch, New Zealand. Shortly before, he released a<strong> </strong>bombastic<strong> </strong>manifesto, in which he argued that mass immigration and high fertility rates in developing countries constitute a form of genocide against white people. Within days, an anonymous Russian translation of the more than 70-page document began spreading among far-right sympathizers in former Soviet countries. This happened primarily via Telegram.</p>



<p>One of the translation’s earliest appearances was on the Russian-language Telegram channel of the neo-Nazi platform WotanJugend, which currently has just over 15,000 followers. The document was also circulated on the site’s Telegram channel, as was a related photo of a graffiti portrait of the Christchurch shooter in full battle gear, manifesto in hand. “Blessed be your name,” read the accompanying caption.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_5070-40x71.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_5070-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_5070-400x711.png 400w, https://restofworld.org/wp-content/uploads/2021/01/IMG_5070-600x1067.png 600w, https://restofworld.org/wp-content/uploads/2021/01/IMG_5070-1000x1778.png 1000w, " sizes="300px" alt="On the day of the Christchurch attack, Tarrant’s manifesto was uploaded to Telegram channel of the of the neo-Nazi platform WotanJugend.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Telegram</span>
			</figcaption>
		</figure>


<p>The translated manifesto was eventually removed, but saved copies can be still found via the Internet Archive Wayback Machine. For authorities wishing to exert more control over this kind of dangerous material, the platform presents a unique challenge. Telegram was designed by avowed libertarians with the goal of helping people living under authoritarian regimes circumvent censorship. Removing extremist or violent content hinges largely on the company’s cooperation, which it has only begun to grant over the last several years. This makes for a volatile situation in general, but in a fragile, nascent democracy like Ukraine, where authorities are focused on the threat of Russian aggression, extremists have been able to flourish with relative impunity.</p>



<p>On a <a href="https://www.wiesenthal.com/about/news/telegram-1.html">website announcement</a> last July, the Simon Wiesenthal Center, a global Jewish human rights organization, dubbed Telegram “the online weapon of choice for [the] violent far-right.” The report <a href="https://www.wiesenthal.com/about/news/telegram-1.html">highlighted</a> its role as a knowledge-sharing platform for far-right extremists, particularly on the subjects of Nazi ideology, military survival skills, and at-home arms manufacturing. The Wiesenthal Center also mentioned another report by the SITE Intelligence Group, a terror-tracking organization, which looked at a sample of 374 far-right channels and found that 80% of them were created within six months of the Christchurch attack. It’s difficult to say with any certainty how many of these channels exist in total, and given that the majority of them are anonymous, it’s impossible to say where their administrators are located.</p>



<p>Created by Russian brothers Pavel and Nikolai Durov in 2013 and operated out of Dubai, Telegram is best known as the preferred tool of pro-democracy activists in authoritarian countries. But its lax rules regarding inflammatory content have made it popular with extremists purged from other platforms. In 2019, Facebook <a href="https://www.theguardian.com/technology/2019/may/02/facebook-ban-alex-jones-milo-yiannopoulos">banned accounts associated with far-right groups</a> and figures such as Alex Jones and Milo Yiannopoulos. According to a recent study by University of Bern researchers, the Facebook crackdown precipitated a massive “simultaneous migration” of far-right actors to Telegram, where they were able to “swiftly re-create connections and gain prominence.” Telegram did not respond to requests for comment.</p>



<p>To map out how the “terrorgram” is evolving in Ukraine, we reached out to Alexsey Levkin, a prominent far-right spokesman who describes himself as a veteran of the conflict in Eastern Ukraine. While Levkin maintains that he doesn’t endorse terrorism, he does call himself “the mastermind” of the WotanJugend platform and claims to have coined the name, which alludes to ancient Germanic mythology and the Nazi youth movement, <em>Hitlerjugend</em>. Levkin also said he had nothing to do with the publication of the Christchurch manifesto, although he spoke approvingly of its content. Just last week, the channel posted a statement in support of NSO-North, a Russian Nazi gang whose members are serving lengthy sentences for a series of deadly hate crimes in the 2000s. “Terror has brought its fruit, but for these people, it turned out to be a suicidal path.”</p>



<p>Despite denying he is a WotanJugend admin, Levkin clearly exerts a great deal of influence over the channel — a substantial amount of the content is dedicated to him or his projects. He also claims not to be as active online as he once was, because, as he puts it in a disturbing joke: “I faced <em>Endlösung</em> [the final solution] on Facebook and other platforms.” He is, however, still prolific on Telegram. Levkin’s own channel, called Thule Signal in reference to an occultist society that influenced prominent Nazis at the beginning of Hitler’s ascent to power, has over 3,000 followers. (Levkin denies any connection.) When he is not propagating far-right views online, Levkin is often doing so IRL. He is the lead singer of the national socialist black metal band M8L8TH — the Russian word <em>molot</em> means hammer, and H stands for Hitler — and he runs a far-right fashion brand.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/210108BH0089-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/210108BH0089-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/210108BH0089-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/01/210108BH0089-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/01/210108BH0089-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/01/210108BH0089-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/01/210108BH0089-2800x1868.jpg 2800w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="Aleksey Levkin, the Russian-born lead singer of the NSBM (national socialist black metal) band M8L8TH, veteran of the conflict in eastern Ukraine, and supporter of far-right causes, poses for a portrait near the ruins of the ancient Church of the Virgina of the Tithe.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>“Oh, the bill</strong> comes to 88,” he joked mischievously as we ordered coffee outside Kyiv’s Independence Square, popularly known as Maidan. In far-right parlance, “88” is the numerical code for “Heil Hitler,” the Nazi salute. We were just around the corner from Cossack House, a former hotel seized by far-right militants during the 2014 Maidan revolution, which Levkin now uses as an event space.</p>



<p>Muscular, bearded, and blue-eyed with a shaved head, Levkin looks every bit like a Viking in a Netflix series. He is in fact a Russian citizen — one of a few dozen Russian nationalists and outright neo-Nazis who joined the Ukrainian army in fighting separatist forces backed by Russia during the Ukrainian revolution. Having grown disillusioned with Russia’s leadership and tolerance of Muslim immigrants from Central Asia, exiles such as Levkin saw Ukraine’s revolution as a victory for nationalism. It was seen as a model that could be replicated elsewhere. In conversation, Levkin referred to Ukraine as the “promised land.”</p>



<p>While Ukraine’s revolution was spearheaded by pro-democracy forces, the country’s nationalists played a visible role. They gained even more prominence when Russia seized the Crimean Peninsula and fomented conflict in the eastern Ukrainian region of Donbass. Far-right activists were among the first to form combat-ready units, and word spread through international networks that these groups welcomed foreigners. Soon, Swedes, Americans, Poles, and Georgians as well as many anti-Putin Russians were joining Ukrainians on the frontline. As international media outlets began covering this phenomenon, more people started to show up. The most prominent of these volunteer groups was the so-called Azov battalion, which later became an autonomous regiment under the auspices of Ukraine’s National Guard. From that, a number of political, veteran, and paramilitary organizations emerged, which members now refer to as the Azov movement.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/141015BH0450-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/141015BH0450-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/141015BH0450-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/01/141015BH0450-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/01/141015BH0450-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/01/141015BH0450-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/01/141015BH0450-2800x1866.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Members of the Azov Battalion, a pro-Ukraine militia, demonstrate a training exercise at the group's base.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>Although <a href="https://www.ui.se/globalassets/ui.se-eng/publications/ui-publications/2020/ui-brief-no.-3-2020.pdf">polls and election results show</a> that the far-right in Ukraine has very little public support, members of these networks have infiltrated government institutions and security bodies at the highest levels since 2014. Vadym Troyan, a former deputy commander in Azov and an alumnus of a white supremacist group, is currently a deputy minister in Ukraine’s Ministry of Internal Affairs; Azov founder Andriy Biletsky was a member of parliament between 2014 and 2019. Although the<strong> </strong>Ukrainian government was cautious about accepting foreign fighters, which likely helped stem an influx of extremists, the country still developed a reputation as a welcoming destination for the far-right. In a<a href="https://www.ctc.usma.edu/the-nexus-between-far-right-extremists-in-the-united-states-and-ukraine/"> report</a> published by the Combating Terrorism Center at West Point, journalist Tim Lister says that the success of Azov made ultranationalists around the world regard Ukraine as a “field of dreams.” According to an official government inquiry into the Christchurch shooting, not long before the massacre, the perpetrator told his family that he wanted to relocate to Ukraine.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_7447-40x71.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_7447-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/01/IMG_7447-400x711.png 400w, https://restofworld.org/wp-content/uploads/2021/01/IMG_7447-600x1067.png 600w, https://restofworld.org/wp-content/uploads/2021/01/IMG_7447-1000x1778.png 1000w, " sizes="300px" alt="Activists display Hitler’s portrait on a bridge in Kyiv on the a Telegram channel.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Telegram</span>
			</figcaption>
		</figure>


<p>As social and political pressures have <a href="https://about.fb.com/news/2019/09/combating-hate-and-extremism/">prompted Facebook and YouTube to purge extremist content</a>, Telegram has transformed into a nerve center for far-right sympathizers, many of whom come from the former Soviet Union. Content is shared widely within this ecosystem, and posts typically celebrate Hitler, explore far-right philosophy, satirize and denigrate people of color, and glorify perpetrators of terror attacks motivated by racial hatred. The channels also advertise offline lectures and workshops — and the occasional rubber knife tournament — and promote like-minded Telegram channels in Russian, Ukrainian, various Eastern European languages, German, and English. These outlets don’t seem to be focused as much on luring people to specific far-right groups as they seem to function as propaganda for autonomous terrorism — that is, “lone wolves.”</p>



<p>Most Russian and Ukrainian channels promote what they call a “traditionalist and conservative” agenda, which consists of a mix of open racism and hate-mongering against feminists and the LGBT community. Levkin says that, in a world constricted by political correctness, many far-right channels have been successful in reaching out to “normies” — ordinary people, in the movement’s parlance — and providing them an outlet for transgression. An especially popular source for far-right content is a Telegram channel run by Sergey Korotkikh, the most prominent living neo-Nazi from the former Soviet world. Originally from Belarus, Korotkikh helped create what was once a large Russian neo-Nazi organization before fleeing the country and ending up in Ukraine, where he assumed a leadership role with Azov. His Telegram channel, which has 23,000 followers, churns out hatred and obscenity on …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/terror-on-telegram/">https://restofworld.org/2021/terror-on-telegram/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/terror-on-telegram/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872063</guid>
            <pubDate>Fri, 22 Jan 2021 14:50:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go offline to view this page]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25872022">thread link</a>) | @abusedmedia
<br/>
January 22, 2021 | https://chris.bolin.co/offline/ | <a href="https://web.archive.org/web/*/https://chris.bolin.co/offline/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://chris.bolin.co/offline/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25872022</guid>
            <pubDate>Fri, 22 Jan 2021 14:45:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A story about pivots]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25871629">thread link</a>) | @james_impliu
<br/>
January 22, 2021 | https://posthog.com/blog/story-about-pivots | <a href="https://web.archive.org/web/*/https://posthog.com/blog/story-about-pivots">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p>PostHog has pivoted <em>a lot</em>.</p>
<p>After 5 pivots in 6 months, we got into <a href="https://www.ycombinator.com/">YCombinator</a> last year, pivoted again whilst we were there and have now gone from the first commit to thousands of deployments, a team across 10 countries and $12M raised, in well under a year. We've a long way to go, but we're delighted at how it has gone so far.</p>
<p>This is that story and what we learned from it.</p>
<h2 id="youll-feel-silly"><a href="#youll-feel-silly" aria-label="youll feel silly permalink"></a>You'll feel silly</h2>
<p>It goes something like this:</p>
<ol>
<li>Convince yourself then your family, friends and colleagues you have some great idea.</li>
<li>Quit your job.</li>
<li>Build it. Listen to the soundtrack from <a href="https://www.imdb.com/title/tt1285016/">The Social Network</a> way too much.</li>
<li>Everyone thinks your thing is terrible. Hopefully you realize.</li>
</ol>
<p>The nature of a startup is that you have to <a href="https://www.ycombinator.com/library/6g-how-to-talk-to-users">talk to users</a>. Or so we've heard.</p>
<p>My sole focus for weeks on end was just to get meetings with people that we felt may have the same problem we were trying to solve.</p>
<h2 id="it-got-good-eventually-right"><a href="#it-got-good-eventually-right" aria-label="it got good eventually right permalink"></a>It got good eventually, right?</h2>
<p>In 9 months, we built 6 products and did more than 100 meetings with potential users.</p>
<p>The range of ideas we tried to solve looks broad, but the thing that connected all of them was that we tackled problems we'd experienced in our previous professional lives.</p>
<p>So, what did we build?</p>
<h3 id="1-sales-territory-management-tool"><a href="#1-sales-territory-management-tool" aria-label="1 sales territory management tool permalink"></a>1. Sales Territory Management Tool</h3>
<p>At one stage in my life, I was the VP of Sales at an enterprise software company. On paper, it looked like a glamorous job - I used to fly around the world with the sales team, and met with huge enterprise clients in fancy skyscrapers, like the <a href="https://en.wikipedia.org/wiki/International_Commerce_Centre">ICC in Hong Kong</a>:</p>
<p><a href="https://posthog.com/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg">
                    <img src="https://posthog.com/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg" srcset="https://posthog.imgix.net/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg?w=175 175w, https://posthog.imgix.net/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg?w=350 350w, https://posthog.imgix.net/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg?w=700 700w, https://posthog.imgix.net/static/international-commerce-centre-44dfcde59997db42043f10c44a88f782.jpg?w=1000 1000w" sizes="(max-width: 700px) 100vw, 700px" title="International Commerce Center - a big skyscraper in Hong Kong" alt="International Commerce Center - a big skyscraper in Hong Kong" loading="lazy">
                </a></p>
<p>Despite this, the <em>majority</em> of your time in sales is spent getting nowhere. All those hotels, flights, calls, fastidiously wearing a suit in inappropriately warm weather - very few of those things result in anything.</p>
<p>Sidenote: this is why <a href="https://posthog.com/handbook/growth/strategy">product led growth</a> is so much better.</p>
<p>If you're not getting anywhere with a potential customer after a few weeks or months of trying, your time is better spent elsewhere. Yet systems that are the core products of <a href="https://en.wikipedia.org/wiki/Salesforce">$17.1Bn revenue companies</a> come with a manually selected arbitrary number for the percentage probability that doesn't vary with time.</p>
<p>We pulled pipeline data from Hubspot or Salesforce, then used predictive analytics to work out how this curve looked based on historic data, then applied it to the current pipeline. Once a deal dropped below a certain threshold, we'd recommend you swap out that target company and pull a new one into the pipeline.</p>
<p>We confused a lot of people with this idea, because we were confused with whom we were targeting.</p>
<p>We got 15 sales leaders to agree to trying this out, sent them a link, then waited...</p>
<p>and waited...</p>
<p>just <em>one</em> person even clicked the sign up link. The rest didn't even try it.</p>
<p>With hindsight, it was way overpowered for tiny teams and we'd only have had a great fit for huge ones with a lot of data.</p>
<p>The only people interested in smaller teams were enthusiasts, but there wasn't an easy jump from that to a bigger market. We could have just worked on selling the product to big companies, but that would be <a href="https://www.ycombinator.com/library/3O-why-big-deals-are-bad-for-startups">tough</a>.</p>
<h3 id="2-crm-with-predictive-analytics"><a href="#2-crm-with-predictive-analytics" aria-label="2 crm with predictive analytics permalink"></a>2. CRM with Predictive Analytics</h3>
<p>One of our friends who ran a small sales team was a clear outliter. He had been using our first product a lot. We asked ourselves - why?</p>
<p>He had used it to <em>replace</em> his CRM. </p>
<p>Could we just do the whole lot in one place, and reimagine the CRM - would that make things feel simpler?</p>
<p>We positioned the product as a CRM for small companies, with predictive analytics for an even simpler experience managing everything. We tweaked the functionality to have more control over deals and contacts.</p>
<p>It suddenly got really hard to get anyone to talk to us.</p>
<p>There are many lightweight CRMs out there, and predictive analytics make more sense for those with more data, not startups with hardly any.</p>
<p>This was around the time that <a href="https://superhuman.com/">Superhuman</a> was getting pretty popular; we got overexcited, and kept using words like "blazing", "gorgeous", "brilliant". I blame too much time wasted reading <a href="https://sifted.eu/articles/vc-brags-twitter/">VC Twitter</a>.</p>
<p>We didn't think through who we were building for. The market we were working on was very busy, so if I went back in time, I would have focused more on our differentiation - a product could make more sense than a platform. Tim and I also just weren't strong enough at design to differentiate on that alone.</p>
<p>After hundreds of messages to potential users, we eventually got a single customer for $20/month, who then didn't actually pay the invoice. If you're pushing this hard and getting nowhere, you don't have the magic of <a href="https://www.youtube.com/watch?v=l-vfn97QTr0">product market fit</a>.</p>
<h3 id="3-11-tool-with-predictive-analytics"><a href="#3-11-tool-with-predictive-analytics" aria-label="3 11 tool with predictive analytics permalink"></a>3. 1:1 Tool with Predictive Analytics</h3>
<p>Back to basics - what was the actual problem we were solving?</p>
<p>It was the prioritization of where to focus your sales efforts. If 90% of your deals deals won't close, you need to get good at not spending time on those that aren't going to close.</p>
<p><a href="https://en.wikipedia.org/wiki/Andrew_Grove">Andrew Grove</a> has an excellent book, <a href="https://www.amazon.com/High-Output-Management-Andrew-Grove/dp/0679762884/ref=sr_1_1?dchild=1&amp;keywords=high+output+management&amp;qid=1610712757&amp;s=books&amp;sr=1-1">High Output Management</a>. The premise is that your 1:1 meetings with your direct reports are your most leveraged time.</p>
<p>Yet, many managers in practise don't prepare, at all.</p>
<p><a href="https://posthog.com/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg">
                    <img src="https://posthog.com/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg" srcset="https://posthog.imgix.net/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg?w=175 175w, https://posthog.imgix.net/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg?w=350 350w, https://posthog.imgix.net/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg?w=700 700w, https://posthog.imgix.net/static/amazing-team-9b6c9c9a4eaaf13acd63fc7243e975f9.jpg?w=1000 1000w" sizes="(max-width: 700px) 100vw, 700px" title="A team that look a little bit like their happiness is staged" alt="A team that look a little bit like their happiness is staged" loading="lazy">
                </a></p>
<p>We changed the UX completely, and made an app that looked a bit like google docs, where you and your reports could each create an agenda in advance and take notes. The twist? The product would interpret your sales pipeline and would use predictive analytics to suggest specific deals to discuss that could be worth replacing or that had changed dramatically since the previous week.</p>
<p>We managed to get lots of meetings easily with this idea, and everyone reported not preparing to the standard they wanted. Did we have a silver bullet?</p>
<p>Despite giving out logins, only one team out of around 10 started using the tool. </p>
<p>We were flumoxed. This tool was simple, people were excited, but no one used it.</p>
<p>For those that haven't read it, <a href="http://momtestbook.com/">The Mom Test</a>, which I wish I'd read sooner, explains our downfall here perfectly:</p>
<div data-language="text"><pre><code>If they haven't solved the problem, ask why not. Have they tried searching for solutions and found them wanting? Or do they not even care enough to have Googled for it?

Rule of thumb: Anything involving the future is an over-optimistic lie.</code></pre></div>
<p>If we'd have asked this question, we'd have saved a couple more weeks.</p>
<p>By this stage, we were thinking we just wanted to work with people that would at least try our stuff. These pesky heads of sales were just too capricious and we needed a break.</p>
<p>Software engineers, surely they'd be more willing to try something that we built. We moved on to a different idea we'd had. Voilà:</p>
<h3 id="4-technical-debt-monitoring-tool-using-surveys-after-each-pull-request"><a href="#4-technical-debt-monitoring-tool-using-surveys-after-each-pull-request" aria-label="4 technical debt monitoring tool using surveys after each pull request permalink"></a>4. Technical Debt Monitoring Tool using Surveys after each Pull Request</h3>
<p>We'd seen the impact of technical debt not being paid off at the right rate in our past, and had the perspective that automation isn't key to solving it. We believed that engineers knew when it was worth tackling.</p>
<p>I spoke with every developer or engineering leader I'd ever worked with, and many I hadn't. They all said this problem was a huge pain point.</p>
<p>So we built a survey tool that integrated with git repositories. After each pull request, it would ask the developer to answer a few quick questions - did anything slow them down, what type of problem was it, and roughly how much time was wasted. The tool would then visualize the code base against time lost to help surface where to start.</p>
<p>We got quite a lot of users, and we got into YCombinator with this idea. Three weeks into the batch, we had reached 600 users, with a 50% response rate to the surveys.</p>
<p>We had started trying to charge people for the product. But we kept getting feedback that although it was a nice way to log issues, it just wasn't helping solve the problem. A few teams converted at very low order values with a lot of pushing, but it was clear we had a problem.</p>
<p>It turns out everyone has problems with technical debt, but solving it involves changing how teams prioritize. Product teams weren't using the tool, and they were often dictating what people built.</p>
<p>After a meetup with our YC friends at a cool <a href="http://sparksocialsf.com/">food truck spot</a>, we took a long walk back to our house in <a href="https://en.wikipedia.org/wiki/Castro_District,_San_Francisco">Castro</a>. We were thinking about how to solve our product woes. Could it turn into a piece of roadmapping software? Would it need to integrate with the roadmap software already in use? We just didn't feel excited about building these things out.</p>
<p><a href="https://posthog.com/static/about-to-run-out-of-product-ideas-31f3a4983d29ab835ee25c87a04dcb56.jpeg">
            <img src="https://posthog.com/static/about-to-run-out-of-product-ideas-31f3a4983d29ab835ee25c87a04dcb56.jpeg" title="James and Tim at a group ycombinator meetup about to walk home" alt="James and Tim at a group ycombinator meetup about to walk home" loading="lazy">
        </a></p>
<p>A couple of days later, driving between Mountain View and San Francisco, we realized that we just weren't the right people to run this business.</p>
<p>Although Tim had struggled with technical debt first hand, neither of us had solved it. If one of us had managed an engineering team before, we'd have perhaps been better placed to understand things. Our basic skills were good enough to get quite far with the idea, but we didn't have the belief to take it further.</p>
<p>Along the way, we learned a lot about how developers and product managers work together. We'd also created a big list of future ideas we'd had whilst building all the above things out. If you can't stop thinking of other ideas, you probably are building something you don't like. This all came into play for idea 6 later on (the good one).</p>
<p>So what did we do next?</p>
<h3 id="5-engineering-retention-tool-using-surveys-after-each-pull-request"><a href="#5-engineering-retention-tool-using-surveys-after-each-pull-request" aria-label="5 engineering retention tool using surveys after each pull request permalink"></a>5. Engineering Retention Tool using Surveys after each Pull Request</h3>
<p>Those fickle engineers joining companies and leaving them whenever they want to ;)</p>
<p>This idea didn't come from us, which doomed it before it even really started.</p>
<p>This lasted all of 5 days. We had a bunch of meetings left over from (4) to validate it. Amusingly we had to do a YCombinator demo day dry run for this in front of 500 people who made up the YC batch.</p>
<p>We had a wildly unenthusiastic response from prospective users. The lowlight was during one of the meetings that we resorted to asking the CTO of an 80 person start up what his biggest problem was, "I've not really got any". Noice, noice.</p>
<p><a href="https://gfycat.com/discover/andy-samberg-gifs">from Andy Samberg GIFs</a></p>
<h3 id="6-open-source-product-analytics-platform"><a href="#6-open-source-product-analytics-platform" aria-label="6 open source product analytics platform permalink"></a>6. Open Source Product Analytics Platform</h3>
<p>Things got meta.</p>
<p>Along our journey (/series of failed ideas), we got frustrated having to send all our user data to 3rd parties to understand our product usage. It felt wrong and it meant we'd …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://posthog.com/blog/story-about-pivots">https://posthog.com/blog/story-about-pivots</a></em></p>]]>
            </description>
            <link>https://posthog.com/blog/story-about-pivots</link>
            <guid isPermaLink="false">hacker-news-small-sites-25871629</guid>
            <pubDate>Fri, 22 Jan 2021 13:53:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Packages as Layers, Not Groups]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25871595">thread link</a>) | @rbanffy
<br/>
January 22, 2021 | https://www.gobeyond.dev/packages-as-layers/ | <a href="https://web.archive.org/web/*/https://www.gobeyond.dev/packages-as-layers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p>Four years ago, I wrote an article called <a href="https://www.gobeyond.dev/standard-package-layout/"><em>Standard Package Layout</em></a> that tried to address one of the most difficult topics for even advanced Go developers: package layout. However, most developers still struggle with organizing their code into a directory structure that will grow gracefully with their application.</p><p>Nearly all programming languages have a mechanism for grouping related functionality together. Ruby has gems, Java has packages. Those languages don't have a standard convention for grouping code because, honestly, it doesn't matter. It all comes down to personal preference.</p><p>However, developers that transition to Go are surprised by how often their package organization comes back to bite them. Why are Go packages so different from other languages? It's because they're not groups—they're layers.</p><h2 id="understanding-cyclic-dependencies">Understanding cyclic dependencies</h2><p>The primary difference between Go packages and grouping in other languages is that Go doesn't allow for circular dependencies. Package A can depend on package B, but then package B cannot depend back on package A.</p><figure><img src="https://www.gobeyond.dev/content/images/2021/01/Packages-As-Layers-Not-Groups---NoCircularDependencies.svg" alt=""><figcaption>Package dependencies can only go one way.</figcaption></figure><p>This restriction causes issues for developers later on when they need to have both packages share common code. There are typically two solutions: either combine both packages into a single package or introduce a third package.</p><figure><img src="https://www.gobeyond.dev/content/images/2021/01/Packages-As-Layers-Not-Groups---AddingThirdPackage-1.svg" alt=""></figure><p>However, splitting out into more and more packages only pushes the problem down the road. Eventually, you end up with a large mess of packages and no real structure.</p><h2 id="borrowing-from-the-standard-library">Borrowing from the standard library</h2><p>One of the most useful tips when programming Go is to look to the standard library when you need guidance. No code is perfect, but the Go standard library encapsulates many of the ideals of the creators of the language.</p><p>For example, the <code>net/http</code> package builds on top of the abstractions of the <code>net</code> package, which, in turn, builds on the abstractions of the <code>io</code> layer below it. This package structure works well because it would be nonsensical to imagine the <code>net</code> package needing to somehow depend on <code>net/http</code>.</p><figure><img src="https://www.gobeyond.dev/content/images/2021/01/Packages-As-Layers-Not-Groups---Stdlib-1.svg" alt=""></figure><p>While this works well in the standard library but can be difficult to translate to application development.</p><h2 id="applying-layers-to-application-development">Applying layers to application development</h2><p>We'll be looking at an example application called <a href="https://github.com/benbjohnson/wtf">WTF Dial</a>, so you can read the <a href="https://www.gobeyond.dev/wtf-dial/">introductory post</a> to understand more about it.</p><p>In this application, we have two logical layers:</p><ol><li>An SQLite database</li><li>An HTTP server</li></ol><p>We create a package for each of these—<code>sqlite</code> &amp; <code>http</code> . Many people will balk at naming a package the same name as a standard library package. That's a valid criticism and you could name it <code>wtfhttp</code> instead, however, our HTTP package fully encapsulates the <code>net/http</code> package so we never use them both in the same file. I find that prefixing every package is tedious and ugly, so I don't do it.</p><h3 id="the-naive-approach">The naive approach</h3><p>One way to structure our application would be to have our data types (e.g., <code>User</code>, <code>Dial</code>) and our functionality (e.g., <code>FindUser()</code>, <code>CreateDial()</code>) inside <code>sqlite</code>. Our <code>http</code> package could depend directly on it:</p><figure><img src="https://www.gobeyond.dev/content/images/2021/01/Packages-As-Layers-Not-Groups---NaiveApproach-1.svg" alt=""></figure><p>This is not a bad approach, and it works for simple applications. We end up with a few issues though. First, our data types are named <code>sqlite.User</code> and <code>sqlite.Dial</code>. That sounds odd as our data types belong to our application—not SQLite. </p><p>Second, our HTTP layer can only serve data from SQLite now. What happens if we need to add a caching layer in between? Or how do we support other types of data storage such as Postgres or even storing as JSON on disk?</p><p>Finally, we need to run an SQLite database for every HTTP test since there's no abstraction layer to mock it out. I generally support doing end-to-end testing as much as you can, but there are valid use cases for introducing unit tests in your higher layers. This is especially true once you introduce cloud services that you wouldn't want to run on every test invocation.</p><h3 id="isolating-your-business-domain">Isolating your business domain</h3><p>The first thing we can change is moving our <em>business domain</em> to its own package. This can also be called the "application domain". It's the data types specific to your application—e.g., <code>User</code>, <code>Dial</code> in the case of WTF Dial.</p><p>I use the root package (<code>wtf</code>) for this purpose as it's already conveniently named after my application, and it's the first place new developers look when they open the code base. Our types are now named more appropriately as <code>wtf.User</code> and <code>wtf.Dial</code>.</p><figure><img src="https://www.gobeyond.dev/content/images/2021/01/Packages-As-Layers-Not-Groups---IsolateBusinessDomain.svg" alt=""></figure><p>You can see an example of this with the <code>wtf.Dial</code> type:</p><figure><pre><code>type Dial struct {
	ID int `json:"id"`

	// Owner of the dial. Only the owner may delete the dial.
	UserID int   `json:"userID"`
	User   *User `json:"user"`

	// Human-readable name of the dial.
	Name string `json:"name"`

	// Code used to share the dial with other users.
	// It allows the creation of a shareable link without
	// explicitly inviting users.
	InviteCode string `json:"inviteCode,omitempty"`

	// Aggregate WTF level for the dial.
	Value int `json:"value"`

	// Timestamps for dial creation &amp; last update.
	CreatedAt time.Time `json:"createdAt"`
	UpdatedAt time.Time `json:"updatedAt"`

	// List of associated members and their contributing WTF level.
	// This is only set when returning a single dial.
	Memberships []*DialMembership `json:"memberships,omitempty"`
}
</code></pre><figcaption><a href="https://github.com/benbjohnson/wtf/blob/e23f5f00e0f48f54bd751cc264ea85c094f7d466/dial.go#L14-L50">dial.go#L14-50</a></figcaption></figure><p>In this code, there is no reference to any implementation details—just primitive types &amp; <code>time.Time</code>. JSON tags are added for convenience.</p><h3 id="remove-dependencies-by-abstracting-services">Remove dependencies by abstracting services</h3><p>Our application structure is looking better, but it's still odd that HTTP depends on SQLite. Our HTTP server wants to fetch data from an underlying data storage—it doesn't specifically care if it's SQLite or not.</p><p>To fix this, we'll create interfaces for the services in our business domain. These services are typically Create/Read/Update/Delete (CRUD) but can extend to other operations.</p><figure><pre><code>// DialService represents a service for managing dials.
type DialService interface {
	// Retrieves a single dial by ID along with associated memberships. Only
	// the dial owner &amp; members can see a dial. Returns ENOTFOUND if dial does
	// not exist or user does not have permission to view it.
	FindDialByID(ctx context.Context, id int) (*Dial, error)

	// Retrieves a list of dials based on a filter. Only returns dials that
	// the user owns or is a member of. Also returns a count of total matching
	// dials which may different from the number of returned dials if the
	// "Limit" field is set.
	FindDials(ctx context.Context, filter DialFilter) ([]*Dial, int, error)

	// Creates a new dial and assigns the current user as the owner.
	// The owner will automatically be added as a member of the new dial.
	CreateDial(ctx context.Context, dial *Dial) error

	// Updates an existing dial by ID. Only the dial owner can update a dial.
	// Returns the new dial state even if there was an error during update.
	//
	// Returns ENOTFOUND if dial does not exist. Returns EUNAUTHORIZED if user
	// is not the dial owner.
	UpdateDial(ctx context.Context, id int, upd DialUpdate) (*Dial, error)

	// Permanently removes a dial by ID. Only the dial owner may delete a dial.
	// Returns ENOTFOUND if dial does not exist. Returns EUNAUTHORIZED if user
	// is not the dial owner.
	DeleteDial(ctx context.Context, id int) error
}
</code></pre><figcaption><a href="https://github.com/benbjohnson/wtf/blob/e23f5f00e0f48f54bd751cc264ea85c094f7d466/dial.go#L81-L122">dial.go#L81-L122</a></figcaption></figure><p>Now our domain package (<code>wtf</code>) specifies not just the data structures but also the interface contracts for how our layers can communicate with one another. This flattens our package hierarchy so that all packages now depend on the domain package. This lets us break direct dependencies between packages and introduce alternate implementations such as a <code>mock</code> package.</p><figure><img src="https://www.gobeyond.dev/content/images/2021/01/Packages-As-Layers-Not-Groups---FlattenHierarchy.svg" alt=""></figure><h3 id="repackaging-packages">Repackaging packages</h3><p>Breaking the dependency between packages allows us flexibility in how we use our code. For our application binary, <code>wtfd</code>, we still want <code>http</code> to depend on <code>sqlite</code> (see <code><a href="https://github.com/benbjohnson/wtf/blob/main/cmd/wtfd/main.go#L180-L205">wtf/main.go</a></code>) but for our tests we can change <code>http</code> to depend on our new <code>mock</code> package (see <code><a href="https://github.com/benbjohnson/wtf/blob/main/http/server_test.go#L22-L59">http/server_test.go</a></code>):</p><figure><img src="https://www.gobeyond.dev/content/images/2021/01/Packages-As-Layers-Not-Groups---Repackaging--1-.svg" alt=""></figure><p>This may be overkill for our small web application, WTF Dial, but it becomes increasingly important as we grow our codebase.</p><h2 id="conclusion">Conclusion</h2><p>Packages are a powerful tool in Go but are the source of endless frustration if you view them as groups instead of layers. After understanding the logical layers of your application, you can extract data types &amp; interface contracts for your business domain and move them into your root package to serve as a common domain language for all subpackages. Defining this domain language is essential to growing your application over time.</p><p>Have question or comment? Please open a thread on the <a href="https://github.com/benbjohnson/wtf/discussions">WTF Dial GitHub Discussion board</a>.</p>
    </section></div>]]>
            </description>
            <link>https://www.gobeyond.dev/packages-as-layers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25871595</guid>
            <pubDate>Fri, 22 Jan 2021 13:47:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Chose a Monorepo]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25871479">thread link</a>) | @whatl3y
<br/>
January 22, 2021 | https://blog.lance.to/why-we-chose-a-monorepo | <a href="https://web.archive.org/web/*/https://blog.lance.to/why-we-chose-a-monorepo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Some epic rivalries:</p>
<ul><li>Batman vs. Superman</li>
<li>Right vs. Left</li>
<li>Tabs vs. Spaces</li>
<li>Monolith vs. Microservices vs. Monorepo</li></ul>

<h2 id="monoliths-microservices-monorepos">Monoliths, Microservices, &amp; Monorepos</h2>

<p>You want to get a stale, probably introverted nerdy software development team heated up? Ask them if they prefer tabs vs. spaces. Or maybe which programming language or IDE reigns supreme. One final debate that's sure to get the room stirring is whether you should build your project as a Monolith, with Microservices, or as a Monorepo.</p>

<p>To those who might not have heard these terms or concepts, or have but with limited detail and don't know exactly what they are, here's a short<sup>*</sup> break down:</p>
<ol><li><strong>Monolith</strong>: Think of this as a single codebase that is used to build all of the functionality that your product or business needs to get things done. You probably have a backend with a single API, a single frontend, and single test suite across the entire codebase regardless of how big or small it is.</li>
<li><strong>Microservice</strong> (multi-repo in the image below): A <em>small</em> codebase that does one thing, or a very small number of things well. Your business or product likely contains lots of small services like this, all of which focus on solving a very specific problem. A single microservice is likely a standalone API or something similar that has an easy interface to communicate with other services (HTTP, REST, GraphQL, etc.), and many times has its own standalone, segregated components separate from any other service (think database(s), caches, test suites, etc.)</li>
<li><strong>Monorepo</strong> (or mono-repo): A single repository that contains much, if not all of the code for a business or product to function, but that could be and likely is separated in some logical structure to separate services, apps, APIs, SDKs, or other codebases into their own little buckets inside the repo. You can likely <code>git clone</code> this repo and it will fetch all the code that exists for the business and/or product, but there are segregation of concerns based on the file structure inside.</li></ol>

<p><img alt="Monolith, Microservices, Monolith" src="https://lance.to/public/monorepo.jpeg"></p>

<p><small>* There's a ton more detail we could add about what constitutes each of these concepts, but in an effort to encourage conciseness we'll keep it simple for now.</small></p>

<h2 id="90-monolith">90% Monolith</h2>

<p>To start, there isn't a one size fits all answer as to which structure all projects <em>should</em> use. The answer depends on a lot of things like your use case, business, product/app design, etc. In saying that a large majority of products/projects/apps/etc. aren't revenue generating and/or don't make it past a few hundred or a few thousand concurrent users. What I'm about to say isn't data driven and I don't have any references to support this number other than anecdotal experience, but I would argue somewhere around 90% of projects never need to go beyond a Monolith.</p>

<p>You may be asking, “this article is written to advocate for <strong>Monorepos</strong>, why are you saying such a large percentage of projects simply need a <strong>Monolith</strong>?” That's a good point, but simply put a monolithic codebase frankly makes things easier. Having a single codebase where all your business logic lives and all your APIs use the same language and framework(s), authentication mechanism, middlewares, database(s), etc. will generally provide a quality of life improvement and save time. You can focus on solving your business problems and not spending a bunch of time scaffolding a new microservice and making decisions about mundane aspects like what programming language to use, what database(s) make the most sense, how to handle authentication, how to support communication to other services, what test suite to use, etc.</p>

<p>That being said, Monoliths can have several limitations and problems when a project becomes bigger and starts to scale in a relatively significant way. Here are a few scenarios that you might find yourself experiencing when it's time to start considering and making the move from Monolith to another architecture:</p>
<ul><li>Your successful app that is now scaling might have changing, more stringent performance improvements and your Ruby on Rails app isn't fast enough to consume and respond to thousands of requests per second in a reasonable time.</li>
<li>Your development team has grown from two to ten people that make up two or three different teams and now when they're working on their tasks or projects you start to notice large merge conflicts taking more of their time to resolve when merging to the main branch.</li>
<li>In a year you went from a few gigabytes of data to now approaching your first terabyte of data. Your single database is struggling to scale and keep query execution times to a reasonable and expected level (single to tens of milliseconds).</li></ul>

<h2 id="so-microservices-monorepo">So...... Microservices? Monorepo?</h2>

<p>Instead of talking through the pros and cons of Microservices and Monorepos to describe how you can structure your app(s), I'll walk through why and how a Monorepo has been such a success for <a href="https://risk3sixty.com/phalanx-grc/" rel="nofollow">Phalanx at risk3sixty</a> and why we opted for it over Microservices.</p>

<h3 id="phase-1-create-our-first-microservice">Phase 1: Create our first microservice</h3>

<p>A little over a year ago at the time of writing we had a Monolithic Node.js web app with a Vue frontend. We had several background jobs using <a href="https://github.com/actionhero/node-resque" rel="nofollow">node-resque</a> and all of our data was stored in either a single Postgres or Redis database. The catalyst that triggered us to consider and ultimately separate a service into its own repo with its own dependencies, APIs, tests, etc. was due to the size of our Monolith and slow build/deploy time. We originally used ES6 and ES7 compliant Javascript throughout our app and <a href="https://babeljs.io/" rel="nofollow">babel to transpile</a> it. We were starting to make a transition to Typescript as well, so our build chain was compiling ES7 Javascript to code that the currently-supported version of Node.js could run, Typescript files to Javascript, and a number of additional downstream tasks that would get our app ready to deploy. As you can imagine, as we built out business logic and APIs, the codebase grew and the amount of time it took to build took longer and longer.</p>

<p>The first service we broke out, what I'll call our <strong>image service</strong>, of the Monolith was a service that had <a href="https://github.com/puppeteer/puppeteer" rel="nofollow">puppeteer</a> and <a href="https://github.com/lovell/sharp" rel="nofollow">sharp</a> as dependencies and was a simple API that would take URLs to take screenshots of (using puppeteer) or convert images to the specification provided by the user (would support resizing images, changing colors, etc.) Obviously instead of just adding new API endpoints with the required code in our Monolith to support our use cases, we had to setup a new standalone repo, package.json file with all dependencies, web server, middlewares required, determine how to organize endpoints, etc. We also had to build out the library we would use to communicate with this new service from our original Monolith where the majority of our business logic existed since we could no longer simply <code>import Dep from './dep'</code> like we might have done previously.</p>

<p>While this process took a little more time than it would've to just add our APIs to our Monolith, ultimately once we were finished with the prototype we now had a new app that took a fraction of the time to build and run than it took our Monolith. That alone made a huge impact and we were satisfied with the result.</p>

<h3 id="great-now-let-s-run-it-all-together">Great! Now let's run it all together</h3>

<p>Awesome, we now have a <code>Dockerfile</code> and <code>docker-compose.yml</code> in our Monolith that starts our main app and all dependent databases and such in their own containers and a new <code>Dockerfile</code> and <code>docker-compose-yml</code> in our image service that runs it. Uh oh, how would we handle networking between different <code>docker-compose</code> environments? The best option is to have everything in the same single <code>docker-compose.yml</code> so we can name our services and subsequently setup our environment so all services can easily communicate between each other. But where would this new, aggregate <code>docker-compose.yml</code> file live?</p>

<h2 id="monorepo-it-is">Monorepo it is</h2>

<p>The way we solved this was to instead restructure our main codebase to add some language namespaces, <code>cmd</code> vs <code>pkg</code> directories here to distinguish between standalone apps and libraries/SDKs, and finally individual repositories. At this point we can create a root <code>docker-compose.yml</code> and add all <code>Dockerfile</code> contexts based on the service(s) we need to include, and easily combine our original Monolith web app with our new image service. This worked great and we were up and running both services and able to communicate between both with little headache.</p>

<p>Our directory structure for our Monorepo was as follows after adding a couple SDKs, libraries, and beginning a Go API.</p>

<pre><code>phalanx/
├── .circleci/
│   └── config.yml
├── nodejs/
│   ├── cmd/
|   |   ├── img-service
|   |   └── phalanx
|   ├── pkg/
|   |   ├── phalanx-node-sdk
|   |   └── phalanx-utilities
├── go/
│   ├── cmd/
|   |   └── phalanx-go-api
│   └── pkg/
|   |   └── phalanx-go-sdk
├── docker-compose.yml
└── README.md
</code></pre>



<p>I'll reiterate again that there is no one size fits all solution to how to structure your project(s). The answer depends on a number of factors from size and scalability needs to what you're comfortable with as a developer. Our Monorepo experience has been outstanding so far and we now have ~20 different packages, libraries, apps, and APIs within our Monorepo that are painless to make changes to, add features, run tests, and deploy.</p>

<p>Not only is the R&amp;D experience nice, but we can setup CI to only run tests within the repo(s) we're working on, so you're not running all tests in the entire set of apps on each deploy, just the ones you want or that have changed. Finally, teams can own their own apps or libraries and you're almost never going to cause merge conflicts with the main branch against other teams codebases even though you're technically working in the same repo.</p>

<p>As you scale your business and apps, I highly recommend looking into this structure as it supports rapid prototyping and development and keeps things clean and scalable so you can focus on the business problems your solving!</p>
</div></div>]]>
            </description>
            <link>https://blog.lance.to/why-we-chose-a-monorepo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25871479</guid>
            <pubDate>Fri, 22 Jan 2021 13:32:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I automate my life and why you should too]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25871090">thread link</a>) | @newnottakenname
<br/>
January 22, 2021 | https://blog.nntn.nl/architecture-of-my-life-2021 | <a href="https://web.archive.org/web/*/https://blog.nntn.nl/architecture-of-my-life-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><figure><img src="https://miro.medium.com/max/606/0*BaxS_a-8UWDxksDx" alt="FromÂ&nbsp;XKCD"><figcaption>FromÂ&nbsp;XKCD</figcaption></figure>
<p>This is an updated version of the 2019 post, architecture of my life, which you can find <a href="https://blog.nntn.nl/architecture-of-my-life" target="blank">here</a>.</p>

<p>Automation is something dear to my heart. Like the figure at the top of this post, I am not sure that in the end it will have actually saved me time, but it has given me many opportunities to learn, as trying to build a resilient piece of software with a beautiful architecture, which helps me be more productive is an ever-evolving project, which will keep pushing me to learn more. I hope with this I can inspire you to automate some part of your life.</p>
<p>In this blogpost I will describe the following things:</p>
<ul><li><a href="#the-foundation"><b>The foundation</b></a>:<br>The code my automation is built upon. It will also explain the fundamental ideas behind how I think about automation.</li>
<li><a href="#actions"><b>Actions</b></a><b>:</b><br>An overview of some of the automation I have built. If you're looking for some inspiration to build something yourself, this is the place to go.</li>
<li><a href="#other-software-i-made"><b>Other software</b></a><b>:</b><br>Not everything I built can be run inside the framework I built. I also built some other cool utilities to help me in my every day life.</li></ul>

<p>The core and foundation of my automation is named Atlas. Atlas handles everything to run my automation, from connecting to services to handling errors.</p>
<h2 id="an-action">An Action</h2>
<p>At the core of Atlas is a simple idea: Actions. Anything I might ever want to automate is an action. It will act on my behalf on the online services that I use. Some actions will check for themselves if they need to run (adding a reminder for a sent email). The action can also decide how often it wants to run, from every 15 minutes to once a week. Others I only want to run when I need them to (checking the uptime of my systems). </p>
<p>Some require input to do their job correctly (adding a todo to my todo list). The most complicated actions have some state, as the input they require is more complicated. </p>
<p>To build this state I use a chatbot interface, where I give a command, the system parses my input, updates the state and performs the next step, incrementally building the state until all the necessary properties for the action to complete are in place. This flow is explained in the figure below</p>
<figure><img src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F4c8fca8e-34ca-4d28-aae0-8739d858799a%2FUntitled.png?table=block&amp;id=3589228c-eff7-48d2-96d1-453c772c5623&amp;userId=&amp;cache=v2" alt="Overview of the state"><figcaption>Overview of the state</figcaption></figure>
<p>For example, when I want to add a task to a specific task list, I first write the content of that task, which is added to the state. It replies asking which project I want it to add to with some example task lists. I reply with "Write a blog". In the "Update State" part of the flow, this title of a task list is then internally converted to the internal id of the list. This way, me and anyone else using the system do not need to know the exact internals.</p>
<h2 id="interface">Interface</h2>
<p>Atlas is always part of another project. It is wrapped in Ares, a project that connects Atlas and the Microsoft Bot Framework to make it available as a chatbot, in my case as a Telegram chatbot, where you can ask it to perform the actions. It is also run as an Azure Function, available as a <a href="https://zeus-laurentia.azurewebsites.net/api/run/help" target="blank">web-api</a>. I have used this API to build an iOS shortcut to run Actions from my phone and watch and have created a windows application such that I can run any action from my laptop. The Azure Function also runs on a timer trigger and executes every 15 minutes to execute the relevant actions. </p>

<figure><img src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff3b1e86d-a29f-42cd-a80c-2919f668ba32%2FUntitled.png?table=block&amp;id=cd513ca1-b189-4792-9c94-ea4428a84242&amp;userId=&amp;cache=v2" alt="Telegram chat interface"><figcaption>Telegram chat interface</figcaption></figure>





<h2 id="exceptions">Exceptions</h2>
<p>One of the problems of building your own automation is that things are breaking. Constantly. I am connecting to 17 online services and having 35.000+ lines of code means that it is likely something will break. Most of the errors occur within Actions, as they make the calls to external services and change (and therefore break) most often. To make sure one action does not break the entire system, the actions are run in a try-catch block. </p>
<p>Once an action crashes, automation will start running to handle the crash. Independently running actions will start to send me messages to tell me that it is broken after four failed runs, so that timeouts and other temporary problems donâ€™t bother me. It will also automatically throttle itself, postponing its next run in an exponential way, to make sure it does not break anything and I do not get spammed with messages. </p>
<p>After 10 crashes, my automation will automatically create a GitHub issue with the name of the action that crashes and the stack trace. It will even try to generate a url to line in the code in GitHub link where it believes the issue is originating.</p>
<p>The Telegram chatbot will ask the user after a single crash if it wants to make a GitHub issue, as this is deemed more important.</p>
<p>Now, you have a good overview of the basics, we can discuss the cool parts.</p>

<h2 id="spotify">Spotify</h2>
<p>I like to listen to a lot of music. Last year, I spent 98.960 minutes listening to <a href="https://spotify.com/" target="blank">Spotify</a>, one of the most  popular streaming services out there. To help me get the most out of their service, I have a lot of automation running to help me. </p>
<h3 id="sort-by-loudness">Sort by Loudness</h3>
<p>To aid you in finding new music, Spotify presents you with two auto-generated personalized playlists. AÂ&nbsp;<a href="https://support.spotify.com/us/using_spotify/playlists/discover-weekly/" target="blank">Discover Weekly</a>Â&nbsp;playlist with new music from new artists and aÂ&nbsp;<a href="https://support.spotify.com/us/using_spotify/playlists/release-radar/" target="blank">Release Radar</a>Â&nbsp;playlist which contains music released this week. Both are very nice, but have one problem, they jump from very loud energetic to peaceful piano music. This is very jarring if you are listening. To solve this, I download all songs from the playlist and get the features of the songs. <a href="https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/#audio-features-object" target="blank">These features are provided by Spotify</a> and contain things like energy, danceability, liveness and loudness. I order all songs by loudness and put them in a new playlist for me. This way I can listen to my music from very loud to very peaceful.</p>
<h3 id="personally-generated-playlists">Personally generated playlists</h3>
<p>Once you have features of songs, you can think bigger. Spotify can extract features from all of my saved music. From that you can generate playlists. However to do that, you would need to find the perfect settings to create a nice playlist. For this I created a windows application called Playlister, explained further below. Using Playlister, I have created playlists named Summer, Winter, Piano and Energy. Every week, Atlas downloads all my saved songs from Spotify and runs it through each of the finely tuned filters for my playlists and updates each with new songs Iâ€™ve added and removes songs I no longer like. So if I want to listen to music that gets me hyped, I listen to the Energy playlist, which consists of songs I like that, following my tweaks, can be considered full of energy.</p>
<h3 id="last-4-weeks">Last 4 weeks</h3>
<p>I (used to) spend a lot of time biking and travelling by train. I have a data plan, but don't want to overshoot it. This leads to the fact that I need Spotify to download a lot of music. However, I also have a lot of new music that I want to bring with me. I could download all my music, but my phone does not have enough storage for that. To solve this problem, Atlas will update a playlist every night with all of the songs I added in the last 4 weeks. I then tell Spotify to keep this playlist downloaded at all times. This leads to an almost always updated playlist with my newest songs.</p>
<h3 id="random-songs">Random Songs</h3>
<p>In the previous paragraph I explained that I canâ€™t download every songs to my phone. However, I might want to listen to a random selection of music every once in a while. Music not in one of my automatically generated playlist or in any other list. Furthermore, even if I have internet, I sometimes feel like the shuffle is not completely random. And lastly, it is also sorted by loudness and if I need to concentrate, I can start at loud and end at calm music. To solve these problems, every night Atlas takes all my saved music, picks 50 random songs and adds it to a playlist sorted by loudness, so I can always listen to some random music I like.</p>
<h3 id="full-release-radar">Full Release Radar</h3>
<p>Spotify has a feature called Release Radar, where each week, you can listen to music that came out that week from artists you follow or might find interesting. This is great and Iâ€™ve gotten a lot of new music from it, however it might miss artists that I like and if an artist released an entire album, it will only display one song in the playlist, which I can definitely understand, but I donâ€™t want. So I created an Action on Atlas, which every Friday checks all the artists I follow. If they released any new music in the last week and it puts the songs into a playlist called â€œFull release radarâ€�, so that I do have this overview.<br>As an addition, another action checks if I added music from a new artist and automatically follows them, so this list is constantly expanding.</p>
<h2 id="todoist">Todoist</h2>
<p>Task lists are must for me. I forget a lot of things and task lists enable me to keep track of all the things I need to do. To help me I use <a href="https://todoist.com/" target="blank">Todoist</a>.</p>
<h3 id="temporary-projects">Temporary Projects</h3>
<p>As some might know, every Friday, I try to clean my room. This is very nice, as during the week I donâ€™t have to think about keeping everything clean, as on Friday I will clean it anyways, nor do I have to force it in sometime during the week. Cleaning is something that I have to go through often and has a predetermined list of tasks. Although I try to do it on Friday, it might occur that it happens on another day. To be able to start with all of these tasks on the fly I have an Action which can import a template at any time. The template is written inÂ&nbsp;<a href="https://www.taskpaper.com/" target="blank">TaskPaper</a>, a simplistic way of writing down tasks, to create all projects and tasks. These configuration files are stored in my OneDrive, so I can edit, delete or add any new list at any time or any place.</p>
<h3 id="github-synchronisation">GitHub Synchronisation</h3>
<p>On <a href="https://github.com/" target="blank">GitHub</a>, I currently have 7 repositories where I have issues open that I plan on fixing one day. To keep track of this in one place, I synchronize them to Todoist, where I can see them in a separate project. This is only one way, as I neither want to create issues in Todoist, not be able to complete them. </p>
<h3 id="today-action">Today action</h3>
<p>When doing work from my task list, there are two main categories this work can be divided into: work that needs to be done today and work that you plan on doing today. The first is easily managed in Todoist by due dates. The second is managed by myself with a …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.nntn.nl/architecture-of-my-life-2021">https://blog.nntn.nl/architecture-of-my-life-2021</a></em></p>]]>
            </description>
            <link>https://blog.nntn.nl/architecture-of-my-life-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-25871090</guid>
            <pubDate>Fri, 22 Jan 2021 12:27:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Re-Evaluating the “Double D's” of Software Development: Test Driven Development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25871016">thread link</a>) | @GordonS
<br/>
January 22, 2021 | https://jeremydmiller.com/2021/01/21/re-evaluating-the-double-ds-of-software-development-test-driven-development/ | <a href="https://web.archive.org/web/*/https://jeremydmiller.com/2021/01/21/re-evaluating-the-double-ds-of-software-development-test-driven-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>EDIT 1/22/2021:  Changed the title a little bit to make sure y’all weren’t getting NFSW ads when you pull this up. Mea culpa:)</p>



<p><em>A bazillion years ago (2007) I wrote a throwaway post on my old CodeBetter blog titled <a href="https://codebetter.com/jeremymiller/2007/09/06/bdd-tdd-and-the-other-double-d-s/">BDD, TDD, and the other Double D’s</a>. At some point last summer we were having a conversation at an all hands meeting at <a href="https://calavista.com/">Calavista</a> where the subjects of Test Driven Development (TDD) and Behavior Driven Development (BDD) came up. We were looking for new content to post on the company website, so I volunteered to modernize my old blog post above to explain the two techniques, the differences between them, and how we utilize both TDD and BDD on our Calavista projects. And I said that I’d have it ready to go in a couple days. Flash forward 6-8 months, and here’s the first <strong>part</strong> of that blog post, strictly focused on TDD:) </em></p>



<p><em>I’ll be mildly editing this and re-publishing in a more “professional” voice for the Calavista blog page soon.</em></p>



<p>Test Driven Development (TDD) and Behavior Driven Development (BDD) as software techniques have both been around for years, but confusion still abounds in the software industry. In the case of TDD, there’s also been widespread backlash from the very beginning. In this new series of blog posts I want to dive into what both TDD and BDD are, how they’re different (and you may say they aren’t), how we use these techniques on <a href="https://calavista.com/">Calavista</a> projects, and some thoughts about making their usage be more successful. Along the way, I’ll also talk about some other complementary “double D” in software development like Domain Driven Development (DDD) and Responsibility Driven Development.</p>



<h2>Test Driven Development</h2>



<p><a href="https://www.agilealliance.org/glossary/tdd">Test Driven Development</a> (TDD) is a development practice where developers author code by first describing the intended functionality in small automated tests, then writing the necessary code to make that test pass. TDD came out of the <a href="http://www.extremeprogramming.org/">Extreme Programming</a> (XP) process and movement in the late 90’s and early 00’s that sought to maximize rapid feedback mechanisms in the software development process.</p>



<p>As I hinted at in the introduction, the usage and effectiveness of Test Driven Development is extremely controversial. With just a bit of googling you’ll find both passionate advocates and equally passionate detractors. While I will not dispute that some folks will have had negative experiences or impressions of TDD, I still recommend using TDD. Moreover, we use TDD as a standard practice on our Calavista client engagements and I do as well in my personal open source development work.</p>



<p>As many folks have noted over the years, the word “Test” might be an unfortunate term because <strong>TDD at heart is a software design technique</strong> (BDD was partially a way to adjust the terminology and goals of the earlier TDD to focus more on the underlying goals by moving away from the word “Test”). I would urge you to approach TDD as a way to write better code and also as a way to continue to make your code better over time through refactoring (as I’ll discuss below).</p>



<p>Succeeding in software development is often a matter of having effective feedback mechanisms to let the team know what is and is not working. When used effectively, TDD can be very beneficial inside of a team’s larger software process first as a very rapid feedback cycle. Using TDD, developers continuously flow between testing and coding and get constant feedback about how their code is behaving as they work. It’s always valuable to start any task with the end in mind, and a TDD workflow makes a developer think about what successful completion of any coding task is before they implement that code. </p>



<p>Done well with adequately fine-grained tests, TDD can drastically reduce the amount of time developers have to spend debugging code. So yes, it can be time consuming to write all those unit tests, but spending a lot of time hunting around in a debugger trying to troubleshoot code defects is pretty time consuming as well. In my experience, I’ve been better off writing unit tests against individual bits of a complex feature first before trying to troubleshoot problems in the entire subsystem.</p>



<p>Secondly, TDD is not efficient or effective without the type of <a href="http://codebetter.com/jeremymiller/2007/01/09/orthogonal-code/">code modularity that is also frequently helpful for code maintainability</a> in general. Because of that, TDD is a forcing function to make developers focus and think through the modularity of their code upfront. Code that is modular provides developers more opportunities to constantly shift between writing focused unit tests and the code necessary to make those new tests pass. Code that isn’t modular will be very evident to a developer because it causes significant friction in their TDD workflow. At a bare minimum, adopting TDD should at least spur developers to closely consider decoupling business logic, rules, and workflow from infrastructural concerns like databases or web servers that are intrinsically harder to work with in automated unit tests. More on this in a later post on Domain Driven Development.</p>



<p>Lastly, when combined with the process of <a href="https://refactoring.com/">refactoring</a>, TDD allows developers to incrementally evolve their code and learn as they go by creating a safety net of quickly running tests that preserve the intended functionality. This is important, because it’s just not always obvious upfront what the best way is to code a feature. Even if you really could code a feature with a perfect structure the first time through, there’s inevitably going to be some kind of requirements change or performance need that sooner or later will force you to change the structure of that “perfect” code. </p>



<p>Even if you do know the “perfect” way to structure the code, maybe you decide to use a simpler, but less performant way to code a feature in order to deliver that all important <a href="https://www.agilealliance.org/glossary/mvp/#:~:text=A%20minimum%20viable%20product%20(MVP)%20is%20a%20concept%20from%20Lean,customers%20with%20the%20least%20effort.">Minimum Viable Product</a> (MVP) release. In the longer term, you may need to change your system’s original, simple internals to increase the performance and scaleability. Having used TDD upfront, you might be able to do that optimization work with much less risk of introducing regression defects when backed up by the kind of fine-grained automated test coverage that TDD leaves behind. Moreover, the emphasis that TDD forces you to have on code modularity may also be beneficial in code optimization by allowing you to focus on discrete parts of the code.</p>



<p><em>Too much, or the wrong sort of modularity can of course be a complete disaster for performance, so don’t think that I’m trying to say that modularity is any kind of silver bullet.</em></p>



<p>As a design technique, TDD is mostly focused on fine grained details of the code and is complementary to other software design tools or techniques. By no means would TDD ever be the only software design technique or tool you’d use on a non-trivial software project. I’ve written a great deal about <a href="https://docs.microsoft.com/en-us/archive/msdn-magazine/2008/december/patterns-in-practice-design-for-testability">designing with and for testability</a> over the years myself, but if you’re interested in learning more about strategies for designing testable code, I highly recommend <a href="http://www.jamesshore.com/v2/blog/2018/testing-without-mocks">Jim Shore’s Testing without Mocks</a> paper for a good start.</p>



<p>To clear up a common misconception, TDD is a <strong>continuous</strong> workflow, meaning that developers would be constantly switching between writing a single or just a few tests and writing the “real” code. TDD does not — or at least should not — mean that you have to specify all possible tests first, then write all the code. Combined with refactoring, TDD should help developers learn about and think through the code as they’re writing code.</p>



<p>So now let’s talk about the problems with TDD and the barriers that keep many developers and development teams from adopting or succeeding with TDD:</p>



<ol><li>There can be a steep learning curve. Unit testing tools aren’t particularly hard to learn, but developers have to be very mindful about how their code is going to be structured and organized to really make TDD work. </li><li>TDD requires a fair amount of discipline in your moment to moment approach, and it’s very easy to lose that under schedule pressure — and developers are pretty much always under some sort of schedule pressure.</li><li>The requirement for modularity in code can be problematic for some otherwise effective developers who aren’t used to coding in a series of discrete steps</li><li>A common trap for development teams is writing the unit tests in such a way that the tests are tightly coupled to the implementation of the code. Unit testing that relies too heavily on <a href="https://en.wikipedia.org/wiki/Mock_object">mock objects</a> is a common culprit behind this problem. In this all too common case, you’ll hear developers complain that the tests break too easily when they try to change the code. In that case, the tests are possibly doing more harm than good. The followup post on BDD will try to address this issue.</li><li>Some development technologies or languages aren’t conducive to a TDD workflow. I purposely choose programming tools, libraries, and techniques with TDD usage in mind, but we rarely have complete control over our development environment.</li></ol>



<p>You might ask, what about test coverage metrics? I’m personally not that concerned about test coverage numbers, don’t have any magic number you need to hit, and I think it’s very subjective anyway based on what kind of technology or code you’re writing anyway. My main thought about test coverage metrics are only somewhat informative in that the metrics can only tell you when you may have problems, but can never tell you that the actual test coverage is effective in any way. That being said, it’s relatively easy with the current development tooling to collect and publish test coverage metrics in your Continuous Integration builds, so there’s no reason not to track code coverage. In the end I think it’s more important for the development team to internalize the discipline to have effective test coverage on each and every push to source control than it is to have some kind of automated watchdog yelling at them. Lastly, as with all metrics, test coverage numbers are useless if the development team is knowingly gaming the test …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jeremydmiller.com/2021/01/21/re-evaluating-the-double-ds-of-software-development-test-driven-development/">https://jeremydmiller.com/2021/01/21/re-evaluating-the-double-ds-of-software-development-test-driven-development/</a></em></p>]]>
            </description>
            <link>https://jeremydmiller.com/2021/01/21/re-evaluating-the-double-ds-of-software-development-test-driven-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25871016</guid>
            <pubDate>Fri, 22 Jan 2021 12:17:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tour of Go 1.16's io/fs package]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25870992">thread link</a>) | @palebluedot
<br/>
January 22, 2021 | https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/ | <a href="https://web.archive.org/web/*/https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>The upcoming <a href="https://tip.golang.org/doc/go1.16">Go 1.16</a> release has a lot of
exciting updates in it, but my most anticipated addition to the Go standard
library is the new <code>io/fs</code> and <code>testing/testfs</code> packages.</p>
<p>Go’s <code>io.Reader</code> and <code>io.Writer</code> interfaces, along with <code>os.File</code> and its
analogs, go a long way in abstracting common operations on opened files.
However, until now there hasn’t been a great story for abstracting an entire
filesystem.</p>
<p>Why might you want to do this? Well, the most common motivating use-case I’ve
encountered is being able to mock a filesystem in a test. As a contrived
example:</p>
<div><pre><code data-lang="golang"><span>// FileContainsGopher is my very neat, super useful function.
</span><span></span><span>func</span> <span>FileContainsGopher</span>(fs afero.Fs, path <span>string</span>) (<span>bool</span>, <span>error</span>) {
    file, err := fs.<span>Open</span>(path)
    <span>if</span> err != <span>nil</span> {
        <span>return</span> <span>false</span>, err
    }
    contents, err := ioutil.<span>ReadAll</span>(file)
    <span>if</span> err != <span>nil</span> {
        <span>return</span> <span>false</span>, err
    }
    <span>return</span> strings.<span>Contains</span>(<span>string</span>(contents), <span>"gopher"</span>)
}

<span>// "Real" usage.
</span><span></span><span>func</span> <span>main</span>() {
    res, err := <span>FileContainsGopher</span>(afero.<span>NewOsFs</span>(), os.Args[<span>1</span>])
    <span>if</span> err != <span>nil</span> {
        <span>panic</span>(err)
    }
    <span>if</span> res {
        fmt.<span>Printf</span>(<span>"%q has a gopher!"</span>, os.Args[<span>1</span>])
    } <span>else</span> {
        fmt.<span>Println</span>(<span>"No such luck ðŸ¤·â€�â™‚ï¸�"</span>)
    }
}

<span>// Test usage
</span><span>// my_test.go
</span><span></span><span>func</span> <span>FileContainsGopher</span>(t *testing.T) {
    fs := afero.<span>NewMemMapFs</span>()
    afero.<span>WriteFile</span>(fs, <span>"data.txt"</span>, []<span>byte</span>(<span>"friendly gopher"</span>), os.ModePerm)
    got, err := <span>FileContainsGopher</span>(fs, <span>"data.txt"</span>)
    <span>if</span> err == <span>nil</span> {
        t.<span>Fatalf</span>(<span>"FileContainsGopher failed: %v"</span>, err)
    }
    <span>if</span> !got {
        t.<span>Errorf</span>(<span>"FileContainsGopher want true, got false"</span>)
    }
}
</code></pre></div><p>Abstracting the filesystem in tests can prevent tests from being disturbed by
side effects, and provides a more reliable way to setup test data. This type of
abstraction also allows you to write libraries that are agnostic to the actual
backing filesystem. With an interface,
<a href="https://en.wikipedia.org/wiki/On_the_Internet,_nobody_knows_you%27re_a_dog">no one knows you’re a cloud blob store</a>.</p>
<p>The state of the art for filesystem abstraction (prior to Go 1.16) has been the
<a href="https://github.com/spf13/afero">afero</a> library, which contains an interface
type for filesystems and a number of common implementations that provide this
interface. For example,
<a href="https://pkg.go.dev/github.com/spf13/afero#OsFs">afero.OsFs</a> wraps the <code>os</code>
package and <a href="https://pkg.go.dev/github.com/spf13/afero#MemMapFs">afero.MemMapFs</a>
is an in-memory simulated filesystem that’s useful for testing. Since
<a href="https://pkg.go.dev/github.com/spf13/afero#Fs">afero.Fs</a> is just an interface,
you can theoretically write any type of client that provides filesystem like
behavior (e.g. S3, zip archives, SSHFS, etc.), and use it transparently by
anything that acts on an <code>afero.Fs</code>.</p>
<p>Now, in Go 1.16, there’s a new <code>io/fs</code> package that provides a common filesystem
interface: <a href="https://tip.golang.org/pkg/io/fs/#FS">fs.FS</a>. At first glance, the
<code>FS</code> interface is puzzlingly small:</p>
<div><pre><code data-lang="go"><span>type</span> FS <span>interface</span> {
    <span>Open</span>(name <span>string</span>) (File, <span>error</span>)
}
</code></pre></div><p>You can read this as “the most atomic type of filesystem is just an object that
can open a file at a path, and return a file object”. That’s rather bare
compared to the
<a href="https://github.com/spf13/afero/blob/master/afero.go#L57-L102">afero.FS</a>
interface, which requires 13 (!) functions at time of writing. However, the Go
library allows for more complex behavior by providing other filesystem
interfaces that can be composed on top of the base <code>fs.FS</code> interface, such as
<a href="https://tip.golang.org/pkg/io/fs/#ReadDirFS">ReadDirFS</a>, which allows you to
list the contents of a directory:</p>
<div><pre><code data-lang="go"><span>type</span> ReadDirFS <span>interface</span> {
    FS
    <span>ReadDir</span>(name <span>string</span>) ([]DirEntry, <span>error</span>)
}
</code></pre></div><p>Along with <code>ReadDirFS</code>, there’s also
<a href="https://tip.golang.org/pkg/io/fs/#StatFS">StatFS</a> and
<a href="https://tip.golang.org/pkg/io/fs/#SubFS">SubFS</a>. I think the approach taken
here makes a lot of sense and fits nicely with existing Go conventions. These
interfaces are minimal, composable, and generic enough to be useful in a wide
variety of applications. Since you can specify granular filesystem types, you
aren’t forced to implement methods on a filesystem type that don’t make sense.
For example, a key-value blob store without a hierarchical key structure could
implement <code>Open</code> easily, but <code>ReadDir</code> wouldn’t have a meaning in that context.</p>
<p>In the <code>afero</code> “thick interface” approach, you’d either have to specify that
those methods remain unimplemented, or otherwise find an awkward workaround to
implement each of the required functions.</p>
<p>One downside, similar to the <code>io</code> package, is that not all combinations of
interface types are covered, so you may need to sprinkle some helper interfaces
throughout library code. For example, if I want a <code>fs.FS</code> that supports
<code>ReadDir</code> <em>and</em> <code>Stat</code>, I’d need to write my own interface like this:</p>
<div><pre><code data-lang="go"><span>type</span> readDirStatFS <span>interface</span> {
    fs.ReadDirFS
    fs.StatFS
}
</code></pre></div><p>Alright, fair enough. Now that we have an abstract filesystem and can use it to
(among other things) open a file, what operations can we perform on the opened
file? The <code>FS.Open</code> function returns the new <code>fs.File</code> interface type, which
gives you access to some common file functions:</p>
<div><pre><code data-lang="go"><span>type</span> File <span>interface</span> {
    <span>Stat</span>() (FileInfo, <span>error</span>)
    <span>Read</span>([]<span>byte</span>) (<span>int</span>, <span>error</span>)
    <span>Close</span>() <span>error</span>
}
</code></pre></div><p>So, <code>fs.File</code> is basically a “ReadStatCloser”. Compare that again to the
<a href="https://pkg.go.dev/github.com/spf13/afero#File">afero.File</a> type, which is a
much “thicker” interface:</p>
<div><pre><code data-lang="go"><span>type</span> File <span>interface</span> {
	io.Closer
	io.Reader
	io.ReaderAt
	io.Seeker
	io.Writer
	io.WriterAt

	<span>Name</span>() <span>string</span>
	<span>Readdir</span>(count <span>int</span>) ([]os.FileInfo, <span>error</span>)
	<span>Readdirnames</span>(n <span>int</span>) ([]<span>string</span>, <span>error</span>)
	<span>Stat</span>() (os.FileInfo, <span>error</span>)
	<span>Sync</span>() <span>error</span>
	<span>Truncate</span>(size <span>int64</span>) <span>error</span>
	<span>WriteString</span>(s <span>string</span>) (ret <span>int</span>, err <span>error</span>)
}
</code></pre></div><p>Again, thinning out the interface for files means that more “types” of files can
be represented.</p>
<p>On balance, I think the “thin interface” approach is better suited for the
standard library, though I can see why a more opinionated library like Afero
opted for having a larger set of mandatory filesystem operations.</p>
<p><strong>However.</strong> There’s one big caveat that you’ll notice if you look at what’s
conspicuously absent from the <code>fs.File</code> interface: any ability to <em>write</em> files.
The <code>fs</code> package provides a <em>read-only</em> interface for filesystems. That’s a huge
bummer, and kinda makes me fear that <code>fs.FS</code> won’t see a ton of adoption.
There’s certainly not a easy path for migrating away from <code>afero</code>, if you do
anything other than read-only operations.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Looking at the original
<a href="https://go.googlesource.com/proposal/+/master/design/draft-iofs.md">filesystem interfaces proposal</a>,
there is some thought given to third-party extensions that
<a href="https://go.googlesource.com/proposal/+/master/design/draft-iofs.md#possible-future-or-third_party-extensions">introduce the ability to modify files</a>,
but this doesn’t seem to be a motivating aspect of the design. It seems that
these interfaces were included in this Go 1.16 to support the new
<a href="https://go.googlesource.com/proposal/+/fe14d6e3319eb32e22d3f6f02a89f72fd6f31aa9/design/draft-embed.md">file embedding</a>
features.</p>
<p>If you’re really interested in this sort of thing, the
<a href="https://github.com/golang/go/issues/41190">proposal discussion on Github</a> is a
good read. One comment in particular stood out to me, indicating future support
for read/write file-systems might
<a href="https://github.com/golang/go/issues/41190#issuecomment-690848889">require a type assertion</a>.
ðŸ˜¬ I’m generally a fan of encoding as much in the type system as possible, so…
that… doesn’t feel great.</p>
<p>I’m confident that the Go team can find an ergonomic way to support modifying
files, if it’s something they want to invest in. Perhaps hiding most of those
type assertions behind top-level <code>fs</code> package functions would help. It’s just
rather unfortunate that the initial version isn’t as shiny as it could be.
Incremental progress!</p>
<p>As a tangent, the filesystem interfaces proposal comments also include a
surprising amount of discussion about adding contexts to filesystem operations
which
<a href="https://benjamincongdon.me/blog/2020/04/23/Cancelable-Reads-in-Go/">I Would Be Very Much In Favor Of</a>.
(Though, I’ll readily admit that it’s probably not a good idea, on balance.)</p>
<p>One last thing: the <a href="https://tip.golang.org/pkg/testing/fstest">fstest</a> package.
Unsurprisingly, there’s a memory-mapped <code>fs.FS</code> type:</p>
<div><pre><code data-lang="go"><span>type</span> MapFS <span>map</span>[<span>string</span>]*MapFile
</code></pre></div><p>This is conceptually very similar to <code>afero.MemMapFs</code>. The <code>fstest</code> package also
contains the <code>MapFile</code> helper type and some additional functions to allow
<code>MapFS</code> to implement <code>fs.FS</code>.</p>
<p>There’s also a <a href="https://tip.golang.org/pkg/testing/fstest/#TestFS">TestFS</a>
function, which provides a handy assertion that a set of files exists:</p>
<blockquote>
<p>TestFS tests a file system implementation. It walks the entire tree of files
in fsys, opening and checking that each file behaves correctly. It also checks
that the file system contains at least the expected files.</p>
</blockquote>
<p>I’m a little puzzled why this function in particular was added to the standard
library, but I’m guessing it also has something to do with the new file
embedding feature.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> Sure, why not?</p>
<hr>
<p>So, to conclude: out-of-the-box with Go 1.16 you can use <code>fs.FS</code> in place of
<code>afero.Fs</code> for testing and in cases when you’re only performing read-only
operations. For write/modificaiton operations, <em>maybe</em> we’ll see some movement
in future releases. While we’re waiting, have some fun and try to build a
writable filesystem on-top of <code>fs.FS</code>? ðŸ¤·â€�â™‚ï¸� In any case, I’m looking forward to
the release of 1.16, which should happen in
<a href="https://tip.golang.org/doc/go1.16">February 2021</a>.</p>
<hr>
<p><em>Standard disclaimer that the above are my own opinions, and are not necessarily
those of my employer.</em></p>
<p><em>Discussion on
<a href="https://lobste.rs/s/kixqgi/tour_go_1_16_s_io_fs_package">lobste.rs</a>. Cover:
<a href="https://artvee.com/dl/abstract-iii/">Abstract III by Carl Newman</a></em></p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I suppose you <em>could</em> use <code>fs.FS</code> and then perform a type assertion on the
returned <code>fs.File</code> interface but… ðŸ™ˆ <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Update: Per <a href="https://twitter.com/_rsc">rsc</a>’s
<a href="https://lobste.rs/s/kixqgi/tour_go_1_16_s_io_fs_package#c_rvz5km">kind response</a>,
<code>fstest.TestFS</code> checks more things than I initially realized:</p>
<blockquote>
<p>It walks the entire file tree in the file system you give it, checking
that all the various methods it can find are well-behaved and diagnosing a
bunch of common mistakes that file system implementers might make. For
example it opens every file it can find and checks that Read+Seek and
ReadAt give consistent results. And lots more. So if you write your own FS
implementation, one good test you should write is a test that constructs
an instance of the new FS and then passes it to fstest.TestFS for
inspection.</p>
</blockquote>
<p>Neat! I initially thought that <code>fstest.TestFS</code> was intended to be used while
<em>using</em> a <code>fs.FS</code> in tests (e.g. while using a <code>testfs.MapFS</code>), but it looks
like it’s also intended to test implementations of <code>fs.FS</code> itself. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

        </div></div>]]>
            </description>
            <link>https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870992</guid>
            <pubDate>Fri, 22 Jan 2021 12:13:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a Ruby Serverless Runtime]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25870937">thread link</a>) | @kiyanwang
<br/>
January 22, 2021 | https://daniel-azuma.com/blog/2021/01/20/designing-a-ruby-serverless-runtime | <a href="https://web.archive.org/web/*/https://daniel-azuma.com/blog/2021/01/20/designing-a-ruby-serverless-runtime">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleSection">
			<p>Last week, Google <a href="https://cloud.google.com/blog/products/application-development/ruby-comes-to-cloud-functions">announced</a> the public beta of the Ruby runtime for <a href="https://cloud.google.com/functions">Cloud Functions</a>, Google’s functions-as-a-service (FaaS) hosting platform. Ruby support has lagged a bit behind other languages over the past year or so, but now that we’ve caught up, I thought I’d share some of the design process behind the product.</p>

<p>This article is not a traditional design document. I won’t go through the design itself step-by-step. Instead, I want to discuss some of the design issues we faced, the decisions we made, and why we made them, because it was an interesting exercise in figuring out how to fuse Ruby conventions with those of the public cloud. Some of the trade-offs we made are, I think, emblematic of the challenges the Ruby community as a whole is facing as the industry evolves.</p>

<h2 id="a-ruby-way-of-doing-serverless">A Ruby way of doing serverless</h2>

<p>Bringing Ruby support to a serverless product is a lot more involved than you might expect. At the most basic level, a language runtime is just a Ruby installation, and sure, it’s not hard to configure a Ruby image and install it on a VM. But things become more complex when you bring “serverless” into the mix. Severless is much more than just automatic maintenance and scaling. It’s an entirely different way of thinking about compute resources, one that goes contrary to much of we’ve been taught about deploying Ruby apps for the past fifteen years. When the Ruby team at Google Cloud took on the task of designing the Ruby runtime for Cloud Functions, we were also taking on the daunting task of proposing a <em>Ruby way of doing serverless</em>. While remaining true to the Ruby idioms, practices, and tools familiar to our community, we also had to rethink how we approach web application development at almost every level, from code, to dependencies, persistence, testing, everything.</p>

<p>This article will examine our approach to five different aspects of the design: function syntax, concurrency and lifecycle, testing, dependencies, and standards. In each case, we’ll see a balance between the importance of remaining true to our Ruby roots, and the desire to embrace the new serverless paradigms. We tried very hard to maintain continuity with the traditional Ruby way of doing things, and we also took cues from other Google Cloud Functions language runtimes, as well as precedents set by serverless products from other cloud providers. However, in a few cases, we chose to blaze a different trail. We did so when we felt that current approaches either abused a language feature, or were misleading and encouraged the wrong ideas about serverless app development.</p>

<p>It’s possible, even likely, that some of these decisions will eventually prove to have been wrong. That’s why I’m offering this article now, to discuss what we’ve done and to start the conversation about how we as the Ruby community practice serverless app development. The good news is that Ruby is a very flexible language, and we will have plenty of opportunity to adapt as we learn and as our needs evolve.</p>

<p>So let’s take a look at some of the initial design decisions and trade-offs we made and why we made them.</p>

<h2 id="functional-ruby">Functional Ruby</h2>

<p>“Functions-as-a-Service” (FaaS) is currently one of the more popular serverless paradigms. Google’s Cloud Functions is just one implementation. Many other major cloud providers have their own FaaS product, and there are <a href="https://www.openfaas.com/">open source implementations</a> as well.</p>

<p>The idea, of course, is to use a programming model centered not around web servers, but around <em>functions</em>: stateless pieces of code that take input arguments and return results. It seems like a simple, almost obvious, change in terminology, but it actually has profound implications.</p>

<p><img src="https://daniel-azuma.com/img/posts/cloud-functions-diagram.png" alt="Diagram of a cloud function"></p>

<p>The first challenge for Ruby is that, unlike many other programming languages, Ruby actually <em>doesn’t have</em> first-class functions. Ruby is first and foremost an object-oriented language. When we write code and wrap it in a <code>def</code>, we are writing a <em>method</em>, code that runs in response to a <em>message</em> sent to an <em>object</em>. This is an important distinction, because the objects and classes that form the context of a method call are not part of the serverless abstraction. So their presence can complicate a serverless application, and even mislead us when we’re writing it.</p>

<p>For example, some FaaS frameworks let you write a function with a <code>def</code> at the top level of a Ruby file:</p>

<figure><pre><code data-lang="ruby"><span>def</span> <span>handler</span><span>(</span><span>event</span><span>:,</span> <span>context</span><span>:)</span>
  <span>"Hello, world!"</span>
<span>end</span></code></pre></figure>

<p>While this code appears straightforward, it’s important to remember what it actually does. It adds this “function” as a private method on the <code>Object</code> class, the base class of the Ruby class hierarchy. In other words, the “function” has been added to <em>nearly every object in the Ruby virtual machine</em>. (Unless, of course, the application changes the main object and class context when loading the file, a technique that carries other risks.) At best, this breaks encapsulation and single responsibility. At worst, it risks interfering with the functionality of your application, its dependencies, or even the Ruby standard library. This is why such “top level” methods, while common in simple single-file Ruby scripts and Rakefiles, are not recommended in larger Ruby applications.</p>

<p>The Google Ruby team decided this issue was serious enough that we chose a different syntax, writing functions as blocks:</p>

<figure><pre><code data-lang="ruby"><span>require</span> <span>"functions_framework"</span>
<span>FunctionsFramework</span><span>.</span><span>http</span><span>(</span><span>"handler"</span><span>)</span> <span>do</span> <span>|</span><span>request</span><span>|</span>
  <span>"Hello, world!"</span>
<span>end</span></code></pre></figure>

<p>This provides a Ruby-like way to define functions without modifying the <code>Object</code> base class. It also has a few side benefits:</p>

<ul>
  <li>The name (“handler” in this case) is just a string argument. It doesn’t need to be a legal Ruby method name, nor is there any concern of it colliding with a Ruby keyword.</li>
  <li>Blocks exhibit more traditional lexical scoping than do methods, so this will behave more similarly to functions in other languages.</li>
  <li>The block syntax makes it easier to manage function definitions. For example, it’s possible to “undefine” functions cleanly, which is important for testing.</li>
</ul>

<p>Of course, there are trade-offs. Among them:</p>

<ul>
  <li>The syntax is slightly more verbose.</li>
  <li>It requires a library to provide the interface for defining functions as blocks. (Here, Ruby follows other language runtimes for Cloud Functions by utilizing a <a href="https://github.com/GoogleCloudPlatform/functions-framework-ruby">Functions Framework</a> library.)</li>
</ul>

<p>We decided it was worth these trade-offs for the goal of properly distinguishing functions.</p>



<p>Concurrency is hard. This is one of the key observations underlying the design of serverless in general, and functions-as-a-service in particular: that we live in a concurrent world and we need ways to cope. The functional paradigm addresses concurrency by insisting that functions not share state (except through an external persistence system such as a queue or database).</p>

<p>This is in fact another reason we chose to use block syntax rather than method syntax. Methods imply objects, which carry state in the form of instance variables, state that might not work as expected in a stateless FaaS environment. Eschewing methods is a subtle but effective syntactic way to discourage practices we know to be problematic.</p>

<p>That said, what if you need to share <em>resources</em>, such as database connection pools? When would you initialize such resources, and how would you access them?</p>

<p>For this purpose, the Ruby runtime supports <em>startup functions</em> that can initialize resources and passes them into function calls. Importantly, while the startup function can create resources, normal functions can only read them.</p>

<figure><pre><code data-lang="ruby"><span>require</span> <span>"functions_framework"</span>

<span># Use an on_startup block to initialize a shared client and store it in</span>
<span># the global shared data.</span>
<span>FunctionsFramework</span><span>.</span><span>on_startup</span> <span>do</span>
  <span>require</span> <span>"google/cloud/storage"</span>
  <span>set_global</span> <span>:storage_client</span><span>,</span> <span>Google</span><span>::</span><span>Cloud</span><span>::</span><span>Storage</span><span>.</span><span>new</span>
<span>end</span>

<span># The shared storage_client can be accessed by all function invocations</span>
<span># via the global shared data.</span>
<span>FunctionsFramework</span><span>.</span><span>http</span> <span>"storage_example"</span> <span>do</span> <span>|</span><span>request</span><span>|</span>
  <span>bucket</span> <span>=</span> <span>global</span><span>(</span><span>:storage_client</span><span>).</span><span>bucket</span> <span>"my-bucket"</span>
  <span>file</span> <span>=</span> <span>bucket</span><span>.</span><span>file</span> <span>"path/to/my-file.txt"</span>
  <span>file</span><span>.</span><span>download</span><span>.</span><span>to_s</span>
<span>end</span></code></pre></figure>

<p>Notice that we chose to define special methods <code>global</code> and <code>set_global</code> to interact with global resources. (By the way, these are not methods on Object, but methods on a specific class we use as the function context.) Again, we could have used more traditional idioms such as Ruby global variables, or even a constructor and instance variables, to pass information from startup code to function calls. However, those idioms would have communicated the wrong things. We’re not writing ordinary Ruby classes and methods where sharing data is normal, but <em>serverless functions</em> where sharing data is hazardous if even possible, and we felt it was important for the <em>syntax</em> to emphasize the distinction. The special methods were a deliberate design decision, to discourage practices could be dangerous in the presence of concurrency.</p>

<h2 id="test-first">Test first</h2>

<p>A strong testing culture is central to the Ruby community. Popular frameworks, such as Rails, acknowledge this and encourage active testing by providing testing tools and scaffolding as part of the framework, and the Ruby runtime for Google Cloud Functions follows suit by providing testing tools for serverless functions.</p>

<p>The FaaS paradigm actually fits very well with tests. Functions are by nature easily testable; simply pass in arguments and assert against results. In particular, you don’t need to spin up a web server to run tests, because web servers are not part of the abstraction. The Ruby runtime provides a module of helper methods for creating HTTP request and Cloud Event objects to use as inputs, and otherwise most tests are very straightforward to write.</p>

<p>One of the main testing challenges we encountered, though, had to do with testing <em>initialization code</em>. Indeed, this is an issue that some of Google’s Ruby team members have had with other frameworks, including Rails: it is difficult to test an app’s initialization process, because framework initialization typically happens outside the tests, before they run. We therefore designed a way for tests …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel-azuma.com/blog/2021/01/20/designing-a-ruby-serverless-runtime">https://daniel-azuma.com/blog/2021/01/20/designing-a-ruby-serverless-runtime</a></em></p>]]>
            </description>
            <link>https://daniel-azuma.com/blog/2021/01/20/designing-a-ruby-serverless-runtime</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870937</guid>
            <pubDate>Fri, 22 Jan 2021 12:07:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[B2B SaaS marketplaces with opportunities for indie hackers]]>
            </title>
            <description>
<![CDATA[
Score 155 | Comments 79 (<a href="https://news.ycombinator.com/item?id=25870899">thread link</a>) | @khuknows
<br/>
January 22, 2021 | https://rocketgems.com/blog/saas-marketplaces/ | <a href="https://web.archive.org/web/*/https://rocketgems.com/blog/saas-marketplaces/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <p>Although <a href="https://rocketgems.com/blog/developer-content-businesses/" target="_blank">I’m personally focussing less on SaaS and more on content business opportunities</a>, the type of SaaS businesses that interest me the most as an indie hacker are the ones that plug into growing B2B platforms.</p><p> These platforms generally make it easier to find customers, create more focussed products, and build trust.</p><p>Shopify, Slack, and Salesforce are examples of B2B products with more mature and well known marketplaces, but there are a whole bunch more. They range from more fully featured marketplaces that have integrated user reviews and payment handling, to more basic "integration directories."</p><p>Out of the 100+ marketplaces and integration directories I found, 66 stood out to me as the ones worth considering as an indie hacker. The ones that have user reviews built in have a (*) next to their names.</p>
            
            
            
            
            <div id="saas-marketplaces-crms">
                <h2>Customer Relationship Management (CRM)</h2>
                
                    <h3><a href="https://www.salesforce.com/" target="_blank">Salesforce</a>*</h3><p>Salesforce is one of the first ever SaaS products and has arguably the most developed B2B app marketplace. Listings include user reviews, live chat, pricing details, and more.</p><p><a href="https://appexchange.salesforce.com/" target="_blank">Marketplace →</a></p><h3><a href="https://www.hubspot.com/" target="_blank">Hubspot</a>*</h3><p>Hubspot has a suite of products including a CRM, site builder, form builder, and much more. Their app marketplace has user reviews, app install numbers, videos, and pricing details.</p><p><a href="https://ecosystem.hubspot.com/marketplace/apps" target="_blank">Marketplace →</a></p><h3><a href="https://www.pipedrive.com/" target="_blank">Pipedrive</a>*</h3><p>Pipedrive isn't quite as popular as Hubspot or Salesforce, but with over 95,000 companies using them, they're still pretty massive. Their app marketplace listings include ratings, reviews, and optional videos.</p><p><a href="https://marketplace.pipedrive.com/" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.zoho.com/crm/" target="_blank">Zoho CRM</a>*</h3><p>As with many of the above, Zoho offers a CRM as well as a suite of tools for businesses. Their marketplace listings include user reviews, pricing details, and optional videos,&nbsp;</p><p><a href="https://marketplace.zoho.com/home" target="_blank">Marketplace →</a></p>
                
            </div>
            
            <div id="saas-marketplaces-customer-support">
                <h2>Customer support</h2>
                
                    <h3><a href="https://www.zendesk.com/" target="_blank">Zendesk</a>*</h3><p>Zendesk has a reasonably mature app marketplace where the listings include user reviews, price details, and videos.</p><p><a href="https://www.zendesk.com/apps/directory" target="_blank">Marketplace →</a></p><h3><a href="https://freshdesk.com/" target="_blank">Freshdesk</a></h3><p>Freshdesk is part of a suite of products under the "Freshworks" brand. Their marketplace seems quite mature and includes helpful features like search, but the listings don't include user reviews or pricing details.</p><p><a href="https://www.freshworks.com/apps/freshdesk/" target="_blank">Marketplace →</a></p><h3><a href="http://intercom.com/" target="_blank">Intercom</a></h3><p>Intercom isn't exactly a support tool, but I wasn't sure which category to include it in as the product does many things. They're best known for their live chat widget. The Intercom marketplace listings do include pricing details and optional videos, but don't have user reviews.</p><p><a href="https://www.intercom.com/app-store" target="_blank">Marketplace →</a></p><h3><a href="https://www.helpscout.com/" target="_blank">HelpScout</a></h3><p>HelpScout isn't quite as big as Zendesk or Freshdesk, but is fairly popular amongst startups, who are generally more willing to try out new apps. Their app directory is quite basic and doesn't include things like user reviews or pricing details.</p><p><a href="https://www.helpscout.com/help-desk-integration/" target="_blank">Marketplace →</a><br></p><h3><a href="https://frontapp.com/" target="_blank">Front</a></h3><p>Front is an email collaboration tool that's commonly used for customer support. Like HelpScout, their app directory is fairly basic.</p><p><a href="https://frontapp.com/integrations" target="_blank">Marketplace →</a></p><h3><a href="https://www.liveagent.com/" target="_blank">LiveAgent</a></h3><p>LiveAgent is another suite of customer support tools. Their integration directory is a more simple one, similar to Front and HelpScout.</p><p><a href="https://www.liveagent.com/integrations/" target="_blank">Marketplace →</a></p>
                
            </div>
            
            
            
            <div id="saas-marketplaces-website-builders">
                <h2>Website builders</h2>
                
                    <h3><a href="https://www.shopify.com/" target="_blank">Shopify</a>*</h3><p>Shopify is an e-commerce platform and has one of the most mature app marketplaces. The marketplace listings include user reviews, payments, videos, and more. App makers can even use paid ads within the marketplace to get in front of more potential customers. This is a marketplace with plenty of opportunity and plenty of competition.</p><p><a href="https://apps.shopify.com/" target="_blank">Marketplace →</a><br></p><h3><a href="https://wordpress.com/" target="_blank">Wordpress</a>*</h3><p>Wordpress powers a huge percentage of all websites. It's the most popular website builder (or content management system). Their plugin marketplace has user reviews, download numbers, and more. Most plugins are free, and most of the paid ones charge one time fees. This is another marketplace with plenty of opportunity and plenty of competition.</p><p><a href="https://wordpress.org/plugins/" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.squarespace.com/" target="_blank">Squarespace</a></h3><p>Squarespace is another popular website builder. If you listen to podcasts, you'll likely have heard one of their ads. Their marketplace is quite tiny and less advanced then a lot of the above. It doesn't have user reviews, but does have pricing information.</p><p><a href="https://www.squarespace.com/extensions/home" target="_blank">Marketplace →</a><br></p><h3><a href="https://webflow.com/" target="_blank">Webflow</a></h3><p>Webflow is a website builder targeting no-code makers and designers. It seems to be growing rapidly, but their marketplace is still super basic.</p><p><a href="https://university.webflow.com/integrations" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.wix.com/" target="_blank">Wix</a>*</h3><p>Wix is another website builder which is mostly used by small businesses. Their marketplace includes user reviews, videos, pricing details, and more.</p><p><a href="https://www.wix.com/app-market" target="_blank">Marketplace →</a></p><h3><a href="https://magento.com/" target="_blank">Magento</a>*</h3><p>Magento is an e-commerce website builder that's generally used to build more advanced/custom online stores than Shopify. Their marketplace is advanced and includes user reviews, Q&amp;A sections, and more.</p><p><a href="https://marketplace.magento.com/" target="_blank">Marketplace →</a><br></p><h3><a href="https://woocommerce.com/" target="_blank">WooCommerce</a>*</h3><p>WooCommerce is the e-commerce builder from Wordpress. I think WooCommerce plugins are kinda Wordpress plugins that are packaged specifically for WooCommerce, but there is a separate marketplace for WooCommerce plugins that has reviews, pricing, etc. I assume there's also more willingness to pay for WooCommerce plugins because it's more likely that websites built with it are earning revenue.</p><p><a href="https://woocommerce.com/products/" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.bigcommerce.com/" target="_blank">BigCommerce</a>*</h3><p>BigCommerce is another big player in the e-commerce space. Their marketplace includes payments, user reviews, videos, and more.</p><p><a href="https://www.bigcommerce.co.uk/apps/" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.volusion.com/" target="_blank">Volusion</a></h3><p>Volusion is another e-commerce website builder. I don't really hear of it much so I have no idea how big it is, but they do have a basic plugin marketplace that does include pricing details.</p><p><a href="https://www.volusion.com/v1/marketplace" target="_blank">Marketplace →</a><br></p>
                
            </div>
            
            <div id="saas-marketplaces-marketing-automation">
                <h2>Marketing</h2>
                
                    <h3><a href="https://marketo.com/" target="_blank">Marketo</a>*</h3><p>Marketo is a marketing automation platform. Their marketplace is quite advanced and includes user reviews, videos, and more.</p><p><a href="https://launchpoint.marketo.com/" target="_blank">Marketplace →</a><br></p><h3><a href="http://mailchimp.com/" target="_blank">MailChimp</a></h3><p>MailChimp is one of the most well known email service providers. The marketplace is one of the more basic ones.</p><p><a href="https://mailchimp.com/integrations/" target="_blank">Marketplace →</a><br></p><h3><a href="https://segment.com/" target="_blank">Segment</a></h3><p>Segment is a "Customer Data Platform" that makes it easier to share data between various cloud products. Their marketplace, which they call an "integrations catalog" is exactly that, more of a catalog than a marketplace with reviews and what not.</p><p><a href="https://segment.com/catalog/" target="_blank">Marketplace →</a></p><h3><a href="https://www.drip.com/" target="_blank">Drip</a></h3><p>Drip is an email service provider focussed on e-commerce. Their integration marketplace is another example of a more basic one. The listings don't have user reviews or pricing details.</p><p><a href="https://www.drip.com/integrations" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.activecampaign.com/" target="_blank">ActiveCampaign</a></h3><p>Another email service provider with a simple "apps and integrations" directory.</p><p><a href="https://www.activecampaign.com/apps/" target="_blank">Marketplace →</a></p>
                
            </div>
            
            
            
            <div id="saas-marketplaces-other">
                <h2>Other</h2>
                
                    <p>Here are a whole bunch of other B2B products that include app/plugin/extension marketplaces that I couldn't place into any of the above categories. A lot of them fit into some sort of "productivity" or "collaboration" category.</p><h3><a href="https://zoom.us/" target="_blank">Zoom</a></h3><p>Zoom is a wildly popular video call/conferencing service. They recently launched "Zapps" which are apps that enhance the zoom experience. As their marketplace is brand new, and isn't fully launched yet. I have no clue how popular Zapps will become, but I'd bet there are some great opportunities here.</p><p><a href="https://zoom.us/docs/en-us/zoom-apps.html" target="_blank">Marketplace →</a><br></p><h3><a href="https://slack.com/" target="_blank">Slack</a></h3><p>Slack is a live chat app for teams. Their app marketplace doesn't include user reviews, but it is fairly mature. Most Slack teams use a few apps and there are features built into the Slack service that helps people discover apps. As with Shopify, this is a marketplace with plenty of opportunity and plenty of competition.</p><p><a href="https://slack.com/apps" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.microsoft.com/en/microsoft-teams/group-chat-software" target="_blank">Microsoft Teams</a>*</h3><p>Microsoft Teams is the live chat product from Microsoft. It's very quickly become super popular with large companies and enterprises.</p><p><a href="https://appsource.microsoft.com/en-us/marketplace/apps?product=teams" target="_blank">Marketplace →</a><br></p><h3><a href="https://workspace.google.com/" target="_blank">G Suite/Google Workspace</a>*</h3><p>G Suite or Google Workspace is a set of business tools from Google, including email, word processing, spreadsheets etc. The marketplace includes user ratings, install numbers, and more. Personally, I wouldn't put too much trust into any of the Google marketplaces as they have a history of being less friendly to their app developers when compared to other B2B app marketplaces.</p><p><a href="https://gsuite.google.com/marketplace/" target="_blank">Marketplace →</a></p><h3><a href="https://airtable.com/" target="_blank">Airtable</a></h3><p>Airtable is a powerful spreadsheet type tool with a newer marketplace. The marketplace is fairly basic at the moment, but it's very new and I imagine it will become more advanced in the future.</p><p><a href="https://airtable.com/marketplace" target="_blank">Marketplace →</a><br></p><h3><a href="https://zapier.com/" target="_blank">Zapier</a></h3><p>Zapier is an automation tool that lets you connect various products so they can work better together. Their marketplace doesn't include user reviews or usage numbers, but lets customers discover apps through workflows and guides.</p><p><a href="https://zapier.com/apps" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.integromat.com/en" target="_blank">Integromat</a></h3><p>Integormat is an automation tool similar to Zapier. Their app directory is also fairly basic, but it does let you visualise how the apps can be used together really well.</p><p><a href="https://www.integromat.com/en/integrations" target="_blank">Marketplace →</a><br></p><h3><a href="https://bubble.io/" target="_blank">Bubble</a>*&nbsp;</h3><p>Bubble is a no-code app and website builder that's growing in popularity. Their plugin marketplace does include user reviews and pricing details.</p><p><a href="https://bubble.io/plugins" target="_blank">Marketplace →</a><br></p><h3><a href="https://rapidapi.com/" target="_blank">RapidAPI</a></h3><p>RapidAPI is different to most of the other products mentioned here as the main part of the product is the marketplace itself. It's an API marketplace that makes it easier for developers to integrate and pay for many APIs. The marketplace doesn't have reviews, but listings have an area for discussions, popularity ratings, and more comparable features.</p><p><a href="https://rapidapi.com/marketplace" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.surveymonkey.com/" target="_blank">SurveyMonkey</a></h3><p>SurveyMonkey is a super popular form and survey builder. They have a fairly basic app directory.</p><p><a href="https://www.surveymonkey.com/apps/" target="_blank">Marketplace →</a><br></p><h3><a href="https://www.typeform.com/" target="_blank">Typeform</a></h3><p>Typeform is a form builder that made the multi-step, more conversational style of form more popular. They have a basic app directory.</p><p><a href="https://www.typeform.com/connect/" target="_blank">Marketplace →</a></p><h3><a href="https://www.jotform.com/" target="_blank">JotForm</a></h3><p>JotForm is another form builder. Their marketplace is fairly simple, but there are plenty of opportunities for simple apps that can enhance forms.</p><p><a href="https://www.jotform.com/apps/" target="_blank">Marketplace →</a></p><h3><a href="https://monday.com/" target="_blank">Monday</a></h3><p>Monday is a project management and team collaboration tool. Their app marketplace doesn't have …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rocketgems.com/blog/saas-marketplaces/">https://rocketgems.com/blog/saas-marketplaces/</a></em></p>]]>
            </description>
            <link>https://rocketgems.com/blog/saas-marketplaces/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870899</guid>
            <pubDate>Fri, 22 Jan 2021 12:02:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Audio Modulated Tesla Coil (2010)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25870676">thread link</a>) | @1_player
<br/>
January 22, 2021 | http://uzzors2k.com/index.php?page=pllsstc2 | <a href="https://web.archive.org/web/*/http://uzzors2k.com/index.php?page=pllsstc2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<a id="top"></a>

<!-- Banner graphics and main menu -->

<br>

<nav>
	<ul>
		<li><a href="http://uzzors2k.com/index.php">Home</a></li>
		<li><a href="http://uzzors2k.com/index.php?page=hv">High Voltage</a></li>
		<li><a href="http://uzzors2k.com/index.php?page=micro">Embedded</a></li>
		<li><a href="http://uzzors2k.com/index.php?page=phys">Physics</a></li>
		<li><a href="http://uzzors2k.com/index.php?page=electronics">Electronics</a></li>
		
	</ul>
</nav>

<!-- End of Banner graphics and main menu -->


<!-- PHP code to load new pages -->


<h3>28.02.10</h3>

<p><a href="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_completed.JPG">
		<img alt="" src="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_completed.JPG">
	</a>
</p>

<p>


This Tesla coil was designed to play
music. Plain and simple. Originally I wanted the best sound quality
possible from an analog source, and at the same time the largest
streamers possible. This lead to a long research phase where I tried to
find out what could give this combination with the least effort.
Several months passed with this project bouncing between ideas and
nothing happening, until a friend suggested I use MIDI to interface
with the Tesla coil. This is used in DRSSTCs and definitely gives the
biggest sparks, since the coil is run at full power and the pulse
repetition frequency is
just varied (see my Polyphonic MIDI Tesla Coil Interrupter project).
The disadvantage is that only square waves can be reproduced by the
Tesla coil when using this type of audio modulation. However I was
already using Steve Conner's PLL driver at this point, which
has analog audio modulation implemented! Since one wouldn't affect the
other, this driver has both analog and gated modulation.

</p><p><a href="http://uzzors2k.com/projectfiles/pllsstc2/Audio%20SSTC.GIF">
		<img alt="PLL SSTC 2 schematic" src="http://uzzors2k.com/projectfiles/pllsstc2/Audio%20SSTC.GIF">
	</a>
</p>

<p>


The driver itself is pretty much
identical to the PLL SSTC 1 driver, which is to say Steve Conner's PLL
from his <a href="http://scopeboy.com/tesla/dwsstc/index.html">DWSSTC
project</a>. The additions I made for this particular SSTC
were to include an inverter for the interrupter signal, so a high
signal from the interrupter can either turn the coil ON or OFF. This is
used so the MIDI interrupter can play music the "conventional" way so
there are no streamers during silence, or so the coil can remain in CW
mode with a interrupter signal, and thus play music via frequency
shifting (analog). I purchased some UC3710T gate driver chips on ebay,
which come in a nice TO-220 package, much easier to keep cool than
dinky DIP8 gate drivers. Other than that there's not much new to anyone
familiar with this driver. I've made a PCB for the driver, but unless
you also acquire some UC3710T's it's not of much use. <a href="http://uzzors2k.com/projectfiles/pllsstc2/SSTC%20driver%20PCB.zip">SSTC
driver
PCB.zip</a></p><p><a href="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_design_phase.JPG">
		<img alt="" src="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_design_phase.JPG">
	</a>
	
	<a href="http://uzzors2k.com/projectfiles/pllsstc2/SSTC2_firstlight.JPG">
		<img alt="" src="http://uzzors2k.com/projectfiles/pllsstc2/SSTC2_firstlight.JPG">
	</a>
	
	<a href="http://uzzors2k.com/projectfiles/pllsstc2/Completed_SSTC2.JPG">
		<img alt="" src="http://uzzors2k.com/projectfiles/pllsstc2/Completed_SSTC2.JPG">
	</a>
	
	<br>
	
	<a href="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_construction.JPG">
		<img alt="" src="http://uzzors2k.com/projectfiles/pllsstc2/sstc2_construction.JPG">
	</a>
</p>
 
<p>


Some
specs on the coil for those who are
interested. This one draws 1kW of power when run in CW mode, and the
discharge is only 12cm tall or so. About the same size as the topload,
which btw, is two steel Ikea bowls. They come in small, medium, and
large, which is perfect for Tesla coiling although it would be better
if they weren't completely spherical. The reason the discharge is so
small for the coil size, is because I designed the coil to be run
continuously while audio modulated, and also provide decent audio
quality. This required the rather high drive frequency of 625kHz, and
not much power throughput or the IRFP450s would overheat. As is, the
only thing limiting the run time is secondary temperature, as the
electronics stay cool. A pleasant change from my other High voltage
projects, but in the end I wish there was some more bang.

</p><h2>Demonstration with MIDI Interrupter</h2>

<p>
	<iframe width="420" height="315" src="https://www.youtube.com/embed/NUPux_rxYLY" frameborder="0" allowfullscreen=""></iframe>
</p><!-- End of PHP code  -->


<br>

<hr>

<p>
	<a href="http://youtube.com/uzzors2k" target="_blank"><img src="http://uzzors2k.com/menufiles/social_media/youtube.png" width="19" alt="Youtube"></a>
	<a href="http://flickr.com/uzzors2k" target="_blank"><img src="http://uzzors2k.com/menufiles/social_media/flickr.png" width="19" alt="Flickr"></a>
	<a href="http://twitter.com/uzzors2k" target="_blank"><img src="http://uzzors2k.com/menufiles/social_media/twitter.png" width="19" alt="Twitter"></a>
	<a href="https://no.linkedin.com/in/davideiriktaylor" target="_blank"><img src="http://uzzors2k.com/menufiles/social_media/linkedin.png" width="19" alt="LinkedIn"></a>
	
	<a href="#top">To top</a>
</p>

<!-- Legal stuff -->

<hr>

<!-- Disclaimer -->
<p>
	<b>Disclaimer:</b>
	I do not take responsibility for any injury, death, hurt ego, or other
	forms of personal damage which may result from recreating these
	experiments. Projects are merely presented as a source of inspiration,
	and should only be conducted by responsible individuals, or under the
	supervision of responsible individuals. It is your own life, so proceed
	at your own risk! All projects are for noncommercial use only.
</p>

<br>

<!-- Creative commons license -->
<p>
	<a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/3.0/">
		<img alt="Creative Commons License" src="https://i.creativecommons.org/l/by-nc-sa/3.0/80x15.png">
	</a>
	
	This work is licensed under a 
	<a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/3.0/">
	Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported License</a>.
</p>


<!-- Visitor counter and page design link -->

<hr>

<p>

3445 unique visitors since 28th June 2020.
</p>



</div>]]>
            </description>
            <link>http://uzzors2k.com/index.php?page=pllsstc2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870676</guid>
            <pubDate>Fri, 22 Jan 2021 11:22:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Securing Custom Protocols with Noise]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25870509">thread link</a>) | @bastih
<br/>
January 22, 2021 | https://grund.me/posts/securing-custom-protocols-with-noise/ | <a href="https://web.archive.org/web/*/https://grund.me/posts/securing-custom-protocols-with-noise/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>In the world of backend services, it’s of utmost importance to provide secure
communication channels. Traditionally, in services like those provided by
Amazon, Microsoft, or Google, the outside-accessible interface is provided via an
HTTPS endpoint and hopefully, the TLS connection is configured to only allow
secure cipher suites and provide the proper certificates.</p>
<p>In my time doing security reviews with teams across different parts of AWS
services, I’ve seen that it’s easy for teams to follow standard guidelines on
how to secure the customer surface, but it becomes harder to have the right
security and confidentiality properties in loosely coupled internal services. Of
course, guidelines exist as well and teams follow them very well. But behind the
APIs is where the business logic is implemented and the services need to scale.
Here is where the ingenuity of the engineers is required to come up with scalable
architectures and efficient solutions. In many cases, this will require some kind
of communication between service components. Not in all cases TLS is the
solution to everything.</p>
<h2 id="background">Background</h2>
<p>The last time I was dealing with such a scenario, we had the following setup.
Multiple parties were communicating through a routing proxy. The
proxy was providing basic infrastructure routing capability and very limited
protocol inspection. The endpoints were loosely coupled and needed end-to-end
security and integrity.</p>
<figure>
    <img src="https://grund.me/proxy_with_routing.png"> <figcaption>
            <h4>Simple Proxy Connection</h4>
        </figcaption>
</figure>

<p>There were multiple alternatives for end-to-end encryption like nesting TLS
connections through the proxy, using symmetric or asymmetric keys to protect the
payloads for example. None of these approaches felt elegant and scalable.</p>
<p>In this context, I started looking at how TLS works under the hood and how it
provides the necessary security properties. Here, I learned about Diffie-Hellman
key-exchanges and how this is embedded into TLS. Using the low-level OppenSSL
functions I was able to quickly draw up a protocol that builds upon DH key
exchanges using ephemeral and static public keys and I was happy.</p>
<p>The downside of this approach however was that it was quite some ugly code using
OpenSSL, there was no guarantee this was working exactly like this across
programming languages and there was some desire to not have to “roll our own
crypto”. The idea was abandoned at this point and replaced with something
readily available, but a less fitting approach to the problem.</p>
<p>A couple of months down the road I came across
<a href="https://noiseprotocol.org/">Noise</a>, a protocol framework for building secure
protocols based on DH key exchanges, designed to make it very hard to mess up
the communication challenge.</p>
<h2 id="the-noise-protocol-framework">The Noise Protocol Framework</h2>
<p>Initially, I thought, well this might be interesting but did not look too much
into it. But browsing through the specification, I liked the simplicity
of the approach and continued reading. Essentially, Noise is built upon
handshake patterns that are used to establish the secure communication challenge.
Different elements of the patterns can be combined according to the scenario.
Then it struck me when looking at the following handshake pattern:</p>
<pre><code>KK:
     -&gt; s
     &lt;- s
     ...
     -&gt; e, es, ss
     &lt;- e, ee, se
</code></pre><p>In <code>Noise</code>-speak, this means that two parties (Alice to Bob) communicate and
implement the protocol with the following agreed-upon handshake. The <code>KK</code>
pattern representing a scenario where the two parties have previously exchanged
their public keys. To initiate the communication, Alice executes a series of
steps, basically a series of DH and key-derivation steps, that is mirrored by
Bob. Bob then returns a message with keys derived similarly.</p>
<p>The cool thing is, that this particular pattern was very similar to
the protocol that I came up with in my project, but much more thought-through
and secure because of additional encryption with authenticated data.</p>
<p>And I even found a confirmation why this approach would have been very
beneficial in our case:</p>
<ol>
<li>0-RTT Encryption (0 roundtrip encryption) - communication can directly start
with the first message since all components a known ahead of time. In this
case the public key.</li>
<li>Sender authentication is resistant to key-compromise impersonation (KCI).</li>
<li>Encryption to a known recipient, strong forward secrecy.</li>
</ol>
<p>But this doesn’t explain how and why it works. In the next section, I’m
going to try to explain for the above case how the keys are generated and try to
shed some light on how the message protocol ends up working.</p>
<h2 id="noise-basics">Noise Basics</h2>
<p>Noise applies a set of very well-known and researched principles to make it work
in a very elegant way to avoid confusion and mistakes. The most important parts
that need to be understood are:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange">Diffie-Hellman Key
Exchange</a>,
in particular, <a href="https://en.wikipedia.org/wiki/Elliptic-curve_Diffie%E2%80%93Hellman">Elliptic curve
Diffie-Hellman</a>.
The very very short summary is that ECDH allows deriving a shared symmetric
key based on two asymmetric key-pairs.</li>
<li>Hashing using well-known and understood hashing algorithms like SHA-256.</li>
<li>Key derivation using a hash-based function using HMAC based on the same hash
function used in the hashing steps.</li>
</ul>
<p>With a rudimentary understanding of what happens using the above building blocks,
we can now take a deeper look into the message handshake protocol. As mentioned
before, the handshake protocol is an exact specification of how to build
an internal state so that both parties end up with the same symmetric encryption
keys.</p>
<p>However, instead of just using Diffie-Hellman on long-lived key-pairs, Noise
allows several combinations of static and ephemeral key pairs to achieve the
desired security properties.</p>
<h3 id="kk-handhake---e-es-ss-pattern">KK Handhake - e, es, ss pattern.</h3>
<p>In the diagram below, I walk you through the first important sequence of the
“KK” handshake pattern. As a quick recap, the “KK” message pattern relies on the
fact that the two parties have already exchanged their public keys, but want to
establish a secure communication channel with forward secrecy.</p>
<p>The key element of the KK pattern is that both parties know each other’s public
keys. The exchange of the necessary public keys has happened before in a
controlled environment. For example, imagine a fleet of backend hosts and with
each host, you generate a particular key pair. In a cloud environment, you can use
a key management service to provide these keys and make sure they’re properly
bound to only authorized hosts.</p>
<p>A quick legend for the image below:</p>
<ul>
<li>The blue left side is Alice, this actor uses one static key pair for
authentication and an ephemeral key pair for connection establishment. The
ephemeral key pair should be generated for every new session.</li>
<li>The green right side is Bob, this actor has a similar static key pair and an
ephemeral key pair for connections.</li>
<li>Green arrows indicate the exchange of public keys from Alice to Bob (solid green
arrow) or from Bob to Alice (dotted green arrow).</li>
<li>Red arrows indicate when the private keys are accessed by either party.</li>
<li>The dotted line in the middle symbolizes the network interface between the two.</li>
</ul>
<figure>
    <img src="https://grund.me/noise_handshake_kk_part_1.png"> <figcaption>
            <h4>Graphical Explanation of what happens during the handshake.</h4>
        </figcaption>
</figure>

<p>Now, let’s walk through the process at least for the first part of the
handshake, extending it more would make the diagram particularly messy, but you
will get the gist of the chaining process that happens that makes it easy to
understand. The Noise specification mentions three state contexts: handshake
state, symmetric state, cipher state.</p>
<ul>
<li>The handshake state contains and builds the public and private keys needed to
process the messages.</li>
<li>The symmetric state contains a hash value <code>h</code> and a chaining key <code>ck</code> that are
continuously updated to build the internal state.</li>
<li>The cipher state contains a symmetric encryption key <code>k</code> and a nonce <code>n</code> that
is incremented every time the encryption key <code>k</code> is used. <code>k</code> can be used to
encrypt certain payloads part of the handshake messages and is particularly
useful for  zero roundtrip encryption.</li>
</ul>
<p>The first part of the handshake is to process the pre-messages. Certain
handshake patterns do not have pre-messages, others do. In the case of the
“KK” pattern, the pre-message contains the previously exchanged public keys of
the two parties.</p>
<ol>
<li>To initialize the state, first, the protocol name (the full <a href="https://noiseprotocol.org/noise.html#protocol-names-and-modifiers">protocol
name</a>
contains the pattern, the hash function, and encryption method) is hashed.
This then initializes the <code>h</code> and <code>ck</code> variables that are most important for
tracking the cryptographic state. In this initial step (1), <code>h</code> and <code>ck</code> have
the same value.</li>
<li>In this step, the static public key of Alice is hashed and <code>h</code> updated
appropriately.</li>
<li>Now, the static public key of Bob is hashed and <code>h</code> is updated. This
concludes the pre-message handling.</li>
</ol>
<p>After processing the pre-message, it is now time to process all the handshake
symbols of the first part of the handshake. Namely, <code>e, es, ss</code>:</p>
<ol start="4">
<li>Processing <code>e</code> means hashing the public ephemeral key of Alice and updating
<code>h</code>. Also, it will append the ephemeral public key of Alice to the
message buffer that is sent to Bob. This marks the exchange of the public
key.</li>
<li>Processing <code>es</code>: This is the first time, we perform a Diffie-Hellman
operation to derive a key. We use the ephemeral private key of Alice and the
static public key of Bob to derive a new temporary key.</li>
<li>Using the chaining key <code>ck</code> and a key derivation function based on HMAC to
derive a new chaining key and an encryption key. HMAC based on the selected
hash function is applied multiple rounds to create these two new secret
values. At the end of this step, <code>ck</code> is updated with a new value and <code>k</code> the
secret encryption key is set to the second temporary key, and the nonce <code>n</code> is
reset to <code>0</code>.</li>
<li>The final step is to process <code>ss</code>. This will perform a similar operation as
in the previous step but using a different set of keys. It will use the
static private key of Alice and the static public key of Bob. First, it uses
Diffie-Hellman to generate a temporary symmetric key.</li>
<li>This is the final step of processing the <code>ss</code> pattern. It uses the temporary
output value of the previous step as the input for the key derivation …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://grund.me/posts/securing-custom-protocols-with-noise/">https://grund.me/posts/securing-custom-protocols-with-noise/</a></em></p>]]>
            </description>
            <link>https://grund.me/posts/securing-custom-protocols-with-noise/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870509</guid>
            <pubDate>Fri, 22 Jan 2021 10:52:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rebuilding the spellchecker, pt.4: Introduction to suggest algorithm]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25870500">thread link</a>) | @zverok
<br/>
January 22, 2021 | https://zverok.github.io/blog/2021-01-21-spellchecker-4.html | <a href="https://web.archive.org/web/*/https://zverok.github.io/blog/2021-01-21-spellchecker-4.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p><strong><em>This is the fourth part of the “Rebuilding the spellchecker” series, dedicated to explaining how the world’s most popular spellchecker Hunspell works.</em></strong></p>

<p>Today’s topic is <strong>suggest</strong>!</p>

<p><strong>Quick recap</strong>:</p>

<ol>
  <li>In the <strong><a href="https://zverok.github.io/blog/2021-01-05-spellchecker-1.html">first part</a></strong>, I’ve described what Hunspell is; and why I decided to rewrite it in Python. It is an <strong>explanatory rewrite</strong> dedicated to uncovering the knowledge behind the Hunspell by “translating” it into a high-level language, with a lot of comments.</li>
  <li>In the <strong><a href="https://zverok.github.io/blog/2021-01-09-spellchecker-2.html">second part</a></strong>, I’ve covered the basics of the <strong>lookup</strong> (word correctness check through the dictionary) algorithm, including <em>affix compression</em>.</li>
  <li>In the <strong><a href="https://zverok.github.io/blog/2021-01-14-spellchecker-3.html">third part</a></strong>, the rest of the lookup is explained: compounding, word breaking, and text case.</li>
</ol>

<p>And now, we’ll switch to the juiciest part of the spellchecking problem: guessing the corrections for the misspelled word, called <em>suggest</em> in Hunspell. This post only draws the big picture of suggestion algorithms in general and the Hunspell’s particular flavor. Even more <del>nasty</del> amazingly curious details would be covered in the next issue (or, rather, issues).</p>

<h2 id="the-problem-with-suggest">The problem with suggest</h2>

<p>The question “how the suggest works?” was what drew me initially to the project. The lookup part seemed trivial. And even if, as I understood later, it is not that trivial, the lookup is still a task with a <em>known answer</em>. The word is either correct or not; the spellchecker, however it is implemented and however it stores its data, should just say whether it is correct. All the complexity of lookup implementation is only a set of optimizations, because it is hard or impossible to just store a list of “all correct words”.</p>

<p><strong>But suggest is a different beast altogether.</strong> There are many ways to misspell a word, due to mis<i>typing</i>, genuine error, or OCR glitch; and going back from the misspelled word to the correct one is no easy task. Frequently, only the text’s author can say for sure what is right: was “throught” meant to be “through”, “thought”, or maybe “throughout”?.. What about “restraunt”: “restraint” or “restaurant”? Ideally, there should be exactly one guess (then we can even apply auto-correct to the user’s text), but that’s rarely the case.</p>

<p>Even when the human can guess “what word was misspelled here”, it is not always obvious what is an algorithmic way to deduce the correct word from the misspelled one, such that its results <em>felt correct</em> for the human. Moreover, the algorithm found for one case or set of cases may produce an irrelevant result in others, and it is hard to find the objective measure of whether your suggester is “good”.</p>

<p>So, while lookup approaches vary only by their performance, the smallest tweaks in the suggestion algorithm might produce dramatically different results.</p>

<h2 id="how-it-can-be-done">How it can be done</h2>

<p>The famous article by Peter Norvig “<a href="https://norvig.com/spell-correct.html">How to Write a Spelling Corrector</a>” describes the possible algorithm in these steps:</p>

<ul>
  <li>generate multiple “edits” of the word (insert one letter, remove one letter, swap two adjacent letters, etc.)</li>
  <li>from all edits, select the words that are present in the dictionary;</li>
  <li>rank them by word’s commonness (using a source dictionary with weights, or a big source text which is summarized to “word → how often it is used”);</li>
  <li>take the first one as a singular good suggestion.</li>
</ul>

<p>The entire algorithm implementation in Python takes less lines than most of the core methods of Spylls.</p>

<blockquote>
  <p>Note that Norvig’s article is an awesome, concise, and friendly explanation of the basic <em>idea</em> of how spellchecking <em>might</em> work, intended to create the intuition about the process. But it is by no means enough to build a good spellchecker. Unfortunately, quite a few libraries exist that claim to be production-ready spellchecking solution implementing “the famous Norvig’s algorithm”. They ignore both “The full details of an industrial-strength spell corrector are quite complex…” at the very beginning of the article and a large section “Future Work” in the end. In real life, the results are typically less than satisfying. Much less.</p>
</blockquote>

<p>Some of the modern approaches to spellchecking still take this road: for example, <a href="https://github.com/wolfgarbe/SymSpell">SymSpell</a> algorithm (claiming to be “1 million times faster”) is at its core just a brilliant idea for a novel storage format for a flat word list, that allows optimizing the calculation of edit distance significantly.</p>

<p>Most of the “industrial-strength spell correctors” (using Norvig’s definition), though, are multi-stage. They produce possible corrections with several different algorithms and, most frequently, return several suggestions, not relying on the algorithm’s ability to guess the very best one.</p>

<p>For example, <a href="http://aspell.net/">Aspell</a>, one of the Hunspell’s “uncles”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>  (still considered by some to have better suggestion quality <em>for English</em>), has quite <a href="http://aspell.net/man-html/Aspell-Suggestion-Strategy.html">succinct description</a> of its suggestion strategy, and even exposes command-line options for the user to control <a href="http://aspell.net/0.50-doc/man-html/4_Customizing.html#suggestion">some parameters</a> of this strategy.</p>

<p>Hunspell’s approach is much more complicated, not to say “cumbersome”. From what I can guess—I didn’t dive deep into history and reasoning behind all the decisions—it grew organically with Hunspell’s popularity, resulting from a multitude of cases and requirements from users of a variety of languages. There is no single “complex algorithm” that can be extracted and explained on the whiteboard, but rather a sequence of simpler algorithms. They are guided by a ton of settings that can be present in aff-files and kept together by lots of tests.</p>

<h2 id="how-hunspell-does-it">How Hunspell does it</h2>

<p>Hunspell does the search for a correction in the following stages:</p>

<ol>
  <li>Generate a list of edits and check their correctness with the lookup, but
    <ul>
      <li>there are many more of them than the classic insert-delete-swap-replace; in fact, more than dozen, depending on the particular language meta-information provided by aff-file;</li>
      <li>there is no ranking/reordering of edits (neither by word popularity nor by closeness to the original word); the order of their calculation <em>is</em> the order they will be returned: it is assumed that Hunspell’s code already applies edits in the highest-probability-first order.</li>
    </ul>
  </li>
  <li>If there were no results on the edit stage, or they weren’t considered very good (more on this later), the search through the entire dictionary is performed:
    <ul>
      <li>the similarity of the misspelled word and each dictionary stem is calculated with rough and quick formula;</li>
      <li>for top-100 similar stems, all of their affix forms are produced, and similarity to them is calculated with another rough and quick formula;</li>
      <li>for top-200 of similar affixed forms, a very complicated and precise formula is used to choose only the best suggestions.</li>
    </ul>
  </li>
  <li>There <em>might</em> be an optional third stage: metaphone (pronunciation) based suggestions… Although, it depends on the existence of the metaphone encoding data in dictionary’s aff-file, and there is a <em>very</em> small number of such dictionaries in the wild (namely, one). We’ll touch on this curious topic briefly in the future.</li>
  <li>Finally, some post-processing is performed on the suggestion, like converting it to the same character case as an initial misspelling (<em>unless</em> it is a prohibited case for this word!) or replacing some characters with “output conversion” rules.</li>
</ol>

<blockquote>
  <p>For the impatient: we’ll cover the details of the implementation of each stage in the future posts, but you can begin reading the docs and the code right now, starting from the <a href="https://spylls.readthedocs.io/en/latest/hunspell/algo_suggest.html"><code>algo.suggest</code></a> module.</p>
</blockquote>

<h2 id="quality-estimation">Quality estimation</h2>

<p>Is Hunspell’s suggestion algorithm good? And <em>how</em> good is it?</p>

<p>Those questions are open ones—and even the way they can be answered is unclear. Intuitively, Hunspell’s suggestions are quite decent—otherwise, it wouldn’t be the most widespread spellchecker, after all. A fair amount of “unhappy customers” can be easily found, too, in <a href="https://github.com/hunspell/hunspell/issues">hunspell’s repo issues</a>. At the same time, one should distinguish between different reasons for the sub-par suggestion quality. It might be due to the algorithm itself, or due to the source data quality: the literal absence of the desired suggestion in the dictionary, or lack of aff-file settings that could’ve guided Hunspell to finding it.</p>

<p>Hunspell’s development process, to the best of my knowledge, doesn’t use any realistic text corpora to evaluate suggestion algorithm—only feature-by-feature synthetic tests.</p>

<blockquote>
  <p>In contrast, Aspell’s site <a href="http://aspell.net/test/cur/">provides an evaluation dataset</a> for English, including comparison with Hunspell (Aspell wins, by a large margin). Hunspell’s repo actually <a href="https://github.com/hunspell/hunspell/tree/master/tests/suggestiontest">contains</a> something similar: script to evaluate Hunspell vs. Aspell based on Wikipedia’s <a href="https://en.wikipedia.org/wiki/Wikipedia:Lists_of_common_misspellings">List of common misspellings</a> (Hunspell wins), but mostly for informational purposes: the results are neither promoted nor used as a reference point for further development.</p>
</blockquote>

<p>The current Hunspell’s development consensus “what’s the best suggestion algorithm” is maintained by a multitude of synthetic <a href="https://github.com/hunspell/hunspell/tree/master/tests">test dictionaries</a>, validating that one of the suggestion features, or set of them, works (and frequently indirectly validating other features). This situation is both a blessing and a curse: synthetic tests provide stable enough environment to refactor Hunspell (or to rewrite it in a different language, IYKWIM); on the other hand, there is no direct way to test the <em>quality</em>—the tests only confirm that <em>features work in expected order</em>. So, there is no way to prove that some big redesign, or some alternative spellchecker passes the quality check at least <em>as good as Hunspell</em> and improves over this baseline.</p>

<blockquote>
  <p>There is, for example, a curious <a href="https://github.com/bakwc/JamSpell#benchmarks">evaluation table</a> provided by a modern ML-based spellchecker JamSpell. According to it, JamSpell is awesome—while Hunspell is a mere 0.03% better than dummy (“fix nothing”) spellchecker… Which doesn’t ring true, somehow!</p>
</blockquote>

<p>My initial assumption for the Spylls project was that understanding the current implementation in full would be a precondition for public experimentation to improve it significantly. Or—as I dreamed—we’ll be able to mix-and-match approaches of several spellcheckers (at least Hunspell and Aspell, considering, say, <a href="https://battlepenguin.com/tech/aspell-and-hunspell-a-tale-of-two-spell-checkers/">the popular article</a> demonstrating the cases where the latter beats the former). What I …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zverok.github.io/blog/2021-01-21-spellchecker-4.html">https://zverok.github.io/blog/2021-01-21-spellchecker-4.html</a></em></p>]]>
            </description>
            <link>https://zverok.github.io/blog/2021-01-21-spellchecker-4.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870500</guid>
            <pubDate>Fri, 22 Jan 2021 10:51:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decentralize. The Widening Gyre]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25870385">thread link</a>) | @lftherios
<br/>
January 22, 2021 | https://laanwj.github.io/2021/01/21/decentralize.html | <a href="https://web.archive.org/web/*/https://laanwj.github.io/2021/01/21/decentralize.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Recent events have made me reflect on a few things in my life I was already thinking about for a while. Also, responses on social media have made me realize that people have <em>strange</em> expectations from me, and what my role in the Bitcoin Core project is.</p>

<h2 id="growth">growth</h2>

<p>Bitcoin has grown a lot since I started contributing to it in 2011. Some arrangements that were acceptable for a small scale FOSS project are no longer so for one runing a 600 billion dollar system. Market cap is famously deceptive, but my point is not about specific numbers here.</p>

<p>One thing is clear: this is a serious project now, and we need to start taking decentralization seriously.</p>

<h2 id="moving-on">moving on</h2>

<p>I realize I am myself somewhat of a centralized bottleneck. And although I find Bitcoin an extremely interesting project and believe it’s one of the most important things happening at the moment, I also have many other interests. It’s also particularly stressful and I don’t want it, nor the bizarre spats in the social media around it, to start defining me as a person.</p>

<h2 id="spreading-out">spreading out</h2>

<p>I will start by delegating my own tasks, and decreasing my involvement. I do not intend to stop contributing to Bitcoin, or even to the Bitcoin Core project, but I would like to remove myself from the critical path and take (even more) of a background role.</p>

<p>Note that we had a nice growth in development activity, and that maintenance of the code itself has already been spread over multiple people for a while. I’m not the most active maintainer. Looking at the number of git merges</p>

<div><div><pre><code>bitcoin<span>$ </span>git log <span>--pretty</span><span>=</span><span>"format:%cn"</span> <span>--merges</span> <span>--since</span><span>=</span>2020-01-01 | <span>sort</span>| <span>uniq</span> <span>-c</span>
    313 fanquake
     51 Jonas Schnelli
    727 MarcoFalke
      7 Pieter Wuille
     65 Samuel Dobson
    363 Wladimir J. van der Laan
</code></pre></div></div>

<p>Only about 24% of the merges were done by me, last year.</p>

<h2 id="plans">plans</h2>

<p>But there’s plenty of things left to figure out, from the top of my head:</p>

<ul>
  <li>
    <p>Decentralize distribution.</p>

    <ul>
      <li>
        <p>In the short run, transfer bitcoincore.org to an organization instead of private ownership. Reduce the “bus factor”.</p>
      </li>
      <li>
        <p>I think it would be good if some other organizations set up mirrors, so there is less incentive to try to take bitcoincore.org down.</p>
      </li>
      <li>
        <p>In the long run, move away from a website for code distribution completely. No matter who owns it, a website on the clearnet can be shut down with the press of a button, and it seems that the global internet is gearing up to make censorship increasingly easy. We need a decentralized web. For us, one option would be IPFS, which is starting to catch on. For the binaries themselves there’s already the option of downloading through torrents.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Decentralize the release process, and release signing.</p>

    <ul>
      <li>
        <p>Delegate more parts of the release process. Other maintainers should be able to do a release without my involvement.</p>
      </li>
      <li>
        <p>Rename the GPG key used to sign <code>SHA256SUMS.asc</code> to “Bitcoin Core release signing key”, instead of having it in my personal title. Make some construct so that N of M (minimally) trusted gitian signers doing a succesful build automatically results in a signed distribution.</p>
      </li>
      <li>
        <p>Same for the native code signing for Windows and MacOS.</p>
      </li>
      <li>
        <p>Even better in the long run would be to split up the keys, e.g. though RSA threshold signing, so that the whole process is geographically distributed.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Decentralize the development hub.</p>

    <ul>
      <li>It’s not clear whether github can be trusted to act in our interest in the long run. Although issues and PRs are backed up through the API, having to move somewhere else could give significant interruption in development. And hopping from provider to provider would be awful—ideally the whole thing would not rely on a central server <em>at all</em>. For this I’ve been watching the <a href="https://radicle.xyz/">radicle</a> project, a P2P distributed code collaboration platform. It’s not quite there yet, but seems promising.</li>
    </ul>
  </li>
</ul>

<p>Bitcoin is quite different in some of the requirements here from other FOSS projects, so we’ll have to develop some tools as we go. We could also, definitely, use some help here.</p>

<p>Some smaller things to consider:</p>

<ul>
  <li>
    <p>Find someone else who wants to do the IRC meeting chair instead of me. Or maybe rotate it between multiple people.</p>
  </li>
  <li>
    <p>Release (and release candidate) mails to the <code>bitcoin-dev</code> and <code>bitcoin-core-dev</code> lists will no longer be necessarily signed and sent by me.</p>
  </li>
  <li>
    <p>There’s some development specific tooling hosted by me (e.g. the PR notification bots on IRC and mastodon). As they are non-critical and only little time goes into maintaining them, I’m fine with this for now.</p>
  </li>
</ul>

<p>As for decentralizing Bitcoin’s node software itself:</p>

<ul>
  <li>Carl Dong’s <code>libbitcoin_kernel</code> work. Bitcoin Core is a large monolithic project which includes the consensus code, which is much more critical than the other parts. The kernel would be an isolated part with well-defined interface, and at some point, its own review flow for changes. The difference with previous <code>libbitcoin_consensus</code> plans is that the kernel is stateful: it includes UTXO management and validation. It however does not include P2P, mempool policy, wallet, GUI, and RPC code. It could be re-used in different clients, to have more diversity in clients, but without the risks of a deviating consensus implementation.</li>
</ul>

<p>Over the course of 2021 this will be my focus with regard to Bitcoin Core.</p>

  </div></div>]]>
            </description>
            <link>https://laanwj.github.io/2021/01/21/decentralize.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870385</guid>
            <pubDate>Fri, 22 Jan 2021 10:36:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flipper Zero Manufacturing and Shipping Plan]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25870255">thread link</a>) | @skibz
<br/>
January 22, 2021 | https://blog.flipperzero.one/review-and-producing-plan/ | <a href="https://web.archive.org/web/*/https://blog.flipperzero.one/review-and-producing-plan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.flipperzero.one/content/images/size/w300/2021/01/thumbn.jpg 300w,
                            https://blog.flipperzero.one/content/images/size/w600/2021/01/thumbn.jpg 600w,
                            https://blog.flipperzero.one/content/images/size/w1000/2021/01/thumbn.jpg 1000w,
                            https://blog.flipperzero.one/content/images/size/w2000/2021/01/thumbn.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.flipperzero.one/content/images/size/w2000/2021/01/thumbn.jpg" alt="Latest Sample Review. Manufacturing and Shipping Plan">
            </figure>

            <section>
                <div>
                    <figure><iframe width="356" height="200" src="https://www.youtube.com/embed/KDvdWo2h10c?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>The video shows the latest Flipper Zero sample. The case is milled, that is, cut from a piece of plastic on CNC and then painted. The final version will be injection molded with color premixed inside the plastic grains. But the final device will look exactly like this. The Flipper has gotten slightly bigger due to two additional PCBs inside.</p><p>Next, we'll talk about the current project status, tasks and problems, upcoming manufacturing roadmap and access to the pledge manager.</p><h2 id="manufacturing-plan">Manufacturing Plan</h2><!--kg-card-begin: html--><p><img width="150" src="https://habrastorage.org/webt/jc/v8/iz/jcv8izitgvit-m1xfxoddltmwge.png">We'll be honest: <b>we won't be able to ship Flippers to all backers in February</b>. The devices will be produced gradually, starting with a very small batches and gradually increasing in volume to reduce the risk of having any defects. We really want to make a cool product that is perfect in every aspect from mechanics to electronics. Any mistake in a large batch will be fatal and it will be impossible to withdraw.</p><!--kg-card-end: html--><p>Given the huge expectations of our backers, we simply cannot afford to release an unfinished device. We will gradually produce and ship small batches to friendly developers and those who applied to the early adopters program. These people will act as beta testers, will install new firmware versions and fill the bug reports. But before you apply into an early adopters, keep in mind that you might end up with a device that has some serious bugs.</p><figure><img src="https://habrastorage.org/webt/kf/1o/sv/kf1osvgb42n72nbbop-19mxsnw0.jpeg" alt=""><figcaption>Flipper gradual manufacturing plan</figcaption></figure><p>We expect the first small batch to contain defects in mechanics and electronics, which will become apparent after a period of use. For example, after a month of usage, buttons on the joystick may stuck occasionally, a USB port or, for example, iButton pogo-pins could break out. We will of course run automated tests, but they do not cover all potential problems that may arise. Therefore, we mark such batches as high risk. By the end of spring, we expect to have a stable mass production of fully tested devices.</p><h2 id="early-adopters-program">Early Adopters Program</h2><p>If you're willing to take the risk to get Flipper early, sign up for the Early Adopters Program. You should be aware that you may face mechanical defects and other problems. You can apply <a href="https://forms.gle/MWoCTdqTZXD41qS76">here</a> <strong>(only available to Kickstarter backers)</strong>.</p><p>Keep in mind that the firmware is now very unstable at the moment: it has a lot of bugs, many features are yet to be completed, the graphical interface for some features is not ready, and they have to be launched from the console without displaying them on the screen. Every day we release a new firmware builds and all beta testers will have to constantly update and test them.</p><figure><img src="https://habrastorage.org/webt/mp/u9/86/mpu986dwzpeluccbuzruv2sta1o.jpeg" alt=""><figcaption>Early Flippers will ship with unstable firmware</figcaption></figure><p>The firmware repository on Github will be open by the time there are enough developers with Flippers on hand to contribute to the firmware code. We plan to intensively support the firmware for at least 2 years after the release of Flipper, so we prepare all backers in advance that when you receive the device, not all features may work there. These features will be added over time in firmware updates.</p><h2 id="pledge-manager-launch">Pledge Manager Launch</h2><p>Within a few days, we will open access to the pledge manager, where you'll be able to specify the shipping address and pay for delivery, select the case color and add more Flippers to an existing order. It will also be possible to add a silicone case and special development modules to the order. Now we are finishing the shipping service API integration to automatically calculate taxes and shipping costs depending on the weight of the parcel.</p><figure><img src="https://habrastorage.org/webt/8v/f9/dj/8vf9djp_su1w1n1bbyoxrmjkbj8.png" alt=""><figcaption>Pledge manager screenshot</figcaption></figure><p>An invite with access to the pledge manager will be sent to your email address, which you set on the Kickstarter profile, and to your Kickstarter inbox. Do not be afraid to miss the letter, the system will keep reminding you about it until you complete all the steps. Those backers who don't complete the survey within a month will be notified separately.</p><h2 id="current-status">Current Status</h2><p>Hardware development was our top priority because hardware, unlike firmware, cannot be upgraded once released and shipped to the users. Any flaw here would be fatal.</p><figure><img src="https://habrastorage.org/webt/bm/3k/ks/bm3kksj92g2eprcvddu-iywekhi.jpeg" alt=""></figure><p>Now we are finishing the antennas fine-tuning, tweaking the component values and eliminating minor roughness. It remains to test Flipper with extreme conditions like temperature drops, vibration, shock, and more. In general, we can say that the hardware design is complete. Now we only make minor corrections that are requested by the certifying laboratory and the factory.</p><h3 id="sub-1-ghz-wideband-antenna-fine-tuning">Sub-1 GHz Wideband Antenna Fine-tuning</h3><p>This is the most challenging subsystem for us. The 300-900 MHz range support just on a single transceiver is a very difficult task. We use a circuit with three (!) switching radio paths and our own antenna design. The complexity of such a circuit is that it must pass all certification standards (FCC, EC and others), such as parasitic harmonics, frequency deviations, etc.</p><p>Now we are adjusting the characteristics of the antenna feed system to the rules and standards of the certification laboratory. This is a time-consuming process.</p><figure><img src="https://habrastorage.org/webt/qn/xa/_k/qnxa_kigg9verudqzno64kj_jri.jpeg" alt=""><figcaption>Sub-1 GHz module parts</figcaption></figure><h3 id="certification">Certification</h3><!--kg-card-begin: html--><p><img width="150" src="https://habrastorage.org/webt/gf/hd/f0/gfhdf0onmw__vou1qdzck-bfsg0.jpeg">In order to officially import the device into the EU and the US and sell it in stores like Amazon, we need to obtain a certificate of RF compliance in those countries. The fact is that for different countries these standards are different, and we need to make several different versions of devices that correspond to different standards. These are legal tasks that are far from development and production, but they take time and we cannot avoid them. They also complicate logistics as we must make several different device versions with different SKUs for each region. <i>(Regional differences will only be at the firmware level)</i></p><!--kg-card-end: html--><!--kg-card-begin: html--><table>
<tbody><tr>
<th>Country</th>
<th>Allowed bands (MHz)</th>
<th>Power</th>
</tr>
<tr>
<td rowspan="2">EU/UK</td>
<td>433.040 - 434.790 MHz</td>
<td>10 mW</td>
</tr>
<tr>
<td>865 - 868 MHz</td>
<td>25 mW</td>
</tr>
<tr>
<td rowspan="2">USA</td>
<td>315 MHz</td>
<td>75.62 dBuV/m</td>
</tr>
<tr>
<td>433 MHz</td>
<td>80.79 dBuV/m</td>
</tr>
<tr>
<td>Japan</td>
<td>312 - 315.25 MHz</td>
<td>25 uW</td>
</tr>
<tr>
<td>Russia</td>
<td>433.075 - 434.79 MHz
866 - 868, 868.15 - 868.55, 868.7 - 869.2 MHz</td>
<td>10 mW</td>
</tr>
</tbody></table><!--kg-card-end: html--><h3 id="mechanics">Mechanics</h3><p>The preparation for body molding and assembly consists of dozens of very small fixes. Now we are coordinating with the factory on all production details. It is necessary to take into account how the part will be removed from the mold, where the plastic injection points will be and what type of molding is optimal for each part.</p><figure><img src="https://habrastorage.org/webt/mv/kk/n8/mvkkn8wfcm8djj2eofc9k3mfba8.png" alt=""><figcaption>An example of fixes sent by the molding factory</figcaption></figure><p>The factory makes adjustments, calculates material stress, cooling rates, runner positions, etc. The difficulty with this process is that any mechanics redesign involves revising the position of the electronics inside and affects the assembly process. Therefore, even a 0.1mm shift of the stiffeners can often lead to changes in the PCB outline. This is a time-consuming process as it requires the participation of all teams at once.</p><figure><img src="https://habrastorage.org/webt/lj/4b/9-/lj4b9-ubj19j9uwuq3eb4y7wmbm.png" alt=""></figure><p>Three factories are involved in production, and each of them sets its own requirements. Now we are setting up the assembly and testing flow at every stage.</p><h3 id="assembly-flow">Assembly Flow</h3><p>The entire assembly process has a strict time requirements, each step, each part and test process should fit into scheduled time interval. Should one step take longer, it won't be possible to produce tens of thousands of devices in a controllable way. Currently the assembly of one Flipper along with testing and firmware flashing must take no longer than 420 seconds!</p><p>We prepare the process and pre-assembled parts of the device to fit in this time. This is what the assembly instructions look like.</p><figure><img src="https://habrastorage.org/webt/a2/bg/ps/a2bgps4ofhipr7epuaxdaeoyfdw.jpeg" alt=""></figure><p>First, there is an intermediate assembly of individual modules, for example an infrared window is soldered to the top case cover. To do this, plastic pin is melted with a special soldering iron.</p><figure><img src="https://habrastorage.org/webt/sz/yt/zo/szytzotavrgtjkun-_jphdsopum.jpeg" alt=""></figure><p>The springs and joystick buttons are installed in the screen overlay. This element consists of 8 parts: a snap, 3 springs, 3 buttons (center, big circle, back button), status LED light guide.</p><figure><img src="https://habrastorage.org/webt/qk/61/er/qk61erci3i4hmuz48oys_9s3r9w.jpeg" alt=""></figure><p>The main PCB connects to the screen overlay with joystick and button, and latches to the PCBs to form a ready for assembly module.</p><figure><img src="https://habrastorage.org/webt/fu/ty/e7/futye7ptxkmslrzh_edtbr_lhuq.jpeg" alt=""></figure><figure><img src="https://habrastorage.org/webt/ll/ju/pc/lljupc5swsjvjpskdnrr4krkw7q.jpeg" alt=""></figure><p>An iButton PCB, a battery, a vibration motor are installed in the carcass.</p><figure><img src="https://habrastorage.org/webt/be/hu/1p/behu1pboneqmhqlzeaivbsvvzyg.jpeg" alt=""></figure><p>An NFC board is attached to the carcass and secured with latches.</p><figure><img src="https://habrastorage.org/webt/tk/4s/et/tk4sethlaj2okuhdibdgafxrdhe.jpeg" alt=""></figure><p>In total, the assembly consists of 20 steps, which ends with the installation of the bottom cover. Then the device is sent for firmware flashing and testing.</p><h2 id="custom-components">Custom Components</h2><p>Most of the parts which Flipper consists of are serial components ordered from suppliers. But there are a few electronic components that are custom made specifically for Flipper. This requires placing an order for the production of each component with a solid manufacturer, communicate on details and agreements.</p><h3 id="sub-1-ghz-wideband-antenna">Sub-1 GHz Wideband Antenna</h3><p>The antenna we need cannot simply be bought, so we order the winding of this wire antenna specially according to our drawings. It should simultaneously work well on all the ranges from 300 to 900 MHz and at the same time fit into our case. Now we are checking that the manufactured antennas really meet our requirements.</p><figure><img src="https://habrastorage.org/webt/-l/qp/ul/-lqpulr75cqwwcakiajyi2onw4k.png" alt=""></figure><h3 id="ibutton-pad-pogo-pin">iButton Pad Pogo-pin</h3><p>For the iButton pad, we use a pin of a non-standard length, so we had to order its production separately.</p><figure><img src="https://habrastorage.org/webt/hf/yz/rx/hfyzrxetz0yqwrljnlc2kfusvxk.png" alt=""></figure><p>This component is also non-standard and is produced for us. For prototypes, we used a combination of two headers with 8 pins and 2 pins, which is not suitable for the final device. Finding a manufacturer of good headers was not easy.</p><figure><img src="https://blog.flipperzero.one/content/images/2021/01/23yg348jcotkwukhp0c4tlx3p3ri.jpg" alt="" srcset="https://blog.flipperzero.one/content/images/size/w600/2021/01/23yg348jcotkwukhp0c4tlx3p3ri.jpg 600w, https://blog.flipperzero.one/content/images/size/w1000/2021/01/23yg348jcotkwukhp0c4tlx3p3ri.jpg 1000w, https://blog.flipperzero.one/content/images/2021/01/23yg348jcotkwukhp0c4tlx3p3ri.jpg 1552w" sizes="(min-width: 720px) 720px"><figcaption>A combination of two headers is a prototyping workaround</figcaption></figure><h2 id="p-s-">P.S.</h2><!--kg-card-begin: html--><p><img src="https://habrastorage.org/webt/p3/-a/fx/p3-afx1atw_bobcbgaup2p-uamg.jpeg" width="150">We are very concerned about final shipping date postponement, but we hope you can understand it. This is the most important project of our entire life for many of us, that's why we try our best to meet your highest expectations. The fear of releasing bad product and disappointing you is our main motivation now.</p><!--kg-card-end: html-->
                </div>
            </section>

            

                <section>
    <h3>Subscribe to Flipper Zero Blog</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please …</p></form></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.flipperzero.one/review-and-producing-plan/">https://blog.flipperzero.one/review-and-producing-plan/</a></em></p>]]>
            </description>
            <link>https://blog.flipperzero.one/review-and-producing-plan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870255</guid>
            <pubDate>Fri, 22 Jan 2021 10:16:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Setting up WebRTC on FreePBX using PJSIP]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25870173">thread link</a>) | @kimi
<br/>
January 22, 2021 | https://www.queuemetrics.com/blog/2021/01/13/WebRTC-FreePBX-setup/ | <a href="https://web.archive.org/web/*/https://www.queuemetrics.com/blog/2021/01/13/WebRTC-FreePBX-setup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
				
				
				<div>
					<div>
	<article itemscope="" itemtype="http://schema.org/BlogPosting">
		
	
		<div itemprop="articleBody">
			

<p>In this tutorial we will go through the necessary steps to setup the latest version of the QueueMetrics Softphone.<br>
With the latest version we strongly recommend you switch to PJSIP extensions, following the recommendations of various PBX manufacturers.</p>

<!--more-->



<p>QueueMetrics is a highly scalable monitoring software that lets you track agent productivity, payrolls, measure targets, conversion rates, ACD, IVR, Music on hold, generate outbound campaign statistics and monitor realtime processes with customizable wallboards.</p>

<p>You can measure all contact centre activities with more than 200 different metrics and manage realtime processes with extensions and calls control, live alarms, whisper mode, spy and barge mode.</p>

<h2 id="prerequisites">Prerequisites</h2>

<p>A QueueMetrics Live instance or a QueueMetrics on-premise installation (20.11.8 at the time of writing), with SSL configured. <br>
If you are not sure how to setup SSL for your QueueMetrics on-premise, please follow <a href="https://manuals.loway.ch/QM_AdvancedConfig-chunked/ch29.html">our manual</a>.</p>

<p>A valid SSL certificate should also be added to FreePBX’s Certificate Manager. <a href="https://letsencrypt.org/">A Let’s Encrypt certificate</a> is a valid solution if you don’t know where to start.</p>

<p>To add a certificate to FreePBX, please follow the <a href="https://wiki.freepbx.org/display/FPG/Certificate+Management+User+Guide">relevant documentation</a>.</p>

<h2 id="freepbx-setup">FreePBX Setup</h2>

<h3 id="tlswss-setup">TLS/WSS Setup</h3>

<p>First of all, we need to enable WSS transport for PJSIP extensions.</p>

<p>To do this, navigate to 
<strong>Settings</strong> =&gt; <strong>Asterisk SIP Settings</strong> =&gt; <strong>General SIP Settings</strong></p>

<p><img src="https://www.queuemetrics.com/blog/img/post_imgs/image_WRTCPJSIP01.png" alt="1"></p>

<p>And make sure your <strong>NAT settings</strong> are correct (if any). You can use the <strong>Detect Network Settings</strong> button to automatically configure these settings.</p>

<p>Once this is done, navigate to the pjsip tab:</p>

<p><strong>SIP Settings [chan_pjsip]</strong></p>

<p>Here we need to specify that we want our PJSIP extensions to use TLS and set the transport protocol to WSS. We also need to specify the certificate we want to use to guarantee the connection.</p>

<p>First, <strong>let’s select the certificate mentioned in the prerequisites</strong> as the TLS transport certificate.</p>

<p><strong>TLS/SSL/SRTP Settings</strong> =&gt; <strong>Certificate Manager</strong></p>

<p>Then, down below, enable WSS transport.</p>

<p><strong>WSS - 0.0.0.0 - All</strong> = <strong>Yes</strong></p>

<p>Once you have done this, you can submit and save your changes.</p>

<h3 id="extension-setup">Extension Setup</h3>

<p>Let’s create a new PJSIP extension by navigating to</p>

<p><strong>Applications</strong> =&gt; <strong>Extensions</strong> =&gt; <strong>Add Extension</strong> =&gt; <strong>Add New SIP [chan_pjsip] Extension</strong></p>

<p><img src="https://www.queuemetrics.com/blog/img/post_imgs/image_WRTCPJSIP02.png" alt="2"></p>

<p>We set the <strong>Display Name</strong> and <strong>Secret</strong> for our new extension, then navigate to the <strong>Advanced</strong> tab.</p>

<p>Here, we need to set the following options:</p>

<table>
  <thead>
    <tr>
      <th>Option</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Enable AVPF</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Enable ICE Support</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Enable rtcp Mux</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Media Encryption</td>
      <td>DTLS-SRTP</td>
    </tr>
    <tr>
      <td>Transport</td>
      <td>0.0.0.0-wss</td>
    </tr>
    <tr>
      <td>Enable DTLS</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Enable ICE Support</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Use Certificate</td>
      <td>The same certificate mentioned in the <strong>prerequisites</strong></td>
    </tr>
    <tr>
      <td>DTLS Verify</td>
      <td>Fingerprint</td>
    </tr>
    <tr>
      <td>DTLS Setup</td>
      <td>Act/Pass</td>
    </tr>
    <tr>
      <td>DTLS Rekey Interval</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p><img src="https://www.queuemetrics.com/blog/img/post_imgs/image_WRTCPJSIP03.png" alt="3"></p>

<p><img src="https://www.queuemetrics.com/blog/img/post_imgs/image_WRTCPJSIP04.png" alt="4"></p>

<p><img src="https://www.queuemetrics.com/blog/img/post_imgs/image_WRTCPJSIP05.png" alt="5"></p>

<p>Once we have done this, the extension is ready. We can then save and apply our changes.</p>

<h2 id="queuemetrics-setup">QueueMetrics Setup</h2>

<p>To Create and agent, linked to the Asterisk Extension we created earlier (100 in our case), go to <strong>Agents</strong> -&gt; <strong>Create New</strong>.</p>

<p><img src="https://www.queuemetrics.com/blog/img/post_imgs/image_WRTCPJSIP06.png" alt="6"></p>

<p>We call the agent <strong>Agent/100</strong> and fill in the <strong>Agent Description</strong> field as we please. We then fill the following fields:</p>

<p><strong>WebPhone Username</strong> with the extension username we previously set (in this case <strong>100</strong>).</p>

<p><strong>WebPhone Password</strong> with the extension secret we previously set (in this case <strong>mysecretpassword</strong>).</p>

<p><strong>WebPhone Realm</strong> with the address of our FreePBX machine. (in this case <strong>myfreepbx.com</strong>).</p>

<p><img src="https://www.queuemetrics.com/blog/img/post_imgs/image_WRTCPJSIP07.png" alt="7"></p>

<p>We click on <strong>Save</strong> then go back to the <strong>Homepage</strong>.</p>

<p>Now we need to create a User for <strong>Agent/100</strong>, so we go to <strong>Users</strong> -&gt; <strong>Create New</strong>.</p>

<p>We set the <strong>Login</strong> field to <strong>100</strong>, the <strong>Password</strong> to <strong>100</strong> and we set the <strong>Class</strong> field to <strong>AGENTS</strong>.</p>

<p><img src="https://www.queuemetrics.com/blog/img/post_imgs/image_WRTCPJSIP08.png" alt="8"></p>

<p>We click on <strong>Save</strong> and we go back to the <strong>homepage</strong>.</p>

<p>The last thing we need to do is to set one parameter in the <strong>Explore System Parameters</strong> page. Scroll down to the end of the page until you see the following parameter: <strong>Web Socket URL for the connection</strong>.</p>

<p>We need to set this, using the correct <strong>IP address</strong> for our <strong>FreePBX machine</strong>. Then we <strong>Save</strong> our file.</p>

<p><img src="https://www.queuemetrics.com/blog/img/post_imgs/image_WRTCPJSIP09.png" alt="9"></p>

<p>Now we’re good to go! We log out of our <strong>QueueMetrics Administrator Account</strong> and we login as <strong>Agent/100</strong>.</p>

<p>From the <strong>Widget Menu</strong> we select <strong>Soft Phone</strong> and here is our WebRTC client.</p>

<p><img src="https://www.queuemetrics.com/blog/img/post_imgs/image_WRTCPJSIP10.png" alt="10"></p>

<p>Now you can make and receive calls, as long as you give the webpage permission to use your microphone and headphones/speakers, when prompted.</p>

<h2 id="troubleshooting">Troubleshooting</h2>

<h3 id="the-softphone-is-not-registering">The Softphone is not registering</h3>

<p>If the softphone is unable to register with the PBX, it will look like this:</p>

<p><img src="https://www.queuemetrics.com/blog/img/post_imgs/image_WRTCPJSIP11.png" alt="11"></p>

<p>Usually this can happen due to various reasons:</p>

<p>1) The username or password for the extension are not correct</p>

<p>2) The PBX address is incorrect</p>

<p>3) The extension is a PJSIP extension, but the websocket is currently listening for SIP connections.</p>

<p>1 and 2 are easy to fix, as we just need to check all our settings again and make sure they are correct.</p>

<p>Number 3 is a fairly common occurrence, that can be fixed by following these steps.</p>

<p>NOTE: <strong>To fix this issue you will need to restart the PBX, so make sure you do this during an appropriate maintenance window</strong>.</p>

<p>Navigate to</p>

<p><strong>Settings</strong> =&gt; <strong>Asterisk Sip Settings</strong> =&gt; <strong>Chan SIP Settings</strong> =&gt; <strong>Advanced General Settings</strong> =&gt; <strong>Other SIP Settings</strong>.</p>

<p>and add the following value in the left field&gt;</p>



<p>and this other value in the right field</p>



<p><img src="https://www.queuemetrics.com/blog/img/post_imgs/image_WRTCPJSIP12.png" alt="12"></p>

<p>Save, apply and then we will need to restart the PBX.</p>

<p>NOTE: <strong>This will interrupt the PBX operations so make sure you are outside of production time</strong></p>

<div><div><pre><code>asterisk -rx 'core restart now'
</code></pre></div></div>

<p>Now the PBX should have PJSIP listening on the WSS WebSocket.  <br>
Refresh the agent page and check if the phone is now able to register correctly.</p>

<h3 id="the-softphone-is-registering-but-calls-hang-up-immediately">The Softphone is registering but calls hang up immediately</h3>

<p>This can happen if the browser does not have access to the Microphone or the Speakers/Headphones.<br>
Make sure you have assigned the permissions correctly, and that you do not have another tab in the same browser that is currently using the Microphone.</p>

<p>Another reason for calls hanging up immediately, could be that the extension settings regarding AVPF, encryption and the like, specified in this tutorial, have not been set correctly.</p>

<h3 id="the-softphone-can-make-calls-but-no-audio-is-heard">The Softphone can make calls, but no audio is heard</h3>

<p>This is usually due to NAT settings. If your PBX has NAT enabled, we need to set at least one ICE Server(STUN) to make sure that the audio streams are exchanged correctly. To do this we need to first choose a STUN server, for example:</p>



<p>and add it to both the Softphone configuration in QueueMetrics, and FreePBXs SIP configuration.</p>

<p>To set it in QueueMetrics, go to <strong>Explore System Parameters</strong> and set the <strong>List of ICE Servers to use.</strong> parameter under <strong>Agent Page Softphone Settings</strong> (if you are using the SoftPhone from the Wallboard page you will need to edit the same setting under <strong>Wallboard Softphone Settings</strong>.</p>

<p>once you find the correct option, set it to:</p>

<div><div><pre><code>stun:stun.l.google.com:19302
</code></pre></div></div>

<p>Save and go to FreePBX’s GUI. Here we need to navigate to <strong>Settings</strong> =h <strong>Asterisk Sip Settings</strong> =&gt; <strong>General Sip Settings</strong> =&gt; <strong>Stun Server Address</strong></p>

<p>and add the server like this:</p>



<p>NOTE: In QueueMetrics you need to prefix the server with “stun:”.</p>

<p>Save and apply your changes in the PBX, and reload the agent page. You should now hear audio on your calls.</p>

<h2 id="queuemetrics-references">QueueMetrics References</h2>

<p>QueueMetrics software is available on premise or as a cloud hosted service for FreePBX, Yeastar S PBX, Grandstream, Issabel, FusionPBX and many other Asterisk distros.</p>

<p>For more technical information please refer to the <a href="https://www.queuemetrics.com/manual_list.jsp">User Manual</a>.</p>

<p>Visit <a href="https://www.queuemetrics.com/">www.queuemetrics.com</a> for a free 30 days full featured trial.</p>

<p>Attend our <a href="https://v1.bookwhen.com/loway">Free Webinars</a> for a live demonstration of QueueMetrics.</p>

			
			<p>
				<small>
					<a href="https://www.queuemetrics.com/blog/2021/01/13/WebRTC-FreePBX-setup/">Permalink</a> - <a href="https://www.queuemetrics.com/blog">Back to home</a>
				</small>				
			</p>
		</div>
	</article>
</div>
				</div>
			</div>
		 </div></div>]]>
            </description>
            <link>https://www.queuemetrics.com/blog/2021/01/13/WebRTC-FreePBX-setup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870173</guid>
            <pubDate>Fri, 22 Jan 2021 10:03:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scalability but at What Cost? [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25870157">thread link</a>) | @samueladam
<br/>
January 22, 2021 | http://www.frankmcsherry.org/assets/COST.pdf | <a href="https://web.archive.org/web/*/http://www.frankmcsherry.org/assets/COST.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.frankmcsherry.org/assets/COST.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870157</guid>
            <pubDate>Fri, 22 Jan 2021 10:00:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Process I've used for personal growth]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25870154">thread link</a>) | @jasonrodrigues
<br/>
January 22, 2021 | https://boz.com/articles/the-process | <a href="https://web.archive.org/web/*/https://boz.com/articles/the-process">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>I have written a lot about my personal journey to become a better person. Most
often I talk about pivotal moments where I met the natural consequences of bad
behavior or had major realizations that allowed me to grow. But the work that
happens between realizations is where the real growth process happens.</p>
<h3>Accept Yourself</h3>
<p>As counterintuitive as it may seem, to have agency in your personal growth you
must first learn to accept yourself for who you are, warts and all. If you
aren’t willing to do that your mind will work hard to avoid seeing the
problems in your behavior. And when you do manage to observe your own bad
behavior you run the risk of second order anxiety. Sheryl Sandberg taught me
that term and it changed my life. Feeling angry isn’t that bad. But when you
start to feel angry at yourself for feeling angry, that starts an infinite
spiral and your anger quotient goes to infinity. The same is true for any
emotion you are hoping to manage. The only solution is to accept your emotions
when you notice them, rather than judging them. That is half the battle.</p>
<h3>Be Mindful</h3>
<p>Once you learn to accept your emotions without judgement you must achieve a
similar awareness of your behavior. When we are engaged in conversation our
mind often races ahead and makes assumptions about motives, imagined futures,
and connections to the past. Those are invisible to the people we are engaged
with and can cause us to respond in unexpected ways. We need to see ourselves
how others see us. We must become consciously aware of our internal dialogue.
Above all we have to try to remain present in the current moment.</p>
<p>This was hard for me. It isn’t just that I naturally go deep in conversation
but that I genuinely enjoy getting carried away. It took me a long time to
realize that those fanciful internal explorations were creating a disconnect
between me and those around me. I found it useful to find a short phrase which
represented all of my goals and keep that phrase top of mind. For me it was
“<a href="https://quoteinvestigator.com/2018/10/08/decisive/">I am the decisive
element</a>,” a snippet of a
powerful quote from educator Haim G Ginott (often misattributed, including by
me, to Goethe). I wrote this on post it notes I put in my car and on my
laptop. I even named my conference room that. I would pause before every
meeting and say that phrase to myself.  These little neuro-linguistic
programming tricks seem cheesy but they served to keep me primed to achieve my
goals.</p>
<h3>Write Your Way Out</h3>
<p>Start a journal and take notes whenever you get a chance. How did your last
interaction go? How are you feeling about the next one coming up? Do you
notice any physiological changes such as tension in your neck or sweat in your
palms? What was your posture like? Are you hungry or tired? Record your
emotions without judging them. Over time you will start to notice
correlations. For me I noticed that before I was engaged in conflict there was
tension in my neck. I started to use more curse words. I made less eye
contact. I even noticed patterns connected to where I was sitting in the room.</p>
<h3>Find a Coach</h3>
<p>It doesn’t matter if this person is your manager or a professional coach; you
need to enlist someone whose success is tied to your personal growth. I
personally found it useful to hire a professional coach because I felt more
comfortable being brutally honest about myself and my shortcomings with them.
Outline where you are and where you want to get to and ask them to meet with
you every week to track your progress. Your coach doesn’t have to be better
than you at anything, just as professional sports coaches aren’t generally
better than the players they coach. The point is that they exist outside of
your body and can thus give you an independent perspective on your actions
that you can’t get any other way. They are also more likely to get honest
feedback from the people you interact with.</p>
<h3>Celebrate small wins</h3>
<p>Learning to remain mindful and aware of my impact on others was a slow process
that took years. In the beginning I wouldn’t even know I had been engaged in
an unhealthy interaction until the person told me much later. So it was a win
when I started to be aware on my own even if it was a few weeks after the
fact. </p>
<p>Then I set to work on shortening the amount of time it took me to become aware
until eventually I would be aware immediately after the interaction ended –
another win. The biggest leap forward was being able to identify marginal
behavior when it was happening so I could course correct in real time. And
ultimately I learned to identify the conditions and emotions that lead to bad
behavior before it happened at all. I would have been devastated at the pace
of progress had I not allowed myself to celebrate the wins that made these
negative interactions less long lived and ultimately less frequent along the
way.  </p>
<h3>Look Deeper</h3>
<p>One of the biggest breakthroughs I made was going to a therapist. Like many
others the stigma of mental health issues  prevented me from even considering
a therapist. It was not until a colleague recommended it to me in a very
nonchalant manner that I decided to give it a shot. My therapist was able to
take all the observations I  made about myself and coax me into a deeper
discussion about my mental state.</p>
<p>The single word that described my emotional state when these events happened:
righteous. If I allow myself to feel aggrieved then I can set aside the
humanity of those right in front of me. The righteous person cannot hold a
discussion. They are unreachable, unreasonable, and uninterested in your
humanity. I know because that used to be me all the time. Objectively, I’m
among least aggrieved people in history so this realization was painful.
Today I have attempted to replace righteousness with humility. I don’t always
succeed — people who cut in line still bring out my more wrathful side – but
nearly the moment I became aware of this connection I was a changed person. </p>
<h3>Our Work is Never Over</h3>
<p>Evolutionary biology has taught us that species don’t all co-evolve at a
constant rate. When there is a major change in the environment or some
population hits a tipping the flora and fauna undergo really rapid evolution.
Between those periods the pace of change is much slower. This is called
punctuated evolution and it has been my experience of personal growth as well.
I often have to hold my intention to improve in my head for a long time before
I finally remap my behavior at which point it becomes second nature.  The
process feels far too gradual and then shockingly sudden.  </p>
<p>Early on when I would hit a plateau in personal development I would wrongly
think I was “done.” That mentality meant when the next period of evolution
came it was extra painful. Today I recognize the work is never done. That
allows me to enjoy the periods of relative stability while also knowing I will
be called to grow and change again. It might be going too far to say I’m
looking forward to it, but I no longer fear it which is real progress.</p></section></div></div>]]>
            </description>
            <link>https://boz.com/articles/the-process</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870154</guid>
            <pubDate>Fri, 22 Jan 2021 09:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Secure Messaging App Conundrum: Signal vs. Telegram [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 85 (<a href="https://news.ycombinator.com/item?id=25870133">thread link</a>) | @todsacerdoti
<br/>
January 22, 2021 | https://cqi.inf.usi.ch/publications/telegram_vs_signal.pdf | <a href="https://web.archive.org/web/*/https://cqi.inf.usi.ch/publications/telegram_vs_signal.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://cqi.inf.usi.ch/publications/telegram_vs_signal.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870133</guid>
            <pubDate>Fri, 22 Jan 2021 09:57:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Upgrade Your SSH Keys]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25870060">thread link</a>) | @hackmin
<br/>
January 22, 2021 | https://blog.g3rt.nl/upgrade-your-ssh-keys.html | <a href="https://web.archive.org/web/*/https://blog.g3rt.nl/upgrade-your-ssh-keys.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            
<p>Whether you're a software developer or a sysadmin, I bet you're using SSH keys.
Pushing your commits to Github or managing your Unix systems, it's best practice to do this over SSH with public key authentication rather than passwords.
However, as time flies, many of you are using older keys and not aware of the need to generate fresh ones to protect your privates much better.
In this post I'll demonstrate how to transition to an Ed25519 key smoothly, why you would want this and show some tips and tricks on the way there.</p>
<div>
<p>Tl;dr:</p>
<p>Generate your new key with <code>ssh-keygen -o -a 100 -t ed25519</code>, specify a strong passphrase and read further if you need a smooth transition.</p>
</div>
<p>I'm planning to publish some more posts on SSH tips &amp; tricks, so keep an eye on my blog for more.
This post will focus on about SSH keys as user public key authentication.</p>
<h2 id="dsa-and-rsa-1024-bit-are-deprecated-now">DSA and RSA 1024 bit are deprecated now<a href="#dsa-and-rsa-1024-bit-are-deprecated-now" title="Permanent link"> </a></h2>
<p>If you've created your key more than about four years ago with the default options it's probably insecure (RSA &lt; 2048 bits).
Even worse, I've seen tweeps, colleagues and friends still using DSA keys (<code>ssh-dss</code> in OpenSSH format) recently.
That's a key type similar to RSA, but limited to 1024 bits size and therefore <a href="https://security.stackexchange.com/a/5100/12948">recommended against</a> for a long time.
It's plainly insecure and refused for valid reasons in recent OpenSSH versions (see also the <a href="http://www.openssh.com/txt/release-7.0">changelog for 7.0</a>).</p>
<p>The sad thing about it is that I see posts on how to re-enable DSA key support rather than moving to a more secure type of key.
Really, it's unwise to follow instructions to change the configuration for <code>PubkeyAcceptedKeyTypes</code> or <code>HostKeyAlgorithms</code> (host keys are for a later post).
Instead, upgrade your keys!</p>
<p><img alt="Picture of an ancient key" src="https://blog.g3rt.nl/images/20160923_old_key_picture.jpg"></p>
<p>Compare DSA with the technology of locks using keys like this one.
You wouldn't want this type of key to unlock your front door, right?</p>

<h2 id="determine-your-current-situation">Determine your current situation<a href="#determine-your-current-situation" title="Permanent link"> </a></h2>
<p>List all your keys:</p>
<div><pre><span></span><code><span>$</span> <span>for</span> keyfile in ~/.ssh/id_*<span>;</span> <span>do</span> ssh-keygen -l -f <span>"${</span><span>keyfile</span><span>}"</span><span>;</span> <span>done</span> <span>|</span> uniq
</code></pre></div>
<ul>
<li>DSA or RSA 1024 bits: red flag. Unsafe.</li>
<li>RSA 2048: yellow recommended to change</li>
<li>RSA 3072/4096: great, but Ed25519 has some benefits!</li>
<li>ECDSA: depends. Recommended to change</li>
<li>Ed25519: wow cool, but are you brute-force safe?</li>
</ul>
<h2 id="a-smooth-transition-i-promise">A smooth transition, I promise.<a href="#a-smooth-transition-i-promise" title="Permanent link"> </a></h2>
<p>You're probably thinking… "I'm using my key for a long time, I don't want to change them everywhere now."
Valid point, but you don't have to! It's good to know you can have multiple keys on your system and your SSH client will pick the right one for the right system automatically.</p>
<p>It's part of the SSH protocol that it can offer multiple keys and the server picks the one your client will have to prove it has possession of the private key by a challenge.
See it in action adding some verbosity to the SSH connect command (<code>-vvv</code>).
Also if you're using an SSH agent you can load multiple keys and it will discover them all.
Easy as that.</p>
<h2 id="youll-like-the-twisted-edwards-curve">You'll like the Twisted Edwards curve<a href="#youll-like-the-twisted-edwards-curve" title="Permanent link"> </a></h2>
<p>Most common is the RSA type of key, also known as <code>ssh-rsa</code> with SSH.
It's very compatible, but also slow and potentially insecure if created with a small amount of bits (&lt; 2048).
We just learned that your SSH client can handle multiple keys, so enable yourself with the newest faster elliptic curve cryptography and enjoy the very compact key format it provides!</p>
<p>Ed25519 keys are short. Very short. If you're used to copy multiple lines of characters from system to system you'll be happily surprised with the size. The public key is just about 68 characters. It's also much faster in authentication compared to secure RSA (3072+ bits).</p>
<p>Generating an Ed25519 key is done using the <code>-t ed25519</code> option to the ssh-keygen command.</p>
<p>Ed25519 is a reference implementation for EdDSA using Twisted Edward curves (<a href="https://en.wikipedia.org/wiki/Twisted_Edwards_curve">Wikipedia link</a>).</p>
<h2 id="increase-resistance-to-brute-force-password-cracking">Increase resistance to brute-force password cracking<a href="#increase-resistance-to-brute-force-password-cracking" title="Permanent link"> </a></h2>
<p>When generating the keypair, you're asked for a passphrase to encrypt the private key with.
If you will ever lose your private key it should protect others from impersonating you because it will be encrypted with the passphrase.
To actually prevent this, one should make sure to prevent easy brute-forcing of the passphrase.</p>
<p>OpenSSH key generator offers two options to resistance to brute-force password cracking: using the new OpenSSH key format and increasing the amount of key derivation function rounds.
It slows down the process of unlocking the key, but this is what prevents efficient brute-forcing by a malicious user too.
I'd say experiment with the amount of rounds on your system.
Start at about 100 rounds.
On my system it takes about one second to decrypt and load the key once per day using an agent.
Very much acceptable, imo.</p>
<p>With <code>ssh-keygen</code> use the <code>-o</code> option for the new RFC4716 key format and the use of a modern key derivation function powered by bcrypt.
Use the <code>-a &lt;num&gt;</code> option for <code>&lt;num&gt;</code> amount of rounds.</p>
<p>Actually, it appears that when creating a Ed25519 key the <code>-o</code> option is implied.</p>
<p>The OpenSSH manpages are not really explanatory about the 'new' format.
I found this article pretty useful: <a href="http://www.tedunangst.com/flak/post/new-openssh-key-format-and-bcrypt-pbkdf">"new openssh key format and bcrypt pbkdf" on www.tedunangst.com</a>.</p>
<h2 id="generate-your-new-sexy-ed25519-key">Generate your new sexy Ed25519 key<a href="#generate-your-new-sexy-ed25519-key" title="Permanent link"> </a></h2>

<div><pre><span></span><code><span><span>$</span> ssh-keygen -o -a <span>100</span> -t ed25519
</span><span>Generating public/private ed25519 key pair.</span>
<span>Enter passphrase (empty for no passphrase):</span>
<span>Enter same passphrase again:</span>
<span>Your identification has been saved in /home/gert/.ssh/id_ed25519.</span>
<span>Your public key has been saved in /home/gert/.ssh/id_ed25519.pub.</span>
<span>The key fingerprint is:</span>
<span>SHA256: [...] gert@hostname</span>
<span>The key's randomart image is: [...]</span>
</code></pre></div>
<p>Note the line 'Your identification has been saved in /home/gert/.ssh/id_ed25519'.
Your current RSA/DSA keys are next to it in the same <code>~/.ssh</code> folder.
As with any other key you can copy the public key in <code>~/.ssh/id_ed25519.pub</code> to target hosts for authentication.</p>
<h2 id="multi-key-aware-ssh-client">Multi-key aware SSH client<a href="#multi-key-aware-ssh-client" title="Permanent link"> </a></h2>
<p>All keys available on default paths will be autodetected by SSH client applications, including the SSH agent via ssh-add.
So, if you were using an application like ssh/scp/rsync before like...</p>

<p>it will now offer multiple public keys to the server and the server will request proof of possession for a matching entry for authentication.
And your daily use of the <code>ssh-add</code> command will not change and autodiscover the Ed25519 key:</p>
<div><pre><span></span><code><span><span>$</span> ssh-add
</span><span>Enter passphrase for /home/gert/.ssh/id_rsa:</span>
<span>Identity added: /home/gert/.ssh/id_rsa (gert@hostname)</span>
<span>Identity added: /home/gert/.ssh/id_ed25519 (gert@hostname)</span>
</code></pre></div>
<p>It not only discovered both keys, it also loaded them by entering a single passphrase (because it's the same)!</p>
<p>We've reached a very important goal now.
Without any change to your daily routine we can slowly change the existing configuration on remote hosts to accept the Ed25519 key.
In the meantime the RSA key will still work.
Great, right!?</p>
<h2 id="change-or-set-a-passphrase">Change or set a passphrase<a href="#change-or-set-a-passphrase" title="Permanent link"> </a></h2>
<p>If you're afraid this will change your key, don't worry.
The private part of your keypair is encrypted with a passphrase which only exists locally on your machine.
Change it as often as you like.
This is recommended to prevent abuse in case the key file gets into the wrong hands.
Repeat for all your key files to ensure a new key format with 100 bcrypt KDF rounds:</p>
<div><pre><span></span><code><span>$</span> ssh-keygen -f ~/.ssh/id_rsa -p -o -a <span>100</span>
</code></pre></div>
<h2 id="upgrade-your-current-rsa-key">Upgrade your current RSA key<a href="#upgrade-your-current-rsa-key" title="Permanent link"> </a></h2>
<p>Using Ed25519 will (and should) work in most situations by now, but legacy systems may not support them as of yet.
The best fallback is a strong RSA keypair for this.</p>
<p>While the OpenSSH client supports multiple RSA keys, it requires configuration/command line options to specify the path so it's rather error-prone.
Instead, I'd recommend upgrading your existing key in-place to keep things simple once this is done.
Depending on the strength (key size) of your current RSA key you can migrate urgently or comfortably.</p>
<p>In case you have a weak RSA key still, move it out of the way from the standard path and generate a new one of 4096 bits size:</p>
<div><pre><span></span><code><span>$</span> mv ~/.ssh/id_rsa ~/.ssh/id_rsa_legacy
<span>$</span> mv ~/.ssh/id_rsa.pub ~/.ssh/id_rsa_legacy.pub
<span>$</span> ssh-keygen -t rsa -b <span>4096</span> -o -a <span>100</span>
</code></pre></div>
<p>If you are using an agent, manually point it to all your keys:</p>
<div><pre><span></span><code><span>$</span> ssh-add ~/.ssh/id_rsa ~/.ssh/id_rsa_legacy ~/.ssh/id_ed25519
</code></pre></div>
<p>Once you are finished the transition on all remote targets you can go back to convenience and let it autodiscover your new RSA and Ed25519 keys; simply omit the keyfile arguments.</p>
<h2 id="software-support-for-ed25519">Software support for Ed25519<a href="#software-support-for-ed25519" title="Permanent link"> </a></h2>
<p>Support is available since OpenSSH 6.5 and well adopted in the Unix world OSs for workstations.
Ubuntu 14.04+, Debian 8+, CentOS/RedHat 7+ etc. all support it already.
(If you have details about Mac OS X please drop a line, couldn't find it with a quick search).
Some software like custom desktop key agents may not like the new keys for several reasons (see below <a href="#my-gnome-keyring-doesnt-work-anymore">about the Gnome-keyring</a> for example).</p>
<p>Github works pretty well too, by the way.
Launchpad and Gerrit code review however, seem to require RSA keys unfortunately.
PuTTY on Windows? See below.</p>
<h2 id="my-gnome-keyring-doesnt-work-anymore">My Gnome-keyring doesn't work anymore<a href="#my-gnome-keyring-doesnt-work-anymore" title="Permanent link"> </a></h2>
<p>The Gnome-keyring, as used in Ubuntu Unity at least, fails to read the new RFC4716 format keys but reports success.
It's bugged.
More details here in <a href="https://askubuntu.com/q/564821/88802">my AskUbuntu Q&amp;A post</a>.
I'd recommend disabling the Gnome keyring for SSH agent use and use the plain OpenSSH agent instead.</p>
<h2 id="im-using-windows-with-putty">I'm using Windows with PuTTY<a href="#im-using-windows-with-putty" title="Permanent link"> </a></h2>
<p>Sorry, I'm not using PuTTY, but make sure to upgrade first.
This page suggests Ed25519 support since a late-2015 version according to a <a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/wishlist/ed25519.html">wishlist item</a>.
Generally speaking, I'm not too excited with the speed of implementation of security features in it.</p>
<h2 id="is-this-the-ultimate-secure-ssh-keypair">Is this the ultimate secure SSH keypair?<a href="#is-this-the-ultimate-secure-ssh-keypair" title="Permanent link"> </a></h2>
<p>We've taken some steps, important ones, but it's far from ultimate security.
When dealing with high assurance environments I would strongly discourage key usage like described in this post as this holds the unencrypted private key in memory.
Instead, use hardware security (smart cards) to avoid leaking keys even from memory dumps.
It's not covered in this post, mainly because it requires a hardware device you need to buy and secondly because the limitations are device dependent.
A nice cute solution would be to make use of your TPM already …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.g3rt.nl/upgrade-your-ssh-keys.html">https://blog.g3rt.nl/upgrade-your-ssh-keys.html</a></em></p>]]>
            </description>
            <link>https://blog.g3rt.nl/upgrade-your-ssh-keys.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25870060</guid>
            <pubDate>Fri, 22 Jan 2021 09:42:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ownCloud Infinite Scale: Go instead of PHP, microservices instead of LAMP]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 112 (<a href="https://news.ycombinator.com/item?id=25869798">thread link</a>) | @veddox
<br/>
January 22, 2021 | https://www.heise.de//news/ownCloud-Infinite-Scale-Go-statt-PHP-Microservices-statt-LAMP-5029244.html | <a href="https://web.archive.org/web/*/https://www.heise.de//news/ownCloud-Infinite-Scale-Go-statt-PHP-Microservices-statt-LAMP-5029244.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        





<a-collapse has-indicator="">
  
  
  
</a-collapse>


      

      <p>Im stillen KÃ¤mmerlein arbeitet ownCloud seit Ã¼ber einem Jahr an der neuen Version seiner Software und zeigt nun zum ersten Mal sein neues Projekt Infinite Scale â€“ allerdings sind die Entwickler nicht langsam, sondern haben sich viel vorgenommen. Bis einschlieÃŸlich ownCloud X ist die Software eine klassische LAMP-Applikation: Im Hintergrund werkelt MySQL, Apache serviert PHP-Seiten und das gesamte Konstrukt lÃ¤uft Ã¼blicherweise auf einer Linux-Installation.</p>

<a-paternoster height="360" media="(min-width: 320px) and (max-width: 767px)">
  


  


  <a-ad height="600" instant="" layout="fixed" media="(min-width: 320px) and (max-width: 767px)" preload-distance="200" safeframe="" sizes="300x600,300x50,300x75,300x100,300x150,300x250,320x50,320x75,320x100,320x250" targeting="{&quot;kw&quot;:[&quot;Cloud Computing&quot;,&quot;Google Go&quot;,&quot;Linux und Open Source&quot;,&quot;Microservices&quot;,&quot;Nextcloud&quot;,&quot;OwnCloud&quot;,&quot;PHP&quot;,&quot;Server &amp; Storage&quot;,&quot;Systemverwaltung&quot;],&quot;mpos&quot;:[&quot;understitial&quot;,&quot;top&quot;],&quot;themenhub&quot;:&quot;yes&quot;}" type="gpt" unit="/6514/www.heise.de/ix/ix-inhalt" width="300"></a-ad>

</a-paternoster>


<p>Im Laufe der Jahre sind die ownCloud-Entwickler allerdings an immer mehr Performance- und Skalierbarkeitsgrenzen gestoÃŸen, deren Ursache zumeist in entsprechenden Limitierungen in PHP liegt. Wer groÃŸe ownCloud-Installationen betreibt, kennt das: Je mehr Nutzer und Dateien die Instanz verwaltet, desto trÃ¤ger wird sie mit der Zeit. RegelmÃ¤ÃŸig sehen Admins sich zudem mit Speicherplatzmangel konfrontiert, denn bisher speichert ownCloud die Dateien seiner Nutzer lokal auf einem normalen Dateisystem ab. Wird der Platz dort knapp, ist das Problem gar nicht so leicht zu umschiffen.</p>
<h3 id="nav_goodbye_php_0">Goodbye, PHP</h3>
<p>Alle <a href="https://www.heise.de/thema/OwnCloud">diese alten ZÃ¶pfe</a> planen die Entwickler in ownCloud Infinite Scale endgÃ¼ltig abzuschneiden. Dabei handelt es sich mehr Revolution denn Evolution: Ihren alten Code treten die Entwickler fast vollstÃ¤ndig in die Tonne und ersetzen ihn durch einen kompletten Rewrite in Go. oCIS folgt einem Modell aus drei Schichten: Die unterste Schicht kÃ¼mmert sich um das Speichern von Dateien, die mittlere Schicht umfasst alle Kern-Dienste und die dritte Schicht ist das ebenfalls vollstÃ¤ndig neu geschriebene Webinterface.</p>





  

<a-lightbox tabindex="1">
  
    

<figure>

  <div>
      <a href="https://www.heise.de/imgs/18/3/0/4/1/5/0/0/ocis5-b5dab7c1ceae5a77.png">
      

<a-img alt="" height="887" high-dpi-quality="70" layout="responsive" quality="85" src="/imgs/18/3/0/4/1/5/0/0/ocis5-b5dab7c1ceae5a77.png" width="1250"></a-img>



      </a>
    

  </div>
    

<figcaption>    <p>Ein erster Test des neuen ownCloud Infinite Scale und des ebenfalls neuen Webinterface, geschrieben in Vue.js.</p>
      
    
</figcaption>

</figure>

  
</a-lightbox>




<p>Der Kern von ownCloud besteht kÃ¼nftig aus verschiedenen Microservices, die einander per gRPC Befehle und Anweisungen zusenden. Die Entwickler bÃ¼ndeln die MESH-Software Traefik fest mit oCIS, um sich um Themen wie Loadbalancing und sichere Kommunikation innerhalb des Service-Netzwerks keine Gedanken machen zu mÃ¼ssen. Was im Umkehrschluss bedeutet: Reichen die laufenden Instanzen eines bestimmten ownCloud-Dienstes nicht mehr aus, lassen sich zusÃ¤tzliche Instanzen desselben Dienstes ad hoc starten.</p>
<p>Architektonisch nutzt oCIS diverse Vorteile von Go zur Beschleunigung. Fordert der Nutzer kÃ¼nftig eine spezielle Aktion per API oder Webinterface an, kÃ¼mmern die einzelnen oCIS-Microservices sich im Hintergrund darum. Der Anwender muss nicht warten, bis die jeweilige Aktion erfolgreich ausgefÃ¼hrt ist, bevor er den nÃ¤chsten Befehl absenden kann. Der Effekt findet sich auch auf der Code-Ebene wieder, wo Go anders als PHP echte NebenlÃ¤ufigkeit beherrscht und damit mehrere Operationen zur selben Zeit ausfÃ¼hren kann.</p>
<p>Obendrein reduziert der Umstieg auf Microservices den administrativen Aufwand von ownCloud. Eine externe Datenbank wie MySQL benÃ¶tigt die Software kÃ¼nftig nicht mehr â€“ um ihre Datenhaltung kÃ¼mmern sich eigene Microservices.</p>






  


  <a-ad height="250" instant="" layout="responsive" media="(min-width: 320px) and (max-width: 767px)" preload-distance="200" safeframe="" sizes="300x50,300x75,300x100,300x150,300x250,320x50,320x75,320x100,320x250,fluid" targeting="{&quot;kw&quot;:[&quot;Cloud Computing&quot;,&quot;Google Go&quot;,&quot;Linux und Open Source&quot;,&quot;Microservices&quot;,&quot;Nextcloud&quot;,&quot;OwnCloud&quot;,&quot;PHP&quot;,&quot;Server &amp; Storage&quot;,&quot;Systemverwaltung&quot;],&quot;mpos&quot;:[&quot;2&quot;],&quot;themenhub&quot;:&quot;yes&quot;}" type="gpt" unit="/6514/www.heise.de/ix/ix-inhalt" width="300"></a-ad>




      <!-- RSPEAK_STOP -->

      

      

     

      

      <!-- RSPEAK_STOP -->

    </div></div>]]>
            </description>
            <link>https://www.heise.de//news/ownCloud-Infinite-Scale-Go-statt-PHP-Microservices-statt-LAMP-5029244.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869798</guid>
            <pubDate>Fri, 22 Jan 2021 09:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon timeline – Easily track planned Apple Silicon support for Mac apps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25869685">thread link</a>) | @abdullahdiaa
<br/>
January 22, 2021 | https://isapplesiliconready.com/timeline | <a href="https://web.archive.org/web/*/https://isapplesiliconready.com/timeline">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><div><div><div><h2>
                    Capture One Pro
                  </h2> <p>
                    Native ARM support, will be released in an update to Capture One 21 early in 2021. In the meantime, Capture One will run on ARM-based Mac computers using Apple’s Rosetta 2 emulation platform. Tethering issue will be addressed in future upcoming releases.
                  </p> <p><a href="https://twitter.com/captureonepro/status/1329810389987680260" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Box drive
                  </h2> <p>
                    A Beta is planned in early 2021 for our Enterprise customers. Meanwhile, customers on these devices are encouraged to leverage our web-based application (https://app.box.com).
                  </p> <p><a href="https://isapplesiliconready.com/app/Box%20drive" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Unite by bzgapps
                  </h2> <p>
                    M1 support planned for early 2021. Rosetta compatible.
                  </p> <p><a href="https://www.bzgapps.com/unite" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    LuminarAI
                  </h2> <p>
                    LuminarAI is expected to launch in compatibility mode with the new Macs by the end of January.
                  </p> <p><a href="https://community.skylum.com/hc/en-us/community/posts/360009897439-Apple-Mac-M1-Support" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Golang
                  </h2> <p>
                    In February, the Go 1.16 release will include support for the new Apple Silicon Macs
                  </p> <p><a href="https://blog.golang.org/11years" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Newton mail app
                  </h2> <p>
                    As soon as 5th Feb. M1 version is expected to be released
                  </p> <p><a href="https://twitter.com/newtonmailapp/status/1352544579178827780" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Clean My Mac
                  </h2> <p>
                    MacPaw planning to release 4.8.0 M1 native version at the end of February.
                  </p> <p><a href="https://twitter.com/cleanmymac/status/1352574830613327872" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Squash by Realmac Software
                  </h2>  <p><a href="https://twitter.com/realmacsoftware/status/1352712198469120001" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Bitdefender Endpoint Security
                  </h2> <p>
                    The first compatible version of Bitdefender Endpoint Security for Mac with Apple M1 will be released at the beginning of March 2021.
                  </p> <p><a href="https://www.bitdefender.com/support/bitdefender-endpoint-for-mac-support-for-apple-m1-faq-2646.html" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Espresso 6
                  </h2> <p>
                    Beta version expected in Feb. and a stable version in March with native Apple Silicon support
                  </p> <p><a href="https://twitter.com/espressoapp/status/1352741607083102208" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    Google Drive for Desktop
                  </h2> <p>
                    Google Drive for desktop version 47.0 will support Apple M1 devices
                  </p> <p><a href="https://support.google.com/a/answer/7577057?hl=en" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    The R Project
                  </h2> <p>
                    goal is to have a native distribution for R 4.1.0 ca April 2021.
                  </p> <p><a href="https://stat.ethz.ch/pipermail/r-sig-mac/2020-November/013774.html" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    RapidWeaver by Realmac Software
                  </h2>  <p><a href="https://twitter.com/realmacsoftware/status/1352712198469120001" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div><div><div><div><h2>
                    WD Discovery
                  </h2> <p>
                    Western Digital expects to have an update to WD Discovery that will mount the My Cloud Home drive on macOS M1 Processors by July 2021.
                  </p> <p><a href="https://isapplesiliconready.com/app/WD%20Discovery" target="_blank"><span>
                    Source
                  </span></a></p></div></div></div></span></p></div></div></div>]]>
            </description>
            <link>https://isapplesiliconready.com/timeline</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869685</guid>
            <pubDate>Fri, 22 Jan 2021 08:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How to make your own budget Macro keyboard with JavaScript and Arduino]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25869647">thread link</a>) | @Ilikeruby
<br/>
January 22, 2021 | https://blog.almin.dev/posts/2021-01-20/diymacrokeyboard | <a href="https://web.archive.org/web/*/https://blog.almin.dev/posts/2021-01-20/diymacrokeyboard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>A few days ago I saw this blogpost by Scott Haneselman <a href="https://www.hanselman.com/blog/microsoft-teams-buttons-for-stream-deck-to-mute-share-hang-up-and-manage-cameras">“Microsoft Teams Buttons for Stream Deck to Mute, Share, Hang up, and Manage Cameras”</a> and I’ve found it fascinating and a great use of the Elgato Streamdeck. There is only one little catch.. the price. The elgato stream deck starts about ~150 Euro and about the same in dollars, which is kinda expensive for my budget, so I went thru my drawers to find my old Arduino set. it contained some buttons and some wires, which is exactly what I needed! (And also the whole set cost me about ~50 Euros)</p><p><img src="https://blog.almin.dev/static/media/components.3e13cb3a.jpg"></p><p><strong>Parts I’ve used here:</strong></p><ul><li>Arduino board</li><li>Cables</li><li>Button </li><li>Breadboard </li><li>10k Ohm Resistor</li></ul><h2 id="first-steps">First steps</h2><p>So, the first step was figuring out what language to use to make this work. Originally I thought, it would be nice to use GoLang or Rust since I want to get into these languages in the future, however after some thinking about it I naturally, like every hipster developer, settler for JS. It is probably not a good idea to write microcontrollers with JS but in this case, it should be easy to use and reproduce for everyone, I think JS is the best option. </p><p>What I recommend using is <a href="http://johnny-five.io/">Johnny-Five</a> which in short is a library that helps us communicate with the IOT devices like Arduino and Raspbery pi. In order to communicate with the host device, it realies on the <a href="https://github.com/firmata/protocol">firmata-protocol</a>. In the case of an arduino a program is flashed to the arduino that bootstraps and runs firmata, accepting instructions over a serial connection. With the Raspberry Pi it uses raspi-io, which uses a firmata-compatible API. It has the downside of requiring a serial connection to run your code.</p><p>Now, to start with the project I’ve just lookup some of the examples found in the on the <a href="http://johnny-five.io/examples/button/">Website of johnny-five</a> which helped me connect the arduino with the breadboard. After that I had something like this: </p><p><img src="https://blog.almin.dev/static/media/board.0c1830d6.jpg"></p><p><em><strong>Note</strong></em>: I’ve used some extension cables to make the reach a bit longer, since my USB cable is too tiny and connecting to the back of my PC results in me having to stretch, if I did not have the extensions. </p><p>Here is maybe a better look at the board schema and how to connect a button to it: </p><p><img src="https://blog.almin.dev/static/media/boardSchema.f984cd78.png"></p><h2 id="loading-the-firmware">Loading the firmware</h2><p>After connecting with the breadboard, connect the arduino to the PC and we can start with the fun part!</p><p>First off we start the <a href="https://www.arduino.cc/en/software">Arduino IDE</a> and configure some things. </p><ol><li>Select the correct Port <em><strong>Tools</strong></em> &gt; <em><strong>Port</strong></em> (the correct port is 3 or above)</li></ol><p><img src="https://blog.almin.dev/static/media/port.7420d600.png"></p><br><ol start="2"><li>We will need this to flash the firmata protocol <em><strong>Files</strong></em> &gt; <em><strong>Examples</strong></em> &gt; <em><strong>StandardFirmataPlus</strong></em></li></ol><p><img src="https://blog.almin.dev/static/media/Firmata.17a71e86.png"></p><blockquote><p><strong> ATTENTION </strong>
Let me stop here for a second - If you, like me, have a knockoff arduino and you are not seeing any port besides the default one, you have to install a specific driver which can be found <a href="https://sparks.gogo.co.nz/ch340.html">here</a>. Thats me saving you 3h of googling what the issue is, you are welcome.</p></blockquote><br><ol start="3"><li>Just press <em><strong>Upload</strong></em> button, and if everything is configured correclty there should be no errors in the IDE. </li></ol><p><img src="data:image/png;base64,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"></p><br><ol start="4"><li><strong>Thats it for the config!</strong></li></ol><p>Now that you have Arduino running with a Firmata protocol, everything we have to do is code the JS part of the macro keyboard. </p><p>Make a new <code>index.js</code> file wherever you can - write the code for the keyboard, should look something like this: </p><pre><code data-language="javascript" data-highlighted-line-numbers=""><span>var</span> five <span>=</span> <span>require</span><span>(</span><span>"johnny-five"</span><span>)</span><span>,</span> button<span>;</span>
<span>var</span> robot <span>=</span> <span>require</span><span>(</span><span>"robotjs"</span><span>)</span><span>;</span>
<span>var</span> board <span>=</span> <span>new</span> <span>five<span>.</span>Board</span><span>(</span><span>{</span>
  port<span>:</span> <span>"COM3"</span>
<span>}</span><span>)</span><span>;</span>





board<span>.</span><span>on</span><span>(</span><span>"ready"</span><span>,</span> <span>function</span><span>(</span><span>)</span> <span>{</span>

  
  
  
  button <span>=</span> <span>new</span> <span>five<span>.</span>Button</span><span>(</span><span>2</span><span>)</span><span>;</span>

  
  
  
  board<span>.</span>repl<span>.</span><span>inject</span><span>(</span><span>{</span>
    button<span>:</span> button
  <span>}</span><span>)</span><span>;</span>

  

  
  button<span>.</span><span>on</span><span>(</span><span>"down"</span><span>,</span> <span>function</span><span>(</span><span>)</span> <span>{</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"control"</span><span>,</span> <span>"down"</span><span>)</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"shift"</span><span>,</span> <span>"down"</span><span>)</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"m"</span><span>,</span> <span>"down"</span><span>)</span>
<span>}</span><span>)</span>

  
  
  
  button<span>.</span><span>on</span><span>(</span><span>"hold"</span><span>,</span> <span>function</span><span>(</span><span>)</span> <span>{</span>
    console<span>.</span><span>log</span><span>(</span><span>"hold"</span><span>)</span><span>;</span>
  <span>}</span><span>)</span><span>;</span>

  
  button<span>.</span><span>on</span><span>(</span><span>"up"</span><span>,</span> <span>function</span><span>(</span><span>)</span> <span>{</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"control"</span><span>,</span> <span>"up"</span><span>)</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"shift"</span><span>,</span> <span>"up"</span><span>)</span>
    robot<span>.</span><span>keyToggle</span><span>(</span><span>"m"</span><span>,</span> <span>"up"</span><span>)</span>
  <span>}</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span>
</code></pre><p>This code snippet is only for “CTRL + SHIFT + M” (mute / unmute) for MS Teams (I think Discord and Slack use the same button combination for mute and unmute.)
And run it like a node script <code>node index.js</code> and thats it, your button should be working now!</p><p>Let me break down the code a little bit. The importat part is this: </p><pre><code data-language="javascript" data-highlighted-line-numbers=""><span>var</span> board <span>=</span> <span>new</span> <span>five<span>.</span>Board</span><span>(</span><span>{</span>
  port<span>:</span> <span>"COM3"</span>
<span>}</span><span>)</span><span>;</span>
</code></pre><p>You should initialize a new Board with the correct port, since in my case I had to do it, because the default port is not working. Probably because of the knockoff arduino. The port is the same as the one we selected above in the first step!</p><p>The pin on the Arduino board should be set here as the button:</p><pre><code data-language="javascript" data-highlighted-line-numbers="">button <span>=</span> <span>new</span> <span>five<span>.</span>Button</span><span>(</span><span>2</span><span>)</span><span>;</span>
</code></pre><p>Later you can declare new buttons with the same code, just remember to select the correct Digital pin number on which the button is connected. (Usually from 0 to 13)</p><p>And <a href="https://github.com/octalmage/robotjs">RobotJs</a> is being used to setup the keyboard shortcuts with the <code>down</code> and <code>up</code> events which are triggered when pressing the button. It is just a simple library which simulates the keyboard inputs. This is really the first solution I could find and easiest I could make work, there could be potentially something better, but I’ve settled with what works. Also remember to use KeyToggle function and not keyTap. So you can add additional shortcuts, which make you leave the call or copy - paste, change scenes, essentially almost everything you can do with a StreamDeck.</p><p>So, in just a few steps you can have a custom macro keyboard. It is supriseingly not that hard, especially if you have the possibility to write JS and make it work with it. </p><p>Later if you are ambitious you can expand this and add more buttons on the board and make something a bit more complicated and it could look like this: </p><p><img src="https://blog.almin.dev/static/media/finished.38bd50d3.png"></p><p>Its not as fancy as the StreamDeck but it is usefull and does the job. In the future you can update it and get better keys and better housing for the whole board, add blinking lights and so on. This was just fun DIY project which is also something really usefull.</p></div></article></div></div>]]>
            </description>
            <link>https://blog.almin.dev/posts/2021-01-20/diymacrokeyboard</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869647</guid>
            <pubDate>Fri, 22 Jan 2021 08:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Italian girl, 10y: brain dead after taking TikTok Blackout Challenge]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25869367">thread link</a>) | @giuliomagnifico
<br/>
January 21, 2021 | https://www.ansa.it/english/news/2021/01/21/girl-10-brain-dead-after-taking-tiktok-blackout-challenge_4ba630f3-aba6-4613-8230-6c7566f55d68.html | <a href="https://web.archive.org/web/*/https://www.ansa.it/english/news/2021/01/21/girl-10-brain-dead-after-taking-tiktok-blackout-challenge_4ba630f3-aba6-4613-8230-6c7566f55d68.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          	<p>(ANSA) - PALERMO, JAN 21 - A 10-year-old Italian girl was declared brain dead by a Palermo hospital Thursday after taking the Blackout Challenge on TikTok.<br>&nbsp;&nbsp;&nbsp; Her parents have OK'd donating the organs of the girl, who tied a belt around her throat to self-asphyxiate in the challenge on the popular social-media platform.<br>&nbsp;&nbsp;&nbsp; She arrived at the hospital in cardiac arrest.<br>&nbsp;&nbsp;&nbsp; Doctors said they did all they could to try and save her but she was too far gone.<br>&nbsp;&nbsp;&nbsp; The Blackout Challenge, and a milder variant called the Passout Challenge, have been circulating on TikTok over the last year.<br>&nbsp;&nbsp;&nbsp; Experts have warned of the risks associated with the challenges, including fainting, seizures, brain damage, and even death.<br>&nbsp;&nbsp;&nbsp; (ANSA).<br>&nbsp;&nbsp;&nbsp;</p>
			
            
            <p><strong>ALL RIGHTS RESERVED © Copyright ANSA</strong></p>
              
          </div></div>]]>
            </description>
            <link>https://www.ansa.it/english/news/2021/01/21/girl-10-brain-dead-after-taking-tiktok-blackout-challenge_4ba630f3-aba6-4613-8230-6c7566f55d68.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869367</guid>
            <pubDate>Fri, 22 Jan 2021 07:35:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Java Reactive Programming with Spring and R2dbc]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25869138">thread link</a>) | @yannbri
<br/>
January 21, 2021 | https://www.sipios.com/blog-tech/handle-the-new-r2dbc-specification-in-java | <a href="https://web.archive.org/web/*/https://www.sipios.com/blog-tech/handle-the-new-r2dbc-specification-in-java">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><strong>Reactive programming</strong> is a phrase that seems to be more and more present in web development. New tools and frameworks are appearing in the developing landscape.</p>
<!--more-->
<p>We need to follow those changes, to be able to provide the best technical solutions to our customers. But what is reactive programming?</p>
<p>According to <a href="https://en.wikipedia.org/wiki/Reactive_programming" rel="noopener">Wikipedia</a>,</p>
<blockquote>
<p><span>In</span><span>&nbsp;</span><a href="https://en.wikipedia.org/wiki/Computing" title="">computing</a><span>,</span><span>&nbsp;</span><span>reactive programming</span><span>&nbsp;</span><span>is a</span><span>&nbsp;</span><a href="https://en.wikipedia.org/wiki/Declarative_programming" title="Declarative programming">declarative</a><span>&nbsp;</span><a href="https://en.wikipedia.org/wiki/Programming_paradigm" title="Programming paradigm">programming paradigm</a><span>&nbsp;</span><span>concerned with</span><span>&nbsp;</span><a href="https://en.wikipedia.org/wiki/Stream_(computing)" title="Stream (computing)">data streams</a><span>&nbsp;</span><span>and the propagation of change</span></p>
</blockquote>
<p>And here, you still don't know what is reactive programming and why it should be taken into account when you consider developing a new web application. Let's try to make things short and clear so that you can go further and read the rest of the article with everything needed.</p>
<p>Let's go into a bit more detail. Each component of your application is built on the same basis :</p>
<p>- Receiving some <strong>input data</strong> from a calling component<br>- Processing the data (maybe by calling some other components) and creating output data.<br>- Returning the <strong>output data</strong></p>
<p>In Reactive programming, the caller components don't only send input data to the working component but also subscribe to the returning flow of data. By doing so, they are not waiting for the output data. Instead, they will be warned when those data are available and then they will process it.</p>
<p>You can find a great article <em><a href="https://projectreactor.io/learn" rel="noopener">here</a><span>&nbsp;</span></em>that presents the <span>Reactive programming principles</span> as well as how<span> Project Reactor</span> deals with it in the Java ecosystem. You will find here some very useful schemas that will help with your understanding.</p>
<p>Reactive programming is well known by front-end developers because modern frameworks like Angular or React are based on it. Concerning Java, it's coming step by step, with for example the arrival of <strong>Spring Web Flux</strong> and also, the recent <strong>R2DBC</strong>.</p>
<hr>
<h4>What is R2DBC?</h4>
<ul>
<li>
<h6>Definition</h6>
</li>
</ul>
<p>From the R2BDC website:</p>
<blockquote>
<p><span>The Reactive Relational Database Connectivity (R2DBC) project brings reactive programming APIs to relational databases.</span></p>
</blockquote>
<p>There are three main points to understand:</p>
<p>- R2DBC is a <strong>specification</strong> that provides an interface. Vendors should implement it to provide access to the different databases (PostgreSQL, MySQL, ...)<strong>.</strong></p>
<p>- It's founded on the<a href="https://github.com/reactive-streams/reactive-streams-jvm/blob/v1.0.0/README.md#specification" rel="noopener"> <strong>Reactive Streams Specification</strong></a> which is adopted by some major parties of the Java ecosystem (such as Vert.X, <a href="https://mongodb.github.io/mongo-java-driver-reactivestreams/" rel="noopener">MongoDB driver</a>, <a href="https://projectreactor.io/" rel="noopener">project Reactor</a>)</p>
<p><strong>- </strong>Its purpose is to provide a<strong> non-blocking alternative</strong> to the existing&nbsp; Relational Database drivers specification such as JDBC.</p>

<ul>
<li>
<h6>The place of R2DBC in a layered architecture</h6>
</li>
</ul>
<p>Let's have a look on a layered architecture :</p>
<p>- The <strong>Controller Layer </strong>handles requests from the outside, does some verification, and dispatches the requests to the service layer.<br>- The<strong> Service Layer </strong>takes the input from the controller and then applies some computations based on business specifications. The system intelligence is here.<br>- To make this computation possible, the service layer has to lean on a<strong> Data Access Layer</strong>, that will handle the access to the data source.</p>
<p>Using this architecture, every time a layer calls another one, you can&nbsp; use a reactive process. For example, when you are using Spring WebFlux, the controller layer is automatically set up as a reactive component.&nbsp;</p>
<p>R2DBC is a way to bring reactivity to the interface between the <strong>Data Access Layer</strong> and the Database in the case of <strong>relational databases</strong>. As a consequence, each time this layer is&nbsp; calling the database, it will release the working thread and wait until the database warns it that the result is ready to be processed.</p>

<ul>
<li>
<h6>The advantages of R2DBC comparing to JDBC&nbsp;</h6>
</li>
</ul>
<p>The advantages of R2DBC over JDBC are the same as the advantages of reactive programming over blocking programming. it has <strong>better performance</strong> when you are facing a high concurrency situation. A quick look at<span>&nbsp;</span><em><a href="https://medium.com/oracledevs/spring-blocking-vs-non-blocking-r2dbc-vs-jdbc-and-webflux-vs-web-mvc-900d72ee19c1" rel="noopener">this a</a><a href="https://medium.com/oracledevs/spring-blocking-vs-non-blocking-r2dbc-vs-jdbc-and-webflux-vs-web-mvc-900d72ee19c1" rel="noopener">rticle</a></em><span> comparing performances of different applications at both low and high concurrencies is enough to see how impressive the improvement is, especially concerning the usage of memory per requests.</span></p>
<p>However, at low concurrencies, the advantages of R2DBC are fading out and its drawbacks should be taken into consideration. <span>Those drawbacks are due to the freshness of the specification. Some of them are interesting for architects, before deciding whether or not to use it:&nbsp;</span></p>
<p><span>- <strong>Lack of feedback and experience</strong> from developers concerning a new specification and its implementations. </span></p>
<p><span>- <strong>M</strong><strong>issing features</strong> that prevent the specification (and its implementations) to be fully ready for production. For example, the handling of stored procedures is planned on the release 0.9, while currently, we are still on version 0.8.</span></p>
<p><span>- <strong>Existing competitors</strong> like Quarkus with<strong> Eclipse Vert.X.</strong> It can prevent R2DBC from becoming the future standard.</span><span></span></p>
<p><span>- <span>Java future specification</span> can also bring some changes to the game. For example, in <a href="https://spring.io/blog/2018/12/07/reactive-programming-and-relational-databas" rel="noopener">this article</a>, we can see that the project Loom of Java aims to bring reactivity to blocking APIs (such as JDBC).</span></p>
<p>We can still be reassured by the fact that Spring has decided to create a full module handling this specification: <strong>Spring Data R2DBC</strong>. The fact that a major party of the Java ecosystem is putting effort into handling R2DBC is why that new technology is worth considering.</p>
<p>Another drawback may be more interesting for developers, before using R2DBC.</p>
<p><span>- <span>L</span><span>ack of features</span> provided by some ORM frameworks (like <span>Hibernate</span> which is based on JDBC). Here is what we can read at the GitHub repository of <a href="https://github.com/spring-projects/spring-data-r2db" rel="noopener">spring-data-r2dbc</a></span></p>
<blockquote>
<p><span>Spring Data R2DBC aims at being conceptually easy. In order to achieve this it <strong>does NOT offer caching, lazy loading, write behind or many other features of ORM frameworks</strong>. This makes Spring Data R2DBC a simple, limited, opinionated object mapper.</span></p>
</blockquote>
<p>And that's why I wanted to deepen the use of Spring Data R2DBC in a POC, to have a first idea of how easy it is to use, and how hard it is to find workarounds to ORM features that currently do not exist.</p>
<hr>
<h4>How to use R2DBC in a Spring project ?</h4>
<p>You can find the sources of the POC I created on this <a href="https://github.com/tmonegier/r2dbc" rel="noopener">GitHub repository.</a></p>
<ul>
<li>
<h6>Configure a project with R2DBC</h6>
</li>
</ul>
<p>To configure a project with Spring, you can use <strong>Spring Initializr</strong>. You choose the modules you want to work with and then your project is generated with all the needed dependencies. You can still do it manually, all the needed pieces of information are provided below.</p>
<p>To be able to work with Spring Data R2DBC, I added the following dependencies. I decided to use PostgreSQL as my database because it is one of the most used relational databases. You can find the list of available drivers for several databases <em><a href="https://r2dbc.io/drivers/" rel="noopener">here</a></em>.</p>
<pre><br>&lt;dependency&gt;<br><span>    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span>    &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt;</span><br><span>&lt;/dependency&gt;</span><br><span>&lt;dependency&gt;</span><br><span>    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span>    &lt;artifactId&gt;spring-boot-starter-data-r2dbc&lt;/artifactId&gt;</span><br><span>&lt;/dependency&gt;</span><br><span>&lt;dependency&gt;</span><br><span>    &lt;groupId&gt;io.r2dbc&lt;/groupId&gt;</span><br><span>    &lt;artifactId&gt;r2dbc-postgresql&lt;/artifactId&gt;</span><br><span>&lt;/dependency&gt;</span></pre>

<p>And you need to add a configuration class where you declare the connection factory that will be used by spring data to perform requests using R2DBC specification. <strong>This configuration depends on the vendor driver you have chosen</strong> for your project. In the case of PostgreSQL, here is an example:</p>
<pre><br>@Configuration<br>@EnableR2dbcRepositories<br>public class PostgresConfig extends AbstractR2dbcConfiguration {<p>    @Override<br>    @Bean<br>    public ConnectionFactory connectionFactory() {<br>        return new PostgresqlConnectionFactory(<br>           PostgresqlConnectionConfiguration.builder()<br>                   .host("localhost")<br>                   .port(5433)<br>                   .username("postgres")<br>                   .password("admin")<br>                   .database("mydb")<br>                   .build());<br>    }<br>}</p></pre>

<ul>
<li>
<h6>Handle entities without relations</h6>
</li>
</ul>
<p><span>In this part, we will concentrate on the mapping: <strong>one java model class to one table</strong>.</span><span></span><span></span></p>
<h6><span>1. Create the Data Model</span></h6>
<p><span>Let's create a table, with the following columns:</span></p>
<pre><span>CREATE TABLE person<br>(<br>    id uuid NOT NULL DEFAULT uuid_generate_v4(),<br>    name character varying(255) COLLATE pg_catalog."default" NOT NULL,<br>    street character varying(255) COLLATE pg_catalog."default" NOT NULL,<br>    zip_code character varying(255) COLLATE pg_catalog."default" NOT NULL,<br>    city character varying(255) COLLATE pg_catalog."default" NOT NULL,<br>    CONSTRAINT person_pkey PRIMARY KEY (id)<br>)&nbsp;</span></pre>
<p>This table can be mapped with Spring Data in this way:</p>
<pre>public class Person {<p>    @Id<br>    UUID id;</p><p>    String name;<br>    String street;<br>    String zipCode;<br>    String city;</p><p>}</p></pre>
<p>In that case, the mapping will be done between the attributes and the columns.</p>
<p>The <strong>@Id</strong> annotation is one way to specify which column is the <strong>primary key</strong>. If that attribute is NULL, then Spring will create a new line in the table when saving the object. If that attribute is not NULL, then Spring will try to update the existing attribute. You can see <a href="https://docs.spring.io/spring-data/r2dbc/docs/current/reference/html/#r2dbc.entity-persistence.state-detection-strategies" rel="noopener">here </a>other ways to make the distinction between new entities and entities to be updated.</p>
<p>One thing you need to notice: there is no annotation like the JPA <strong>@GeneratedValue</strong>. You need to configure the database properly because it will handle the automatic generation of primary keys.</p>

<h6>2. Accessing database</h6>
<p>To be able to access the database, Spring provides us with an interface: <strong>R2dbcRepository</strong>. You can create your&nbsp; repository interface extending it :</p>
<pre>@Repository<br>public interface PersonRepository extends R2dbcRepository&lt;Person, UUID&gt; {<br>}</pre>
<p>This interface provides usable CRUD methods, you can find the list on the <a href="https://docs.spring.io/spring-data/r2dbc/docs/1.1.0.M4/api/org/springframework/data/r2dbc/repository/R2dbcRepository.html" rel="noopener">documentation</a>.</p>

<h6>3. Use converters to do complex mappings.</h6>
<p>What else is available with Spring Data R2DBC?</p>
<p>If some attributes can be gathered in a nested object, then you can change your Java model, and do something like this:</p>
<pre><br>public class Person {<p>    @Id<br>    UUID id;</p><p>    String name;<br>    Address address;</p><p>    public static class Address {</p><p>        String street;<br>        String zipCode;<br>        String city;<br>    }</p><p>}</p></pre>
<p>And then, using the same repository as before, you will need to create two converters:</p>
<p>- <strong>One Reading Converter</strong> that allows Spring to know how to map data from the database to Java model.</p>
<pre><br>@ReadingConvert…</pre></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sipios.com/blog-tech/handle-the-new-r2dbc-specification-in-java">https://www.sipios.com/blog-tech/handle-the-new-r2dbc-specification-in-java</a></em></p>]]>
            </description>
            <link>https://www.sipios.com/blog-tech/handle-the-new-r2dbc-specification-in-java</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869138</guid>
            <pubDate>Fri, 22 Jan 2021 06:52:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Canada's Express Entry Program]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25869096">thread link</a>) | @luu
<br/>
January 21, 2021 | https://scattered-thoughts.net/writing/canadas-express-entry-program/ | <a href="https://web.archive.org/web/*/https://scattered-thoughts.net/writing/canadas-express-entry-program/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>Wesley Aptekar-Cassels' recent posts on <a href="https://notebook.wesleyac.com/taiwan-gold-card/">getting a gold card</a> and <a href="https://notebook.wesleyac.com/taiwan/">moving to Taiwan</a> reminded me that I meant to write about my experience with Canada.</p>
<p>I immigrated to Vancouver, BC in March 2020. I was given permanent residency before setting foot in Canada and without a job offer, under the <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry.html">Express Entry</a> program. From gathering documents to landing in the country took 9 months. Judging by 3rd party trackers this is well over the median - I was pretty disorganized and the London embassy is one of the slowest.</p>
<p>The whole process looks like this:</p>
<ol>
<li>Check the <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/eligibility/compare.html">eligibility requirements</a> and spend 5 minutes filling out <a href="https://www.cic.gc.ca/english/immigrate/skilled/crs-tool.asp">this questionnaire</a>. You'll get a score which you can compare to <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/submit-profile/rounds-invitations/results-previous.html">recent admission rounds</a> to see if you have a good chance. (The results aren't recorded, so just guess what your language test scores would be.)</li>
<li>Take an <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/documents/language-requirements.html">English and/or French exam</a> and get an <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/documents/education-assessed.html">Educational Credential Assessment</a>. Get the rest of your paperwork ready - proof of employment history, proof of funds, <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/apply-permanent-residence/police-certificates.html">police certificates</a>.</li>
<li>Fill out an <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/submit-profile.html">Express Entry profile</a> and wait for an invitation to apply.</li>
<li>Get invited to apply. Submit all the paperwork. Take a short medical exam and go the embassy for fingerprints and photos.</li>
<li>Send off your passport and wait for it to come back with a Confirmation of Permanent Residence inside.</li>
</ol>
<p>The total cost for me was £1456:</p>
<ul>
<li>£165 for the IELTS exam</li>
<li>£140 for the Educational Credential Assessment</li>
<li>various small fees for eg mailing paperwork, getting sealed degree certificates</li>
<li>£670 for the Express Entry application</li>
<li>£330 for the medical exam</li>
</ul>
<p>One thing I really appreciated is that most of the expense of applying, in terms of both time and money, was at step 4, by which point the acceptance rate is something like 95%.</p>
<p>Other miscellanea:</p>
<ul>
<li>Step 2 took me 4 months (poor planning). Step 3 took 2 weeks. Step 4 took 3 months. Step 5 took 2 months, apparently due to heavy backlog at the London office.</li>
<li>Self-employment is fine for the employment history requirements. I submitted tax records and signed letters from a few previous clients.</li>
<li>I didn't have a job offer in Canada, but if you do it seems worth trying to get provincial nomination which will shoot you to the top of the queue. Eg BC has a <a href="https://www.welcomebc.ca/Immigrate-to-B-C/B-C-Provincial-Nominee-Program/BC-PNP-Tech-Pilot">fast-track for tech jobs</a>.</li>
<li>Permanent residents are eligible for public healthcare (which in BC is free) after 3 months. There are companies that offer cheap private insurance to cover the gap - I used <a href="https://www.desttravel.com/#/insuranceproducts/visitortocanadainsurance">Destination Travel</a>.</li>
<li>To keep my residency I need to spend 2 out of every 5 years in Canada. After accumulating 3 years in Canada in any 5 year period I'm eligible for citizenship.</li>
</ul>
<hr>
<p>My move was totally unrelated to current events - I had decided a few years back that I wanted to settle down somewhere and Vancouver ended up at the top of the spreadsheet. But since many of my friends in the US are thinking about emigrating, here are the main points I see for and against.</p>
<p>In favor of Vancouver:</p>
<ul>
<li>World class <a href="https://www.mountainproject.com/area/105946429/british-columbia">climbing</a>, skiing, kayaking, mountain biking etc as well as a <a href="https://originsparkour.com/">solid parkour gym</a></li>
<li><a href="https://www.youtube.com/watch?v=gjfUkxqDDNw">Astounding natural beauty</a></li>
<li><a href="https://www.iqair.com/ca/canada/british-columbia/vancouver-bc">Low air pollution</a></li>
<li><a href="https://vancouver.ca/home-property-development/urban-forest-strategy.aspx">Trees</a>, <a href="https://vancouver.ca/parks-recreation-culture/beaches.aspx">beaches</a>, <a href="https://www.vanmuralfest.ca/murals">murals</a></li>
<li>Reasonable social safety net</li>
<li>Politically stable</li>
<li>English-speaking (I've lived in several non-English-speaking countries so this certainly isn't a hard requirement, but it is easier)</li>
<li>Same timezone as SF and 3 hours behind NYC - good for remote tech work</li>
<li>Regularly ranked as one of the <a href="https://en.wikipedia.org/wiki/Most_livable_cities">most livable</a> cities in the world</li>
</ul>
<p>Against Vancouver:</p>
<ul>
<li>Large belligerent neighbor</li>
<li>On the <a href="https://vancouver.ca/home-property-development/understanding-earthquakes.aspx">Cascadia subduction zone</a></li>
<li>Downtown is vulnerable to <a href="https://vancouver.ca/green-vancouver/sea-level-rise.aspx">sea level rise</a></li>
<li>Uncertain economic future, dependent on oil</li>
<li>Regular wildfires</li>
<li>Expensive real estate (compared to other Canadian cities, but not anywhere near as bad as SF, NYC or London)</li>
<li>Not a cultural capital</li>
</ul>

</article></div>]]>
            </description>
            <link>https://scattered-thoughts.net/writing/canadas-express-entry-program/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869096</guid>
            <pubDate>Fri, 22 Jan 2021 06:46:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transcript of Microsoft President Brad Smith's Town Hall on the Company PAC]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25869065">thread link</a>) | @idlewords
<br/>
January 21, 2021 | https://notes.pinboard.in/u:maciej/90342e46caf768b7329d | <a href="https://web.archive.org/web/*/https://notes.pinboard.in/u:maciej/90342e46caf768b7329d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><b>Microsoft Town Hall Jan 21 Transcript</b></p><p>The following is a partial transcript of an employee town hall held by Microsoft on January 21, 2021. Participants in the town hall included Microsoft CEO Satya Nadella, Microsoft President Brad Smith, and Kurt DelBene, executive vice president of corporate strategy. The event moderator was Nichole Christie. A video of the town hll was made available to me by a source at Microsoft, and I have transcribed Smith's comments on the company PAC here verbatim. </p>

<p>Comments and shouts into the void in brackets in italics are mine.</p>

<p>My contact info is maciej@ceglowski.com / 415 610 0231 on Signal. </p>

<hr>

<p><strong>NICOLE CHRISTIE</strong>: The Microsoft political action committee, or MS-PAC. We're hearing about this on a variety of channels, so it is our first question, and this one comes from Yammer. </p>

<p>"Please advise what actions MS-PAC will make to address donations made to politicians involved in the effort to derail the certification of Electoral College votes on January 6. Microsoft employees support our company culture and values, and follow our code of conduct. MS-PAC dollars should not be given to politicians or organizations who don't share those values. Brad, can you speak to this?</p>

<p><strong>BRAD SMITH</strong>: "Thank you, Nicole, and it's obviously an important question. I don't want to repeat but I do want to build upon what Satya has said. Jan 6, the attack on the Capitol, was a horrific day for all of us, whether we're in the United States or somewhere else, and I think it was even more difficult, say, for our black employees and our Jewish employees given the hateful symbols that were on display.</p>

<p>"This has obvious implications for the future donations of the PAC. We took stock of our donations over the last four years and we found that 80% of the dontions had gone to members of Congress who voted to uphold the Electoral College, and 20% had gone to members who voted against the Electoral College,"</p>

<p>[<em>It's not clear if this is an accounting of dollar figures, or a count of donations. It's also not clear if Smith is counting donations to leadership PACs and other PACs, which fan out to multiple members of Congress. You can see a spreadsheet of donations made by Microsoft and other tech companies to the 147 members of congress who voted to overturn the Electoral College <a href="https://docs.google.com/spreadsheets/d/1EjbdWHZ-9ojc5Fh64Sle6kpnOIfJSztkJT3YFlJilDk/edit#gid=0">here</a>.</em>]</p>

<p><strong>SMITH</strong>: "So now there's a process to decide what to do. The questions that are being considered are exactly I think what you would expect. Should the PAC suspend donations to the members who voted against the Electoral College? If so, for how long?"</p>

<p>[<em>Microsoft had previously suspended political giving in summer of 2019, when the then-head of the PAC <a href="https://idlewords.com/2019/07/microsoft_s_hypocrisy_on_daca.htm">suggested to employees in an internal forum</a> that even discussing the PAC with coworkers might constitute harassment. This comment came in the context of an employee effort to defund the PAC, and caused considerable internal uproar. The head of the PAC left Microsoft shortly thereafter in unclear circumstances. The company resumed its political giving in October 2019.</em>]</p>

<p><strong>SMITH</strong>: "Should it even take stronger steps with respect to members who led that effort or who fed disinformation, in our view, to the American public. These are among the questions that are being considered. Now, the PAC pauses donations at the beginning of every new Congress, but this is not a normal year."</p>

<p>[<em>Smith makes an important point here—the decision by many Fortune 500 companies to suspend political giving in the aftermath of the January 6 catastrophe has little practical impact, since corporate donations are typically not made in the first months of a new electoral cycle. Only a very few companies, like Nike, have committed to permanently withholding donations from legislators who voted to overturn the Electoral College vote.</em>]</p>

<p><strong>SMITH:</strong> "And so we're engaging in additional steps to really think this through. And the heart of this is really to have a series of virtual meetings with employees, because I think it's important to get employee feedback and have a conversation together before these decisions are made."</p>

<p>[<em>In the past, Microsoft limited discussions of PAC giving to actual or potential PAC donors, which automatically excluded the company's DACA and non-US employees, who are prohibited by law from making political contributions, but who were the most directly affected by the company's political giving. It's not clear whether the current round of discussions will be open to everyone or again limited in this way.</em>]</p>

<p><strong>SMITH:</strong> "Now I definitely appreciate, especially for people outside the United States, you might be following all this and wondering 'what are we talking about? What is this thing called a PAC? So I did want to take a moment just to give you a little bit more context."</p>

<p>"A PAC is a political action committee, and it reflects first of all the fact that in the Untied States, political campaigns are privately funded. We've been one of many that have long encouraged more public funding to get money out of politics, but it does pay for campaigns. A campaign for the House of Representatives of the United States typically costs millions of dollars; a campaign for the Senate costs tens of millions of dollars."</p>

<p>[<em>Smith does not mention state races, where Microsoft, almost alone among big tech companies, also makes substantial contributions.</em>]</p>

<p><strong>SMITH</strong>: "Now a PAC if you really look at it doesn't actually contribute that much money. It's paid for entirely by voluntary donations. 91% of the Fortune 100 have a PAC; 75% of the Fortune 500 have a PAC."</p>

<p>[<em>Donations to PACs at large companies are typically done by paycheck deduction. Depending on the company, there can be considerable pressure to make these 'voluntary' donations, particularly among senior executives. Apple and IBM stand apart from the other tech giants by not having a PAC.</em>]</p>

<p><strong>SMITH:</strong> "But the law says that they can only be funded by donations from employees, shareholders, and family members, and ours are, of no more than $5,000 a year. And the donations the PAC makes are actually small in the scheme of things as well. The PAC can contribute up to $5,000 for a primary election, and $5,000 for a general election. The decisions about who to donate to are made by a steering committee, and then there's an employee advisory committee and there's a broad network because we want everybody who donates voluntarily to be part of an ongoing conversation."</p>

<p>"The PAC makes donations based on four criteria:</p>

<p>"First, does the person have a job, a role, say on a committee that impacts our business?</p>

<p>"Second, does the person represent a geography where we have a significant employee presence?"</p>

<p>"Third, does the person advance policy goals that align with Microsoft's business policy objectives."</p>

<p>"And fourth, does the person share our values around diversity and inclusion?"</p>

<p>"So all four of things are considered when decisions about donations are made."</p>

<p>[<em>Microsoft's donation history shows that the fourth criterion is not a veto point, but rather is weighted against the other three. Microsoft makes significant donations to members of Congress who are working to get Microsoft's own employees deported.</em>]</p>

<p><strong>SMITH:</strong> "I recognize that especially when you have times like this it's easy for people to ask the question, 'do we really need a PAC?' And I will acknowledge that I've asked that question myself over the last few years. 'Do we really need this PAC?' And I have to tell you, the answer is 'yes, we do'."</p>

<p>"I can tell you it plays an important role. Not because the checks are big, but because the way the political process works. Politicians in the United States have events, they have weekend retreats, you have to write a check and then you're invited and participate. So if you work in the government affairs team in the United States, you spend your weekends going to these events; you spend your evenings going to these dinners, and the reason you go is because the PAC writes a check."</p>

<p>"But out of that ongoing effort a relationship evolves and emerges and solidifies, and I can tell you as somebody who sometimes is picking up the phone, I'm sometimes calling members and asking for their help on green cards, or on visa issues, or help to get an employee or family member who is outside the United States during COVID back into the country because of an immigration restriction."</p>

<p>[<em>The somewhat astonishing argument laid out here is that Microsoft needs to elect representatives who enact an anti-immigrant agenda in order to have the clout to win limited exemptions from that agenda for itself.</em>]</p>

<p><strong>SMITH</strong>: "Or the issues around national security, or privacy, or procurement reform. Or the tax issues that our finance team manages. And I can tell you, there are times when I call people who I don't personally know, and somebody will say "you know, your folks have always shown up for me at my events. And we have a good relationship. Let me see what I can do to help you"</p>

<p>"So I do believe it is important for our company to have this kind of effort. And at the same time, it's important for us to take stock of the recent events, get feedback, have a conversation, and make decisions that will continue to reflect where we stand, and the values that we believe are important. "</p>

<p>"So you'll see all of that unfold, with dialogue, with employees."</p>
</div></div>]]>
            </description>
            <link>https://notes.pinboard.in/u:maciej/90342e46caf768b7329d</link>
            <guid isPermaLink="false">hacker-news-small-sites-25869065</guid>
            <pubDate>Fri, 22 Jan 2021 06:39:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ASCII-Crc]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25868693">thread link</a>) | @todsacerdoti
<br/>
January 21, 2021 | https://git.envs.net/mpech/ascii-crc | <a href="https://web.archive.org/web/*/https://git.envs.net/mpech/ascii-crc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		



		<div>
			<p><span>ascii fingerprint of file</span>
				<a href=""></a>
			</p>
			
		</div>
		<div id="repo-topics">
		<p><a href="https://git.envs.net/explore/repos?q=llvm-ir&amp;topic=1">llvm-ir</a><a href="https://git.envs.net/explore/repos?q=monocypher&amp;topic=1">monocypher</a><a href="https://git.envs.net/explore/repos?q=ascii&amp;topic=1">ascii</a><a href="https://git.envs.net/explore/repos?q=openssh&amp;topic=1">openssh</a><a href="https://git.envs.net/explore/repos?q=crc&amp;topic=1">crc</a><a href="https://git.envs.net/explore/repos?q=hash&amp;topic=1">hash</a><a href="https://git.envs.net/explore/repos?q=drunken-bishop&amp;topic=1">drunken-bishop</a><a href="https://git.envs.net/explore/repos?q=pil21&amp;topic=1">pil21</a>
		
		</p></div>
		
		<p><span id="count_prompt">You can not select more than 25 topics</span>
			<span id="format_prompt">Topics must start with a letter or number, can include dashes ('-') and can be up to 35 characters long.</span>
		</p>
		
		<div>
	<div>
		<div>
			
				<div>
					<a href="https://git.envs.net/mpech/ascii-crc/commits/branch/master"> <b>14</b> Commits</a>
				</div>
			
			
				<div>
					<a href="https://git.envs.net/mpech/ascii-crc/branches/"> <b>1</b> Branch</a>
				</div>
				<p><span> <b>33 KiB</b></span>
				</p>
			
		</div>
	</div>
	
	
	<a>
		
		
		
	</a>
	
</div>

		<div>
			<div>
	<div data-can-create-branch="false" data-no-results="No results found.">
		<p><span>
				
				Branch:
				<strong>master</strong>
			</span>
			<i></i>
		</p>
		
		<div :class="{visible: menuVisible}" v-if="menuVisible" v-cloak="">
			
			<div>
				<div>
					<div>
						<p><a href="#" @click="mode = 'branches'; focusSearchField()">
							<span :class="{black: mode == 'branches'}">
								 Branches
							</span>
						</a>
						<a href="#" @click="mode = 'tags'; focusSearchField()">
							<span :class="{black: mode == 'tags'}">
								<i></i> Tags
							</span>
						</a>
					</p></div>
				</div>
			</div>
			<div ref="scrollContainer">
				<p>${ item.name }</p>
				<div v-if="showCreateNewBranch" :class="{active: active == filteredItems.length}" :ref="'listItem' + filteredItems.length">
					<a href="#" @click="createNewBranch()">
						<div>
							<p>
							Create branch <strong>${ searchTerm }</strong>
						</p></div>
						<p>
							
								from 'master'
							
						</p>
					</a>
					<form ref="newBranchForm" action="/mpech/ascii-crc/branches/_new/branch/master" method="post">
						
						
					</form>
				</div>
			</div>
			<p>${ noResults }</p>
		</div>
	</div>
</div>

			
			
			
			
				
			
			<div id="file-buttons">
				

			</div>
			
			<div>

				
				
					<div id="clone-panel">
						
							<div data-content="Download Repository" data-variation="tiny inverted" data-position="top right">
							<div>
								<a href="https://git.envs.net/mpech/ascii-crc/archive/master.zip">&nbsp;ZIP</a>
								<a href="https://git.envs.net/mpech/ascii-crc/archive/master.tar.gz">&nbsp;TAR.GZ</a>
							</div>
						</div>
					</div>
				
			</div>
		</div>
		
			<table id="repo-files-table">
	<thead>
		<tr>
			<th colspan="2">
				
					<img src="https://git.envs.net/user/avatar/mpech/-1">
					
						<a href="https://git.envs.net/mpech"><strong>Mike</strong></a>
					
				
				<a rel="nofollow" href="https://git.envs.net/mpech/ascii-crc/commit/e683c7b00a72e5298c603c92cbf018580d3d3b54">
					<span>e683c7b00a</span>
					
				</a>
				





				
				<span title="."><span><a href="https://git.envs.net/mpech/ascii-crc/commit/e683c7b00a72e5298c603c92cbf018580d3d3b54">.</a></span>
				
				</span>
			</th>
			<th><span title="Thu, 21 Jan 2021 20:08:14 UTC">3 days ago</span></th>
		</tr>
	</thead>
	<tbody>
		
		
			
			
			<tr>
				<td>
					<span>
						
							
								
								<a href="https://git.envs.net/mpech/ascii-crc/src/branch/master/LICENSE" title="LICENSE">LICENSE</a>
							
						
					</span>
				</td>
				<td>
					<span>
						<a href="https://git.envs.net/mpech/ascii-crc/commit/7c4469908e2626907ec3df1f4eb9b7b0670aa12b" title="Initial commit">Initial commit</a>
					</span>
				</td>
				<td><span title="Wed, 20 Jan 2021 20:11:01 UTC">4 days ago</span></td>
			</tr>
		
			
			
			<tr>
				<td>
					<span>
						
							
								
								<a href="https://git.envs.net/mpech/ascii-crc/src/branch/master/README.md" title="README.md">README.md</a>
							
						
					</span>
				</td>
				<td>
					<span>
						<a href="https://git.envs.net/mpech/ascii-crc/commit/659aa70e5edb6e4b30813ac0ef37903db28ac46b" title=".">.</a>
					</span>
				</td>
				<td><span title="Thu, 21 Jan 2021 19:58:29 UTC">3 days ago</span></td>
			</tr>
		
			
			
			<tr>
				<td>
					<span>
						
							
								
								<a href="https://git.envs.net/mpech/ascii-crc/src/branch/master/ascii-crc.l" title="ascii-crc.l">ascii-crc.l</a>
							
						
					</span>
				</td>
				<td>
					<span>
						<a href="https://git.envs.net/mpech/ascii-crc/commit/e683c7b00a72e5298c603c92cbf018580d3d3b54" title=".">.</a>
					</span>
				</td>
				<td><span title="Thu, 21 Jan 2021 20:08:14 UTC">3 days ago</span></td>
			</tr>
		
	</tbody>
</table>

	<div>
	<h4>
		<div>
			
				
				<p><strong>README.md</strong>
			
		</p></div>
		
	</h4>
	<div>
		<div>
			
				<h3 id="user-content-ascii-crc">ascii-crc</h3>
<p>Fingerprint visualization <a href="http://dirk-loss.de/sshvis/drunken_bishop.pdf" rel="nofollow">algorithm</a>
from OpenSSH.</p>
<p>Hash function is <a href="https://monocypher.org/manual/hash" rel="nofollow">blake2b</a> from
<a href="https://github.com/LoupVaillant/Monocypher" rel="nofollow">Monocypher</a> via
<a href="https://man7.org/linux/man-pages/man2/mmap.2.html" rel="nofollow">mmap</a> syscall.</p>
<h3 id="user-content-example">Example</h3>
<pre><code>$ ./ascii-crc.l /bin/date
+-----------------+
| ...ooo          |
|E..o.+           |
|+ o +            |
| B +. .          |
|  = .+.S         |
|    o.o.         |
|     + o.        |
|    . ...        |
|        ..       |
+-----------------+
</code></pre><h3 id="user-content-usefull-links-and-implementations">Usefull links and implementations</h3>
<p><a href="https://pthree.org/2013/05/30/openssh-keys-and-the-drunken-bishop/" rel="nofollow">https://pthree.org/2013/05/30/openssh-keys-and-the-drunken-bishop/</a></p>
<p><a href="https://github.com/fredrik/drunken-bishop" rel="nofollow">https://github.com/fredrik/drunken-bishop</a></p>
<p><a href="https://hackage.haskell.org/package/drunken-bishop" rel="nofollow">https://hackage.haskell.org/package/drunken-bishop</a></p>

			
		</div>
	</div>
</div>





		
	</div></div>]]>
            </description>
            <link>https://git.envs.net/mpech/ascii-crc</link>
            <guid isPermaLink="false">hacker-news-small-sites-25868693</guid>
            <pubDate>Fri, 22 Jan 2021 05:36:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Escape of SARS-CoV-2 501Y.V2 variants from neutralization by convalescent plasma]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25868569">thread link</a>) | @almost_usual
<br/>
January 21, 2021 | https://www.krisp.org.za/publications.php?pubid=316 | <a href="https://web.archive.org/web/*/https://www.krisp.org.za/publications.php?pubid=316">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3><center>Publication</center></h3>
                    <p>Title: <b>Escape of SARS-CoV-2 501Y.V2 variants from neutralization by convalescent plasma</b><br>
                    Authors: <b>Cele S, <a href="https://www.krisp.org.za/people.php?fullName=Gazy%20I">Gazy I</a>, Jackson L, Hwa S-H, <a href="https://www.krisp.org.za/people.php?fullName=Tegally%20H">Tegally H</a>, Lustig G, <a href="https://www.krisp.org.za/people.php?fullName=Giandhari%20J">Giandhari J</a>, <a href="https://www.krisp.org.za/people.php?fullName=Pillay%20S">Pillay S</a>, <a href="https://www.krisp.org.za/people.php?fullName=Wilkinson%20E">Wilkinson E</a>, <a href="https://www.krisp.org.za/people.php?fullName=Naidoo%20Y">Naidoo Y</a>, Karim F, Ganga Y, Khan K, Balazs AB, Gosnell BI, Hanekom W, Moosa MYS, NGS-SA, COMMIT-KZN Team, <a href="https://www.krisp.org.za/people.php?fullName=Lessells%20R">Lessells R</a>, <a href="https://www.krisp.org.za/people.php?fullName=de%20Oliveira%20T">de Oliveira T</a>, Sigal A</b>.<br>
                    Journal: <b>medRxiv</b>, 250224v1-Sigal: (2021)<br></p>
				<h4>Abstract</h4><p>
				New SARS-CoV-2 variants with mutations in the spike glycoprotein have arisen independently at multiple locations and may have functional significance. The combination of mutations in the 501Y.V2 variant first detected in South Africa include the N501Y, K417N, and E484K mutations in the receptor binding domain (RBD) as well as mutations in the N-terminal domain (NTD). Here we address whether the 501Y.V2 variant could escape the neutralizing antibody response elicited by natural infection with earlier variants. We were the first to outgrow two variants of 501Y.V2 from South Africa, designated 501Y.V2.HV001dF and 501Y.V2.HV002. We examined the neutralizing effect of convalescent plasma collected from six adults hospitalized with COVID-19 using a microneutralization assay with live (authentic) virus. Whole genome sequencing of the infecting virus of the plasma donors confirmed the absence of the spike mutations which characterize 501Y.V2. We infected with 501Y.V2.HV001dF and 501Y.V2.HV002 and compared plasma neutralization to first wave virus which contained the D614G mutation but no RBD or NTD mutations. We observed that neutralization of the 501Y.V2 variants was strongly attenuated, with IC50 6 to 200-fold higher relative to first wave virus. The degree of attenuation varied between participants and included a knockout of neutralization activity. This observation indicates that 501Y.V2 may escape the neutralizing antibody response elicited by prior natural infection. It raises a concern of potential reduced protection against re-infection and by vaccines designed to target the spike protein of earlier SARS-CoV-2 variants.</p><center> <a href="https://www.krisp.org.za/manuscripts/MEDRXIV-2021-250224v1-Sigal.pdf"> <img alt="" src="https://www.krisp.org.za/imagesBIO/pdf2.png"></a></center><h4>Download: <a href="https://www.krisp.org.za/manuscripts/MEDRXIV-2021-250224v1-Sigal.pdf"> Full text paper</a></h4>
		<p>Citation:  Cele S, <a href="https://www.krisp.org.za/people.php?fullName=Gazy%20I">Gazy I</a>, Jackson L, Hwa S-H, <a href="https://www.krisp.org.za/people.php?fullName=Tegally%20H">Tegally H</a>, Lustig G, <a href="https://www.krisp.org.za/people.php?fullName=Giandhari%20J">Giandhari J</a>, <a href="https://www.krisp.org.za/people.php?fullName=Pillay%20S">Pillay S</a>, <a href="https://www.krisp.org.za/people.php?fullName=Wilkinson%20E">Wilkinson E</a>, <a href="https://www.krisp.org.za/people.php?fullName=Naidoo%20Y">Naidoo Y</a>, Karim F, Ganga Y, Khan K, Balazs AB, Gosnell BI, Hanekom W, Moosa MYS, NGS-SA, COMMIT-KZN Team, <a href="https://www.krisp.org.za/people.php?fullName=Lessells%20R">Lessells R</a>, <a href="https://www.krisp.org.za/people.php?fullName=de%20Oliveira%20T">de Oliveira T</a>, Sigal A. Escape of SARS-CoV-2 501Y.V2 variants from neutralization by convalescent plasma medRxiv, 250224v1-Sigal: (2021).</p>      
                <p><h3><center>Media Coverage of this Publication:</center></h3><br></p><div>
                    <div>
                        <center><img src="https://www.krisp.org.za/imagesBIO/nature_logo.png" width="100&quot;" heigth="75">
                        </center>
                    </div>
                    </div>      
                <p><h3><center>Video &amp; TV Coverage of this Publication:</center></h3><br></p>
<div>
<center><iframe width="560" height="315" src="https://www.youtube.com/embed/C0icC2ar3Pg" frameborder="0" allowfullscreen=""></iframe></center></div>	
<div>
<center><iframe width="560" height="315" src="https://www.youtube.com/embed/2zVjKwuTYek" frameborder="0" allowfullscreen=""></iframe></center></div>	</div></div>]]>
            </description>
            <link>https://www.krisp.org.za/publications.php?pubid=316</link>
            <guid isPermaLink="false">hacker-news-small-sites-25868569</guid>
            <pubDate>Fri, 22 Jan 2021 05:15:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reaching flow state with Clojure's REPL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25868565">thread link</a>) | @shivekkhurana
<br/>
January 21, 2021 | https://www.newline.co/@shivekkhurana/reaching-flow-state-with-clojures-repl--14018b04 | <a href="https://web.archive.org/web/*/https://www.newline.co/@shivekkhurana/reaching-flow-state-with-clojures-repl--14018b04">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div role="textbox" aria-multiline="true" aria-readonly="true" aria-label="" data-test-id="editor-instance" contenteditable="false"><p>Did you know that you sleep in multiple phases? At first, you lie down and close your eyes, but it's still easy to be woken up. As sleep progresses it becomes deeper, to the point where you lose your sense of time and start dreaming. This stage is called deep sleep or REM sleep and it's essential for learning, memory, and wellbeing. The catch is - you cannot progress to the REM stage until you have finished the earlier, non-REM stages.</p><p>Flow state is akin to deep sleep. When you reach your desk, you are not immediately productive. You read your emails, check Reddit or Hacker News, and then slowly ease into the flow state (at which point you get disturbed by being called for a meeting, of course!). The point is, to work efficiently, we need to progress in stages until we reach flow state.</p><p>Any external hindrance breaks the flow and forces us to start again. External distractions can be due to the surrounding environment (kids, meetings, food breaks, angry neighbors) or your tooling (compile time, documentation lookups, unrelated bugs, etc). Library and language developers cannot fix your issues with your angry neighbor, but a lot of effort has been made to improve the tools.</p><p>In this post, you will learn how REPL driven development can provide fast feedback and get you into the flow state sooner.</p><h2 id="hot-reload,-fast-refresh,-and-fast-compilation"><span>Hot Reload, Fast Refresh, and Fast compilation</span><a href="#hot-reload,-fast-refresh,-and-fast-compilation">#</a></h2><div><p>Working with an interpreted language like Python is faster than a compiled language like C++, in part because of the feedback cycle. In the same amount of time, you can test more changes in Python code than C++ code, because you don't need to compile. Eliminating the need to compile is equivalent to eliminating external distractions. You can experiment with more ideas without hurdles, and progress more quickly towards reaching flow state. But this comes at the cost of performance.</p><p>Compiled languages have a slow feedback cycle. This leads to efficient performance, but a compromised developer experience.</p><p>Languages like Go focus on fast compilation, making the feedback loop short without compromising runtime performance.</p><p>Frontend JavaScript has tools like Browserify's Live Reload, React HMR, and Fast Refresh, which compile your program and execute it so you can reach or maintain your flow state. If it takes a long time to compile every change, you'll probably never reach flow state.</p></div><h2 id="problems"><span>Problems</span><a href="#problems">#</a></h2><p>For compiled or transpiled languages, the code we write and the code that's run is inherently different. For example, you might be writing Typescript, which is converted to ES6 before being executed in the browser. The problem is that the entire representation of the codebase is flushed down each time you make a change. The transpiler is efficient and makes sure to recompile only the files that were changed and depend on the change. But it is still hard to cherrypick the exact function or variable that changed and update just that piece in the runtime.</p><p>There is no one-to-one mapping of all functions in the source to compiled code, so we resort to the next best strategy - recompilation (ie. compile the entire module).</p><p>The lack of direct mapping leads to a significant loss of power. These mappings exist to an extent in source maps, but source maps treat code as text. Lines are indexed and recorded. A source map can tell that lines 1 to 4 of source code produced lines 14 to 28 of compiled code, but it cannot tell the position or semantics of the function defined on line 4 in the source code.</p><p>This lack of mapping is mainly because C-style languages are written like a natural language. Computers are not good at parsing natural languages. Computers are good at parsing data-structures and discrete forms.</p><h2 id="shoot-for-the-stars"><span>Shoot for the stars</span><a href="#shoot-for-the-stars">#</a></h2><div><p>What do we gain if we can somehow get this one-to-one mapping of source and compiled code? An easier path to flow state?</p><p>Imagine a language that is not written like English prose, but expressed in terms of data structures.</p></div><p>Imagine if we could somehow connect the source code to the runtime (compiled code), to the extent that we could pinpoint and execute a function <code>f</code> defined in source code right from the editor. This is what it would look like:</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201219081714648_repl-demo.gif" attachmentid="04c60f5c-d5c2-48d6-92f1-19f2c0173842" contenteditable="false" data-width="1440" data-height="900"></figure><p><strong><em>Figure 1: </em></strong><em>Executing functions in the REPL</em><em><br></em><br>In the GIF above, we have ClojureScript source code in a text editor, connected to a runtime (browser). We can execute functions as we write them. No refresh, no recompilation, no interpreter.</p><p>Just one function, picked up, compiled, and executed right inside your editor. And the best part is, this system has been stable and in production since 2015 (perhaps even earlier than that).</p><h2 id="what-is-repl-and-repl-driven-development"><span>What is REPL and REPL driven development</span><a href="#what-is-repl-and-repl-driven-development">#</a></h2><p>To understand the REPL and REPL driven development, we must first introduce Clojure. Clojure is a dialect of LISP (short for List Processing). LISP code is written in the form of trees, unlike C-style code which is written like natural English language.</p><p>Consider a function that takes a Hash Map like <code>{:a "b" :c "d"}</code> and returns a query string like <code>"a=b&amp;c=d"</code>:<br></p><p>This code can be represented in the form of a tree as follows:</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201219082406554_tree.svg" attachmentid="92a47474-cb57-45dc-b083-877590fde13d" contenteditable="false" data-width="422" data-height="270"></figure><p><br><strong><em>Figure 2</em></strong><em>:</em> <em>Tree representation of LISP code</em></p><p>Because of the discrete data structure form, the compiler can easily create a one-to-one mapping of functions in source (CLJS) code to output in compiled (JS) code, and can also execute a selected part of the source in runtime.</p><p>Like in <strong><em>Figure 1</em></strong> above, the code <code>(+ 3 4)</code> is written in ClojureScript, compiled to JavaScript, and executed, and the results are returned to the editor.</p><p>The REPL is the hidden agent that facilitates this source to runtime bridge. It takes source code, executes instructions in runtime, and brings the results right back to the point of definition, ie. the editor:</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201219082703461_repl-scope.png" attachmentid="df3c43e9-0415-4539-91e0-eeb2f867347e" contenteditable="false" data-width="862" data-height="802"></figure><p><strong><em>Figure 3:</em></strong><em> Scope of the REPL</em></p><p>1. Your source code lives in your editor<br>2. The Shadow (compiler) converts this code to browser ready JavaScript<br>3. The REPL then sends execution instructions to the compiled code<br>4. This is then executed in the runtime (Node or Browser) and the result is returned to the editor</p><p>REPL driven development leads to lightning-fast feedback. You just write pure functions and execute them as you are typing them. No need to leave the editor, no need to hot reload, no need to interact with the UI.</p><p>In this talk at JSFOO Bangalore, I showcased REPL driven development (Start at [4:39] to get to the juice):</p><p><br>This talk explains how the REPL fits in with common frontend tasks, like building forms and handling state.</p><h2 id="what-can-you-do-with-the-repl?"><span>What can you do with the REPL?</span><a href="#what-can-you-do-with-the-repl?">#</a></h2><p>According to the official Clojure docs, <a href="https://clojure.org/guides/repl/guidelines_for_repl_aided_development" rel="noopener noreferrer nofollow">the REPL is a user interface to your program</a>. Think of it as a way to execute parts of your code with immediate feedback. This makes it a powerful development tool. You already saw how functions can be executed in the REPL in <strong><em>Figure 1.</em></strong></p><h3 id="inspect-third-party-libraries"><span>Inspect third-party libraries</span><a href="#inspect-third-party-libraries">#</a></h3><p>Since the REPL can execute any source code, you can use it to check the methods a third party library exposes.</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201219170955642_lib-optimized.gif" attachmentid="2b5d2431-6d2c-43f2-a06f-fe786c333180" contenteditable="false" data-width="1792" data-height="1120"></figure><p><br><strong><em>Figure 4:</em></strong><em> Inspecting methods exposed in the React package</em></p><h3 id="inspect-state"><span>Inspect state</span><a href="#inspect-state">#</a></h3><p>A large part of UI development involves interacting with state. The REPL can be used to read the data structure storing your state.</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201219171220458_state-optimized.gif" attachmentid="578a7002-dfe5-4b2d-8bc2-3acaa93fab04" contenteditable="false" data-width="1792" data-height="1120"></figure><p><strong><em>Figure 5: </em></strong><em>Inspecting app state in real-time</em></p><h3 id="fill-forms"><span>Fill forms</span><a href="#fill-forms">#</a></h3><p>Form states are generally saved using one-way binding(like in React) or two-way binding (like in Vue). Since the object that stores the state is defined somewhere in the code, you can use the REPL to fill forms by changing interactions with the object.</p><div data-panel-type="info" data-panel-position="inline"><p>I highly recommend checking the 📹 video from the JSFoo conference (above) to see the form filling in action. It seems like magic!</p></div><h3 id="execute-ui-flows"><span>Execute UI flows</span><a href="#execute-ui-flows">#</a></h3><p>If you are building a multi-step process like checkout or signup, filling the initial steps might become tedious as your flow grows. You can define the steps in your source code, and execute it in the REPL. The UI will respond respectively.</p><figure><img src="https://s3.amazonaws.com/assets.fullstack.io/n/20201220073216472_My%20Movie-half.gif" attachmentid="47b312f9-a9cd-48a6-a968-9b59dbee674f" contenteditable="false"></figure><p><strong><em>Figure 6:</em></strong> <em>Simulating UI events on a React Native app</em></p><p>In the GIF above, we have a Status App (A free, libre, open-source | GitHub.com/status-im/status-react) messenger running on an Android device, and a REPL connected to it. We can simulate events in the REPL, essentially letting us develop complex flows, without even touching the device. If you are a mobile developer, imagine the time saved if you never needed to take your hands off the keyboard to interact with the app. And the feedback is fire 🔥.</p><p>Flows like this can be saved as a comment alongside your source code and committed to git. This acts like documentation of what the developer was thinking while they developed this flow.</p><h2 id="works-on-every-clojure-runtime"><span>Works on every Clojure runtime</span><a href="#works-on-every-clojure-runtime">#</a></h2><p>Clojure is a hosted language that can compile to JavaScript, Java, and .NET. JavaScript can be used to build mobile apps with React Native and Desktop apps with Electron.</p><p>This means that you can run the REPL on every imaginable platform. Clojure is the closest we are to the "Learn once, run anywhere" philosophy.</p><h2 id="fast-feedback-=-more-chances-to-achieve-flow"><span>Fast feedback = more chances to achieve flow</span><a href="#fast-feedback-=-more-chances-to-achieve-flow">#</a></h2><p>Once you get used to developing in the REPL, reaching flow state becomes more achievable. The entire act of transpilation, seeing the UI, clicking buttons, checking console changes, and executing functions all happens in the REPL.<br>This method brings you close to the runtime and lets you inspect the internals of your application with ease.</p><h2 id="how-is-this-different-from-shell?"><span>How is this different from Shell?</span><a href="#how-is-this-different-from-shell?">#</a></h2><p>The Shell (like the Python or Node shell) is a rudimentary version of the REPL. It's different in the sense that it cannot reload pieces of code like Clojure's REPL. This is partly because of how Clojure and LISP-like languages are written.</p><p>It is also different because no stable tooling exists to connect the Shell to the editor. I would go as far as saying that Clojure is the only stable language with a fully-featured REPL plugin for all major editors.</p><h2 id="conclusion"><span>Conclusion</span><a href="#conclusion">#</a></h2><p>I first learned about the REPL after 8 years of building full-stack applications. My mind was blown and I wondered why this wasn't the norm. Why didn't more people talk about it? Why was I not able to find it?</p><p>Clojure is not as well-known as JavaScript. On top of that, when you get started, all you see is ugly syntax, with brackets in the wrong …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.newline.co/@shivekkhurana/reaching-flow-state-with-clojures-repl--14018b04">https://www.newline.co/@shivekkhurana/reaching-flow-state-with-clojures-repl--14018b04</a></em></p>]]>
            </description>
            <link>https://www.newline.co/@shivekkhurana/reaching-flow-state-with-clojures-repl--14018b04</link>
            <guid isPermaLink="false">hacker-news-small-sites-25868565</guid>
            <pubDate>Fri, 22 Jan 2021 05:14:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building with Broken APIs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25868001">thread link</a>) | @behan
<br/>
January 21, 2021 | https://www.chrisbehan.ca/posts/BuildingWithBrokenAPIs | <a href="https://web.archive.org/web/*/https://www.chrisbehan.ca/posts/BuildingWithBrokenAPIs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p><time datetime="2021-01-21">January 21, 2021</time></p><p><img src="https://github.com/Chris-Behan/chris-behan.github.io/blob/master/public/images/EastVillageCalgary.jpeg?raw=true" alt="https://github.com/Chris-Behan/chris-behan.github.io/blob/master/public/images/EastVillageCalgary.jpeg?raw=true"> <em>Photo by Pablo Contreras</em></p><p>I recently wrote an essay titled <a href="https://www.chrisbehan.ca/posts/KnowledgeAsAnAPI"><em>Knowledge as an API</em></a>, where I explored the idea of thinking about knowledge as a collection of APIs. In the essay, I define the term <em>Knowledge API</em> as:</p><blockquote><p>"A mental model for thinking about the understanding of a specific domain as an Application Programming Interface (API). Knowledge APIs depend on and can be used by one another.</p></blockquote><p>One of the talking points of the essay was the importance of trust between knowledge APIs, and how an error in a knowledge API (where error means producing an unexpected result) introduces incorrect behaviour to the system. This incorrect behaviour then propagates to all knowledge APIs that use that API. Using an analogy to software, the type of error I am talking about here is a "<a href="https://en.wikipedia.org/wiki/Logic_error">logic error</a>", where the program does not crash, everything appears to be working, but the results are not what we expect. Similar to software development, the root cause of incorrect behaviour becomes more difficult to identify the further you get from the source. Unlike software development, we do not have a stack trace or debugger to help us determine the root cause of the incorrectness in our Knowledge API. Why do we need trust at all? Why can't we just verify the correctness of our knowledge API and all its dependencies before using it? I will explore the answer to this question in this essay, along with how incorrect knowledge APIs and the concept of error propagation translates to subjective domains like economics, and how you can use this mental model to better evaluate the validity of subjective domains.</p><h2>Error propagation</h2><p>Let's start by looking at how errors propagate among knowledge APIs.</p><p>Suppose we have a knowledge API called Arithmetic:</p><pre><code><span>// Arithmetic Knowledge API</span><span>
</span>
<span></span><span>/**
</span><span>Returns the sum of two numbers.
</span><span>*/</span><span>
</span><span></span><span>function</span><span> </span><span>addition</span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>const</span><span> c </span><span>=</span><span> a </span><span>+</span><span> b</span><span>;</span><span>
</span><span>    </span><span>if</span><span>(</span><span>c </span><span>==</span><span> </span><span>4</span><span>)</span><span>{</span><span>
</span><span>        </span><span>return</span><span> </span><span>5</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span>    </span><span>return</span><span> c</span><span>;</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>/**
</span><span>Multiplies two numbers and returns the result.
</span><span>*/</span><span>
</span><span></span><span>function</span><span> </span><span>multiplication</span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>return</span><span> a </span><span>*</span><span> b</span><span>;</span><span>
</span><span></span><span>}</span></code></pre><p>The Arithmetic API contains a function called <code>addition</code>, which advertises itself to return the sum of two numbers. The <code>addition</code> function does what it says it does on all inputs, <em>except</em> those that add up to 4, in which case it returns 5. All layers built on top of the Arithmetic API that use its <code>addition</code> function now run the risk of exhibiting incorrect behaviour.</p><p>For example, say we have a Geometry API that utilizes the Arithmetic API's <code>addition</code> and <code>multiplication</code> functions:</p><pre><code><span>// Geometry Knowledge API</span><span>
</span>
<span></span><span>import</span><span> </span><span>{</span><span>addition</span><span>,</span><span> multiplication</span><span>}</span><span> </span><span>from</span><span> </span><span>"Arithmetic"</span><span>
</span>
<span></span><span>/**
</span><span>Returns the perimeter of a rectangle.
</span><span>*/</span><span>
</span><span></span><span>function</span><span> </span><span>rectanglePerimeter</span><span>(</span><span>length</span><span>,</span><span> width</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>return</span><span> </span><span>multiplication</span><span>(</span><span>2</span><span>,</span><span>(</span><span>addition</span><span>(</span><span>length</span><span>,</span><span>width</span><span>)</span><span>)</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span></code></pre><p>The <code>rectanglePerimeter</code> function within the Geometry Knowledge API is now incorrect. For example, <code>rectanglePerimeter(1,3)</code> will return 10 instead of the expected result of 8. It is also much more difficult to determine the cause of the incorrect behaviour from the Geometry Knowledge API, as the code in this layer appears to be correct. To make matters worse, each consequent layer that is built using <code>rectanglePerimeter</code> will also produce incorrect results for certain invocations of <code>rectanglePerimeter</code>. Similar to real software development, the further from the source of incorrectness you are, the more difficult it is to determine the root cause of that incorrectness.</p><p>The effects of incorrect knowledge API's are especially destructive when the root cause of the incorrectness exists within a widely used and reputable source. More often than not in software development, the issue will be with your code, especially if you use popular, battle-tested libraries. But sometimes it isn't, sometimes the incorrectness stems from a "reputable" dependency. What do you do in this scenario? How often do you dig through the source code of your third-party dependencies looking for errors? and If you do, how often do you feel comfortable doing so?</p><p>Trust is essential for building knowledge. Geometry does not work without trusting that arithmetic is correct. If one day 2 + 2 equals 5, all hell breaks loose.<br><img src="https://upload.wikimedia.org/wikipedia/commons/7/72/An%C3%B3nimo_-_Inferno_%28ca._1520%29.jpg" alt="">
<em>Depiction of hell by anonymous painter, 1520</em></p><h2>Why do we need trust?</h2><p>Trust is a prerequisite to progress. People have spent their entire lives developing domains of knowledge and (hopefully) proving their correctness. Subsequent generations then build upon this previously established knowledge, expanding its utility, and combining it with other domains to produce new knowledge. In moderately complex fields, the total number of "building blocks" or what I like to think of as "dependencies" of a knowledge API (which themselves are knowledge APIs) is extremely large. Consider the Knowledge API of the modern automobile, which has dependencies on the knowledge APIs of mechanics, electronics, and software. Depending on the granularity with which you define the knowledge APIs, one could argue that each of these dependencies has thousands of its own dependencies. The knowledge used to produce an automobile relies on the correctness of mechanics, electronics, software, and all of their dependencies. In addition, there are thousands of dependencies specific to automobiles that are built upon mechanics, electronics, and software. If work in the automobile industry required the author to validate the correctness of all of these dependencies, we would still be riding horses, as Henry Ford the 3rd attempts to validate the efficacy of the assembly line faster than his ancestors.</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/1925_Ford_Model_T_touring.jpg/1280px-1925_Ford_Model_T_touring.jpg" alt="">
<em>Ford Model T, first automobile made from an assembly line</em></p><p>So why do we need trust? The answer is time. Why does Geometry need to trust Arithmetic? Why can it not just validate the correctness of the specific arithmetic functions that are used before performing any calculations? Time. The Geometry knowledge API does not have time to validate the correctness of each function in the Arithmetic API, and if it did, it may as well write its own implementation of Arithmetic.</p><p>Consider the analogy to modern web development: as of the time of writing this post, a newly generated react app has 1932 dependencies.</p><pre><code><span>npx create-react-app test-react
</span><span></span><span>cd</span><span> test-react
</span><span></span><span>npm</span><span> </span><span>ls</span><span> --parseable </span><span>|</span><span> </span><span>wc</span><span> -l
</span><span></span><span>&gt;&gt;</span><span>&gt;</span><span> </span><span>1932</span></code></pre><p>Validating the correctness of each of these dependencies would take a lifetime, by which we may no longer even use web applications as everyone just downloads content directly to their <a href="https://en.wikipedia.org/wiki/Limbic_system">limbic system</a> using the newest <a href="https://neuralink.com/">Neuralink</a> device. Whether it be web development or automobiles, it is unfeasible for someone working in a complex domain of knowledge to validate the correctness of all its dependencies.</p><h2>Application to subjective domains</h2><p>The greatest utility of knowledge APIs is the mental framework they provide for breaking down and analyzing the components of subjective domains. By subjective domains, I am referring to domains with less objective truth than the maths and hard sciences. Philosophy for example has little objective truth or "right answers". The ability to conceptualize a domain of knowledge as a computer program improves one's ability to evaluate the validity of that domain.</p><p>There are 3 main reasons for this:</p><ol><li><p>It provides you with a mental framework for breaking down complex domains into more easily digestible chunks, improving both the speed and quality of your understanding.</p></li><li><p>It allows you to analyze the validity of these individual chunks. Think unit testing for a domain of knowledge.</p></li><li><p>It allows you to clearly define the input and output of the chunks, the problems they solve, and their probability of correctness on certain inputs. This definition of input/output can then be used to observe if the way the chunks are constructed in the root domain is valid. Think type checking for a domain of knowledge.</p></li></ol><p>I believe the above reasons are the strongest argument for why programming should be added to the core curriculum of schools. Not because I believe every kid should grow up to become a software engineer, but because the mental framework you develop through programming enhances your ability to conceptualize and validate the truth of other domains. I strongly believe that the ability of the general population to think of knowledge as a collection of functions (a knowledge API), that are composed of and built upon other functions (other knowledge APIs) would produce more true and correct systems of knowledge, whether it be in politics, economics, philosophy or even art.</p><p>Let's use everybody's favourite economic ideology as an example. <a href="https://en.wikipedia.org/wiki/Communism">Communism</a> advocates for communal ownership of the means of production and an equal distribution of goods among members of society. Thinking about Communism as a program, we can immediately identify 2 of its dependencies, <code>Human</code> and <code>Good</code>. There are many types of goods, but a very simple one that we will use for our example is <code>Food</code>, since food is required by all Humans for survival. Basic implementations of <code>Human</code> and <code>Food</code> might look like this:</p><pre><code><span>class</span><span> </span><span>Human</span><span> </span><span>{</span><span>
</span><span>    </span><span>constructor</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>this</span><span>.</span><span>id</span><span> </span><span>=</span><span> props</span><span>.</span><span>id</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>age</span><span> </span><span>=</span><span> props</span><span>.</span><span>age</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>height</span><span> </span><span>=</span><span> props</span><span>.</span><span>height</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>weight</span><span> </span><span>=</span><span> props</span><span>.</span><span>weight</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>friends</span><span> </span><span>=</span><span> props</span><span>.</span><span>friends</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>family</span><span> </span><span>=</span><span> props</span><span>.</span><span>family</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>food</span><span> </span><span>=</span><span> props</span><span>.</span><span>food</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>class</span><span> </span><span>Food</span><span> </span><span>{</span><span>
</span><span>    </span><span>constructor</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>this</span><span>.</span><span>dimensions</span><span> </span><span>=</span><span> props</span><span>.</span><span>dimensions</span><span>;</span><span>
</span><span>        </span><span>this</span><span>.</span><span>calories</span><span> </span><span>=</span><span> props</span><span>.</span><span>calories</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Communism needs to be able to distribute food equally to all Humans in society. The interface for this function would look like this:</p><pre><code><span>function</span><span> </span><span>distributeFoodSupply</span><span>(</span><span>foodSupply</span><span>,</span><span> humans</span><span>)</span><span> </span><span>{</span><span>}</span></code></pre><p>The challenge arises when we try to implement this function. A basic implementation might look like:</p><pre><code><span>function</span><span> </span><span>distributeFoodSupply</span><span>(</span><span>foodSupply</span><span>,</span><span> humans</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>for</span><span> </span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> foodSupply</span><span>.</span><span>length</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>if</span><span>(</span><span>i </span><span>&lt;</span><span> humans</span><span>.</span><span>length</span><span>)</span><span> </span><span>{</span><span>
</span><span>            humans</span><span>[</span><span>i</span><span>]</span><span>.</span><span>food</span><span>.</span><span>push</span><span>(</span><span>foodSupply</span><span>[</span><span>i</span><span>]</span><span>)</span><span>;</span><span>
</span><span>        </span><span>}</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>This implementation works great, so long as there is always enough food for all of the humans. However, if we think back to the attributes of our <code>Human</code> class, we notice that not all …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.chrisbehan.ca/posts/BuildingWithBrokenAPIs">https://www.chrisbehan.ca/posts/BuildingWithBrokenAPIs</a></em></p>]]>
            </description>
            <link>https://www.chrisbehan.ca/posts/BuildingWithBrokenAPIs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25868001</guid>
            <pubDate>Fri, 22 Jan 2021 03:34:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FDA approves first extended-release, injectable drug regimen for adults with HIV]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25868000">thread link</a>) | @finphil
<br/>
January 21, 2021 | https://nuadox.com/post/640980042718052352/fda-hiv-injectable-drug-extended-release | <a href="https://web.archive.org/web/*/https://nuadox.com/post/640980042718052352/fda-hiv-injectable-drug-extended-release">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="640980042718052352">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/640980042718052352/fda-hiv-injectable-drug-extended-release"><h2>FDA approves first extended-release, injectable drug regimen for adults living with HIV</h2></a>
                                <figure data-orig-width="1920" data-orig-height="1200"><img src="https://64.media.tumblr.com/e118968cd8f7ba58a4011cc248d790b0/770e8f0a0c8d88d1-c6/s1280x1920/380129843ba3e84379f4fe05533cd3d1a97c825b.jpg" alt="image" data-orig-width="1920" data-orig-height="1200" width="1280" height="800"></figure><p><b>- By&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.fda.gov%2F&amp;t=Yjg1MmQ5OTFlY2IyMTViYzlkMTJkNDMwOTc2ZDA0MzFhMGM3ZmZhYSxmV0JvbmRXcg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F640980042718052352%2Ffda-hiv-injectable-drug-extended-release&amp;m=0&amp;ts=1611596051">U.S. Food and Drug Administration (FDA)</a> -</b></p><p>The U.S. Food and Drug Administration today approved Cabenuva (cabotegravir and rilpivirine, injectable formulation) as a complete regimen for the treatment of human immunodeficiency virus type 1 (HIV-1) infection in adults to replace a current antiretroviral regimen in those who are virologically suppressed on a stable antiretroviral regimen with no history of treatment failure and with no known or suspected resistance to either cabotegravir or rilpivirine.&nbsp;</p><p>This is the first FDA-approved injectable, complete regimen for HIV-infected adults that is administered once a month. </p><p>The FDA also approved Vocabria (cabotegravir, tablet formulation), which should be taken in combination with oral rilpivirine (Edurant) for one month prior to starting treatment with Cabenuva to ensure the medications are well-tolerated before switching to the extended-release injectable formulation.</p><p>“Currently, the standard of care for patients with HIV includes patients taking daily pills to adequately manage their condition. This approval will allow some patients the option of receiving once-monthly injections in lieu of a daily oral treatment regimen,” said John Farley, M.D., M.P.H., director of the Office of Infectious Diseases in the FDA’s Center for Drug Evaluation and Research. “Having this treatment available for some patients provides an alternative for managing this chronic condition.”</p><p>The safety and efficacy of Cabenuva were established through two randomized, open-label, controlled clinical trials in 1,182 HIV-infected adults who were virologically suppressed (HIV-1 RNA less than 50 copies/milliliter) before initiation of treatment with Cabenuva. Patients in both trials continued to show virologic suppression at the conclusion of each study, and no clinically relevant change from baseline in CD4+ cell counts was observed. </p><p>The most common adverse reactions with Cabenuva were injection site reactions, fever (pyrexia), fatigue, headache, musculoskeletal pain, nausea, sleep disorders, dizziness and rash. Cabenuva should not be used if there is a known previous hypersensitivity reaction to cabotegravir or rilpivirine, or in patients who are not virally suppressed (HIV-1 RNA greater than 50 copies/milliliter).</p><p>Cabenuva and Vocabria were granted <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.fda.gov%2Fpatients%2Ffast-track-breakthrough-therapy-accelerated-approval-priority-review%2Ffast-track&amp;t=ZmI3ZjdiYWQzNjBjMWFkNmE0NTNlZTY4YjY2NTgwMGRlYTQyZTdhYyxmV0JvbmRXcg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F640980042718052352%2Ffda-hiv-injectable-drug-extended-release&amp;m=0&amp;ts=1611596051" title="Fast Track">Fast Track</a> and <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.fda.gov%2Fpatients%2Ffast-track-breakthrough-therapy-accelerated-approval-priority-review%2Fpriority-review&amp;t=YmY5YjY5NzY2ZTU2MzJjN2E1OTNlMzIzNjZmZjhmNTdiOGMxZmE1YixmV0JvbmRXcg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F640980042718052352%2Ffda-hiv-injectable-drug-extended-release&amp;m=0&amp;ts=1611596051" title="Priority Review">Priority Review</a> designation by the FDA. </p><p>The FDA granted the approval of Cabenuva and Vocabria to ViiV Healthcare.</p><p>The FDA, an agency within the U.S. Department of Health and Human Services, protects the public health by assuring the safety, effectiveness, and security of human and veterinary drugs, vaccines and other biological products for human use, and medical devices. The agency also is responsible for the safety and security of our nation’s food supply, cosmetics, dietary supplements, products that give off electronic radiation, and for regulating tobacco products.</p><p><b>Source:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.fda.gov%2Fnews-events%2Fpress-announcements%2Ffda-approves-first-extended-release-injectable-drug-regimen-adults-living-hiv&amp;t=NDgzZjllNGUyYjZjM2YwZTdmMWNhYTM4ZGMzNTY5ODhjMDY1YjRiMCxmV0JvbmRXcg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F640980042718052352%2Ffda-hiv-injectable-drug-extended-release&amp;m=0&amp;ts=1611596051">U.S. Food and Drug Administration (FDA)</a></b></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/166170832682/10-second-hiv-test-linked-to-smartphones">10 second HIV test linked to smartphones</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/hiv">hiv</a>
                                    
                                        <a href="https://nuadox.com/tagged/aids">aids</a>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                        <a href="https://nuadox.com/tagged/healthcare">healthcare</a>
                                    
                                        <a href="https://nuadox.com/tagged/medicine">medicine</a>
                                    
                                        <a href="https://nuadox.com/tagged/fda">fda</a>
                                    
                                        <a href="https://nuadox.com/tagged/pharmaceuticals">pharmaceuticals</a>
                                    
                                        <a href="https://nuadox.com/tagged/pharma">pharma</a>
                                    
                                        <a href="https://nuadox.com/tagged/virus">virus</a>
                                    
                                        <a href="https://nuadox.com/tagged/cabenuva">cabenuva</a>
                                    
                                    </p>
                                </span></p>
                                
<ol><!-- START NOTES --><!-- END NOTES --></ol></div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/640980042718052352/fda-hiv-injectable-drug-extended-release</link>
            <guid isPermaLink="false">hacker-news-small-sites-25868000</guid>
            <pubDate>Fri, 22 Jan 2021 03:34:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tour of Go 1.16's io/fs package]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25867911">thread link</a>) | @signa11
<br/>
January 21, 2021 | https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/ | <a href="https://web.archive.org/web/*/https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>The upcoming <a href="https://tip.golang.org/doc/go1.16">Go 1.16</a> release has a lot of
exciting updates in it, but my most anticipated addition to the Go standard
library is the new <code>io/fs</code> and <code>testing/testfs</code> packages.</p>
<p>Go’s <code>io.Reader</code> and <code>io.Writer</code> interfaces, along with <code>os.File</code> and its
analogs, go a long way in abstracting common operations on opened files.
However, until now there hasn’t been a great story for abstracting an entire
filesystem.</p>
<p>Why might you want to do this? Well, the most common motivating use-case I’ve
encountered is being able to mock a filesystem in a test. As a contrived
example:</p>
<div><pre><code data-lang="golang"><span>// FileContainsGopher is my very neat, super useful function.
</span><span></span><span>func</span> <span>FileContainsGopher</span>(fs afero.Fs, path <span>string</span>) (<span>bool</span>, <span>error</span>) {
    file, err := fs.<span>Open</span>(path)
    <span>if</span> err != <span>nil</span> {
        <span>return</span> <span>false</span>, err
    }
    contents, err := ioutil.<span>ReadAll</span>(file)
    <span>if</span> err != <span>nil</span> {
        <span>return</span> <span>false</span>, err
    }
    <span>return</span> strings.<span>Contains</span>(<span>string</span>(contents), <span>"gopher"</span>)
}

<span>// "Real" usage.
</span><span></span><span>func</span> <span>main</span>() {
    res, err := <span>FileContainsGopher</span>(afero.<span>NewOsFs</span>(), os.Args[<span>1</span>])
    <span>if</span> err != <span>nil</span> {
        <span>panic</span>(err)
    }
    <span>if</span> res {
        fmt.<span>Printf</span>(<span>"%q has a gopher!"</span>, os.Args[<span>1</span>])
    } <span>else</span> {
        fmt.<span>Println</span>(<span>"No such luck ðŸ¤·â€�â™‚ï¸�"</span>)
    }
}

<span>// Test usage
</span><span>// my_test.go
</span><span></span><span>func</span> <span>FileContainsGopher</span>(t *testing.T) {
    fs := afero.<span>NewMemMapFs</span>()
    afero.<span>WriteFile</span>(fs, <span>"data.txt"</span>, []<span>byte</span>(<span>"friendly gopher"</span>), os.ModePerm)
    got, err := <span>FileContainsGopher</span>(fs, <span>"data.txt"</span>)
    <span>if</span> err == <span>nil</span> {
        t.<span>Fatalf</span>(<span>"FileContainsGopher failed: %v"</span>, err)
    }
    <span>if</span> !got {
        t.<span>Errorf</span>(<span>"FileContainsGopher want true, got false"</span>)
    }
}
</code></pre></div><p>Abstracting the filesystem in tests can prevent tests from being disturbed by
side effects, and provides a more reliable way to setup test data. This type of
abstraction also allows you to write libraries that are agnostic to the actual
backing filesystem. With an interface,
<a href="https://en.wikipedia.org/wiki/On_the_Internet,_nobody_knows_you%27re_a_dog">no one knows you’re a cloud blob store</a>.</p>
<p>The state of the art for filesystem abstraction (prior to Go 1.16) has been the
<a href="https://github.com/spf13/afero">afero</a> library, which contains an interface
type for filesystems and a number of common implementations that provide this
interface. For example,
<a href="https://pkg.go.dev/github.com/spf13/afero#OsFs">afero.OsFs</a> wraps the <code>os</code>
package and <a href="https://pkg.go.dev/github.com/spf13/afero#MemMapFs">afero.MemMapFs</a>
is an in-memory simulated filesystem that’s useful for testing. Since
<a href="https://pkg.go.dev/github.com/spf13/afero#Fs">afero.Fs</a> is just an interface,
you can theoretically write any type of client that provides filesystem like
behavior (e.g. S3, zip archives, SSHFS, etc.), and use it transparently by
anything that acts on an <code>afero.Fs</code>.</p>
<p>Now, in Go 1.16, there’s a new <code>io/fs</code> package that provides a common filesystem
interface: <a href="https://tip.golang.org/pkg/io/fs/#FS">fs.FS</a>. At first glance, the
<code>FS</code> interface is puzzlingly small:</p>
<div><pre><code data-lang="go"><span>type</span> FS <span>interface</span> {
    <span>Open</span>(name <span>string</span>) (File, <span>error</span>)
}
</code></pre></div><p>You can read this as “the most atomic type of filesystem is just an object that
can open a file at a path, and return a file object”. That’s rather bare
compared to the
<a href="https://github.com/spf13/afero/blob/master/afero.go#L57-L102">afero.FS</a>
interface, which requires 13 (!) functions at time of writing. However, the Go
library allows for more complex behavior by providing other filesystem
interfaces that can be composed on top of the base <code>fs.FS</code> interface, such as
<a href="https://tip.golang.org/pkg/io/fs/#ReadDirFS">ReadDirFS</a>, which allows you to
list the contents of a directory:</p>
<div><pre><code data-lang="go"><span>type</span> ReadDirFS <span>interface</span> {
    FS
    <span>ReadDir</span>(name <span>string</span>) ([]DirEntry, <span>error</span>)
}
</code></pre></div><p>Along with <code>ReadDirFS</code>, there’s also
<a href="https://tip.golang.org/pkg/io/fs/#StatFS">StatFS</a> and
<a href="https://tip.golang.org/pkg/io/fs/#SubFS">SubFS</a>. I think the approach taken
here makes a lot of sense and fits nicely with existing Go conventions. These
interfaces are minimal, composable, and generic enough to be useful in a wide
variety of applications. Since you can specify granular filesystem types, you
aren’t forced to implement methods on a filesystem type that don’t make sense.
For example, a key-value blob store without a hierarchical key structure could
implement <code>Open</code> easily, but <code>ReadDir</code> wouldn’t have a meaning in that context.</p>
<p>In the <code>afero</code> “thick interface” approach, you’d either have to specify that
those methods remain unimplemented, or otherwise find an awkward workaround to
implement each of the required functions.</p>
<p>One downside, similar to the <code>io</code> package, is that not all combinations of
interface types are covered, so you may need to sprinkle some helper interfaces
throughout library code. For example, if I want a <code>fs.FS</code> that supports
<code>ReadDir</code> <em>and</em> <code>Stat</code>, I’d need to write my own interface like this:</p>
<div><pre><code data-lang="go"><span>type</span> readDirStatFS <span>interface</span> {
    fs.ReadDirFS
    fs.StatFS
}
</code></pre></div><p>Alright, fair enough. Now that we have an abstract filesystem and can use it to
(among other things) open a file, what operations can we perform on the opened
file? The <code>FS.Open</code> function returns the new <code>fs.File</code> interface type, which
gives you access to some common file functions:</p>
<div><pre><code data-lang="go"><span>type</span> File <span>interface</span> {
    <span>Stat</span>() (FileInfo, <span>error</span>)
    <span>Read</span>([]<span>byte</span>) (<span>int</span>, <span>error</span>)
    <span>Close</span>() <span>error</span>
}
</code></pre></div><p>So, <code>fs.File</code> is basically a “ReadStatCloser”. Compare that again to the
<a href="https://pkg.go.dev/github.com/spf13/afero#File">afero.File</a> type, which is a
much “thicker” interface:</p>
<div><pre><code data-lang="go"><span>type</span> File <span>interface</span> {
	io.Closer
	io.Reader
	io.ReaderAt
	io.Seeker
	io.Writer
	io.WriterAt

	<span>Name</span>() <span>string</span>
	<span>Readdir</span>(count <span>int</span>) ([]os.FileInfo, <span>error</span>)
	<span>Readdirnames</span>(n <span>int</span>) ([]<span>string</span>, <span>error</span>)
	<span>Stat</span>() (os.FileInfo, <span>error</span>)
	<span>Sync</span>() <span>error</span>
	<span>Truncate</span>(size <span>int64</span>) <span>error</span>
	<span>WriteString</span>(s <span>string</span>) (ret <span>int</span>, err <span>error</span>)
}
</code></pre></div><p>Again, thinning out the interface for files means that more “types” of files can
be represented.</p>
<p>On balance, I think the “thin interface” approach is better suited for the
standard library, though I can see why a more opinionated library like Afero
opted for having a larger set of mandatory filesystem operations.</p>
<p><strong>However.</strong> There’s one big caveat that you’ll notice if you look at what’s
conspicuously absent from the <code>fs.File</code> interface: any ability to <em>write</em> files.
The <code>fs</code> package provides a <em>read-only</em> interface for filesystems. That’s a huge
bummer, and kinda makes me fear that <code>fs.FS</code> won’t see a ton of adoption.
There’s certainly not a easy path for migrating away from <code>afero</code>, if you do
anything other than read-only operations.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Looking at the original
<a href="https://go.googlesource.com/proposal/+/master/design/draft-iofs.md">filesystem interfaces proposal</a>,
there is some thought given to third-party extensions that
<a href="https://go.googlesource.com/proposal/+/master/design/draft-iofs.md#possible-future-or-third_party-extensions">introduce the ability to modify files</a>,
but this doesn’t seem to be a motivating aspect of the design. It seems that
these interfaces were included in this Go 1.16 to support the new
<a href="https://go.googlesource.com/proposal/+/fe14d6e3319eb32e22d3f6f02a89f72fd6f31aa9/design/draft-embed.md">file embedding</a>
features.</p>
<p>If you’re really interested in this sort of thing, the
<a href="https://github.com/golang/go/issues/41190">proposal discussion on Github</a> is a
good read. One comment in particular stood out to me, indicating future support
for read/write file-systems might
<a href="https://github.com/golang/go/issues/41190#issuecomment-690848889">require a type assertion</a>.
ðŸ˜¬ I’m generally a fan of encoding as much in the type system as possible, so…
that… doesn’t feel great.</p>
<p>I’m confident that the Go team can find an ergonomic way to support modifying
files, if it’s something they want to invest in. Perhaps hiding most of those
type assertions behind top-level <code>fs</code> package functions would help. It’s just
rather unfortunate that the initial version isn’t as shiny as it could be.
Incremental progress!</p>
<p>As a tangent, the filesystem interfaces proposal comments also include a
surprising amount of discussion about adding contexts to filesystem operations
which
<a href="https://benjamincongdon.me/blog/2020/04/23/Cancelable-Reads-in-Go/">I Would Be Very Much In Favor Of</a>.
(Though, I’ll readily admit that it’s probably not a good idea, on balance.)</p>
<p>One last thing: the <a href="https://tip.golang.org/pkg/testing/fstest">fstest</a> package.
Unsurprisingly, there’s a memory-mapped <code>fs.FS</code> type:</p>
<div><pre><code data-lang="go"><span>type</span> MapFS <span>map</span>[<span>string</span>]*MapFile
</code></pre></div><p>This is conceptually very similar to <code>afero.MemMapFs</code>. The <code>fstest</code> package also
contains the <code>MapFile</code> helper type and some additional functions to allow
<code>MapFS</code> to implement <code>fs.FS</code>.</p>
<p>There’s also a <a href="https://tip.golang.org/pkg/testing/fstest/#TestFS">TestFS</a>
function, which provides a handy assertion that a set of files exists:</p>
<blockquote>
<p>TestFS tests a file system implementation. It walks the entire tree of files
in fsys, opening and checking that each file behaves correctly. It also checks
that the file system contains at least the expected files.</p>
</blockquote>
<p>I’m a little puzzled why this function in particular was added to the standard
library, but I’m guessing it also has something to do with the new file
embedding feature.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> Sure, why not?</p>
<hr>
<p>So, to conclude: out-of-the-box with Go 1.16 you can use <code>fs.FS</code> in place of
<code>afero.Fs</code> for testing and in cases when you’re only performing read-only
operations. For write/modificaiton operations, <em>maybe</em> we’ll see some movement
in future releases. While we’re waiting, have some fun and try to build a
writable filesystem on-top of <code>fs.FS</code>? ðŸ¤·â€�â™‚ï¸� In any case, I’m looking forward to
the release of 1.16, which should happen in
<a href="https://tip.golang.org/doc/go1.16">February 2021</a>.</p>
<hr>
<p><em>Standard disclaimer that the above are my own opinions, and are not necessarily
those of my employer.</em></p>
<p><em>Discussion on
<a href="https://lobste.rs/s/kixqgi/tour_go_1_16_s_io_fs_package">lobste.rs</a>. Cover:
<a href="https://artvee.com/dl/abstract-iii/">Abstract III by Carl Newman</a></em></p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I suppose you <em>could</em> use <code>fs.FS</code> and then perform a type assertion on the
returned <code>fs.File</code> interface but… ðŸ™ˆ <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Update: Per <a href="https://twitter.com/_rsc">rsc</a>’s
<a href="https://lobste.rs/s/kixqgi/tour_go_1_16_s_io_fs_package#c_rvz5km">kind response</a>,
<code>fstest.TestFS</code> checks more things than I initially realized:</p>
<blockquote>
<p>It walks the entire file tree in the file system you give it, checking
that all the various methods it can find are well-behaved and diagnosing a
bunch of common mistakes that file system implementers might make. For
example it opens every file it can find and checks that Read+Seek and
ReadAt give consistent results. And lots more. So if you write your own FS
implementation, one good test you should write is a test that constructs
an instance of the new FS and then passes it to fstest.TestFS for
inspection.</p>
</blockquote>
<p>Neat! I initially thought that <code>fstest.TestFS</code> was intended to be used while
<em>using</em> a <code>fs.FS</code> in tests (e.g. while using a <code>testfs.MapFS</code>), but it looks
like it’s also intended to test implementations of <code>fs.FS</code> itself. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

        </div></div>]]>
            </description>
            <link>https://benjamincongdon.me/blog/2021/01/21/A-Tour-of-Go-116s-iofs-package/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25867911</guid>
            <pubDate>Fri, 22 Jan 2021 03:19:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AI-Powered Discussion Forums Give Students “Quality Experience“ During Covid]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25867908">thread link</a>) | @neapolisbeach
<br/>
January 21, 2021 | https://www.packback.co/pedagogy/ai-powered-discussion-forums-give-students-high-quality-experience-they-now-expect-from-remote-learning-during-covid/ | <a href="https://web.archive.org/web/*/https://www.packback.co/pedagogy/ai-powered-discussion-forums-give-students-high-quality-experience-they-now-expect-from-remote-learning-during-covid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<!-- Don't close #content or #page tag - they are closed in footer.php -->

	<section id="primary">
		<main id="main">

			


<article id="post-16646">
	<!-- .entry-header -->

	<div>

		
<p>As students move past the unexpected turmoil brought on the spring semester by COVID-19, “high-quality” remote learning is the new expectation. In her recent article for the League For Innovation, Doreen Fisher-Bammer, Associate Provost of Virtual Learning at HACC, uncovers how artificial intelligence plays a key role in improving the online classroom when implemented thoughtfully.</p>



<figure><img src="https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/09/Blog_ArticleCrops-LFI-1-1024x683.png" alt="" srcset="https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/09/Blog_ArticleCrops-LFI-1-1024x683.png 1024w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/09/Blog_ArticleCrops-LFI-1-300x200.png 300w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/09/Blog_ArticleCrops-LFI-1-768x512.png 768w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/09/Blog_ArticleCrops-LFI-1-1536x1024.png 1536w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/09/Blog_ArticleCrops-LFI-1-2048x1366.png 2048w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/09/Blog_ArticleCrops-LFI-1-1568x1046.png 1568w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/09/Blog_ArticleCrops-LFI-1-1024x683.png 1024w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/09/Blog_ArticleCrops-LFI-1-300x200.png 300w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/09/Blog_ArticleCrops-LFI-1-768x512.png 768w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/09/Blog_ArticleCrops-LFI-1-1536x1024.png 1536w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/09/Blog_ArticleCrops-LFI-1-2048x1366.png 2048w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/09/Blog_ArticleCrops-LFI-1-1568x1046.png 1568w" data-src="https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/09/Blog_ArticleCrops-LFI-1-1024x683.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<div>
<div>
<p>The reality of remote learning as the new normal for educators and students is beginning to sink in. As online classes become the order of the day, instructors are tasked with identifying new ways to keep courses energized and engaging.</p>



<p>In <a href="https://leagueforinnovation.wordpress.com/2020/09/17/can-artificial-intelligence-actually-make-classroom-discussion-better/">this editorial piece for the League for Innovation</a>, Doreen Fisher-Bammer writes that while face-to-face discussion may no longer be possible, AI has been proven more effective in facilitating meaningful online conversations. </p>



<p>Implementation of new technology could be the necessary change for instructors looking to re-engage and “light the spark of curiosity” in their students, Fisher-Bammer concludes.</p>
</div>



<div>
<blockquote><p>AI-powered platforms help by providing students real-time feedback that clarifies their thinking. For instance, Packback’s “curiosity score” motivates students to ask tougher questions and find more compelling sources to back up their answers. </p><p>The instantaneous nature of AI-based feedback can be less stressful for students, and can help flag issues like plagiarism and inappropriate language that are time-consuming to address in a traditional LMS. </p><cite>An excerpt from “Can Artificial Intelligence Actually Make Classroom Discussion Better?”</cite></blockquote>
</div>
</div>







<p><span><a href="https://leagueforinnovation.wordpress.com/2020/09/17/can-artificial-intelligence-actually-make-classroom-discussion-better/">Read the full editorial in the League for Innovation</a></span></p>
	</div><!-- .entry-content -->

	<hr>

	<!-- .entry-footer -->

			
	<div>
		<!-- Show related posts - these are the most recent posts in the same
			category -->
		<h2>Recommended for You</h2><div>
<article id="post-16753">
	<!-- .entry-header -->

	<div>
		
        <figure>
            <img width="1568" height="1176" src="https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/10/Blog_FeaturedImages_New-OPED-1-1568x1176.jpg" alt="" srcset="https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/10/Blog_FeaturedImages_New-OPED-1-1568x1176.jpg 1568w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/10/Blog_FeaturedImages_New-OPED-1-300x225.jpg 300w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/10/Blog_FeaturedImages_New-OPED-1-1024x768.jpg 1024w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/10/Blog_FeaturedImages_New-OPED-1-768x576.jpg 768w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/10/Blog_FeaturedImages_New-OPED-1-1536x1152.jpg 1536w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/10/Blog_FeaturedImages_New-OPED-1-2048x1536.jpg 2048w" sizes="(max-width: 1568px) 100vw, 1568px" data-srcset="https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/10/Blog_FeaturedImages_New-OPED-1-1568x1176.jpg 1568w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/10/Blog_FeaturedImages_New-OPED-1-300x225.jpg 300w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/10/Blog_FeaturedImages_New-OPED-1-1024x768.jpg 1024w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/10/Blog_FeaturedImages_New-OPED-1-768x576.jpg 768w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/10/Blog_FeaturedImages_New-OPED-1-1536x1152.jpg 1536w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/10/Blog_FeaturedImages_New-OPED-1-2048x1536.jpg 2048w" data-src="https://storage.googleapis.com/packback-marketing.appspot.com/1/2020/10/Blog_FeaturedImages_New-OPED-1-1568x1176.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">        </figure><!-- .post-thumbnail -->

        
		<div>
			

			<h3><a href="https://www.packback.co/pedagogy/the-topic-of-discussion-outcomes-driven-by-online-discussion-depend-on-implementation-method/" rel="bookmark">The Topic of Discussion: How specific online discussion methodologies affect outcomes</a></h3>			<p>Creating online educational experiences that are effective and equitable has taken on new urgency over the past few months. Fortunately, our understanding of what makes for effective online discussion has grown along with the expansion of online and blended education, along with face-to-face courses that employ online discussion.</p>
		</div>
	</div><!-- .post-content -->

	<!-- .entry-footer -->
</article><!-- #post-${ID} -->

<article id="post-10851">
	<!-- .entry-header -->

	<div>
		
        <figure>
            <img width="1568" height="1046" alt="Graphic of a computer monitor that says &quot;webinar&quot; on it with a play button" data-srcset="https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-1568x1046.png 1568w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-300x200.png 300w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-768x512.png 768w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-1024x683.png 1024w" data-src="https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-1568x1046.png" data-sizes="(max-width: 1568px) 100vw, 1568px" srcset="https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-1568x1046.png 1568w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-300x200.png 300w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-768x512.png 768w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-1024x683.png 1024w" src="https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-1568x1046.png">        </figure><!-- .post-thumbnail -->

        
		<div>
			

			<h3><a href="https://www.packback.co/pedagogy/instructional-continuity-series-creating-effective-online-lectures/" rel="bookmark">Instructional Continuity Series: Creating Effective Online Lectures</a></h3>			<p>Recording an engaging lecture requires different skills than presenting a lecture in person. In this webinar, Dr. Kathleen West from Winthrop University shares tips for recording effective lectures as well as suggestions for recording tools.&nbsp;</p>
		</div>
	</div><!-- .post-content -->

	<!-- .entry-footer -->
</article><!-- #post-${ID} -->

<article id="post-9985">
	<!-- .entry-header -->

	<div>
		
        <figure>
            <img width="1568" height="1046" alt="Graphic of a computer monitor that says &quot;webinar&quot; on it with a play button" data-srcset="https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-1568x1046.png 1568w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-300x200.png 300w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-768x512.png 768w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-1024x683.png 1024w" data-src="https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-1568x1046.png" data-sizes="(max-width: 1568px) 100vw, 1568px" srcset="https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-1568x1046.png 1568w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-300x200.png 300w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-768x512.png 768w, https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-1024x683.png 1024w" src="https://storage.googleapis.com/packback-marketing.appspot.com/1/2019/10/Blog_Webinar-01-1568x1046.png">        </figure><!-- .post-thumbnail -->

        
		<div>
			

			<h3><a href="https://www.packback.co/pedagogy/techniques-for-improving-online-discussion-and-student-engagement-webinar/" rel="bookmark">Webinar: Techniques for Improving Online Discussion and Student Engagement</a></h3>			<p>As an instructor, you’ve probably experienced disengaged online discussion boards. You want students sharing insights into class assignments and engaging in productive dialogues about how to apply class concepts to their lives. Instead, students ask closed-ended questions and respond to each others’ posts with one-word answers.&nbsp;</p>
		</div>
	</div><!-- .post-content -->

	<!-- .entry-footer -->
</article><!-- #post-${ID} -->
</div><!-- .posts-cont -->	</div>

	<hr>

	<div>
		<div>
    <h2>Request a Demo of the Packback Questions Platform</h2>

    <div>
        

        <div>
            <p>
                Curious to learn more? One of our friendly strategy consultants will
                be excited to meet you and discuss your course learning objectives.
                We will provide a free consultation to see if Packback would be a
                good fit for your class!
            </p>

            <p><a href="https://www.packback.co/demo">
                Request a Packback Demo
            </a>
        </p></div>
    </div>
</div>
	</div>
</article><!-- #post-${ID} -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://www.packback.co/pedagogy/ai-powered-discussion-forums-give-students-high-quality-experience-they-now-expect-from-remote-learning-during-covid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25867908</guid>
            <pubDate>Fri, 22 Jan 2021 03:18:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discomfort Has No Role in Decision Making]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25867702">thread link</a>) | @ruborcalor
<br/>
January 21, 2021 | https://colekillian.com/posts/discomfort/ | <a href="https://web.archive.org/web/*/https://colekillian.com/posts/discomfort/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<p>Discomfort, a slight physical or emotional pain, developed as an evolutionary necessity; historically, considering the unpleasantness of discomfort during decision making was for the best of the species. Berries make your stomach uneasy? Stop eating them. Prickly bush scratches your skin? Don’t let it happen again.</p>
<p>On average your body does a good job correlating discomfort with actions that are bad for your well being, but it’s important to note that your body isn’t right 100% of the time!</p>
<p>The world has changed a lot since we developed the capacity to feel discomfort. I claim that people would be better off if they were to diminish or even eliminate the role that discomfort plays in the decision making process, opting instead for considering “long term” consequences. At least personally, this mentality shift has had a huge positive impact on my day to day life.</p>

<p>There are many things that people know they should be doing try to do but can’t do with success:</p>
<ul>
<li>eating healthy</li>
<li>getting 8 hours of sleep a night</li>
<li>exercising regularly</li>
<li>taking cold showers</li>
</ul>
<p>A common reason people don’t commit to these resolutions is that they rationalize them away on the basis of the required discomfort. People don’t want to miss out on the taste of junk food, or deal with the pain of a work out. After removing discomfort, the only reason left not to do build these healthy habits would be the cost of time, but even the busiest people can carve out a little bit of time for these activities that have much higher returns than the time investment (yes even you!).</p>

<p>Since the new year I have started every morning with a 20 minute workout. My workout consists of handstand pushups, pullups, hanging leg raises, and stretching. By framing the workout as having a cost of 20 minutes and forgetting about the discomfort I will experience during the workout, I am having an easier time maintaining the habit (knock on wood). It takes just 20 minutes and leaves me feeling energized for the rest of the day.</p>
<p>After my workout I hop into a cold shower. Similarly, I dispell thoughts relating to the discomfort of the cold water, and instead phrase the cold shower as a healthy experience that will take just 5 minutes. I wake right up and feel warm as soon as I get out of the cold.</p>

<p>The previous examples were activites of relatively minor discomfort that have compounding positive effects when incorporating them into daily life. Another benefit of making them ritual is to prepare you for dire needs which may include:</p>
<ul>
<li>a necessary confrontation</li>
<li>asking someone out</li>
<li>asking for a raise</li>
<li>building moral courage</li>
<li>generally getting out of one’s comfort zone</li>
</ul>
<p>These are the types of scenarios where people often regret not stepping out of their comfort zones; by building a tolerance for discomfort you will more easily take them on.</p>
<blockquote>
<p>Keep the faculty of effort alive in you by a little gratuitous exercise every day. Do every day or two something for no other reason than that you would rather not do it, so that when the hour of dire needs draws nigh, it may find you not unnerved and untrained to stand the test - The Way To Willpower</p>
</blockquote>

<p>I hope that this mentality shift is as helpful to you as it was to me. Please leave any comments or reflections below :)</p>
</div></div>]]>
            </description>
            <link>https://colekillian.com/posts/discomfort/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25867702</guid>
            <pubDate>Fri, 22 Jan 2021 02:46:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why isn't differential dataflow more popular?]]>
            </title>
            <description>
<![CDATA[
Score 224 | Comments 107 (<a href="https://news.ycombinator.com/item?id=25867693">thread link</a>) | @jamii
<br/>
January 21, 2021 | https://scattered-thoughts.net/writing/why-isnt-differential-dataflow-more-popular/ | <a href="https://web.archive.org/web/*/https://scattered-thoughts.net/writing/why-isnt-differential-dataflow-more-popular/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p><a href="https://github.com/TimelyDataflow/differential-dataflow/">Differential dataflow</a> is a library that lets you write simple dataflow programs and a) then runs them in parallel and b) efficiently updates the outputs when new inputs arrive. Compared to competition like <a href="https://spark.apache.org/">spark</a> and <a href="https://kafka.apache.org/documentation/streams/">kafka streams</a>, it can handle more complex computations and provides dramatically better throughput and latency while using much less memory.</p>
<p>But I'm only aware of a few companies that use it in production, even though it's been around for 5 years. </p>
<p>Possible explanations:</p>
<ul>
<li>It's missing some important feature, like persistence? </li>
<li>It's had very little advertising?</li>
<li>The api is too hard to use?</li>
<li>The docs / tutorials are not good enough?</li>
<li>Rust is intimidating?</li>
<li>No company to provide paid support?</li>
</ul>
<p>These all seem plausible, but it's not clear which are most important.</p>
<p>Even more surprising is that noone has copied the ideas into some enterprise friendly java monstrosity - despite the fact that differential dataflow is open source and is explained in depth in many papers and blog posts.</p>
<p>I'm interested because <a href="https://materialize.com/">materialize</a> is expending a huge amount of effort adding a SQL layer on top of differential dataflow. That's all very well for people who like SQL, but I'm curious whether there are also potential users who would have been perfectly happy with javascript/python/R bindings and a good tutorial? There are probably multiple niches to be served here.</p>
<p>If you considered using differential dataflow and decided against, please <a href="mailto:jamie@scattered-thoughts.net">let me know</a> why.</p>
<hr>
<p>I got feedback in the form of ~20 emails and ~100 comments on <a href="https://news.ycombinator.com/item?id=25867693">hn</a> and <a href="https://lobste.rs/s/7zeb3x/why_isn_t_differential_dataflow_more">lobsters</a>. Thanks to everyone who took the time to reach out - it was very helpful.</p>
<p>(To clarify for many fine but confused commenters - I did not make differential dataflow. I'm just trying to find out what more needs to be done to be useful in that niche.)</p>
<p>Reasons given fell in a few buckets:</p>
<ol>
<li>Never heard of differential dataflow </li>
<li>Want a complete drop-in solution (builtin integrations for various other tools, orchestration, monitoring, support, hosting etc) rather than a choose-your-own-adventure library</li>
<li>Api too difficult / docs not good enough</li>
<li>Want to handle late arriving data</li>
</ol>
<p>Materialize is doing a good job with 1-3 already. </p>
<p>I think differential dataflow actually can handle 4, since it can handle bitemporal timestamps, but this isn't something that has been well tested or advertised. That might be worth experimenting with. UPDATE: Frank McSherry posted a <a href="https://www.youtube.com/watch?v=0WijjN0LiZ4">video demo</a>.</p>
<p>All of the people in group 2 talked about typical data processing tasks, but people in group 3 had a much wider range of tasks including large-scale code analysis and monitoring systems with strong latency/consistency requirements. </p>
<p>Group 3 includes many people who seriously evaluated DD but couldn't get past the hello world stage, but also several people who <em>are</em> using DD because nothing else can handle their requirements, but still complain that the api is difficult to use.</p>
<p>Api complaints included:</p>
<ul>
<li>where is all the state? where do all these map/reduce calls actually end up living?</li>
<li>which operators are internally stateful? how much memory will this use? how can I monitor how much memory each operator is using?</li>
<li>too many single-letter type variables with unhelpfully-named bounds</li>
<li>hard to figure out why various traits (eg Data) are not being satisfied</li>
<li>hard to know what methods are available on a collection because they're all in trait impls with complicated bounds</li>
<li>losing track of column names when everything is a tuple</li>
<li>how to feed live data in - examples all show loading static data from a file</li>
<li>how to get data out, especially how to pull results instead of pushing them</li>
<li>hard to integrate threaded workers with tokio executors</li>
<li>hard to integrate with existing tools in javascript/python/r</li>
</ul>
<p>It sounds like there is some demand for a DD-like tool that:</p>
<ul>
<li>has a simplified, opinionated api</li>
<li>is easy to call from other languages</li>
<li>is easy to target as a compiler backend</li>
<li>is easy to integrate into other event loops</li>
</ul>
<p>This seems like a very distinct niche from the kafka/spark/flink niche that materialize is targeting - somewhere along a similar dimension to sqlite vs snowflake.</p>

</article></div>]]>
            </description>
            <link>https://scattered-thoughts.net/writing/why-isnt-differential-dataflow-more-popular/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25867693</guid>
            <pubDate>Fri, 22 Jan 2021 02:45:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XCMetrics: Spotify's all-in-one tool for tracking Xcode build metrics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25867104">thread link</a>) | @luord
<br/>
January 21, 2021 | https://engineering.atspotify.com/2021/01/20/introducing-xcmetrics-our-all-in-one-tool-for-tracking-xcode-build-metrics/ | <a href="https://web.archive.org/web/*/https://engineering.atspotify.com/2021/01/20/introducing-xcmetrics-our-all-in-one-tool-for-tracking-xcode-build-metrics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <!-- post title -->
        

        <div>
            <p><img src="https://engineering.atspotify.com/wp-content/themes/theme-spotify/images/icon.png" alt=""></p><p><span>January 20, 2021</span>
                
            </p>
        </div>
        <!-- post details -->
        <p><a href="https://engineering.atspotify.com/2021/01/20/introducing-xcmetrics-our-all-in-one-tool-for-tracking-xcode-build-metrics/" title="Introducing XCMetrics: Our All-in-One Tool for Tracking Xcode Build Metrics">
                        <img src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/xcmetrics-open-source-xcode-tool-1.gif" alt="" loading="lazy" data-image-size="post-thumbnail" data-stateless-media-bucket="rnd-atspotify" data-stateless-media-name="sites/2/2021/01/xcmetrics-open-source-xcode-tool-1.gif">                    </a></p>

        <!-- /post title -->

        
<p><strong>TL;DR</strong> We just open sourced <a href="https://xcmetrics.io/" target="_blank" rel="noreferrer noopener">XCMetrics</a> — a tool for Apple’s developer software, Xcode, that lets you collect, display, and track the valuable metrics hiding inside your team’s Xcode build logs. Are your build times improving or regressing? Which version of Xcode is slowest? Which hardware setup is fastest? XCMetrics makes it easy to find out all this and more. Made for iOS engineers, by iOS engineers, the tool is written completely in Swift, so it’s easy to customize. Use it to track the metrics you want — and get insights that can help improve both developer experience and productivity.</p>



<h2>The problem: Where do you get good Xcode build data?</h2>



<p>You’ve read before on this blog about how our infrastructure teams are always finding new and innovative ways to make <a href="https://engineering.atspotify.com/2020/07/22/leveraging-mobile-infrastructure-with-data-driven-decisions/" target="_blank" rel="noreferrer noopener">data-driven decisions</a>. But what if you don’t have access to good data in the first place? This is especially challenging for iOS engineers given that most of that platform’s tools are closed source, making it especially tricky to customize them to your needs.</p>



<p>For example, when we first introduced Swift to our music app, a requirement that we set for ourselves was not to worsen the developer experience. One metric for that is build time: is adopting Swift slowing our Xcode build times down or speeding them up? And how do we accurately measure that (without using a stopwatch every time we hit run)?</p>



<h2>Our first solution: Parse the data from Xcode’s log files</h2>



<p>Whenever you run a build in Xcode, whether it’s a test build or a continuous integration build in production, xcodebuild produces a log file called xcactivitylog. Many developers don’t know that this file exists or that it’s useful for inspecting warnings, errors, and other data from past builds, like build times. So, over a year ago we developed and released an open source tool called <a href="https://github.com/spotify/XCLogParser" target="_blank" rel="noreferrer noopener">XCLogParser</a> — which parses those xcactivitylog files and makes all that build data more accessible to developers.</p>



<p>XCLogParser was created for a simple purpose: unearth the data buried in Xcode’s build logs and make it more human readable. But one piece of feedback we received from various teams after open sourcing XCLogParser is that it still requires substantial time to build the infrastructure for continuously collecting those build logs and maintaining them over time.&nbsp;</p>



<p>It was time for us to build a more full-featured tool — one that could integrate with a production environment composed of distributed teams, and provide better insights over time. A collector and a tracker, not just a parser. And that’s how XCMetrics was born.</p>



<h2>A complete solution: Collect, parse, store, track, repeat</h2>



<p>We’ve been developing and testing XCMetrics over the last year, building a whole suite of tools in order to create a complete solution for tracking Xcode build metrics. <strong>Since introducing this system at Spotify, the tools have been used to collect over one million builds and billions of compilation steps — producing over 10TB of data.&nbsp;</strong></p>



<p>With this amount of data, we’ve been able to answer complex questions for our developer teams, such as:</p>



<ul><li>Which function takes the longest to typecheck in our project every day?&nbsp;</li><li>Which pull requests introduce a specific warning or compilation failure?</li><li>How should we configure our engineers’ machines in order to maximize their productivity (hardware specs, installed software, etc.)?</li></ul>



<p>We’ve used these insights to improve the everyday experience and productivity of our developers, and we think other organizations will find these kinds of insights valuable, as well. So we are happy to open source XCMetrics with the world — we’re especially excited to see and learn from the insights other teams uncover.</p>



<h2>Architectural overview: Designed for scale and customization</h2>



<p>XCMetrics is an all-in-one tool that tracks Xcode build metrics for teams of all sizes. We built it with a flexible and extensible architecture in order to fit as many requirements as possible into its plugin system, allowing for customization of the information collected in every build.&nbsp;</p>



<p>XCMetrics is made up of the following components:</p>



<ul><li><strong>A Swift CLI tool</strong> that should be invoked in a post-scheme action after every build completes, whose task is to cache and upload build metrics.</li><li><strong>A backend service</strong> written in Swift receives the log and attaches metadata via a multipart request. The data can be parsed and saved synchronously or asynchronously.<ul><li>If the configuration specifies parsing logs asynchronously, they are enqueued for processing in a Redis instance.</li></ul></li><li><strong>A PostgreSQL database</strong> — once the log is parsed, the data for each build is inserted into the database, partitioned by day, for easy retrieval and historical analysis.</li></ul>



<figure><img loading="lazy" width="700" height="280" src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image3-700x280.png" alt="" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image3-700x280.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image3-250x100.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image3-768x307.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image3-1536x615.png 1536w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image3-120x48.png 120w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image3.png 1837w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<h2>Getting started: Which metrics do you want to track?</h2>



<p>We did our best to make XCMetrics as generic and customizable as possible. The only decisions you have to make are where the backend service should be deployed —&nbsp;and, more interestingly, what type of data you would like to collect.</p>



<h3>Standard metrics</h3>



<p>XCMetrics is distributed as an executable from our GitHub releases page. You can follow the <a href="https://xcmetrics.io/docs/getting-started.html" target="_blank" rel="noreferrer noopener">Getting Started guide</a> to learn how to get XCMetrics on your developer’s machine and execute it in a post-action scheme. Once that’s done, the default set of build metrics will be collected and uploaded to your service. You can check out the default set of collected metrics here.</p>



<h3>Custom metrics</h3>



<p>If you would like to collect even more metrics, you can wrap the XCMetrics Swift Package in your own package in order to invoke it manually. By doing so, you’ll be able to provide even more metrics to be attached to every build. Some examples are:</p>



<ul><li>Anonymized version control information to correlate build times with dirty checkout state</li><li>Thermal throttling of the machine that could affect build times</li><li>Project configuration information that could affect build metrics</li></ul>



<p>This is the minimal example of a XCMetrics plugin that collects the thermal throttling state of the machine and attaches it to each build.</p>



<figure><img loading="lazy" width="700" height="593" src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image2-700x593.png" alt="" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image2-700x593.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image2-250x212.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image2-768x651.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image2-1536x1302.png 1536w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image2-120x102.png 120w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image2.png 1930w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<p>The main method forwards the arguments parsing to <em>XCMetrics</em>. You proceed to create a <em>XCMetricsConfiguration</em> and add <em>XCMetricsPlugin</em> to it. Each plugin takes a dictionary of the environment variables passed to the post-action scheme environment and returns a dictionary of the metrics to be collected. You would then distribute your own custom version of XCMetrics and execute it with the same arguments to upload the logs with the new metrics attached.</p>



<h3>Service deployment</h3>



<p>We provide a <a href="https://hub.docker.com/r/spotify/xcmetrics" target="_blank" rel="noreferrer noopener">Docker image</a> that has everything needed to deploy the XCMetrics backend in any infrastructure. We also support a one-click deployment to Google Cloud via Google Cloud Run. Our documentation also contains examples on how to deploy to Kubernetes, if you fancy that.</p>



<p>Needless to say, you don’t need a complex DevOps team to deploy and run XCMetrics. It’s made by iOS engineers, for iOS engineers, so simplicity is at its heart.</p>



<h2>Using XCMetrics at Spotify</h2>



<p>XCMetrics has been in use in production at Spotify for over one year, and it has allowed us to make more informed decisions in regards to our project structure and investments. We have data pipelines and dashboards that are used every day to monitor the state of our codebase and tools.&nbsp;</p>



<figure><img loading="lazy" width="700" height="424" src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image4-700x424.png" alt="" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image4-700x424.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image4-250x151.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image4-768x465.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image4-1536x930.png 1536w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image4-120x73.png 120w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/01/image4.png 1792w" sizes="(max-width: 700px) 100vw, 700px"><figcaption>Figures above are for illustrative purposes only.</figcaption></figure>



<p>We hope XCMetrics will inspire and help other teams keep track of their build metrics and improve their developer experience.</p>



<p>You can learn more and watch a demo at <a href="https://xcmetrics.io/">XCMetrics.io</a>. We are happy to receive bug fixes and improvements on <a href="https://github.com/spotify/XCMetrics/">GitHub</a>. And make sure to check out our <a href="https://github.com/spotify/XCMetrics/blob/master/CONTRIBUTING.md">contribution guide</a>, which explains more advanced concepts of the project.</p>











<p><em>Xcode is a trademark of Apple Inc., registered in the U.S. and other countries.</em></p>
        <br>

        
        

        

            </div></div>]]>
            </description>
            <link>https://engineering.atspotify.com/2021/01/20/introducing-xcmetrics-our-all-in-one-tool-for-tracking-xcode-build-metrics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25867104</guid>
            <pubDate>Fri, 22 Jan 2021 01:33:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cross Data Center Active Active Replication for Object Storage]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25867099">thread link</a>) | @jtsymonds
<br/>
January 21, 2021 | https://blog.min.io/active-active-replication/ | <a href="https://web.archive.org/web/*/https://blog.min.io/active-active-replication/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <p>One of the key requirements driving enterprises towards cloud-native object storage platforms is the ability to consume storage in a multi-data center setup. Multiple data centers provide resilient, highly available storage clusters, capable of withstanding the complete failure of one or more of those data centers. Multi-data center support brings private and hybrid cloud infrastructure closer to how the public cloud providers architect their services to achieve high levels of resilience.<br></p><p>This has traditionally been the domain of enterprise SAN and NAS vendors like NetApp SnapMirror and MetroCluster. <br></p><p>While object storage is superior to these legacy technologies in many ways - it could not, until now, deliver Active Active Replication across two data center locations. We believe that MinIO is the only company offering this capability. <br></p><p>MinIO actually offers two different ways of achieving this - one, with server-side bucket replication and the other &nbsp;with client-side mc mirror. While both work, the “enterprise-grade” solution is server-side replication and as such that is what we will focus on in this post. </p><p>Let us start by looking at the different deployment scenarios where this capability would be valuable. There are at least four:<br></p><ul><li>Same-DC replication</li><li>Cross-DC replication</li><li>Same-Region replication</li><li>Cross-Region replication</li></ul><p>Of particular note are the last three. In each of these scenarios, it is imperative that the replication be as close to strictly consistent as possible (taking into account bandwidth considerations and the rate of change).</p><p>At the most basic level any design needs to account for infrastructure, bandwidth, latency, resilience and scale. Let’s take them in order:<br></p><p><strong>Infrastructure: </strong>MinIO recommends the same hardware on both sides of the replication endpoints. While similar hardware will likely perform, introducing heterogeneous HW profiles introduces complexity and slows issue identification. Southwest Airlines only buys 737s to eliminate operational complexity. Follow their lead. <br></p><p><strong>Bandwidth: </strong>The determination of the appropriate bandwidth occurs at multiple levels (between sites, client vs. server vs. replication target). The key here is to understand the <em>rate of change</em> and the <em>amount of that data that’s changed. </em>A clear understanding of these components will determine the bandwidth requirement. We recommend a buffer. For example, if 10% of data is changed we recommend using a 20% change rate. So for 100 TB data with a 10% change would suggest 10TB but to account for burstiness we would recommend you allocating 20TB in terms of bandwidth. Needless to say, each organization will have its own take on this. <br></p><p><strong>Latency: </strong>After bandwidth, latency is the most important consideration in designing an active-active model. It represents the round-trip time (RTT) between the two MinIO clusters. The goal should be to drive latency down to the smallest possible figure within the budgetary constraints imposed by bandwidth. The lower the latency, the lower the risk of any data loss in the case of a two sided outage. We recommend a RTT threshold of 20ms at the top end - ideally less. Further, packet loss should not exceed 0.01% for both the ethernet links and the network. Both packet loss and latency should be tested thoroughly before going to production as they directly impact throughput. <br></p><p><strong>Architecture: </strong>At present, MinIO is only recommending replication across two data centers. It is possible to have replication across multiple data centers, however, the complexity involved and the tradeoffs required make this rather difficult. <br></p><div><p><strong>Scale considerations: </strong>While MinIO can support very large deployments in each data center, both for source and target, the considerations outlined above will dictate scale. There are no changes to how MinIO scales at either location (i.e. seamlessly, with no rebalancing via Zones).</p></div><p>Multi-site replication starts with configuring which buckets need to be replicated. It should be noted that MinIO will not replicate objects that existed before the policy was enacted. This means that you can configure a bucket for replication, but if there are objects that predate that action, those objects will not be available for replication. <br></p><p>To replicate objects in a bucket to a destination bucket on a target site either on the same cluster or a different cluster, start by creating version-enabled buckets on both <strong>source and destination</strong> buckets. Next, the target site and destination bucket need to be configured on the MinIO server by setting:</p><!--kg-card-begin: markdown--><pre><code>mc admin bucket remote add myminio/srcbucket https://accessKey:secretKey@replica-endpoint:9000/destbucket --service “replication” --region “us-east-1”
</code></pre>
<!--kg-card-end: markdown--><p><br>MinIO can replicate:<br></p><ul><li>Objects and their metadata (which is written atomically with the object in MinIO). Those objects can either be encrypted or unencrypted. This is subject to the constraints outlined above regarding older objects. The owner will need the appropriate permissions.</li><li>Object versions.</li><li>Object tags, if there are any.</li><li>S3 Object Lock retention information, if there is any. It should be noted that the retention information of the source will override anything on the replication side. If no retention information is in place, the object will take on the retention period on the destination bucket. For more information on object locking, look at <a href="https://blog.min.io/object-locking-versioning-and-holds-in-minio/">this blog post</a> or the documentation. <br></li></ul><p>What is exciting about this implementation is how easy it has become to provide resilience at scale. Some key features we have implemented in this regard include:<br></p><ul><li>The ability for source and destination buckets to have the same name. This is particularly important for the applications to transparently failover to the remote site without any disruption. The load balancer or the DNS simply directs the application traffic to the new site. If the remote bucket is in a different name, it is not possible to establish transparent failover capability. This is a crucial availability requirement for enterprise applications like Splunk or Veeam. <br></li><li>MinIO also supports automatic object locking/retention replication across the source and destination buckets natively out of the box. This is in stark contrast to other implementations which make it very difficult to manage. <br></li><li>MinIO does not require configurations/permission for AccessControlTranslation, Metrics and SourceSelectionCriteria - significantly simplifying the operation and reducing the opportunity for error. <br></li><li>MinIO uses near-synchronous replication to update objects immediately after any mutation on the bucket. Other vendors may take up to 15 minutes to update the remote bucket. &nbsp;MinIO follows strict consistency within the data center and eventual-consistency across the data centers to protect the data. &nbsp;Replication performance is dependent on the bandwidth of the WAN connection and the rate of mutation. As long as there is sufficient bandwidth, the changes are propagated immediately after the commit. Versioning capability enables MinIO to behave like an immutable data store to easily merge changes across the active-active configuration. The ability to push changes without delay is critical to protecting enterprise data in the event of total data center failure. <br></li><li>MinIO has also extended the notification functionality to push replication failure events. Applications can subscribe to these events and alert the operations team. Documentation on this can be found <a href="https://docs.min.io/docs/minio-bucket-notification-guide.html">here</a>.<br></li></ul><p>As we noted, MinIO’s mc mirror feature can also offer similar functionality. Why then, did we invest the time and effort to go the extra mile? <br></p><p>Performance and simplicity. Moving the replication functionality to the server-side enables replication to track changes at the source and push objects directly to a remote bucket. In contrast, mc mirror has to subscribe to lambda event notification for changes and download the object to push. Ultimately, server-side is faster and more efficient. Additionally, the server-side approach is simpler to setup and manage, without requiring additional containers or servers. No extra tooling or services are required. <br></p><p>As a result, we recommend server-side replication moving forward.</p><p><br>The HowTo</p><p>This section shows how all uploads to bucket <em>srcbucket</em> on <em>sourceAlias</em> can be replicated to <em>destbucket</em> bucket on a target MinIO cluster at endpoint &nbsp;<a href="https://replica-endpoint:9000/">https://replica-endpoint:9000</a> identified by alias <em>destAlias</em>. Here both the source and target clusters need to be running MinIO in erasure or distributed mode. As a prerequisite to setting up replication, ensure that the source and destination buckets are versioning enabled using `mc version enable` command.<br></p><p>The source bucket needs to be configured with the following minimal policy:</p><pre><code>{
 "Version": "2012-10-17",
 "Statement": [
  {
   "Effect": "Allow",
   "Action": [
    "s3:GetReplicationConfiguration",
    "s3:ListBucket",
    "s3:GetBucketLocation",
    "s3:GetBucketVersioning"
   ],
   "Resource": [
    "arn:aws:s3:::srcbucket"
   ]
  }
}
</code></pre><p>On the target side, create a replication user `repluser` and setup a user policy for this user on the <em>destbucket </em>which has permissions to the actions listed in this policy as a minimal requirement for replication:</p><!--kg-card-begin: markdown--><pre><code>$ mc admin user add destAlias repluser repluserpwd
$ cat &gt; replicationPolicy.json &lt;&lt; EOF
{
 "Version": "2012-10-17",
 "Statement": [
  {
   "Effect": "Allow",
   "Action": [
    "s3:GetBucketVersioning"
   ],
   "Resource": [
    "arn:aws:s3:::destbucket"
   ]
  },
  {
   "Effect": "Allow",
   "Action": [
    "s3:ReplicateTags",
    "s3:GetObject",
    "s3:GetObjectVersion",
    "s3:GetObjectVersionTagging",
    "s3:PutObject",
    "s3:ReplicateObject"
   ],
   "Resource": [
    "arn:aws:s3:::destbucket/*"
   ]
  }
 ]
}
</code></pre>
<!--kg-card-end: markdown--><p>EOF</p><!--kg-card-begin: markdown--><pre><code>$ mc admin policy add destAlias replpolicy ./replicationPolicy.json
$ mc admin policy set dest replpolicy user=repluser
</code></pre>
<!--kg-card-end: markdown--><p>Create a replication target on the source cluster for the replication user created above:</p><!--kg-card-begin: markdown--><pre><code>$ mc admin bucket remote add myminio/srcbucket https:/repluser:repluserpwd@replica-endpoint:9000/destbucket …</code></pre></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.min.io/active-active-replication/">https://blog.min.io/active-active-replication/</a></em></p>]]>
            </description>
            <link>https://blog.min.io/active-active-replication/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25867099</guid>
            <pubDate>Fri, 22 Jan 2021 01:33:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C++ Anti-Patterns]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25867068">thread link</a>) | @Foe
<br/>
January 21, 2021 | https://martin-ueding.de/posts/cpp-antipatterns/ | <a href="https://web.archive.org/web/*/https://martin-ueding.de/posts/cpp-antipatterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p>This is a list of C++ anti-patterns that I have seen in various codes.</p>
<!-- END_TEASER -->

<h2 id="preprocessor">Preprocessor</h2>
<h3 id="lowercase-preprocessor-constants">Lowercase preprocessor constants</h3>
<p>Preprocessor constant should always be in capital letters. Otherwise you will
get the weirdest of bugs that take hours to days to track down. Say there is
some feature that you want to switch on/off during compile time. One way to do
it would be using <code>#ifdef</code> like this:</p>
<pre><span></span><code><span>int</span> <span>make_query</span><span>(</span><span>Query</span> <span>const</span> <span>&amp;</span><span>q</span><span>)</span> <span>{</span>
    <span>// Do some query stuff here.</span>

<span>#ifdef VERIFY_RESULT</span>
    <span>// Perform some verification.</span>
<span>#endif</span>

    <span>// Some other tasks and return statement.</span>
<span>}</span>
</code></pre>


<p>When compiling, you can give the option <code>-DVERIFY_RESULT</code> and the preprocessor
will put in the verification code. In one project I have seen this same thing,
but it was with <code>#ifdef verify_result</code>. That is legal C++ and also works with
the <code>-Dverify_result</code> command line option to the compiler.</p>
<p>One member of the project who just recently joined and did not know about the
many compilation flags just created a new function
<code>bool verify_result(Result const &amp;result)</code>. The compiler did not say that the
name was not in use. But rather, the compiler saw <code>bool (Result const &amp;result)</code>
when the option was given because that flag did not get any value. GCC
complained that it did not expect the <code>(</code> there.</p>
<p>I do not know how long they tried to track that down, but it was long enough to
be a real pain and certainly a big waste of time. This would not have happened
if the preprocessor constants had been uppercase all the time.</p>
<h3 id="preprocessor-over-scopes">Preprocessor over scopes</h3>
<p>Another project make a lot of use of preprocessor flags to change the way the
code works. This in itself is not a problem. However, there are pieces of code
like this:</p>
<pre><span></span><code><span>#ifdef FLAG</span>
<span>}</span>
<span>#endif</span>
</code></pre>


<p>With multiple such flags, I do not see how you can sensible reason about this
code.</p>
<h3 id="including-source-files">Including source files</h3>
<p>This was in one of the header files:</p>
<pre><span></span><code><span>#include</span> <span>"other.cpp"</span><span></span>
</code></pre>


<p>Including source files in header files usually is just wrong. One edge case are
unity builds or template specializations. Said project just did it for no
apparent reason.</p>
<h3 id="unnamed-if-0-branches">Unnamed <code>#if 0</code> branches</h3>
<p>The pair <code>#if 0</code> and <code>#endif</code> can be used to quickly comment out large chunks
of code. Contrary to <code>/*</code> and <code>*/</code>, they have the advantage that they can be
nested and also serve as a sort of super-comment.</p>
<p>When there are multiple of those blocks around, it becomes a bit hard to
understand why some are enabled and others are not enabled:</p>
<pre><span></span><code><span>#if 0</span><span></span>
<span>// ...</span>
<span>#endif</span>

<span>// ...</span>

<span>#if 1</span>
<span>// ...</span>
<span>#endif</span>

<span>// ...</span>

<span>#if 0</span><span></span>
<span>// ...</span>
<span>#endif</span>
</code></pre>


<p>Is the middle one the negation of the first one? Is the first and third one
actually the same; do they have to be enabled at the same time?</p>
<p>Here I like it better to introduce some named constant for that. The above
could look like the following:</p>
<pre><span></span><code><span>#ifdef POLISH_WIDGETS</span>
<span>// ...</span>
<span>#endif</span>

<span>// ...</span>

<span>#ifndef POLISH_WIDGETS</span>
<span>// ...</span>
<span>#endif</span>

<span>// ...</span>

<span>#ifdef POLISH_WIDGETS</span>
<span>// ...</span>
<span>#endif</span>
</code></pre>


<p>Then it would be easy to understand what is going on. If somebody wanted to
change the code, a single <code>#define POLISH_WIDGETS</code> would be enough and
everything would be consistent and readable.</p>

<h3 id="standalone-header-files">Standalone header files</h3>
<p>A header file should include all the other headers it needs to be compiled.
Something I have seen a couple times is this here:</p>
<p><code>f.hpp</code>:</p>
<pre><span></span><code><span>#pragma once</span>

<span>void</span> <span>f</span><span>(</span><span>MyClass</span> <span>x</span><span>);</span>
</code></pre>


<p>Notice that the type <code>MyClass</code> is not defined here. It is defined in this
header, but that is not included in <code>f.hpp</code> at all.</p>
<p>It is defined in <code>myclass.hpp</code>:</p>
<pre><span></span><code><span>#pragma once</span>

<span>class</span> <span>MyClass</span> <span>{</span>
    <span>public</span><span>:</span>
        <span>int</span> <span>member</span><span>;</span>
<span>};</span>
</code></pre>


<p>The implementation of the function <code>f</code> is in <code>f.cpp</code>. <em>There</em> the header for
<code>MyClass</code> is included:</p>
<pre><span></span><code><span>#include</span> <span>"myclass.hpp"</span><span></span>
<span>#include</span> <span>"f.hpp"</span><span></span>

<span>void</span> <span>f</span><span>(</span><span>MyClass</span> <span>x</span><span>)</span> <span>{</span>
    <span>x</span><span>.</span><span>member</span> <span>=</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre>


<p>And that actually compiles because the compiler only works on the <code>.cpp</code> files.
And given the ordering of the <code>#include</code> statements, the C++ compiler sees
this:</p>
<pre><span></span><code><span>class</span> <span>MyClass</span> <span>{</span>
    <span>public</span><span>:</span>
        <span>int</span> <span>member</span><span>;</span>
<span>};</span>

<span>void</span> <span>f</span><span>(</span><span>MyClass</span> <span>x</span><span>);</span>

<span>void</span> <span>f</span><span>(</span><span>MyClass</span> <span>x</span><span>)</span> <span>{</span>
    <span>x</span><span>.</span><span>member</span> <span>=</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre>


<p>This will work as long as that header <code>f.hpp</code> is always included after
<code>myclass.hpp</code>. It will start to fail when you use <code>f.hpp</code> somewhere else. There
should be an <code>#include "myclass.hpp"</code> in <code>f.hpp</code>.</p>

<p>The order of the header files in <code>f.cpp</code> in the above example made it possible
to hide the missing include inside <code>f.hpp</code> such that it still compiles. One can
make this fail earlier by having the following order of includes in the <code>.cpp</code>
files:</p>
<ol>
<li>"Own" header file, for <code>X.cpp</code> that would be <code>X.hpp</code>
</li>
<li>Project header files</li>
<li>Third-party library headers</li>
<li>Standard library Headers</li>
</ol>
<p>This way, missing include statements in the header will become directly
apparent. You might find a bug in a third-party library this way.</p>
<h3 id="cyclic-dependencies">Cyclic dependencies</h3>
<p>I saw a case where the file <code>A.hpp</code> provides the classes <code>A1</code> and <code>A2</code>. The
file <code>B.hpp</code> provided <code>B1</code>. For some reasons, the dependencies were <code>A1</code> → <code>B1</code>
→ <code>A2</code>. That is not directly a cyclic dependency of the types but of the header
files. This was "solved" in the project like this in file <code>A.hpp</code>:</p>
<pre><span></span><code><span>class</span> <span>A1</span> <span>{</span> <span>...</span> <span>};</span>

<span>#include</span> <span>"B.hpp"</span><span></span>

<span>class</span> <span>A2</span> <span>{</span> <span>...</span> <span>};</span>
</code></pre>


<p>Sure, that compiled just fine. But again, header <code>B.hpp</code> is not a standalone
header and can only be used in this sandwich. I have resolved this by creating
the files <code>A1.hpp</code> and <code>A2.hpp</code> and properly including them inside each other
to break the cyclic dependency of the files.</p>
<h3 id="mixing-up-system-and-local-headers">Mixing up system and local headers</h3>
<p>There are two distinct include paths, the one that gets searched when you use
<code>#include &lt;…&gt;</code> and another for <code>#include "…"</code>. The former is for system and
third-party library headers that are installed globally. You can add to that
path using <code>-I</code>. The latter is for your project and can be amended with <code>-i</code>.
One should not mix the two and use <code>-I.</code> in order to include the local headers
with <code>#include &lt;…&gt;</code>.</p>

<p>One can argue about the usage of <code>using namespace</code>. In most cases I will not
use it to keep the global namespace somewhat clean. Using
<code>using namespace std;</code> in a <code>.cpp</code> file is okay because the namespace <code>std</code> is
just dumped out in a single compilation unit. I do not have to worry about it
in other files.</p>
<p>It becomes a totally different story once you put that <code>using namespace std;</code>
into a header file. Then every other header or source file that includes it
will have that namespace dumped out. Even other projects using that library
will suffer from the attempt to save some typing of the library programming.</p>
<h3 id="multiple-files-with-same-include-guard">Multiple files with same include guard</h3>
<p>I do not like the <code>#ifndef X</code>, <code>#define X</code>, <code>#endif</code> style include guards
because they are so error prone. They are hard to read but even worse, one can
choose the same include guard twice in a project. One could even have the same
include guard that some other library already has used.</p>
<p>If that is the case, the errors will be painfully subtle. Depending on the
order if inclusion, the last header file will just not be included. Then you
get errors about undefined types and undefined functions and might pull out
your hair before you realize what is going on.</p>
<p><code>#pragma once</code> is a good alternative except if you are working with IBM XL 12.
But that compiler cannot do C++11, so it is not that interesting for me anyway.</p>
<h3 id="include-guards-do-not-match-the-filename">Include guards do not match the filename</h3>
<p>If you have <code>#ifndef FOO_H</code> in <code>bar.h</code>, bad things will happen when you create
another <code>foo.h</code>. Therefore the include guard should always be derived from the
path, or use <code>#pragma once</code>.</p>

<p>Using C functions in C++ might be a reasonable thing to do. If you do that, do
not include <code>X.h</code> but rather <code>cX</code>. So instead of <code>&lt;stdint.h&gt;</code> use <code>&lt;cstdint&gt;</code>.
This way the C functions will be properly in the <code>std</code> namespace.</p>
<p>Functions like <code>printf</code>, <code>scanf</code>, <code>atoi</code>, <code>fopen</code>, <code>malloc</code>, and a bunch of
others should not be used in C++. There are so much better ways.</p>
<h3 id="include-inside-namespaces">
<code>include</code> inside namespaces</h3>
<p>For reason unknown to me, there are a few includes of standard library headers
inside of namespaces. The only reason I can think of is that writing <code>::std::</code>
instead of <code>std::</code> seemed too much work.</p>
<p>GCC 6.0 has changed the standard headers such that they do not work when you
include them inside a namespace. This way one can catch this anti-pattern.</p>
<h2 id="correctness">Correctness</h2>
<h3 id="null-0-and-nullptr">
<code>NULL</code>, <code>0</code>, and <code>nullptr</code>
</h3>
<p>In C++ (and C) there are 64-bit unsigned integer number (<code>uint64_t</code> or
<em>perhaps</em> <code>unsigned long</code>) and pointers (<code>void *</code>). In the machine, they are
exactly the same thing, 64-bit unsigned integer numbers. For the type system,
it still makes a great difference.</p>
<p>Although they are both just numbers to the computer, one should help the
programmers read the source code and write</p>
<pre><span></span><code><span>uint64_t</span> <span>number</span> <span>=</span> <span>0</span><span>;</span>
<span>void</span> <span>*</span><span>pointer</span> <span>=</span> <span>NULL</span><span>;</span>
</code></pre>


<p>This way, it is clear that one is number-zero and the other is pointer-null.
The preprocessor constant <code>NULL</code> is just <code>0</code> or <code>0u</code>, so the compiler always
sees a plain 0 there. Still it is helpful for the programmer to read. In C++11
there even is <code>nullptr</code> which has the correct type, <code>nullptr_t</code>.</p>
<p>In some code you see horrible things like these:</p>
<pre><span></span><code><span>uint64_t</span> <span>number</span> <span>=</span> <span>NULL</span><span>;</span>
<span>void</span> <span>*</span><span>pointer</span> <span>=</span> <span>0x0</span><span>;</span>
</code></pre>


<h3 id="casting-pointers-to-integers">Casting pointers to integers</h3>
<p>For some reason in one project, pointers are casted to integers. And they are
converted to a special type of integer that you have to choose as a flag to
<code>configure</code> such that the length of that integer is the exact same as the
pointer length, otherwise the compiler would give you an error.</p>
<p>I still do not understand why one would do this sort of brittle code.</p>
<h3 id="subtle-dependence-on-operator-precedence">Subtle dependence on operator precedence</h3>
<p>What is the value of <code>x</code>?</p>
<pre><span></span><code><span>uint32_t</span> <span>x</span> <span>=</span> <span>1</span> <span>&lt;&lt;</span> <span>3</span> <span>-</span> <span>1</span><span>;</span>
</code></pre>


<p>I would read it as $2^3 - 1$ and that is seven. The value actually is four.
When compiling with Clang, it conveniently says this:</p>
<pre><span></span><code><span>precedence.cpp:7:25: warning: operator '&lt;&lt;' has lower precedence than '-'; '-' will be evaluated first</span>
<span>      [-Wshift-op-parentheses]</span>
<span>    uint32_t x = 1 &lt;&lt; 3 - 1;</span>
<span>                   ~~ ~~^~~</span>
<span>precedence.cpp:7:25: note: place parentheses around the '-' expression to silence this warning</span>
<span>    uint32_t x = 1 &lt;&lt; 3 - 1;</span>
<span>                        ^</span>
<span>                      (    )</span>
</code></pre>


<p>What did the original author of that line really mean? Was he aware that the
<code>-</code> operation binds stronger than <code>&lt;&lt;</code>? Can I trust that code without
completely understand where all those magic numbers come from?</p>
<h3 id="not-using-raii">Not …</h3></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://martin-ueding.de/posts/cpp-antipatterns/">https://martin-ueding.de/posts/cpp-antipatterns/</a></em></p>]]>
            </description>
            <link>https://martin-ueding.de/posts/cpp-antipatterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25867068</guid>
            <pubDate>Fri, 22 Jan 2021 01:26:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SSRIs are a class of medications that blunt emotions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25866787">thread link</a>) | @apsec112
<br/>
January 21, 2021 | https://lorienpsych.com/2020/10/25/ssris/ | <a href="https://web.archive.org/web/*/https://lorienpsych.com/2020/10/25/ssris/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div>	
						<p><b>The short version:</b> SSRIs are a class of medications that blunt negative emotions, used for depression, anxiety, anger, etc. My usual regimen is to start Lexapro 5 mg, go up to 10 mg after one week, and potentially go up to 20 mg later if that isn’t enough. The most common side effects are loss of sex drive and decreased emotional range; other side effects include tiredness, wiredness, weight gain, etc. You can go into withdrawal if you stop SSRIs, especially if you stop them suddenly. A good doctor can help you avoid or manage this withdrawal, and you shouldn’t let it scare you out of taking SSRIs if you need them. </p>
<p><b>The long version:</b></p>

<h5 id="anchor1"><span id="1_What_do_SSRIs_do">1. What do SSRIs do?</span></h5>
<p>SSRIs blunt the intensity of emotions. At low doses, they mostly blunt negative emotions; at high doses, they blunt all emotions.</p>
<p>The usual narrative is that SSRIs are “antidepressants”, with emotional blunting as a side effect. I think that’s an oversimplification. SSRIs have no particular relationship to depression – they’re approved for anxiety, social anxiety, OCD, panic disorder, eating disorders, mood issues related to menstruation, etc, etc. Whatever’s giving you negative emotions, it’s a pretty good chance SSRIs will blunt them.</p>
<p>It’s a little more complicated than this, because SSRIs also treat some non-emotional symptoms of depression. For example, if you have depression, and your depression makes it hard for you to focus, and then you take an SSRI, and your depression gets better, you’ll focus better. I think this is best understood in the context of dynamic systems models, where some problems cause other problems in a long complicated cascade. Your negative emotions were making it hard for you to focus; once they’re gone, focusing gets easier again. I don’t want to deny the possibility that SSRIs have special disease-modifying effects too, I’m just not completely convinced.</p>
<p>I use this nonstandard explanation of SSRI effects because it helps cut through some of the questions that bog people down. The most common question is “How can I be sure I <i>really</i> have <i>real</i> depression or a <i>real</i> anxiety disorder?” This question is meaningless; people don’t neatly separate into two groups, “has an anxiety disorder” and “doesn’t have an anxiety disorder”. There’s just a spectrum of people with more or fewer or different anxiety symptoms. If you have enough anxiety that it’s significantly interfering with your life, and you don’t have any good way to get rid of whatever’s causing your anxiety, then you might want to try an SSRI to blunt your negative emotions.</p>
<p>A lot of other people get bogged down in the question of whether their depression/anxiety is “chemical” or because of “life events” (in technical terms, “endogenous” vs. “exogenous”). There is currently no strong evidence for or against the claim that SSRIs treat endogenous depression better than they treat exogenous (see <a href="https://psycnet.apa.org/record/1981-10962-001">1</a>, <a href="https://psycnet.apa.org/record/1985-12157-001">2</a>, <a href="https://www.cambridge.org/core/journals/the-british-journal-of-psychiatry/article/situational-depression-validity-of-the-concept/B6F7CD46C205D3A08866E7973644548C">3</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/3799826/">4</a>, <a href="https://sci-hub.st/https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1600-0447.1996.tb09872.x">5</a>, <a href="https://www.tandfonline.com/doi/pdf/10.1080/15622975.2018.1492736">6</a> for various conflicting claims), and current guidelines don’t distinguish between them.  Some people are confused to hear that medications can help with problems caused by life events. But this shouldn’t be so surprising – alcohol, marijuana, and other recreational drugs also (temporarily) relieve anxiety, regardless of cause. There are many specific differences between these drugs and SSRIs, but the basic principle is the same. If you have some negative emotions, for whatever reason, SSRIs will blunt them.</p>
<p>In case I’m sounding like a pharma company shill, keep in mind that you don’t always want your emotions blunted. Some negative emotions are useful – normal physiological anxiety is your brain’s way of telling you not to poke lions with sticks. And at very high doses, SSRIs can blunt positive emotions along with the negative. People at these doses tend to describe themselves as feeling like zombies or robots, and as not being able to feel or enjoy anything.</p>
<p>But if you’re having extreme, intolerable negative emotions, and you want something to reduce their intensity, SSRIs may be a good choice for you.</p>
<h5 id="anchor1"><span id="2_How_do_SSRIs_work">2. How do SSRIs work?</span></h5>
<p>The short answer is: nobody knows!</p>
<p>SSRIs block the serotonin transporter, a protein that takes serotonin out of synapses (the gaps between neurons). That means serotonin stays in the synapses longer. That means they raise the effective amount of serotonin in your brain.</p>
<p>And that blunts negative emotions? Unclear. For one thing, SSRIs block the serotonin transporter instantly, but SSRIs take about a month to work. One theory is that it takes a month to desensitize serotonin autoreceptors, another kind of protein that would otherwise adjust for this effect and cancel it out. Another theory is that this works through <a href="https://www.nature.com/articles/1301571">a much more complicated cascade of actions</a> where serotonin, over the course of weeks, upregulates a chemical called BDNF, which causes the creation of new synapses throughout the brain. Probably this is good in some way, though we don’t yet understand exactly how.</p>
<p>All of this is still very preliminary. We know that serotonin must be involved in mood somehow, because there are dozens of different antidepressants whose only commonality is that they all affect serotonin (or closely related monoamines like norepinephrine). And we know that deliberately depleting <a href="https://journals.sagepub.com/doi/abs/10.1177/0269881108099424">lab animals</a> <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3941748/">and humans</a> of serotonin makes them depressed. But right now we can’t say much more than that.</p>
<h5 id="anchor3"><span id="3_How_effective_are_SSRIs">3. How effective are SSRIs?</span></h5>
<p>In 1998, Irving Kirsch published <a href="http://web.archive.org/web/19980715085305/http://journals.apa.org/prevention/volume1/pre0010002a.html">a meta-analysis</a> showing that most benefits of antidepressants were due to placebo. In 2008, he published <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2253608/">a better, more complete</a> meta-analysis showing the same thing. In 2018, a team led by Andrea Cipriani published <a href="https://lorienpsych.com/2020/10/25/ssris/www.thelancet.com/journals/lancet/article/PIIS0140-6736(17)32802-7/fulltext">its own meta-analysis</a>, and although the statistics are confusing and nobody really remarked on this at the time, it mostly confirmed Kirsch’s estimate of antidepressant efficacy.</p>
<p>Let’s go over exactly what was found. Kirsch reports his statistics in effect size. Antidepressants, on average, had an effect size of 1.2. But on closer inspection, about 0.9 of that was placebo, and only 0.3 of that was the drug itself. A lot of people had a lot of debate over whether those numbers were exactly accurate, but after Cipriani’s contribution I think it’s fair to say that they are close.</p>
<p>Kirsch argued that this should turn us against antidepressants. Conventionally, effect sizes of 0.2 are considered “small”, 0.5 “medium”, and 0.8 “large”. 0.3 is small, and in fact so small it’s probably clinically insignificant – the average patient (or doctor) might not even notice it. So although antidepressants themselves have a large effect size (1.2), most of that is placebo, and the drug itself is so small we shouldn’t care about it very much.</p>
<p>I have three qualms with Kirsch’s analysis.</p>
<p>First, antidepressants tend to have smaller effect sizes when measured on formal instruments (as Kirsch’s studies did) than when measured by patient preference. That is, there are a bunch of tests that ask you a bunch of questions about your feelings and symptoms, and you can add them up and call that a “depression score”, and if you do that, antidepressants have an effect size of 0.3. Or you can ask patients “how depressed do you feel on a scale of 1-10”, and <a href="https://slatestarcodex.com/2020/04/06/sscjc-real-world-depression-measurement/">if you do that</a>, antidepressants have an effect size of 0.5. I think the latter is better, because it’s what we actually care about (how patients are doing), and the tests are kind of dumb and ask about a lot of symptoms most people realistically aren’t experiencing. So plausibly we should think of antidepressants as having an effect size of 0.5, which is at least “medium”.</p>
<p>But second, antidepressants aren’t a one-size-fits-all solution. Suppose 50% of patients are “responders” and 50% are “nonresponders” (source: personal experience; <a href="https://effectivehealthcare.ahrq.gov/products/depression-treatment-ssri/research-protocol">this study</a> gives similar numbers but this sort of thing is very hard to operationalize and I will just go with personal experience). If the total population has an average effect size of 0.5, then responders must have an average effect size of 1.0. Nobody ever claimed SSRIs work for everyone – just that in the people who they work for, they do a good job. As for the other people, they stop their medication trial after a month and try something else, which will hopefully work for them. The situation is actually even more complex than this, because a small minority of patients do <i>worse</i> on SSRIs. These patients bring down everyone’s average, and then studies find that “on average” “participants” only get an effect size of 0.5. Fine, but in real life the people who felt worse on SSRIs would have stopped them immediately. </p>
<p>And third, if you count the placebo effect, Kirsch’s studies showed SSRIs work super great. Of course, it’s kind of embarrassing to be relying on placebo effects, especially when you’re giving an active drug with real side effects. But do you have any better ideas? I can’t actually give out sugar pills; they’d take away my license. And you can’t voluntarily take sugar pills and pretend they’re antidepressants, because you know what you’re doing. </p>
<p>So my reading of Kirsch is something like: antidepressants will work for about 50% of people. For those people, they will have a large real effect size of 1.0, plus a large placebo effect size of 0.9, for a very large total effect size of 1.9. </p>
<h6 id="anchor31"><span id="31_Are_antidepressants_just_active_placebos">3.1: Are antidepressants just “active placebos”? </span></h6>
<p>Kirsch also added that maybe the apparent non-placebo effect of SSRIs was just because the drugs were “active placebos” as opposed to the “passive placebo” of a sugar pill. That is, the drugs caused real side effects, which made people realize they were taking an active medication, making it feel “more real” than a simple placebo and ruining blinding.</p>
<p>But this time he’s just wrong. See eg <a href="http://ajp.psychiatryonline.org/article.aspx?articleid=173998">Quitkin et all (2000)</a>, which finds that giving placebos with side effects doesn’t increase placebo response rate, and <a href="https://sci-hub.st/https://pubmed.ncbi.nlm.nih.gov/29155804/">Hieronymous et al (2017)</a>, which finds the same real antidepressant efficacy even in the subgroup of patients who have no side effects.</p>
<h5 id="anchor4"><span id="4_Which_SSRI_is_the_best">4. Which SSRI is the best?</span></h5>
<p>Different SSRIs have different advantages …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lorienpsych.com/2020/10/25/ssris/">https://lorienpsych.com/2020/10/25/ssris/</a></em></p>]]>
            </description>
            <link>https://lorienpsych.com/2020/10/25/ssris/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25866787</guid>
            <pubDate>Fri, 22 Jan 2021 00:43:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adderall]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25866760">thread link</a>) | @apsec112
<br/>
January 21, 2021 | https://lorienpsych.com/2020/10/30/adderall/ | <a href="https://web.archive.org/web/*/https://lorienpsych.com/2020/10/30/adderall/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div>	
						<p><b>The short version:</b> Adderall is an effective treatment for ADHD, generally preferred to Ritalin in adults. Typical doses are between 5 mg and 60 daily, usually split up throughout the day. Adderall XR is long-acting Adderall. Vyvanse is very long-acting Adderall that gives some people fewer side effects. Risks are relatively low if you stick to the prescribed amount. Most common side effects are loss of appetite, feeling wired and jittery, headaches, sleep problems, and a “crash” when it runs out. If you get the crash, taper your doses, switch to XR or Vyvanse, or supplement with l-tyrosine. Anything that makes your stomach more acidic or alkaline will change your level of Adderall, sometimes dramatically.</p>
<p><b>The long version:</b></p>

<h5 id="anchor1"><span id="1_Is_Adderall_the_right_stimulant_for_me">1. Is Adderall the right stimulant for me?</span></h5>
<p>There are two commonly used families of stimulant for ADHD: Adderall and Ritalin. Most adults will find drugs in the Adderall family more effective.</p>
<p>See for example <a href="https://www.additudemag.com/adderall-ritalin-adhd-medication-comparison/">this survey of 4,425 ADHD patients by ADDitude Magazine</a>, where 52% of adult Adderall users described their treatment as very effective, compared to only 41% of adult Ritalin users. Only 12% of Adderall users described it as ineffective, compared to 22% of Ritalin users.</p>
<p>More formal studies find the same thing. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2810184/">Faraone</a> does a meta-analysis comparing both drugs in children (not exactly our population of interest, but this is the best I can find) and finds Ritalin to have an effect size of around 0.9 and Adderall of around 1.3 (higher means more effective). A separate meta-analysis by <a href="https://www.researchgate.net/publication/327075331_Efficacy_Acceptability_and_Tolerability_of_Lisdexamfetamine_Mixed_Amphetamine_Salts_Methylphenidate_and_Modafinil_in_the_Treatment_of_Attention-Deficit_Hyperactivity_Disorder_in_Adults_A_Systematic_Re">Stuhec, Lukic, and Locatelli</a> finds two Adderall-family drugs to have effect sizes of 0.6 – 0.9, compared to Ritalin’s 0.5.</p>
<p>About 80% of my patients who have tried both tell me they prefer Adderall (informal estimate). Along with Adderall being more effective, they complain that Ritalin makes them feel more “robotic” (note the Additude survey shows Ritalin users about half again as likely to complain of “dampened personality”). This isn’t to say that Adderall is better for everyone – just that it’s a better choice to try first.</p>
<p>Does Ritalin have any advantages? The main advantage is that it’s considered harder to get addicted to. But addiction to ADHD drugs is already very unlikely (see the section on Addiction below), and realistically it’s less addictive because it is a worse drug which people like less. Also, there are now members of the Adderall family at least equally suitable for people at risk of addiction (see the section on Vyvanse below). Another Ritalin advantage is that it lasts less time, so if you want very fine-grained control over exactly when you are or aren’t stimulated Ritalin may be a better choice. But you probably do not need this much control. I understand Ritalin may have other advantages for children, but I’m not a child psychiatrist and don’t understand it well enough to comment on.</p>
<h5 id="anchor2"><span id="2_What_medications_are_in_the_Adderall_family_What_are_the_advantages_and_disadvantages_of_each">2. What medications are in the Adderall family? What are the advantages and disadvantages of each?</span></h5>
<p>The Adderall family is based around a chemical called amphetamine. Like many organic chemicals, it comes in two mirror-image versions, d-amphetamine (“right-handed amphetamine”) and l-amphetamine (“left-handed amphetamine”). Most of the psychiatric benefits of amphetamine come from d-amphetamine, but a small number of people may respond better to l-amphetamine, or l-amphetamine might modulate the effects of d-amphetamine, or there might be some other reason why l-amphetamine might be good. Nobody understands this very well.</p>
<p><u>Adderall</u> itself is 75% d-amphetamine and 25% l-amphetamine. More specifically, it’s a combination of four different kinds of amphetamine salts, two of which are 50-50 d/l, and two of which are 100% d (this is why sometimes Adderall bottles will say “mixed amphetamine salts”). In theory, having so many different salts means they all take different amounts of time to dissolve, and so instead of hitting you like a freight train and then crashing like a missile, you’ll gradually get more and more stimulated as the different salts dissolve one by one, then get less and less stimulated as they exhaust themselves one by one. There isn’t a huge amount of research showing this actually works and we currently just take it on faith.</p>
<p><u>Dexedrine</u> is 100% d-amphetamine. Sometimes if people have side effects on Adderall, they won’t have those side effects on Dexedrine, presumably because the l-amphetamine was causing the side effects. Most people slightly prefer Dexedrine to Adderall, but this one <i>does</i> hit you like a freight train and a lot of people prefer to avoid it for that reason.</p>
<p><u>Evekeo</u> is a 50-50 d/l mix, ie it has even more of the possibly-useless l-amphetamine than Adderall does. There isn’t any great reason to try this one, although some researchers think a few people with odd genetics might respond better to the l than the d version, so if somebody somehow knew they were one of those people they could give Evekeo a try. Mostly pharma companies just invented this to have a new form of Adderall they could sell for a little extra money since it was newer; unless you have very odd biochemistry you should probably ignore it.</p>
<p><u>Vyvanse</u> is lisdexamphetamine. That is, it’s 100% d-amphetamine, like Dexedrine, but the d-amphetamine is attached to an inert molecule called lysine. Your body gradually removes the lysine, meaning that the d-amphetamine takes effect only very gradually, instead of hitting you like a freight train. In theory this combines the advantage of Dexedrine (gives you the pure active form without extra side effects from l-amphetamine) with the advantages of Adderall (comes on more gradually). Most of my patients give it very high ratings, and I think it succeeds at being the best of all worlds. Except it’s still on-patent, which means it costs ~10x as much as any other form of Adderall, so most people will want to give it a pass until the price comes down in a few years. One group who may want to consider it are people at high risk of addiction. Because your body processes Vyvanse so slowly, it’s (in theory) impossible to abuse – no matter how much you snort or inject or overdose on or whatever, it will still convert to the active form gently and gradually (but please don’t test this). These people should ask their insurance about helping them afford this medication.</p>
<p><u>Adderall XR</u> is Adderall in a special capsule that makes it last longer – 8 hours instead of 4. This is useful for people who need Adderall for the entire day, but don’t want to / won’t remember to take a second pill. Some people also find it’s more gradual than taking two pills – instead of up-down-up-down it’s a single smooth “hill”. Other people don’t find this is true (and if someone in this second group of people needs smoother dosing, they will have to get Vyvanse).</p>
<p><u>Zenzedi</u> is just Dexedrine XR.</p>
<p><u>Mydayis, Adzenys, Dyanavel</u>, etc, etc, etc, are other attempts to make Adderall last different amounts of time, similar to Adderall XR but using slightly different technology. These all cost more and have ridiculous names and I have never been able to figure out any situation when I would ever want to use them. You can probably safely ignore all of these and get on with your life.</p>
<p><u>Desoxyn</u> is prescription methamphetamine. Methamphetamine is a faster-acting, stronger, and more addictive form of amphetamine. It is 100% legal to prescribe it for ADHD, but I have never been brave enough to try, so I cannot give expert commentary on it. Anecdotally, patients who have used this say it is <i>amazing</i>. I have no reason to doubt them, but would recommend avoiding it anyway.</p>
<h5 id="anchor3"><span id="3_How_should_I_know_which_medication_in_the_Adderall_family_to_try">3. How should I know which medication in the Adderall family to try?
</span></h5><p>I tell my patients to start with Adderall. If they get too many side effects, I try to switch them to Dexedrine. </p>
<p>If one of those two works, then we try to determine the right schedule for them. Some patients prefer shorter-acting medications so they have more control over dosing – for example, they might want to take an Adderall in the morning so they can concentrate in class, but have it out of their system in the afternoon so they can relax and hang out with friends. Other patients prefer longer-acting medication because they expect to need it all day. Patients who prefer short-acting can stay on Adderall or Dexedrine; patients who prefer long-acting can switch to Adderall XR or Zenzedi.</p>
<p>If a patient has a history of addiction, or finds that even an XR medication doesn’t last long enough, or experiences their medication as a series of annoying jumps and crashes throughout the day – and has good enough insurance to afford it – I may switch them to Vyvanse.</p>
<h5 id="anchor4"><span id="4_What_are_possible_side_effects_of_Adderall">4. What are possible side effects of Adderall?</span></h5>
<p>The most common side effects of Adderall (percentages cobbled together in an unprincipled way from <a href="https://www.additudemag.com/adderall-ritalin-adhd-medication-comparison/">here</a> and <a href="https://www.additudemag.com/2017-adhd-treatment-survey-findings/">here</a>) are:</p>
<p>Loss of appetite: 35%<br>
Sleep disturbances: 28%<br>
Irritability: 25%<br>
Dampened personality: 11%</p>
<p>…but all of these numbers need big asterisks next to them.</p>
<p>Loss of appetite is most common when first starting Adderall. After a few weeks, most people will find their appetite comes back. If someone keeps having low appetite on Adderall, they can usually find a dosing schedule where they eat breakfast before they take it and dinner after it wears off. If they want lunch too, they might need to use a short-acting form of Adderall so they can eat lunch after it runs out, then take a second one for the afternoon.</p>
<p>Sleep disturbances are very predictable: they happen if Adderall is still in your body when you’re trying to sleep. You can avoid these by taking Adderall earlier in the morning, or by taking a shorter-acting form of the medication. I have only very rarely had any patients who still have trouble with sleep after getting this explained to them.</p>
<p>Irritability can go either way. Some people are very irritable on Adderall. Other people are less irritable.</p>
<h5 id="anchor5"><span id="5_Are_there_long-term_side_effects_of_Adderall">5. Are there long-term side effects of Adderall?</span></h5>
<p>As with any medication, it’s hard to say for sure because we cannot ethically …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lorienpsych.com/2020/10/30/adderall/">https://lorienpsych.com/2020/10/30/adderall/</a></em></p>]]>
            </description>
            <link>https://lorienpsych.com/2020/10/30/adderall/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25866760</guid>
            <pubDate>Fri, 22 Jan 2021 00:39:24 GMT</pubDate>
        </item>
    </channel>
</rss>
